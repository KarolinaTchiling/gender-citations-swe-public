FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Jia, DY
   Zhou, JL
   Zhang, CAW
AF Jia, Dongyao
   Zhou, Jialin
   Zhang, Chuanwang
TI Detection of cervical cells based on improved SSD network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SSD network; Cell classification; Target detection
ID CANCER; CLASSIFICATION; APPEARANCE
AB Cervical cancer has influenced life of women worldwide as the fourth most severe cancer. Early screening, detection and treatment of cervical cancer notably increase the life quality and reduce the death rate of patients. Therefore, automatic diagnosis of cervical cancer could bridge the gap between testing needs and capabilities. Cervical cell detection plays an important role in cancer screening, the intent of this study is to classify the cervical cells through deep learning models, which helps to monitor the patients' health. SSD (Single Shot MultiBox Detector) network is integrated with the positive and negative features to address the shortcomings of insufficient sensitivity to small objects. Besides, center loss function is added to better address situations that intra-class differences are greater than inter-class differences. A dataset containing 1462 benchmarked cervical cells was utilized. 80% (1167) are used for training and the remaining 20% (295) are allocated for testing. Proposed optimized SSD network achieved the accuracy of 90.8% and mAP (mean Average Precision) of 81.53%, which is 7.54% and 4.92% higher than YOLO (You Only Look Once) and classical SSD, respectively. The addition of complementary features improves the network sensitivity and the overall accuracy. It is also concluded that the proposed SSD network could be applied in cell classification for the early automatic detection of cervical cancer.
C1 [Jia, Dongyao; Zhang, Chuanwang] Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
   [Zhou, Jialin] China Telecommun Technol Labs, 52 Huayuan North Rd, Beijing 100191, Peoples R China.
C3 Beijing Jiaotong University
RP Zhang, CAW (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
EM cwzhang1995@qq.com
CR Agrawal S., 2017, IOSR J DENT MED SCI, V16, P67, DOI [10.9790/0853-1602046773, DOI 10.9790/0853-1602046773]
   Arbyn M, 2020, LANCET GLOB HEALTH, V8, pE191, DOI 10.1016/S2214-109X(19)30482-6
   Arya M, 2018, IET COMPUT VIS, V12, P1049, DOI 10.1049/iet-cvi.2018.5349
   Basheer S, 2019, J COMPUT THEOR NANOS, V16, P2523, DOI DOI 10.1166/JCTN.2019.7925
   Buggenthin F, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-297
   Dewi EM, 2019, INT J ONLINE BIOMED, V15, P91, DOI 10.3991/ijoe.v15i02.9796
   Dong N, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106311
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gorantla R, 2019, IEEE INT C BIOINF BI, P397, DOI 10.1109/BIBE.2019.00078
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang P, 2020, IEEE ACCESS, V8, P24219, DOI 10.1109/ACCESS.2020.2970121
   Iliyasu AM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122935
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Jia ADY, 2020, NEUROCOMPUTING, V411, P112, DOI 10.1016/j.neucom.2020.06.006
   Khamparia A, 2020, J SUPERCOMPUT, V76, P8590, DOI 10.1007/s11227-020-03159-4
   Kido S, 2018, PROC INT WORKSH ADV
   Kuko M, 2020, INFORM SYST FRONT, V22, P1039, DOI 10.1007/s10796-020-10028-1
   Kurnianingsih, 2019, IEEE ACCESS, V7, P116925, DOI 10.1109/ACCESS.2019.2936017
   Li KX, 2018, EUR J RADIOL, V106, P160, DOI 10.1016/j.ejrad.2018.07.024
   Lin HM, 2019, IEEE ACCESS, V7, P71541, DOI 10.1109/ACCESS.2019.2919390
   Lin YC, 2020, EUR RADIOL, V30, P1297, DOI 10.1007/s00330-019-06467-3
   Lu JY, 2020, FUTURE GENER COMP SY, V106, P199, DOI 10.1016/j.future.2019.12.033
   Malli P., 2017, Int J Emerg Trend Technol Comput Sci (IJETTCS), V6, P145
   Momenimovahed Z, 2017, BIOMED RES THER, V4, P1795, DOI 10.15419/bmrat.v4i12.386
   Priyadharson, 2018, ANN RES REV BIOL, V24, P1, DOI [10.9734/ARRB/2018/37826, DOI 10.9734/ARRB/2018/37826]
   Prum S., 2018, 2018 4 INT C ADV COM, P1, DOI 10.1109/ICACCAF.2018.8776766
   Rayavarapu K., 2018 International Conference on Current Trends towards Converging Technologies (ICCTCT), Coimbatore, P1, DOI DOI 10.1109/ICCTCT.2018.8551176
   Redmon J., 2018, COMPUTER VISION PATT
   Shiraz A, 2020, CYTOPATHOLOGY, V31, P258, DOI 10.1111/cyt.12835
   Singh N., 2020, ARXIV PREPRINT ARXIV
   Singh SK, 2020, INT J HEALTHC INF SY, V15, P1, DOI 10.4018/IJHISI.2020040101
   Sompawong N, 2019, IEEE ENG MED BIO, P7044, DOI [10.1109/embc.2019.8856369, 10.1109/EMBC.2019.8856369]
   Sun G., 2017, INT J PERFORMABILITY, V13, P446, DOI [10.23940/ijpe.17.04.p12.446457, DOI 10.23940/IJPE.17.04.P12.446457]
   Thohir Muhammad, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P373, DOI 10.1109/ICAIIC48513.2020.9065027
   Wentzensen N, 2021, JNCI-J NATL CANCER I, V113, P72, DOI 10.1093/jnci/djaa066
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
   Xu T, 2017, PATTERN RECOGN, V63, P468, DOI 10.1016/j.patcog.2016.09.027
   Yoo TK, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103628
   Yuan L., 2017, INT SOC OPT PHOTON, V10420
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
NR 41
TC 20
Z9 22
U1 6
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13371
EP 13387
DI 10.1007/s11042-021-11015-7
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000653635900001
DA 2024-07-18
ER

PT J
AU Thanki, R
   Kothari, A
   Borra, S
AF Thanki, Rohit
   Kothari, Ashish
   Borra, Surekha
TI Hybrid, blind and robust image watermarking: RDWT - NSCT based secure
   approach for telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind; Non-subsampled Contourlet transform (NSCT); Medical image;
   Redundant discrete wavelet transform (RDWT); Robustness; Watermarking
ID CONTOURLET TRANSFORM; MEDICAL IMAGES; DCT-SVD; SCHEME
AB Images frequently are helpless to burglary and copyright encroachment. There are numerous events where pictures were illegally copied from websites for utilization or monetary profit and were gotten away from equity, prompting misfortunes for the battled proprietors or innovators. Techniques for securing and recognizing digital pictures and their owners from adversaries are thus required. In this paper, a watermarking procedure in hybrid domain is proposed for copyright assurance of images. The strategy inserts watermarks in Non-Subsampled Contourlet Transform (NSCT) and Redundant Discrete Wavelet Transform (RDWT) areas to accomplish better invisibility, and robustness. The blind extraction of watermark can be performed associating the arbitrarily produced PN arrangements. The experimental results demonstrate that the combination of NSCT - RDWT improves the nature of watermarked image when tried on standard and medical images. The experimental results indicated that the proposed scheme provides good imperceptibility and robustness against various kind of watermarking attacks. The main strength of proposed scheme is that it provides good imperceptibility for watermarked images up to 58 dB along with good robustness for watermark image up to 0.99 against various types of attacks and equally works for various kind of images such as greyscale and medical images. Further, the performance of proposed scheme indicated that the quality of generated watermarked medical image has fulfilled all parameters and benefits for secure telemedicine applications.
C1 [Thanki, Rohit] Progn Labs Tech FZCO, Dubai, U Arab Emirates.
   [Kothari, Ashish] Atmiya Univ, Rajkot, Gujarat, India.
   [Borra, Surekha] KS Inst Technol, ECE Dept, Bangalore, Karnataka, India.
RP Thanki, R (corresponding author), Progn Labs Tech FZCO, Dubai, U Arab Emirates.
EM rohitthanki9@gmail.com
RI Borra, Surekha/AAD-5332-2022; Kothari, Ashish/AFQ-8291-2022; Thanki,
   Rohit/Q-9029-2017
OI Borra, Surekha/0000-0002-1842-806X; Kothari, Ashish/0000-0002-1981-8465;
   Thanki, Rohit/0000-0002-0645-6266
CR Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Ananthaneni Venkateshwarlu, 2017, INT J IMAGE PROCESSI, V11, P85
   [Anonymous], 2008, ELCVIA ELECT LETT CO, DOI DOI 10.5565/REV/ELCVIA.267
   [Anonymous], 2017, P 15 INT C STAT SCI
   [Anonymous], 2009, ADAPTIVE WATERMARKIN
   [Anonymous], 2015, Trend Watch
   [Anonymous], 2012, INT J NETW SECUR
   [Anonymous], 2017, MEDPIXTM MEDICAL IMA
   [Anonymous], 2011, INT J COMPUTER APPL
   Aparna P, 2020, J INTELL SYST, V29, P1558, DOI 10.1515/jisys-2018-0370
   Bajaj A, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ENGINEERING AND TECHNOLOGY RESEARCH (ICAETR)
   Borra S, 2017, FRONT ARTIF INTEL AP, V296, P450, DOI 10.3233/978-1-61499-785-6-450
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das S., 2011, INT C PATTERN RECOGN, P288
   Dey N, 2017, STUD COMPUT INTELL, V660, P345, DOI 10.1007/978-3-319-44790-2_16
   Dey N, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P224, DOI 10.1109/WICT.2012.6409079
   Dey N, 2012, INT CONF INTELL SYST, P680, DOI 10.1109/ISDA.2012.6416619
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Gavini NS, 2014, IEEE REGION 10 SYMP, P73, DOI 10.1109/TENCONSpring.2014.6863000
   Hien TD, 2006, ADV SOFT COMP, V34, P401, DOI 10.1007/3-540-31662-0_31
   Hong-Ying Y, 2011, COMPUT ELECTR ENG, V37, P695, DOI 10.1016/j.compeleceng.2011.07.002
   Jayalakshmi M, 2006, INT C PATT RECOG, P861
   Kahlessenane F, 2020, J AMB INTEL HUM COMP, P1
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kothari, 2016, INTELLIGENT ANAL MUL, P431
   Kumar C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4912
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mohanpurkar AA, 2016, INT J AMBIENT COMPUT, V7, P114, DOI 10.4018/IJACI.2016070106
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Patil Harsha M., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P302, DOI 10.1109/ICGTSPICC.2016.7955316
   Reddy, 2012, P 3 INT C COMP COMM, P1
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Singh, 2015, THESIS NIT KURUKSHE
   Singh MK, 2021, IET IMAGE PROCESS, V15, P666, DOI 10.1049/ipr2.12052
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2018, HDB RES INFORM SECUR
   Thanki R., 2017, INFORMATICA, V41
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   University of South Carolina, 2017, SIPI IMAGE DATABASE
   Wang Z., 2017, Digital Video image quality and perceptual coding, P225, DOI DOI 10.1201/9781420027822-7
   Wang ZQ, 2007, LECT NOTES COMPUT SC, V4688, P307
   Yassin, 2015, INT J COMPUT APPL, V129, P30, DOI DOI 10.5120/IJCA2015907183
   Yuan XC, 2018, SIGNAL PROCESS, V149, P103, DOI 10.1016/j.sigpro.2018.03.007
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhong Z, 2020, MULTIMED TOOLS APPL, V79, P26225, DOI 10.1007/s11042-020-09044-9
NR 54
TC 20
Z9 20
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27593
EP 27613
DI 10.1007/s11042-021-11064-y
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652455100002
DA 2024-07-18
ER

PT J
AU Banerjee, S
AF Banerjee, Suman
TI Designing and connectivity checking of implicit social networks from the
   user-item rating data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Rating data; Clique; Connected component
ID EXPLICIT
AB Implicit Social Network is a connected social structure among a group of persons, where two of them are linked if they have some common interest. One real-life example of such networks is the implicit social network among the customers of an online commercial house, where there exists an edge between two customers if they like similar items. Such networks are often useful for different commercial applications such as target advertisement, viral marketing, etc. In this article, we study two fundamental problems in this direction. The first one is that, given the user-item rating data of an E-Commerce house, how we can design implicit social networks among its users and the second one is at the time of designing itself can we obtain the connectivity information among the users. Formally, we call the first problem as the Implicit User Network Design Problem and the second one as Implicit User Network Design with Connectivity Checking Problem. For the first problem, we propose three different algorithms, namely 'Exhaustive Search Approach', 'Clique Addition Approach', and 'Matrix Multiplication-Based Approach'. For the second problem, we propose two different approaches. The first one is the sequential approach: designing and then connectivity checking, and the other one is a concurrent approach, which is basically an incremental algorithm that performs designing and connectivity checking simultaneously. Proposed methodologies have experimented with three publicly available rating network datasets such as Flixter, Movielens, and Epinions. Reported computational time shows that the 'Clique Addition Approach' is the fastest one for designing the implicit social network. For designing and connectivity checking problem the concurrent approach is faster than the other one. We have also investigated the scalability issues of the algorithms by increasing the data size.
C1 [Banerjee, Suman] Indian Inst Technol, Dept Comp Sci & Engn, Jammu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) Jammu
RP Banerjee, S (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Jammu, India.
EM suman.banerjee@iitjammu.ac.in
FU Indian Institute of Technology Gandhinagar [MIS/IITGN/PD-SCH/201415/006]
FX Major part of this work was done when the author was a Post Doctoral
   Scholar at the Department of Computer Science and Engineering, IIT
   Gandhinagar. Part of the was supported by the Post Doctoral Fellowship
   Grant provided by Indian Institute of Technology Gandhinagar (Project
   No. MIS/IITGN/PD-SCH/201415/006). A small part of this study has been
   previously published as [4].
CR Aggarwal C, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2601412
   Al-Garadi MA, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3155897
   Alsaleh S, 2011, LECT NOTES COMPUT SC, V6612, P313, DOI 10.1007/978-3-642-20291-9_32
   [Anonymous], 2017, NIPS 2016 TIM SER WO
   Banerjee S, 2020, KNOWL INF SYST, V62, P3417, DOI 10.1007/s10115-020-01461-4
   Banerjee S, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.270-035
   Bl├a┬nser M., 2013, THEORY COMPUTING LIB, V5, P1, DOI [10.4086/toc.gs.2013.005, DOI 10.4086/TOC.GS.2013.005, DOI 10.4086/T0C.GS.2013.005.URL]
   Bonchi F, 2013, J INTELL INF SYST, V40, P211, DOI 10.1007/s10844-011-0181-4
   Chen W., 2010, ACM SIGKDD INT C KNO, P1029, DOI DOI 10.1145/1835804.1835934
   Chiantini L, 2018, B LOND MATH SOC, V50, P369, DOI 10.1112/blms.12147
   Diestel R., 2000, GRAPH THEORY, V173
   Feng CJ, 2020, INFORM SCIENCES, V521, P365, DOI 10.1016/j.ins.2020.02.052
   Frey D, 2011, LECT NOTES COMPUT SC, V6976, P193, DOI 10.1007/978-3-642-24550-3_16
   Goel S, 2014, MARKET SCI, V33, P82, DOI 10.1287/mksc.2013.0817
   Grcar M., 2005, Advances in Web Mining and Web Usage Analysis. 7th International Workshop on Knowledge Discovery on the Web, WebKDD 2005. Revised Papers (Lecture Notes in Artificial Intelligence Vol. 4198), P58
   Gujral E, 2020, PROCEEDINGS OF THE 2020 SIAM INTERNATIONAL CONFERENCE ON DATA MINING (SDM), P577, DOI 10.1137/1.9781611976236.65
   Gupte M, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P109
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Hill S., 2005, VIRAL MARKETING IDEN
   Huh J, 2017, CONSIDERATIONS APPL, DOI [10.4324/9781315623252-29, DOI 10.4324/9781315623252-29]
   Iosup A, 2014, IEEE INTERNET COMPUT, V18, P36, DOI 10.1109/MIC.2014.19
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Le Gall F, 2012, ANN IEEE SYMP FOUND, P514, DOI 10.1109/FOCS.2012.80
   Lin C, 2014, INFORM SCIENCES, V254, P1, DOI 10.1016/j.ins.2013.08.034
   Lin Chen., 2012, Proceedings of the 21st ACM international conference on Information and knowledge management, P1607
   Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201
   Massa Paolo, 2005, AAAI, V1, P121
   Myers SA, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P493, DOI 10.1145/2567948.2576939
   Nauerz A, 2008, P AAAI SPRING S SOC, P60
   Oliveira SEL, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3365375
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Podobnik V, 2015, PROCEDIA COMPUT SCI, V60, P583, DOI 10.1016/j.procs.2015.08.185
   Ram S, 2014, P 25 ACM C HYP SOC M, P190
   Reafee W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154848
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   Roth M., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P233, DOI [10.1145/1835804.1835836, DOI 10.1145/1835804.1835836]
   Rui X, 2020, COMPUTING, P1
   Samadi N, 2019, COMPUTING, V101, P1147, DOI 10.1007/s00607-018-0659-9
   Song M, 2010, AAAI CONF ARTIF INTE, P1425
   Staab S, 2005, IEEE INTELL SYST, V20, P80, DOI 10.1109/MIS.2005.16
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Taheri SM, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1343, DOI 10.1145/3041021.3051153
   Tasnádi E, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1117, DOI 10.1145/2740908.2743037
   Tucker, 2015, ASME IDETC CIE, P15
   Xiao X, 2017, J COMPUT SCI-NETH
   Yang XW, 2013, IEEE T PARALL DISTR, V24, P642, DOI 10.1109/TPDS.2012.192
   Yorke-Smith, 23 INT JOINT C ART I
   Zhang J, 2013, INFORM PROCESS MANAG, V49, P721, DOI 10.1016/j.ipm.2012.07.006
   Zheng, 2012, JOINT INT C PERV COM, P97
NR 49
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26615
EP 26635
DI 10.1007/s11042-021-10876-2
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648024500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, YY
   Wang, RF
   Ren, HL
AF Yang, Yunyun
   Wang, Ruofan
   Ren, Huilin
TI Active contour model based on local intensity fitting and atlas
   correcting information for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atlas correcting information; Local intensity fitting; Medical image
   segmentation
AB Intensity inhomogeneity and noises often occur in real medical images, which present a large degree of challenge to image segmentation. At the same time, most of the existing image segmentation algorithms are sensitive to initial conditions and model parameters. This paper presents an accurate and robust active contour model to solve the above problems. Inspired by the idea of the region-scalable fitting (RSF) model, we first define a local atlas fitting term transformed by the segmentation contour of the coherent local intensity clustering (CLIC) model. Then, we define a new energy functional by merging the atlas term into the energy functional of the RSF model. The advantage of this operation is that it makes full use of the existing segmentation features and advantages of the two models and avoids cumbersome adjustment of model parameters and initial contours. The experimental results clearly show that the improved model not only has better segmentation results than the RSF model and other active contour models such as the LINC, REGAC and SMAP models, but also solves the problem of sensitivity to initial contours, parameters adjustment and noise.
C1 [Yang, Yunyun; Wang, Ruofan; Ren, Huilin] Harbin Inst Technol Shenzhen, HIT Campus Shenzhen Univ Town,G710, Shenzhen 518055, Peoples R China.
C3 Harbin Institute of Technology
RP Yang, YY (corresponding author), Harbin Inst Technol Shenzhen, HIT Campus Shenzhen Univ Town,G710, Shenzhen 518055, Peoples R China.
EM yangyunyun@hit.edu.cn; 18s058441@stu.hit.edu.cn;
   19s058011@stu.hit.edu.cn
OI Wang, Ruofan/0009-0000-8236-1122
CR Bustamante M, 2015, J CARDIOVASC MAGN R, V17, DOI 10.1186/s12968-015-0190-5
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng J, 2006, IEEE INT SYMP CIRC S, P5567
   EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308
   Gong Z., 2017, DIGIT MED, V3, P76
   Guo DQ, 2013, ELECTRON LETT, V49, P1209, DOI 10.1049/el.2012.4256
   Karasawa K, 2017, MED IMAGE ANAL, V39, P18, DOI 10.1016/j.media.2017.03.006
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Lim KY, 2018, EXPERT SYST APPL, V112, P288, DOI 10.1016/j.eswa.2018.06.041
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tanzi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041507
   Tashk Ashkan, 2019, WSEAS Transactions on Systems and Control, V14, P384
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Tashk A, 2019, IJST-T ELECTR ENG, V43, P167, DOI 10.1007/s40998-018-0098-9
   Tor-Díez C, 2018, COMPUT MED IMAG GRAP, V70, P73, DOI 10.1016/j.compmedimag.2018.09.003
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2017, INFORM SCIENCES, V418, P61, DOI 10.1016/j.ins.2017.06.042
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhang WH, 2017, COMPUT BIOL MED, V91, P168, DOI 10.1016/j.compbiomed.2017.10.005
NR 32
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26493
EP 26509
DI 10.1007/s11042-021-10890-4
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646953200001
DA 2024-07-18
ER

PT J
AU Ghosh, R
AF Ghosh, Rajib
TI On-road vehicle detection in varying weather conditions using faster
   R-CNN with several region proposal networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE On-road vehicle detection; Faster R-CNN; Several RPNs; Varying weather
   conditions
ID DETECTION SYSTEM
AB Developing automated systems to detect and track on-road vehicles is a demanding research area in Intelligent Transportation System (ITS). This article proposes a method for on-road vehicle detection and tracking in varying weather conditions using several region proposal networks (RPNs) of Faster R-CNN. The use of several RPNs in Faster R-CNN is still unexplored in this area of research. The conventional Faster R-CNN produces regions-of-interest (ROIs) through a single fixed sized RPN and therefore cannot detect varying sized vehicles, whereas the present investigation proposes an end-to-end method of on-road vehicle detection where ROIs are generated using several varying sized RPNs and therefore it is able to detect varying sized vehicles. The novelty of the proposed method lies in proposing several varying sized RPNs in conventional Faster R-CNN. The vehicles have been detected in varying weather conditions. Three different public datasets, namely DAWN, CDNet 2014, and LISA datasets have been used to evaluate the performance of the proposed system and it has provided 89.48%, 91.20%, and 95.16% average precision on DAWN, CDNet 2014, and LISA datasets respectively. The proposed system outperforms the existing methods in this regard.
C1 [Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR [Anonymous], P IEEE INT TRANSP SY, P1
   Atibi M, 2015, PROCEDIA COMPUT SCI, V73, P24, DOI 10.1016/j.procs.2015.12.044
   Bertozzi M, 1997, J SYST ARCHITECT, V43, P317, DOI 10.1016/S1383-7621(96)00106-3
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chan YM, 2007, 2007 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE, VOLS 1 AND 2, P706
   Chellappa R, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P793
   Chen DY, 2013, IET COMPUT VIS, V7, P81, DOI 10.1049/iet-cvi.2012.0088
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Dong EZ, 2019, IET COMPUT VIS, V13, P730, DOI 10.1049/iet-cvi.2018.5787
   Fossati A, 2011, MACH VISION APPL, V22, P439, DOI 10.1007/s00138-009-0243-6
   Gao Y, 2020, SCIENCE, V368, P779, DOI 10.1126/science.abb7498
   Ghosh R, 2018, ADV EXP MED BIOL, V1049, P1, DOI 10.1007/978-3-319-71779-1_1
   Hadi RA, 2017, ARAB J SCI ENG, V42, P817, DOI 10.1007/s13369-016-2351-8
   Haselhoff A, 2009, IEEE INT VEH SYM, P261, DOI 10.1109/IVS.2009.5164288
   Hassaballah M, 2021, IEEE T INTELL TRANSP, V22, P4230, DOI 10.1109/TITS.2020.3014013
   Hassaballah M, 2020, PATTERN ANAL APPL, V23, P1505, DOI 10.1007/s10044-020-00874-9
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Kenk Mourad A, 2020, ARXIV200805402
   Khairdoost N., 2013, Signal Image Process, V4, P31, DOI DOI 10.5121/SIPIJ.2013.4403
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Matthews ND, 1996, CONTROL ENG PRACT, V4, P473, DOI 10.1016/0967-0661(96)00028-7
   Qing Ming, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P729, DOI 10.1109/IFOST.2011.6021126
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Singh V., 2020, P 4 INT C INT THINGS, P1
   Sivaraman S, 2014, MACH VISION APPL, V25, P599, DOI 10.1007/s00138-011-0388-y
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Tian Y, 2014, J ZHEJIANG U-SCI C, V15, P372, DOI 10.1631/jzus.C1300291
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wen XZ, 2015, IEEE T CIRC SYST VID, V25, P508, DOI 10.1109/TCSVT.2014.2358031
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yan G, 2016, OPTIK, V127, P7941, DOI 10.1016/j.ijleo.2016.05.092
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu T, 2015, IET COMPUT VIS, V9, P174, DOI 10.1049/iet-cvi.2013.0334
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou Y, 2016, LECT NOTES COMPUT SC, V9906, P278, DOI 10.1007/978-3-319-46475-6_18
NR 39
TC 27
Z9 28
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25985
EP 25999
DI 10.1007/s11042-021-10954-5
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644268000003
DA 2024-07-18
ER

PT J
AU Harshalatha, Y
   Biswas, PK
AF Harshalatha, Y.
   Biswas, Prabir Kumar
TI Structural similarity-based rate control algorithm for 3D video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; Virtual view synthesis; Bit allocation; Perceptual quality;
   SSIM
AB Human vision easily identifies the structural degradation in a video and thus perceptual quality improvement is necessary. To adjust the video quality to match with the human vision we proposed a structural similarity (SSIM) based rate control algorithm for the 3D video. We incorporated a structural similarity index (SSIM) as the quality metric in rate control algorithm. The rate-distortion model and Lagrange multiplier are derived considering the structural dissimilarity (dSSIM) as the distortion metric to achieve the rate control with perceptual quality improvement. Furthermore, the optimal joint bit allocation scheme at texture video/depth map level, frame level, and basic unit (BU) level is modified to incorporate dSSIM for measuring distortion. The proposed algorithm is implemented in HEVC compression standard HTM-16.2. The performance of the proposed algorithm is compared using RD curves, BD-Rate comparison, and subjective evaluation. Besides, rate accuracy is also computed to measure the bit rate mismatch. Compared to the original lambda-domain rate control algorithm, the proposed algorithm achieves a better SSIM along with a reduction in bit rate.
C1 [Harshalatha, Y.] Siddaganga Inst Technol, Dept Elect & Commun Engn, Tumakuru 572103, India.
   [Biswas, Prabir Kumar] Indian Inst Technol Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 Siddaganga Institute of Technology; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Kharagpur
RP Harshalatha, Y (corresponding author), Siddaganga Inst Technol, Dept Elect & Commun Engn, Tumakuru 572103, India.
EM latha_rupesh2002@sit.ac.in; pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAV-4935-2021; Biswas, Prabir Kumar/AAY-5904-2021
CR Bai YJ, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P142, DOI 10.1109/CIS.2015.42
   Chen X, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/680859
   Cordina M, 2016, IEEE INT CONF MULTI
   Cui Z., 2011, P IEEE INT C WIR COM, P1
   De Silva DVSX, 2010, IEEE IMAGE PROC, P4013, DOI 10.1109/ICIP.2010.5653353
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Harshalatha Y, 2018, MULTIMED TOOLS APPL, V77, P19051, DOI 10.1007/s11042-017-5327-0
   Hui Yuan, 2010, 2010 International Conference on Computer and Communication Technologies in Agriculture Engineering (CCTAE 2010), P380, DOI 10.1109/CCTAE.2010.5543319
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Morvan Y, 2007, PICT COD S PCS
   Ou TS, 2010, PROC SPIE, V7744, DOI 10.1117/12.863266
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Tan SC, 2017, IEEE T CIRC SYST VID, V27, P337, DOI 10.1109/TCSVT.2015.2511878
   Tan SC, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P382, DOI 10.1109/VCIP.2014.7051586
   Yang C, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001127.pub3
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhao HL, 2013, PICT COD SYMP, P85, DOI 10.1109/PCS.2013.6737689
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 18
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25897
EP 25908
DI 10.1007/s11042-021-10922-z
EA APR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643186000001
DA 2024-07-18
ER

PT J
AU Sangeetha, D
   Chakkaravarthy, SS
   Satapathy, SC
   Vaidehi, V
   Cruz, MV
AF Sangeetha, D.
   Chakkaravarthy, S. Sibi
   Satapathy, Suresh Chandra
   Vaidehi, V.
   Cruz, Meenalosini Vimal
TI Multi keyword searchable attribute based encryption for efficient
   retrieval of health Records in Cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authorized deduplication; Location based encryption; Personal health
   record; Sorted inverted index; Searchable attribute based encryption
ID RANKED SEARCH
AB Personal Health Record (PHR) is an online electronic application used by patients to store, retrieve and share their health information in a private and secure environment. While outsourcing the PHR into cloud environment, there exist issues in privacy while storing, searching and sharing of health information. To overcome these issues, an efficient retrieval of health records using Multi Keyword Searchable Attribute Based Encryption (MK-SABE) is proposed. To manage the increasing PHR data in the cloud, an Authorized File Level Deduplication technique is adopted. It eliminates redundant files, thereby reducing the communication overhead. Moreover, PHR data is encrypted before outsourcing and to perform searching over encrypted data, the proposed MK-SABE introduces Conjunctive Multi Keyword Searchable Attribute Based Encryption (CM-SABE). This maintains the searchable property after encryption for efficient retrieval of health files using range query. Further to ensure the trustworthiness while sharing the sensitive data, MK-SABE introduces the Location Based Encryption (LBE) and Dynamic Location Based ReEncryption (DLBRE) technique to provide additional security. From the experimental analysis, it is proved that the proposed MK-SABE reduces the storage complexity by 5%, keyword search time by 25% and improves the overall performance of PHR by 40% compared to the existing schemes.
C1 [Sangeetha, D.] Anna Univ, Madras Inst Technol, Chennai, Tamil Nadu, India.
   [Chakkaravarthy, S. Sibi] Vellore Inst Technol Andhra Pradesh VIT AP, Amaravati, India.
   [Satapathy, Suresh Chandra] KIIT Deemed Univ, Bhubaneswar, India.
   [Vaidehi, V.] Mother Teresa Womens Univ, Kodaikanal, India.
   [Cruz, Meenalosini Vimal] Keene State Coll, Keene, NH USA.
C3 Anna University; Anna University Chennai; Madras Institute of
   Technology; VIT-AP University; Kalinga Institute of Industrial
   Technology (KIIT); Mother Teresa Women's University; University System
   Of New Hampshire; Keene State College
RP Satapathy, SC (corresponding author), KIIT Deemed Univ, Bhubaneswar, India.
EM dsangeetha@mitindia.edu; sb.sibi@gmail.com; sureshsatapathy@gmail.com;
   vaidehi@mitindia.edu; Meenalosini.Vimal.Cruz@keene.edu
RI Cruz, Meenalosini Vimal/AAX-3872-2021; V, Vaidehi/AAD-4040-2022
OI Cruz, Meenalosini Vimal/0000-0003-3164-4848; satapathy, suresh
   chandra/0000-0001-8236-4104
CR Agrawal R., 2004, P SIGMOID 04, P563
   Besher KM, 2021, IEEE SENS J, V21, P11977, DOI 10.1109/JSEN.2020.3013634
   Bing Wang, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P2092, DOI 10.1109/INFOCOM.2015.7218594
   Boldyreva, 2009, LECT NOTES COMPUTER, V5479
   Borse Dhiraj, 2014, INT J COMPUTER APPL, V3, P610
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Cao N, 2011, IEEE INFOCOM SER, P829, DOI 10.1109/INFCOM.2011.5935306
   Ding JH, 2020, IEEE T BIG DATA, V8, P1107, DOI 10.1109/TBDATA.2020.2997732
   Golle, 2004, SECURE CONJUNCTIVE K
   Guo C, 2019, IEEE INTERNET THINGS, V6, P1520, DOI 10.1109/JIOT.2018.2845106
   Guo C, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0588-0
   Handa R, 2019, ARAB J SCI ENG, V44, P3559, DOI 10.1007/s13369-018-3580-9
   Karimi R., 2011, 2011 Fourth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT 2011), P30, DOI 10.1109/ICADIWT.2011.6041421
   Kaushik K, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 2, P200, DOI 10.1109/MDM.2013.94
   Krall A, 2021, IEEE J BIOMED HEALTH, V25, P2184, DOI 10.1109/JBHI.2020.3036422
   Li J, 2015, J COMPUT SYST SCI, V81, P1532, DOI 10.1016/j.jcss.2014.12.026
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Liang, 2013, CIPHERTEXT POLICY AT
   Liang KT, 2015, IEEE T INF FOREN SEC, V10, P1981, DOI 10.1109/TIFS.2015.2442215
   Liang KT, 2014, IEEE T INF FOREN SEC, V9, P1667, DOI 10.1109/TIFS.2014.2346023
   Milojicic D, 2011, IEEE INTERNET COMPUT, V15, P11, DOI 10.1109/MIC.2011.44
   Sahai A, 2005, IEEE T PARALLEL DIST
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Tang X, 2019, IEEE T IND INF
   Vidya, 2012, INT J ENG RES TECHNO, V1
   Wang B, 2016, IEEE T DEPENDABLE SE
   Wang SP, 2019, IEEE ACCESS, V7, P50136, DOI 10.1109/ACCESS.2019.2910828
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Ya-ling Z, 2014 10 INT C COMP I
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zheng QJ, 2014, IEEE INFOCOM SER, P522, DOI 10.1109/INFOCOM.2014.6847976
   Zhou TQ, 2022, IEEE TETCI, V6, P6, DOI 10.1109/TETCI.2020.2993841
   Zhu Y, 2014 3 INT C ADV COM
NR 34
TC 12
Z9 12
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22065
EP 22085
DI 10.1007/s11042-021-10817-z
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000638867400004
DA 2024-07-18
ER

PT J
AU Chen, JY
   Sun, JG
   Li, YQ
   Hou, CB
AF Chen, Jinyong
   Sun, Jianguo
   Li, Yuqian
   Hou, Changbo
TI Object detection in remote sensing images based on deep transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Remote sensing images; Transfer learning; Domain
   adaptation; Adversarial training
ID CLASSIFICATION
AB Object detection is a basic part in remote sensing image processing. At present, it is more common to conduct the topic based on deep learning, however the volume of remote sensing images has become a limitation. In order to solve the problem of small sample of remote sensing image, transfer learning is combined with deep learning in the research. First, the detection problem is caused by insufficient data, such as over-fitting, which is solved by model-based transfer learning. The structure of models and parameters obtained based on natural images are transferred to the detection task in remote sensing target domain. In addition, it is usually assumed that the distribution of training data and the testing data are the same in detection, but this is not the case. Therefore, how to improve the robustness of training models and widen the scope of application should be taken into consideration. In the research, Domain Adaptation Faster R-CNN (DA Faster R-CNN) algorithm is proposed for detecting aircraft in remote sensing images. Two domain adaptation structures are designed and selected as the criterion of similarity measurement between domains. Adversarial training is applied to alleviate the domain shift. Finally, the effectiveness of the algorithm is certified in the low brightness experiment. DA Faster R-CNN detection algorithm improves the accuracy of the original algorithm for low quality images. It is worth noting that the DA Faster R-CNN algorithm is a kind of unsupervised transfer learning method for remote sensing object detection.
C1 [Chen, Jinyong; Sun, Jianguo] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Peoples R China.
   [Li, Yuqian; Hou, Changbo] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University
RP Hou, CB (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
EM houchangbo@hrbeu.edu.cn
CR Acharya A., 2014, Comput. Sci, V11, P689
   Chen J, 2018, 2018 INTERNATIONAL CONFERENCE ON MANIPULATION, AUTOMATION AND ROBOTICS AT SMALL SCALES (MARSS)
   Dan ZP, 2014, OPTIK, V125, P482, DOI 10.1016/j.ijleo.2013.07.021
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo YQ, 2017, INT GEOSCI REMOTE SE, P2215, DOI 10.1109/IGARSS.2017.8127428
   Huang FR, 2021, IEEE T CYBERNETICS, V51, P1506, DOI 10.1109/TCYB.2019.2896100
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lang HT, 2018, IEEE GEOSCI REMOTE S, V15, P439, DOI 10.1109/LGRS.2018.2792683
   Li A, 2017, 2017 IEEE International Conference on Communications (ICC), P1
   Li X, 2017, IEEE J-STARS, V10, P2022, DOI 10.1109/JSTARS.2016.2646138
   Li Z, 2015, CONTR DEC C
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pan B, 2017, J SENSORS, V2017, DOI 10.1155/2017/1796728
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Persello C, 2012, IEEE T GEOSCI REMOTE, V50, P4468, DOI 10.1109/TGRS.2012.2192740
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wen JM, 2019, IEEE T VEH TECHNOL, V68, P6847, DOI 10.1109/TVT.2019.2919612
   Wen JM, 2019, IEEE T COMMUN, V67, P1424, DOI 10.1109/TCOMM.2018.2877460
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xia JS, 2017, INT GEOSCI REMOTE SE, P4762, DOI 10.1109/IGARSS.2017.8128066
   Xiao Q, 2010, INTELLIGENT CONTROL
NR 24
TC 22
Z9 21
U1 5
U2 104
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12093
EP 12109
DI 10.1007/s11042-021-10833-z
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000636933000003
DA 2024-07-18
ER

PT J
AU Jamal, AT
   Abdel-Khalek, S
   Ben Ishak, A
AF Tariq Jamal, Amani
   Abdel-Khalek, Sayed
   Ben Ishak, Anis
TI Multilevel segmentation of medical images in the framework of quantum
   and classical techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Quantum image representation; Quantum R&#233;
   nyi entropy; Quantum genetic algorithm; Medical images
ID GENETIC ALGORITHM; ENTROPY; OPTIMIZATION
AB Nowadays, the numerical segmentation is an important step in the processing and interpretation of medical images. The segmentation consists in extracting, from the image, one or more objects forming the regions of interest. Image thresholding is one of the simplest and effective techniques of image segmentation. In this work, we propose and compare multilevel segmentation approaches based on classical and quantum techniques. The Classical Renyi (CR) and the Quantum Renyi (QR) entropies are used to quantify the information contained in the image. Within the quantum framework, the digital image is expressed as a quantum system by means of the Flexible Representation of Quantum Images (FRQI). Generally, the multilevel thresholding formulation leads to a complex optimization problem. The Classical Genetic Algorithm (CGA) and the Quantum Genetic Algorithm (QGA) are employed to efficiently determine the optimal thresholding values by maximizing the entropy-based fitness functions. The segmentation performances of the proposed methods are assessed and compared using some prevailing criteria. The achieved results on a sample of medical images demonstrated that the QGA-QR method outperforms significantly the other combinations for this thresholding exercise.
C1 [Tariq Jamal, Amani] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
   [Abdel-Khalek, Sayed] Taif Univ, Fac Sci, Dept Math, At Taif 11099, Saudi Arabia.
   [Abdel-Khalek, Sayed] Sohag Univ, Dept Math, Fac Sci, Sohag, Egypt.
   [Ben Ishak, Anis] Higher Inst Management Univ Tunis, Dept Quantitat Methods, Tunis, Tunisia.
C3 King Abdulaziz University; Taif University; Egyptian Knowledge Bank
   (EKB); Sohag University
RP Abdel-Khalek, S (corresponding author), Taif Univ, Fac Sci, Dept Math, At Taif 11099, Saudi Arabia.; Abdel-Khalek, S (corresponding author), Sohag Univ, Dept Math, Fac Sci, Sohag, Egypt.
EM atjamal@kau.edu.sa; sayedquantum@yahoo.co.uk; anisisg@yahoo.fr
RI Jamal, Amani/JAC-5807-2023; Jamal, Amani/AAW-9744-2020
OI Ben Ishak, Anis/0000-0002-3619-2070
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah
   [D-276-612-1440]
FX This project was funded by the Deanship of Scientific Research (DSR),
   King Abdulaziz University, Jeddah, under grant No. (D-276-612-1440). The
   authors, therefore, gratefully acknowledge the DSR technical and
   financial support.
CR Abbasy NH, 2009, IEEE T POWER SYST, V24, P806, DOI 10.1109/TPWRS.2009.2016596
   Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Ben Ishak A, 2017, PHYSICA A, V466, P521, DOI 10.1016/j.physa.2016.09.053
   Du S., 2014, J COMPUT INF SYS, V10, P3359
   Eldar YC, 2002, IEEE SIGNAL PROC MAG, V19, P12, DOI 10.1109/MSP.2002.1043298
   Holland J., 1992, Q REV BIOL, DOI DOI 10.1086/418447
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080942
   Lang CB, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030318
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Liang YC, 2013, ENTROPY-SWITZ, V15, P2181, DOI 10.3390/e15062181
   Liu K, 2015, IEEE T INDUST, V62
   Lou Suhua, 2005, High Voltage Engineering, V31, P69
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   Müller-Lennert M, 2013, J MATH PHYS, V54, DOI 10.1063/1.4838856
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Roy U., 2014, Int. J. Comput. Appl., V102, P1, DOI DOI 10.5120/17896-8732
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shu WN, 2007, LECT NOTES COMPUT SC, V4683, P169
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Tuba M, 2014, COMPUT SCI J MOLD, V22, P318
   Upadhyay P, APPL SOFT COMPUT
   Wang H, 2013, MATH PROB ENG, V10
   Wang XL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100728
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei XK, 2014, IET MICROW ANTENNA P, V8, P965, DOI 10.1049/iet-map.2014.0034
   Yan F, 2016, QUANTUM INF PROCESS, V15, P1, DOI 10.1007/s11128-015-1195-6
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang Ge-xiang, 2004, Acta Electronica Sinica, V32, P476
   Zhang GX, 2007, LECT NOTES COMPUT SC, V4490, P243
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
NR 36
TC 3
Z9 3
U1 6
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13167
EP 13180
DI 10.1007/s11042-020-10235-7
EA APR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000636933000002
DA 2024-07-18
ER

PT J
AU Zhou, JH
   Zeng, SN
   Zhang, B
AF Zhou, Jianhang
   Zeng, Shaoning
   Zhang, Bob
TI Subspace-level dictionary fusion for robust multimedia classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dictionary Learning; Subspace; Multimedia; Classification
ID SPARSE; REPRESENTATION; ALGORITHM; SECURE
AB Nowadays, dictionary learning has become an important tool in many classification tasks, especially for images. The tailor-made atoms in a dictionary are trained for the reconstruction of the test sample. In the classification, atoms are associated with different classes from several subspaces such that the test sample is labeled according to the distances of each subspace. However, it is hard to fix the number of atoms to obtain the optimal result for each scenario since the optimal subspaces required are different. To improve the classification performance as well as the robustness, we proposed subspace-level dictionary fusion (SLDF) to construct a dictionary-based classifier. A full-size dictionary and a locality-constrained dictionary are constructed in parallel. Then, the reconstruction coefficients of the two dictionaries are obtained, which leads to a pair of distances between the test sample and the subspaces. Finally, a decision is made according to the pair-wise fusion of the distances. The experimental results on multimedia datasets from distinct categories such as image, text, and audio show that the proposed method outperforms other state-of-the-art dictionary-based classification methods with accuracies of 99.74% (image), 83.96% (Text), and 87.07% (Audio).
C1 [Zhou, Jianhang; Zeng, Shaoning; Zhang, Bob] Univ Macau, Dept Comp & Informat Sci, PAMI Res Grp, Taipa, Macau, Peoples R China.
C3 University of Macau
RP Zhang, B (corresponding author), Univ Macau, Dept Comp & Informat Sci, PAMI Res Grp, Taipa, Macau, Peoples R China.
EM mb85405@um.edu.mo; zsn@outlook.com; bobzhang@um.edu.mo
RI Zhang, Bob/ABD-5926-2021; Zhang, Bob/HIR-3656-2022; Zhou,
   Jianhang/KMY-4500-2024
OI Zhang, Bob/0000-0003-2497-9519; Zhang, Bob/0000-0001-6512-0474; Zhou,
   Jianhang/0000-0002-2423-2311
FU University of Macau [MYRG2018-00053-FST]
FX This work was supported by the University of Macau (File no.
   MYRG2018-00053-FST).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Benavente, 1998, 24 OH STAT U
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cunningham P., 2007, MULTIPLE CLASSIFIER, V34, P1, DOI DOI 10.1145/3459665
   Deterding, 1989, SPEAKER NORMALISATIO
   doCampo SB, 2006, FEI FACE DATABASE
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Gangeh Mehrdad J, 2015, ARXIV150205928
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kumar S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020374
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Mairal J., 2008, NIPS, V21, P1033
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Merz, 1998, 24 U CAL
   Milborrow S., 2010, Pattern Recognition Association of South Africa, V201, P1
   Mu Y., 2019, INT J HIGH PERFORM C, V14, P333, DOI [10.1504/IJHPCN.2019.102133, DOI 10.1504/IJHPCN.2019.102133]
   Olivetti, 1994, ORL FAC DAT
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Pham DS, 2008, PROC CVPR IEEE, P517
   Pouyanfar S, 2017, IEEE INT CON MULTI, P373, DOI 10.1109/ICME.2017.8019447
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23815, DOI 10.1007/s11042-018-5915-7
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang LC, 2019, IEEE INTERNET THINGS, V6, P1402, DOI 10.1109/JIOT.2018.2844727
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu J, 2019, PATTERN RECOGN, V88, P679, DOI 10.1016/j.patcog.2018.12.023
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Zeng SN, 2017, MULTIMED TOOLS APPL, V76, P20889, DOI 10.1007/s11042-016-4035-5
   Zhang B, 2019, 30 BRIT MACH VIS C
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang L, 2011, PATTERN RECOGN, V44, P1990, DOI 10.1016/j.patcog.2010.06.007
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhou JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112609
NR 47
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21885
EP 21898
DI 10.1007/s11042-021-10661-1
EA MAR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848000001
DA 2024-07-18
ER

PT J
AU Zhao, JD
   Li, CJ
   Xu, Z
   Jiao, LX
   Zhao, ZM
   Wang, ZB
AF Zhao, Jiandong
   Li, Chunjie
   Xu, Zhou
   Jiao, Lanxin
   Zhao, Zhimin
   Wang, Zhibin
TI Detection of passenger flow on and off buses based on video images and
   YOLO algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bus passenger flow statistics; YOLOv3; Cam-shift; Data matching
AB Bus passenger flow information is very important as a reference data for bus company line optimization, schedule scheduling basis, and passenger travel mode arrangement. With the development of image processing technology, it has become a current research trend to count passenger flow with the help of surveillance video of passengers getting on and off the bus. The specific research contents of this paper based on video image detection and statistics of passengers are as follows:(1) Collect head target image samples through a variety of ways, including 3960 positive head target samples and 4150 negative head target samples, which together constitute the head target feature database. (2) Established a head target detection model based on deep learning. First, the labeling of the head target training data set is completed. Then, after 15,000 iterations of model training, the YOLOv3 head target detection network model was obtained, with a recall rate of 92.12% and an accuracy rate of 89.71%. (3) A multi-target matching tracking algorithm based on the combination of Cam-shift and YOLOv3 is proposed. First, the Cam-shift algorithm is used to track the head target. Secondly, the head target tracking data and the YOLOv3 detection data are combined to solve the problem of drift during the tracking of the Cam-shift algorithm through the data association matching method based on the minimum distance, and then combined with the time constraint, a passenger location information judgment rule is proposed. Optimize the error and missed detection in the process of head target detection and tracking, and improve the reliability of passenger trajectory tracking. (4) A statistical algorithm for the detection of passengers getting on and off the bus is proposed. First, the trajectory of passengers in the bus boarding and disembarking area is analyzed, and a process for judging passengers' boarding and boarding behavior is proposed. At the same time, a passenger position information judgment rule is proposed according to the different situations of whether there are new passengers or missing passengers, so as to optimize the problem of wrong detection and missing detection in the process of head target detection and tracking. (5) Finally, experiments are carried out in actual bus scenes and simulation scenes. The experiment proves that the statistical algorithm for the detection of passengers getting on and off the bus proposed in this paper has good detection, tracking and statistics effects in bus scenes and simulation scenes.
C1 [Zhao, Jiandong; Jiao, Lanxin; Zhao, Zhimin] Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.
   [Zhao, Jiandong] Beijing Jiaotong Univ, Minist Transport, Key Lab Transport Ind Big Data Applicat Technol C, Beijing 100044, Peoples R China.
   [Li, Chunjie] Hebei Prov Commun Planning & Design Inst, Shijiazhuang 050000, Hebei, Peoples R China.
   [Xu, Zhou] Beijing Jiaotong Univ, Sch Mech & Elect Control Engn, Beijing 100044, Peoples R China.
   [Wang, Zhibin] Jingde Temporary Construct Off Hebei Expressway, Baoding 071051, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Beijing
   Jiaotong University
RP Zhao, JD (corresponding author), Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.; Zhao, JD (corresponding author), Beijing Jiaotong Univ, Minist Transport, Key Lab Transport Ind Big Data Applicat Technol C, Beijing 100044, Peoples R China.
EM zhaojd@bjtu.edu.cn
RI chen, qiang/JXY-6982-2024; YAN, LING/JXY-6904-2024; Peng,
   Ziyi/JTT-8210-2023; luo, yuan/JLS-6416-2023; zhang, yuyang/IVV-5089-2023
OI Zhao, Jiandong/0000-0001-8402-0380
FU National Key R&D Program of China [2019YFB1600200]; National Natural
   Science Foundation of China [71871011, 71890972/71890970, 71621001];
   first batch of science and technology projects of Jingde Expressway
   [JD-202014]
FX This work is supported by the National Key R&D Program of China
   (2019YFB1600200), National Natural Science Foundation of China
   (71871011, 71890972/71890970, 71621001), and the first batch of science
   and technology projects of Jingde Expressway(JD-202014).
CR Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Chen, 2010, BUS TECHNOLOGY RES, V32
   Deng, 2019, J TRANSPORTATION SYS, V3, P54
   Gao M, 2019, RES PASSENGER FLOW S
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu J, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P2307
   Huiying J, 2018, RES VIDEO PEOPLE COU
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Lecheng Ouyang, 2019, IOP Conference Series: Materials Science and Engineering, V569, DOI 10.1088/1757-899X/569/5/052018
   Li B, 2019, ANAL APPL BUS SURVEI
   Li M, 2019, RES PREDICTION SHORT
   Liu Q, 2019, P 3 INT C COMP ENG I, P152
   Liu X, 2013, METHOD REALIZATION B
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shi T, 2011, RES IMPROVEMENT DATA
   Tang, 2015, COMPUT ENG, V4, P176
   Tang Q, 2014, RES REALIZATION KEY
   Wang ZW, 2009, PATTERN RECOGN LETT, V30, P407, DOI 10.1016/j.patrec.2008.10.017
   Yi Z, 2017, RES PUBLIC TRANSPORT
   ZHANG Hongzhi, 2006, COMPUTER ENG DESIGN, V27, P2012
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang W, 2018, RES BUS PASSENGER FL
   Zhao Q, 2016, RES IMPLEMENTATION B
   Zhou X, 2020, STAT STUDY BUS PASSE
NR 27
TC 12
Z9 12
U1 3
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4669
EP 4692
DI 10.1007/s11042-021-10747-w
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000630647100001
DA 2024-07-18
ER

PT J
AU Caballero, P
   Ortiz, G
   Garcia-de-Prado, A
   Boubeta-Puig, J
AF Caballero, Pablo
   Ortiz, Guadalupe
   Garcia-de-Prado, Alfonso
   Boubeta-Puig, Juan
TI Paving the way to collaborative context-aware mobile applications: a
   case study on preventing worsening of allergy symptoms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative context awareness; Mobile application; Contextual alert;
   Internet of things; Smart city; E-health
ID FRAMEWORK; INTERNET
AB In recent years, the evolution of smartphones and their software applications has grown exponentially; together with the advance of the Internet of Things and smart cities, it has raised huge demand for services and applications in these domains. Although the wide range of mobile applications is unquestionable, citizens already demand that applications adapt to their specific needs and situations in real time, that is, that they are context-aware. However, context-aware mobile applications are often very limited and miss out on the opportunity of benefiting from feedback provided by citizen collaboration. In order to fill this gap, this paper proposes a context-aware and collaborative software architecture and mobile application. In particular, we have implemented them in the scope of e-health, more specifically in the area of seasonal allergies, which cause allergic people to experience annoying symptoms that could be avoided by having access to pollen information in real time. Furthermore, they will also benefit from citizen collaboration through the knowledge of the symptoms other allergic people with the same allergy and in the same location are experiencing. To this end, users will be able to provide their symptoms at any time through their mobile application and the proposed architecture will constantly process that information in real time, sending notifications to users as soon as reported symptoms are seen to exceed a certain threshold. The architecture's performance, the application's resource consumption and a satisfaction survey of the app's usability and usefulness have been tested; all results have been fully satisfactory.
C1 [Caballero, Pablo; Ortiz, Guadalupe; Garcia-de-Prado, Alfonso; Boubeta-Puig, Juan] Univ Cadiz, UCASE Software Engn Grp, Sch Engn, Avda Univ Cadiz 10, Cadiz 11519, Spain.
C3 Universidad de Cadiz
RP Ortiz, G (corresponding author), Univ Cadiz, UCASE Software Engn Grp, Sch Engn, Avda Univ Cadiz 10, Cadiz 11519, Spain.
EM pablo.caballero@uca.es; guadalupe.ortiz@uca.es;
   alfonso.garciadeprado@uca.es; juan.boubeta@uca.es
RI Boubeta-Puig, Juan/L-9429-2014; Ortiz, Guadalupe/K-8601-2014;
   Garcia-de-Prado, Alfonso/H-4890-2015
OI Boubeta-Puig, Juan/0000-0002-8989-7509; Ortiz,
   Guadalupe/0000-0002-5121-6341; Garcia-de-Prado,
   Alfonso/0000-0002-6523-9974; CABALLERO TORRES, PABLO/0000-0003-0610-9608
FU Spanish Ministry of Science and Innovation; European Union FEDER Funds
   [RTI2018-093608-B-C33, RED2018-102654-T]
FX This work was supported by the Spanish Ministry of Science and
   Innovation and the European Union FEDER Funds [grant numbers
   RTI2018-093608-B-C33, RED2018-102654-T]. We would like to thank the
   personal support offered by Puerto Real Hospital pulmonologist
   CarmenMaza, as well as researcher Winfried Lamersdorf, for their
   interest in our ongoing research projects. We would also like to thank
   Ruben Rivas for his support with the initial versions of the server-side
   architecture.
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Aguilera U, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071022
   Alhamid MF, 2015, MULTIMED TOOLS APPL, V74, P11399, DOI 10.1007/s11042-014-2236-3
   American Academy of Allergy Asthma & Immunology (AAAAI), YOUR QUEST ANSW AIR
   [Anonymous], 2015, Collaborative Internet of Things (C-IoT): For Future Smart Connected Life and Business
   [Anonymous], 2012, WEB SERVICES SOA PRI
   Asthma and Allergy Foundation of America (aafa), 2018, ALL FACT FIG
   Athanasopoulos D, 2008, PERVASIVE MOB COMPUT, V4, P360, DOI 10.1016/j.pmcj.2007.12.004
   Baralis E, 2011, KNOWL INF SYST, V28, P283, DOI 10.1007/s10115-010-0359-z
   Benítez-Guerrero E, 2012, SENSORS-BASEL, V12, P13491, DOI 10.3390/s121013491
   Berrocal J, 2017, PERVASIVE MOB COMPUT, V35, P32, DOI 10.1016/j.pmcj.2016.06.011
   Botev J, 2018, L N INST COMP SCI SO, V196, P113, DOI 10.1007/978-3-319-55834-9_13
   CASINO F, 2018, 2018 INT S SENS, pNIL76
   Chung HM., 2012, 2012 INT C SYST INF, DOI 10.1109/ICSAI.2012.6223262
   de Backere F, 2017, COMPUT METH PROG BIO, V140, P111, DOI 10.1016/j.cmpb.2016.11.008
   De Pessemier T, 2016, MULTIMED TOOLS APPL, V75, P3323, DOI 10.1007/s11042-014-2437-9
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Dr. Safadi & Associates Inc., 2018, ALLERGY POLLEN COUNT
   European Academy of Allergy and Clinical Inmunology (EAACY), 2015, TACKL AL CRIS EUR CO
   European Investment Bank Deloitte, 2019, HORIZON 2030 LOOKING
   European Research Group in the Internet of Things, 2012, INTERNET THINGS 2012
   de Prado AG, 2017, IEEE ACCESS, V5, P4646, DOI 10.1109/ACCESS.2017.2679338
   Garcia-de-Prado A., 2020, NITROGEN INTERNET TH
   Garcia-de-Prado A, 2018, J UNIVERS COMPUT SCI, V24, P846
   Garcia-De-Prado A, 2017, EXPERT SYST APPL, V85, P231, DOI 10.1016/j.eswa.2017.05.034
   Gil D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071069
   Gilman E, 2011, INT J PERVASIVE COMP, V7, P339, DOI 10.1108/17427371111189665
   Harchay A, 2015, JUCS J U COMPUT SCI, V8, DOI 10.3217/jucs-021-08-1061
   Hong-Linh Truong, 2008, 2008 International Symposium on Applications and the Internet, P118, DOI 10.1109/SAINT.2008.70
   IMMANUEL VA, 2015, P 2015 INT C APPL TH
   Inc E., 2021, 7 MILLION EVENTS PER
   Innovatech Innovatech Informatica & Telecomunicaciones, 2019, POLEN REA
   Inzinger C, 2014, SOFTWARE PRACT EXPER, V44, P805, DOI 10.1002/spe.2254
   Java.net, 2021, JAVA API RESTFUL SER
   1996, USABILITY EVALUATION, DOI 10.1201/9781498710411
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim K, 2016, EXPERT SYST APPL, V46, P463, DOI 10.1016/j.eswa.2015.11.005
   LI F, 2010, IEEE CONF WIREL MOB
   Luckham D, 2012, EVENT PROCESSING FOR BUSINESS: ORGANIZING THE REAL-TIME ENTERPRISE, P1
   Luckham D., 2002, The Power of Events: An Introduction to Complex Event Processing in Distributed Enterprise Systems
   Montane-Jimenez, 2014, EAI ENDORSED T CONTE, V1, pE4, DOI [10.4108/casa.1.1.e4, DOI 10.4108/CASA.1.1.E4]
   OASIS, 2021, AMQP IS INTERNET PRO
   Oracle Corporation, 2021, MYSQL MYSQL STANDARD
   Oracle Corporation: JERSEY, 2020, RESTFUL WEB SERVICES
   Ortiz G, 2019, IEEE ACCESS, V7, P65228, DOI 10.1109/ACCESS.2019.2918239
   Papazoglou M. P., 2006, International Journal of Web Engineering and Technology, V2, P412, DOI 10.1504/IJWET.2006.010423
   Peinado S, 2015, COMPUT ELECTR ENG, V44, P262, DOI 10.1016/j.compeleceng.2015.02.004
   Pollen Sense LLC, 2020, POLLEN WISE
   Rahman MA, 2014, MULTIMED TOOLS APPL, V73, P1147, DOI 10.1007/s11042-013-1595-5
   Sauro J, 2016, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, 2ND EDITION, P249, DOI 10.1016/B978-0-12-802308-2.00009-6
   Siriwardena P., 2019, Advanced API Security: OAuth 2.0 and Beyond
   SonarSource S.A,, 2021, SONARQUBE
   SQLite Consortium, 2021, SQLITE HOME PAGE
   STARx Technology Corporation, 2020, ACCUPOLLEN ALLERGY T
   StatCounter Global Stats, 2021, MOBILE OPERATING SYS
   Sundermann CV, 2016, EXPERT SYST APPL, V57, P139, DOI 10.1016/j.eswa.2016.03.036
   The Apache Software Foundation, 2021, APACHE TOMCAT WELCOM
   Thomas F Roy, 2000, THESIS U CALIFORNIA
   Thomas S.A., 2000, SSL TLS Essentials: Securing the Web
   Truong H, 2007, 2 EUR C EUROSSC KEND, DOI 10.1007/978-3-540-75696-5_13
   University of Melbourne, 2020, MELB POLL COUNT
   VMware, 2020, MESSAGING JUST WORKS
   Wlab Ltd, 2020, SENSIO AIR POLLEN PO
   Xu YS, 2016, EXPERT SYST APPL, V53, P75, DOI 10.1016/j.eswa.2016.01.010
   Yu J., 2012, LNCS, V7636, P173, DOI DOI 10.1007/978-3-642-34321-6_
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
   Zavala L, 2011, P 4 AAAI C ACT CONT, P79
NR 67
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21101
EP 21133
DI 10.1007/s11042-021-10759-6
EA MAR 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627670100002
DA 2024-07-18
ER

PT J
AU Tommasi, F
   De Luca, V
   Melle, C
AF Tommasi, Franco
   De Luca, Valerio
   Melle, Catiuscia
TI QoS monitoring in real-time streaming overlays based on lock-free data
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time streaming; P2P streaming; Peer churning; QoS; Playback
   continuity; Lock-free
AB Peer-to-peer streaming is a well-known technology for the large-scale distribution of real-time audio/video contents. Delay requirements are very strict in interactive real-time scenarios (such as synchronous distance learning), where playback lag should be of the order of seconds. Playback continuity is another key aspect in these cases: in presence of peer churning and network congestion, a peer-to-peer overlay should quickly rearrange connections among receiving nodes to avoid freezing phenomena that may compromise audio/video understanding. For this reason, we designed a QoS monitoring algorithm that quickly detects broken or congested links: each receiving node is able to independently decide whether it should switch to a secondary sending node, called "fallback node". The architecture takes advantage of a multithreaded design based on lock-free data structures, which improve the performance by avoiding synchronization among threads. We will show the good responsiveness of the proposed approach on machines with different computational capabilities: measured times prove both departures of nodes and QoS degradations are promptly detected and clients can quickly restore a stream reception. According to PSNR and SSIM, two well-known full-reference video quality metrics, QoE remains acceptable on receiving nodes of our resilient overlay also in presence of swap procedures.
C1 [Tommasi, Franco; De Luca, Valerio; Melle, Catiuscia] Univ Salento, Dept Engn Innovat, Lecce, Italy.
C3 University of Salento
RP De Luca, V (corresponding author), Univ Salento, Dept Engn Innovat, Lecce, Italy.
EM franco.tommasi@unisalento.it; valerio.deluca@unisalento.it;
   catiuscia.melle@unisalento.it
RI De Luca, Valerio/JBJ-2116-2023; De Luca, Valerio/HGJ-6239-2022; Tommasi,
   Franco/N-9334-2015
OI Tommasi, Franco/0000-0003-2419-7381; De Luca,
   Valerio/0000-0003-3018-7251
CR [Anonymous], 2012, P IEEE AS PAC SIGN I
   Backhaus M, 2016, GLOB INFORM INFRAS
   Bishop M, 2006, IEEE INFOCOM SER, P653
   Budhkar S, 2018, J NETW SYST MANAG, V26, P401, DOI 10.1007/s10922-017-9420-5
   Egilmez H. E., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2241, DOI 10.1109/ICIP.2011.6116083
   Egilmez HE, 2014, IEEE T MULTIMEDIA, V16, P1597, DOI 10.1109/TMM.2014.2325791
   Egilmez HE, 2013, IEEE T MULTIMEDIA, V15, P710, DOI 10.1109/TMM.2012.2232645
   Espina F, 2014, MULTIMED TOOLS APPL, V72, P361, DOI 10.1007/s11042-012-1344-1
   Feldman S, 2015, INT J PARALLEL PROG, V43, P572, DOI 10.1007/s10766-014-0308-7
   Fraser K., 2004, UCAM-CL-TR-579
   Fujita S, 2019, J INTERCONNECT NETW, V19, DOI 10.1142/S0219265919500099
   Garroppo RG, 2012, COMPUT COMMUN, V35, P759, DOI 10.1016/j.comcom.2012.01.002
   Goh C. Y., 2013, J MULTIMEDIA UBIQUIT, V8, P97, DOI DOI 10.14257/ijmue.2013.8.6.10
   Gu WJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118022
   Hammami C, 2014, PROCEDIA COMPUT SCI, V32, P158, DOI 10.1016/j.procs.2014.05.410
   Hei XJ, 2007, IEEE J SEL AREA COMM, V25, P1640, DOI 10.1109/JSAC.2007.071204
   Hemminger Stephen., 2005, LINUX C, P18
   HERLIHY MP, 1990, ACM T PROGR LANG SYS, V12, P463, DOI 10.1145/78969.78972
   Hsieh YL, 2012, COMPUT NETW, V56, P3609, DOI 10.1016/j.comnet.2012.07.011
   Jae Cheol Kwon, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P224, DOI 10.1109/QOMEX.2010.5516127
   Jeyasekar A, 2017, J NETW COMPUT APPL, V93, P91, DOI 10.1016/j.jnca.2017.05.008
   Jurgelionis A, 2011, IEEE IC COMP COM NET
   Kouchi T, 2015, IEICE T INF SYST, VE98D, P1667, DOI 10.1587/transinf.2015EDP7021
   Laborde P, 2017, INT J PARALLEL PROG, V45, P421, DOI 10.1007/s10766-015-0376-3
   Magnetto A, 2010, IEEE T MULTIMEDIA, V12, P901, DOI 10.1109/TMM.2010.2077623
   Maheswari BU, 2018, PROCEEDINGS OF THE 2018 4TH INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT - 2018), P255, DOI 10.1109/iCATccT44854.2018.9001285
   Marques, 2017, MULTIVIEW REAL TIME, DOI [10.1016/j.comnet.2017.03.002, DOI 10.1016/J.COMNET.2017.03.002]
   Michael M. M., 2002, P 14 ANN ACM S PAR A, P73, DOI DOI 10.1145/564870.564881
   Michael MM, 2004, IEEE T PARALL DISTR, V15, P491, DOI 10.1109/TPDS.2004.8
   Mwela JS, 2010, COMP ALGORITHMS CONC
   Ooi WT, 2005, PROC SPIE, V5680, P77, DOI 10.1117/12.592088
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Ren DN, 2009, IEEE T MULTIMEDIA, V11, P1446, DOI 10.1109/TMM.2009.2032677
   Salsano Stefano, 2012, TECH REP
   Sayit M, 2016, PEER PEER NETW APPL, V9, P1074, DOI 10.1007/s12083-015-0390-7
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sedrati M, 2018, WIRELESS PERS COMMUN, V99, P999, DOI 10.1007/s11277-017-5163-6
   Shalev O., 2003, PODC 03, P102
   Singh M, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P80, DOI 10.1109/ICICCS.2016.7542315
   Sousa, 2016, 2016 11 INT C DIG IN
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Taubenfeld G, 2017, THEOR COMPUT SCI, V677, P41, DOI 10.1016/j.tcs.2017.03.017
   Tommasi, 2015, 2015 2 WORLD S WEB A, P1, DOI DOI 10.1109/WSWAN.2015.7209091
   Tommasi Franco, 2014, Journal of Communications, V9, P248
   Tommasi F, 2015, J VIS COMMUN IMAGE R, V27, P7, DOI 10.1016/j.jvcir.2014.12.003
   Tsigas Philippas, 2001, P 13 ANN ACM S PARAL, P134, DOI [10.1145/378580.378611, DOI 10.1145/378580.378611, 10.1145/378580]
   Ullah I, 2012, IEEE COMMUN SURV TUT, V14, P734, DOI 10.1109/SURV.2011.082611.00134
   WANG F, 2008, IEEE INFOCOM SER
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   WU W, 2009, P 5 INT C COLL COMP, P1
   Zhang M, 2007, IEEE J SEL AREA COMM, V25, P1678, DOI 10.1109/JSAC.2007.071207
   Zheng QH, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P805, DOI 10.1109/WCICA.2011.5970626
NR 53
TC 2
Z9 3
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20929
EP 20970
DI 10.1007/s11042-020-10198-9
EA MAR 2021
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627245100003
OA hybrid
DA 2024-07-18
ER

PT J
AU Rakshit, RD
   Kisku, DR
   Gupta, P
   Sing, JK
AF Rakshit, Rinku Datta
   Kisku, Dakshina Ranjan
   Gupta, Phalguni
   Sing, Jamuna Kanta
TI Cross-resolution face identification using deep-convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face identification; Deep-convolutional neural network; Pooling; Cosine
   similarity; cross-resolution face recognition
ID RECOGNITION; SUPERRESOLUTION
AB Low resolution (LR) and very low resolution (VLR) face images captured by surveillance cameras make automatic face recognition (AFR) a challenging task. The performance of an automatic face recognition system (AFRS) degrades when these types of face images are compared with high resolution (HR) gallery images. This paper has presented a face identification system called Cross-Resolution Face Identification System, to address this issue. It makes use of the Deep Convolutional Neural Network (DCNN) having different pooling operations to extract resolution robust features from high resolution, low resolution and very low resolution face images. The proposed system is evaluated on four face databases, namely, the ORL, the extended Yale face B, the LFW, and the Georgia Tech under three cross resolution environmental conditions based on resolution of probe images (i.e., high resolution to high resolution, low resolution to high resolution, and very low resolution to high resolution).The experimental outcomes exhibit the effectiveness of the proposed face identification system.
C1 [Rakshit, Rinku Datta] Asansol Engn Coll, Dept Informat Technol, Asansol 713305, West Bengal, India.
   [Kisku, Dakshina Ranjan] Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur 713209, West Bengal, India.
   [Gupta, Phalguni] GLA Univ, Mathura, India.
   [Sing, Jamuna Kanta] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, WB, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; GLA University; Jadavpur University
RP Kisku, DR (corresponding author), Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur 713209, West Bengal, India.
EM drkisku@cse.nitdgp.ac.in
RI RAKSHIT, RINKU DATTA/ABI-2257-2020; Kisku, Dakshina Ranjan/E-1680-2013
OI Kisku, Dakshina Ranjan/0000-0003-1116-2972; DATTA RAKSHIT,
   RINKU/0000-0002-9262-2450
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Ahmed A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P144, DOI 10.1109/ICAIBD.2018.8396183
   Alobaidi T, 2018, MIDWEST SYMP CIRCUIT, P214, DOI 10.1109/MWSCAS.2018.8623943
   Anas IY, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01880
   [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2016, PROC 10 EUR C ANTENN
   [Anonymous], 2001, UCSD REPOSITORY
   [Anonymous], 2017, 2017 IEEE INT C ID S
   Arya K, 2017, 2017 C INF COMM TECH, P1
   Best-Rowden L, 2014, IEEE T INF FOREN SEC, V9, P2144, DOI 10.1109/TIFS.2014.2359577
   Bhatt HS, 2014, IEEE T IMAGE PROCESS, V23, P5654, DOI 10.1109/TIP.2014.2362658
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Cirrincione G., 2017, IT WORKSH NEUR NETS, P153
   Coskun M, 2017, 2017 INTERNATIONAL CONFERENCE ON MODERN ELECTRICAL AND ENERGY SYSTEMS (MEES), P376, DOI 10.1109/MEES.2017.8248937
   Cristobal G, 2008, ADV SIGNAL PROCESSIN, V7074
   Dabaghchian M, 2016, IEEE CONF COMM NETW, P100, DOI 10.1109/CNS.2016.7860475
   Ding CH, 2017, I C COMM SOFTW NET, P1157, DOI 10.1109/ICCSN.2017.8230292
   Ebrahimpour R., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P265, DOI 10.1109/SOCPAR.2010.5686495
   Elazhari Abbas, 2014, 2014 World Automation Congress (WAC), P185, DOI 10.1109/WAC.2014.6935767
   Elazhari A, 2013, IEEE I C ELECT CIRC, P425, DOI 10.1109/ICECS.2013.6815445
   Elsaeidy Asmaa, 2017, 2017 27th International Telecommunication Networks and Applications Conference (ITNAC), P1, DOI 10.1109/ATNAC.2017.8215388
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Fu TC, 2017, IEEE INT WORKS MACH
   Ganguly S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P275, DOI 10.1109/CGVIS.2015.7449936
   Gaston J, 2019, IEEE T CYBERNETICS, V49, P3191, DOI 10.1109/TCYB.2018.2846579
   Hennings-Yeomans PH, 2008, PROC CVPR IEEE, P3637
   Nguyen HV, 2011, LECT NOTES COMPUT SC, V6493, P709
   Huang T, 2010, IMAGE SUPER RESOLUTI, P15
   Huy NQ, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P54, DOI [10.1109/ZINC50678.2020.9161798, 10.1109/zinc50678.2020.9161798]
   Jain A.K., 2011, HDB FACE RECOGNITION, V1
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Jiao JN, 2018, AAAI CONF ARTIF INTE, P6967
   Kangming Xu, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1665, DOI 10.1109/ICCT46805.2019.8947113
   Kasemsumran P, 2016, INT CONF KNOWL SMART, P55, DOI 10.1109/KST.2016.7440531
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li YJ, 2019, IEEE I CONF COMP VIS, P8089, DOI 10.1109/ICCV.2019.00818
   Lu Z, 2017, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2017.7952478
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Lui YM, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P139
   Maafiri A., 2019, 2019 INT C VIS EM TR, P1
   Massoli FV, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103927
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Nakada M, 2017, IEEE COMPUT SOC CONF, P35, DOI 10.1109/CVPRW.2017.11
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Rajput S, 2020, 2020 INT C EM FRONT, P1
   Rakshit RD, 2018, EXPERT SYST APPL, V92, P82, DOI 10.1016/j.eswa.2017.09.038
   Rakshit RD, 2017, J CHIN INST ENG, V40, P82, DOI 10.1080/02533839.2016.1259020
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Singh M., 2018, P IEEE C COMP VIS PA, P479
   Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Vezzetti E, 2014, AESTHET PLAST SURG, V38, P796, DOI 10.1007/s00266-014-0334-2
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Yang FW, 2018, IEEE SIGNAL PROC LET, V25, P388, DOI 10.1109/LSP.2017.2746658
NR 58
TC 5
Z9 6
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20733
EP 20758
DI 10.1007/s11042-021-10745-y
EA MAR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000626425400002
DA 2024-07-18
ER

PT J
AU Ahmadi, M
   Karimi, N
   Samavi, S
AF Ahmadi, Mahdi
   Karimi, Nader
   Samavi, Shadrokh
TI Context-aware saliency detection for image retargeting using
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retargeting; Human visual system; Semantic segmentation;
   Convolutional neural networks; Saliency detection
ID FUSION
AB Image retargeting is the task of making images capable of being displayed on screens with different sizes. This work should be done so that high-level visual information and low-level features such as texture remain as intact as possible to the human visual system. At the same time, the output image may have different dimensions. Thus, simple methods such as scaling and cropping are not adequate for this purpose. In recent years, researchers have tried to improve the existing retargeting methods, and they have introduced new ones. However, a specific method cannot be utilized to retarget all types of images. In other words, different images require different retargeting methods. Image retargeting has a close relationship to image saliency detection, which is a relatively new image processing task. Earlier saliency detection methods were based on local and global but low-level image information. These methods are called bottom-up processes. On the other hand, newer approaches are top-down and mixed methods that consider the high level and semantic knowledge of the image too. In this paper, we introduce the proposed methods in both saliency detection and retargeting. For the saliency detection, the use of image context and semantic segmentation are examined, and a novel mixed bottom-up and top-down saliency detection method is introduced. After saliency detection, a modified version of an existing retargeting technique is utilized for retargeting the images. The results suggest that the proposed image retargeting pipeline has excellent performance compared to other tested methods. Also, the subjective evaluations on the Pascal dataset can be used as a retargeting quality assessment dataset for further research.
C1 [Ahmadi, Mahdi; Karimi, Nader; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
C3 Isfahan University of Technology; McMaster University
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.; Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
EM mahdi.ahmadi@ec.iut.ac.ir; nader.karimi@cc.iut.ac.ir; samavi@mcmaster.ca
RI Ahmadi, Mahdi/AGM-0779-2022; Samavi, Shadrokh/KPY-5766-2024; Karimi,
   Nader/HWP-4206-2023
OI Samavi, Shadrokh/0000-0003-3951-3770; Karimi, Nader/0000-0001-8904-1607;
   Ahmadi, Mahdi/0000-0001-7529-9463
CR Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Borji A, 2015, ARXIV PREPRINT ARXIV
   Cho D, 2017, IEEE I CONF COMP VIS, P4568, DOI 10.1109/ICCV.2017.488
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Esmaeili SA, 2017, PROC CVPR IEEE, P4178, DOI 10.1109/CVPR.2017.445
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Fujimura Makoto, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P347, DOI 10.1109/ICCE-China.2017.7991138
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hooshmand M, 2013, J NETW COMPUT APPL, V36, P409, DOI 10.1016/j.jnca.2012.04.017
   Hu WM, 2014, IEEE T IMAGE PROCESS, V23, P1513, DOI 10.1109/TIP.2014.2303639
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Li C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2757287
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Panozzo D, 2012, COMPUT GRAPH FORUM, V31, P229, DOI 10.1111/j.1467-8659.2012.03001.x
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rabbani N, 2017, IET IMAGE PROCESS, V11, P1103, DOI 10.1049/iet-ipr.2017.0267
   Razzaghi P, 2015, MULTIMED TOOLS APPL, V74, P11517, DOI 10.1007/s11042-014-2249-y
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Shafieyan F, 2017, SIGNAL PROCESS-IMAGE, V50, P34, DOI 10.1016/j.image.2016.10.006
   Shao F, 2017, IEEE T IMAGE PROCESS, V26, P4790, DOI 10.1109/TIP.2017.2721546
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Tang F., 2018, ARXIV PREPRINT ARXIV
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Wang L., 2016, INT J SIGNAL PROCESS, V9, P281, DOI [10.14257/ijsip.2016.9.3.25, DOI 10.14257/IJSIP.2016.9.3.25]
   Wang Q, 2014, NEUROCOMPUTING, V131, P348, DOI 10.1016/j.neucom.2013.09.032
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Yan B, 2015, IEEE T CIRC SYST VID, V25, P15, DOI 10.1109/TCSVT.2014.2329374
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhao H., IEEE INT SYMP ELEC
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 44
TC 16
Z9 18
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11917
EP 11941
DI 10.1007/s11042-020-10185-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200009
DA 2024-07-18
ER

PT J
AU Liu, K
   Li, XJ
AF Liu, Ke
   Li, Xujian
TI De-hazing and enhancement method for underwater and low-light images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge detail preservation; Guided filtering; Underwater image; Image
   de-hazing; Image enhancement
AB Because underwater and low-light images have different characteristics, there are few methods to jointly improve the visibility of these images. This paper proposes a de-hazing and enhancement method for underwater and low-light images to describe the two types of images uniformly. Multi-scale retinex color recovery (MSRCR) and guided filtering methods are used for de-hazing; the proposed method of white balance fusion global guided image filtering (G-GIF), effectively solve the problems of dim light, color distortion, and loss of edge details. Experiments show that compared with other methods, this method can effectively solve the image exposure, and at the same time, it can better protect and enhance the image's color saturation and edge texture details, thus achieving a very good visual effect.
C1 [Liu, Ke; Li, Xujian] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Liu, K (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM keliucs@163.com
FU National Key Research and Development Program of China [2017YFC0804406]
FX The authors acknowledge this paper was supported by the National Key
   Research and Development Program of China under Grant 2017YFC0804406.
CR Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bertalmío M, 2013, IEEE T IMAGE PROCESS, V22, P712, DOI 10.1109/TIP.2012.2221730
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Dai CG, 2019, IEEE ACCESS, V7, P178685, DOI 10.1109/ACCESS.2019.2958078
   DING X, 2017, OCEANS-IEEE, P1, DOI DOI 10.1109/OCEANSE.2017.8084665
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2018, OCEAN ENG, V162, P224, DOI 10.1016/j.oceaneng.2018.05.027
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, MULTIMED TOOLS APPL, V79, P20199, DOI 10.1007/s11042-020-08759-z
   Jing H., 2018, 2018 IEEE 3 INT C IM, P27
   Kumar M, 2020, IEEE T IMAGE PROCESS, V29, P7525, DOI 10.1109/TIP.2020.3004036
   Lee S, 2018, IEEE ACCESS, V6, P49913, DOI 10.1109/ACCESS.2018.2868246
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2016, INT CONF ACOUST SPEE, P1731, DOI 10.1109/ICASSP.2016.7471973
   Li CY, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033023
   Li YJ, 2019, IEEE ACCESS, V7, P83721, DOI 10.1109/ACCESS.2019.2925209
   Li ZG, 2018, IEEE T IMAGE PROCESS, V27, P442, DOI 10.1109/TIP.2017.2750418
   Liu YH, 2018, IET IMAGE PROCESS, V12, P880, DOI 10.1049/iet-ipr.2017.0171
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Steffens C, 2018, P 2018 LAT AM ROB S
   Vasu S., 2018, P7
   Wang YF, 2017, P 2017 INT C PROGR I, P15
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao L, 2020, OPT EXPRESS, V28, P30234, DOI 10.1364/OE.399542
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
NR 31
TC 10
Z9 11
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19421
EP 19439
DI 10.1007/s11042-021-10740-3
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622245500002
DA 2024-07-18
ER

PT J
AU Xiang, HY
   Liu, LF
AF Xiang, Hongyue
   Liu, Lingfeng
TI A new perturbation-feedback hybrid control method for reducing the
   dynamic degradation of digital chaotic systems and its application in
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; Dynamical degradation; Perturbation feedback;
   Hybrid control method
ID GENERATOR; SECURE; PERIODICITY; SCHEME; MAPS
AB In a finite precision computing environment, the trajectories of all chaotic sequences enter a cycle leading to degradation of their dynamics. In this paper a new perturbation feedback hybrid control method to reduce the influence of finite precision. A traditional logistic map is introduced as a pseudo-random sequence generator for time-varying perturbation to perturb the coefficients of chaotic map and make them iteratively changed in the chaotic region. The nonlinear feedback mechanism has high complexity. Numerical analysis results show that the perturbation-feedback hybrid control method can effectively attenuate the dynamic degradation of digital chaotic systems. Further, we propose a simple encryption algorithm based on the perturbation-feedback hybrid control method and apply it to image encryption. The NPCR and UACI of our encryption method are 0.99609 and 0.33464, respectively and the information entropy is as high as 7.9976. All the numerical experiments results prove that the proposed algorithm is highly secure, resistant to multiple attacks, and is more competitive than other encryption algorithms.
C1 [Xiang, Hongyue; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China [61862042, 61601215]; 2019
   Innovation Special Fund of Jiangxi Province [YC2019-S101]
FX This work is supported by the National Natural Science Foundation of
   China (61862042, 61601215); 2019 Innovation Special Fund of Jiangxi
   Province (YC2019-S101).
CR Alawida M, 2019, NONLINEAR DYNAM, V96, P601, DOI 10.1007/s11071-019-04809-w
   Arpaci B, 2020, J ELECTR ENG TECHNOL, V15, P1413, DOI 10.1007/s42835-020-00393-x
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P1792, DOI 10.1016/j.cnsns.2012.11.025
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Ben Farah MA, 2011, COMMUN NONLINEAR SCI, V16, P2543, DOI 10.1016/j.cnsns.2010.09.005
   Chen C, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12374-y
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Dastgheib MA, 2017, NONLINEAR DYNAM, V89, P2957, DOI 10.1007/s11071-017-3638-3
   Gopalakrishnan T, 2019, WIRELESS PERS COMMUN, V109, P437, DOI 10.1007/s11277-019-06573-x
   Gopalakrishnan T, 2017, IETE J RES, V63, P172, DOI 10.1080/03772063.2016.1251855
   GUSTAFSON H, 1994, COMPUT SECUR, V13, P687, DOI 10.1016/0167-4048(94)90051-5
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hua ZY, 2018, IEEE T CIRCUITS-I, V65, P235, DOI 10.1109/TCSI.2017.2717943
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang N, 2019, OPT LETT, V44, P1536, DOI 10.1364/OL.44.001536
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Lambic D, 2017, NONLINEAR DYNAM, V90, P223, DOI 10.1007/s11071-017-3656-1
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li XW, 2019, OPT LASER ENG, V112, P162, DOI 10.1016/j.optlaseng.2018.09.015
   Liu LF, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501036
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu LF, 2015, IMA J MATH CONTROL I, V32, P703, DOI 10.1093/imamci/dnu015
   Liu LF, 2015, PHYS SCRIPTA, V90, DOI 10.1088/0031-8949/90/8/085205
   Liu YQ, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750033X
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Nesa N, 2019, J INF SECUR APPL, V47, P320, DOI 10.1016/j.jisa.2019.05.017
   Persohn KJ, 2012, CHAOS SOLITON FRACT, V45, P238, DOI 10.1016/j.chaos.2011.12.006
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Tang JY, 2019, MULTIMED TOOLS APPL, V78, P24765, DOI 10.1007/s11042-019-7602-8
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang SH, 2004, INT J MOD PHYS B, V18, P2617, DOI 10.1142/S0217979204025798
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu Y, 2014, IEEE T CIRCUITS-I, V61, P3469, DOI 10.1109/TCSI.2014.2336512
   Xie YY, 2016, J LIGHTWAVE TECHNOL, V34, P5101, DOI 10.1109/JLT.2016.2606121
   Yuan ZS, 2015, ACTA PHYS SIN-CH ED, V64, DOI 10.7498/aps.64.240503
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 42
TC 9
Z9 9
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19237
EP 19261
DI 10.1007/s11042-021-10680-y
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621742800006
DA 2024-07-18
ER

PT J
AU Raj, A
   Maji, K
   Shetty, SD
AF Raj, Aparna
   Maji, Kavita
   Shetty, Sujala D.
TI Ethereum for Internet of Things security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things (IoT); Ethereum; Blockchain; IoT Security; Home
   automation systems; IoT applications
ID IOT SECURITY; BLOCKCHAIN
AB The influence of Internet of Things (IoT) is growing exponentially in the consumer patterns and will continue to increase in the coming years. With millions of interconnected devices over the internet, IoT is currently running into its monumental security and centralization issues that can be resolved using Blockchain. This paper aims to demonstrate the use of a smart contract on a private Ethereum Blockchain (also known as permission less Blockchain) to check whether a user holds enough tokens to utilize a service. Private in this context implies a private instance of the Ethereum implementation in which we make use of the same security and principles of the Ethereum main chain on a personal network of connected IoT devices which improves the overall privacy and security of the system than the traditional schemes. The proposed model consists of a target IoT device controlled by a Raspberry Pi, running a client application that makes decisions based on the state of the smart contract. With this environment, we are able to achieve the following goals: (1) no data leaves the private network (2) all services are employed with transparency and accountability (3) only registered devices can issue requests for using a service. Although the demonstration is made on a home network, the model presented in this paper can be utilized in commercial environments where any service can be availed from a wide array of smart devices through a mobile application.
C1 [Raj, Aparna; Maji, Kavita; Shetty, Sujala D.] Birla Inst Technol & Sci, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
RP Raj, A (corresponding author), Birla Inst Technol & Sci, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
EM p20190003@dubai.bits-pilani.ac.in; h20180002@dubai.bits-pilani.ac.in;
   sujala@dubai.bits-pilani.ac.in
RI Raj, Dr. Aparna/AAW-4893-2021
OI Raj, Dr. Aparna/0000-0002-0094-0444
CR Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ali J A T, 2020, SECURE IOT COMMUNICA
   Alrubei S., 2019, IEEE Cyber Security, P1
   Asadullah M, 2016, INT CONF ROBOT ARTIF, P27, DOI 10.1109/ICRAI.2016.7791223
   ATLAM H., 2019, Technical aspects of blockchain and iot advances in computers
   Aung YN, 2017, PROC INT CONF INF TE, P219
   Buterin V., 2014, CISC VIS NETW IND GL, V3, P1, DOI DOI 10.1145/2939672.2939785
   Chen HS, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3391195
   Cheng JR, 2021, MULTIMED TOOLS APPL, V80, P30623, DOI 10.1007/s11042-020-09368-6
   Dorri Ali, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P618, DOI 10.1109/PERCOMW.2017.7917634
   Dorri A, 2019, J PARALLEL DISTR COM, V134, P180, DOI 10.1016/j.jpdc.2019.08.005
   Fakhri D., 2019, ISESD 2018 INT S EL, DOI [10.1109/ISESD.2018.8605485, DOI 10.1109/ISESD.2018.8605485]
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Hossain M., 2020, INT J RECENT TECHNOL, V8
   Hsu HT, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P674, DOI [10.1109/ccoms.2019.8821678, 10.1109/CCOMS.2019.8821678]
   Huh S, 2017, INT CONF ADV COMMUN, P464, DOI 10.23919/ICACT.2017.7890132
   Jeyanthi N, SECURITY BREACHES TH, DOI [10.4018/978-1-5225-2296-6, DOI 10.4018/978-1-5225-2296-6]
   Jones MT, 2011, PLATFORM EMULATION B
   Ma M, 2019, ACM INT C P SER, P525, DOI [10.1145/3377170.3377281, DOI 10.1145/3377170.3377281]
   Makhdoom I, 2019, J NETW COMPUT APPL, V125, P251, DOI 10.1016/j.jnca.2018.10.019
   Mohanta BK, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100107
   Monti M, 2017, ARTIF LIFE, V23, P552, DOI 10.1162/ARTL_a_00247
   Mtetwa N., 2019, 2019 INT MULT INF TE, DOI [10.1109/IMITEC45504.2019.9015865, DOI 10.1109/IMITEC45504.2019.9015865]
   Nakahara Shinichi, 2019, European Journal of Taxonomy, P1, DOI 10.5852/ejt.2019.551
   Nguyen DC, 2020, J NETW COMPUT APPL, V166, DOI 10.1016/j.jnca.2020.102693
   Paunikar NO, 2020, INT J ALL RES WRIT, V1, P19
   Poh GS, 2021, IEEE T DEPEND SECURE, V18, P1095, DOI 10.1109/TDSC.2019.2914911
   Ravi R., 2020, INT J RECENT TECHNOL, V8, P2277, DOI [10.35940/ijrte.D9547.018520, DOI 10.35940/IJRTE.D9547.018520]
   Reyna A, 2018, FUTURE GENER COMP SY, V88, P173, DOI 10.1016/j.future.2018.05.046
   Rifi N., 2017, Ubiquitous Wireless Broadband (ICUWB), 2017 IEEE 17th International Conference on, P1
   Shouran Z., 2019, INT J COMPUTER APPL, V182, P3, DOI DOI 10.5120/IJCA2019918450
   Singh P, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER-HUMAN INTERACTION RESEARCH AND APPLICATIONS (CHIRA), P221, DOI 10.5220/0008494402210228
   Tantidham T, 2019, INT CONF PERVAS COMP, P888, DOI [10.1109/percomw.2019.8730816, 10.1109/PERCOMW.2019.8730816]
   Thakore R, 2019, PROCEDIA COMPUT SCI, V155, P704, DOI 10.1016/j.procs.2019.08.101
   Wöhrer M, 2018, 2018 IEEE 1ST INTERNATIONAL WORKSHOP ON BLOCKCHAIN ORIENTED SOFTWARE ENGINEERING (IWBOSE), P2, DOI 10.1109/IWBOSE.2018.8327565
   Yin CY, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0195-4
NR 36
TC 12
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18901
EP 18915
DI 10.1007/s11042-021-10715-4
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619905700003
DA 2024-07-18
ER

PT J
AU Kohli, A
   Gupta, A
AF Kohli, Aditi
   Gupta, Abhinav
TI Detecting DeepFake, FaceSwap and Face2Face facial forgeries using
   frequency CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE First keyword; Second keyword; More
AB The face of a person plays a vital role in any communication or visual content. To enhance this visual content, popular and easy accessible editing tools are used. However, there malicious usage is spreading disharmony in the society, by tampering video evidences, defaming a person's image etc. Therefore a robust detection method is required to authenticate the visual content. Thus, a novel method is proposed to detect facial forgeries. The proposed method extracts faces from a target video and convert them into frequency domain using two dimensional global discrete Cosine transform (2D- GDCT). Thereafter, a 3 layered frequency convolutional neural network (fCNN) is employed to detect forged facial image. The proposed method is trained and tested on FaceForensics++ dataset and Celeb-DF(v2) dataset. In addition, its robustness is evaluated on standardized benchmark dataset and compared with the state-of-the-art methods to prove its effectiveness.
C1 [Kohli, Aditi; Gupta, Abhinav] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, Dept Elect & Commun Engn, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
EM abhinav.gupta@jiit.ac.in
OI GUPTA, ABHINAV/0000-0002-1939-5407
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   Baek JY, 2020, IEEE ACCESS, V8, P45421, DOI 10.1109/ACCESS.2020.2968612
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Li Y., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YM, 2019, PROC CVPR IEEE, P8712, DOI 10.1109/CVPR.2019.00892
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Rahmouni Nicolas, 2017, Information Forensics and Security (WIFS), 2017 IEEE Workshop on, P1
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu JJ, 2016, ADV NEUR IN, V29
   Yang L.-C., 2017, ARXIV PREPRINT ARXIV, P324
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang XJ, 2019, 2019 IEEE 18TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P229, DOI 10.1109/nca.2019.8935043
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 30
TC 20
Z9 20
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18461
EP 18478
DI 10.1007/s11042-020-10420-8
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300003
DA 2024-07-18
ER

PT J
AU Nadian-Ghomsheh, A
   Farahani, B
   Kavian, M
AF Nadian-Ghomsheh, Ali
   Farahani, Bahar
   Kavian, Mohammad
TI A hierarchical privacy-preserving IoT architecture for vision-based hand
   rehabilitation assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Machine learning; Privacy-preserving; Range of
   motion measurement; Physical rehabilitation
ID EHEALTH PROMISES; CHALLENGES; RELIABILITY; STROKE
AB The healthcare industry requires the integration of digital technologies, such as Artificial Intelligence (AI) and the Internet of Things (IoT), to their full potential, particularly during this challenging time and the recent outbreak of the COVID-19 pandemic, which resulted in the disruptions in healthcare delivery, service operations, and shortage of healthcare personnel. However, every opportunity has barriers and bumps, and when it comes to IoT healthcare, data privacy is one of the main growing issues. Despite the recent advances in the development of IoT healthcare architectures, most of them are invasive for the data subjects. In this context, the broad applications of AI in the IoT domain have also been hindered by emerging strict legal and ethical requirements to protect individual privacy. Camera-based solutions that monitor human subjects in everyday settings, e.g., for Online Range of Motion (ROM) detection, are making this problem even worse. One actively practiced branch of such solutions is telerehabilitation, which provides remote solutions for the physically impaired to regain their strength and get back to their normal daily routines. The process usually involves transmitting video/images from the patient performing rehabilitation exercises and applying Machine Learning (ML) techniques to extract meaningful information to help therapists devise further treatment plans. Thereby, real-time measurement and assessment of rehabilitation exercises in a reliable, accurate, and Privacy-Preserving manner is imperative. To address the privacy issue of existing solutions, this paper proposes a holistic Privacy-Preserving (PP) hierarchical IoT solution that simultaneously addresses the utilization of AI-driven IoT and the demands for data protection. Furthermore, the efficiency of the proposed architecture is demonstrated by a novel machine learning-based system that allows immediate assessment and extraction of ROM as the critical information for analyzing the progress of patients.
C1 [Nadian-Ghomsheh, Ali; Farahani, Bahar; Kavian, Mohammad] Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
C3 Shahid Beheshti University
RP Nadian-Ghomsheh, A; Farahani, B (corresponding author), Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
EM a_nadian@sbu.ac.ir; b_farahani@sbu.ac.ir
OI Nadian-Ghomsheh, Ali/0000-0002-2215-409X; Farahani,
   Bahar/0000-0002-7016-6853
CR Acar A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3214303
   Al-Rubaie M, 2019, IEEE SECUR PRIV, V17, P49, DOI 10.1109/MSEC.2018.2888775
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Bonawitz K., 2019, ARXIV190201046, V1, P374
   BOONE DC, 1978, PHYS THER, V58, P1355, DOI 10.1093/ptj/58.11.1355
   Bronzino J.D., 2000, The Biomedical Engineering Handbook, V2nd
   Carter TI, 2009, J HAND SURG-AM, V34A, P1422, DOI 10.1016/j.jhsa.2009.06.002
   Chen SZ, 2020, SENSOR REV, V40, P121, DOI 10.1108/SR-03-2019-0074
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Eini DS, 2010, P 8 INT C DIS VIRT R, P123
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Fern'ndez-Baena, 2012, 4 INT C INT NETW COL, DOI 10.1109/iNCoS.2012.66
   Firouzi F, 2018, IEEE T COMPUT AID D, V37, P2965, DOI 10.1109/TCAD.2018.2801227
   GAJDOSIK RL, 1987, PHYS THER
   GEORGEU G, 2002, J HAND SURG-BRIT EUR
   Gibert S, 2012, COMPUT METHOD BIOMEC, DOI 10.1080/10255842.2012.713730
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Ji Z., 2014, Differential privacy and machine learning: a survey and review
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   KAKUMANU P, 2007, PATTERN RECOGN
   Kavian, 2020, INT C MACH VIS IM PR, DOI 10.1109/MVIP49855.2020.9116876
   Knepley KD, 2021, TELEMED E-HEALTH, V27, P239, DOI 10.1089/tmj.2020.0019
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Trejo RL, 2017, CONSUM COMM NETWORK, P137, DOI 10.1109/CCNC.2017.7983095
   Mastos M, 2007, CLIN REHABIL, V21, P47, DOI 10.1177/0269215506073494
   McVeigh Kimberly H, 2016, J Hand Surg Am, V41, pe21, DOI 10.1016/j.jhsa.2015.12.014
   Mortazavi F, 2019, MULTIMED TOOLS APPL, V78, P32055, DOI 10.1007/s11042-019-08020-2
   Mortazavi F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200992
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Nadian-Ghomsheh, 2017, 10 IR C MACH VIS IM, DOI 10.1109/IranianMVIP.2017.8342336
   Naji S, 2019, ARTIF INTELL REV, V52, P1041, DOI 10.1007/s10462-018-9664-9
   Paracchini M, 2020, PATTERN RECOGN LETT, V131, P322, DOI 10.1016/j.patrec.2019.12.021
   Pendleton HM., 2017, Pedretti's occupational therapy, V8th
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Reither LR, 2018, DISABIL REHABIL-ASSI, V13, P54, DOI 10.1080/17483107.2016.1278473
   Roy, 2019, RELIABILITY INCLINOM, V39, P655
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   SHAMSI M, 2019, MED REHAB
   Shifa A, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103859
   THOMAS CK, 1997, EXP NEUROL
   Timmermans AAA, 2010, NEUROREHAB NEURAL RE, V24, P858, DOI 10.1177/1545968310368963
   Veerbeek JM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087987
   Voigt P., 2017, The EU General Data Protection Regulation (GDPR): a practical guide, V1st
   WANG Y, 2013, P 12 ACM SIGGRAPH
   WENG J, 2017, PROC CVPR IEEE
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 48
TC 11
Z9 11
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31357
EP 31380
DI 10.1007/s11042-021-10563-2
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000617861300002
PM 33613083
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zaccagnino, R
   Capo, C
   Guarino, A
   Lettieri, N
   Malandrino, D
AF Zaccagnino, Rocco
   Capo, Carmine
   Guarino, Alfonso
   Lettieri, Nicola
   Malandrino, Delfina
TI Techno-regulation and intelligent safeguards Analysis of touch gestures
   for online child protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online child protection; Touch-based gesture analysis; Machine learning;
   Multi-view learning; Techno-regulation
ID AUTHENTICATION; CLASSIFICATION; SMOTE
AB The growth of Internet and the pervasiveness of ICT have led to a radical change in social relationships. One of the drawbacks of this change is the exposure of individuals to threats during online activities. In this context, the techno-regulation paradigm is inspiring new ways to safeguard legally interests by means of tools allowing to hamper breaches of law. In this paper, we focus on the exposure of individuals to specific online threats when interacting with smartphones. We propose a novel techno-regulatory approach exploiting machine learning techniques to provide safeguards against threats online. Specifically, we study a set of touch-based gestures to distinguish between underages or adults who is accessing a smartphone, and so to guarantee protection. To evaluate the proposed approach's effectiveness, we developed an Android app to build a dataset consisting of more than 9000 touch-gestures from 147 participants. We experimented both single-view and multi-view learning techniques to find the best combination of touch-gestures able of distinguishing between adults and underages. Results show that the multi-view learning combining scrolls, swipes, and pinch-to-zoom gestures, achieves the best ROC AUC (0.92) and accuracy (88%) scores.
C1 [Zaccagnino, Rocco; Capo, Carmine; Guarino, Alfonso; Malandrino, Delfina] Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II, I-84084 Fisciano, SA, Italy.
   [Lettieri, Nicola] Natl Inst Publ Policy Anal INAPP, Corso Italia 33, I-00198 Rome, Italy.
C3 University of Salerno
RP Zaccagnino, R (corresponding author), Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II, I-84084 Fisciano, SA, Italy.
EM rzaccagnino@unisa.it; alguarino@unisa.it; n.lettieri@inapp.org;
   dmalandrino@unisa.it
RI Zaccagnino, Rocco/ADA-9205-2022; MALANDRINO, Delfina/GSE-2906-2022;
   MALANDRINO, Delfina/JAX-3427-2023
OI Zaccagnino, Rocco/0000-0002-9089-5957; Capo,
   Carmine/0000-0002-7299-4804; Malandrino, Delfina/0000-0003-2693-0196;
   Lettieri, Nicola/0000-0001-6342-3252
FU Universita degli Studi di Salerno
FX Open Access funding provided by Universita degli Studi di Salerno.
CR Agrawal Amritanshu, 2018, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). Proceedings, P1050, DOI 10.1145/3180155.3180197
   Anthony L, 2014, PERS UBIQUIT COMPUT, V18, P1471, DOI 10.1007/s00779-013-0749-9
   BALLARD L., 2006, P 10 INT WORKSH FRO
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Bo C., 2013, Proceedings of the International Conference on Mobile Computing and Networking MobiCom, P187, DOI [DOI 10.1145/2500423.2504572, 10.1145/2500423.2504572, 10.1145/2500423.2504572.]
   Bratton BH, 2015, SOFTW STUD, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brownsword R., 2008, Regulating Technologies: Legal Futures, Regulatory Frames and Technological Fixes
   Buzzi MC, 2017, MULTIMED TOOLS APPL, V76, P5141, DOI 10.1007/s11042-016-3594-9
   Cavoukian A., 2011, A white paper for regulators, decision-makers and policy-makers
   Chaczko Z, 2013, ADV METHODS APPL COM, V6
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Choo BJ, 2019, MULTIMED TOOLS APPL, V78, P28805, DOI 10.1007/s11042-018-6630-0
   Chu F, 2005, STUD FUZZ SOFT COMP, V177, P343
   Cosimato A, 2019, IEEE ACCESS, V7, P123289, DOI 10.1109/ACCESS.2019.2937743
   Cozza F, 2020, COMPUT NETW, V167, DOI 10.1016/j.comnet.2019.106993
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Eskander GS, 2014, INFORM SCIENCES, V259, P170, DOI 10.1016/j.ins.2013.09.004
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Fratello M, 2017, NEUROINFORMATICS, V15, P199, DOI 10.1007/s12021-017-9324-2
   Hassan S., 2017, The journal of field actions, V17, P88
   Hildebrandt M., 2011, Legisprudence, V5, P223, DOI [10.5235/175214611797885693, DOI 10.5235/175214611797885693]
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Jaccard P., 1901, B SOC VAUDOISE SCI N, V37, P547
   Langheinrich Marc, 2001, Ubicomp 2001: Ubiquitous Computing, P273
   Leenes R., 2011, Legisprudence, V5, P143, DOI DOI 10.5235/175214611797885675
   Lettieri N, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11070163
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Li YF, 2018, BRIEF BIOINFORM, V19, P325, DOI 10.1093/bib/bbw113
   Li YF, 2015, IEEE INT C BIOINFORM, P1665, DOI 10.1109/BIBM.2015.7359925
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Livingstone S, 2009, Z PSYCHOL, V217, P236, DOI 10.1027/0044-3409.217.4.236
   Masood Rahat, 2018, Proceedings on Privacy Enhancing Technologies, V2018, P122, DOI 10.1515/popets-2018-0016
   Mitchell KJ, 2005, CHILD ABUSE NEGLECT, V29, P753, DOI 10.1016/j.chiabu.2004.05.008
   Nacher V, 2015, INT J HUM-COMPUT ST, V73, P37, DOI 10.1016/j.ijhcs.2014.08.004
   Narudin FA, 2016, SOFT COMPUT, V20, P343, DOI 10.1007/s00500-014-1511-6
   Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   PewResearchCenter, 2018, TEENS SOCIAL MEDIA T
   Richardson CR, 2002, JAMA-J AM MED ASSOC, V288, P2887, DOI 10.1001/jama.288.22.2887
   Rosenblatt W., 2001, DIGITAL RIGHTS MANAG
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rzecki K, 2017, INFORM SCIENCES, V415, P70, DOI 10.1016/j.ins.2017.05.041
   Sae-Bae N., 2012, Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems, P977, DOI DOI 10.1145/2207676.2208543
   Shen C, 2018, INFORM SCIENCES, V430, P538, DOI 10.1016/j.ins.2017.11.058
   SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615
   Nguyen T, 2019, COMPUT SECUR, V84, P334, DOI 10.1016/j.cose.2019.04.001
   Van den Berg B., 2013, Human law and computer law: Comparative perspectives, P67
   Van Hulse Jason, 2007, P 24 INT C MACH LEAR, P935, DOI DOI 10.1145/1273496.1273614
   Vatavu RD, 2015, LECT NOTES COMPUT SC, V9299, P1, DOI 10.1007/978-3-319-22723-8_1
   Villamor C., 2010, Touch Gesture Reference Guide
   Wojciechowski A, 2017, MULTIMED TOOLS APPL, V76, P5419, DOI 10.1007/s11042-016-3995-9
   Zhao RB, 2018, IEEE T SIGNAL PROCES, V66, P1155, DOI 10.1109/TSP.2017.2784360
NR 56
TC 20
Z9 20
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15803
EP 15824
DI 10.1007/s11042-020-10446-y
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615173600002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Khwildi, R
   Zaid, AO
   Dufaux, F
AF Khwildi, Raoua
   Ouled Zaid, Azza
   Dufaux, Frederic
TI Query-by-example HDR image retrieval based on CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Convolutional neural networks; High dynamic range;
   Feature extraction; VGGNet; Perceptually uniform encoding
ID NETWORK
AB Due to the expension of High Dynamic Range (HDR) imaging applications into various aspects of daily life, an efficient retrieval system, tailored to this type of data, has become a pressing challenge. In this paper, the reliability of Convolutional Neural Networks (CNN) descriptor and its investigation for HDR image retrieval are studied. The main idea consists in exploring the use of CNN to determine HDR image descriptor. Specifically, a Perceptually Uniform (PU) encoding is initially applied to the HDR content to map the luminance values in a perceptually uniform scale. Afterward, the CNN features, using Fully Connected (FC) layer activation, are extracted and classified by applying the Support Vector Machines (SVM) algorithm. Experimental evaluation demonstrates that the CNN descriptor, using the VGG19 network, achieves satisfactory results for describing HDR images on public available datasets such as PascalVoc2007, Cifar-10 and Wang. The experimental results also show that the features, after a PU processing, are more descriptive than those directly extracted from HDR contents. Finally, we show the superior performance of the proposed method against a recent state-of-the-art technique.
C1 [Khwildi, Raoua; Ouled Zaid, Azza] Univ Tunis El Manar, Lab Syst Commun, Ecole Natl Ingenieurs Tunis, BP 37 Belvedere, Tunis 1002, Tunisia.
   [Dufaux, Frederic] Univ Paris Saclay, Lab Signaux & Syst, CNRS, Cent Supelec, F-91190 Gif Sur Yvette, France.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite Paris Saclay; Universite Paris Cite; Centre National
   de la Recherche Scientifique (CNRS)
RP Khwildi, R (corresponding author), Univ Tunis El Manar, Lab Syst Commun, Ecole Natl Ingenieurs Tunis, BP 37 Belvedere, Tunis 1002, Tunisia.
EM khwildi.raoua135@gmail.com; azza.ouledzaid@isi.rnu.tn;
   frederic.dufaux@l2s.centralesupelec.fr
RI Dufaux, Frederic/HJJ-1496-2023
OI Dufaux, Frederic/0000-0001-6388-4112
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2003, OPENEXR
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   Chalmers A, 2017, SIGNAL PROCESS-IMAGE, V54, P49, DOI 10.1016/j.image.2017.02.003
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Dufaux F., 2016, High Dynamic Range Video: From Acquisition, to Display and Applications
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Hayat T, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONIC AND ELECTRICAL ENGINEERING (ICE CUBE), P1, DOI 10.1109/ICECUBE.2016.7495203
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Husain SS, 2019, IEEE T IMAGE PROCESS, V28, P5201, DOI 10.1109/TIP.2019.2917234
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Khwildi R, 2016, INT C MACH VIS
   Khwildi R, 2020, VISUAL COMPUT, V36, P1111, DOI 10.1007/s00371-019-01719-1
   Khwildi R, 2018, I C COMP SYST APPLIC
   Kim BK, 2016, SIGNAL IMAGE VIDEO P, V10, P1425, DOI 10.1007/s11760-016-0942-1
   Kovaleski RP, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P49, DOI 10.1109/SIBGRAPI.2014.29
   Kovaleski RP, 2009, VISUAL COMPUT, V25, P539, DOI 10.1007/s00371-009-0327-3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Masia B, 2017, MULTIMED TOOLS APPL, V76, P631, DOI 10.1007/s11042-015-3036-0
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pribyl B, 2016, J VIS COMMUN IMAGE R, V38, P141, DOI 10.1016/j.jvcir.2016.02.007
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rana A, 2015, IEEE INT SYM MULTIM, P289, DOI 10.1109/ISM.2015.58
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Seidel HP, 2008, P SPIE, P6806
   Seidel P, 2015, High Dynamic Range Imaging, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2020, INT J COMPUT VISION, V128, P2243, DOI 10.1007/s11263-020-01305-2
   Tang Y., 2013, DEEP LEARNING USING
   Tolias G., 2016, Conference Track Proceedings,
   Uricchio T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1020, DOI 10.1109/ICCVW.2015.134
   Vaccaro Federico, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P311, DOI 10.1145/3372278.3390732
   Vinyals Oriol., 2012, Advances in Neural Information Processing Systems, P2834
   Ward G., 1991, REAL PIXELS, DOI [10.1016/B978-0-08-050754-5.50025-6, DOI 10.1016/B978-0-08-050754-5.50025-6]
   Zhang JS, 2017, IEEE I CONF COMP VIS, P4529, DOI 10.1109/ICCV.2017.484
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zheng Liang, 2016, arXiv preprint arXiv
   Zhu HG, 2015, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2015.7351502
NR 53
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15413
EP 15428
DI 10.1007/s11042-020-10416-4
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kapoor, K
   Rani, S
   Kumar, M
   Chopra, V
   Brar, GS
AF Kapoor, Kanika
   Rani, Shalli
   Kumar, Munish
   Chopra, Vinay
   Brar, Gubinder Singh
TI Hybrid local phase quantization and grey wolf optimization based SVM for
   finger vein recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Finger vein; Support vector machines (SVM); Local directional
   pattern (LDP); Local phase quantization (LQP); Grey wolf optimization
   (GWO)
AB As a novelist and the most secure biometric method, finger vein recognition has gained substantial significance and various pertinent researches have been reported in literature. However, it is difficult to extract a more reliable and accurate finger vein pattern due to the random noise, poor lighting, illumination variation, image deformation and blur. Furthermore, improper parameter settings of SVMs lead to poor classification accuracy and apparently, not much relevant research has been conducted on its optimal parameter setting. To alleviate these problems, this paper proposes an efficient finger vein recognition framework consisting of the hybrid Local Phase Quantization (LPQ) for robust feature extraction and Grey Wolf Optimization based SVM (GWO-SVM) to compute the best parameter combination of SVM for optimal results of binary classification. Finger vein features are first extracted by integrating LPQ, which is invariant to motion blur and deformation, with Local Directional Pattern (LDP), which is robust to random noise and illumination variation, to augment the recognition performance and reduce the computational time. Then, GWO-SVM is used for classification in order to maximize the classification accuracy by determining the optimal SVM parameters. The extensive experimental results indicate remarkable performance and significant enhancements in terms of recognition accuracy by the proposed framework compared to the existing techniques and prove the effectiveness of the proposed framework on four tested finger vein datasets. It has outperformed the typical SVM approach and kNCN-SRC two-stage methodology via achieving the recognition accuracy of 98% and equal error rate as low as 0.1020%.
C1 [Kapoor, Kanika; Chopra, Vinay] DAV Inst Engn & Technol DAVIET, CSE Dept, Jalandhar, Punjab, India.
   [Rani, Shalli] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
   [Brar, Gubinder Singh] AIET, CSE Dept, Faridkot, Punjab, India.
C3 DAV Institute of Engineering & Technology; Chitkara University, Punjab
RP Rani, S (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM kannu.kapoor99@gmail.com; shalli.rani@chitkara.edu.in;
   munishcse@gmail.com; vinaychopra222@yahoo.co.in; maatibrar@gmail.com
RI Rani, Shalli/AGY-9513-2022; Kumar, Munish/P-7756-2018
OI Rani, Shalli/0000-0002-8474-9435; Kumar, Munish/0000-0003-0115-1620;
   Brar, Gurbinder Singh/0009-0006-7128-2844
CR Akintoye K. A., 2018, Journal of Computational and Theoretical Nanoscience, V8, P196
   [Anonymous], 2006, Handbook of Multibiometrics
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   Cao K., 2018, IEEE T PATTERN ANAL
   Cardoso, 2014, IEEE IPAS 14 INT IM
   Chiu CC, 2018, MICROSYST TECHNOL, V24, P4165, DOI 10.1007/s00542-017-3701-5
   Das R, 2019, IEEE T INF FOREN SEC, V14, P360, DOI 10.1109/TIFS.2018.2850320
   Dev R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1209, DOI 10.1109/CCAA.2017.8229983
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Gao, 2018, 2018 INT C SEC PRIV
   Giri KJ, 2017, STUD COMPUT INTELL, V660, P93, DOI 10.1007/978-3-319-44790-2_5
   Gull S, 2018, Journal of Ambient Intelligence and Humanized Computing, P1
   Gupta P, 2015, DIGIT SIGNAL PROCESS, V38, P43, DOI 10.1016/j.dsp.2014.12.003
   Gupta S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES FOR SMART NATION (IC3TSN), P306, DOI 10.1109/IC3TSN.2017.8284496
   Hashimoto J., 2006, S VLSI CIRC, P5, DOI DOI 10.1109/VLSIC.2006.1705285
   He CL, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P456, DOI 10.1109/ICCI-CC.2017.8109788
   Hsia CH, 2018, IEEE SENS J, V18, P790, DOI 10.1109/JSEN.2017.2772799
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Ibrahim MZ., 2017, J TELECOMM ELECT COM, V10, P167
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Jabid T, 2010, IEEE ICCE
   Jadhav M., 2015, INT J COMPUTER APPL, P14
   Kalaimathi P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P723, DOI 10.1109/ICCSP.2016.7754239
   Khellat-kihel S, 2014, 2014 FIRST INTERNATIONAL IMAGE PROCESSING, APPLICATIONS AND SYSTEMS CONFERENCE (IPAS)
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Li, 2017, IEEE INT C ID SEC BE
   Li J., 2017, 2017 IEEE CHIN AUT C
   Liu CG, 2016, IEEE IMAGE PROC, P3141
   Liu HY, 2019, NEUROCOMPUTING, V365, P62, DOI 10.1016/j.neucom.2019.07.057
   Liu WJ, 2017, C IND ELECT APPL, P205, DOI 10.1109/ICIEA.2017.8282842
   Lu Y, 2018, IEEE ACCESS, V6, P56445, DOI 10.1109/ACCESS.2018.2872493
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ortiz N., 2018, CES, V11, P1677, DOI [10.12988/ces.2018.84166, DOI 10.12988/CES.2018.84166]
   Piciucco E, 2018, IET BIOMETRICS, V7, P439, DOI 10.1049/iet-bmt.2017.0192
   Rawate, 2017, IJSRSET, V3, P578
   Reddy, 2017, IEEE INT C SMART TEC
   Rosdi, 2018, IET BIOMETRICS, P1
   Rosdi BA, 2015, AIP CONF PROC, V1643, P649, DOI 10.1063/1.4907507
   Saadat, 2016, IEEE 1 C SWARM INT E
   Sabhanayagam T., 2018, International Journal of Applied Engineering Research, V13, P2276, DOI [10.1016/j.matpr.2021.07.005, DOI 10.1016/J.MATPR.2021.07.005]
   Sehrawat V. Siwach, 2017, INT J ADV RES COMPUT, V8, P1818
   Shaheed K, 2018, INFORMATION, V9, DOI 10.3390/info9090213
   Shazeeda S, 2019, IEEE ACCESS, V7, P5874, DOI 10.1109/ACCESS.2018.2889506
   Shazia Bakhtiar Affendi, 2016, INDIAN J SCI TECHNOL, V9, DOI [10.17485/ijst/2016/v9i48/109315, DOI 10.17485/ijst/2016/v9i48/109315]
   Syarif MA, 2017, MULTIMED TOOLS APPL, V76, P6859, DOI 10.1007/s11042-016-3315-4
   Szymkowski M, 2018, LECT NOTES COMPUT SC, V11127, P80, DOI 10.1007/978-3-319-99954-8_8
   Ting E., 2018, J Telecommun Electron Comput Eng, V10, P167
   Veluchamy S, 2017, IET BIOMETRICS, V6, P232, DOI 10.1049/iet-bmt.2016.0112
   Wu GQ, 2020, NEURAL NETWORKS, V122, P24, DOI 10.1016/j.neunet.2019.10.002
   Wu JD, 2011, EXPERT SYST APPL, V38, P14284, DOI 10.1016/j.eswa.2011.05.086
   Wu JD, 2011, EXPERT SYST APPL, V38, P5423, DOI 10.1016/j.eswa.2010.10.013
   Xiao R.Y., 2012, INTELLIGENT SCI INTE, P364
   Yang G, 2017, IEEE INT C AC SPEECH
   Yang GP, 2012, SENSORS-BASEL, V12, P1738, DOI 10.3390/s120201738
   Yang LM, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105483
   Yang L, 2018, IEEE T CIRC SYST VID, V28, P1892, DOI 10.1109/TCSVT.2017.2684833
   Yang L, 2017, IEEE ACCESS, V5, P21020, DOI 10.1109/ACCESS.2017.2728797
   Yang L, 2014, LECT NOTES COMPUT SC, V8833, P234, DOI 10.1007/978-3-319-12484-1_26
   Yang WM, 2014, IEICE T INF SYST, VE97D, P1371, DOI 10.1587/transinf.E97.D.1371
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yin, 2017, FINGER VEIN RECOGNIT
   Yin Y., 2016, LEARNING DISCRIMINAT
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou, 2014, FEATURE COMPONENT BA
   Zhou LZ, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416500154
NR 69
TC 21
Z9 22
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15233
EP 15271
DI 10.1007/s11042-021-10548-1
EA FEB 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613993900001
DA 2024-07-18
ER

PT J
AU Wati, V
   Kusrini, K
   Al Fatta, H
   Kapoor, N
AF Wati, Vera
   Kusrini, Kusrini
   Al Fatta, Hanif
   Kapoor, Nitika
TI Security of facial biometric authentication for attendance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attendance; Authentication; Biometric; Face detection; Viola-jones;
   Gabor wavelet; Feature extraction
AB Face image processing has become one of the fields of computer vision in processing computerized image patterns; the face becomes one of the vital biometrics that stores essential information used in predicting the characteristics of a person. Biometric techniques with facial recognition systems are now required in various fields, including business, one of which is the attendance marking system that is a crucial repetitive transaction requirement because it relates to employee productivity. In terms of ethics, attendance recording using a person's face has many benefits; one of them is removing the necessity to make direct contact with the scanning device. Before doing face recognition, one of the preprocessing stages is face detection as an effort to find the existence of a face image consisting of eyes, nose, mouth, and other facial features. This research employed Viola-Jones method for face detection, Gabor Wavelet for feature extraction, and Template Matching. Two scenarios are applied for attendance recording, individual face recording, and group face recording where several faces are captured simultaneously, and each face is extracted and recognized. For Individual attendance recognition, this research achieved an accuracy of 75%, recall 64%, and precision of 88%. The better result is shown on simultaneous/group face recognition, and the research achieved 88% accuracy, 75% of recall, and 97% of the precision score.
C1 [Wati, Vera] Univ Tunas Pembangunan Surakarta, Jl Balekambang Lor 1, Surakarta, Jawa Tengah, Indonesia.
   [Kusrini, Kusrini; Al Fatta, Hanif] Univ AMIKOM Yogyakarta, Jl Ringroad Utara Condong Catur Depok Sleman, Yogyakarta, Indonesia.
   [Kapoor, Nitika] Chandigarh Univ, NH-95 Chandigarh Ludhiana Highway, Mohali, Punjab, India.
C3 Chandigarh University
RP Wati, V (corresponding author), Univ Tunas Pembangunan Surakarta, Jl Balekambang Lor 1, Surakarta, Jawa Tengah, Indonesia.
EM vera.w@lecture.utp.ac.id; kusrini@amikom.ac.id; hanif.a@amikom.ac.id;
   nitika.cse@cumail.in
RI Phull, Nitika/GLU-4427-2022; Kusrini, Kusrini/C-7787-2015
OI Kusrini, Kusrini/0000-0001-9573-3909
CR Alphonse AS, 2019, MULTIMED TOOLS APPL, V78, P23369, DOI 10.1007/s11042-019-7646-9
   Banerjee SP, 2012, J PATTERN RECOGNIT R, V7, P116, DOI 10.13176/11.427
   Barina D, 2016, ABS160202 CORR, P1
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhattacharyya D, 2009, INT J GRID DISTRIB, V2, P13
   Boka A, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P933, DOI 10.1109/CCWC.2019.8666483
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Chatterjee D, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P62, DOI 10.1109/ICRCICN.2016.7813552
   Christou N, 2019, ADV INTELL SYST COMP, V797, P539, DOI 10.1007/978-981-13-1165-9_49
   Crisan S, 2017, SIGNAL PROC SEC TEC, P21, DOI 10.1007/978-3-319-47301-7_2
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Gao Q., 2012, INT ENERGY SUSTAINAB, P1, DOI DOI 10.1109/IESC.2012.6217197
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kim KH, 2017, J KOREAN PHYS SOC, V71, P231, DOI 10.3938/jkps.71.231
   Kim Y, 2007, IEEE C BIOM THERO AP, DOI [10.1109/BTAS.2007.4401913, DOI 10.1109/BTAS.2007.4401913]
   Kristian Y, 2018, JURNAL NASIONAL TEKN, P7, DOI [10.22146/jnteti.v7i3.440, DOI 10.22146/JNTETI.V7I3.440]
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Nedjah N, 2017, FUTURE GENER COMP SY, V76, P18, DOI 10.1016/j.future.2017.05.008
   Nyein T, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGIES (ICAIT), P171, DOI [10.1109/AITC.2019.8921316, 10.1109/aitc.2019.8921316]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pato J.N., 2010, Biometric recognition: Challenges and opportunities, V1st
   Patro KK, 2020, J SUPERCOMPUT, V76, P858, DOI 10.1007/s11227-019-03022-1
   Praveenbalaji D, 2020, INT CONF ADVAN COMPU, P1449, DOI [10.1109/icaccs48705.2020.9074246, 10.1109/ICACCS48705.2020.9074246]
   Sameem MSI, 2016, 2016 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P62, DOI 10.1109/ICOSST.2016.7838578
   Shoba VBT, 2020, MULTIMED TOOLS APPL, V79, P22595, DOI 10.1007/s11042-020-08997-1
   Taloba AI, 2018, INT COMPUT ENG CONF, P209, DOI 10.1109/ICENCO.2018.8636121
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wati DAR, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P342, DOI 10.1109/ICITISEE.2017.8285524
   Wati Vera, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P497
NR 31
TC 5
Z9 5
U1 5
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23625
EP 23646
DI 10.1007/s11042-020-10246-4
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000613057400003
DA 2024-07-18
ER

PT J
AU Karmakar, P
   Teng, SW
   Lu, GJ
   Zhang, DS
AF Karmakar, Priyabrata
   Teng, Shyh Wei
   Lu, Guojun
   Zhang, Dengsheng
TI A novel fusion approach in the extraction of kernel descriptor with
   improved effectiveness and efficiency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel descriptor; Tamura features; Descriptor fusion; Image
   classification; Image retrieval
AB Image representation using feature descriptors is crucial. A number of histogram-based descriptors are widely used for this purpose. However, histogram-based descriptors have certain limitations and kernel descriptors (KDES) are proven to overcome them. Moreover, the combination of more than one KDES performs better than an individual KDES. Conventionally, KDES fusion is performed by concatenating them after the gradient, colour and shape descriptors have been extracted. This approach has limitations in regard to the efficiency as well as the effectiveness. In this paper, we propose a novel approach to fuse different image features before the descriptor extraction, resulting in a compact descriptor which is efficient and effective. In addition, we have investigated the effect on the proposed descriptor when texture-based features are fused along with the conventionally used features. Our proposed descriptor is examined on two publicly available image databases and shown to provide outstanding performances.
C1 [Karmakar, Priyabrata; Teng, Shyh Wei; Lu, Guojun; Zhang, Dengsheng] Federat Univ Australia, Sch Engn IT & Phys Sci, Gippsland Campus, Churchill, Vic 3842, Australia.
C3 Federation University Australia
RP Karmakar, P (corresponding author), Federat Univ Australia, Sch Engn IT & Phys Sci, Gippsland Campus, Churchill, Vic 3842, Australia.
EM p.karmakar@federation.edu.au; shyh.wei.teng@federation.edu.au;
   guojun.lu@federation.edu.au; dengsheng.zhang@fedeartion.edu.au
RI Karmakar, Priyabrata/AAT-6127-2021
OI Karmakar, Priyabrata/0000-0001-8015-1375; Teng, Shyh
   Wei/0000-0003-0347-3797
FU Australian Research Council [DP130100024]
FX This research was partially supported by Australian Research Council
   Discovery Projects scheme: DP130100024.
CR Abu Bakar S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P83, DOI 10.1109/ICSIPA.2013.6707982
   [Anonymous], 2014, P INT C MULT RETR
   Bo L., 2010, ADV NEURAL INFORM PR, V23, P244
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bo LF, 2011, PROC CVPR IEEE, P1729, DOI 10.1109/CVPR.2011.5995719
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dov D, 2016, IEEE T SIGNAL PROCES, V64, P6406, DOI 10.1109/TSP.2016.2605068
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Günter S, 2007, J MACH LEARN RES, V8, P1893
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hong Pan, 2015, Pattern Recognition Applications and Methods. 4th International Conference (ICPRAM 2015). Revised Selected Papers: LNCS 9493, P69, DOI 10.1007/978-3-319-27677-9_5
   Hu DN, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.48
   Karmakar P., 2018, INT CONF IMAG VIS, P1
   Karmakar P, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P461
   Konstantinidis K, 2005, OPT COMMUN, V248, P375, DOI 10.1016/j.optcom.2004.12.029
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu XW, 2014, AAAI CONF ARTIF INTE, P1975
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Manning C. D., 2008, Introduction to information retrieval, DOI [DOI 10.1017/CBO9780511809071, 10.1017/CBO9780511809071]
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pilario KE, 2020, PROCESSES, V8, DOI 10.3390/pr8010024
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Shawe-Taylor J., 2004, Kernel Methods for Pattern Analysis, DOI [DOI 10.1017/CBO9780511809682, 10.1017/cbo9780511809682]
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tran TH, 2015, LECT NOTES COMPUT SC, V9163, P137, DOI 10.1007/978-3-319-20904-3_13
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Varma M, 2007, IEEE I CONF COMP VIS, P369
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang P, 2013, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2013.368
   Xie BJ, 2016, NEUROCOMPUTING, V182, P94, DOI 10.1016/j.neucom.2015.12.007
   Xie BJ, 2013, IEEE IMAGE PROC, P3479, DOI 10.1109/ICIP.2013.6738718
   Yang S., 2012, Advances in Neural Information Processing Systems, P3122
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhou YZ, 2017, PROC CVPR IEEE, P4961, DOI 10.1109/CVPR.2017.527
NR 45
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14545
EP 14564
DI 10.1007/s11042-020-10300-1
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000611465900002
OA Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Alzu'bi, A
   Najadat, H
   Doulat, W
   Al-Shari, O
   Zhou, LM
AF Alzu'bi, Amal
   Najadat, Hassan
   Doulat, Wesam
   Al-Shari, Osama
   Zhou, Leming
TI Predicting the recurrence of breast cancer using machine learning
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Natural language processing; Healthcare; Breast cancer
ID ELECTRONIC HEALTH RECORDS; TUMOR RECURRENCE; RISK; INFORMATION;
   SURVIVAL; TEXT; ER
AB Breast cancer is one of the most common types of cancer among Jordanian women. Recently, healthcare organizations in Jordan have adopted electronic health records, which makes it feasible for researchers to access huge amounts of medical records. The goal of this study is to predict the recurrence of breast cancer using machine learning algorithms. We developed a Natural Language Processing algorithm to extract key features about breast cancer from medical records at King Abdullah University Hospital (KAUH) in Jordan. We integrated these features and built a medical dictionary for breast cancer. We applied multiple machine learning algorithms on the extracted information to predict the recurrence of breast cancer in patients. Our predicted results were approved by specialist physicians from KAUH. The medical dictionary was created and the accuracy of the data had been validated by targeted users (physicians, researchers). This dictionary can be used for personalized medicine. All machine learning algorithms had a nice performance. OneR algorithm has the best balance of sensitivity and specificity. The medical dictionary will help physicians to choose the most appropriate treatment plan in a short time. The machine learning prediction results can help physicians to make the correct clinical decision regarding their treatment options.
C1 [Alzu'bi, Amal; Najadat, Hassan] Jordan Univ Sci & Technol, Dept Comp Informat Syst, Irbid, Jordan.
   [Doulat, Wesam] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
   [Al-Shari, Osama] Jordan Univ Sci & Technol, Dept Internal Med Clin, Irbid, Jordan.
   [Zhou, Leming] Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA USA.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology; Jordan University of Science & Technology; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); University of
   Pittsburgh
RP Alzu'bi, A (corresponding author), Jordan Univ Sci & Technol, Dept Comp Informat Syst, Irbid, Jordan.
EM aazoubi9@just.edu.jo; najadat@just.edu.jo; Wesam.dolat@gmail.com;
   omshari@just.edu.jo; Leming.Zhou@pitt.edu
OI Najadat, Hassan/0000-0003-1599-6608
CR Abdel-Razeq Hikmat, 2015, Hematol Oncol Stem Cell Ther, V8, P64, DOI 10.1016/j.hemonc.2015.02.001
   Abualigah L. M. Q., 2019, FEATURE SELECTION EN, V816
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Al-Adwan AS, 2015, INT J HEALTHC TECHNO, V15, P89, DOI 10.1504/IJHTM.2015.074538
   Alzu'bi Amal, 2014, Perspect Health Inf Manag, V11, p1c
   Amin MB, 2017, CA-CANCER J CLIN, V67, P93, DOI 10.3322/caac.21388
   Bagaria SP, 2014, JAMA SURG, V149, P125, DOI 10.1001/jamasurg.2013.3181
   Bakre MM, 2019, CANCER MED-US, V8, P1755, DOI 10.1002/cam4.2049
   Battineni G, 2020, J PERS MED, V10, DOI 10.3390/jpm10020021
   Boeri C, 2020, CANCER MED-US, V9, P3234, DOI 10.1002/cam4.2811
   Chae S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15081596
   Chang CC, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00848
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Chung SR, 2019, ASIAN J SURG, V42, P613, DOI 10.1016/j.asjsur.2018.10.009
   Dahiwade D, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P1211, DOI [10.1109/ICCMC.2019.8819782, 10.1109/iccmc.2019.8819782]
   Dawes TJW, 2017, RADIOLOGY, V283, P381, DOI 10.1148/radiol.2016161315
   Eidemüller M, 2019, RADIAT PROT DOSIM, V183, P259, DOI 10.1093/rpd/ncy219
   Eshlaghy AbbasToloie., 2013, Journal of Health and Medicine Information, V4, P124, DOI DOI 10.4172/2157-7420.1000124
   Falck AK, 2013, BMC CANCER, V13, DOI 10.1186/1471-2407-13-558
   Feliciano EMC, 2017, CANCER-AM CANCER SOC, V123, P2535, DOI 10.1002/cncr.30637
   Filipits M, 2011, CLIN CANCER RES, V17, P6012, DOI 10.1158/1078-0432.CCR-11-0926
   Ford E, 2016, J AM MED INFORM ASSN, V23, P1007, DOI 10.1093/jamia/ocv180
   Gerhard W., 1850, DIAGNOSIS PATHOLOGY
   Guo JW, 2016, DISCRETE DYN NAT SOC, V2016, DOI 10.1155/2016/1516271
   Hardavella G, 2017, BREATHE, V13, P129, DOI 10.1183/20734735.006616
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Lafourcade A, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4076-4
   Meric F, 2003, CANCER, V97, P926, DOI 10.1002/cncr.11222
   Meystre S, 2006, J BIOMED INFORM, V39, P589, DOI 10.1016/j.jbi.2005.11.004
   Partridge SC, 2005, AM J ROENTGENOL, V184, P1774, DOI 10.2214/ajr.184.6.01841774
   Sada Y, 2016, MED CARE, V54, pE9, DOI 10.1097/MLR.0b013e3182a30373
   Sharma H., 2017, Int. J. Recent Innov. Trends Comput. Commun, V5, P99
   Shim HJ, 2014, ASIAN PAC J CANCER P, V15, P5539, DOI 10.7314/APJCP.2014.15.14.5539
   Song WJ, 2012, J BREAST CANCER, V15, P218, DOI 10.4048/jbc.2012.15.2.218
   STENKVIST B, 1982, CANCER-AM CANCER SOC, V50, P2884, DOI 10.1002/1097-0142(19821215)50:12<2884::AID-CNCR2820501231>3.0.CO;2-K
   Tseng YJ, 2019, INT J MED INFORM, V128, P79, DOI 10.1016/j.ijmedinf.2019.05.003
   Young IJB, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103971
   Yousefi M, 2018, CELL ONCOL, V41, P123, DOI 10.1007/s13402-018-0376-6
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhou M, 2016, SCI REP-UK, V6, DOI 10.1038/srep31038
NR 43
TC 24
Z9 25
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13787
EP 13800
DI 10.1007/s11042-020-10448-w
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608669300005
DA 2024-07-18
ER

PT J
AU Hasnat, A
   Barman, D
   Barman, B
AF Hasnat, Abul
   Barman, Dibyendu
   Barman, Bandana
TI Luminance approximated vector quantization algorithm to retain better
   image quality of the decompressed image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image quantization; Lossy image compression; PSNR; Redundancy;
   SSIM; Vector quantization; YCbCr
ID COMPRESSION
AB Some compressed images using Vector Quantization algorithm suffers from blocking artifacts which degrades the visual appeal of the image. Present study proposes a hybrid vector quantization method applicable on de-correlated color model. As luminance channel carries image information and loss of image information results in degradation of the visual appeal of an image, so aim of this study is focused on retaining more image information during compression process. For luminance channel compression, a new four level quantization based compression method is developed. Luminance channel is partitioned into smaller blocks. Then for each block, four level quantization is applied which local to the current block only. This results many level luminance value effectively for the whole image. It helps to retain better information. Chrominance channels are compressed using conventional Vector Quantization. This hybrid compression method improves visual quality of the decompressed image reasonably compared to VQ. The proposed method is applied on many standard images found in literature and images of UCIDv.2 color image database. Results are analyzed in terms of Peak Signal to Noise Ratio, Structure Similarity Index and space requirement reduction for compressed image using the method. Experimental results show that proposed method retains better quality of image in terms of PSNR and SSIM than Vector Quantization and Modified Vector Quantization. This method reduces storage space requirement for the compressed images in the range of 84% to 89%.
C1 [Hasnat, Abul; Barman, Dibyendu] Govt Coll Engn & Text Technol, Dept Comp Sci & Engn, Berhampur, W Bengal, India.
   [Barman, Bandana] Kalyani Govt Engn Coll, Dept Elect & Commun Engn, Nadia, W Bengal, India.
C3 Kalyani Government Engineering College
RP Barman, D (corresponding author), Govt Coll Engn & Text Technol, Dept Comp Sci & Engn, Berhampur, W Bengal, India.
EM dibyendu.barman@gmail.com
OI BARMAN, DIBYENDU/0000-0002-4146-4069
CR Al-Najjar Y.A.Y., 2012, INT J SCI ENG RES, V3, P8
   [Anonymous], 2007, DATA CLUSTERING THEO
   Avcibas I, 2002, IEEE SIGNAL PROC LET, V9, P312, DOI 10.1109/LSP.2002.804129
   Barman D, 2016, IEEE INT C INV COMP, DOI 10.1109/INVENTIVE.2016.7823295
   Bing Z, 2004, PATTERN RECOGN LETT, V25, P1787, DOI 10.1016/j.patrec.2004.07.005
   Celebi ME, 2011, IEEE IMAGE PROC, P1729, DOI 10.1109/ICIP.2011.6115792
   Chang HB, 2014, IEEE T SIGNAL PROCES, V62, P718, DOI 10.1109/TSP.2013.2290508
   Charrier C, 2012, IEEE T IMAGE PROCESS, V21, P4682, DOI 10.1109/TIP.2012.2210723
   Cheng SC, 2001, PATTERN RECOGN LETT, V22, P845, DOI 10.1016/S0167-8655(01)00025-3
   Chiranjeevi K, 2018, AIN SHAMS ENG J, V9, P1417, DOI 10.1016/j.asej.2016.09.009
   Freisleben B, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P459, DOI 10.1109/ICEC.1997.592355
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hasnat A, 2019, J INTELL FUZZY SYST, V36, P3177, DOI 10.3233/JIFS-18360
   Hasnat A, 2017, J INTELL FUZZY SYST, V32, P3711, DOI 10.3233/JIFS-169304
   Hurtik P, 2017, IEEE INT CONF FUZZY
   Jain AK., 2004, ALGORITHMS CLUSTERIN
   Karri C, 2016, ENG SCI TECHNOL, V19, P769, DOI 10.1016/j.jestch.2015.11.003
   Kil D. H., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P500, DOI 10.1109/ICIP.1995.537681
   Leitao HAS, 2015, IEEE LAT AM T, V13, P961, DOI 10.1109/TLA.2015.7106343
   Li CK, 1996, IEEE T CONSUM ELECTR, V42, P239, DOI 10.1109/30.494427
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Mahapatra DK, 2013, IEEE C ICT NOOR ISL, DOI 10.1109/CICT.2013.6558278
   Omran MG, 2005, INFORM-J COMPUT INFO, V29, P261
   Oztan B., 2009, US patent, Patent No. [US 7634150 B2, 7634150]
   Oztan B, 2007, PROC SPIE, V6493, DOI 10.1117/12.705414
   Ozturk C, 2014, INFORMATICA-LITHUAN, V25, P485, DOI 10.15388/Informatica.2014.25
   Rajini H, 2019, INT J INNOVATIVE TEC, V8, P359
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Scheunders P, 1997, PATTERN RECOGN, V30, P859, DOI 10.1016/S0031-3203(96)00131-8
   Soh JW, 2017, IEEE INT C AS PAC SI
   THEPADE SD, 2013, ICETACS, P161
   Wang J, 2015, IEEE INT C IM SYST T, DOI 10.1109/IST.2015.7294570
   Winarno Wiranto, 2018, IEEE INT C AUT COGN, DOI 10.1109/ICACOMIT.2017.8253383
   Wu MT, 2015, 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), P1919, DOI 10.1109/FSKD.2015.7382241
NR 38
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11985
EP 12007
DI 10.1007/s11042-020-10403-9
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296800006
DA 2024-07-18
ER

PT J
AU Evsutin, O
   Kultaev, P
AF Evsutin, Oleg
   Kultaev, Pavel
TI An algorithm for embedding information in digital images based on
   discrete wavelet transform and learning automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Image steganography; Frequency-domain image
   embedding; DWT; Learning automata
ID REVERSIBLE WATERMARKING SCHEME; STEGANOGRAPHY; SVD; DOMAIN; DCT
AB The paper presents a new algorithm for embedding information in the frequency domain of the discrete wavelet-transform (DWT) of digital images. A block version of quantization index modulation (QIM) is used as a basic embedding operation. A distinctive feature of the algorithm consists in the adaptive selection of the data block size depending on the local properties of the cover image. It has been shown experimentally that for image areas containing a larger number of edge pixels, it is necessary to select blocks of greater length in the corresponding frequency domains. In addition, the problem of optimization the distortions in the blocks of DWT coefficients is substantiated and solved in order to improve the quality of embedding. A computing model of learning automata is used to solve this problem. The advantage of the obtained algorithm is that the receiver of the stego-image does not need additional information to extract the embedded message. The algorithm is highly efficient in terms of the main criteria of embedding quality and can be used both for embedding digital watermarks and arbitrary messages.
C1 [Evsutin, Oleg] HSE Univ, 20 Myasnitskaya Ulitsa, Moscow 101000, Russia.
   [Evsutin, Oleg] Russian Acad Sci, VA Trapeznikov Inst Control Sci, 65 Profsoyuznaya St, Moscow 117997, Russia.
   [Kultaev, Pavel] Tomsk State Univ Control Syst & Radioelect, 40 Lenina Prospect, Tomsk 634050, Russia.
C3 HSE University (National Research University Higher School of
   Economics); Russian Academy of Sciences; V.A. Trapeznikov Institute of
   Control Sciences, Russian Academy of Sciences; Tomsk State University of
   Control Systems & Radioelectronics
RP Evsutin, O (corresponding author), HSE Univ, 20 Myasnitskaya Ulitsa, Moscow 101000, Russia.; Evsutin, O (corresponding author), Russian Acad Sci, VA Trapeznikov Inst Control Sci, 65 Profsoyuznaya St, Moscow 117997, Russia.
EM evsutin.oo@gmail.com
RI Evsutin, Oleg/E-6719-2017
OI Evsutin, Oleg/0000-0002-8257-2082
FU Russian Science Foundation [19-71-00106]; Russian Science Foundation
   [19-71-00106] Funding Source: Russian Science Foundation
FX The study was supported by the grant of the Russian Science Foundation
   (project No 19-71-00106). We are very grateful to the anonymous referees
   for their constructive comments and helpful suggestions to improve the
   quality of this paper.
CR Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Bakthula R, 2018, MULTIMED TOOLS APPL, V77, P8375, DOI 10.1007/s11042-017-4738-2
   Beigy H, 2004, ADV COMPLEX SYST, V7, P295, DOI 10.1142/S0219525904000202
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Ejaz N, 2014, MULTIMED TOOLS APPL, V73, P825, DOI 10.1007/s11042-013-1377-0
   Evsutin O, 2016, P 1 INT SCI C INT IN, P47
   Evsutin O, 2018, MULTIMED TOOLS APPL, V77, P28567, DOI 10.1007/s11042-018-6055-9
   Evsutin O, 2017, 2017 SECOND RUSSIA AND PACIFIC CONFERENCE ON COMPUTER TECHNOLOGY AND APPLICATIONS (RPC 2017), P49, DOI 10.1109/RPC.2017.8168066
   Fridrich J., 2009, Steganography in Digital Media: Principles, Algorithms, and Applications
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kaewkamnerd N, 2000, ELECTRON LETT, V36, P312, DOI 10.1049/el:20000269
   Khan A, 2019, MULTIMED TOOLS APPL, V78, P25999, DOI 10.1007/s11042-019-7664-7
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Saidi M, 2019, IMAGING SCI J, V67, P237, DOI 10.1080/13682199.2019.1620525
   Salomon D., 2010, Handbook of Data Compression, V5th
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Xia XG, 1998, OPT EXPRESS, V3, P497, DOI 10.1364/OE.3.000497
   Zhang LN, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102805
   Zheng PJ, 2020, MULTIMED TOOLS APPL, V79, P18343, DOI 10.1007/s11042-019-08490-4
NR 39
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11217
EP 11238
DI 10.1007/s11042-020-10316-7
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605119800004
DA 2024-07-18
ER

PT J
AU Al-shammari, MKM
   Gao, TH
   Mohammed, RK
   Zhou, S
AF Al-shammari, Marwan Kadhim Mohammed
   Gao, TianHan
   Mohammed, Rana Kadhim
   Zhou, Song
TI Attention enhancement system for college students with brain biofeedback
   signals based on virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ADHD; VR; BCI; EEG biofeedback; Artificial neural network; Deep learning
AB Attention Deficit Hyperactivity Disorder (ADHD) is a common and heritable disease that has an environmental influence on brain function. The diseases affects multiple aspects of the lives of college students, not only on their study but also on the relationships with other people. The problem with ADHD attention involves short term memory. The purpose of this paper is to investigate the capability of improving short term working memory for ADHD patients by the aid of technology a proper VR environment is built for ADHD, who are isolated from the real circumference. Electroencephalography (EEG) is taken as biofeedback to read the brain signal from the patient. A deep learning approach and an artificial neural network method, are employed to efficiently and accurately process EEG. The findings of the trial indicate that the virtual reality recommended system will play a greater role in improving the attention to the ADHD patient.
C1 [Al-shammari, Marwan Kadhim Mohammed; Gao, TianHan; Zhou, Song] Northeastern Univ, Shenyang, Peoples R China.
   [Mohammed, Rana Kadhim] Univ Baghdad, Baghdad, Iraq.
C3 Northeastern University - China; University of Baghdad
RP Al-shammari, MKM (corresponding author), Northeastern Univ, Shenyang, Peoples R China.
EM alkaseralshamary@gmail.com; gaoth@mail.neu.edu.cn;
   phd.rana.kadhim@gmail.com; 718281245@qq.com
RI Mohammed, Rana/ACY-0446-2022; Kadhim, Marwan/AAL-4519-2020; Gao,
   Tianhan/AAK-1248-2020
OI Kadhim, Marwan/0000-0002-4433-5086; Gao, Tianhan/0000-0002-0701-1701;
   Kadhim Mohammed, Rana/0000-0002-3913-5290
CR Abbasi-Asl R, 2019, I IEEE EMBS C NEUR E, P1220, DOI [10.1109/NER.2019.8717158, 10.1109/ner.2019.8717158]
   Al-shammari MKM, 2018, INT C INN MOB INT SE, P412
   Alchalcabi AE, 2017, MORE ATTENTION LESS, P1
   Alyagon U, 2020, NEUROIMAGE-CLIN, V26, DOI 10.1016/j.nicl.2020.102206
   Areces D, 2018, JOVE-J VIS EXP, V134, P56796
   Barba MC, 2019, LECT NOTES COMPUT SC, V11613, P394, DOI 10.1007/978-3-030-25965-5_30
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Britton JW, 2016, ELECTROENCEPHALOGRAP, P1103
   Bul KCM, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5173
   BurdeaGrigore C, 1994, VIRTUAL REALITY TECH, P233
   Carvalho SR, 2017, SIBGRAPI, P178, DOI 10.1109/SIBGRAPI.2017.30
   Daly JJ, 2008, LANCET NEUROL, V7, P1032, DOI 10.1016/S1474-4422(08)70223-0
   Davis J., 2015, NEUROREGULATION, V2, P50
   Deiber MP, 2020, NEUROIMAGE-CLIN, V25, DOI 10.1016/j.nicl.2019.102145
   Deiber MP, 2019, BIORXIV
   Drake MB, 2019, J ATTEN DISORD, V23, P1729, DOI 10.1177/1087054717698222
   Hofmann SM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P128, DOI 10.1109/AIVR.2018.00026
   Javaid A., 2016, EAI ENDORSED T SECUR, P21, DOI DOI 10.4108/EAI.3-12-2015.2262516
   Kanellos T, 2018, PROC SPIE, V10662, DOI 10.1117/12.2307087
   Kiiski H, 2020, EUR J NEUROSCI, V51, P2095, DOI 10.1111/ejn.14645
   Kim O, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2180-x
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Lapborisuth P, 2019, IEEE ENG MED BIO, P5536, DOI [10.1109/EMBC.2019.8856761, 10.1109/embc.2019.8856761]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2017, APPL MICROBIOL BIOT, P1
   Li G, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P163, DOI 10.1109/AIVR46125.2019.00033
   Liu YS, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P161, DOI 10.1109/CW.2014.30
   Mahato S, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1486-z
   McAuliffe D, 2020, EUR J NEUROSCI, V51, P1815, DOI 10.1111/ejn.14642
   McMahon Michael, 2018, 2018 IEEE Games, Entertainment, Media Conference (GEM), P1, DOI 10.1109/GEM.2018.8516468
   Müller A, 2020, WORLD J BIOL PSYCHIA, V21, P172, DOI 10.1080/15622975.2019.1605198
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Park S, 2019, IEEE ACCESS, V7, P163604, DOI 10.1109/ACCESS.2019.2952613
   Pope AT, 2014, BIOCYBERNETIC ADAPTA, P91
   Robertson MM, 2019, J NEUROPHYSIOL, P80
   Schalkoff RJ, 1997, ARTIFICIAL NEURAL NE, V1, P11
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Sherman WR, 2018, UNDERSTANDING VIRTUA, P111
   Suhaimi NS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P167, DOI 10.1109/CSPA.2018.8368706
   Teo J, 2018, DEEP NEURAL CLASSIFI, P1
   Teplan M., 2002, Measurement science review, V2, DOI DOI 10.1021/PR070350L
   Tremmel C, 2019, IEEE SYS MAN CYBERN, P2806, DOI 10.1109/SMC.2019.8914264
   Tremmel C, 2019, IEEE ENG MED BIO, P4576, DOI [10.1109/EMBC.2019.8856961, 10.1109/embc.2019.8856961]
   Van Wijk CH, 2019, J PSYCHOL S AFRICAN, P12
   Wang J., 2019, IEEE C COMP VIS PATT, P12
   Wang S., 2010, NEW METHOD VIRTUAL R
   Zhang MH, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P159, DOI 10.1109/AIVR46125.2019.00032
NR 47
TC 4
Z9 4
U1 5
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19097
EP 19112
DI 10.1007/s11042-020-10159-2
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000604816700001
DA 2024-07-18
ER

PT J
AU Zandi, G
   Roodaki, H
   Shirmohammadi, S
AF Zandi, Ghane
   Roodaki, Hoda
   Shirmohammadi, Shervin
TI A novel fast search method to find disparity vectors in multiview video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview disparity estimation; View-dependent geometry; Depth
   information; Multiview video coding
ID ADAPTIVE MOTION ESTIMATION; COMPLEXITY; SCHEME
AB In multiview/3D video, the amount of data to be transmitted to the decoder increases proportionally with the number of cameras. One way to efficiently compress such video is to use Multiview Video Coding (MVC) which simultaneously reduces temporal and spatial redundancy within the same view and among multiple views. But, existing disparity estimation methods used to extract the redundancy among views are typically too computationally complex. In this paper, we propose a method for fast disparity estimation in multiview/3D video. First, for each block of the predicted frame, the view-dependent geometry and the depth information are used to find the corresponding block in the reference views. Then, a fast and greedy search method is proposed to search the surrounding areas to find the most similar block. Simulation results show that our proposed method achieves better bitrate and quality with much lower computational complexity compared to state-of-the-art methods.
C1 [Zandi, Ghane; Roodaki, Hoda] KN Toosi Univ Technol, Tehran, Iran.
   [Shirmohammadi, Shervin] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
C3 K. N. Toosi University of Technology; University of Ottawa
RP Roodaki, H (corresponding author), KN Toosi Univ Technol, Tehran, Iran.
EM ghane.zandi@email.kntu.ac.ir; hroodaki@kntu.ac.ir;
   shervin@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012
OI Shirmohammadi, Shervin/0000-0002-3973-4445
CR Afonso V, 2019, IEEE T CIRC SYST VID, V29, P1878, DOI 10.1109/TCSVT.2018.2847633
   Afonso V, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351350
   Aksehir Y, 2018, J REAL-TIME IMAGE PR, V15, P3, DOI 10.1007/s11554-013-0383-9
   [Anonymous], 2006, 7 WORKSH DIG BROADC
   Atienza R, 2018, IEEE INT CONF ROBOT, P3207
   Bjotegaard G., 2001, VCEGM33
   Boonthep N, 2020, WIRELESS PERS COMMUN, V115, P2833, DOI 10.1007/s11277-019-06766-4
   Chen Y, 2016, IEEE T MULTIMEDIA, V18, P576, DOI 10.1109/TMM.2016.2525010
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Gonzales CA, 1999, IBM J RES DEV, V43, P453, DOI 10.1147/rd.434.0453
   Han Chan-Hee, 2016, IEIE Transactions on Smart Processing & Computing, V5, P323
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd, P201, DOI DOI 10.1017/CBO9780511811685
   Jiang CY, 2016, IEEE DATA COMPR CONF, P609, DOI 10.1109/DCC.2016.20
   Jiang CY, 2016, IEEE T CIRC SYST VID, V26, P346, DOI 10.1109/TCSVT.2015.2402853
   Lin CL, 2018, MICROSYST TECHNOL, V24, P4057, DOI 10.1007/s00542-017-3620-5
   Micallef B, 2010, P IFIP WIR DAYS OCT, P1
   Micallef BW, 2014, IEEE T CONSUM ELECTR, V60, P74, DOI 10.1109/TCE.2014.6780928
   Naigao Jin, 2011, Proceedings of the 2011 2nd International Conference on Intelligent Control and Information Processing (ICICIP), P260, DOI 10.1109/ICICIP.2011.6008244
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Ohm JR, 1999, PROC SPIE, V3639, P242, DOI 10.1117/12.349385
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Qiao ZM, 2011, IEEE INT SYMP CIRC S, P2805
   Shen LQ, 2010, IEEE T CIRC SYST VID, V20, P925, DOI 10.1109/TCSVT.2010.2045910
   Song YX, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P173, DOI 10.1109/IIH-MSP.2013.52
   Wang YQ, 2018, IEEE ACCESS, V6, P21840, DOI 10.1109/ACCESS.2018.2827085
   Zakeri FS, 2019, PROC SPIE, V11172, DOI 10.1117/12.2521747
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhu W, 2010, IEEE T CONSUM ELECTR, V56, P957, DOI 10.1109/TCE.2010.5506026
NR 29
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10821
EP 10837
DI 10.1007/s11042-020-10260-6
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100014
DA 2024-07-18
ER

PT J
AU Girija, R
   Singh, H
AF Girija, R.
   Singh, Hukum
TI An asymmetric cryptosystem based on the random weighted singular value
   decomposition and fractional Hartley domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Recent Trends in Image Processing and
   Pattern Recognition (RTIP2R)
CY DEC 21-22, 2018
CL Solapur, INDIA
DE Random weighted singular value decomposition; Fractional Hartley
   transform; Orthogonal triangular decomposition; Truncated singular value
   decomposition
AB A new asymmetric encryption system for double random phase encoding based on random weighted singular value decomposition and fractional Hartley transform domain has been proposed. Random weighted singular value decomposition is purely based upon random weights, isometric matrix and orthogonal triangular decomposition and all these fragments enhances the security of double random phase encoding cryptosystem. Random weights and orthogonal triangular decomposition are considered as heart of this cryptosystem. This system is carried out in fractional Hartley domain, where fractional orders play a vital role. On the receiver side, it is only possible to decrypt the image if anyone knows all the three components, its multiplication order, fractional order of fractional Hartley transform. Proposed cryptosystem is efficiently compared with singular value decomposition and truncated singular value decomposition. Similar to singular value decomposition and truncated singular value decomposition, proposed cryptosystem also yields three components. Because of random weights, these three components are highly differing from traditional singular value decomposition and truncated singular value decomposition components. Some analysis is offered to authenticate the opportunity.
C1 [Girija, R.] NorthCap Univ, Dept Comp Sci & Engn, Gurugram, India.
   [Singh, Hukum] NorthCap Univ, Dept Appl Sci, Gurugram, India.
C3 The Northcap University; The Northcap University
RP Girija, R (corresponding author), NorthCap Univ, Dept Comp Sci & Engn, Gurugram, India.
EM girija.srikanth09@gmail.com; hukumsingh@ncuindia.edu
RI Singh, Hukum/AAU-5676-2021; GIRIJA, R/AAB-9969-2021
OI Singh, Hukum/0000-0002-3586-4592; GIRIJA, R/0000-0001-6635-7975
CR Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   DEMOOR B, 1992, SIAM J MATRIX ANAL A, V13, P993, DOI 10.1137/0613060
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   Girija R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0165-z
   Girija R, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1472-6
   Khurana M., 2019, RECENT PATENTS COMPU, V12, P80, DOI [10.2174/2213275911666181030111102, DOI 10.2174/2213275911666181030111102]
   Khurana M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0137-8
   Li XX, 2008, CHINESE PHYS LETT, V25, P2477, DOI 10.1088/0256-307X/25/7/040
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Liu ZJ, 2005, OPT COMMUN, V255, P357, DOI 10.1016/j.optcom.2005.06.031
   Maan P, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0218-y
   Maan P, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0205-8
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nishchal NK, 2003, OPT ENG, V42, P1583, DOI 10.1117/1.1570429
   Pei SC, 2002, IEEE T SIGNAL PROCES, V50, P1661, DOI 10.1109/TSP.2002.1011207
   Pei SC, 1998, IEEE T CIRCUITS-II, V45, P665, DOI 10.1109/82.686685
   Qin W, 2011, OPT ENG, V50, DOI 10.1117/1.3607421
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   Rajput SK, 2012, APPL OPTICS, V51, P5377, DOI 10.1364/AO.51.005377
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rodrigo JA, 2007, OPT COMMUN, V278, P279, DOI 10.1016/j.optcom.2007.06.023
   Singh H, 2018, IET IMAGE PROCESS, V12, P1994, DOI 10.1049/iet-ipr.2018.5399
   Singh H, 2017, OPT APPL, V47, P557, DOI 10.5277/oa170406
   Singh H, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0110-y
   Singh H, 2016, AIP CONF PROC, V1728, DOI 10.1063/1.4946114
   Singh H, 2016, OPT LASER ENG, V81, P125, DOI 10.1016/j.optlaseng.2016.01.014
   Singh H, 2015, INT J OPT, V2015, DOI 10.1155/2015/926135
   Singh H, 2015, OPT LASER ENG, V67, P145, DOI 10.1016/j.optlaseng.2014.10.011
   Singh H, 2014, APPL OPTICS, V53, P6472, DOI 10.1364/AO.53.006472
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Towghi N, 1999, J OPT SOC AM A, V16, P1915, DOI 10.1364/JOSAA.16.001915
   Unnikrishnan G, 2000, OPT ENG, V39, P2853, DOI 10.1117/1.1313498
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Vaidya SP, 2018, INT J MACH LEARN CYB, P1
   Vashisth S, 2015, P SPIE, V9654
   Vashisth S, 2014, OPTIK, V125, P5309, DOI 10.1016/j.ijleo.2014.06.068
   Vilardy JM, 2013, 8 IB OPT M 11 LAT AM, V8785, p87851R
   Wu JH, 2017, J MOD OPTIC, V64, P334, DOI 10.1080/09500340.2016.1236990
   Yadav AK, 2015, SPRINGER PROC PHYS, V166, P25, DOI 10.1007/978-81-322-2367-2_5
   Yadav AK, 2015, OPT COMMUN, V344, P172, DOI 10.1016/j.optcom.2015.01.019
   Yadav PL, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0172-0
   Zamrani W, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103108
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
NR 44
TC 7
Z9 7
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34717
EP 34735
DI 10.1007/s11042-019-7733-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900003
DA 2024-07-18
ER

PT J
AU Khamparia, A
   Saini, G
   Pandey, B
   Tiwari, S
   Gupta, D
   Khanna, A
AF Khamparia, Aditya
   Saini, Gurinder
   Pandey, Babita
   Tiwari, Shrasti
   Gupta, Deepak
   Khanna, Ashish
TI KDSAE: Chronic kidney disease classification with multimedia data
   learning using deep stacked autoencoder network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chronic kidney disease (CKD); Classification; Deep learning (DL);
   Machine learning (ML); Multimedia; Artificial intelligence (AI); Stacked
   autoencoder (SAE); Softmax classifier
AB In recent times, Chronic Kidney Disease (CKD) has affected more than 10% of the population worldwide and millions of people die every year. So, early-stage detection of CKD could be beneficial for increasing the life expectancy of suffering patients and reducing the treatment cost. It is required to build such a multimedia driven model which can help to diagnose the disease efficiently with higher accuracy before leading to worse conditions. Various techniques related to conventional machine learning models have been used by researchers in the past time without involvement of multimodal data-driven learning. This research paper offers a novel deep learning framework for chronic kidney disease classification using stacked autoencoder model utilizing multimedia data with a softmax classifier. The stacked autoencoder helps to extract the useful features from the dataset and then a softmax classifier is used to predict the final class. It has experimented on UCI dataset which contains early stages of 400 CKD patients with 25 attributes, which is a binary classification problem. Precision, recall, specificity and F1-score were used as evaluation metrics for the assessment of the proposed network. It was observed that this multimodal model outperformed the other conventional classifiers used for chronic kidney disease with a classification accuracy of 100%.
C1 [Khamparia, Aditya; Saini, Gurinder] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, India.
   [Pandey, Babita] BabaSaheb Bhim Rao Ambedkar Univ, Dept Comp Sci & IT, Lucknow, Uttar Pradesh, India.
   [Tiwari, Shrasti] Lovely Profess Univ, Div Examinat, Phagwara, India.
   [Gupta, Deepak; Khanna, Ashish] Maharaja Agrasen Inst Technol, MAIT, Delhi, India.
C3 Lovely Professional University; Babasaheb Bhimrao Ambedkar University;
   Lovely Professional University; Maharaja Agrasen Institute of Technology
RP Gupta, D (corresponding author), Maharaja Agrasen Inst Technol, MAIT, Delhi, India.
EM aditya.khamparia88@gmail.com; gurindersaini25@gmail.com;
   shukla_babita@yahoo.co.in; shrastitiwari@gmail.com;
   deepakgupta@mait.ac.in; ashishkhanna@mait.ac.in
RI Gupta, Deepak/AAV-2728-2020; Saini, Gurinder/ABD-4911-2020; Khamparia,
   Dr Aditya/Y-7616-2018
OI Gupta, Deepak/0000-0002-3019-7161; Saini, Gurinder/0000-0003-4051-4463;
   Pandey, Babita/0000-0003-3290-3899; Khamparia, Dr
   Aditya/0000-0001-9019-8230; Khanna, Ashish/0000-0002-8418-3929
CR Adam T, 2012, DESIGNING ARTIFICIAL, P27
   Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Ahmed S, 2014, DIAGNOSIS KIDNEY DIS
   [Anonymous], 2018, PERFORMANCE COMP SOM
   Arasu S. D., 2017, P INT C COMP COMM TE, P127, DOI DOI 10.1109/ICCCT2.2017.7972256
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bikbov B, 2018, NEPHRON, V139, P313, DOI 10.1159/000489897
   Chen WS, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010110
   Chetty N., 2015, 2015 INT C COMP COMM, DOI [10.1109/CCCS.2015.7374193, DOI 10.1109/CCCS.2015.7374193]
   Chw RKEI, 2012, INTELLIGENT SYSTEMS, P15
   Dulhare UN, 2016, EXTRACTION ACTION RU, P4
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Kannadasan K, 2018, TYPE 2 DIABETES DATA, P2
   Khamparia A, 2019, INT J DATA ANAL TECH, V12, P1
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P818, DOI 10.1007/s00034-019-01041-0
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Khamparia A, 2019, IEEE ACCESS, V7, P21559, DOI 10.1109/ACCESS.2019.2897175
   Khamparia A, 2019, IEEE ACCESS, V7, P7717, DOI 10.1109/ACCESS.2018.2888882
   Khamparia A, 2018, COMPUT ELECTR ENG, V66, P531, DOI 10.1016/j.compeleceng.2017.12.041
   Kunwar V., 2016, CLOUD SYST BIG DAT E, P300
   Lakshmanaprabu SK, 2018, IEEE ACCESS, V6, P24196, DOI 10.1109/ACCESS.2018.2830651
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Pandey B, 2019, EXPERT SYST APPL, V124, P164, DOI 10.1016/j.eswa.2019.01.040
   PARK CH., 2017, INF, V20, P789
   Pujari RM, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P380, DOI 10.1109/CNSC.2014.6906704
   Qian S, 2018, NEUROCOMPUTING, V272, P204, DOI 10.1016/j.neucom.2017.06.070
   Raja KB, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P724
   Rosso R, 2010, 32 ANN INT C IEEE EM, V2010, P6850
   Roventa Eugene, 2009, 2009 3rd International Workshop on Soft Computing Applications (SOFA 2009), P219, DOI 10.1109/SOFA.2009.5254849
   Varughese S, 2018, CLIN J AM SOC NEPHRO, V13, P802, DOI 10.2215/CJN.09180817
   Wibawa MS, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM 2017), P126
NR 32
TC 44
Z9 45
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35425
EP 35440
DI 10.1007/s11042-019-07839-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900039
DA 2024-07-18
ER

PT J
AU Ma, XY
   Jiang, XH
AF Ma, Xiaoyu
   Jiang, Xiuhua
TI Multimedia image quality assessment based on deep feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual image quality assessment; Passive aggressive learning
   algorithm
ID SIMILARITY
AB Measurement of visual quality is of significant importance to many image processing tasks. The target of image quality assessment (IQA) is to design effective computational models in order to automatically predict the quality of images in a perceptual consistent manner. We propose a full reference (FR) IQA metric based on deep convolutional neural networks and information-theoretic IQA framework. The previous proposed PAVIF is incorporated into the powerful convolutional network VGG19. Both the reference and distorted image are fed into the VGG19, and the output of each channels in the first 35 layers are utilized to measure the perceptual quality difference. The final objective score is obtained by averaging all the channel-wise quality scores. Experimental results on TID2013 and LIVE image database demonstrate that our proposed metric is competitive with many state-of-the-art IQA metrics.
C1 [Ma, Xiaoyu; Jiang, Xiuhua] Commun Univ China, Informat Engn Sch, Beijing 100024, Peoples R China.
C3 Communication University of China
RP Ma, XY (corresponding author), Commun Univ China, Informat Engn Sch, Beijing 100024, Peoples R China.
EM xiaohaozi1b@163.com
RI Ma, Xiaoyu/JTS-9783-2023
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   [Anonymous], LIVE IMAGE QUALITY A
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Kim J, 2017, IEEE IMAGE PROC, P3180, DOI 10.1109/ICIP.2017.8296869
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Oszust M, 2016, IEEE SIGNAL PROC LET, V23, P65, DOI 10.1109/LSP.2015.2500819
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   Ponomarenko N., 2014, P 4 EUR WORKSH VIS I, P106
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang HL, 2017, IEEE T IMAGE PROCESS, V26, P915, DOI 10.1109/TIP.2016.2639451
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xiaoyu Ma, 2017, 2017 27th International Telecommunication Networks and Applications Conference (ITNAC), P1, DOI 10.1109/ATNAC.2017.8215389
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang H, 2012, P IEEE INT C E-SCI
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 28
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35209
EP 35220
DI 10.1007/s11042-019-7571-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900028
DA 2024-07-18
ER

PT J
AU Xu, XL
   Li, YD
   Jin, Y
AF Xu, Xiaolin
   Li, Yidong
   Jin, Yi
TI Hierarchical discriminant feature learning for cross-modal face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal face recognition; Coupled discriminant filters; Hierarchical
   boosting network
AB Heterogeneous Face Recognition (HFR) refers to the problem of recognizing faces across different visual domains and has attached great attention owing to its tremendous potential benefits in practical applications. In this paper, a novel feature learning approach named hierarchical discriminant feature learning (HDFL) has been proposed for HFR. Different from traditional feature learning based HFR approaches, the proposed HDFL aims to learn the most discriminative information via a two-layer hierarchical boosting network (HBN), where the hierarchical discriminative information can be exploited in the learned features and the appearance difference can be effectively reduced, simultaneously. Extensive experiments on three different heterogeneous face databases demonstrate that our approach consistently outperforms the state-of-the-art methods.
C1 [Xu, Xiaolin; Li, Yidong; Jin, Yi] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Jin, Y (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 16120435@bjtu.edu.cn; ydli@bjtu.edu.cn; yjin@bjtu.edu.cn
OI Jin, Yi/0000-0001-8408-3816
CR Abel-Aziz HGM, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P107, DOI 10.1145/2908446.2908492
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen T, 2008, INT C PATT RECOG, P2779
   [Anonymous], 2008, REAL LIF IM WORKSH E
   Catarious DM, 2006, MED PHYS, V33, P4104, DOI 10.1118/1.2358326
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   He R, 2017, IEEE T PATTERN ANAL, VPP, P1
   He R, 2017, AAAI CONF ARTIF INTE, P2000
   Jin Y, 2015, IEEE T INF FOREN SEC, V10, P640, DOI 10.1109/TIFS.2015.2390414
   Kan M, 2012, MULTIVIEW DISCRIMINA, DOI [10.1007/978-3-642-33718-5_58, DOI 10.1007/978-3-642-33718-5_58]
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   Liu XM, 2016, AER ADV ENG RES, V116, P1, DOI 10.1145/2875194.2875248
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JB, 2019, INT J ROBUST NONLIN, V29, P5002, DOI 10.1002/rnc.3971
   Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47
   Sarfraz MS, 2015, ARXIV150702879
   Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   She LB, 2018, BOUND VALUE PROBL, DOI 10.1186/s13661-018-0928-8
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wambura P, 2008, INT J FOOD ENG, V4, DOI 10.2202/1556-3758.1393
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu X, 2018, AAAI CONF ARTIF INTE, P1679
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yi DW, 2015, INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (ICCSAI 2014), P1
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
NR 38
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33483
EP 33502
DI 10.1007/s11042-019-7683-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000010
DA 2024-07-18
ER

PT J
AU Dash, PP
   Mishra, SK
   Senapati, KK
   Panda, G
AF Dash, Prajna Parimita
   Mishra, Sudhansu Kumar
   Senapati, Kishore Kumar
   Panda, Ganapati
TI Interactive teaching learning based optimization technique for multiple
   object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiobject tracking; PSO; Detection rate; Non-parametric testing; TLBO;
   In-TLBO
ID ALGORITHM; EVOLUTIONARY; DESIGN; FILTER
AB In this paper, an Interactive Teaching Learning Based Optimization (In-TLBO) algorithm is proposed for tracking multiple objects with several challenges. The performance of the four other competitive approaches, such as the Mean Shift (MS), Particle Swarm Optimization (PSO), Sequential PSO (SPSO), and Adaptive Gaussian Particle Swarm Optimization (AGPSO) are investigated for comparison. The quantitative and qualitative analyses of these approaches have been performed to demonstrate their efficacy. The comparison of various performance measures includes the convergence rate, tracking accuracy, Mean Square Error (MSE) and coverage test. To assess the dominance of the proposed In-TLBO approach, Sign and Wilcoxon test are also performed. These two non-parametric tests reveal considerable advancement of the proposed Interactive TLBO (In-TLBO) over other four competitive approaches. In-TLBO shows significant improvement over the MS and PSO algorithms with a level of significance alpha = 0.05, and over SPSO, with a level of significance alpha = 0.1 by considering detection rate as winning parameter. The analyses of comparative results demonstrate that the proposed approach effectively tracks similar objects in the presence of many real time challenges.
C1 [Dash, Prajna Parimita] Birla Inst Technol, Dept ECE, Ranchi, Bihar, India.
   [Mishra, Sudhansu Kumar] Birla Inst Technol, Dept EEE, Ranchi, Bihar, India.
   [Senapati, Kishore Kumar] Birla Inst Technol, Dept CSE, Ranchi, Bihar, India.
   [Panda, Ganapati] CV Raman Global Univ, Dept ETC, Bhubaneswar 752054, India.
C3 Birla Institute of Technology Mesra; Birla Institute of Technology
   Mesra; Birla Institute of Technology Mesra
RP Dash, PP (corresponding author), Birla Inst Technol, Dept ECE, Ranchi, Bihar, India.
EM ppdash@bitmesra.ac.in; sudhansumishra@bitmesra.ac.in;
   kksenapati@bitmesra.ac.in; ganapati.panda@gmail.com
RI Dash, Prajna Parimita/AAE-9282-2021; Mishra, Sudhansu
   Kumar/AFT-7650-2022; Panda, Ganapati/AFP-7044-2022; Senapati, Kishore
   Kumar/M-1222-2017
OI Dash, Prajna Parimita/0000-0002-9767-8234; Mishra, Sudhansu
   Kumar/0000-0003-1733-8270; Panda, Ganapati/0000-0002-3555-5685;
   Senapati, Kishore Kumar/0000-0002-5696-4832
CR An ZY, 2018, J INTELL FUZZY SYST, V34, P3983, DOI 10.3233/JIFS-171071
   Arteta C, 2013, P IEEE C COMP VIS PA
   Bhuyan MK, 2006, J EXP THEOR ARTIF IN, V18, P435, DOI 10.1080/09528130600975931
   Boudjit K, 2018, J EXP THEOR ARTIF IN, V30, P1013, DOI 10.1080/0952813X.2018.1509896
   Dash P.P., 2013, IEEE INT SYMP CIRC S, P1, DOI [10.1109/ISCAS.2013.6572049, DOI 10.1109/ISCAS.2013.6572049]
   Dash PP, 2012, IEEE IND ELEC, P1001, DOI 10.1109/IECON.2012.6388584
   Dash PP, 2019, MEASUREMENT, V144, P311, DOI 10.1016/j.measurement.2019.05.030
   Dash PP, 2019, J AMB INTEL HUM COMP, V10, P449, DOI 10.1007/s12652-017-0663-5
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Eiben AE, 2011, SWARM EVOL COMPUT, V1, P19, DOI 10.1016/j.swevo.2011.02.001
   Kanagamalliga S, 2019, J INTELL FUZZY SYST, V36, P67, DOI 10.3233/JIFS-172257
   Kordestani JK, 2016, J EXP THEOR ARTIF IN, V28, P137, DOI 10.1080/0952813X.2015.1020521
   Kumar M, 2017, BIO-MED MATER ENG, V28, P643, DOI 10.3233/BME-171702
   Kwolek B, 2009, FUND INFORM, V95, P449, DOI 10.3233/FI-2009-159
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lim WH, 2015, EXPERT SYST APPL, V42, P5887, DOI 10.1016/j.eswa.2015.03.025
   Mirzamohammad M, 2014, J INTELL FUZZY SYST, V27, P929, DOI 10.3233/IFS-131052
   Naik B, 2018, J KING SAUD UNIV-COM, V30, P120, DOI 10.1016/j.jksuci.2016.01.001
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Qin QD, 2015, COMPUT OPER RES, V60, P91, DOI 10.1016/j.cor.2015.02.008
   Rajikietgumjorn S, 2013, P IEEE C COMP VIS PA
   Rao RV, 2016, APPL THERM ENG, V103, P572, DOI 10.1016/j.applthermaleng.2016.04.135
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Seo JH, 2006, IEEE T MAGN, V42, P1095, DOI 10.1109/TMAG.2006.871568
   Supreeth HSG, 2018, SIGNAL IMAGE VIDEO P, V12, P1097, DOI 10.1007/s11760-018-1259-z
   Tanweer MR, 2015, INFORM SCIENCES, V294, P182, DOI 10.1016/j.ins.2014.09.053
   Xi ZH, 2015, J INTELL FUZZY SYST, V29, P2059, DOI 10.3233/IFS-151683
   Xiong T, 2003, LECT NOTES COMPUT SC, V2756, P190
   Zhang LM, 2015, APPL SOFT COMPUT, V28, P138, DOI 10.1016/j.asoc.2014.11.018
   Zhang X, 2008, PROC CVPR IEEE, P117
   Zhang XQ, 2010, IEEE T CIRC SYST VID, V20, P1590, DOI 10.1109/TCSVT.2010.2087455
NR 33
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10577
EP 10600
DI 10.1007/s11042-020-10057-7
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593002700004
DA 2024-07-18
ER

PT J
AU Iqbal, M
   Riaz, MM
   Ghafoor, A
   Ahmad, A
AF Iqbal, Mehwish
   Riaz, Muhammad Mohsin
   Ghafoor, Abdul
   Ahmad, Attiq
TI Kernel estimation and optimization for image de-blurring using mask
   construction and super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super pixels; Kernel optimization; Gradient map; Super-resolution; Edge
   extraction
AB The blur of image is displayed by convolving an image with the blur kernel. Thus, estimating blur kernel is significants of image de-blurring. We aim at obtaining optimized blur kernel of image for de-blurring. Kernel estimation and optimization for de-blurring of image is proposed in this paper. Mask is created for kernel estimation through super pixels and gradient map (generated through illuminant layer). Structural information is extracted through creation of mask through super-pixels, instead of using exemplars and together with the illuminant part of image and gradient map estimates the kernel which is optimized using super-resolution. The proposed method extracts good structural information and edges, hence better de-blurring as compared to state-of-art de-blurring methods.
C1 [Iqbal, Mehwish; Ghafoor, Abdul; Ahmad, Attiq] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Riaz, Muhammad Mohsin] COMSATS, Ctr Adv Studies Telecommun CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM mehwish.phd@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk; attiq@mcs.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Ghafoor, Abdul/0000-0002-6117-3656
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bai YC, 2019, IEEE T IMAGE PROCESS, V28, P1404, DOI 10.1109/TIP.2018.2874290
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen CLZ, 2016, PATTERN RECOGN, V52, P410, DOI 10.1016/j.patcog.2015.09.033
   Chrysos GG, 2018, INT J COMPUT VISION, P1
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fang XH, 2019, IEEE T MICROW THEORY, V67, P195, DOI 10.1109/TMTT.2018.2870830
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203505
   Li LRH, 2019, INT J COMPUT VISION, V127, P1025, DOI 10.1007/s11263-018-01146-0
   Li TH, 2019, PATTERN RECOGN, V90, P134, DOI 10.1016/j.patcog.2019.01.019
   LIU F, 2018, YOUNG AC ANN C CHIN, P28
   Liu Shida, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3444, DOI 10.1109/TNNLS.2019.2892327
   Liu YH, 2018, LECT NOTES COMPUT SC, V11205, P467, DOI 10.1007/978-3-030-01246-5_28
   Ljubenovic M, 2019, INT J DOC ANAL RECOG, V22, P79, DOI 10.1007/s10032-019-00318-z
   Mei JH, 2019, MULTIMED TOOLS APPL, V78, P18869, DOI 10.1007/s11042-019-7251-y
   Mu CX, 2019, ISA T, V92, P1, DOI 10.1016/j.isatra.2019.01.025
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan Jinshan, 2018, IEEE TPAMI
   Ren DW, 2018, IEEE T IMAGE PROCESS, V27, P511, DOI 10.1109/TIP.2017.2764261
   Sacramento I, 2019, IEEE GEOSCI REMOTE S, V16, P315, DOI 10.1109/LGRS.2018.2870732
   Shen ZY, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1350-3
   Shen ZY, 2018, PROC CVPR IEEE, P8260, DOI 10.1109/CVPR.2018.00862
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Xu XY, 2018, IEEE T IMAGE PROCESS, V27, P194, DOI 10.1109/TIP.2017.2753658
   Yair N, 2018, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2018.00334
   YAN YY, 2017, PROC CVPR IEEE, P6978, DOI DOI 10.1109/CVPR.2017.738
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Yuan Q, 2019, COMPUTER VISION PATT, P1
   Yuan XF, 2018, IEEE T IND INFORM, V14, P3235, DOI 10.1109/TII.2018.2809730
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang Xinyi., 2018, P BMVC
   Zhang Yan, 2019, Comput Assist Surg (Abingdon), P1, DOI 10.1080/24699322.2018.1560090
NR 37
TC 3
Z9 3
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10361
EP 10372
DI 10.1007/s11042-020-09762-0
EA NOV 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591138600001
DA 2024-07-18
ER

PT J
AU Sharma, D
   Kumar, B
   Chand, S
   Shah, RR
AF Sharma, Deepak
   Kumar, Bijendra
   Chand, Satish
   Shah, Rajiv Ratn
TI Uncovering research trends and topics of communities in machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Author-topic model; Information retrieval; Overlapping community
   detection; Machine learning; Research trend analysis
ID SCIENTIFIC COLLABORATION NETWORKS; CLASSIFICATION; RECOGNITION;
   COMPLEXITY; ALGORITHM; ACCURACY; RECOVERY; MODELS; GROWTH; NOISE
AB This paper aims to uncover the research topics in machine learning research communities in a scientific collaboration network (SCN) to enhance the characteristic of systems such as retrieval or recommendation in intelligence-based systems. The existing research mainly focuses on the community evolution and measurement of typical features of the network. It is however unexplored how to identify the research interest of the communities along with authors in each community. A dataset is prepared consisting of 21,906 scientific articles from six top journals in the field of machine learning published from 1988 to 2017. An integrated approach combining the author-topic (AT) model with communities using through the directed affiliations (CoDA) method is explored to identify the research interest of the communities in a scientific collaboration network. The top rank communities are identified using the crank network community prioritization method. Finally, the similarity and dissimilarity of research interest in communities across decades are uncovered using the cosine similarity. The experimental results demonstrate the effectiveness and efficacy of the proposed technique. This study may be helpful for upcoming researchers to explore the research trends and topics in machine learning research communities.
C1 [Sharma, Deepak; Kumar, Bijendra] Univ Delhi, Netaji Subash Inst Technol, Dept Comp Engn, Sect 3, Delhi 110078, India.
   [Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi 110067, India.
   [Shah, Rajiv Ratn] Indraprastha Inst Informat Technol, Multimodal Digital Media Anal Lab, Delhi 110020, India.
C3 University of Delhi; Netaji Subhas University of Technology; Jawaharlal
   Nehru University, New Delhi; Indraprastha Institute of Information
   Technology Delhi
RP Sharma, D (corresponding author), Univ Delhi, Netaji Subash Inst Technol, Dept Comp Engn, Sect 3, Delhi 110078, India.
EM deepak.btg@gmail.com
RI Kumar, Bijendra/ABG-2754-2021; Sharma, Deepak/F-1486-2014
OI Kumar, Bijendra/0000-0002-5729-8982; Sharma, Deepak/0000-0002-6132-1719
CR Abbasi A., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P774, DOI 10.1109/HICSS.2012.664
   Abbasi A, 2011, SCIENTOMETRICS, V89, P687, DOI 10.1007/s11192-011-0463-1
   Abbasi AA, 2011, SCI REP-UK, V1, DOI 10.1038/srep00032
   ABDELMOTTALEB M, 1992, PATTERN RECOGN, V25, P1371, DOI 10.1016/0031-3203(92)90149-D
   ABDELMOTTALEB M, 1992, PATTERN RECOGN, V25, P641, DOI 10.1016/0031-3203(92)90080-3
   Abel GJ, 2019, EUR J POPUL, V35, P543, DOI 10.1007/s10680-018-9493-1
   Adamic N., 2005, INT WORKSHOP LINK DI, P36, DOI DOI 10.1145/1134271.1134277
   Ahn YY, 2010, NATURE, V466, P761, DOI 10.1038/nature09182
   [Anonymous], INT JOURNAL U E SERV
   Arenas A, 2004, EUR PHYS J B, V38, P373, DOI 10.1140/epjb/e2004-00130-1
   Backstrom L., 2006, P 12 ACM SIGKDD INT, P44, DOI DOI 10.1145/1150402.1150412
   Balakrishnan H, 2006, THESIS
   BANERJEE S, 1993, PATTERN RECOGN, V26, P963, DOI 10.1016/0031-3203(93)90061-Z
   BHASKAR SK, 1989, PATTERN RECOGN, V22, P533, DOI 10.1016/0031-3203(89)90022-8
   BHATTACHARYA P, 1995, PATTERN RECOGN, V28, P769, DOI 10.1016/0031-3203(94)00139-D
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1007/BF00993345
   Bradford RogerB., 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08, P153, DOI DOI 10.1145/1458082.1458105
   Brunson JC, 2014, SCIENTOMETRICS, V99, P973, DOI 10.1007/s11192-013-1209-z
   Buckley C, 1995, STOPWORD LIST 2
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   CINQUE L, 1995, PATTERN RECOGN, V28, P901, DOI 10.1016/0031-3203(94)00147-E
   CUCKA P, 1992, PATTERN RECOGN, V25, P189, DOI 10.1016/0031-3203(92)90100-W
   CUCKA P, 1993, PATTERN RECOGN, V26, P1417, DOI 10.1016/0031-3203(93)90147-O
   DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841
   DEMICHELI E, 1993, IEEE T PATTERN ANAL, V15, P434, DOI 10.1109/34.211464
   Depiero F, 1996, PATTERN RECOGN, V29, P1031, DOI 10.1016/0031-3203(95)00140-9
   DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788
   DOERMANN DS, 1994, PATTERN RECOGN, V27, P233, DOI 10.1016/0031-3203(94)90056-6
   Evans TS, 2011, SCIENTOMETRICS, V89, P381, DOI 10.1007/s11192-011-0439-1
   Evans TS, 2010, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2010/12/P12037
   Fejes S, 1997, PATTERN RECOGN, V30, P817, DOI 10.1016/S0031-3203(96)00120-3
   FELD SL, 1981, AM J SOCIOL, V86, P1015, DOI 10.1086/227352
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Friedland NS, 1997, PATTERN RECOGN, V30, P525, DOI 10.1016/S0031-3203(96)00091-X
   FRIEDLAND NS, 1992, IEEE T PATTERN ANAL, V14, P770, DOI 10.1109/34.142912
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Gregori E, 2013, IEEE T PARALL DISTR, V24, P1651, DOI 10.1109/TPDS.2012.229
   Han HQ, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/529842
   He B, 2013, J INFORMETR, V7, P117, DOI 10.1016/j.joi.2012.09.005
   HechtNielsen R, 1995, NEURAL NETWORKS, V8, P1309, DOI 10.1016/0893-6080(95)00106-9
   Hemminger TL, 1996, PATTERN RECOGN, V29, P487, DOI 10.1016/0031-3203(95)00100-X
   HEMMINGER TL, 1994, IEEE T NEURAL NETWOR, V5, P712, DOI 10.1109/72.317723
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   HUANG XF, 1993, IEEE T PATTERN ANAL, V15, P838, DOI 10.1109/34.236243
   Ichise R, 2006, INFORMATION VISUALIZATION-BOOK, P276
   JOLION JM, 1989, PATTERN RECOGN, V22, P603, DOI 10.1016/0031-3203(89)90028-9
   Kamgar-Parsi B., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P282, DOI 10.1109/CVPR.1989.37862
   Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130
   KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1023/A:1022642017308
   Krichel T, 2006, INT C WEB INF SCIENT, P10
   Krogan NJ, 2006, NATURE, V440, P637, DOI 10.1038/nature04670
   Kronegger L, 2012, SCIENTOMETRICS, V90, P631, DOI 10.1007/s11192-011-0493-8
   LATECKI L, 1995, PATTERN RECOGN, V28, P1191, DOI 10.1016/0031-3203(94)00168-L
   Leskovec J, 2016, ACM T INTEL SYST TEC, V8, DOI 10.1145/2898361
   Liu XM, 2005, INFORM PROCESS MANAG, V41, P1462, DOI 10.1016/j.ipm.2005.03.012
   McAuley J, 2014, ACM T KNOWL DISCOV D, V8, P73, DOI 10.1145/2556612
   MEER P, 1990, IEEE T PATTERN ANAL, V12, P216, DOI 10.1109/34.44408
   MEER P, 1988, PATTERN RECOGN, V21, P217, DOI 10.1016/0031-3203(88)90056-8
   MEER P, 1990, IEEE T PATTERN ANAL, V12, P363, DOI 10.1109/34.50622
   Nguyen MV, 2012, IEEE C EVOL COMPUTAT
   MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607
   Pepe A, 2010, SCIENTOMETRICS, V84, P687, DOI 10.1007/s11192-009-0147-2
   PHILLIPS TY, 1989, PATTERN RECOGN, V22, P741, DOI 10.1016/0031-3203(89)90010-1
   Porter MA, 2009, NOTICES AMS, V56
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Rosen-Zvi Michal., 2004, UAI
   ROSENFELD A, 1988, PATTERN RECOGN, V21, P147, DOI 10.1016/0031-3203(88)90021-0
   Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001
   Shi Qingwei, 2013, Journal of the China Society for Scientific and Technical Information, V32, P912, DOI 10.3772/j.issn.1000-0135.2013.09.002
   Simmel George., 2010, CONFLICT WEB GROUP A
   SITARAMAN R, 1989, PATTERN RECOGN, V22, P331, DOI 10.1016/0031-3203(89)90080-0
   Steyvers M., 2004, P 2004 ACM SIGKDD IN, DOI [DOI 10.1145/1014052.1014087, 10.1145/1014052, DOI 10.1145/1014052]
   THOMPSON S, 1995, PATTERN RECOGN, V28, P241, DOI 10.1016/0031-3203(94)00095-4
   Thompson SF, 1997, PATTERN RECOGN, V30, P321, DOI 10.1016/S0031-3203(96)00067-2
   Tóth B, 2013, J STAT PHYS, V151, P689, DOI 10.1007/s10955-012-0640-5
   Waksman A, 1996, PATTERN RECOGN, V29, P297, DOI 10.1016/0031-3203(95)00080-1
   WU AY, 1989, PATTERN RECOGN, V22, P165, DOI 10.1016/0031-3203(89)90063-0
   WU AY, 1988, PATTERN RECOGN, V21, P559, DOI 10.1016/0031-3203(88)90029-5
   WU YJ, 1995, IEEE T NEURAL NETWOR, V6, P986, DOI 10.1109/72.392260
   WU YY, 1994, IEEE T PATTERN ANAL, V16, P961, DOI 10.1109/34.329012
   Xie JR, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501657
   Xu S, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/280892
   Yang J, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P323, DOI 10.1145/2556195.2556243
   Yang YY, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P587
   Zakarauskas P, 1996, IEEE T PATTERN ANAL, V18, P663, DOI 10.1109/34.506419
   Zhang CW, 2018, J ASSOC INF SCI TECH, V69, P72, DOI 10.1002/asi.23916
   Zhang ZF, 2013, DECIS SUPPORT SYST, V54, P870, DOI 10.1016/j.dss.2012.09.012
   Zhao WZ, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S13-S8
   Zitnik M, 2018, ARXIV180502411
NR 98
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9281
EP 9314
DI 10.1007/s11042-020-10072-8
EA NOV 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972400003
DA 2024-07-18
ER

PT J
AU Lakshmi, C
   Thenmozhi, K
   Rayappan, JBB
   Amirtharajan, R
AF Lakshmi, C.
   Thenmozhi, K.
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Genetic and chaotic signatures in offspring - an encrypted generation of
   image family
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; 1D chaotic map; Hybrid image encryption; Optimised
   encryption; Novel crossover and mutation; Image fusion
ID MEDICAL IMAGE; ALGORITHM; DNA
AB With the rapid escalation of information technology and the internet, the digital image has turned out to be a vital medium for communication. Hence, there is an increasing demand to protect these digital images as they are transmitted over the insecure medium such as the Internet. This paper proposes the Genetic Algorithm influenced image encryption scheme. Both crossover and mutation operations were performed to enhance the statistical measures of the grayscale cipher images. Intra-pixel bit manipulation improved the diffusion property during mutation. Crossover accomplished the generation of offspring with the confluence of image intensities and keys. The chaotic Logistic and Tent maps provided improvement in keyspace through their role in the generation of initial seeds. Noticeably, the initial seeds were generated from the features of input image such as minimum & maximum number of occurrences of intensity and minimum & maximum intensity levels. In this regard, every image will accompany a unique key sequence as a session key which needs to be shared with the intended receiver for the distortion-free recovery of original images. Besides, the multi-point genetic crossover was employed for diffusion which resulted in the production of a couple of offspring. The Fitness test which decides the number of generations was executed by performing correlation and entropy analyses at a threshold of 0.01 and 7.99 for the former and later respectively. The investigational consequences authenticate that the proposed scheme not only reveals simple and optimised encryption, it is also defending against various distinctive attacks. The proposed image security solutions can be incorporated in banking, medical insurances, e-healthcare, and e-governance sectors for document confidentiality and integrity checking mechanisms.
C1 [Lakshmi, C.; Thenmozhi, K.; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM lakshmi_c@ece.sastra.edu; thenmozhik@ece.sastra.edu;
   rjbosco@ece.sastra.edu; amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; Rayappan, John Bosco
   Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870
FU Department of Science & Technology, New Delhi [SR/FST/ET-II/2018/221]
FX Authors thank Department of Science & Technology, New Delhi for the FIST
   funding (SR/FST/ET-II/2018/221). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work and also wish to thank Dr. R.
   Sundraraman, Sridevi Arumugam, Dhivya Ravichandran, Sivaraman Rethinam
   and Information Security Research Group/SEEE/SASTRA Deemed University
   for their Time and Linguistic support.
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chandrasekaran J, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/6729896
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   Dagadu JC, 2019, MULTIMED TOOLS APPL, V78, P24979, DOI 10.1007/s11042-019-7693-2
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Hu B, 2018, IEEE T IND INFORM, V14, P3775, DOI 10.1109/TII.2018.2808966
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kumar J, 2012, ADV INTELLIGENT SYST, V167, DOI [10.1007/978-3-642-30111-7_75, DOI 10.1007/978-3-642-30111-7_75]
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Lakshmi C, 2018, COMPUT METH PROG BIO, V159, P11, DOI 10.1016/j.cmpb.2018.02.021
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P20465, DOI 10.1007/s11042-019-7186-3
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Rajagopalan S, 2019, MULTIMED TOOLS APPL, V78, P10513, DOI 10.1007/s11042-018-6574-4
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ratan R., 2014, P 3 INT C SOFT COMPU, P821
   Suri S, 2019, J INTELL SYST, V28, P333, DOI 10.1515/jisys-2017-0069
   Wang B, 2016, OPTIK, V127, P3541, DOI 10.1016/j.ijleo.2016.01.015
   Wang CQ, 2017, MULTIMED TOOLS APPL, V76, P24251, DOI 10.1007/s11042-016-4102-y
   Wang J, 2016, INT J OPT, V2016, DOI 10.1155/2016/2053724
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wu Y, 2011, 2011 AASRI CONFERENCE ON APPLIED INFORMATION TECHNOLOGY (AASRI-AIT 2011), VOL 2, P37
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P15605, DOI 10.1007/s11042-018-6973-6
NR 35
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8581
EP 8609
DI 10.1007/s11042-020-09978-0
EA NOV 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500002
DA 2024-07-18
ER

PT J
AU Hanif, M
   Ling, HF
   Tian, WY
   Shi, YX
   Rauf, M
AF Hanif, Muhammad
   Ling, Hefei
   Tian, Weiyi
   Shi, Yuxuan
   Rauf, Mudassar
TI Re-ranking person re-identification using distance aggregation of
   k-nearest neighbors hierarchical tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-ranking; Person re-identification; Distance aggregation; Hierarchical
   tree; k-nearest neighbors; Multi-query
ID SIMILARITY
AB Person re-identification is a challenging task due to the critical factors like illumination, occlusion, pose variation, view-points, low resolution, inter/intra-class variations, etc. Re-identification mainly treated as the target retrieval process, which can be improved by multi-query and re-ranking. Due to the high computational cost and consideration of fixed length gallery size, existing re-ranking approaches are not feasible for real-time re-identification applications, specifically with the variable-length gallery. We have proposed a fast yet effective re-ranking approach that utilize the pre-computed pair-wise distance used for initial ranking. We have integrated the advantages of nearest neighbors, hierarchical tree, and multi-query for re-ranking. We hypothesize that the hierarchy of k-nearest neighbors of an image leads to more positive matches in the child layer. Hence the aggregated distance decreases for true match and increases for false match images of the initial rank. We have structured k-nearest neighbor's hierarchical tree and calculated the aggregated distance. Hierarchical nearest neighbors are treated as multi-query under distance aggregation. Final re-ranked distance is computed as the weighted sum of aggregated and actual distance. Our proposed re-ranking approach is computationally efficient, feasible for real-time applications, unsupervised, and completely automatic. The effectiveness of our proposed method (Source code isavailable upon request) has been verified by various experiments on MARS, Market-1501, DukeMTMC, and CUHK03 datasets.
C1 [Hanif, Muhammad; Ling, Hefei; Tian, Weiyi; Shi, Yuxuan] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Rauf, Mudassar] Huazhong Univ Sci & Technol, SANY Joint Lab Adv Mfg, State Key Lab Digital Mfg Equipment & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Hanif, M (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM muhammadhanif@hust.edu.cn
RI Rauf, Mudassar/J-5209-2018
OI Rauf, Mudassar/0000-0002-2325-9512; HANIF, MUHAMMAD/0000-0002-8517-8179
FU Natural Science Foundation of China [U1536203, 61972169]; National key
   research and development program of China [2016QY01W0200]; Major
   Scientific and Technological Project of Hubei Province [2018AAA068,
   2019AAA051]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203 and 61972169, in part by the National key
   research and development program of China (2016QY01W0200), in part by
   the Major Scientific and Technological Project of Hubei Province
   (2018AAA068 and 2019AAA051).
CR Abdolali M, 2020, INFORM SCIENCES, V514, P333, DOI 10.1016/j.ins.2019.11.031
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2007, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2007.382970
   [Anonymous], 2013, ICCV
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2011, CVPR
   Arandjelovic R., 2012, BMVC
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen XQ, 2020, IEEE ACCESS, V8, P131352, DOI 10.1109/ACCESS.2020.3009653
   Chen Y, 2019, J VIS COMMUN IMAGE R, V58, P486, DOI 10.1016/j.jvcir.2018.11.044
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   García J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   Hanif M, 2017, LECT NOTES COMPUT SC, V10317, P352, DOI 10.1007/978-3-319-59876-5_39
   Hassaan O, 2019, ICAS
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M., 2012, ECCV
   JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640
   Kim K, 2019, PATTERN RECOGN LETT, V128, P326, DOI 10.1016/j.patrec.2019.09.020
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ksibi S, 2019, MULTIMED TOOLS APPL, V78, P1583, DOI 10.1007/s11042-018-6200-5
   Lavi Bahram., 2018, Survey on deep learning techniques for person re-identification task
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu J, 2019, APPL INTELL, V49, P3436, DOI 10.1007/s10489-019-01459-8
   Mang Ye, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P105, DOI 10.1007/978-3-319-14445-0_10
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Syed MA, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/3202495
   Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25
   Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yuan CH, 2018, MULTIMED TOOLS APPL, V77, P12437, DOI 10.1007/s11042-017-4896-2
   Zhang GW, 2014, IEICE T INF SYST, VE97D, P2461, DOI 10.1587/transinf.2013EDP7424
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 54
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 8015
EP 8038
DI 10.1007/s11042-020-10123-0
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583128600006
DA 2024-07-18
ER

PT J
AU Mahadevan, A
   Arock, M
AF Mahadevan, Anbazhagan
   Arock, Michael
TI A class imbalance-aware review rating prediction using hybrid sampling
   and ensemble learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Class imbalanced learning; Ensemble learning; Machine learning
   classification; Over sampling; Under sampling; Review rating prediction
ID DATA-SETS; CLASSIFICATION
AB Imbalanced distribution of instances across the classes is a challenging issue when the underlying problem is of type classification. The reason is that classifiers will tend to favor the classes with a large number of instances i.e. instances of minority classes may be identified as instances of majority classes by the classifiers. In recent years, plenty of researches have been done to resolve the class imbalance issue in binary classification problems which resulted in many class imbalance learning techniques for binary classification problems. But, the class imbalance in multi-class classification problems did not draw much attention from the research community. Unlike binary class imbalance learning, multi-class imbalance learning techniques experience more than one majority class and more than one minority class. This paper tries to come up with a multi-class imbalanced learning technique that can overcome the effects of multi-class imbalance problem in review rating prediction tasks. The proposed model handles the multi-class imbalance issue by using the combination of hybrid sampling and ensemble learning techniques. Sampling techniques such as Random Under Sampling (RUS) and Synthetic Minority Over-sampling TEchnique(SMOTE) are jointly used in the proposed model to create balanced training sets for base learners. Also, the proposed model creates a powerful ensemble structure by amalgamating a manually created bagging ensemble and AdaBoost boosting ensembles. Experiments are done using the Amazon product dataset in order to investigate the performance of the proposed model. The experimental results show that the proposed Class Imbalance-Aware Review rating prediction(CIAR) model outperforms almost all the baseline models in-terms of G-mean, F-Score, and ROC_AUC_Score.
C1 [Mahadevan, Anbazhagan; Arock, Michael] Madanapalle Inst Technol & Sci, Dept Comp Sci & Engn, Chittoor, Andhra Pradesh, India.
   [Arock, Michael] Natl Inst Technol, Dept Comp Applicat, Trichy, Tamil Nadu, India.
C3 Madanapalle Institute of Technology & Science; National Institute of
   Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Mahadevan, A (corresponding author), Madanapalle Inst Technol & Sci, Dept Comp Sci & Engn, Chittoor, Andhra Pradesh, India.
EM anbazhaganm@mits.ac.in
RI Mahadevan, Anbazhagan/AAQ-9001-2021; Mahadevan, Anbazhagan/AAL-6539-2021
OI Mahadevan, Anbazhagan/0000-0002-4644-9984
CR Agrawal A, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT (IC3K), P226
   Ahmed S, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTION (CSITSS-2017), P126, DOI [10.1109/CSITSS.2017.8447799, 10.1109/HONET.2017.8102204]
   Allwein E., 2002, JMLR, V1, P113
   [Anonymous], 2004, DISCRIMINANT ANAL ST
   [Anonymous], 2011, ENCY MACHINE LEARNIN
   [Anonymous], 2009, P 14 AUSTRALASIAN DO
   [Anonymous], 2009, 3 INT AAAI C WEBL SO
   Arora S, 2012, ANN IEEE SYMP FOUND, P1, DOI 10.1109/FOCS.2012.49
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Beyan C, 2015, PATTERN RECOGN, V48, P1653, DOI 10.1016/j.patcog.2014.10.032
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Dang Y, 2010, IEEE INTELL SYST, V25, P46, DOI 10.1109/MIS.2009.105
   Denil M, 2010, LECT NOTES ARTIF INT, V6085, P220
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Domingos Pedro, 1999, P 5 ACM SIGKDD INT C, P155, DOI DOI 10.1145/312129.312220
   Fernández A, 2013, KNOWL-BASED SYST, V42, P97, DOI 10.1016/j.knosys.2013.01.018
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gonzalez-Barcenas V. M., 2019, Pattern Recognition and Image Analysis. 9th Iberian Conference, IbPRIA 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11867), P216, DOI 10.1007/978-3-030-31332-6_19
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Hassan J, 2020, NEURAL PROCESS LETT, V51, P1031, DOI 10.1007/s11063-019-10125-6
   Hastie T, 1998, ADV NEUR IN, V10, P507
   Hendry, 2019, IAENG International Journal of Computer Science, V46, P109
   Hensman P., 2015, Degree Project in Computer Science
   Honnibal Matthew, 2017, SPACY 2 NATURAL LANG, V7
   Hu N, 2009, COMMUN ACM, V52, P144, DOI 10.1145/1562764.1562800
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Kubat M., 1997, ICML, P179
   Lee H, 2016, IEEE IMAGE PROC, P3713, DOI 10.1109/ICIP.2016.7533053
   Li W., 2012, J INF COMPUT SCI, V9, P4551
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Loyola-González O, 2016, NEUROCOMPUTING, V175, P935, DOI 10.1016/j.neucom.2015.04.120
   Lu Y, 2016, LECT NOTES ARTIF INT, V9651, P14, DOI 10.1007/978-3-319-31753-3_2
   Ma X, 2018, MULTIMED TOOLS APPL, V77, P6425, DOI 10.1007/s11042-017-4550-z
   McAuley Julian, 2013, RECSYS
   Orriols-Puig A, 2009, SOFT COMPUT, V13, P213, DOI 10.1007/s00500-008-0319-7
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pouyanfar S, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P112, DOI 10.1109/MIPR.2018.00027
   Salton G, 1986, Introduction to Modern Information Retrieval
   Schapire RE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1401
   Shengguo Hu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P13, DOI 10.1109/WCSE.2009.756
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659, DOI 10.1109/TKDE.2002.1000348
   Usuga Cadavid JP, 2020, ENTERPRISE INFORM SY, P1
   Wang HS, 2018, IEEE ACM T COMPUT BI, V15, P1968, DOI 10.1109/TCBB.2018.2827029
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Wang S, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P324, DOI 10.1109/CIDM.2009.4938667
   [谢丽星 Xie Lixing], 2012, [中文信息学报, Journal of Chinese Information Processing], V26, P73
   Zadrozny B., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P204, DOI 10.1145/502512.502540
NR 53
TC 11
Z9 14
U1 6
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6911
EP 6938
DI 10.1007/s11042-020-10024-2
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583495800002
DA 2024-07-18
ER

PT J
AU Bisen, D
AF Bisen, Dhananjay
TI Deep convolutional neural network based plant species recognition
   through features of leaf
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image pre-processing; Feature extraction; Leaf
   recognition; CNN classifier; Swedish leaf dataset
ID CLASSIFICATION
AB In present scenario, the research under image processing has been rapidly transformed from machine learning to deep learning. The deep learning algorithms are usually applied in the various areas like images to be classified or identified more accurately. One of the application areas of deep learning is the plant identification through its leaf which helps to recognize plant species. Botanists consume most of time in identifying plant species by manually scrutinizing and finding its features. This paper proposes an automated plant identification system, for identifying the plants species through their leaf. This task is accomplished using deep convolutional neural network to achieve higher accuracy. Image pre-processing, feature extraction and recognition are three main identification steps which are taken under consideration. Proposed CNN classifier learns the features of plants such as classification of leafs by using hidden layers like convolutional layer, max pooling layer, dropout layers and fully connected layers. The model acquires a knowledge related to features of Swedish leaf dataset in which 15 tree classes are available, that helps to predict the correct category of unknown plant with accuracy of 97% and minimum losses. Result is slightly better than the previous work that analyzes 93.75% of accuracy.
C1 [Bisen, Dhananjay] Rajkiya Engn Coll Banda, Atarra, UP, India.
RP Bisen, D (corresponding author), Rajkiya Engn Coll Banda, Atarra, UP, India.
EM bisen.it2007@gmail.com
RI bisen, dhananjay/ABG-6485-2021
OI bisen, dhananjay/0000-0003-4165-3959
CR [Anonymous], 2020, PYTHON STANDARD LIB
   Arafat SV, 2016, INT CONF DIGIT INFO, P136, DOI 10.1109/DICTAP.2016.7544015
   Bambil Deborah, 2020, Environment Systems & Decisions, V40, P480, DOI 10.1007/s10669-020-09769-w
   Barré P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005
   Beghin T., 2010, LECT NOTES COMPUTER
   Chaki J, 2019, OPTIK, V181, P639, DOI 10.1016/j.ijleo.2018.12.107
   Chollet F., 2017, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Kadir A, 2011, INT J COMPUT TRENDS
   Kan H. X., 2017, Pattern Recognition and Image Analysis, V27, P581, DOI 10.1134/S105466181703018X
   Kumar N, 2012, LECT NOTES COMPUTER, V7573
   Lukic M, 2017, 2017 IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), P485, DOI 10.1109/SAMI.2017.7880358
   Patil J.K., 2017, Engineering in agriculture, environment and food, V10, P69
   Kumar JP, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-019-01056-2
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038
   Singh Krishna., 2010, International Journal of Signal Processing Image Processing and Pattern Recognition, V3, P67
   Swedish Leaf Dataset, 2020, SWEDISH LEAF DATASET
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108
NR 20
TC 33
Z9 36
U1 9
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6443
EP 6456
DI 10.1007/s11042-020-10038-w
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000579257900004
DA 2024-07-18
ER

PT J
AU Shelke, NA
   Kasana, SS
AF Shelke, Nitin Arvind
   Kasana, Singara Singh
TI A comprehensive survey on passive techniques for digital video forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery detection; Inter-frame forgery; Intra-frame forgery;
   Passive techniques; Video anti-forensics; Deepfake detection
ID DETECTION ALGORITHM; FRAME DELETION; DUPLICATION FORGERY; TAMPERING
   DETECTION; LOCALIZATION; FORENSICS; INCONSISTENCY; MOTION
AB Digital videos are one of the most widespread forms of multimedia in day to day life. These are widely transferred over social networking websites such as Facebook, Instagram, WhatsApp, YouTube, etc. through the Internet. Availability of modern and easy to use editing tools have facilitated the modification of the contents of the digital videos. Therefore, it has become an essential concern for the legitimacy, trustworthiness, and authenticity of these digital videos. Digital video forgery detection aims to identify the manipulations in the video and to check its authenticity. These techniques can be divided into active and passive techniques. In this paper, a comprehensive survey on video forgery detection using passive techniques have been presented. The primary goal of this survey is to study and analyze the existing passive video forgery detection techniques. Firstly, the preliminary information required for understanding video forgery detection is presented. Later, a brief survey of existing passive video forgery detection techniques based on the features, forgery identified, datasets used, and performance parameters detail along with their limitations are reviewed. Then, anti-forensics strategy and deepfake detection in the video are discussed. After that, standard benchmark video forgery datasets and the generalized architecture for passive video forgery detection techniques are discussed. Finally, few open challenges in the field of passive video forgery detection are also described.
C1 [Shelke, Nitin Arvind; Kasana, Singara Singh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Shelke, NA (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM nshelke_phd17@thapar.edu; singara@thapar.edu
RI Shelke, Nitin Arvind/JCD-7173-2023
OI Shelke, Nitin Arvind/0000-0002-4801-1345
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   Aghamaleki JA, 2017, MULTIMED TOOLS APPL, V76, P20691, DOI 10.1007/s11042-016-4004-z
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Aloraini M, 2020, IEEE T CIRC SYST TEC
   Aloraini M, 2019, ELECT IMAG, V2019, P543
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   [Anonymous], 2014, 10 INT S TELECOMMUNI
   Aparicio-Díaz E, 2019, J INTELL FUZZY SYST, V36, P5023, DOI 10.3233/JIFS-179048
   Ardizzone E, 2015, LECT NOTES COMPUT SC, V9280, P665, DOI 10.1007/978-3-319-23234-8_61
   Bagiwa MA, 2016, DIGIT INVEST, V19, P29, DOI 10.1016/j.diin.2016.09.001
   Bai SS, 2019, LECT NOTES COMPUT SC, V11903, P244, DOI 10.1007/978-3-030-34113-8_21
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bidokhti A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P13, DOI 10.1109/AISP.2015.7123529
   Bozkurt I, 2017, TURK J ELECTR ENG CO, V25, P4558, DOI 10.3906/elk-1703-125
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen CC, 2017, INF HIDING MULTIMED, V8, P86
   Chen R., 2012, Information Technology Journal, V11, P1456, DOI [10.3923/itj.2012.1456.1462, DOI 10.3923/itj.2012.1456.1462]
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Chetty Girija, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P606, DOI 10.1109/NSS.2010.8
   Chittapur GB, 2014, EMERGING RES ELECT C, P557
   Cho K., 2014, ARXIV14061078
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Fan Y., 2016, J INFORM HIDING MULT, V7, P399
   Fayyaz MA, 2020, MULTIMED TOOLS APPL, V79, P5767, DOI 10.1007/s11042-019-08236-2
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   GRIP, 2018, COP MOV DAT
   GRIP, 2017, SPLIC DAT
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong JH, 2019, DIGIT INVEST, V30, P23, DOI 10.1016/j.diin.2019.06.002
   Hongmei Liu, 2014, Information Security Practice and Experience. 10th International Conference, ISPEC 2014. Proceedings: LNCS 8434, P262, DOI 10.1007/978-3-319-06320-1_20
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hu X, 2015, P IEEE SEMICOND THER, P280, DOI 10.1109/SEMI-THERM.2015.7100173
   Hu YJ, 2012, INT J DIGIT CRIME FO, V4, P20, DOI 10.4018/jdcf.2012070102
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hyun D-K, 2012, ERA INTERACTIVE MEDI, P25, DOI DOI 10.1007/978-1-4614-3501-3_3
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnston P, 2020, NEURAL COMPUT APPL, V32, P12243, DOI 10.1007/s00521-019-04272-z
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kancherla K, 2012, LECT NOTES ARTIF INT, V7198, P308, DOI 10.1007/978-3-642-28493-9_33
   Kang XG, 2016, MULTIMED TOOLS APPL, V75, P13833, DOI 10.1007/s11042-015-2762-7
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Kingra S, 2017, MULTIMED TOOLS APPL, V76, P25767, DOI 10.1007/s11042-017-4762-2
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Kobayashi M, 2009, LECT NOTES COMPUT SC, V5414, P306, DOI 10.1007/978-3-540-92957-4_27
   Kono Kazuhiro, 2020, Proceedings of the Tenth International Conference on Soft Computing and Pattern Recognition (SoCPaR 2018). Advances in Intelligent Systems and Computing (AISC 942), P381, DOI 10.1007/978-3-030-17065-3_38
   Koopman M., 2018, 20 IR MACH VIS IM PR, P133
   Korshunov P., 2018, arXiv
   Labartino D, 2013, IEEE INT WORKSH MULT, P494, DOI 10.1109/MMSP.2013.6659338
   Li F., 2014, Proceedings of the 3rd International Conference on Multimedia Technology (ICMT 2013), P63
   Li L., 2012, INT WORKSH DIG WAT, P242
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li Y., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li YM, 2019, PROC CVPR IEEE, P8712, DOI 10.1109/CVPR.2019.00892
   Li ZH, 2016, SECUR COMMUN NETW, V9, P4548, DOI 10.1002/sec.1648
   Liao SY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P864, DOI 10.1109/CISP.2013.6745286
   Lin C-S., 2013, 2 INT C CYB SEC CYB, P107
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P7405, DOI 10.1007/s11042-017-4652-7
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Mathai M, 2016, IEEE SW SYMP IMAG, P149, DOI 10.1109/SSIAI.2016.7459197
   Mizher MA, 2017, INT J ELECTRON SECUR, V9, P191, DOI 10.1504/IJESDF.2017.10005634
   Mondaini N, 2007, PROC SPIE, V6505, DOI 10.1117/12.704924
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen T. T., 2019, CoRR
   NTHU, FOR PROJ DAT
   NTHU, VID INP PROJ
   Oh SM, 2011, PROC CVPR IEEE
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Pu H., 2019, UK WORKSH COMP INT, P541
   Qadir G., 2012, IET C IMAGE PROCESSI
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Rossler Andreas, 2018, Faceforensics: a large-scale video dataset for forgery detection in human faces
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Sabour Sara, 2017, Advances in Neural Information Processing Systems, P3856
   Saddique M, 2019, ADV ELECTR COMPUT EN, V19, P97, DOI 10.4316/AECE.2019.03012
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Shelke NA, 2013, IJCSET, V4
   Shelke NA, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1068, DOI 10.1109/WiSPNET.2016.7566301
   Shih TK, 2011, IEEE T SYST MAN CY C, V41, P720, DOI 10.1109/TSMCC.2010.2077674
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, FORENSIC SCI INT, V281, P75, DOI 10.1016/j.forsciint.2017.10.028
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Su LC, 2019, IEEE ACCESS, V7, P109719, DOI 10.1109/ACCESS.2019.2933871
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Su LC, 2015, MULTIMED TOOLS APPL, V74, P6641, DOI 10.1007/s11042-014-1915-4
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Su Y., 2009, 2009 International Conference on Computational Intelligence and Software Engineering, P1, DOI DOI 10.1109/CLSE.2009.5366884
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan SQ, 2015, ASIAPAC SIGN INFO PR, P719, DOI 10.1109/APSIPA.2015.7415366
   TREC, VID RETR EV TRECVID
   Ulutas G, 2018, MULTIMEDIA SYST, V24, P549, DOI 10.1007/s00530-017-0581-6
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang Q., 2014, Sens. Transducers, V166, P229
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wang W, 2013, IEEE INT CON DIS, P244, DOI 10.1109/ICDCSW.2013.69
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Xu J, 2018, INT J CIV ENG, V16, P335, DOI 10.1007/s40999-016-0132-0
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yao HC, 2019, J REAL-TIME IMAGE PR, V16, P751, DOI 10.1007/s11554-019-00865-y
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Yin LG, 2014, INT CONF INFO SCI, P148, DOI 10.1109/ICIST.2014.6920352
   Yu LY, 2016, NEUROCOMPUTING, V205, P84, DOI 10.1016/j.neucom.2016.03.051
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zampoglou M, 2019, LECT NOTES COMPUT SC, V11295, P374, DOI 10.1007/978-3-030-05710-7_31
   Zhang J, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P49, DOI 10.1109/ETCS.2009.273
   Zhang Z, 2019, INT C NAT COMP FUZZ, P415
   Zhang ZZ, 2015, SECUR COMMUN NETW, V8, P311, DOI 10.1002/sec.981
   Zhao DN, 2018, MULTIMEDIA TOOLS APP
   Zheng J, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P18, DOI 10.1109/CHINACOM.2014.7054251
   Zhenzhen Zhang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P94, DOI 10.1007/978-3-319-31960-5_9
NR 141
TC 36
Z9 36
U1 3
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6247
EP 6310
DI 10.1007/s11042-020-09974-4
EA OCT 2020
PG 64
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578275200002
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Ertam, F
AF Tuncer, Turker
   Ertam, Fatih
TI Novel tent pooling based human activity recognition approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tent pooling method; Human activity recognition; ReliefF; Smartphone;
   Information fusion
ID PHYSICAL-ACTIVITY RECOGNITION; SYSTEM; CLASSIFICATION; BEHAVIOR
AB Nowadays, mobile devices have been widely used worldwide and they have variable sensors. By using these sensors, many applications for instance navigation, healthcare, and human activity recognition (HAR) have been developed. The primary objective of this paper is to present a multi lightweight HAR method with high prediction performance. To implement this objective, novel pooling methodology is presented and it is called as tent pooling since pooling is processed using the variable size of blocks. 2 x 2, 3 x 3, 4 x 4, 5 x 5, 6 x 6, 7 x 7 and 8 x 8 sized non-overlapping blocks are used for pooling and maximum, minimum and average pooling methods. These pooling methods have been utilized as a feature generation model. The generated features are forwarded to the ReliefF feature selection method. ReliefF is a weight-based feature selector and uses Manhattan distance based fitness function. By using relief, the weights of the features are calculated and the negative weighted features are eliminated. This operation is named positive weighted feature selection. The selected positive weighted features are classified using a cubic support vector machine (SVM). To test the proposed method, a publicly and freely published HAR dataset is used. There are 6 activities in the used dataset. Also, the results of the proposed method were compared to other state of art methods. The best accuracy rate of the proposed tent pooling based HAR method was calculated as 99.81% using the average pooling. This results clearly prove that the success of the proposed tent pooling based method. The proposed method is also simple and effective. It has the highest success rates among the selected state-art-of HAR methods.
C1 [Tuncer, Turker; Ertam, Fatih] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
C3 Firat University
RP Tuncer, T (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
EM turkertuncer@firat.edu.tr; fatih.ertam@firat.edu.tr
RI TUNCER, Türker/ABG-1146-2020; Ertam, Fatih/V-5288-2018; TUNCER,
   Turker/W-4846-2018
OI Ertam, Fatih/0000-0002-9736-8068; 
CR Abdelnasser H, 2015, IEEE CONF COMPUT, P17, DOI 10.1109/INFCOMW.2015.7179321
   Abowd D., 1998, Virtual Reality, V3, P200, DOI 10.1007/BF01408562
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Alaa M, 2017, J NETW COMPUT APPL, V97, P48, DOI 10.1016/j.jnca.2017.08.017
   Amft O, 2008, ARTIF INTELL MED, V42, P121, DOI 10.1016/j.artmed.2007.11.007
   Anguita D., 2012, INT WORKSH AMB ASS L, P216
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   Anguita D, 2013, J UNIVERS COMPUT SCI, V19, P1295
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Banno W, 2019, 2019 IEEE 8 GLOB C C
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Benaissa B, 2018, INT J AFFECT ENG, V17, P81, DOI 10.5057/ijae.IJAE-D-17-00020
   Chen YF, 2017, IEEE ACCESS, V5, P3095, DOI 10.1109/ACCESS.2017.2676168
   Cheng L, 2017, 2017 COMPUTING CONFERENCE, P756, DOI 10.1109/SAI.2017.8252181
   CHO H, 2018, SENSORS BASEL, V18
   Chua SL, 2009, LECT NOTES COMPUTER
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Ehatisham-ul-Haq M, 2018, J NETW COMPUT APPL, V109, P24, DOI 10.1016/j.jnca.2018.02.020
   Fu BY, 2020, IEEE ACCESS, V8, P83791, DOI 10.1109/ACCESS.2020.2991891
   Giansanti D, 2008, PHYSIOL MEAS, V29, pN11, DOI 10.1088/0967-3334/29/3/N01
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   Hussain Z, 2020, J NETW COMPUT APPL, V167, DOI 10.1016/j.jnca.2020.102738
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Kastner M., 2013, EUR S ART NEUR NETW, P24
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   KIRA K, 1992, MACHINE LEARNING /, P249
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li LY, 2018, IEEE ACCESS, V6, P81, DOI 10.1109/ACCESS.2017.2749323
   Liu J, 2019, P IEEE INFOCOM
   Lu Y, 2018, BIOMED SIGNAL PROCES, V45, P50, DOI 10.1016/j.bspc.2018.05.011
   Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Mohamed R, 2018, J INF COMMUN TECHNOL, V17, P209
   Narayanan MR, 2007, P ANN INT IEEE EMBS, P4037, DOI 10.1109/IEMBS.2007.4353219
   Narayanan MR, 2010, IEEE T BIO-MED ENG, V57, P534, DOI 10.1109/TBME.2009.2033038
   Narayanan MR, 2008, IEEE ENG MED BIO, P2840, DOI 10.1109/IEMBS.2008.4649794
   NGUYEN TG, 2018, MICROPROCESS MICROSY, V56, P34
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Pu Q, 2013, P ANN INT C MOB COMP
   Reiss A, 2013, ESANN 2013
   Reyes-Ortiz JL, 2013, EUR S ART NEUR NETW, P24
   Romera-Paredes AMS, 2013, ESANN 2013, V2013, P24
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   San-Segundo R, 2016, PERVASIVE MOB COMPUT, V30, P84, DOI 10.1016/j.pmcj.2016.01.004
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   Subasi A., 2019, Procedia Computer Science, V163, P54, DOI DOI 10.1016/J.PROCS.2019.12.086
   Tolstikov Andrei, 2011, Journal of Control Theory and Applications, V9, P18, DOI 10.1007/s11768-011-0260-7
   Torres-Huitzil Cesar., 2015, MOBILE HLTH, P147
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang W, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P363, DOI 10.1145/2971648.2971670
   Wang XL, 2017, LECT NOTES COMPUT SC, V10612, P74, DOI 10.1007/978-3-319-69781-9_8
   Wang Y, 2019, EXPERT SYST APPL, V137, P167, DOI 10.1016/j.eswa.2019.04.057
   Wickramasinghe A, 2017, PERVASIVE MOB COMPUT, V34, P14, DOI 10.1016/j.pmcj.2016.06.004
   Xiao F, 2018, COMPUT NETW, V132, P108, DOI 10.1016/j.comnet.2018.01.003
   Yang J, 2011, J COMPUT SCI TECH-CH, V26, P239, DOI 10.1007/s11390-011-9430-9
   Yao LN, 2018, IEEE T MOBILE COMPUT, V17, P293, DOI 10.1109/TMC.2017.2706282
   Yu YG, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P298, DOI 10.1145/3356250.3360045
   Zeng Y, 2015, WPA 2015 P 2 WORKSH
   Zhou ZM, 2017, IEEE ACM T NETWORK, V25, P2405, DOI 10.1109/TNET.2017.2689063
   Zolfaghari S, 2016, ACSIS-ANN COMPUT SCI, V8, P1435, DOI 10.15439/2016F132
NR 64
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4639
EP 4653
DI 10.1007/s11042-020-09893-4
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573766000001
DA 2024-07-18
ER

PT J
AU Patel, A
   Rani, K
   Kumar, S
   Figueiredo, IN
   Figueiredo, PN
AF Patel, Abhinav
   Rani, Kumi
   Kumar, Sunil
   Figueiredo, Isabel N.
   Figueiredo, Pedro N.
TI Automated bleeding detection in wireless capsule endoscopy images based
   on sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless Capsule Endoscopy; Bleeding detection; Sparse coding;
   Dictionary learning
ID CLASSIFICATION; FEATURES; SCALE
AB Wireless Capsule Endoscopy (WCE) is a revolutionary technique for screening of gastrointestinal (GI) tract. However, WCE needs automated methods to reduce the time required for viewing its large image data and also to improve the accuracy of inspection. In this work, we propose novel sparse coded features to detect bleeding in WCE images. We acquire Scale-Invariant Feature Transform (SIFT) based key points as regions of interest of an image. Further, we compute SIFT and uniform Local Binary Pattern (LBP) features around the key points from an image. After that sparse coded features are obtained and support vector machine (SVM) is used for image classification. We provide comprehensive experimental results and also comparison with some recent bleeding detection methods and with traditional ways of computing sparse coded features. The best results are obtained with a dictionary size of 300 atoms. The classification accuracy we achieve with the proposed approach is 98.18%. The results presented in the paper indicate that the proposed method is reliable for bleeding detection in WCE images.
C1 [Patel, Abhinav; Rani, Kumi; Kumar, Sunil] Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
   [Figueiredo, Isabel N.] Univ Coimbra, Dept Math CMUC, Fac Sci & Technol, Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Coimbra, Fac Med, Coimbra, Portugal.
   [Figueiredo, Pedro N.] CHUC Ctr Hosp & Univ Coimbra, Dept Gastroenterol, Coimbra, Portugal.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Universidade de Coimbra;
   Universidade de Coimbra; Universidade de Coimbra
RP Kumar, S (corresponding author), Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
EM abhinav.patel.mat16@itbhu.ac.in; kumichauhan@gmail.com;
   skumar.mat@iitbhu.ac.in; isabelf@mat.uc.pt; pnf11@sapo.pt
RI Kumar, Sunil/ABU-7487-2022; Kumar, Sunil/Q-8557-2016; Figueiredo, Isabel
   Narra/ABD-7828-2020
OI Figueiredo, Isabel Narra/0000-0002-0215-8851; KUMAR,
   SUNIL/0000-0001-9991-1012; Rani, Kumi/0000-0002-8733-5844
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Appleyard M, 2001, NEW ENGL J MED, V344, P232, DOI 10.1056/NEJM200101183440316
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P173, DOI 10.1109/LGRS.2010.2055033
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Joshi I, 2016, LECT NOTES COMPUT SC, V9730, P575, DOI 10.1007/978-3-319-41501-7_64
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Lei Cui, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P1746, DOI 10.1109/ICINFA.2010.5512218
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Ren HM, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P66, DOI 10.1109/AVSS.2016.7738016
   Saini S, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503272
   Sidibé D, 2015, COMPUT BIOL MED, V62, P175, DOI 10.1016/j.compbiomed.2015.04.026
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 37
TC 7
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30353
EP 30366
DI 10.1007/s11042-020-09605-y
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000573766700001
DA 2024-07-18
ER

PT J
AU Roy, SS
   Basu, A
   Chattopadhyay, A
   Das, TS
AF Sinha Roy, Subhrajit
   Basu, Abhishek
   Chattopadhyay, Avik
   Das, Tirtha Sankar
TI Implementation of image copyright protection tool using
   hardware-software co-simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; FPGA implementation; Hardware-software
   co-simulation; LSB matching; Spatial domain; Visual information hiding
ID DATA HIDING SCHEME; WATERMARKING ALGORITHM; DIGITAL IMAGES; SYSTEM;
   FPGA; STEGANALYSIS; ARCHITECTURE; DESIGN; DSP
AB The proposed work presents particulars of a technique for the design and hardware implementation of an information hiding scheme using hardware-software co-simulation. The methodology aims to improve the design verification efficiency, development time and cost for DSP solutions. The scheme represents architecture for visual information hiding framework where information bits embedded into the host image by means of LSB matching technique. The design is tested by targeting a Spartan-3A DSP edition board (XC3SD3400A-4FGG676C) and the simulated results illustrate that this architecture provides a better opening for application specific events as well as explores different areas concerned to low cost hardware implementation through a graphical user interface.
C1 [Sinha Roy, Subhrajit; Basu, Abhishek] RCC Inst Informat Technol, Elect & Commun Engn, South Canal Rd, Kolkata 700015, India.
   [Sinha Roy, Subhrajit; Chattopadhyay, Avik] Univ Calcutta, Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
   [Das, Tirtha Sankar] Ramakrishna Mahato Govt Engn Coll, Elect & Commun Engn, Purilia, W Bengal, India.
C3 RCC Institute of Information Technology (RCCIIT); University of Calcutta
RP Roy, SS (corresponding author), RCC Inst Informat Technol, Elect & Commun Engn, South Canal Rd, Kolkata 700015, India.; Roy, SS (corresponding author), Univ Calcutta, Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
EM subhrajitkcs@gmail.com
RI Roy, Subhrajit Sinha/AAU-3651-2021; Basu, Abhishek/S-6016-2019
OI Basu, Abhishek/0000-0003-4167-3722
CR Anumol TJ, 2013, IJSER, V4
   Batlle J, 2002, REAL-TIME IMAGING, V8, P345, DOI 10.1006/rtim.2001.0273
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   ElAraby WS, 2010, INT C MICROELECTRON, P463, DOI 10.1109/ICM.2010.5696189
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Ghosh S, 2014, 5 INT S EL SYST DES, P15
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Guo L, 2017, MULTIMED TOOLS APPL, V76, P16949, DOI 10.1007/s11042-016-3597-6
   Hajjaji MA, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/1294267
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Kalomiros JA, 2008, MICROPROCESS MICROSY, V32, P95, DOI 10.1016/j.micpro.2007.09.001
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kougianos E, 2009, COMPUT ELECTR ENG, V35, P339, DOI 10.1016/j.compeleceng.2008.06.002
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lobo PJ, 2011, IEEE T CONSUM ELECTR, V57, P372, DOI 10.1109/TCE.2011.5955169
   Maity HK, 2014, J SYST SOFTWARE, V96, P93, DOI 10.1016/j.jss.2014.05.079
   Majumder S., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P938, DOI 10.1109/ICRTIT.2011.5972409
   Mert AC, 2018, EFFICIENT MULTIPLE C
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Moctezuma JC, 2008, ELE COM ENG, P284
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Mohanty SP, 2004, LECT NOTES COMPUT SC, V3356, P344
   Nayak MR, 2017, AEU-INT J ELECTRON C, V71, P1, DOI 10.1016/j.aeue.2016.10.025
   Ownby M, 2003, SOUTHEAST SYMP SYSTE, P404, DOI 10.1109/SSST.2003.1194601
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pexaras K, 2017, IEEE I C ELECT CIRC, P347, DOI 10.1109/ICECS.2017.8292014
   Phadikar A, 2020, MULTIMED TOOLS APPL, V79, P12507, DOI 10.1007/s11042-019-08392-5
   RS Sinha, 2018, FPGA IMPLEMENTATION
   Saidani T, 2009, P WORLD C ENG UK, VI
   Seo Y.H., 2003, P ISTWORKSHOP EMBEDD, P88
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Sinha Roy S, 2019, INTELLIGENT COPYRIGH
   Sinha RS, 2018, QUANTUM INSPIRED INT, P95
   Su GD, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102618
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wong M. L. D., 2013, INT J INNOVATION MAN, V4, P228
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zemcik Pavel., 2002, P 18 SPRING C COMPUT, P25
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 47
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4263
EP 4277
DI 10.1007/s11042-020-09944-w
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573567600004
DA 2024-07-18
ER

PT J
AU Wu, QE
   An, ZM
   Chen, H
   Qian, XL
   Sun, LJ
AF Wu, QingE
   An, Ziming
   Chen, Hu
   Qian, Xiaoliang
   Sun, Lijun
TI Small target recognition method on weak features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Small target detection; Small target recognition; Track tracking;
   Multi-frame chain; Fusion
ID SELECTION; FUSION; CLASSIFICATION; MODEL
AB For real time tracking the moving small target under complex backgrounds, this paper will present a tracking algorithm and a recognition method for small target based on the fusion filtering of single frame and multiple frames. For a case that the moving small target is masked or submersed easily by other objects or noise in complex background, this paper will present an opening and closing transform algorithm to eliminate or weaken background and noise; present a competitive model with adaptive neural network of online learning for the puniness characteristics of moving small target, use its competitive active unit to extract the multidimensional characteristic parameter of small target; consequently, present a tracking recognition method for moving small target based on a complex background. In conclusion, the significant novelty is the small target recognition method proposed, including the eliminating noise method, extraction method for weak small features, establishment of prediction model of motion target state, recognition method for small target. These researches development in this paper help to the personnel of target recognition and image processing understand the motion law, reduce expenditure, decrease unnecessary damage or injury, etc.
C1 [Wu, QingE; An, Ziming; Chen, Hu; Qian, Xiaoliang] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
   [Sun, Lijun] Henan Univ Technol, Key Lab Grain Informat Proc & Control, Minist Educ, Zhengzhou 450001, Peoples R China.
   [Sun, Lijun] Henan Univ Technol, Zhengzhou Key Lab Machine Percept & Intelligent S, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University of Light Industry; Henan University of Technology;
   Henan University of Technology
RP Wu, QE (corresponding author), Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
EM wqe969699@163.com
RI Qian, Xiaoliang/AAV-1480-2020; Sun, Lijun/AAD-1293-2020
OI Sun, Lijun/0000-0002-9830-1527; Wu, QingE/0000-0002-7746-8694
FU Center Plain Science and Technology Innovation Talents [194200510016];
   Science and Technology Innovation Team Project of Henan Province
   University [19IRTSTHN013]; Fourth Intelligent Compilation Zhengzhou 1125
   Science and Technology Innovation Talents [192101059006]; Key Science
   and Technology Program of Henan Province [172102310447]; Key Science
   Projects of Henan Universities [19A120004]
FX This work is supported by Center Plain Science and Technology Innovation
   Talents (194200510016); Science and Technology Innovation Team Project
   of Henan Province University (19IRTSTHN013); The Fourth Intelligent
   Compilation Zhengzhou 1125 Science and Technology Innovation Talents
   (192101059006); Key Science and Technology Program of Henan Province
   (172102310447); Key Science Projects of Henan Universities (19A120004),
   respectively.
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Cekli S., 2018, 26 SIGN PROC COMM AP, P1, DOI 10.1109/SIU.2018.8404311
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen SK, 2018, IEEE T CIRC SYST VID, V28, P2359, DOI 10.1109/TCSVT.2017.2703946
   Chen S, 2016, IEEE SENS J, V16, P4949, DOI 10.1109/JSEN.2016.2539391
   Cho W, 2018, IEEE SIGNAL PROC LET, V25, P80, DOI 10.1109/LSP.2017.2773128
   Dimitriou N, 2015, IMAGE VISION COMPUT, V36, P70, DOI 10.1016/j.imavis.2015.01.005
   Farrajota M, 2019, PATTERN ANAL APPL, V22, P1307, DOI 10.1007/s10044-018-0727-y
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   He Q, 2019, IEEE SIGNAL PROC LET, V26, P194, DOI 10.1109/LSP.2018.2880836
   Hou J., 2013, Laser Infrared, V43, P683
   Huss N, 2020, MED TEACH, V42, P1097, DOI 10.1080/0142159X.2020.1797998
   Kang CC, 2007, PATTERN RECOGN, V40, P609, DOI 10.1016/j.patcog.2006.03.016
   khan MA, 2020, APPL SOFT COMPUT J, V87, P256
   Kim S, 2014, ELECTRON LETT, V50, P81, DOI 10.1049/el.2013.2109
   Korytkowski M, 2016, INFORM SCIENCES, V327, P175, DOI 10.1016/j.ins.2015.08.030
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Nam Yul Y, 2017, IEEE SIGNAL PROCESS, V24, P181
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Qu HM, 2013, OPTIK, V124, P2313, DOI 10.1016/j.ijleo.2012.06.093
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Raza M, 2018, FUTURE GENER COMP SY, V88, P28, DOI 10.1016/j.future.2018.05.002
   Sharif A, 2019, CONTROL ENG APPL INF, V21, P3
   SHARIF M, 2017, EURASIP J IMAGE VIDE, V89, P1
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang WH, 2012, PROCEDIA ENGINEER, V29, P1201, DOI 10.1016/j.proeng.2012.01.113
   Wu QE, 2011, COMPUT MATH APPL, V61, P1267, DOI 10.1016/j.camwa.2010.08.101
   Xiankai Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8957, DOI 10.1109/CVPR42600.2020.00898
   Yunlong L, 2013, INFRARED LASER ENG, V42, P814
NR 34
TC 5
Z9 5
U1 7
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4183
EP 4201
DI 10.1007/s11042-020-09926-y
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573567600001
DA 2024-07-18
ER

PT J
AU Sun, JC
   Li, JQ
   Liu, L
AF Sun, Jingchao
   Li, Jianqiang
   Liu, Lu
TI Semantic segmentation of brain tumor with nested residual attention
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumors; Social media environment; Telemedicine systems; Residual
   attention block; Nested residual attention block
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Brain tumors are one of the most serious brain diseases, which often result in a short life. However, in developing areas, medical resources are in shortage, which affect the diagnosis of brain tumors. With the development of computer science, many diseases can be diagnosed by telemedicine systems, which help physicians save much time and improve diagnostic accuracy. Therefore, we propose a semantic segmentation method for brain tumors based on nested residual attention networks. It can be deployed in social mx'edia environment to work as a remote diagnosis system. The proposed method uses an improved residual attention block (RAB) as the basic unit. Based on the improved RAB, a nested RAB is designed to build the proposed method, which has better generalization. The proposed method includes an encoder part, a decoder part and skip connections. The encoder part learns multiple feature representations from inputs and the decoder part utilizes the learnt features to make segmentation predictions. In addition, high-level attention feature maps are exploited to induce low-level feature maps in skip connections to discard useless information. The proposed method is mainly validated on the dataset of Brain Tumor Segmentation challenge (BraTS) 2015. The proposed method achieves an average dice score of 0.87 (0.80, 0.72) for the whole tumor (core tumor, enhancing tumor) regions on BraTS 2015 dataset.
C1 [Sun, Jingchao; Li, Jianqiang; Liu, Lu] Beijing Univ Technol, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Li, JQ (corresponding author), Beijing Univ Technol, Sch Software Engn, Beijing, Peoples R China.
EM lijianqiang@bjut.edu.cn
RI li, jy/HTT-1535-2023; LI, JIAN/JAX-3092-2023; Liu, Jing/IQX-0664-2023;
   LI, Jing/HNB-5575-2023; LI, JIAN/GRY-2197-2022; li, jian/IAQ-2794-2023;
   l, j/HNC-5728-2023; li, jian/GSE-0245-2022; Li, Jing/GYU-5036-2022; Li,
   Jin/GYQ-5363-2022
FU National Key R&D Program of China [2017YFB1400803]
FX This study is supported by the National Key R&D Program of China with
   project No. 2017YFB1400803.
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Chandra S, 2019, LECT NOTES COMPUT SC, V11384, P299, DOI 10.1007/978-3-030-11726-9_27
   Chen X, 2018, LECT NOTES COMPUT SC, V11217, P674, DOI 10.1007/978-3-030-01261-8_40
   El-Melegy MT, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-21
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hung CJ, 2003, J CLIN ENDOCR METAB, V88, P3694, DOI 10.1210/jc.2003-030080
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Isensee Fabian, 2018, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Third International Workshop, BrainLes 2017. Held in Conjunction with MICCAI 2017. Revised Selected Papers: LNCS 10670, P287, DOI 10.1007/978-3-319-75238-9_25
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kamnitsas K, 2016, LECT NOTES COMPUT SC, V10154, P138, DOI 10.1007/978-3-319-55524-9_14
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kermi A, 2019, LECT NOTES COMPUT SC, V11384, P37, DOI 10.1007/978-3-030-11726-9_4
   Li JQ, 2019, IEEE ACCESS, V7, P63709, DOI 10.1109/ACCESS.2019.2916724
   Li JQ, 2016, NEUROCOMPUTING, V177, P385, DOI 10.1016/j.neucom.2015.11.042
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   McKinley R, 2019, LECT NOTES COMPUT SC, V11384, P456, DOI 10.1007/978-3-030-11726-9_40
   Menon N, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P6, DOI 10.1109/ICCSP.2015.7322635
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Pereira S, 2018, LECT NOTES COMPUT SC, V11072, P706, DOI 10.1007/978-3-030-00931-1_81
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma M, 2013, INT J, V3
   Shreyas V, 2017, IEEE INT WORKSH MULT
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Wang L, 2019, FOOD SAFETY & MYCOTOXINS, P13, DOI 10.1007/978-981-32-9038-9_2
   Weninger L, 2019, LECT NOTES COMPUT SC, V11384, P3, DOI 10.1007/978-3-030-11726-9_1
   Xu X, 2020, IEEE J BIOMED HEALTH, V24, P556, DOI 10.1109/JBHI.2019.2914690
   Yang JJ, 2016, COMPUT METH PROG BIO, V124, P45, DOI 10.1016/j.cmpb.2015.10.007
   Yang JJ, 2015, COMPUT IND, V69, P3, DOI 10.1016/j.compind.2015.01.012
   Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhou C., 2019, ARXIV190601796
   Zhou CH, 2019, LECT NOTES COMPUT SC, V11384, P497, DOI 10.1007/978-3-030-11726-9_44
NR 44
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34203
EP 34220
DI 10.1007/s11042-020-09840-3
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000572335600004
DA 2024-07-18
ER

PT J
AU Redondo, RPD
   Rodríguez, MC
   Escobar, JJL
   Vilas, AF
AF Diaz Redondo, Rebeca P.
   Caeiro Rodriguez, Manuel
   Lopez Escobar, Juan Jose
   Fernandez Vilas, Ana
TI Integrating micro-learning content in traditional e-learning platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-learning; Learning Tools Interoperability (LTI); Learning
   Management System (LMS); Learning Information Service (LIS)
AB Lifelong learning requires appropriate solutions, especially for corporate training. Workers usually have difficulty combining training and their normal work. In this context, micro-learning emerges as a suitable solution, since it is based on breaking down new concepts into small fragments or pills of content, which can be consumed in short periods of time. The purpose of this paper is twofold. First, we offer an updated overview of the research on this training paradigm, as well as the different technologies leading to potential commercial solutions. Second, we introduce a proposal to add micro-learning content to more formal distance learning environments (traditional Learning Management Systems or LMS), with the aim of taking advantage of both learning philosophies. Our approach is based on a Service-Oriented Architecture (SOA) that is deployed in the cloud. In order to ensure the full integration of the micro-learning approach in traditional LMSs, we have used two well-known standards in the distance learning field: LTI (Learning Tools Interoperability) and LIS (Learning Information Service). The combination of these two technologies allows the exchange of data with the LMS to monitor the student's activity and results. Finally, we have collected the opinion of lectures from different countries in order to know their thoughts about the potential of this new approach in higher education, obtaining positive feedback.
C1 [Diaz Redondo, Rebeca P.; Caeiro Rodriguez, Manuel; Lopez Escobar, Juan Jose; Fernandez Vilas, Ana] Univ Vigo, AtlantTIC Res Ctr, Sch Telecommun Engn, Vigo, Spain.
C3 Universidade de Vigo; atlanTTic
RP Redondo, RPD (corresponding author), Univ Vigo, AtlantTIC Res Ctr, Sch Telecommun Engn, Vigo, Spain.
EM rebeca@det.uvigo.es; mcaeiro@det.uvigo.es; juanjo@det.uvigo.es;
   avilas@det.uvigo.es
RI López Escobar, Juan José/AAC-5441-2022; Vilas, Ana
   Fernández/L-2055-2014; Díaz Redondo, Rebeca P./L-3108-2014; Caeiro
   Rodriguez, Manuel/D-2329-2018
OI López Escobar, Juan José/0000-0001-7727-0832; Vilas, Ana
   Fernández/0000-0003-1047-2143; Díaz Redondo, Rebeca
   P./0000-0002-2367-2219; Caeiro Rodriguez, Manuel/0000-0002-2784-6060
FU European Regional Development Fund (ERDF); Galician Regional Government;
   Spanish Ministry of Economy and Competitiveness under the National
   Science Program [TEC2017-84197-C4-2-R]; Education, Audiovisual and
   Culture Executive Agency under the Capacity Building Programme; project
   ELEMEND [585681-EPP-1-2017-1-EL-EPPKA2-CBHE-JP]
FX This work is funded by: the European Regional Development Fund (ERDF)
   and the Galician Regional Government under the agreement for funding the
   Atlantic Research Center for Information and Communication Technologies
   (AtlantTIC), the Spanish Ministry of Economy and Competitiveness under
   the National Science Program (TEC2017-84197-C4-2-R) and the Education,
   Audiovisual and Culture Executive Agency under the Capacity Building
   Programme with the project ELEMEND
   (585681-EPP-1-2017-1-EL-EPPKA2-CBHE-JP).
CR Aleven V., 2017, P 5 ANN GEN INT FRAM, P11
   Aleven V, 2018, PROCEEDINGS OF THE FIFTH ANNUAL ACM CONFERENCE ON LEARNING AT SCALE (L@S'18), DOI 10.1145/3231644.3231671
   Anil Job M, 2012, INT J SCI TECHNOLOGY, V1, P92, DOI [10.15373/22778179/JUL2012/30, DOI 10.15373/22778179/JUL2012/30]
   [Anonymous], 2009, Instructional Design Theories and Models: Building a Common Knowledge Base, DOI [10.4324/9780203872130, DOI 10.4324/9780203872130]
   [Anonymous], 2004, Hum. Resour. Dev. Int, DOI DOI 10.1080/13678860410001676574
   [Anonymous], 2002, 1484121 IEEE
   Arroyo S, 2005, MICROMEDIA E LEARNIN, P260
   ATD, 2018, LONG DEV ON HOUR TRA
   Bakharia A, 2017, ARXIV170404846
   Beaudin JS, 2007, LECT NOTES COMPUT SC, V4794, P55
   Beydoun G, 2009, EXPERT SYST APPL, V36, P10952, DOI 10.1016/j.eswa.2009.02.023
   Bruck PA, 2008, 4 INT MICR 2008 C
   Bruck PA, 2005, MICROLEARNING EMERGI
   Bruck Peter A., 2012, Bled eConference, V25, P527
   Buchem I, 2010, ELearning Papers, V2010, p1e15
   Cobo JL, 2006, ADV ELECT BUSINESS, V2, P141
   Davenport G, 2004, BT TECHNOL J, V22, P160, DOI 10.1023/B:BTTJ.0000047595.31067.f1
   Eriksson T, 2017, J COMPUT HIGH EDUC, V29, P133, DOI 10.1007/s12528-016-9127-8
   Gabrielli S, 2005, MICROLEARNING EMERGI
   Gassler G, 2004, INTERACTIVE COMPUTER
   Guo P.J., 2014, P 1 ACM C LEARN SCAL, P41, DOI DOI 10.1145/2556325.2566239
   Hayles Katherine N., 2007, Profession, P187
   Hug T., 2006, MICROLEARNING EMERGI, V5, P74, DOI DOI 10.1007/978-1-4419-1428-6_1583
   IMS Global Learning Consortium, 2014, OV LTI VERS BAS FUNC
   IMS Global Learning Consortium, 2012, LEARN TOOLS INT V1 1
   IMS Global Learning Consortium, 2010, REC MAK LTI 1 TOOL
   IMS Global Learning Consortium, 2013, IMS GLOB LEARN INF S
   IMS Global Learning Consortium, 2018, LTI AD ROADM
   Jomah O, 2016, BRAIN-BROAD RES ARTI, V7, P103
   Jurado F, 2016, INT J ENG EDUC, V32, P1007
   Knowles MS., 1975, SELF DIRECTED LEARNI
   Kovachev D, 2011, INT C WEB BAS LEARN
   Lave J., 1991, Situated Learning: Legitimate Peripheral Partic- ipation
   Leene A, 2006, P MICR C 2006
   Linder M, 2006, RES P 13 ASS LEARN T
   O'Malley C, 2005, IGUIDELINES LEARNING
   Pérez-Berenguer D, 2018, SOFTWARE PRACT EXPER, V48, P1238, DOI 10.1002/spe.2572
   Severance C., 2010, Technology, Instruction, Cognition and Learning, V7, P245
   Souza M., 2014, Creative Education, V5, P672, DOI [10.4236/ce.2014.59079, DOI 10.4236/CE.2014.59079]
   Stevic MP, 2015, PROGRAM-ELECTRON LIB, V49, P91, DOI 10.1108/PROG-11-2013-0063
   Stracke CM, 2017, IEEE INT CONF ADV LE, P13, DOI 10.1109/ICALT.2017.109
   Sun G, 2017, INT J WEB SERV RES, V14, P50, DOI 10.4018/IJWSR.2017100103
   Sun G, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC), P196, DOI 10.1109/SCC.2017.32
   Sun G, 2015, IEEE INT CONF MO, P120, DOI [10.1109/MobServ.2015.26, 10.1109/MS.2015.26]
   Sun G, 2014, IEEE T LEARN TECHNOL, V7, P207, DOI 10.1109/TLT.2014.2340402
   Then M, 2017, 1 WORKSH GAM GAM LEA
   Then M, 2018, GSTF J COMPUTING JOC, V4
   Then M, 2018, IEEE GLOB ENG EDUC C, P1787, DOI 10.1109/EDUCON.2018.8363451
   Tuparov G, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P772, DOI 10.23919/MIPRO.2018.8400143
   Veeramachaneni K, 2013, ART INT ED WORKSH
   Vossensteyn H, 2015, TECHNICAL REPORT
   W3C Consortium, 2005, WEB SERVICE MODELING
   Webster M, 2012, BRINGING INFORM WORK
   Wenger E., 1998, Systems Thinker, V9, P2
   Williams JR, 1998, P HUM FACT ERG SOC A, DOI DOI 10.1145/2556325.2566239
   Xueting Li, 2011, IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011), P80, DOI 10.1049/cp.2011.0851
   Yamamoto S, 2010, APPL PHYS EXPRESS, V3, DOI 10.1143/APEX.3.122102
   Zhang X, 2011, DESIGN APPL MICROLEA, DOI [10.1109/AIMSEC.2011.6011235, DOI 10.1109/AIMSEC.2011.6011235]
NR 58
TC 36
Z9 43
U1 11
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3121
EP 3151
DI 10.1007/s11042-020-09523-z
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200013
OA hybrid
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Thounaojam, DM
AF Chakraborty, Saptarshi
   Thounaojam, Dalton Meitei
TI SBD-Duo: a dual stage shot boundary detection technique robust to motion
   and illumination effect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient; Luminance; Abrupt; Gradual; CIEDE2000 colour-difference;
   Adaptive threshold; Illumination; Motion
AB In this paper, we propose a novel shot boundary detection technique using gradient and colour information. The gradient similarity and luminance distortion are calculated to measure the contrast and structural changes of each frame including luminance changes. In the proposed system, the effects of the changes in luminance and contrast-structure are integrated via an adaptive method to extract the possible transitions using an adaptive threshold across the videos. In the verification part, CIEDE2000 colour-difference values of the possible transition frames are compared for declaration of abrupt and gradual transitions. Our system takes effectively less computational time to detect abrupt and gradual transition for a video as compared with contemporary solutions. Our proposed system also gives dominate the performance as compared with latest techniques in terms of F1 score using TRECVid 2001 and 2007 selected dataset. We have performed a series of rigorous experimentation to validate our claims.
C1 [Chakraborty, Saptarshi; Thounaojam, Dalton Meitei] Natl Inst Technol Silchar, CSE Dept, Comp Vis Lab, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Chakraborty, S (corresponding author), Natl Inst Technol Silchar, CSE Dept, Comp Vis Lab, Silchar, India.
EM chakraborty0007@gmail.com
RI thounaojam, Dalton/AAN-8432-2020; Thounaojam, Dalton/AAO-8511-2021
OI Thounaojam, Dalton/0000-0002-2655-3821; Chakraborty,
   Saptarshi/0000-0002-8213-1615
CR Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   [Anonymous], 2006, INT WORKSH MULT INF
   [Anonymous], 2016, COMPUT INTELL NEUROS
   [Anonymous], 2014, SURVEY VIDEO SEGMENT
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Baber J, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413550070
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Chakraborty S, 2019, APPL INTELL, V49, P3207, DOI 10.1007/s10489-019-01444-1
   Chu J, 2020, IEEE ACCESS, V8, P856, DOI 10.1109/ACCESS.2019.2961778
   Fu QF, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P219, DOI 10.1109/CIS.2013.53
   Gao XB, 2005, LECT NOTES COMPUT SC, V3656, P231
   Heng WJ, 2001, J VIS COMMUN IMAGE R, V12, P217, DOI 10.1006/jvci.2001.0457
   Heng WJ, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P439, DOI 10.1109/ISCAS.1999.780036
   Jadon RS, 2001, PATTERN RECOGN LETT, V22, P1359, DOI 10.1016/S0167-8655(01)00041-1
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Ko KC, 2007, LECT NOTES COMPUT SC, V4705, P1003
   Lee MS, 2001, PATTERN RECOGN, V34, P711, DOI 10.1016/S0031-3203(00)00007-8
   Lienhart RW, 1998, STORAGE RETRIEVAL IM, V3656
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mas J., 2003, Video shot boundary detection based on color histogram
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Ruxandra Tapu TZ, 2012, INT J MULTIMED DATA, V2, P38
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Singh AV, 2019, TOXICOL MECH METHOD, V29, P378, DOI 10.1080/15376516.2019.1566425
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Thounaojam D, 2019, INT ARAB J INF TECHN, V16, P686
   Thounaojam DM, 2017, INT J MULTIMED INF R, V6, P167, DOI 10.1007/s13735-017-0123-1
   Tian XW, 2018, PROCESS BIOCHEM, V68, P1, DOI 10.1016/j.procbio.2017.11.017
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Warhade KK, 2013, SIGNAL IMAGE VIDEO P, V7, P581, DOI 10.1007/s11760-011-0262-4
   Xuemei Sun, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P144, DOI 10.1109/IHMSC.2011.41
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao Huan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1124, DOI 10.1109/CSSE.2008.939
NR 35
TC 11
Z9 11
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3071
EP 3087
DI 10.1007/s11042-020-09683-y
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100006
DA 2024-07-18
ER

PT J
AU Zhao, MH
   Zhang, Z
   Zhang, X
   Zhang, LL
   Li, B
AF Zhao, Minghua
   Zhang, Zhe
   Zhang, Xin
   Zhang, Lili
   Li, Bing
TI Eyeglasses removal based on attributes detection and improved TV
   restoration model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eyeglasses attribute; Reflective area detection; Total variation model;
   Eyeglasses removal; Image analysis
AB Eyeglasses are common occlusions on face images. The detection of eyeglasses attributes and eyeglasses removal are key factors for correct automatic face recognition. A method for eyeglasses removal based on attributes detection and improved Total Variation (TV) restoration model is proposed in this paper. First, existence of eyeglasses frames is determined based on the width-length ratio after location of the eyeglasses; second, color coefficient and skin likelihood ratio are defined and color information is determined; third, bright index is defined and the reflective areas are detected based on luminance information. Finally, for rimmed, colorless and non-reflective eyeglasses, influence function based on gray difference ratio is defined to improve TV restoration model for eyeglasses removal. Experimental results show that our proposed method can not only discriminate the existence of the frame, but also detect color information and reflective areas accurately. In addition, the eyeglasses removal effect is superior to the traditional methods.
C1 [Zhao, Minghua; Zhang, Zhe; Zhang, Xin; Zhang, Lili; Li, Bing] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
   [Zhao, Minghua] Shaanxi Key Lab Network Comp & Secur Technol, Xian, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, MH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.; Zhao, MH (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, Xian, Shaanxi, Peoples R China.
EM mh_zhao@126.com
FU National Key Technology R&D Program of China [2017YFB1402103-3];
   National Natural Science Foundation of China [61602373]; Natural Science
   Foundation of Shaanxi province, China [2019JM-381]; Key Laboratory
   Foundation of Shaanxi Education Department [20JS086]
FX This research was funded by National Key Technology R&D Program of
   China, grant number 2017YFB1402103-3, National Natural Science
   Foundation of China, grant number 61602373, Natural Science Foundation
   of Shaanxi province, China, grant number 2019JM-381, and Key Laboratory
   Foundation of Shaanxi Education Department(grant number 20JS086).
CR Bai Cuixia, 2013, Journal of Electronics (China), V30, P91, DOI 10.1007/s11767-013-2130-6
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   [陈文青 Chen Wenqing], 2016, [计算机工程与应用, Computer Engineering and Application], V52, P178
   Criminisi A., 2003, PROC CVPR IEEE, V2, pII, DOI DOI 10.1109/CVPR.2003.1211538
   Da-sheng Wu, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P74, DOI 10.1109/AICI.2010.138
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du C, 2005, PATTERN RECOGN LETT, V26, P2215, DOI 10.1016/j.patrec.2005.03.031
   Fan HC, 2014, INT J GEOGR INF SCI, V28, P700, DOI 10.1080/13658816.2013.867495
   Jia Y, 2012, IMAGE PROCESSING PRO
   Jiang X, 2000, PATTERN ANAL APPL, V3, P9, DOI 10.1007/s100440050002
   Kang J, 2017, J SHAANXI U SCI TECH, V35, P174
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Lei T, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P359, DOI 10.1109/ChinaSIP.2014.6889264
   Li KS, 2016, SOFT COMPUT, V20, P885, DOI 10.1007/s00500-014-1547-7
   Li ZM, 2014, IND INSTRUMENTATION, V3, P51
   [刘仲民 Liu Zhongmin], 2014, [光学技术, Optical Technology], V40, P429
   Mei YP, 2012, RES GLASSES DETECTIO
   Moreno-Cadenas JA, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE)
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Ren MG, 2014, SOFTWARE GUIDE, V13, P141
   Shen H, 2018, J IMAGE GRAPHICS, V1, P1764
   SMirkamali S, 2015, IMAGE VIDEO PROCESSI, V1, P1785, DOI [10.1007/s11760-014-0673-0, DOI 10.1007/S11760-014-0673-0]
   Srivastava N, 2015, INT CONF CONTEMP, P365, DOI 10.1109/IC3.2015.7346708
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wu CY, 2004, IEEE T PATTERN ANAL, V26, P322, DOI 10.1109/TPAMI.2004.1262319
   Yang F, 2014, APPL MATH SER B, V29, P468, DOI 10.1007/s11766-014-3240-0
   [印勇 Yin Yong], 2013, [重庆大学学报, Journal of Chongqing University], V36, P80
   Zhang XL, 2015, INT CONF SOFTW ENG, P587, DOI 10.1109/ICSESS.2015.7339126
   Zhao MH, 2018, MULTIMED TOOLS APPL, V77, P14931, DOI 10.1007/s11042-017-5080-4
   Zhao Y, 2008, COMPUTER SIMULATION, P2
   Zhong J, 2000, LECT NOTES COMPUT SC, V1948, P127
   Zhou X, 2018, COMPUTER APPL SOFTWA, V35, P183
NR 34
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2691
EP 2712
DI 10.1007/s11042-020-09715-7
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570041100002
DA 2024-07-18
ER

PT J
AU Chaa, M
   Akhtar, Z
AF Chaa, Mourad
   Akhtar, Zahid
TI 3D Palmprint recognition using Tan and Triggs normalization technique
   and GIST descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D palmprint; Tan and Triggs normalization technique; GIST descriptor;
   Biometric system; PCA plus LDA
ID 2D; EIGENFACES; PCA
AB The 3D palmprint biometric recognition system is being considered as a very promising way to address the limitations of 2D palmprint recognition systems. This paper introduces a novel method for the 3D palmprint recognition based on the Tan and Triggs normalization technique (TT) for the preprocessing data and GIST descriptor for feature extraction. The TT technique can effectively and efficiently eliminate not only the low frequencies containing the undesirable effects of shadows but also high frequencies containing aliasing and noise in 3D palmprint. The holistic feature extraction method has been employed to attain salient characteristics. Finally, for the features matching the cosine Mahalanobis distance has been used for 3D palmprint recognition. The proposed system has been evaluated on publicly available 3D palmprint database of 8000 samples. Experimental analyses show that the proposed method can functionally eradicate the effect of uneven illumination and greatly improve the performance of the recognition system. Moreover, experimental results demonstrate that our method is capable of competing with many existing state-of-the-art 3D palmprint recognition techniques as well as outperforming many others.
C1 [Chaa, Mourad] Univ Ouargla, ELEC Lab, Fac New Informat & Commun Technol, Ouargla 30000, Algeria.
   [Akhtar, Zahid] SUNY Polytech Inst, Dept Network & Comp Secur, Utica, NY 13502 USA.
C3 Universite Kasdi Merbah Ouargla; SUNY Polytechnic Institute
RP Chaa, M (corresponding author), Univ Ouargla, ELEC Lab, Fac New Informat & Commun Technol, Ouargla 30000, Algeria.
EM chaa.mourad@univ-ouargla.dz; akhtarz@sunypoly.edu
RI MOURAD, CHAA/ABG-4044-2020
OI Akhtar, Zahid/0000-0002-5026-5416
CR Akhtar Z, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/4721849
   Akhtar Z, 2011, INT PROC COMPUT SCI, V4, P52
   [Anonymous], 2017, POLYU 2D 3D PALMPRIN
   Bardwell WE, 2005, U.S. patent, Patent No. [6,959,874. 1, 69598741]
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaa M, 2019, IET IMAGE PROCESS, V13, P736, DOI 10.1049/iet-ipr.2018.5642
   Chaa M, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013018
   Cui JR, 2014, NEURAL COMPUT APPL, V24, P497, DOI 10.1007/s00521-012-1265-y
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jaafar H, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/360217
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Li W, 2011, IEEE T SYST MAN CY C, V41, P274, DOI 10.1109/TSMCC.2010.2055849
   Li W, 2010, PROC CVPR IEEE, P795, DOI 10.1109/CVPR.2010.5540134
   Li XB, 2008, CAN J EDUC ADM POLIC, P1
   Liu M, 2012, INT CONF SIGN PROCES, P1597, DOI 10.1109/ICoSP.2012.6491885
   Meraoumia A, 2013, INTEGR COMPUT-AID E, V20, P303, DOI 10.3233/ICA-130431
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Samai D, 2018, 2018 3 INT C PATT AN, P1, DOI DOI 10.1109/PAIS.2018.8598522
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang B, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043040
   Zhang D, 2010, PATTERN RECOGN, V43, P358, DOI 10.1016/j.patcog.2009.04.026
   Zhang D, 2009, IEEE T SYST MAN CY C, V39, P505, DOI 10.1109/TSMCC.2009.2020790
   Zhang L, 2015, IEEE T PATTERN ANAL, V37, P1730, DOI 10.1109/TPAMI.2014.2372764
   Zhang SW, 2013, INT CONF ROBOT VISIO, P115, DOI 10.1109/RVSP.2013.33
NR 31
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2263
EP 2277
DI 10.1007/s11042-020-09689-6
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600002
DA 2024-07-18
ER

PT J
AU Al-qazzaz, S
   Sun, XF
   Yang, H
   Yang, YX
   Xu, RH
   Nokes, L
   Yang, X
AF Al-qazzaz, Salma
   Sun, Xianfang
   Yang, Hong
   Yang, Yingxia
   Xu, Ronghua
   Nokes, Len
   Yang, Xin
TI Image classification-based brain tumour tissue segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumour segmentation; Multi-modal MRI; Convolutional neural
   networks; Decision tree
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Brain tumour tissue segmentation is essential for clinical decision making. While manual segmentation is time consuming, tedious, and subjective, it is very challenging to develop automatic segmentation methods. Deep learning with convolutional neural network (CNN) architecture has consistently outperformed previous methods on such challenging tasks. However, the local dependencies of pixel classes cannot be fully reflected in the CNN models. In contrast, hand-crafted features such as histogram-based texture features provide robust feature descriptors of local pixel dependencies. In this paper, a classification-based method for automatic brain tumour tissue segmentation is proposed using combined CNN-based and hand-crafted features. The CIFAR network is modified to extract CNN-based features, and histogram-based texture features are fused to compensate the limitation in the CIFAR network. These features together with the pixel intensities of the original MRI images are sent to a decision tree for classifying the MRI image voxels into different types of tumour tissues. The method is evaluated on the BraTS 2017 dataset. Experiments show that the proposed method produces promising segmentation results.
C1 [Al-qazzaz, Salma; Nokes, Len; Yang, Xin] Cardiff Univ, Sch Engn, Cardiff CF24 3AA, Wales.
   [Al-qazzaz, Salma] Baghdad Univ, Dept Phys, Coll Sci Women, Baghdad, Iraq.
   [Sun, Xianfang] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
   [Yang, Hong] Second Peoples Hosp Guangxi Zhuang Autonomous Reg, Dept Radiol, Guilin 541002, Peoples R China.
   [Yang, Yingxia] Peoples Hosp Guangxi Zhuang Autonomous Reg, Dept Radiol, Nanning 530021, Peoples R China.
   [Xu, Ronghua] Peoples Hosp Guangxi Zhuang Autonomous Reg, Ctr Informat & Network Management, Nanning 530021, Peoples R China.
C3 Cardiff University; University of Baghdad; Cardiff University
RP Yang, X (corresponding author), Cardiff Univ, Sch Engn, Cardiff CF24 3AA, Wales.
EM Al-QazzazSA@cardiff.ac.uk; sunx2@cardiff.ac.uk; 11186956@qq.com;
   gx_yyx@163.com; tearmanjason@hotmail.com; Nokes@cardiff.ac.uk;
   YangX26@cardiff.ac.uk
RI Sun, Xianfang/ABG-8970-2021; Xu, Ronghua/AAE-8353-2021
CR Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Holli Kirsi K, 2010, BMC Med Imaging, V10, P8, DOI 10.1186/1471-2342-10-8
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2014, CIFAR NETWORK CUDA C
   Lai Y, 2011, NORTHEAST BIOENGIN C
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Niyazi M, 2016, RADIOTHER ONCOL, V118, P35, DOI 10.1016/j.radonc.2015.12.003
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patel MR, 2004, SEMIN ROENTGENOL, V39, P347, DOI 10.1016/j.ro.2004.05.005
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Phophalia A, 2018, LECT NOTES COMPUT SC, V10670, P159, DOI 10.1007/978-3-319-75238-9_14
   Pinto A, 2015, IEEE ENG MED BIO, P3037, DOI 10.1109/EMBC.2015.7319032
   Razzak MI, 2019, IEEE J BIOMED HEALTH, V23, P1911, DOI 10.1109/JBHI.2018.2874033
   Rehman ZU, 2019, EXPERT SYST APPL, V118, P598, DOI 10.1016/j.eswa.2018.10.040
   Revanuru-karthikrvnr Karthik, 2017, P 6 MICCAI BRATS CHA, P239
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Castillo LS, 2017, PROC SPIE, V10572, DOI 10.1117/12.2285942
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Van Huffel S, 2017, INT MICCAI BRAINLESI, P463
   Vilaplana V, 2017, P INT MICCAI BRAIN W, P381
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
NR 38
TC 8
Z9 8
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 993
EP 1008
DI 10.1007/s11042-020-09661-4
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Khan, SS
   Ran, Q
   Khan, M
AF Khan, Sarwar Shah
   Ran, Qiong
   Khan, Muzammil
TI Image pan-sharpening using enhancement based approaches in remote
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-domain; Laplacian filter; Discrete Fourier transform;
   Pan-sharpening; Matting model; Image enhancement; Multispectral and
   panchromatic images
ID TRANSFORM; FUSION
AB This paper proposes to do image enhancement before pan-sharpening; that is, the image enhancement techniques are used as a pre-processing step. The image enhancement techniques are proposed in two domains, same-domain and cross-domain. In the same-domain methods, the image enhancement techniques (such as Laplacian, Unsharp) are simply applied to multispectral (MS) and panchromatic (PAN) images to sharpen both images in the spatial domain. While in cross-domain, a novel hybrid combination of Laplacian Filter (LF) and Discrete Fourier Transformation (DFT) image sharpening technique is introduced. After image enhancement, the powerful Matting Model (MM) pan-sharpening technique is used to fuse both the enhanced images and produce a resultant image with the high spatial and spectral resolutions. The experimental results of the proposed approach outperform the others as compared to the state-of-art techniques over three datasets. The results are evaluated, considering both Qualitative and Quantitative evaluation metrics.
C1 [Khan, Sarwar Shah; Ran, Qiong] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
   [Khan, Muzammil] Univ Swat, Dept Comp & Software Technol, Swat 19130, Pakistan.
C3 Beijing University of Chemical Technology
RP Ran, Q (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM ranqiong@mail.buct.edu.cn
RI Khan, Sarwar Shah/AAW-2827-2021
CR Abdullah SMU, 2015, IEEE T GEOSCI REMOTE, V53, P3974, DOI 10.1109/TGRS.2015.2388497
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Beaudoin N, 2002, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2002.1048189
   Benzenati T, 2019, IEEE GEOSCI REMOTE S
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   Chen Y, 2018, INT GEOSCI REMOTE SE, P5005, DOI 10.1109/IGARSS.2018.8518885
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Ehlers M, 2010, INT J IMAGE DATA FUS, V1, P25, DOI 10.1080/19479830903561985
   Gangkofner UG, 2008, PHOTOGRAMM ENG REM S, V74, P1107, DOI 10.14358/PERS.74.9.1107
   Gharbia R, 2018, FUTURE GENER COMP SY, V88, P501, DOI 10.1016/j.future.2018.06.022
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Hariharan K, 2018, MULTIMED TOOLS APPL, P1
   Ibarrola-Ulzurrun E, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020228
   Javed U, 2014, SCI WORLD J, DOI 10.1155/2014/708075
   Kahraman S, 2017, ISPRS ANN PHOTO REM, V4-4, P263, DOI 10.5194/isprs-annals-IV-4-W4-263-2017
   Kalpoma KA, 2007, IEEE T GEOSCI REMOTE, V45, P3075, DOI 10.1109/TGRS.2007.897692
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P5088, DOI 10.1109/TGRS.2013.2286827
   Khan SA, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806317
   Khan SS, 2020, INT J ADV COMPUT SC, V11, P414
   Khan SS, 2019, ICCCV 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON CONTROL AND COMPUTER VISION, P41, DOI 10.1145/3341016.3341019
   Laporterie-Dejean F., 2005, Information Fusion, V6, P193, DOI 10.1016/j.inffus.2004.06.006
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li H, 2019, MULTIMED TOOLS APPL, V78, P7563, DOI 10.1007/s11042-018-6499-y
   Liu JM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060712
   Mokrzycki WS, 2009, IMAGE PROCESSING COM, P429
   Padwick C., 2010, P ASPRS 2010 ANN C S, V2630, P1
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Siddique A, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P458, DOI 10.1109/ICIVC.2018.8492725
   Tan H., 2013, J COMPUT INFORM SYST, V9, P327
   Tierney S., 2014, IEEE 2014 INT C DIG, P1, DOI [10.1109/DICTA.2014.7008094, DOI 10.1109/DICTA.2014.7008094]
   Trentacoste M, 2012, COMPUT GRAPH FORUM, V31, P555, DOI 10.1111/j.1467-8659.2012.03056.x
   Wang XH, 2020, MINIM INVASIV THER, V29, P344, DOI 10.1080/13645706.2019.1649286
   Wu HL, 2019, IEEE ACCESS, V7, P46562, DOI 10.1109/ACCESS.2019.2908968
   Xu YM, 2018, GEODERMA, V320, P52, DOI 10.1016/j.geoderma.2018.01.017
   Yang C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113624
   Yang Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040391
   Zhang Y, 1999, INT J REMOTE SENS, V20, P2003, DOI 10.1080/014311699212317
NR 37
TC 6
Z9 6
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32791
EP 32805
DI 10.1007/s11042-020-09682-z
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900007
DA 2024-07-18
ER

PT J
AU Xiang, SC
   Fu, YZ
   Chen, H
   Ran, W
   Liu, T
AF Xiang, Suncheng
   Fu, Yuzhuo
   Chen, Hao
   Ran, Wei
   Liu, Ting
TI Multi-level feature learning with attention for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Multi-branch; Semantically aligned region;
   Self-attention
ID NETWORK
AB Person re-identification (re-ID) aims to match a specific person in a large gallery with different cameras and locations. Previous part-based methods mainly focus on part-level features with uniform partition, which increases learning ability for discriminative feature but not efficient or robust to scenarios with large variances. To address this problem, in this paper, we propose a novel feature fusion strategy based on traditional convolutional neural network. Then, a multi-branch deeper feature fusion network architecture is designed to perform discriminative learning for three semantically aligned region. Based on it, a novel self-attention mechanism is employed to softly assign corresponding weights to the semantic aligned feature during back-propagation. Comprehensive experiments have been conducted on several large-scale benchmark datasets, which demonstrates that proposed approach yields consistent and competitive re-ID accuracy compared with current single-domain re-ID methods.
C1 [Xiang, Suncheng; Fu, Yuzhuo; Chen, Hao; Ran, Wei; Liu, Ting] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Xiang, SC (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM xiangsuncheng17@sjtu.edu.cn
RI Liu, Ting/AAZ-7386-2021
OI Liu, Ting/0000-0003-3489-4578; Xiang, Suncheng/0000-0002-9141-6460
FU National Natural Science Foundation of China [61977045]; National
   Defense Pre-Research Foundation of China [513110501]
FX This work was supported by the National Natural Science Foundation of
   China under Project(Grant No.61977045), the National Defense
   Pre-Research Foundation of China(Grant No.513110501). The authors would
   like to thank the anonymous reviewers for their valuable suggestions and
   constructive criticism.
CR Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Gao M, 2016, IEEE IMAGE PROC, P4274, DOI 10.1109/ICIP.2016.7533166
   He JJ, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691320500071
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Huang H, 2019, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2019.00089
   Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Navaneet KL, 2020, IEEE T INF FOREN SEC, V15, P2375, DOI 10.1109/TIFS.2019.2957701
   Paszke A, 2019, ADV NEUR IN, V32
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P19769, DOI 10.1007/s11042-020-08723-x
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 38
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32079
EP 32093
DI 10.1007/s11042-020-09569-z
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360100004
DA 2024-07-18
ER

PT J
AU Gasch, C
   Chover, M
   Remolar, I
   Rebollo, C
AF Gasch, Cristina
   Chover, Miguel
   Remolar, Inmaculada
   Rebollo, Cristina
TI Procedural modelling of terrains with constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Terrain modelling; Procedural generation; Perlin noise; GPS routes
ID GENERATION
AB Terrain is an essential part of any outdoor environment and, consequently, many techniques have appeared that deal with the problem of its automatic generation, such as procedural modeling. One form to create terrains is using noise functions because its low computational cost and its random result. However, the randomness of these functions also makes it difficult to have any control over the result obtained. In order to solve the problem of lack of control, this paper presents a new method noise-based that allows procedural terrains creation with elevation constraints (GPS routes, points of interest and areas of interest). For this, the method establishes the restrictions as fixed values in the heightmap function and creates a system of equations to obtain all points that they depend this restrictions. In this way, the terrain obtained maintains the random noise, but including the desired restrictions. The paper also includes how we apply this method on large terrain models without losing resolution or increasing the computational cost excessively. The results show that our method makes it possible to integrate this kind of constraints with high accuracy and realism while preserving the natural appearance of the procedural generation.
C1 [Gasch, Cristina; Chover, Miguel; Remolar, Inmaculada; Rebollo, Cristina] Univ Jaume 1, Inst New Imaging Technol, Castelln 12006, Spain.
C3 Universitat Jaume I
RP Gasch, C (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castelln 12006, Spain.
EM cgasch@uji.es; chover@uji.es; remolar@uji.es; rebollo@uji.es
RI Chover Sellés, Miguel/P-9933-2018; Rebollo Santamaría,
   Cristina/T-1272-2017; Remolar Quintana, Inmaculada/T-1268-2017
OI Chover Sellés, Miguel/0000-0002-0525-7038; Rebollo Santamaría,
   Cristina/0000-0002-1328-2110; Remolar Quintana,
   Inmaculada/0000-0002-7743-2579; Gasch, Cristina/0000-0003-2013-2839
FU Spanish Ministry of Science and Technology [TIN2016-75866-C3-1-R,
   PID2019-106426RB-C32]; Universitat Jaume I research project
   [UJI-B2018-56]
FX This work was supported by the Spanish Ministry of Science and
   Technology (Project TIN2016-75866-C3-1-R) and (PID2019-106426RB-C32) and
   the Universitat Jaume I research project (UJI-B2018-56).
CR [Anonymous], 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '08
   Belhadj F, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P197
   Bernhardt A., 2011, Proceedings of the 2011 24th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2011), P64, DOI 10.1109/SIBGRAPI.2011.28
   Bradbury GA, 2014, P 11 EUR C VIS MED P, P13
   Bruneton E, 2008, COMPUT GRAPH FORUM, V27, P311, DOI 10.1111/j.1467-8659.2008.01128.x
   Cordonnier G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073667
   De Carpentier GJ, 2009, FDG 09
   Doran J, 2010, IEEE T COMP INTEL AI, V2, P111, DOI 10.1109/TCIAIG.2010.2049020
   Emilien A, 2012, VISUAL COMPUT, V28, P809, DOI 10.1007/s00371-012-0699-7
   FOURNIER A, 1982, COMMUN ACM, V25, P371, DOI 10.1145/358523.358553
   Gain J, 2015, COMPUT GRAPH FORUM, V34, P105, DOI 10.1111/cgf.12545
   Gain J., 2009, P 2009 S INT 3D GRAP, V1, P31, DOI [10.1145/1507149.1507155, DOI 10.1145/1507149.1507155]
   Gasch C, 2016, PROCEDURAL MODELING
   Génevaux JD, 2015, COMPUT GRAPH FORUM, V34, P198, DOI 10.1111/cgf.12530
   Génevaux JD, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461996
   Guérin E, 2016, COMPUT GRAPH FORUM, V35, P177, DOI 10.1111/cgf.12821
   Hnaidi H, 2010, COMPUT GRAPH FORUM, V29, P2179, DOI 10.1111/j.1467-8659.2010.01806.x
   Hou F, 2016, VISUAL COMPUT, V32, P151, DOI 10.1007/s00371-015-1061-7
   Kamal KR, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P17
   Kelley A. D., 1988, Computer Graphics, V22, P263, DOI 10.1145/378456.378519
   Kristof P, 2009, COMPUT GRAPH FORUM, V28, P219, DOI 10.1111/j.1467-8659.2009.01361.x
   Li WH, 2018, MULTIMED TOOLS APPL, V77, P6267, DOI 10.1007/s11042-017-4535-y
   Mandelbrot B.B., 1983, FRACTAL GEOMETRY NAT, DOI DOI 10.1119/1.13295
   Mei X, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P47, DOI 10.1109/PG.2007.15
   Miller G. S. P., 1986, Computer Graphics, V20, P39, DOI 10.1145/15886.15890
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Nagashima K, 1997, VISUAL COMPUT, V13, P456, DOI 10.1007/s003710050117
   Neidhold B, 2005, INTERACTIVE PHYS BAS, V1
   Pajarola R, 2007, VISUAL COMPUT, V23, P583, DOI [10.1007/s00371-007-0163-2, 10.1007/S00371-007-0163-2]
   Parberry Ian., 2014, Journal of Computer Graphics Techniques, V3, P74
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Peytavie A, 2009, COMPUT GRAPH FORUM, V28, P457, DOI 10.1111/j.1467-8659.2009.01385.x
   PRUSINKIEWICZ P, 1993, GRAPH INTER, P174
   Puig-Centelles A, 2009, P 17 INT C CENTR EUR
   Puig-Centelles A, 2014, MULTIMED TOOLS APPL, V70, P1957, DOI 10.1007/s11042-012-1214-x
   Puig-Centelles A, 2009, VISUAL COMPUT, V25, P1037, DOI 10.1007/s00371-009-0366-9
   Ramos F, 2006, LECT NOTES COMPUT SC, V4245, P460
   Rebollo C, 2004, LECT NOTES COMPUT SC, V3044, P703
   Rebollo C, 2014, INT J DIGIT EARTH, V7, P789, DOI 10.1080/17538947.2013.783126
   Ripolles O, 2012, COMPUT GEOSCI-UK, V41, P147, DOI 10.1016/j.cageo.2011.08.025
   Rusnell B, 2009, VISUAL COMPUT, V25, P573, DOI 10.1007/s00371-009-0332-6
   Schneider J., 2006, Vision, modeling, and BIBLIOGRAPHY 131 visualization 2006: proceedings, November 22-24, 2006, Aachen, Germany, IOS Press, P145
   Smelik R, 2010, P EUR 2010
   Smelik RM, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12276
   Stachniak S., 2005, Computer Graphics and Artificial Intelligence, V1, P64
   Tasse FP, 2012, COMPUT GRAPH FORUM, V31, P1959, DOI 10.1111/j.1467-8659.2012.03076.x
   Vanek J, 2011, IEEE COMPUT GRAPH, V31, P35, DOI 10.1109/MCG.2011.66
   Veilleux S, 2018, INT CONF WIREL SPAC, P30, DOI 10.1109/WiSEE.2018.8637348
   Yoon JC, 2008, GRAPH MODELS, V70, P105, DOI 10.1016/j.gmod.2008.04.001
   Zhang J, 2019, VISUAL COMPUT, V35, P223, DOI 10.1007/s00371-017-1465-7
   Zhou H, 2007, IEEE T VIS COMPUT GR, V13, P834, DOI 10.1109/TVCG.2007.1027
NR 51
TC 4
Z9 4
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31125
EP 31146
DI 10.1007/s11042-020-09476-3
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900006
DA 2024-07-18
ER

PT J
AU Wang, XP
   Ling, BWK
AF Wang, Xinpeng
   Ling, Bingo Wing-Kuen
TI Decision regions and decision boundaries of generalized<i>K</i>mean
   algorithm based on various norm criteria
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GeneralizedKmean algorithms; Decision regions; Decision boundaries;
   Nonconvex set; Mixed integer quadratic programming; Mixed integer linear
   programming
ID K-MEANS
AB This paper derives the decision regions and the decision boundaries of the generalizedKmean algorithms based on theL(1)norm criterion, theL(2)norm criterion and theL(infinity)norm criterion. The decision boundaries of these three generalizedKmean algorithms are all linear hyperplanes. However, the total numbers of the decision boundaries of the generalizedKmean algorithms based on both theL(1)norm criterion and theL(infinity)norm criterion are more than that based on theL(2)norm criterion. On the other hand, the decision regions of the generalizedKmean algorithm based on theL(2)norm criterion are convex while that based on both theL(1)norm criterion and theL(infinity)norm criterion are in general nonconvex. The computer numerical simulations on a toy example demonstrate the above phenomena. Besides, two examples are illustrated. The first example on the patent image retrieval system shows that the recognition accuracies of using the generalizedKmean algorithms based on theL(2)norm criterion, theL(1)norm criterion and theL(infinity)norm criterion are 58.25%, 61% and 58.75%, respectively. The second example on the electromyogram based Parkinson's disease detection system shows that the recognition accuracies of using the generalizedKmean algorithms based on theL(2)norm criterion, theL(1)norm criterion and theL(infinity)norm criterion are 60%, 60% and 67%, respectively, if the signals are classified directly in the time domain. On the other hand, the recognition accuracies of the generalizedKmean algorithms based on theL(2)norm criterion, theL(1)norm criterion and theL(infinity)norm criterion are 60%, 87% and 60%, respectively, if the signals are classified directly in the discrete cosine transform domain. The improvements are due to the nonconvexity of the decision regions of the generalizedKmean algorithm based on theL(1)norm criterion and theL(infinity)norm criterion.
C1 [Wang, Xinpeng; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Wang, XP (corresponding author), Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
EM yongquanling@gdut.edu.cn
FU National Nature Science Foundation of China [U1701266, 61372173,
   61671163]; Team Project of the Education Ministry of the Guangdong
   Province [2017KCXTD011]; Guangdong Higher Education Engineering
   Technology Research Center for Big Data on Manufacturing Knowledge
   Patent [501130144]; Guangdong Province Intellectual Property Key
   Laboratory Project [2018B030322016]; Hong Kong Innovation and Technology
   Commission, Enterprise Support Scheme [S/E/070/17]
FX This paper was supported partly by the National Nature Science
   Foundation of China (no. U1701266, no. 61372173 and no. 61671163), the
   Team Project of the Education Ministry of the Guangdong Province (no.
   2017KCXTD011), the Guangdong Higher Education Engineering Technology
   Research Center for Big Data on Manufacturing Knowledge Patent (no.
   501130144), the Guangdong Province Intellectual Property Key Laboratory
   Project (no. 2018B030322016) and Hong Kong Innovation and Technology
   Commission, Enterprise Support Scheme (no. S/E/070/17).
CR Aslan MF, 2020, MEASUREMENT, V158, DOI 10.1016/j.measurement.2020.107704
   Blumensath T, 2016, IEEE T NEUR NET LEAR, V27, P2095, DOI 10.1109/TNNLS.2015.2505060
   Chen LZ, 2019, NEUROCOMPUTING, V339, P210, DOI 10.1016/j.neucom.2019.02.015
   Dahlke S, 2010, J COMPLEXITY, V26, P102, DOI 10.1016/j.jco.2009.10.002
   Dai Yizhong, 2015, IEEE INT C IND INF I
   Forero PA, 2012, IEEE T SIGNAL PROCES, V60, P4163, DOI 10.1109/TSP.2012.2196696
   Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048
   Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lin LC, 2020, COMPUT STAT DATA AN, V151, DOI 10.1016/j.csda.2020.106992
   Liu BZ, 2017, SIGNAL PROCESS-IMAGE, V54, P1, DOI 10.1016/j.image.2017.02.008
   Liu YP, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107252
   Papalexakis EE, 2013, IEEE T SIGNAL PROCES, V61, P493, DOI 10.1109/TSP.2012.2225052
   Sahoo SK, 2013, IEEE SIGNAL PROC LET, V20, P587, DOI 10.1109/LSP.2013.2258912
   Tan HL, 2014, IET COMPUT VIS, V8, P224, DOI 10.1049/iet-cvi.2012.0302
   Tang KW, 2019, PATTERN RECOGN, V89, P45, DOI 10.1016/j.patcog.2018.12.025
   Tzortzis GF, 2009, IEEE T NEURAL NETWOR, V20, P1181, DOI 10.1109/TNN.2009.2019722
   Wang QQ, 2020, NEUROCOMPUTING, V391, P119, DOI 10.1016/j.neucom.2020.01.097
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Zhang XZ, 2017, CIRC SYST SIGNAL PR, V36, P2012, DOI 10.1007/s00034-016-0392-6
NR 21
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30669
EP 30684
DI 10.1007/s11042-020-09402-7
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300012
DA 2024-07-18
ER

PT J
AU Ulrich, L
   Vezzetti, E
   Moos, S
   Marcolin, F
AF Ulrich, Luca
   Vezzetti, Enrico
   Moos, Sandro
   Marcolin, Federica
TI Analysis of RGB-D camera technologies for supporting different facial
   usage scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensors; 3D cameras; 3D face analysis; Stereoscopy; ToF; Structured
   light
ID FACE RECOGNITION; DEPTH CAMERAS; 3D; PERCEPTION; EXPRESSION; NETWORK;
   MODEL
AB Recently a wide variety of applications has been developed integrating 3D functionalities. Advantages given by the possibility of relying on depth information allows the developers to design new algorithms and to improve the existing ones. In particular, for what concerns face morphology, 3D has led to the possibility to obtain face depth maps highly close to reality and consequently an improvement of the starting point for further analysis such as Face Detection, Face Authentication, Face Identification and Face Expression Recognition. The development of the aforementioned applications would have been impossible without the progress of sensor technologies for obtaining 3D information. Several solutions have been adopted over time. In this paper, emphasis is put on passive stereoscopy, structured light, time-of-flight (ToF) and active stereoscopy, namely the most used technologies for the cameras design and fulfilment according to the literature. The aim of this article is to investigate facial applications and to examine 3D camera technologies to suggest some guidelines for addressing the correct choice of a 3D sensor according to the application that has to be developed.
C1 [Ulrich, Luca; Vezzetti, Enrico; Moos, Sandro; Marcolin, Federica] Politecn Torino, DIGEP, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Vezzetti, E (corresponding author), Politecn Torino, DIGEP, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM luca.ulrich@polito.it; enrico.vezzetti@polito.it
OI MOOS, SANDRO/0000-0001-5097-7344; Ulrich, Luca/0000-0001-8407-0660;
   Marcolin, Federica/0000-0002-4360-6905; VEZZETTI,
   Enrico/0000-0001-8910-7020
FU Politecnico di Torino within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Torino within the
   CRUI-CARE Agreement.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Akao Yoji., 1994, CUSTOMER DRIVEN APPR, P339
   Albakri G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081928
   Albino V, 2015, J URBAN TECHNOL, V22, P3, DOI 10.1080/10630732.2014.942092
   Alexandre GR, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107108
   Aljohani M, 2017, ADV INTELL SYST, V509, P245, DOI 10.1007/978-981-10-2525-9_24
   Andersen PE, 2012, ACTA RADIOL OPEN, V1, DOI 10.1258/arsr.2012.120001
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2015, IEEE INT C AC SPEECH
   [Anonymous], 2018, MACH VIS APPL
   Ashbourn J., 2014, Biometrics: Advanced Identity Verification: The Complete Guide
   BETTADAPURA V, 2012, COMPUTER SCI
   Bock RD, 2018, PROC SPIE, V10643, DOI 10.1117/12.2305455
   Boffano M, 2018, ORTHOPAEDIC P S5, V100, P93
   Bouguet J., 2000, P ACM SIGGRAPH WORKS
   Bruce V., 1998, In the eye of the beholder: the science of face perception
   Calvo MG, 2016, COGNITION EMOTION, V30, P1081, DOI 10.1080/02699931.2015.1049124
   Cament LA, 2015, PATTERN RECOGN, V48, P3371, DOI 10.1016/j.patcog.2015.05.017
   Cao J, 2019, IEEE T INF FOREN SEC, V14, P2028, DOI 10.1109/TIFS.2019.2891116
   Carfagni M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030489
   Chae MP, 2015, FRONT SURG, V2, DOI 10.3389/fsurg.2015.00025
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen Y., 2019, 2019 IEEE INT C AC S
   Chowdhury M., 2016, 2016 IEEE 11 C IND E
   Chuang PT, 2001, INT J ADV MANUF TECH, V18, P842, DOI 10.1007/s001700170010
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   DAMASIO AR, 1982, NEUROLOGY, V32, P331, DOI 10.1212/WNL.32.4.331
   Dawood A, 2015, BRIT DENT J, V219, P521, DOI 10.1038/sj.bdj.2015.914
   Deng JK, 2019, INT J COMPUT VISION, V127, P599, DOI 10.1007/s11263-018-1134-y
   Driver T. P., 2009, U.S. Patent, Patent No. [11/945, 11945]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 2003, UNMASKING FACE GUIDE
   Elrefaei L. A., 2017, 2017 2 INT C ANT CRI
   FANTZ RL, 1961, SCI AM, V204, P66, DOI 10.1038/scientificamerican0561-66
   Forte M, 2014, J EAST MEDITERR ARCH, V2, P1
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Geng ZL, 2019, PROC CVPR IEEE, P9813, DOI 10.1109/CVPR.2019.01005
   Giancola S, 2018, SPRINGERBRIEF COMPUT, P71, DOI 10.1007/978-3-319-91761-0_6
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Horaud R, 2016, MACH VISION APPL, V27, P1005, DOI 10.1007/s00138-016-0784-4
   Hossain MS, 2015, MOBILE NETW APPL, V20, P391, DOI 10.1007/s11036-015-0586-3
   Ingxin B, 2019, P 2019 INT C INF TEC
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Kahraman C, 2006, EUR J OPER RES, V171, P390, DOI 10.1016/j.ejor.2004.09.016
   Kedzierski M, 2014, SENSORS-BASEL, V14, P12070, DOI 10.3390/s140712070
   Kirsten E., 2018, GARSS 2018
   Lamba S., 2016, 2016 12 INT C SIGN I
   Lee JS, 2014, LECT NOTES COMPUT SC, V8582, P652, DOI 10.1007/978-3-319-09147-1_47
   Maes C., 2010, BIOMETRICS THEORY AP, DOI [DOI 10.1109/BTAS.2010.5634543, 10.1109/BTAS.2010.5634543]
   McDuff D., 2016, P CHI C HUM FACT COM, P3723
   MEADOWS JC, 1974, J NEUROL NEUROSUR PS, V37, P489, DOI 10.1136/jnnp.37.5.489
   Mohammed M. I., 2016, P 27 ANN INT SOL FRE, P1695
   Mondal S, 2019, PROCEEDINGS OF THE ASME TURBO EXPO: TURBOMACHINERY TECHNICAL CONFERENCE AND EXPOSITION, 2019, VOL 2D
   MORTON J, 1991, PSYCHOL REV, V98, P164, DOI 10.1037/0033-295X.98.2.164
   Neethu A., 2016, 2016 INT C INF SCI I
   Nonis F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020609
   Olivetti EC, INT C DES INN EXCH S
   Olivetti EC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010314
   Patil J. V., 2016, 2016 INT C INV COMP
   Pribanic T, 2016, INT C IM AN REC
   Raghavendra R., 2013, 2013 IEEE INT C TECH
   Rattani, 2019, SELFIE BIOMETRICS AD
   Riaz S, 2019, MACH VISION APPL, V30, P91, DOI 10.1007/s00138-018-0975-2
   Robertson DA, 2017, PROC SPIE, V10189, DOI 10.1117/12.2262264
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Roy S, 2013, Int J Adv Res Comput Sci Soft Eng, V1, P1, DOI [10.48550/arXiv.1312.6150, DOI 10.48550/ARXIV.1312.6150]
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Sepas-Moghaddam A, 2019, ARXIV190100713 CORR
   Siebert S, 2014, AUTOMAT CONSTR, V41, P1, DOI 10.1016/j.autcon.2014.01.004
   Small DA, 2009, J MARKETING RES, V46, P777, DOI 10.1509/jmkr.46.6.777
   Streeter L, 2019, IEEE INSTRU MEAS MAG, V22, P21, DOI [10.1109/MIM.2019.8674630, 10.1109/mim.2019.8674630]
   Taylor RH, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1657
   Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350
   Valverde I, 2015, CARDIOL YOUNG, V25, P698, DOI 10.1017/S1047951114000742
   Verschuren P., 2010, Designing a Research Project
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Vezzetti E, 2014, MULTIMED TOOLS APPL, V68, P895, DOI 10.1007/s11042-012-1091-3
   Vezzetti E, 2012, COMPUT METH PROG BIO, V108, P1078, DOI 10.1016/j.cmpb.2012.07.008
   Wang ZZ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105798
   Wu H., 2020, C COMPL INT SOFTW IN
   Yarboro SR, 2017, UNFALLCHIRURG, V120, pS5, DOI 10.1007/s00113-016-0226-9
   Young AW, 2008, J NEUROPSYCHOL, V2, P1, DOI 10.1348/174866407X269848
   Zhang C., 2010, A survey of recent advances in face detection
   Zhou S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0157-2
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 88
TC 27
Z9 27
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29375
EP 29398
DI 10.1007/s11042-020-09479-0
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400009
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wang, CP
   Zhang, JS
   Song, XL
   Wu, TJ
AF Wang, Changpeng
   Zhang, Jiangshe
   Song, Xueli
   Wu, Tianjun
TI Face clustering via learning a sparsity preserving low-rank graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-rank representation; Graph learning; Face clustering
ID FACIAL EXPRESSION RECOGNITION; SYSTEMS; SEGMENTATION; ALGORITHM;
   EQUATIONS
AB Face clustering aims to group the face images without any label information into clusters, and has recently attracted considerable attention in machine learning and data mining. Many graph based clustering methods have been proposed and among which sparse representation (SR) and low-rank representation (LRR) are two representative methods for affinity graph construction. The clustering result may be inaccurate if the affinity graph is constructed with low quality. In this paper, we propose a novel face clustering method via learning a sparsity preserving low-rank graph (LSPLRG), where the initial affinity graph is derived on the sparse coefficients without any a priori graph or similarity matrix. In addition, an adaptive weighted matrix is imposed on the data reconstruction errors to enhance the role of important features, while a constraint on the representation matrix is to reduce the redundant features. By integrating the local distance regularization term into LRR, LSPLRG could exploit the global and local structures of data simultaneously. These appealing properties allow LSPLRG to well capture the intrinsic structure of data, and thus has potential to improve clustering performance. Experiments conducted on several face image databases demonstrate the effectiveness and robustness of LSPLRG compared with several state-of-the-art subspace clustering methods.
C1 [Wang, Changpeng; Song, Xueli; Wu, Tianjun] Changan Univ, Sch Sci, Xian 710064, Peoples R China.
   [Zhang, Jiangshe] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
C3 Chang'an University; Xi'an Jiaotong University
RP Song, XL (corresponding author), Changan Univ, Sch Sci, Xian 710064, Peoples R China.
EM xlsung@sina.com
FU National Natural Science Foundation of China [61572393, 71701021,
   41601437]; Basic Science Research of Shaanxi province [2018JQ1038];
   Fundamental Research Funds for the Central Universities in Chang'an
   University [300102120201]; Special Fund for Basic Scientific Research of
   Central Colleges in Chang'an University [310812163504]
FX This work was supported by the National Natural Science Foundation of
   China under Grant no. 61572393, 71701021 and 41601437, the Basic Science
   Research of Shaanxi province under Grant no. 2018JQ1038, the Fundamental
   Research Funds for the Central Universities in Chang'an University under
   Grant no. 300102120201, and the Special Fund for Basic Scientific
   Research of Central Colleges in Chang'an University under Grant no.
   310812163504.
CR Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Dornaika F, 2017, NEURAL NETWORKS, V95, P91, DOI 10.1016/j.neunet.2017.08.002
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fang XZ, 2016, IEEE T CYBERNETICS, V46, P1828, DOI 10.1109/TCYB.2015.2454521
   Glowinski R, 1989, MATH COMPUT, V58
   Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P1819, DOI 10.3233/IFS-141468
   Khan SA, 2014, J INTELL FUZZY SYST, V27, P3131, DOI 10.3233/IFS-141270
   Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2016, IEEE T SIGNAL PROCES, V64, P5623, DOI 10.1109/TSP.2016.2586753
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Wen J, 2018, PATTERN RECOGN, V81, P326, DOI 10.1016/j.patcog.2018.04.004
   Wen JT, 2018, ADV IND CONTROL, P1, DOI 10.1007/978-3-319-68462-8_1
   Xu Linli, 2005, ADV NEURAL INFORM PR, V17
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang JF, 2013, MATH COMPUT, V82, P301
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang XJ, 2016, NEUROCOMPUTING, V182, P36, DOI 10.1016/j.neucom.2015.12.009
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zheng JW, 2017, IEEE T IMAGE PROCESS, V26, P2408, DOI 10.1109/TIP.2017.2681841
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou T, 2020, IEEE T INTELL TRANSP, V21, P1229, DOI 10.1109/TITS.2019.2905036
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P1655, DOI 10.1109/TCYB.2018.2883673
NR 49
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29179
EP 29198
DI 10.1007/s11042-020-09392-6
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557749700001
DA 2024-07-18
ER

PT J
AU Fazlali, H
   Shirani, S
   McDonald, M
   Kirubarajan, T
AF Fazlali, Hamidreza
   Shirani, Shahram
   McDonald, Mike
   Kirubarajan, Thia
TI Cloud/haze detection in airborne videos using a convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airborne video surveillance; Cloud detection; Classification;
   Convolutional neural network; Spatial information; Temporal information
ID SALIENT OBJECT DETECTION; RANKING; MODIS
AB In airborne videos surveillance, moving object detection and target tracking are the key steps. However, under bad weather conditions, the presence of clouds and haze or even smoke coming from buildings can make the processing of these videos very challenging. Current cloud detection or classification methods only consider a single image. Moreover, the images they use are often captured by satellites or planes at high altitudes with very long ranges to clouds, which can help distinguish cloudy regions from non-cloudy ones. In this paper, a new approach for cloud and haze detection is proposed by exploiting both spatial and temporal information in airborne videos. In this method, several consecutive frames are divided into patches. Then, consecutive patches are collected as patch sets and fed into a deep convolutional neural network. The network is trained to learn the appearance of clouds as well as their motion characteristics. Therefore, instead of relying on single frame patches, the decision on a patch in the current frame is made based on patches from previous and subsequent consecutive frames. This approach, avoids discarding the temporal information about clouds in videos, which may contain important cues for discriminating between cloudy and non-cloudy regions. Experimental results show that using temporal information besides the spatial characteristics of haze and clouds can greatly increase detection accuracy.
C1 [Fazlali, Hamidreza; Shirani, Shahram; McDonald, Mike; Kirubarajan, Thia] McMaster Univ, ECE Dept, 1280 Main St West, Hamilton, ON, Canada.
C3 McMaster University
RP Fazlali, H (corresponding author), McMaster Univ, ECE Dept, 1280 Main St West, Hamilton, ON, Canada.
EM fazlalih@mcmaster.com
CR ABADI M, 2016, P 12 USENIX S OP SYS, V16, P256
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ackerman SA, 2008, J ATMOS OCEAN TECH, V25, P1073, DOI 10.1175/2007JTECHA1053.1
   An ZY, 2015, IEEE J-STARS, V8, P4206, DOI 10.1109/JSTARS.2015.2438015
   Cheng HY, 2012, IEEE T IMAGE PROCESS, V21, P2152, DOI 10.1109/TIP.2011.2172798
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Frey RA, 2008, J ATMOS OCEAN TECH, V25, P1057, DOI 10.1175/2008JTECHA1052.1
   Huang XM, 2018, PATTERN RECOGN, V76, P95, DOI 10.1016/j.patcog.2017.10.027
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   Le Hégarat-Mascle S, 2009, ISPRS J PHOTOGRAMM, V64, P351, DOI 10.1016/j.isprsjprs.2008.12.007
   Ling ZG, 2018, IEEE T MULTIMEDIA, V20, P1699, DOI 10.1109/TMM.2017.2778565
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186
   SAUNDERS RW, 1988, INT J REMOTE SENS, V9, P123, DOI 10.1080/01431168808954841
   Shi MY, 2016, INT GEOSCI REMOTE SE, P701, DOI 10.1109/IGARSS.2016.7729176
   Sommer L.W., 2016, 2016 IEEE WINTER C A, P1
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Teutsch Michael, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P26, DOI 10.1109/CVPRW.2015.7301396
   Teutsch M., 2016, P IEEE C COMP VIS PA, P27
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xie FY, 2017, IEEE J-STARS, V10, P3631, DOI 10.1109/JSTARS.2017.2686488
   Yuan Y, 2015, IEEE J-STARS, V8, P4197, DOI 10.1109/JSTARS.2015.2431676
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zhang Q, 2014, IEEE T GEOSCI REMOTE, V52, P7264, DOI 10.1109/TGRS.2014.2310240
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 26
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28587
EP 28601
DI 10.1007/s11042-020-09359-7
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200002
DA 2024-07-18
ER

PT J
AU Purwar, S
   Tripathi, R
   Barwad, AW
   Dinda, AK
AF Purwar, Shikha
   Tripathi, Rajiv
   Barwad, Adarsh Wamanrao
   Dinda, A. K.
TI Detection of Mesangial hypercellularity of MEST-C score in
   immunoglobulin A-nephropathy using deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Convolution neural network; MEST-C score;
   Mesangial hypercellularity; Immunoglobulin A-nephropathy
ID IGA NEPHROPATHY; CLASSIFICATION; DISEASE; RISK; TRANSPLANTATION;
   PROGRESSION; DIAGNOSIS; SYSTEM; LEVEL
AB Immunoglobulin A (IgA)-nephropathy (IgAN) is one of the major reasons for renal failure. It provides vital clues to estimate the stage and the proliferation rate of end-stage kidney disease. IgA stage can be estimated with the help of MEST-C score. The manual estimation of MEST-C score from whole slide kidney images is a very tedious and difficult task. This study uses some Convolutional neural networks (CNNs) related models to detect mesangial hypercellularity (M score) in MEST-C. CNN learns the features directly from image data without the requirement of analytical data. CNN is trained efficiently when image data size is large enough for a particular class. In the case of smaller data size, transfer learning can be used efficiently in which CNN is pre-trained on some general images and then on subject images. Since the data set size is small, time spent in collecting large data set is saved. The training time of transfer learning is also reduced because the model is already pre-trained. This research work aims at the detection of mesangial hypercellularity from biopsy images with small data size by utilizing the transfer learning. The dataset used in this research work consists of 138 individual glomerulus (x 20 magnification digital biopsy) images of IgA patients received from All India Institute of Medical Science, Delhi. Here, machine learning (k-nearest neighbour (KNN) and support vector machine (SVM)) classifiers are compared to transfer learning CNN methods. The deep extracted image features are used by machine learning classifiers. The different evaluation parameters have been used for comparing the predictions of basic classifiers to the deep learning model. The research work concludes that the transfer learning deep CNN method can improve the detection of mesangial hypercellularity as compare to KNN, SVM methods when using the small data set. This model could help the pathologists to understand the stages of kidney failure.
C1 [Purwar, Shikha; Tripathi, Rajiv] Natl Inst Technol Delhi, Elect & Commun Dept, Delhi, India.
   [Barwad, Adarsh Wamanrao; Dinda, A. K.] All India Inst Med Sci, Dept Pathol, New Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; All India Institute of Medical Sciences (AIIMS) New
   Delhi
RP Purwar, S (corresponding author), Natl Inst Technol Delhi, Elect & Commun Dept, Delhi, India.
EM shikhapurwar@nitdelhi.ac.in
RI tripathi, rajiv/F-1353-2018
OI tripathi, rajiv/0000-0002-1036-046X; purwar, shikha/0000-0001-5362-1669
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Ahn E, 2016, I S BIOMED IMAGING, P855, DOI 10.1109/ISBI.2016.7493400
   Al-Gheethi AAS, 2019, WATER SCI TECHNOL LI, V87, P1, DOI 10.1007/978-3-319-90269-2_1
   ALAMARTINE E, 1991, AM J KIDNEY DIS, V18, P12, DOI 10.1016/S0272-6386(12)80284-8
   Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107279
   Avci E, 2009, EXPERT SYST APPL, V36, P10618, DOI 10.1016/j.eswa.2009.02.053
   Barbour SJ, 2016, KIDNEY INT, V89, P167, DOI 10.1038/ki.2015.322
   Bartosik LP, 2001, AM J KIDNEY DIS, V38, P728, DOI 10.1053/ajkd.2001.27689
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berthoux F, 2011, J AM SOC NEPHROL, V22, P752, DOI 10.1681/ASN.2010040355
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Cannone R., 2011, Proceedings of the 2011 11th International Conference on Intelligent Systems Design and Applications (ISDA), P1353, DOI 10.1109/ISDA.2011.6121848
   Cattran DC, 2009, KIDNEY INT, V76, P534, DOI 10.1038/ki.2009.243
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Cruz-Ramírez M, 2013, ARTIF INTELL MED, V58, P37, DOI 10.1016/j.artmed.2013.02.004
   Di Noia T, 2013, EXPERT SYST APPL, V40, P4438, DOI 10.1016/j.eswa.2013.01.046
   El-Rahiem Basma Abd., 2019, INT C ADV MACHINE LE, P23
   Escudero J, 2013, IEEE T BIO-MED ENG, V60, P164, DOI 10.1109/TBME.2012.2212278
   Esposito M, 2011, INT J MED INFORM, V80, pE245, DOI 10.1016/j.ijmedinf.2011.09.003
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Geddes CC, 1998, NEPHROL DIAL TRANSPL, V13, P67, DOI 10.1093/ndt/13.1.67
   Goto M, 2009, NEPHROL DIAL TRANSPL, V24, P3068, DOI 10.1093/ndt/gfp273
   Gray H, 1918, ANATOMY HUMAN BODY, V8
   Phan HTH, 2016, I S BIOMED IMAGING, P1208, DOI 10.1109/ISBI.2016.7493483
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kassahun Y, 2014, ARTIF INTELL MED, V61, P79, DOI 10.1016/j.artmed.2014.03.001
   Kensert A, 2019, SLAS DISCOV, V24, P466, DOI 10.1177/2472555218818756
   Kirienko M, 2018, CONTRAST MEDIA MOL I, DOI 10.1155/2018/1382309
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu MH, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00035
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Mackinnon B, 2008, NEPHRON CLIN PRACT, V109, pC148, DOI 10.1159/000145458
   Maglogiannis I, 2009, APPL INTELL, V30, P1, DOI 10.1007/s10489-007-0077-8
   Mandal I, 2013, INT J MED INFORM, V82, P359, DOI 10.1016/j.ijmedinf.2012.10.006
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Purwar S, 2019, MULTIMED TOOLS APPL, V79, P1
   Radford MG, 1997, J AM SOC NEPHROL, V8, P199
   Rauta V, 2002, CLIN NEPHROL, V58, P85
   Roychowdhury S, 2014, IEEE J BIOMED HEALTH, V18, P1717, DOI 10.1109/JBHI.2013.2294635
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sheppard D, 1999, INT J MED INFORM, V54, P55, DOI 10.1016/S1386-5056(98)00169-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tenório JM, 2011, INT J MED INFORM, V80, P793, DOI 10.1016/j.ijmedinf.2011.08.001
   Tortora GJ, 2009, Principles of Anatomy and Physiology
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhimin Gao, 2014, 2014 1st Workshop on Pattern Recognition Techniques for Indirect Immunofluorescence Images, P24, DOI 10.1109/I3A.2014.15
NR 56
TC 4
Z9 4
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27683
EP 27703
DI 10.1007/s11042-020-09304-8
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554200006
DA 2024-07-18
ER

PT J
AU Wang, WC
   Yuan, XH
   Wu, XJ
   Dong, YH
AF Wang, Wencheng
   Yuan, Xiaohui
   Wu, Xiaojin
   Dong, Yihua
TI An airlight estimation method for image dehazing based on gray
   projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airlight estimation; Atmospheric light; Gray projection; Image
   restoration
ID CONTRAST ENHANCEMENT; ATMOSPHERIC LIGHT; PHYSICAL MODEL; SINGLE;
   REMOVAL; WEATHER; RESTORATION; VISIBILITY
AB As the key parameter of dehazing algorithms, airlight value directly affect the calculation accuracy of sky region, and any deviation will lead to the chromatic aberration in the image restoration. Many methods are proposed to address this problem, but the large amount of calculation or large deviations make them difficult to apply to real-time systems. In this paper, a fast algorithm is proposed based on the statistics of sky area's distribution in hazy images. Firstly, fast mean filter is used to process gray image; and then the anti-interference ability of regional projection is analysied. Through the horizontal projection and vertical projection, the main sky area is quickly located, and finally the sky region are calculated by selecting some special pixels as atmospheric light. A large number of experiments show that the proposed algorithm can obtain the airlight value quickly for the images with sky region, and can be used in real-time conditions.
C1 [Wang, Wencheng; Wu, Xiaojin; Dong, Yihua] Weifang Univ, Coll Informat & Control Engn, Weifang, Peoples R China.
   [Yuan, Xiaohui] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
C3 Weifang University; University of North Texas System; University of
   North Texas Denton
RP Wang, WC (corresponding author), Weifang Univ, Coll Informat & Control Engn, Weifang, Peoples R China.
EM wwcwfu@126.com
RI Wang, Wencheng/A-6146-2018
OI Wang, Wencheng/0000-0002-0888-9225; Yuan, Xiaohui/0000-0001-6897-4563
FU Science and Technology Plan for Youth Innovation of Shandong's
   Universities [2019KJN012]; Natural Science Foundation of Shandong
   Province [ZR2019FM059]; National Natural Science Foundation of China
   [61403283]
FX This work was supported by Science and Technology Plan for Youth
   Innovation of Shandong's Universities (No. 2019KJN012), Natural Science
   Foundation of Shandong Province (No. ZR2019FM059), National Natural
   Science Foundation of China (No. 61403283).
CR Alajarmeh A, 2018, MULTIMED TOOLS APPL, V77, P26315, DOI 10.1007/s11042-018-5861-4
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2011 I E COMP SOC C
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cheng FC, 2015, ENG APPL ARTIF INTEL, V43, P27, DOI 10.1016/j.engappai.2015.03.011
   Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182
   Deng H, 2010, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL SYMPOSIUM ON STRUCTURAL ENGINEERING, VOL I AND II, P1048
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Dong XM, 2010, IEEE IMAGE PROC, P3593, DOI 10.1109/ICIP.2010.5651965
   El Khoury J, 2018, MULTIMED TOOLS APPL, V77, P15409, DOI 10.1007/s11042-017-5122-y
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2013, IEEE IMAGE PROC, P714, DOI 10.1109/ICIP.2013.6738147
   Hautiere N., 2007, 2007 IEEE C COMP VIS, P1
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P3125, DOI 10.1007/s11042-017-4954-9
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Lee JS, 2019, MULTIMED TOOLS APPL, V78, P1831, DOI 10.1007/s11042-018-6280-2
   [李权合 Li Quanhe], 2014, [自动化学报, Acta Automatica Sinica], V40, P744
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Park H, 2014, IEEE IMAGE PROC, P4502, DOI 10.1109/ICIP.2014.7025913
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Seow MJ, 2006, NEUROCOMPUTING, V69, P954, DOI 10.1016/j.neucom.2005.07.003
   Shiau YH, 2013, IEEE T CIRC SYST VID, V23, P1369, DOI 10.1109/TCSVT.2013.2243650
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IET IMAGE PROCESS, V6, P966, DOI 10.1049/iet-ipr.2011.0472
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang WC, 2018, IEEE ACCESS, V6, P5641, DOI 10.1109/ACCESS.2018.2794340
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wang Z, 2014, COMPUT ELECTR ENG, V40, P785, DOI 10.1016/j.compeleceng.2013.06.009
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Yin JH, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P2241, DOI 10.1109/FSKD.2016.7603530
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Zhang WB, 2018, MULTIMED TOOLS APPL, V77, P2947, DOI 10.1007/s11042-017-4547-7
   [张小刚 Zhang Xiaogang], 2014, [自动化学报, Acta Automatica Sinica], V40, P1733
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 51
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27185
EP 27203
DI 10.1007/s11042-020-09380-w
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551736600002
DA 2024-07-18
ER

PT J
AU Zhong, Z
   Gao, WL
   Khattak, AM
   Wang, MJ
AF Zhong, Zhen
   Gao, Wanlin
   Khattak, Abdul Mateen
   Wang, Minjuan
TI A novel multi-source image fusion method for pig-body multi-feature
   detection in NSCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonsubsampled contourlet transform; Gabor filter; Improved average
   gradient; Pig-body shape segmentation; Pig-body temperature detection
ID SHEARLET TRANSFORM; EXTRACTION; ALGORITHM
AB The multi-source image fusion has been a hot topic during the recent years because of its higher detection rate. To improve the accuracy of pig-body multi-feature detection, a multi-source image fusion method was adopted in this field. However, the traditional multi-source image fusion methods could not obtain better contrast and more details of the fused image. To better detect shape and temperature feature of pig-body, a novel infrared and visible image fusion method was proposed in non-subsampled contourlet transform (NSCT) domain and named NSCT-GF-IAG. Through this technique, the visible and infrared images were first decomposed into a series of multi-scale and multi-directional sub-bands using NSCT. Then, to better represent the fine-scale of texture information and coarse-scale detail information, Gabor filter with even-symmetry and improved average gradient (IAG) were employed to fuse low-frequency and high-frequency sub-bands, respectively. Next, the fused coefficients were reconstructed into a final fusion image by inverse NSCT. Finally, the shape feature of pig-body was obtained by automatic threshold segmentation and optimized by morphological processing. Moreover, the highest temperature was extracted based on shape segmentation of pig-body. Experimental results showed that the proposed fusion method for detecting multi-feature was capable of achieving 2.175-5.129% higher average segmentation rate than the prevailing conventional methods. Besides this, the proposed method also improved efficiency in terms of time consumption.
C1 [Zhong, Zhen; Gao, Wanlin; Wang, Minjuan] Minist Agr & Rural Affairs, Key Lab Agr Informatizat Standardizat, Beijing 100083, Peoples R China.
   [Zhong, Zhen; Gao, Wanlin; Khattak, Abdul Mateen; Wang, Minjuan] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Zhong, Zhen] Tianjin Univ Technol & Educ, Coll Informat Technol Engn, Tianjin 300222, Peoples R China.
C3 Ministry of Agriculture & Rural Affairs; China Agricultural University;
   Tianjin University of Technology & Education
RP Gao, WL; Wang, MJ (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Informatizat Standardizat, Beijing 100083, Peoples R China.; Gao, WL; Wang, MJ (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
EM 672968853@qq.com; wanlin_cau@163.com; mateen@aup.edu.pk;
   minjuan@cau.edu.cn
OI Zhong, Zhen/0000-0002-7349-1256
FU Key Research and Development Project of Shandong Province
   [2019GNC106091]; National Key Research and Development Program
   [2016YFD0200600-2016YFD0200602]
FX The authors would like to thank their colleagues for their support of
   this work. The detailed comments from the anonymous reviewers were
   gratefully acknowledged. This work was supported by the Key Research and
   Development Project of Shandong Province (Grant No. 2019GNC106091) and
   the National Key Research and Development Program (Grant No.
   2016YFD0200600-2016YFD0200602).
CR Bai XZ, 2015, INFRARED PHYS TECHN, V71, P77, DOI 10.1016/j.infrared.2015.03.001
   Bai XZ, 2011, OPT EXPRESS, V19, P8444, DOI 10.1364/OE.19.008444
   Balakrishnan S, 2012, NDT&E INT, V51, P51, DOI 10.1016/j.ndteint.2012.06.006
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Chen YF, 2015, OPTIK, V126, P4243, DOI 10.1016/j.ijleo.2015.08.120
   Fendri E, 2017, PATTERN ANAL APPL, V20, P907, DOI 10.1007/s10044-017-0621-z
   Feng Zijun, 2012, Computer Engineering and Applications, V48, P9, DOI 10.3778/j.issn.1002-8331.2012.07.003
   Font-i-Furnols M, 2015, ANIMAL, V9, P166, DOI 10.1017/S1751731114002237
   He L. I, 2016, INFRARED PHYS TECHN, V74, P28
   Howe K, 2013, NATURE, V496, P498, DOI 10.1038/nature12111
   Huang Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041169
   Huang ZW, 2017, J MED IMAG HEALTH IN, V7, P229, DOI 10.1166/jmihi.2017.2011
   Jin X, 2017, INFRARED PHYS TECHNO, P88
   Kashisha MA, 2013, ADV CONCEPTS INTELLI
   Kong WW, 2016, NEUROCOMPUTING, V212, P12, DOI 10.1016/j.neucom.2016.01.120
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Leung Y, 2014, IEEE GEOSCI REMOTE S, V11, P985, DOI 10.1109/LGRS.2013.2284282
   Li M., 2016, SCIENCE, V8, P2281
   Liu X, 2014, AEU-INT J ELECTRON C, V68, P471, DOI 10.1016/j.aeue.2013.12.003
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma Y, 2016, NEUROCOMPUTING, V202, P12, DOI 10.1016/j.neucom.2016.03.009
   Meng F, 2016, COMPUTERS ELECT ENG
   Moghadam F. V., 2017, NEW MULTIFOCUS IMAGE
   Paramanandham N, 2017, INFRARED PHYS TECHNO, P88
   Pu T, 2000, OPT ENG, V39, P2075, DOI 10.1117/1.1303728
   Qian JX, 2018, INFRARED VISUAL IMAG
   Remy S, 2014, GENOME RES, V24, P1371, DOI 10.1101/gr.171538.113
   Rockinger O, 1998, P SOC PHOTO-OPT INS, V3374, P378, DOI 10.1117/12.327135
   Shen G, 2011, INT C DIG MAN AUT
   Stajnko D, 2008, COMPUT ELECTRON AGR, V61, P233, DOI 10.1016/j.compag.2007.12.002
   TILL JE, 1961, RADIAT RES, V14, P213, DOI 10.2307/3570892
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Xie K, 2005, MULTIFOCUS IMAGE FUS
   Yang GJ, 2017, INT CONF ELECTRO INF, DOI 10.1109/HealthCom.2017.8210793
   Yang JF, 2011, COMPUT HUM BEHAV, V27, P1565, DOI 10.1016/j.chb.2010.10.029
   Yang JF, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P87, DOI 10.1109/ICIG.2009.170
   Yang S, 2018, RES FINGERPRINT IMAG
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   [郑红 Zheng Hong], 2012, [仪器仪表学报, Chinese Journal of Scientific Instrument], V33, P1613
   Zheng YF, 2005, OPT ENG, V44, DOI 10.1117/1.1871812
NR 45
TC 9
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26225
EP 26244
DI 10.1007/s11042-020-09044-9
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548128400007
DA 2024-07-18
ER

PT J
AU Li, YM
   Gao, Z
   Tao, YB
   Wang, LL
   Xue, YB
AF Li, Yin-min
   Gao, Zan
   Tao, Ya-bin
   Wang, Li-li
   Xue, Yan-bing
TI 3D Object retrieval based on non-local graph neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Non-local graph neural network; 3D shape
   descriptors
ID MODEL RETRIEVAL; DISCRIMINATION; SEARCH
AB 3D object retrieval is a hot research field in computer vision and multimedia analysis domain. Since the appearance feature and points of view of 3D objects are very different, thus, the distribution of the training set and test set are variant which is very suitable for transfer learning or cross-domain learning. In the transfer learning or cross-domain learning, the feature extraction is very important which should have good robust for different domains. Thus, in this work, we pay attention to the feature extraction of 3D objects. So far, different feature representations and object retrieval approaches have been proposed. Among them, view-based deep learning retrieval methods achieve state-of-the-art performance, but the existing deep learning retrieval methods only simply use a deep neural network to extract features from each view and directly obtain the view-level shape descriptors without utilizing the spatial relationship between the views. In order to mine the spatial relationship among different views and obtain more discriminative 3D shape descriptors, in this work, 3D object retrieval based on non-local graph neural networks (NGNN) is proposed. In detail, the residual network is firstly utilized as the infrastructure, and then the non-local structure is embedded in the resnet to learn the intrinsic relationship between the views. Finally, the view pooling layer is employed to further fuse the information from different views, and obtain the discriminate feature for the 3D object. Experimental results on two public MVRED and NTU 3D datasets show that the non-local graph network is very efficient for exploring the latent relationship among different views, and the performance ofNGNNsignificantly outperforms state-of-the-art approaches whose improvement can reaches 12.4%-22.7% on ANMRR.
C1 [Li, Yin-min; Xue, Yan-bing] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Li, Yin-min; Gao, Zan] Qilu Univ Technol, Shandong Artif Intelligence Inst, Shandong Acad Sci, Jinan 250014, Peoples R China.
   [Tao, Ya-bin] Jiangxi Vocat Tech Coll Ind Trade, Nanchang 330038, Jiangxi, Peoples R China.
   [Wang, Li-li] China Unicorn Yantai Branch, Yantai 264006, Peoples R China.
C3 Tianjin University of Technology; Qilu University of Technology
RP Gao, Z (corresponding author), Qilu Univ Technol, Shandong Artif Intelligence Inst, Shandong Acad Sci, Jinan 250014, Peoples R China.
EM zangaonsh4522@gmail.com
RI zhang, yuyang/IVV-5089-2023
FU National Natural Science Foundation of China [61872270, 61572357,
   61971309]; National Key R&D Program of China [2019YFBB1404700]; Young
   creative team in universities of Shandong Province [2020KJN012]; Tianjin
   Key Laboratory of Intelligence Computing and Novel Software Technology,
   Tianjin University of Technology, China; Tianjin Municipal Natural
   Science Foundation [18JCYBJC85500]; NSF project of Tianjin
   [17JCYBJC15600]; Jinan 20 projects in universities [2018GXRC014]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61872270, No.61572357, No.61971309). National
   Key R&D Program of China (No.2019YFBB1404700). Jinan 20 projects in
   universities (No.2018GXRC014). Young creative team in universities of
   Shandong Province (No.2020KJN012), Opening Foundation of Tianjin Key
   Laboratory of Intelligence Computing and Novel Software Technology,
   Tianjin University of Technology, China. Tianjin Municipal Natural
   Science Foundation (No.18JCYBJC85500), NSF project of Tianjin (No.
   17JCYBJC15600).
CR [Anonymous], 2000, P KDD WORKSH TEXT MI, DOI DOI 10.1109/ICCCYB.2008.4721382
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Baranowski T, 2017, GAMES HEALTH J, V6, P1, DOI 10.1089/g4h.2016.0106
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P755, DOI 10.1007/978-3-319-27671-7_63
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Gao Z, 2018, AAAI CONF ARTIF INTE, P2223
   Garcia-Garcia A, 2016, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2016.7727386
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu XL, 2015, IEEE T CYBERNETICS, V45, P2461, DOI 10.1109/TCYB.2014.2374755
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Lu K, 2014, INFORM SCIENCES, V281, P703, DOI 10.1016/j.ins.2014.03.079
   Maturana D., 2015, IEEE INT C INT ROBOT, DOI DOI 10.1109/IROS.2015.7353481
   Mihael A, 1999, P INT S SPAT DAT
   Minsu C., 2010, ECCV
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Polewski P, 2015, ISPRS J PHOTOGRAMM, V105, P252, DOI 10.1016/j.isprsjprs.2015.01.010
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tatsuma A, 2009, VISUAL COMPUT, V25, P785, DOI 10.1007/s00371-008-0304-2
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang LR, 1996, PATTERN RECOGN, V29, P1061, DOI 10.1016/0031-3203(95)00147-6
   Zan G, 2020, 43 INT ACM SIGIR C R
   Zhou J, 2018, ARXIV181208434
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 50
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34011
EP 34027
DI 10.1007/s11042-020-09248-z
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000547355800001
DA 2024-07-18
ER

PT J
AU Saldanha, M
   Conceiçao, R
   Afonso, V
   Avila, G
   Susin, A
   Porto, M
   Zatt, B
   Correa, G
   Agostini, L
AF Saldanha, Mario
   Conceicao, Ruhan
   Afonso, Vladimir
   Avila, Giovanni
   Susin, Altamiro
   Porto, Marcelo
   Zatt, Bruno
   Correa, Guilherme
   Agostini, Luciano
TI Complexity and compression efficiency assessment of 3D-HEVC encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; HEVC; Video coding; Performance analysis; Computational
   complexity
ID VIDEO; HEVC; DEPTH; MULTIVIEW; QUADTREE
AB This paper presents a complexity and compression efficiency assessment of the 3D-High Efficiency Video Coding (3D-HEVC) encoder. An experimental evaluation was carried out to identify the encoding tools with the highest impact on the computational complexity of 3D-HEVC. The evaluated tools were firstly divided into three categories: HEVC, multiview, and depth maps tools. Thus, incremental analyses with a set of 28 encoder configurations were performed to point out the compression efficiency and the computational complexity of each encoding tool individually. Experimental results demonstrated different compression-complexity operation points for the 3D-HTM reference software, providing relevant information for the implementation of 3D-HEVC encoders with different tradeoff possibilities between compression efficiency and complexity. The obtained results also allowed identifying encoding tools that can be further optimized in future works.
C1 [Saldanha, Mario; Conceicao, Ruhan; Avila, Giovanni; Susin, Altamiro; Porto, Marcelo; Zatt, Bruno; Correa, Guilherme; Agostini, Luciano] Fed Univ Pelotas UFPel, Video Technol Res Grp ViTech, Pelotas, RS, Brazil.
   [Afonso, Vladimir] Fed Univ Rio Grande do Sul UFRGS, Porto Alegre, RS, Brazil.
C3 Universidade Federal de Pelotas; Universidade Federal do Rio Grande do
   Sul
RP Saldanha, M (corresponding author), Fed Univ Pelotas UFPel, Video Technol Res Grp ViTech, Pelotas, RS, Brazil.
EM mrdfsaldanha@inf.ufpel.edu.br; radconceicao@inf.ufpel.edu.br;
   vafonso@inf.ufpel.edu.br; altamiro.susin@ufrgs.br;
   porto@inf.ufpel.edu.br; zatt@inf.ufpel.edu.br; gcorrea@inf.ufpel.edu.br;
   agostini@inf.ufpel.edu.br
RI Corrêa, Guilherme/AAW-7619-2021; Zatt, Bruno/B-2651-2017
OI Corrêa, Guilherme/0000-0002-2739-6194; Saldanha,
   Mario/0000-0002-6771-6359
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen Y, 2016, IEEE T MULTIMEDIA, V18, P576, DOI 10.1109/TMM.2016.2525010
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Jäger F, 2012, INT CONF 3D IMAG
   Jager F, 2013, DEPTH BASED BLOCK PA, DOI [10.1109/PCS.2013.6737770, DOI 10.1109/PCS.2013.6737770]
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee JY, 2015, ANN TRANSL MED, V3, DOI 10.3978/j.issn.2305-5839.2014.11.03
   Li X, 2014, IEEE INT C IM P, DOI [10.1109/ICIP.2013.6738360, DOI 10.1109/ICIP.2013.6738360]
   Liu H, 2015, IEEE INT C IM P, DOI [10.1109/ICIP.2014.7025651, DOI 10.1109/ICIP.2014.7025651]
   Liu H., 2012, 3D-CE2. h: Results of illumination compensation for inter-view prediction
   Merkle P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1717, DOI 10.1109/ICME.2006.262881
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Mora EG, 2014, IEEE T CIRC SYST VID, V24, P1554, DOI 10.1109/TCSVT.2013.2283110
   Müller K, 2012, ASIAPAC SIGN INFO PR
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Muller K., 2014, COMMON TEST CONDITIO
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Sanchez G, 2019, IEEE T CIRC SYST VID, V29, P2509, DOI 10.1109/TCSVT.2018.2865645
   Sebai D, 2020, J SIGNAL PROCESS SYS, V92, P747, DOI 10.1007/s11265-020-01521-6
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Winken M, 2012, PICT COD S, DOI [10.1109/PCS.2012.6213284, DOI 10.1109/PCS.2012.6213284]
   Zhang L, 2013, VISUAL COMMUN IMAGE, DOI [10.1109/VCIP.2013.6706401, DOI 10.1109/VCIP.2013.6706401]
NR 28
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25723
EP 25746
DI 10.1007/s11042-020-09257-y
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545938900002
DA 2024-07-18
ER

PT J
AU Wang, JH
   Yan, W
   Huang, C
AF Wang, Jihua
   Yan, Wei
   Huang, Chao
TI Surface shape-based clustering for B-rep models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface shape; B-rep model; Surface curvature; 3D model clustering;
   STEP(standard for exchange of product model); Bipartite graph matching;
   Earth mover's distance
ID TOPOLOGICAL SIMILARITY; DATABASE SYSTEM; RECOGNITION; RETRIEVAL
AB Matching, clustering, and retrieving 3D CAD models of mechanical components based on their shape are useful for many CAD/CAM applications such as design reuse, variant process planning and group technology. Surfaces are the prominent elements of the B-Rep (Boundary Representation) CAD model, but the current methods of similarity assessment are not centered on the surfaces and lack an accurate description of their geometric features. In order to solve the problem of retrieval and clustering of B-Rep models more efficiently, the concept of "most crucial surface" is proposed and its corresponding characteristics are studied in detail. The contribution of our approach is that surfaces are the major shape determinants of the B-Rep model, and the distribution of Carosati curvatures is the optimum shape features of surfaces. First, the surface elements are extracted from the STEP (Standard for Exchange of Product Model) files of the B-rep models, and the distribution of minimum, Gauss and Carosati surface curvatures are converted into the shape feature space by the wavelet transform, the Fourier transform, and the grouping calculation. Thus we characterize the B-Rep model as a histogram with surfaces as bins, and then compare and cluster the B-Rep models by the bipartite matching algorithm or the earth mover's distance. The surface-based methods are evaluated with the four effectiveness indices in the clustering experiment of the NDR (National Design Reservoir) data, and the results indicated that the grouping method for the surface Carosati curvatures has a highly competent matching and clustering performance.
C1 [Wang, Jihua; Yan, Wei; Huang, Chao] Shandong Normal Univ, Coll Informat Sci & Engn, 1 Daxue Rd, Jinan 250014, Peoples R China.
C3 Shandong Normal University
RP Yan, W (corresponding author), Shandong Normal Univ, Coll Informat Sci & Engn, 1 Daxue Rd, Jinan 250014, Peoples R China.
EM jihuaaw@126.com; wyaninsa@gmail.com; 963792481@qq.com
RI Huang, Chao/L-1445-2019; YAN, Wei/AAR-2168-2021; Huang,
   Chao/JJD-0553-2023
OI Huang, Chao/0000-0001-8775-3192
FU National Natural Science Foundation of China [61472233]; Natural Science
   Foundation of Shandong Province [ZR2014FM018]
FX This work was supported by The National Natural Science Foundation of
   China (61472233), The Natural Science Foundation of Shandong Province
   (ZR2014FM018).
CR Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   BARLOW HB, 1983, J MATH PSYCHOL, V27, P107, DOI 10.1016/0022-2496(83)90030-5
   Cicek Adem, 2007, Mathematical & Computational Applications, V12, P141
   Ekroll V, 2015, I-PERCEPTION, V6, P15, DOI 10.1068/i0676sas
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P83, DOI 10.1016/S0010-4485(01)00177-4
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6
   Fradi A., 2018, IEEE ACS INT C COMP
   Furuya T, 2013, INT C CYB
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gibson JJ, 1979, AM J PSYCHOL, V102, P443
   Huangfu ZM, 2017, MULTIMED TOOLS APPL, V76, P8145, DOI 10.1007/s11042-016-3456-5
   Jayanti S, 2009, COMPUT AIDED DESIGN, V41, P999, DOI 10.1016/j.cad.2009.07.003
   Kovacs I, 1996, BEHAV BRAIN RES, V82, P1, DOI 10.1016/S0166-4328(97)81103-5
   Li K, 2014, COMPUT AIDED DESIGN, V53, P70, DOI 10.1016/j.cad.2014.03.005
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Li Z, 2015, COMPUT AIDED DESIGN, V62, P190, DOI 10.1016/j.cad.2014.05.008
   Peabody M., 2001, DUMCS0101
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Tao SQ, 2018, MULTIMED TOOLS APPL, V77, P16249, DOI 10.1007/s11042-017-5197-5
   Tao SQ, 2017, MULTIMED TOOLS APPL, V76, P103, DOI 10.1007/s11042-015-3033-3
   Wang J, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat7392
   Wang JH, 2014, KNOWL-BASED SYST, V56, P97, DOI 10.1016/j.knosys.2013.11.002
   Wang QM, 2014, COMPUT IND, V65, P1041, DOI 10.1016/j.compind.2014.04.004
   Wang ZS, 2014, CHIN J MECH ENG-EN, V27, P1112, DOI 10.3901/CJME.2014.0815.134
   Yamane Y, 2008, NAT NEUROSCI, V11, P1352, DOI 10.1038/nn.2202
   Zehtaban L, 2016, J COMPUT DES ENG, V3, P274, DOI 10.1016/j.jcde.2016.04.002
NR 30
TC 2
Z9 2
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25747
EP 25761
DI 10.1007/s11042-020-09252-3
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545938900001
DA 2024-07-18
ER

PT J
AU Giabelli, A
   Malandri, L
   Mercorio, F
   Mezzanzanica, M
AF Giabelli, Anna
   Malandri, Lorenzo
   Mercorio, Fabio
   Mezzanzanica, Mario
TI GraphLMI: A data driven system for exploring labor market information
   through graph databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph database; Labor market intelligence; Social networking; Web data
AB Labor Market Intelligence (LMI) is an emerging field of study that has been gaining interest as it allows employing Artificial Intelligence (AI) algorithms on labor market information. The goal of LMI is to support decision and policy making activities (e.g., real-time monitoring of Online Job Vacancies (OJV) across countries, forecast skill requested within vacancies, compare similar labor markets across borders, etc.). The European project in which this work is framed can be placed in this field, as it aims at collecting and classifying millions of OJVs from 28 EU Countries, handling 32 languages, and also extracting the requested skills. The result is a huge amount of information useful for understanding labor market dynamics and trends. The goal of this work is to realize a system - namely GraphLMI - that organizes such Labor Market information as a graph, enabling the representation of occupation/skill relevance and similarity over the European Labor Market; another goal is to enrich the European standard taxonomy of occupations and skills (ESCO) to better fit the labor market expectations. We formalize and design the GraphLMI data model, then we implement it as a graph-database, generated by processing 5.3+ million OJVs composed by free text and collected between 2018 and 2019 for France, Germany, and the United Kingdom. Finally, we show how the resulting knowledge can be queried through a declarative query language to understand, compare and evaluate country-based labor market dynamics for supporting policy and decision making activities at European level.
C1 [Giabelli, Anna; Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario] Univ Milano Bicocca, CRISP Res Ctr, Milan, Italy.
   [Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario] Univ Milano Bicocca, Dept Stat & Quantitat Methods, Milan, Italy.
C3 University of Milano-Bicocca; University of Milano-Bicocca
RP Giabelli, A (corresponding author), Univ Milano Bicocca, CRISP Res Ctr, Milan, Italy.
EM anna.giabelli@unimib.it; lorenzo.malandri@unimib.it;
   fabio.mercorio@unimib.it; mario.mezzanzanica@unimib.it
RI Mercorio, Fabio/E-4369-2013
OI Mercorio, Fabio/0000-0001-6864-2702; MEZZANZANICA,
   MARIO/0000-0003-0399-2810; malandri, lorenzo/0000-0002-0222-9365
FU EU
FX This work is partially supported within the research activity of a EU
   Project entitled "Real-time Labor Market information on Skill
   Requirements: Setting up the EU system for online vacancy analysis27 in
   which some of the authors are involved as coordinators and researchers.
CR Alabdulkareem A, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao6030
   Angles R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322433
   Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101
   Bergamaschi S, 2016, ENGINEERING-PRC, V2, P163, DOI 10.1016/J.ENG.2016.02.011
   Bonifati A., 2018, Synthesis Lectures on Data Management, DOI DOI 10.2200/S00873ED1V01Y201808DTM051
   Bonifati Angela, 2015, P INT C EXT DAT TECH, P109, DOI DOI 10.5441/002
   Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132
   Boselli Roberto, 2013, Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data. Third International Workshop, HCI-KDD 2013. Held at SouthCHI 2013. Proceedings: LNCS 7947, P183, DOI 10.1007/978-3-642-39146-0_17
   BOSELLI R, 2017, LECT NOTES ARTIF III, V536, P330
   Boselli R, 2018, J INTELL INF SYST, V51, P477, DOI 10.1007/s10844-017-0488-x
   Boselli R, 2018, FUTURE GENER COMP SY, V86, P319, DOI 10.1016/j.future.2018.03.035
   CEDEFOP, 2016, REAL TIM LAB MARK IN
   CEDEFOP, 2014, REAL TIM LAB MARK IN
   Chikhaoui B, 2015, AAAI CONF ARTIF INTE, P51
   Chung F.R.K, 1997, CBMS Regional Conference Series in Mathematics
   Colombo E, 2019, INF ECON POLICY, V47, P27, DOI 10.1016/j.infoecopol.2019.05.003
   Davoudian A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158661
   Durand Gabriel Campero, 2018, EDBT
   Durrett R., 2007, Random Graph Dynamics, V200
   Fleming M., 2019, The Future of Work: How New Technologies Are Transforming Tasks
   Francis N, 2018, INT CONF MANAGE DATA, P1433, DOI 10.1145/3183713.3190657
   Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019
   Gupta S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1267, DOI 10.1145/3041021.3053062
   Javed F, 2017, AAAI CONF ARTIF INTE, P4627
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Khurana U., 2016, **DATA OBJECT**, DOI 10.5441/002/edbt.2016.09
   Kipf TN, 2016, ARXIV
   Li HJ, 2016, MULTIMED TOOLS APPL, V75, P8939, DOI 10.1007/s11042-014-2336-0
   Liu L, 2012, MULTIMED TOOLS APPL, V56, P179, DOI 10.1007/s11042-010-0568-1
   Lovaglio PG, 2018, STAT ANAL DATA MIN, V11, P78, DOI 10.1002/sam.11372
   Malewicz Grzegorz, 2010, P ACM SIGMOD INT C M, P135, DOI [DOI 10.1145/1807167.1807184, 10.1145/1807167.1807184]
   Mercorio F, 2020, LECT NOTES COMPUTER, V11908
   Mercorio F, 2021, IEEE T EMERG TOP COM, V9, P1987, DOI 10.1109/TETC.2019.2952765
   Mezzanzanica Mario, 2012, Proceedings of the DATA 2012. 1st International Conference on Data Technologies and Applications, P97
   Mezzanzanica M, 2018, MULTIMED TOOLS APPL, V77, P18657, DOI 10.1007/s11042-017-5503-2
   Mezzanzanica M, 2015, ACM J DATA INF QUAL, V5, DOI 10.1145/2641575
   Mezzanzanica M, 2011, LECT NOTES COMPUT SC, V7014, P270, DOI 10.1007/978-3-642-24800-9_26
   Papoutsoglou M, 2019, IEEE ACCESS
   Robinson I., 2015, Graph databases: New Opportunities for Connected Data
   Stonebraker M, 2010, COMMUN ACM, V53, P10, DOI 10.1145/1721654.1721659
   Sung-Hyuk C, 2007, INT J MATH MODELS ME
   Turrell A, 2018, 737 BANK ENGL
   Vicknair C, 2010, PROCEEDINGS OF THE 48TH ANNUAL SOUTHEAST REGIONAL CONFERENCE (ACM SE 10), P104, DOI 10.1145/1900008.1900037
   Vinel M., 2019, C ART INT NAT LANG, P99
   Wang SY, 2019, FUTURE GENER COMP SY, V91, P10, DOI 10.1016/j.future.2018.08.047
   Xiao L, 2020, FUTURE GENERATION CO
   Yao WL, 2015, WORLD WIDE WEB, V18, P1351, DOI 10.1007/s11280-014-0307-z
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
NR 48
TC 13
Z9 13
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3061
EP 3090
DI 10.1007/s11042-020-09115-x
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000544143200001
DA 2024-07-18
ER

PT J
AU Zefreh, EZ
AF Zefreh, Ebrahim Zarei
TI An image encryption scheme based on a hybrid model of DNA computing,
   chaotic systems and hash functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA computing; Chaotic system; Hash function; DNA
   circular shift
ID HENON-SINE MAP; SEQUENCE OPERATION; COMBINING CHAOS; CRYPTANALYSIS;
   BREAKING
AB In this paper, we propose a novel image encryption scheme based on a hybrid model of DNA computing, chaotic systems and hash functions. The significant advantage of the proposed scheme is high efficiency. The proposed scheme consists of the DNA level permutation and diffusion. In the DNA level permutation, a mapping function based on the logistic map is applied on the DNA image to randomly change the position of elements in the DNA image. In the DNA level diffusion, not only we define two new algebraic DNA operators, called the DNA left-circular shift and DNA right-circular shift, but we also use a variety of DNA operators to diffuse the permutated DNA image with the key DNA image. The experimental results and security analyses indicate that the proposed image encryption scheme not only has good encryption effect and able to resist against the known attacks, but also is sufficiently fast for practical applications. The MATLAB source code of the proposed image encryption scheme is publicly available at the URL:.
C1 [Zefreh, Ebrahim Zarei] Univ Khansar, Dept Comp Sci, Khansar, Iran.
RP Zefreh, EZ (corresponding author), Univ Khansar, Dept Comp Sci, Khansar, Iran.
EM zarei@khansar-cmc.ac.ir
RI ZareiZefreh, Ebrahim/KVB-6115-2024
OI Zarei Zefreh, Ebrahim/0000-0002-8318-7485
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Boeing G., 2017, SOC SCI ELECT PUBLIS, V4, P37
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chen J, 2014, MATH PROBL ENG, V2014
   Chen J, 2020, INFORM SCI WUJLIAO L
   Choi J, 2016, MULTIMED TOOLS APPL, V75, P14685, DOI 10.1007/s11042-016-3274-9
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li DZ, 2017, INT CONF SYST INFORM, P288, DOI 10.1109/ICSAI.2017.8248306
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Li T, 2017, COMPLEXITY
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu XQ, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.81
   Maddodi G, 2018, MULTIMED TOOLS APPL, V3, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Rachmawati D, 2018, J PHYS CONF SER, V1013, DOI 10.1088/1742-6596/1013/1/012159
   Rajput A S., 2015, ADV INTELLIGENT INFO, P277
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Som S, 2013, 2013 1ST INTERNATIONAL CONFERENCE ON EMERGING TRENDS AND APPLICATIONS IN COMPUTER SCIENCE (ICETACS), P108, DOI 10.1109/ICETACS.2013.6691405
   Song CY, 2015, ENTROPY-SWITZ, V17, P6954, DOI 10.3390/e17106954
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wen HP, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030246
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang J, 2014, MATH PROBL ENG
   Zhang L-B, 2015, MATH PROBL ENG
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang X, 2017, COMPUTATIONAL INTELL
   Zhou S, 2016, DISCRETE DYN NAT SOC
NR 51
TC 101
Z9 103
U1 7
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24993
EP 25022
DI 10.1007/s11042-020-09111-1
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543948700001
DA 2024-07-18
ER

PT J
AU Polinati, S
   Dhuli, R
AF Polinati, Srinivasu
   Dhuli, Ravindra
TI Structural and functional medical image fusion using an adaptive Fourier
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fourier decomposition method (FDM); Fourier intrinsic band of
   frequencies (FIBFs); Image fusion; Principal component analysis (PCA);
   Maximum selection rule
ID CT IMAGES; PERFORMANCE; INFORMATION; TRANSFORM
AB Medical image fusion helps in meaningfully combining, the information provided by various imaging sensors, targeting the clinical details of human organs. It is well known that the Magnetic Resonance Imaging (MRI) provides the structural content, whereas Positron Emission Tomography (PET) and Single Photon Emission Computed Tomography (SPECT) provides functional information. The structural and functional details are required in a single image, to accurately identify the abnormalities in the initial stages. We propose a combination of Fourier Decomposition Method (FDM), Principal Component Analysis (PCA) and maximum selection rule-based technique for generating MRI-PET and MRI-SPECT fused images. Here, FDM is used as an analysis tool, whereas PCA and maximum selection are used for generating the fusion mechanism. FDM helps to decompose the source images into meaningful layers called modes, based on the local features of the images. PCA a tool for dimensionality reduction preserves significant information from the image layers. Crucial details from the modes are properly combined using the rule of max selection. The proposed fusion methodology, when compared with the state-of-the-art fusion methods in terms of visual quality and objective metrics, exhibited promising performance.
C1 [Polinati, Srinivasu] SENSE Vellore Inst Technol, Vellore, Tamil Nadu, India.
   [Dhuli, Ravindra] SENSE VIT AP Univ, Amaravati, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; VIT-AP University
RP Dhuli, R (corresponding author), SENSE VIT AP Univ, Amaravati, India.
EM srinivasu.polinati@gmail.com; ravindradhuli@gmail.com
RI polinati, srinivasu/A-8135-2018; Polinati, Dr. Srinivasu/AAZ-1424-2020
OI Polinati, Dr. Srinivasu/0000-0003-0592-2154
CR Anderson Charles H., 1988, U.S. Patent, Patent No. [4,718,104, 4718104]
   [Anonymous], 2000, CURVES SURFACES
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Bashir R, 2019, MULTIMED TOOLS APPL, V78, P1235, DOI 10.1007/s11042-018-6229-5
   Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   Bhateja V, 2016, MED IMAGE FUSION CUR
   Burt P.J., 1992, PROC SOC INFORM DISP, P467
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Du J, 2017, IEEE T IMAGE PROCESS, V26, P5855, DOI 10.1109/TIP.2017.2745202
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li G, 2011, IMAGE FUSION BASED C, P55
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li X, 2010, IET IMAGE PROCESS, V4, P283, DOI 10.1049/iet-ipr.2008.0259
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Llinas, 2017, HDB MULTISENSOR DATA, P21
   MATSOPOULOS GK, 1994, IEE P-VIS IMAGE SIGN, V141, P137, DOI 10.1049/ip-vis:19941184
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Qu GH, 2001, OPT EXPRESS, V9, P184, DOI 10.1364/OE.9.000184
   Rockinger O, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P288, DOI 10.1109/ICIP.1997.632093
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Singh P., 2015, ARXIV150404104
   Singh P, 2015, ARXIV150708117
   Singh P, 2017, P ROY SOC A-MATH PHY, V473, DOI 10.1098/rspa.2016.0871
   Stokman H, 2007, IEEE T PATTERN ANAL, V29, P371, DOI 10.1109/TPAMI.2007.58
   Summers D, 2003, J NEUROL NEUROSUR PS, V74, P288, DOI 10.1136/jnnp.74.3.288
   Tannaz A, 2020, MULTIDIM SYST SIGN P, V31, P269, DOI 10.1007/s11045-019-00662-7
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang YF, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P487, DOI 10.1109/ICNIDC.2012.6418801
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
NR 46
TC 4
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23645
EP 23668
DI 10.1007/s11042-020-09017-y
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539889900005
DA 2024-07-18
ER

PT J
AU Fei, JW
   Xia, ZH
   Yu, PP
   Xiao, FJ
AF Fei, Jianwei
   Xia, Zhihua
   Yu, Peipeng
   Xiao, Fengjun
TI Exposing AI-generated videos with motion magnification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Fake videos; DeepFakes detection; Motion magnification
AB Recent progress of artificial intelligence makes it easier to edit facial movements in videos or create face substitutions, bringing new challenges to anti-fake-faces techniques. Although multimedia forensics provides many detection algorithms from a traditional point of view, it is increasingly hard to discriminate the fake videos from real ones while they become more sophisticated and plausible with updated forgery technologies. In this paper, we introduce a motion discrepancy based method that can effectively differentiate AI-generated fake videos from real ones. The amplitude of face motions in videos is first magnified, and fake videos will show more serious distortion or flicker than the pristine videos. We pre-trained a deep CNN on frames extracted from the training videos and the output vectors of the frame sequences are used as input of an LSTM at secondary training stage. Our approach is evaluated over a large fake video dataset Faceforensics++ produced by various advanced generation technologies, it shows superior performance contrasted to existing pixel-based fake video forensics approaches.
C1 [Fei, Jianwei; Xia, Zhihua; Yu, Peipeng] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Xiao, Fengjun] Hangzhou Dianzi Univ, Sch Management, Hangzhou 310018, Peoples R China.
C3 Nanjing University of Information Science & Technology; Hangzhou Dianzi
   University
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Peoples R China.
EM feijianwei@nuist.edu.cn; xia_zhihua@163.com; ypp865@163.com;
   bhxfj@126.com
RI Peipeng, Yu/AEX-3356-2022; Xia, Zhihua/C-8581-2011
OI Xia, Zhihua/0000-0001-6860-647X
FU Jiangsu Basic Research Programs-Natural Science Foundation [BK20181407,
   BK20150925, BK20151530]; National Natural Science Foundation of China
   [61672294, U1836208, 61502242, 61702276, U1536206, 61772283, 61602253,
   61601236, 61572258]; Six peak talent project of Jiangsu Province
   [R2016L13]; Qing Lan Project of Jiangsu Province; "333" project of
   Jiangsu Province; National Key R&D Program of China [2018YFB1003205];
   Humanity and Social Science Youth foundation of Ministry of Education of
   China [15YJC870021]; Priority Academic Program Development of Jiangsu
   Higher Education Institutions (PAPD) fund; Collaborative Innovation
   Center of Atmospheric Environment and Equipment Technology (CICAEET)
   fund, China; BK21+ program from the Ministry of Education of Kore; 
   [NRF-2016R1D1A1B03933294]
FX This work is supported in part by the Jiangsu Basic Research
   Programs-Natural Science Foundation under grant numbers BK20181407, in
   part by the National Natural Science Foundation of China under grant
   numbers 61672294, in part by Six peak talent project of Jiangsu Province
   (R2016L13), Qing Lan Project of Jiangsu Province and "333" project of
   Jiangsu Province, in part by the National Natural Science Foundation of
   China under grant numbers U1836208, 61502242, 61702276, U1536206,
   61772283, 61602253, 61601236, and 61572258, in part by National Key R&D
   Program of China under grant 2018YFB1003205, in part by
   NRF-2016R1D1A1B03933294, in part by the Jiangsu Basic Research
   Programs-Natural Science Foundation under grant numbers BK20150925 and
   BK20151530, in part by Humanity and Social Science Youth foundation of
   Ministry of Education of China (15YJC870021), in part by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) fund, in part by the Collaborative Innovation Center of
   Atmospheric Environment and Equipment Technology (CICAEET) fund, China.
   Zhihua Xia is supported by BK21+ program from the Ministry of Education
   of Kore.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   [Anonymous], 2009, ACM SIGGRAPH 2009 Courses, SIGGRAPH '09
   [Anonymous], 2012, ACM Transactions on Graphics (TOG), DOI DOI 10.1145/2185520.2185561
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   COZZOLINO D, 2019, IEEE T INFORM FORENS
   Engelsma J.J., 2018, IEEE Trans Pattern Anal Mach Intell., V8828, P1, DOI [10.1109/TPAMI.2018.2858764, DOI 10.1109/TPAMI.2018.2858764]
   Fei JW, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0490-z
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   GUERA D, 2019, ARXIV190608743
   Guera D., 2018, 15 IEEE INT C ADV VI, P1, DOI [DOI 10.1109/AVSS.2018.8639163, 10.1109/AVSS.2018.8639163]
   Hyeongwoo Kim, 2018, ACM Transactions on Graphics, V37, DOI [10.1145/3197517.3201283, 10.18022/acfco.2018.37.1.001]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Koopman M., 2018, 20 IR MACH VIS IM PR, P133
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Liu C, 2005, ACM T GRAPHIC, V24, P519, DOI 10.1145/1073204.1073223
   Liu DL, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA), P406, DOI 10.1109/ICSGEA.2017.74
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen T. T., 2019, CoRR
   Oh TH, 2018, LECT NOTES COMPUT SC, V11208, P663, DOI 10.1007/978-3-030-01225-0_39
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Peng B, 2016, IEEE IMAGE PROC, P3932, DOI 10.1109/ICIP.2016.7533097
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2019, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2019.00009
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Scherhag Ulrich, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P302, DOI 10.1109/TBIOM.2019.2942395
   Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   TARASIOU M, 2019, ARXIV191113269
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   THIES J, 1904, ARXIV190412356
   Tu Xiaoguang, 2019, ARXIV190105635
   Wadhwa N, 2014, IEEE INT CONF COMPUT
   Wang KD, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SIMULATION, MODELING, AND PROGRAMMING FOR AUTONOMOUS ROBOTS (SIMPAR), P1, DOI 10.1109/SIMPAR.2018.8376263
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 49
TC 15
Z9 18
U1 12
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30789
EP 30802
DI 10.1007/s11042-020-09147-3
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000539519000006
DA 2024-07-18
ER

PT J
AU Blesswin, AJ
   Raj, C
   Sukumaran, R
   Mary, GS
AF Blesswin, John A.
   Raj, Christhu
   Sukumaran, Rajeev
   Mary, Selva G.
TI Enhanced semantic visual secret sharing scheme for the secure image
   communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meaningful shares; Revealing; Share construction; Visual secret sharing
ID CRYPTOGRAPHY
AB Sharing multimedia information through the means of internet has increased many folds in this digital world. Information needs to be send across various secure channel as it contains sensitive data such as bank account details, medical reports or any financial documents. Due to the importance of information sharing, security is the most important objective that needs to be addressed while sharing this sensitive information. In order to share the information securely, one such way is visual secret sharing or visual cryptography. In this paper, introduced Enhanced Semantic Visual Secret Sharing (ESVSS) Scheme that transmits a gray-scale secret image to the receiver using two color cover images. At the receiver end, the secret image is reconstructed by digitally stacking the shares together. The result analysis shows that the ESVSS achieves security and improves the quality of the reconstructed image. The quality is measured by Peak Signal to Noise Ratio (PSNR) up to +39 dB and Mean Square Error is reduced to 6. The Universal Image Quality Index (UIQI) results are recorded up to 90% for the reconstructed image with minimal computational complexity.
C1 [Blesswin, John A.] Anna Univ, Comp Sci & Engn, K Ramakrishnan Coll Technol, Trichy, India.
   [Raj, Christhu] SRM Inst Sci & Technol, Ctr Appl Res Educ, Chennai, Tamil Nadu, India.
   [Sukumaran, Rajeev] Indian Inst Technol IIT, Teaching Learning Ctr, Chennai, Tamil Nadu, India.
   [Mary, Selva G.] Anna Univ, K Ramakrishnan Coll Engn, Comp Sci & Engn, Trichy, India.
C3 Anna University; Anna University of Technology Tiruchirappalli; SRM
   Institute of Science & Technology Chennai; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Madras; Anna University; Anna University of Technology Tiruchirappalli
RP Blesswin, AJ (corresponding author), Anna Univ, Comp Sci & Engn, K Ramakrishnan Coll Technol, Trichy, India.
EM johnblesswin@gmail.com
RI A, John Blesswin/AAF-4319-2021; G, Dr. Selva Mary/AAF-3465-2021;
   Sukumaran, Rajeev/GNH-2278-2022
OI A, John Blesswin/0000-0003-3338-850X; G, Dr. Selva
   Mary/0000-0003-3133-0603; Sukumaran, Rajeev/0000-0003-0263-3031
CR Blesswin A., 2014, Asian Journal of Information Technology, V13, P506, DOI [10.3923/ajit.2014.506.512, DOI 10.3923/AJIT.2014.506.512]
   Blesswin A. J., 2015, Int. J. Control Theory Appl., V8, P1511
   Blesswin J., 2016, INT J CONTROL THEORY, V9, P967
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Chang CC, 2009, IEEE T INF FOREN SEC, V4, P790, DOI 10.1109/TIFS.2009.2034203
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Fu ZX, 2018, IEEE ACCESS, V6, P59567, DOI 10.1109/ACCESS.2018.2874527
   Gayathri M, 2016, IND J SCI TECHNOL, V9, P1
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Kester Q. A., 2013, International Journal of Advanced Research in Computer Engineering and Technology (IJARCET), V2, P848
   Lee JS, 2013, IET NETW, V2, P81, DOI 10.1049/iet-net.2011.0019
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Mhala NC, 2018, IET IMAGE PROCESS, V12, P422, DOI 10.1049/iet-ipr.2017.0759
   Mrunali G, 2014, INT J RES, V1, P1694
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shakeel A, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0404-9
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P106, DOI 10.1007/978-3-642-14298-7_6
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yan XH, 2018, IEEE ACCESS, V6, P45246, DOI 10.1109/ACCESS.2018.2865421
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2000, DESIGN CODE CRYPTOGR, V20, P325, DOI 10.1023/A:1008382327051
NR 33
TC 9
Z9 9
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17057
EP 17079
DI 10.1007/s11042-019-7535-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600070
DA 2024-07-18
ER

PT J
AU Nair, LR
AF Nair, Lekha R.
TI RetoNet: a deep learning architecture for automated retinal ailment
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; ANN; Convolutional neural network; E-health; Retinal
   disease detection
ID NEURAL-NETWORKS; RETINOPATHY; SEGMENTATION; DRUSEN
AB Researchers are trying to tap the immense potential of big data to revolutionize all aspects of societal activity and to assist in having well informed decisions. Healthcare being one such field where proper analytics of available big medical data can lead to early detection and treatment of many ailments. Machine learning played a significant role in the design of automated diagnostic systems and today we have deep learning models in this arena which are outperforming human expertise in terms of predictive accuracy. This paper proposes RetoNet, a convolutional neural network architecture, which is trained and optimized to detect retinal ailment from fundus images with pronounced accuracy and its performance is also proven to be superior to a transfer learning based model developed for the same. Deep learning based e-diagnostic system can be an accurate, cost effective and convenient solution for the shortage of expertise on demand in the healthcare field.
C1 [Nair, Lekha R.] Coll Engn, Kallooppara, India.
RP Nair, LR (corresponding author), Coll Engn, Kallooppara, India.
EM lekharnair@gmail.com
CR [Anonymous], 2018, J PHYS CONF SER
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Arunkumar R, 2017, NEURAL COMPUT APPL, V28, P329, DOI 10.1007/s00521-015-2059-9
   Chen DP, 2015, IEEE-ACM T AUDIO SPE, V23, P1172, DOI 10.1109/TASLP.2015.2422573
   Cheng J, 2012, 19 IEEE INT C IM PRO
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   Dhoot DS, 2018, OPHTHALMOLOGY, V125, P51, DOI 10.1016/j.ophtha.2017.06.029
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Ferris FL, 2013, OPHTHALMOLOGY, V120, P844, DOI 10.1016/j.ophtha.2012.10.036
   Frcophth AT, 2017, OPHTHALMOLOGY, V124, P343, DOI 10.1016/j.ophtha.2016.11.014
   Fu H, 2016, 2016 IEEE 13 INT S B
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Helbing D., 2019, DIGITAL ENLIGHTENMEN, P47
   Hijazi MHA, 2010, IEEE IJCNN
   Khanamiri HN, 2017, JOVE-J VIS EXP, DOI 10.3791/55958
   Khunger Mishkin, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P323, DOI 10.1007/978-981-13-1501-5_28
   Kingma D. P., 2014, arXiv
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Lamoureux E, 2013, OPHTHALMOLOGY AGEING
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Niemeijer M, 2007, INVEST OPHTH VIS SCI, V48, P2260, DOI 10.1167/iovs.06-0996
   Rapantzikos K, 2003, MED IMAGE ANAL, V7, P95, DOI 10.1016/S1361-8415(02)00093-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Wang SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040254
   Zheng YL, 2012, INVEST OPHTH VIS SCI, V53, P8310, DOI 10.1167/iovs.12-9576
NR 32
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15319
EP 15328
DI 10.1007/s11042-018-7114-y
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900054
DA 2024-07-18
ER

PT J
AU Yurttakal, AH
   Erbay, H
   Ikizceli, T
   Karacavus, S
AF Yurttakal, Ahmet Hasim
   Erbay, Hasan
   Ikizceli, Turkan
   Karacavus, Seyhan
TI Detection of breast cancer via deep convolution neural networks using
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Convolutional neural network; Classification
ID COMPUTER-AIDED DIAGNOSIS; MAGNETIC-RESONANCE; CLASSIFICATION;
   SEGMENTATION; GUIDELINES; ACCURACY; LESIONS; BENIGN; CNN
AB Breast cancer is the type of cancer that develops from cells in the breast tissue. It is the leading cancer in women. Early detection of the breast cancer tumor is crucial in the treatment process. Mammography is a valuable tool for identifying breast cancer in the early phase before physical symptoms develop. To reduce false-negative diagnosis in mammography, a biopsy is recommended for lesions with greater than a 2% chance of having suspected malignant tumors and, among them, less than 30 percent are found to have malignancy. To decrease unnecessary biopsies, recently, Magnetic Resonance Imaging (MRI) has also been used to diagnose breast cancer. MRI is the highly recommended test for detecting and monitoring breast cancer tumors and interpreting lesioned regions since it has an excellent capability for soft tissue imaging. However, it requires an experienced radiologist and time-consuming process. On the other hand, convolutional neural networks (CNNs) have demonstrated better performance in image classification compared to feature-based methods and show promising performance in medical imaging. Herein, CNN was employed to characterize lesions as malignant or benign tumors using MRI images. Using only pixel information, a multi-layer CNN architecture with online data augmentation was designed. Later, the CNN architecture was trained and tested. The accuracy of the network is 98.33% and the error rate 0.0167. The sensitivity of the network is 1.0 whereas specificity is 0.9688. The precision is 0.9655.
C1 [Yurttakal, Ahmet Hasim] Bozok Univ, Tech Sci Vocat Sch, Comp Technol Dept, Yozgat, Turkey.
   [Erbay, Hasan] Kirikkale Univ, Engn Fac, Comp Engn Dept, TR-71450 Kirikkale, Turkey.
   [Ikizceli, Turkan] Univ Hlth Sci, Haseki Training & Res Hosp, Dept Radiol, Istanbul, Turkey.
   [Karacavus, Seyhan] Univ Hlth Sci, Kayseri Training & Res Hosp, Dept Nucl Med, Kayseri, Turkey.
C3 Bozok University; Kirikkale University; University of Health Sciences
   Turkey; Istanbul Haseki Training & Research Hospital; Erciyes
   University; University of Health Sciences Turkey; Kayseri Training &
   Research Hospital
RP Erbay, H (corresponding author), Kirikkale Univ, Engn Fac, Comp Engn Dept, TR-71450 Kirikkale, Turkey.
EM ahmet.yurttakal@bozok.edu.tr; hasan_erbay@yahoo.com
RI İkizceli, Türkan/AAP-5697-2020; YURTTAKAL, Ahmet Haşim/HPG-3175-2023;
   Erbay, Hasan/F-1093-2016
OI İkizceli, Türkan/0000-0002-5683-0391; Erbay, Hasan/0000-0002-7555-541X;
   YURTTAKAL, Ahmet Hasim/0000-0001-5170-6466
CR ADLER DD, 1992, CURR OPIN RADIOL, V4, P123
   Agner SC, 2014, RADIOLOGY, V272, P91, DOI 10.1148/radiol.14121031
   [Anonymous], STED
   [Anonymous], 2008, J BREAST HEALTH
   [Anonymous], COMPUTER METHODS PRO
   [Anonymous], 2018, THESIS
   [Anonymous], 2018 40 ANN INT C IE
   [Anonymous], MED IMAGING 2016 COM
   Berg WA, 2010, JAMA-J AM MED ASSOC, V303, P168, DOI 10.1001/jama.2009.1993
   Bhooshan N, 2014, J MAGN RESON IMAGING, V39, P59, DOI 10.1002/jmri.24145
   Cady B, 2001, CANCER-AM CANCER SOC, V91, P1699, DOI 10.1002/1097-0142(20010501)91:9<1699::AID-CNCR1186>3.0.CO;2-W
   Cai HM, 2014, BMC CANCER, V14, DOI 10.1186/1471-2407-14-366
   Carneiro G, 2015, LECT NOTES COMPUT SC, V9351, P652, DOI 10.1007/978-3-319-24574-4_78
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Feig SA, 1998, AM J ROENTGENOL, V171, P29, DOI 10.2214/ajr.171.1.9648758
   Fonseca P, 2015, PROC SPIE, V9414, DOI 10.1117/12.2081576
   Gallego-Ortiz C, 2016, RADIOLOGY, V278, P679, DOI 10.1148/radiol.2015150241
   Gity M, 2017, J BREAST CANCER, V20, P116, DOI 10.4048/jbc.2017.20.1.116
   Gu Q, 2009, COMM COM INF SC, V51, P461, DOI 10.1007/978-3-642-04962-0_53
   Gubern-Mérida A, 2015, MED IMAGE ANAL, V20, P265, DOI 10.1016/j.media.2014.12.001
   Hamidinekoo A, 2018, MED IMAGE ANAL, V47, P45, DOI 10.1016/j.media.2018.03.006
   Hassanien AE, 2012, J APPL LOGIC, V10, P277, DOI 10.1016/j.jal.2012.07.003
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuhl C, 2007, RADIOLOGY, V244, P356, DOI 10.1148/radiol.2442051620
   Kuhl CK, 2014, J CLIN ONCOL, V32, P2304, DOI 10.1200/JCO.2013.52.5386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levy D., 2016, Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks, (Nips)
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mendelson E.B., 2013, ACR BI-RADS® Atlas, Breast Imaging Reporting and Data System
   Milenkovic J, 2013, ARTIF INTELL MED, V58, P101, DOI 10.1016/j.artmed.2013.03.002
   Prince J. L., 2006, Medical Imaging Signals and Systems
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Retter F, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-157
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shin JY, 2016, PROC CVPR IEEE, P2526, DOI 10.1109/CVPR.2016.277
   SICKLES EA, 1991, RADIOLOGY, V179, P463, DOI 10.1148/radiology.179.2.2014293
   SICKLES EA, 1991, CLIN IMAG, V15, P253, DOI 10.1016/0899-7071(91)90113-A
   Simonyan K., 2014, 14091556 ARXIV
   Smith RA, 2003, CA-CANCER J CLIN, V53, P27, DOI 10.3322/canjclin.53.1.27
   Soares F, 2014, IEEE SYST J, V8, P929, DOI 10.1109/JSYST.2013.2284101
   Spick C, 2018, EUR RADIOL, V28, P1919, DOI 10.1007/s00330-017-5127-y
   STAVROS AT, 1995, RADIOLOGY, V196, P123, DOI 10.1148/radiology.196.1.7784555
   Waugh SA, 2016, EUR RADIOL, V26, P322, DOI 10.1007/s00330-015-3845-6
   Weiss WA, 2014, MED PHYS, V41, DOI 10.1118/1.4851615
   Wollins DS, 2008, J ONCOL PRACT, V4, P18, DOI 10.1200/JOP.0813501
   Yang Q, 2015, MED PHYS, V42, P103, DOI 10.1118/1.4903280
   Yurttakal AH, 2018, IIOAB J, V9, P23
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 53
TC 42
Z9 42
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15555
EP 15573
DI 10.1007/s11042-019-7479-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900065
DA 2024-07-18
ER

PT J
AU Jia, Q
   Xu, WD
   Hu, JH
   Liu, J
   Yang, X
   Zhu, L
AF Jia, Qi
   Xu, Wei Dong
   Hu, Jiang Hua
   Liu, Jun
   Yang, Xin
   Zhu, Li Yan
TI Design and evaluation of digital camouflage pattern by spot combination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camouflage; Digital camouflage pattern; Spot combination; Saliency map
ID DISRUPTIVE COLORATION; CUTTLEFISH; CONTRAST
AB Traditional camouflage pattern painting is not effective enough due to development of the high-tech reconnaissance. The recently proposed digital pattern painting, a new form of camouflage pattern painting, which has better performance in countering reconnaissance. In this study, we present a novel design and evaluation of digital camouflage pattern based on spot combination. Firstly, we compared three clustering algorithms to extract dominant colors. At the meantime, on the basis of spot database, a spot combination algorithm is proposed to generate camouflage spot pattern. Finally, we evaluate its camouflage effect using saliency map based on human visual perception mechanism, as well as detection time. The herein proposed digital camouflage pattern can effectively blend with surrounding background, significantly prolong the detection time, and thus has a good camouflage effect.
C1 [Jia, Qi; Xu, Wei Dong; Hu, Jiang Hua; Liu, Jun; Yang, Xin; Zhu, Li Yan] Army Engn Univ PLA, Coll Field Engn, Nanjing, Peoples R China.
C3 Army Engineering University of PLA
RP Jia, Q; Xu, WD (corresponding author), Army Engn Univ PLA, Coll Field Engn, Nanjing, Peoples R China.
EM jiaqi1983@aliyun.com; xweibing1968@aliyun.com; hjhhbm@163.com;
   nanjnliujn@163.com; 1435227062@qq.com; zhuliyan0522@163.com
RI Li, Mengqi/AAG-6804-2021
FU China Postdoctoral Science Foundation [2017 M613328]; Natural Science
   Foundation of Jiangsu Province [BK20180579]; Equipment Pre-research Key
   Laboratory Fund [614220602010517]
FX We are appreciated to the funding supporting by China Postdoctoral
   Science Foundation (Grant No.2017 M613328), Natural Science Foundation
   of Jiangsu Province (Grant No. BK20180579), Equipment Pre-research Key
   Laboratory Fund (Grant No.614220602010517).
CR [Anonymous], 2009, MILITARY TECHNOLOGY, P71
   Buresch KC, 2015, J EXP MAR BIOL ECOL, V462, P121, DOI 10.1016/j.jembe.2014.10.017
   Chiao CC, 2005, BIOL BULL-US, V208, P7, DOI 10.2307/3593095
   Cott H., 1941, Adaptive Coloration in Animals
   Cuthill IC, 2005, NATURE, V434, P72, DOI 10.1038/nature03312
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Friskovec M, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.2.020507
   Friskovec M, 2010, FIBRES TEXT EAST EUR, V18, P68
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gonzalez-Bellido PT, 2018, ISCIENCE, V1, P24, DOI 10.1016/j.isci.2018.01.001
   Hepfinger Lisa., 2010, SOLDIER CAMOUFLAGE O
   Hogervorst MA, 2010, P SOC PHOTO-OPT INS, V7662, DOI 10.1117/12.850423
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Q, 2019, CLUSTER COMPUT, V22, pS9293, DOI 10.1007/s10586-018-2129-8
   Jia Qi, 2011, Journal of Applied Sciences, V29, P294, DOI 10.3969/j.issn.0255-8297.2011.03.013
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   [吕绪良 Lv Xuliang], 2005, [兵工学报, Acta Armamentarii], V26, P681
   Marshall NJ, 1996, NATURE, V382, P408, DOI 10.1038/382408b0
   Mäthger LM, 2006, VISION RES, V46, P1746, DOI 10.1016/j.visres.2005.09.035
   Merilaita S, 2005, P ROY SOC B-BIOL SCI, V272, P665, DOI 10.1098/rspb.2004.3000
   O'Neill TR, 1978, EVALUATION DUAL TEXT, Patent No. ADA056471
   Thayer Gerald, 1909, Concealing-coloration in the animal kingdom. An exposition of the laws of disguise through color and pattern: Being a summary of Abbott H. Thayer's discoveries
   Todd PA, 2009, J BIOL EDUC, V43, P81, DOI 10.1080/00219266.2009.9656156
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Wang W. G., 2020, ARXIV190409146
   [徐英 Xu Ying], 2007, [光电工程, Opto-Electronic Engineering], V34, P100
   Xue F, 2018, NEUROCOMPUTING, V274, P106, DOI 10.1016/j.neucom.2016.07.081
   Xue F, 2016, NEUROCOMPUTING, V172, P262, DOI 10.1016/j.neucom.2014.12.108
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zheng YF, 2019, IEEE SIGNAL PROC LET, V26, P29, DOI 10.1109/LSP.2018.2825959
   Zylinski S, 2009, P ROY SOC B-BIOL SCI, V276, P3963, DOI 10.1098/rspb.2009.1083
NR 31
TC 10
Z9 10
U1 3
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 22047
EP 22064
DI 10.1007/s11042-020-09002-5
EA MAY 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000533058600001
DA 2024-07-18
ER

PT J
AU Ariatmanto, D
   Ernawan, F
AF Ariatmanto, Dhani
   Ernawan, Ferda
TI An improved robust image watermarking by using different embedding
   strengths
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Different embedding strengths; Adaptive scaling factor; Embedding
   scheme; Extracting scheme; Image watermarking; Discrete cosine
   transforms
ID SINGULAR-VALUE DECOMPOSITION; INTEGER WAVELET TRANSFORM; DIGITAL
   WATERMARKING; DWT-SVD; SCHEME; DCT; EFFICIENT; PROTECTION; SYSTEM;
   INFORMATION
AB Image watermarking technique is an alternative solution to protecting digital image copyright. This paper proposed a new embedding technique based on different embedding strengths for embedding a watermark. An image is divided into non-overlapping blocks of 8 x 8 pixels. The variance pixel value was computed for each image block. Image blocks with the highest variance value were selected for the embedding regions. Therefore, it was transformed by discrete cosine transforms (DCT). Five DCT coefficients in the middle frequency were selected and the average of selected DCT blocks was calculated to generate different embedding strengths by using a set of rules. The watermark bits were embedded by using a set of embedding rules with the proposed different embedding strengths. For an additional security, the binary watermark was scrambled by using an Arnold Transform before it was embedded. The experimental results showed that the proposed scheme achieved a higher imperceptibility than the other existing schemes. The proposed scheme achieved a watermarked image quality with a PSNR value of 46 dB. The proposed scheme also produced a high watermark extracting resistance under various attacks.
C1 [Ariatmanto, Dhani] Univ AMIKOM Yogyakarta, Fac Comp Sci, Ring Rd Utara Condong Catur, Sleman 55283, Yogyakarta, Indonesia.
   [Ernawan, Ferda] Univ Malaysia Pahang, Fac Comp, Gambang 26300, Kuantan, Malaysia.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Ernawan, F (corresponding author), Univ Malaysia Pahang, Fac Comp, Gambang 26300, Kuantan, Malaysia.
EM ferda1902@gmail.com
RI Ariatmanto, Dhani/F-1862-2018; Ernawan, Ferda/B-4214-2012
OI Ariatmanto, Dhani/0000-0001-8877-9941; Ernawan,
   Ferda/0000-0002-6779-1594
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Ansari IA, 2015, P 4 INT C SOFT COMP, P209
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Chetan KR, 2015, J INF SECUR APPL, V24-25, P13, DOI 10.1016/j.jisa.2015.07.002
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dey N, 2014, J MED IMAG HEALTH IN, V4, P384, DOI 10.1166/jmihi.2014.1265
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   Ernawan F, 2017, Journal of Telecommunication, Electronic and Computer Engineering (JTEC), V9, P111
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Ernawan F, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P221, DOI 10.1109/CSPA.2018.8368716
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Ernawan F, 2016, J ICT RES APPL, V10, P228, DOI 10.5614/itbj.ict.res.appl.2016.10.3.3
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Giri KJ, 2017, STUD COMPUT INTELL, V660, P93, DOI 10.1007/978-3-319-44790-2_5
   Guo JH, 2019, MECH ADV MATER STRUC, V26, P1390, DOI 10.1080/15376494.2018.1432810
   Hien TD, 2006, ADV SOFT COMP, V34, P401, DOI 10.1007/3-540-31662-0_31
   Hsiao CY, 2018, MULTIMED TOOLS APPL, V77, P30419, DOI 10.1007/s11042-018-6121-3
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Kester QA, 2016, 17 UKSIM AMSS INT C, P322
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Manikandan VM, 2018, COMPUT ELECTR ENG, V72, P614, DOI 10.1016/j.compeleceng.2018.03.007
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Naseri M, 2017, OPTIK, V139, P77, DOI 10.1016/j.ijleo.2017.03.091
   Parekh M, 2018, ADV INTELL SYST, V710, P519, DOI 10.1007/978-981-10-7871-2_50
   Peng YW, 2018, MULTIMED TOOLS APPL, V77, P7239, DOI 10.1007/s11042-017-4631-z
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2017, ELECTRON COMMUN PROB, V22, DOI 10.1214/17-ECP3955
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Sui LS, 2017, OPT LASER ENG, V92, P85, DOI 10.1016/j.optlaseng.2017.01.003
   Sun L, 2018, NEURAL COMPUT APPL, V30, P2425, DOI 10.1007/s00521-016-2788-4
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Tomar R, 2015, ADV INTELL SYST, V338, P81, DOI 10.1007/978-3-319-13731-5_10
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
NR 56
TC 30
Z9 30
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12041
EP 12067
DI 10.1007/s11042-019-08338-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400035
DA 2024-07-18
ER

PT J
AU Hsu, CS
   Tu, SF
AF Hsu, Ching-Sheng
   Tu, Shu-Fen
TI Enhancing the robustness of image watermarking against cropping attacks
   with dual watermarks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Robust watermark; QR decomposition; Fragile
   watermark
ID COMPUTATIONALLY EFFICIENT; SECURE; SCHEME; REALIZATION; DOMAIN
AB In this study, a QR-based digital watermarking scheme that can use color images is proposed. The main purpose of this method is to enhance robustness against cropping attacks. To achieve this aim, each bit of the robust watermark has four copies, which are hidden in different image blocks. The embedding rule is designed based on the sinusoidal function, and the wavelength of the sinusoidal function controls the trade-off between imperceptibility and robustness. The four copies of the watermark bit may be inconsistent if the watermarked image undergoes cropping attacks. Therefore, after the four copies of the watermark bit are extracted, the actual value of the watermark bit is judged based on the result of the tampering detection. Experimental results indicate that improving robustness with the help of tampering detection results effectively assists in watermark extraction. In addition, the method is superior to other methods in terms of invisibility, robustness, and embedding payload.
C1 [Hsu, Ching-Sheng] Ming Chuan Univ, Dept Informat Management, 5 Deming Rd, Taoyuan 333, Taiwan.
   [Tu, Shu-Fen] Chinese Culture Univ, Dept Informat Management, 55 Huagang Rd, Taipei 11114, Taiwan.
C3 Ming Chuan University; Chinese Culture University
RP Tu, SF (corresponding author), Chinese Culture Univ, Dept Informat Management, 55 Huagang Rd, Taipei 11114, Taiwan.
EM dsf3@ulive.pccu.edu.tw
CR [Anonymous], 2013, P 3 INT C TRENDS INF, DOI DOI 10.1007/978-1-4614-3363-7_74
   [Anonymous], P 4 ACM INT WORKSH C
   [Anonymous], 2019, INT J ADV INTELL PAR
   [Anonymous], IM INF PROC ICIIP 20
   [Anonymous], WSEAS T MATH
   [Anonymous], LECT NOTES ELECT ENG
   [Anonymous], 2017, P 9 INT C COMP AUT E
   [Anonymous], DIGITAL WATERMARKING
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Kutter M, 2000, ART H COMP SCI LIBR, P97
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Parah SA, 2017, J GLOB INF MANAG, V25, P80, DOI 10.4018/JGIM.2017100106
   Parah SA, 2017, INTEL SYST REF LIBR, V115, P223, DOI 10.1007/978-3-319-44270-9_10
   Parah SA, 2017, INT J ELECTRON, V104, P659, DOI 10.1080/00207217.2016.1242162
   Schlauweg M, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORK, AND INFORMATION SECURITY, P1
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   University of Granada, 2012, CVG UGR IM DAT
   Wang DY, 2016, J INF PROCESS SYST, V12, P765, DOI 10.3745/JIPS.03.0055
   Wang Y, 2017, LECT NOTES COMPUT SC, V10431, P163, DOI 10.1007/978-3-319-64185-0_13
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 27
TC 22
Z9 22
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11297
EP 11323
DI 10.1007/s11042-019-08367-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LJ2WK
UT WOS:000530029800002
DA 2024-07-18
ER

PT J
AU Kansal, I
   Kasana, SS
AF Kansal, Isha
   Kasana, Singara Singh
TI Improved color attenuation prior based image de-fogging technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dehazing; De-fogging; Enhancement; CAP; Transmission; Atmospheric light;
   Brightness; Saturation
ID ENHANCEMENT ALGORITHM
AB Single image de-fogging has been a confronting problem due to its ill-posed nature. In this paper, a de-fogging technique based upon color attenuation prior (CAP) has been proposed. CAP uses linear model and learning the parameters of this model with a supervised learning method for estimating the scene depth of a foggy image. This depth map is utilized for transmission map estimation. Transmission (t) is one of the important parameter of physical model based de-fogging techniques which describes the portion of the light coming from the scene point that is not scattered and reaches the camera. It is a map called transmission or transparency of the fog 0 < t(x) < 1, t(x) = 0 means completely foggy, t(x) = 1 means fog-free. The more accurately the transmission or depth is estimated, the better the defogging performance will be. In the proposed work, to quickly and accurately estimate the transmission map, a sub-sampling based local minimum operation and fast gradient domain guided image filtering (GDGF) is applied on CAP based initial depth map. The edge attentive restraints of GDGF make edges to be conserved better in the de-fogged images. The de-fogged images obtained by CAP technique suffer from dullness and higher illumination variations due to consideration of fog image degradation model in homogeneous environment and a constant value of atmospheric light. Such variations are removed in the proposed work by using Lambert's law of illumination reflection, which helps to compensate non uniform illumination, causes simultaneous dynamic range modification, color consistency, and lightness rendition without producing the artifacts in a de-fogged image. To improve the processing speed, image sub-sampling mechanism is used in various steps of image de-fogging. The sub-sampling is used in such a way that the quality of the output at any step is not compromised as demonstrated through various quality parameters. Experimental results show that the proposed approach outperforms state-of-the-art fog removal techniques in terms of efficiency and the de-fogging effect.
C1 [Kansal, Isha; Kasana, Singara Singh] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kansal, I (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
EM isha.kansal@thapar.edu; singara@thapar.edu
RI Kansal, Isha/KJL-7828-2024
OI Kansal, Isha/0000-0002-6681-9612
CR [Anonymous], IEEE WORKSH COL PHOT
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2008, P IEEE C COMP VIS PA
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cheng FC, 2012, ELECTRON LETT, V48, P1404, DOI 10.1049/el.2012.2737
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Economopoulos TL, 2010, IMAGE VISION COMPUT, V28, P45, DOI 10.1016/j.imavis.2009.04.011
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   He K, 2015, ARXIVABS150500996 CO
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Kansal I, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500546
   Kansal I, 2018, J MOD OPTIC, V65, P2103, DOI 10.1080/09500340.2018.1499976
   Kansal I, 2017, J MOD OPTIC, V64, P2023, DOI 10.1080/09500340.2017.1333641
   Kaplan NH, 2017, SIGNAL IMAGE VIDEO P, V11, P1389, DOI 10.1007/s11760-017-1097-4
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Meng G., 2013, P IEEE INT C COMP VI
   Narasimhan SG, 2000, P IEEE C COMP VIS PA, V1
   Nayar SK, 1999, P 7 IEEE INT C COMP
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NS, 2018, IETE TECH REV, V35, P223, DOI 10.1080/02564602.2016.1276868
   Ren Wenqi, 2016, P EUR C COMP VIS
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2001, P IEEE C COMP VIS PA, V1
   Shi ZW, 2014, OPTIK, V125, P3868, DOI 10.1016/j.ijleo.2014.01.170
   Shiau YH, 2014, J VIS COMMUN IMAGE R, V25, P445, DOI 10.1016/j.jvcir.2013.12.011
   Shwartz S, 2006, P IEEE C COMP SOC, V2
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sun W, 2014, J MOD OPTIC, V61, P466, DOI 10.1080/09500340.2014.897387
   Tarel JP, 2009, P 12 IEEE INT C COMP
   Wang Z, 2014, COMPUT ELECTR ENG, V40, P785, DOI 10.1016/j.compeleceng.2013.06.009
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xie CH, 2017, SIGNAL IMAGE VIDEO P, V11, P705, DOI 10.1007/s11760-016-1013-3
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yang Dong, 2018, P EUR C COMP VIS
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 41
TC 17
Z9 18
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12069
EP 12091
DI 10.1007/s11042-019-08240-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400036
DA 2024-07-18
ER

PT J
AU Sidhu, RK
   Kumar, R
   Rana, PS
AF Sidhu, Ravneet Kaur
   Kumar, Ravinder
   Rana, Prashant Singh
TI Machine learning based crop water demand forecasting using minimum
   climatological data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support vector regressor; Decision tree; Random forest; Drip irrigation;
   Crop water demand; Irrigation scheduling; Weather
ID DECISION-SUPPORT-SYSTEM; SOIL-WATER; POTENTIAL ESTIMATION; IRRIGATION;
   MODEL; EVAPOTRANSPIRATION; PRODUCTIVITY; STRATEGIES; YIELD
AB Rice is one of the world's most popular food crops. Since its production is dependent on intensive water use, water management is critical to ensure sustainability of water resource. However, very limited data is available on water use in rice irrigation. In the present study, traditional machine learning methods have been used to predict the irrigation schedule of rice daily. The data of year 2013-2015 is used to train the models and to further optimise it. The data of 2016-2017 is used for testing the models. Correlation thresholds are used for feature selection which helps in reducing the number of input parameters from the initial 26 to final 11. The models estimated the crop water demand as a function of weather parameters. Results show that Adaboost performed consistently well with an average accuracy of 71% as compared to other models for predicting the irrigation schedule.
C1 [Sidhu, Ravneet Kaur; Kumar, Ravinder; Rana, Prashant Singh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Sidhu, RK (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM rksidhu37@gmail.com; ravinder@thapar.edu; psrana@gmail.com
RI Rana, Prashant Singh/AAE-1784-2019; Kumar, Dr. Ravinder/ACH-7233-2022;
   Kumar, Ravinder/JLL-7567-2023
OI Rana, Prashant Singh/0000-0002-0142-7925; Kumar, Dr.
   Ravinder/0000-0001-5294-9646; Kumar, Ravinder/0000-0002-0271-2373
CR Abdullah SS, 2015, J HYDROL, V527, P184, DOI 10.1016/j.jhydrol.2015.04.073
   Abrisqueta I, 2015, COMPUT ELECTRON AGR, V114, P7, DOI 10.1016/j.compag.2015.03.004
   Ahlawat IPS., 1993, Agronomic terminology, V3rd ed
   Amer K. H., 2016, Journal of Water Resource and Protection, V8, P277, DOI 10.4236/jwarp.2016.83024
   Andriyas S, 2013, ENVIRON MODELL SOFTW, V47, P207, DOI 10.1016/j.envsoft.2013.05.011
   [Anonymous], 1965, 19 S SOC EXP BIOL
   [Anonymous], 2009, MANAGEMENT
   [Anonymous], 1998, CROP EVAPOTRANSPIRAT
   BAUSCH WC, 1987, T ASAE, V30, P703
   Belder P, 2004, AGR WATER MANAGE, V65, P193, DOI 10.1016/j.agwat.2003.09.002
   Campos I, 2016, AGR WATER MANAGE, V165, P141, DOI 10.1016/j.agwat.2015.11.018
   Djaman K, 2017, PADDY WATER ENVIRON, V15, P469, DOI 10.1007/s10333-016-0564-9
   El-Magd IA, 2005, INT J REMOTE SENS, V26, P2359, DOI 10.1080/0143116042000298261
   Garg KK, 2009, AGR WATER MANAGE, V96, P1705, DOI 10.1016/j.agwat.2009.06.018
   Giusti E, 2015, ENVIRON MODELL SOFTW, V63, P73, DOI 10.1016/j.envsoft.2014.09.020
   Perea RG, 2019, COMPUT ELECTRON AGR, V157, P173, DOI 10.1016/j.compag.2018.12.043
   Goumopoulos C, 2014, COMPUT ELECTRON AGR, V105, P20, DOI 10.1016/j.compag.2014.03.012
   Hargreaves G. H., 1985, Applied Engineering in Agriculture, V1, P96
   JENSEN ME, 1971, T ASAE, V14, P954, DOI 10.13031/2013.38430
   Jones HG, 2004, J EXP BOT, V55, P2427, DOI 10.1093/jxb/erh213
   Karandish F, 2016, J HYDROL, V543, P892, DOI 10.1016/j.jhydrol.2016.11.007
   Khan MA., 2011, J RES PRACT INF TECH, V43, P1
   Kukal SS, 2005, IRRIGATION SCI, V23, P153, DOI 10.1007/s00271-005-0103-8
   Maton L, 2005, AGR SYST, V86, P293, DOI 10.1016/j.agsy.2004.09.010
   Mimi Z, 2000, WATER INT, V25, P464, DOI 10.1080/02508060008686854
   Navarro-Hellín H, 2016, COMPUT ELECTRON AGR, V124, P121, DOI 10.1016/j.compag.2016.04.003
   Ojha T, 2015, COMPUT ELECTRON AGR, V118, P66, DOI 10.1016/j.compag.2015.08.011
   PENMAN HL, 1948, PROC R SOC LON SER-A, V193, P120, DOI 10.1098/rspa.1948.0037
   Pulido-Calvo I, 2009, BIOSYST ENG, V102, P202, DOI 10.1016/j.biosystemseng.2008.09.032
   Saleem S. K., 2013, IFAC P, V2013, P299, DOI [DOI 10.3182/20130828-2-SF-3019.00062, 10.3182/20130828-2-SF-3019. 00062]
   Sreekanth M. S., 2015, Journal of Applied Sciences, V15, P153, DOI 10.3923/jas.2015.153.156
   Steduto P, 2009, AGRON J, V101, P426, DOI 10.2134/agronj2008.0139s
   Steppe K, 2008, IRRIGATION SCI, V26, P505, DOI 10.1007/s00271-008-0111-6
   Timsina J, 2001, FIELD CROP RES, V69, P93, DOI 10.1016/S0378-4290(00)00143-X
   Torres AF, 2011, AGR WATER MANAGE, V98, P553, DOI 10.1016/j.agwat.2010.10.012
   Valdés-Vela M, 2015, COMPUT ELECTRON AGR, V115, P150, DOI 10.1016/j.compag.2015.05.019
   Yadav S, 2011, FIELD CROP RES, V122, P104, DOI 10.1016/j.fcr.2011.03.004
NR 37
TC 10
Z9 10
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13109
EP 13124
DI 10.1007/s11042-019-08533-w
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700016
DA 2024-07-18
ER

PT J
AU Martin, PE
   Benois-Pineau, J
   Péteri, R
   Morlier, J
AF Martin, Pierre-Etienne
   Benois-Pineau, Jenny
   Peteri, Renaud
   Morlier, Julien
TI Fine grained sport action recognition with Twin spatio-temporal
   convolutional neural networks Application to table tennis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Spatio-temporal convolutions; Two Stream neural
   network; Sport video analysis
AB Human action recognition in video is one of the key problems in visual data interpretation. Despite intensive research, the recognition of actions with low inter-class variability remains a challenge. This paper presents a new Twin Spatio-Temporal Convolutional Neural Network (TSTCNN) for this purpose. When applied to table tennis, it is possible to detect and recognize 20 table tennis strokes. The model has been trained on a specific dataset, so called TTStroke-21, recorded in natural conditions at the Faculty of Sports of the University of Bordeaux. Our model takes as inputs an RGB image sequence and its computed Optical Flow. The proposed Twin architecture is a two stream network both comprising 3 spatio-temporal convolutional layers, followed by a fully connected layer where data are fused. Our method reaches an accuracy of 91.4% against 43.1% for our baseline, a Two-Stream Inflated 3D ConvNet (I3D).
C1 [Martin, Pierre-Etienne; Benois-Pineau, Jenny] Univ Bordeaux, LaBRI, Talence, France.
   [Peteri, Renaud] Univ La Rochelle, MIA, La Rochelle, France.
   [Morlier, Julien] Univ Bordeaux, IMS, Talence, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); La Rochelle Universite; Universite de Bordeaux
RP Martin, PE (corresponding author), Univ Bordeaux, LaBRI, Talence, France.
EM pierre-etienne.martin@u-bordeaux.fr; jenny.benois-pineau@u-bordeaux.fr;
   renaud.peteri@univ-lr.fr; julien.morlier@u-bordeaux.fr
RI Benois-Pineau, Jenny/ABG-6325-2020; Martin,
   Pierre-Etienne/AAB-6739-2021; PETERI, Renaud/AAT-6771-2021
OI Benois-Pineau, Jenny/0000-0003-0659-8894; Martin,
   Pierre-Etienne/0000-0002-9593-4580; 
FU CRISP project of the Nouvelle-Aquitaine Region and Bordeaux IDEX
   Initiative
FX This work was supported by the CRISP project of the Nouvelle-Aquitaine
   Region and Bordeaux IDEX Initiative
CR Ahmadi A, 2015, IEEE INTERNET THINGS, V2, P23, DOI 10.1109/JIOT.2014.2377238
   [Anonymous], 2017, ARXIV170508421
   [Anonymous], 2016, ABS161200738 CORR
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Debard Q, 2018, IEEE INT CONF AUTOMA, P114, DOI 10.1109/FG.2018.00026
   Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kay W., 2017, ARXIV170506950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li ZH, 2016, IEEE IMAGE PROC, P3056, DOI 10.1109/ICIP.2016.7532921
   Liu Ce, 2009, THESIS
   Martí P, 2019, COMPUT ENVIRON URBAN, V74, P161, DOI 10.1016/j.compenvurbsys.2018.11.001
   Martin PE, 2019, IEEE IMAGE PROC, P554, DOI [10.1109/ICIP.2019.8803780, 10.1109/icip.2019.8803780]
   Martin PE, 2019, IEEE IMAGE PROC, P3027, DOI [10.1109/ICIP.2019.8803382, 10.1109/icip.2019.8803382]
   Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269, P543
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Noiumkar S, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P310, DOI 10.1109/ICICM.2013.58
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stoian A, 2016, IEEE T CIRC SYST VID, V26, P1917, DOI 10.1109/TCSVT.2015.2475835
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 32
TC 30
Z9 31
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20429
EP 20447
DI 10.1007/s11042-020-08917-3
EA APR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000527468000001
DA 2024-07-18
ER

PT J
AU Farzana, MF
   Valarmathi, A
AF Farzana, Faleela M.
   Valarmathi, A.
TI Secure architecture to circumvent collision using RSSI measurement in
   WSN: a cross layer design approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collision avoidance; Cross layer design; Energy conservation; Security;
   Wireless sensor networks
ID CONGESTION CONTROL; WIRELESS; PROTOCOL; MAC
AB 'Wireless sensor networks' (WSNs) follow layered architecture for the fruitful and reliable working of distributed WSNs. The region of WSN is attaining importance in the research field on account of its wide-ranging scope of applications in different domains. The CLD (cross-layer design) is a rising trend in the network layer architectures. And it normally involves significant connections between disparate layers. This paper manages CLD instead of single layer in order to attain good performance. Collision amid packet transmission is the chief issues that directly influence the performance and lifetime of distributed WSNs. This present model specifically provided a secure solution to avoid collision utilizing cross-layer in WSNs. For the foremost time, the transport layer was chosen as a primary platform for the calculation of RSSI ('received signal strength indicator') values to enrich cross-layer interaction. Effectively, this sort of selection in the order of nodes bypasses the collision in packet transmission and hence extends the network lifetime by avoiding transmission failure.
C1 [Farzana, Faleela M.; Valarmathi, A.] Anna Univ, Dept Comp Applicat, BIT Campus, Tiruchirappalli, India.
C3 Anna University; Anna University of Technology Tiruchirappalli
RP Farzana, MF (corresponding author), Anna Univ, Dept Comp Applicat, BIT Campus, Tiruchirappalli, India.
EM faleelamubarak@gmail.com
OI A, valarmathi/0000-0002-7293-7922
CR Ahmed AM, 2017, WIREL NETW, V23, P881, DOI 10.1007/s11276-015-1151-5
   [Anonymous], 2016, WIRELESS SENSOR NETW
   [Anonymous], 2006, A survey of security issues in wireless sensor networks
   Bahadori-Jahromi F, 2017, WIREL NETW, V23, P2361, DOI 10.1007/s11276-016-1292-1
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Bansal RK, 2010, GLOBAL J COMPUTER SC, V10, P67
   Farzana MF, 2015, INT J APPL ENG RES, V10, P21143
   Ferrara D, 2005, IEEE INFOCOM SER, P1770
   Gupta M, 2012, APEEJAY J COMPUTER S
   Holland M, 2011, ACM T SENSOR NETWORK, V7, DOI 10.1145/1921621.1921622
   Iala I., 2017, IEEE INT C ADV TECHN, P1
   Javaid S, 2018, MULTIMED TOOLS APPL, V77, P4433, DOI 10.1007/s11042-016-4224-2
   Kafi MA, 2017, COMPUT COMMUN, V101, P1, DOI 10.1016/j.comcom.2016.05.018
   Kaur N., 2014, International Journal of Advanced Engineering Technology, VV, P34
   Liew SY, 2018, IEEE COMPUT INTELL M, V13, P30, DOI 10.1109/MCI.2017.2773800
   Nikose Mr. M. D, 2013, INT J EMERGING TREND, V02, P7
   Oguejiofor O., 2013, INT J INNOVATIVE TEC, V2, P1
   Öztürk C, 2012, TURK J ELECTR ENG CO, V20, P255, DOI 10.3906/elk-1101-1030
   Padmavathi Dr.G., 2009, A Survey of Attacks, Security Mechanisms and Challenges in Wireless Sensor Networks
   Panda M., 2013, INT J ADV RES COMPUT, V3, P61
   Patel JS, INT J COMPUTER SCI E, P258
   Puri S, 2012, INT J INF TECHNOL CO, V4, P45, DOI DOI 10.5815/ijitcs.2012.06.07
   Radja P, OVERVIEW WIRED WIREL
   Sahoo PK, 2017, J NETW COMPUT APPL, V80, P10, DOI 10.1016/j.jnca.2016.12.020
   Sastry Anitha S., 2013, International Journal of Advanced Networking and Applications, V4, P1657
   Saxena M, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P503, DOI 10.1109/COMSWA.2008.4554465
   Selvaraju E, 2018, ADV INTELL SYST, V628, P237, DOI 10.1007/978-981-10-5272-9_23
   Sharma K, 2011, INT J SECUR APPL, V5, P39
   Sundaram BA, 2013, CURR SCI INDIA, V104, P1496
   Thamilarasu G, 2009, CROSS LAYER DESIGNS
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
NR 31
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8969
EP 8984
DI 10.1007/s11042-018-6780-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600031
DA 2024-07-18
ER

PT J
AU Yang, XJ
   Chen, P
AF Yang, XiuJie
   Chen, Ping
TI Person re-identification based on multi-scale convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Evaluation methods; Feature representation;
   Real application
ID PEDESTRIAN RECOGNITION
AB Person re-identification (re-ID) has become increasingly popular in the community due to its application and research significance. In the early days, hand-crafted algorithms and small-scale evaluation were predominantly reported. Recently, with the success of deep learning methods on many computer vision tasks, researchers started to put their focuses on learning high-performance features. In this paper, we propose a method by fusing features learned from a multi-scale convolutional neural network and the traditional hand-crafted features, which improves the performance significantly. The Shinpuhkan2014dataset has been selected as the training data, and we compare the proposed method on VIPeR, PRID, iLIDS and CUHK03 datasets. The experimental results show that the performance of the proposed method is superior to the current methods which have a training step on the testing sets.
C1 [Yang, XiuJie] Chongqing Coll Elect Engn, Digital Media Coll, Chongqing 401331, Peoples R China.
   [Chen, Ping] Chongqing Coll Elect Engn, Gen Educ & Int Coll, Chongqing, Peoples R China.
C3 Chongqing College of Electronic Engineering; Chongqing College of
   Electronic Engineering
RP Yang, XJ (corresponding author), Chongqing Coll Elect Engn, Digital Media Coll, Chongqing 401331, Peoples R China.
EM 8331772@qq.com
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Bazzani L., 2010, INT C PATT REC, P1413, DOI [DOI 10.1109/ICPR.2010.349, 10.1109/ICPR.2010.349]
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Davis J. V., 2007, ICML, P209
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Globerson A., 2005, ADV NEURAL INFORM PR
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu Y, 2013, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2013.119
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu Y, 2012, INT CONF INTELL SYST, P884, DOI 10.1109/ISDA.2012.6416655
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Prosser Bryan., 2010, BMVC, V1, P5
   SIMPSON DG, 1987, J AM STAT ASSOC, V82, P802, DOI 10.2307/2288789
   Taigman Y, 2014, C COMP VIS PATT REC
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xing E. P., 2002, NEURIPS, P505
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 42
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9299
EP 9313
DI 10.1007/s11042-019-7387-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600053
DA 2024-07-18
ER

PT J
AU Ali, TS
   Ali, R
AF Ali, Tahir Sajjad
   Ali, Rashid
TI A new chaos based color image encryption algorithm using permutation
   substitution and Boolean operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Logistic map; Piece-wise linear chaotic map; S-box
AB A new color image encryption algorithm is proposed by using chaotic maps. Cipher image is constructed in three phases. In the first phase permutation of digital image is performed with the help of a chaotic map. The second phase uses chaotic substitution box for pixel substitution and finally in the third phase a Boolean operator XOR is used for mixing chaotic logistic based random sequence. Chaotic maps have main role in this encryption. Chaos theory, due to its randomness and unpredictable behaviors, is known as favorite for the purpose of image encryption. The RGB components of image scrambled by permutation-substitution and Boolean operation, show good results for security and performance analysis. Different tests of security analysis like key space, key sensitivity, correlation analysis, entropy, histogram analysis, number of pixel change rate (NPCR) and unified average changing intensity (UACI) tests are employed on the proposed scheme. On the basis of these tests, we believe that proposed scheme is well suited for practical applications.
C1 [Ali, Tahir Sajjad; Ali, Rashid] Capital Univ Sci & Technol, Islamabad, Pakistan.
C3 Capital University of Science & Technology
RP Ali, TS (corresponding author), Capital Univ Sci & Technol, Islamabad, Pakistan.
EM tahir.sajjad@cust.edu.pk
OI Ali, Tahir Sajjad/0000-0002-1262-9426; Ali, Rashid/0000-0002-4952-6199
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2019, IEEE T CIRCUITS SYST
   Asim M, 2008, ETRI J, V30, P170, DOI 10.4218/etrij.08.0207.0188
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   DHALL S, 2018, J KING SAUD U COMPUT
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hrestak D, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1400, DOI 10.1109/MIPRO.2014.6859786
   Knudsen R. A. E. B. L., 1998, 1 ADV ENCR STAND AES
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   LORENZ EN, 1969, J ATMOS SCI, V26, P636, DOI 10.1175/1520-0469(1969)26<636:APARBN>2.0.CO;2
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Luo YL, 2018, IEEE ACCESS, V6, P77740, DOI 10.1109/ACCESS.2018.2884013
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Markus M, 1998, CHAOS AND FRACTALS: A COMPUTER GRAPHICAL JOURNEY, P73, DOI 10.1016/B978-044450002-1/50015-1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh P, 2011, INT J ADV COMPUT SC, V2, P126
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Thiyagarajan J., 2019, Serb. J. Electr. Eng, V16, P247, DOI [10.2298/SJEE1902247T, DOI 10.2298/SJEE1902247T]
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 33
TC 60
Z9 61
U1 4
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19853
EP 19873
DI 10.1007/s11042-020-08850-5
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522711000002
DA 2024-07-18
ER

PT J
AU Cegar, DD
   Barreda-Angeles, M
   Kukolj, D
   Le Callet, P
AF Cegar, Dragana Dordevic
   Barreda-Angeles, Miguel
   Kukolj, Dragan
   Le Callet, Patrick
TI Modelling effects of S3D visual discomfort in human emotional state
   using data mining techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience; Artificial neural network; Multilayer perception;
   Machine learning; Data mining; Heart rate; Electro-dermal activity;
   Electro-encephalogram; Self-assessment manikin; Emotional state; S3D
   video; Content recommendation; Visual discomfort
ID STRESS
AB In recent years, the rapid development of diverse media has been evident in disparate fields such as consumer electronics, automotive infotainment and healthcare software. There is a need for innovative methods to assess user perceived Quality of Experience (QoE), as a proxy for consumer satisfaction with such systems and services. Users emotional state plays a key role in QoE; thus, it is necessary to consider it in user experience evaluation and the design process of stereoscopic 3D video content. In the present article we introduce the use of a specially designed model based on a feedforward Multilayer Perception Artificial Neural Network as an appropriate Machine Learning technique for the estimation of human emotional state while viewing various categories of stereoscopic 3D video content. The goal is to design an emotional state estimator based on direct psychophysiological measurements. The considered psychophysiological signals include heart rate (HR) calculated from an echocardiogram (ECG), electro-dermal activity (EDA), and brain activity (BA) in EEG signals. Participants watched a series of 3D video contents varying in terms of visual quality, while the mentioned psychophysiological signals were recorded, and self-reported subjectively experienced emotions using a Self-Assessment Manikin (SAM) questionnaire. The obtained results show that it is possible to construct such a highly precise estimator of emotional states.
C1 [Cegar, Dragana Dordevic] RT RK Inst Comp Based Syst, Novi Sad, Serbia.
   [Barreda-Angeles, Miguel] Eurecat Technol Ctr Catalonia, Barcelona, Spain.
   [Kukolj, Dragan] Univ Novi Sad, Fac Tech Sci, Novi Sad, Serbia.
   [Le Callet, Patrick] IRCCyN Inst Rech Commun & Cybernet Nantes, Nantes, France.
C3 University of Novi Sad
RP Cegar, DD (corresponding author), RT RK Inst Comp Based Syst, Novi Sad, Serbia.
EM dragana.djordjevic.cegar@rt-rk.com; miguel.barreda@eurecat.org;
   dragan.kukolj@rt-rk.uns.ac.rs; patrick.le-callet@univ-nantes.fr
RI Kukolj, Dragan/JUU-6299-2023; Le Callet, Patrick/F-5772-2010;
   Barreda-Ángeles, Miguel/AAX-4359-2020
OI Kukolj, Dragan/0000-0003-0711-0168; Barreda-Ángeles,
   Miguel/0000-0002-5056-7633
CR [Anonymous], QUALINET WHITE PAPER
   Barreda-Angeles M, 2014, IEEE IMAGE PROC, P753, DOI 10.1109/ICIP.2014.7025151
   Berne RM, 2000, PRINCIPALS PHYSL
   Boucsein W., 1992, Electrodermal activity, DOI [10.1007/978-1-4757-5093-5, DOI 10.1007/978-1-4757-5093-5]
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cernea D., 2011, P IRTG 1131 WORKSH V, V27, P113
   Chung L, 2005, C P ANN INT C IEEE E, V5, P5523
   Costadopoulos N, 2019, P 18 INT C MACH LEAR, P468
   Dabas H, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (CSAI 2018) / 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY (ICIMT 2018), P380, DOI 10.1145/3297156.3297177
   Dawson M.E., 2000, HDB PSYCHOPHYSIOLOGY
   Devi T., 2012, INT J COMPUTER APPL, V48, DOI [10.5120/7358-0095, DOI 10.5120/7358-0095]
   Dordevi egar D, 2013, 21 TEL FOR TELFOR TE, P765, DOI [0.1109/TELFOR.2013.6716342, DOI 10.1109/TELFOR.2013.6716342]
   Drachen A., 2010, Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games, P49, DOI DOI 10.1145/1836135.1836143
   Durairaj M., 2014, INT J INNOVATIVE RES, V2, P6457
   Eibe F., 2016, The WEKA Workbench. Online Appendix for Data Mining: Practical Machine Learning Tools and Techniques, V4th ed.
   FELDMAN LA, 1995, J PERS SOC PSYCHOL, V69, P153, DOI 10.1037/0022-3514.69.1.153
   Greene S, 2016, IEEE CONSUM ELECTR M, V5, P44, DOI 10.1109/MCE.2016.2590178
   Harmon-Jones E, 2012, SOC PERSONAL PSYCHOL, V6, P314, DOI 10.1111/j.1751-9004.2012.00432.x
   Holzinger A., 2013, International Conference on Availability, Reliability, and Security, P469, DOI DOI 10.1007/978
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kim A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P601, DOI 10.1109/VR.2018.8446046
   Kim HS, 2019, IEEE T INTELL TRANSP, V20, P1215, DOI 10.1109/TITS.2018.2848300
   Kivikangas JM, 2011, J GAMING VIRTUAL WOR, V3, P181, DOI 10.1386/jgvw.3.3.181_1
   Klotzsche F, 2018, IEEE C VIRT REAL, DOI [10.1109/VR.2018.8446275, DOI 10.1109/VR.2018.8446275]
   Koelstra S, 2011, IEEE T AFFECTIVE COM
   Kukolj D, 2013, INT SYMP COMP INTELL, P125, DOI 10.1109/CINTI.2013.6705177
   Kwon M, 2013, INT WINT WORKSH BR, P67, DOI 10.1109/IWW-BCI.2013.6506633
   Lang A, 2009, COMMUN SER, P185
   Lang P., 2007, Handbook of emotion elicitation and assessment, V29, P70, DOI DOI 10.1037/0021-9010.69.1.85
   Lin CT, 2005, IEEE T CIRCUITS-I, V52, P2726, DOI 10.1109/TCSI.2005.857555
   Lisetti CL, 2004, EURASIP J APPL SIG P, V2004, P1672, DOI 10.1155/S1110865704406192
   Mäki T, 2013, INT WORK QUAL MULTIM, P6, DOI 10.1109/QoMEX.2013.6603193
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Michael S, 2011, P 6 INT DRIV S HUM F, V6, P31, DOI [10.17077/drivingassessment.1374, DOI 10.17077/DRIVINGASSESSMENT.1374]
   Millán JD, 2002, IEEE T NEURAL NETWOR, V13, P678, DOI 10.1109/TNN.2002.1000132
   Miranda-Correa Juan Abdon., 2017, Amigos: A dataset for affect, personality and mood research on individuals and groups
   Ooi JSK, 2016, IEEE EMBS CONF BIO, P365, DOI 10.1109/IECBES.2016.7843475
   Ravaja N, 2004, MEDIA PSYCHOL, V6, P193, DOI 10.1207/s1532785xmep0602_4
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Stickel C., 2011, ACM C REC SYST CHIC
   Stickel C, 2010, LECT NOTES COMPUT SC, V6389, P278
   Stickel C, 2009, LECT NOTES COMPUT SC, V5614, P615, DOI 10.1007/978-3-642-02707-9_70
   Sun HY, 2015, INT J SECUR APPL, V9, P125, DOI 10.14257/ijsia.2015.9.6.13
   Swangnetr M, 2013, IEEE T HUM-MACH SYST, V43, P63, DOI 10.1109/TSMCA.2012.2210408
   Thayer JF, 2012, NEUROSCI BIOBEHAV R, V36, P747, DOI 10.1016/j.neubiorev.2011.11.009
   Wang CH, 2016, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS FOR SCIENCE AND ENGINEERING (IEEE-ICAMSE 2016), P512, DOI 10.1109/ICAMSE.2016.7840185
   Watanabe I, 2018, P INT COMP SOFTW APP, P589, DOI 10.1109/COMPSAC.2018.10301
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Yang B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P156, DOI 10.1109/ROBIO.2018.8665247
NR 50
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19803
EP 19829
DI 10.1007/s11042-020-08844-3
EA MAR 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522592200003
DA 2024-07-18
ER

PT J
AU Kim, JC
   Chung, KY
AF Kim, Joo-Chang
   Chung, Kyung-Yong
TI Knowledge expansion of metadata using script mining analysis in
   multimedia recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Data mining; Knowledge discovery; Recommendation; Metadata
ID ALGORITHM
AB In this paper, a method for knowledge expansion of metadata using script mining analysis for multimedia recommendation systems is proposed. The method allows the extraction of new metadata and knowledge expansion through the mining analysis of multimedia scripts, which include a large amount of information. The scripts are collected by a Web crawler based on Python. From the collected scripts, hidden information is extracted through keyword analysis and sentiment analysis. In keyword analysis, scripts, unlike general documents, show a high frequency of names of characters or proper nouns. Such names or proper nouns are not frequently used in other media content, and therefore, their importance is high. Frequently, they are already offered in the conventional metadata, and consequently cause information duplication. Accordingly, term frequency-inverse document and metadata frequency (TF-IDMF), which considers the frequency of metadata in general term frequency-inverse document frequency (TF-IDF), is used. Thus, the importance of the names of characters or proper nouns in scripts can be decreased. Because the keywords for the extracted scripts are in fact included in the scripts, they can be used for precise multimedia search and recommendation. In sentiment analysis, the AFINN lexicon and the Bing lexicon are utilized to scan words in a script. The Bing lexicon is used to examine whether the words in the entire script are positive or negative. Then, the total numbers of positive words and negative words are used to calculate the representative sentiment of the script. The AFINN lexicon includes approximately 170 sentiment words, the negative or positive sentiment of which is presented in the range - 5 to +5. One script is divided into 100 sentences, and then, the representative sentiment in each sentence is evaluated as either positive or negative. Through script scanning, the flow of sentiment in multimedia streams can be discovered. The Bing lexicon categorizes words into positive, negative, and neutral sentiments. Through script scanning, the words included in each category can be quantified. Depending on the result of the script sentiment analysis, a different sentence embedding method based on inter-sentence similarity is used to cluster similar media. The results of the keyword analysis and sentiment analysis of a script are added to the metadata in a new column in a knowledge base to expand knowledge. To evaluate the significance of multimedia recommendations, keywords and sentiment information are used, and then, the similarity and clustering of the extracted media are assessed. As a result, script mining analysis based on the attributes that include actual information of media is considerably better than that based on types or a range of metadata attributes. Therefore, the proposed knowledge expansion method achieves significant results and shows an excellent performance in multimedia recommendation.
C1 [Kim, Joo-Chang] Kyonggi Univ, Dept Comp Sci, Data Min Lab, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
   [Chung, Kyung-Yong] Kyonggi Univ, Div Comp Sci & Engn, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
C3 Kyonggi University; Kyonggi University
RP Chung, KY (corresponding author), Kyonggi Univ, Div Comp Sci & Engn, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
EM kjc2232@naver.com; kyungyong.chung@gmail.com
RI Joochang, Kim/AAB-4892-2021; Chung, Kyungyong/JAC-2276-2023
OI Chung, Kyungyong/0000-0002-6439-9992
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2018-0-01405]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2018-0-01405) supervised by the IITP(Institute for
   Information and Communications Technology Planning and Evaluation).
CR Aghdam MH, 2019, PHYSICA A, V518, P89, DOI 10.1016/j.physa.2018.11.037
   Back JW, 2019, TECHNOL HEALTH CARE, V27, P459, DOI 10.3233/THC-191730
   Beigi G, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P213, DOI 10.1145/3289600.3291026
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Christodoulou L, 2016, IEEE T BROADCAST, V62, P540, DOI 10.1109/TBC.2016.2570020
   Coyle K., 2010, Library Technology Reports, V46, P12
   Deldjoo Y, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P537, DOI 10.1145/3240323.3241620
   Gupta Vishal, 2009, Journal of Emerging Technologies in Web Intelligence, V1, P60, DOI 10.4304/jetwi.1.1.60-76
   Jung H, 2016, INFORM TECHNOL MANAG, V17, P29, DOI 10.1007/s10799-015-0218-4
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kim JC, 2019, KSII T INTERNET INF, V13, P2060, DOI 10.3837/tiis.2019.04.018
   Kim JC, 2019, WIRELESS PERS COMMUN, V105, P691, DOI 10.1007/s11277-018-5722-5
   Kim JC, 2018, PEER PEER NETW APPL, V11, P1278, DOI 10.1007/s12083-018-0631-7
   Kim JC, 2017, CLUSTER COMPUT, V20, P547, DOI 10.1007/s10586-016-0702-6
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Mwinyi IH, 2018, WIREL TELECOMM SYMP
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Park RC, 2015, MULTIMED TOOLS APPL, V74, P2519, DOI 10.1007/s11042-014-1964-8
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Thorat PB., 2015, INT J COMPUTER APPL, V110, P31, DOI DOI 10.5120/19308-0760
   Toch E, 2012, USER MODEL USER-ADAP, V22, P203, DOI 10.1007/s11257-011-9110-z
   Vijayarani S., 2015, International Journal of Computer Science Communication Networks, V5, P7
   Weiss S. M., 2015, Texts in Computer Science)
   Yoo H, 2018, PEER PEER NETW APPL, V11, P1309, DOI 10.1007/s12083-017-0620-2
   Zhou L, 2019, IEEE MULTIMEDIA, V26, P8, DOI 10.1109/MMUL.2018.2875256
NR 26
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34679
EP 34695
DI 10.1007/s11042-020-08774-0
EA MAR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000560968200002
DA 2024-07-18
ER

PT J
AU Liu, N
   Wan, LH
   Huang, Q
   Ji, YF
AF Liu, Na
   Wan, Lihong
   Huang, Qiao
   Ji, Yunfeng
TI Multi-view Deep Representations with Cross-Dataset Transfer for Remote
   Sensing Image Retrieval and Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; multi-view; deep representation; image
   classification; image retrieval; remote sensing
AB Transfer learning is a challenging task in computer vision, due to the differences of data distribution. Although convolutional neural network (CNN) could learn different levels of image abstraction, the single-view features extracted from the final layer of a pre-trained or fine-tuned CNN may result in insufficient image description over different datasets. To address this issue, we focus on deep representations with multi-view analysis for remote sensing image (RSI) retrieval and classification tasks using five recently released large-scale datasets. First, cross-dataset transfer learning is presented by fine-tuning a pre-trained CNN on one dataset and testing the fine-tuned network on another one. Second, multi-view image representations are explored in terms of different activation vectors as well as CNNs. Finally, a multi-view fusion and a random projection (RP) strategy are proposed to improve the accuracies and computational cost of both RSI tasks, respectively. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method.
C1 [Liu, Na; Ji, Yunfeng] Univ Shanghai Sci & Technol, Inst Machine Intelligence, Shanghai, Peoples R China.
   [Wan, Lihong] Netease Inc, Hangzhou, Zhejiang, Peoples R China.
   [Huang, Qiao] Mayo Clin, Dept Radiol, Radiol Informat Lab, Rochester, MN USA.
C3 University of Shanghai for Science & Technology; Mayo Clinic
RP Ji, YF (corresponding author), Univ Shanghai Sci & Technol, Inst Machine Intelligence, Shanghai, Peoples R China.
EM ji_yunfeng@usst.edu.cn
RI Huang, Qiao/AAX-2824-2020
OI Huang, Qiao/0000-0002-9044-2464
CR [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2019, P IEEE C COMP VIS PA
   [Anonymous], 2001, P 7 ACM SIGKDD INT C
   Cao G, 2019, IEEE T KNOWL DATA EN
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H., 2017, ARXIV170510450
   Li JX, 2019, INFORM FUSION, V45, P215, DOI 10.1016/j.inffus.2018.02.005
   Liu N, 2018, IEEE ACCESS, V6, P11215, DOI 10.1109/ACCESS.2018.2798799
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Penatti OtavioA B., 2015, Proceedings of the IEEE conference on computer vision and pattern recognition workshops, P44
   Peng X., 2019, IEEE T CYBERNETICS, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Zhou T., 2018, IEEE T CYBERNETICS
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
NR 28
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22891
EP 22905
DI 10.1007/s11042-020-08712-0
EA MAR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000517923300001
DA 2024-07-18
ER

PT J
AU Chou, YC
   Nien, YW
   Chen, YC
   Li, B
   Lee, JS
AF Chou, Yung-Chen
   Nien, Yu-Wei
   Chen, Ying-Chin
   Li, Bo
   Lee, Jung-San
TI Learning salient seeds refer to the manifold ranking and
   background-prior strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manifold ranking; Object detection; Salient map; Edge detecting prior
ID VISUAL-ATTENTION; REGION DETECTION
AB Recently, the key technique of image processing has been widely applied to pattern recognition, content retrieval, and object segmentation. These applications have brought much higher complexity in image computation. Accordingly, the processed results may be interfered due to the interlacing reference. To overcome this problem, researchers have developed the object detection mechanism, which is a preprocessing procedure to extract significant feature to stand for the whole image. However, the error rate of detection is a crucial challenge in this research field. Based on the concept of manifold ranking, we have designed a brand-new object detection method considering both local and global features. The experimental results have demonstrated that the new method is able to lower down the detection error rate in case that the object located near the boundary.
C1 [Chou, Yung-Chen] Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
   [Nien, Yu-Wei; Chen, Ying-Chin; Lee, Jung-San] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Li, Bo] Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.
C3 Asia University Taiwan; Feng Chia University; University of Illinois
   System; University of Illinois Urbana-Champaign
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM yungchen@gmail.com; leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Fu J, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P500, DOI 10.1109/FSKD.2016.7603224
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huiling Wang, 2016, Advances in Brain-Inspired Cognitive Systems. 8th International Conference, BICS 2016. Proceedings: LNAI 10023, P113, DOI 10.1007/978-3-319-49685-6_11
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1875, DOI 10.1007/s11042-015-3184-2
   Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhang D.W., 2017, 2017 IEEE INT C COMP
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
NR 29
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5859
EP 5879
DI 10.1007/s11042-019-08299-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900019
DA 2024-07-18
ER

PT J
AU Kannao, R
   Guha, P
AF Kannao, Raghvendra
   Guha, Prithwijit
TI A system for semantic segmentation of TV news broadcast videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation system; TV news broadcast segmentation; Advertisement
   detection; Program segmentation; Story segmentation; Software
   architecture; Scheduling
ID STORY SEGMENTATION; MULTIPLE
AB TV news channels present rich and complete experience of various events through audio-visual content. This makes television news an influential medium to affect masses and thus persuaded various social scientists and regulators to monitor and analyze the content of broadcast videos. An organized archive of newscast is a prerequisite for any such analysis. Creating such archive requires segmentation of continuous news videos into suitable logical units. Based on the application, these logical units may be one of channel content obtained after advertisement removal, different shows, news stories or video shots. In this work, we propose an end to end system with software architecture for segmenting the TV broadcast videos at all these four granularities. The videos are segmented into shots. Video shots are used as basic unit for all further processing. Video shots are first subjected to advertisement detection and removal to obtain the non-commercial channel content. This channel content is further processed to identify various program boundaries. We propose to identify three types of shows based on the presentation format viz. news bulletins, interviews and debates. News bulletins so obtained are processed further to obtain news stories. We propose a modular and scalable framework and software architecture for the broadcast segmentation system for deployment on a computation cluster. This involves scheduler based recording module and broadcast segmentation module. We have presented the detailed software architecture for individual modules, automation of entire processing pipeline along with resource and database management systems. We have implemented and verified the software architecture by deploying the proposed system on a cluster of nine desktops and one workstation. The deployed system was used for round the clock processing of three Indian English news channels.
C1 [Kannao, Raghvendra; Guha, Prithwijit] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Kannao, R (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
EM raghvendra@iitg.ac.in; pguha@iitg.ac.in
OI Kannao, Raghvendra/0000-0003-2083-2560
CR Ananthanarayanan G, 2018, REAL TIME VIDEO ANAL
   [Anonymous], 2015, MULTIMED TOOLS APPL
   [Anonymous], 2003, TRECVID C GAITH WASH
   [Anonymous], TECHNOLOGY PEDAGOGY
   [Anonymous], TREC VIDEO RETRIEVAL
   [Anonymous], 2005, CRF++: Yet another CRF toolkit
   [Anonymous], 2015, J. Comput. Sci. Coll.
   [Anonymous], TECH REP
   Awad G., 2016, ITE Transactions on Media Technology and Applications, V4, P187, DOI DOI 10.3169/MTA.4.187
   BEHR RL, 1985, PUBLIC OPIN QUART, V49, P38, DOI 10.1086/268900
   Bradski G, 2000, THE OPENCV LIB
   Broadcast Audience Research Counsel India, 2018, BARC IND HOUS IND UN
   Broadcast Audience Research Counsel India, 2019, WEEKL BROADC VIEW SH
   Broadcast Seva Ministry of Information & Broadcasting Government of India, 2019, PERM PRIV SAT TV CHA
   Cable Quest, 2019, LIST REG MSOS DTH CA
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YH, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P973, DOI 10.1109/ICME.2006.262695
   Chifu AG, 2016, PROCEDIA COMPUT SCI, V96, P1371, DOI 10.1016/j.procs.2016.08.182
   Comcowich B, 2019, NEW APPROACHES BROAD
   Comcowichm W, 2016, IMPORTANCE TV NEWS M
   Cyber Alert, 2016, NAT BROADC MON SERV
   de Castro Lopo E, 1999, LIBSNDFILE LIB
   Duygulu P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1267, DOI 10.1109/ICME.2004.1394454
   Ernst & Young LLP and FICCI Media & Entertainment Committee, 2018, REIM IND MED ENT M E
   Feng BL, 2014, MULTIMEDIA SYST, V20, P347, DOI 10.1007/s00530-013-0350-0
   Feng BL, 2012, INT CONF ACOUST SPEE, P1417, DOI 10.1109/ICASSP.2012.6288156
   Feng W, 2019, NEUROCOMPUTING, V355, P121, DOI 10.1016/j.neucom.2019.05.016
   Fomichev A, 2006, LECT NOTES COMPUT SC, V3831, P272
   Galassi M, 2002, GNU SCI LIB, P3
   Ghosh H, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/486487
   Gohmert L, 2014, P DEB 109 C 2 SESS H, V152, pH7939
   Gönen M, 2013, PATTERN RECOGN, V46, P795, DOI 10.1016/j.patcog.2012.09.002
   Hachten WA., 2015, The World News Prism: Digital, Social and Interactive, V9th
   Hill M. D., 1990, Computer Architecture News, V18, P18, DOI 10.1145/121973.121975
   Ishtiaq F, 2018, US Patent, Patent No. [9,888,279, 9888279]
   Jindal A., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P458, DOI 10.1109/ISM.2011.81
   Kannao R, 2016, TV COMMERCIAL DETECT
   Kannao R, 2016, ACM MULTIMEDIA, P546
   Kannao R, 2016, INT C PATT RECOG, P2948, DOI 10.1109/ICPR.2016.7900085
   Kannao R, 2017, PATTERN RECOGN, V68, P38, DOI 10.1016/j.patcog.2017.02.029
   Kevin D, 2019, MARKET TELEVISION NE
   Kim J, 2014, ENG APPL COMP FLUID, V8, P229
   Kim W, 2010, J SIGNAL PROCESS SYS, V61, P251, DOI 10.1007/s11265-009-0446-0
   Lee J, 2019, US Patent App, Patent No. [16/133,240, 16133240]
   Levy KL, 2017, US Patent 9,843,846, Patent No. [9,843,846, 9843846]
   Li Hongzhi., 2013, Proceedings of the 21st ACM international conference on Multimedia, P449
   Li MY, 2017, PROCEEDINGS OF 2017 VI INTERNATIONAL CONFERENCE ON NETWORK, COMMUNICATION AND COMPUTING (ICNCC 2017), P48, DOI 10.1145/3171592.3171619
   Lienhart RW, 2015, US Patent, Patent No. [9,147,112, 9147112]
   Liu N, 2011, IEEE T MULTIMEDIA, V13, P961, DOI 10.1109/TMM.2011.2160334
   Liu Z, 2018, IEEE INT CONF MULTI
   LjOdal S, 2014, THESIS
   Lu XM, 2013, INT CONF ACOUST SPEE, P8465, DOI 10.1109/ICASSP.2013.6639317
   Mei T, 2005, IEEE IMAGE PROC, P481
   Mühling M, 2012, LECT NOTES COMPUT SC, V7131, P40
   Nesvadba J., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Oracle Corporation, 2016, MYSQL 5 5 REF MAN
   Perebinossoff Philippe., 2005, PROGRAMMING TV RADIO
   Pereira JP, 2017, US Patent App. US Patent App, Patent No. [15/297,658, 15297658]
   Petrovic R, 2017, US Patent, Patent No. [9,648,282, 9648282]
   Poulisse GJ, 2010, MULTIMED TOOLS APPL, V48, P3, DOI 10.1007/s11042-009-0358-9
   Pratomo DA, 2016, KKU INT J HUMANITIES, V6, P1
   Racine J, 2000, CYGWIN TOOLS GNU TOO
   Rajat K, 2019, ANAL COMPETITION REG
   Ramires A, 2018, ARXIV181102411
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schuck ART, 2016, BRIT J POLIT SCI, V46, P177, DOI 10.1017/S0007123413000525
   Smeaton AF, 2003, AAAI SPRING S INT MU, P24
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Su XK, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P175
   Takeuchi H, 2015, CEREB CORTEX, V25, P1188, DOI 10.1093/cercor/bht315
   The Media Bureau, 2008, PUBL BROADC GET MOST
   Video Lan Organization, 2016, VLC MED PLAYER
   Wu XM, 2013, IEEE T CIRC SYST VID, V23, P1054, DOI 10.1109/TCSVT.2013.2248991
   Xiang Wang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.70
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
   Zedan IA, 2018, STUD COMPUT INTELL, V730, P89, DOI 10.1007/978-3-319-63754-9_5
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
   Zhu X, 2013, 2013 13TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P24, DOI 10.1109/NANO.2013.6720970
NR 79
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6191
EP 6225
DI 10.1007/s11042-019-08445-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900034
DA 2024-07-18
ER

PT J
AU Singh, SK
   Srivastava, R
AF Singh, Surya Kant
   Srivastava, Rajeev
TI A robust salient object detection using edge enhanced global
   topographical saliency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Laplacian of Gaussian; Central surround
   contrast; Global contrast; Regional saliency; Central saliency
ID REGION DETECTION; VISUAL SALIENCY; MODEL
AB Complex salient object detection is the most challenging task in clutter background images. In this prevailing problem, global contrast-based methods are comprehensively preferred. But these methods fail in preserving the structure, shape and broader related geometrical information. Aiming at these limitations, the proposed method uses global contrast and iterative Laplacian of Gaussian to generate initial global topographical saliency. In this topographical saliency, iterative Laplacian of Gaussian is used to preserve the structural, shape and broader related geometrical information. This global topographical saliency is used as a reference plane for integrating regional saliencies. The color, spatial and distance based regional saliencies are integrated into the boundary enhanced global topographical saliency to improve the substantial information of the object. Boundary-based Gaussian weighted, background suppression model, is used to remove the background and edge-effects. Finally, central saliency addition is used to enhance the final saliency. The proposed method is compared with recent six global contrasts based state-of-art methods, two deep learning based methods and four publicly available datasets. The experimental result presented here shows that the proposed method performs better in comparison to the state-of-the-art methods.
C1 [Singh, Surya Kant; Srivastava, Rajeev] Banaras Hindu Univ Varanasi, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Singh, SK (corresponding author), Banaras Hindu Univ Varanasi, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM suryakantsingh20@gmail.com; rajeev.cse@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chen MQ, 2013, COMPUT METHOD BIOMEC, V16, P185, DOI 10.1080/10255842.2011.615310
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng Y, 2014, IEEE INT CON MULTI
   Dabkowski P, 2017, ADV NEUR IN, V30
   Dong SJ, 2018, INT SYM COMPUT INTEL, P3, DOI 10.1109/ISCID.2018.10102
   Durand T, 2017, P IEEE C COMP VIS PA
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   HUANG K, 2017, ARXIV171100322
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Kourtzi Z, 2001, SCIENCE, V293, P1506, DOI 10.1126/science.1061133
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li R, 2018, MULTIMED TOOLS APPL, V77, P12139, DOI 10.1007/s11042-017-4862-z
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Mehrani Paria., 2010, BMVC, P1
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang G, 2017, J VIS COMMUN IMAGE R, V48, P432, DOI 10.1016/j.jvcir.2017.02.004
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 52
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17885
EP 17902
DI 10.1007/s11042-020-08644-9
EA FEB 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516508100001
DA 2024-07-18
ER

PT J
AU Li, C
   Chen, ZH
   Sheng, B
   Li, P
   He, GQ
AF Li, Chao
   Chen, Zhihua
   Sheng, Bin
   Li, Ping
   He, Gaoqi
TI Video flickering removal using temporal reconstruction optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video processing; Flickering removal; Multiple frames; Temporal
   coherence; Spatial coherence
AB In this paper, we introduce an approach to remove the flickers in the videos, and the flickers are caused by applying image-based processing methods to original videos frame by frame. First, we propose a multi-frame based video flicker removal method. We utilize multiple temporally corresponding frames to reconstruct the flickering frame. Compared with traditional methods, which reconstruct the flickering frame just from an adjacent frame, reconstruction with multiple temporally corresponding frames reduces the warp inaccuracy. Then, we optimize our video flickering method from following aspects. On the one hand, we detect the flickering frames in the video sequence with temporal consistency metrics, and just reconstructing the flickering frames can accelerate the algorithm greatly. On the other hand, we just choose the previous temporally corresponding frames to reconstruct the output frames. We also accelerate our video flicker removal with GPU. Qualitative experimental results demonstrate the efficiency of our proposed video flicker method. With algorithmic optimization and GPU acceleration, the time complexity of our method also outperforms traditional video temporal coherence methods.
C1 [Li, Chao; Chen, Zhihua; He, Gaoqi] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai, Peoples R China.
   [Li, Ping] Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.
C3 East China University of Science & Technology; Shanghai Jiao Tong
   University; Shanghai Jiao Tong University; Macau University of Science &
   Technology
RP Chen, ZH (corresponding author), East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM lichao-smile@l63.com; czh@ecust.edu.cn; shengbin@sjtu.edu.cn;
   pli@must.edu.mo; hegaoqi@ecust.edu.cn
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240; Sheng, Bin/0000-0001-8510-2556
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2014, 18 IEEE INT S CONSUM
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P SPIE
   Aydin TO, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661268
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Bhattacharya S, 2016, ACM S THEORY COMPUT, P398, DOI 10.1145/2897518.2897568
   Bonneel N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818107
   Bonneel N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661253
   Bonneel N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461939
   Dong X, 2015, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2015.7298671
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Farbman Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964984
   Gong WG, 2014, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2014.158
   HaCohen Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461997
   Hsu CY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1938
   Hsu E, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1399504.1360669, 10.1145/1360612.1360669]
   Huang CR, 2011, IEEE T MULTIMEDIA, V13, P950, DOI 10.1109/TMM.2011.2135844
   Kalantari NK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508402
   Kanj A, 2017, IEEE IMAGE PROC, P245, DOI 10.1109/ICIP.2017.8296280
   Lang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185530
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Oskam T, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P49, DOI 10.1109/3DIMPVT.2012.36
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Wang CM, 2006, MATH COMPUT MODEL, V44, P608, DOI 10.1016/j.mcm.2006.01.029
   Yao CH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P777, DOI 10.1145/3123266.3123363
   Ye GZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601135
   Zeng HQ, 2012, IEEE IMAGE PROC, P3017, DOI 10.1109/ICIP.2012.6467535
   Zhao XT, 2018, IET IMAGE PROCESS, V12, P88, DOI 10.1049/iet-ipr.2017.0060
NR 34
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4661
EP 4679
DI 10.1007/s11042-019-7413-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500023
DA 2024-07-18
ER

PT J
AU Lokesh, S
   Kanisha, B
   Nalini, S
   Devi, MR
   Kumar, R
AF Lokesh, S.
   Kanisha, B.
   Nalini, S.
   Devi, M. Ramya
   Kumar, R.
TI Speech to speech interaction system using Multimedia Tools and Partially
   Observable Markov Decision Process for visually impaired students
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partially Observable Markov Decision Process; Human computer
   interaction; Automatic speech recognition; Agenda based dialogue
   management system; Visually impaired students
AB In general, visually impaired students need of another person's to teach them with the help of computers and book. However, a number of students are not aware of using the computers and understanding the concepts by self. In order to solve this issue, a speech to speech interaction system is developed on the basis of a novel dialogue management system. This interaction is developed by combining Multimedia tools and Partially Observable Markov Decision Process (POMDP) with agenda based model used in the proposed dialogue management system to learn the speech signals from user and system will reply accordingly. The proposed system helps visually impaired students to learn easily using a novel dialogue management system. Word Error Rate, Recognition cum retrieval rate and Misrecognition Retrieval Rate are calculated for the proposed POMDP with Agenda Based dialogue management system. The experimental results are compared with Finite-State Based dialogue management system, Frame Based dialogue management system, and Probabilistic dialogue management system. The experimental results proved that the good performance of the proposed POMDP with Agenda Based dialogue management system. The proposed model is trained with 125 speakers out of which 46 were visually impaired and tested with 95 untrained speakers out of which 32 are visually impaired.
C1 [Lokesh, S.] Hindusthan Inst Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Kanisha, B.] Indra Ganesan Coll Engn, Dept Informat Technol, Trichirappalli, India.
   [Nalini, S.] Velammal Inst Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Devi, M. Ramya] Hindusthan Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Kumar, R.] Sri Ramakrishna Inst Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
RP Lokesh, S (corresponding author), Hindusthan Inst Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM lok.for.you@gmail.com; jolumykanisha@gmail.com;
   nalinitamihnani@gmail.com; ramyammugadasan@gmail.com;
   rkeskumar@gmail.com
RI Lokesh, S./ADA-1844-2022; SUBRAMANI, NALINI/ABC-1511-2020; M, Ramya
   Devi/ABC-1510-2020
OI Lokesh, S./0000-0003-2067-6756; SUBRAMANI, NALINI/0000-0003-2393-5848;
   M, Ramya Devi/0000-0003-4551-0680; B, Kanisha/0000-0001-6942-2576
CR Aida-zade K, 2012, 2012 INT S INNOVATIO, P1
   Alexandersson J, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT ENVIRONMENTS (IE), P365, DOI 10.1109/IE.2014.67
   [Anonymous], 2012, Annual Meeting of the Association for Computational Linguistics
   [Anonymous], 2010, 11 ANN M SPECIAL INT
   Baumann T., 2017, Lecture Notes in Electrical Engineering, P421
   Bokaei M. H., 2010, 2010 5th International Symposium on Telecommunications (IST), P591, DOI 10.1109/ISTEL.2010.5734093
   Budkov V. Y., 2010, 2010 International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT 2010), P485, DOI 10.1109/ICUMT.2010.5676593
   Bui TH, 2009, NAT LANG ENG, V15, P273, DOI 10.1017/S1351324908005032
   Celikyilmaz A, 2012, IEEE W SP LANG TECH, P216, DOI 10.1109/SLT.2012.6424225
   Di Lecce V., 2010, P IEEE INT C VIRT EN, P103
   Dinarelli M, 2010, INT CONF ACOUST SPEE, P5366, DOI 10.1109/ICASSP.2010.5494952
   Doshi F., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P65
   Dzikovska MyroslavaO., 2010, P ACL 2010 SYST DEM, P13
   Dzikovska MyroslavaO., 2011, Proceedings of the SIGDIAL 2011 Conference, P338
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Galescu L, 2009, SPEECH RECOGNITION D
   GALIBERT O, 2005, INTERSPEECH, P909
   Hastie H., 2013, P SIGDIAL 2013 C, P154
   Henderson James., 2005, P WORKSHOP KNOWLEDGE, P68
   Hsieh MC, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS, P67, DOI 10.1109/HIS.2009.21
   Hung V, 2009, INTERNATIONAL CONFERENCE ON INFORMATION, PROCESS, AND KNOWLEDGE MANAGEMENT: EKNOW 2009, PROCEEDINGS, P60, DOI 10.1109/eKNOW.2009.10
   Jokinen K, 2011, COGN INF COGINFCOM 2, P1
   Kanisha B, 2018, PERS UBIQUIT COMPUT, V22, P1083, DOI 10.1007/s00779-018-1139-0
   Karpov A, 2010, MULTIMODAL HUMAN COM, P3862
   Kim D., 2008, P INT
   Lee J, 2008, PR IEEE SEN ARRAY, P381, DOI 10.1109/SAM.2008.4606895
   Lefevre F, 2009, P SIGDIAL
   Lemaignan S., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P107, DOI 10.1109/ROMAN.2011.6005249
   Li Lihong, 2009, P INT
   Liu J., 2012, INTERSPEECH 2012, P2454
   Lokesh S, 2019, CLUSTER COMPUT, V22, P11669, DOI 10.1007/s10586-017-1447-6
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Lokesh S., 2012, Information Technology Journal, V11, P1644, DOI 10.3923/itj.2012.1644.1649
   LOKESH S, 2012, EUR J SCI RES, V73, P202
   Mantena G. V., 2011, 2011 Joint Workshop on Hands-Free Speech Communication and Microphone Arrays (HSCMA 2011), P153, DOI 10.1109/HSCMA.2011.5942384
   Mantena GV, 2011, P ICON 2011 9 INT C
   Morbini F., 2012, Proceedings of the 13th annual meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), P137
   Peters J, 2005, LECT NOTES ARTIF INT, V3720, P280, DOI 10.1007/11564096_29
   Roy N., 2000, P ACL
   Schwärzler S, 2009, IEEE INT CON MULTI, P958, DOI 10.1109/ICME.2009.5202655
   Selvaraj Lokesh, 2014, ScientificWorldJournal, V2014, P270576, DOI 10.1155/2014/270576
   Shah SY, 2013, PROCEEDINGS OF THE 2013 IEEE 2ND INTERNATIONAL NETWORK SCIENCE WORKSHOP (NSW), P1, DOI 10.1109/NSW.2013.6609187
   Sharif KJ, 2012, INT J ONLINE MARKET, V2, P1, DOI 10.4018/ijom.2012070101
   Thomson B, 2008, INT CONF ACOUST SPEE, P4937, DOI 10.1109/ICASSP.2008.4518765
   Ultes S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P73, DOI 10.18653/v1/P17-4013
   Varatharajan R, 2018, CLUSTER COMPUT, V21, P681, DOI 10.1007/s10586-017-0977-2
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Vishnupriya R, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING APPLICATIONS (ICICA 2014), P426, DOI 10.1109/ICICA.2014.93
   Vlasenko B, 2009, IEEE INT CON MULTI, P950, DOI 10.1109/ICME.2009.5202653
   Wang HM, 2008, PROC INT C TOOLS ART, P357, DOI 10.1109/ICTAI.2008.15
   Williams J. D., 2008, P AAAI WORKSH ADV PO
   Williams JD, 2007, IEEE T AUDIO SPEECH, V15, P2116, DOI 10.1109/TASL.2007.902050
   YOUNG S, 2005, CUEDFINFENGTR544
   Young S, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P577, DOI 10.1145/3018661.3022746
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
   Zhang B, 2001, 7 EUR C SPEECH COMM
NR 57
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5023
EP 5042
DI 10.1007/s11042-018-6264-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500044
DA 2024-07-18
ER

PT J
AU Swathika, R
   Sharmila, TS
AF Swathika, R.
   Sharmila, T. Sree
TI Multi-model fusion based satellite image classification using versatile
   unsupervised vector zone (VUVZ) fusion and intensive pragmatic blossoms
   (IPB) technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fusion; Temporal filter; Linear iterative clustering; Intensive
   pragmatic blossoms
ID REGISTRATION; ALGORITHM
AB To get the result if satellite image classification in precisely the image fusion method is widely used. The satellite images at different spectral and spatial resolutions with the guide of image handling strategies can improve the idea of data. For the most part image fusion is important to expel the spatial data from two images of different spatial, spectral and worldly images of a comparable zone. A task of image examination, for instance, image order on fused images gives better results in contrast with one of a kind data. In this work versatile unsupervised vector zone (VUVZ) method have been used for image fusion. The resultant images have been classified using the supervised classification with Intensive Pragmatic Blossoms (IPB) rule for information extraction and comparison between them regarding their accuracy. In This work describes a case study of micro seepage signals detection in the land, using multi-sensor satellite time series based on linear iterative segmentation (LIS) and Intensive Pragmatic Blossoms (IPB). Results show that the spectral anomalies identified from a satellite are closely correlated to the known oilfields and that the micro seepage maps can produce new high-quality data to reduce exploration risk. The simulation work classification accuracy of 94.12% which is much better than past outcomes in this engaged field of research. The execution of the usage is analyzed, an examination is likewise influenced concerning the clustering precision, time complexity, and false proportion are introduced.
C1 [Swathika, R.; Sharmila, T. Sree] SSN Coll Engn, Dept Informat Technol, Chennai 603110, Tamil Nadu, India.
C3 SSN College of Engineering
RP Swathika, R (corresponding author), SSN Coll Engn, Dept Informat Technol, Chennai 603110, Tamil Nadu, India.
EM swathikaphd123@yahoo.com
RI T., Sree Sharmila/ABC-3930-2021; rengasamy, swathika/JZE-6413-2024; R,
   Swathika/ABC-2981-2021
OI T., Sree Sharmila/0000-0001-5744-9739; rengasamy,
   swathika/0000-0002-4794-029X; T, Sree Sharmila/0009-0009-1736-2669
CR Ardizzone F., 2013, Landslide science and practice, P95, DOI [DOI 10.1007/978-3-642-31325-712, 10.1007/978-3-642-31325-7_12, DOI 10.1007/978-3-642-31325-7_]
   Chen C, 2015, IEEE T IMAGE PROCESS, V24, P4213, DOI 10.1109/TIP.2015.2456415
   Chen Y, 2014, INVEST OPHTH VIS SCI, V55, DOI 10.1167/iovs.14-15029
   Gharbia R, 2014, ADV INTELL SYST, V303, P311, DOI 10.1007/978-3-319-08156-4_31
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   He T, 2014, IEEE T GEOSCI REMOTE, V52, P3428, DOI 10.1109/TGRS.2013.2272935
   Huynh HNT, 2016, J OCEANOGR, V72, P707, DOI 10.1007/s10872-016-0365-1
   Kalay Adnan, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P125, DOI 10.1109/SIU.2009.5136348
   Kumaraswamy S, 2016, ACTA U SAPIEN INFORM, V8, P241, DOI 10.1515/ausi-2016-0011
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Luo N, 2018, IET COMPUT VIS, V12, P220, DOI 10.1049/iet-cvi.2017.0130
   Misra N, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P97
   Mukherjee Subhadip, 2014, AISC, V249, P293
   Ren H, 2017, IEEE T GEOSCI REMOTE
   Saul'skii VK, 2017, COSMIC RES+, V55, P275, DOI 10.1134/S0010952517040049
   Sawada Y, 2017, IEEE T GEOSCI REMOTE, V55, P6195, DOI 10.1109/TGRS.2017.2722468
   Singh PP, 2015, ADV COMPUTING NETWOR, V1, P283
   Son S, 2017, IEEE T GEOSCI REMOTE, V55, P6793, DOI [10.1109/TGRS.2017.2734079, 10.1109/tgrs.2017.2734079]
   Song HH, 2013, IEEE T GEOSCI REMOTE, V51, P1883, DOI 10.1109/TGRS.2012.2213095
   Tao L., 2017, IPSJ T COMPUT VISION, V9, P122, DOI [10.1186/s41074-017-0025-4, DOI 10.1186/S41074-017-0025-4]
   Tao X., 2017, IEEE T GEOSCI REMOTE
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Vanjare A, 2016, AISC, V177, P757
   Wei JB, 2017, IEEE T GEOSCI REMOTE, V55, P7126, DOI 10.1109/TGRS.2017.2742529
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Yang B, 2018, IEEE T GEOSCI REMOTE, V56, P474, DOI 10.1109/TGRS.2017.2750320
   Yu X, 2015, CCIS, V482, P252
   Zeng T, 2015, IEEE T MAGN, V51, DOI 10.1109/TMAG.2015.2438018
NR 28
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4239
EP 4260
DI 10.1007/s11042-019-07872-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700064
DA 2024-07-18
ER

PT J
AU Mukherjee, N
   Paul, G
   Saha, SK
   Burman, D
AF (Ganguly) Mukherjee, Nabanita
   Paul, Goutam
   Saha, Sanjoy Kumar
   Burman, Debanjan
TI A PVD based high capacity steganography algorithm with embedding in
   non-sequential position
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; PVD based embedding; High capacity steganography;
   Data hiding
ID WATERMARKING SCHEME; IMAGE
AB Modern research in Steganography focuses on increasing the capacity without keeping any perceptible signature into the stego-media. In this work, we present a pixel value difference (PVD) based high capacity methodology. Embedding is not restricted only to high contrast pixel pairs. Low contrast pairs are also considered to enhance the capacity. Embedding process varies depending on the local contrast of the pair. Secret message is encrypted before embedding and pixels pairs are chosen in a non-sequential manner, rendering the methodology more secure. Experiment is performed on more than two hundred images. It is observed that embedding by proposed technique is visually imperceptible and can withstand various types of attacks. The benchmark test like StirMark analysis also indicates the strength of the work. Comparison of performance with a number of other methods shows that proposed methodology maintains high PSNR with enhanced capacity.
C1 [(Ganguly) Mukherjee, Nabanita; Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Paul, Goutam] Indian Stat Inst, RC Bose Ctr Cryptol & Secur, Cryptol & Secur Res Unit, Kolkata 700108, India.
   [Burman, Debanjan] Infosys Ltd, Dept Comp Sci & Engn, Bengaluru 560100, Karnataka, India.
C3 Jadavpur University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; Infosys Limited
RP Paul, G (corresponding author), Indian Stat Inst, RC Bose Ctr Cryptol & Secur, Cryptol & Secur Res Unit, Kolkata 700108, India.
EM nabanitaganguly0@gmail.com; goutam.paul@isical.ac.in;
   sks_ju@yahoo.co.in; burmandebanjan@gmail.com
CR Biswas R, 2019, MULTIMED TOOLS APPL, V78, P20019, DOI 10.1007/s11042-019-7369-y
   Boehmm B., 2014, STEGEXPOSE TOOL DETE
   Bozek J, 2011, ELMAR PROC, P11
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Couchot JF, 2015, ANN TELECOMMUN, V70, P441, DOI 10.1007/s12243-015-0466-7
   Datta B, 2019, MULTIMED TOOLS APPL, V78, P1511, DOI 10.1007/s11042-018-6195-y
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Fouad MM, 2017, FED CONF COMPUT SCI, P545, DOI 10.15439/2017F10
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2007, IEEE T INFORM THEORY, V53, P1547, DOI 10.1109/TIT.2007.892768
   Halder P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P411, DOI 10.1109/ICRCICN.2015.7434274
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Imaizumi Shoko, 2013, 6 PACIFIC RIM S IMAG, P99
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Kharrazi M, 2006, LECT NOTES COMPUT SC, V4300, P123
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Mukherjee Imon, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P270, DOI 10.1007/978-3-642-45204-8_21
   Paul G., 2012, INT C INF SYST SEC, P134, DOI 10.1007/978-3-642-35130-3_10
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Provos N., 2001, 10 USENIX SEC S, P325
   Pun K, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1, DOI 10.1109/ICEPT.2014.6922552
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Smorynski C., LOGICAL NUMBER THEOR, V1
   Song SC, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.521
   Sun ZH, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND APPLICATIONS (WCNA2017), P144, DOI 10.1145/3180496.3180622
   Swain G., 2013, CSI Trans. ICT, V1, P127, DOI [10.1007/s40012-013-0015-3, DOI 10.1007/S40012-013-0015-3]
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Tseng HW, 2013, J APPL MATH, DOI 10.1155/2013/189706
   Westfeld A., 1999, 3 INT WORKSH INF HID
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
   Zhang HL, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL II, P109, DOI 10.1109/ISECS.2009.139
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 41
TC 22
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13449
EP 13479
DI 10.1007/s11042-019-08178-9
EA JAN 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515728200001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Wang, HX
   Chen, Y
   Wu, HZ
   Wang, H
AF Liu, Yong
   Wang, Hongxia
   Chen, Yi
   Wu, Hanzhou
   Wang, Huan
TI A passive forensic scheme for copy-move forgery based on superpixel
   segmentation and K-means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Image segmentation; Cluster analysis;
   Harris points; Sector mean; RGB color feature
AB Copy-move forgery is a commonly used operation for digital image. Most of the existing copy-move schemes designed to region duplication are block-based and keypoint-based. In general, block-based methods fail to handle geometric transformations. Though keypoint-based methods can handle geometric transformations, they have a poor detection effect on the smooth region. This has motivated us to propose an efficient copy-move forgery detection method, which is based on superpixel segmentation and cluster analysis to improve the detection accuracy due to some specified attacks in this paper. In the proposed method, K-means clustering technology is used to divide the superpixel of the image into complex regions and smooth regions. The clustering rule is based on the mean and standard deviation of the pixels, and the ratio of the feature points in the superpixel block, this clustering method can distinguish complex regions (non-smooth regions) and smooth regions. In complex regions, Scale-Invariant Feature Transform (SIFT) features are used to detect tampering. In smooth regions, the sector mask feature and RGB color feature are proposed to detect tampering. Filtering out error matching is applied to these two kinds of regions for the copy-move detection. Experimental results have shown that the proposed method can detect the tampering of complex regions and smooth regions and it indeed has the advantage in the detection accuracy compared with some related works when the test images are processed by blurring, adding noise, JPEG compression and rotation.
C1 [Liu, Yong; Wu, Hanzhou] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Wang, Hongxia] Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
   [Chen, Yi] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.
   [Wang, Huan] Guizhou Univ Finance & Econ, Guiyang 550025, Guizhou, Peoples R China.
C3 Shanghai University; Sichuan University; Southwest Jiaotong University;
   Guizhou University of Finance & Economics
RP Liu, Y (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM liuyongresearch@163.com; hxwang@scu.edu.cn; yichen.research@gmail.com;
   wuhanzhou_2007@126.com; ideahuan@163.com
RI Wang, Hongxia/AAE-2135-2022; Wu, Hanzhou/AAL-3361-2021
OI Wu, Hanzhou/0000-0002-1599-7232; Chen, Yi/0000-0003-4272-7956
FU Fundamental Research Funds for the Central Universities [YJ201881];
   Doctoral Innovation Fund Program of Southwest Jiaotong University
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under the grant No. YJ201881 and Doctoral
   Innovation Fund Program of Southwest Jiaotong University.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Avola D, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P638, DOI 10.5220/0006722506380645
   Avola D, 2017, PATTERN RECOGN LETT, V100, P110, DOI 10.1016/j.patrec.2017.10.029
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hamdi D, 2016, I C DEV ESYST ENG, P130, DOI 10.1109/DeSE.2016.22
   Huang H., 2009, WORKSHOP COMPUTATION, V2, P272
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Kumar Sunil, 2015, International Journal of Computing and Digital Systems, V4, P27, DOI 10.12785/ijcds/040203
   Li G., 2007, IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2007.4285009
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li Kang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2419, DOI 10.1109/CISP.2010.5648249
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   MacDonald A, 2019, NUTR RES REV, V32, P70, DOI [10.1017/S0954422418000173, 10.1017/s0954422418000173]
   Mao Y., 2009, Comput. Technol. Develop., V19, P130
   Popescu AC, 2004, COMPUT SCI DARTMOUTH, P646
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sharma A, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P1, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.18
   Shi ZF, 2012, IEICE T INF SYST, VE95D, P2585, DOI 10.1587/transinf.E95.D.2585
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wang H, 2017, MULTIMED TOOLS APPL, V76, P12627, DOI 10.1007/s11042-016-3687-5
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang X., 2016, INT J PATTERN RECOGN, V30, P304
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Yong Liu, 2017, Cloud Computing and Security. Third International Conference, ICCCS 2017. Revised Selected Papers: LNCS 10602, P61, DOI 10.1007/978-3-319-68505-2_6
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
   Zhang T, 2012, INT C DIG IM PROC, V8334
   ZHANG T, 2013, INF TECHNOL J, V12, P2342, DOI DOI 10.3923/itj.2013.2342.2349
   Zhou LN, 2007, LECT NOTES ARTIF INT, V4496, P990
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 35
TC 15
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 477
EP 500
DI 10.1007/s11042-019-08044-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600020
DA 2024-07-18
ER

PT J
AU Sang, HF
   Chen, ZZ
   He, DK
AF Sang, Hai-Feng
   Chen, Zi-Zhen
   He, Da-Kuo
TI Human Motion prediction based on attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human motion prediction; Gated recurrent unit; Attention mechanism; Deep
   neural networks; seq2seq
ID HUMAN-BEHAVIOR; RECOGNITION
AB Human motion prediction, although in the field of human-computer interaction, personnel tracking, automatic driving and other fields have very important significance. However, human motion prediction is affected by uncertainties such as motion speed and amplitude, which results in the predicted first frame is discontinuous and the time for accurate prediction is short. This paper proposes a method that combines sequence-to-sequence (seq2seq) structure and Attention mechanisms to improve the problems of current methods. We refer to the proposed structure as the At-seq2seq model, which is a sequence-to-sequence model based on GRU (Gated Recurrent Unit). We added an attention mechanism in the decoder part of the seq2seq model to further encode the output of the encoder into a vector sequence containing multiple subsets so that the decoder selects the most relevant part of the sequence for decoding prediction. The At-seq2seq model has been validated on the human3.6 m dataset. The experimental results show that the proposed model can not only improve the error of short-term motion prediction but also significantly increase the time of accurate prediction.
C1 [Sang, Hai-Feng; Chen, Zi-Zhen] Shenyang Univ Technol, Sch Informat Sci & Engn, Shenyang 110870, Liaoning, Peoples R China.
   [He, Da-Kuo] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Shenyang University of Technology; Northeastern University - China
RP Chen, ZZ (corresponding author), Shenyang Univ Technol, Sch Informat Sci & Engn, Shenyang 110870, Liaoning, Peoples R China.
EM sanghaif@163.com; chenziz@126.com
OI Sang, Haifeng/0000-0002-1471-6101
FU National Natural Science Foundation of China [61773105, 61374147];
   Fundamental Research Funds for the Central Universities [N182008004]
FX Thanks are due to the National Natural Science Foundation of China under
   grant nos. 61773105 and 61374147 and the Fundamental Research Funds for
   the Central Universities under grant no. N182008004 for supporting this
   research work.
CR Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523
   [Anonymous], 2000, NIPS
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Cascianelli S, 2018, IEEE ROBOT AUTOM LET, V3, P841, DOI 10.1109/LRA.2018.2793345
   CHO K, 2014, COMPUT THERM SCI
   Chu C, 2017, INT CONF COMPUT ADV
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Graves A., 2013, GENERATING SEQUENCES
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A., 2015, Structural-RNN: deep learning on spatio-temporal graphs, P5308, DOI [10.1109/CVPR.2016.573, DOI 10.1109/CVPR.2016.573]
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   KIM B, 2016, ADV PARALLEL DISTRIB
   KOMBRINK S, 2011, P INTERSPEECH 2011
   Kuligowski ED, 2017, FIRE TECHNOL, V53, P649, DOI 10.1007/s10694-016-0586-2
   LEE YM, 2017, ROBOT INTELLIGENCE T, V4
   Mao CS, 2017, COMM COM INF SC, V771, P180, DOI 10.1007/978-981-10-7299-4_15
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   NOAH W, 2018, FINE LINE LINGUISTIC
   Saini S, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/704861
   Shen YL, 2016, KNOWL INF SYST, V49, P455, DOI 10.1007/s10115-015-0910-z
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Sutskever Ilya, 2011, P 28 INT C MACH LEAR, P1017
   Nguyen VT, 2017, JOINT INT CONF SOFT
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   WANG J, 2007, INT C MACH LEARN
   WANG JM, 2007, GAUSSIAN PROCESS DYN
   Xia JJ, 2016, ADV COGN NEURODYN, P493, DOI 10.1007/978-981-10-0207-6_67
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhan JY, 2018, COMPUT ECON, V52, P1277, DOI 10.1007/s10614-017-9744-y
   ZHU Z, 2018, INT C SEC
NR 31
TC 21
Z9 24
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5529
EP 5544
DI 10.1007/s11042-019-08269-7
EA DEC 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000500863600001
DA 2024-07-18
ER

PT J
AU Bin, CZ
   Gu, TL
   Sun, YP
   Chang, L
AF Bin, Chenzhong
   Gu, Tianlong
   Sun, Yanpeng
   Chang, Liang
TI A personalized POI route recommendation system based on heterogeneous
   tourism data and sequential pattern mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI route recommendation; Sequential pattern mining; Heterogeneous
   Tourism data; Tourism contexts
AB Planning a personalized POI route before touring a new city is an important travel preparation activity; however, it is a challenging and time-consuming task for tourists. Although some previous works focus on suggesting POI visit list or sequences, they fail to suggest personalized POI routes due to ignoring multifaceted tourism contexts. Also, they often suffer from tourist cold start or data sparsity problem because of the lack of tourism related data. To address the above weaknesses, we first propose a novel method to integrate heterogeneous tourism data collected from websites to construct a POI knowledgebase and massive structured POI visit sequences. Next, a POI-Visit sequential pattern mining algorithm is proposed to generate various fine-grained candidate POI routes from POI visit sequences while considering various tourism contexts. At the POI route recommendation stage, our system retrieve and rank a list of candidate routes according to the querying tourist's tourism contexts, including the intended travel duration, the companion type in trip, the visit season and the preferring POI tourism types, etc. In our validation experiments, we select Guilin city in China as an example to construct a real POI knowledgebase which consists of 132 POIs and 8778 POI traffic time, and construct 5694 structured POI visit sequences based on 10,109 downloaded original travelogues. The experimental results demonstrate the advantages of our system in recommending fine-grained and high personalized POI routes for specific tourists.
C1 [Bin, Chenzhong] Guilin Univ Elect Technol, Sch Informat & Commun, 1 Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
   [Bin, Chenzhong; Gu, Tianlong] Guilin Univ Elect Technol, Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
   [Sun, Yanpeng] Guilin Univ Elect Technol, Sch Mech & Elect Engn, Guilin 541004, Peoples R China.
   [Chang, Liang] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology; Guilin University of Electronic Technology;
   Guilin University of Electronic Technology
RP Bin, CZ (corresponding author), Guilin Univ Elect Technol, Sch Informat & Commun, 1 Jinji Rd, Guilin 541004, Guangxi, Peoples R China.; Bin, CZ (corresponding author), Guilin Univ Elect Technol, Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
EM binchenzhong@guet.edu.cn; cctlgu@guet.edu.cn; yanpeng_sun@yeah.net;
   changl@guet.edu.cn
RI bin, chen/HZI-0300-2023
OI Bin, Chenzhong/0000-0002-7200-0929
FU National Natural Science Foundation of China [U1501252, 61572146,
   U1711263]; Natural Science Foundation of Guangxi Province
   [2016GXNSFDA380006, AC16380122]; Guangxi Innovation-Driven Development
   Grand Project [AA17202024]; Guangxi University Young and Middle-aged
   Teacher Basic Ability Enhancement Project [2018KY0203B]
FX This work was partially supported by the National Natural Science
   Foundation of China (Nos. U1501252, 61572146, U1711263), the Natural
   Science Foundation of Guangxi Province (No. 2016GXNSFDA380006,
   AC16380122), the Guangxi Innovation-Driven Development Grand Project
   (No. AA17202024) and the Guangxi University Young and Middle-aged
   Teacher Basic Ability Enhancement Project (No. 2018KY0203B).
CR AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   [Anonymous], 2010, Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems, DOI 10.1145/1869790.1869857
   Bao J, 2015, GEOINFORMATICA, V19, P525, DOI 10.1007/s10707-014-0220-8
   Bhargava P, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P130, DOI 10.1145/2736277.2741077
   Cai GC, 2018, EXPERT SYST APPL, V94, P32, DOI 10.1016/j.eswa.2017.10.049
   Chen C, 2015, IEEE T INTELL TRANSP, V16, P1259, DOI 10.1109/TITS.2014.2357835
   Chen YL, 2003, EXPERT SYST APPL, V25, P343, DOI 10.1016/S0957-4174(03)00075-7
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Fang Q, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2842631
   Gao H, 2013, CHIN CONT DECIS CONF, P92
   GUO T, 2016, PCM-PREM PERS COMPUT, V2, P617
   Hechen Liu, 2011, 2011 IEEE International Conference on Data Mining Workshops, P1239, DOI 10.1109/ICDMW.2011.149
   Jiawei Han, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P355
   Kesorn K, 2017, IEEE ACCESS, V5, P26703, DOI 10.1109/ACCESS.2017.2778293
   Lim K.H., 2015, P 2015 ACM SIGMOD PH, P33, DOI DOI 10.1145/2744680.2744693
   Lim KH, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1778
   Luo Wuman, 2013, SIGMOD, P713
   Lv MQ, 2016, NEUROCOMPUTING, V173, P1142, DOI 10.1016/j.neucom.2015.08.071
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Pei J, 2001, PROC INT CONF DATA, P215
   SHEN J, 2014, MMM, V2, P227
   Shen JG, 2017, IEEE ACCESS, V5, P1600, DOI 10.1109/ACCESS.2017.2656878
   Shen JG, 2016, NEUROCOMPUTING, V173, P789, DOI 10.1016/j.neucom.2015.08.030
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   SUN Y, 2018, PRICAI, V1, P463
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tsai CY, 2015, KNOWL-BASED SYST, V73, P97, DOI 10.1016/j.knosys.2014.09.012
   Tsai CY, 2012, EXPERT SYST APPL, V39, P3593, DOI 10.1016/j.eswa.2011.09.049
   Xiao XY, 2014, J AMB INTEL HUM COMP, V5, P3, DOI 10.1007/s12652-012-0117-z
   Xie M, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P15, DOI 10.1145/29833213.2983711
   Yin HZ, 2016, IEEE T KNOWL DATA EN, V28, P2566, DOI 10.1109/TKDE.2016.2580511
   Yuan NJ, 2015, IEEE T KNOWL DATA EN, V27, P712, DOI 10.1109/TKDE.2014.2345405
   Zhang CY, 2016, KNOWL INF SYST, V46, P369, DOI 10.1007/s10115-015-0825-8
   Zheng Y, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P357, DOI 10.1109/MDM.2009.50
   Zhu Z, 2016, NEUROCOMPUTING, V204, P61, DOI 10.1016/j.neucom.2015.04.129
NR 36
TC 24
Z9 25
U1 12
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35135
EP 35156
DI 10.1007/s11042-019-08096-w
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800040
DA 2024-07-18
ER

PT J
AU Shivhare, SN
   Kumar, N
   Singh, N
AF Shivhare, Shiv Naresh
   Kumar, Nitin
   Singh, Navjot
TI A hybrid of active contour model and convex hull for automated brain
   tumor segmentation in multimodal MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Multimodal MRI; Active contour model; Convex
   hull
ID MEDICAL IMAGE-ANALYSIS; TEXTURE FEATURES; FRAMEWORK
AB Segmenting tumor automatically in human brain Magnetic Resonance (MR) images is challenging because of uneven, irregular and unstructured size and shape of the tumor. This paper proposes an automated two stage brain tumor segmentation method. In the first stage, coarse estimation of the brain tumor is carried out using convex hull approach. The coarse estimate thus obtained is employed as the initialization for the active contour model applied in the second stage thereby eliminating the need of human intervention. Multiscale Harris energy is estimated at different levels to identify high-energy regions and thereafter constructing convex hull over the selected key-points in order to detect the abnormality in the input MR images. The proposed method is applied to 2-d axial images of fluid attenuated inversion recovery (FLAIR) and post-contrast T1-weighted (T1c) MRI images from the brain tumor segmentation benchmark challenge 2015 (BRATS2015) dataset. Different subcompartments of the tumor such as enhanced tumor, edema, and necrosis are segmented and in addition combined in the form of tumor core, complete tumor, and enhanced tumor labels. The proposed method is evaluated in terms of Dice Similarity Coefficient (DSC), Sensitivity and Positive Predictive Value (PPV). Average DSC score of 81% for brain tumor core, 92% for complete brain tumor, and 83% for enhanced brain tumor are achieved which is better than several state-of-the-art methods.
C1 [Shivhare, Shiv Naresh; Kumar, Nitin] Natl Inst Technol Uttarakhand, Srinagar, India.
   [Singh, Navjot] Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Shivhare, SN (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, India.
EM shiv.naresh@nituk.ac.in; nitin@nituk.ac.in; navjot.singh.09@gmail.com
RI Kumar, Nitin/AAT-9454-2020; Shivhare, Shiv Naresh/V-9384-2019; Singh,
   Navjot/I-5444-2017
OI Shivhare, Shiv Naresh/0000-0002-6306-1113; Singh,
   Navjot/0000-0003-0409-8482
CR [Anonymous], 2015, P MICCAI BRATS
   [Anonymous], 2016, P BRATS MICCAI
   Avola D, 2011, LECT NOTES COMPUT SC, V6979, P414, DOI 10.1007/978-3-642-24088-1_43
   Avola D, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/213901
   Avola D, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1338
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Banday SA, 2017, MULTIMED TOOLS APPL, V76, P3809, DOI 10.1007/s11042-016-3979-9
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817
   Cui S, 2018, AUTOMATIC SEMANTIC S, V2018
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Drevelegas A., 2010, Imaging of Brain Tumors with Histological Correlations
   Dupont C, 2016, IRBM, V37, P131, DOI 10.1016/j.irbm.2015.12.004
   Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7
   Gong YJ, 2018, IEEE T IMAGE PROCESS, V27, P1390, DOI 10.1109/TIP.2017.2778569
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Hamamci A, 2012, IEEE T MED IMAGING, V31, P790, DOI 10.1109/TMI.2011.2181857
   Harris C., 1988, ALVEY VISION C, P147151
   Hasan AM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110132
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hsieh TM, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-54
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIM J, 2002, NUCL SCI S, V3, P1580
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Menze BH, 2010, LECT NOTES COMPUT SC, V6362, P151
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nabizadeh N, 2017, EXPERT SYST APPL, V77, P1, DOI 10.1016/j.eswa.2017.01.036
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pereira Sergio, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P131, DOI 10.1007/978-3-319-30858-6_12
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Shivhare SN, 2019, ADV INTELL SYST COMP, V748, P485, DOI 10.1007/978-981-13-0923-6_42
   Shivhare SN, 2019, INT C EM TRENDS INF
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Song B, 2016, LECT NOTES COMPUT SC, V10154, P162, DOI 10.1007/978-3-319-55524-9_16
   Tong JJ, 2019, BIOMED SIGNAL PROCES, V47, P387, DOI 10.1016/j.bspc.2018.06.001
   Van Huffel S, 2017, INT MICCAI BRAINLESI, P463
   Wang KQ, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0153-6
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhao XM, 2016, LECT NOTES COMPUT SC, V10154, P75, DOI 10.1007/978-3-319-55524-9_8
NR 50
TC 18
Z9 18
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34207
EP 34229
DI 10.1007/s11042-019-08048-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800001
DA 2024-07-18
ER

PT J
AU Shrivastava, G
   Kumar, P
AF Shrivastava, Gulshan
   Kumar, Prabhat
TI SensDroid: Analysis for Malicious Activity Risk of Android Application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android analysis; Data leak assessment; Intent analysis; Permission
   analysis; Android application clustering; Security and privacy
ID MALWARE; CLASSIFICATION
AB In Android, the inter-communication structure is governed by a late runtime binding message called Intent. Intents are having rich features which can detect the true nature of malware when compared to another known trait such as permissions. In this work, a framework called SensDroid is formulated that evaluates the efficiency of android intents and permissions as a differentiating trait to spot malicious apps through sensitive analysis technique. Efficiency escalation has been achieved by integrating these traits with other well-known malware detection attributes. The proposed work also uses sufficient number of samples collected from official and third-party Android app market. Multiple parameters are evaluated and compared with the existing techniques. Successful categorization of clean and malware app with high identification rate has been achieved. As a background discussion, we also give a comprehensive review of ancient android application analysis techniques, risk identification techniques, and intent analysis techniques for contemporary malicious activity.
C1 [Shrivastava, Gulshan; Kumar, Prabhat] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Shrivastava, G (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM gulshanstv@gmail.com; prabhat@nitp.ac.in
RI Shrivastava, Gulshan/AAH-7765-2021; Kumar, Prabhat/HGC-8304-2022; Kumar,
   Prabhat/AAA-9743-2019
OI Shrivastava, Gulshan/0000-0003-3671-4921; Kumar,
   Prabhat/0000-0001-9945-7702
CR Allix K, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P468, DOI [10.1145/2901739.2903508, 10.1109/MSR.2016.056]
   [Anonymous], 2018, DENSITY ESTIMATION S, DOI DOI 10.1201/9781315140919
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Bagheri H, 2015, IEEE T SOFTWARE ENG, V41, P866, DOI 10.1109/TSE.2015.2419611
   Bhat P, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301285
   Faruki P, 2015, IEEE COMMUN SURV TUT, V17, P998, DOI 10.1109/COMST.2014.2386139
   Feizollah A, 2017, COMPUT SECUR, V65, P121, DOI 10.1016/j.cose.2016.11.007
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Idrees F, 2017, COMPUT SECUR, V68, P36, DOI 10.1016/j.cose.2017.03.011
   Jing YM, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P735, DOI 10.1145/2897845.2897904
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P5027, DOI 10.1007/s11042-017-4756-0
   Kim T, 2019, IEEE T INF FOREN SEC, V14, P773, DOI 10.1109/TIFS.2018.2866319
   Liu X, 2020, IEEE T MOBILE COMPUT, V19, P1184, DOI 10.1109/TMC.2019.2903186
   Martín I, 2019, FUTURE GENER COMP SY, V97, P295, DOI 10.1016/j.future.2019.03.006
   Nirumand A, 2019, SOFTWARE PRACT EXPER, V49, P70, DOI 10.1002/spe.2643
   Onwuzurike L, 2019, ACM T PRIV SECUR, V22, DOI 10.1145/3313391
   Qamar A, 2019, FUTURE GENER COMP SY, V97, P887, DOI 10.1016/j.future.2019.03.007
   Shabtai A, 2014, COMPUT SECUR, V43, P1, DOI 10.1016/j.cose.2014.02.009
   Sharma Kavita, 2019, International Journal of E-Services and Mobile Applications, V11, P1, DOI 10.4018/IJESMA.2019040101
   Sharma K, 2018, COMPUT ELECTR ENG, V71, P416, DOI 10.1016/j.compeleceng.2018.08.003
   Shrivastava G, 2017, SCALABLE COMPUT-PRAC, V18, P243, DOI 10.12694/scpe.v18i3.1304
   Suarez-Tangil G, 2017, PROCEEDINGS OF THE SEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY'17), P309, DOI 10.1145/3029806.3029825
   Thoresen HM, 2017, THESIS
   Wan SH, 2019, FUTURE GENER COMP SY, V91, P382, DOI 10.1016/j.future.2018.08.007
   Wang CH, 2018, WIRELESS PERS COMMUN, V102, P1095, DOI 10.1007/s11277-017-5144-9
   Xu K, 2016, IEEE T INF FOREN SEC, V11, P1252, DOI 10.1109/TIFS.2016.2523912
   Zhang LL, 2018, IEEE T MOBILE COMPUT, V17, P279, DOI 10.1109/TMC.2017.2708716
   Zhou QG, 2019, MULTIMED TOOLS APPL, V78, P3529, DOI 10.1007/s11042-018-6498-z
   Zhu HJ, 2018, NEUROCOMPUTING, V272, P638, DOI 10.1016/j.neucom.2017.07.030
NR 29
TC 13
Z9 14
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35713
EP 35731
DI 10.1007/s11042-019-07899-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800066
DA 2024-07-18
ER

PT J
AU Tang, L
   Guan, WL
AF Tang, Li
   Guan, Weili
TI Robust matrix completion with complex noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matrix completion; Subspace learning; Sparse outliers
ID FACTORIZATION; MOTION
AB Matrix completion plays an important role in machine learning and data mining. Although a great number of algorithms have been developed for this issue, most of them can cope with only the Gaussian noise or sparse outliers. This paper focus on an intractable setting that the known entries are corrupted by Gaussian noise and sparse outliers simultaneously. Specifically, we construct a novel model with a loss function derived from the celebrated Huber function. Furthermore, an efficient optimization method is presented to solve the constructed model. The promising performance of our algorithm is demonstrated via numerous experiments on several benchmark datasets.
C1 [Tang, Li] Daqing Normal Univ, Teacher Educ Inst, Xibin Xi Rd, Daqing 163712, Heilongjiang, Peoples R China.
   [Guan, Weili] Hewlett Packard Enterprise Singapore, Singapore, Singapore.
C3 Daqing Normal University
RP Tang, L (corresponding author), Daqing Normal Univ, Teacher Educ Inst, Xibin Xi Rd, Daqing 163712, Heilongjiang, Peoples R China.
EM litang_2011@126.com; honeyguan@gmail.com
CR Agudo A, 2018, PROC CVPR IEEE, P2607, DOI 10.1109/CVPR.2018.00276
   Alquier P, 2019, ANN STAT, V47, P2117, DOI 10.1214/18-AOS1742
   [Anonymous], 2013, P AAAI C ART INT
   Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cambier L, 2016, SIAM J SCI COMPUT, V38, pS440, DOI 10.1137/15M1025153
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2
   Elsener A, 2016, ROBUST LOW RANK MATR
   Eriksson A., 2010, Efficient computation of robust low-rank matrix approximations in the presence of missing data using the l 1 norm
   Fei X, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/403584
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   HERLOCKER JL, 2017, ACM SIGIR FORUM, V51, P227, DOI DOI 10.1145/3130348.3130372
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Hu Z, 2019, INF FUSION
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Ke QF, 2005, PROC CVPR IEEE, P739
   Kwok J, 2018, P ADV NEURAL INFORM, P369
   Lin ZC, 2018, IEEE T PATTERN ANAL, V40, P208, DOI 10.1109/TPAMI.2017.2651816
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu Q, 2019, IEEE T NEUR NET LEAR, V30, P803, DOI 10.1109/TNNLS.2018.2851957
   Lovric M., 2011, International encyclopedia of statistical science, DOI DOI 10.1007/978-3-642-04898-2594
   Lu CY, 2015, AAAI CONF ARTIF INTE, P1805
   Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526
   Ngo T., 2012, P ADV NEURAL INFORM, P1412
   Nie F., 2012, AAAI, P655
   Nie FP, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2012, DOI 10.1145/3219819.3219951
   Nie FP, 2019, IEEE T IMAGE PROCESS, V28, P2378, DOI 10.1109/TIP.2018.2886712
   Shang F, 2017, IEEE T PATTERN ANAL, P1
   Shang FH, 2018, IEEE T FUZZY SYST, V26, P2039, DOI 10.1109/TFUZZ.2017.2760287
   Shang FH, 2015, INFORM SCIENCES, V307, P53, DOI 10.1016/j.ins.2015.02.026
   Sun Q, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P311
   Tanner J, 2016, APPL COMPUT HARMON A, V40, P417, DOI 10.1016/j.acha.2015.08.003
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Vandereycken B, 2013, SIAM J OPTIMIZ, V23, P1214, DOI 10.1137/110845768
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wen ZW, 2012, MATH PROGRAM COMPUT, V4, P333, DOI 10.1007/s12532-012-0044-1
   Yao Q, 2018, ARXIV180708725
   Yao Q., 2017, ARXIV170800146
   Zhao LC, 2016, IEEE T SIGNAL PROCES, V64, P4767, DOI 10.1109/TSP.2016.2572049
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 47
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2703
EP 2717
DI 10.1007/s11042-019-08430-2
EA NOV 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000499562100001
DA 2024-07-18
ER

PT J
AU AL Zamil, MGH
   Samarah, S
   Rawashdeh, M
   Karime, A
   Hossain, MS
AF AL Zamil, Mohammed G. H.
   Samarah, Samer
   Rawashdeh, Majdi
   Karime, Ali
   Hossain, M. Shamim
TI Multimedia-oriented action recognition in Smart City-based IoT using
   multilayer perceptron
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Multimedia big data; Multilayer perceptron neural
   networks; Smart City
ID HOME; MODELS; LIVE; FOG
AB The Internet of Things (IoT) devices and technologies for smart city applications produces a vast amount of multimedia data (e.g., audio, video, image, text and sensorial data), such big data are difficult to handle with traditional techniques and algorithms. The emerging machine learning techniques have the potential to facilitate the development of a new class of applications that can deal with such multimedia big data. Recently, Activity Recognition systems suggest using of multimedia data to detect daily actions, since it provides more accurate patterns; prevent the arising complain on privacy issues (in case of using audio-base data) and able to work on a big data. In this paper, we propose a Deep Learning (DL) methodology for classifying audio data that is based on multilayer perceptron neural networks. The contributions of our work are to propose an efficient design of the network topology including hidden layers, neurons, and the fitness function. In addition, the proposed methodology contributed in producing high performance classifier in terms of accuracy and f-measure. The experiments have been conducted on four large audio-datasets that have been collected to represent different modalities in a smart city. The results indicated that the proposed methodology achieved high performance as compared to the state-of-the-art machine learning techniques.
C1 [AL Zamil, Mohammed G. H.; Samarah, Samer] Yarmouk Univ, Dept Comp Informat Syst, Irbid, Jordan.
   [Rawashdeh, Majdi] Princess Sumaya Univ Technol, Dept Business Informat Technol, Amman, Jordan.
   [Karime, Ali] Univ Ottawa, Sch Elect Engn & Comp Sci EECS, Ottawa, ON, Canada.
   [Hossain, M. Shamim] King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Yarmouk University; Princess Sumaya University for Technology;
   University of Ottawa; King Saud University; King Saud University
RP Hossain, MS (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM mshossain@ksu.edu.sa
RI AL Zamil, Mohammed/GYJ-1489-2022; Hossain, M. Shamim/K-1362-2014;
   Guizani, Mohsen/AAX-4534-2021
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094; Karime, Ali/0000-0001-7826-1540; AL Zamil,
   Mohammed/0000-0003-4533-5894
FU Deanship of Scientific Research, King Saud University through the Vice
   Deanship of Scientific Research Chairs
FX The authors are very grateful for the support from the Deanship of
   Scientific Research, King Saud University through the Vice Deanship of
   Scientific Research Chairs.
CR Al Zamil MGH, 2017, CLUSTER COMPUT, V20, P1815, DOI 10.1007/s10586-017-0837-0
   Al Zamil MG, 2018, IEEE ACCESS, V6, P1471, DOI 10.1109/ACCESS.2017.2779158
   Bouakaz S, 2014, IRBM, V35, P100, DOI 10.1016/j.irbm.2014.02.011
   Chahuara P, 2016, J AMB INTEL SMART EN, V8, P399, DOI 10.3233/AIS-160386
   Cook DJ, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P521, DOI 10.1109/PERCOM.2003.1192783
   De Carolis B., 2004, INT J COMPUT INTELLI, V1, P1
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Hargreaves T, 2018, BUILD RES INF, V46, P127, DOI 10.1080/09613218.2017.1286882
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Hossain MS, 2018, IEEE COMMUN MAG, V56, P44, DOI 10.1109/MCOM.2018.1700577
   Hossain MS, 2019, MULTIMEDIA SYST, V25, P565, DOI 10.1007/s00530-017-0561-x
   Hou L, 2016, IEEE COMMUN MAG, V54, P32, DOI 10.1109/MCOM.2016.1600398CM
   Kidd CD, 1999, LECT NOTES COMPUT SC, V1670, P191
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   LaMarca A, 2005, LECT NOTES COMPUT SC, V3468, P116
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lin K, 2017, IEEE T IND INFORM, V13, P1932, DOI 10.1109/TII.2016.2641467
   Mozer M., 2005, IEE SEM, V11059, pv1
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Qian SS, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659521
   Rawashdeh M., 2017, FUTURE GENER COMPUT, DOI [10.1016/j.future.2017.10.031, DOI 10.1016/J.FUTURE.2017.10.031]
   Rawashdeh M, 2018, J NETW COMPUT APPL, V115, P86, DOI 10.1016/j.jnca.2018.04.015
   Samarah S, 2018, J PARALLEL DISTR COM, V122, P122, DOI 10.1016/j.jpdc.2018.07.020
   Yassine A, 2019, FUTURE GENER COMP SY, V91, P563, DOI 10.1016/j.future.2018.08.040
   Zheng H, 2017, IEEE T SYST MAN CYBE, pA
   Zhou YZ, 2017, TSINGHUA SCI TECHNOL, V22, P714, DOI 10.23919/TST.2017.8195353
   Zuhairy RM, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718764641
NR 28
TC 13
Z9 13
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30315
EP 30329
DI 10.1007/s11042-018-6919-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200038
DA 2024-07-18
ER

PT J
AU Shi, L
   Chi, ZX
   Meng, XZ
AF Shi, Lin
   Chi, Zengxiao
   Meng, Xiangzeng
TI A New Automatic Visual Scene Segmentation Algorithm for Flash Movie
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flash retrieval; Visual scene; Flash movie; Adaptive threshold
AB Flash movie retrieval system can improve the utilization of Flash movie on the Internet. The key step of a content-based Flash movie retrieval system is visual scene segmentation that directly affects the retrieval effect. In this paper, an adaptive threshold method for visual scene segmentation based on frame difference of color histogram is proposed. Firstly, all key frame sequences of a Flash movie are obtained; then the region-weighted color histogram difference of adjacent key frames is calculated; lastly, the visual scene is classified by comparing the result with the average difference. In the process of visual scene segmentation, the spatial characteristics of color are considered and the regional weighting coefficient of key frames is determined by comparing the experiments. The proposed algorithm replaces the traditional fixed global threshold with a variable adaptive threshold. The experiments show that the proposed algorithm has a better detection effect than the fixed threshold algorithm. This algorithm can easily be implemented with moderate computational complexity. The proposed algorithm can be used to extract visual features of the visual scene, generate dynamic summary, and finally can be applied to content-based Flash animation retrieval system. Moreover, the proposed algorithm can also be used in non-flash applications.
C1 [Shi, Lin] Shandong Jianzhu Univ, Sch Business, Jinan, Shandong, Peoples R China.
   [Shi, Lin] Shandong Normal Univ, Fac Educ, Jinan, Shandong, Peoples R China.
   [Chi, Zengxiao] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan, Shandong, Peoples R China.
   [Meng, Xiangzeng] Shandong Normal Univ, Sch Journalism & Commun, Jinan, Shandong, Peoples R China.
C3 Shandong Jianzhu University; Shandong Normal University; Shandong
   Jiaotong University; Shandong Normal University
RP Shi, L (corresponding author), Shandong Jianzhu Univ, Sch Business, Jinan, Shandong, Peoples R China.; Shi, L (corresponding author), Shandong Normal Univ, Fac Educ, Jinan, Shandong, Peoples R China.
EM shilin_2010@126.com; tomorrow0567@163.com; mxz_sdnu@126.com
OI Chi, Zengxiao/0000-0001-7913-2353
FU National Natural Science Foundation of China [61502259]; cooperative
   project "Tomato Department Store-Implementation Design of Campus New
   Retail E-commerce Mode in College"
FX The work is supported by National Natural Science Foundation of China
   (61502259), and cooperative project "Tomato Department
   Store-Implementation Design of Campus New Retail E-commerce Mode in
   College".
CR Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699
   Bulanon DM, 2002, BIOSYST ENG, V83, P405, DOI 10.1006/bioe.2002.0132
   Fei L, 2010, RES SCENE STRUCTURE, P28
   Haisheng D, 2018, TELEVISION TECHNOLOG, V42, P75
   Hongyu C, 2019, J COMPUT APPL, V39, P136
   Juan C, 2011, J SHANGHAI JIAOTONG, V45, P1542
   Lin S, 2017, INT J SIGNAL PROCESS, V10, P85
   Ling H, 2019, ACTA PHYSL SINICA, V71, P11
   Liu L, 2008, CONTENT ANAL FEATURE, P52
   Mingmin Z, 2019, J ZHEJIANG U, V46, P9
   Nagasaka A, 2010, VISUAL DATABASE SYST
   Nie L, 2012, ACM INT C MULT
   Nie L, 2011, P 34 INT ACM SIGIR C
   Qiangjun L, 2019, COMPUT TECHNOL DEV, V29, P35
   Shanwu K, 2017, J GUANGXI UNIVNAT SC, V42, P728
   Shi L, 2018, MECHATRON SYST CONTR, V46, P39, DOI 10.2316/Journal.201.2018.1.201-2938
   Ye Z, 2018, J GUANGXI U NAT SCI, V43, P2258
   Yin Yong, 2010, Computer Engineering and Applications, V46, P186, DOI 10.3778/j.issn.1002-8331.2010.09.053
NR 18
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31617
EP 31632
DI 10.1007/s11042-019-08024-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000029
DA 2024-07-18
ER

PT J
AU Trujillo, AGS
   Orozco, ALS
   Villalba, LJG
   Kim, TH
AF Silva Trujillo, Alejandra Guadalupe
   Sandoval Orozco, Ana Lucila
   Garcia Villalba, Luis Javier
   Kim, Tai-Hoon
TI A traffic analysis attack to compute social network measures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks analysis; Privacy; Statistical disclosure attack;
   Anonymous network communications
ID STATISTICAL DISCLOSURE; COMMUNITY STRUCTURE; DISCOVERY; ANONYMITY;
   BEHAVIOR
AB The development of digital media, the increasing use of social networks, the easier access to modern technological devices, is perturbing thousands of people in their public and private lives. People love posting their personal news without consider the risks involved. Privacy has never been more important. Privacy enhancing technologies research have attracted considerable international attention after the recent news against users personal data protection in social media websites like Facebook. It has been demonstrated that even when using an anonymous communication system, it is possible to reveal user's identities through intersection attacks or traffic analysis attacks. Combining a traffic analysis attack with Analysis Social Networks (SNA) techniques, an adversary can be able to obtain important data from the whole network, topological network structure, subset of social data, revealing communities and its interactions. The aim of this work is to demonstrate how intersection attacks can disclose structural properties and significant details from an anonymous social network composed of a university community.
C1 [Silva Trujillo, Alejandra Guadalupe] UASLP, Fac Ingn, San Luis Potosi 78290, Mexico.
   [Sandoval Orozco, Ana Lucila; Garcia Villalba, Luis Javier] Univ Complutense Madrid, GASS, Fac Comp Sci & Engn, Dept Software Engn & Artificial Intelligence DISI, Off 431,Calle Prof Jose Garcia Santesmases 9, E-28040 Madrid, Spain.
   [Kim, Tai-Hoon] Sungshin Womens Univ, Dept Convergence Secur, 249-1 Dongseon Dong 3 Ga, Seoul 136742, South Korea.
C3 Universidad Autonoma de San Luis Potosi; Complutense University of
   Madrid; Sungshin Women's University
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, GASS, Fac Comp Sci & Engn, Dept Software Engn & Artificial Intelligence DISI, Off 431,Calle Prof Jose Garcia Santesmases 9, E-28040 Madrid, Spain.
EM asilva@uaslp.mx; asandoval@fdi.ucm.es; javiergv@fdi.ucm.es;
   taihoonn@daum.net
RI Silva, Alejandra/JAC-5470-2023; Silva, Alejandra/ABG-1430-2020;
   Villalba, Luis Javier Garcí­a/N-4631-2014; Orozco, Ana Lucila
   Sandoval/H-4148-2012
OI Silva-Trujillo, Alejandra Guadalupe/0000-0002-2419-8379
FU Sungshin Women's University; European Union [700326]; PRODEP (Apoyo para
   gastos de publicacion) [SEP-23-007-B]
FX This research work was supported by Sungshin Women's University. In
   addition, this project has received funding from the European Union's
   Horizon 2020 research and innovation programme under grant agreement No
   700326. Website: http://ramses2020.eu.Also, this work was funded by
   grants provided from PRODEP (Apoyo para gastos de publicacion
   SEP-23-007-B).
CR Ahmed HS, 2013, INT J SMART SENS INT, V6, P1317, DOI 10.21307/ijssis-2017-592
   Al Hasan M, 2011, SOCIAL NETWORK DATA ANALYTICS, P243
   AlFalahi K, 2014, INT J INTELL SYST, V29, P161, DOI 10.1002/int.21631
   Anderson A, 2001, COMMUNICATIONS ACM
   Anderson J, 2009, 2ND ACM SIGCOMM WORKSHOP ON ONLINE SOCIAL NETWORKS (WOSN 09), P1
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Barnes S. B., 2006, 1 MONDAY, V11, DOI DOI 10.5210/FM.V11I9.1394
   Bekkerman C, 2004, P CEAS 1
   Bonchi F, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961194
   Chapanond A., 2005, Computational & Mathematical Organization Theory, V11, P265, DOI 10.1007/s10588-005-5381-4
   Collingsworth B, 2009, COMPLEX NETWORKS STU, V207
   Culotta A, 2004, P 1 C EM ANT CEAS
   Danezis G, 2004, LECT NOTES COMPUT SC, V3200, P293
   Danezis G, 2009, SYSTEM ANONYMOUS COM
   Danezis G, 2007, LECT NOTES COMPUT SC, V4776, P30
   Danezis G, 2009, LECT NOTES COMPUT SC, V5672, P56, DOI 10.1007/978-3-642-03168-7_4
   Ding X, 2013, INF TECHNOL J, V12, P4882, DOI [10.3923/itj.2013.4882.4888, DOI 10.3923/ITJ.2013.4882.4888]
   Ebel H, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.035103
   Erdos P., 1959, Publicationes Mathematicae Debrecen, V6, P18
   Garg V, 2015, LECT NOTES COMPUTER, V7807
   Gross R., 2005, Proceedings of WPES'05, P71, DOI DOI 10.1145/1102199.1102214
   Hansen M, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P159, DOI 10.1109/SPW.2015.13
   Hopper N, 2006, P 5 ACM WORKSH PRIV, P9, DOI 10.1145/1179601.1179604
   Imizcoz J, 2001, INTRO ACTORES SOCIAL, P19
   Kala R, 2014, DISCRET MATH ALGORIT, V6, DOI 10.1142/S1793830914500372
   Knoke D, 2008, SOCIAL NETWORKS ANAL
   Leskovec J., 2007, ACM T KNOWL DISCOV D, V1, P2, DOI [DOI 10.1145/1217299.1217301, 10.1145/1217299.1217301]
   Leskovec J, 2009, INTERNET MATH, V6, P29, DOI 10.1080/15427951.2009.10129177
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Lian Liu, 2010, Proceedings IADIS International Conference Information Systems 2010, P372
   Liu Y., 2007, ACM SIGKDD Explorations Newsletter, V9, P62, DOI [10.1145/1345448.1345462, DOI 10.1145/1345448.1345462]
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI [DOI 10.1145/1217299.1217302, 10.1109/icde.2006.1, DOI 10.1109/ICDE.2006.1]
   McCallum A, 2007, J ARTIF INTELL RES, V30, P249, DOI 10.1613/jair.2229
   Moradi F, 2012, P 12 C OP INN ASS FR, P1, DOI [10.1145/2181176.2181185, DOI 10.1145/2181176.2181185]
   Portela J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111832
   Portela J, 2016, J SUPERCOMPUT, V72, P3787, DOI 10.1007/s11227-015-1524-7
   Portela J, 2015, SENSORS-BASEL, V15, P4052, DOI 10.3390/s150204052
   Socievole A, 2013, 2013 IEEE THIRD INTERNATIONAL CONFERENCE ON CLOUD AND GREEN COMPUTING (CGC 2013), P305, DOI 10.1109/CGC.2013.55
   Spiekermann S, 2017, J INF TECHNOL-UK, V32, P62, DOI 10.1057/jit.2016.4
   Streeter C.L., 1992, Journal of Social Service Research, V16, P201, DOI [DOI 10.1300/J079V16N0110, 10.1300/J079v16n01_10, DOI 10.1300/J079V16N01_10]
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Tyler JR, 2005, INFORM SOC, V21, P133, DOI 10.1080/01972240590925348
   Tyler JR, 2003, COMMUNITIES AND TECHNOLOGIES, P81
   Uddin M, 2010, P PAC AS C INF SYST, V415, P1937
   VANALSTYNE M, 2003, P ANN C N AM ASS COM
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Wey T, 2008, ANIM BEHAV, V75, P333, DOI 10.1016/j.anbehav.2007.06.020
   Wu XT, 2010, ADV DATABASE SYST, V40, P421, DOI 10.1007/978-1-4419-6045-0_14
NR 48
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29731
EP 29745
DI 10.1007/s11042-018-6217-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200006
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Cheng, KS
   Zhu, L
   Chen, RP
   Zhang, ZP
   Huang, F
AF Zhang, Chengyuan
   Cheng, Kesheng
   Zhu, Lei
   Chen, Ruipeng
   Zhang, Zuping
   Huang, Fang
TI Efficient continuous top-<i>k</i> geo-image search on road network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Geo-visual objects; Continuous top-k query; Road
   network
ID KEYWORD SEARCH; SIFT
AB With the rapid development of mobile Internet and cloud computing technology, large-scale multimedia data, e.g., texts, images, audio and videos have been generated, collected, stored and shared. In this paper, we propose a novel query problem named continuous top-k geo-image query on road network which aims to search out a set of geo-visual objects based on road network distance proximity and visual content similarity. Existing approaches for spatial textual query and geo-image query cannot address this problem effectively because they do not consider both of visual content similarity and road network distance proximity on road network. In order to address this challenge effectively and efficiently, firstly we propose the definition of geo-visual objects and continuous top-k geo-visual objects query on road network, then develop a score function for search. To improve the query efficiency in a large-scale road network, we propose the search algorithm named geo-visual search on road network based on a novel hybrid indexing framework called VIG-Tree, which combines G-Tree and visual inverted index technique. In addition, an important notion named safe interval and results updating rule are proposed, and based on them we develop an efficient algorithm named moving monitor algorithm to solve continuous query. Experimental evaluation on real multimedia dataset and road network dataset illustrates that our solution outperforms state-of-the-art method.
C1 [Zhang, Chengyuan; Cheng, Kesheng; Zhu, Lei; Chen, Ruipeng; Zhang, Zuping; Huang, Fang] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
C3 Central South University
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM cyzhang@csu.edu.cn; chengks0901@csu.edu.cn; leizhu@csu.edu.cn;
   rpchen@csu.edu.cn; zpzhang@csu.edu.cn; hfang@csu.edu.cn
RI Zhu, Lei/GQQ-1130-2022; HUANG, FANG/JBS-3517-2023
OI Zhu, Lei/0000-0002-5348-7532; 
FU National Natural Science Foundation of China [61702560]; project of
   Science and Technology Plan of Hunan Province [2018JJ3691, 2016JC2011];
   Research and Innovation Project of Central South University Graduate
   Students [2018zzts177]
FX This work was supported in part by the National Natural Science
   Foundation of China (61702560), project (2018JJ3691, 2016JC2011) of
   Science and Technology Plan of Hunan Province, and the Research and
   Innovation Project of Central South University Graduate
   Students(2018zzts177).
CR Alsubaiee Sattam., 2010, Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS'10, P61
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   [Anonymous], 2013, P 16 INT C EXT DAT T
   [Anonymous], 2012, Advances in neural information processing systems
   Cary A, 2010, LECT NOTES COMPUT SC, V6187, P87, DOI 10.1007/978-3-642-13818-8_8
   Chen C, 2013, J COMPUTER RES DEV
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Cong G., 2009, PROC VLDB ENDOW, V2, P337, DOI DOI 10.14778/1687627.1687666
   De Felipe I, 2008, PROC INT CONF DATA, P656, DOI 10.1109/ICDE.2008.4497474
   Fagin R, 2003, J COMPUT SYST SCI, V66, P614, DOI 10.1016/S0022-0000(03)00026-6
   Fang HL, 2015, LECT NOTES COMPUT SC, V9093, P194, DOI 10.1007/978-3-319-19548-3_16
   Fu R., 2016, P 2 IEEE INT C COMP
   Gao YJ, 2015, IEEE T KNOWL DATA EN, V27, P1205, DOI 10.1109/TKDE.2014.2365820
   Guo L, 2015, GEOINFORMATICA, V19, P29, DOI 10.1007/s10707-014-0204-8
   Hariharan Ramaswamy, 2007, 2007 International Conference on Scientific and Statistical Database Management, DOI 10.1109/SSDBM.2007.22
   He J., 2011, 20 INT C INFORM KNOW, P423
   Hjaltason GR, 1999, ACM T DATABASE SYST, V24, P265, DOI 10.1145/320248.320255
   Huang K, 2012, MIDWEST SYMP CIRCUIT, P932, DOI 10.1109/MWSCAS.2012.6292174
   Irtaza A, 2015, MULTIMED TOOLS APPL, V74, P5055, DOI 10.1007/s11042-013-1679-2
   Ke Y, 2004, PROC CVPR IEEE, P506
   Li CW, 2014, PROC VLDB ENDOW, V8, P113
   Li Y, 2013, J HUAZHONG U SCI T E, P29
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Lin X, 2016, PROC INT CONF DATA, P1488, DOI 10.1109/ICDE.2016.7498388
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo CY, 2016, KNOWL-BASED SYST, V93, P121, DOI 10.1016/j.knosys.2015.11.009
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Rocha-Junior J.B., 2012, EDBT, P168
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.2013.6738166
   Wu DM, 2012, VLDB J, V21, P797, DOI 10.1007/s00778-012-0271-0
   Wu DM, 2012, IEEE T KNOWL DATA EN, V24, P1889, DOI 10.1109/TKDE.2011.172
   Wu DM, 2011, PROC INT CONF DATA, P541, DOI 10.1109/ICDE.2011.5767861
   Wu L, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (9TH), VOL II, P598
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Xiao ZM, 2014, MULTIMED TOOLS APPL, V73, P2157, DOI 10.1007/s11042-013-1693-4
   Yang Wang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P234, DOI 10.1007/978-3-319-06605-9_20
   Yao B, 2010, PROC INT CONF DATA, P545, DOI 10.1109/ICDE.2010.5447836
   Zhang C., 2014, 17 INT C EXTENDING D, P367
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zhang CY, 2013, PROC INT CONF DATA, P901, DOI 10.1109/ICDE.2013.6544884
   Zhang DX, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/2600428.2609562
   Zhang DX, 2010, PROC INT CONF DATA, P521, DOI 10.1109/ICDE.2010.5447897
   Zhang DX, 2009, PROC INT CONF DATA, P688, DOI 10.1109/ICDE.2009.77
   Zhang GX, 2017, NEUROCOMPUTING, V238, P399, DOI 10.1016/j.neucom.2017.01.081
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhou Y., 2005, ACM CIKM, P155
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 63
TC 5
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30809
EP 30838
DI 10.1007/s11042-018-6633-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200064
DA 2024-07-18
ER

PT J
AU Du, SY
   Liu, ZG
AF Du, Sheng-Yong
   Liu, Zhao-Guang
TI Hybridizing Particle Swarm Optimization with JADE for continuous
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous optimization; Particle swarm optimization; Differential
   evolution; Hybrid algorithm
ID DIFFERENTIAL EVOLUTION; ALGORITHM; COLONY
AB As a population-based random search optimization technique, particle swarm optimization (PSO) has become an important branch of swarm intelligence (SI). To utilizing the advantage of operations in different SI, this study proposed a hybrid of multi-crossover operation and adaptive differential evolution with optional external archive (JADE), named PSOJADE, to balance the global and local search capabilities. In the experiments, the proposed algorithm is compared with six other advanced differential evolution (DE), PSO, and hybrid of DE and PSO techniques using 30 benchmark functions in CEC2017. To evaluate the effectiveness of the proposed PSOJADE more comprehensively, the experiments were implemented on 10-D, 30-D, and 50-D respectively. The experimental results indicate that the proposed algorithm yields better solution accuracy than the other techniques on 10-D, 30-D, and 50-D meanwhile.
C1 [Du, Sheng-Yong] Shandong Univ Finance & Econ, Sch Management Sci & Engn, Jinan, Shandong, Peoples R China.
   [Liu, Zhao-Guang] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University of
   Finance & Economics
RP Du, SY (corresponding author), Shandong Univ Finance & Econ, Sch Management Sci & Engn, Jinan, Shandong, Peoples R China.
EM dushy@sdufe.edu.cn; liuzhg@sdufe.edu.cn
OI Du, Sheng-Yong/0000-0003-0339-1222
FU Shandong Provincial Natural Science Foundation, China [ZR2017MF067,
   2016GGX101022]
FX This work was supported by a grant from the Shandong Provincial Natural
   Science Foundation, China (Grant nos. ZR2017MF067 and 2016GGX101022).
CR [Anonymous], 1995, Technical Report tr-95-012
   Chang WD, 2007, EXPERT SYST APPL, V33, P620, DOI 10.1016/j.eswa.2006.06.003
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Juang CF, 2004, IEEE T SYST MAN CY B, V34, P997, DOI 10.1109/TSMCB.2003.818557
   Kao YT, 2008, APPL SOFT COMPUT, V8, P849, DOI 10.1016/j.asoc.2007.07.002
   Kennedy J., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1931, DOI 10.1109/CEC.1999.785509
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li ZY, 2015, EXPERT SYST APPL, V42, P8881, DOI 10.1016/j.eswa.2015.07.043
   Lim WH, 2014, INFORM SCIENCES, V273, P49, DOI 10.1016/j.ins.2014.03.031
   LIN GH, 2016, INT J AUT COMPUT
   Mahmoodabadi MJ, 2014, INFORM SCIENCES, V273, P101, DOI 10.1016/j.ins.2014.02.150
   Mandloi M, 2016, EXPERT SYST APPL, V50, P66, DOI 10.1016/j.eswa.2015.12.008
   Marinakis Y, 2017, EUR J OPER RES, V261, P819, DOI 10.1016/j.ejor.2017.03.031
   Meng AB, 2014, KNOWL-BASED SYST, V67, P218, DOI 10.1016/j.knosys.2014.05.004
   Meng AB, 2016, INFORM SCIENCES, V329, P52, DOI 10.1016/j.ins.2015.08.018
   Nwankwor E, 2013, COMPUTAT GEOSCI, V17, P249, DOI 10.1007/s10596-012-9328-9
   Shelokar PS, 2007, APPL MATH COMPUT, V188, P129, DOI 10.1016/j.amc.2006.09.098
   Singh N, 2014, PATTERN RECOGN, V47, P1731, DOI 10.1016/j.patcog.2013.11.012
   Soleimani H, 2015, APPL MATH MODEL, V39, P3990, DOI 10.1016/j.apm.2014.12.016
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Suganthan P, 2016, Problem definitions and evaluation criteria for the CEC 2017 special session and competition on single objective bound constrained real-parameter numerical optimization
   Tanabe R, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P71
   Nguyen TT, 2014, EXPERT SYST APPL, V41, P2134, DOI 10.1016/j.eswa.2013.09.012
   Wang SC, 2014, EXPERT SYST APPL, V41, P3069, DOI 10.1016/j.eswa.2013.10.038
   Wu GH, 2016, INFORM SCIENCES, V329, P329, DOI 10.1016/j.ins.2015.09.009
   Wu G, 2014, EXPERT SYST APPL, V41, P7536, DOI 10.1016/j.eswa.2014.06.005
   Yu Xiaobing, 2014, ScientificWorldJournal, V2014, P215472, DOI 10.1155/2014/215472
   Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613
   Zhang WJ, 2003, IEEE SYS MAN CYBERN, P3816
NR 29
TC 20
Z9 21
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4619
EP 4636
DI 10.1007/s11042-019-08142-7
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000492341300002
DA 2024-07-18
ER

PT J
AU Awad, M
   Abd El-Samie, FE
   Abd Elnaby, MM
   El-Rabaie, ESM
   Faragallah, OS
   El-Khobby, HA
AF Awad, Maha
   Abd El-Samie, Fathi E.
   Abd Elnaby, Mustafa M.
   El-Rabaie, El-Sayed M.
   Faragallah, Osama S.
   El-Khobby, Heba A.
TI Efficient storage and classification of color patterns based on
   integrating interpolation with ANN/SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Color interpolation; CFA; ANN; SVM; Adaptive
   sharpening
ID CEPSTRAL COEFFICIENTS; SPEECH; PREDICTION
AB Color images usually have large storage sizes as they are composed of three planes in the raw image format represented with the red, green, and blue components. Traditional color image compression schemes can be used to save the storage size of the color images. Unfortunately, most of these schemes are lossy in nature, which affects the details of color images. This paper presents a different treatment to the color image storage problem depending on the original color image formation process. In the color image formation process, not all the red, green, and blue components of the color images are acquired, simultaneously. Only, one component at each pixel position is acquired and Color Filter Array (CFA) interpolation is used to estimate the other two components using interpolation algorithms like Minimized-Laplacian Residual Interpolation (MLRI) and Linear Interpolation with Laplacian Second Order Correction (LILSOC). We adopt a similar strategy in this paper for reducing the storage sizes of color images by 66.67% of their original sizes. The sensitivity of the pattern recognition process to the proposed color image storage and interpolation strategy is studied in this paper. A cepstral feature extraction algorithm is adopted in this paper for extracting features from the interpolated patterns for further classification. Moreover, two types of classifiers are considered and compared in this paper for the pattern recognition: Artificial Neural Networks (ANNs), and Support Vector Machines (SVMs). Simulation results reveal the success of the proposed strategy for color image storage and interpolation in obtaining high-quality color images in addition to the high Recognition Rates (RR) of color patterns after interpolation. This success encourages the use of the proposed color image storage strategy in storing large volumes of color databases.
C1 [Awad, Maha; Abd Elnaby, Mustafa M.; El-Khobby, Heba A.] Tanta Univ, Dept Elect & Elect Commun, Fac Engn, Tanta, Egypt.
   [Abd El-Samie, Fathi E.; El-Rabaie, El-Sayed M.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Taif Univ, Dept Informat Technol, Coll Comp & Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Menofia
   University; Taif University
RP Awad, M (corresponding author), Tanta Univ, Dept Elect & Elect Commun, Fac Engn, Tanta, Egypt.
EM maha3782@yahoo.com; fathi_sayed@yahoo.com; mnaby@f-eng.tanta.edu.eg;
   srabie1@yahoo.com; o.salah@tu.edu.sa; H.El-Khobby@f-eng.tanta.edu.eg
RI Faragallah, Osama S./AHB-8031-2022; Sayed, Fathi/HRA-4752-2023; Deyab,
   Mustafa/B-4350-2019
OI Faragallah, Osama S./0000-0003-1982-335X; Sayed,
   Fathi/0000-0001-8749-9518; Deyab, Mustafa/0000-0001-8281-1840;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abdelghafour F, 2019, COMPUT ELECTRON AGR, V158, P345, DOI 10.1016/j.compag.2019.02.017
   [Anonymous], 1999, The Nature Statist. Learn. Theory
   [Anonymous], 2015, INDIAN J SCI TECHNOL
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bloodgood M, 2018, IEEE 12 INT C SEM CO
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cernadas E, 2017, PATTERN RECOGN, V61, P120, DOI 10.1016/j.patcog.2016.07.002
   Chengalvarayan R, 1998, IEEE T SPEECH AUDI P, V6, P505, DOI 10.1109/89.725317
   Cristianini Nello., 2004, INTRO SUPPORT VECTOR
   Daisoku K, 2014, ELECT IMAGING SPIE, V9023, p90230L
   Deo RC, 2018, RENEW ENERG, V116, P309, DOI 10.1016/j.renene.2017.09.078
   Dharanipragada S, 2007, IEEE T AUDIO SPEECH, V15, P224, DOI 10.1109/TASL.2006.876776
   Feres M, 2018, INT DENT J, V68, P39, DOI 10.1111/idj.12326
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611
   Hamilton Jr J. F., 1997, US Patent, Patent No. [5,629,734, 5629734]
   Hantke S, 2017, INTERSPEECH, P3951, DOI 10.21437/Interspeech.2017-406
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jiang B, 2008, J MACH LEARN RES, V9, P521
   Kasban H., 2009, Progress In Electromagnetics Research C, V6, P79, DOI 10.2528/PIERC08112002
   Kasban H, 2008, IEEE INT C COMP ENG
   Kinnunen Tomi, 2003, THESIS
   Kofidis E, 1999, FUTURE GENER COMP SY, V15, P223, DOI 10.1016/S0167-739X(98)00066-1
   Kumar YHS, 2015, PROCEDIA COMPUT SCI, V45, P226, DOI 10.1016/j.procs.2015.03.125
   Lu BL, 2009, FRONT COMPUT SCI CHI, V3, P109, DOI 10.1007/s11704-009-0013-7
   Mitra SK, 2000, IETE J RES, V46, P279, DOI 10.1080/03772063.2000.11416168
   Oyewole SA, 2018, EGYPT INFORM J, V19, P83, DOI 10.1016/j.eij.2017.10.002
   Peng J, 2003, T NEURAL NETWORKS, V14, P158
   Polur PD, 2005, IEEE T NEUR SYS REH, V13, P558, DOI 10.1109/TNSRE.2005.856074
   Sarikaya R., 2001, THESIS
   Schomer DF, 1998, RADIOGRAPHICS, V18, P469, DOI 10.1148/radiographics.18.2.9536490
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Thakur RK, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 1, PROCEEDINGS, P905, DOI 10.1109/CSO.2009.383
   Tufekci Z, 2001, THESIS
   Vergin R, 1999, IEEE T SPEECH AUDI P, V7, P525, DOI 10.1109/89.784104
   Wu YG, 2002, IEEE T INF TECHNOL B, V6, P86, DOI 10.1109/4233.992167
   Xiang N, 2003, J ACOUST SOC AM, V113, P1333, DOI 10.1121/1.1543554
   Xiang N, 2000, P SOC PHOTO-OPT INS, V4038, P645, DOI 10.1117/12.396292
   Xiong Z, 1999, IEEE T CIRCUITS SYST, V9, P352
   Yassin M, 2017, INT J ADV SCI ENG IN, V7
   Zeng R, 2016, NEUROCOMPUTING, V216, P416, DOI 10.1016/j.neucom.2016.08.006
   Zhang Z, 2020, MECH ADV MATER STRUC, V27, P3, DOI 10.1080/15376494.2018.1444216
   Zhu X, 2011, RESTORATION WEAKLY B
NR 44
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 947
EP 978
DI 10.1007/s11042-019-07915-4
EA OCT 2019
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492236300004
DA 2024-07-18
ER

PT J
AU Choi, CR
   Jeong, HY
AF Choi, Cheol-Rim
   Jeong, Hwa-Young
TI Quality evaluation for multimedia contents of e-learning systems using
   the ANP approach on high speed network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ANP; E-learning system; System quality attribute; Quality evaluation
   model; QoS for learning system
ID SUCCESS MODEL; MCLEAN MODEL; DELONE; TECHNOLOGY; ADOPTION
AB E-learning systems have played an important role in the education field and have been widely employed in many educational institutions. Although the need to evaluate the quality of e-learning systems is emerging, there is currently no appropriate evaluation method due to the complicated correlations between quality attributes. This study develops a quality evaluation model that calculates the priority weights of each quality attribute while accounting for their correlations and evaluates the overall quality of a learning system with numerical results. First, the study constructs a quality attribute network that reflects the correlations between 4 main quality clusters and 19 sub-attributes. Second, it calculates the priority weights of the attributes using the Analytic Network Process (ANP). Finally, using the quality network and weights, this study evaluates three types of e-learning systems employed by Kyunghee Cyber University. The results indicate that the proposed evaluation method provides a mechanism for objectively analyzing and comparing the qualities of various kinds of learning systems and suggests guidelines for constructors and managers of learning systems.
C1 [Choi, Cheol-Rim; Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul 130701, South Korea.
C3 Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul 130701, South Korea.
EM cr_brian@khu.ac.kr; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Adibi Sasan, 2010, Telematics and Informatics, V27, P377, DOI 10.1016/j.tele.2010.01.001
   Aldholay AH, 2018, TELEMAT INFORM, V35, P1421, DOI 10.1016/j.tele.2018.03.012
   Alkhattabi M, 2011, COMPUT HUM BEHAV, V27, P862, DOI 10.1016/j.chb.2010.11.011
   Aragonés-Beltrán P, 2010, RENEW SUST ENERG REV, V14, P249, DOI 10.1016/j.rser.2009.07.012
   Aragonés-Beltrán P, 2017, INT J PROJ MANAG, V35, P451, DOI 10.1016/j.ijproman.2017.01.001
   Carchiolo V, 2010, INFORM SCIENCES, V180, P1893, DOI 10.1016/j.ins.2009.12.023
   Chang CW, 2007, INFORM SCIENCES, V177, P3383, DOI 10.1016/j.ins.2007.02.010
   Chao RJ, 2009, EXPERT SYST APPL, V36, P10657, DOI 10.1016/j.eswa.2009.02.047
   Chiu CM, 2007, COMPUT EDUC, V49, P1224, DOI 10.1016/j.compedu.2006.01.010
   Chuang SC, 2005, COMPUT HUM BEHAV, V21, P255, DOI 10.1016/j.chb.2004.02.015
   Chung SH, 2005, INT J PROD ECON, V96, P15, DOI 10.1016/j.ijpe.2004.02.006
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   Georgieva ES, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.106
   Gunasekaran A., 2002, IND COMMER TRAIN, V34, P44, DOI [10.1108/00197850210417528, DOI 10.1108/00197850210417528]
   Halonen R, 2008, WORKING PAPERS INFOR, V8, P1
   Halonen R., 2009, International Conference on Organizational Learning, Knowlodge and Capabilities, P1
   Herrera-Viedma E, 2006, J AM SOC INF SCI TEC, V57, P538, DOI 10.1002/asi.20308
   Huang YM, 2012, COMPUT EDUC, V58, P273, DOI 10.1016/j.compedu.2011.08.008
   Jiang XD, 2018, POLAR SCI, V17, P83, DOI 10.1016/j.polar.2018.05.009
   Jung HW, 2004, IEEE SOFTWARE, V21, P88, DOI 10.1109/MS.2004.1331309
   Jung U, 2010, DECIS SUPPORT SYST, V49, P335, DOI 10.1016/j.dss.2010.04.005
   Lee-Post A, 2009, ELECTRON J E-LEARN, V7, P61
   Lin HF, 2010, COMPUT EDUC, V54, P877, DOI 10.1016/j.compedu.2009.09.017
   Meade LM, 1999, INT J PROD RES, V37, P241, DOI 10.1080/002075499191751
   Michael R, 2005, ECIS 2005 INFORM SYS, P26
   Ngai EWT, 2007, COMPUT EDUC, V48, P250, DOI 10.1016/j.compedu.2004.11.007
   Pituch KA, 2006, COMPUT EDUC, V47, P222, DOI 10.1016/j.compedu.2004.10.007
   Rai A, 2002, INFORM SYST RES, V13, P50, DOI 10.1287/isre.13.1.50.96
   Ramayah T, 2010, PROCD SOC BEHV, V2, P5422, DOI 10.1016/j.sbspro.2010.03.885
   Ranganathan C, 2002, INFORM MANAGE-AMSTER, V39, P457, DOI 10.1016/S0378-7206(01)00112-4
   Roky H, 2015, PROC ECON FINANC, V26, P903, DOI 10.1016/S2212-5671(15)00903-X
   Saaty T.L., 1996, DECISION MAKING DEPE
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   Samarasinghe S.M., 2009, P ASC SAM PLAC DIFF, P908
   SRINIVASAN A, 1985, MIS QUART, V9, P243, DOI 10.2307/248951
   Su JH, 2010, INFORM SCIENCES, V180, P113, DOI 10.1016/j.ins.2009.08.005
   Villalba MT, 2010, IET SOFTW, V4, P1, DOI 10.1049/iet-sen.2009.0040
   Wang SL, 2011, EXPERT SYST APPL, V38, P10831, DOI 10.1016/j.eswa.2011.02.083
   Wang WT, 2009, COMPUT EDUC, V53, P761, DOI 10.1016/j.compedu.2009.02.021
   Wang YS, 2007, COMPUT HUM BEHAV, V23, P1792, DOI 10.1016/j.chb.2005.10.006
   Wixom BH, 2005, INFORM SYST RES, V16, P85, DOI 10.1287/isre.1050.0042
   Wu T-T, 2011, INF SCI, V21, P1
   Yüksel I, 2007, INFORM SCIENCES, V177, P3364, DOI 10.1016/j.ins.2007.01.001
   Zhang LX, 2010, MATH COMPUT MODEL, V51, P1428, DOI 10.1016/j.mcm.2009.11.013
   Zhao L., 2007, Journal of Technology and Teacher Education, V15, P311
NR 47
TC 19
Z9 19
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28853
EP 28875
DI 10.1007/s11042-019-7351-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700028
DA 2024-07-18
ER

PT J
AU Khan, MA
   Rashid, M
   Sharif, M
   Javed, K
   Akram, T
AF Khan, Muhammad Attique
   Rashid, Muhammad
   Sharif, Muhammad
   Javed, Kashif
   Akram, Tallha
TI Classification of gastrointestinal diseases of stomach from WCE using
   improved saliency-based method and discriminant features selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WCE; Active contour; Disease segmentation; Pixel-based fusion; Feature
   extraction; Reduction; Classification
ID CAPSULE ENDOSCOPY IMAGES; WIRELESS; RECOGNITION
AB Wireless capsule endoscopy (WCE) is a new imaging procedure that is used to record internal conditions of gastrointestinal tract for medical diagnosis. However, due to the presence of bulk of WCE image data, it becomes difficult for the physician to investigate it thoroughly. Therefore, considering aforementioned constraint, lately gastrointestinal diseases are identified by computer-aided methods and with better classification accuracy. In this research, a new computer-based diagnosis method is proposed for the detection and classification of gastrointestinal diseases from WCE images. The proposed approach comprises of four fundamentalsteps:1) HSI color transformation before implementing automatic active contour segmentation; 2) implementation of a novel saliency-based method in YIQ color space; 3) fusion of images using proposed maximizing a posterior probability method; 4) fusion of extracted features, calculated using SVD, LBP, and GLCM, prior to final classification step. We perform our simulations on our own collected dataset - containing total 9000 samples of ulcer, bleeding and healthy. To prove the authenticity of proposed work, list of statistical measures is considered including classification accuracy, FNR, sensitivity, AUC, and Time. Further, a fair comparison of state-of-the-art classifiers is also provided which will be giving readers a deep inside of classifier's selection for this application. Simulation results clearly reveal that the proposed method shows improved performance in terms of segmentation and classification accuracy.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
   [Khan, Muhammad Attique; Rashid, Muhammad; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Cantt, Pakistan.
   [Javed, Kashif] NUST, Sch Mech & Mfg Engn, H-12, Islamabad, Pakistan.
   [Akram, Tallha] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah Cantt, Pakistan.
C3 NITEC University; COMSATS University Islamabad (CUI); National
   University of Sciences & Technology - Pakistan; COMSATS University
   Islamabad (CUI)
RP Akram, T (corresponding author), COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah Cantt, Pakistan.
EM tallha@ciitwah.edu.pk
RI Rashid, Muhammad/KSM-3480-2024; Sharif, Muhammad/AAB-8376-2022; Javed,
   Kashif/AAF-8436-2020; Akram, Tallha/KPB-3017-2024; Sharif,
   Muhammad/ACD-2598-2022; khan, sajid/HGE-2406-2022; Khan, Dr. Muhammad
   Attique/AAX-2644-2021
OI Rashid, Muhammad/0000-0002-2557-6845; Akram, Tallha/0000-0003-4578-3849;
   Sharif, Muhammad/0000-0002-7258-8400; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890
CR Akram T., 2018, J AMB INTEL HUM COMP, P1, DOI DOI 10.1007/S12652-018-1051-5
   [Anonymous], IM PROC ICIP 2017 IE
   [Anonymous], MICROSC RES TECH
   [Anonymous], ADV TECHN SIGN IM PR
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], COMPUT METHODS PROG
   [Anonymous], SIGN PROC MED BIOL S
   [Anonymous], INT J CONTROL AUTOMA
   [Anonymous], REG 10 C TENCON 2017
   [Anonymous], MICROSC RES TECH
   [Anonymous], HUM TECHN C R10 HTC
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Duan QC, 2016, OPTIK, V127, P7418, DOI 10.1016/j.ijleo.2016.05.027
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imran M, 2018, 2018 INTERNATIONAL CONFERENCE ON ENGINEERING & EMERGING TECHNOLOGIES (ICEET), P1
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan S.A., 2019, Microsc. Res. Tech
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Maghsoudi O.H., 2018, ARXIV PREPRINT ARXIV
   Mergener Klaus, 2008, Gastroenterol Hepatol (N Y), V4, P107
   Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Sharif N, 2018, J OCUL PHARMACOL TH, V34, P1, DOI 10.1089/jop.2017.29037.int
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21395]
   Sivakumar P, 2018, CLUSTER COMPUT, P1
   STEWART GW, 1993, SIAM REV, V35, P551, DOI 10.1137/1035134
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Xue Z, 2003, PATTERN RECOGN, V36, P2819, DOI 10.1016/S0031-3203(03)00181-X
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang SW, 2016, NEUROCOMPUTING, V205, P341, DOI 10.1016/j.neucom.2016.04.034
NR 38
TC 41
Z9 41
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27743
EP 27770
DI 10.1007/s11042-019-07875-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000044
DA 2024-07-18
ER

PT J
AU Szczuko, P
AF Szczuko, Piotr
TI Deep neural networks for human pose estimation from a very low
   resolution depth image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Pose estimation; Artificial neural networks; Deep learning
ID GESTURE RECOGNITION
AB The work presented in the paper is dedicated to determining and evaluating the most efficient neural network architecture applied as a multiple regression network localizing human body joints in 3D space based on a single low resolution depth image. The main challenge was to deal with a noisy and coarse representation of the human body, as observed by a depth sensor from a large distance, and to achieve high localization precision. The regression network was expected to reason about relations of body parts based on depth image, and to extract locations of joints, and provide coordinates defining the body pose. The method involved creation of a dataset with 200,000 realistic depth images of a 3D body model, then training and testing numerous architectures including feedforward multilayer perceptron network and deep convolutional neural networks. The results of training and evaluation are included and discussed. The most accurate DNN network was further trained and evaluated on an augmented depth images dataset. The achieved accuracy was similar to a reference Kinect algorithm results, with a great benefit of fast processing speed and significantly lower requirements on sensor resolution, as it used 100 times less pixels than Kinect depth sensor. The method was robust against sensor noise, allowing imprecision of depth measurements. Finally, our results were compared with VGG, MobileNet, and ResNet architectures.
C1 [Szczuko, Piotr] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczuko, P (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, Gdansk, Poland.
EM szczuko@multimed.org
RI Szczuko, Piotr/AAB-4822-2020
OI Szczuko, Piotr/0000-0003-3703-8734
FU Statutory Funds of Electronics, Telecommunications and Informatics
   Faculty, Gdansk University of Technology
FX This work has been partially supported by Statutory Funds of
   Electronics, Telecommunications and Informatics Faculty, Gdansk
   University of Technology.
CR Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Chen T, 2018, MXNET R PACKAGE VERS
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Crabbe B, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P312, DOI 10.1109/ICCVW.2015.49
   Ganapathi V., 2010, Computer Vision and Pattern Recognition (CVPR 2010), P755, DOI DOI 10.1109/CVPR.2010.5540141
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hesse N, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P427, DOI 10.1109/ICCVW.2015.63
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jung H, 2017, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2017.129
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leite DQ, 2017, MULTIMED TOOLS APPL, V76, P20423, DOI 10.1007/s11042-016-3959-0
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Ly DL, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P967, DOI 10.1145/2330163.2330297
   Mahendran S, 2018, ARXIV171107426
   Mahendran S, 2017, IEEE COMPUT SOC CONF, P494, DOI 10.1109/CVPRW.2017.73
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Núñez JC, 2017, MULTIMED TOOLS APPL, V76, P4249, DOI 10.1007/s11042-016-3759-6
   Park S, 2017, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2017.19
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Szczuko P, 2018, 11 INT C HUM SYST IN, DOI [10.1109/HSI.2018.8431338, DOI 10.1109/HSI.2018.8431338]
   Szczuko P, 2018, VERY LOW RESOLUTION
   Szczuko P, 2017, SIG P ALGO ARCH ARR, P354, DOI 10.23919/SPA.2017.8166892
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Togootogtokh E, 2018, MULTIMED TOOLS APPL, V77, P9233, DOI 10.1007/s11042-017-4784-9
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang K, 2016, IEEE INT C BIOINFORM, P1228, DOI 10.1109/BIBM.2016.7822694
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
NR 34
TC 14
Z9 14
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29357
EP 29377
DI 10.1007/s11042-019-7433-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700052
OA hybrid
DA 2024-07-18
ER

PT J
AU Yuan, QY
   Xiao, NF
AF Yuan, Qunyong
   Xiao, Nanfeng
TI A monotonic policy optimization algorithm for high-dimensional
   continuous control problem in 3D MuJoCo
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reinforcement learning; Policy optimization; Continuous control policy;
   Deep neural network
AB One challenge in applying reinforcement learning with nonlinear function approximator to high- dimensional continuous control problems is that the update policy produced by the many existed algorithms may fail to improve policy performance or even causes a serious degradation of the policy performance. To address this challenge, this paper proposes a new lower bound on the policy improvement where an average policy divergence on state space is penalized. To the best of our knowledge, this is currently the best result about the lower bound on the policy improvement. Optimizing directly the lower bound on the policy improvement is very difficult, because it demands for high computational overhead. According to the ideal of the trust region policy optimization (TRPO), this paper also presents a monotonic policy optimization algorithm, which is based on the new lower bound on the policy improvement introduced in this paper, it can generate a sequence of monotonically improving policies, and it is suitable for the large-scale continuous control problems. This paper also evaluates and compares the proposed algorithms with some of the existed algorithms on highly challenging robot locomotion tasks.
C1 [Yuan, Qunyong; Xiao, Nanfeng] South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology
RP Yuan, QY (corresponding author), South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM 201410102104@mail.scut.edu.cn; xiaonf@scut.edu.cn
FU National Natural Science Foundation [61573145]; Public Research and
   Capacity Building of Guangdong Province [2014B010104001]; Basic and
   Applied Basic Research of Guangdong Province [2015A03030 8018]
FX This research is funded by the National Natural Science Foundation
   (Project No. 61573145), the Public Research and Capacity Building of
   Guangdong Province (Project No. 2014B010104001) and the Basic and
   Applied Basic Research of Guangdong Province (Project No. 2015A03030
   8018), the authors are greatly thanks to these grants.
CR [Anonymous], 2015, ABS150906461 CORR
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ARXIV160209118
   Duan Y, 2016, PR MACH LEARN RES, V48
   HAVIV M, 1984, ADV APPL PROBAB, V16, P804, DOI 10.2307/1427341
   Kakade S. M., 2002, INT C MACH LEARN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Martens James, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P479, DOI 10.1007/978-3-642-35289-8_27
   Martens J, 2015, PR MACH LEARN RES, V37, P2408
   Mnih V., 2016, PROC INT C MACH LEAR, P1928
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278
   Peters J, 2008, NEUROCOMPUTING, V71, P1180, DOI 10.1016/j.neucom.2007.11.026
   Pirotta M., 2013, INT C MACHINE LEARNI, P307
   Schull J, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P1, DOI 10.1145/2700648.2809870
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Silver David, 2014, ICML, P387
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Thomas PS, 2015, AAAI CONF ARTIF INTE, P3000
   Thomas PS, 2015, PR MACH LEARN RES, V37, P2380
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Wang ZY, 2016, PR MACH LEARN RES, V48
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Ye YY, 2011, MATH OPER RES, V36, P593, DOI 10.1287/moor.1110.0516
NR 24
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28665
EP 28680
DI 10.1007/s11042-018-6098-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700018
DA 2024-07-18
ER

PT J
AU Zhang, H
   Hong, XG
AF Zhang, Hao
   Hong, Xianggong
TI Recent progresses on object detection: a brief review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Object detection; Deep convolutional neural networks (CNNs); Recent
   progress; Computer vision
AB Object detection, aiming at locating objects from a large number of specific categories in natural images, is a fundamental but challenging task in the field of computer vision. Recent years have seen significant progress of object detection using deep CNN mainly due to its robust feature representation ability. The goal of this paper is to provide a simple but comprehensive survey of the recent improvements in object detection in the era of deep learning. More than 100 key contributions are investigated mainly from five directions: architecture diagram, contextual reasoning, multi-layer exploiting, training strategy, and others which includes some other progress like real-time object detectors and works borrowing the idea from RNN and GAN. We discuss comprehensive but straightforward experimental comparisons under widely used benchmarks and metrics. This review finishes by providing promising trends for future research.
C1 [Zhang, Hao; Hong, Xianggong] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Hong, XG (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM haozhang@email.ncu.edu.cn; fengshenglanshan@163.com
RI Zhang, Hao/AAP-9462-2020
OI Zhang, Hao/0000-0003-1923-589X
CR [Anonymous], P INT C COMP VIS ICC
   [Anonymous], 2017, ARXIV171200726
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, COMPUT RES REPOS
   [Anonymous], 2018, COMPUTER VISION PATT
   [Anonymous], ARXIV1711115758
   [Anonymous], 2018, ARXIV180206488
   [Anonymous], 2017, FSSD FEATURE FUSION
   [Anonymous], 2012, PROC IEEE C COMPUTER
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2017, ARXIV171107264
   [Anonymous], ARXIV180711164
   [Anonymous], 9 INT C GRAPH IM PRO
   [Anonymous], 2017, COMPUT GRAPH-UK, DOI DOI 10.1109/TPAMI.2017.2771779
   [Anonymous], 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ARXIV180506157
   [Anonymous], 2018, ARXIV180406882
   [Anonymous], ARXIV180507009
   [Anonymous], 2018, ARXIV180105918
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], ARXIV180506361
   [Anonymous], 2015, P INT C COMP VIS ICC
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], IMAGENET TRAINING MI
   [Anonymous], ARXIV180701696
   [Anonymous], CVPR
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, IEEE CVPR
   [Anonymous], 2017, BMVC, DOI DOI 10.5244/C.31.76
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2002, ARXIV170802002
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   [Anonymous], ARXIV180406215
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2018, INVERTED RESIDUALS L
   Bansal Ankan, 2018, P EUR C COMP VIS ECC, P384
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cruz-Manzo S, 2018, MACHINES, V6, DOI 10.3390/machines6040043
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R.B., 2012, Discriminatively trained deformable part models, release 5
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goyal Priya, 2017, abs/1706.02677
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   He K., 2018, arXiv
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hong S, 2016, ARXIV161108588
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JA, 2018, IEEE T MULTIMEDIA, V20, P1645, DOI 10.1109/TMM.2017.2772796
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J., 2017, Adversarial examples that fool detectors
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Shen Z., 2017, P IEEE INT C COMP VI, V3, P7
   Shrivastava A., 2016, ARXIV PREPRINT ARXIV
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Simonyan K., 2014, 14091556 ARXIV
   Singh B, 2018, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2018.00119
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang JQ, 2014, IEEE T CIRC SYST VID, V24, P1620, DOI 10.1109/TCSVT.2014.2308616
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yeong-Hyeon Byeon, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P975, DOI 10.1007/978-981-10-0557-2_93
   Yin DY, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P44, DOI 10.1109/DSC.2016.74
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng X, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON MECHANICAL, ELECTRONIC AND INFORMATION TECHNOLOGY ENGINEERING (ICMITE 2016), P355
   Zhang S, 2017, SINGLE SHOT REFINEME
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YQ, 2018, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.2018.00103
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 107
TC 23
Z9 24
U1 10
U2 150
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27809
EP 27847
DI 10.1007/s11042-019-07898-2
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000047
DA 2024-07-18
ER

PT J
AU Kansal, S
   Tripathi, RK
AF Kansal, Shubhi
   Tripathi, Rajiv Kumar
TI Adaptive gamma correction for contrast enhancement of remote sensing
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamma correction; DCT transformation; Enhancement
ID ALGORITHM
AB Contrast magnification is a critical parameter of image enhancement. Remote sensing images are distance captured images, so they naturally have very low contrast as compared to other images. In this paper a very simple and efficient technique based on adaptive gamma correction and Discrete cosine transform(DCT) is proposed which can bring out the maximum information present in the image and enhance the contrast of the image very well. We first apply an adaptive gamma correction which enhances the image globally and than high frequency components of DCT transformation are further altered to intensify the minute details of the image. Proposed method is judged on the basis of visual quality and numerical parameters compared with the other existing techniques. The results obtained for proposed technique surpasses all the other methods both qualitatively and quantitatively.
C1 [Kansal, Shubhi; Tripathi, Rajiv Kumar] Natl Inst Technol, Delhi 110040, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi
RP Kansal, S (corresponding author), Natl Inst Technol, Delhi 110040, India.
EM kansalshubhi@yahoo.com
RI tripathi, rajiv/F-1353-2018
OI tripathi, rajiv/0000-0002-1036-046X; kansal, shubhi/0000-0001-8917-6843
FU Dept. of Electronics and Communication Engineering, NIT Delhi
FX This work was supported by Dept. of Electronics and Communication
   Engineering, NIT Delhi.
CR Agaian SS, 2000, IASTED INT C SIGN PR
   Atta R, 2013, IET IMAGE PROCESS, V7, P472, DOI 10.1049/iet-ipr.2013.0083
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jang JH, 2011, IEEE GEOSCI REMOTE S, V8, P983, DOI 10.1109/LGRS.2011.2146227
   Kallel F, 2018, SIGNAL IMAGE VIDEO P, V12, P905, DOI 10.1007/s11760-017-1232-2
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee E, 2013, IEEE GEOSCI REMOTE S, V10, P62, DOI 10.1109/LGRS.2012.2192412
   Liu JH, 2017, IEEE GEOSCI REMOTE S, V14, P1715, DOI 10.1109/LGRS.2017.2730247
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Singh H, 2019, COMPUT ELECTR ENG, V75, P245, DOI 10.1016/j.compeleceng.2017.11.014
   Singh H, 2018, INT J ELECTRON, V105, P1695, DOI 10.1080/00207217.2018.1477199
   Suresh S, 2017, IEEE J-STARS, V10, P3665, DOI 10.1109/JSTARS.2017.2699200
NR 22
TC 12
Z9 14
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25241
EP 25258
DI 10.1007/s11042-019-07744-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700002
DA 2024-07-18
ER

PT J
AU Kumar, A
   Kansal, A
   Singh, K
AF Kumar, Amit
   Kansal, Ankush
   Singh, Kulbir
TI An improved anti-forensic technique for JPEG compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG anti-forensics; Double JPEG compression; Blocking artifacts;
   TV-based deblocking
ID TRACES
AB The availability of numerous powerful image processing tools or software makes it easier to manipulate the digital information without the addition of any footprints. JPEG compression based tampering detectors are generally employed in digital image forensics. An efficient anti-forensic technique is required to measure the capability of JPEG forensic detectors. In this article, an efficient JPEG anti-forensic technique is presented to hide the JPEG compression artifacts in spatial as well as Discrete Cosine Transform (DCT) domain. We initially employ shifted block DCT approach on the considered JPEG compressed image to fill the gaps in the comb-like distribution of DCT coefficients. This shifted block DCT approach led to the addition of dithering noise itself without the need of any adaptive dithering model. Therefore, the computational cost to create a JPEG forgery reduces significantly. The result of this shifted block DCT approach is further processed in the second step by TV (Total variation)-based deblocking operation to remove the blocking artifacts left during the JPEG compression in the spatial domain. The experimental results illustrate that the presented approach has better performance in comparison to the existing techniques in terms of image visual quality and forensic undetectability with highly reduced computational cost.
C1 [Kumar, Amit; Kansal, Ankush; Singh, Kulbir] TIET, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), TIET, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM akumar2_phd16@thapar.edu; akansal@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019; Kansal, Ankush/AAM-4521-2020
OI Singh, Kulbir/0000-0001-8070-3395; KUMAR, AMIT/0000-0003-0922-2606
CR Alter F, 2005, J MATH IMAGING VIS, V23, P199, DOI 10.1007/s10851-005-6467-9
   [Anonymous], 2011, P INT WORKSHOP DIGIT
   Banerji A., 2010, Multimedia Technologies
   Barnett Michael, 2016, Paternalism beyond Borders, P1
   Barni M, 2015, LECT NOTES COMPUT SC, V9023, P31, DOI 10.1007/978-3-319-19321-2_3
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bohme R., 2012, DIGITAL IMAGE FORENS, P327, DOI [DOI 10.1007/978-1-4614-0757-7_12, 10.1007/978-1-4614-0757-7_12]
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Das TK, 2018, MULTIMED TOOLS APPL, P1
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li HD, 2015, MULTIMED TOOLS APPL, V74, P6729, DOI 10.1007/s11042-014-1927-0
   Li HD, 2012, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2012.6466840
   Li YM, 2015, IEEE SIGNAL PROC LET, V22, P2219, DOI 10.1109/LSP.2015.2472561
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P460, DOI 10.1109/TIFS.2009.2024715
   LUO W, 2007, IEEE INT C AC SPEECH, V2, P217
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Pasquini C, 2013, IEEE INT WORKSH MULT, P500, DOI 10.1109/MMSP.2013.6659339
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Price JR, 1999, IEEE SIGNAL PROC LET, V6, P297, DOI 10.1109/97.803427
   Qian ZX, 2014, J SYST SOFTWARE, V91, P100, DOI 10.1016/j.jss.2013.12.043
   Shelke MP, 2017, IMAGING SCI J, P1
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Stamm MC, 2010, IEEE IMAGE PROC, P1737, DOI 10.1109/ICIP.2010.5652845
   Stamm MC, 2010, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2010.5652553
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Valenzise G., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1949, DOI 10.1109/ICIP.2011.6115854
   Valenzise G, 2011, INT CONF ACOUST SPEE, P1884
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Vongurai N., 2012, 2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2012), P249, DOI 10.1109/CIMSim.2012.37
   Zhou HY, 2016, FORENSIC SCI INT, V266, P379, DOI 10.1016/j.forsciint.2016.06.005
NR 43
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25427
EP 25453
DI 10.1007/s11042-019-7734-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700010
DA 2024-07-18
ER

PT J
AU Liu, X
   Yang, P
   Dong, YQ
   Shah, SC
AF Liu, Xuan
   Yang, Peng
   Dong, Yongqiang
   Shah, Sayed Chhattan
TI Dual-structural edge networking paradigm: an analysis study in terms of
   multimedia content delivery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-structural; Edge networking; Multimedia content delivery;
   Comparative analysis; Network performance; User utility
ID CLEAN-SLATE
AB To eliminate the phenomenon of the digital divide in the area lacking Internet infrastructure support and accomplish the vision of "The Internet is for everyone" envisaged by Vint Cerf, our group pioneered a dual-structural edge networking paradigm, being utilized to construct a DSN (dual-structural network) for multimedia content delivery. The aim of this paper is to study multimedia content delivery capability for the edge networking paradigm. First of all, for further understanding the delivery capability, we formalize DSN in terms of network architecture and logical entity interaction and propose a hierarchical model and triple B model sequentially. Then, we propose a multi-dimension analysis methodology of multimedia content delivery for networking paradigm from a high-level perspective, in which network performance and user evaluation are taken into account. Further, according to the methodology, we design a specific comparative analysis model of multimedia content delivery capability for DSN, consisting of sub-model based on transmission performance and sub-model based on user utility. Lastly, we conduct direct and indirect comparative analysis studies by utilizing the model, and numerical results shed light on that DSN outperforms TCP/IP, NDN (named data networking) and BSN (broadcast-storage network) in terms of the delivery capability. Given this, we conclude that DSN is a more promising paradigm for multimedia content delivery.
C1 [Liu, Xuan; Yang, Peng; Dong, Yongqiang] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Liu, Xuan; Yang, Peng; Dong, Yongqiang] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Jiangsu, Peoples R China.
   [Shah, Sayed Chhattan] Hankuk Univ Foreign Studies, Dept Informat Commun Engn, Seoul, South Korea.
C3 Southeast University - China; Southeast University - China; Hankuk
   University Foreign Studies
RP Yang, P (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.; Yang, P (corresponding author), Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Jiangsu, Peoples R China.
EM yusuf@seu.edu.cn; pengyang@seu.edu.cn; dongyq@seu.edu.cn;
   shah@hufs.ac.kr
RI Liu, Xuan/R-6748-2016
OI Liu, Xuan/0000-0002-7966-4488; Shah, Sayed Chhattan/0000-0003-0252-1064
FU National Natural Science Foundation of China [61472080, 61672155];
   Academician Consulting Project of Chinese Academy of Engineering
   [2018-XY-07]; National High Technology Research and Development Program
   of China [2013AA013503]; Collaborative Innovation Center of Novel
   Software Technology and Industrialization; National Research Foundation
   of Korea [2017R1C1B5017629]; Hankuk University of Foreign Studies
   Research Fund of 2018
FX We would like to express our heartfelt gratitude to Prof. Youping Li and
   anonymous reviewers for their valuable comments. This work is supported
   by National Natural Science Foundation of China under Grant No. 61472080
   and No. 61672155, Academician Consulting Project of Chinese Academy of
   Engineering under Grant No. 2018-XY-07, National High Technology
   Research and Development Program of China under Grant No. 2013AA013503,
   Collaborative Innovation Center of Novel Software Technology and
   Industrialization, Hankuk University of Foreign Studies Research Fund of
   2018 and National Research Foundation of Korea under Grant No.
   2017R1C1B5017629.
CR Ahmed SH, 2017, IEEE COMMUN MAG, V55, P60, DOI 10.1109/MCOM.2017.1601137
   Alvarez J, 2016, AEROSP CONF PROC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], J SW U SCI TECHNOLOG
   [Anonymous], POPOLATION J
   [Anonymous], TECHNICAL REPORT
   [Anonymous], TELECOMMUNICATIONS S
   [Anonymous], ARCH INT EV
   [Anonymous], IEEE S COMP COMM ISC
   [Anonymous], ENG SCI
   Cui J, 2017, IEEE T VEH TECHNOL, V66, P10283, DOI 10.1109/TVT.2017.2718101
   Dovrolis C, 2010, ACM SIGCOMM COMP COM, V40, P72, DOI 10.1145/1764873.1764886
   Feldmann A, 2007, ACM SIGCOMM COMP COM, V37, P59, DOI 10.1145/1273445.1273453
   Garlan D, 2009, PROC INT CONF SOFTW, P591, DOI 10.1109/ICSE.2009.5070563
   Gill P, 2011, ACM SIGCOMM COMP COM, V41, P14, DOI 10.1145/2043164.2018439
   Hao PT, 2019, MULTIMED TOOLS APPL, V78, P3471, DOI 10.1007/s11042-018-6111-5
   [李幼平 Li Youping], 2002, [中国工程科学, Engineering science], V4, P8
   Lin Song, 2010, Journal of Tsinghua University (Science and Technology), V50, P58
   [刘旋 Liu Xuan], 2018, [电子学报, Acta Electronica Sinica], V46, P849
   Liu X, 2017, AD HOC NETW, V58, P255, DOI 10.1016/j.adhoc.2016.04.005
   Mertz J, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3145813
   Rexford J, 2010, COMMUN ACM, V53, P36, DOI 10.1145/1810891.1810906
   Trossen D, 2016, ACM SIGCOMM COMP COM, V46, P44, DOI 10.1145/2875951.2875959
   Wang En-hai, 2011, Acta Electronica Sinica, V39, P737
   Xing Ling, 2008, Transactions of Beijing Institute of Technology, V28, P737
   Xu Ke, 2013, Chinese Journal of Computers, V36, P903, DOI 10.3724/SP.J.1016.2013.00903
   [杨鹏 Yang Peng], 2015, [电子学报, Acta Electronica Sinica], V43, P974
   [杨鹏 Yang Peng], 2015, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V12, P18
   [尹浩 Yin Hao], 2018, [中国科学. 信息科学, Scientia Sinica Informationis], V48, P1651
   Zaitsev D.A, 2009, P 16 WORKSH ALG TOOL, V501, P15
   Zhang Guo-giang, 2012, Journal on Communications, V33, P158
   [朱敏 Zhu Min], 2013, [计算机学报, Chinese Journal of Computers], V36, P1785
NR 32
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24555
EP 24572
DI 10.1007/s11042-018-6649-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900041
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Geetha, K
   Mahalakshmi, N
   Archana, N
AF Sasikaladevi, N.
   Geetha, K.
   Mahalakshmi, N.
   Archana, N.
TI SNAP-compressive lossless sensitive image authentication and protection
   scheme based on Genus-2 hyper elliptic curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper elliptic curve cryptography; Divisor; Mumford representation;
   Cantor algorithm
ID HYBRID CHAOTIC SYSTEM; ENCRYPTION SCHEME; CRYPTOSYSTEM
AB Hyper Elliptic Curve Cryptography (HECC) offers comparable security as that of Elliptic Curve Cryptography (ECC) even with much reduced key size. This reduction in key size minimizes processing overhead and hence is particularly more attractive for the constrained environment, key agreement protocols, and digital signature applications. In the digital communication world, the most dominant communication happens in Image form, which is highly sensitive as they possess biometric information or individual's privacy information like medical history. As images consume large storage, it needs to be compressed for faster processing before encryption without compromising security. This, of course, incurs additional overhead at the receiver end along with data loss. To minimize storage space by compression without any loss of data and to speed up the encryption process without compromising security a lightweight model named SNAP (SeNsitive image Authentication Protection) has been proposed. This SNAP employs genus-2 HECC that can be constructed on 80-bit finite field to attain security features as compared with 160 bit ECC or 1024 bit RSA. Since HECC comes under Discrete Logarithm Problem (DLP) based cryptography, solving the DLP with the prime field of size 256 bits is not feasible with modern quantum computing power. It compresses the points of the chosen curve to divisor by using Mumford representation. This representation can perform compression without any loss which is desirable for ensuring sensitive protection. As HECC processing relies on divisors rather than points, it is faster than EC based image encryption. Rigorous security analysis has been conducted on the proposed SNAP model. The observed results claim ideal measures for MSE and PSNR values in comparison against a contemporary benchmark image encryption scheme. Security strength of the SNAP method has been ratified by examining key space analysis, entropy analysis, NPCR, and UACI analysis. The proposed method can be recommended as a good candidature as it out-performs in all the above performance measures from the security perspective.
C1 [Sasikaladevi, N.; Geetha, K.; Mahalakshmi, N.; Archana, N.] SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
EM sasikalade@gmail.com
RI KRISHNAN, GEETHA/IUO-9520-2023; , Sasikaladevi/AAF-7847-2019
OI KRISHNAN, GEETHA/0000-0002-8546-2719; , Sasikaladevi
   N/0000-0002-0841-502X
FU Department of Science and Technology (DST), Science and Engineering
   Board (SERB), Government of India under ECR grant [ECR/2017/000679/ES]
FX This part of this research work is supported by Department of Science
   and Technology (DST), Science and Engineering Board (SERB), Government
   of India under the ECR grant (ECR/2017/000679/ES)
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   [Anonymous], 2019, IEEE T CIRCUITS SYST
   [Anonymous], 1985, C THEOR APPL CRYPT T
   [Anonymous], 2005, Handbook of Elliptic and Hyperelliptic Curve Cryptography
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Galbraith SD, 2008, INT ALG NUMB THEOR S
   Gaudry P, 2006, INT C THEOR APPL CRY
   Hankerson D., 2006, Guide to Elliptic Curve Cryptography, DOI DOI 10.1007/0-387-21846-73
   Jacobson M, 2004, FIELDS I COMMUN, V41, P255
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Liao X, 2018, MULTIMED TOOLS APPL, P1
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   Liu Z, 2018, DISCRETE DYNAMICS NA, V2018
   McCurley Kevin S., 1990, P S APPL MATH, V42, P49
   Reyad O, 2015, COMM COM INF SC, V566, P34, DOI 10.1007/978-3-319-26404-2_3
   Shankar K, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501383
   Shankar K, 2016, ADV INTELL SYST, V394, P705, DOI 10.1007/978-81-322-2656-7_64
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
NR 25
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26163
EP 26179
DI 10.1007/s11042-019-7738-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700041
DA 2024-07-18
ER

PT J
AU Yang, WK
   Zhou, LK
   Li, TH
   Wang, HR
AF Yang, Wankou
   Zhou, Lukuan
   Li, Tianhuang
   Wang, Haoran
TI A Face Detection Method Based on Cascade Convolutional Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Cascade convolution structure; Soft non-maximum
   suppression
AB Cascade has been widely used in face detection where classifier with low computational cost can be firstly used to shrink most of the background while keeping the recall. In this paper, a new cascaded convolutional neural network method consisting of two main steps is proposed. During the first stage, low-pixel candidate window is used as an input such that the shallow convolutional neural network quickly extracts the candidate window. In the second stage, the window from the former stage is resized and used as an input to the corresponding network layer respectively. During the training period, joint online training is conducted for hard samples and the soft non-maximum suppression algorithm is used to test on the dataset. The whole network achieves improved performance on the FDDB and PASCAL face datasets.
C1 [Yang, Wankou; Zhou, Lukuan; Li, Tianhuang] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Yang, Wankou; Zhou, Lukuan; Li, Tianhuang] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Wang, Haoran] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Southeast University - China; Northeastern University - China
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Yang, WK (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM wkyang@seu.edu.cn
FU National Natural Science Foundation (NNSF) of China [61473086, 61603080,
   61773117]; Jiangsu key RD plan [BE2017157]
FX This work is supported by National Natural Science Foundation (NNSF) of
   China under Grant No. 61473086, 61603080 and 61773117. Jiangsu key R&D
   plan (No. BE2017157).
CR Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Dollar P, 2009, BMVA
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Farfade SS, ICMR2015
   Girshick R, ICCV2015
   Girshick R, IEEE CVPR2014
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang L., 2015, Comput. Sci.
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li H., 2015, CONVOLUTIONAL NEURAL
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liu L, 2018, ARXIV180902165V1CSCV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Najibi M, ICCV2007
   Nie L, ACMM2017
   Peiyun H, 2017, CVPR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Song X, SIGIR2018
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H., 2017, CoRR
   Wang X, 2009, IEEE ICCV
   Xie L, IJCAI2017
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Yang MH, 2002, IEEE T PAMI
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zheng R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135694
   Zhu L, ACMM2017
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu Q, 2006, IEEE CVPR
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 39
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24373
EP 24390
DI 10.1007/s11042-018-6995-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900031
DA 2024-07-18
ER

PT J
AU Arunachalam, R
AF Arunachalam, Revathi
TI A strategic approach to recognize the speech of the children with
   hearing impairment: different sets of features and models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hearing impaired speech recognition; Gamma tone energy features; Hard of
   hearing
ID COMMUNICATION; DEAF
AB The automatic speech recognition system is developed and tested for recognizing the speeches of a normal person in various languages. This paper mainly emphasizes the need for the development of a more challenging speaker independent speech recognition system for hearing impaired to recognize the speeches uttered by any Hearing Impaired (HI) speaker. In this work, Gamma tone energy features with filters spaced an equivalent rectangular bandwidth (ERB), MEL & BARK scale, and MFPLPC features are used at the front end and vector quantization (VQ) & multivariate hidden Markov models (MHMM) at the back end for recognizing the speeches uttered by any hearing impaired speaker. Performance of the system is compared for the three modeling techniques VQ, FCM (Fuzzy C means) clustering and MHMM for the recognition of isolated digits and simple continuous sentences in Tamil. Recognition accuracy (RA) is 81.5% with speeches of eight speakers considered for training and speeches of the remaining two speakers considered for testing for speaker independent isolated digit recognition system. Accuracy is found to be 91% and 87.5% for considering 90% of the data for training and 10% for testing for speaker independent isolated digit and continuous speech recognition systems respectively. Accuracy can be further enhanced by having an extensive database for creating models/templates. Receiver operating characteristics (ROC) drawn between True Positive Rate and False Positive Rate is used to assess the performance of the system for HI. This system can be utilized to understand the speech uttered by any hearing impaired speaker and the system facilitates the provision of necessary assistance to them. It ultimately improves the social status of the hearing impaired people and their confidence level will be enhanced.
C1 [Arunachalam, Revathi] Sastra Deemed Univ, Dept ECE SEEE, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Arunachalam, R (corresponding author), Sastra Deemed Univ, Dept ECE SEEE, Thanjavur, India.
EM revathi@ece.sastra.edu
OI Arunachalam, Revathi/0000-0001-9515-3592
CR Brookes C, 2000, IEE SEM SPEECH LANG
   Chee LS, 2009, IEEE ST CONF RES DEV, P146, DOI 10.1109/SCORED.2009.5443210
   DELLER JR, 1991, COMPUT METH PROG BIO, V35, P125, DOI 10.1016/0169-2607(91)90071-Z
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Girgin MC, 2008, World Appl Sci J, V4, P891
   Gudi AB, 2010, Int J Eng Technol, V2, P169
   Han ZY, 2009, INT J MODEL IDENTIF, V8, P240, DOI 10.1504/IJMIC.2009.029269
   Hawley MS, 2013, IEEE T NEUR SYS REH, V21, P23, DOI 10.1109/TNSRE.2012.2209678
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Jamil MHM, 2011, COMM COM INF SC, V251, P42
   Jeyalakshmi C, 2018, INT J BIOMED ENG TEC, V26, P84, DOI 10.1504/IJBET.2018.089261
   Jeyalakshmi C, 2015, INT J MODEL IDENTIF, V23, P278, DOI 10.1504/IJMIC.2015.069932
   Jeyalakshmi C, 2015, INT J BIOMED ENG TEC, V17, P356, DOI 10.1504/IJBET.2015.069402
   Jeyalakshmi C, 2012, INT J EE TIMES INDIA, P1
   Jeyalakshmi C., 2013, INT J ENG TECHNOLOGY, V5, P4938
   Jeyalakshmi C, 2014, J ENG RES, V2, P6, DOI [10.7603/s40632-014-0006-z, DOI 10.7603/S40632-014-0006-Z]
   Jeyalakshml C, 2010, 2010 2 INT C MECH EL, Vi, P83
   Karjalainen M, 1997, 5 EUR C SPEECH COMM
   Le Prell CG, 2017, HEARING RES, V349, P76, DOI 10.1016/j.heares.2016.10.004
   LEVITT H, 1972, IEEE T ACOUST SPEECH, VAU20, P35, DOI 10.1109/TAU.1972.1162351
   Mahmoudi Z, 2010, 10 INT C INF SCI SIG, V1, P304
   Mengistu KT, 2011, INT CONF ACOUST SPEE, P4924
   Newman CW, HEARING LOSS IS OFTE
   PICKETT JM, 1969, IEEE T ACOUST SPEECH, VAU17, P283, DOI 10.1109/TAU.1969.1162064
   Pitts AB., 2010, COMP SPEECH ASSESSME
   Polur PD, 2006, MED ENG PHYS, V28, P741, DOI 10.1016/j.medengphy.2005.11.002
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Revathi A, 2017, J ENG RES-KUWAIT, V5, P110
   Revathi A., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P198, DOI 10.1109/ICCSP.2011.5739300
   Revathi A, 2012, EE TIMES INDIA, P1
   Revathy a, 2010, SIGNAL IMAGE PROCESS, V1, P14, DOI DOI 10.5121/sipij.2010.1102
   Stevens CG, 1988, INT J REHABIL RES, V11, P396, DOI [10.1097/00004356-198812000-00013, DOI 10.1097/00004356-198812000-00013]
   Tseng S.-C., 2011, 17 INT C PHON SCI, P2030
   Yamada Y, 2000, SPEECH COMMUN, V30, P179, DOI 10.1016/S0167-6393(99)00039-4
   Zhiyan Han, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2036
NR 36
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20787
EP 20808
DI 10.1007/s11042-019-7329-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400011
DA 2024-07-18
ER

PT J
AU Li, C
   Li, YP
   Zhao, ZC
   Yu, LL
   Luo, Z
AF Li, Chun
   Li, Yuepeng
   Zhao, Zhicheng
   Yu, Longlong
   Luo, Ze
TI A mixed noise removal algorithm based on multi-fidelity modeling with
   nonsmooth and nonconvex regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Inverse problem; Alternating direction method of
   multipliers; Nonconvex optimization
ID EDGE-PRESERVING REGULARIZATION; IMAGE-RESTORATION; VARIATIONAL APPROACH;
   SPARSE; MINIMIZATION; RECONSTRUCTION; RECOVERY; OPTIMIZATION; RELAXATION
AB In this article, we propose a mixed-noise removal model which incorporates with a nonsmooth and nonconvex regularizer. To solve this model, a multistage convex relaxation method is used to deal with the optimization problem due to the nonconvex regularizer. Besides, we adopt the number of iteration steps as the termination condition of the proposed algorithm and select the optimal parameters for the model by a genetic algorithm. Several experiments on classic images with different level noises indicate that the robustness, running time, ISNR (Improvement in Signalto-Noise ratio) and PSNR (Peak Signal to Noise Ratio) of our model are better than those of other three models, and the proposed model can retain the local information of the image to obtain the optimal quantitative metrics and visual quality of the restored images.
C1 [Li, Chun; Li, Yuepeng; Zhao, Zhicheng; Yu, Longlong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Li, Chun; Zhao, Zhicheng; Yu, Longlong; Luo, Ze] Chinese Acad Sci, E Sci Technol & Applicat Lab, Comp Network Informat Ctr, Beijing 100190, Peoples R China.
   [Li, Yuepeng] Chinese Acad Sci, Dept Big Data Technol & Applicat, Comp Network Informat Ctr, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Computer Network Information Center,
   CAS; Chinese Academy of Sciences; Computer Network Information Center,
   CAS
RP Li, C (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Li, C (corresponding author), Chinese Acad Sci, E Sci Technol & Applicat Lab, Comp Network Informat Ctr, Beijing 100190, Peoples R China.
EM lichun@cnic.cn
RI Li, Chun/AAK-9036-2021
OI Li, Chun/0000-0002-2021-751X
FU Natural Science Foundation of China [61361126011, 90912006]; Special
   Project of Informatization of Chinese Academy of Sciences in "the
   Twelfth Five-Year Plan" [XXH12504-1-06]; Science and Technology Service
   Network Initiative, CAS, (STS Plan); IT integrated service platform of
   Sichuan Wolong Natural Reserve [Y82E01]; National R&D Infrastructure and
   Facility Development Program of China, "Fundamental Science Data Sharing
   Platform" [DKA2018-12-02-XX]; Strategic Priority Research Program of the
   Chinese Academy of Sciences [XDA19060205]; Special Project of
   Informatization of Chinese Academy of Sciences [XXH13505-03-205,
   XXH13506-305, XXH13506-303]; Around Five Top Priorities of
   "One-Three-Five" Strategic Planning, CNIC [CNIC PY-1408, CNIC PY-1409]
FX Funding were provided by the Natural Science Foundation of China under
   Grant NO. 61361126011, No. 90912006; the Special Project of
   Informatization of Chinese Academy of Sciences in "the Twelfth Five-Year
   Plan" under Grant No. XXH12504-1-06, Science and Technology Service
   Network Initiative, CAS, (STS Plan); he IT integrated service platform
   of Sichuan Wolong Natural Reserve, under Grant No. Y82E01; The National
   R&D Infrastructure and Facility Development Program of China,
   "Fundamental Science Data Sharing Platform" (DKA2018-12-02-XX);
   Supported by the Strategic Priority Research Program of the Chinese
   Academy of Sciences, Grant No. XDA19060205; the Special Project of
   Informatization of Chinese Academy of Sciences (XXH13505-03-205); the
   Special Project of Informatization of Chinese Academy of Sciences
   (XXH13506-305); the Special Project of Informatization of Chinese
   Academy of Sciences (XXH13506-303); Supported by Around Five Top
   Priorities of "One-Three-Five" Strategic Planning, CNIC(Grant No. CNIC
   PY-1408); Supported by Around Five Top Priorities of "One-Three-Five"
   Strategic Planning, CNIC(Grant No. CNIC PY-1409) The authors wish to
   gratefully thank all anoymous reriewers who provided insightful and
   helpful comments.
CR Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], 2006, MATH PROBLEMS IMAGE
   [Anonymous], 1996, PRINCETON MATH SER
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bar L., 2011, Handbook of Math. Methods in Imaging, P1095, DOI DOI 10.1007/978-0-387-92920-0_25
   Bovik Alan C, 2010, Handbook of image and video processing
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chartrand R, 2008, TECH REP
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Deng LZ, 2018, IEEE ACCESS, V6, P62120, DOI 10.1109/ACCESS.2018.2876038
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Esser E., 2009, CAM REP, P9
   Feng WS, 2018, IEEE T CYBERNETICS, V48, P1708, DOI 10.1109/TCYB.2017.2713421
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Han Y, 2013, PATTERN RECOGN, V46, P989, DOI 10.1016/j.patcog.2012.10.010
   He BS, 2002, MATH PROGRAM, V92, P103, DOI 10.1007/s101070100280
   He KJ, 2018, IEEE ACCESS, V6, P32850, DOI 10.1109/ACCESS.2018.2845855
   Hintermuller M, 2012, SUBSPACE CORRECTION
   Huang T, 2017, IEEE T IMAGE PROCESS, V26, P3171, DOI 10.1109/TIP.2017.2676466
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Ji H, 2010, ROBUST VIDEO DENOISI
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jia TT, 2016, J VIS COMMUN IMAGE R, V38, P461, DOI 10.1016/j.jvcir.2016.03.022
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jung M, 2015, J SCI COMPUT, V62, P336, DOI 10.1007/s10915-014-9860-y
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Liu LC, 2017, IEEE T CYBERNETICS, V47, P600, DOI 10.1109/TCYB.2016.2521428
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nikolova M, 2005, MULTISCALE MODEL SIM, V4, P960, DOI 10.1137/040619582
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Nikolova M, 1999, IEEE T IMAGE PROCESS, V8, P1204, DOI 10.1109/83.784433
   Nikolova M, 2007, IEEE T IMAGE PROCESS, V16, P1623, DOI 10.1109/TIP.2007.896622
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   Nikolova M, 2008, SIAM J IMAGING SCI, V1, P2, DOI 10.1137/070692285
   Ochs P, 2013, PROC CVPR IEEE, P1759, DOI 10.1109/CVPR.2013.230
   Osher S, 2017, SIAM J IMAGING SCI, V10, P1669, DOI 10.1137/16M1058686
   Robini MC, 2007, IEEE T IMAGE PROCESS, V16, P2576, DOI 10.1109/TIP.2007.904975
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189
   Vogel CR, 1998, IEEE T IMAGE PROCESS, V7, P813, DOI 10.1109/83.679423
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang T, 2010, J MACH LEARN RES, V11, P1081
   Zhang XQ, 2012, J SCI COMPUT, V50, P519, DOI 10.1007/s10915-011-9533-z
NR 75
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23117
EP 23140
DI 10.1007/s11042-019-7625-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400042
DA 2024-07-18
ER

PT J
AU Qian, XH
   Zhong, XP
AF Qian, Xiaohui
   Zhong, Xiaopeng
TI Optimal individualized multimedia tourism route planning based on ant
   colony algorithms and large data hidden mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant colony algorithm; Big data; Implicit mining; Tourist routes;
   Planning
ID RECOMMENDATION
AB This paper collects the coordinates of longitude and latitude of each city and the actual inter-city train tickets and air tickets aiming at the route optimization of 34 cities in China. Ant colony algorithm is used for heuristic search on the basis of this large amount of data, and a reasonable and optimal travel route is given for practical problems. At the same time, the increment of pheromone was adjusted by positive and negative feedback, and the volatile factors of pheromone were randomized, it enables the ant colony algorithm to automatically adjust the pheromone amount on the path to improve the performance of the ant colony algorithm. Finally, the performance advantages of the proposed algorithm in personalized tourism route planning are verified by simulation experiments.
C1 [Qian, Xiaohui; Zhong, Xiaopeng] Anhui Finance & Trade Vocat Coll, Dept Tourism & Culture, Hefei, Anhui, Peoples R China.
C3 Anhui University of Finance & Economics
RP Qian, XH (corresponding author), Anhui Finance & Trade Vocat Coll, Dept Tourism & Culture, Hefei, Anhui, Peoples R China.
EM wyqg245@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Ashokkumar P, 2018, COMPUT ELECTR ENG, V68, P526, DOI 10.1016/j.compeleceng.2018.05.004
   Brown MJF, 1997, BEHAVIOUR, V134, P849, DOI 10.1163/156853997X00188
   Dussutour A, 2009, ANIM COGN, V12, P21, DOI 10.1007/s10071-008-0165-0
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Giehr J, 2017, BMC EVOL BIOL, V17, DOI 10.1186/s12862-017-1026-8
   Gupta D, 2018, COGN SYST RES, V52, P36, DOI 10.1016/j.cogsys.2018.06.006
   Hussein AF, 2018, COGN SYST RES, V52, P1, DOI 10.1016/j.cogsys.2018.05.004
   Hussein AF, 2018, IEEE ACCESS, V6, P77055, DOI 10.1109/ACCESS.2018.2831209
   Individual T H, 2013, MATH PROBL ENG, V2013, P1
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Lu HC, 2016, IEEE INT C SYST MAN
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Pei Zhi-li, 2008, Application Research of Computers, V25, P1036
   Ranke MB, 2013, HORM RES PAEDIAT, V79, P51, DOI 10.1159/000347121
   Ressom HW, 2008, FRONT BIOSCI-LANDMRK, V13, P691, DOI 10.2741/2712
   Skolnik ML, 1983, CAN J HIGH ED, V13
   Wei JL, 2018, FUTURE GENER COMP SY, V86, P355, DOI 10.1016/j.future.2018.03.048
   Wei W, 2011, INT C EL INF CONTR E
   Zhao JP, 2010, INT C ADV COMP CONTR
NR 23
TC 12
Z9 13
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22099
EP 22108
DI 10.1007/s11042-019-7537-0
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400068
DA 2024-07-18
ER

PT J
AU Singh, SP
   Bhatnagar, G
AF Singh, Satendra Pal
   Bhatnagar, Gaurav
TI A simplified watermarking algorithm based on lifting wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Binary d-sequence; Lifting wavelet transform (LWT);
   Random number generator (RNG)
ID SPREAD-SPECTRUM WATERMARKING; IMAGE; DOMAIN
AB This paper presents a new blind image watermarking scheme using binary decimal sequence (d-sequence) and lifting wavelet transform (LWT) for copyright protection. The core idea is to produce a d- sequence based on random number generator (RNG) algorithm and secret keys. A reference set is then generated using the d-sequence for embedding purpose. For embedding, the host image is decomposed into different frequency bands using the LWT and watermark bits are then embedded in selected band, considering the reference set. The extensive experimental results, comparative and security analysis demonstrate the better robustness of the proposed scheme against different kind of attacks.
C1 [Singh, Satendra Pal; Bhatnagar, Gaurav] Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Singh, SP (corresponding author), Indian Inst Technol Jodhpur, Dept Math, Jodhpur, Rajasthan, India.
EM pg201383504@iitj.ac.in; goravb@iitj.ac.in
RI Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372
CR Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   [Anonymous], INT C COMPUT VISION
   [Anonymous], ARXIVCS0603029
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bas P, 2013, IEEE T INF FOREN SEC, V8, P1306, DOI 10.1109/TIFS.2013.2267960
   Bhatnagar G, 2012, COMPUT ELECTR ENG, V38, P1164, DOI 10.1016/j.compeleceng.2012.02.002
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Cox I. J., 2002, Digital Watermarking
   Ding WP, 2007, IEEE T IMAGE PROCESS, V16, P416, DOI 10.1109/TIP.2006.888341
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lei B, 2011, INT WORKSH DI WAT, P86
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Pérez-Freire L, 2009, IEEE T INF FOREN SEC, V4, P2, DOI 10.1109/TIFS.2008.2009603
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, P NATL A SCI INDIA A, V85, P295, DOI 10.1007/s40010-014-0197-6
   Singh SP, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P140, DOI 10.1109/CSPA.2018.8368701
   Singh SP, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P135, DOI 10.1109/CSPA.2018.8368700
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Singh SP, 2017, IEEE I C SIGNAL IMAG, P440, DOI 10.1109/ICSIPA.2017.8120651
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 30
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20765
EP 20786
DI 10.1007/s11042-019-7394-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400010
DA 2024-07-18
ER

PT J
AU Subhedar, MS
   Mankar, VH
AF Subhedar, Mansi S.
   Mankar, Vijay H.
TI Image steganography using contourlet transform and matrix decomposition
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Contourlet transform; Singular value decomposition;
   QR factorisation; Non-negative matrix factorisation; Universal
   steganalysis
ID DISCRETE WAVELET TRANSFORM; SCHEME; CAPACITY
AB This paper presents the transform domain image steganography schemes using three popular matrix factorization techniques and contourlet transform. It is known that security of image steganography is mainly evaluated using undetectability of stego image when steganalyzer examines it in order to detect the presence of hidden secret information. Good imperceptibility only suggests eavesdropper's inability to suspect about the hidden information; however stego image may be analyzed by applying certain statistical checks when it is being transmit- ted through the channel. This work focusses on improving undetectability by employing ma- trix decomposition techniques along with transform domain image steganography. Singular value decomposition (SVD), QR factorization, Nonnegative matrix factorization (NMF) are employed to decompose contourlet coefficients of cover image and secret is embedded into its matrix factorized coefficients. The variety of investigations include the effect of matrix decomposition techniques on major attributes of image steganography like imperceptibility, robustness to a variety of image processing operations, and universal steganalysis perfor- mance. Better imperceptibility, large capacity, and poor detection accuracy compared to existing work validate the efficacy of the proposed image steganography algorithm. Compa- rative analysis amongst three matrix factorization methods is also presented and analyzed.
C1 [Subhedar, Mansi S.] Pillai HOC Coll Engn & Technol, Raigad, Maharashtra, India.
   [Mankar, Vijay H.] Govt Polytech, Nagpur, Maharashtra, India.
RP Subhedar, MS (corresponding author), Pillai HOC Coll Engn & Technol, Raigad, Maharashtra, India.
EM mansi_subhedar@rediffmail.com
RI Subhedar, Mansi/ABE-4740-2020; Mankar, Vijay H/G-2293-2012
OI Subhedar, Mansi/0000-0002-4628-354X; 
CR Ahn CJ, 2008, IEEE T VEH TECHNOL, V57, P2578, DOI 10.1109/TVT.2007.913179
   [Anonymous], ARXIV180203528
   [Anonymous], IEEE C SYST APPL TEC
   [Anonymous], INFORM COMMUNICATION
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIPLE RGB IMAGE S
   [Anonymous], 2 INT C KNOWL BAS EN
   [Anonymous], P 11 ACM MULT SEC WO
   [Anonymous], P SPIE MULTISPECTRAL
   [Anonymous], ADV INTELLIGENT SYST
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], HINDAWI MATH PROBLEM
   [Anonymous], USC SIPI
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Do MN, 2002, IEEE IMAGE PROC, P357
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li Y, 2020, MULTIMED TOOLS APPL, V79, P9665, DOI 10.1007/s11042-017-5557-1
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Maheswari SU, 2017, MULTIMED TOOLS APPL, V76, P415, DOI 10.1007/s11042-015-3035-1
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Mostafa R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P300, DOI 10.1109/IntelCIS.2015.7397238
   Muhammad N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1534-1
   Ogiela MR, 2015, SOFT COMPUT, V19, P3331, DOI 10.1007/s00500-015-1728-z
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajedi H, 2010, J SIGNAL PROCESS SYS, V61, P367, DOI 10.1007/s11265-010-0460-2
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Song X., 2015, P ACM WORKSH INF HID, P15, DOI DOI 10.1145/2756601.2756608
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Subramanian M, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/8695103
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
NR 40
TC 13
Z9 13
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22155
EP 22181
DI 10.1007/s11042-019-7512-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400071
DA 2024-07-18
ER

PT J
AU Fakhredanesh, M
   Rahmati, M
   Safabakhsh, R
AF Fakhredanesh, Mohammad
   Rahmati, Mohammad
   Safabakhsh, Reza
TI Steganography in discrete wavelet transform based on human visual system
   and cover model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model-based steganography; Human visual system; Discrete wavelet
   transform; Cover modeling; Perceptual model
ID HIDING ALGORITHM; IMAGE; VISIBILITY
AB In this paper we present a model-based image steganography method in discrete wavelet transform (DWT). This method is based on the human visual system model. The proposed steganography method assumes a model for cover image statistics. In this algorithm, the DWT coefficients are used as the carrier of the hidden message. An unpleasant outcome of this algorithm is that its perceptual characteristic is degraded. The perceptual detectability weakness of this approach is improved by introducing another algorithm which is proposed based on the Watson visual system model to prevent visually perceptible changes during embedding. In the first step, the maximum tolerable change in each DWT coefficient is extracted using the human visual model. Then, a model is fitted to the histogram of low-precision coefficients and the message bits are encoded to this model. In the final step, the encrypted message bits are embedded in the coefficients whose maximum possible changes are visually imperceptible. Experimental results illustrate that changes occurred during data embedding by employing the human visual model leads to perceptually undetectable changes. The perceptual detectability is satisfied while the perceptual quality and the security usually increased. The perceptual quality is measured by structural similarity measure, and the security is measured by two well-known steganalysis methods.
C1 [Fakhredanesh, Mohammad; Rahmati, Mohammad; Safabakhsh, Reza] Amirkabir Univ Technol, Comp Engn & Informat Technol Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Fakhredanesh, M (corresponding author), Amirkabir Univ Technol, Comp Engn & Informat Technol Dept, Tehran, Iran.
EM m-fakhredanesh@aut.ac.ir
CR Ahmidi N., 2008, 2008 Canadian Conference on Electrical and Computer Engineering - CCECE, P001077, DOI 10.1109/CCECE.2008.4564703
   Amar M, 2016, LECT NOTES COMPUT SC, V9680, P328, DOI 10.1007/978-3-319-33618-3_33
   [Anonymous], P TENCON 2005 2005 I
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Awrangjeb M, 2004, LECT NOTES COMPUT SC, V2939, P581
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P4916, DOI 10.1109/TIP.2016.2598492
   Böhme R, 2004, LECT NOTES COMPUT SC, V3193, P125
   Bohme R., 2010, Advanced Statistical Steganalysis
   Cachin C, 1998, P 2 INT WORKSH INF H
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen T. H., 2003, PAKISTAN J INFORM TE, V2, P213
   Cover Thomas M, 1999, Elements of information theory
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Delaigle JF, 1998, SIGNAL PROCESS, V66, P319, DOI 10.1016/S0165-1684(98)00013-9
   Droogenbroeck MV, 2002, P 3 IEEE BEN SIGN PR
   Fakhredanesh M, 2014, ETRI J, V36, P479, DOI 10.4218/etrij.14.0113.0171
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2003, PROC SPIE, V5020, P191, DOI 10.1117/12.479739
   Fridrich J, 2000, LECT NOTES COMPUT SC, V1768, P47
   Hu R, 2010, IEEE IMAGE PROC, P3705, DOI 10.1109/ICIP.2010.5652638
   Huang HP, 2014, INT J COMMUN SYST, V27, P2426, DOI 10.1002/dac.2551
   Jayalakshmi M, 2006, LECT NOTES COMPUT SC, V4338, P206
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kim SW, 2004, P 37 ANN HAW INT C S
   Kim YS, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P80, DOI 10.1109/ISCAS.1999.779947
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kwon OH, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P76, DOI 10.1109/ISCAS.1999.779946
   Levicky D, 2004, RADIOENGINEERING, V13, P38
   Li YZ, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P904, DOI 10.1109/ISECS.2008.83
   Lou DC, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P325
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Niu BH, 2017, SMART INNOV SYST TEC, V64, P93, DOI 10.1007/978-3-319-50212-0_12
   Oueslati S., 2010, Int J Image Process, V4, P218
   Pan F, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P490, DOI 10.1109/ICECC.2011.6067565
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Nguyen PB, 2013, SIGNAL PROCESS-IMAGE, V28, P1506, DOI 10.1016/j.image.2013.09.011
   Podilchuk C, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P363, DOI 10.1109/MMSP.1997.602662
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Porter J., 2006, P SSST COOK TN US MA, P354
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Qazanfari K, 2011, P 6 IR C MACH VIS IM
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Roy A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P537, DOI 10.1109/SPIN.2015.7095399
   SAFABAKHSH R, 2004, P IEEE INT C INF TEC
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Shu ZH, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P208, DOI 10.1109/ISECS.2009.76
   Tsai MJ, 2014, MULTIMED TOOLS APPL, V72, P1311, DOI 10.1007/s11042-013-1423-y
   Ullerich Christian, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P127
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Watson AB, 1997, P SPIE
   Wenhua Tang, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9218, P430, DOI 10.1007/978-3-319-21963-9_39
   Xie G, 2006, IEEE IMAGE PROC, P1381, DOI 10.1109/ICIP.2006.312592
   Yong Ju Jung, 2003, Digital Watermarking. First International Workshop, IWDW 2002. Revised Papers (Lecture Notes Computer Science Vol.2613), P224
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhang YN, 2014, P INT CONF NAT COMPU, P958, DOI 10.1109/ICNC.2014.6975969
   Zhang Yanhong., 2009, Wseas Trans Comput, V8, P174
   Shu ZH, 2008, IEEE I C EMBED SOFTW, P348, DOI 10.1109/ICESS.2008.52
   Zhu GM, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P546, DOI 10.1109/ISISE.2008.287
NR 65
TC 20
Z9 20
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18475
EP 18502
DI 10.1007/s11042-019-7238-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200051
DA 2024-07-18
ER

PT J
AU Hegde, RB
   Prasad, K
   Hebbar, H
   Singh, BMK
AF Hegde, Roopa B.
   Prasad, Keerthana
   Hebbar, Harishchandra
   Singh, Brij Mohan Kumar
TI Development of a robust algorithm for detection of nuclei of white blood
   cells in peripheral blood smear images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peripheral blood smear images; Nuclei detection; WBC detection;
   Illumination variations; Computer aided detection
ID SEGMENTATION; CLASSIFICATION
AB Microscopic evaluation of peripheral blood smear analysis is a commonly used laboratory procedure to diagnose various diseases such as anemia, malaria, leukemia, etc. Manual microscopic evaluation is laborious and hence many research groups have attempted to automate smear analysis. Variations in staining procedure and smear preparation introduces color shade variations into peripheral blood smear images. Illumination provided by point source bulb introduces brightness variations across the smear which affects the performance of an automated method. In this paper we present an image processing algorithm for detection of nuclei of white blood cells which is robust to color and brightness variations. In the proposed method we used two different datasets and also five datasets which were derived from original images by introducing brightness variations. We also compared the results of the proposed method with four state-of-the-art methods. The results demonstrate that the proposed method detects nuclei accurately with an average accuracy of 0.99 and Dice coefficient of 0.965.
C1 [Hegde, Roopa B.; Prasad, Keerthana; Hebbar, Harishchandra] MAHE, Sch Informat Sci, Manipal 576104, Karnataka, India.
   [Hegde, Roopa B.] NAMAMIT, Dept ECE, Nitte 574110, India.
   [Singh, Brij Mohan Kumar] MAHE, KMC, Dept Pathol, Manipal 574106, Karnataka, India.
C3 Manipal Academy of Higher Education (MAHE); NITTE (Deemed to be
   University); NMAM Institute of Technology; Manipal Academy of Higher
   Education (MAHE); Kasturba Medical College, Manipal
RP Prasad, K (corresponding author), MAHE, Sch Informat Sci, Manipal 576104, Karnataka, India.
EM roopabhegde@gmail.com; keerthana.prasad@manipal.edu;
   harish.hebbar@manipal.edu; brij.singh@manipal.edu
RI Singh, BrijMohan/KFR-4451-2024
OI Hegde, Roopa B/0000-0002-7152-3971; Singh, Brij Mohan
   Kumar/0000-0001-6891-9302; Kumar, Dr. Sumit/0000-0002-1906-5539
CR Amin Morteza Moradi, 2015, J Med Signals Sens, V5, P49
   [Anonymous], INT J ELECT COMMUN E
   [Anonymous], INT J TECHNOL ENG SC
   [Anonymous], INT J ENG RES TECHNO
   AZAM B, 2014, RES J RECENT SCI, V3, P34
   Chen JZ, 2017, NEUROCOMPUTING, V251, P16, DOI 10.1016/j.neucom.2017.04.020
   Chu R, 2015, PROCEEDINGS 7TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS CICSYN 2015, P152, DOI 10.1109/CICSyN.2015.36
   Devi SS, 2018, MULTIMED TOOLS APPL, V77, P631, DOI 10.1007/s11042-016-4264-7
   Dorini LB, 2007, SIBGRAPI, P294, DOI 10.1109/SIBGRAPI.2007.33
   Huang DC, 2012, J SYST SOFTWARE, V85, P2104, DOI 10.1016/j.jss.2012.04.012
   Jan Z, 2018, MULTIMED TOOLS APPL, V77, P9801, DOI 10.1007/s11042-017-4495-2
   Kalinathan L, 2018, MULTIMED TOOLS APPL, V77, P1761, DOI 10.1007/s11042-016-4260-y
   Khashman A, 2008, PROG NAT SCI-MATER, V18, P1309, DOI 10.1016/j.pnsc.2008.03.026
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Li Y, 2017, MULTIMED TOOLS APPL, V16
   Li Y, 2016, COMPUT MATH METHODS, V2016, P12
   Liu N, 2015, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2015.7298633, DOI 10.1109/CVPR.2015.7298633]
   Loffler H, 2005, Atlas of Clinical Hematology
   Longo D, 2012, ATLAS HEMATOLOGY ANA
   Madhloom H. T., 2010, Journal of Applied Sciences, V10, P959, DOI 10.3923/jas.2010.959.966
   Madhloom HT, 2012, J MED SYST, V36, P2149, DOI 10.1007/s10916-011-9679-0
   Marzuki NIC, 2015, J TEKNOL, V74, P115
   Mathur Atin, 2013, J Pathol Inform, V4, pS15, DOI 10.4103/2153-3539.109883
   Nemane JB., 2013, Int J Emerging Technol Adv Eng, V3, P639
   Neoh SC, 2015, SCI REP-UK, V5, DOI 10.1038/srep14938
   Prasad K, 2012, J DIGIT IMAGING, V25, P542, DOI 10.1007/s10278-011-9442-6
   Prasad K, 2012, COMPUT METH PROG BIO, V106, P27, DOI 10.1016/j.cmpb.2011.08.004
   Prinyakupt J, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0037-1
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Rawat J, 2014, IEEE INT SYMP SIGNAL, P456, DOI 10.1109/ISSPIT.2014.7300632
   Rezatofighi SH, 2011, COMPUT MED IMAG GRAP, V35, P333, DOI 10.1016/j.compmedimag.2011.01.003
   Sadeghian F, 2009, BIOL PROCED ONLINE, V11, P196, DOI 10.1007/s12575-009-9011-2
   Taneja A, 2017, MULTIMED TOOLS APPL, P1
   Yang L, 2005, IEEE T INF TECHNOL B, V9, P475, DOI 10.1109/TITB.2005.847515
   Yang YP, 2014, J INNOV OPT HEAL SCI, V7, DOI 10.1142/S1793545814500072
   Zhang CC, 2014, SENSORS-BASEL, V14, P16128, DOI 10.3390/s140916128
NR 36
TC 21
Z9 21
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17879
EP 17898
DI 10.1007/s11042-018-7107-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200025
DA 2024-07-18
ER

PT J
AU Isaza, C
   Anaya, K
   Fuentes-Silva, C
   de Paz, JPZ
   Rizzo, A
   Garcia-Moreno, AI
AF Isaza, Cesar
   Anaya, Karina
   Fuentes-Silva, Carlos
   Zavala de Paz, Jonny Paul
   Rizzo, Amilcar
   Garcia-Moreno, Angel-Ivan
TI Dynamic set point model for driver alert state using digital image
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Driver fatigue detection; Learning model
ID TRACKING; EYE
AB The driver fatigue and lose of attention while driving are the most important causes of traffic accidents. Each year more than one million of deaths occur due to these facts. Thus, this problem has been converted into a serious social issue with high impact not only in economic terms, but also in the public health sector all around the world. Several approaches based on computer vision systems have been proposed to deal with this severe situation, but none of them have fully considered the non-fatigue state as a primary knowledge to detect an unusual event of a person while driving. In fact, typical approaches to deal with the problem of fatigue detection, are based on the analysis of behavioral features extracted with digital image processing such as frequency of blinking, yawning, among others. However, the huge limitation is the short interval of time between each analysis, that generally is few frames per second. Furthermore, all available methods are focus in modeling the fatigue, instead of representing the set point alert state of the driver, which is the main core of the proposed strategy. Hence, in this paper a dynamic set point model for alert state while driving using digital image processing and machine learning techniques is presented. The approach uses an embedded system build with a Raspberry prototyping board and a USB HD camera. Raspbian operative system controls OPEN CV libraries written in Python to detect face parts with an algorithm running Harr descriptors. The features extracted were the position and orientation of the head throw several minutes. Then, a mixture of Gaussians model with its learning and updating stages is used to represent the behaviour of features. Also, a dataset was built considering professional and non-professional drivers under two main scenarios: real and simulated conditions. Experimental results show the viability of the method for posterior analysis of unusual events while driving like fatigue detection, cellphone call or chat detection, or any other distraction not related to the driving process.
C1 [Isaza, Cesar; Anaya, Karina; Fuentes-Silva, Carlos; Zavala de Paz, Jonny Paul; Rizzo, Amilcar; Garcia-Moreno, Angel-Ivan] Univ Politecn Queretaro, Carretera Estatal 420 S-N, El Marques, Qro, Mexico.
RP Isaza, C (corresponding author), Univ Politecn Queretaro, Carretera Estatal 420 S-N, El Marques, Qro, Mexico.
EM cesar.isaza@upq.mx
RI Isaza, Cesar/AGQ-5228-2022; Garcia-Moreno, Angel-Ivan/AHD-3205-2022;
   Garcia-Moreno, Angel-Ivan/AHD-3775-2022; Rivera, Karina
   Anaya/AAU-2929-2020
OI Isaza, Cesar/0000-0002-0995-6231; Garcia-Moreno,
   Angel-Ivan/0000-0003-3427-9209; Garcia-Moreno,
   Angel-Ivan/0000-0003-3427-9209; 
FU Consejo Nacional de Ciencia y Tecnologia (CONACYT), Mexico, under
   Sistema Nacional de Investigadores (SNI) program
FX Authors would like to acknowledge the financial support of this work by
   grants from Consejo Nacional de Ciencia y Tecnologia (CONACYT), Mexico,
   under Sistema Nacional de Investigadores (SNI) program.
CR Abdulin Evgeniy., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P1265, DOI DOI 10.1145/2702613.2732812
   Abulkhair M, 2015, PROCEDIA COMPUT SCI, V62, P555, DOI 10.1016/j.procs.2015.08.531
   [Anonymous], 2013, WHO global status report on road safety 2013: supporting a decade of action
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Chai R, 2015, IEEE ENG MED BIO, P514, DOI 10.1109/EMBC.2015.7318412
   Chan AB, 2011, MACH VISION APPL, V22, P751, DOI 10.1007/s00138-010-0262-3
   Consejo Nacional para la Prevencion de Accidentes, 2013, TERC INF SIT SEG VIA
   Craye C, 2016, INT J INTELL TRANSP, V14, P173, DOI 10.1007/s13177-015-0112-9
   Dahiphale V. E., 2015, INT J ADV RES ELECT, V4, P2331
   Eskandarian A., 2007, Advanced Driver Fatigue Research
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gao XY, 2015, I IEEE EMBS C NEUR E, P767, DOI 10.1109/NER.2015.7146736
   Goyal R, 2015, 2015 AAAS ANN M 12 1
   Ji Q, 2002, REAL-TIME IMAGING, V8, P357, DOI 10.1006/rtim.2002.0279
   Kong WZ, 2015, J SENSORS, V2015, DOI 10.1155/2015/548602
   Li Z, 2015, IET INTELLIGENT TRAN
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   McLachlan GJ, 1988, MIXTURE MODELS MARCE
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Mu ZD, 2015, AEBMR ADV ECON, V8, P1031
   Papadelis C, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4136
   Patel ShreyaP., 2015, International Journal for Innovative Research in Science and Technology, V1, P133
   Qin Wang, 2015, Applied Mechanics and Materials, V701-702, P30, DOI 10.4028/www.scientific.net/AMM.701-702.30
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Shen HM, 2015, ADV INTEL SYS RES, V123, P103
   Sigari MH., 2014, International Journal of Advanced Science and Technology, V64, P73, DOI DOI 10.14257/IJAST.2014.64.07
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun KJ, 2015, P 2014 INT C MULT CO, V2014, P269
   Tanaka M, FACE DETECTION PARTS
   Tansakul Wasan, 2016, Journal of Automation and Control Engineering, V4, P33, DOI 10.12720/joace.4.1.33-39
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P, 2015, AEBMR ADV ECON, V8, P538
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Zhang LY, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629482
NR 36
TC 5
Z9 5
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19543
EP 19563
DI 10.1007/s11042-019-7218-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800028
DA 2024-07-18
ER

PT J
AU Lee, HY
AF Lee, Hae-Yeoun
TI Adaptive reversible watermarking for authentication and privacy
   protection of medical records
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imagery; Privacy protection; Reversible watermarking; Estimated
   error expansion; Segmentation
ID HIGH-CAPACITY; IMAGES; INFORMATION; CONTRAST; SCHEME
AB Medical systems, such as PACS or scanners, are vulnerable to security and forgery attacks. Consequently, medical records, such as patient information and medical imagery, can be easily leaked or forged. Reversible watermarking is an efficient solution used to protect medical records. However, previous studies have not sufficiently addressed medical applications. This study proposes an adaptive reversible watermarking algorithm that is directly applicable to medical systems that preserves the quality of medical imagery. In particular, the characteristics of medical imagery are considered. Once object and background regions are segmented, the reversible watermarking algorithm is applied based on an estimated error expansion approach. The watermark is embedded by expanding the estimated error from adjacent pixels. This watermark can include patient information or a hash code to detect forgery. When the watermark is extracted, original imagery is perfectly reconstructed without any quality degradation. Inherent over- and underflow problems are solved using an error pre-compensation technique. With the use of medical images from MRI, CT, and X-ray scanners, intensive experiments are performed to analyze the performance of the proposed algorithm with respect to capacity, perceptual quality, and reconstruction rate.
C1 [Lee, Hae-Yeoun] Kumoh Natl Inst Technol, Dept Comp Software Engn, 61 Daehak Ro, Gumi Si, Gyeongsangbuk D, South Korea.
C3 Kumoh National University Technology
RP Lee, HY (corresponding author), Kumoh Natl Inst Technol, Dept Comp Software Engn, 61 Daehak Ro, Gumi Si, Gyeongsangbuk D, South Korea.
EM haeyeoun.lee@kumoh.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1 A1B03030432]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2017R1D1 A1B03030432).
CR Abdeldaim AM, 2018, STUD COMPUT INTELL, V730, P131, DOI 10.1007/978-3-319-63754-9_7
   Al-Dmour H, 2016, COMPUT METH PROG BIO, V127, P24, DOI 10.1016/j.cmpb.2016.01.011
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2014, INT J TELEMED APPL
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Dou WB, 2012, J DIGIT IMAGING, V25, P751, DOI 10.1007/s10278-012-9518-y
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Eltoukhy M.M., 2018, J Ambient Intell Humaniz Comput, V247, P1, DOI [10.1007/s12652-018-0905-1, DOI 10.1007/S12652-018-0905-1]
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Lee HY, 2010, IEEE T BIO-MED ENG, V57, P905, DOI 10.1109/TBME.2009.2014545
   Lee HY, 2008, J MAGN RESON IMAGING, V28, P1393, DOI 10.1002/jmri.21586
   Lee HY, 2014, J CONVERGENCE INFORM, V8, P48
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li MY, 2005, COMPUT MED IMAG GRAP, V29, P367, DOI 10.1016/j.compmedimag.2005.02.003
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Wang DQ, 2017, J SIGNAL PROCESS SYS, V87, P215, DOI 10.1007/s11265-016-1169-7
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Yeo DG, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3532833
NR 33
TC 14
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19663
EP 19680
DI 10.1007/s11042-019-7322-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800034
DA 2024-07-18
ER

PT J
AU Rafi, M
   Mukhopadhyay, S
AF Rafi, Mudassir
   Mukhopadhyay, Susanta
TI Salient object detection employing regional principal color and texture
   cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Regional principal color; Color saliency; Texture
   saliency
ID VISUAL-ATTENTION; BOTTOM-UP; MODEL; EXTRACTION
AB Saliency in a scene describes those facets of any stimulus that makes it stand out from the masses. Saliency detection has attracted numerous algorithms in recent past and proved to be an important aspect in object recognition, image compression, classification and retrieval tasks. The present method makes two complementary saliency maps namely color and texture. The method employs superpixel segmentation using Simple Linear Iterative Clustering (SLIC). The tiny regions obtained are further clustered on the basis of homogeneity using DBSCAN. The method also employs two levels of quantization of color that makes the saliency computation easier. Basically, it is an adaptation to the property of the human visual system by which it discards the less frequent colors in detecting the salient objects. Furthermore, color saliency map is computed using the center surround principle. For texture saliency map, Gabor filter is employed as it is proved to be one of the appropriate mechanisms for texture characterization. Finally, the color and texture saliency maps are combined in a non-linear manner to obtain the final saliency map. The experimental results along with the performance measures have established the efficacy of the proposed method.
C1 [Rafi, Mudassir; Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Rafi, M (corresponding author), Indian Inst Technol ISM, Dhanbad, Bihar, India.
EM mudassir.rafi23@gmail.com; msushanta2001@gmail.com
RI Rafi, Mudassir/AAC-7520-2019
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen ZH, 2016, MULTIMED TOOLS APPL, V75, P16943, DOI 10.1007/s11042-015-2965-y
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hiremath, 2008, International Journal of Image Processing, V2, P10
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang H, 2010, COMPUT GRAPH FORUM, V29, P2055, DOI 10.1111/j.1467-8659.2010.01792.x
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   KURITA T, 1992, PATTERN RECOGN, V25, P1231, DOI 10.1016/0031-3203(92)90024-D
   Li A, 2013, PROC SPIE, V8878, DOI 10.1117/12.2030719
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lou J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112475
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Portilla J, 1996, OPT ENG, V35, P2403, DOI 10.1117/1.600814
   Ren YF, 2014, INT CONF MACH LEARN, P7, DOI 10.1109/ICMLC.2014.7009083
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Xia C, 2015, PATTERN RECOGN, V48, P1337, DOI 10.1016/j.patcog.2014.10.007
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yiqun Hu, 2005, 13th Annual ACM International Conference on Multimedia, P716
   Yu ZW, 2007, IEEE T MULTIMEDIA, V9, P766, DOI 10.1109/TMM.2007.893351
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149328
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
NR 52
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19735
EP 19751
DI 10.1007/s11042-019-7153-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800037
DA 2024-07-18
ER

PT J
AU Shet, KS
   Aswath, AR
   Hanumantharaju, MC
   Gao, XZ
AF Shet, K. Sathish
   Aswath, A. R.
   Hanumantharaju, M. C.
   Gao, Xiao-Zhi
TI Novel high-speed reconfigurable FPGA architectures for EMD-based image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Image steganography; Exploiting modification direction
   (EMD); Reconfigurable architectures; Field programmable gate arrays
   (FPGA)
AB Exploiting modification direction (EMD)-based image steganography algorithm has higher embedding efficiency, low distortion, and best security that finds application in secure communication, data protection, access control in digital content distribution, etc., EMD steganography encapsulates secret digit represented in (2n+1)-ary notational system by increasing or decreasing one of the n cover pixels by one. New high-speed reconfigurable architectures and field programmable gate array (FPGA) implementation of EMD based image steganography algorithms have been proposed. Although, earlier work on FPGA implementation of steganography algorithms offer higher speed, low chip area, and better throughput it usually operates on a fixed number of pixels. The proposed system works well for both arbitrary numbers of pixel groups and variable image resolution. The developed system is capable of embedding a secret message from two to eight-pixel groups with an image resolution of 512x512 pixels at a real-time video rate of 549 frames/s.. The complete design is implemented using RTL compliant Verilog code which fits into a single FPGA/ASIC chip with a gate density of two million gates.
C1 [Shet, K. Sathish] JSS Acad Tech Educ, Dept Elect & Commun Engn, Bengaluru, India.
   [Aswath, A. R.] Dayananda Sagar Coll Engn, Dept Telecommun Engn, Bengaluru, India.
   [Hanumantharaju, M. C.] BMS Inst Technol & Management, Dept Elect & Commun Engn, Bengaluru, India.
   [Gao, Xiao-Zhi] Univ Eastern Finland, Sch Comp, Kuopio, Finland.
C3 Dayananda Sagar College of Engineering; University of Eastern Finland
RP Shet, KS (corresponding author), JSS Acad Tech Educ, Dept Elect & Commun Engn, Bengaluru, India.
EM satish.personal@gmail.com
RI Raju, Hanumantha/N-9205-2017; K, Dr. Sathish Shet/J-9718-2019; R,
   Aswatha A/AAZ-1107-2020; GAO, XIAO/JED-3257-2023
OI Raju, Hanumantha/0000-0001-5549-2522; K, Dr. Sathish
   Shet/0000-0001-9616-1439; 
CR [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   [Anonymous], IEEE T INFORM FORENS
   Biswapati J, 2017, P 1 INT C INT COMP C
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Dhawale CA, 2017, ADV IMAGE PROCESSING
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Gómez-Hernández E, 2008, INT CONF ELECTR COMM, P123, DOI 10.1109/CONIELECOMP.2008.24
   Kasana G, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500205
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kumar V, 2018, MED RES REV, V38, P684, DOI 10.1002/med.21454
   Lee C-F, 2007, IEEE P INT INF HID M, V1
   MacLean W.J., 2005, P 2005 IEEE C COMPUT, P131
   Manyika J., 2013, DISRUPTIVE TECHNOLOG
   Niu XJ, 2015, INT J SECUR APPL, V9, P243, DOI 10.14257/ijsia.2015.9.5.24
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Pradhan A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149126
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rajagopalan Sundararaman, 2012, Journal of Applied Sciences, V12, P201, DOI 10.3923/jas.2012.201.210
   Ramalingam B, 2014, SCI WORLD J, DOI 10.1155/2014/192512
   Roy R, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P309, DOI 10.1109/ComManTel.2013.6482411
   Saidi M., 2016, MULTIMED TOOLS APPL, V76, P1
   Sharma VK, 2017, LECT NOTE NETW SYST, V12, P353, DOI 10.1007/978-981-10-3935-5_36
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Shet KS, 2017, MULTIMED TOOLS APPL, V76, P13197, DOI 10.1007/s11042-016-3736-0
   Shih FY, 2017, MULTIMEDIA SECURITY
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Vallathan G., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI DOI 10.17485/ijst/2017/v10i8/104011
   WANG CG, 2018, J MULTIMED TOOLS APP, V30, P1711, DOI DOI 10.1007/S10811-017-1349-2
   Wang ZH, 2010, J INFORM HIDING MULT, V1, P1, DOI DOI 10.1007/978-3-642-35473-114
   Wang ZH, 2017, INT J ADV MANUF TECH, V93, P3325, DOI 10.1007/s00170-017-0711-5
   Xu JJ, 2017, MULTIMED TOOLS APPL, V76, P15491, DOI 10.1007/s11042-016-3850-z
   XUE R, 2018, INT J NETWORK SECURI, V200, P65, DOI DOI 10.1016/J.TRSL.2018.05.006
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Younus Safaa, 2017, J AL QADISIYAH COMPU, V8, P1
   Zaidan BB, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S021812661750116X
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhou H, 2017, IEEE T IMAGE PROCESS, V26, P1623, DOI 10.1109/TIP.2017.2657886
   Zhou WB, 2017, IEEE T INF FOREN SEC, V12, P2654, DOI 10.1109/TIFS.2017.2718480
NR 40
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18309
EP 18338
DI 10.1007/s11042-019-7187-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200044
DA 2024-07-18
ER

PT J
AU Abozaid, A
   Haggag, A
   Kasban, H
   Eltokhy, M
AF Abozaid, Anter
   Haggag, Ayman
   Kasban, Hany
   Eltokhy, Mostafa
TI Multimodal biometric scheme for human authentication technique based on
   voice and face recognition fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometrics; SVM; ANN; GMM; Voice identification; Face
   recognition
ID SPEECH
AB In this paper, an effective multimodal biometric identification approach for human authentication tool based on face and voice recognition fusion is proposed. Cepstral coefficients and statistical coefficients are employed to extract features of voice recognition and these two coefficients are compared. Face recognition features are extracted utilizing different extraction techniques, Eigenface and Principle Component Analysis (PCA) and the results are compared. Voice and face identification modality are performed using different three classifiers, Gaussian Mixture Model (GMM), Artificial Neural Network (ANN), and Support Vector Machine (SVM). The combination of biometrics systems, voice and face, into a single multimodal biometric system is performed using features fusion and scores fusion. The computer simulation experiments reveal that better results are given in case of utilizing for voice recognition the cepstral coefficients and statistical coefficients and in case of face, Eigenface and SVM experiment gives better results for face recognition. Also, in the proposed multimodal biometrics system the scores fusion performs better than other scenarios.
C1 [Abozaid, Anter; Haggag, Ayman; Eltokhy, Mostafa] Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
   [Kasban, Hany] Atom Energy Author, Dept Engn, Nucl Res Ctr, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Modern Sciences & Arts
   University (MSA); Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy
   Authority (EAEA)
RP Abozaid, A (corresponding author), Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
EM anter19731973@gmail.com
RI Eltokhy, Mostafa/AAZ-8088-2020; Kasban, Hani/AAJ-6375-2020; Haggag,
   Ayman/AAS-3597-2020
OI Kasban, Hani/0000-0002-2249-5804; Haggag, Ayman/0000-0003-1637-1298
CR Abdelkarim N., 2015, ASIAN J INFORM TECHN, V14, P166
   Abhishree TM, 2015, PROCEDIA COMPUT SCI, V45, P312, DOI 10.1016/j.procs.2015.03.149
   Agashe NM, 2015, INT J ADV RES COMPUT, V4, P4247
   Baken R., 2000, Clinical measurement of speech and voice
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chetty G, 2008, IMAGE VISION COMPUT, V26, P1249, DOI 10.1016/j.imavis.2008.02.009
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   De A, 2015, PROCEDIA COMPUT SCI, V45, P282, DOI 10.1016/j.procs.2015.03.142
   Dodangeh P, 2018, J INF SECUR APPL, V41, P62, DOI 10.1016/j.jisa.2018.06.001
   El-Bendary MA, 2015, DEV SECURITY TOOLS W
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   Elmir Y, 2014, J INF PROCESS SYST, V10, P555, DOI 10.3745/JIPS.02.0007
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Gad R, 2015, INT J ADV COMPUT SC, V6, P128
   Galka J, 2014, IEEE T CONSUM ELECTR, V60, P653, DOI 10.1109/TCE.2014.7027339
   Halvi S, 2017, PROCEDIA COMPUT SCI, V115, P383, DOI 10.1016/j.procs.2017.09.095
   Inthavisas K, 2012, IET BIOMETRICS, V1, P46, DOI 10.1049/iet-bmt.2011.0008
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kasban H, 2017, ARAB J NUCL SCI APPL, V50, P120
   Kinnunen T, 2006, IEEE T AUDIO SPEECH, V14, P277, DOI 10.1109/TSA.2005.853206
   Kumar HCS, 2016, INT J SCI ENG APPL S, V2, P534
   Li HJ, 2016, PATTERN RECOGN, V60, P13, DOI 10.1016/j.patcog.2016.05.014
   Liu T, 2016, NEUROCOMPUTING, V214, P944, DOI 10.1016/j.neucom.2016.06.071
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Morgen B., 2012, BIOMETRIC TECHNOLOGY, V2012, P8, DOI DOI 10.1016/S0969-4765(12)70054-1
   Palanivel S, 2008, COMPUT VIS IMAGE UND, V109, P44, DOI 10.1016/j.cviu.2006.11.013
   Poh N, 2001, LECT NOTES COMPUT SC, V2091, P348
   Qi MP, 2018, COMPUT METH PROG BIO, V164, P101, DOI 10.1016/j.cmpb.2018.07.008
   Raghavendra R, 2010, PROCEDIA COMPUT SCI, V2, P181, DOI 10.1016/j.procs.2010.11.023
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Soltane M, 2015, INT J ENG TECHNOLOGY, V15, P41
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Xuan SB, 2016, IET COMPUT VIS, V10, P493, DOI 10.1049/iet-cvi.2015.0350
   Zheng CH, 2016, NEUROCOMPUTING, V198, P114, DOI 10.1016/j.neucom.2015.07.146
NR 36
TC 33
Z9 33
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16345
EP 16361
DI 10.1007/s11042-018-7012-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500028
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Singh, SK
   Chakraborty, P
AF Chakraborty, Soumendu
   Singh, Satish Kumar
   Chakraborty, Pavan
TI R-theta local neighborhood pattern for unconstrained facial image
   recognition and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local pattern descriptors; Local binary pattern (LBP); Local derivative
   pattern (LDP); Local ternary pattern (LTP); Local tetra pattern (LTrP);
   Semi local binary pattern (SLBP); R-theta local neighborhood pattern
   (RTLNP); Face recognition; Image retrieval
ID PRINCIPAL COMPONENT ANALYSIS; FACE-RECOGNITION; DISCRIMINANT-ANALYSIS;
   FEATURE DESCRIPTOR; INTEREST REGIONS; PCA
AB In this paper R-Theta Local Neighborhood Pattern (RTLNP) is proposed for facial image retrieval. RTLNP exploits relationships amongst the pixels in local neighborhood of the reference pixel at different angular and radial widths. The proposed encoding scheme divides the local neighborhood into sectors of equal angular width. These sectors are again divided into subsectors of two radial widths. Average grayscales values of these two subsectors are encoded to generate the micropatterns. Performance of the proposed descriptor has been evaluated and results are compared with the state of the art descriptors e.g. LBP, CSLBP, CSLTP, LDP, LTrP, MBLBP, and SLBP. The most challenging facial constrained and unconstrained databases, namely; AT&T, CARIA-Face-V5-Cropped, LFW, and Color FERET have been used for showing the efficiency of the proposed descriptor. Proposed descriptor is also tested on near infrared (NIR) face databases; CASIA NIR-VIS 2.0 and PolyU-NIRFD to explore its potential with respect to NIR facial images. Better retrieval rates of RTLNP as compared to the existing state of the art descriptors show the effectiveness of the descriptor.
C1 [Chakraborty, Soumendu] Indian Inst Informat Technol Lucknow, Lucknow, Uttar Pradesh, India.
   [Singh, Satish Kumar; Chakraborty, Pavan] Indian Inst Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Chakraborty, S (corresponding author), Indian Inst Informat Technol Lucknow, Lucknow, Uttar Pradesh, India.
EM soum.uit@gmail.com
RI Singh, Dr Satish Kumar/JMP-6186-2023; singh, satish/U-7158-2018;
   Chakraborty, Soumendu/ABA-2031-2020
OI Singh, Dr Satish Kumar/0000-0003-1991-7727; singh,
   satish/0000-0002-8536-4991; Chakraborty, Soumendu/0000-0002-8778-8229;
   chakraborty, pavan/0000-0002-9260-1131
CR [Anonymous], 2 IEEE WORKSH APPL C
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Jeong K, 2015, IEEE SIGNAL PROC LET, V22, P1400, DOI 10.1109/LSP.2014.2372762
   Kong H, 2005, NEURAL NETWORKS, V18, P585, DOI 10.1016/j.neunet.2005.06.041
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Noushath S, 2006, NEUROCOMPUTING, V69, P1711, DOI 10.1016/j.neucom.2006.01.012
   Noushath S, 2006, PATTERN RECOGN, V39, P1396, DOI 10.1016/j.patcog.2006.01.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhao SQ, 2008, IEEE IMAGE PROC, P2144, DOI 10.1109/ICIP.2008.4712212
NR 31
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14799
EP 14822
DI 10.1007/s11042-018-6846-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, QX
AF Li, Qingxia
TI Understanding the causal impact of the video delivery throughput on user
   engagement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video delivery; Throughput; User engagement
AB In this paper, we first examine the causal relationship between the perceived video download speed and user engagement, while the speed has a very limited impact on views of short-length videos, a lower speed could significantly impair the viewing completion rate of medium and long-length videos. In addition, we observe that a view with an experienced speed close to half of the video bitrate lasts 10% of the video less in comparison to a similar view with a higher relative speed. At last, We also pointed out that crossing AS (Autonomous System) borders does not necessarily imply a higher likelihood of being a problem session, as only 22% of the AS pairs show a statistically significant impact on video download speed.
C1 [Li, Qingxia] Dongguan Univ Technol, City Coll, Dept Comp, Dongguan 523419, Peoples R China.
C3 Dongguan University of Technology
RP Li, QX (corresponding author), Dongguan Univ Technol, City Coll, Dept Comp, Dongguan 523419, Peoples R China.
EM lee_qxia@163.com
FU Guangdong provincial science and technology plan projects
   [2016A010101034]
FX This work was supported by the Guangdong provincial science and
   technology plan projects (No. 2016A010101034)
CR [Anonymous], 2013, INTERNET CONNECTION
   [Anonymous], KENDALLS ADV THEOR A
   Balachandran A, 2013, ACM SIGCOMM COMP COM, V43, P339, DOI 10.1145/2534169.2486025
   Bauer Steven., 2010, UNDERSTANDING BROADB
   China Internet Network Information Center, 2017, TECHNICAL REPORT
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   dos Santos DAS, 2003, INT SYM PERFORM ANAL, P156, DOI 10.1109/ISPASS.2003.1190242
   Finamore A., 2011, ACM IMC, P345, DOI DOI 10.1145/2068816.2068849
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Jiang JC, 2013, PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT '13), P357, DOI 10.1145/2535372.2535394
   Kanrar S, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/7829570
   Kim Y, 2016, EDUC PSYCHOL-US, V51, P395, DOI 10.1080/00461520.2016.1207177
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Li ZY, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P307, DOI 10.1145/2740908.2743054
   Li ZY, 2014, IEEE INFOCOM SER, P397, DOI 10.1109/INFOCOM.2014.6847962
   Li ZY, 2015, IEEE T MULTIMEDIA, V17, P880, DOI 10.1109/TMM.2015.2417771
   Li ZG, 2012, PLANT SCI, V185, P185, DOI 10.1016/j.plantsci.2011.10.006
   Liu X, 2012, ACM SIGCOMM COMP COM, V42, P359, DOI 10.1145/2377677.2377752
   Mahimkar A, 2009, ACM SIGCOMM COMP COM, V39, P231, DOI 10.1145/1594977.1592596
   Mitchell T. M., 2003, Machine Learning
   Mu M, 2008, INT CONF NEXT GEN, P521, DOI 10.1109/NGMAST.2008.24
   Nam H., 2016, IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications, P1
   Otto JS, 2011, ACM SIGCOMM COMP COM, V41, P110, DOI 10.1145/2043164.2018450
   Rao A., 2011, Em: Proceedings of the Seventh COnference on emerging Networking EXperiments and Technologies, P1, DOI DOI 10.1145/2079296.2079321
   Shafiq M. Zubair, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P367, DOI 10.1145/2591971.2591975
   Yu M., 2012, Proceedings of the 8th international conference on Emerging networking experiments and technologies, P145
NR 27
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15589
EP 15604
DI 10.1007/s11042-018-7013-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700063
OA Bronze
DA 2024-07-18
ER

PT J
AU Tariq, J
AF Tariq, Junaid
TI RD-cost as statistical inference for early intra mode decision in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast intra prediction; Variance of reference pixels; High Efficiency
   Video Coding (HEVC); Image coding; Most probable mode; MPM; Features;
   RDOQ; Rate distortion optimization; RMD; Rough mode decision; Video
   coding
ID CU SIZE DECISION; PARALLEL FRAMEWORK; PREDICTION; ALGORITHM; EFFICIENCY
AB Fast intra mode decision strategy is proposed to overcome the brute force mode decision for the coding unit (CU) in High Efficiency Video Coding (HEVC). In this work, firstly, the intra mode in HEVC is studied and various facts are present in the form of statistical evidence that will be of great importance for the future of intra mode. Secondly, a novel rate distortion (RD) cost prediction model is developed for early termination that is based on the RD cost variation in the neighboring CUs with-respect-to their co-located CUs. Finally, an early termination of intra mode decision process is predicted using this predicted RD cost. Experimental results demonstrate that the predicted RD cost has a high correlation (R-2) of 96% with the original RD cost, and it is the highest accuracy achieved as compared to the existing state-of-the-art RD cost prediction methods. The proposed work saves 21% to 31% of total encoding time of the codec with BjOntegaard delta bit rate (BDBR) of 1.0% to 2.1% on average, respectively.
C1 [Tariq, Junaid] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
C3 NITEC University
RP Tariq, J (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
EM jtariq2-c@my.cityu.edu.hk
CR [Anonymous], 2001, VCEGM33
   [Anonymous], 2012, P 2012 VISUAL COMMUN
   [Anonymous], JCTVCH0166 ISOIEC MP
   Bossen F, 2011, COMMON TEST CONDITIO
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Fini MR, 2016, MULTIMED TOOLS APPL, V75, P7541, DOI 10.1007/s11042-015-2675-5
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Hu QH, 2016, MONUM SERI MONOG S, P1
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kim M, 2014, IEEE INT CON MULTI
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Rosewarne C, 2015, High Efficiency Video Coding (HEVC) Test model 16 (HM16) improved encoder description update 3
   Ruiz D, 2017, MULTIMED TOOLS APPL, V76, P861, DOI 10.1007/s11042-015-3014-6
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P2001, DOI 10.1007/s11042-015-3155-7
   Sullivan GJ, OHM J R HIGH EFFICIE
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1782, DOI 10.1109/SMC.2015.312
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wang P, 2017, ACSR ADV COMPUT, V76, P1
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
   Zhu J, 2013, IEEE IMAGE PROC, P1977, DOI 10.1109/ICIP.2013.6738407
NR 40
TC 7
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16783
EP 16801
DI 10.1007/s11042-018-7111-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500046
DA 2024-07-18
ER

PT J
AU Chen, X
   He, FZ
   Yu, H
AF Chen, Xiao
   He, Fazhi
   Yu, Haiping
TI A matting method based on full feature coverage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image matting; Edge sampling; Sample-set reduction; Search strategy;
   Selection criterion; Propagation matting
ID IMAGE SEGMENTATION; OPTIMIZATION; SALIENCY
AB The sampling-based matting method is an important method for image matting. There are three key techniques in sampling-based matting: 1) how to build a sample-set; 2) how to travel a sample-set; 3) how to obtain a good sample-pair. Although sampling range has expanded from local to global, the existing approaches to build the sample-set are still limited within the boundary areas of a trimap. Therefore, some valid samples may be ignored if they are far away from the trimap boundary. The so-called global samplings are limited by this disadvantage. Our idea comes from the observation that the samples on both sides of a image edge of the whole image are most representative. Furthermore, in the color space, the pixels in the smooth region are very close to the pixels near the image edge. Based on the discoveries, we present a full feature coverage sampling method, which utilizes the edges as clues to search all possible samples of the whole image area. First, we adopt edge detection to find the edges of the image. Second, the pixels near the edges are gathered into the sample-set. Third, because the population of a complete sample-set is much larger than existing sample-set, we propose an optimization approach to accelerate travelling sample-sets. Fourth, we propose a selective strategy and adopt a propagation matting to enhance the results of sampling matting. Finally, the experimental results are tested on an online benchmark. The results show that the proposed method outperforms many other sampling-based matting methods. The ranking of our method is at the forefront.
C1 [Chen, Xiao; He, Fazhi; Yu, Haiping] Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
C3 Wuhan University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
EM fzhe@whu.edu.cn
RI He, Fazhi/Q-3691-2018
FU National Natural Science Foundation of China [61472289]; National Key
   Research and Development Project [2016YFC0106305]
FX We would like to thank all the anonymous reviewers for their valuable
   comments. This work is supported by the National Natural Science
   Foundation of China(Grant No. 61472289) and the National Key Research
   and Development Project(Grant No.2016YFC0106305).
CR Aksoy Y., 2017, ARXIV170705055
   An FP, 2017, MULTIMED TOOLS APPL, V76, P13153, DOI 10.1007/s11042-016-3746-y
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], BR MACH VIS C BMVC
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Cheng Y, 2016, CLUSTER COMPUT, V19, P237, DOI 10.1007/s10586-016-0538-0
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Eberhart R., 1995, P INT S MICROMACHINE
   Feng XX, 2016, LECT NOTES COMPUT SC, V9906, P204, DOI 10.1007/978-3-319-46475-6_13
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   He B, 2013, IEEE IMAGE PROC, P4282, DOI 10.1109/ICIP.2013.6738882
   He B, 2014, J VIS COMMUN IMAGE R, V25, P1031, DOI 10.1016/j.jvcir.2014.03.002
   He B, 2012, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2012.6466851
   Hillman P, 2001, 2001 CVPR 2001, V1, pI
   Hullin M, 2016, P TINTERNATIONAL S V, P111
   Johnson J, 2014, BRIT MACH VIS C
   Johnson J, 2016, IEEE T IMAGE PROCESS, V25, P3032, DOI 10.1109/TIP.2016.2555705
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Karacan L, 2017, IEEE T IMAGE PROCESS, V26, P4523, DOI 10.1109/TIP.2017.2718664
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2017, COMPUTER VISION IMAG
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li K, 2016, FRONT COMPUT SCI-CHI, V10, P689, DOI 10.1007/s11704-016-5106-5
   Lin YC, 2012, MULTIMED TOOLS APPL, V61, P551, DOI 10.1007/s11042-010-0678-9
   Lv X, 2018, ADV ENG INFORM, V38, P381, DOI 10.1016/j.aei.2018.08.008
   Lv X, 2018, FUTURE GENER COMP SY, V82, P41, DOI 10.1016/j.future.2017.11.046
   Lv X, 2017, ADV ENG INFORM, V33, P397, DOI 10.1016/j.aei.2016.10.005
   Ni B, 2016, APPL MATH SER B, V31, P37, DOI 10.1007/s11766-016-3340-0
   Porter T., 1984, Computers & Graphics, V18, P253
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shi Y., 2013, EURASIP J AUDIO SPEE, V2013, P1, DOI DOI 10.1093/HMG/DDT066.SHIN
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Tan GH, 2016, MULTIMED TOOLS APPL, V75, P10213, DOI 10.1007/s11042-015-3160-x
   VARNOUSFADERANI ES, 1970, TIP, V22, P4260, DOI DOI 10.1109/TIP.2013.2271549
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   WANG J, 2007, IEEE CONFERENCE ON C, V7, P1
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wei X, 2017, MULTIMED TOOLS APPL, V76, P21547, DOI 10.1007/s11042-016-4073-z
   Wu YP, 2017, MULTIMED TOOLS APPL, V76, P19781, DOI 10.1007/s11042-015-3192-2
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu N., 2017, ARXIV170303872
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yan XM, 2018, INT J MACH LEARN CYB, V9, P621, DOI 10.1007/s13042-016-0584-1
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang ZP, 2012, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2012.6467308
   Zhang Zhanpeng, 2012, LECT NOTES COMPUTER, P433
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou Y, 2016, J SUPERCOMPUT, V72, P2394, DOI 10.1007/s11227-016-1738-3
   Zhou YF, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0102
NR 67
TC 54
Z9 54
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11173
EP 11201
DI 10.1007/s11042-018-6690-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900005
OA Bronze
DA 2024-07-18
ER

PT J
AU Knutas, A
   van Roy, R
   Hynninen, T
   Granato, M
   Kasurinen, J
   Ikonen, J
AF Knutas, Antti
   van Roy, Rob
   Hynninen, Timo
   Granato, Marco
   Kasurinen, Jussi
   Ikonen, Jouni
TI A process for designing algorithm-based personalized gamification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamification; Adaptive systems; Personalization; Design process; Machine
   learning
ID SCIENCE RESEARCH; EDUCATION
AB Personalization is an upcoming trend in gamification research, with several researchers proposing that gamified systems should take personal characteristics into account. However, creating good gamified designs is effort intensive as it is and tailoring system interactions to each user will only add to this workload. We propose machine learning algorithm -based personalized content selection to address a part of this problem and present a process for creating personalized designs that allows automating a part of the implementation. The process is based on Deterding's 2015 framework for gameful design, the lens of intrinsic skill atoms, with additional steps for selecting a personalization strategy and algorithm creation. We then demonstrate the process by implementing personalized gamification for a computer-supported collaborative learning environment. For this demonstration, we use the gamification user type hexad for personalization and the heuristics for effective design of gamification for overall design. The result of the applied design process is a context-aware, personalized gamification ruleset for collaborative environments. Lastly, we present a method for translating gamification rulesets to machine-readable classifier algorithm using the CN2 rule inducer.
C1 [Knutas, Antti; Kasurinen, Jussi; Ikonen, Jouni] LUT Univ, Skinnarilankatu 34, Lappeenranta 53850, Finland.
   [van Roy, Rob] Katholieke Univ Leuven, IMEC, Mintlab, Pk Str 45,Box 3500, B-3000 Leuven, Belgium.
   [Hynninen, Timo] South Eastern Finland Univ Appl Sci, Patteristonkatu 3, Mikkeli, Finland.
   [Granato, Marco] Univ Milan, Via Comelico 39, Milan, Italy.
C3 Lappeenranta-Lahti University of Technology LUT; IMEC; KU Leuven;
   South-Eastern Finland University of Applied Sciences; University of
   Milan
RP Knutas, A (corresponding author), LUT Univ, Skinnarilankatu 34, Lappeenranta 53850, Finland.
EM antti.knutas@lut.fi
RI Knutas, Antti/L-5808-2019; Kasurinen, Jussi/B-5147-2015
OI Knutas, Antti/0000-0002-6953-0021; Kasurinen, Jussi/0000-0001-9454-8664;
   GRANATO, MARCO/0000-0002-7322-4350
FU Lappeenranta University of Technology (LUT); European Union [A70554];
   Ulla Tuominen foundation
FX Open access funding provided by Lappeenranta University of Technology
   (LUT). Research was partially funded by European Union Regional
   Development Fund grant number A70554, "Kyberturvallisuusosaamisen ja
   liiketoiminnan kehittaminen," administrated by the Council of
   Kymenlaakso. The work of the first author was supported by the Ulla
   Tuominen foundation.
CR [Anonymous], 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems CHI13, DOI DOI 10.1145/2470654.2481341
   [Anonymous], 2012, P 8 AUSTR C INT ENT
   [Anonymous], 2007, SCAND J INF SYST
   [Anonymous], 2010, DESIGN RES INFORM SY
   [Anonymous], 2006, EMERGING TRENDS CHAL
   Antin J., 2011, CHI 2011 GAMIFICATIO
   Barata G., 2015, Smart Learning Environments, V2, P1, DOI DOI 10.1186/S40561-015-0017-8
   Bockle M., 2017, P 25 EUR C INF SYST
   Böckle M, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1227
   Busch M., 2015, Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P811
   Choi TST, 2017, J TRANSCULT NURS, V28, P315, DOI 10.1177/1043659616677641
   Clark P, 1991, Proceedings of the Fifth European Working Session on Learning, P151, DOI DOI 10.1007/BFB0017011
   Codish D, 2014, INT CONF UTIL CLOUD, P609, DOI 10.1109/UCC.2014.94
   Deci E. L., 2012, OXFORD HDB HUMAN MOT, P85, DOI [DOI 10.1093/OXFORDHB/9780195399820.013.0006, 10.1093/oxfordhb/9780195399820.013.0006]
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Deterding S, 2014, EUDAIMONIC DESIGN 6
   Deterding S, 2015, HUM-COMPUT INTERACT, V30, P294, DOI 10.1080/07370024.2014.993471
   Dicheva D, 2015, EDUC TECHNOL SOC, V18, P75
   Dillenbourg P., 1999, Collaborative-learning: Cognitive and computational approaches, P1
   Domínguez A, 2013, COMPUT EDUC, V63, P380, DOI 10.1016/j.compedu.2012.12.020
   Dubois D.J., 2013, Proceedings of the 2013 ninth Joint Meeting on Foundations of Software Engineering, P659
   Falkner N J., 2014, Proceedings of the 14th Koli Calling International Conference on Computing Education Research, P127, DOI DOI 10.1145/2674683.2674698
   Goldkuhl G, 2010, LECT NOTES COMPUT SC, V6105, P45
   Gregor S, 2013, MIS QUART, V37, P337, DOI 10.25300/MISQ/2013/37.2.01
   Habgood MPJ, 2011, J LEARN SCI, V20, P169, DOI 10.1080/10508406.2010.508029
   Hakulinen L, 2013, 2013 LEARNING AND TEACHING IN COMPUTING AND ENGINEERING (LATICE 2013), P47, DOI 10.1109/LaTiCE.2013.34
   Hanus M. D., 2018, LEVELING CLASSROOM T, P583, DOI DOI 10.4018/978-1-5225-5198-0.CH030
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Jabbour J, 2017, INT J RADIAT ONCOL, V97, P866, DOI 10.1016/j.ijrobp.2016.11.023
   Jianu EM, 2017, DESIGNING LEARNING S, P1
   Johnson DW, 1999, THEOR PRACT, V38, P67, DOI 10.1080/00405849909543834
   Kapp K.M., 2013, GAMIFICATION LEARNIN
   Kaptein M, 2015, INT J HUM-COMPUT ST, V77, P38, DOI 10.1016/j.ijhcs.2015.01.004
   Kasurinen J, 2018, COMPUT SCI REV, V27, P33, DOI 10.1016/j.cosrev.2017.10.003
   Knutas A, 2016, INT J HUM CAP INF TE, V7, P47, DOI 10.4018/IJHCITP.2016070104
   Knutas Antti., 2014, P 15 INT C COMPUTER, P370, DOI DOI 10.1145/2659532.2659620
   Knutas Antti, 2015, J INFORM TECHNOLOGIE, V7, P4
   Koster Raph, 2013, Theory of fun for game design
   Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3
   Looyestyn J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173403
   Marczewski A, 2015, EVEN NINJA MONKEYS P
   Mekler ED, 2017, COMPUT HUM BEHAV, V71, P525, DOI 10.1016/j.chb.2015.08.048
   Moccozet Laurent, 2013, 2013 International Conference on Interactive Collaborative Learning (ICL), P171, DOI 10.1109/ICL.2013.6644565
   Monterrat Baptiste, 2014, 6th International Conference on Computer-Supported Education (CSEDU 2014). Proceedings, P117
   Monterrat B, 2015, COMM COM INF SC, V510, P115, DOI 10.1007/978-3-319-25768-6_8
   Monterrat B, 2015, LECT NOTES ARTIF INT, V9112, P297, DOI 10.1007/978-3-319-19773-9_30
   Mora A, 2018, EDUCON 2018
   Nah Fiona Fui-Hoon, 2014, HCI in Business. First International Conference, HCIB 2014. Held as Part of HCI International 2014. Proceedings: LNCS 8527, P401, DOI 10.1007/978-3-319-07293-7_39
   Orji R, 2018, P 2018 ACM C HUM FAC
   Orji R, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P413, DOI 10.1145/3099023.3099116
   Osatuyi B, 2018, COMMUN ASSOC INF SYS, V42, P95, DOI 10.17705/1CAIS.04205
   Ostrowski L., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P4074, DOI 10.1109/HICSS.2012.51
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Song H, 2013, COMPUT HUM BEHAV, V29, P1702, DOI 10.1016/j.chb.2013.01.042
   Stahl G, 2006, CAMB HANDB PSYCHOL, P409
   Thomas C., 2013, 2013 International Conference on Interactive Collaborative Learning (ICL), P778, DOI [10.1109/ICL.2013.6644707, DOI 10.1109/ICL.2013.6644707]
   Tondello GF, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P129, DOI 10.1145/3116595.3116627
   Tondello GF, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P229, DOI 10.1145/2967934.2968082
   van Roy R, 2015, CHI 15 WORKSH RES GA
   van Roy R, 2015, CHI PLAY 15 WORKSH P
   Van Roy R., 2017, Serious Games Edutainment Applications, VII, P485, DOI DOI 10.1007/978-3-319-51645-5_22
NR 62
TC 26
Z9 27
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13593
EP 13612
DI 10.1007/s11042-018-6913-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900044
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kumar, D
   Verma, H
   Mehra, A
   Agrawal, RK
AF Kumar, Dhirendra
   Verma, Hanuman
   Mehra, Aparna
   Agrawal, R. K.
TI A modified intuitionistic fuzzy c-means clustering approach to segment
   human brain MRI image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intuitionistic fuzzy sets; Fuzzy c-means; Intuitionistic fuzzy c-means;
   Hesitation degree; Image segmentation; Magnetic resonance imaging
ID SPATIAL INFORMATION; ALGORITHM
AB Fuzzy c-means (FCM) is one of the prominent method utilized for medical image segmentation. In literature intuitionistic fuzzy c-means (IFCM) is suggested which is based on intuitionistic fuzzy sets (IFSs) theory to handle uncertainty and vagueness associated with real data. The objective function of which is defined using the hesitation degree along with membership degree. However, instead of solving the objective function analytically, the approximate solution is obtained using FCM. In this paper, we have proposed a modified intuitionistic fuzzy c-means algorithm (MIFCM) and solved analytically the objective function of the MIFCM method using Lagrange method of undetermined multiplier. To incorporate hesitation degree, two parametric intuitionistic fuzzy complements namely Sugeno's negation function and Yager's negation function are investigated. The performance of the MIFCM method is compared with three intuitionistic fuzzy clustering methods and the FCM on two publicly available MRI dataset and a synthetic dataset. The performance measures (average segmentation accuracy, dice score, jaccard score, false negative ratio and false positive ratio) are used to compare the performance of the MIFCM method with three variants of intuitionistic fuzzy clustering methods and the FCM. Experimental results demonstrate the superior performance of the MIFCM method over others.
C1 [Kumar, Dhirendra; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
   [Kumar, Dhirendra] Banasthali Vidyapith, Dept Comp Sci, Banasthali, Rajasthan, India.
   [Verma, Hanuman] Univ Delhi, Acharya Narendra Dev Coll, New Delhi, India.
   [Mehra, Aparna] Indian Inst Technol, Dept Math, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi; Banasthali Vidyapith; University
   of Delhi; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Delhi
RP Kumar, D (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.; Kumar, D (corresponding author), Banasthali Vidyapith, Dept Comp Sci, Banasthali, Rajasthan, India.
EM dhirendra.bhu08@gmail.com; hv4231@gmail.com; apmehra@maths.iitd.ac.in;
   rkajnu@gmail.com
RI Kumar, Dhirendra/AAE-8371-2021; AGRAWAL, RAMESH/AAR-8896-2020; Verma,
   Hanuman/AAX-5426-2020
OI Kumar, Dhirendra/0000-0002-8902-5022; Verma, Hanuman/0000-0003-4144-4858
FU CSIR [09/263(1016)/2014-EMR-I]; DST PURSE
FX The authors would like to thank CSIR (Grant no. 09/263(1016)/2014-EMR-I)
   and DST PURSE for the financial support. The authors are also thankful
   to the anonymous reviewers for their constructive suggestions.
CR Alipour S, 2014, MACH VISION APPL, V25, P1469, DOI 10.1007/s00138-014-0606-5
   [Anonymous], 1997, NEUROIMAGE
   [Anonymous], 1981, PATTERN RECOGN
   Atanassov K.T., 2003, Conf. Eur. Soc. Fuzzy Log. Technol., P12
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Bustince H, 2000, FUZZY SET SYST, V114, P485, DOI 10.1016/S0165-0114(98)00279-6
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chen X, 2016, 2016 IEEE INT C SYST
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Huang CW, 2015, SOFT COMPUT, V19, P459, DOI 10.1007/s00500-014-1264-2
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5259, P764, DOI 10.1007/978-3-540-88458-3_69
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Ji ZX, 2014, PATTERN RECOGN, V47, P3979, DOI 10.1016/j.patcog.2014.08.005
   Kannan SR, 2013, COMPUT BIOL MED, V43, P73, DOI 10.1016/j.compbiomed.2012.10.002
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Murofushi T, 2000, STUD FUZZ SOFT COMP, V40, P3
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Pelekis Nikos, 2008, International Journal of Business Intelligence and Data Mining, V3, P45, DOI 10.1504/IJBIDM.2008.017975
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Qiu CY, 2013, PATTERN RECOGN LETT, V34, P1329, DOI 10.1016/j.patrec.2013.04.021
   Sato M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P448, DOI 10.1109/ICIP.2000.899432
   Szmidt E, 2000, FUZZY SET SYST, V114, P505, DOI 10.1016/S0165-0114(98)00244-9
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Verma H, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015500165
   Vlachos LK, 2007, LECT NOTES COMPUT SC, V4529, P104
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wang L, 2010, J NEUROSCI METH, V188, P316, DOI 10.1016/j.jneumeth.2010.03.004
   Wang ZM, 2013, COMPUT VIS IMAGE UND, V117, P1412, DOI 10.1016/j.cviu.2013.05.001
   Xu ZS, 2010, J SYST ENG ELECTRON, V21, P580, DOI 10.3969/j.issn.1004-4132.2010.04.009
   YAGER RR, 1979, INT J GEN SYST, V5, P221, DOI 10.1080/03081077908547452
   YAGER RR, 1980, INFORM CONTROL, V44, P236, DOI 10.1016/S0019-9958(80)90156-4
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 38
TC 34
Z9 36
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12663
EP 12687
DI 10.1007/s11042-018-5954-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900003
DA 2024-07-18
ER

PT J
AU Yi, Y
   Wang, HL
AF Yi, Yun
   Wang, Hanli
TI Multi-modal learning for affective content analysis in movies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective content analysis; Convolutional neural networks; Motion
   keypoint trajectory; Multi-modal learning; Trajectory-based covariance
ID CONTENT REPRESENTATION; HISTOGRAMS; FRAMEWORK
AB Affective content analysis is an important research topic in video content analysis, and has extensive applications in many fields. However, it is a challenging task to design a computational model for predicting emotions induced by videos, since the elicited emotions can be considered relatively subjective. Intuitively, several features of different modalities can depict the elicited emotions, but the correlation and influence of these features are still not well studied. To address this issue, we propose a multi-modal learning framework, which classifies affective contents in the valence-arousal space. In particular, we utilize the features extracted by the methods of motion keypoint trajectory and convolutional neural networks to depict the visual modality of elicited emotions, and extract a global audio feature by the openSMILE toolkit to describe the audio modality. Then, the linear support vector machine and support vector regression are employed to learn the affective models. By comparing these three features with five baseline features, we discover that the three features are significant for describing affective content. Experimental results also demonstrate that the three features complement each other. Moreover, the proposed framework obtains the state-of-the-art results on two challenging datasets of video affective content analysis.
C1 [Yi, Yun; Wang, Hanli] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
   [Yi, Yun; Wang, Hanli] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
   [Yi, Yun] Gannan Normal Univ, Dept Math & Comp Sci, Ganzhou 341000, Peoples R China.
   [Wang, Hanli] Shanghai Engn Res Ctr Ind Vis Percept & Intellige, Shanghai 200092, Peoples R China.
C3 Tongji University; Tongji University; Gannan Normal University
RP Wang, HL (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.; Wang, HL (corresponding author), Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.; Wang, HL (corresponding author), Shanghai Engn Res Ctr Ind Vis Percept & Intellige, Shanghai 200092, Peoples R China.
EM hanliwang@tongji.edu.cn
RI Wang, Hanli/G-5111-2014; Yi, Yun/O-8432-2018
OI Wang, Hanli/0000-0002-9999-4871; Yi, Yun/0000-0002-5644-8002
FU National Natural Science Foundation of China [61622115, 61472281];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning [GZ2015005]; Shanghai
   Engineering Research Center of Industrial Vision Perception &
   Intelligent Computing [17DZ2251600]; Key Research and Development
   Project of Jiangxi Provincial Department of Science and Technology
   [20171BBE50065]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61622115 and 61472281, the Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning (No. GZ2015005), Shanghai Engineering
   Research Center of Industrial Vision Perception & Intelligent Computing
   (17DZ2251600), and the Key Research and Development Project of Jiangxi
   Provincial Department of Science and Technology (20171BBE50065).
CR Acar E, 2017, MULTIMED TOOLS APPL, V76, P11809, DOI 10.1007/s11042-016-3618-5
   Anastasia T, 2016, MEDIAEVAL 2016 WORKS
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Baecchi C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P72, DOI 10.1145/3078971.3079027
   Baveye Y, 2017, IEEE T AFFECT COMPUT
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Bosch A, 2007, ICCV 07, P1
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Chakraborty R, 2015, MEDIAEVAL 2015 WORKS
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dai Q., 2015, MEDIAEVAL 2015 WORKS
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Eggink J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P140, DOI 10.1109/ICME.2012.68
   Ellis D.P. W., 2005, PLP and RASTA (and MFCC, and inversion) in Matlab
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Lam V., 2015, MEDIAEVAL 2015 WORKS
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li C. C., 2016, ENVIRON EARTH SCI, V75, P14
   Lin CJ, 2007, J MACH LEARN RES, V9, P561, DOI DOI 10.1145/1273496.1273567
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Mironica I., 2015, MEDIAEVAL 2015 WORKS
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Poria S, 2015, NEURAL NETWORKS, V63, P104, DOI 10.1016/j.neunet.2014.10.005
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Schuller B, 2010, INTERSPEECH 10
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Teixeira RMA, 2012, MULTIMED TOOLS APPL, V61, P21, DOI 10.1007/s11042-010-0702-0
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   Trigeorgis G, 2015, MEDIAEVAL 2015 WORKS
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Verma D, 2016, ADV CHEM MAT ENG B, P1, DOI 10.4018/978-1-5225-0424-5
   Wang H, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1175, DOI 10.1145/2733373.2806310
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Yi Y. W. Hanli., 2015, MEDIAEVAL 2015 WORKS
   Yi Y, 2018, VISUAL COMPUT, V34, P391, DOI 10.1007/s00371-016-1345-6
   Yu HF, 2011, MACH LEARN, V85, P41, DOI 10.1007/s10994-010-5221-8
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu ZC, 2017, ATMOS CHEM PHYS, V17, P10001, DOI 10.5194/acp-17-10001-2017
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang SL, 2009, IEEE IMAGE PROC, P1853, DOI 10.1109/ICIP.2009.5413590
   Zhang SL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1369, DOI 10.1109/ICME.2008.4607698
NR 72
TC 15
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13331
EP 13350
DI 10.1007/s11042-018-5662-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900033
DA 2024-07-18
ER

PT J
AU Zhao, YC
   Tang, F
   Dong, WM
   Huang, FY
   Zhang, XP
AF Zhao, Yucheng
   Tang, Fan
   Dong, Weiming
   Huang, Feiyue
   Zhang, Xiaopeng
TI Joint face alignment and segmentation via deep multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face alignment; Face segmentation; Multi-task learning; Virtual makeup;
   Face swap
AB Face alignment and segmentation are challenging problems which have been extensively studied in the field of multimedia. These two tasks are closely related and their learning processes are supposed to benefit each other. Hence, we present a joint multi-task learning algorithm for both face alignment and segmentation using deep convolutional neural network (CNN). The proposed multi-task learning approach allows CNN model to simultaneously share visual knowledge between different tasks. With a carefully designed refinement residual module, the cross-layer features are fused in a collaborative manner. To the best of our knowledge, this is the first time that face alignment and segmentation are learned together via deep multi-task learning. Our experiments show that learning these two related tasks simultaneously builds a synergy between them, improves the performance of each individual task, and rivals recent approaches. Furthermore, we demonstrate the effectiveness of our model in two practical applications: virtual makeup and face swap.
C1 [Zhao, Yucheng; Tang, Fan; Dong, Weiming; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
   [Zhao, Yucheng; Tang, Fan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Huang, Feiyue] Tencent, YouTu Lab, Shanghai, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Tencent
RP Dong, WM (corresponding author), Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
EM weiming.dong@ia.ac.cn; xiaopeng.zhang@ia.ac.cn
RI DONG, Weiming/AAG-7678-2020; Wang, Jiacheng/ABE-5948-2020; Zhao,
   Yucheng/JYP-8261-2024; Tang, Fan/O-3923-2018
OI DONG, Weiming/0000-0001-6502-145X; Wang, Jiacheng/0000-0003-4327-1508;
   Tang, Fan/0000-0002-3975-2483
FU National Natural Science Foundation of China [61672520, 61702488,
   61501464, 6120106003]; Beijing Natural Science Foundation [4162056];
   National Key Technology RAMP;D Program of China [2015BAH53F02];
   CASIA-Tencent YouTu jointly research project
FX This work was supported by National Natural Science Foundation of China
   under nos. 61672520, 61702488, 61501464 and 6120106003, by Beijing
   Natural Science Foundation under No. 4162056, by National Key Technology
   R&D Program of China under No. 2015BAH53F02, and by CASIA-Tencent YouTu
   jointly research project.
CR [Anonymous], 2014, ARXIV14065212
   [Anonymous], 2014, ACCV
   [Anonymous], 2016, ARXIV161109577
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Elad M, 2017, IEEE T IMAGE PROCESS, V26, P2338, DOI 10.1109/TIP.2017.2678168
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Koestinger M., 2011, IEEE INT C COMP VIS, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Liu S., 2016, 25 INT JOINT C ART I
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JY, 2016, IEEE INT CONF MULTI
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Oikawa MA, 2016, IEEE T INF FOREN SEC, V11, P5, DOI 10.1109/TIFS.2015.2442527
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Ranjan R., 2016, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saito S, 2016, LECT NOTES COMPUT SC, V9912, P244, DOI 10.1007/978-3-319-46484-8_15
   Sheng KK, 2015, COMPUT GRAPH FORUM, V34, P213, DOI 10.1111/cgf.12760
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang Y, 2014, ARXIV14127489
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 42
TC 15
Z9 19
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13131
EP 13148
DI 10.1007/s11042-018-5609-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900022
DA 2024-07-18
ER

PT J
AU Dai, YW
   Liu, WW
   Liu, GJ
   Ji, XP
   Zhai, JT
AF Dai, Yuewei
   Liu, Weiwei
   Liu, Guangjie
   Ji, Xiaopeng
   Zhai, Jiangtao
TI An end-to-end generative network for environmental sound-based covert
   communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Generative model; Covert communication;
   Environmental sounds; Orthogonal quantization layer
AB Environmental sounds, everyday audio events that do not consist of music or speech data and are often more diverse and chaotic in their structure, have proven to be a promising type of carrier signals to carry out covert communication as they occur frequently in the natural environment, e.g., marine communication by mimicking dolphin or sea lion whistles. However, a mass collection of the carrier signals still remains a challenging task. Recently proposed generator models represented by Generator Adversarial Nets (GAN) have provided an effective way to synthesize environmental sounds. In this study, an end-to-end convolutional neural network (CNN) is proposed to directly transform the randomly sampled Gaussian noise into environmental sound that contains the secret message. The proposed network structure is composed of upsampling groups and orthogonal quantization layer, which can simultaneously realize factor analysis and information embedding. The design of the orthogonal quantization layer to complete the message embedding task is inspired by spread spectrum, model-based modulation, and compensative quantization. The underlying idea in this study is to treat the secret message as the constraint information in the generative model with the aim of maximizing the complete data model. The alternating back-propagation algorithm is used to train the overall network. Experimental results show that the proposed scheme can generate realistic environmental sounds that convey secret messages, while guaranteeing a high degree of communication reliability.
C1 [Dai, Yuewei; Liu, Weiwei; Liu, Guangjie; Ji, Xiaopeng] Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Jiangsu, Peoples R China.
   [Dai, Yuewei; Zhai, Jiangtao] Jiangsu Univ Sci & Technol, Sch Elect & Comp Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Jiangsu University of
   Science & Technology
RP Liu, WW (corresponding author), Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Jiangsu, Peoples R China.
EM lwwnjust@njust.edu.cn
RI Liu, Weiwei/HTN-4565-2023; Ji, Xiao-Peng/J-9175-2012; JI,
   Xiao-Peng/X-2622-2019
OI Liu, Weiwei/0000-0001-7353-9136; Ji, Xiao-Peng/0000-0001-6094-4626; JI,
   Xiao-Peng/0000-0001-6094-4626
FU National Natural Science Foundation of China [61602247, 61702235,
   U1636117, 61472188]; Natural Science Foundation of Jiangsu Province
   [BK20150472, BK20160840]; CCF-VENUSTECH Foundation [2016011];
   Fundamental Research Funds for the Central Universities [30920140121006,
   30915012208]
FX This work was supported by The National Natural Science Foundation of
   China (Grant No. 61602247, 61702235, U1636117, 61472188), Natural
   Science Foundation of Jiangsu Province (Grant No. BK20150472,
   BK20160840), CCF-VENUSTECH Foundation (Grant No. 2016011), Fundamental
   Research Funds for the Central Universities (30920140121006,
   30915012208).
CR [Anonymous], ARXIV180309043
   [Anonymous], 2017, ARXIV170701613
   Bengio Yoshua, Advances in Neural Information Processing Systems, P2672
   Bloch MR, 2016, IEEE T INFORM THEORY, V62, P2334, DOI 10.1109/TIT.2016.2530089
   Dol HS, 2008, COVERT UNDERWATER CO
   El-Atawy A, 2017, IEEE T DEPEND SECURE, V14, P116, DOI 10.1109/TDSC.2015.2443779
   Fridrich J, 2007, ELECT IMAGING, V2007
   Goeckel D, 2016, IEEE COMMUN LETT, V20, P236, DOI 10.1109/LCOMM.2015.2507594
   Han T., 2017, ADV COND MATTER PHYS, V2017, P1
   He B, 2017, IEEE COMMUN LETT, V21, P941, DOI 10.1109/LCOMM.2016.2647716
   Hu J, 2017, ARXIV170404946
   JIA Y, 2015, INFORM SCIENCES, V2015, P332
   Kingma DP, 2013, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LIU S, 2013, OCEANS, V2013, P1
   Liu SZ, 2013, J ACOUST SOC AM, V133, pEL300, DOI 10.1121/1.4795219
   Liu Songzuo., 2013, 2013 MTS/IEEE OCEANS-Bergen, P1
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   McDermott Josh H., 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P297, DOI 10.1109/ASPAA.2009.5346467
   McDermott JH, 2011, NEURON, V71, P926, DOI 10.1016/j.neuron.2011.06.032
   Neal RM, 2012, HDB MARKOV CHAIN MON, V2
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Radford A., 2015, ARXIV151106434
   RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Sobers TV, 2017, IEEE T WIREL COMMUN, V16, P6193, DOI 10.1109/TWC.2017.2720736
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wendzel S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2684195
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yang J., 2018, ARXIV180407939
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 36
TC 2
Z9 3
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8635
EP 8653
DI 10.1007/s11042-018-6592-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800040
DA 2024-07-18
ER

PT J
AU Liang, XL
   Zhang, H
AF Liang, Xiaolin
   Zhang, Hao
TI Remotely detectable signs of life based on impulse UWB radar
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breathing rate (BR); Signs of life; Ultra-wideband (UWB) radar; Wavelet
   transform (WT)
ID TRAPPED VICTIMS; ALGORITHM
AB It is challenging to extract signs of life under low signal to noise ratio (SNR) using a contactless radar in complex environments. Via analyzing the characteristics of signs of life, a feasible localization and detection technique is investigated by employing the through-wall ultra-wide band (UWB) radar. Based on the time-frequency matrix from the wavelet transform (WT) technique performed on the skewness and kurtosis of the received pulses, the distance from the radar to human beings is acquired. Human breathing rate (BR) is measured only using the pulses in the effective area. Different experiments are conducted to test the presented detection technique compared with several traditional methods.
C1 [Liang, Xiaolin] 41st Res Inst CETC, Sci & Technol Elect Test & Measurement Lab, Xiang Jiang Rd 98th, Qingdao, Shandong, Peoples R China.
   [Zhang, Hao] Ocean Univ China, Dept Elect Engn, Song Ling Rd 238th, Qingdao, Shandong, Peoples R China.
C3 China Electronics Technology Group; Ocean University of China
RP Liang, XL (corresponding author), 41st Res Inst CETC, Sci & Technol Elect Test & Measurement Lab, Xiang Jiang Rd 98th, Qingdao, Shandong, Peoples R China.
EM iamxiaolin2016@126.com; zhanghao@ouc.edu.cn
OI Liang, Xiaolin/0000-0002-8807-6661
FU Science and Technology on Electronic Test AMP; Measurement Laboratory
   [9140C120102150C12055, 6142001010101]; Nature Science Foundation of
   China [41527901, 61501424, 61701462]; Ao Shan Science and Technology
   Innovation Project of Qingdao National Laboratory for Marine Science and
   Technology [2017ASKJ01]
FX This work was funded by the Science and Technology on Electronic Test &
   Measurement Laboratory (9140C120102150C12055 and 6142001010101), Nature
   Science Foundation of China (41527901, 61501424 and 61701462), and the
   Ao Shan Science and Technology Innovation Project of Qingdao National
   Laboratory for Marine Science and Technology (2017ASKJ01).
CR Antoni J, 2006, MECH SYST SIGNAL PR, V20, P282, DOI 10.1016/j.ymssp.2004.09.001
   Ascione M, 2013, IEEE T INSTRUM MEAS, V62, P13, DOI 10.1109/TIM.2012.2209917
   Barros J, 2012, IEEE T INSTRUM MEAS, V61, P2604, DOI 10.1109/TIM.2012.2199194
   Conte E, 2010, IEEE SIGNAL PROC LET, V17, P905, DOI 10.1109/LSP.2010.2071382
   Gennarelli G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080621
   Hu W, 2014, IEEE T BIO-MED ENG, V61, P725, DOI 10.1109/TBME.2013.2288319
   Kumar A, 2018, AEU-INT J ELECTRON C, V84, P100, DOI 10.1016/j.aeue.2017.11.024
   Li CZ, 2008, IEEE T MICROW THEORY, V56, P3143, DOI 10.1109/TMTT.2008.2007139
   Li J, 2014, IEEE J-STARS, V7, P783, DOI 10.1109/JSTARS.2013.2259801
   Li Z. Q., 2017, IEEE T KNOWL DATA EN, V99, P1
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li Z, 2013, IEEE T MICROW THEORY, V61, P2086, DOI 10.1109/TMTT.2013.2247054
   Liang XL, 2018, PHYS COMMUN-AMST, V29, P31, DOI 10.1016/j.phycom.2018.04.004
   Liang XL, 2018, IET COMMUN, V12, P771, DOI 10.1049/iet-com.2017.1177
   Liang XL, 2018, DIGIT SIGNAL PROCESS, V74, P72, DOI 10.1016/j.dsp.2017.12.004
   Liang XL, 2017, IEEE ACCESS, V5, P22101, DOI 10.1109/ACCESS.2017.2761771
   LIANG XL, 2018, EURASIP J WIREL 0222, DOI DOI 10.1186/s13638-017-1011-3
   Liu L, 2016, NEUROCOMPUTING, V181, P108, DOI [10.1016/j.neucom.2015.08.096, DOI 10.1016/J.NEUCOM.2015.08.096]
   Liu LB, 2011, IEEE J-STARS, V4, P791, DOI 10.1109/JSTARS.2011.2157461
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Mercuri M, 2013, IEEE T MICROW THEORY, V61, P2061, DOI 10.1109/TMTT.2013.2247619
   Naishadham K, 2008, IEEE T ANTENN PROPAG, V56, P1742, DOI 10.1109/TAP.2008.916932
   Nezirovic A, 2010, IEEE T GEOSCI REMOTE, V48, P2005, DOI 10.1109/TGRS.2009.2036840
   Nijsure Y, 2013, IEEE T BIO-MED ENG, V60, P1509, DOI 10.1109/TBME.2012.2237401
   Park BK, 2007, IEEE T MICROW THEORY, V55, P1073, DOI 10.1109/TMTT.2007.895653
   REN L, 2016, TMTT, V64, P3319, DOI DOI 10.1109/TMTT.2016.2597824
   Ren LY, 2015, IEEE MICROW WIREL CO, V25, P690, DOI 10.1109/LMWC.2015.2463214
   Singh A, 2013, IEEE T MICROW THEORY, V61, P1718, DOI 10.1109/TMTT.2013.2249525
   Wang JY, 2014, IEEE T INSTRUM MEAS, V63, P145, DOI 10.1109/TIM.2013.2277530
   Wu SY, 2016, IET RADAR SONAR NAV, V10, P468, DOI 10.1049/iet-rsn.2015.0159
   Xu YY, 2012, IEEE T GEOSCI REMOTE, V50, P3132, DOI 10.1109/TGRS.2011.2178248
   Xu YY, 2012, IEEE T GEOSCI REMOTE, V50, P1254, DOI 10.1109/TGRS.2011.2164928
   Yan ZH, 2017, MECH SYST SIGNAL PR, V96, P385, DOI 10.1016/j.ymssp.2017.04.019
NR 34
TC 2
Z9 3
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10583
EP 10599
DI 10.1007/s11042-018-6642-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400047
DA 2024-07-18
ER

PT J
AU Shreelekshmi, R
   Wilscy, M
   Madhavan, CEV
AF Shreelekshmi, R.
   Wilscy, M.
   Madhavan, C. E. Veni
TI Undetectable least significant bit replacement steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; LSB replacement; Undetectability; Security
ID IMAGES; STEGANALYSIS
AB In this paper we propose a novel method based on Inverse Transitions for increasing the security of Least Significant Bit (LSB) replacement steganography. Before hiding data using LSB replacement, cover image is preprocessed using inverse transitions. The preprocessing modifies the LSBs in such a way that the resulting change in pixel values can not occur with LSB replacement. The proposed method ensures 100% undetectability for payload up to 1.5 bpp in colour images against most accurate length estimation methods for LSB replacement. The proposed method is faster, does not require any additional storage and ensures complete recovery of hidden data in comparison to state of the art steganography methods. The proposed method can be used in resource constrained applications which demand fast and secure data hiding and loss less recovery of hidden data.
C1 [Shreelekshmi, R.] LBSITW, Dept Comp Sci, Engn, Thiruvananthapuram 695012, Kerala, India.
   [Shreelekshmi, R.] Coll Engn, Dept Comp Sci, Engn, Thiruvananthapuram 695016, Kerala, India.
   [Wilscy, M.] Univ Kerala, Dept Comp Sci, Thiruvananthapuram 695581, Kerala, India.
   [Madhavan, C. E. Veni] Indian Inst Sci, Comp Sci, Automat, Bangalore 560012, Karnataka, India.
C3 LBS Institute of Technology for Women; College of Engineering,
   Trivandrum; University of Kerala; Indian Institute of Science (IISC) -
   Bangalore
RP Shreelekshmi, R (corresponding author), LBSITW, Dept Comp Sci, Engn, Thiruvananthapuram 695012, Kerala, India.; Shreelekshmi, R (corresponding author), Coll Engn, Dept Comp Sci, Engn, Thiruvananthapuram 695016, Kerala, India.
EM shreelekshmir@gmail.com; wisyphilipose@hotmail.com;
   cevm@csa.iisc.ernet.in
RI R, Shreelekshmi/AAH-6910-2020
OI R, Shreelekshmi/0000-0002-6523-3652
FU Kerala State Council for Science Technology and Environment [149/ 2012/
   KSCSTE]
FX This work was supported by the Kerala State Council for Science
   Technology and Environment [grant number 149/ 2012/ KSCSTE].
CR Abdulrahman H, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P448, DOI 10.1109/ARES.2015.44
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Chandramouli R, 2002, ADAPTIVE STEGANOGRAP, P69
   Dumitrescu S, 2005, IEEE T SIGNAL PROCES, V53, P3936, DOI 10.1109/TSP.2005.855078
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2012, LNCS, P31
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Goljan M, 2014, IEEE INT WORKS INFOR, P185, DOI 10.1109/WIFS.2014.7084325
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ker A, 2004, QUANTITATIVE EVALUAT, P83
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Liao X, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P76, DOI 10.1109/IIH-MSP.2015.28
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu WW, 2014, ANN TELECOMMUN, V69, P403, DOI 10.1007/s12243-013-0386-3
   Lu PZ, 2004, LECT NOTES COMPUT SC, V3200, P116
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Schaefer G, 2004, UCID UNCOMPRESSED CO, P472
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Shreelekshmi R, 2013, SIGNAL IMAGE VIDEO P, V7, P811, DOI 10.1007/s11760-011-0270-4
   Shreelekshmi R, 2010, IMAGE CLASSIFICATION, P66
   Tang WX, 2016, IEEE SIGNAL PROC LET, V23, P197, DOI 10.1109/LSP.2015.2504583
   Tao Z, 2003, RELIABLE DETECTION L, P545
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xin Liao, 2015, Algorithms and Architectures for Parallel Processing. 15th International Conference, ICA3PP 2015. Proceedings: LNCS 9530, P695, DOI 10.1007/978-3-319-27137-8_50
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yang M, 2015, IEEE IMAGE PROC, P402, DOI 10.1109/ICIP.2015.7350829
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 32
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10565
EP 10582
DI 10.1007/s11042-018-6541-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400046
DA 2024-07-18
ER

PT J
AU Wu, XQ
   Li, JB
   Tu, R
   Cheng, JR
   Bhatti, UA
   Ma, JX
AF Wu, Xiaoqi
   Li, Jingbing
   Tu, Rong
   Cheng, Jieren
   Bhatti, Uzair Aslam
   Ma, Jixin
TI Contourlet-DCT based multiple robust watermarkings for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Contourlet-DCT; Zero watermarking; Robust
ID TRANSFORM
AB In the current medical system, the privacy and security of the medical information with respect to its transmission and storage is a key challenge. In pursuit of this, we proposed a contourlet transform and Discrete Cosine Transform (DCT) based multiple robust watermarking algorithms for medical imaging. The proposed scheme uses contourlet transform to extract multidirectional and multiscale texture information, and then the DCT was used to acquire the feature vector in the low frequency directional subbands. Then we used Logistic Map to encrypt the watermark to ensure the security of the original watermarking information under a chaotic system. In watermark embedding and extraction phases, we adopted zero-watermarking technique to ensure the integrity of the medical images. Our experimental results show that the proposed algorithm can embed much more data with less complexity and dose not change the pixel value of the original image. Moreover, the proposed algorithm can extract the watermark effectively with good invisibility and robustness to common and geometric attacks.
C1 [Wu, Xiaoqi; Li, Jingbing; Cheng, Jieren; Bhatti, Uzair Aslam] Hainan Univ, Coll Informat Sci & Technol, Haikou 570228, Hainan, Peoples R China.
   [Li, Jingbing] Hainan Univ, State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.
   [Tu, Rong] Hainan Med Univ, Affiliated Hosp 1, Haikou 570102, Hainan, Peoples R China.
   [Ma, Jixin] Univ Greenwich, Sch Comp & Math Sci, London, England.
C3 Hainan University; Hainan University; Hainan Medical University;
   University of Greenwich
RP Li, JB (corresponding author), Hainan Univ, Coll Informat Sci & Technol, Haikou 570228, Hainan, Peoples R China.; Li, JB (corresponding author), Hainan Univ, State Key Lab Marine Resource Utilizat South Chin, Haikou 570228, Hainan, Peoples R China.; Tu, R (corresponding author), Hainan Med Univ, Affiliated Hosp 1, Haikou 570102, Hainan, Peoples R China.
EM xiaoqiwu567@163.com; Jingbingli2008@hotmail.com; turong37472@126.com;
   cjr22@163.com; uzairslambhatti@hotmail.com; J.Ma@greenwich.ac.uk
RI Ma, Jixin/AAF-3008-2021; Ma, Jixin/ABG-9343-2021
OI Ma, Jixin/0000-0001-7458-7412; 
FU Key Research Project of Hainan Province [ZDYF2018129]; National Natural
   Science Foundation of China [61762033]; Natural Science Foundation of
   Hainan [617048, 2018CXTD333]
FX This work is supported by the Key Research Project of Hainan Province
   [ZDYF2018129], and by the National Natural Science Foundation of China
   [61762033] and the Natural Science Foundation of Hainan [617048,
   2018CXTD333].
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   [Anonymous], 2012, INT J DIGIT CONTENT
   Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Deng ZJ, 2004, JCU, V27, P61
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Feng HY, 2012, J CONVERG INF TECHNO, V7, P292
   Hu D, 2018, IEEE ACCESS, V1, P1, DOI DOI 10.1109/TDSC.2018.2875697
   Jin C., 2008, DIGITAL WATERMARKING
   [刘英 Liu Ying], 2016, [光电子·激光, Journal of Optoelectronics·Laser], V27, P317
   Rangel-Espinoza K., 2017, MULTIMED TOOLS APPL, V77, P1
   Roberto HB, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI [10.1109/78.127960, DOI 10.1109/78.127960]
   Sun X, 2002, J COMPUTER AIDED DES, V14, P1
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Yaxun Zhou, 2011, 2011 International Conference on Multimedia Technology, P2873
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhou QL, 2018, CMC-COMPUT MATER CON, V55, P151, DOI [10.3970/cmc.2018.055.15l, 10.3970/cmc.2018.055.151]
   Zhu TT, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P87, DOI 10.1109/MINES.2009.105
NR 23
TC 28
Z9 29
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8463
EP 8480
DI 10.1007/s11042-018-6877-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800032
DA 2024-07-18
ER

PT J
AU Xiang, ZY
   Hu, YC
   Yao, H
   Qin, C
AF Xiang, Zhaoyang
   Hu, Yu-Chen
   Yao, Heng
   Qin, Chuan
TI Adaptive and dynamic multi-grouping scheme for absolute moment block
   truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Lossy compression; Block truncation coding;
   Multi-grouping
ID IMAGE COMPRESSION
AB Image compression technique is widely used in multimedia signal processing. As a conventional lossy compression technique, block truncation coding (BTC) deserves further improvements to enhance its performance of compression. The improvements of BTC mainly focus on: 1) enhancing the quality of reconstructed image and 2) decreasing the bit rate. In this paper, an adaptive and dynamic multi-grouping scheme is proposed for the absolute moment block truncation coding (AMBTC), which is mainly based on an optimized grouping mechanism with the adaptive threshold setting according to the complexity of image blocks. Besides, the values of the reconstruction levels are replaced by their compressed difference values in order to decrease the bit rate. Experimental results demonstrate that the proposed scheme can enhance the compression performance of AMBTC effectively.
C1 [Xiang, Zhaoyang; Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
C3 University of Shanghai for Science & Technology; Providence University -
   Taiwan
RP Qin, C (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
EM warrior_xy@163.com; ychu@pu.edu.tw; hyao@usst.edu.cn; qin@usst.edu.cn
RI Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017; Hui, Yu/JOZ-3598-2023;
   Hu, Yu-Chen/AAT-5264-2020; xiang, zhao/HGB-8063-2022
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623; Hu,
   Yu-Chen/0000-0002-5055-3645; 
FU National Natural Science Foundation of China [61672354, 61702332]; Open
   Project Program of the National Laboratory of Pattern Recognition
   [201600003]; Open Project Program of Shenzhen Key Laboratory of Media
   Security, Shanghai Engineering Center Project of Massive Internet of
   Things Technology for Smart Home [GCZX14014]; Hujiang Foundation of
   China [C14001, C14002]
FX This work was supported by the National Natural Science Foundation of
   China (61672354, 61702332), the Open Project Program of the National
   Laboratory of Pattern Recognition (201600003), the Open Project Program
   of Shenzhen Key Laboratory of Media Security, Shanghai Engineering
   Center Project of Massive Internet of Things Technology for Smart Home
   (GCZX14014), and Hujiang Foundation of China (C14001, C14002).
CR Al-Azawi Saad, 2011, 2011 7th International Workshop on Systems, Signal Processing and their Applications (WOSSPA 2011), P131, DOI 10.1109/WOSSPA.2011.5931432
   Al-Salhi YEA, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY, IEEE 3RD INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING, (HPSC) AND 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P112, DOI 10.1109/BigDataSecurity.2017.16
   Amarunnishad T. M., 2006, ADCOM 2006: Autonomic Computing Fourteenth International Conference on Advanced Computing and Communications, P344
   Anil D., 2011, Proceedings of the 2011 International Conference on Pattern Analysis and Intelligent Robotics (ICPAIR 2011), P31, DOI 10.1109/ICPAIR.2011.5976907
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P489, DOI 10.1109/IIH-MSP.2014.128
   CHEN LG, 1994, IEEE T CIRC SYST VID, V4, P92, DOI 10.1109/76.276177
   CHENG SC, 1994, PATTERN RECOGN, V27, P1439, DOI 10.1016/0031-3203(94)90123-6
   Chin-Chen Chang, 2008, 2008 Second International Conference on Future Generation Communication and Networking Symposia (FGCNS), P154, DOI 10.1109/FGCNS.2008.33
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   FRANTI P, 1994, COMPUT J, V37, P308, DOI 10.1093/comjnl/37.4.308
   Hu YC, 2004, J ELECTRON IMAGING, V13, P871, DOI 10.1117/1.1785158
   Hu YC, 2003, ELECTRON LETT, V39, P1377, DOI 10.1049/el:20030884
   Hu YC, 2003, OPT ENG, V42, P1964, DOI 10.1117/1.1576776
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P134, DOI 10.1109/IIH-MSP.2014.40
   LIU JF, 2016, INF SCI, V59, P1
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mathews J, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P377, DOI 10.1109/iMac4s.2013.6526440
   Olsen SI, 2000, PATTERN RECOGN LETT, V21, P1141, DOI 10.1016/S0167-8655(00)00075-1
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Tsou CC, 2008, IMAGING SCI J, V56, P217, DOI 10.1179/174313108X281335
   Vijayanagar KR, 2012, P 2012 3DTV C TRUE V, P1
   Yang CY, 1996, ELECTRON LETT, V32, P1870, DOI 10.1049/el:19961267
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 31
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7895
EP 7909
DI 10.1007/s11042-018-6030-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800002
DA 2024-07-18
ER

PT J
AU Xue, F
   Lu, W
   Ye, ZY
   Liu, HM
AF Xue, Fei
   Lu, Wei
   Ye, Ziyi
   Liu, Hongmei
TI JPEG image tampering localization based on normalized gray level
   co-occurrence matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Double compressed JPEG image; Tampered region
   localization; Normalized gray level co-occurrence matrix
ID EXPOSING DIGITAL FORGERIES; WATERMARKING
AB To locate the tampered region of double compressed JPEG images, one of the most effective methods is based on the statistical characteristic of the images. After tampering operation, the tampered region and the original region will have different statistical distributions. And according to this cue, the histogram of DCT coefficients can be moded as the mixture of the distributions of DCT coefficients in tampered and untampered regions. By estimating each distribution of the mixture model, the probability of being tampered of each DCT block can be calculated and the final localization result can be obtained. Thus the mixture model will significant impact the result. In this paper, a novel mixture model based on normalized gray level co-occurrence matrix (NGLCM) is proposed for tampering localization in JPEG images. Firstly, NGLCM is used to measure the conditional probabilities of being tampered regions and being untampered regions for each 8 x 8 DCT coefficient block, which can take advantage of both the statistical characteristic of double quantization effect and the relationship among neighboring blocks. Then the Bayesian posterior probability map is generated by the conditional probabilities, which indicates the tampering probability of each block. Finally, the map is refined based on a inter-block connectivity and Gaussian weighted filter strategy to determine the final tampered region location. Experimental results demonstrate that the proposed approach can localize the tampered region of JPEG images with a satisfactory performance and outperforms the state-of-the-art methods.
C1 [Xue, Fei; Lu, Wei; Ye, Ziyi; Liu, Hongmei] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM xuefeicn@qq.com; luwei3@mail.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   R&D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2010, INFOCOM IEEE C COMPU
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Chen J, 2018, BINARY IMAGE STEGANA
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Dong L, 2011, ADV INF SCI SERV SCI, V3, P384
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fu D, 2007, SPIE ELECT IMAGING S, V6505
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   LI B, 2008, IEEE 10TH WORKSHOP O, V10, P730
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Suhail MA, 2003, INFORM SCIENCES, V151, P93, DOI 10.1016/S0020-0255(02)00291-8
   Wang C., 2016, P 2016 ACM MULT C, P988, DOI 10.1145/2964284.2964299
   Wang CH, 2019, TRANSPORTMETRICA A, V15, P55, DOI 10.1080/23249935.2018.1449913
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wang W, 2010, 9 INT WORKSH DIG WAT
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zhang F, 2018, MULTIMEDIA TOOLS APP
   Zhang Y, 2018, SIGNAL PROCESSING
NR 39
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9895
EP 9918
DI 10.1007/s11042-018-6611-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400018
DA 2024-07-18
ER

PT J
AU Yang, JH
   Kang, XG
   Wong, EK
   Shi, YQ
AF Yang, Jianhua
   Kang, Xiangui
   Wong, Edward K.
   Shi, Yun-Qing
TI JPEG steganalysis with combined dense connected CNNs and SCA-GFR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; JPEG image steganalysis; Convolutional neural
   networks; Ensemble
AB The detection of weakly hidden information in a JPEG compressed image is challenging. In this paper, we propose a 32-layer convolutional neural network (CNN) involving feature reuse by concatenating all features from previous layers. The proposed method can improve the flow of gradient, and the sharing of features and bottleneck layers can also dramatically reduce the number of parameters in the proposed CNN model. To further improve the detection accuracy and combine the directional features from the selection-channel-aware Gabor filtering residual (SCA-GFR) method with Gabor filtering and non-directional feature maps from the CNN model, an ensemble architecture called CNN-SCA-GFR is used, which combines the proposed CNN method with the conventional SCA-GFR method to detect J-UNIWARD and UERD. This can significantly reduce the detection error rate to below that of the existing JPEG steganalysis methods. For example, in the detection of J-UNIWARD at 0.1 bpnzAC, the detection error rate using our proposed method is 5.67% lower than that achieved by XuNet, and 7.89% lower than that achieved by the conventional SCA-GFR method. When detecting UERD at 0.1 bpnzAC, the detection error rate using our proposed method is 5.94% lower than that achieved by XuNet, and 10.28% lower than that achieved by the conventional SCA-GFR method.
C1 [Yang, Jianhua; Kang, Xiangui] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
   [Wong, Edward K.] NYU, Comp Sci & Engn Dept, New York, NY USA.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Sun Yat Sen University; New York University; New York University Tandon
   School of Engineering; New Jersey Institute of Technology
RP Kang, XG (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
EM isskxg@mail.sysu.edu.cn; ewong@nyu.edu; shi@njit.edu
RI Yang, JianHua/A-5330-2011; Kang, Xiangui/AAO-5527-2020
FU NSFC [NSFC 61772571, U1536204]; Sun Yat-sen University [6177060230]
FX This work was supported by NSFC (Grant Nos. U1536204, NSFC 61772571) and
   special funding for basic scientific research from Sun Yat-sen
   University (Grant No.6177060230).
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ARXIV161103233
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2007, Bows-2
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Chen YF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2111, DOI 10.1109/ICASSP.2018.8462057
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   GUO L, 2015, INFO, V10, P2669, DOI DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2075239
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yan XB, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P1, DOI 10.1109/QRS-C.2017.11
   Yang JH, 2017, LECT NOTES COMPUT SC, V10431, P263, DOI 10.1007/978-3-319-64185-0_20
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
NR 28
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8481
EP 8495
DI 10.1007/s11042-018-6878-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800033
DA 2024-07-18
ER

PT J
AU Zhu, HM
   Wang, D
   Zhang, P
   Luo, Z
   Jiao, LC
   Han, H
AF Zhu, Huming
   Wang, Duo
   Zhang, Peng
   Luo, Zheng
   Jiao, Licheng
   Han, Hong
TI Parallel implementations of frame rate up-conversion algorithm using
   OpenCL on heterogeneous computing devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frame rate up-conversion; Parallel computing; OpenCL; GPU
ID MOTION ESTIMATION; OPTIMIZATION; INTERPOLATION
AB As a video post-processing technology, frame rate up-conversion (FRUC) converts a low frame rate video into a higher one by inserting intermediate frames between adjacent original frames. Because computing consumption grows rapidly with the increase of video resolution and frame rate, accelerating FRUC by parallel computing may serve as an appropriate method. In this paper, an effective parallel FRUC algorithm is proposed, which consists mainly of two parts: parallel motion estimation algorithm (Three-dimensional Recursive Search algorithm, 3DRS algorithm) and parallel motion compensation algorithm. We design macro-block-level parallelism and candidate motion vector level parallelism strategies based on different granularity in the motion estimation module, and pixel-level parallelism in the motion compensation module. The proposed parallel FRUC algorithm has been tested on different hardware platforms. The results show that the method achieves significant speedups of up to 96x for 1920x1080 video and 254x for 3840x2160 video when compared with sequential implementation on CPU. Moreover, the OpenCL program of the parallel FRUC algorithm shows good portability on various GPU platforms.
C1 [Zhu, Huming; Wang, Duo; Zhang, Peng; Luo, Zheng; Jiao, Licheng; Han, Hong] Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Zhu, HM (corresponding author), Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
EM zhuhum@mail.xidian.edu.cn
RI Jiao, Licheng/JOZ-0842-2023
OI Jiao, Licheng/0000-0003-3354-9617
FU National Natural Science Foundation of China [61303032]; Fundamental
   Research Funds for the Central Universities [JB160209]; National Basic
   Research Program (973 Program) of China [2013CB329402]
FX This work is funded in part by the National Natural Science Foundation
   of China (No. 61303032), the Fundamental Research Funds for the Central
   Universities (JB160209), and the National Basic Research Program (973
   Program) of China (No. 2013CB329402).
CR Ahn J, 2009, 2009 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC 2009), P357, DOI 10.1109/SOCDC.2009.5423843
   Al-kadi Ghiath, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P21, DOI 10.1109/ICCE.2010.5418693
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], 2011, NVIDIA CUDA PROGR GU
   Calandra H, 2013, EUROMICRO WORKSHOP P, P405, DOI 10.1109/PDP.2013.65
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   Diniz C, 2010, IEEE LAT AMER SYMP, P113, DOI 10.1109/LASCAS.2010.7410233
   Du P, 2012, PARALLEL COMPUT, V38, P391, DOI 10.1016/j.parco.2011.10.002
   Gaetano R., 2011, OPENCL IMPLEMENTATIO, P1
   GUO Y, 2016, TECHNOL, V12, P89, DOI DOI 10.1109/JDT.2015.2466104
   Ha T, 2004, IEEE T CONSUM ELECTR, V50, P752, DOI 10.1109/TCE.2004.1309458
   He SQ, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P216
   Hwang J, 2011, IEICE T ELECTRON, VE94C, P896, DOI 10.1587/transele.E94.C.896
   Jääskeläinen P, 2015, INT J PARALLEL PROG, V43, P752, DOI 10.1007/s10766-014-0320-y
   Lee B, 2013, IEEE T BROADCAST, V59, P20, DOI 10.1109/TBC.2012.2226533
   Lee SH, 2003, IEEE T CONSUM ELECTR, V49, P485, DOI 10.1109/TCE.2003.1233759
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Monteiro E, 2014, INT J PARALLEL PROG, V42, P239, DOI 10.1007/s10766-012-0216-7
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Paramkusam AV, 2016, J REAL-TIME IMAGE PR, V11, P645, DOI 10.1007/s11554-014-0431-0
   Poljicak A, 2018, J REAL-TIME IMAGE PR, V14, P87, DOI 10.1007/s11554-016-0616-9
   Smistad E, 2015, J REAL-TIME IMAGE PR, V10, P67, DOI 10.1007/s11554-012-0257-6
   Tay R., 2013, OpenCL Parallel Programming Development Cookbook
   The KhronosOpenCL Working Group, 2011, OPENCL OP STAND PAR
   Trawczynski D, 2013, SAE INT J PASSENG CA, V6, P93, DOI 10.4271/2013-01-0179
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhao M, 2009, INT J PROD RES, V47, P6085, DOI 10.1080/00207540802101945
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou Y, 2016, J SUPERCOMPUT, V72, P2394, DOI 10.1007/s11227-016-1738-3
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 40
TC 2
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9311
EP 9334
DI 10.1007/s11042-018-6532-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800075
DA 2024-07-18
ER

PT J
AU Auh, Y
   Sim, HR
AF Auh, Yoonil
   Sim, Heejung Raina
TI Uses of social network topology and network-integrated multimedia for
   designing a large-scale open learning system: case studies of
   unsupervised featured learning platform Design in South Korea
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network-integrated multimedia; Hyper-connected learning; Distributed
   learning; Open learning system; MOOC; ICT
ID ISSUES
AB This paper discusses the uses of network-integrated multimedia and social network modeling to design a large-scale open learning system (OLS) for unsupervised learning. Multimedia uses for enriching learning experiences have greatly improved within the last decade due to advances in broadband technology and high-speed transmission. The multimedia integrated learning environment is no longer limited to embedding low-quality video and audio streaming but can provide multivariant information delivery to enhance the self-directed learning experience. This paper discusses two case studies of an open learning system developed in South Korea that used social learning network models and multimedia: the NOOC Project for civic education, and the Genesis Project for professional and continuing education. While the focus of study is on uses of social network topology modeling and network-integrated multimedia to design an open learning system, the underlying design has broad implications for modeling any gradient-based, unsupervised open learning system for continuing education and informal learning.
C1 [Auh, Yoonil] Kyung Hee Cyber Univ, Dept Comp Informat & Commun Engn, Seoul 02447, South Korea.
   [Sim, Heejung Raina] Seoul Natl Univ, Asia Dev Inst, Grad Sch Publ Adm, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Auh, Y (corresponding author), Kyung Hee Cyber Univ, Dept Comp Informat & Commun Engn, Seoul 02447, South Korea.
EM yoonil@khcu.ac.kr
OI , Yoonila/0000-0002-0092-425X
CR Aguirre RTP, 2014, J SOC WORK, V14, P279, DOI 10.1177/1468017313476797
   Alias N., 2013, ICT Development for Social and Rural Connectedness
   Alsagoff Z. A., 2015, NANOOPEN ONLINE COUR
   Amato F, 2016, IEEE INT C SEMANT CO, P447, DOI 10.1109/ICSC.2016.20
   [Anonymous], 2007, Giving knowledge for free: The emergence of open educational resources
   [Anonymous], 2018, REV MOOC STATS TREND
   Azam F., 2000, THESIS
   Bar-Yam Y., 2011, Concepts: Power law
   Barabasi A.-L., 2014, LINKED NEW SCI NETWO
   BARABASI A.-L., 2009, SCIENCE
   Barabási AL, 2003, SCI AM, V288, P60, DOI 10.1038/scientificamerican0503-60
   Bradford WC, 2004, LAW TEACHER, V11
   Cadima R, 2012, EDUC TECHNOL SOC, V15, P296
   Couros A, 2010, ISS ONLINE EDUC, P109
   D'Antoni S, 2009, OPEN LEARN, V24, P3, DOI 10.1080/02680510802625443
   De Laat M., 2002, Vocational Training: European Journal, V27, P13
   Downes Stephen., 2012, CONNECTIVISM CONNECT
   Ferrara E, 2011, COMMUN APPL IND MATH, V2, DOI 10.1685/journal.caim.381
   Fox A, 2013, COMMUN ACM, V56, P38, DOI 10.1145/2535918
   HAPPEL BLM, 1994, NEURAL NETWORKS, V7, P985, DOI 10.1016/S0893-6080(05)80155-8
   Jones C, 2002, COMP SUPP COMP W SER, P1
   Kanellopoulos D, 2013, IGI GLOBAL
   Leskovec J., 2008, WWW
   Leskovec J., 2005, P 11 ACM SIGKDD INT, P177
   Luo JX, 2011, COMPLEXITY, V16, P53, DOI 10.1002/cplx.20368
   Lynch C., 2009, INT J ARTIF INTELL E, V19, P253
   Mackey T.P., 2014, METALITERACY REINVEN
   Maisonneuve N, 2007, MANAGING SOCIAL INTE
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   O'Donnell A.M., 1999, COGNITIVE PERSPECTIV
   Olson J.F., 2008, TIMSS 2007 TECHNICAL, DOI [10.1787/9789264130852-en, DOI 10.1787/9789264130852-EN]
   Paterson B.L., 2001, Meta-study of qualitative health research: A practical guide to meta-analysis and meta-synthesis
   Powell TE, 2015, J COMMUN, V65, P997, DOI 10.1111/jcom.12184
   Ravasz E, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026112
   Reyes G, 2016, CAN CENTRALIZED DECE
   Sang J, 2012, ACM T MULTIMEDIA COM, V9
   Siemens G., 2008, What is the unique idea in connectivism?
   TRAVERS J, 1969, SOCIOMETRY, V32, P425, DOI 10.2307/2786545
   UNDESA, 2009, CREAT INCL SOC PRACT
   UNESCO, 2005, KNOWL SOC WAY FORW B
   Utsumi N, 2005, HDB RES E GOVT READI
   Vaughan T., 2011, Multimedia: Making it work, V8th
   WANG M, 2010, ED BENEFITS MULTIMED, V54
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
NR 45
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5445
EP 5462
DI 10.1007/s11042-018-6658-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100021
DA 2024-07-18
ER

PT J
AU Bulkan, U
   Dagiuklas, T
   Iqbal, M
AF Bulkan, Utku
   Dagiuklas, Tasos
   Iqbal, Muddesar
TI On the modelling of CDNaaS deployment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content delivery network (CDN); OTT streaming; Live streaming; Online
   video platform; QoE; User perception; Subjective analysis; Analytical
   modelling
AB With the increasing demand for over the top media content, understanding user perception and Quality of Experience (QoE) estimation have become a major business necessity for service providers. Online video broadcasting is a multifaceted procedure and calculation of performance for the components that build up a streaming platform requires an overall understanding of the Content Delivery Network as a service (CDNaaS) concept. Therefore, to evaluate delivery quality and predicting user perception while considering NFV (Network Function Virtualization) and limited cloud resources, a relationship between these concepts is required. In this paper, a generalized mathematical model to calculate the success rate of different tiers of online video delivery system is presented. Furthermore, an algorithm that indicates the correct moment to switch between CDNs is provided to improve throughput efficiency while maintaining QoE and keeping the cloud hosting costs as lowest possible.
C1 [Bulkan, Utku; Dagiuklas, Tasos; Iqbal, Muddesar] London South Bank Univ, Div Comp Sci, SuITE Res Grp, 103 Borough Rd, London SE1 0AA, England.
C3 London South Bank University
RP Bulkan, U (corresponding author), London South Bank Univ, Div Comp Sci, SuITE Res Grp, 103 Borough Rd, London SE1 0AA, England.
EM bulkanu@lsbu.ac.uk; tdagiuklas@lsbu.ac.uk; m.iqbal@lsbu.ac.uk
RI Iqbal, Muddesar/JJC-7510-2023
OI Iqbal, Muddesar/0000-0002-8438-6726; Bulkan, Utku/0000-0003-1177-0660
CR Ahmad A, 2016, QOE CTR SERVICE DELI
   Aioffi WM, 2004, LECT NOTES COMPUT SC, V3293, P19
   Akamai Inc, 2018, WHY AK
   Amazon Web Services Inc, 2018, AM WEB SERV TIER PRI
   Amazon Web Services Inc, 2018, AM CLOUD FRONT CDN
   Amazon Web Services Inc, 2018, AM EC2
   Broadcasters' Audience Research Board, 2018, ONL TV VIEW
   Chen Z, 2017, IEEE COMMUN LETT, V21, P584, DOI 10.1109/LCOMM.2016.2628032
   Chu Y, 2014, SOFTWARE DEFINED QOE
   Cunqian Y, 2016, OPTICAL SWITCHING NE
   D'Amico V, 2016, IEEE COMMUNICATIONS
   Fan Q., 2017, COMPUTERS ELECT ENG
   Faraci G, 2017, 12 INT C FUT NETW CO
   Frias Z., 2017, TELECOMMUNICATIONS P
   Gilani SMM, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0856-9
   ITU-T, 2016, P 1203 3 PAR BITSTR
   Jones W, 2016, WILEY SYSTEMS ENG J
   KLEINROCK L, 1993, P IEEE, V81, P1179, DOI 10.1109/5.236194
   Knoll T, 2016, ITU STUDY PERIOD 201
   Koumaras H, 2016, INT CONF TELECOMM, P57
   Mestric R, 2018, STRETCHING CDN
   Neves P, 2016, COMPUTER STANDARDS I
   Roeder TMK, 2016, WINT SIM C
   Ruiz M, 2016, COMPUTER COMMUNICATI
   Sjoberg D, 2008, CONTENT DELIVERY NET, P7
   Stallings W., 2016, Foundations of modern networking : Sdn, nfv,qoe, iot, and cloud
   Taleb T., 2016, ANYTHING SERVICE 5G
   Yousaf F., 2017, IEEE INT C COMM WORK
NR 28
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6805
EP 6825
DI 10.1007/s11042-018-6441-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ding, WJ
   Xie, Y
   Wang, YL
AF Ding, Wenjia
   Xie, Yi
   Wang, Yulin
TI Image authentication and tamper localization based on relative
   difference between DCT coefficient and its estimated value
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Digital image signature; Semi-fragile watermark;
   DCT transforms
ID FRAGILE WATERMARKING
AB Digital images are increasingly transmitted over non-secure channels such as Internet, therefore image authentication techniques have recently gained great attention due to their importance for a large number of multimedia applications. To protect the authenticity of images, several approaches have been proposed. These approaches include conventional cryptography, semi-fragile watermarking and digital signatures. In this paper, we propose two techniques of the same type based on what we call characteristic data digest. Both techniques can blindly detect and localize malicious tampering, while maintaining reasonable tolerance to conventional content-preserving manipulations. The characteristic data is derived from the relative difference between each pair of selected DCT coefficient, AC for one technique and DC for another technique, in a central block and its counterpart estimated by the center block and its adjacent blocks. In order to maintain the relative difference relationship when the image undergoes legitimate processing, we make a pre-compensation for the coefficients. Experimental results show that our techniques are significantly superior to semi-fragile techniques under the condition of the same image fidelity, especially in tolerance range of legitimate processing, and/or the ability to detect and localize the tampered area. Due to the simplicity of the algorithms, our techniques can be used in video frame authentication, and even other digital media. In addition, this kind of proposed techniques can be extended to use other characteristic data, such as high-level moment, statistical data of images, and so on.
C1 [Ding, Wenjia; Xie, Yi; Wang, Yulin] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Ding, Wenjia] Wuhan Univ, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 Wuhan University; Wuhan University
RP Wang, YL (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM yulinwang@whu.edu.cn
FU applied basic research plan of Wuhan Science and Technology Bureau
   [2017010201010105]; Shenzhen Science and Technology Innovation Committee
   [JCYJ20170306170559215]
FX This work was supported by applied basic research plan of Wuhan Science
   and Technology Bureau with Grant No. 2017010201010105 in China, and
   Shenzhen Science and Technology Innovation Committee with Grant No.
   JCYJ20170306170559215 in China.
CR Andres F, 2001, IEEE MULTIMEDIA, V8, P20, DOI 10.1109/MMUL.2001.959096
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bennett W, 1970, INTRO SIGNAL TRANSMI, P100
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Fei CH, 2006, IEEE T INF FOREN SEC, V1, P43, DOI 10.1109/TIFS.2005.863505
   Feng W, 2008, IEEE T IMAGE PROCESS, V17, P2413, DOI 10.1109/TIP.2008.2006435
   Gonzales C. A., 1990, Signal Processing: Image Communication, V2, P145, DOI 10.1016/0923-5965(90)90017-C
   Guzman AM, 2013, IEEE J BIOMED HEALTH, V17, P214, DOI 10.1109/TITB.2012.2207729
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Lampson B., 1997, TECHNICAL REPORT
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   LIU S, 2017, DISTRIBUTION, V76, P5787, DOI DOI 10.1007/s11042-014-2408-1
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Rey C, 2000, P IEE SEC IM IM AUTH, p7/1
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Toyokawa K, 2000, P SOC PHOTO-OPT INS, V3971, P438, DOI 10.1117/12.384998
   Tse D, 2005, FUNDAMENTALS WIRELES, P203
   Wu CW, 2012, IEEE T MULTIMED, V4, P385
   Yu GJ, 2001, OPT ENG, V40, P1396, DOI 10.1117/1.1384885
   Yuan H, 2006, IEEE T IMAGE PROCESS, V15, P3189, DOI 10.1109/TIP.2006.877310
   Yuan L, 2017, OPT LASER TECHNOL, V88, P111, DOI 10.1016/j.optlastec.2016.09.004
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
NR 29
TC 8
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5305
EP 5328
DI 10.1007/s11042-018-5732-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100013
DA 2024-07-18
ER

PT J
AU Gautam, A
   Raman, B
AF Gautam, Anjali
   Raman, Balasubramanian
TI Segmentation of ischemic stroke lesion from 3d mr images using random
   forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Ischemic stroke; Random forest; FLAIR; MR; ISLES-2015
ID DIFFUSION; IDENTIFICATION; EVOLUTION; REGION; CORE
AB This paper focuses on segmentation of ischemic stroke lesion from the dataset contributed by Ischemic Stroke Lesion Segmentation (ISLES)-2015 Sub-acute Ischemic Stroke lesion Segmentation (SISS) challenge. The dataset comprises 28 stroke cases of magnetic resonance (MR) images. This study considers fluid attenuation inversion recovery (FLAIR) MR images for the segmentation of lesions. MR images are affected by various artifacts and noise. Hence, we applied wavelet based data denoising technique by optimal parameter selection for stroke lesion enhancement followed by random forest (RF). RF classifier was trained for different part of the brain for segmenting the stroke lesion. The obtained results show best overall segmentation accuracy when compared with the other methods. To measure the image similarity between the ground truth and the segmented image, we used the evaluation method provided by the ISLES-2015. The average symmetric surface distance (ASSD) of the segmentation was measured to be 4.57 mm, while Dice's coefficient ((DC) lies between 0 and 1) was used to measure the volume overlap accuracy with an average of 0.67. The maximum of all surface distance was given by Hausdorff distance (HD) with an average of 28.09 mm. The average precision and average recall observed was 0.70 and 0.71 respectively. The ISLES image data and ground truth images kept on being openly accessible through an online virtual skeleton database which is an ongoing benchmarking resource.
C1 [Gautam, Anjali; Raman, Balasubramanian] Indian Inst Technol Roorkee, Comp Sci & Engn Dept, Roorkee, Uttarakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Gautam, A (corresponding author), Indian Inst Technol Roorkee, Comp Sci & Engn Dept, Roorkee, Uttarakhand, India.
EM anga3.dcs2015@iitr.ac.in; balarfma@iitr.ac.in
OI Gautam, Dr. Anjali/0000-0003-2675-4073
FU Ministry of Human Resource Development, Government of India, India
   [MHC-02-23-200-428]
FX This study was funded by the Ministry of Human Resource Development,
   Government of India, India (grant number MHC-02-23-200-428).
CR Alexander B, 2017, NEUROIMAGE, V147, P841, DOI 10.1016/j.neuroimage.2016.09.068
   Anbeek P, 2003, LECT NOTES COMPUT SC, V2878, P610
   [Anonymous], INT J COMPUT VIS
   [Anonymous], IEEE T MED IMAGING
   [Anonymous], Stroke statistics
   Bernarding J, 2000, MAGN RESON MED, V43, P52, DOI 10.1002/(SICI)1522-2594(200001)43:1<52::AID-MRM7>3.0.CO;2-5
   Bisio I, 2018, MULTIMED TOOLS APPL, V77, P9341, DOI 10.1007/s11042-017-4867-7
   Bonita R, 2004, LANCET NEUROL, V3, P391, DOI 10.1016/S1474-4422(04)00800-2
   Braun Juergen, 2002, Comput Methods Biomech Biomed Engin, V5, P411, DOI 10.1080/1025584021000011082
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Carano RAD, 2000, J MAGN RESON IMAGING, V12, P842, DOI 10.1002/1522-2586(200012)12:6<842::AID-JMRI7>3.0.CO;2-5
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Castillo J, 2004, STROKE, V35, P520, DOI 10.1161/01.STR.0000109769.22917.B0
   Chawla M, 2009, IEEE ENG MED BIO, P3581, DOI 10.1109/IEMBS.2009.5335289
   Chen L, 2015, ISLES P 02, P9
   Chyzhyk D, 2015, NEUROCOMPUTING, V150, P26, DOI 10.1016/j.neucom.2014.01.077
   Crinion J, 2013, NEUROIMAGE, V73, P208, DOI 10.1016/j.neuroimage.2012.07.044
   Crowley JL, 1981, THESIS
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   DONOHO DL, 1927, IEEE TRANS INF THEOR, V41, P613
   Gao SB, 2014, MULTIMED TOOLS APPL, V72, P2321, DOI 10.1007/s11042-013-1553-2
   GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056
   Grzesik A, 2000, CHARACTERIZATION STO
   Güler I, 2009, DIGIT SIGNAL PROCESS, V19, P668, DOI 10.1016/j.dsp.2008.08.002
   Guerrero R, 2018, NEUROIMAGE-CLIN, V17, P918, DOI 10.1016/j.nicl.2017.12.022
   Haeck T, 2015, P INT C MED IM COMP, P47
   HILLMAN GR, 1995, PROC SPIE, V2434, P16, DOI 10.1117/12.208723
   Hong YC, 2002, STROKE, V33, P2165, DOI 10.1161/01.STR.0000026865.52610.5B
   Hutter A, 2003, NEUROIMAG CLIN N AM, V13, P237, DOI 10.1016/S1052-5149(03)00016-9
   Jacobs MA, 2001, STROKE, V32, P950, DOI 10.1161/01.STR.32.4.950
   Jenkinson M., 2005, 11 ANN M ORG HUM BRA, V17, P167
   Kabir Y, 2007, P ANN INT IEEE EMBS, P1595, DOI 10.1109/IEMBS.2007.4352610
   Kamnitsas K, 2015, P MICCAI ISLES MUN G, V2015, P13
   Kleinfeld A, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P17, DOI 10.1007/978-3-662-46224-9_5
   KOHLER R, 1981, COMPUT VISION GRAPH, V15, P319, DOI 10.1016/S0146-664X(81)80015-9
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mackay J., 2004, The atlas of heart disease and stroke
   Mahmood Q, 2015, BRAINLES 2015, P43
   Maier O, 2017, MED IMAGE ANAL, V35, P250, DOI 10.1016/j.media.2016.07.009
   Mitra J, 2014, NEUROIMAGE, V98, P324, DOI 10.1016/j.neuroimage.2014.04.056
   Neumann-Haefelin T, 1999, STROKE, V30, P1591, DOI 10.1161/01.STR.30.8.1591
   Parsons MW, 2007, NEUROLOGY, V68, P730, DOI 10.1212/01.wnl.0000256366.86353.ff
   Plunkett JW, 2008, PLUNKETTS HLTH CARE
   Rajini NH, 2013, MEASUREMENT, V46, P1865, DOI 10.1016/j.measurement.2013.01.010
   Rekik I, 2012, NEUROIMAGE-CLIN, V1, P164, DOI 10.1016/j.nicl.2012.10.003
   Reza S.M.S, 2015, Ischemic Stroke Lesion Segmentation, P23
   Robb D.M., 2015, Proceeding of Canadian Society for Civil Engineering 22nd Hydrotechnical Conference, P27
   Roy Sudipta, 2014, SMART INNOVATION SYS, P453
   Schaefer PW, 2003, AM J NEURORADIOL, V24, P436
   Schlaug G, 1997, NEUROLOGY, V49, P113, DOI 10.1212/WNL.49.1.113
   Seghier ML, 2008, NEUROIMAGE, V41, P1253, DOI 10.1016/j.neuroimage.2008.03.028
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shih LC, 2003, STROKE, V34, P1425, DOI 10.1161/01.STR.0000072998.70087.E9
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang XF, 2017, MULTIMED TOOLS APPL, V76, P7869, DOI 10.1007/s11042-016-3399-x
   Zhang YY, 2014, IEEE T IMAGE PROCESS, V23, P97, DOI 10.1109/TIP.2013.2286901
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 61
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6559
EP 6579
DI 10.1007/s11042-018-6418-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700007
DA 2024-07-18
ER

PT J
AU Li, CL
   Liu, CD
   Gao, GS
   Liu, ZF
   Wang, YP
AF Li, Chunlei
   Liu, Chaodie
   Gao, Guangshuai
   Liu, Zhoufeng
   Wang, Yuping
TI Robust low-rank decomposition of multi-channel feature matrices for
   fabric defect detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Second-order gradient; Multi-channel feature; Joint low-rank
   decomposition; Fabric images; Defect detection
ID SALIENCY DETECTION; INSPECTION
AB Fabric defect detection plays an important role in the quality control of textile products. Most existing defect detection techniques adopted traditional pattern recognition methods, which were lacking adaptability and presented the undesirable detection accuracy. In this paper, a fabric defect detection algorithm based on multi-channel feature matrixes extraction and joint low-rank decomposition was proposed by simulating biological visual perception mechanism. Based on the fact that the second-order gradient information is more suitable for characterizing the fabric texture, we developed a novel second-order multi-channel feature extraction method by modeling the response and distribution properties of the P-type ganglion cells in the primate retina. Upon devising a powerful descriptor, a joint low-rank decomposition method is utilized to model biological visual saliency, and decomposes the fabric images into backgrounds and salient defect objects. Experimental results demonstrate that our proposed algorithm has good self-adaptability and detection performance for plain and twill fabrics or complex patterned fabrics, and is superior to the state-of-the-art methods.
C1 [Li, Chunlei; Liu, Chaodie; Gao, Guangshuai; Liu, Zhoufeng] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Henan, Peoples R China.
   [Wang, Yuping] Tulane Univ, Dept Biomed Engn, New Orleans, LA 70118 USA.
C3 Zhongyuan University of Technology; Tulane University
RP Li, CL (corresponding author), Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Henan, Peoples R China.
EM lichunlei1979@sina.com
RI Gao, Guangshuai/KMY-2284-2024
OI Li, Chunlei/0000-0001-6543-1838
FU National Natural Science Foundation of China [61772576, 61379113]; Key
   Natural Science Foundation of Henan Province [162300410338]; Science and
   technology innovation talent project of Education Department of Henan
   Province [17HASTIT019]; Henan Science Fund for Distinguished Young
   Scholars [184100510002]
FX This work was supported by the National Natural Science Foundation of
   China ((No.61772576, No.61379113), the Key Natural Science Foundation of
   Henan Province(No.162300410338), Science and technology innovation
   talent project of Education Department of Henan Province(17HASTIT019),
   The Henan Science Fund for Distinguished Young Scholars (184100510002).
CR [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2013, WORKGROUP TEXTURE AN
   Baykal IC, 2002, IEEE INT S CIRC SYST, V5
   Brzakovic DP, 1997, IEEE INT CONF ROBOT, P1
   Cao J., 2015, MULTIMEDIA TOOLS APP, V76, P1
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Guan SQ, 2016, J TEXT I, V107, P215, DOI 10.1080/00405000.2015.1020680
   [管声启 Guan Shengqi], 2014, [纺织学报, Journal of Textile Research], V35, P56
   Huang D, 2014, IEEE T IMAGE PROCESS, V23, P4680, DOI 10.1109/TIP.2014.2353814
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Kamermans M, 1996, VISION RES, V36, P4105, DOI 10.1016/S0042-6989(96)00143-5
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li C., 2017, TEXT RES J, V38, P153
   Li C., 2014, J SHANDONG U ENG SCI, V44, P1
   Li CL, 2016, INT J CLOTH SCI TECH, V28, P530, DOI 10.1108/IJCST-12-2015-0134
   [李敏 Li Min], 2015, [纺织学报, Journal of Textile Research], V36, P94
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   [李瑶 Li Yao], 2011, [生物物理学报, Acta Biophysica Sinica], V27, P211
   Li YD, 2017, IEEE T AUTOM SCI ENG, V14, P1256, DOI 10.1109/TASE.2016.2520955
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu ZF, 2015, INT J CLOTH SCI TECH, V27, P738, DOI 10.1108/IJCST-02-2014-0028
   Ng MK, 2014, IEEE T AUTOM SCI ENG, V11, P943, DOI 10.1109/TASE.2014.2314240
   Ngan HYT, 2006, OPT ENG, V45, DOI 10.1117/1.2345189
   Ngan HYT, 2005, PATTERN RECOGN, V38, P559, DOI 10.1016/j.patcog.2004.07.009
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qu T, 2016, J TEXT I, V107, P743, DOI 10.1080/00405000.2015.1061760
   RODIECK R. W., 1965, VISION RES, V5, P583, DOI 10.1016/0042-6989(65)90033-7
   Selver MA, 2014, J TEXT I, V105, P998, DOI 10.1080/00405000.2013.876154
   Shapley R, 1997, CURR BIOL, V7, pR421, DOI 10.1016/S0960-9822(06)00207-7
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Tong L, 2017, IEEE ACCESS, V5, P5947, DOI 10.1109/ACCESS.2017.2667890
   Wen ZJ, 2014, INT J CLOTH SCI TECH, V26, P202, DOI 10.1108/IJCST-03-2013-0031
   Weng DW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2409739
   XIA D, 2017, TEXTILE INSTITUTE, V108, P239, DOI DOI 10.1080/00405000.2016.1161700
   YAN J, 2010, IMAGE PROCESS, V119, P1089
   Yang X, 2005, IEE P-VIS IMAGE SIGN, V152, P715, DOI 10.1049/ip-vis:20045131
   Zengbo X, 2000, THEORY, V26, P6
   Zhang D, 2016, PROC SPIE, V10033, DOI 10.1117/12.2244861
   Zhou J, 2014, J TEXT I, V105, P223, DOI 10.1080/00405000.2013.836784
   Zhou J, 2013, TEXT RES J, V83, P1846, DOI 10.1177/0040517513478451
   Zhu QP, 2014, TEXT RES J, V84, P1634, DOI 10.1177/0040517514525880
NR 44
TC 15
Z9 19
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7321
EP 7339
DI 10.1007/s11042-018-6483-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700041
DA 2024-07-18
ER

PT J
AU Liu, XY
   Wang, YF
   Du, JY
   Liao, SH
   Lou, JT
   Zou, BJ
AF Liu, Xiyao
   Wang, Yifan
   Du, Jingyu
   Liao, Shenghui
   Lou, Jieting
   Zou, Beiji
TI Robust hybrid image watermarking scheme based on KAZE features and
   IWT-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid image watermarking scheme; KAZE feature; IWT-SVD; Attention-based
   fusion; Digital rights management
ID HISTOGRAM-MODIFICATION; DWT-SVD; TRANSFORM
AB Digital watermarking is a critical technique for digital rights management (DRM). In the last decade, the local feature-based watermarking schemes have attracted much attention because of their remarkable robustness against geometrical attacks, which will destroy the synchronization between watermark embedding and detection. However, they only used local feature and thus their robustness is based on invariances of the particular local features, which still have limitations when suffering various signal processing attacks. To address this problem, a robust hybrid color image watermarking scheme (RHIW) is proposed in our study by fusing a local feature-based watermarking procedure with a traditional transform domain-based watermarking procedure. In the local feature-based procedure, watermarks are embedded into significant bit-planes of the KAZE feature regions repeatedly by modifying their histograms. In the transform domain-based procedure, watermark is embedded into the IWT-SVD domain by modifying the entries of left singular vector matrices. For a queried image, all the watermarks of KAZE-based and IWT-SVD-based procedures are extracted and compared with the original watermark. Then, the comparison results are fused following an attention-based fusion method to identify the copyright ownership. The experimental results demonstrate that RHIW is sufficient robust not only against geometrical attacks such as cropping, row & column removal and rotation attacks, but also against various common signal processing attacks such as filtering, noise addition, brightness modification and contrast modification, which outperforms state-of-the-art local feature-based watermarking schemes.
C1 [Liu, Xiyao; Wang, Yifan; Du, Jingyu; Liao, Shenghui; Lou, Jieting; Zou, Beiji] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Liu, Xiyao; Wang, Yifan; Du, Jingyu; Liao, Shenghui; Lou, Jieting; Zou, Beiji] Cent South Univ, Ctr Ophthalm Imaging Res, Changsha 410083, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Liao, SH (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.; Liao, SH (corresponding author), Cent South Univ, Ctr Ophthalm Imaging Res, Changsha 410083, Hunan, Peoples R China.
EM lsh@csu.edu.cn
RI liu, xiyao/GSE-0791-2022
OI Du, Jingyu/0000-0002-6771-7407
FU National Natural Science Foundations of China [61602527, 61772556,
   61573380]; Natural Science Foundations of Hunan Province [2017JJ3416,
   2017JJ2330]; China Postdoctoral Science Foundation [2017M612585];
   Fundamental Research Funds for the Central Universities of Central South
   University [2018zzts584]
FX This research is supported by the National Natural Science Foundations
   of China (61602527, 61772556, 61573380), Natural Science Foundations of
   Hunan Province (2017JJ3416, 2017JJ2330), China Postdoctoral Science
   Foundation (2017M612585) and Fundamental Research Funds for the Central
   Universities of Central South University (2018zzts584).
CR Agung B. W. R., 2012, 2012 IEEE International Conference on Communication, Networks and Satellite (ComNetSat 2012), P167, DOI 10.1109/ComNetSat.2012.6380799
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Castiglione A, 2015, INT CON ADV INFO NET, P476, DOI 10.1109/AINA.2015.224
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Hua XS, 2004, LECT NOTES COMPUT SC, V3332, P1001
   Jun-Dong Chang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P173, DOI 10.1109/ISNE.2013.6512330
   Lianshan L, 2004, J XIAN JIAOTONG U, V38, P12
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu XY, 2017, NEUROCOMPUTING, V222, P155, DOI 10.1016/j.neucom.2016.10.015
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lyu WL, 2014, KSII T INTERNET INF, V8, P3591, DOI 10.3837/tiis.2014.10.018
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Niu PP, 2017, MULTIMED TOOLS APPL, V76, P3403, DOI 10.1007/s11042-016-3935-8
   Pizzolante R, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P65, DOI 10.1109/INCoS.2014.116
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Sverdlov Alexander, 2005, 2005 13th European Signal Processing Conference, P1
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Wang XY, 2012, J VIS COMMUN IMAGE R, V23, P892, DOI 10.1016/j.jvcir.2012.05.008
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 36
TC 12
Z9 12
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6355
EP 6384
DI 10.1007/s11042-018-6361-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100063
DA 2024-07-18
ER

PT J
AU Mathivanan, P
   Ganesh, AB
AF Mathivanan, P.
   Ganesh, A. Balaji
TI QR code based color image cryptography for the secured transmission of
   ECG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel permutation; Color image encryption; Chaos; Security analysis
ID OPTICAL ENCRYPTION; STEGANOGRAPHY; PERMUTATION; INFORMATION
AB The paper presents a novel QR code based color image steganography to facilitate remote transmission of ECG signal along with patient diagnosis data. The proposed system is configured with two stage security processes, namely pixel permutation and chaos encryption. A three step sequential strategy is adapted for the implementation of the system. At first, the diagnose information in the form of alphanumeric data is given to QR code generator for the generation of equivalent 2D binary matrix. Similarly, the ECG signal samples are transformed into alphanumeric cipher text by involving integer to binary sequence conversion process and eventually into corresponding QR codes. Secondly, the both diagnose data as well as ECG signal integrated QR codes are embedded within individual R, G and B color image components by using the pixel permutation process. Finally, the color image components, R, B and G are individually encrypted by using 1D chaotic encryption technique as an attempt to enhance further the security of existing steganography process. The experimental results are validated in terms of NCPR, UACI and also entropy which found to be better and comparable than other baseline algorithms.
C1 [Mathivanan, P.] Velammal Engn Coll, Dept Elect & Commun Engn, Chennai 600066, Tamil Nadu, India.
   [Ganesh, A. Balaji] Velammal Engn Coll, Dept Elect & Elect Engn, Elect Syst Design Lab, Chennai 600066, Tamil Nadu, India.
C3 Velammal Engineering College; Velammal Engineering College
RP Ganesh, AB (corresponding author), Velammal Engn Coll, Dept Elect & Elect Engn, Elect Syst Design Lab, Chennai 600066, Tamil Nadu, India.
EM abganesh@velammal.edu.in
RI P, Mathivanan/ABI-8419-2020; GANESH, DR. A/JJD-0095-2023; GANESH, A
   BALAJI/GOP-3284-2022
OI P, Mathivanan/0000-0002-0580-7757; GANESH, DR. A/0000-0002-0692-6213; 
CR Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   [Anonymous], 2006, 18004 ISO IEC
   [Anonymous], 2014, JMM
   [Anonymous], TPDS
   [Anonymous], 1968, MATH PHYS MONOGRAPH
   Ardagna CA, 2008, J COMPUT SECUR, V16, P369, DOI 10.3233/JCS-2008-0328
   Bertino E, 2005, PROC INT CONF DATA, P521
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Brumen B, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2471
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Engin Mehmet, 2005, J Med Syst, V29, P589, DOI 10.1007/s10916-005-6126-0
   Barrera JF, 2014, OPT LETT, V39, P3074, DOI 10.1364/OL.39.003074
   Barrera JF, 2013, OPT EXPRESS, V21, P5373, DOI 10.1364/OE.21.005373
   Ibaida A, 2013, IEEE T BIO-MED ENG, V60, P3322, DOI 10.1109/TBME.2013.2264539
   Jain Mamta, 2017, Brain Inform, V4, P95, DOI 10.1007/s40708-016-0057-z
   Jain Mamta., 2016, Perspectives in Science, V8, P417, DOI [10.1016/j.pisc.2016.04.093, DOI 10.1016/J.PISC.2016.04.093]
   Jawad LM, 2015, INDIAN J SCI TECHNOL, V8, P27
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kaur R., 2013, J COMPUT ENG, V9, P80, DOI 10.9790/0661-0968083
   Li L, 2016, J SYST SOFTWARE, V116, P85, DOI 10.1016/j.jss.2015.07.009
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lin YH, 2004, IEEE T INF TECHNOL B, V8, P439, DOI 10.1109/TITB.2004.837829
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Ng HS, 2006, BT TECHNOL J, V24, P138, DOI 10.1007/s10550-006-0051-8
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pashakolaee PG, 2017, MULTIMED TOOLS APPL, V5, P1
   Priya S, 2017, OPTIK INT J LIGHT EL
   Roy R, 2013, PROC TECH, V10, P138, DOI 10.1016/j.protcy.2013.12.346
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Thambiraja E., 2012, International Journal of Advanced Research in Computer Science and Software Engineering, V2, P226
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiaoqiang Zhang, 2010, Proceedings of the 2010 Fifth International Conference on Frontier of Computer Science and Technology (FCST 2010), P565, DOI 10.1109/FCST.2010.11
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zhai X, 2016, J PARAL DISTRIB COMP
NR 47
TC 20
Z9 21
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6763
EP 6786
DI 10.1007/s11042-018-6471-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700016
DA 2024-07-18
ER

PT J
AU Jiang, Y
   Guo, RL
   Ma, FF
   Shi, JL
AF Jiang, Yan
   Guo, Ruiliang
   Ma, Fenfen
   Shi, Jinlong
TI Cloth simulation for Chinese traditional costumes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloth simulation; Chinese traditional costumes; Interactive multimedia
   system; Virtual reality; Digital cultural heritage
ID VIRTUAL-REALITY; TRY-ON; MODELS
AB Cloth simulation has received much attention recently due to its commercial potential. It can be used for virtual try-on systems, digital films, games and cultural heritage applications. In this paper, we present an interactive multimedia system for Chinese traditional costumes based on two key technologies. One is cloth simulation based on a fabric parameter algorithm, in which a BP neural network is constructed to acquire a nonlinear relationship between fabric mechanical parameters and control parameters in a simulation process. The other is an improved Verlet algorithm for implementing systemic numerical integration. The major contribution of this system is that it can facilitate self-study by fashion majors to understand the cutting and sewing features and can provide a learning platform for people who are interested in traditional costumes. This system can fully demonstrate the characteristics of structures of classic Chinese costumes, such as Cheongsam, Qing Dynasty robes and Tibetan clothing. Three-dimensional virtual display technology is used to make and present the ancient garment by using two-dimensional garment CAD software to produce the garment pattern, image processing software to process fabric texture, and finally sewing the three-dimensional clothing. The user study shows that an interactive system based on virtual reality technology has a better intuitional and cognitive visual effect and is feasible for reproducing traditional costumes using digital technology.
C1 [Jiang, Yan; Guo, Ruiliang; Ma, Fenfen] Beijing Inst Fash Technol, Beijing 100029, Peoples R China.
   [Shi, Jinlong] Jiangsu Univ Sci & Technol, Zhenjiang 212003, Jiangsu, Peoples R China.
C3 Beijing Institute of Fashion Technology; Jiangsu University of Science &
   Technology
RP Jiang, Y (corresponding author), Beijing Inst Fash Technol, Beijing 100029, Peoples R China.
EM jsjjy@bift.edu.cn
RI shi, jin/KDO-7906-2024; shi, jin/JCD-8826-2023; Shi, JIn/JYP-1805-2024
FU science and technology project of the Beijing Municipal Education
   Commission [SQKM201610012008]; China Scholarship Council [201609970003]
FX This paper is sponsored by the science and technology project of the
   Beijing Municipal Education Commission (SQKM201610012008), and the
   research project of the China Scholarship Council (NO. 201609970003).
   Thanks to Dr. Chen Guo who has participated in the development and
   experiments of this project.
CR Cao ML, 2015, IEEE COMPUT GRAPH, V35, P83, DOI 10.1109/MCG.2015.130
   Cao ML, 2014, IEEE COMPUT GRAPH, V34, P83, DOI 10.1109/MCG.2014.87
   Chen Kim Lim, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P589
   Chen ML, 2015, ASIAPAC SIGN INFO PR, P1041, DOI 10.1109/APSIPA.2015.7415430
   Fei Su, 2015, 2015 23rd International Conference on Geoinformatics. Proceedings, P1, DOI 10.1109/GEOINFORMATICS.2015.7378588
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   Jiang Y, 2012, AASRI PROC, V3, P661, DOI 10.1016/j.aasri.2012.11.105
   Knuth M, 2016, IEEE COMPUT GRAPH AP
   Le QT, 2015, INT J ENG EDUC, V31, P713
   Li JT, 2010, COMPUT GRAPH-UK, V34, P742, DOI 10.1016/j.cag.2010.07.008
   Li Y, 2006, COMPUT AIDED DESIGN, V38, P726, DOI 10.1016/j.cad.2006.03.003
   Ling Wu, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P35, DOI 10.1109/ICCASM.2010.5619182
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P506, DOI 10.1007/s00371-005-0347-6
   Gutiérrez JM, 2015, INT J ENG EDUC, V31, P323
   Martin Kathi, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P329
   Martin K., 2011, 2011 Second International Conference on Culture and Computing, P51, DOI 10.1109/Culture-Computing.2011.18
   Martin K, 2013, 2013 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND COMPUTING 2013), P62, DOI 10.1109/CultureComputing.2013.19
   Martin K, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P104, DOI 10.1109/VSMM.2009.21
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P721, DOI 10.1016/j.cad.2012.03.006
   Nakamura R, 2013, IEEE SYS MAN CYBERN, P3733, DOI 10.1109/SMC.2013.636
   Sampaio AZ, 2013, INT J ENG EDUC, V29, P1331
   Traumann Andres, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P75, DOI 10.1109/CVPRW.2015.7301339
   Yang S, 2016, IEEE T VIS COMPUT GR, V22, P2122, DOI 10.1109/TVCG.2015.2505285
   Yeonkyung Kang, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P239
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Zhang S, 2016, RES DIGITAL DISPLAY
   Zhou Z, 2012, SIGGRAPH ASIA 2012 T, P33
   Zhu XJ, 2016, INT CONF INFO SCI, P476, DOI 10.1109/ICIST.2016.7483461
NR 28
TC 14
Z9 18
U1 13
U2 139
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 5025
EP 5050
DI 10.1007/s11042-018-5983-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200057
DA 2024-07-18
ER

PT J
AU Kang, D
   Seo, S
AF Kang, Dongwann
   Seo, Sanghyun
TI Personalized smart home audio system with automatic music selection
   based on emotion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Emotion estimation; Music recommendation
ID INTERNET; VALENCE; AROUSAL; THINGS
AB In this paper, we introduce a personalized home audio system that uses IoT technologies to recommend and play music remotely based on a user's estimated emotion. This system estimates a user's emotion based on texts on their smartphone collected during outdoor activities. Based on this emotion, our system then searches for music that matches it from a music database. The system automatically detects the user when they return home, and plays the recommended music via a connected audio system. Consequently, personalized emotion-based music recommendation is provided transparently without the user's awareness.
C1 [Kang, Dongwann] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
   [Seo, Sanghyun] Sungkyul Univ, Div Media Software, Anyang, South Korea.
C3 Seoul National University of Science & Technology; Sungkyul University
RP Seo, S (corresponding author), Sungkyul Univ, Div Media Software, Anyang, South Korea.
EM shseo75@gmail.com
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Seoul National University of Science Technology; National Research
   Foundation of Korea (NRF) - Korea government (MSIT)
   [2016R1D1A1B03935378]
FX This work has supported by Seoul National University of Science &
   Technology and the National Research Foundation of Korea (NRF) grant
   funded by the Korea government (MSIT) (No. 2016R1D1A1B03935378).
CR [Anonymous], 1999, Tech. Rep. C-1
   [Anonymous], SIGGRAPH ASIA 2016 T
   [Anonymous], 2006, BODY SENSOR NETWORKS
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Phan D, 2015, 2015 INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB), P144, DOI 10.1109/ISBB.2015.7344944
   Feng YZ, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P235
   Fernandes E, 2016, P IEEE S SECUR PRIV, P636, DOI 10.1109/SP.2016.44
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Jun S, 2015, J SUPERCOMPUT, V71, P1933, DOI 10.1007/s11227-014-1182-1
   Kang D, 2018, MULTIMED TOOLS APPL, V77, P4985, DOI 10.1007/s11042-017-4667-0
   Kim M, 2013, MULTIMED TOOLS APPL, V64, P505, DOI 10.1007/s11042-011-0897-8
   Kummer M, 2017, REV ECOBEE4 SMART TH
   Nack F., 2001, IEEE Multimedia, V8, P10, DOI 10.1109/93.959093
   Rho S, 2013, J SUPERCOMPUT, V65, P274, DOI 10.1007/s11227-010-0447-6
   Rho S, 2013, MULTIMED TOOLS APPL, V65, P259, DOI 10.1007/s11042-011-0803-4
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.3.CO;2-9
   Schimmack U, 2002, EMOTION, V2, P412, DOI 10.1037//1528-3542.2.4.412
   Seo S, 2016, J SUPERCOMPUT, V72, P3478, DOI 10.1007/s11227-015-1510-0
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Thayer R.E., 1990, BIOPSYCHOLOGY MOOD A, V1
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Zhang DQ, 2012, J UNIVERS COMPUT SCI, V18, P1069
NR 24
TC 10
Z9 12
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3267
EP 3276
DI 10.1007/s11042-018-6733-7
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600033
DA 2024-07-18
ER

PT J
AU Ma, YC
   Liu, YJ
   Xie, Q
   Li, L
AF Ma, Yanchun
   Liu, Yongjian
   Xie, Qing
   Li, Lin
TI CNN-feature based automatic image annotation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Convolutional neural network; Feature extraction;
   Semantic extension
AB Automatic image annotation(AIA) methods are considered as a kind of efficient schemes to solve the problem of semantic-gap between the original images and their semantic information. However, traditional annotation models work well only with finely crafted manual features. To address this problem, we combined the CNN feature of an image into our proposed model which we referred as SEM by using a famous CNN model-AlexNet. We extracted a CNN feature by removing its final layer and it is proved to be useful in our SEM model. Additionally, based on the experience of the traditional KNN models, we propose a model to address the problem of simultaneously addressing the image tag refinement and assignment while maintaining the simplicity of the KNN model. The proposed model divides the images which have similar features into a semantic neighbor group. Moreover, utilizing a self-defined Bayesian-based model, we distribute the tags which belong to the neighbor group to the test images according to the distance between the test image and the neighbors. At last, the experiments are performed on three typical image datasets corel5k, espGame and laprtc12, which verify the effectiveness of the proposed model.
C1 [Ma, Yanchun; Liu, Yongjian; Xie, Qing; Li, Lin] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Xie, Q (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM mayanchun@whut.edu.cn; liuyj626@163.com; felixxq@whut.edu.cn;
   cathylilin@whut.edu.cn
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU Natural Science Foundation of China [61602353]; Fundamental Research
   Funds for the Central Universities [WUT:2017IVA053, WUT:2017IVB028,
   WUT:2017YB028]
FX This research is partially supported by Natural Science Foundation of
   China (Grant No. 61602353) and the Fundamental Research Funds for the
   Central Universities (WUT:2017IVA053, WUT:2017IVB028 and WUT:2017YB028).
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], DECAF DEEP CONVOLUTI
   [Anonymous], 1999, MISRM
   [Anonymous], IEEE 17 INT WORKSH M
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], TAGPROP DISCRIMINATI
   [Anonymous], 1989, Backpropagation applied to handwritten zip code recognition
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Cusano C, 2004, PROC SPIE, V5304, P330
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duygulu P., 2002, Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Gao Y., 2006, MULTI-MEDIA '06, P901
   Grubinger M., 2006, Language Resources and Evaluation, P13
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Simonyan K., 2014, 14091556 ARXIV
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wang S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003729
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825
   Yang Yang, 2015, IEEE Transactions on Big Data, V1, P162, DOI 10.1109/TBDATA.2016.2516024
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu Xiangyu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI [DOI 10.1109/TPAMI.2017.2778152, DOI 10.1109/TBDATA.2017.2736547]
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 37
TC 43
Z9 45
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3767
EP 3780
DI 10.1007/s11042-018-6038-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600060
DA 2024-07-18
ER

PT J
AU Zhou, GQ
   Qin, S
   Zhou, HF
   Cheng, DS
AF Zhou, Guoqiang
   Qin, Shui
   Zhou, Hongfei
   Cheng, Dansong
TI A differential privacy noise dynamic allocation algorithm for big
   multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big multimedia data; Differential privacy; SDC-DP; Standard deviation
   circle radius; Relative errors
ID DIMENSIONALITY REDUCTION
AB An advanced differential privacy algorithm is proposed in this paper to solve the problem of non-uniformity faced with two-dimensional big multimedia data, such as images. Traditional privacy-preserving algorithms partition a spatial data space into grids and then add noise to each grid at same scale. Such a treatment increases relative errors and reduces accuracy. To address this issue, a differential privacy noise dynamic allocation algorithm is proposed based on the standard deviation circle radius hereafter referred to as SDC-DP algorithm. In our proposed algorithm, the intensity of privacy-preserving needs is defined by the divergence of each grid which is calculated by the standard deviation circle radius. The different scale of noise is mixed dynamically into count query results for each grid on the privacy-preserving needs. Experimental results show that the SDC-DP can effectively reduce the relative errors and improve accuracies, compared to the state-of-the-art techniques.
C1 [Zhou, Guoqiang; Qin, Shui; Zhou, Hongfei] Nanjing Univ Posts & Telecommun, Coll Comp Sci, Nanjing 210003, Jiangsu, Peoples R China.
   [Cheng, Dansong] Harbin Inst Technol, Sch Comp Sci, Harbin 150006, Heilongjiang, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Harbin Institute of
   Technology
RP Zhou, GQ (corresponding author), Nanjing Univ Posts & Telecommun, Coll Comp Sci, Nanjing 210003, Jiangsu, Peoples R China.
EM zhougq@njupt.edu.cn; 1205395120@qq.com; zhouhfsix@foxmail.com;
   cdsinhit@hit.edu.cn
RI Cheng, Dan/ITT-7298-2023
FU Shenzhen Science and Technology Innovation Commission (SZSTI)
   [JCYJ20170302153752613]
FX This work is supported by Shenzhen Science and Technology Innovation
   Commission (SZSTI) project No. JCYJ20170302153752613.
CR Amiri F, 2016, KNOWL-BASED SYST, V101, P71, DOI 10.1016/j.knosys.2016.03.004
   [Anonymous], 2011, Proceedings of the ACM SIGMOD International Conference on Management of data, DOI DOI 10.1145/1989323.1989348
   Cormode G., 2012, ICDT, P299
   Cormode G, 2012, PROC INT CONF DATA, P20, DOI 10.1109/ICDE.2012.16
   Dwork C., 2006, P 3 THEOR CRYPT C, V7, P637
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Gao JB, 2007, NEURAL NETWORKS, V20, P791, DOI 10.1016/j.neunet.2007.03.001
   Hay M, 2009, P VLDB ENDOWMENT, V3, P66
   Inan A., 2010, EDBT '10, P123
   Jiang XW, 2014, IEEE T CYBERNETICS, V44, P1795, DOI 10.1109/TCYB.2013.2295329
   Li H, 2015, MED DATA PRIVACY HDB
   LIU MY, 2014, OCEANS IEEE
   Mcsherry F, 2007, IEEE S FDN COMP SCI
   Nguyen MN, 2006, IEEE T SYST MAN CY B, V36, P1180, DOI 10.1109/TSMCB.2006.874691
   Peng Shangfu., 2012, ACM SIGMOD INT C MAN, P864
   Pouget V., 2017, IEEE T NEUR NET LEAR, V64, P13, DOI DOI 10.1109/TNNLS.2016.2521602
   Qardaji W, 2013, PROC INT CONF DATA, P757, DOI 10.1109/ICDE.2013.6544872
   Qardaji Wahbeh., 2012, Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security, P38
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shi D, 2005, NEURAL NETWORKS, V18, P951, DOI 10.1016/j.neunet.2005.02.006
   Shi DM, 2017, PATTERN RECOGN LETT, V89, P67, DOI 10.1016/j.patrec.2016.12.023
   Shi DM, 2010, IEEE T SYST MAN CY B, V40, P548, DOI 10.1109/TSMCB.2009.2030333
   To H, 2014, PROC VLDB ENDOW, V7, P919, DOI 10.14778/2732951.2732966
   Wang J, 2016, NEUROCOMPUTING, V214, P1026, DOI 10.1016/j.neucom.2016.07.015
   Xiao XK, 2011, IEEE T KNOWL DATA EN, V23, P1200, DOI 10.1109/TKDE.2010.247
   Xu J, 2013, VLDB J, V22, P797, DOI 10.1007/s00778-013-0309-y
   Xu J, 2012, PROC INT CONF DATA, P32, DOI 10.1109/ICDE.2012.48
   Zhang XJ, 2014, J COMPUT, V4, P927
   [张志杰 Zhang Zhijie], 2008, [中国卫生统计, Chinese Journal of Health Statistics], V25, P136
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2015, NEUROCOMPUTING, V169, P43, DOI 10.1016/j.neucom.2014.08.106
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
NR 33
TC 7
Z9 8
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3747
EP 3765
DI 10.1007/s11042-018-5776-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600059
DA 2024-07-18
ER

PT J
AU Isogawa, M
   Mikami, D
   Takahashi, K
   Kimata, H
AF Isogawa, Mariko
   Mikami, Dan
   Takahashi, Kosuke
   Kimata, Hideaki
TI Image quality assessment for inpainted images via learning to rank
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learning to rank; Image inpainting; Image quality assessment (IQA)
AB This paper proposes an image quality assessment (IQA) method for image inpainting, aiming at selecting the best one from a plurality of results. It is known that inpainting results vary largely with the method used for inpainting and the parameters set. Thus, in a typical use case, users need to manually select the inpainting method and the parameters that yield the best result. This manual selection takes a great deal of time and thus there is a great need for a way to automatically estimate the best result. Unlike existing IQA methods for inpainting, our method solves this problem as a learning-based ordering task between inpainted images. This approach makes it possible to introduce auto-generated training sets for more effective learning, which has been difficult for existing methods because judging inpainting quality is quite subjective. Our method focuses on the following three points: (1) the problem can be divided into a set of pairwise preference order estimation elemental problems, (2) this pairwise ordering approach enables a training set to be generated automatically, and (3) effective feature design is enabled by investigating actually measured human gazes for order estimation.
C1 [Isogawa, Mariko; Takahashi, Kosuke; Kimata, Hideaki] NTT Media Intelligence Labs, 1-1 Hikarino Oka, Yokosuka, Kanagawa, Japan.
   [Mikami, Dan] NTT Media Intelligence Labs, Cross Modal Comp Project, 1-1 Hikarino Oka, Yokosuka, Kanagawa, Japan.
   [Mikami, Dan] NTT Commun Sci Labs, 3-1 Wakamiya, Atsugi, Kanagawa, Japan.
C3 Nippon Telegraph & Telephone Corporation
RP Isogawa, M (corresponding author), NTT Media Intelligence Labs, 1-1 Hikarino Oka, Yokosuka, Kanagawa, Japan.
EM mariko.isogawa.kt@hco.ntt.co.jp; dan.mikami.vp@hco.ntt.co.jp;
   kosuke.takahashi.rd@hco.ntt.co.jp; hideaki.kimata.yu@hco.ntt.co.jp
CR Abe T, 2012, INT C PATT RECOG, P3712
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2016, IEEE VIS COMMUN IMAG
   Ardis Paul A., 2009, P SOC PHOTO-OPT INS, V7257
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Darabi S, 2012, P SIGGRAPH 2012, V31
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   FRANTC VA, 2014, P SOC PHOTO-OPT INS, V9120
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Herbrich R, 2000, ADV NEUR IN, P115
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Isogawa M, 2017, MULTIMED TOOLS APPL, V76, P9443, DOI 10.1007/s11042-016-3550-8
   Isogawa M, 2016, IEEE IMAGE PROC, P3538, DOI 10.1109/ICIP.2016.7533018
   Ma L, 2016, IEEE T MULTIMEDIA, V18, P2228, DOI 10.1109/TMM.2016.2614187
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oncu AI, 2012, LECT NOTES COMPUT SC, V7583, P561, DOI 10.1007/978-3-642-33863-2_58
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Thanh Trung A, 2013, IM PROC ICIP 2013 20, P398
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Voronin VV, 2015, P SOC PHOTO-OPT INS, V9399
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang S, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P786, DOI 10.1109/ICYCS.2008.461
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2016, DISPLAYS, V44, P21, DOI 10.1016/j.displa.2016.06.002
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yan JZ, 2014, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2014.382
NR 34
TC 8
Z9 8
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1399
EP 1418
DI 10.1007/s11042-018-6186-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700008
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, W
   Zhu, LH
   Chu, LY
   Ma, HD
AF Liu, Wu
   Zhu, Lingheng
   Chu, Lingyang
   Ma, Huadong
TI A common subgraph correspondence mining framework for map search
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Map searching; Graph pattern match; Common pattern mining; Multi-model
   information
ID GRAPH; MODEL
AB With the development of GPS, Internet, and mobile devices, the map searching services become an essential application in people's lives. However, existing map searching services only support simple keywords based location search, which neglect users' complex search requirements, such as searching a hotel surrounded by station, shopping mall, cinema, etc. In this paper, we propose a map searching framework which maps users' complex search requirements into a graph pattern match problem. In this framework, the user's query requirements are mapped into a undirected graph, where the vertexes indicate the searched locations, and the edges represent the distance between connected locations. In this way, we propose a common pattern searching algorithm to give the top k matches groups and arrange them using a similarity. The similarity is defined by multi-model information, i.e., the graph structure, location categories, review stars, and review counts. Moreover, this method also allows user to input ambiguous and uncertain query condition with sketching query map. To adapt the method to large-scale data, we also filter the candidate groups by effective pruning methods. The evaluations on Yelp dataset demonstrate the proposed method is effective and flexibility in both certain and uncertain query graphs.
C1 [Liu, Wu; Zhu, Lingheng; Ma, Huadong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Chu, Lingyang] Simon Fraser Univ, Sch Comp Sci, Vancouver, BC V5A1S6, Canada.
C3 Beijing University of Posts & Telecommunications; Simon Fraser
   University
RP Liu, W (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM liuwu@bupt.edu.cn; zhulingheng0712@bupt.edu.cn; lca117@sfu.ca;
   mhd@bupt.edu.cn
RI Liu, Wu/AAG-3615-2019
OI Liu, Wu/0000-0003-1633-7575
FU Funds for International Cooperation and Exchange of the National Natural
   Science Foundation of China [61720106007]; National Natural Science
   Foundation of China [61602049]; NSFC-Guangdong Joint Fund [U1501254];
   Beijing Committee of Education
FX This work is partially supported by the Funds for International
   Cooperation and Exchange of the National Natural Science Foundation of
   China (No. 61720106007), the National Natural Science Foundation of
   China (No. 61602049), the NSFC-Guangdong Joint Fund (U1501254), and the
   Cosponsored Project of Beijing Committee of Education.
CR [Anonymous], 2007, Proceedings of the 2007 ACM SIGMOD international conference on Management of data (2007)
   [Anonymous], 2009, Encyclopedia of Complexity and Systems Science, DOI DOI 10.1007/978-0-387-30440-3_188
   Cheng JF, 2008, PROC INT CONF DATA, P913, DOI 10.1109/ICDE.2008.4497500
   Chu LY, 2016, IEEE T CIRC SYST VID, V26, P556, DOI 10.1109/TCSVT.2014.2347551
   Chu LY, 2013, IEEE T MULTIMEDIA, V15, P1982, DOI 10.1109/TMM.2013.2270455
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855
   Khan A., 2011, SIGMOD 11, P901
   Khan A, 2013, PROC VLDB ENDOW, V6, P181, DOI 10.14778/2535569.2448952
   Lingyang Chu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2465, DOI 10.1109/ICIP.2011.6116160
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu DB, 2017, IEEE INT CONF MULTI
   Liu HR, 2010, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2010.5539780
   Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994
   Liu W, 2014, IEEE T MULTIMEDIA, V16, P2242, DOI 10.1109/TMM.2014.2359332
   Liu W, 2013, IEEE T CYBERNETICS, V43, P1442, DOI 10.1109/TCYB.2013.2272636
   MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   Pérez J, 2009, ACM T DATABASE SYST, V34, DOI 10.1145/1567274.1567278
   Yang SQ, 2014, PROC VLDB ENDOW, V7, P565, DOI 10.14778/2732286.2732293
   Zhu LH, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P413, DOI 10.1109/BigMM.2017.80
   Zou L, 2011, PROC VLDB ENDOW, V4, P482, DOI 10.14778/2002974.2002976
NR 26
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 747
EP 766
DI 10.1007/s11042-017-5553-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500042
DA 2024-07-18
ER

PT J
AU Ma, CB
   Lv, XW
   Ao, J
AF Ma, Chunbo
   Lv, Xuewei
   Ao, Jun
TI Difference based median filter for removal of random value impulse noise
   in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Difference method; Random value impulse noise; Median filter; Image
   processing
ID PEPPER NOISE; HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT; SALT
AB Random value impulse noise of images has many sources, such as image sensor, electronic components, etc. How to removal of noise and restore degraded image is always an interesting problem. The decision based algorithms as efficient methods to suppress noise have been extensively studied for a long time. In this type of algorithms, the first step is to classify the corrupted pixels from the surroundings, but it is not an easy thing since each image is different. The efficiency of the classification has great influence on the overall performances of the algorithms. A difference based median filter which can efficiently locate the random value impulse noise is proposed in this paper. Based on this filter, a new algorithm for removal of impulse noise in images is designed. A comparison of the performances is made among several existing algorithms in term of Image Enhancement Factor, Peak Signal-to-Noise Ratio and Structure Similarity Index. Finally, the proposed method is used for underwater image processing to suppress the random value impulse noise modified by Histogram Equalization operation. Visual and quantitative results indicate that the proposed method outperforms most of algorithms for removal of impulse noise in literatures.
C1 [Ma, Chunbo; Lv, Xuewei; Ao, Jun] Guilin Univ Elect Technol, Guilin, Guangxi, Peoples R China.
C3 Guilin University of Electronic Technology
RP Ao, J (corresponding author), Guilin Univ Elect Technol, Guilin, Guangxi, Peoples R China.
EM machunbo@guet.edu.cn; pony@guet.edu.cn; junjunao1@263.net
FU program for National Natural Science Foundation of China [61167006];
   GUET Excellent Graduate Thesis Program [16YJPYSS13]
FX This work is supported by the program for National Natural Science
   Foundation of China (No. 61167006) and GUET Excellent Graduate Thesis
   Program (No. 16YJPYSS13).
CR Ao J, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540010
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   DALEJONES R, 1993, PATTERN RECOGN, V26, P1373, DOI 10.1016/0031-3203(93)90143-K
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gonzalez RC, 2008, DIGITAL IMAGE PROCES, P343
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   KARTHIK B, 2014, MIDDLE EAST J SCI RE, V20, P1222, DOI DOI 10.5829/idosi.mejsr.2014.20.10.114063
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Nair MS, 2008, LECT NOTES ENG COMP, P611
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Stinson DR, 2005, CRYPTOGRAPHY THEORY
   Sun Feifei, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P417, DOI 10.1109/ICICTA.2011.388
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang XH, 2015, INT J APPL EARTH OBS, V34, P89, DOI 10.1016/j.jag.2014.06.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zou R, 2011, ENERGY PROCEDIA, V13, P4712, DOI [10.1016/S1876-6102(14)00454-8, DOI 10.1016/S1876-6102(14)00454-8]
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 22
TC 14
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1131
EP 1148
DI 10.1007/s11042-018-6442-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500064
DA 2024-07-18
ER

PT J
AU Qin, PL
   Li, CP
   Chen, J
   Chai, R
AF Qin, Pinle
   Li, Chuanpeng
   Chen, Jun
   Chai, Rui
TI Research on improved algorithm of object detection based on feature
   pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature pyramid; Object detection; Convolutional neural network;
   Multi-scale detection; Deep learning
AB To solve the low detection accuracy of SSD for the small size object, this paper proposed an improved algorithm of SSD object detection based on the feature pyramid (FP-SSD). In the deep convolutional neural network, the high-level features contain well semantic information but are not sensitive to the translations. The low-level features have high resolutions but could not represent the features well. The feature pyramid structure contains multi-scale features. To combine the high and low-level features of the pyramid, the algorithm of this paper applied the deconvolution network to the high-level features of the feature pyramid to get the semantic information, dilated convolution network to learn the position information of the low-level features and used convolution for the middle level features to reduce the feature channels, then used convolution to fuse the features. After using the algorithm, a multi-scale detection structure is constructed. FP-SSD achieves a mean accuracy of 79% on PASCAL VOC2007, and 47% on MSCOCO, which has a great improve compared with SSD. We compared the detection accuracy and results with all kinds of scales by experiments, compared with SSD, the accuracy of FP-SSD is higher, which has more accurate location and higher recognition confidence.
C1 [Qin, Pinle; Li, Chuanpeng; Chen, Jun; Chai, Rui] North Univ China, Sch Data Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
C3 North University of China
RP Qin, PL (corresponding author), North Univ China, Sch Data Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
EM pinleqinl@163.com
FU Shanxi Science Foundation [2015011045]
FX This work is partially supported by Shanxi Science Foundation
   (No.2015011045). The authors also gratefully acknowledge the helpful
   comments and suggestions of the reviewers, which have improved the
   presentation.
CR Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nair Vinod, 2010, INT C MACH LEARN, P807
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2014, 3RD INT C LEARNING R, P580
   Szegedy C., 2017, AAAI, V4, P12
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zhou QY, 2018, ELECTRON COMMER RES, V18, P109, DOI 10.1007/s10660-017-9265-8
NR 18
TC 12
Z9 15
U1 1
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 913
EP 927
DI 10.1007/s11042-018-5870-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500052
DA 2024-07-18
ER

PT J
AU Xue, F
   Wang, JW
   Qian, SS
   Zhang, TZ
   Liu, XL
   Xu, CS
AF Xue, Feng
   Wang, Jianwei
   Qian, Shengsheng
   Zhang, Tianzhu
   Liu, Xueliang
   Xu, Changsheng
TI Multi-modal max-margin supervised topic model for social event analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social event classification; Multi-modal; Max-margin; Social media;
   Topic model
AB In this paper, we proposed a novel multi-modal max-margin supervised topic model (MMSTM) for social event analysis by jointly learning the representation together with the classifier in a unified framework. Compared with existing methods, the proposed MMSTM model has several advantages. (1) The proposed model can utilize the classifier as the regularization term of our model to jointly learn the parameters in the generative model and max-margin classifier, and use the Gibbs sampling to learn parameters of the representation model and max-margin classifier by minimizing the expected loss function. (2) The proposed model is able to not only effectively mine the multi-modal property by jointly learning the latent topic relevance among multiple modalities for social event representation, but also exploit the supervised information by considering a discriminative max-margin classifier for event classification to boost the classification performance. (3) In order to validate the effectiveness of the proposed model, we collect a large-scale real-world dataset for social event analysis, and both qualitative and quantitative evaluation results have demonstrated the effectiveness of the proposed MMSTM.
C1 [Xue, Feng; Wang, Jianwei; Liu, Xueliang; Xu, Changsheng] Hefei Univ Technol, Hefei, Anhui, Peoples R China.
   [Qian, Shengsheng; Zhang, Tianzhu; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Xue, F (corresponding author), Hefei Univ Technol, Hefei, Anhui, Peoples R China.
EM feng.xue@hfut.edu.cn; jwwang2015@mail.hfut.edu.cn;
   shengsheng.qian@nlpr.ia.ac.cn; tzzhang@nlpr.ia.ac.cn;
   liuxueliang@hfut.edu.cn; csxu@nlpr.ia.ac.cn
RI Zhang, Tianzhu/AGY-9389-2022; xu, cj/HJZ-3488-2023
OI Zhang, Tianzhu/0000-0003-0764-6106; 
FU National Key Research and Development Program of China [2017YFB080
   3301]; National Natural Science Foundation of China [61772170, 614
   72115, 61572498, 61532009, 61472379, 61572296]
FX The work is supported by the National Key Research and Development
   Program of China (No. 2017YFB080 3301). This work is also supported by
   the National Natural Science Foundation of China (No.61772170, 614
   72115, 61572498, 61532009, 61472379, 61572296).
CR [Anonymous], 2010, P 24 ANN C NEUR INF, DOI DOI 10.1109/ICPR.2014.65
   [Anonymous], 2011, Advances in neural information processing systems
   [Anonymous], 2008, P ADV NEURAL INFORM
   [Anonymous], 2009, Proceedings of the Second ACM international Conference on Web Search and Data Mining (Barcelona, Spain, February 09-12, DOI DOI 10.1145/1498759.1498809
   Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P239, DOI 10.1145/2505515.2505556
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Firan C.S., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P189
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krestel R., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P61, DOI [DOI 10.1145/1639714.1639726, 10.1145/1639714.1639726]
   Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P297, DOI 10.1145/1008992.1009044
   Lin DH, 2013, IEEE I CONF COMP VIS, P841, DOI 10.1109/ICCV.2013.109
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86
   Min W, 2017, IEEE T MULTIMED, P1
   Min WQ, 2014, IEEE MULTIMEDIA, V21, P20, DOI 10.1109/MMUL.2014.1
   Niu ZX, 2011, PROC CVPR IEEE, P1769, DOI 10.1109/CVPR.2011.5995426
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Qian Shengsheng, 2016, P 24 ACM INT C MULTI
   Radinsky K., 2013, P 6 ACM INT C WEB SE, P255, DOI DOI 10.1145/2433396.2433431
   Ramage D., 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, EMNLP'09, P248, DOI 10.3115/1699510.1699543
   Wang Y., 2011, LECT NOTES COMPUTER, V1674, P39, DOI DOI 10.1007/978-3-642-23620-4_8
   Yang S, 2015, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2015.7298769
   Yang WW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P686
   Zhang TZ, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2602633
   Zhang TZ, 2012, IEEE T MULTIMEDIA, V14, P1206, DOI 10.1109/TMM.2012.2191944
   Zhu J, 2014, J MACH LEARN RES, V15, P1073
   Zhuang Y., 2012, P 20 ACM INT C MULT, P957
NR 31
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 141
EP 160
DI 10.1007/s11042-017-5605-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500008
DA 2024-07-18
ER

PT J
AU Zhang, C
   Kim, J
AF Zhang, Chen
   Kim, Joohee
TI Multi-scale pedestrian detection using skip pooling and recurrent
   convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Deep learning; Convolutional neural networks;
   Multi-scale object detection; Recurrent neural networks
ID NETWORKS
AB Detecting pedestrians of different scales is essential for applications like autonomous driving. Recent research progress showed that combining multiple feature maps and contextual information helps detecting objects of different scales. In this paper, we propose a multi-scale pedestrian detector that combines skip pooling from multi-resolution feature maps and recurrent convolutional layers for extracting contextual information. To fully exploit the unique characteristics of the features at different levels for multi-scale pedestrian detection, the multi-scale features and the context features are fused at the fully connected layer. To gather spatial contextual information, we propose a modified recurrent convolutional layer that produces context feature maps with different resolutions. In addition, we construct a set of scale-dependent classification and bounding box regression subnetworks to further improve the performance of multi-scale pedestrian detection. Experiments on Caltech and KITTI pedestrian detection benchmark datasets show that the proposed method achieves the state-of-the-art performance with faster speed.
C1 [Zhang, Chen; Kim, Joohee] IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
C3 Illinois Institute of Technology
RP Zhang, C (corresponding author), IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
EM czhang57@hawk.iit.edu; joohee@ece.iit.edu
FU Industrial Core Technology Development Program of MOTIE/KEIT, KOREA
   [10083639]
FX This work is supported by the Industrial Core Technology Development
   Program of MOTIE/KEIT, KOREA.[#10083639, Development of Camera-based
   Real-time Artificial Intelligence System for Detecting Driving
   Environment and Recognizing Objects on Road Simultaneously]
CR [Anonymous], IEEE T MULTIMED
   [Anonymous], EUR C COMP VIS
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, P BRIT MACH VIS C
   [Anonymous], ARXIV150604579
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV150400941
   [Anonymous], ARXIV161003466
   [Anonymous], 2015, LECT NOTES BUS INF P
   [Anonymous], 2009, P 2009 BRIT MACH VIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV151204143
   Braun M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1546, DOI 10.1109/ITSC.2016.7795763
   Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu QC, 2018, IEEE T CIRC SYST VID, V28, P1358, DOI 10.1109/TCSVT.2017.2648850
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jung SI, 2017, PATTERN RECOGN LETT, V90, P43, DOI 10.1016/j.patrec.2017.02.018
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Pham CC, 2017, SIGNAL PROCESS-IMAGE, V53, P110, DOI 10.1016/j.image.2017.02.007
   Ren J, 2017, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2017.87
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xiang Y, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhu YS, 2017, LECT NOTES COMPUT SC, V10112, P416, DOI 10.1007/978-3-319-54184-6_26
NR 48
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1719
EP 1736
DI 10.1007/s11042-018-6240-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700022
DA 2024-07-18
ER

PT J
AU El Kaitouni, SE
   Abbad, A
   Tairi, H
AF El Idrissi El Kaitouni, Soukaina
   Abbad, Abdelghafour
   Tairi, Hamid
TI A breast tumors segmentation and elimination of pectoral muscle based on
   hidden markov and region growing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Tumors; Mammogram image; Otsu thresholding; LBP (Local
   Binary Pattern); K-means; Markov
ID MAMMOGRAMS; IMAGES; CLASSIFICATION; DISTRIBUTIONS; MODEL
AB In this article, we propose an automatic method for the detection and segmentation of the tumor on mammogram images. Most methods of detection of a tumor require an extraction of a large number of texture features from multiple calculations. The study first examines a technique of pre-processing images to obtain the Otsu thresholding method which eliminate items that do not belong in. After performing the thresholding, we estimate the number of base classes of technical LBP (Local Binary Pattern). To automate the initialization task, the classification proposed by applying dynamic k-means and improve the classes obtained by the method of Markov. Then we calculate the correlation between these classes and the original image, we deduce the class that contains the tumor and pectoral muscle. Finally, it uses the method of growing the region to eliminate pectoral muscle. The result obtained by this approach shows the quality and accuracy of extracting parts of the tumor compared to existing approaches in the literature.
C1 [El Idrissi El Kaitouni, Soukaina; Abbad, Abdelghafour; Tairi, Hamid] Univ Sidi Mohamed Ben Abdelah, Fac Sci Dhar El Mahraz, Dept Comp Sci, LIIAN, BP 1796, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP El Kaitouni, SE (corresponding author), Univ Sidi Mohamed Ben Abdelah, Fac Sci Dhar El Mahraz, Dept Comp Sci, LIIAN, BP 1796, Fes, Morocco.
EM soukaina.elidrissi1@usmba.ac.ma; gh.abbad@gmail.com; htairi@yahoo.fr
OI Tairi, Hamid/0000-0002-5445-0037
CR Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   Alayli RM, 2013, ITERATIVE MAMMOGRAPH
   [Anonymous], INT J COMP TECH APPL
   Aschwanden P., 1992, Robust Computer Vision, P268
   Bon AT, 2009, J APPL SCI RES, V5, P2189
   Boss R, 2013, ARXIV13077474
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen X., 2010, Medical Image Understanding and Analysis, P71
   David R, 2005, LNCS, V3523, P471
   Djukovic D, 2018, METHODS MOL BIOL, V1765, P229, DOI 10.1007/978-1-4939-7765-9_15
   Dokládal P, 1999, LECT NOTES COMPUT SC, V1679, P98
   El Idrissi El Kaitouni Soukaina, 2017, International Journal of Medical Engineering and Informatics, V9, P316
   El Idrissi el Kaitouni S, 2017, INT C ADV TECHN SING
   Elmoufidi Abdelali, 2014, 2014 Fifth International Conference on Next-Generation Networks and Services (NGNS), P118, DOI 10.1109/NGNS.2014.6990239
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gumaei A., 2012, 2012 Symposium on Broadband Networks and Fast Internet (RELABIRA), P97, DOI 10.1109/RELABIRA.2012.6235102
   Jen CC, 2015, EXPERT SYST APPL, V42, P3048, DOI 10.1016/j.eswa.2014.11.061
   Kwok SM, 2004, IEEE T MED IMAGING, V23, P1129, DOI 10.1109/TMI.2004.830529
   Liu CC, 2012, EXPERT SYST APPL, V39, P4505, DOI 10.1016/j.eswa.2011.09.136
   Liu L, 2011, BREAST PECTORAL MUSC
   Margolies LR, 2018, CLIN IMAG, V50, P13, DOI 10.1016/j.clinimag.2017.12.002
   Mustra M, 2013, SIGNAL PROCESS, V93, P2817, DOI 10.1016/j.sigpro.2012.07.026
   Mustra M, 2009, EUROCON 2009: INTERNATIONAL IEEE CONFERENCE DEVOTED TO THE 150 ANNIVERSARY OF ALEXANDER S. POPOV, VOLS 1- 4, PROCEEDINGS, P1426, DOI 10.1109/EURCON.2009.5167827
   Nagi J., 2010, 2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2010), P87, DOI 10.1109/IECBES.2010.5742205
   Nakajima Takahiro, 2017, INTERVENTIONS PULMON, P245
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ray S., 1999, PROC 4 INT C ADV PAT, P137
   Selle D, 2002, IEEE T MED IMAGING, V21, P1344, DOI 10.1109/TMI.2002.801166
   Singh Nalini, 2011, INT J COMPUTER APPL, V22, P2
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Wang L, 2010, J ZHEJIANG U-SCI C, V11, P111, DOI 10.1631/jzus.C0910025
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 36
TC 15
Z9 15
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31347
EP 31362
DI 10.1007/s11042-018-6089-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600054
DA 2024-07-18
ER

PT J
AU Abdelhakim, AM
   Saad, MH
   Sayed, M
   Saleh, HI
AF Abdelhakim, Assem M.
   Saad, M. H.
   Sayed, M.
   Saleh, H., I
TI Optimized SVD-based robust watermarking in the fractional Fourier domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust watermarking; Fractional Fourier Transform; Singular Value
   Decomposition; Meta-heuristic optimization; Artificial Bee Colony
ID BEE COLONY ALGORITHM; IMAGE WATERMARKING; TRANSFORM
AB Digital watermarking is one of the most effective methods for protecting multimedia from different kind of threats. It has been used for many purposes, like copyright protection, ownership identification, tamper detection, etc. Many watermarking applications require embedding techniques that provide robustness against common watermarking attacks, like compression, noise, filtering, etc. In this paper, an optimized robust watermarking method is proposed using Fractional Fourier Transform and Singular Value Decomposition. The approach provides a secure way for watermarking through the embedding parameters that are required for the watermark extraction. It is a block-based method, where each watermark bit is embedded in its corresponding image block. First, the transform is applied to each block, and then the singular values are evaluated through which the embedding modification is performed. The optimum fractional powers, of the transform, and the embedding strength factor are evaluated through a Meta-heuristic optimization to optimize the watermark imperceptibility and robustness. The Artificial Bee Colony is used as the Meta-heuristic optimization method. A fitness function is employed, at the optimization process, through which the maximum achievable robustness can be provided without degrading the watermarking quality below a predetermined quality threshold Qth. The effectiveness of the proposed method is demonstrated through a comparison with recent watermarking techniques in terms of the watermarking performance. The watermarking quality and robustness are evaluated for different quality threshold values. Experimental results show that the proposed approach achieves a better quality compared to that of other existing watermarking methods. On the other hand, the robustness is examined against the most common applied attacks. It is noticed that the proposed method can achieve a higher robustness degree when decreasing the quality threshold value.
C1 [Abdelhakim, Assem M.; Saad, M. H.; Sayed, M.; Saleh, H., I] Egyptian Atom Energy Author, Radiat Engn Dept, NCRRT, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA)
RP Saad, MH (corresponding author), Egyptian Atom Energy Author, Radiat Engn Dept, NCRRT, Cairo, Egypt.
EM assemh81@gmail.com; m.hassansaad@gmail.com; m.s_kamel@yahoo.com;
   h_i_saleh@hotmail.com
RI Saad, Mohamed H./AGU-7078-2022; saleh, hassan I./ABA-6608-2022;
   Abdelhakim, Assem/HIK-1016-2022
OI Saad, Mohamed H./0000-0001-8370-3614; Saleh, Hassan/0000-0001-5395-2214;
   kamel, Mahmoud/0000-0002-4684-6752
CR Abdelhakim AM, 2016, IET IMAGE PROCESS, V10, P247, DOI 10.1049/iet-ipr.2015.0379
   Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Anwar Muhammad Jamil, 2010, 2010 6th International Conference on Emerging Technologies (ICET), P204, DOI 10.1109/ICET.2010.5638488
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bedi P, 2012, PROC TECH, V4, P612, DOI 10.1016/j.protcy.2012.05.098
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1999, SIGNAL PROC SERIES, P461
   Cox IJ., 2007, DIGITAL WATERMARKING
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Draa A, 2014, SWARM EVOL COMPUT, V16, P69, DOI 10.1016/j.swevo.2014.01.003
   Elhoseny HM, 2015, SIGNAL IMAGE VIDEO P, V9, P611, DOI 10.1007/s11760-013-0490-x
   Farhan AA, 2011, 14 INT MULT C
   Hanbay K, 2014, APPL SOFT COMPUT, V21, P433, DOI 10.1016/j.asoc.2014.04.008
   Fung CWH, 2011, PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON NETWORKS (ICN 2011), P24
   Hussain F, 2009, 2009 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES, P280, DOI 10.1109/MSPCT.2009.5164230
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karaboga D., 2005, Technical report-tr06
   Kumsawat P, 2011, WORLD ACAD SCI ENG T
   Lai CC, 2012, INT CONF GENET EVOL, P476, DOI 10.1109/ICGEC.2012.103
   Li B, 2014, ENG APPL ARTIF INTEL, V27, P70, DOI 10.1016/j.engappai.2013.06.010
   Liu J., 2005, P 1 INT C INF COMM T, P337
   Loukhaoukha K, 2013, J OPTIM, V2013, DOI 10.1155/2013/921270
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Ozaktas HM, 1996, IEEE T SIGNAL PROCES, V44, P2141, DOI 10.1109/78.536672
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Prashanth R, 2012, INT J ELECT SIGNALS
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Sejdic E, 2011, SIGNAL PROCESS, V91, P1351, DOI 10.1016/j.sigpro.2010.10.008
   Wang J, 2011, INFORM SCIENCES, V181, P5501, DOI 10.1016/j.ins.2011.07.040
   Wei ZC, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1117, DOI 10.1109/ICME.2006.262731
   Yusof Y, 2007, ICT-MICC: 2007 IEEE INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P665
NR 37
TC 19
Z9 20
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27895
EP 27917
DI 10.1007/s11042-018-6014-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500008
DA 2024-07-18
ER

PT J
AU Li, D
   Hu, DS
   Sun, YK
   Hu, YS
AF Li, Dan
   Hu, Disheng
   Sun, Yuke
   Hu, Yingsong
TI 3D scene reconstruction using a texture probabilistic grammar
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Texture probabilistic grammar; Semantic segmentation;
   Scene analysis; Dynamic programming
ID PARALLEL FRAMEWORK; CALIBRATION; FEATURES; OBJECT
AB In this paper, texture probabilistic grammar is defined for the first time. We have developed an algorithm to obtain the 3D information in a 2D scene by training the texture probabilistic grammar from the prebuilt model library. The well-trained texture probabilistic grammar could also be applied to 3D reconstruction. Our detailed process contains: dividing the 2D scene into texture fragments; assigning the most suitable 3D object label to the 2D texture fragments; using our texture probabilistic grammar to predict 3D information of the texture fragments in 2D scene image; constructing the 3D model of the original 2D scene image. Through experiments, it is proved that the algorithm has a better effect on reconstruction of indoor scenes and building structures, and the algorithm is superior to the traditional reconstruction method based on point clouds. Different datasets and reconstructed objects are tested, which verifies the robustness of the algorithm. As a result, our algorithm is able to deal with the large numbers of scenes with similar semantics and it is also fast enough to deal with the online 3D reconstruction.
C1 [Li, Dan; Hu, Disheng; Sun, Yuke; Hu, Yingsong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Sun, YK (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM yukesun@hust.edu.cn
FU National Natural Science Foundation of China [61502185]; Fundamental
   Research Funds for the Central Universities [2017KFYXJJ071]
FX This work is supported by National Natural Science Foundation of China
   (No. 61502185) and the Fundamental Research Funds for the Central
   Universities (No: 2017KFYXJJ071).
CR Ahmed MT, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P231
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2015, ARXIV150500171
   AUDRAS C, 2011, AUSTR C ROB AUT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12693
   Campen M, 2012, EUROGRAPHICS
   Chang Angel X., 2015, arXiv
   Chaudhuri S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866205
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Couprie C., 2013, ARXIV13013572, P1
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fraser CS, 1997, ISPRS J PHOTOGRAMM, V52, P149, DOI 10.1016/S0924-2716(97)00005-1
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Guillou E, 2010, VISUAL COMPUT, V16, P396
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Hong W, 2004, INT J COMPUT VISION, V60, P241, DOI 10.1023/B:VISI.0000036837.76476.10
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Hu G, 2012, IEEE INT C INT ROBOT, P1714, DOI 10.1109/IROS.2012.6386103
   Jiang NJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618459
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Kato Hiroharu, 2017, ARXIV171107566
   Kim VG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461933
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liebowitz D, 1999, COMPUT GRAPH FORUM, V18, pC39, DOI 10.1111/1467-8659.00326
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Orghidan R, 2014, MACH VISION APPL, V25, P489, DOI 10.1007/s00138-013-0517-x
   Rashidi A, 2013, ADV ENG INFORM, V27, P270, DOI 10.1016/j.aei.2013.01.002
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Seo Y. H., 2008, SPOIE OPT ENG, V47, P525
   Shi YF, 2016, COMPUT GRAPH-UK, V55, P55, DOI 10.1016/j.cag.2015.11.003
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Socher R., 2012, NIPS, V3, P8
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Vanegas CA, 2010, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.2010.5540190
   Wilczkowiak M, 2005, IEEE T PATTERN ANAL, V27, P194, DOI 10.1109/TPAMI.2005.40
   Wu JJ, 2016, LECT NOTES COMPUT SC, V9910, P365, DOI 10.1007/978-3-319-46466-4_22
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Z, 2017, IEEE INT PERF COMP C
   Yu K, 2010, ECCV
NR 54
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28417
EP 28440
DI 10.1007/s11042-018-6052-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500028
DA 2024-07-18
ER

PT J
AU Sun, MJ
   Zhou, ZQ
   Zhang, D
   Wang, Z
AF Sun, Meijun
   Zhou, Ziqi
   Zhang, Dong
   Wang, Zheng
TI Hybrid convolutional neural networks and optical flow for video visual
   attention prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Optical flow; Spatial temporal feature;
   Visual attention
ID SALIENCY DETECTION; FRAMEWORK; EFFICIENT
AB In this paper, a convolutional neural networks (CNN) and optical flow based method is proposed for prediction of visual attention in the videos. First, a deep-learning framework is employed to extract spatial features in frames to replace those commonly used handcrafted features. The optical flow is calculated to obtain the temporal feature of the moving objects in video frames, which always draw audiences' attentions. By integrating these two groups of features, a hybrid spatial temporal feature set is obtained and taken as the input of a support vector machine (SVM) to predict the degree of visual attention. Finally, two publicly available video datasets were used to test the performance of the proposed model, where the results have demonstrated the efficacy of the proposed approach.
C1 [Sun, Meijun; Zhou, Ziqi] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Zhang, Dong] Tianjin Univ Tradit Chinese Med, Inst Tradit Chinese Med, Tianjin, Peoples R China.
   [Wang, Zheng] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University of Traditional Chinese Medicine;
   Tianjin University
RP Wang, Z (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
EM wzheng@tju.edu.cn
RI wang, zheng/C-7204-2009
FU National Natural Science Foundation, China [61572351, 61772360]
FX The authors wish to acknowledge the support from the National Natural
   Science Foundation, China, under the grants [61572351] and [61772360].
CR [Anonymous], IEEE C COMP VIS PATT
   BAK C, 2016, ARXIV160704730
   Baluja S., 1994, P ADV NEUR INF PROC, P451
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Berg DJ, 2009, J VISION, V9, DOI 10.1167/9.5.19
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cui Xinyi, 2009, P 17 ACM INT C MULT, P617, DOI DOI 10.1145/1631272.1631370
   Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Han JW, 2014, NEUROCOMPUTING, V145, P140, DOI 10.1016/j.neucom.2014.05.049
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Liu D, 2013, IEEE 7 INT C SEM COM
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Lu XQ, 2013, NEUROCOMPUTING, V106, P12, DOI 10.1016/j.neucom.2012.09.014
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Maioli C, 2001, EUR J NEUROSCI, V13, P364, DOI 10.1046/j.1460-9568.2001.01381.x
   Milanese  R., 1993, THESIS
   Muhl C, 2007, LECT NOTES ARTIF INT, V4667, P264
   Ni Q, 2014, INT JOINT C NEUR NET
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren J, 2010, IET IMAGE PROCESS, V4, P294, DOI 10.1049/iet-ipr.2009.0071
   Ren JC, 2007, SIGNAL PROCESS, V87, P541, DOI 10.1016/j.sigpro.2006.06.013
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Vig E, 2012, IEEE T PATTERN ANAL, V34, P1080, DOI 10.1109/TPAMI.2011.198
   Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519
   Wang N, 2013, P ADV NEURAL INFORM
   Wang W., 2017, DEEP LEARNING VIDEO
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wu Z, 2016, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-40991-7
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zabalza J, 2015, IEEE T GEOSCI REMOTE, V53, P4418, DOI 10.1109/TGRS.2015.2398468
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhong S. H., 2013, AAAI
NR 58
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29231
EP 29244
DI 10.1007/s11042-018-5793-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800003
DA 2024-07-18
ER

PT J
AU Wu, L
   Zhu, XF
   Tong, T
AF Wu, Lin
   Zhu, Xiaofeng
   Tong, Tao
TI Global and local clustering with kNN and local PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE k nearest neighbor; Local PCA; Spectral clustering
ID FEATURE-SELECTION; SPARSE; REGRESSION; IMAGE
AB This paper proposes a new clustering method that combines the k Near Neighbor (kNN) method and the local Principal Component Analysis (PCA) to consider the global and local information of data points for clustering. Specifically, we propose firstly preserving the local information of samples using the kNN method to obtain a neighborhood subset and a covariance matrix for each data point, and then preserving the global information of the data by conducting the local PCA on each covariance matrix to obtain a binary affinity matrix of the data. Furthermore, our method conducts clustering on the resulting affinity matrix without the assignment of clustering number. Experimental analysis on 8 UCI benchmark datasets showed that our proposed method outperformed the state-of-the-art clustering methods in terms of clustering performance.
C1 [Wu, Lin; Zhu, Xiaofeng; Tong, Tao] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zhu, Xiaofeng] Massey Univ, Inst Nat & Math Sci, Auckland 0745, New Zealand.
C3 Guangxi Normal University; Massey University
RP Zhu, XF (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Zhu, XF (corresponding author), Massey Univ, Inst Nat & Math Sci, Auckland 0745, New Zealand.
EM seanzhuxf@gmail.com
RI Zhu, Xiaofeng/HII-5291-2022; Wu, Lin/GOE-3613-2022
OI Zhu, Xiaofeng/0000-0001-6840-0578; Wu, Lin/0000-0002-3188-0640
FU China Key Research Program [2016YFB1000905]; Natural Science Foundation
   of China [61573270, 61672177]; Project of Guangxi Science and Technology
   [GuiKeAD17195062]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; Guangxi
   High Institutions Program of Introducing 100 High-Level Overseas
   Talents; Research Fund of Guangxi Key Lab of Multisource Information
   Mining Security [18-A-01-01]
FX This work is partially supported by the China Key Research Program
   (Grant No: 2016YFB1000905); the Natural Science Foundation of China
   (Grants No: 61573270 and 61672177); the Project of Guangxi Science and
   Technology (GuiKeAD17195062); the Guangxi Natural Science Foundation
   (Grant No: 2015GXNSFCB139011); the Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing; the Guangxi High Institutions Program of Introducing 100
   High-Level Overseas Talents; and the Research Fund of Guangxi Key Lab of
   Multisource Information Mining & Security (18-A-01-01).
CR [Anonymous], IEEE T KNOWLEDGE DAT
   Arias-Castro E, 2017, J MACH LEARN RES, V18, P1
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, DOI DOI 10.1016/J.PMCJ.2015.02.001
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chen YS, 2007, ICCV, P446
   Deng X., 2018, MULTIMED TOOLS APPL, P1
   Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fayed HA, 2009, NOVEL TEMPLATE REDUC
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Goldberg AB, 2010, YNH LR ARFAL NLLGN M, V5, P169
   Gong D, 2012, ROBUST MULTIPLE MANI, P25
   Góra G, 2002, LECT NOTES ARTIF INT, V2430, P111
   Hagen L., 1991, 1991 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (91CH3026-2), P10, DOI 10.1109/ICCAD.1991.185177
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Luo DJ, 2011, LECT NOTES ARTIF INT, V6912, P405, DOI 10.1007/978-3-642-23783-6_26
   Meila Marina., 2003, MULTIWAY CUTS SPECTR
   Nie F., 2016, P 25 INT JOINT C ART, P1874
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114
   Shen F, 2018, UNSUPERVISED DEEP HA, DOI [10.1109/TPAMI.2018.2789887, DOI 10.1109/TPAMI.2018.2789887]
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song JK, 2016, IEEE T MULTIMEDIA, V18, P484, DOI 10.1109/TMM.2016.2515990
   Song Y, 2007, LECT NOTES ARTIF INT, V4702, P248
   Wang S., 2011, AAAI, V1, P519
   Wang Y, 2011, IEEE T NEURAL NETWOR, V22, P1149, DOI 10.1109/TNN.2011.2147798
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang Y, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026018
   Zhang Y, 2012, BIOMED SIGNAL PROCES, V7, P104, DOI 10.1016/j.bspc.2011.02.002
   Zhao J, 2017, PATTERN RECOGN ART C, V205, P22
   Zheng Q, 2016, CHIN CONT DECIS CONF, P1981, DOI 10.1109/CCDC.2016.7531308
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Yingying, 2017, Med Image Comput Comput Assist Interv, V10435, P205, DOI 10.1007/978-3-319-66179-7_24
   Zhu YY, 2017, LECT NOTES COMPUT SC, V10265, P158, DOI 10.1007/978-3-319-59050-9_13
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 54
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29727
EP 29738
DI 10.1007/s11042-018-6488-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800030
DA 2024-07-18
ER

PT J
AU Banharnsakun, A
AF Banharnsakun, Anan
TI Artificial bee colony approach for enhancing LSB based image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Steganography; Least Significant Bit (LSB); Artificial Bee Colony
   (ABC); Data Hiding
ID HIDING DATA
AB The development of the internet offers the ability to transmit large amounts of data quite conveniently via networks. However, sensitive data in transmission can easily be intercepted by unknown persons or hackers on the internet. Steganography techniques are thus needed to protect the information being transmitted over the internet. In this paper, a new efficient method based on the artificial bee colony (ABC) approach is proposed to enhance LSB based image steganography. The ABC is employed to optimize the block assignment for embedding a secret image into a host image. However, this block assignment is considered as a combinatorial optimization problem, but the ordinary ABC algorithm is designed to solve numerical optimization problems. A block assignment list, which is used to represent the solutions in the ABC algorithm, is thus introduced and the solution updating process in the ABC based on the block assignment list is also presented in this work. Experimental results demonstrate that the stego image obtained by the proposed method is not only of good quality, but is also able to tolerate certain noise attacks when compared with other recent data hiding techniques in the spatial domain. In addition, the advantage of this proposed method is that it embeds the corresponding block of a secret image into each block of the host image with permutation. Thus, the secret image cannot be recovered from the stego image without knowing this permutation.
C1 [Banharnsakun, Anan] Kasetsart Univ, Fac Engn Sriracha, Dept Comp Engn, Computat Intelligence Res Lab CIRLab, Sriracha Campus, Chon Buri 20230, Thailand.
C3 Kasetsart University
RP Banharnsakun, A (corresponding author), Kasetsart Univ, Fac Engn Sriracha, Dept Comp Engn, Computat Intelligence Res Lab CIRLab, Sriracha Campus, Chon Buri 20230, Thailand.
EM ananb@ieee.org
RI Banharnsakun, Anan/A-7608-2016
OI Banharnsakun, Anan/0000-0003-2004-4070
FU Faculty of Engineering at Sriracha, Kasetsart University Sriracha Campus
   [2560/1]
FX This work is partially supported by the Faculty of Engineering at
   Sriracha, Kasetsart University Sriracha Campus (2560/1).
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2000, Digital Watermarking
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Banharnsakun A, 2014, COMPUT INTEL NEUROSC, V2014, P7
   Banharnsakun A, 2017, PATTERN RECOGN LETT, V93, P78, DOI 10.1016/j.patrec.2016.07.027
   Banharnsakun A, 2017, INT J MACH LEARN CYB, V8, P699, DOI 10.1007/s13042-015-0471-1
   Banharnsakun A, 2012, IEEE SYS MAN CYBERN, P1610, DOI 10.1109/ICSMC.2012.6377967
   Banoci V., 2011, 21 INT C RAD EL, P1, DOI [10.1109/RADIOELEK.2011.5936455, DOI 10.1109/RADIOELEK.2011.5936455]
   Bedi P, 2013, COMPUT ELECTR ENG, V39, P640, DOI 10.1016/j.compeleceng.2012.12.021
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chandramouli R., 2003, International Workshop on Digital Watermarking, P35
   Chanu Yambem Jina, 2012, 2012 3rd National Conference on Emerging Trends and Applications in Computer Science (NCETACS), P52, DOI 10.1109/NCETACS.2012.6203297
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen Yuefen, 2010, 2010 International Conference on Computer and Communication Technologies in Agriculture Engineering (CCTAE 2010), P308, DOI 10.1109/CCTAE.2010.5544569
   Ching-Sheng Hsu, 2010, Proceedings of the Second International Conference on Communication Software and Networks (ICCSN 2010), P293, DOI 10.1109/ICCSN.2010.61
   Forczmanski Pawel, 2009, Elektronika, V50, P60
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Nickfarjam A. M., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P360, DOI 10.1109/AISP.2012.6313773
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wegrzyn M., 2011, VIRTUAL STEGANOGRAPH
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yu YH, 2007, COMPUT VIS IMAGE UND, V107, P183, DOI 10.1016/j.cviu.2006.11.002
NR 30
TC 19
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27491
EP 27504
DI 10.1007/s11042-018-5933-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500056
DA 2024-07-18
ER

PT J
AU Mozaffari, S
AF Mozaffari, Saeed
TI Parallel image encryption with bitplane decomposition and genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel image encryption; Bitplain decomposition; Local binary pattern;
   Metaheuristic algorithms; Parallel genetic algorithm; GPU programming
ID CHAOS; TRANSFORM; SCHEME
AB Image encryption is an efficient technique to protect image content from unauthorized parties. In this paper a parallel image encryption method based on bitplane decomposition is proposed. The original grayscale image is converted to a set of binary images by local binary pattern (LBP) technique and bitplane decomposition (BPD) methods. Then, permutation and substitution steps are performed by genetic algorithm (GA) using crossover and mutation operations. Finally, these scrambled bitplanes are combined together to obtain encrypted image. Instead of random population selection in GA, a deterministic method with security keys is utilized to improve security level. The proposed encryption method has parallel processing capability for multiple bitplanes encryption. This distributed GA with multiple populations increases encryption speed and makes it suitable for real-time applications. Simulations and security analysis are done to demonstrate efficiency of our algorithm.
C1 [Mozaffari, Saeed] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Mozaffari, S (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM mozaffari@semnan.ac.ir
OI zy, P/0009-0006-2820-8788
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   [Anonymous], Introduction to genetic algorithms
   Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen TH, 2012, INFORM SCIENCES, V189, P255, DOI 10.1016/j.ins.2011.11.026
   Daemen J., 1999, AES proposal: Rijndael
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Engel D, 2008, IEEE T INF FOREN SEC, V3, P173, DOI 10.1109/TIFS.2008.922058
   Faraoun KM, 2014, EXPERT SYST APPL, V41, P7958, DOI 10.1016/j.eswa.2014.06.048
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Han JW, 1999, OPT ENG, V38, P47, DOI 10.1117/1.602060
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li J, 2018, MATH COMPUT SIMULAT, V143, P114, DOI 10.1016/j.matcom.2016.07.011
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Machicao J, 2017, CHAOS, V27, P5
   Moon D, 2006, ETRI J, V28, P444, DOI 10.4218/etrij.06.0106.0013
   National Institute of Standards and Technology Data encryption standard (DES), 1999, DAT ENCR STAND DES
   Park M, 2015, MICROELECTRON J, V46, P1364, DOI 10.1016/j.mejo.2015.09.015
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shen XJ, 2016, APPL OPTICS, V55, P8513, DOI 10.1364/AO.55.008513
   Taheri M, 2012, ISECURE-ISC INT J IN, V4, P115
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   Talbi E.-G, 2009, METAHEURISTICS DESIG, V74, DOI DOI 10.1002/9780470496916
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wang XY, 2012, NONLINEAR DYNAM, V70, P1589, DOI 10.1007/s11071-012-0558-0
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Yuan S, 2018, OPT LASER ENG, V100, P105, DOI 10.1016/j.optlaseng.2017.07.015
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang YP, 2017, BIOSYSTEMS, V159, P51, DOI 10.1016/j.biosystems.2017.07.002
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 43
TC 45
Z9 45
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25799
EP 25819
DI 10.1007/s11042-018-5817-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400050
DA 2024-07-18
ER

PT J
AU Purificato, E
   Rinaldi, AM
AF Purificato, Erasmo
   Rinaldi, Antonio M.
TI Multimedia and geographic data integration for cultural heritage
   information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Geographic information retrieval;
   Multimodal query; Digital cultural heritage
ID IMAGE RETRIEVAL; COLOR
AB In this paper a system providing an efficient integration between Content-Based Image Retrieval (CBIR) and Geographic Information Retrieval (GIR) is presented. Over the years, many CBIR systems have been proposed to give a solution for an efficient use of multimedia/visual contents and other issues as performance, quality of retrieval, data heterogeneity, and multimodal information integration. The aim of the proposed approach is to prove that the use of geographic data can improve the results obtained by an image matching system based only on visual data. Our framework is composed of three parts, each of them described in detail in this paper: the first part is dedicated to CBIR, with an experimental comparison of a large number of different multimedia features to choose the one to use in the system implementation; in the second part the methodology to integrate geographic and multimedia data is showed; in the last part is presented a GIR system implementation using a "points of interest" search. An Android application has been developed for the client-side using Apache Solr as server side provider for the information retrieval functionalities. An experimental evaluation is carried out to demonstrate the effective improvement given by the combination of geographic and multimedia data. Our results have been obtained using a real dataset composed of artworks located in Naples's museums.
C1 [Purificato, Erasmo; Rinaldi, Antonio M.] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
C3 University of Naples Federico II
RP Rinaldi, AM (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
EM erasmopurif@gmail.com; antoniomaria.rinaldi@unina.it
RI Purificato, Erasmo/HKF-7484-2023; Rinaldi, Antonio M./O-7452-2019
OI Purificato, Erasmo/0000-0002-5506-3020; Rinaldi, Antonio
   M./0000-0001-7003-4781
CR Adams B, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P12, DOI 10.1145/2736277.2741137
   Agnello F., 2003, INT ARCH PHOTOGRAMM, V34, P7
   Ai LF, 2013, J ZHEJIANG U-SCI C, V14, P505, DOI 10.1631/jzus.CIDE1304
   Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   [Anonymous], 9 INT WORKSH IM AN M
   Basanth Kumar HB, 2015, OVERVIEW CONTENT BAS
   Bhatti A., 2014, SCI INT, V26, P1
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chatzichristofis S., 2009, Proc. ofthe 6th IASTED International Conference, V134643, page, P064
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, MULTIMED TOOLS APPL, V46, P493, DOI 10.1007/s11042-009-0349-x
   Chen CC, 2005, INT J DIGIT LIBRARIE, V5, P275, DOI 10.1007/s00799-004-0097-5
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Vries AP, 2004, IEEE IMAGE PROC, P2387
   Deselaers T, 2005, LECT NOTES COMPUT SC, V3491, P688
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Frederix G, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P222
   Fu RG, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P638, DOI 10.1109/CompComm.2016.7924779
   Giuca AM, 2012, IEEE IMAGE PROC, P2397, DOI 10.1109/ICIP.2012.6467380
   Golubovic Nevena, 2016, P 10 WORKSH GEOGR IN, DOI 10.1145/3003464.3003468
   Hariharan Ramaswamy, 2007, 2007 International Conference on Scientific and Statistical Database Management, DOI 10.1109/SSDBM.2007.22
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Iqbal Q., 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P205
   Irtaza A, 2015, MULTIMED TOOLS APPL, V74, P5055, DOI 10.1007/s11042-013-1679-2
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Karamti H., 2017, MULTIMEDIA TOOLS APP, P1
   Kim J, 2017, INT J GEOGR INF SCI, V31, P56, DOI 10.1080/13658816.2016.1188930
   Koolen M, 2009, INTERDISCIPL SCI REV, V34, P268, DOI 10.1179/174327909X441153
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Larson RR, 1996, 1995 CLIN LIB APPL D
   Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010
   Liew CL, 2005, PROGRAM-ELECTRON LIB, V39, P4, DOI 10.1108/00330330510578778
   Longley P. A., 2005, Geographic Information Systems and Science
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maliene V, 2011, URBAN DES INT, V16, P1, DOI 10.1057/udi.2010.25
   Mark D.M., 2003, Foundations of Geographic Information Science, P3
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Ng J. Y.-H., 2015, arXiv:1504.05133
   Ohm J.-R., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P2
   Rasuli B, 2017, WEB GEOGRAPHIC INFOR
   Rinaldi Antonio M., 2011, International Journal of Knowledge and Web Intelligence, V2, P231, DOI 10.1504/IJKWI.2011.045162
   Rinaldi AM, 2014, INFORM SCIENCES, V277, P234, DOI 10.1016/j.ins.2014.02.017
   Shete D.S., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P85
   Shyu CR, 2007, IEEE T GEOSCI REMOTE, V45, P839, DOI 10.1109/TGRS.2006.890579
   Siggelkow S., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P9
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Squire D, 1998, CONTENT BASED QUERY
   Stanchev P., 2012, ACCESS TO DIGITAL CU
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tsai CF, 2007, ONLINE INFORM REV, V31, P185, DOI 10.1108/14684520710747220
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Zaila YL, 2017, THESIS
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 60
TC 14
Z9 15
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27447
EP 27469
DI 10.1007/s11042-018-5931-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500054
DA 2024-07-18
ER

PT J
AU Xiao, F
   Huang, KJ
   Qiu, Y
   Shen, HB
AF Xiao, Feng
   Huang, Kejie
   Qiu, Yue
   Shen, Haibin
TI Accurate iris center localization method using facial landmark,
   snakuscule, circle fitting and binary connected component
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris centers; Facial landmark; Snakuscule; Circle fitting; Binary
   connected component
AB Iris centers have been widely used in machine vision for face matching, gaze estimation, etc. However, in low resolution eye images, the iris and its surrounding region present a variety of appearance characteristics, which make it difficult to accurately locate the iris center. In this paper, we propose a robust, accurate and real-time iris center localization method by combining the facial landmark, snakuscule, circle fitting and binary connected component. Facial landmarks are used to extract an accurate eye Region of Interest (ROI). Thereafter, a fixed size circle-based active contour snakuscule is used to detect the iris center. Based on the snakuscule center and inner radius, a novel method is proposed to extract accurate iris edges for circle fitting. In addition, the quality of the detected iris center is evaluated by a circle-binary quality evaluation method. Binary connected component method is used to improve the accuracies in those unqualified images. The proposed method is tested on three publicly available databases BioID, GI4E and Talking Face Video. The result shows that it could achieve an accuracy of 94.35% on the BioID database when the normalized error is smaller than 0.05, which outperforms all state-of-the-art methods.
C1 [Xiao, Feng; Huang, Kejie; Qiu, Yue; Shen, Haibin] Zhejiang Univ, Inst VLSI Design, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Huang, KJ (corresponding author), Zhejiang Univ, Inst VLSI Design, Hangzhou 310027, Zhejiang, Peoples R China.
EM huangkejie@zju.edu.cn
RI , 黄科杰/J-5919-2019; Huang, Kejie/E-7511-2018
OI Huang, Kejie/0000-0003-3722-9979
CR Ahuja K, 2016, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2016.7532934
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], 2001, PROC IEEE COMPUT SOC
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   Cai HB, 2016, LECT NOTES COMPUT SC, V9834, P300, DOI 10.1007/978-3-319-43506-0_26
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Dongheng L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P79
   Garg S., 2016, INT J INF SECUR, P1
   Gou C, 2016, INT C PATT RECOG, P3362, DOI 10.1109/ICPR.2016.7900153
   Han ZC, 2014, MULTIMED TOOLS APPL, V68, P931, DOI 10.1007/s11042-012-1090-4
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Jaehan Koh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2852, DOI 10.1109/ICPR.2010.699
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kim ST, 2015, I SYMP CONSUM ELECTR
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Kyung-Nam Kim, 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P324, DOI 10.1109/ICSMC.1999.825279
   Laddi A, 2017, MULTIMED TOOLS APPL, V76, P7129, DOI 10.1007/s11042-016-3361-y
   Li YT, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3178
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Newman R., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P122, DOI 10.1109/AFGR.2000.840622
   Taghizadeh M, 2011, J MATH COMPUT SCI-JM, V2, P255
   Thévenaz P, 2008, IEEE T IMAGE PROCESS, V17, P585, DOI 10.1109/TIP.2007.914742
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Villanueva A, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501647
   Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136
   Wojciechowski A, 2015, B POL ACAD SCI-TECH, V63, P879, DOI 10.1515/bpasts-2015-0100
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zhang C., 2014, 2014 IEEE INT C MULT, P1
   Zhang W, 2011, OPT ENG, V50, DOI 10.1117/1.3562327
   Zhang WH, 2016, J OPT SOC AM A, V33, P314, DOI 10.1364/JOSAA.33.000314
   Zhao YF, 2016, Adv Inform Managemen, P988, DOI 10.1109/IMCEC.2016.7867358
   Zhou MC, 2015, IEEE IMAGE PROC, P4466, DOI 10.1109/ICIP.2015.7351651
NR 42
TC 7
Z9 10
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25333
EP 25353
DI 10.1007/s11042-018-5787-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400033
DA 2024-07-18
ER

PT J
AU Abouelaziz, I
   El Hassouni, M
   Cherifi, H
AF Abouelaziz, Ilyass
   El Hassouni, Mohammed
   Cherifi, Hocine
TI Blind 3D mesh visual quality assessment using support vector regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind mesh quality assessment; Support vector regression; Dihedral
   angles; Statistical distributions; Visual masking effect; Human visual
   system; Mean opinion score
ID METRICS; ERROR; COMPRESSION
AB Various visual distortions can inevitably affect the 3D meshes during their transmission and geometrical processing. In most practical cases, blind quality assessment becomes a challenging issue due to the unavailability of reference meshes and distortion related information. In this paper, we present a novel method to blindly assess the quality of 3D meshes. This method relies on a feature learning based approach to predict the objective quality scores. For this, we propose the mesh dihedral angles statistics as a feature and the support vector regression (SVR) as a learning tool based quality predictor. The proposed method takes into account the main functions of the human visual system (HVS) by introducing the visual masking and the saturation effects. Experiments have been successfully conducted on LIRIS/EPFL general-purpose, LIRIS Masking and UWB compression databases. The obtained results show that the proposed method provides good correlation and competitive scores comparing to some influential and effective full and reduced reference existing methods.
C1 [Abouelaziz, Ilyass; El Hassouni, Mohammed] Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT CNRST,URAC 29, Rabat, Morocco.
   [El Hassouni, Mohammed] Mohammed V Univ Rabat, FLSH, Rabat IT Ctr, LRIT CNRST,URAC 29, Rabat, Morocco.
   [Cherifi, Hocine] Univ Burgundy, UMR 6306, CNRS, LE2I, Dijon, France.
C3 Mohammed V University in Rabat; Mohammed V University in Rabat; Centre
   National de la Recherche Scientifique (CNRS); Universite de Bourgogne
RP Abouelaziz, I (corresponding author), Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT CNRST,URAC 29, Rabat, Morocco.
EM ilyass.abouelaziz@gmail.com; mohamed.elhassouni@gmail.com;
   hocine.cherifi@u-bourgogne.fr
RI El Hassouni, Mohammed/AAL-8452-2020; Cherifi, Hocine/X-9376-2019
OI El Hassouni, Mohammed/0000-0002-6741-4799; Cherifi,
   Hocine/0000-0001-9124-4921
CR Abouelaziz I, 2016, LECT NOTES COMPUT SC, V9680, P369, DOI 10.1007/978-3-319-33618-3_37
   Alliez P, 2005, MATH VIS, P3, DOI 10.1007/3-540-26808-1_1
   [Anonymous], 2010, P INT WORKSH VID PRO
   [Anonymous], 2006, SPIE OPTICS PHOTONIC
   [Anonymous], ADV COGN PSYCHOL
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   [Anonymous], 2003, S GEOM PROC
   [Anonymous], 2017, Electron Imaging
   [Anonymous], COMPUTER VISION GRAP
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Babu RV, 2007, SIGNAL PROCESS, V87, P1493, DOI 10.1016/j.sigpro.2006.12.014
   Bian Z, 2009, J COMPUT SCI TECH-CH, V24, P65, DOI 10.1007/s11390-009-9198-3
   Botsch M., 2010, Polygon Mesh Processing
   Bulbul A, 2011, IEEE SIGNAL PROC MAG, V28, P80, DOI 10.1109/MSP.2011.942466
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Corsini M, 2013, COMPUT GRAPH FORUM, V32, P101, DOI 10.1111/cgf.12001
   Corsini M, 2007, IEEE T MULTIMEDIA, V9, P247, DOI 10.1109/TMM.2006.886261
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gastaldo P, 2005, SIGNAL PROCESS-IMAGE, V20, P643, DOI 10.1016/j.image.2005.03.013
   Gastaldo P, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1988313
   Gelasca E. D., 2005, IEEE INT C IM PROC, P241
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Lavoué G, 2016, IEEE T VIS COMPUT GR, V22, P1987, DOI 10.1109/TVCG.2015.2480079
   Lavoué G, 2011, COMPUT GRAPH FORUM, V30, P1427, DOI 10.1111/j.1467-8659.2011.02017.x
   Lavoué G, 2010, IEEE T MULTIMEDIA, V12, P636, DOI 10.1109/TMM.2010.2060475
   Lavoué G, 2009, ACM T APPL PERCEPT, V5, DOI 10.1145/1462048.1462052
   Lee H, 2011, VISUAL COMPUT, V27, P781, DOI 10.1007/s00371-011-0586-7
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Lin WS, 2012, IEEE J-STSP, V6, P614, DOI 10.1109/JSTSP.2012.2215433
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Luebke DP, 2001, IEEE COMPUT GRAPH, V21, P24, DOI 10.1109/38.920624
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narwaria M, 2010, IEEE T NEURAL NETWOR, V21, P515, DOI 10.1109/TNN.2010.2040192
   Pan YX, 2005, IEEE T MULTIMEDIA, V7, P269, DOI 10.1109/TMM.2005.843364
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Torkhani F., 2014, Machine Graphics Vision, V23, P59
   Vapnik V., 2013, The nature of statistical learning theory
   Vása L, 2012, COMPUT GRAPH FORUM, V31, P1715, DOI 10.1111/j.1467-8659.2012.03176.x
   Wang K, 2012, COMPUT GRAPH-UK, V36, P808, DOI 10.1016/j.cag.2012.06.004
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wang YP, 2009, IEEE T VIS COMPUT GR, V15, P285, DOI 10.1109/TVCG.2008.101
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
NR 44
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24365
EP 24386
DI 10.1007/s11042-018-5706-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900057
DA 2024-07-18
ER

PT J
AU Guo, YN
   Gao, XL
   Yang, Z
   Lian, J
   Du, SQ
   Zhang, HQ
   Ma, YD
AF Guo, Ya'nan
   Gao, Xiaoli
   Yang, Zhen
   Lian, Jing
   Du, Shiqiang
   Zhang, Huaiqing
   Ma, Yide
TI SCM-motivated enhanced CV model for mass segmentation from
   coarse-to-fine in digital mammography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammography; Mass segmentation; Spiking Cortical Model (SCM); Enhanced
   CV model; Local Region-Scalable Force (LRSF)
ID LEVEL SET METHOD; IMAGE SEGMENTATION; TRANSFORM; ALGORITHM
AB A novel approach for mass segmentation from coarse-to-fine in digital mammography, termed as SCM-motivated enhanced CV algorithm, is presented in this paper. As well known, it is difficult to robustly achieve mammogram mass segmentation due to low contrast between normal and lesion tissues, as well as high density tissue interference in mammograms. Therefore, Spiking Cortical Model with biology background is introduced to achieve mammary-specific and mass edge detection, and this mass candidate is regarded as the initial contour of improved CV model followed by, effectively overcoming the drawback that CV method is sensitive to the initial contour; especially, the enhanced CV model innovatively combines the techniques of physical imaging principle, and local region-scalable force, harvesting the coarse-to-fine mass boundary accurately. The proposed method is tested totally on 400 mammograms from two well-known digitized datasets (digital database for screening mammography and mammography image analysis society database), achieving the average detection rate of 93.25%. By comparing with the region-based model with bias field (Method 1) and typical CV model (Method 2), we can reach the conclusion that proposed method is outperform other methods, yielding the average sensitivity of 95.83%, specificity of 99.13%, dice similarity co-efficient of 92.21% and AUC of 98.02%. In addition, this method is verified on the mammograms from Gansu Provincial Cancer Hospital, the detection results reveal that our method can accurately detect the abnormal in clinical application.
C1 [Guo, Ya'nan; Gao, Xiaoli; Yang, Zhen; Lian, Jing; Du, Shiqiang; Zhang, Huaiqing; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
EM yidema@gmail.com
RI Yang, Zhen/GWQ-4960-2022; Guo, yanan/KPY-7899-2024; GAO,
   XIAO/JED-3257-2023
FU National Natural Science Foundation of China [61175012, 61201421];
   Natural Science Foundation of Gansu Province [145RJZA181, 1208RJZA265]
FX Authors would like to thank the retrieval of all the public database for
   the experiments of this paper. This study was funded by the National
   Natural Science Foundation of China (nos. 61175012 and 61201421) and
   Natural Science Foundation of Gansu Province (nos. 145RJZA181 and
   1208RJZA265).
CR Ali H, 2016, PATTERN RECOGN, V51, P27, DOI 10.1016/j.patcog.2015.08.022
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2017, AAAI
   Badshah N, 2012, E ASIAN J APPL MATH, V2, P150, DOI 10.4208/eajam.090312.190412a
   Berber T, 2013, COMPUT METH PROG BIO, V110, P150, DOI 10.1016/j.cmpb.2012.11.003
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang JY, 2016, IEEE T PATTERN ANAL, V38, P1612, DOI 10.1109/TPAMI.2016.2519021
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Silva LCD, 2017, ARTIF INTELL MED, V80, P29, DOI 10.1016/j.artmed.2017.07.003
   Dera D, 2016, B MATH BIOL, V78, P1450, DOI 10.1007/s11538-016-0190-0
   Eches O, 2010, HYPERSPECTRAL IMAGE, P1
   Edwards SD, 2013, MAGN RESON IMAGING C, V21, P483, DOI 10.1016/j.mric.2013.02.005
   Elter M, 2010, PHYS MED BIOL, V55, P5299, DOI 10.1088/0031-9155/55/18/004
   Faisal A., 2012, 2012 IEEE International Conference on Information Science and Technology, P18, DOI 10.1109/ICIST.2012.6221601
   Gao XL, 2015, LECT NOTES COMPUT SC, V9475, P664, DOI 10.1007/978-3-319-27863-6_62
   Guo YN, 2018, NEUROCOMPUTING, V275, P2179, DOI 10.1016/j.neucom.2017.10.057
   Guo YN, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023022
   Guo YN, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P786, DOI [10.1109/CSCI.2016.0153, 10.1109/CSCI.2016.152]
   Guo YN, 2016, COMPUT METH PROG BIO, V130, P31, DOI 10.1016/j.cmpb.2016.02.019
   Hsu WY, 2012, EXPERT SYST APPL, V39, P3950, DOI 10.1016/j.eswa.2011.08.148
   Jemal A., 2011, CA-CANCER J CLIN, V61, P69, DOI DOI 10.3322/CAAC.20107
   Jun Liu, 2011, Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence. 7th International Conference, ICIC 2011. Revised Selected Papers, P502, DOI 10.1007/978-3-642-25944-9_65
   Kim DH, 2015, COMPUT BIOL MED, V63, P238, DOI 10.1016/j.compbiomed.2014.09.006
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu CC, 2012, COMPUT MATH APPL, V64, P1100, DOI 10.1016/j.camwa.2012.03.028
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Lu X, 2015, EMERG ING TRENDS IMA, P201
   Ma Yi-de, 2012, Journal of University of Electronic Science and Technology of China, V41, P754, DOI 10.3969/j.issn.1001-0548.2012.05.022
   Niu SJ, 2016, BIOMED OPT EXPRESS, V7, P581, DOI 10.1364/BOE.7.000581
   Panetta K, 2011, IEEE T INF TECHNOL B, V15, P918, DOI 10.1109/TITB.2011.2164259
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Salmeri M, 2009, IEEE INT WORK MED ME, P160, DOI 10.1109/MEMEA.2009.5167976
   Solem JE, 2006, INT C PATT RECOG, P171
   Timp S, 2007, IEEE T MED IMAGING, V26, P945, DOI 10.1109/TMI.2007.897392
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wei K., 2006, 2005 IEEE ENG MED BI, P6500
   Wu Y.-Q., 2011, T TIANJIN U, V17, P215
   Xia RB, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P411, DOI 10.1109/ICAL.2007.4338597
   Xie WY, 2016, OPTIK, V127, P1644, DOI 10.1016/j.ijleo.2015.09.250
   Xu SZ, 2011, J DIGIT IMAGING, V24, P754, DOI 10.1007/s10278-011-9365-2
   Zhan K, 2017, ARCH COMPUT METHOD E, V24, P573, DOI 10.1007/s11831-016-9182-3
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
NR 49
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24333
EP 24352
DI 10.1007/s11042-018-5685-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900055
DA 2024-07-18
ER

PT J
AU Pal, K
   Govil, MC
   Ahmed, M
AF Pal, Kunwar
   Govil, Mahesh Chandra
   Ahmed, Mushtaq
TI Priority-based scheduling scheme for live video streaming in
   peer-to-peer network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer network; Live video streaming; Scheduling schemes; Resource
   utilization
ID PUSH
AB The P2P networks play a crucial role in communication and data transfer. During recent years the importance of P2P network is increasing due to its scalability and an easy cost-efficient model. From the last few years, a P2P network has also been playing a significant role in real-time data transmission. The features offered by P2P network for video on demand/ live video streaming are getting popular day by day. The key factors which affect the performance of the P2P network are Scheduling and Overlay. Scheduling schemes like push-based, pull-based scheduling schemes that can be further classified into FCFS, rarity based and deadline based scheduling schemes are not sufficient to fulfill the demand of P2P network. So in this paper, we have defined two new scheduling schemes which overcome the shortcomings of the existing schemes. These are priority based scheduling schemes which calculate the priority by combining the different factors which directly affect the performance of a network. This approach is a combination of priority based chunk selection and bandwidth aware peer selection mechanism, which improves the delay between the peers. A comparative analysis of the new priority-based scheduling scheme is done with previous approaches. The simulation results are shown in this paper verify the approach and depict that performance of network and quality of video receiver is improved with the use of priority based scheduling scheme. Performance analysis of scheduling schemes is evaluated using parameters like startup delay, end-to-end delay, playback delay, and frame redundancy, and for the quality of video the distortion, frame loss ratio of video parameter is used.
C1 [Pal, Kunwar; Ahmed, Mushtaq] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Govil, Mahesh Chandra] Natl Inst Technol Sikkim, Ravangla, Sikkim, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; National Institute of Technology (NIT
   System); National Institute of Technology Sikkim
RP Pal, K (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM kunwar.11mar@gmail.com; govilmc@gmail.com; mahmed.cse@mnit.ac.in
RI Ahmed, Mushtaq/GSN-9818-2022; PAL, KUNWAR/A-5785-2019
OI PAL, KUNWAR/0000-0001-9482-696X; AHMED, MUSHTAQ/0000-0002-7576-2531
CR [Anonymous], 2011, VTC FALL 2011
   Awiphan S, 2010, 2010 7 IEEE CONS COM, P1
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Bideh MK, 2016, PEER PEER NETW APPL, V9, P436, DOI 10.1007/s12083-015-0355-x
   Bouten N, 2015, COMPUT NETW, V81, P96, DOI 10.1016/j.comnet.2015.02.007
   Byers JW, 2004, IEEE ACM T NETWORK, V12, P767, DOI 10.1109/TNET.2004.836103
   Byun H, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P840
   Chan Y.T., 2014, ELECT COMPUTER ENG C, P1, DOI [10.1109/ccece.2014. 6900968, DOI 10.1109/CCECE.2014.6900968]
   Efthymiopoulou M, 2016, PEER PEER NETW APPL, V9, P1162, DOI 10.1007/s12083-015-0403-6
   Fesci-Sayit M, 2009, IEEE IMAGE PROC, P945, DOI 10.1109/ICIP.2009.5414021
   Tran HTT, 2017, MULTIMED TOOLS APPL, V76, P2557, DOI 10.1007/s11042-016-3249-x
   Hammami C, 2014, PROCEDIA COMPUT SCI, V32, P158, DOI 10.1016/j.procs.2014.05.410
   Hao P, 2016, ADAPTIVE PACKET SCHE, P5
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Hobfeld T, 2008, INVESTIGATION CHUNK
   Huang S, 2015, 6 LAT AM C NETW EL M, P12
   Huang SL, 2016, IEEE T MULTIMEDIA, V18, P752, DOI 10.1109/TMM.2016.2530411
   Jannotti J., 2000, OSDI 00 P 4 C S OPER, P14
   Kao HH, 2016, J NETW COMPUT APPL, V60, P180, DOI 10.1016/j.jnca.2015.09.010
   Karayer E, 2016, MULTIMED TOOLS APPL, V75, P16039, DOI 10.1007/s11042-015-2912-y
   Keong CY, 2011, INT C PAR DISTRIB SY, P735, DOI 10.1109/ICPADS.2011.55
   Kim J, 2016, IEEE ACM T NETWORK, V24, P2319, DOI 10.1109/TNET.2015.2452272
   Li B, 2007, IEEE J SEL AREA COMM, V25, P1627, DOI 10.1109/JSAC.2007.071203
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Li Z, 2008, P 5 INT ICST C HET N, P13
   Liu L, 2015, RECOGNIZING COMPLEX, P1266
   Liu N, 2013, CLUSTER COMPUT, V16, P767, DOI 10.1007/s10586-013-0268-5
   Liu Y, 2012, ACTION2ACTIVITY RECO
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lo Cigno R, 2008, 2008 SECOND INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS, P66
   Lu Y., 2016, Multimedia Tools and Appl, P1
   Magharei N., 2006, P 2006 INT WORKSH NE, P10
   Magnetto A, 2010, IEEE T MULTIMEDIA, V12, P901, DOI 10.1109/TMM.2010.2077623
   Meskovic M, 2015, INT CONF SOFTW, P205, DOI 10.1109/SOFTCOM.2015.7314110
   Mol JJD, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P342, DOI 10.1109/ISM.2009.16
   Nen-Fu Huang, 2010, Proceedings of the 2010 International Conference on Communications and Mobile Computing (CMC 2010), P541, DOI 10.1109/CMC.2010.317
   Padmanabhan V, 2002, DISTRIBUTING STREAMI, P177
   Pal K, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P431, DOI 10.1109/ICACCI.2015.7275647
   Rejaie R., 2003, Proceedings of ACM International Workshop on Network and Operating Systems Support for Digital Audio and Video (NOSSDAV), P153
   Russo A, 2010, IEEE ICC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seyyedi S. M. Y., 2011, 2011 International Symposium on Computer Networks and Distributed Systems (CNDS), P175, DOI 10.1109/CNDS.2011.5764567
   Shen HY, 2015, IEEE ACM T NETWORK, V23, P987, DOI 10.1109/TNET.2014.2311431
   Summary E, 2017, CISC VIS NETW IND GL
   Szymkowiak M, 2016, STAT PROBABIL LETT, V111, P41, DOI 10.1016/j.spl.2016.01.004
   Triningsih E, 2016, INT CONF ICT SMART S, P6, DOI 10.1109/ICTSS.2016.7792857
   Tu XP, 2013, IEEE T SYST MAN CY-S, V43, P379, DOI 10.1109/TSMCA.2012.2189878
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
   Wang F., 2007, 27 INT C DISTR COMP, P49
   Wang WN, 2015, ANN ALLERTON CONF, P337, DOI 10.1109/ALLERTON.2015.7447024
   Xiao X, 2009, IEEE INFOCOM SER, P603, DOI 10.1109/INFCOM.2009.5061967
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yu LC, 2012, IEEE I C EMBED SOFTW, P666, DOI 10.1109/HPCC.2012.95
   Zhang JW, 2016, IEEE COMMUN LETT, V20, P2390, DOI 10.1109/LCOMM.2016.2608776
   Zhang JW, 2014, COMPUT COMMUN, V40, P22, DOI 10.1016/j.comcom.2013.12.002
   Zhang M, 2007, IEEE J SEL AREA COMM, V25, P1678, DOI 10.1109/JSAC.2007.071207
   Zhang M, 2009, IEEE T PARALL DISTR, V20, P97, DOI 10.1109/TPDS.2008.69
   Zhang XM, 2005, AIP CONF PROC, V805, P3, DOI 10.1063/1.2149667
   Zheng GF, 2009, IEEE INT CON MULTI, P1158, DOI 10.1109/ICME.2009.5202705
   Zheng Y, 2016, PEER PEER NETW APPL, V9, P1089, DOI 10.1007/s12083-015-0381-8
   Zhou YP, 2015, IEEE ACM T NETWORK, V23, P1163, DOI 10.1109/TNET.2014.2321422
NR 63
TC 8
Z9 9
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24427
EP 24457
DI 10.1007/s11042-018-5741-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900060
DA 2024-07-18
ER

PT J
AU Wang, DP
   Gao, TG
   Yang, FS
AF Wang, Dong-ping
   Gao, Tiegang
   Yang, Fusheng
TI A forensic algorithm against median filtering based on coefficients of
   image blocks in frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Median filtering; Discrete cosine transform;
   DCT subband coefficients
ID COMPRESSION; TRACES
AB Median filtering is a popular nonlinear denoising operator, it not only can be used for image enhancement, and it also is an effective tool in application of anti-forensics. So, the blind detection of median filtering is a particularly hot topic. Different from the existing median filtering forensic methods using the image pixel statistical features, this paper proposed a novel approach for detecting median filtering in digital images using coefficients of image blocks in frequency domain, based on the theory analysis and experiments test. Large numbers of experimental results show that the proposed approach achieved a high accuracy in median filtering detection and a good robustness of defending JPEG compression, the algorithm also can be used to locate the median filtering area. The approach achieves much better performance than the existing state-of-the-art methods with different format and size of image blocks, particularly when the image blocks are tiny and have high JPEG compression ratio.
C1 [Wang, Dong-ping; Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
   [Yang, Fusheng] Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin 300384, Peoples R China.
C3 Nankai University; Tianjin Chengjian University
RP Wang, DP (corresponding author), Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
EM wangdongping0822@163.com; gaotiegang@nankai.edu.cn; yong_nk@sina.com
RI Wang, Dongping/AAJ-2166-2020; Gao, Tiegang/AAT-9599-2021
OI Wang, Dongping/0000-0002-4368-7426; 
CR [Anonymous], ELECT IMAGING INT SO
   [Anonymous], 2012, INFORM HIDING IH 201
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Cao G, 2011, IEEE SIGNAL PROC LET, V18, P603, DOI 10.1109/LSP.2011.2164791
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Kirchner M, 2010, MEDIA FORENSICS SECU, V7541
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Kong XW, 2016, LECT NOTES ELECTR EN, V393, P509, DOI 10.1007/978-981-10-1536-6_66
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P460, DOI 10.1109/TIFS.2009.2024715
   Liu A, 2017, MULTIMED TOOLS APPL, V6, P1
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Ng T.T., 2004, ADVENT Technical Report
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Singh G, 2018, MULTIMED TOOLS APPL, V77, P485, DOI 10.1007/s11042-016-4290-5
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
NR 23
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23411
EP 23427
DI 10.1007/s11042-018-5651-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900016
DA 2024-07-18
ER

PT J
AU Zhang, A
   Gao, XW
AF Zhang, Ao
   Gao, Xianwen
TI Data-dependent kernel sparsity preserving projection and its application
   for semi-supervised classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparsity preserving projection; Data-dependent kernel; Semi-supervised
   learning; Dimensionality reduction
ID RECOGNITION; REPRESENTATION; MACHINES
AB Dimensionality reduction methods (DR) have been commonly used as a principled way to understand the high-dimensional data. In this paper, a novel semi-supervised nonlinear method called semi-supervised data-dependent kernel sparsity preserving projection (SDKSPP) is proposed for dimensionality reduction. To achieve performance improvements, SDKSPP adopts a data-dependent kernel (DK) instead of a standard kernel. The coefficients in DK are optimized with labeled samples by using the Fisher criterion. Then the labeled and unlabeled samples are mapped into a high dimensional space by DK. The sparse reconstructive relationship among the whole samples is calculated by minimizing l(1) regularization-related objective function. Finally, a transform matrix that can preserve this relationship is obtained to project the mapped data into a low-dimensional space. The effectiveness of the proposed method is tested and compared with seven methods on four popular datasets.
C1 [Zhang, Ao; Gao, Xianwen] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Gao, XW (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
EM gaoxianwen@mail.neu.edu.cn
FU National Natural Science Foundation of China [61573088, 61573087,
   61433004]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61573088, No. 61573087 and No. 61433004).
CR Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], ORL FAC DAT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Cai D, 2007, IEEE INT C COMP VIS, P1313
   Chen B, 2008, PATTERN RECOGN, V41, P2107, DOI 10.1016/j.patcog.2007.10.006
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fan MY, 2011, PATTERN RECOGN, V44, P1777, DOI 10.1016/j.patcog.2011.02.013
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gao QX, 2015, IEEE T IMAGE PROCESS, V24, P5684, DOI 10.1109/TIP.2015.2479559
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Georghiades A., 1997, Yale face database
   Gu NN, 2014, NEUROCOMPUTING, V139, P345, DOI 10.1016/j.neucom.2014.02.022
   He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692
   He Z, 2015, EXPERT SYST APPL, V42, P1118, DOI 10.1016/j.eswa.2014.09.004
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee MMS, 2004, IEEE T NEURAL NETWOR, V15, P750, DOI 10.1109/TNN.2004.824266
   Lin C, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/847062
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Lou SJ, 2016, NEUROCOMPUTING, V173, P290, DOI 10.1016/j.neucom.2015.04.116
   Luo LJ, 2016, J PROCESS CONTR, V38, P11, DOI 10.1016/j.jprocont.2015.12.005
   Meng M, 2017, INT J MACH LEARN CYB, V8, P793, DOI 10.1007/s13042-015-0380-3
   Motai Y, 2013, IEEE T KNOWL DATA EN, V25, P1863, DOI 10.1109/TKDE.2012.110
   Ong CS, 2005, J MACH LEARN RES, V6, P1043
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiong HL, 2005, IEEE T NEURAL NETWOR, V16, P460, DOI 10.1109/TNN.2004.841784
   Xiong HL, 2007, IEEE ACM T COMPUT BI, V4, P583, DOI 10.1109/TCBB.2007.1048
   Yang Y., 2016, MULTIMED TOOLS APPL, V76, P1
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zhang DQ, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P629
   Zhang L, 2016, INFORM SCIENCES, V343, P79, DOI 10.1016/j.ins.2016.01.053
   Zhang PY, 2016, PATTERN RECOGN, V52, P249, DOI 10.1016/j.patcog.2015.09.024
NR 43
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24459
EP 24475
DI 10.1007/s11042-018-5707-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900061
DA 2024-07-18
ER

PT J
AU Zhang, H
   Dai, G
   Tang, D
   Xu, X
AF Zhang, Hong
   Dai, Gang
   Tang, Du
   Xu, Xin
TI Cross-media retrieval based on semi-supervised regularization and
   correlation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Common space; Semi-supervised regularization;
   Correlation learning; Semantic level
ID REPRESENTATION; INFORMATION; SPARSE
AB As large scale multimedia data in heterogeneous spaces is flooding into the Internet, cross-media retrieval is becoming increasingly significant. In cross-media retrieval, users can retrieve the results containing various types of media by submitting a query of any media type. However, most existing cross-media retrieval methods are restricted to the retrieval between two types of media, which ignores the semantic consistency of different media data. In addition, although some methods consider the similarity between same semantic category data in different media, they neglect the dissimilarity between different semantic category data in different media. To solve the above problems, we propose a novel feature learning algorithm for cross-media retrieval, called semi-supervised regularization and correlation learning (SSRCL), which is capable of modeling multiple types of media simultaneously. More importantly, SSRCL considers both semantic category similarity and dissimilarity simultaneously, and utilizes both labeled and unlabeled data to learn the projection matrices for different media types. The experimental results show that our proposed approach, compared with four state-of-the-art methods, has better performance on two extensively used datasets.
C1 [Zhang, Hong; Dai, Gang; Xu, Xin] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Hubei, Peoples R China.
   [Zhang, Hong; Dai, Gang; Xu, Xin] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
   [Tang, Du] BNP Paribas, FIRST, 10 Harewood Ave, London NW16AA, England.
C3 Wuhan University of Science & Technology; BNP Paribas
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Hubei, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
EM zhanghong_wust@163.com
RI Xu, Xin/JRW-5800-2023
FU National Natural Science Foundation of China [61373109, 61602349];
   Educational Research Project from the Educational Commission of Hubei
   Province [2016234]
FX This research is supported by the National Natural Science Foundation of
   China (No. 61373109, No. 61602349), the Educational Research Project
   from the Educational Commission of Hubei Province (2016234).
CR [Anonymous], AM ASS ARTIFICIAL IN
   [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 2013, MULTIFEATURE CANONIC
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUTER SCI
   [Anonymous], P SPIE
   [Anonymous], 2005, P INT C MUS INF RETR
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   Battiato S, 2009, MULTIMED TOOLS APPL, V42, P5, DOI 10.1007/s11042-008-0250-z
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Blaschko M.B., 2008, IEEE C COMPUTER VISI
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Li B, 2016, NEUROCOMPUTING, V188, P225, DOI 10.1016/j.neucom.2014.11.105
   Li B, 2016, NEUROCOMPUTING, V173, P137, DOI 10.1016/j.neucom.2015.01.099
   Liu Y., 2010, Proc. ACM International Conference on Image and Video Re- trieval, P89, DOI DOI 10.1145/1816041.1816057
   Moffat A, 1996, ACM T INFORM SYST, V14, P349, DOI 10.1145/237496.237497
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sindhwani V., 2005, ICML, V2005, P74
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang YJ, 2012, IEEE T MULTIMEDIA, V14, P597, DOI 10.1109/TMM.2012.2189550
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu J, 2008, IEEE T CIRC SYST VID, V18, P544, DOI 10.1109/TCSVT.2008.918763
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2012, LECT NOTES COMPUT SC, V7131, P312
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhai XH, 2012, INT CONF ACOUST SPEE, P2337, DOI 10.1109/ICASSP.2012.6288383
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu LC, 2017, INT J COMPUT VISION, V124, P409, DOI 10.1007/s11263-017-1033-7
   Znaidia A, 2012, INT C PATT RECOG, P1509
NR 47
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22455
EP 22473
DI 10.1007/s11042-018-6037-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500038
DA 2024-07-18
ER

PT J
AU Choi, MR
   Ko, SJ
   Kwon, GR
   Lama, RK
AF Choi, Moo-Rak
   Ko, Sung-Jea
   Kwon, Goo-Rak
   Lama, Ramesh Kumar
TI Color image interpolation in the DCT domain using a wavelet-based
   differential value
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Adaptive directional wavelet transform; Discrete
   cosine transform; Hybrid transforms
ID COMPRESSED DOMAIN; DISCRETE; MODEL
AB We propose a new image-interpolation technique using a combination of an adaptive directional wavelet transform (ADWT) and discrete cosine transform (DCT). In the proposed method, we use ADWT to decompose the low-resolution image into different frequency subband images. The high-frequency subband images are further transformed to DCT coefficients, and the zero-padding method is used for interpolation. Simultaneously, the low-frequency subband image is replaced by the original low-resolution image. Finally, we generate the interpolated image by combining the original low-resoultion image and the interpolated subband images by using inverse DWT. Experimental results demonstrate that the proposed algorithm yields better quality images in terms of subjective and objective quality metrics compared to the other methods considered in this paper.
C1 [Choi, Moo-Rak; Ko, Sung-Jea] Korea Univ, Sch Elect Engn Dept, 145 Anam Ro, Seoul 02841, South Korea.
   [Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
   [Lama, Ramesh Kumar] Gachon Univ, Dept Software, 1342 Seongnamdaero, Seongnam 13120, Gyeonggido, South Korea.
C3 Korea University; Chosun University; Gachon University
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
EM grkwon@chosun.ac.kr
OI Kwon, Goo-Rak/0000-0003-3486-8812
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   Cao FL, 2015, IEEE T CIRC SYST VID, V25, P1261, DOI 10.1109/TCSVT.2014.2372351
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   Elharar E, 2007, J DISP TECHNOL, V3, P321, DOI 10.1109/JDT.2007.900915
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Jeon G, 2007, P INT C IM PROC ICIP, V7, P397
   Kim CH, 2003, IEEE T CIRC SYST VID, V13, P549, DOI 10.1109/TCSVT.2003.813431
   Lama Ramesh Kumar, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P184, DOI 10.1109/ICCE.2016.7430573
   Lama Ramesh Kumar, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P219, DOI 10.1109/ICCE.2014.6775980
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   Park YS, 2006, IEEE T IMAGE PROCESS, V15, P494, DOI 10.1109/TIP.2005.863117
   Ratakonda K, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P203, DOI 10.1109/ICIP.1998.727167
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Wang Q, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P899, DOI 10.1109/ICIP.2001.958269
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhu SY, 2016, IEEE T MULTIMEDIA, V18, P1707, DOI 10.1109/TMM.2016.2593039
NR 21
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21539
EP 21556
DI 10.1007/s11042-018-5616-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300053
DA 2024-07-18
ER

PT J
AU Sun, Y
   Tang, GM
   Xu, XY
   Jiang, MM
AF Sun, Yi
   Tang, Guangming
   Xu, Xiaoyu
   Jiang, Mingming
TI Steganography using Gabor filter and anisotropic diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Adaptive steganography; Distortion function;
   Syndrome trellis codec (STC)
ID STEGANALYSIS
AB In order to improve the statistical security and the ability of resistance to steganalysis of adaptive steganography, an adaptive steganography algorithm based on Gabor filters and anisotropic diffusion is proposed, which can be utilized in an arbitrary domain. Compared with other adaptive embedding schemes, this method can define image distortion more accurately. Firstly, Gabor filters with multi-orientation and multi-scale is employed to determine the noisy regions or textures of cover image. Then the P-M anisotropic diffusion model is utilized to make image elements with low distortion cost relatively cluster in complex areas of image, and better retain the image edge information. At last, the syndrome-trellis codes is used to realize the actual embedding method to minimize the expected distortion for a given payload. The experimental results illustrate that the proposed method can significantly improve the accuracy of embedding in noisy regions and textures, and gains a better performance on resisting the current state-of-the-art steganalysis over prior algorithms.
C1 [Sun, Yi; Xu, Xiaoyu; Jiang, Mingming] Zhengzhou Informat Sci & Technol Inst, Informat Secur, Zhengzhou, Henan, Peoples R China.
   [Tang, Guangming] Zhengzhou Informat Sci & Technol Inst, Dept Informat Secur, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Sun, Y (corresponding author), Zhengzhou Informat Sci & Technol Inst, Informat Secur, Zhengzhou, Henan, Peoples R China.
EM mickyfaith@163.com; tgm1983@sina.com; xxyin1992@163.com;
   361362342@qq.com
RI TANG, Guang-Ming/E-5315-2013
CR [Anonymous], 2015, 12 LEARN TECHN C WEA
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], LECT NOTES INFORM TH
   [Anonymous], 2011, P 13 INF HID C PRAG
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Filler T, 2009, LECT NOTES COMPUT SC, V5806, P31, DOI 10.1007/978-3-642-04431-1_3
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Sedighi V, 2016, IEEE IMAGE PROC, P2747, DOI 10.1109/ICIP.2016.7532859
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Song XF, 2017, MULTIMED TOOLS APPL, V76, P26391, DOI 10.1007/s11042-016-4157-9
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
NR 28
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20247
EP 20265
DI 10.1007/s11042-017-5464-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500060
DA 2024-07-18
ER

PT J
AU Vidyadharan, DS
   Thampi, SM
AF Vidyadharan, Divya S.
   Thampi, Sabu M.
TI Evaluating color and texture features for forgery localization from
   illuminant maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery localization; Illumination inconsistency; Color
   descriptor; Texture descriptor; Combined color-texture descriptor; Local
   phase quantization
ID CLASSIFICATION; CONSTANCY; DISTANCE; SCALE
AB Images are widely accepted as a record of events even when images are prone to easy manipulations. It is difficult to identify image alterations by the human visual system. Once an image is identified as forged, the next step is to locate forged regions. Recently, distribution of scene illumination across an image has been analyzed to detect forged images and to locate forged image regions. In this paper, we investigate the problem of locating spliced image region based on illumination inconsistency. We investigated the discriminative power of a number of color and texture descriptors in locating spliced image regions. During digital crime investigations, often it is required to detect the spliced face in a group photo. Here, we have selected forged images containing human facial regions where the regions to be compared are of similar object material, human skin regions. We evaluated various color, texture, and combined color-texture descriptors in an unsupervised manner by comparing the distance between the feature vectors to identify the inconsistent image region. We also investigated the performance of different histogram similarity measures including heuristic histogram distance measures, non-parametric test statistics, information theoretic divergences, and cross-bin measures. Experiments show that the Local Phase Quantization (LPQ) descriptor performs best in identifying the spliced image region from the illuminant map.
C1 [Vidyadharan, Divya S.] Coll Engn Trivandrum, Thiruvananthapuram, Kerala, India.
   [Vidyadharan, Divya S.] Univ Kerala, LBS Ctr Sci & Technol, Thiruvananthapuram, Kerala, India.
   [Thampi, Sabu M.] Indian Inst Informat Technol & Management Kerala, Thiruvananthapuram, Kerala, India.
C3 College of Engineering, Trivandrum; University of Kerala; Kerala
   University of Digital Sciences, Innovation & Technology (Digital
   University Kerala)
RP Vidyadharan, DS (corresponding author), Coll Engn Trivandrum, Thiruvananthapuram, Kerala, India.; Vidyadharan, DS (corresponding author), Univ Kerala, LBS Ctr Sci & Technol, Thiruvananthapuram, Kerala, India.
EM divya.s.vidyadharan@ieee.org; smthampi@ieee.org
RI Thampi, Sabu/O-2118-2019; Vidyadharan, Divya S/AAM-4078-2020
OI Thampi, Sabu/0000-0001-6453-5520; Vidyadharan, Divya
   S/0000-0002-1593-9235
FU Department of Higher Education, Government of Kerala
FX Authors acknowledge the Department of Higher Education, Government of
   Kerala for funding the research and the Department of Computer Science
   and Engineering, College of Engineering-Trivandrum for providing lab
   facilities to carry out the work. The authors would like to thank Dr.
   Tiago Jose De Carvalho for sharing the database. Also, authors would
   like to thank Mr. Aniruddha Mazumdar for sharing the source code of
   previous works for comparison.
CR Alvarez S, 2012, PATTERN RECOGN, V45, P4312, DOI 10.1016/j.patcog.2012.04.032
   [Anonymous], 1978, ACM SIGGRAPH COMPUT, DOI [10.1145/800248.807361, DOI 10.1145/965139.807361]
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014 ANN SUMM C AS P
   [Anonymous], 2015 IEEE INT C SIGN
   [Anonymous], 2014 20 NAT C COMM N
   [Anonymous], P 10 IND C COMP VIS
   Benavente R, 2008, J OPT SOC AM A, V25, P2582, DOI 10.1364/JOSAA.25.002582
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   CARRON T, 1994, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.1994.413699
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   DURBIN J, 1972, J ROY STAT SOC B, V34, P290
   Fan Y, 2015, IEEE IMAGE PROC, P2940, DOI 10.1109/ICIP.2015.7351341
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   Gang Cao, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1186, DOI 10.1109/ICOSP.2008.4697342
   Gholap S., 2008, TENCON 2008 - 2008 IEEE Region 10 Conference, P1
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kannala J, 2012, INT C PATT RECOG, P1363
   Khan FS, 2015, PATTERN RECOGN LETT, V51, P16, DOI 10.1016/j.patrec.2014.07.020
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ludwig O, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P432
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Meshgi K, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P475, DOI 10.1109/MVA.2015.7153234
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pedone M, 2012, INT C PATT RECOG, P2476
   Riess C, 2010, LECT NOTES COMPUT SC, V6387, P66, DOI 10.1007/978-3-642-16435-4_6
   Roemer J, 2014, IEEE INT CONF MOB, P702, DOI 10.1109/MASS.2014.74
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   STEIGER JH, 1985, PSYCHOMETRIKA, V50, P253, DOI 10.1007/BF02294104
   Tai JZ, 2017, IEEE T CLOUD COMPUT, V5, P537, DOI 10.1109/TCC.2015.2424886
   Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vidyadharan DS, 2015, INT CONF SOFT COMPUT, P175, DOI 10.1109/SOCPAR.2015.7492803
   Wei X., 2007, GRAY LEVEL RUN LENGT
   Xuemin Wu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P600, DOI 10.1109/MINES.2011.135
   Yang Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7364216
   Yang ZY, 2016, INT CONF CLOUD COMP, P245, DOI [10.1109/CloudCom.2016.46, 10.1109/CloudCom.2016.0049]
   Zhang L, 2012, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2012.6466800
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 56
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21131
EP 21161
DI 10.1007/s11042-017-5574-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300036
DA 2024-07-18
ER

PT J
AU Ge, Y
   Jiang, SL
   Xu, QY
   Jiang, CL
   Ye, FM
AF Ge, Yun
   Jiang, Shunliang
   Xu, Qingyong
   Jiang, Changlong
   Ye, Famao
TI Exploiting representations from pre-trained convolutional neural
   networks for high-resolution remote sensing image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-trained; CNN; Remote sensing; Image retrieval; Feature combination;
   Feature compression
ID FEATURES
AB With the increasing amount of high-resolution remote sensing images, it becomes more and more urgent to retrieve remote sensing images from large archives efficiently. The existing methods are mainly based on shallow features to retrieve images, while shallow features are easily affected by artificial intervention. Recently, convolutional neural networks (CNNs) are capable of learning feature representations automatically, and CNNs pre-trained on large-scale datasets are generic. This paper exploits representations from pre-trained CNNs for high-resolution remote sensing image retrieval. CNN representations from AlexNet, VGGM, VGG16, and GoogLeNet are first transferred for high-resolution remote sensing images, and then CNN features are extracted via two approaches. One is extracting the outputs of high-level layers directly and the other is aggregating the outputs of mid-level layers by means of average pooling with different pooling regions. Given the generalization and high dimensionality of the CNN features, feature combination and feature compression are also adopted to improve the feature representation. Experimental results demonstrate that aggregated features with pooling region smaller than the feature map size perform excellently, especially for VGG16 and GoogLeNet. Shallow feature makes a great contribution to enhance the retrieval precision when combined with CNN features, and compressed features reduce redundancy effectively. Compared with the state-of-the-art methods, the proposed feature extraction methods are very simple, and the features are able to improve retrieval performance significantly.
C1 [Ge, Yun; Xu, Qingyong; Ye, Famao] Nanchang Univ, Informat Engn Sch, Nanchang, Jiangxi, Peoples R China.
   [Jiang, Shunliang] Nanchang Univ, Informat Engn Sch, Comp Sci & Technol Dept, Nanchang, Jiangxi, Peoples R China.
   [Ge, Yun; Jiang, Changlong] Nanchang Hangkong Univ, Software Sch, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University; Nanchang Hangkong University
RP Ye, FM (corresponding author), Nanchang Univ, Informat Engn Sch, Nanchang, Jiangxi, Peoples R China.
EM geyun@nchu.edu.cn; yefamao@ncu.edu.cn
FU National Natural Science Foundation of China [41261091, 61662044,
   61663031, 61762067]
FX This work has been supported by National Natural Science Foundation of
   China [grant numbers 41261091, 61662044, 61663031, and 61762067].
CR [Anonymous], 2015, ACTA ECOL SIN
   [Anonymous], 2015, ARXIV150906033
   [Anonymous], ARXIV160400133V1
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2017, ARXIV170603424
   [Anonymous], 2017, ARXIV170200338
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, P BRIT MACH VIS C, DOI DOI 10.5244/C.28.6
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], ARXIV161003023
   [Anonymous], 2015, CHANGINGCROPPINGPATT
   [Anonymous], ARXIV160200970V1
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai S, 2017, MULTIMED TOOLS APPL, V76, P16145, DOI 10.1007/s11042-016-3900-6
   Bretschneider T, 2002, INT GEOSCI REMOTE SE, P2253, DOI 10.1109/IGARSS.2002.1026510
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Demir B, 2015, IEEE T GEOSCI REMOTE, V53, P2323, DOI 10.1109/TGRS.2014.2358804
   Ferecatu M, 2007, IEEE T GEOSCI REMOTE, V45, P818, DOI 10.1109/TGRS.2007.892007
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hu F, 2016, INT CONF SIGN PROCES, P198, DOI 10.1109/ICSP.2016.7877823
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu TT, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Özkan S, 2014, IEEE GEOSCI REMOTE S, V11, P1996, DOI 10.1109/LGRS.2014.2316143
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Scott GJ, 2011, IEEE T GEOSCI REMOTE, V49, P1603, DOI 10.1109/TGRS.2010.2088404
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uricchio T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1020, DOI 10.1109/ICCVW.2015.134
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang M, 2013, IEEE T GEOSCI REMOTE, V51, P2874, DOI 10.1109/TGRS.2012.2217397
   Wang YB, 2016, IEEE T GEOSCI REMOTE, V54, P6020, DOI 10.1109/TGRS.2016.2579648
   Xia GS, 2010, INT ARCH PHOTOGRAMM, V38, P298
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yang Y, 2013, IEEE T GEOSCI REMOTE, V51, P818, DOI 10.1109/TGRS.2012.2205158
   Yao HY, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P733
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
NR 47
TC 43
Z9 51
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17489
EP 17515
DI 10.1007/s11042-017-5314-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300067
DA 2024-07-18
ER

PT J
AU Lomaliza, JP
   Park, H
AF Lomaliza, Jean-Pierre
   Park, Hanhoon
TI Improved peak detection technique for robust PPG-based heartrate
   monitoring system on smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peak detection; Heartratemonitoring; Photo-plethysmography; Smartphone;
   Healthcare
ID HEALTH INFORMATICS
AB Heartrate monitoring can be very decisive in terms of detecting heart-related diseases in early stages. Given that smartphones are used almost ubiquitously by humans on a daily basis and that they are equipped with several sensors and a powerful CPU, they are the ideal tools to accomplish daily heartrate monitoring. Many studies have shown the possibility of monitoring the heartrate in a very accurate way by using smartphone camera and the photo-plethysmography technique. However, in real cases, when using a smartphone camera as the input sensor, the pulse signal usually contains noise caused by fingertip movements, pressure changes between the smartphone camera and the fingertip, or changes in ambient light intensity. Hence, many techniques have been proposed to filter and detect real peaks in the pulse signal and avoid noise peaks. Most of those state-of-the-art techniques rely on the assumption that real peaks are those having the maximum values in their respective cycles. In some cases, the assumption is not correct, which decreases the accuracy of peak detection. Hence, this paper proposes a novel method to detect a pulse signal's real peaks. The proposed method first smoothens a pulse signal by using a second-order Butterworth band-pass filter over a wide frequency range. Then, it considers the local minima of the signal as peaks and builds an optimization tree based on statistical properties, such as uniformity of peak time locations, peak count within a period, and variance in times elapsed between adjacent peaks, to detect combinations of peaks that optimize the heartrate computation. Results from experiments conducted using synthetic and real signals show that the proposed method can detect a pulse signal's real peaks with higher precision as compared to conventional methods, and is very robust to signal noises. The proposed method has a significant heartrate estimation accuracy in various real scenarios and across smartphone models; its error rate is as low as 0.8588 +/- 0.0653 beats per minute, even in cases of signals with extensive noise.
C1 [Lomaliza, Jean-Pierre; Park, Hanhoon] Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
C3 Pukyong National University
RP Park, H (corresponding author), Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
EM hanhoon_park@pknu.ac.kr
RI KOMBOZI, LOMALIZA/ABG-9489-2020
OI KOMBOZI, LOMALIZA/0000-0002-6954-0852; Park, Hanhoon/0000-0002-6968-4565
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2014R1A1A2059579]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2014R1A1A2059579).
CR [Anonymous], ACM SIGGRAPH 2011 EM
   Baek HJ, 2012, IEEE T INF TECHNOL B, V16, P150, DOI 10.1109/TITB.2011.2175742
   Balakrishnan G, 2013, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2013.440
   Banitsas K, 2009, P INT C TECHN APPL B, P1
   Grimaldi D., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P488, DOI 10.1109/IDAACS.2011.6072801
   Guede-Fernández F, 2015, IEEE ENG MED BIO, P7332, DOI 10.1109/EMBC.2015.7320085
   Jonathan E, 2010, PHYSIOL MEAS, V31, pN79, DOI 10.1088/0967-3334/31/11/N01
   Lagido RB, 2014, 2014 IEEE-EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS (BHI), P556, DOI 10.1109/BHI.2014.6864425
   Lanatà A, 2010, IEEE T INF TECHNOL B, V14, P817, DOI 10.1109/TITB.2009.2024414
   Laure D, 2013, PROC CONF OPEN INNOV, P85, DOI 10.23919/FRUCT.2013.8124232
   Leonard Paul, 2004, J Clin Monit Comput, V18, P309, DOI 10.1007/s10877-005-2697-z
   Lomaliza J-P, 2016, MULTIME TOOLS APPL, V17, P21051
   Maeda Y, 2011, J MED SYST, V35, P829, DOI 10.1007/s10916-010-9506-z
   Michahelles F, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P4, DOI 10.1109/ISWC.2004.27
   Muaremi A, 2013, BIONANOSCIENCE, V3, P172, DOI 10.1007/s12668-013-0089-2
   Pelegris P, 2010, IEEE ENG MED BIO, P5488, DOI 10.1109/IEMBS.2010.5626580
   Po LM, 2015, IEEE INT SYMP CIRC S, P1634, DOI 10.1109/ISCAS.2015.7168963
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Scully CG, 2012, IEEE T BIO-MED ENG, V59, P303, DOI 10.1109/TBME.2011.2163157
   Valdez AC, 2016, LECT NOTES COMPUT SC, V9605, P391, DOI 10.1007/978-3-319-50478-0_20
   Walter M, 2011, PERS UBIQUIT COMPUT, V15, P707, DOI 10.1007/s00779-010-0350-4
   Wu KF, 2006, 2006 3RD IEEE/EMBS INTERNATIONAL SUMMER SCHOOL ON MEDICAL DEVICES AND BIOSENSORS, P98, DOI 10.1109/ISSMDBS.2006.360107
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 23
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17131
EP 17155
DI 10.1007/s11042-017-5282-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300051
DA 2024-07-18
ER

PT J
AU Rosales-Roldan, L
   Chao, JH
   Nakano-Miyatake, M
   Perez-Meana, H
AF Rosales-Roldan, Luis
   Chao, Jinhui
   Nakano-Miyatake, Mariko
   Perez-Meana, Hector
TI Color image ownership protection based on spectral domain watermarking
   using QR codes and QIM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; QIM; QR code; Ownership; Color Images; SVD/DWT/DCT
ID DIGITAL WATERMARKING; QUALITY ASSESSMENT; WAVELET TRANSFORM; SCHEME;
   ROBUST; AUTHENTICATION; DECOMPOSITION; ENTROPY
AB Some watermarking authentication methods based on spectral domain using QR codes and Quantization Index Modulation (QIM) are proposed for ownership protection in color images. The QR code is created with the owners' information and used as binary watermark sequence, which is permuted using Arnold Permutation to increase the security before embedding it. Once the watermark sequence is generated, the original color image is transformed from RGB to YCbCr color space where the Luminance Channel (Y) is processed by the Singular Value Decomposition (SVD), Discrete Wavelet Transform (DWT) and Discrete Cosine Transform (DCT) to embed the binary watermark sequence using Quantization Index Modulation (QIM). The experimental results show the effectiveness of the proposed method.
C1 [Rosales-Roldan, Luis] Univ Popular Autonoma Estado Puebla, Dept Mech, 17 Sur 901 Barrio Santiago, Puebla, Mexico.
   [Chao, Jinhui] Chuo Univ, Fac Sci & Technol, Dept Informat Engn, Tokyo, Japan.
   [Nakano-Miyatake, Mariko; Perez-Meana, Hector] Inst Politecn Nacl, Mech Elect Engn Sch, Grad Sect, Mexico City, DF, Mexico.
C3 Universidad Popular Autonoma del Estado de Puebla; Chuo University;
   Instituto Politecnico Nacional - Mexico
RP Rosales-Roldan, L (corresponding author), Univ Popular Autonoma Estado Puebla, Dept Mech, 17 Sur 901 Barrio Santiago, Puebla, Mexico.
EM luis.rosales@upaep.mx
RI Nakano, Mariko/N-4075-2019; Rosales-Roldan, Luis/S-3248-2019;
   Perez-Meana, Hector/N-1624-2019
OI Rosales-Roldan, Luis/0000-0002-0908-3944; Perez-Meana,
   Hector/0000-0002-7786-2050
FU National Council of Science and Technology of Mexico (CONACyT); Chuo
   University of Japan
FX Authors thank to the National Council of Science and Technology of
   Mexico (CONACyT) and to the Chuo University of Japan for the support to
   carry out this work.
CR [Anonymous], 2011, QR COD ESS
   Botta M, 2016, SIGNAL PROCESS, V119, P102, DOI 10.1016/j.sigpro.2015.07.018
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen WY, 2008, APPL MATH COMPUT, V197, P243, DOI 10.1016/j.amc.2007.07.078
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Gao J, 2007, 39563 MRPA, P1, DOI [10.1111/j.1467-9892.2009.00642.x, DOI 10.1111/J.1467-9892.2009.00642.X]
   Guo YF, 2016, SIGNAL PROCESS-IMAGE, V41, P85, DOI 10.1016/j.image.2015.12.002
   Haribabu M, 2016, PROCEDIA COMPUT SCI, V93, P462, DOI 10.1016/j.procs.2016.07.234
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kim J, 2010, SIGNAL PROCESS-IMAGE, V25, P559, DOI 10.1016/j.image.2010.07.004
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Laur L, 2015, RADIOENGINEERING, V24, P1025, DOI 10.13164/re.2015.1025
   Li M, 2013, ADV INTEL SYS RES, V84, P1309
   Lyon D, 2010, J OBJECT TECHNOL, V9, P17, DOI 10.5381/jot.2010.9.2.c2
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Memon F, 2015, MEHRAN UNIV RES J EN, V34, P379
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Roldan LR, 2016, IEEE LAT AM T, V14, P1050, DOI 10.1109/TLA.2016.7437257
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Vaidya SP, 2015, PROCEDIA COMPUT SCI, V58, P233, DOI 10.1016/j.procs.2015.08.063
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia XG, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P548, DOI 10.1109/ICIP.1997.647971
NR 29
TC 11
Z9 11
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16031
EP 16052
DI 10.1007/s11042-017-5178-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300002
DA 2024-07-18
ER

PT J
AU Dash, B
   Rup, S
   Mohapatra, A
   Majhi, B
   Swamy, MNS
AF Dash, Bodhisattva
   Rup, Suvendu
   Mohapatra, Anjali
   Majhi, Banshidhar
   Swamy, M. N. S.
TI Decoder driven side information generation using ensemble of MLP
   networks for distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding (DVC); Transform domain Wyner-Ziv video coding
   (TDWZ); Ensemble neural network; Side information (SI); Multi-layer
   perceptron (MLP); Structural similarity index (SSIM); Rate-Distortion
   (RD)
ID MOTION ESTIMATION; NEURAL-NETWORKS
AB This paper proposes an ensemble of multi-layer perceptron (MLP) networks for side information (SI) generation in distributed video coding (DVC). In the proposed scheme, both three-layer and four-layer MLP structures are used to form the ensemble model. The proposed model includes four sub-modules. The first sub-module involves the training of the individual networks. The second sub-module selects 'M' number of trained MLPs based on the mean square error (MSE) performance metric. Next, the third sub-module involves the testing phase of each of the selected MLPs. Finally, in the last sub-module, the overall ensemble SI is generated using a dynamically averaging (DA) method. The primary goal of this work is to minimize the estimation error between the SI and the corresponding Wyner-Ziv (WZ) frame so that the overall efficiency of DVC codec can be increased. The proposed scheme is evaluated with respect to different parameters such as Rate-Distortion (RD), Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM), and number of parity requests made per estimated frame. The evaluation indicates that the proposed ensemble model shows better generalization capabilities with improved PSNR (in dB) as compared to each of the individual selected networks. Additionally, the comparative analysis also exhibits that the proposed SI generation scheme generates better SI frames in comparison with the contemporary techniques. Further, using a statistical test, namely, ANOVA with significance level of 5%, it has been validated that the proposed technique yields a significant enhancement in the performance as compared to that of the benchmark schemes.
C1 [Dash, Bodhisattva; Rup, Suvendu; Mohapatra, Anjali] Int Inst Informat Technol, Dept Comp Sci & Engn, Bhubaneswar 751003, Odisha, India.
   [Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Res Lab, Rourkela 769004, India.
   [Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 International Institute of Information Technology, Bhubaneswar; National
   Institute of Technology (NIT System); National Institute of Technology
   Rourkela; Concordia University - Canada
RP Dash, B (corresponding author), Int Inst Informat Technol, Dept Comp Sci & Engn, Bhubaneswar 751003, Odisha, India.
EM bdash.fac@gmail.com
RI Rup, Suvendu/AAQ-6535-2021
OI Rup, Suvendu/0000-0002-9407-0469
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Aaron A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P869
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   Adhikari R, 2015, NEUROCOMPUTING, V157, P231, DOI 10.1016/j.neucom.2015.01.012
   Adikari ABB, 2006, ELECTRON LETT, V42, P1447, DOI 10.1049/el:20062268
   [Anonymous], 2005, DISTR COD VID SERV
   [Anonymous], THESIS
   Artigas X, 2007, PICT COD S PCS 07 LI
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   Ascenso J, 2010, MULTIMED TOOLS APPL, V48, P381, DOI 10.1007/s11042-009-0316-6
   Bhandari S., 2017, AIAA GUIDANCE NAVIGA, DOI [10.2514/6.2017-1524, DOI 10.2514/6.2017-1524]
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Cao MS, 2017, NEURAL COMPUT APPL, V28, P1583, DOI 10.1007/s00521-015-2132-4
   Cheng MH, 2008, LECT NOTES COMPUT SC, V5353, P782, DOI 10.1007/978-3-540-89796-5_81
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hameed AA, 2016, KNOWL-BASED SYST, V114, P79, DOI 10.1016/j.knosys.2016.10.001
   Hansel R., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2629, DOI 10.1109/ICIP.2011.6116206
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Hossain M.K., 2017, 2017 IEEE TEXAS POWE, DOI [DOI 10.1109/TPEC.2017.7868274, DOI 10.1109/IITC-AMC.2017.7968959]
   Islam MF, 2006, 2006 IEEE/PES POWER SYSTEMS CONFERENCE AND EXPOSITION. VOLS 1-5, P1063, DOI 10.1109/PSCE.2006.296457
   Jimenez D, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P753, DOI 10.1109/IJCNN.1998.682375
   Ko B, 2007, LECT NOTES COMPUT SC, V4872, P816
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8
   Maqsood I, 2004, NEURAL COMPUT APPL, V13, P112, DOI 10.1007/s00521-004-0413-4
   Moretti F, 2015, NEUROCOMPUTING, V167, P3, DOI 10.1016/j.neucom.2014.08.100
   Mukherjee D, 2007, ELECT IMAGING 2007
   Neelakanta P.S., 1994, Neural Network Modeling: Statistical Mechanics and Cybernetic Perspectives
   Opitz D. W., 1996, Connection Science, V8, P337, DOI 10.1080/095400996116802
   Opitz DW, 1996, ADV NEUR IN, V8, P535
   Puri R., 2002, P ANN ALLERTON C COM, V40, P586
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Rencher AC, 1996, COMPUT STAT DATA AN, V22, P334
   Rupa S, 2014, AEU-INT J ELECTRON C, V68, P201, DOI 10.1016/j.aeue.2013.08.005
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tagliasacchi M, 2006, IEEE IMAGE PROC, P593, DOI 10.1109/ICIP.2006.312405
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yang WA, 2015, J INTELL MANUF, V26, P1161, DOI 10.1007/s10845-013-0847-6
   Ye SM, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/683510
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
   Zhou Zhi-Hua, 2002, Chinese Journal of Computers, V25, P1
NR 44
TC 9
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15221
EP 15250
DI 10.1007/s11042-017-5103-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200036
DA 2024-07-18
ER

PT J
AU Hasheminejad, M
   Farsi, H
AF Hasheminejad, Mohammad
   Farsi, Hassan
TI Sample-specific late classifier fusion for speaker verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Speaker verification; Logistic regression;
   Classifier fusion
ID PARALLEL FRAMEWORK; FEATURES
AB Due to the mismatch between training and test conditions, speaker verification in real environments, continues to be a challenging problem. An effective way of improving such a system is taking advantage of multiple speaker verification systems. In this paper, we propose a novel sample specific speaker verification system. Using this system, the best classifiers are selected as the ensemble set and the optimal weights are obtained for each test sample. In this process, more reliable scores are forced to have higher weights, while less reliable scores are forced to have lower weights. We achieved an improvement of 0.81% in equal error rate (EER), 0.76% in minimum decision cost function (minDCF) and 3.62% in minimum log-likelihood ratio cost (minCLLR) on the NIST 2004 Speaker Recognition Evaluation dataset.
C1 [Hasheminejad, Mohammad] Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
   [Farsi, Hassan] Univ Birjand, Dept Elect & Comp Engn, Commun Engn, Birjand, Iran.
C3 University of Birjand; University of Birjand
RP Farsi, H (corresponding author), Univ Birjand, Dept Elect & Comp Engn, Commun Engn, Birjand, Iran.
EM mhashemi@birjand.ac.ir; hfarsi@birjand.ac.ir
RI Farsi, hassan/AAF-5297-2021; Hasheminejad, Mohammad/ABE-6315-2021
OI Hasheminejad, Mohammad/0000-0001-9557-7563
CR Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007
   Ali H, 2014, ELECTRON LETT, V50, P1098, DOI 10.1049/el.2014.1207
   [Anonymous], MATLAB SPEECH FEATUR
   [Anonymous], XLP
   [Anonymous], NIST YEAR 2010 SPEAK
   [Anonymous], 2007, INFORM SCI STAT
   [Anonymous], IEEE INT C AC SPEECH
   Brümmer N, 2007, IEEE T AUDIO SPEECH, V15, P2072, DOI 10.1109/TASL.2007.902870
   Campbell W., 2006, IEEE INT C ACOUSTICS, V1, pI
   Campbell WM, 2007, INT CONF ACOUST SPEE, P217
   Diez Mireia, 2014, IEEE Signal Processing Letters, V21, P649, DOI 10.1109/LSP.2014.2312213
   Hasan T, 2014, IEEE-ACM T AUDIO SPE, V22, P381, DOI 10.1109/TASLP.2013.2292356
   Hastie T., 2009, The Elements of Statistical Learning
   Hautamäki V, 2013, IEEE T AUDIO SPEECH, V21, P1622, DOI 10.1109/TASL.2013.2256895
   Kumar A., 2015, ARXIV150201823
   Lai KT, 2015, IEEE T IMAGE PROCESS, V24, P2772, DOI 10.1109/TIP.2015.2423560
   Lei ZC, 2006, INT J COMPUT SCI NET, V6, P163
   Magi C, 2009, SPEECH COMMUN, V51, P401, DOI 10.1016/j.specom.2008.12.005
   Pigeon S, 2000, DIGIT SIGNAL PROCESS, V10, P237, DOI 10.1006/dspr.1999.0358
   Sadjadi S. O., 2013, MSRTR2013133
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Schmidt M, 2007, LECT NOTES ARTIF INT, V4701, P286
   Sedlák F, 2011, INT CONF ACOUST SPEE, P4544
   Solomonoff A, 2005, INT CONF ACOUST SPEE, P629
   Sturim D, 2011, INT CONF ACOUST SPEE, P5272
   Tong R, 2006, LECT NOTES COMPUT SC, V4274, P566
   van Leeuwen David A., 2007, Speaker Classification I. Fundamentals, Features, and Methods. (Lecture Notes in Artificial Intelligence vol. 4343), P330, DOI 10.1007/978-3-540-74200-5_19
   Veeramachaneni K, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN MULTI-CRITERIA DECISION MAKING, P128, DOI 10.1109/MCDM.2007.369427
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   You CH, 2010, IEEE T AUDIO SPEECH, V18, P1300, DOI 10.1109/TASL.2009.2032950
   Zhang H, 2013, FRONT MICROBIOL, V4, DOI 10.3389/fmicb.2013.00269
NR 33
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15273
EP 15289
DI 10.1007/s11042-017-5114-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200038
DA 2024-07-18
ER

PT J
AU Lai, YC
   Huang, TQ
   Lin, J
   Lu, HN
AF Lai, Yuecong
   Huang, Tianqiang
   Lin, Jing
   Lu, Henan
TI An improved block-based matching algorithm of copy-move forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Copy-move forgery; Region duplication detection
AB Copy-move forgery is a common way of image tampering. Matching algorithm is the key step in copy-move forgery detection. Usually, the classical block-based matching algorithm (CBMA) can't find all matched sub-blocks. In this paper, we propose an improved block-based matching algorithm (IBMA) to solve the problem. Firstly, we put the sum of feature vectors in the first column to get a new matrix. Secondly, the matrix is sorted by first column. Finally, every row of the matrix will search the following rows until the difference in the first column is larger than the threshold value. Experiment results show that the improved block-based matching algorithm is better than the classical block-based matching algorithm when an image was distorted by Gaussian noise, salt-pepper noise, or JPEG compression. The reason is that improved block-based matching algorithm can look for all matched sub-blocks, which makes copy-move forgery detection methods more robust.
C1 [Lai, Yuecong; Lin, Jing; Lu, Henan] Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou 350007, Fujian, Peoples R China.
   [Huang, Tianqiang] Fujian Normal Univ, Fac Software, Fuzhou 350007, Fujian, Peoples R China.
   [Huang, Tianqiang] Fujian Normal Univ, Fujian Engn Res Ctr Publ Serv Big Data Min & Appl, Fuzhou 350007, Fujian, Peoples R China.
C3 Fujian Normal University; Fujian Normal University; Fujian Normal
   University
RP Huang, TQ (corresponding author), Fujian Normal Univ, Fac Software, Fuzhou 350007, Fujian, Peoples R China.; Huang, TQ (corresponding author), Fujian Normal Univ, Fujian Engn Res Ctr Publ Serv Big Data Min & Appl, Fuzhou 350007, Fujian, Peoples R China.
EM fjhtq@fjnu.edu.cn
FU National Natural Science Foundation of China [61070062, 61502103];
   Industry-University Cooperation Major Projects in Fujian Province
   [2015H6007]; Fuzhou science and technology project [2014-G-76]; Science
   and Technology Department of Fujian province K-class Foundation Project
   [JK2011007]; Education Department of Fujian Province A-class Foundation
   Project [JA10064]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61070062,61502103), the Industry-University Cooperation
   Major Projects in Fujian Province (Grant No. 2015H6007), Fuzhou science
   and technology project (Grant No. 2014-G-76), the Science and Technology
   Department of Fujian province K-class Foundation Project (Grant No.
   JK2011007), and The Education Department of Fujian Province A-class
   Foundation Project (Grant No. JA10064).
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 13
TC 16
Z9 16
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15093
EP 15110
DI 10.1007/s11042-017-5094-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200029
DA 2024-07-18
ER

PT J
AU Cheng, HN
   Chung, SM
AF Cheng, Huaining
   Chung, Soon M.
TI Action recognition from point cloud patches using discrete orthogonal
   moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LIDAR; Point cloud; Action recognition; Discrete orthogonal moment;
   Tchebichef moment
ID IMAGE-ANALYSIS
AB 3D sensors such as standoff Light Detection and Ranging (LIDAR) generate partial 3D point clouds that resemble patches of irregularly-shaped, coarse groups of points. 3D modeling of this type of data for human action recognition has been rarely studied. Although 2D-based depth image analysis is an option, its effectiveness on this type of low-resolution data hasn't been well answered. This paper investigates a new multi-scale 3D shape descriptor, based on the discrete orthogonal Tchebichef Moments, for the characterization of 3D action pose shapes made of low-resolution point cloud patches. Our shape descriptor consists of low-order 3D Tchebichef moments computed with respect to a new point cloud voxelization scheme that normalizes translation, scale, and resolution. The action recognition is built on the Na < ve Bayes classifier using temporal statistics of a 'bag of pose shapes'. For performance evaluation, a synthetic LIDAR pose shape baseline was developed with 62 human subjects performing three actions aEuro center dot digging, jogging, and throwing. Our action classification experiments demonstrated that the 3D Tchebichef moment representation of point clouds achieves excellent action and viewing direction predictions with superb consistency across a large range of scale and viewing angle variations.
C1 [Cheng, Huaining] Air Force Res Lab, Human Performance Wing 711, Dayton, OH 45433 USA.
   [Chung, Soon M.] Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
C3 University System of Ohio; Wright State University Dayton
RP Chung, SM (corresponding author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
EM huaining.cheng@us.af.mil; soon.chung@wright.edu
CR Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], P INT C IM AN PROC
   [Anonymous], P WORKSH NON RIG SHA
   [Anonymous], BIOL INSPIRED COGNIT
   [Anonymous], P SPIE IS T EL IM SP
   [Anonymous], 2015, PROC IEEE C COMPUT V
   [Anonymous], RRLIRIS2012004 ICPR
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cheng HN, 2016, PATTERN RECOGN, V52, P397, DOI 10.1016/j.patcog.2015.09.028
   Chihara T.S., 2011, INTRO ORTHOGONAL POL
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Johnstone IM, 2009, J AM STAT ASSOC, V104, P682, DOI 10.1198/jasa.2009.0121
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Klaser A., 2008, BRIT MACHINE VISION
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lassoued I, 2011, COMM COM INF SC, V185, P196
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lu YA, 2012, INT C INTEL HUM MACH, P76, DOI 10.1109/IHMSC.2012.114
   Mademlis A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P743
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   McCallum Andrew., 2000, ICML
   Metsis V., 2006, CEAS 2006 - Third Conference on Email and Anti-Spam, P27
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhouhui Lian, 2010, Proceedings of the Shape Modeling International (SMI 2010), P25, DOI 10.1109/SMI.2010.20
NR 56
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8213
EP 8236
DI 10.1007/s11042-017-4711-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800020
DA 2024-07-18
ER

PT J
AU Dorj, UO
   Lee, KK
   Choi, JY
   Lee, M
AF Dorj, Ulzii-Orshikh
   Lee, Keun-Kwang
   Choi, Jae-Young
   Lee, Malrey
TI The skin cancer classification using deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Skin cancer types; Classification; Convolutional neural
   network; Deep learning; Image analysis
ID DIAGNOSIS
AB This paper addresses the demand for an intelligent and rapid classification system of skin cancer using contemporary highly-efficient deep convolutional neural network. In this paper, we mainly focus on the task of classifying the skin cancer using ECOC SVM, and deep convolutional neural network. RGB images of the skin cancers are collected from the Internet. Some collected images have noises such as other organs, and tools. These images are cropped to reduce the noise for better results. In this paper, an existing, and pre-trained AlexNet convolutional neural network model is used in extracting features. A ECOC SVM clasifier is utilized in classification the skin cancer. The results are obtained by executing a proposed algorithm with a total of 3753 images, which include four kinds of skin cancers images. The implementation result shows that maximum values of the average accuracy, sensitivity, and specificity are 95.1 (squamous cell carcinoma), 98.9 (actinic keratosis), 94.17 (squamous cell carcinoma), respectively. Minimum values of the average in these measures are 91.8 (basal cell carcinoma), 96.9 (Squamous cell carcinoma), and 90.74 (melanoma), respectively.
C1 [Dorj, Ulzii-Orshikh; Lee, Malrey] Chon Buk Natl Univ, Sch Elect & Informat Engn, Ctr Adv Image & Informat Technol, 664-14,1Ga, Jeonju 561756, Chon Buk, South Korea.
   [Lee, Keun-Kwang] Koguryeo Coll, Dept Skin & Beauty Arts, Naju 58280, South Korea.
   [Choi, Jae-Young] Sungkyunkwan Univ, Dept Comp Engn, Seoul, South Korea.
C3 Jeonbuk National University; Sungkyunkwan University (SKKU)
RP Lee, M (corresponding author), Chon Buk Natl Univ, Sch Elect & Informat Engn, Ctr Adv Image & Informat Technol, 664-14,1Ga, Jeonju 561756, Chon Buk, South Korea.; Lee, KK (corresponding author), Koguryeo Coll, Dept Skin & Beauty Arts, Naju 58280, South Korea.; Choi, JY (corresponding author), Sungkyunkwan Univ, Dept Comp Engn, Seoul, South Korea.
EM ulzii158@chonbuk.ac.kr; kklee@kgrc.ac.kr; jaeychoi@skku.edu;
   mrlee@chonbuk.ac.kr
OI Choi, JaeYoung/0000-0003-1042-6171
FU National Research Foundation of Korea (NRF) - Korea government (MSP)
   [2017R1A2B4006667]
FX This work is supported by the National Research Foundation of Korea
   (NRF) granted by the Korea government (MSP) (No: 2017R1A2B4006667).
CR Abbas Q, 2013, PATTERN RECOGN, V46, P86, DOI 10.1016/j.patcog.2012.07.027
   Allwein E., 2002, JMLR, V1, P113
   Almansour E, 2016, INT J COMPUT SCI NET, V16, P135
   Anas M., 2017, International Journal of Technical Research and Applications, V5, P62
   [Anonymous], INTERSPEECH ICSLP 19
   [Anonymous], ARXIV14124564V3CSCV
   [Anonymous], 2003, J MACHINE LEARNING R
   [Anonymous], 2015, INT J COMPUT SCI APP
   [Anonymous], 2011, 22 INT JT C ART INT, DOI 10.5555/2283516.2283603
   [Anonymous], COMPUT INTELL NEUROS
   [Anonymous], INT J MATH COMPUT SI
   Bagheri Mohammad Ali, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P508, DOI 10.1109/AISP.2012.6313800
   Blum A, 2004, BRIT J DERMATOL, V151, P1029, DOI 10.1111/j.1365-2133.2004.06210.x
   Capdehourat G, 2011, PATTERN RECOGN LETT, V32, P2187, DOI 10.1016/j.patrec.2011.06.015
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Isasi AG, 2011, COMPUT BIOL MED, V41, P742, DOI 10.1016/j.compbiomed.2011.06.010
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Iyatomi H, 2008, J INVEST DERMATOL, V128, P2049, DOI 10.1038/jid.2008.28
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Xiao-feng, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P336, DOI 10.1109/PCSPA.2010.88
   Ramlakhan K, 2011, PROC INT C TOOLS ART, P138, DOI 10.1109/ICTAI.2011.29
   Ruiz D, 2011, EXPERT SYST APPL, V38, P15217, DOI 10.1016/j.eswa.2011.05.079
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Yan ZG, 2014, INT J GRID DISTRIB, V7, P67, DOI 10.14257/ijgdc.2014.7.1.07
   Yan ZG, 2014, INT ARCH PHOTOGRAMM, V40-2, P191, DOI 10.5194/isprsarchives-XL-2-191-2014
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 31
TC 149
Z9 153
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9909
EP 9924
DI 10.1007/s11042-018-5714-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200036
DA 2024-07-18
ER

PT J
AU Franco, P
   Nguyen, G
   Mullot, R
   Ogier, JM
AF Franco, Patrick
   Nguyen, Giap
   Mullot, Remy
   Ogier, Jean-Marc
TI Alternative patterns of the multidimensional Hilbert curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Space-filling curve; Hilbert curve; New patterns; Locality preserving;
   Image retrieval
ID SPACE-FILLING CURVES; IMAGE RETRIEVAL; RE-RANKING; SIMILARITY; ALGORITHM
AB Locality-preserving (distance preserving-mapping) is a useful property to manage multidimensional data. Close points in space remain -as much as possible- close after mapping on curve. That is why Hilbert space-filling curve is used in many domains and applications. Hilbert curve preserves well locality because from a construction aspect, it is guided by adajacency constraint on points ordering : the curve connects all points of a D-dimensional discrete space, without favoring any direction, under the constrainst that two successive points are separated by an unit distance. Originally defined in 2-D, all existing multidimensional extensions of the Hilbert curve satisfy adjacency by using the RBG pattern (based on Reflected Binary Gray code). The RBG pattern is then duplicated and arranged (geometrical transformations) to build the multidimensional Hilbert curve at a given order. In this paper, we emphasize that there are other patterns that can satisfy the adjacency. A formulation is given, an algorithm to find out solutions is provided and their respective level of locality preservation is estimated through a standard criterion. Results show that some new patterns can carry a comparable levels of locality and sometimes better than RBG. Moreover, selecting the best locality preserving pattern allows one to design, through orders, a new curve with a comparable overall locality preserving refer to Hilbert curve. The contribution of new patterns is experimented through a CBIR (Content-Based Image Retrieval) application. Large-scale image retrieval tests show that exploring the image feature space with an alternative way to the classical Hilbert curve can lead to improved image searching performances.
C1 [Franco, Patrick; Nguyen, Giap; Mullot, Remy; Ogier, Jean-Marc] Univ La Rochelle France, Lab Informat Image Interact L3i, EA 2118, Ave M Crepeau, F-17000 La Rochelle, France.
RP Franco, P (corresponding author), Univ La Rochelle France, Lab Informat Image Interact L3i, EA 2118, Ave M Crepeau, F-17000 La Rochelle, France.
EM patrick.franco@univ-lr.fr
CR Amory Abduljawad A., 2012, 2012 Seventh International Conference on Digital Information Management (ICDIM 2012), P221, DOI 10.1109/ICDIM.2012.6360121
   [Anonymous], 2010, International Journal of Engineering Science and Technology
   [Anonymous], 1890, Math. Ann.
   [Anonymous], 1994, Multidimensional Scaling
   [Anonymous], 2013, THESIS
   Armstrong J, 2009, LECT NOTES COMPUT SC, V5627, P594, DOI 10.1007/978-3-642-02611-9_59
   Bader M., 2012, ser. Texts in Computational Science and Engineering, V9, DOI DOI 10.1007/978-3-642-31046-1
   Bilenko M., 2004, P INT C MACH LEARN, P11
   Biswas S, 2000, INT C PATT RECOG, P207, DOI 10.1109/ICPR.2000.903522
   Butz A. R., 1969, J COMPUTER SYSTEM SC, V3, P128, DOI [DOI 10.1016/S0022-0000(69)80010-3, 10.1016/S0022-0000(69)80010-3]
   BUTZ AR, 1971, IEEE T COMPUT, VC 20, P424, DOI 10.1109/T-C.1971.223258
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chen HL, 2005, INFORM SYST, V30, P205, DOI 10.1016/j.is.2003.12.002
   Chierichetti Flavio, 2007, P 26 ACM SIGMOD SIGA, P103
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Ebrahim Y, 2007, LECT NOTES COMPUT SC, V4633, P411
   Ebrahim Y, 2009, PATTERN RECOGN LETT, V30, P348, DOI 10.1016/j.patrec.2008.09.013
   Faloutsos C., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P247, DOI 10.1145/73721.73746
   Pedronette DCG, 2013, PATTERN RECOGN, V46, P2350, DOI 10.1016/j.patcog.2013.01.004
   Haji-Hashemi MR, 2006, PIERS 2006 CAMBRIDGE: PROGRESS IN ELECTROMAGNETICS RESEARCH SYMPOSIUM, PROCEEDINGS, P69
   Hamilton CH, 2008, INFORM PROCESS LETT, V105, P155, DOI 10.1016/j.ipl.2007.08.034
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He XF, 2004, ADV NEUR IN, V16, P153
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   Jan-Ming Ho, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P785, DOI 10.1109/ICSAI.2012.6223128
   Jin GH, 2005, ACM T MATH SOFTWARE, V31, P120, DOI 10.1145/1055531.1055537
   Jolliffe L., 2002, Principal Component Analysis
   Kanungo T, 2000, IEEE T PATTERN ANAL, V22, P1209, DOI 10.1109/34.888707
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim DH, 2005, J SYST SOFTWARE, V78, P9, DOI 10.1016/j.jss.2005.02.005
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Lawder JK, 2001, INT J COMPUT MATH, V78, P327, DOI 10.1080/00207160108805115
   Lawder JK, 2000, LECT NOTES COMPUT SC, V1832, P20
   LEBESGUE H, 1904, LECONS INTEGRATION
   Liu X, 2004, APPL MATH COMPUT, V147, P741, DOI 10.1016/S0096-3003(02)00808-1
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   McVay J., 2005, 2005 IEEE Antennas and Propagation Society International Symposium (IEEE Cat. No. 05CH37629), P22
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   MITCHISON G, 1986, SIAM J ALGEBRA DISCR, V7, P571, DOI 10.1137/0607063
   Mokbel ME, 2003, GEOINFORMATICA, V7, P179, DOI 10.1023/A:1025196714293
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nagthane D, 2013, INT J COMPUT APPL IN, V3, P22
   Nguyen G, 2012, INT C PATT RECOG, P425
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Park G, 2005, INFORM PROCESS MANAG, V41, P177, DOI 10.1016/j.ipm.2003.08.002
   Pengyu L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P471, DOI 10.1109/CISP.2008.508
   PEREZ A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P565, DOI 10.1109/ICPR.1992.202050
   Sagan H., 1994, SPACE FILLING CURVES, DOI DOI 10.1007/978-1-4612-0871-6
   Sergeyev Y., 2013, Introduction to global optimization exploiting space-filling curves
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsai Chih-Fong, 2012, BAG WORDS REPRESENTA
   Velho Luiz, 1991, P 18 ANN C COMP GRAP, P81, DOI 10.1145/122718.122727
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 55
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8419
EP 8440
DI 10.1007/s11042-017-4744-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800029
DA 2024-07-18
ER

PT J
AU Song, B
   Baik, DK
   Zhou, SX
AF Song, Bin
   Baik, Doo-Kwon
   Zhou, Shunxian
TI Human eye location algorithm based on multi-scale self-quotient image
   and morphological filtering for multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia Big Data; Multi-scale Self-quotient Image; Morphological
   Filtering; Human Eye Location; Variance Projection
AB In order to reduce the effect on the eyes location caused by the variation of illumination and expression, this paper proposes a human eye location algorithm based on the multi-scale self-quotient image and morphological filtering. Firstly, the multi-scale self-quotient image is used to offset the lighting effects on the face, then the morphological open-close operation will be taken to enhance the local features around the eyes and relevant coefficient is used to roughly position the eyes. At last, the variance projection method will be used to analyze the roughly-positioned areas and binarize them to position accurately the central point of the eye. The experiments on the images from JAFFE Database, Yale B Database and AR database have shown that the proposed algorithm can well position the center of the eye, and it is robust to deal with the changes of illumination and expressions.
C1 [Song, Bin] Henan Univ Sci & Technol, Sch Informat Engn, Luoyang 471023, Peoples R China.
   [Song, Bin; Baik, Doo-Kwon] Korea Univ, Dept Comp & Radio Commun Engn, Seoul 136701, South Korea.
   [Zhou, Shunxian] Xiangnan Univ, Coll Software & Commun Engn, Chenzhou 423000, Peoples R China.
C3 Henan University of Science & Technology; Korea University; Xiangnan
   University
RP Baik, DK (corresponding author), Korea Univ, Dept Comp & Radio Commun Engn, Seoul 136701, South Korea.
EM songbin@korea.ac.kr; baikdk@korea.ac.kr; zsx_hd@hnu.edu.cn
FU National Natural Science Foundation of China [61402165]; Scientific
   Research Fund of Hunan Provincial Education Department Project [15C1288,
   16B244]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61402165, and the Scientific Research Fund of
   Hunan Provincial Education Department Project under Grant No. 15C1288
   and No. 16B244. The authors would like to thank the anonymous reviewers
   and the editor for the very instructive suggestions that led to the much
   improved quality of this paper.
CR Chan Woo Park, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P586, DOI 10.1109/ICCIT.2007.288
   [陈华杰 CHEN Huajie], 2007, [光电子·激光, Journal of Optoelectronics·Laser], V18, P241
   Feng GC, 1998, PATTERN RECOGN LETT, V19, P899, DOI 10.1016/S0167-8655(98)00065-8
   [付晓峰 FU Xiaofeng], 2008, [光电子·激光, Journal of Optoelectronics·Laser], V19, P823
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Reinders MJT, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P230, DOI 10.1109/AFGR.1996.557269
   Wang J., 2005, P INT C MULT EXP, P1528
   [武妍 Wu Yan], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P45
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
NR 10
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10063
EP 10075
DI 10.1007/s11042-017-4945-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200046
DA 2024-07-18
ER

PT J
AU Sun, WJ
   Pan, SX
AF Sun, Wangjie
   Pan, Shuxia
TI A random walk based multi-kernel graph learning framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph learning; Mulit-kernel learning; Randomwalk; Gaussian kernel; LLE
ID RECOGNITION
AB Graph learning is an important approach for machine learning. Kernel method is efficient for constructing similarity graph. Single kernel isn't sufficient for complex problems. In this paper we propose a framework for multi-kernel learning. We give a brief introduction of Gaussian kernel, LLE and sparse representation. Then we analyze the advantages and disadvantages of these methods and give the reason why the combine of these methods with random walk is efficient. We compare our method with baseline methods on real-world data sets. The results show the efficiency of our method.
C1 [Sun, Wangjie] Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
   [Pan, Shuxia] Jilin Med Univ, Sch Publ Hlth Coll, Jilin 132013, Jilin, Peoples R China.
C3 Jilin Institute of Chemical Technology; Jilin Medical University
RP Sun, WJ (corresponding author), Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
EM sunwj405@163.com
CR [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2011, INT C NEURAL INF PRO
   [Anonymous], SEMISUPERVISED LEARN
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], 2004, P 21 INT C MACH LEAR
   AZRAN A., 2006, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V1, P190
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Karasuyama Masayuki, 2013, Adv. Neural Inf. Process. Syst., V26, P1547
   Liu JF, 2011, NEUROCOMPUTING, V74, P2566, DOI 10.1016/j.neucom.2010.12.043
   Lovasz L., 1993, Combinatorics, Paul Erdos is Eighty, V2, P1
   Norris J. R., 1998, MARKOV CHAINS
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang XC, 2011, FRONT COMPUT SCI CHI, V5, P268, DOI 10.1007/s11704-011-0023-0
NR 22
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9943
EP 9957
DI 10.1007/s11042-017-4599-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200039
DA 2024-07-18
ER

PT J
AU Li, F
   Mao, Q
   Chang, CC
AF Li, Fan
   Mao, Qian
   Chang, Chin-Chen
TI Reversible data hiding scheme based on the Haar discrete wavelet
   transform and interleaving prediction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Haar DWT; Zig-Zagscan; Histogram-shifting;
   Interleaving-prediction
ID DIFFERENCE EXPANSION; WATERMARKING; IMAGES
AB Although many data hiding schemes have been proposed in the frequency domain, the tradeoff between hiding capacity and image quality is still an existing problem to be solved. In this paper, we proposed a novel reversible data hiding scheme based on the Haar discrete wavelet transform (DWT) and interleaving-prediction method. First, a one-level Haar discrete wavelet transform (DWT) is implemented to the cover image, and four sub-bands, LL , aEuro,HL , aEuro,LH andaEuro,HH, are obtained. Sub-bands HL, LH aEuro,andaEuro,HH are chosen for embedding. After that, the wavelet coefficients of the chosen sub-bands are zig-zag scanned and two adjacent coefficients are used for prediction. The secret data is embedded in the prediction errors, which is the difference between the original value and the predicted value of the wavelet coefficients. The experimental results showed that our scheme has good performance compared with other existing reversible data hiding schemes.
C1 [Li, Fan; Mao, Qian] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
C3 University of Shanghai for Science & Technology; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM lifansunshine@gmail.com; maoqiansh@gmail.com; alan3c@gmail.com
RI Li, Fan/GRX-7461-2022; Chang, Ching-Chun/JAN-6210-2023; Li,
   Fan/JRY-4017-2023
CR Al-Qershi OM, 2014, AEU-INT J ELECTRON C, V68, P346, DOI 10.1016/j.aeue.2013.09.008
   Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2008, 3 INT C INN COMP INF
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chen B, 2014, MULTIMED TOOLS APPL, V72, P1985, DOI 10.1007/s11042-013-1493-x
   Chui C. K., 1992, WAVELETS TUTORIAL TH
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hsu FH, 2014, PEER PEER NETW APPL, V7, P723, DOI 10.1007/s12083-013-0212-8
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Ker A, 2005, INFORM HIDING, V3200, P97
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Luo T, 2016, DIGIT SIGNAL PROCESS, V48, P116, DOI 10.1016/j.dsp.2015.09.007
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Vignesh Kumar PR, 2016, INT C CIRC POW COMP
   Wu HZ, IH MMSEC 16 P 4 ACM, P187
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3304, P115
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 36
TC 11
Z9 13
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5149
EP 5168
DI 10.1007/s11042-017-4388-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800003
DA 2024-07-18
ER

PT J
AU Qiu, YG
   Gu, HH
   Sun, JY
AF Qiu, Yinguo
   Gu, Hehe
   Sun, Jiuyun
TI High-payload reversible watermarking scheme of vector maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; QR code; Polar coordinate conversion; Copyright
   protection
AB The vast majority of current reversible watermarking schemes for vector maps cannot embed abundant copyright information into host vector data, and most of them are not very robust under common attacks. In this paper, based on QR code and polar coordinate transformation, a novel high-payload and reversible watermarking scheme is proposed for vector maps. A QR code is used as the container of abundant copyright information, which is considered as the watermarking image. To enhance the robustness of this scheme under geometric transformation, watermarks are embedded into polar coordinates of map vertices. After watermark extraction, this scheme can not only obtain the original QR code, but also strictly recover the original vector data based on the reversible embedding method. Theoretical analysis and comprehensive experimental results validate that the proposed scheme can effectively increase the size of watermark payload, and it has strong robustness against common geometric and non-geometric attacks.
C1 [Qiu, Yinguo; Gu, Hehe; Sun, Jiuyun] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Peoples R China.
   [Qiu, Yinguo] Anhui Sci & Technol Univ, Coll Resource & Environm, Chuzhou 233100, Peoples R China.
C3 China University of Mining & Technology; Anhui Science & Technology
   University
RP Qiu, YG (corresponding author), China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Peoples R China.; Qiu, YG (corresponding author), Anhui Sci & Technol Univ, Coll Resource & Environm, Chuzhou 233100, Peoples R China.
EM 568733927@qq.com
RI Qiu, Yinguo/IZD-6490-2023
OI Sun, Jiuyun/0009-0007-2697-5673
FU Special Project for Talents Introduction of Anhui Science and Technology
   University [ZRC2014460]; National Natural Science Foundation of China
   [41171343]
FX This research is supported by National Natural Science Foundation of
   China (Grant No. 41171343) and Special Project for Talents Introduction
   of Anhui Science and Technology University (Grant No. ZRC2014460).
CR Cao L., 2012, 18 AM C INF SYST AMC
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   [曹刘娟 Cao Liujuan], 2011, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V32, P340
   [曹刘娟 Cao Liujuan], 2010, [测绘学报, Acta Geodetica et Cartographica Sinica], V39, P422
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Jian-Guo Sun, 2014, International Journal of Network Security, V16, P40
   [林威 Lin Wei], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P26
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   [邵承永 SHAO Chengyong], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P206
   Voigt M, 2005, P SOC PHOTO-OPT INS, V5681, P409, DOI 10.1117/12.588195
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   [王奇胜 Wang Qisheng], 2013, [测绘学报, Acta Geodetica et Cartographica Sinica], V42, P310
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   [杨成松 Yang Chengsong], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P256
   [杨成松 YANG Chengsong], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P684
NR 21
TC 8
Z9 10
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6385
EP 6403
DI 10.1007/s11042-017-4546-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800059
DA 2024-07-18
ER

PT J
AU Yang, X
   Guo, JB
   Xue, TL
   Cheng, KT
AF Yang, Xin
   Guo, Jiabin
   Xue, Tangli
   Cheng, Kwang-Ting (Tim)
TI Robust and real-time pose tracking for augmented reality on mobile
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature tracking; Featureless tracking; Inertial sensing; Sensor fusion;
   Kalman filtering; Smartphones
AB This paper addresses robust and ultrafast pose tracking on mobile devices, such as smartphones and small drones. Existing methods, relying on either vision analysis or inertial sensing, are either too computational heavy to achieve real-time performance on a mobile platform, or not sufficiently robust to address unique challenges in mobile scenarios, including rapid camera motions, long exposure time of mobile cameras, etc. This paper presents a novel hybrid tracking system which utilizes on-device inertial sensors to greatly accelerate the visual feature tracking process and improve its robustness. In particular, our system adaptively resizes each video frame based on inertial sensor data and applies a highly efficient binary feature matching method to track the object pose in each resized frame with little accuracy degradation. This tracking result is revised periodically by a model-based feature tracking method (Hare et al. 2012) to reduce accumulated errors. Furthermore, an inertial tracking method and a solution of fusing its results with the feature tracking results are employed to further improve the robustness and efficiency. We first evaluate our hybrid system using a dataset consisting of 16 video clips with synchronized inertial sensing data and then assess its performance in a mobile augmented reality application. Experimental results demonstrated our method's superior performance to a state-of-the-art feature tracking method (Hare et al. 2012), a direct tracking method (Engel et al. 2014) and the Vuforia SDK (Ibaez and Figueras 2013), and can run at more than 40 Hz on a standard smartphone. We will release the source code with the pubilication of this paper.
C1 [Yang, Xin; Guo, Jiabin; Xue, Tangli] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, 1037 Luoyu Rd,1st South Bldg,Rm W205, Wuhan 430074, Hubei, Peoples R China.
   [Cheng, Kwang-Ting (Tim)] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Cheng, Kwang-Ting (Tim)] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Cheng, Kwang-Ting (Tim)] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Huazhong University of Science & Technology; University of California
   System; University of California Santa Barbara; Hong Kong University of
   Science & Technology; Hong Kong University of Science & Technology
RP Yang, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, 1037 Luoyu Rd,1st South Bldg,Rm W205, Wuhan 430074, Hubei, Peoples R China.
EM xinyang2014@hust.edu.cn; i_am_path@hust.edu.cn; joytl1993@hust.edu.cn;
   timcheng@ust.hk
OI Cheng, Kwang-Ting Tim/0000-0002-3885-4912
FU National Science Foundation of China [61502188]
FX This work is funded by the National Science Foundation of China (grant
   no. 61502188).
CR [Anonymous], 2012, Asian Conf. Comput. Vis, DOI DOI 10.1007/978-3-642-37331-2_45
   [Anonymous], 2007, P 12 COMP VIS WINT W
   Chliveros Georgios, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P234, DOI 10.1007/978-3-642-39402-7_24
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Crivellaro A, 2015, IEEE I CONF COMP VIS, P4391, DOI 10.1109/ICCV.2015.499
   DiVerdi S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P75
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Hallaway D, 2004, APPL ARTIF INTELL, V18, P477, DOI 10.1080/08839510490462768
   Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Klein Georg., 2006, BMVC, P1119
   Klein George, 2007, P1
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li M, 2013, IEEE INT CONF ROBOT, P4712, DOI 10.1109/ICRA.2013.6631248
   Ligorio G, 2013, SENSORS-BASEL, V13, P1919, DOI 10.3390/s130201919
   Morgan DL, 2014, THESIS
   Obeidy WK, 2013, LECT NOTES COMPUT SC, V8237, P447, DOI 10.1007/978-3-319-02958-0_41
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Rolland JP, 2001, FUNDAMENTALS OF WEARABLE COMPUTERS AND AUGMENTED REALITY, P67
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schöps T, 2014, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2014.6948420
   Simonetti Ibanez A., 2013, THESIS
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   White S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P119, DOI 10.1109/TRIDUI.2006.1618281
   Yang X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P671, DOI 10.1145/2647868.2654888
   Yang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1039, DOI 10.1145/2733373.2806396
   Yang X, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P68, DOI 10.1109/ISMAR.2015.23
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150
NR 36
TC 7
Z9 8
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6607
EP 6628
DI 10.1007/s11042-017-4575-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700009
DA 2024-07-18
ER

PT J
AU Krawiec, P
   Sosnowski, M
   Batalla, JM
   Mavromoustakis, CX
   Mastorakis, G
AF Krawiec, Piotr
   Sosnowski, Maciej
   Batalla, Jordi Mongay
   Mavromoustakis, Constandinos X.
   Mastorakis, George
TI DASCo: dynamic adaptive streaming over CoAP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive streaming; CoAP; Internet of things; Multimedia IoT; Dash
ID VIDEO; INTERNET
AB This paper presents the Dynamic Adaptive Streaming over CoAP (DASCo), a solution for adaptive media streaming in the Internet of Things (IoT) environment. DASCo combines DASH (Dynamic Adaptive Streaming over HTTP), the widespread open standard for HTTP-compliant streaming, with Constrained Application Protocol (CoAP), the vendor-independent web transfer protocol designed for resource-constrained devices. The proposed solution uses DASH formats and mechanisms to make media segments available for consumers, and exploits CoAP to deliver media segments to consumers' applications. Consequently, the DASCo player offers native interoperability with IoT devices that are accessed via CoAP, thus it allows easy access to data collected by different sensors in order to enrich the multimedia services. In the paper we present an overview of constraints of default CoAP implementation with respect to media streaming, and propose guidelines for development of adaptive streaming service over CoAP. Moreover, we discuss the features of CoAP that can be investigated when designing an efficient adaptive algorithm for DASCo. Presented experimental results show poor performance of DASCo when default values of CoAP transmission parameters have been used. However, adjusting the parameters according to the network conditions considerably improves DASCo efficiency. Furthermore, in bad network conditions the enhanced DASCo is characterized by a more stable download rate compared to DASH. This feature is important in the context of dynamic media adaptation, since it allows an adaptation algorithm to better fit media bit rate with download conditions.
C1 [Krawiec, Piotr; Sosnowski, Maciej; Batalla, Jordi Mongay] Natl Inst Telecommun, Szachowa Str 1, PL-04894 Warsaw, Poland.
   [Sosnowski, Maciej; Batalla, Jordi Mongay] Warsaw Univ Technol, Nowowiejska 15-19, PL-00665 Warsaw, Poland.
   [Mavromoustakis, Constandinos X.] Univ Nicosia, 46 Makedonitissas Ave,POB 24005, CY-1700 Nicosia, Cyprus.
   [Mastorakis, George] Technol Educ Inst Crete, Iraklion 71500, Crete, Greece.
C3 National Institute of Telecommunications - Poland; Warsaw University of
   Technology; University of Nicosia; Hellenic Mediterranean University
RP Krawiec, P (corresponding author), Natl Inst Telecommun, Szachowa Str 1, PL-04894 Warsaw, Poland.
EM p.krawiec@itl.waw.pl
RI Mavromoustakis, Constandinos/M-8305-2014; Mastorakis,
   George/L-9001-2019; Batalla, Jordi/AAL-9056-2021; Krawiec,
   Piotr/M-9095-2013
OI Mavromoustakis, Constandinos/0000-0003-0333-8034; Mastorakis,
   George/0000-0002-6733-5652; Batalla, Jordi/0000-0002-1489-5138;
   Sosnowski, Maciej/0000-0003-0563-1111; Krawiec,
   Piotr/0000-0002-2395-5155
FU Narodowe Centrum Badan i Rozwoju in Poland, under grant Celtic-Plus
   Monalis; Narodowe Centrum Badan i Rozwoju in Poland, under grant
   Celtic-Plus Monalis
FX This work was partially founded by the Narodowe Centrum Badan i Rozwoju
   in Poland, under grant Celtic-Plus Monalis.
CR 3GPP Technical Specification BTransparent end- to- end packet- switched streaming service (PSS), 26247 3GPP TS
   Adame T, 2014, IEEE WIRELESS COMMUN
   Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Afzal Bilal, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P895, DOI 10.1109/CCNC.2016.7444907
   [Anonymous], 2015, 7641 IETF RFC
   [Anonymous], COAP SIMPLE IN PRESS
   [Anonymous], 2014, 230091 ISOIEC
   [Anonymous], PL LAB2020 EXP INFR
   [Anonymous], CISCO VISUAL NETWORK
   [Anonymous], 2014, 7252 IETF
   [Anonymous], 2007, 4944 IETF RFC
   Batalla JM, 2016, IEEE J SEL AREA COMM, V34, P2154, DOI 10.1109/JSAC.2016.2577360
   Batalla JM, 2016, J REAL-TIME IMAGE PR, V12, P443, DOI 10.1007/s11554-015-0496-4
   Batalla JM, 2014, PERS UBIQUIT COMPUT, V18, P465, DOI 10.1007/s00779-013-0664-0
   Beben A, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P13, DOI 10.1145/2910017.2910596
   Beben A, 2012, P 13 ACIS INT C SOFT
   Bormann C., 2016, 7959 IETF RFC
   Choi G, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P476, DOI 10.1109/ICOIN.2016.7427163
   Chotard L, 2016, IEEE INT SYMP CIRC S, P455, DOI 10.1109/ISCAS.2016.7527273
   Colitti W, 2011, INT LOW POW LOSS NET
   Eriksson EA, 2015, CONSUM COMM NETWORK, P654, DOI 10.1109/CCNC.2015.7158057
   Gao WC, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P103, DOI 10.1145/2987386.2987400
   Gowri S R, 2015, P 13 INT C ADV MOB C, P211
   Hui J., 2011, IETF 6LO WG
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Lederer S, 2012, P ACM MULT SYST C 20
   Lin CH, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P565
   Martinez-Julia P, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P411, DOI 10.1109/IMIS.2013.76
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Mitrea M, 2016, USE CASES INTERNET M
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Rikli NE, 2014, CAN J ELECT COMPUT E, V37, P182, DOI 10.1109/CJECE.2014.2324279
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Shelby Z., 2012, RFC 6690
   Skodzik J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1851, DOI 10.1109/ICIT.2015.7125366
   Tanganelli G, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P63, DOI 10.1109/WF-IoT.2015.7389028
   Thomsen Mads S., 2014, NeoBiota, V22, P1
   Wisniewski P, 2015, IEEE ICC, P6867, DOI 10.1109/ICC.2015.7249420
   Xu J, 2014, IEEE J SEL AREA COMM, V32, P782, DOI 10.1109/JSAC.2014.140410
NR 41
TC 16
Z9 17
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4641
EP 4660
DI 10.1007/s11042-017-4854-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500033
OA hybrid
DA 2024-07-18
ER

PT J
AU Shen, M
AF Shen, Miao
TI Social image tag enrichment based on textual similarity modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag enrichment; Tag ranking; Flickr; Image Annotation; Social image;
   Social Media
ID LOCATION ESTIMATION; ANNOTATION; SEARCH; WEB; RELEVANCE
AB In social image sharing websites, users provide several descriptive tags to annotate their shared images. Usually, the user annotated tags are noisy, biased and incomplete. How to improve tag quality is very important for tag based applications. The content relevant tags have certain similarities or connections with each other. Thus from some highly relevant tags, we can infer the other content relevant tags for an image. In this paper, a social image tag enrichment approach is proposed. Considering the diversity of content relevant tags for the image, we first determine some seed tags which are highly relevant to image content and cover wide range of semantics. Then the seed tags are utilized to adopt semantic similarity tags for the input image. Experiments demonstrate the effectiveness of the proposed approach.
C1 [Shen, Miao] Xi An Jiao Tong Univ City Coll, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University City College
RP Shen, M (corresponding author), Xi An Jiao Tong Univ City Coll, Xian 710049, Peoples R China.
EM 28855546@qq.com
CR Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chua T., 2009, PROC CIVR
   Datta R., 2007, Proc. ACM Multimedia, P393
   Feng S, 2010, P ACM INT C IM VID R, P288
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gu Y, 2015, IEEE T IMAGE PROCESS, V24, P3450, DOI 10.1109/TIP.2015.2443501
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Joshi D, 2011, USING GEOTAGS DERIVE
   Kleban J, 2009, P CIVR
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Li GD, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379797
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li J, 2015, SIGNAL PROCESS-IMAGE, V38, P141, DOI 10.1016/j.image.2015.07.007
   Li J, 2013, IEEE T MULTIMEDIA, V15, P2058, DOI 10.1109/TMM.2013.2280127
   Li X, 2006, ACM MM
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Liu D., 2010, Proceedings of the 19th international conference on World wide web, WWW '10, ACM, New York, NY, USA, P1149, DOI DOI 10.1145/1772690.1772848
   Liu D, 2010, P ACM MULT
   Liu D, 2011, IEEE T MULTIMEDIA
   Liu D, 2011, IEEE T MULTIMEDIA, V13, P82, DOI 10.1109/TMM.2010.2087744
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Lu X, 2016, IEEE T CYBERN
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P149, DOI 10.1109/TCYB.2013.2286496
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P2815, DOI 10.1109/TGRS.2012.2213825
   Mei T, 2008, P CVPR
   Moxley E, 2010, IEEE T MULTIMEDIA, V12, P184, DOI 10.1109/TMM.2010.2041101
   Qian X, 2012, P ICIP
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Qian XM, 2015, IEEE T CIRC SYST VID, V25, P1857, DOI 10.1109/TCSVT.2014.2369731
   Qian XM, 2015, IEEE T IMAGE PROCESS, V24, P4348, DOI 10.1109/TIP.2015.2462131
   Qian XM, 2014, IEEE T CYBERNETICS, V44, P2493, DOI 10.1109/TCYB.2014.2309593
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Qian XM, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1111
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Shen J, 2010, SIGIR
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Wang C, 2007, P CVPR
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang X., 2009, Proc. 3rd international Workshop on Data Mining and Audience Intelligence for Advertising, P18
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wang XJ, 2010, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2010.5540046
   Weinberger K.Q., 2008, Proceedings of Conference on Multimedia, P111
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Wu L, 2009, P ACM WWW
   Xu H, 2009, P ACM MULT
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yuan Y, 2017, IEEE T IMAGE PROCESS, V26, P51, DOI 10.1109/TIP.2016.2617462
   Zha Z.-J., 2008, P CVPR
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhao GS, 2017, IEEE T BIG DATA, V3, P67, DOI 10.1109/TBDATA.2016.2552541
   Zhao GS, 2016, IEEE T KNOWL DATA EN, V28, P3382, DOI 10.1109/TKDE.2016.2607172
   Zhao GS, 2016, IEEE T MULTIMEDIA, V18, P496, DOI 10.1109/TMM.2016.2515362
   Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204
NR 79
TC 0
Z9 0
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3659
EP 3676
DI 10.1007/s11042-017-5184-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600041
DA 2024-07-18
ER

PT J
AU Bahrami, Z
   Tab, FA
AF Bahrami, Zhila
   Tab, Fardin Akhlaghian
TI A new robust video watermarking algorithm based on SURF features and
   block classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video watermarking; SURF features; Block classification; Visual
   cryptography
ID COPYRIGHT PROTECTION SCHEME; VISUAL CRYPTOGRAPHY; IMAGE
AB In this paper, we propose a robust block classification based semi-blind video watermarking algorithm using visual cryptography and SURF (Speed-Up Robust Features) features to enhance the robustness, stability, imperceptibility and real-time performance. A method of selecting the best frames in each shot and the best regions or blocks within best frames is proposed to avoid employing frame-by-frame method for generating owner's share in order to enhance robustness as well as reducing time complexity. In our method, Owner's share is generated using the classification of selected robust blocks within the chosen frames along with corresponding watermark information. In extraction process, the SURF features are employed to match the feature points of selected frames with all frames to detect selected frames. Moreover, we resynchronize the embedded regions from distorted video to original sequence using SURF feature points matching. Afterwards, based on these matched feature points, rotation and scaling parameters are estimated next, selected blocks are retrieved using side information being stored eventually, watermark information is reconstructed successfully. Selecting Best frames, best regions, and employing surf features make our method to be highly robust against various kinds of attacks including image processing attacks, geometrical attacks and temporal attacks. Experimental results confirm the superiority of our scheme in case of being applicable in the real world, enhancing robustness and exploiting idea imperceptibility, over previous related methods.
C1 [Bahrami, Zhila] Univ Kurdistan, Dept Comp Engn, Kurdistan, Iran.
   [Tab, Fardin Akhlaghian] Univ Kurdistan, Comp Engn Dept, Sanandaj, Iran.
C3 University of Kurdistan; University of Kurdistan
RP Bahrami, Z (corresponding author), Univ Kurdistan, Dept Comp Engn, Kurdistan, Iran.
EM Bahrami.zhila.B@ieee.org; F.Akhlagian@uok.ac.ir
RI Akhlaghian, Fardin/AAA-5198-2021
OI Akhlaghian, Fardin/0000-0002-0300-9233
CR Al-Taweel FAP., 2009, TENCON IEEE REGION 1, P1
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhattacharya S, 2006, I SYMP CONSUM ELECTR, P616
   Campisi P, 2005, IM PROC ICIP 2005 IE, V1, pI
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan PW, 2003, CODE
   Chang CC, 2002, IMAGING SCI J, V50, P133, DOI 10.1080/13682199.2002.11784400
   Chen HY, 2014, MULTIMED TOOLS APPL, V71, P991, DOI 10.1007/s11042-012-1238-2
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Cvejic N, 2005, J UNIVERS COMPUT SCI, V11, P56
   Fallahpour M, 2014, IEEE T INSTRUM MEAS, V63, P1057, DOI 10.1109/TIM.2014.2299371
   He D, 2004, EURASIP J ADV SIG PR, V1, P1
   Ho YK, 2004, PATTERN RECOGN LETT, V25, P1673, DOI 10.1016/j.patrec.2004.06.011
   Hsu C.-S, 2005, WORLD ACAD SCI TECHN, V2, P172
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Huang HY, 2008, OPT ENG, V47, DOI 10.1117/1.2896539
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lee JS, 2004, LECT NOTES COMPUTER, V3332
   Ling HF, 2011, SIGNAL PROCESS, V91, P1863, DOI 10.1016/j.sigpro.2011.02.009
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Megha KD, 2013, INT J ADV RES COMPUT
   Pham VQ, 2008, IEICE T INF SYST, VE91D, P2027, DOI 10.1093/ietisy/e91-d.7.2027
   Schlauweg M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P53, DOI 10.1145/1411328.1411339
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sun TF, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P179, DOI 10.1109/ISECS.2009.223
   Sun Tanfeng, 2009, EL COMM SEC 2009 ISE, V1
   Sun ZW, 2009, NEURAL COMPUT APPL, V18, P507, DOI 10.1007/s00521-009-0253-3
   Swanberg D, 1993, INT SOC OPTICS PHOTO, V14, P13
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weir J, 2012, DIGITAL FORENSICS WA, V7128, P196, DOI DOI 10.1007/978-3-642-32205-1_17
   Wu CH, 2010, INT J ELECT COMMUN A
   Yassin NI., 2012, IJCSI inter J ComprSci, V9, P296
NR 41
TC 18
Z9 18
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 327
EP 345
DI 10.1007/s11042-016-4226-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400014
DA 2024-07-18
ER

PT J
AU Jahani-Fariman, H
   Kavakli, M
   Boyali, A
AF Jahani-Fariman, Hessam
   Kavakli, Manolya
   Boyali, Ali
TI MATRACK: block sparse Bayesian learning for a sketch recognition
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Gesture recognition; Sketch recognition;
   Interface design; Compressed sensing; BSBL
ID GESTURE RECOGNITION; FACE RECOGNITION; RECOVERY; REPRESENTATION; SIGNALS
AB Human-computer interaction has become increasingly easy and popular using widespread smart devices. Gestures and sketches as the trajectory of hands in 3D space are among the popular interaction media. Therefore, their recognition is essential. However, diversity of human gestures along with the lack of visual cues make the sketch recognition process challenging. This paper aims to develop an accurate sketch recognition algorithm using Block Sparse Bayesian Learning (BSBL). Sketches are acquired from three datasets using a Wii-mote in a virtual-reality environment. We evaluate the performance of the proposed sketch recognition approach (MATRACK) on diverse sketch datasets. Comparisons are drawn with three high accuracy classifiers namely, Hidden Markov Model (HMM), Principle Component Analysis (PCA) and K-Nearest Neighbour (K-NN). MATRACK, the developed BSBL based sketch recognition system, outperforms k-NN, HMM and PCA. Specifically, for the most diverse dataset, MATRACK reaches the accuracy of 93.5%, where other three classifiers approximately catches 80% accuracy.
C1 [Jahani-Fariman, Hessam; Kavakli, Manolya] Macquarie Univ, VISOR Res Grp, Dept Comp, Fac Sci & Engn, Room 349,Bldg E6A, Sydney, NSW 2109, Australia.
   [Boyali, Ali] Natl Inst Adv Ind Sci & Technol, Tsukuba, Ibaraki 3058561, Japan.
C3 Macquarie University; National Institute of Advanced Industrial Science
   & Technology (AIST)
RP Jahani-Fariman, H (corresponding author), Macquarie Univ, VISOR Res Grp, Dept Comp, Fac Sci & Engn, Room 349,Bldg E6A, Sydney, NSW 2109, Australia.
EM Hessam.jahani-fariman@students.mq.edu.au
OI Kavakli, Manolya/0000-0003-3241-6839
FU iMQRES scholarship from Macquarie University, Sydney, NSW, Australia
FX This paper has been funded by iMQRES scholarship from Macquarie
   University, Sydney, NSW, Australia.
CR Akl A, 2010, INT CONF ACOUST SPEE, P2270, DOI 10.1109/ICASSP.2010.5495895
   Alvaro F, 2014, PATTERN RECOGN LETT, V35, P58, DOI 10.1016/j.patrec.2012.09.023
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   [Anonymous], 2009, Found. Trends Hum.-Comput. Interact, DOI DOI 10.1561/1100000013
   [Anonymous], 7 DIGITAL IMAGE COMP
   [Anonymous], 2013, International Journal of Computer Applications
   [Anonymous], 2012, P 20 ACM INT C MULT
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Billinghurst M, 2014, IEEE COMPUT GRAPH, V34, P77, DOI 10.1109/MCG.2014.8
   Boyali A., 2012, 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012). Proceedings, P243, DOI 10.1109/ICIEA.2012.6360730
   Boyali A, 2014, IEEE INT VEH SYM, P1133, DOI 10.1109/IVS.2014.6856392
   Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Company P, 2009, COMPUT IND, V60, P592, DOI 10.1016/j.compind.2009.05.018
   Cunningham P., 2007, MULTIPLE CLASSIFIER, V34, P1, DOI DOI 10.1145/3459665
   Dix A., 2005, Human-computer interaction
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Eitz M, 2011, ACM SIGGRAPH 2011 TA, P30
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Fariman HJ, 2015, AUSTRALAS PHYS ENG S, V39, P1
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Ghorbel A, 2015, PATTERN RECOGN, V48, P2446, DOI 10.1016/j.patcog.2015.01.028
   Ghorbel A, 2014, PATTERN RECOGN LETT, V35, P78, DOI 10.1016/j.patrec.2013.08.011
   Hammond TA, 2010, IAAI
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Karam Maria., 2006, AVI '06: Proceedings of the working conference on Advanced visual interfaces, P225
   Kavakli M, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P613
   Kavakli M, 2012, INTEL SYST REF LIBR, V26, P201
   Kavakli M, 2008, INT J ARTS TECHNOL, V1, P215, DOI 10.1504/IJART.2008.021928
   Kim KS, 2011, CURR APPL PHYS, V11, P740, DOI 10.1016/j.cap.2010.11.051
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Landay JA, 2001, COMPUTER, V34, P56, DOI 10.1109/2.910894
   LaViola J. J., 2015, ACM SIGGRAPH 2015 CO, DOI https://doi.org/10.1145/2776880.2792711
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Mantyjarvi J, 2005, J MOBILE MULTIMEDIA, V1, P92
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Mu-Chun Su, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P420, DOI 10.1109/ISPACS.2012.6473523
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rehm M., 2008, P 22 BRIT HCI GROUP, V1, P13
   Seddati Omar, 2015, CONT BAS MULT IND CB, P1, DOI DOI 10.1109/CBMI.2015.7153606
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Vinayak, 2015, COMPUT AIDED DESIGN, V69, P11, DOI 10.1016/j.cad.2015.06.006
   Wiethoff A., 2012, P 6 INT C TANGIBLE E, P309, DOI DOI 10.1145/2148131.2148196
   Wilson AD, 2001, INT J PATTERN RECOGN, V15, P123, DOI 10.1142/S0218001401000812
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang K, 2012, ENG APPL ARTIF INTEL, V25, P392, DOI 10.1016/j.engappai.2011.10.001
   Zhang ZL, 2013, IEEE T SIGNAL PROCES, V61, P2009, DOI 10.1109/TSP.2013.2241055
   Zhang ZL, 2012, INT CONF ACOUST SPEE, P3345, DOI 10.1109/ICASSP.2012.6288632
NR 55
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1997
EP 2012
DI 10.1007/s11042-017-4368-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400024
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Wang, XH
   Yan, K
AF Liu, Yanqiu
   Wang, Xiuhui
   Yan, Ke
TI Hand gesture recognition based on concentric circular scan lines and
   weighted K-nearest neighbor algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Linear discriminant analysis; Tortoise model;
   Weighted K-nearest neighbor
ID SAMPLE-SIZE PROBLEM; MODEL
AB Human-computer interactions based on hand gestures are of the most popular natural interactive modes, which severely depends on real-time hand gesture recognition approaches. In this paper, a simple but effective hand feature extraction method is described, and the corresponding hand gesture recognition method is proposed. First, based on a simple tortoise model, we segment the human hand images by skin color features and tags on the wrist, and normalize them to create the training dataset. Second, feature vectors are computed by drawing concentric circular scan lines (CCSL) according to the center of the palm, and linear discriminant analysis (LDA) algorithm is used to deal with those vectors. Last, a weighted k-nearest neighbor (W-KNN) algorithm is presented to achieve real-time hand gesture classification and recognition. Besides the efficiency and effectiveness, we make sure that the whole gesture recognition system can be easily implemented and extended. Experimental results with a user-defined hand gesture dataset and multi-projector display system show the effectiveness and efficiency of the new approach.
C1 [Liu, Yanqiu; Wang, Xiuhui; Yan, Ke] China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Yan, K (corresponding author), China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
EM yanke@cjlu.edu.cn
RI Yan, Keyu/IXX-0343-2023; Wang, Xiuhui/O-5616-2019
OI Wang, Xiuhui/0000-0003-1773-9760; Yan, Ke/0000-0002-1611-6636
FU National Science Foundation of China [61303146, 61602431]
FX This work is supported by National Science Foundation of China (Numbers:
   61303146, 61602431).
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Chen TW, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P324, DOI 10.1109/MMSP.2008.4665097
   Chen WL, 2015, INT SYMP NEXTGEN
   Darrell TJ, 1994, ADV NEURAL INFORM PR, P945
   Dinh DL, 2016, MULTIMED TOOLS APPL, V75, P1333, DOI 10.1007/s11042-014-2370-y
   Dinh DL, 2014, ENRGY PROCED, V62, P576, DOI 10.1016/j.egypro.2014.12.419
   Gregorio P, 2008, US Patent App, Patent No. [12/ 250,815, 12250815]
   Hasan H, 2014, NEURAL COMPUT APPL, V25, P251, DOI 10.1007/s00521-013-1481-0
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Jadooki S, 2017, NEURAL COMPUT APPL, V28, P3285, DOI 10.1007/s00521-016-2244-5
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lu Z., 2013, Proceedings of the 21st ACM international conference on Multimedia, P621, DOI DOI 10.1145/2502081.2502163
   Lu Z., 2013, SIGGRAPH Asia 2013 Posters, P28
   Lv Z., 2013, Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia, P16
   Lv Z, 2013, MULTIGESTURE BASED F
   Lv ZH, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P149, DOI 10.1109/ICVR.2015.7358623
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P436, DOI 10.1109/ICCVW.2013.64
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Mehdi SA, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2204
   Morency L.P., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383299
   Pu Q., 2013, P 19 ANN INT C MOB C, P27, DOI DOI 10.1145/2500423.2500436
   Pu Qifan., 2015, GetMobile Mob. Comput. Commun., V18, P15, DOI DOI 10.1145/2721914.2721919
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Wang Xiuhui, 2007, Journal of Computer Aided Design & Computer Graphics, V19, P1056
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Wu CH, 2013, I SYMP CONSUM ELECTR, P279
   Wu CX, 2015, EVID-BASED COMPL ALT, V2015, DOI 10.1155/2015/414965
   Xie RQ, 2016, IEEE SENS J, V16, P4537, DOI 10.1109/JSEN.2016.2546942
   Xie YH, 2002, INT C PATT RECOG, P957, DOI 10.1109/ICPR.2002.1048464
   Yang Bo, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1841
   Yin L, 2014, MULTIMED TOOLS APPL, V72, P843, DOI 10.1007/s11042-013-1368-1
   Yuan Yao, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P705, DOI 10.1109/ICME.2012.48
   Zhang QY, 2010, PATTERN RECOGNITION, V4
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 39
TC 15
Z9 15
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 209
EP 223
DI 10.1007/s11042-016-4265-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400010
DA 2024-07-18
ER

PT J
AU Zampoglou, M
   Kapetanakis, K
   Stamoulias, A
   Malamos, AG
   Panagiotakis, S
AF Zampoglou, Markos
   Kapetanakis, Kostas
   Stamoulias, Andreas
   Malamos, Athanasios G.
   Panagiotakis, Spyros
TI Adaptive streaming of complex Web 3D scenes based on the MPEG-DASH
   standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D streaming; MPEG-DASH; Quality of Experience; Web 3D; X3D; HTML5
ID COMPRESSION
AB Modern Web 3D technologies allow us to display complex interactive 3D content, including models, textures, sounds and animations, using any HTML-enabled web browser. Thus, due to the device-independent nature of HTML5, the same content might have to be displayed on a wide range of different devices and environments. This means that the display of Web 3D content is faced with the same Quality of Experience (QoE) issues as other multimedia types, concerning bandwidth, computational capabilities of the end device, and content quality. In this paper, we present a framework for adaptive streaming of interactive Web 3D scenes to web clients using the MPEG-DASH standard. We offer an analysis of how the standard's Media Presentation Description schema can be used to describe adaptive Web 3D scenes for streaming, and explore the types of metrics that can be used to maximize the user's QoE. Then, we present a prototype client we have developed, and demonstrate how the 3D streaming process can take place over such a client. Finally, we discuss how the client framework can be used to design adaptive streaming policies that correspond to real-world scenarios.
C1 [Zampoglou, Markos; Kapetanakis, Kostas; Stamoulias, Andreas; Malamos, Athanasios G.; Panagiotakis, Spyros] TEI Crete, Dept Informat Engn, Multimedia Content Lab, Iraklion 71004, Crete, Greece.
C3 Hellenic Mediterranean University
RP Panagiotakis, S (corresponding author), TEI Crete, Dept Informat Engn, Multimedia Content Lab, Iraklion 71004, Crete, Greece.
EM markzampoglou@yahoo.gr; kapekost@gmail.com; stamoulias@gmail.com;
   amalamos@ie.teicrete.gr; spanag@ie.teicrete.gr
RI Zampoglou, Markos/AAP-1579-2021
OI Panagiotakis, Spyros/0000-0001-8091-6462; Malamos,
   Athanasios/0000-0001-5910-5702
FU European Union; Hellenic General Secretary of Research and Technology
   [COOPERATION 2009/09SYN-72-956]
FX The research of this paper is granted by the European Union and the
   Hellenic General Secretary of Research and Technology under the
   "COOPERATION 2009/09SYN-72-956" Framework.
CR Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   [Anonymous], 2003, LEVEL DETAIL 3D GRAP
   [Anonymous], 2004, 1477222004 ISOIEC, P14772
   [Anonymous], 2014, 14496112014 ISOIEC, P14496
   [Anonymous], 2014, 2300912014 ISOIEC, P23009
   [Anonymous], 1997, 1477211997 ISOIEC, P14772
   Behr J., 2010, Proceedings of the 15th International Conference on Web 3D Technology-Web3D '10 p, P185, DOI [10.1145/1836049.1836077, DOI 10.1145/1836049.1836077]
   Behr J, 2012, WEB3D 2012, P17
   Bourdena Athina, 2013, 2013 IEEE International Conference on Communications (ICC), P2415, DOI 10.1109/ICC.2013.6654893
   Brooks RJ, 1996, MATH COMPUT MODEL, V24, P1, DOI 10.1016/0895-7177(96)00103-3
   Carmona-Murillo J, 2014, RESOURCE MANAGEMENT, P25
   Gandoin PM, 2002, COMP GRAPH INT TECHN, P372
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Kapetanakis Kostas, 2014, International Journal of Wireless Networks and Broadband Technologies, V3, P1, DOI 10.4018/ijwnbt.2014100101
   Kapetanakis K, 2014, INT CONF TELECOMM, P226, DOI 10.1109/TEMU.2014.6917765
   Kapetanakis K, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P211, DOI 10.1109/IISA.2014.6878738
   Lavoué G, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P19
   Limper M, 2013, COMPUT GRAPH FORUM, V32, P197, DOI 10.1111/cgf.12227
   Limper M, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P11
   Lv ZH, 2016, IEEE ACCESS, V4, P407, DOI 10.1109/ACCESS.2016.2517076
   Mamou K, 2010, IEEE IMAGE PROC, P3425, DOI 10.1109/ICIP.2010.5653218
   Narayanan RGL, 2014, RESOURCE MANAGEMENT, P461
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Stamoulias A, 2014, WEB3D 2014, P99
   Valette S, 2009, COMPUT GRAPH FORUM, V28, P1301, DOI 10.1111/j.1467-8659.2009.01507.x
   Zhihan Lv, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P503, DOI 10.1007/978-3-642-42054-2_63
NR 26
TC 11
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 125
EP 148
DI 10.1007/s11042-016-4255-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400006
DA 2024-07-18
ER

PT J
AU Hsia, CH
   Guo, JM
   Wu, CS
AF Hsia, Chih-Hsien
   Guo, Jing-Ming
   Wu, Chong-Sheng
TI Finger-vein recognition based on parametric-oriented corrections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics identification; Parametric-oriented histogram equalization;
   Finger-vein recognition; Personal identification; Low-price requirement
ID USER IDENTIFICATION; EXTRACTION; PATTERNS; SYSTEM
AB The two key factors in a biometric identification system are its high identification rate and convenience of device usage. In a finger-vein identification task, these two problems often occur since the captured device of finger-vein image should accommodate the high identification rate as well as the easy-to-use device design. The finger-vein is visually invisible inside the human skin. This work develops a new finger-vein capturing device using Near-Infrared (NIR) LED light and proposes an efficient technique for finger-vein identification. The vein image may contain noise and shadows due to device lighting conditions. Parametric-Oriented Histogram Equalization (POHE) is utilized to enhance image contrast and reduce the noise effect. This work also discusses normalized issues related to the angle correction of the finger edge and Region of Interest (ROI) for width normalization. In the experimental result, the proposed method yields a clear finger-vein pattern with a superior identification rate in the recognition task compared to the state-of-the-art methods.
C1 [Hsia, Chih-Hsien] Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
   [Guo, Jing-Ming; Wu, Chong-Sheng] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 Chinese Culture University; National Taiwan University of Science &
   Technology
RP Hsia, CH (corresponding author), Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
EM chhsia625@gmail.com
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU Ministry of Science and Technology of Taiwan, R.O.C. [MOST
   104-2221-E-034-013-MY2-]
FX The authors would like to thank the anonymous reviewers of their paper
   for the many helpful suggestions. This work was supported by the
   Ministry of Science and Technology of Taiwan, R.O.C. under grant number
   MOST 104-2221-E-034-013-MY2-.
CR [Anonymous], MULTIMEDIA TOOLS APP
   Chen CY, 2016, MULTIMED TOOLS APPL, V75, P9949, DOI 10.1007/s11042-015-2776-1
   Guo JM, 2012, EXPERT SYST APPL, V39, P11728, DOI 10.1016/j.eswa.2012.04.081
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hashimoto J., 2006, S VLSI CIRC, P5, DOI DOI 10.1109/VLSIC.2006.1705285
   Hollingsworth KP, 2011, IEEE T PATTERN ANAL, V33, P2465, DOI 10.1109/TPAMI.2011.89
   Lee EC, 2009, ELECTRON LETT, V45, P1074, DOI 10.1049/el.2009.1231
   Lee H, 2008, IEEE T CONSUM ELECTR, V54, P1798, DOI 10.1109/TCE.2008.4711237
   Liu T, 2015, NEURAL COMPUT APPL, V26, P969, DOI 10.1007/s00521-014-1783-x
   Liu Y, 2013, RSC ENERGY ENVIRON S, P26, DOI 10.1039/9781849737777-00026
   Liu YF, 2014, IEEE T INF FOREN SEC, V9, P1953, DOI 10.1109/TIFS.2014.2355495
   Liu Z, 2012, IEEE T CONSUM ELECTR, V58, P522, DOI 10.1109/TCE.2012.6227456
   Lu Y, 2014, ELECTRON LETT, V50, P1591, DOI 10.1049/el.2014.1956
   Lu Y, 2013, SENSORS-BASEL, V13, P14339, DOI 10.3390/s131114339
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Mulyono D, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P134
   Nakamaru Yuri, 2015, HITACHI REV, V64, P275
   Prabhakar S, 2003, PATTERN RECOGN, V36, P1847, DOI 10.1016/S0031-3203(02)00322-9
   Qin HF, 2011, OPT ENG, V50, DOI 10.1117/1.3572129
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Struc V, 2009, IET SIGNAL PROCESS, V3, P258, DOI 10.1049/iet-spr.2008.0152
   Venayagamoorthy GK, 1998, PROCEEDINGS OF THE 1998 SOUTH AFRICAN SYMPOSIUM ON COMMUNICATIONS AND SIGNAL PROCESSING, P29, DOI 10.1109/COMSIG.1998.736916
   Wang DS, 2010, IEEE T CONSUM ELECTR, V56, P799, DOI 10.1109/TCE.2010.5506004
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang L, 2013, SENSORS-BASEL, V13, P3799, DOI 10.3390/s130303799
   Yang W., 2011, P INT C HAND BAS BIO, P176
   Yu Chengbo, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P1876
NR 27
TC 19
Z9 19
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25179
EP 25196
DI 10.1007/s11042-016-4296-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300035
DA 2024-07-18
ER

PT J
AU Roh, HJ
   Han, SW
   Ryu, ES
AF Roh, Hyun-Joon
   Han, Sung Won
   Ryu, Eun-Seok
TI Prediction complexity-based HEVC parallel processing for asymmetric
   multicores
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Parallel processing; Asymmetric multicores; Prediction Complexity
ID VIDEO CODING HEVC; EFFICIENCY
AB This paper proposes a novel Tile allocation method considering the computational ability of asymmetric multicores as well as the computational complexity of each Tile. This paper measures the computational ability of asymmetric multicores in advance, and measures the computational complexity of each Tile by using the amount of HEVC prediction unit (PU) partitioning. The implemented system counts and sorts the amount of PU partitions of each Tile, and also allocates Tiles to asymmetric big.LITTLE cores according to their expected computational complexity. When experiments were conducted, the amount of PU partitioning and the computational complexity (decoding time) showed a close correlation, and average performance gains of decoding time with the proposed adaptive allocation were around 36 % with 12 Tiles, 28 % with 18 Tiles, and 31 % with 24 Tiles, respectively.
C1 [Roh, Hyun-Joon; Ryu, Eun-Seok] Gachon Univ, Dept Comp Engn, 1342 Seongnam Daero, Seongnam Si 13120, Gyeonggi Do, South Korea.
   [Han, Sung Won] Korea Univ, Sch Ind Management Engn, 145 Anam Ro, Seoul 02841, South Korea.
C3 Gachon University; Korea University
RP Ryu, ES (corresponding author), Gachon Univ, Dept Comp Engn, 1342 Seongnam Daero, Seongnam Si 13120, Gyeonggi Do, South Korea.
EM ggyo@gc.gachon.ac.kr; swhan@korea.ac.kr; esryu@gachon.ac.kr
RI Ryu, Eun-Seok/AAA-3536-2021
OI Ryu, Eun-Seok/0000-0003-4894-6105
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2015R1C1A1A02037743]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning (NRF-2015R1C1A1A02037743).
CR Ahn Heejune, 2013, [The Journal of Korean Institute of Communications and Information Sciences B, 한국통신학회논문지B], V38, P46
   Baik H, 2015, IEEE IMAGE PROC, P4298, DOI 10.1109/ICIP.2015.7351617
   Blem E, 2013, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2013.6522302
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Carroll A, 2014, IEEE REAL TIME, P287, DOI 10.1109/RTAS.2014.6926010
   Koufaty D, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P125
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pricopi M., 2013, PROC CASES, P1
   Shelepov Daniel, 2009, Operating Systems Review, V43, P66, DOI 10.1145/1531793.1531804
   Springer D, 2014, IEEE IMAGE PROC, P2189, DOI 10.1109/ICIP.2014.7025443
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   Yoo S., 2015, P WORKSH POW AW COMP, P1
NR 14
TC 5
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25271
EP 25284
DI 10.1007/s11042-017-4413-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300040
DA 2024-07-18
ER

PT J
AU Alnusair, A
   Zhong, C
   Rawashdeh, M
   Hossain, MS
   Alamri, A
AF Alnusair, Awny
   Zhong, Chen
   Rawashdeh, Majdi
   Hossain, M. Shamim
   Alamri, Atif
TI Context-aware multimodal recommendations of multimedia data in cyber
   situational awareness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber situational awareness; Multimedia recommendation; Cyber security;
   Context awareness; Cloud computing
AB The current proliferation of large amounts of multimedia data creates an unprecedented challenge for security analysts in the context of Cyber Situational Awareness. Due to this phenomenal growth of multimedia data, security analysts have to invest enormous time and efforts in filtering and correlating multimedia data in order to make informed decisions about identifying and mitigating threats and vulnerabilities. In particular, analysts have to analyze and interpret diverse multimedia network data with varying contexts in order to find the true evidence of cyber attacks. Considering the multimedia nature of cyber security data, we propose a cloud-assisted recommendation system that can identify and retrieve multimedia data of interest based on contextual information and security analysts' personal preferences. This recommendation system benefits security analysts by establishing a bridge between their personal preferences, the contextual information of their analytical process, and the various types of modality of multimedia data. Evaluation of the proposed system shows evidence that our multimedia recommendation mechanisms promotes cyber threat understanding and risk assessment.
C1 [Alnusair, Awny; Zhong, Chen] Indiana Univ, Dept Informat & Comp Sci, Kokomo, IN 46904 USA.
   [Rawashdeh, Majdi] Princess Sumaya Univ Technol, Dept Management Informat Syst, Amman, Jordan.
   [Hossain, M. Shamim; Alamri, Atif] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim; Alamri, Atif] King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
C3 Indiana University System; Indiana University Kokomo; Princess Sumaya
   University for Technology; King Saud University; King Saud University
RP Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
EM alnusair@iuk.edu; chzhong@iuk.edu; m.rawashdeh@psut.edu.jo;
   mshossain@ksu.edu.sa; atif@ksu.edu.sa
RI Guizani, Mohsen/AAX-4534-2021; Alamri, Atif/KFQ-0028-2024; Alnusair,
   Awny/AAY-5066-2020; Hossain, M. Shamim/K-1362-2014
OI Guizani, Mohsen/0000-0002-8972-8094; Alamri, Atif/0000-0002-1887-5193;
   Alnusair, Awny/0000-0001-9513-3022; Hossain, M.
   Shamim/0000-0001-5906-9422; Zhong, Chen/0000-0003-2547-941X
FU Deanship of Scientific Research, King Saud University through Vice
   Deanship of Scientific Research Chairs
FX The authors are grateful to the Deanship of Scientific Research, King
   Saud University for supporting through Vice Deanship of Scientific
   Research Chairs.
CR Alhamid MF, 2016, MULTIMEDIA SYST, V22, P587, DOI 10.1007/s00530-015-0469-2
   [Anonymous], P 17 NAT COMP SEC C
   [Anonymous], J INF SECUR
   [Anonymous], MULTIMEDIA SYST
   [Anonymous], CMUSEI2003TR001 CARN
   [Anonymous], HDB RES MODERN CRYPT
   [Anonymous], RECENT ADV CYBER SA
   [Anonymous], 2015, PITCH BASED CARBON E
   [Anonymous], 2001, Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection
   [Anonymous], ASS ADV ARTIFICIAL I
   Cuppens F, 2002, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2002.1004372
   D'Amico A, 2008, MATH VISUAL, P19, DOI 10.1007/978-3-540-78243-8_2
   DAmico Anita, 2005, Proceedings of the Human Factors and Ergonomics Society 49th Annual Meeting, V49, P229, DOI DOI 10.1177/154193120504900304
   Dutt V, 2011, LECT NOTES COMPUT SC, V6818, P280, DOI 10.1007/978-3-642-22348-8_24
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Hossain MA, 2014, IEEE INT CON MULTI
   Hossain MS, 2016, IEEE WIREL COMMUN, V23, P44, DOI 10.1109/MWC.2016.7721741
   Hossain MS, 2013, MULTIMED TOOLS APPL, V67, P433, DOI 10.1007/s11042-012-1006-3
   Julisch K., 2003, ACM Transactions on Information and Systems Security, V6, P443, DOI 10.1145/950191.950192
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   MUKHERJEE B, 1994, IEEE NETWORK, V8, P26, DOI 10.1109/65.283931
   Pappas N, 2015, MULTIMED TOOLS APPL, V74, P1175, DOI 10.1007/s11042-013-1840-y
   Pombinho P., 2012, Proceedings of the Context-Awareness in Retrieval and Recommendation Workshop, in conjunction with IUI 2012 - International Conference on Intelligent User Interfaces, P30
   Ramezani Maryam, 2011, Journal of Emerging Technologies in Web Intelligence, V3, P168, DOI 10.4304/jetwi.3.2.168-176
   Rawashdeh M, 2016, MULTIMED TOOLS APPL, V75, P13299, DOI 10.1007/s11042-015-2813-0
   Rebollo O, 2015, INFORM SOFTWARE TECH, V58, P44, DOI 10.1016/j.infsof.2014.10.003
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Wang K., 2005, Recent Advances in Intrusion Detection. 8th International Symposium, RAID 2005. Revised Papers (Lecture Notes in Computer Science Vol. 3858), P227
   Wetzker R., 2010, WSDM 10, P71, DOI 10.1145/1718487.1718497.
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zhong C, 2015, 2015 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P165, DOI 10.1109/COGSIMA.2015.7108193
NR 31
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22823
EP 22843
DI 10.1007/s11042-017-4681-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200048
DA 2024-07-18
ER

PT J
AU El Kaddouhi, S
   Saaidi, A
   Abarkan, M
AF El Kaddouhi, S.
   Saaidi, A.
   Abarkan, M.
TI Eye detection based on the Viola-Jones method and corners points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye detection; Face detection; Viola-Jones detector; Corner points; Eye
   template
ID LOCALIZATION; SYSTEM; RECOGNITION; FEATURES; FATIGUE; ROBUST
AB Eyes detection is a very interesting field of research that verifies the presence of eyes and locates their positions in an image. Similarly, it is often the first step in such applications such as face recognition, human machine interaction systems, facial expression recognition, and driver fatigue monitoring systems. In this paper, we proposed a robust eye detection method based on the Viola and Jones method and corner points. Firstly, faces are detected by a system composed of two detectors of Viola-Jones (one for the frontal faces and the other for the profile faces). Secondly, we used the Shi-Tomasi detector (to detect corner points) and K-means (for clustering the neighbor corner points) to determine eye candidate regions. Thirdly, the localization of eyes is achieved by matching of these regions with an eye template. The results obtained show that our method is robust and provides superior performance compared to other recently published methods.
C1 [El Kaddouhi, S.; Saaidi, A.; Abarkan, M.] Sidi Mohamed Ben Abdellah Univ, Dept Math Phys & Comp Sci, Polydisciplinary Fac Taza, LSI, BP 1223, Taza, Morocco.
   [Saaidi, A.] Sidi Mohamed Ben Abdellah Univ, Dept Math & Comp Sci, Fac Sci, LIIAN, BP 1796, Atlas, Fez, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Kaddouhi, S (corresponding author), Sidi Mohamed Ben Abdellah Univ, Dept Math Phys & Comp Sci, Polydisciplinary Fac Taza, LSI, BP 1223, Taza, Morocco.
EM samir.elkaddouhi@usmba.ac.ma; abderrahim.saaidi@usmba.ac.ma;
   mustapha.abarkan@usmba.ac.ma
RI Saaidi, Abderrahim/R-1916-2019
OI Saaidi, Abderrahim/0000-0003-1708-0468
CR Abdel-Kader RF, 2014, ENG APPL ARTIF INTEL, V31, P90, DOI 10.1016/j.engappai.2013.06.017
   Al-Rahayfeh A, 2013, IEEE J TRANSL ENG HE, V1, DOI 10.1109/JTEHM.2013.2289879
   [Anonymous], 2016, BIOID FACE DATABASE
   [Anonymous], INT J SOFTWARE ENG I
   [Anonymous], 2016, FEI FACE DATABASE
   Bhatta L.K., 2014, International Journal of Engineering Research Technology (IJERT), V3, P1177
   Cheddad A, 2008, PATTERN RECOGN, V41, P3842, DOI 10.1016/j.patcog.2008.06.007
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Choi I, 2017, PATTERN RECOGN, V61, P417, DOI 10.1016/j.patcog.2016.08.009
   Choi SI, 2015, IEEE SIGNAL PROC LET, V22, P225, DOI 10.1109/LSP.2014.2335198
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   Ge SM, 2016, NEUROCOMPUTING, V173, P418, DOI 10.1016/j.neucom.2015.03.125
   Ghazali KH, 2015, OPT LASER ENG, V67, P49, DOI 10.1016/j.optlaseng.2014.11.003
   González-Ortega D, 2013, PATTERN ANAL APPL, V16, P285, DOI 10.1007/s10044-013-0331-0
   Gu JY, 2013, NEUROCOMPUTING, V113, P138, DOI 10.1016/j.neucom.2013.01.007
   Han ZC, 2014, MULTIMED TOOLS APPL, V68, P931, DOI 10.1007/s11042-012-1090-4
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hassaballah M, 2010, IET COMPUT VIS, V4, P261, DOI 10.1049/iet-cvi.2009.0097
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Jian M, 2013, ERA INTERACTIVE MEDI, P89, DOI [10.1007/978-1-4614-3501-3_8, DOI 10.1007/978-1-4614-3501-3_8]
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jung C, 2013, NEUROCOMPUTING, V113, P130, DOI 10.1016/j.neucom.2013.01.038
   Karaaba MF, 2014, ENG APPL ARTIF INTEL, V33, P69, DOI 10.1016/j.engappai.2014.04.008
   Kim C, 2012, IEEE T SYST MAN CY B, V42, P1095, DOI 10.1109/TSMCB.2012.2186798
   Lin YT, 2013, MULTIMED TOOLS APPL, V65, P543, DOI 10.1007/s11042-012-1202-1
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Monzo D, 2011, MACH VISION APPL, V22, P471, DOI 10.1007/s00138-010-0273-0
   Nanaa Kutiba, 2013, American Journal of Applied Sciences, V10, P1448, DOI 10.3844/ajassp.2013.1448.1456
   Ren JF, 2013, PATTERN RECOGN, V46, P45, DOI 10.1016/j.patcog.2012.06.013
   Ren Y, 2014, IEEE T IMAGE PROCESS, V23, P226, DOI 10.1109/TIP.2013.2287614
   Rusek K, 2016, MULTIMED TOOLS APPL, V75, P10617, DOI 10.1007/s11042-014-2114-z
   Sharma R, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063007
   Shi J, 1994, P IEEE C COMP VIS PA, DOI [10.3844/ajassp.2013.1448.1456, DOI 10.3844/AJASSP.2013.1448.1456]
   Siddiqi MH, 2015, MULTIMEDIA SYST, V21, P541, DOI 10.1007/s00530-014-0400-2
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Srutek M, 2010, ADV INTEL SOFT COMPU, V84, P361
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yu MX, 2016, TURK J ELECTR ENG CO, V24, P1586, DOI 10.3906/elk-1312-150
NR 42
TC 16
Z9 16
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 23077
EP 23097
DI 10.1007/s11042-017-4415-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200061
DA 2024-07-18
ER

PT J
AU Malik, A
   Sikka, G
   Verma, HK
AF Malik, Aruna
   Sikka, Geeta
   Verma, Harsh K.
TI Image interpolation based high capacity reversible data hiding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Image interpolation; NMI; Weighted neighbor mean
   interpolation; PSNR
ID DIFFERENCE EXPANSION; ALGORITHM
AB In this paper, we propose a new interpolation technique which considers all the neighboring pixels as well as their impact on the reference pixels to provide better quality interpolated image and a new data hiding scheme which embeds the secret data in the interpolated pixels by taking into account the human visual system so that quality of the resultant image is maintained. The proposed interpolation technique is an improvement of the existing neighbor mean interpolation (NMI) technique in such a way that the interpolated image would have more resemblance to the input image. The proposed interpolation technique has less computational cost like NMI as it does not perform much computation during estimation unlike B-Spline, Bilinear Interpolation etc. The proposed data hiding scheme comes into the category of reversible data hiding scheme as the input image can be reconstructed after extraction of the entire secret data at the receiver side. Thus, it reduces the communication cost. Furthermore, the proposed data hiding scheme identifies the smooth and complex regions of the interpolated (or cover) image by dividing the same into blocks. It then embeds more bits into the complex regions of the image so that data hiding capacity as well as the image quality can be enhanced. The experimental results shows that the percentage increment in the PSNR value and capacity of the proposed scheme with respect to Chang et al. method is in the range of 0.26 to 30.60% and 0.87 to 73.82%, respectively. Moreover, the modified NMI yields higher PSNRs than other interpolating methods such as NMI, BI, and ENMI.
C1 [Malik, Aruna; Sikka, Geeta; Verma, Harsh K.] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Malik, A; Sikka, G; Verma, HK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
EM arunacsrke@gmail.com; sikkag@nitj.ac.in; vermah@nitj.ac.in
RI Malik, Aruna/AAL-1997-2020; Malik, Aruna/GOH-0709-2022; Sikka,
   Geeta/X-8526-2019; Verma, Harsh Kumar/Y-4606-2019
OI Malik, Aruna/0000-0003-1136-6828; Verma, Harsh
   Kumar/0000-0003-4826-6150; Sikka, Geeta/0000-0003-4795-1842
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Jan SR, 2011, 7 INT C INT INF HID, P185
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee CF, 2010, INT J INNOV COMPUT I, V6, P5485
   Lee CF, 2010, J SYST SOFTWARE, V83, P832, DOI 10.1016/j.jss.2009.12.018
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sun HM, 2011, IEEE J SEL AREA COMM, V29, P1392, DOI 10.1109/JSAC.2011.110806
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang FS, 2012, DIGIT SIGNAL PROCESS, V22, P569, DOI 10.1016/j.dsp.2012.03.008
   Weng SW, 2008, INT J INNOV COMPUT I, V4, P351
   Yalman Y., 2010, Proceedings 2010 IEEE 13th International Conference on Computational Science and Engineering (CSE 2010), P346, DOI 10.1109/CSE.2010.52
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
NR 24
TC 20
Z9 20
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24107
EP 24123
DI 10.1007/s11042-016-4186-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700044
DA 2024-07-18
ER

PT J
AU Poignant, J
   Bredin, H
   Barras, C
AF Poignant, Johann
   Bredin, Herve
   Barras, Claude
TI Multimodal person discovery in broadcast TV: lessons learned from
   MediaEval 2015
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Benchmark; Information retrieval; Unsupervised person recognition;
   Multimodal fusion; Error analysis
ID DIARIZATION; VIDEO
AB We describe the "Multimodal Person Discovery in Broadcast TV" task of MediaEval 2015 benchmarking initiative. Participants were asked to return the names of people who can be both seen as well as heard in every shot of a collection of videos. The list of people was not known a priori and their names had to be discovered in an unsupervised way from media content using text overlay or speech transcripts. The task was evaluated using information retrieval metrics, based on a posteriori collaborative annotation of the test corpus. The first edition of the task gathered 9 teams which submitted 34 runs. This paper provides quantitative and qualitative comparisons of participants submissions. We also investigate why all systems failed for particular shots, paving the way for future promising research directions.
C1 [Poignant, Johann; Bredin, Herve; Barras, Claude] Univ Paris Saclay, Univ Paris Sud, LIMSI, CNRS, F-91405 Orsay, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Cite; Universite Paris Saclay
RP Poignant, J (corresponding author), Univ Paris Saclay, Univ Paris Sud, LIMSI, CNRS, F-91405 Orsay, France.
EM johann.poignant@imag.fr
FU French National Agency for Research [ANR-12-CHRI-0006-01]; Agence
   Nationale de la Recherche (ANR) [ANR-12-CHRI-0006] Funding Source:
   Agence Nationale de la Recherche (ANR)
FX This work was supported by the French National Agency for Research under
   grant ANR-12-CHRI-0006-01. The open source CAMOMILE collaborative
   annotation platform was used extensively throughout the progress of the
   task: from the run submission script to the automated leaderboard,
   including a posteriori collaborative annotation of the test corpus. We
   thank ELDA and INA for supporting the task by distributing development
   and test datasets.
CR [Anonymous], LREC
   Bechat F, 2014, INTERSPEECH, P607
   Bechet F, 2014, MULTIMODAL UNDERSTAN
   Bendris M, 2015, PERCOLATTE MULTIMODA
   Bendris M, 2013, UNSUPERVISED FACE ID
   Bernard G., 2013, SLAM INTERSPEECH
   Bredin H, 2012, ECCV IFCVCR
   Bredin H, 2014, PERSON INSTANCE GRAP
   Bredin H, 2013, SLAM INTERSPEECH
   Bredin H., 2014, IJMIR
   Bredin H, 2013, INTERSPEECH, P1466
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Budnik M, 2015, LIG MEDIAEVAL 2015 M
   Canseco L, 2005, ASRU
   Canseco-Rodriguez L, 2004, 5 ANN C SPEECH COMM
   CEJr dos Santos, 2015, SSIG IRISA MULTIMODA
   Chen S, 1998, DARPA BROADC NEWS WO
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damnati G, 2011, INT CONF ACOUST SPEE, P5684
   Dinarelli M, 2011, IJCNLP
   Esteve Y, 2007, INTERSPEECH
   Favre B, 2013, SLAM INTERSPEECH
   Gay P., 2014, CBMI
   Guillaumin M, 2012, FACE RECOGNITION CAP
   Houghton R, 1999, IEEE INTELL SYST, V14
   India M, 2015, MEDIAEVAL
   Jousse V, 2009, INT CONF ACOUST SPEE, P4557, DOI 10.1109/ICASSP.2009.4960644
   Kahn J, 2012, CBMI
   Khoury E, 2012, AUDIOVISUAL DIARIZAT
   Lamel L., 2011, IWSLT
   Le N, 2015, MEDIAEVAL
   Lopez-Otero P, 2015, MEDIAEVAL
   Mauclair J, 2006, IEEE ODYSSEY 2006 SP
   Nishi F, 2015, MEDIAEVAL
   Over Paul., 2011, TRECVID 2010-an overview of the goals, tasks, data, evaluation mechanisms, and metrics
   Petit-Renaud S, 2010, IDENTIFICATION SPEAK
   Pham P, 2010, NAMINGPERSONS NEWS V
   Pham P, 2011, NAMING PEOPLE NEWS V
   Poignant J, 2012, ICME
   Poignant J, NAMING MULTIMODAL CL
   Poignant J., 2012, INTERSPEECH
   Poignant J, 2016, LREC
   Poignant J, 2013, SLAM INTERSPEECH
   Poignant J., 2013, CORIA
   Poignant J, 2014, DOCUMENTS NUMERIQUES
   Poignant J, 2013, UNSUPERVISED AMING S
   Poignant J, 2015, UNSUPERVISED SPEAKER
   Poignant Johann, 2015, MEDIAEVAL 2015
   Rouvier M., 2014, CBMI
   Rouvier M, 2013, INTERSPEECH, P1476
   Sato T, 1999, ACM MULTIMEDIA SYSTE
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Tranter SE, 2006, ICASSP
   Uricar M., 2012, VISAPP
   Vallet F, 2013, IEEE T MULTIMEDIA, V15, P509, DOI 10.1109/TMM.2012.2233724
   Xiong W, 2017, IEEE-ACM T AUDIO SPE, V25, P2410, DOI 10.1109/TASLP.2017.2756440
   Yang J, 2004, ACM MULTIMEDIA
   Yang Jun., 2005, ACM Multimedia
   Yilmaz E, 2006, ACM INT C INF KNOWL
NR 60
TC 3
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22547
EP 22567
DI 10.1007/s11042-017-4730-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200034
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, BK
   Oh, SJ
   Jang, SB
   Ko, YW
AF Kim, Byung-Kwan
   Oh, Su-Jin
   Jang, Sung-Bong
   Ko, Young-Woong
TI File similarity evaluation scheme for multimedia data using partial hash
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE File similarity; File digest; Media data; Hash function
AB File similarity is a numerical indicator that how many duplicated data exist in target files. With this information, we can reduce storage capacity with data deduplication scheme, further it can be exploited in the digital forensic field for finding malicious software. However, measuring file similarity between files can cause a high overhead in terms of processing time and the capacity of disk storage. For this reason, in this paper, we propose a novel file similarity evaluation algorithm called PHISA (Partial Hash Information String Algorithm). To evaluate the performance of the proposed system, we compare PHISA to well-known file similarity tools. The evaluation result shows that PHISA reduces the processing time and increases the similarity evaluation accuracy.
C1 [Kim, Byung-Kwan; Oh, Su-Jin; Ko, Young-Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
   [Jang, Sung-Bong] Kumoh Natl Inst Technol, Dept Comp Software Engn, 61 Daehak Ro, Gumi 730701, Kyoung Buk, South Korea.
C3 Hallym University; Kumoh National University Technology
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM yuko@hallym.ac.kr
OI OH, SUJIN/0009-0008-2249-2217
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT and future Planning
   [2014R1A2A1A11054160]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT and future Planning(2014R1A2A1A11054160).
CR [Anonymous], 2009, FAST
   [Anonymous], 2012, USENIX ANN TECHN C M
   [Anonymous], 2009, 7 USENIX C FIL STOR
   Bhagwat D, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS & SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS (MASCOTS), P237
   Breitinger F., 2012, DIGITAL FORENSICS CY, P141
   Breitinger F, 2013, DIGIT INVEST, V10, pS50, DOI 10.1016/j.diin.2013.06.006
   Ji M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT RAIL TRANSPORTATION (ICIRT), P32, DOI 10.1109/ICIRT.2013.6696263
   Ko YW, 2013, IEICE T INF SYST, VE96D, P1544, DOI 10.1587/transinf.E96.D.1544
   Kornblum J, 2006, DIGIT INVESTIG, pS91, DOI 10.1016/j.diin.2006.06.015
   Li R, 2011, LECT NOTES COMPUT SC, V6612, P412, DOI 10.1007/978-3-642-20291-9_46
   MANBER U, 1994, PROCEEDINGS OF THE WINTER 1994 USENIX CONFERENCE, P1
   Meyer DT, 2012, ACM T STORAGE, V7, DOI 10.1145/2078861.2078864
   Muthitacharoen A., 2001, Operating Systems Review, V35, P174, DOI 10.1145/502059.502052
   Pucha H, 2007, EXPLOITING SIMILARIT
   Quinlan S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FAST'02 CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P89
   Roussev V, 2010, IFIP ADV INF COMM TE, V337, P207
   Roussev V, 2012, DIGIT INVEST, V9, pS60, DOI 10.1016/j.diin.2012.05.012
   Song L, 2013, P 15 IEEE INT C HIGH
   Xia Wen, 2011, 2011 USENIX ANN TECH
   Xia Wen., 2011, Proceedings of the USENIX Annual Technical Conference, USENIXATC'11, P26
   Yang J, 2014, WIT TRANS ENG SCI, V84, P1, DOI 10.2495/MEEE20130011
NR 21
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19649
EP 19663
DI 10.1007/s11042-016-3373-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500020
DA 2024-07-18
ER

PT J
AU Li, XX
   Cao, Q
   Wei, S
AF Li, Xi-Xi
   Cao, Qun
   Wei, Sha
TI 3D object retrieval based on multi-view convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Multi-view; CNN; Deep learning
ID MODEL
AB Recently, 3D objects have been widely designed and applied in various technical applications. In this paper, we propose a novel 3D model retrieval method based on Multi-View Convolutional Neural Networks (MVCNN). By integrating visual information from multiple views, we construct a composite CNN structure to generate single terse descriptor with powerful discrimination for individual 3D object. Our method can benefit from the hidden relevance of visual information in deep structure. Instead of computing similarities between each pair of view-feature, we only need to measure the comparability of two object once, which brings high efficiency. Moreover, this method can avoid camera constraint when capturing multi-view representation. Extensive experiments on NTU and ITI datasets can support the superiority of the proposed method.
C1 [Li, Xi-Xi; Cao, Qun] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Wei, Sha] China Elect Standardizat Inst, Beijing, Peoples R China.
C3 Tianjin University
RP Wei, S (corresponding author), China Elect Standardizat Inst, Beijing, Peoples R China.
EM weisha_2016@126.com
CR Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bai S, 2015, PATTERN RECOGN LETT, V65, P15, DOI 10.1016/j.patrec.2015.06.022
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen N, 2013, DIGIT SIGNAL PROCESS, V23, P1216, DOI 10.1016/j.dsp.2013.01.012
   Cheng YH, 2014, INT C PATT RECOG, P2377, DOI 10.1109/ICPR.2014.412
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Gao Z, 2016, IEEE T INSTRUM MEAS, P1
   Guo Y, 2016, VISUAL COMPUT, P1
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Hao T, 2014, BMC SYST BIOL, V8, DOI 10.1186/1752-0509-8-39
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu Q, 2012, COMPUTER SCI
   Lu K, 2014, IEEE T IMAGE PROCESS, V23, P4553, DOI 10.1109/TIP.2014.2343460
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie W, 2016, NEUROCOMPUTING
   Nie W, 2015, MULTIMEDIA SYST, P1
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tong H, 2016, INT J MOL SCI, V7
   Wang B, 2016, MOL BIOSYST, V12, P246, DOI 10.1039/c5mb00571j
   Wang Xiao-feng, 2012, Application Research of Computers, V29, P2350, DOI 10.3969/j.issn.1001-3695.2012.06.093
NR 37
TC 5
Z9 9
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20111
EP 20124
DI 10.1007/s11042-016-4250-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500046
DA 2024-07-18
ER

PT J
AU Wang, XN
   Zhang, C
   Wu, YJ
   Shu, YY
AF Wang, Xinnian
   Zhang, Chi
   Wu, Yanjun
   Shu, Yingying
TI A manifold ranking based method using hybrid features for crime scene
   shoeprint retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crime scene shoeprint; Manifold ranking; Shoeprint retrieval; Hybrid
   features
ID IMAGE; ROTATION
AB Shoeprints are frequently acquired at crime scenes and can provide vital clues for investigation. How to retrieve the most similar shoeprints available in the dataset to the highly degraded query crime scene shoeprint is a challenging work. Some existing shoeprint retrieval algorithms cannot work well with highly degraded shoeprint image on a large scale dataset, and the results are not well correlated with the forensic experts. This study proposes a manifold ranking based method using hybrid features of region and appearance to improve the retrieval performance. Manifold ranking method is introduced to narrow the well-known gap between visual features and semantic concepts. We define the ranking cost function from three perspectives: (i) the feature similarity between the query and the dataset images, (ii) the relationship between every two shoeprints in the dataset, (iii) the assigned opinion scores for multiple shoeprints left in one crime scene by the forensic expert. Experiments on the real crime scene datasets show that the cumulative match score of the proposed method is more than 93.5 % on the top 2 % of the dataset composed of 10096 crime scene shoeprints.
C1 [Wang, Xinnian] Dalian Maritime Univ, Informat & Commun Engn, 1 Linghai Rd, Dalian, Peoples R China.
   [Zhang, Chi; Wu, Yanjun; Shu, Yingying] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian, Peoples R China.
C3 Dalian Maritime University; Dalian Maritime University
RP Wang, XN (corresponding author), Dalian Maritime Univ, Informat & Commun Engn, 1 Linghai Rd, Dalian, Peoples R China.
EM wxn@dlmu.edu.cn; Ricezhang91@163.com; 420718992@qq.com; syydip@163.com
RI Wang, Xinnian/AAP-4328-2020
OI wang, xin nian/0000-0002-4574-1553
CR AlGarni G, 2008, FORENSIC SCI INT, V181, P10, DOI 10.1016/j.forsciint.2008.07.004
   [Anonymous], IEEE T SYST MAN CY B, DOI DOI 10.1109/TSMCB.2012.2198916
   Bouridane A, 2000, IEEE IMAGE PROC, P474, DOI 10.1109/ICIP.2000.900998
   Camps-Valls G, 2007, IEEE T GEOSCI REMOTE, V45, P3044, DOI 10.1109/TGRS.2007.895416
   Cervelli F, 2010, EUR SIGNAL PR CONF, P1665
   Crookes D, 2007, NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P67
   Dardi F, 2009, LECT NOTES COMPUT SC, V5716, P384, DOI 10.1007/978-3-642-04146-4_42
   Dardi F, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P668
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Chazal P, 2005, IEEE T PATTERN ANAL, V27, P341, DOI 10.1109/TPAMI.2005.48
   Deshmukh M.P., 2009, INT J COMPUT SCI COM, V2, P281
   Gueham Mourad, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P441
   Gueham M, 2008, INT C PATT RECOG, P484
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   He RH, 2009, 2009 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL II, P299, DOI 10.1109/CCCM.2009.5270431
   Kortylewski A, 2015, LECT NOTES COMPUT SC, V9008, P644, DOI 10.1007/978-3-319-16628-5_46
   Li ZW, 2011, INT C MULT TECHN HAN, P5488
   Nibouche O, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P94, DOI 10.1109/IMVIP.2009.24
   Patil PM, 2009, PATTERN RECOGN, V42, P1308, DOI 10.1016/j.patcog.2008.11.008
   Pavlou M, 2006, LECT NOTES COMPUT SC, V4224, P721
   Pavlou M, 2009, IMAGE VISION COMPUT, V27, P402, DOI 10.1016/j.imavis.2008.06.003
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Su H., 2007, P BRIT MACH VIS C WA, P1
   Tang Y, 2011, LECT NOTES COMPUT SC, V6540, P88, DOI 10.1007/978-3-642-19376-7_8
   Wan XJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2182
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang XN, 2015, ACCV, P399
   Wei CH, 2014, IEEE C EL EL ENG ISE, P1069
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Yi Tang, 2010, Proceedings of the 2010 IEEE International Conference on Granular Computing (GrC-2010), P459, DOI 10.1109/GrC.2010.175
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 34
TC 12
Z9 13
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21629
EP 21649
DI 10.1007/s11042-016-4029-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400058
DA 2024-07-18
ER

PT J
AU dos Santos, WHS
   Ataky, STM
   Silva, AC
   de Paiva, AC
   Gattass, M
AF dos Santos, Wallas Henrique S.
   Mpinda Ataky, Steve Tsham
   Silva, Aristofanes C.
   de Paiva, Anselmo C.
   Gattass, Marcelo
TI Automatic method for quantitative automatic evaluation in dynamic renal
   scintilography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; Nuclear medicine; Renal scintilography; Quantitative
   evaluation
ID GLOMERULAR-FILTRATION-RATE; TRANSIT-TIME; DECONVOLUTION; RADIONUCLIDES;
   CONSENSUS; RENOGRAM
AB Renal insufficiency is one of the most frequent health problems in Brazil and in the world. In some cases, the renal insufficiency symptoms are not easily perceived, and the disease may evolute to a more serious stage. Nuclear medicine is a specialty for human body image acquisition based on the use of radioisotopes for the analysis of some organ functionalities. Renal scintigraphy is an image based examination used for the diagnosing of problems in renal functions. This work presents an automatic method for quantitative analysis based on renal scintigraphy. The proposed methodology is capable of segmenting regions in the image associated with kidney, background, and aorta. Based on parameters obtained from these segmented images, it is possible to compute the glomerular filtration rate, renogram and renal transit time by deconvolution. The result obtained by the methodology were compared with results of a manual analysis made by a specialist, reaching promising results to be used in a clinical use.
C1 [dos Santos, Wallas Henrique S.; Gattass, Marcelo] Pontifical Catholic Univ Rio de Janeiro PUC Rio, BR-22430060 Rio De Janeiro, Brazil.
   [Mpinda Ataky, Steve Tsham] Univ Fed Sao Carlos, Rodovia Washington Luis,Km 235 SP-310, BR-13565905 Sao Carlos, SP, Brazil.
   [Silva, Aristofanes C.; de Paiva, Anselmo C.] Fed Univ Maranhao UFMA, BR-65065545 Sao Luis, Brazil.
C3 Pontificia Universidade Catolica do Rio de Janeiro; Universidade Federal
   de Sao Carlos; Universidade Federal do Maranhao
RP Ataky, STM (corresponding author), Univ Fed Sao Carlos, Rodovia Washington Luis,Km 235 SP-310, BR-13565905 Sao Carlos, SP, Brazil.
EM wallashs@tecgraf.puc-rio.br; steve.mpinda@dc.ufscar.br; ari@dee.ufma.br;
   paiva@deinf.ufma.br; mgattass@tecgraf.puc-rio.br
RI Paiva, Anselmo/L-2358-2013
OI Paiva, Anselmo/0000-0003-4921-0626
FU CAPES; CNPq; FAPEMA
FX The authors acknowledge CAPES, CNPq and FAPEMA for financial support. We
   thank the Clinica Nuclear Maranhao for provided image database.
CR [Anonymous], 2007, P 18 ANN ACM SIAM S
   Bajen MT, 1997, J NUCL MED, V38, P1295
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Durand E, 2008, SEMIN NUCL MED, V38, P82, DOI 10.1053/j.semnuclmed.2007.09.009
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, DOI DOI 10.1007/978-0-387-84858-7
   GATES GF, 1982, AM J ROENTGENOL, V138, P565, DOI 10.2214/ajr.138.3.565
   Kalman R.E., 1960, J BASIC ENG-T ASME, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   Kojima A, 1996, Ann Nucl Med, V10, P401
   Landgren M, 2011, LECT NOTES COMPUT SC, V6688, P489, DOI 10.1007/978-3-642-21227-7_46
   Lawson RS, 1999, PHYS MED BIOL, V44, pR57, DOI 10.1088/0031-9155/44/4/028
   Lin KJ, 2011, J DIGIT IMAGING, V24, P1010, DOI 10.1007/s10278-011-9361-6
   Marcuzzo M, 2007, P ANN INT IEEE EMBS, P3438, DOI 10.1109/IEMBS.2007.4353070
   OSIRIX, 2016, OS VIEW SOFTW
   Outcomes KDIG, 2012, KDIG 2012 CLIN PRACT
   Prigent A, 1999, SEMIN NUCL MED, V29, P146, DOI 10.1016/S0001-2998(99)80005-1
   RUSSELL CD, 1990, NUKLEARMED, V29, P170
   RUTLAND MD, 1985, NUCL MED COMMUN, V6, P11, DOI 10.1097/00006231-198501000-00003
   Shih F.Y., 2010, IMAGE PROCESSING MAT
   Stahl D, 2011, LECT NOTES COMPUT SC, V6688, P557, DOI 10.1007/978-3-642-21227-7_52
   Stevens LA, 2006, NEW ENGL J MED, V354, P2473, DOI 10.1056/NEJMra054415
   TAYLOR A, 1995, AM J ROENTGENOL, V164, P31, DOI 10.2214/ajr.164.1.7998566
   Ting K.M., 2010, Confusion Matrix, P209, DOI DOI 10.1007/978-0-387-30164-8_157
   VALENTINUZZI ME, 1975, MED BIOL ENG, V13, P123, DOI 10.1007/BF02478200
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Xefteris S, 2012, ENG TECHNOL APPL SCI, V2, P251
NR 25
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19291
EP 19315
DI 10.1007/s11042-017-4715-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800052
DA 2024-07-18
ER

PT J
AU Abedi, A
   Kabir, E
AF Abedi, Ali
   Kabir, Ehsanollah
TI Text image super resolution using within-scale repetition of characters
   and strokes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-image super resolution; Within-scale repetition; Frequent
   characters; Text-specific regularization; Example-based super resolution
ID SUPERRESOLUTION
AB In text images, there are some frequently used characters repeating more than others. Likewise, some characters have common strokes. This characteristic is used in this paper for machine-printed text-image super resolution. After segmenting the input low-resolution image into text lines and characters, 1) the characters are clustered and the clusters with large number of members, corresponding to the frequent characters, are detected. 2) A text-specific multiple-image super resolution is applied to the members of each large cluster and the result is verified by the recognition confidence of an OCR system. 3) A training example set is then constructed by extracting patches from the low-resolution frequent characters and their verified super resolution. Using this example set, infrequent characters are super resolved through the neighbor embedding SR algorithm. By placing all the super-resolved characters on their corresponding positions in the high-resolution grid, the final high-resolution image is generated. Our method achieves significant improvements in visual image quality and OCR character accuracy compared to related SR methods.
C1 [Abedi, Ali; Kabir, Ehsanollah] Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Abedi, A (corresponding author), Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
EM ali.abedi@modares.ac.ir
RI Abedi, Ali/B-4835-2013; kabir, ehsanollah/D-1708-2010
OI Abedi, Ali/0000-0001-7879-9375; kabir, ehsanollah/0000-0002-5610-7611;
   Abedi, Ali/0000-0002-7393-1362
CR Abedi A, 2016, IET IMAGE PROCESS, V10, P158, DOI 10.1049/iet-ipr.2014.1021
   Andrew KDC, 2011, STAT PATTERN RECOGNI
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Chan TM, 2009, PATTERN RECOGN LETT, V30, P494, DOI 10.1016/j.patrec.2008.11.008
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen X, 2014, DOCUMENT IMAGE SUPER
   Dai D., 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/WACV.2016.7477613
   Datsenko D, 2007, MULTIDIM SYST SIGN P, V18, P103, DOI 10.1007/s11045-007-0018-z
   Donaldson K., 2005, International Journal on Document Analysis and Recognition, V7, P159, DOI 10.1007/s10032-004-0139-y
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Lu Y., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P440, DOI 10.1109/ICDAR.1993.395699
   Luong HQ, 2008, INT J DOC ANAL RECOG, V11, P39, DOI 10.1007/s10032-008-0068-2
   Ma D, 2013, IS T SPIE ELECT IMAG
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nayef N, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P227, DOI 10.1109/DAS.2014.25
   Peyrard C, 2015, PROC INT CONF DOC, P1201, DOI 10.1109/ICDAR.2015.7333951
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Thouin P. D., 2000, International Journal on Document Analysis and Recognition, V2, P200, DOI 10.1007/s100320050006
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Walha R, 2015, IJDAR, P1
   Walha R, 2016, IET IMAGE PROCESS, V10, P325, DOI 10.1049/iet-ipr.2015.0334
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 27
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16415
EP 16438
DI 10.1007/s11042-016-3919-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100016
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Jeong, HY
AF Joo, Hae-Jong
   Jeong, Hwa-Young
TI Implementation of quality coverage map system via wireless communication
   service and big data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless communication service big data; Coverage map; Statistics map;
   Service quality of experience; Service quality
AB The objective of this study is to realize the big data service quality maps of mobile communication companies, so that the users can objectively compare communication service qualities and make a reasonable choice. A measurement software was installed on smart phones for the purpose of measuring the service qualities of experience by the users. Furthermore, a measurement of five wireless internet services (broadband LTE, LTE-A, LTE, 3G, WiBro, and WiFi) was performed for evaluating the qualities of the service provider networks and the nationwide qualities. The measured data were stored and periodically uploaded to the database. These data were stored in PostGIS spatial DBMS through the connection of DBs, and they were connected to GeoServer for sharing and editing the geospatial data. The measured data were realized into coverage maps by using Google Maps. The coverage range was defined in Google Maps, and the defined range was divided by a specific cell (approximately 100 m x 100 m). The measured GPS ranges of each cell were retrieved from the quality data collection server table, and their average values were used for organizing and updating the coverage maps. These contents were stored in GeoServer, retrieved by database queries, and provided as visible layers in OpenLayers. In addition, statistical coverage maps via Flash maps were provided.
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
EM hjjoo@dongguk.edu; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 2002, METHODOLOGY SUBJECTI
   [Anonymous], 2000, J143 ITUT
   Cho M-h, 2003, KICS
   Choi S, 2011, IFIP WIREL DAY
   Dai Q, 2010, IEEE INTERNET
   Dunham MH, 1999, P INT WORKSH DAT ENG, P14
   Ekman C, 2013, The U.S. Registered Patent, Patent No. 0279354
   Joo H, 2013, LECT NOTES ELECT ENG
   Joo H-J, 2015, QUALITY MEASUREMENT
   Kim H, 2010, IEEE ICACT
   Lee J-h, 2010, E BUSINESS RES, V11
   Lee J-W, 2011, DES RES, V24
   Maier G, 2010, LECT NOTES COMPUT SC, V6032, P161, DOI 10.1007/978-3-642-12334-4_17
   조대균, 2011, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V9, P109
   Shmueli R, 2008, IEEE T BROADCAST, V54, P628, DOI 10.1109/TBC.2008.2001242
   주해종, 2005, [The KIPS Transactions : Part D, 정보처리학회논문지D], V12, P521
NR 16
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17353
EP 17370
DI 10.1007/s11042-017-4360-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500026
DA 2024-07-18
ER

PT J
AU Lee, EC
   Park, MW
AF Lee, Eui Chul
   Park, Min Woo
TI Music chord recommendation of self composed melodic lines for making
   instrumental sound
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music Chords; Automatic Music Chord Recommendation; Harmony
ID AUDIO; KEY
AB Music chords are important to enable musical instruments to be played harmonically. Therefore, appropriate chord determination is essential. However, automatic chord determination using only monotonic melodic information is very difficult because chords can be subjectively variable. In this paper, we propose a method for the appropriate basic chord recommendation of melodic lines. The proposed method functions by using the notes feature of each bar based on the theory of harmony. The feature is defined by the pitch and duration of each note. Also, two chords in a bar can be estimated by using bar segmentation policy based on statistical analysis. The experimental results showed that compared with the original songs, an overall accuracy of 92.04 % (81 recommended chords/88 bars) was achieved. Subsequently, the proposed method was applied to our self-composed songs for which chords had not been determined. The results confirmed that the chords derived by our proposed method were fairly harmonious with the songs.
C1 [Lee, Eui Chul] Sangmyung Univ, Dept Comp Sci, Seoul, South Korea.
   [Park, Min Woo] Sangmyung Univ, Grad Sch, Dept Comp Sci, Seoul, South Korea.
C3 Sangmyung University; Sangmyung University
RP Park, MW (corresponding author), Sangmyung Univ, Grad Sch, Dept Comp Sci, Seoul, South Korea.
EM nogood79dle@gmail.com
RI lee, eui chul/E-1107-2013
FU Sangmyung University
FX This research was supported by a 2015 Research Grant from Sangmyung
   University
CR CHEN CH, 1969, IEEE T SYST SCI CYB, VSSC5, P30, DOI 10.1109/TSSC.1969.300241
   Lee K, 2008, IEEE T AUDIO SPEECH, V16, P291, DOI 10.1109/TASL.2007.914399
   Mauch M, 2010, IEEE T AUDIO SPEECH, V18, P1280, DOI 10.1109/TASL.2009.2032947
   McVicar M, 2014, IEEE-ACM T AUDIO SPE, V22, P556, DOI 10.1109/TASLP.2013.2294580
   Min Woo Park, 2013, WSEAS Transactions on Information Science and Applications, V10, P381
   MOOG B, 1986, J AUDIO ENG SOC, V34, P394
   Ni YZ, 2013, IEEE T AUDIO SPEECH, V21, P2607, DOI 10.1109/TASL.2013.2280218
   Ni YZ, 2012, IEEE T AUDIO SPEECH, V20, P1771, DOI 10.1109/TASL.2012.2188516
   Pauwels J, 2011, IEEE INT C MULTIMED, V2011, P1
   Rocher T., 2010, 11 INT SOC MUSIC INF, P141, DOI DOI 10.5281/ZENODO.1417485
   Shenoy A, 2005, COMPUT MUSIC J, V29, P75, DOI 10.1162/0148926054798205
   Zenz V, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1175
NR 12
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17255
EP 17271
DI 10.1007/s11042-016-3984-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500021
DA 2024-07-18
ER

PT J
AU Kim, H
   Cha, M
   Mun, D
AF Kim, Hyungki
   Cha, Moohyun
   Mun, Duhwan
TI Shape distribution-based retrieval of 3D CAD models at different levels
   of detail
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D CAD model retrieval; Freehand 2D sketch; Different LODs; Model
   simplification; Shape distribution-based comparison
ID DESIGN; PART; SIMPLIFICATION; SIMILARITY; SYSTEM; SHIP
AB With increasing design reuse in modern products, accurate and efficient 3D CAD model retrieval methods are required. To improve retrieval capability, a 3D shape comparison method is often utilized. In this method, the shapes of 3D CAD models in a database are compared with the shape given by a user. Meanwhile, for rapid generation of query models, a freehand sketch-based modeling method is adopted for retrieval systems. This method creates a low-level-of-detail (low-LOD) 3D CAD model with abbreviated exterior shapes. On the other hand, the target 3D CAD model in the database is a high-LOD 3D CAD model including detailed shapes of a product or components of a product. Considering different LODs of query and target models, we propose a new 3D CAD model retrieval method consisting of a 3D CAD model simplification system and a shape distribution-based shape comparison engine that compares multi-resolution models in a database to improve retrieval accuracy using a query model with simple shape. Experiment is conducted on 64 LOD models generated from 8 test cases and 8 query models generated by freehand sketch-based modelling method. Result shows a 200 % improvement on retrieval success rate for lower LOD models (100 %) compared with source models (50 %). Moreover, the proposed method has an advantage on efficiency, due to the simple calculation method and short computation time.
C1 [Kim, Hyungki; Cha, Moohyun] Korea Inst Machinery & Mat, Mech Syst Safety Res Div, 156 Gajeongbuk Ro, Daejeon 305701, South Korea.
   [Mun, Duhwan] Kyungpook Natl Univ, Dept Precis Mech Engn, 2559 Gyeongsang Daero, Sangju 742711, Gyeongsangbuk D, South Korea.
C3 Korea Institute of Machinery & Materials (KIMM); Kyungpook National
   University
RP Mun, D (corresponding author), Kyungpook Natl Univ, Dept Precis Mech Engn, 2559 Gyeongsang Daero, Sangju 742711, Gyeongsangbuk D, South Korea.
EM diskhkme@gmail.com; mhcha@kimm.re.kr; dhmun@knu.ac.k
RI Mun, Duhwan/AAV-6700-2021; Mun, Duhwan/AAC-5360-2020
OI Mun, Duhwan/0000-0002-5477-0671; 
FU Civil-Military Technology [14-CM-MC-15]; Industrial Core Technology
   Development Program - Ministry of Trade, Industry and Energy [10048341];
   Plant Research Program - Ministry of Land, Infrastructure and Transport
   of the Korean government [14IFIP-B091004-01]
FX This research was supported by the Civil-Military Technology (Project
   ID: 14-CM-MC-15), the Industrial Core Technology Development Program
   (Project ID: 10048341) funded by the Ministry of Trade, Industry and
   Energy, and the Plant Research Program (Project ID: 14IFIP-B091004-01)
   funded by the Ministry of Land, Infrastructure and Transport of the
   Korean government. The authors gratefully acknowledge this support.
CR [Anonymous], P IEEE, DOI DOI 10.1109/PR0C.1984.13073
   [Anonymous], 2005, COMPUTER AIDED DESIG
   Cheon SU, 2008, COMPUT AIDED DESIGN, V40, P975, DOI 10.1016/j.cad.2008.07.006
   Cheon SU, 2012, COMPUT AIDED DESIGN, V44, P123, DOI 10.1016/j.cad.2011.10.003
   Contero M, 2004, P EUROGRAPHICS WORKS
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P83, DOI 10.1016/S0010-4485(01)00177-4
   Foucault G, 2008, COMPUT AIDED DESIGN, V40, P176, DOI 10.1016/j.cad.2007.10.009
   GUNN TG, 1982, SCI AM, V247, P114, DOI 10.1038/scientificamerican0982-114
   Hoppe H, 1996, P ACM SIGGRAPH
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Kallio K., 2005, P 2 EUR WORKSH SKET
   Kang Y, 2014, J MAR SCI TECH-JAPAN, V19, P185, DOI 10.1007/s00773-013-0239-9
   Koo S, 2002, COMPUT GRAPH-UK, V26, P687, DOI 10.1016/S0097-8493(02)00124-3
   Kwon S, 2015, J COMPUT INF SCI ENG, V15, DOI 10.1115/1.4030748
   Kwon S, 2015, COMPUT AIDED DESIGN, V59, P140, DOI 10.1016/j.cad.2014.03.003
   Lee SH, 2012, COMPUT AIDED DESIGN, V44, P457, DOI 10.1016/j.cad.2011.12.005
   Leizerowicz W., 1996, P WET ICE 96
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pu J., 2006, 14 PAC C COMP GRAPH
   Ramesh M., 2001, Journal of Computing and Information Science in Engineering, V1, P245, DOI DOI 10.1115/1.1412456
   Rodríguez MA, 2003, IEEE T KNOWL DATA EN, V15, P442, DOI 10.1109/TKDE.2003.1185844
   Sheffer A, 2001, COMPUT AIDED DESIGN, V33, P925, DOI 10.1016/S0010-4485(00)00116-0
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
NR 27
TC 16
Z9 18
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15867
EP 15884
DI 10.1007/s11042-016-3881-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900029
DA 2024-07-18
ER

PT J
AU Liu, CZ
   Chen, QC
   Li, HC
AF Liu, Chanzi
   Chen, Qingchun
   Li, Hengchao
TI Single Image Super-Resolution Reconstruction Technique based on A Single
   Hybrid Dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Hybrid dictionary; Degeneration model
ID LARGE UNDERDETERMINED SYSTEMS; EQUATIONS
AB A new sparse domain approach is proposed in this paper to realize the single image super-resolution (SR) reconstruction based upon one single hybrid dictionary, which is deduced from the mixture of both the high resolution (HR) image patch samples and the low resolution (LR) ones. Moreover, a linear model is proposed to characterize the relationship between the sparse representations of both the HR image patches and the corresponding LR ones over the same hybrid dictionary. It is shown that, the requirement on the identical sparse representation of both HR and LR image patches over the corresponding HR dictionary and the LR dictionary can be relaxed. It is unveiled that, the use of one single hybrid dictionary can not only provide a more flexible framework to keep the similar sparse characteristics between the HR patches and the corresponding degenerated LR patches, but also to accommodate their differences. On this basis, the sparse domain based SR reconstruction problem is reformulated. Moreover, the proposed linear model between the sparse representations of both the HR patch and the corresponding LR patch over the same hybrid dictionary offers us a new method to interpret the image degeneration characteristics in sparse domain. Finally, practical experimental results are presented to test and verify the proposed SR approach.
C1 [Liu, Chanzi; Chen, Qingchun; Li, Hengchao] Southwest Jiaotong Univ, Key Lab Informat Coding & Transmiss, Chengdu, Peoples R China.
C3 Southwest Jiaotong University
RP Liu, CZ (corresponding author), Southwest Jiaotong Univ, Key Lab Informat Coding & Transmiss, Chengdu, Peoples R China.
EM liuchanzi@126.com; qcchen@swjtu.edu.cn; hcli@swjtu.edu.cn
RI Chen, Qingchun/AFP-1317-2022
FU NSFC [61271246, 61371165]
FX The authors would like to thank the NSFC under grant No. 61271246 and
   no. 61371165 for financial support.
CR Ai N, 2016, MULTIMED TOOLS APPL, V75, P6647, DOI 10.1007/s11042-015-2597-2
   [Anonymous], 2000, SURPRISINGLY EFFECTI
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Gowreesunker BV, 2010, IEEE T SIGNAL PROCES, V58, P3055, DOI 10.1109/TSP.2010.2044251
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Moustapha M., 2015, P 12 INT C APPL STAT, P12
   Murray JF, 2006, J VLSI SIG PROC SYST, V45, P97, DOI 10.1007/s11265-006-9774-5
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Shaker GM, 2013, NAT RADIO SCI CO, P306
   Sun Y, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2015.2511080
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JJ, 2016, MULTIMED TOOLS APPL, V75, P13107, DOI 10.1007/s11042-015-2744-9
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 27
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14759
EP 14779
DI 10.1007/s11042-016-4022-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400012
DA 2024-07-18
ER

PT J
AU Nie, L
   Huang, YL
   Xu, Y
AF Nie, Lei
   Huang, Yaolong
   Xu, Yan
TI Distribution and evolutionary of turfy soil identified by remote-sensing
   images based on fuzzy evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Turfy soil; Block analysis; Fuzzy evaluation; Membership degree;
   Evolutionary mechanism; remote sensing
ID MOISTURE; AREA
AB Turfy soil is a kind of special soil accumulated by undecomposed plants which is detrimental to the engineering. In this paper, particular identified patterns for the turfy soil in the northeast of China was raised including the method of extracting threshold value, block analysis and fuzzy evaluation. And field investigations were undertaken to verify the accuracy of identification by remote sensing, and the correlation of field result and remote sensing result was summarized so as to analyze the regularities of distribution and evolutionary mechanism of turfy soil. The result shows that the combination of extracting threshold value, block analysis and fuzzy evaluation are effective methods to predict the distribution of the turfy soil; with the correlation of membership degree and field result, we can analyze the evolutionary mechanism of turfy soil affected by both nature factors and human activities, which is beneficial for the preservation of the turfy soil and also shows significant environmental ecological benefit.
C1 [Nie, Lei; Huang, Yaolong] Jilin Univ, Changchun, Peoples R China.
   [Xu, Yan] Jilin Univ, Coll Construct Engn, Changchun, Peoples R China.
C3 Jilin University; Jilin University
RP Nie, L (corresponding author), Jilin Univ, Changchun, Peoples R China.
EM leiniejlu@163.com
FU National Natural Science Foundation of China [41502272, 41572254]; Basic
   Research Foundation of Jilin University [450060491447]; Science and
   Technology Development Program of Jilin Province [20150520077JH]; China
   Postdoctoral Science Foundation [2014M551453]
FX This project was financially supported by the National Natural Science
   Foundation of China (Grant NO. 41502272, Grant NO. 41572254), the Basic
   Research Foundation of Jilin University (Grant NO. 450060491447),
   Science and Technology Development Program of Jilin Province (Grant NO.
   20150520077JH) and China Postdoctoral Science Foundation (Grant No.
   2014M551453). All of them are gratefully acknowledged.
CR Bai X, 2015, INT J REMOTE SENSING, V36
   Bai XJ, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096062
   Bocco M, 2015, INT J REMOTE SENSING, V35
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Boylan N, 2008, Q J ENG GEOL HYDROGE, V41, P93, DOI 10.1144/1470-9236/06-028
   Campbell JB., 1996, Cartographica, V2
   Canters F, 1997, PHOTOGRAMM ENG REM S, V63, P403
   Chapin FS, 2000, NATURE, V405, P234, DOI 10.1038/35012241
   Chen NC, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.097097
   Du YJ, 2016, MULTIMED TOOLS APPL, V75, P987, DOI 10.1007/s11042-014-2338-y
   Dykes A, 2008, Q J ENG GEOL HYDROGE, V44, P5
   Friedl MA, 2002, REMOTE SENS ENVIRON, V83, P287, DOI 10.1016/S0034-4257(02)00078-0
   Godio A, 2014, Q J ENG GEOL HYDROGE, V47, P351, DOI 10.1144/qjegh2014-015
   Goodin DG, 2015, INT J REMOTE SENSING, V36
   Gropius M, 2010, Q J ENG GEOL HYDROGE, V43, P23, DOI 10.1144/1470-9236/08-105
   Guellala R, 2016, HYDROLOG SCI J, V61, P636, DOI 10.1080/02626667.2014.914213
   Han YM, 2012, COMM COM INF SC, V267, P599
   Hao LB, 2014, ORE GEOL REV, V63, P226, DOI 10.1016/j.oregeorev.2014.05.017
   He T, 2015, J APPL REMOTE SENS, V8
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Huang ZK, 2008, APPL MATH COMPUT, V205, P899, DOI 10.1016/j.amc.2008.05.130
   Jenicka S, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083540
   Kalra GS, 2016, MULTIMED TOOLS APPL, V75, P4467, DOI 10.1007/s11042-015-2484-x
   Krankina ON, 2011, EURASIAN ARCTIC LAND COVER AND LAND USE IN A CHANGING CLIMATE, P79, DOI 10.1007/978-90-481-9118-5_5
   Kumar P, 2015, INT J REMOTE SENSING, V36
   Lee EM, 2015, Q J ENG GEOL HYDROGE, V48, P147, DOI 10.1144/qjegh2014-048
   Lei N, 2015, ASIAN J CHEM, V25, P10150
   Liao KH, 2013, SOIL SCI PLANT NUTR, V59, P488, DOI 10.1080/00380768.2013.802643
   Liu TG, 2016, MULTIMED TOOLS APPL, V75, P5417, DOI 10.1007/s11042-015-2510-z
   Liu Y, 2014, ADV MATER RES-SWITZ, V864-867, P2695, DOI 10.4028/www.scientific.net/AMR.864-867.2695
   Long M, 2013, Q J ENG GEOL HYDROGE, V46, P303, DOI 10.1144/qjegh2011-063
   Lv Y, 2012, APPL MECH MATER, V105-107, P1551, DOI 10.4028/www.scientific.net/AMM.105-107.1551
   Maxwell AE, 2015, INT J REMOTE SENSING, V36
   Meyer W, 1994, CHANGES LAND USE LAN, P437
   Nie L, 2012, Q J ENG GEOL HYDROGE, V45, P435, DOI 10.1144/qjegh2010-042
   Osinowo OO, 2012, J GEOPHYS ENG, V9, P374, DOI 10.1088/1742-2132/9/4/374
   Pont D, 2015, INT J REMOTE SENSING, V36
   Reschke J, 2012, REMOTE SENS-BASEL, V4, P2923, DOI 10.3390/rs4102923
   Saha S, 2015, MULTIMED TOOLS APPL, V74, P10621, DOI 10.1007/s11042-014-2196-7
   Sela S, 2014, REMOTE SENS-BASEL, V6, P7469, DOI 10.3390/rs6087469
   Singh PP, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083526
   Tang S, 2012, MAT PROCESS TECHNOL, V538-541
   Wang YJ, 2014, IEEE J-STARS, V7, P3892, DOI 10.1109/JSTARS.2014.2345743
   Xu C, 2015, INT J REMOTE SENSING, V36
   [徐惠风 XU Huifeng], 2006, [生态环境, Ecology and Environment], V15, P120
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yan Y, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083647
   Yilmaz I, 2015, Q J ENG GEOL HYDROGE, V48, P124, DOI 10.1144/qjegh2014-087
   Zakeri F, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.095043
   Zhang T, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083558
   Zhu AX, 2010, GEODERMA, V158, P199, DOI 10.1016/j.geoderma.2010.05.001
NR 52
TC 1
Z9 1
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14635
EP 14651
DI 10.1007/s11042-016-3842-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400006
DA 2024-07-18
ER

PT J
AU Zhao, L
   Dong, X
   Chen, WY
   Jiang, LF
   Dong, XJ
AF Zhao, Long
   Dong, Xue
   Chen, WeiYang
   Jiang, LinFeng
   Dong, XiangJun
TI The combined cloud model for edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crack detection; Combined cloudmodel; Distribution rule; Membership
   degree
ID CRACK DETECTION METHOD
AB With the support of modern dam facilities, many dams are equipped with multiple cameras. A large number of labeled images can be provided by the crack extraction process. But the most existed dam crack detection algorithms are based on one image. A new dam crack detection algorithm based on combined cloud model (CCM) is proposed in this paper. The algorithm can effectively utilize the detected image. The randomness and fuzziness of cracks are expressed by unified mathematical model. The algorithm extracts the pixel distribution rulers of crack and background through training samples. The expectation, entropy and hyper entropy of concept clouds are calculated based on the inverse cloud model. The concepts of the foreground crack and background are extracted by CMM. The membership degree of each pixel is calculated for crack detection. The results of experiment show that CMM algorithm has a good universality. The CMM method can extract the background and foreground concepts. Segmentation results show that our method performs well in eliminating noise points and detecting cracks.
C1 [Zhao, Long; Chen, WeiYang; Jiang, LinFeng; Dong, XiangJun] QiLu Univ Technol, Qilu, Shandong, Peoples R China.
   [Dong, Xue] Jinan Univ, Sch Math Sci, Jinan, Shandong, Peoples R China.
C3 Qilu University of Technology; University of Jinan
RP Zhao, L; Dong, XJ (corresponding author), QiLu Univ Technol, Qilu, Shandong, Peoples R China.
EM zxcvbnm9515@163.com; d-xj@163.com
RI huang, libo/JMB-4345-2023; chen, weiyu/M-5972-2018; Dong,
   Xiangjun/AAJ-3630-2021; Chen, WY/HKN-5931-2023
OI chen, weiyu/0000-0003-4436-2743; Dong, Xiangjun/0000-0002-5364-5844; 
FU National Natural Science Foundation of China [71271125, 61502260];
   Natural Science Foundation of Shandong Province, China [ZR2011FM028]
FX This work was supported by the National Natural Science Foundation of
   China (71271125, 61502260) and Natural Science Foundation of Shandong
   Province, China (ZR2011FM028).
CR Abdel-Qader I, 2006, ADV ENG SOFTW, V37, P771, DOI 10.1016/j.advengsoft.2006.06.002
   Abdel-Qader L, 2003, J COMPUT CIVIL ENG, V17, P255, DOI 10.1061/(ASCE)0887-3801(2003)17:4(255)
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Fujita Y, 2011, MACH VISION APPL, V22, P245, DOI 10.1007/s00138-009-0244-5
   Ito A, 2002, IEEE IND ELEC, P2202
   Iyer S, 2005, IMAGE VISION COMPUT, V23, P921, DOI 10.1016/j.imavis.2005.05.017
   Jahanshahi Mohammad R., 2013, Machine Vision and Applications, V24, P227, DOI 10.1007/s00138-011-0394-0
   Jeon G, 2012, MULTIMED TOOLS APPL, V59, P149, DOI 10.1007/s11042-010-0694-9
   Jia XB, 2016, MULTIMED TOOLS APPL, V75, P1099, DOI 10.1007/s11042-014-2359-6
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Kazakova W, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P913
   Landström A, 2012, IEEE J-STSP, V6, P866, DOI 10.1109/JSTSP.2012.2212416
   Lee JH, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P363
   Lopez-Molina C, 2014, INFORM SCIENCES, V278, P127, DOI 10.1016/j.ins.2014.03.028
   Oh AR, 2015, MULTIMED TOOLS APPL, V74, P1
   PAL SK, 1983, IEEE T PATTERN ANAL, V5, P69, DOI 10.1109/TPAMI.1983.4767347
   Qin K., 2006, Journal of Geomatics, V31, P3
   Robinson GS, 1975, P SPIE INT SOC OPT E, V87, P117
   Setayesh M, 2013, INFORM SCIENCES, V246, P28, DOI 10.1016/j.ins.2013.05.031
   Sharifi M, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P117, DOI 10.1109/ITCC.2002.1000371
   Subirats P, 2006, IEEE IMAGE PROC, P3037, DOI 10.1109/ICIP.2006.313007
   Tsai Y, 2011, AUTOM CONSTR, V31, P10
   Xu DQ, 2017, MULTIMED TOOLS APPL, V76, P17839, DOI 10.1007/s11042-015-3097-0
   Yamaguchi T, 2010, MACH VISION APPL, V21, P797, DOI 10.1007/s00138-009-0189-8
   Yang L, INT C IM SIGN PROC I, P1197
   Zhu ZH, 2011, AUTOMAT CONSTR, V20, P874, DOI 10.1016/j.autcon.2011.03.004
NR 26
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15007
EP 15026
DI 10.1007/s11042-017-4411-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400026
DA 2024-07-18
ER

PT J
AU Norouzi, B
   Mirzakuchaki, S
AF Norouzi, Benyamin
   Mirzakuchaki, Sattar
TI An image encryption algorithm based on DNA sequence operations and
   cellular neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA operations; Cellular neural network;
   Bit-substitution
ID SCHEME; PERMUTATION; SYSTEM
AB This paper presents a new way of image encryption based on biologic DNA sequence operations and Cellular Neural Network (CNN), which consists of three processes; bit-substitution, key stream generation process, and diffusion process. Firstly, a plain-image is equally divided into four sub-images and a DNA sequence matrix of each sub-image is obtained. Then we employed the hamming distance (between DNA sequences) and DNA sequence operation to encrypt each DNA sub-image. The second process is a pseudo-random key stream generator based on Cellular Neural Network. The parameters and initial conditions of the CNN system are derived using a 256 bit-long external secret key by applying some algebraic transformations to the key. The original key stream is related to the plain-image which increases the level of security and key sensitivity of the proposed algorithm. In the final process, we use the chaotic sequences generated by CNN to modify the pixel gray level values and crack the strong correlations between adjacent pixels of an image simultaneously. This feature will significantly increase plaintext sensitivity. Moreover, in order to reach higher security and higher complexity, the proposed method employs the image size in key stream generation process. The experimental results reveal that the new image encryption algorithm has the advantages of large key space (2(256)), high security, high sensitivity (Number of Pixels Change Rate: NPCR > 99.6201 %, Unified Average Changing Intensity: UACI > 33.5065 %), and high entropy (> 7.9975). Also, the distribution of gray level values of the encrypted image has a semi-random behavior.
C1 [Norouzi, Benyamin; Mirzakuchaki, Sattar] Iran Univ Sci & Technol, Sch Elect Engn, Elect Res Ctr, POB 16846-13114, Tehran, Iran.
C3 Iran University Science & Technology
RP Norouzi, B (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Elect Res Ctr, POB 16846-13114, Tehran, Iran.
EM Benyamin_Norouzi@elec.iust.ac.ir; M_Kuchaki@iust.ac.ir
RI Mirzakuchaki, Sattar/JCO-4452-2023; Mirzakuchaki, Sattar/I-8764-2016
OI Mirzakuchaki, Sattar/0000-0003-0232-9267
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chou JK, 2016, MULTIMED TOOLS APPL, V75, P13805, DOI 10.1007/s11042-015-2917-6
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Ghebleh M, 2013, IMAGE COMMU IN PRESS
   Hermassi H., 2013, MULTIMED TOOLS APPL, P1
   Huang JJ, 2012, OPT LASER TECHNOL, V44, P2238, DOI 10.1016/j.optlastec.2012.02.032
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li CQ, 2007, PHYS LETT A, V369, P23, DOI 10.1016/j.physleta.2007.04.023
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Lima JB, 2013, SIGNAL PROCESS-IMAGE, V28, P1537, DOI 10.1016/j.image.2013.05.008
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Norouzi B, 2016, OPTIK, V127, P5695, DOI 10.1016/j.ijleo.2016.03.076
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Seyedzadeh SM, 2014, J SYST SOFTWARE, V97, P128, DOI 10.1016/j.jss.2014.07.025
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Sui LS, 2013, OPT LASER TECHNOL, V48, P117, DOI 10.1016/j.optlastec.2012.10.016
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Tong XJ, 2009, OPT COMMUN, V282, P2722, DOI 10.1016/j.optcom.2009.03.075
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, ADV SCI LETT, V3, P447, DOI 10.1166/asl.2010.1170
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2005, LECT NOTES COMPUT SC, V3497, P860
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 55
TC 50
Z9 51
U1 4
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13681
EP 13701
DI 10.1007/s11042-016-3769-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900035
DA 2024-07-18
ER

PT J
AU Uddin, MZ
AF Uddin, Md. Zia
TI Human activity recognition using segmented body part and body joint
   features with hidden Markov models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Randomforests; Body joints; Depth information; Hidden Markov models
ID POSE
AB In recent years, human activity recognition from video has been getting considerable research attentions by computer vision researchers due to its prominent applications in various fields such as surveillance environments, human computer interactions, and smart home healthcare. For instance, activity recognition can be used in a surveillance environment to alert the related authority of potential dangerous behaviors. Similarly, the activity recognition can improve the human computer interaction (HCI) in an entertainment environment such as the automatic recognition of different player's actions in a game so as to create an avatar to play on behalf for the player. Furthermore, the activity recognition can help the rehabilitation of patients in a healthcare system where patient's action recognition can help to facilitate the rehabilitation processes. Basically, a video-based activity recognition system consists of many prominent goals, one of which is to provide information based on people's behavior in order to allow the system to proactively assist them with their tasks. A novel approach is proposed here for depth video based human activity recognition, using joint-based spatiotemporal features of depth body shapes and hidden Markov models. From depth video, different body parts of human activities are first segmented using a trained random forest. Spatial features consisting of the 3-D body joint pair angles, the mean of the depth values, the variance of the depth values, and the area of each segmented body part are combined with the motion features representing the magnitude and direction of each joint in the next frame to build the spatiotemporal features in a frame. The activity features are then further enhanced using generalized discriminant analysis to classify them nonlinearly in order to convert them to more robust features. Finally, the features are utilized for training distinguished activity hidden Markov models that can be later used for recognition. The proposed approach shows superior recognition performance compared to other conventional activity recognition approaches.
C1 [Uddin, Md. Zia] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Uddin, MZ (corresponding author), Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
EM ziauddin@skku.edu
RI Uddin, Zia/AAC-1309-2020
OI Uddin, Zia/0000-0002-5215-1834
FU Samsung Research Fund, Sungkyunkwan University
FX This work was supported by the Samsung Research Fund, Sungkyunkwan
   University, 2015.
CR Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   [Anonymous], 2011, ACM transactions on graphics (TOG), DOI DOI 10.1145/1964921.1964972
   [Anonymous], 16 ACM S COMP GEOM
   [Anonymous], 3 D GESTURE BASED SC
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.458
   BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breitenstein MD, 2009, LECT NOTES COMPUT SC, V5575, P219, DOI 10.1007/978-3-642-02230-2_23
   Breuer P, 2007, LECT NOTES COMPUT SC, V4418, P247, DOI 10.1007/978-3-540-71457-6_23
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Derpanis KG, 2004, LECT NOTES COMPUT SC, V3021, P282
   Dreuw P., 2010, P INT C LANG RES EV, P476
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Ferrari V, 2009, LECT NOTES COMPUT SC, V5604, P128, DOI 10.1007/978-3-642-03061-1_7
   Hamer H, 2010, PROC CVPR IEEE, P671, DOI 10.1109/CVPR.2010.5540150
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   Jalal A, 2012, INDOOR BUILT ENVIRON, V21, P184, DOI 10.1177/1420326X11423163
   Jia XF, 2012, INT C PATT RECOG, P3001
   Knossow D, 2008, INT J COMPUT VISION, V79, P247, DOI 10.1007/s11263-007-0116-2
   Kollorz Eva, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P334, DOI 10.1504/IJISTA.2008.021296
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lahamy H, 2010, P CAN GEOM C
   Lei JN, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P208
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li Z., 2009, P AUSTR C ROB AUT
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu L., 2013, 23 INT JOINT C ART I
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Lu H, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/261317
   Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Luong DD, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P905, DOI 10.1109/ICCAS.2013.6704043
   Marnik J, 2007, ADV INTEL SOFT COMPU, V45, P454
   Martinez-Camarena M, 2015, IEEE IMAGE PROC, P2454, DOI 10.1109/ICIP.2015.7351243
   McCallum Andrew., 2000, ICML
   Mian A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P735
   Microsoft Corporation, 2014, KIN XBOX 360 XBOX CO
   Morency LP, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P45
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   Nishimura H, 2001, PROC INT CONF DOC, P417, DOI 10.1109/ICDAR.2001.953824
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885
   Oikonomidis I, 2012, P IEEE C COMP VIS PA, P1
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pei T., 2009, P IEEE INT C AC SPEE, P4757
   Penne J., 2008, P INT C AUT FAC GEST, P1
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   Shotton J, 2013, Commun. ACM, V56, P119, DOI [DOI 10.1145/2398356.2398381, 10.1145/2398356.2398381]
   Simari P, 2009, COMPUT GRAPH FORUM, V28, P1415, DOI 10.1111/j.1467-8659.2009.01518.x
   Song YM, 2014, INT CONF CONTR AUTO, P132, DOI 10.1109/ICCAIS.2014.7020544
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Sun Y, 2008, INT C PATT RECOG, P104
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Takimoto H, 2010, 2010 IEEE RO-MAN, P292, DOI 10.1109/ROMAN.2010.5598646
   Theodorakis S, 2010, INT CONF ACOUST SPEE, P2262, DOI 10.1109/ICASSP.2010.5495875
   Uddin MZ, 2010, APPL INTELL, V33, P193, DOI 10.1007/s10489-008-0159-2
   Uddin MZ, 2015, MULTIMED TOOLS APPL, V74, P11207, DOI 10.1007/s11042-014-2225-6
   Uddin MZ, 2015, MULTIMED TOOLS APPL, V74, P3675, DOI 10.1007/s11042-013-1793-1
   Uddin MZ, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/57054
   Uddin MZ, 2013, INDOOR BUILT ENVIRON, V22, P289, DOI 10.1177/1420326X12469734
   Ulrich Neumann ZhenyaoMoand., 2006, IEEE Conference on Computer Vision and Pattern Recognition, P1499, DOI DOI 10.1109/CVPR.2006.237
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Viet VH, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P222, DOI 10.1109/KSE.2015.39
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang YL., 2007, Sci. STKE, V2007, P1
   Weise T., 2007, IEEE CVPR, P1, DOI DOI 10.1109/CVPR.2007.383291
   Wright J, 2009, PROC CVPR IEEE, P1502, DOI 10.1109/CVPRW.2009.5206786
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang HD, 2007, PATTERN RECOGN, V40, P3120, DOI 10.1016/j.patcog.2007.01.033
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zafrulla Zahoor., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, P48
NR 82
TC 11
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13585
EP 13614
DI 10.1007/s11042-016-3742-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900031
DA 2024-07-18
ER

PT J
AU Yang, Y
   Liu, YX
   Dong, QF
AF Yang, Yang
   Liu, Yun-Xia
   Dong, Qi-Fan
TI Sliced integral histogram: an efficient histogram computing algorithm
   and its FPGA implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Integral histogram; Parallel processing; FPGA architecture
ID HARDWARE ARCHITECTURE; PARTICLE FILTER
AB Integral histogram provides efficient histogram computation for all possible target regions, and is widely applied in many computer vision tasks. In this paper, to address the intensive computation and frequent memory accessing bottleneck in real-time applications, a sliced integral histogram algorithm is proposed for efficient integral histogram computation. We explore how maximum parallel computation and storage reduction are simultaneously achieved. Hardware implementation architecture on Field-programmable gate array (FPGA) platform is presented. We also suggest criterion for the optimal number of slices, which allows the most appropriate architecture to be selected. Comparing with the state-of-the-art methods, experimental results on Cyclone platform demonstrate the validity of the proposed algorithm in terms of computation speed, storage capacity and power consumption. Meanwhile, the proposed algorithm can be extended to other histogram based feature descriptors and implemented on any parallel processing platforms.
C1 [Yang, Yang; Dong, Qi-Fan] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Liu, Yun-Xia] Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.
C3 Shandong University; Shandong University
RP Yang, Y (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
EM yyang@sdu.edu.cn
FU National Natural Science Foundation of China [61203239, 61305015];
   Postdoctoral Science Foundation of China [2015M580591]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61203239, 61305015), and Postdoctoral Science Foundation of
   China (No. 2015M580591). The authors would like to thank the associate
   editor and the reviewers for helpful comments that greatly improved this
   paper.
CR [Anonymous], 2014, BMVC
   [Anonymous], 2015, MULTIMEDIA TOOL APPL
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bellens P, 2011, LECT NOTES COMPUT SC, V6915, P586, DOI 10.1007/978-3-642-23687-7_53
   Chai Y, 2010, IEEE T CONSUM ELECTR, V56, P510, DOI 10.1109/TCE.2010.5505963
   Fan ZH, 2015, SIGNAL PROCESS-IMAGE, V36, P140, DOI 10.1016/j.image.2015.07.001
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Kyrkou C, 2011, IEEE T VLSI SYST, V19, P1034, DOI 10.1109/TVLSI.2010.2048224
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Müller T, 2008, LECT NOTES COMPUT SC, V5099, P209, DOI 10.1007/978-3-540-69905-7_24
   Ouyang P, 2015, IEEE T CIRCUITS-II, V62, P75, DOI 10.1109/TCSII.2014.2362651
   Paris S, 2011, LECT NOTES COMPUT SC, V6838, P276, DOI 10.1007/978-3-642-24728-6_37
   Park JG, 2012, J BIOMED BIOTECHNOL, V2012, P1, DOI DOI 10.1109/SC.2012.53
   Poostchi Mahdieh., 2012, ASIAN C COMPUTER VIS, P266
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Ramík DM, 2014, APPL INTELL, V40, P358, DOI 10.1007/s10489-013-0461-5
   Tsai YW, 2015, MULTIMED TOOLS APPL, P1
   Wang XY, 2010, MULTIMED TOOLS APPL, V49, P323, DOI 10.1007/s11042-009-0362-0
   Yang PF, 2016, MULTIMED TOOLS APPL, V75, P4723, DOI 10.1007/s11042-015-2499-3
   Zhang SX, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P1, DOI 10.1109/ICMIPE.2013.6864491
NR 20
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14327
EP 14344
DI 10.1007/s11042-016-3816-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800029
DA 2024-07-18
ER

PT J
AU Fu, YH
   Zhang, T
   Wang, WJ
AF Fu, Yinghua
   Zhang, Tao
   Wang, Wenjin
TI Sparse coding-based space-time video representation for action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse coding; Space-time saliency; Action recognition;
   Self-information; Shannon entropy
AB Methods based on feature descriptors around local interest points are now widely used in action recognition. Feature points are detected using a number of measures, namely saliency, periodicity, motion activity etc. Each of these measures is usually intensity-based and provides a trade-off between density and informativeness. In this paper, we address the problem of action recognition by representing image sequences as a sparse collection of patch-level space-time events that are salient in both space and time domain. Our method uses a multi-scale volumetric representation of video and adaptively selects an optimal space-time scale under which the saliency of a patch is most significant. The input image sequences are first partitioned into non-overlapping patches. Then, each patch is represented by a vector of coefficients that can linearly reconstruct the patch from a learned dictionary of basis patches. The space-time saliency of patches is measured by Shannon's self-information entropy, where a patch's saliency is determined by information variation in the contents of the patch's spatiotemporal neighborhood. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed method.
C1 [Fu, Yinghua; Zhang, Tao] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
   [Fu, Yinghua; Wang, Wenjin] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; University of Shanghai for Science &
   Technology
RP Fu, YH (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.; Fu, YH (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM fuyh@usst.edu.cn
RI Fu, Yinghua/KEJ-1910-2024
OI Fu, Yinghua/0000-0002-8616-1811
FU National 973 Program of China [2013CB329401]; NSFC, China [61273258,
   61105001]
FX This research is partly supported by the National 973 Program of China
   (2013CB329401) and NSFC, China (No: 61273258, 61105001). Shanghai Key
   Lab of Modern Optical System gives much help for providing the
   experiment material.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], 2009, ANN PHARMACOTHER
   [Anonymous], 2006, ACM International Workshop on Video Surveillance and Sensor Networks, DOI DOI 10.1145/1178782.1178808
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gangeh MJ, 2013, IEEE T SIGNAL PROCES, V61, P4753, DOI 10.1109/TSP.2013.2274276
   Gangeha M, 2015, SUPERVISED DICT LEAR
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Kadir T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P25, DOI 10.1049/cp:20030478
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li J, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.86
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J., 2008, NIPS, V21, P1033
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rapantzikos K., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P294, DOI DOI 10.1145/1282280.1282326
   RAPANTZIKOS K, 2009, P C COMP VIS PATT RE, P1
   Rudoy D, 2013, CVPR, P4321
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sun Q, 2012, ACTION DISAMBIGUATIO
   Wang L, 2006, INT C PATT RECOG, P1266
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Weinland D., 2008, CVPR, P1
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yang JC, 2011, CVPR, P3517
NR 37
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12645
EP 12658
DI 10.1007/s11042-016-3630-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200021
DA 2024-07-18
ER

PT J
AU Jung, Y
   Xi, Y
   Cho, S
   Song, W
   Fong, SM
   Cho, K
AF Jung, Yunji
   Xi, Yulong
   Cho, Seoungjae
   Song, Wei
   Fong, Simon
   Cho, Kyungeun
TI Design and implementation of a same-user identification system in
   invoked reality space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Invoked reality; User identification; Feature extraction
AB The objective of this study is to solve the problem of user data not being precisely received from sensors because of sensing region limitations in invoked reality (IR) space, distortion of colors or patterns by lighting, and blocking or overlapping of a user by other users. The sensing scope range is thus expanded using multiple sensors in the IR space. Moreover, user feature data are accurately identified by user sensing. Specifically, multiple sensors are employed when not all of user data are sensed because they overlap with data of other users. In the proposed approach, all clients share the user feature data from multiple sensors. Accordingly, each client recognizes that the user is the same individual on the basis of the shared data. Furthermore, the identification accuracy is improved by identifying the user features based on colors and patterns that are less affected by lighting. Therefore, accurate identification of the user feature data is enabled, even under lighting changes. The proposed system was implemented based on system performance analysis standards. The practicality and system performance in identifying the same person using the proposed method were verified through an experiment.
C1 [Jung, Yunji; Xi, Yulong; Cho, Seoungjae; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 04620, South Korea.
   [Song, Wei] North China Univ Technol, Dept Digital Media Technol, 5 Jinyuanzhuang Rd, Beijing 100144, Peoples R China.
   [Fong, Simon] Univ Macau, Dept Comp & Informat Sci, Ave Univ, Taipa 3000, Macau, Peoples R China.
C3 Dongguk University; North China University of Technology; University of
   Macau
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 04620, South Korea.
EM cke@dongguk.edu
OI Song, Wei/0000-0002-5909-9661
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [IITP-2016-H8501-16-1014];
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and future Planning
   [NRF-2015R1A2A2A01003779]
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2016-H8501-16-1014) supervised by the
   IITP(Institute for Information & communications Technology Promotion)
   and was supported by Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Science,
   ICT and future Planning (NRF-2015R1A2A2A01003779).
CR [Anonymous], J CONVERGE
   [Anonymous], INT J U E SERVICE SC
   [Anonymous], POW EN SOC GEN M 201
   [Anonymous], 2011, P VIRT REAL INT C
   Blanco-Gonzalo R, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0043-0
   Tran C, 2012, IEEE T IND INFORM, V8, P178, DOI 10.1109/TII.2011.2172450
   Gao Y, 2015, J INF PROCESS SYST, V11, P643, DOI 10.3745/JIPS.02.0027
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Hu NH, 2014, IEEE INT CONF ROBOT, P5299, DOI 10.1109/ICRA.2014.6907638
   MAES P, 2009, TED 2009
   O'Hara K, 2014, COMMUN ACM, V57, P70, DOI 10.1145/2541883.2541899
   Satta Riccardo, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P407
   Shimura K, 2014, 2014 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P304, DOI 10.1109/SII.2014.7028055
   Sim S, 2015, THESIS
   Song W, 2014, FUTURETECH 2014 ZHAN, V309, P497
   Yumak Z, 2014, SIGGRAPH ASIA 2014 A, P3
NR 16
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11429
EP 11447
DI 10.1007/s11042-016-4117-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000018
OA hybrid
DA 2024-07-18
ER

PT J
AU Marouf, A
   Houacine, A
AF Marouf, A.
   Houacine, A.
TI Improving parametric active contours by using attracting point distance
   map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parametric active contours; Deformable models; Snakes; Distance map;
   Balloon method
ID GRADIENT VECTOR FLOW; SNAKES; MODELS; SEGMENTATION; BALLOONS; IMAGE;
   FORCE; FIELD
AB In this paper, we propose an improvement of the classical parametric active contours. The method, presented here, consists in adding a new energy term based on attraction point distance map chosen on the object. This additional term acts as attraction forces that constrain the contour to remain in the vicinity of the object. The distance map introduced here differs from the classical one since it is not based on the whole binary image, but rather constitutes a simplified and very fast version that relates only to one point. The additional forces, so introduced, act as a kind of balloon method. The attracting point is selected on an image based the shape of the object of interest. To improve convergence, we also propose the use of weighting factors for the externals forces as dependent on snake points. The method is evaluated for object segmentation in images, and is also tested for multi-object segmentation. Compared to the conventional balloon method, the presented approach admits a faster convergence and provides better results in particular at object concavities.
C1 [Marouf, A.; Houacine, A.] Univ Sci & Technol Houari Boumediene, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Houacine, A (corresponding author), Univ Sci & Technol Houari Boumediene, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
EM ahouacine@usthb.dz
CR Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   AUBERT G, 2002, APPL MATH SCI, V147
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen Q, 2008, PATTERN RECOGN LETT, V29, P126, DOI 10.1016/j.patrec.2007.09.009
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Das SK, 2011, PATTERN RECOGN, V44, P173, DOI 10.1016/j.patcog.2010.08.024
   Hou ZQ, 2005, PATTERN RECOGN LETT, V26, P513, DOI 10.1016/j.patrec.2004.09.001
   Jacob M, 2004, IEEE T IMAGE PROCESS, V13, P1231, DOI 10.1109/TIP.2004.832919
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lee J, 2012, IEEE ENG MED BIO, P4450, DOI 10.1109/EMBC.2012.6346954
   Li CM, 2005, PROC CVPR IEEE, P430
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Ranchin F, 2005, P ORASIS TOUL
   Shih FY, 2007, COMPUT VIS IMAGE UND, V105, P93, DOI 10.1016/j.cviu.2006.08.007
   Sum KW, 2007, PATTERN RECOGN, V40, P1635, DOI 10.1016/j.patcog.2006.11.006
   Torkan S, 2010, P 18 IR C EL ENG ISF, P150, DOI [10.1109/IRANIANCEE.2010.5507085, DOI 10.1109/IRANIANCEE.2010.5507085]
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P1421, DOI 10.1016/j.cviu.2013.05.003
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P990, DOI 10.1016/j.cviu.2012.12.008
   Xu C., 2000, HDB MEDICAL IMAGING, P129
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
NR 23
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12583
EP 12595
DI 10.1007/s11042-016-3648-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200018
DA 2024-07-18
ER

PT J
AU Song, W
   Cai, XQ
   Xi, YL
   Cho, S
   Cho, K
AF Song, Wei
   Cai, Xingquan
   Xi, Yulong
   Cho, Seoungjae
   Cho, Kyungeun
TI Real-time single camera natural user interface engine development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NUI; GPU programming; Mixed reality; Foreground segmentation; Motion
   detection
ID SEGMENTATION
AB Natural user interfaces (NUIs) provide human computer interaction (HCI) with natural and intuitive operation interfaces, such as using human gestures and voice. We have developed a real-time NUI engine architecture using a web camera as a means of implementing NUI applications. The system captures video via the web camera, implements real-time image processing using graphic processing unit (GPU) programming. This paper describes the architecture of the engine and the real-virtual environment interaction methods, such as foreground segmentation and hand gesture recognition. These methods are implemented using GPU programming in order to realize real-time image processing for HCI. To verify the efficacy of our proposed NUI engine, we utilized it in the development and implementation of several mixed reality games and touch-less operation applications, using the developed NUI engine and the DirectX SDK. Our results confirm that the methods implemented by the engine operate in real time and the interactive operations are intuitive.
C1 [Song, Wei; Cai, Xingquan] North China Univ Technol, Coll Comp, 5 Jinyuanzhuang Rd, Beijing 100144, Peoples R China.
   [Xi, Yulong; Cho, Seoungjae; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
C3 North China University of Technology; Dongguk University
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
EM cke@dongguk.edu
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [IITP-2015-H8501-15-1014]
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2015-H8501-15-1014) supervised by the
   IITP(Institute for Information & communications Technology Promotion).
CR Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], J CONVERGENCE
   [Anonymous], 2011, P 5 IEEE INT C AUTOM
   [Anonymous], J CONVERGENCE
   Betke M, 2002, IEEE T NEUR SYS REH, V10, P1, DOI 10.1109/TNSRE.2002.1021581
   Dickinson P, 2009, IMAGE VISION COMPUT, V27, P1326, DOI 10.1016/j.imavis.2008.12.001
   Fan YC, 2013, I SYMP CONSUM ELECTR, P189
   Homer BD, 2014, COMPUT EDUC, V74, P37, DOI 10.1016/j.compedu.2014.01.007
   Hussain A, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-14
   Manh HT, 2013, J INF PROCESS SYST, V9, P592, DOI 10.3745/JIPS.2013.9.4.592
   Kam Lai, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P185, DOI 10.1109/SSIAI.2012.6202484
   Kim J.-o., 2012, International Journal of Smart Home, V6, P117
   Ling Q, 2014, NEUROCOMPUTING, V133, P32, DOI 10.1016/j.neucom.2013.11.034
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sabir K, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P49, DOI 10.1109/BioVis.2013.6664346
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Song W, 2012, SENSORS-BASEL, V12, P17186, DOI 10.3390/s121217186
   Vanus J, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0019-5
   Wang Y, 2014, 2012 4 INT C INT HUM, P274
   Wilson A.D., 2010, Proc. UIST, P273
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
NR 21
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11159
EP 11175
DI 10.1007/s11042-015-2986-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000002
DA 2024-07-18
ER

PT J
AU Yao, H
   Wang, SZ
   Zhang, XP
   Qin, C
   Wang, JW
AF Yao, Heng
   Wang, Shuozhong
   Zhang, Xinpeng
   Qin, Chuan
   Wang, Jinwei
TI Detecting Image Splicing Based on Noise Level Inconsistency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Image splicing detection; Noise level function
   (NLF); Bayesian maximum a posteriori (MAP)
ID EXPOSING DIGITAL FORGERIES; CALIBRATION; SPACE
AB In a spliced image, areas from different origins contain different noise features, which may be exploited as evidence for forgery detection. In this paper, we propose a noise level evaluation method for digital photos, and use the method to detect image splicing. Unlike most noise-based forensic techniques in which an AWGN model is assumed, the noise distribution used in the present work is intensity-dependent. This model can be described with a noise level function (NLF) that better fits the actual noise characteristics. NLF reveals variation in the standard deviation of noise with respect to image intensity. In contrast to denoising problems, noise in forensic applications is generally weak and content-related, and estimation of noise characteristics must be done in small areas. By exploring the relationship between NLF and the camera response function (CRF), we fit the NLF curve under the CRF constraints. We then formulate a Bayesian maximum a posteriori (MAP) framework to optimize the NLF estimation, and develop a method for image splicing detection according to noise level inconsistency in image blocks taking from different origins. Experimental results are presented to show effectiveness of the proposed method.
C1 [Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Minist Educ, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.
   [Wang, Shuozhong; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Shanghai University; Nanjing University of
   Information Science & Technology
RP Yao, H (corresponding author), Univ Shanghai Sci & Technol, Minist Educ, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.; Yao, H (corresponding author), Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.
EM hyao@usst.edu.cn
RI Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623
FU National Natural Science Foundation of China [61303203, 61525203,
   61472235]; Natural Science Foundation of Shanghai, China [13ZR1428400];
   Innovation Program of Shanghai Municipal Education Commission [14YZ087];
   Program of Shanghai Dawn Scholar [14SG36]; Shanghai Academic Research
   Leader [16XD1401200]; Open Project Program of the National Laboratory of
   Pattern Recognition [201600003]; Shanghai Engineering Center Project of
   Massive Internet of Things Technology for Smart Home [GCZX14014]; PAPD
   Fund; CICAEET Fund
FX This work was supported by the National Natural Science Foundation of
   China (61303203, 61525203, 61472235), the Natural Science Foundation of
   Shanghai, China (13ZR1428400), the Innovation Program of Shanghai
   Municipal Education Commission (14YZ087), the Program of Shanghai Dawn
   Scholar (14SG36), Shanghai Academic Research Leader (16XD1401200), the
   Open Project Program of the National Laboratory of Pattern Recognition
   (201600003), Shanghai Engineering Center Project of Massive Internet of
   Things Technology for Smart Home (GCZX14014), the PAPD Fund, and the
   CICAEET Fund.
CR [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.207
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin S, 2004, PROC CVPR IEEE, P938
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu XH, 2013, IEEE IMAGE PROC, P79, DOI 10.1109/ICIP.2013.6738017
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Takamatsu J, 2008, LECT NOTES COMPUT SC, V5305, P623, DOI 10.1007/978-3-540-88693-8_46
   Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555
   Yang JY, 2015, IEEE T IMAGE PROCESS, V24, P1561, DOI 10.1109/TIP.2015.2405417
   Yang JY, 2012, IEEE IMAGE PROC, P673, DOI 10.1109/ICIP.2012.6466949
   Yao H, 2016, MATEC WEB CONF, V42, DOI 10.1051/matecconf/20164206004
   Yao H, 2012, IEEE SIGNAL PROC LET, V19, P123, DOI 10.1109/LSP.2011.2182191
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
NR 32
TC 51
Z9 51
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12457
EP 12479
DI 10.1007/s11042-016-3660-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200013
DA 2024-07-18
ER

PT J
AU Zhang, JW
   Liu, J
   Li, T
   Zheng, YH
   Wang, J
AF Zhang, Jianwei
   Liu, Jing
   Li, Tong
   Zheng, Yuhui
   Wang, Jin
TI Gaussian mixture model learning based image denoising method with
   adaptive regularization parameters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Gaussian mixture model; Adaptive regularization
   parameter; Gradient fidelity term
ID ALTERNATING MINIMIZATION; SPARSE; REPRESENTATIONS
AB Gaussian mixture model learning based image denoising as a kind of structured sparse representation method has received much attention in recent years. In this paper, for further enhancing the denoised performance, we attempt to incorporate the gradient fidelity term with the Gaussian mixture model learning based image denoising method to preserve more fine structures of images. Moreover, we construct an adaptive regularization parameter selection scheme by combing the image gradient with the local entropy of the image. Experiment results show that our proposed method performs an improvement both in visual effects and peak signal to noise values.
C1 [Zhang, Jianwei; Liu, Jing] Nanjing Univ Informat Sci & Technol, Coll Math & Stat, Nanjing 210044, Jiangsu, Peoples R China.
   [Li, Tong] Univ Chinese Acad Sci, Sch Engn Sci, Beijing 100049, Peoples R China.
   [Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Wang, Jin] Yangzhou Univ, Coll Informat Engn, Yangzhou 215127, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Nanjing
   University of Information Science & Technology; Yangzhou University
RP Zhang, JW (corresponding author), Nanjing Univ Informat Sci & Technol, Coll Math & Stat, Nanjing 210044, Jiangsu, Peoples R China.
EM zhangjw@nuist.edu.cn
RI li, tong/HPC-6702-2023; Zheng, Yuhui/AAF-2420-2019; Wang,
   Jin/AAI-7009-2020
OI Wang, Jin/0000-0001-5473-8738
FU NSFC [61402234, 61402235]; PAPD
FX This work was supported in part by the NSFC(Grants 61402234 and
   61402235) and the PAPD.
CR Beck A, 2015, SIAM J OPTIMIZ, V25, P185, DOI 10.1137/13094829X
   Chantas G, 2005, IM PROC 2005 ICIP 20, V1
   Cong-Cong Xie, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P835, DOI 10.1109/CISP.2010.5646859
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247
   Hu H.-y., 2012, 2012 INT C LIGHTN PR, P1
   Jain P, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P665
   Kaganovsky Y, 2015, SPIE MED IMAGING
   Layer T, 2015, EJNMMI PHYS, V2, DOI 10.1186/s40658-015-0110-7
   Liu K, 2016, SPRINGERPLUS, V5, P1
   Peleg T, 2012, IEEE T SIGNAL PROCES, V60, P2286, DOI 10.1109/TSP.2012.2188520
   Qin Y, 2015, EURASIP J ADV SIG PR, P1, DOI 10.1186/s13634-015-0294-y
   Ren J, 2013, IEEE T IMAGE PROCESS, V22, P1454, DOI 10.1109/TIP.2012.2231690
   Tang L, 2016, EURASIP J ADV SIG PR, V2016, P1
   Nguyen TM, 2012, IEEE T SYST MAN CY B, V42, P193, DOI 10.1109/TSMCB.2011.2161284
   van den Oord A, 2014, J MACH LEARN RES, V15, P2061
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P1770, DOI 10.1109/TIP.2011.2181401
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Yuan QQ, 2010, IEEE T IMAGE PROCESS, V19, P3157, DOI 10.1109/TIP.2010.2055571
   Zeng Y.-H., 2016, J INEQUAL APPL, V2016, P1, DOI DOI 10.1016/J.EXER.2016.05.002
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zheng Y., 2012, INT J HYBRID INF TEC, V5, P33
   Zheng YH, 2015, ELECTRON LETT, V51, P144, DOI 10.1049/el.2014.3494
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhu LX, 2008, IMAGE VISION COMPUT, V26, P1163, DOI 10.1016/j.imavis.2008.01.008
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
   Zuo ZY, 2013, CIRC SYST SIGNAL PR, V32, P2407, DOI 10.1007/s00034-013-9581-8
NR 32
TC 10
Z9 10
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11471
EP 11483
DI 10.1007/s11042-016-4214-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000020
DA 2024-07-18
ER

PT J
AU Buzzi, MC
   Buzzi, M
   Franchi, D
   Gazzè, D
   Iervasi, G
   Marchetti, A
   Pingitore, A
   Tesconi, M
AF Buzzi, Maria Claudia
   Buzzi, Marina
   Franchi, Daniele
   Gazze, Davide
   Iervasi, Giorgio
   Marchetti, Andrea
   Pingitore, Alessandro
   Tesconi, Maurizio
TI Facebook: a new tool for collecting health data?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Facebook; Mediterranean diet; Health; e-health
ID CORONARY-HEART-DISEASE; MEDITERRANEAN DIET; PHYSICAL-ACTIVITY;
   CARDIOVASCULAR-DISEASE; PRIMARY PREVENTION; SOCIAL NETWORKING;
   LIFE-STYLE; FOLLOW-UP; MORTALITY; MEN
AB This study investigates the use of social networks as a scientific tool for gathering medical data from young subjects while promoting healthier habits. Our first hypothesis is that social networks can facilitate epidemiological studies, reducing time and cost. The second question is whether social networks can enable the collection of data from young and healthy subjects who are otherwise beyond the reach of conventional social health polls. A Facebook application was created to collect data concerning adherence to the Mediterranean diet, considering the significant risk of cardiovascular and neurological degenerative diseases in subjects with poor adherence to a healthy diet. More than 1400 users were recruited in a short time without any promotional action. Collected data indicate that adherence to the Mediterranean diet is in general greater in older users vs young (p < 0.01) and Italian vs Other Countries (mainly participants from the US) (p < 0.03), while no statistical differences were found concerning gender. Results show that the proposed approach offers advantages in terms of reduced cost, faster data gathering and processing, and improved efficiency compared to a form-based epidemiology campaign. However, the initial network may influence the sample constitution in age and geographical location, especially if the spread does not become viral and autonomous. Based on the case study, we provide designers of Facebook apps with some simple guideline suggestions aimed at maximizing the heterogeneity of the sample, in order to collect significant data. The proposed scenario, suitable for collecting health data, can easily be extended to other fields.
C1 [Buzzi, Maria Claudia; Buzzi, Marina; Gazze, Davide; Marchetti, Andrea; Tesconi, Maurizio] CNR, IIT, Pisa, Italy.
   [Franchi, Daniele; Iervasi, Giorgio; Pingitore, Alessandro] CNR, Inst Clin Physiol IFC, Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Informatica e
   Telematica (IIT-CNR); Consiglio Nazionale delle Ricerche (CNR); Istituto
   di Fisiologia Clinica (IFC-CNR)
RP Buzzi, M (corresponding author), CNR, IIT, Pisa, Italy.
EM claudia.buzzi@iit.cnr.it; marina.buzzi@iit.cnr.it;
   daniele.franchi@ifc.cnr.it; davide.gazze@iit.cnr.it;
   giorgio.iervasi@ifc.cnr.it; andrea.marchetti@iit.cnr.it;
   alessandro.pingitore@ifc.cnr.it; maurizio.tesconi@iit.cnr.it
RI Pingitore, Alessandro/K-1843-2018; Buzzi, Marina/A-3038-2013; Buzzi,
   Maria Claudia/A-3286-2016; TESCONI, MAURIZIO/P-2441-2016
OI Buzzi, Marina/0000-0003-1725-9433; Buzzi, Maria
   Claudia/0000-0001-7818-0601; TESCONI, MAURIZIO/0000-0001-8228-7807;
   MARCHETTI, ANDREA/0000-0003-4512-1642
CR Amerson R, 2011, J NURS EDUC, V50, P414, DOI 10.3928/01484834-20110331-01
   [Anonymous], 2003, World Health Organ Tech Rep Ser, V916, pi
   [Anonymous], 1999, Designing Web Usability: The Practice of Simplicity
   [Anonymous], 1998, ISO 9241-11
   Armstrong AW, 2013, SKIN RES TECHNOL, V19, P55, DOI 10.1111/j.1600-0846.2012.00667.x
   Armstrong April W, 2012, Dermatol Online J, V18, P15
   Arnrich B, 2010, METHOD INFORM MED, V49, P67, DOI 10.3414/ME09-02-0044
   Barabási AL, 2007, NEW ENGL J MED, V357, P404, DOI 10.1056/NEJMe078114
   Behrens G, 2013, EUR J EPIDEMIOL, V28, P361, DOI 10.1007/s10654-013-9796-9
   BERKMAN LF, 1979, AM J EPIDEMIOL, V109, P186, DOI 10.1093/oxfordjournals.aje.a112674
   Bhaskar Pinaki, 2015, Information Technology in Bio- and Medical Informatics. 6th International Conference, ITBAM 2015. Proceedings: LNCS 9267, P3, DOI 10.1007/978-3-319-22741-2_1
   Celi LA, 2014, JMIR MED INF, V2, P111, DOI 10.2196/medinform.3110
   Chainani-Wu N, 2011, AM J CARDIOL, V108, P498, DOI 10.1016/j.amjcard.2011.03.077
   Chou WYS, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1249
   Christakis NA, 2004, BRIT MED J, V329, P184, DOI 10.1136/bmj.329.7459.184
   Darnton-Hill I, 2004, PUBLIC HEALTH NUTR, V7, P101, DOI 10.1079/PHN2003584
   Daviglus ML, 2009, CIRCULATION, V120, pS462
   Doan A, 2011, COMMUN ACM, V54, P86, DOI 10.1145/1924421.1924442
   Estruch R, 2013, NEW ENGL J MED, V368, P1279, DOI 10.1056/NEJMoa1200303
   Farmer AD, 2009, POSTGRAD MED J, V85, P455, DOI 10.1136/pgmj.2008.074674
   Fleury J, 1992, J CRIT CARE, V22, P134
   Forouhi NG, 2006, DIABETOLOGIA, V49, P2580, DOI 10.1007/s00125-006-0393-2
   Gardener S, 2012, TRANSL PSYCHIAT, V2, DOI 10.1038/tp.2012.91
   Greene JA, 2011, J GEN INTERN MED, V26, P287, DOI 10.1007/s11606-010-1526-3
   Griffiths KM, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1270
   Hamer M, 2009, EUR J CARDIOV PREV R, V16, P156, DOI 10.1097/HJR.0b013e32831f1b77
   Hawn C, 2009, HEALTH AFFAIR, V28, P361, DOI 10.1377/hlthaff.28.2.361
   Hoevenaar-Blom MP, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045458
   Hoey LM, 2008, PATIENT EDUC COUNS, V70, P315, DOI 10.1016/j.pec.2007.11.016
   LEON AS, 1987, JAMA-J AM MED ASSOC, V258, P2388, DOI 10.1001/jama.258.17.2388
   Li JS, 2013, CIRCULATION, V127, P260, DOI 10.1161/CIR.0b013e3182756d8e
   Liu GW, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2162
   Lohse B, 2013, J NUTR EDUC BEHAV, V45, P69, DOI 10.1016/j.jneb.2012.06.006
   Meingast Marci, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5453
   NIE L, 2015, P 23 ANN ACM C MULT, P591, DOI DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Norman Don, 2013, The design of everyday things
   Röcker C, 2014, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-4471-6413-5_1
   Sartori A, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2503
   Schuler D., 1993, Participatory Design: Principles and Practices
   Sofi F, 2008, BMJ-BRIT MED J, V337, DOI 10.1136/bmj.a1344
   Trichopoulou A, 2003, NEW ENGL J MED, V348, P2599, DOI 10.1056/NEJMoa025039
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   van den Brandt PA, 2011, AM J CLIN NUTR, V94, P913, DOI 10.3945/ajcn.110.008250
   Vandelanotte C, 2013, J HEALTH COMMUN, V18, P1070, DOI 10.1080/10810730.2013.768731
   Weinstein RS, 2008, STUD HEALTH TECHNOL, V131, P23
   Weintraub WS, 2011, CIRCULATION, V124, P967, DOI 10.1161/CIR.0b013e3182285a81
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 49
TC 11
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10677
EP 10700
DI 10.1007/s11042-015-3190-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400021
DA 2024-07-18
ER

PT J
AU Isogawa, M
   Mikami, D
   Takahashi, K
   Kojima, A
AF Isogawa, Mariko
   Mikami, Dan
   Takahashi, Kosuke
   Kojima, Akira
TI Image and video completion via feature reduction and compensation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Completion; Inpainting; Restoration; Low-dimensional feature space;
   Image transfer
AB This paper proposes a novel framework for image and video completion that removes and restores unwanted regions inside them. Most existing works fail to carry out the completion processing when similar regions do not exist in undamaged regions. To overcome this, our approach creates similar regions by projecting a low dimensional space from the original space. The approach comprises three stages. First, input images/videos are converted to a lower dimensional feature space. Second, a damaged region is restored in the converted feature space. Finally, inverse conversion is performed from the lower dimensional space to the original space. This generates two advantages: (1) it enhances the possibility of applying patches dissimilar to those in the original color space and (2) it enables the use of many existing restoration methods, each having various advantages, because the feature space for retrieving the similar patches is the only extension. The framework's effectiveness was verified in experiments using various methods, the feature space for restoration in the second stage, and inverse conversion methods.
C1 [Isogawa, Mariko; Mikami, Dan; Takahashi, Kosuke] NTT Media Intelligence Labs, 1-1 Hikarinooka, Yokosuka, Kanagawa, Japan.
   [Kojima, Akira] NTT Media Intelligence Labs, Visual Media Project, Yokosuka, Kanagawa, Japan.
RP Isogawa, M (corresponding author), NTT Media Intelligence Labs, 1-1 Hikarinooka, Yokosuka, Kanagawa, Japan.
EM isogawa.mariko@lab.ntt.co.jp
CR [Anonymous], P IEEE COMP SOC C CO
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Herling J, 2014, IEEE T VIS COMPUT GR, V20, P866, DOI 10.1109/TVCG.2014.2298016
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Isogawa M, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P178, DOI 10.1109/ISMAR.2015.53
   Kawai Norihiko, 2011, Information and Media Technologies, V6, P158
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933
   Shih TK, 2009, IEEE T CIRC SYST VID, V19, P347, DOI 10.1109/TCSVT.2009.2013519
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
NR 18
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9443
EP 9462
DI 10.1007/s11042-016-3550-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300015
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, JG
   Wang, GD
   Pan, ZK
AF Lu, Jingge
   Wang, Guodong
   Pan, Zhenkuan
TI Nonlocal active contour model for texture segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture segmentation; Nonlocal means method; Tikhonov regularization;
   Nonlocal tikhonov regularization; Nonlocal active contour model;
   Split-Bregman algorithm
AB Texture segmentation is a very important subject in the fields of computer vision. In order to segment the textures, active contour model based on nonlocal means method and tikhonov regularization is proposed. In detail, a new nonlocal tikhonov regularization smoothness term is added. The nonlocal operator is based on the image slice similarity. So better segmentation accuracy can be achieved for the images which contain special texture features. The good matter of our method is not only nonlocal operator added but also the original tikhonov regularization smoothness item based on the pixel values retained. The nonlocal operator is time consuming, while the reserved smoothness term can save time to some extent. The traditional active contour model can only be used to segment the conventional images. The nonlocal active contour model can dispose the textures well. What's more, in order to improve the computation efficiency, this paper designs the Split-Bregman algorithm. At last, our performance is demonstrated by segmenting many real texture images.
C1 [Lu, Jingge; Wang, Guodong; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM doctorwgd@gmail.com
FU National Natural Science Foundation of China [61305045, 61170106];
   National "Twelfth Five-Year" development plan of science and technology
   [2013BAI01B03]; Qingdao science and technology development project
   [13-1-4-190-jch]
FX This work was supported by National Natural Science Foundation of China
   (No. 61305045 and No. 61170106), National "Twelfth Five-Year"
   development plan of science and technology (No. 2013BAI01B03), Qingdao
   science and technology development project (No. 13-1-4-190-jch).
CR AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   Bresson X, 2008, 0867 CAM
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358
   Guodong W, 2014, J APPL MATH, V2014
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2016, IEEE T NEUR NET LEAR, V27, P2216, DOI 10.1109/TNNLS.2015.2475750
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paragios N., 1999, P IEEE COMP SOC C CO, P699
   Savelonas MA, 2008, PATTERN RECOGN LETT, V29, P1404, DOI 10.1016/j.patrec.2008.02.013
   Savelonas MA, 2006, LECT NOTES COMPUT SC, V4179, P197
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yaroslavsky L.P., 1985, Digital Picture Processing: An Introduction
NR 17
TC 11
Z9 12
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10991
EP 11001
DI 10.1007/s11042-016-3462-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400038
DA 2024-07-18
ER

PT J
AU Nguyen, TV
   Kankanhalli, M
AF Nguyen, Tam V.
   Kankanhalli, Mohan
TI As-similar-as-possible saliency fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient region detection; Saliency; Saliency fusion; Visual attention;
   Regions of interest; Interestingness; Importance; Scene understanding;
   Image retargeting
ID SCENE; MODEL
AB Salient region detection has gradually become a popular topic in multimedia and computer vision research. However, existing techniques exhibit remarkable variations in methodology with inherent pros and cons. In this paper, we propose fusing the saliency hypotheses, namely the saliency maps produced by different methods, by accentuating their advantages and attenuating the disadvantages. To this end, our algorithm consists of three basic steps. First, given the test image, our method finds the similar images and their saliency hypotheses by comparing the similarity of the learned deep features. Second, the error-aware coefficients are computed from the saliency hypotheses. Third, our method produces a pixel-accurate saliency map which covers the objects of interest and exploits the advantages of the state-of-the-art methods. We then evaluate the proposed framework on three challenging datasets, namely MSRA-1000, ECSSD and iCoSeg. Extensive experimental results show that our method outperforms all state-of-the-art approaches. In addition, we have applied our method to the SquareMe application, an autonomous image resizing system. The subjective user-study experiment demonstrates that human prefers the image retargeting results obtained by using the saliency maps from our proposed algorithm.
C1 [Nguyen, Tam V.] Univ Dayton, Dept Comp Sci, 300 Coll Pk, Dayton, OH 45469 USA.
   [Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117417, Singapore.
C3 University System of Ohio; University of Dayton; National University of
   Singapore
RP Nguyen, TV (corresponding author), Univ Dayton, Dept Comp Sci, 300 Coll Pk, Dayton, OH 45469 USA.
EM vantam@gmail.com
RI Nguyen, Tam/HSG-3007-2023; Nguyen, Tam/AAU-6504-2020; Kankanhalli,
   Mohan/Q-9284-2019
OI Nguyen, Tam/0000-0003-0236-7992; Kankanhalli, Mohan/0000-0002-4846-2015
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], ABS14105926 CORR
   [Anonymous], 1995, HDB BRAIN THEORY NEU
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2008, NIPS
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce Neil, 2005, C NEUR INF PROC SYST
   Cerf Moran., 2007, Advances in Neural Information and Processing Systems, P241
   Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Fan X, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P53
   Fang Y., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1049
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang R, 2014, AAAI CONF ARTIF INTE, P2773
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Koch C., 1985, SHIFTS SELECTIVE VIS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lawson C. L., 1995, SOLVING LEAST SQUARE, V15
   Mai L, 2013, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2013.150
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Nguyen T., 2015, IEEE T CIRCUITS SYST
   Nguyen T.V., 2013, P 21 ACM INT C MULT, P987, DOI DOI 10.1145/2502081.2502128
   Nguyen TV, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2176
   Nguyen TV, 2013, IEEE T MULTIMEDIA, V15, P1910, DOI 10.1109/TMM.2013.2272919
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 42
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10501
EP 10519
DI 10.1007/s11042-016-3615-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400012
DA 2024-07-18
ER

PT J
AU Zhao, J
   Xie, G
   Han, JW
AF Zhao, Jie
   Xie, Gang
   Han, Jiwan
TI Conditional random field with the multi-granular contextual information
   for pixel labeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conditional Random Field(CRF); Contextual information; Multi-granular
   context; Pixel labeling
ID IMAGE ANNOTATION; FRAMEWORK; CLASSIFICATION; SEGMENTATION
AB To make full use of the contextual information object recognition and scene understanding, a multi-granular context conditional random field (MGCCRF) model is presented to combine context information in a variety of scales. It is efficiently implemented through extending the pairwise clique to the multi-granular context windows. In the fine-granular context window, the label consistency of similar features can be obtained with the probability of the label transferring between two adjacent pixels. At the same time, the spatial relationships among different classes in the coarse-granular context window are explicated in details. To train the MGCCRF model, a piecewise training method with the bound optimization algorithm is designed to improve the performance. Experiments on two real-world image databases show that compared with other methods, the modified conditional random field model is more competitive and effective in terms of the quantitative and qualitative labeling performance.
C1 [Zhao, Jie; Xie, Gang] Taiyuan Univ Technol, Coll Informat Engn, 79 West Yingze St, Taiyuan 030024, Shanxi, Peoples R China.
   [Zhao, Jie] Taiyuan Coll, Dept Comp Engn, 18 South Dachang Rd, Taiyuan 030032, Shanxi, Peoples R China.
   [Han, Jiwan] Aberystwyth Univ, Natl Plant Phen Ctr, Aberystwyth SY23 3EE, Dyfed, Wales.
C3 Taiyuan University of Technology; Aberystwyth University
RP Xie, G (corresponding author), Taiyuan Univ Technol, Coll Informat Engn, 79 West Yingze St, Taiyuan 030024, Shanxi, Peoples R China.
EM tydxcomputer@163.com; xiegang@tyut.edu.cn
FU Innovation Foundations of Education for Graduate Students of Shanxi
   Province [2015BY23]
FX This work was supported by Innovation Foundations of Education for
   Graduate Students of Shanxi Province (No. 2015BY23).
CR [Anonymous], 2007, Proc. Int. Conf. Mach. Learn
   Bao BK, 2012, IEEE T MULTIMEDIA, V14, P199, DOI 10.1109/TMM.2011.2170557
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   He XM, 2004, PROC CVPR IEEE, P695
   Heili A, 2014, IEEE T IMAGE PROCESS, V23, P3040, DOI 10.1109/TIP.2014.2324292
   Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263
   Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127
   Kumar S, 2005, IEEE I CONF COMP VIS, P1284
   Kumar S, 2003, PROC CVPR IEEE, P119
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Liu Y., 2006, AAAI, P421
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P476, DOI 10.1109/TPAMI.2012.100
   Nasierding G, 2009, IEEE SYS MAN CYBERN, P4514, DOI 10.1109/ICSMC.2009.5346902
   Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Poggi G, 2005, IEEE T GEOSCI REMOTE, V43, P1901, DOI 10.1109/TGRS.2005.852163
   Posner I, 2009, AUTON ROBOT, V26, P153, DOI 10.1007/s10514-009-9110-6
   Provost JN, 2004, COMPUT VIS IMAGE UND, V93, P155, DOI 10.1016/j.cviu.2003.07.004
   Qixing Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1953, DOI 10.1109/CVPR.2011.5995571
   Roig Gemma, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P657, DOI 10.1109/FG.2011.5771328
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sutton Charles., 2005, PROC C UNCERTAINTY A, P568
   Nguyen TM, 2012, IEEE T SYST MAN CY B, V42, P193, DOI 10.1109/TSMCB.2011.2161284
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
   Xu X, 2004, LECT NOTES ARTIF INT, V3056, P272
   Yang Michael Ying, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P196, DOI 10.1109/ICCVW.2011.6130243
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Yu Y, 2013, INT J APPROX REASON, V54, P1373, DOI 10.1016/j.ijar.2013.06.003
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhong P, 2006, INT C PATT RECOG, P160
NR 34
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9169
EP 9194
DI 10.1007/s11042-016-3513-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300003
DA 2024-07-18
ER

PT J
AU Huang, ZW
   Xue, WT
   Mao, QR
   Zhan, YZ
AF Huang, Zhengwei
   Xue, Wentao
   Mao, Qirong
   Zhan, Yongzhao
TI Unsupervised domain adaptation for speech emotion recognition using
   PCANet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Domain adaption; PCANet; Feature mapping
ID NETWORKS
AB Research in emotion recognition seeks to develop insights into the variances of features of emotion in one common domain. However, automatic emotion recognition from speech is challenging when training data and test data are drawn from different domains due to different recording conditions, languages, speakers and many other factors. In this paper, we propose a novel feature transfer approach with PCANet (a deep network), which extracts both the domain-shared and the domain-specific latent features to facilitate performance improvement. The proposal attempts to learn multiple intermediate feature representations along an interpolating path between the source and target domains using PCANet by considering the distribution shift between source domain and target domain, and then aligns other feature representations on the path with target subspace to control them to change in the right direction towards the target. To exemplify the effectiveness of our approach, we select the INTERSPEECH 2009 Emotion Challenge's FAU Aibo Emotion Corpus as the target database and two public databases (ABC and Emo-DB) as source set. Experimental results demonstrate that the proposed feature transfer learning method outperforms the conventional machine learning methods and other transfer learning methods on the performance.
C1 [Huang, Zhengwei; Xue, Wentao; Mao, Qirong; Zhan, Yongzhao] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Mao, QR (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM zhengwei.hg@gmail.com; striveyou@163.com; mao_qr@mail.ujs.edu.cn;
   yzzhan@mail.ujs.edu.cn
FU National Nature Science Foundation of China [61272211]; Talent Peaks
   Foundation of Jiangsu Province [DZXX-027]; China Postdoctoral Science
   Foundation [2015M570413]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grants 61272211, the Six Talent Peaks
   Foundation of Jiangsu Province under Grant DZXX-027, and by the general
   Financial Grant from the China Postdoctoral Science Foundation (No.
   2015M570413).
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   [Anonymous], 2012, UNSUPERVISED TRANSF
   [Anonymous], OPENEAR INTRO MUNICH
   [Anonymous], 2009, DATASET SHIFT MACHIN
   [Anonymous], AAAI C ART INT
   [Anonymous], 2014, ARXIV14043606
   [Anonymous], ASS ADV ARTIFICIAL I
   [Anonymous], DATABASE GERMAN EMOT
   Chopra Sumit., 2013, ICML W, V2, P5
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Daumé H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Deng J, 2014, IEEE SIGNAL PROC LET, V21, P1068, DOI 10.1109/LSP.2014.2324759
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Glorot X., 2011, P 28 INT C INT C MAC, P513
   Han K, 2014, INTERSPEECH, P223
   Huang ZW, 2015, FRONT INFORM TECH EL, V16, P358, DOI 10.1631/FITEE.1400323
   Jun Deng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4818, DOI 10.1109/ICASSP.2014.6854517
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Kim Y, 2013, INT CONF ACOUST SPEE, P3677, DOI 10.1109/ICASSP.2013.6638344
   Le D, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P216, DOI 10.1109/ASRU.2013.6707732
   Mao QR, 2013, J ZHEJIANG U-SCI C, V14, P573, DOI 10.1631/jzus.CIDE1310
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mao QR, 2010, INT J HUM ROBOT, V7, P245, DOI 10.1142/S0219843610002088
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328
   Schuller B, 2007, INT CONF ACOUST SPEE, P733
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Seide F, 2013, ARXIV13013605
   Sun Y, 2014, ADV NEUR IN, V27
   Swietojanski P, 2012, IEEE W SP LANG TECH, P246, DOI 10.1109/SLT.2012.6424230
NR 34
TC 46
Z9 50
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6785
EP 6799
DI 10.1007/s11042-016-3354-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400031
DA 2024-07-18
ER

PT J
AU Laddi, A
   Prakash, NR
AF Laddi, Amit
   Prakash, Neelam Rup
TI An augmented image gradients based supervised regression technique for
   iris center localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervised; Regression; Gradients; Iris centers; Eye gaze
AB This paper describes a robust and accurate technique for iris center localization by combining supervised regression based approach and image gradients. The proposed work consist of two stages. The first stage comprises regression approach which is based upon learning of local binary features to detect the periocular regions. In the second stage, image gradients were applied to the extracted eye patch regions to detect the accurate iris centers. The proposed augmented image gradients based supervised regression approach tested on the two publicly available challenging datasets show good accuracy. The results proved that supervised regression technique when augmented with image gradients approach improved the accuracy of iris center detection on the face image acquired under unconstraint conditions. The outcome of the proposed work suggests that by augmenting effective unsupervised techniques such as image gradients improves the accuracy and robustness of the supervised approaches used for face alignment applications. This work may be extended towards the development of accurate and fast eye gaze tracking systems.
C1 [Laddi, Amit] CSIO, CSIR, Biomed Instrumentat V 02, Sect 30-C, Chandigarh 160030, India.
   [Prakash, Neelam Rup] PEC Univ Technol, Dept ECE, Sect 12, Chandigarh 160012, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO); Punjab Engineering
   College (Deemed University)
RP Laddi, A (corresponding author), CSIO, CSIR, Biomed Instrumentat V 02, Sect 30-C, Chandigarh 160030, India.
EM amitcsio@yahoo.com; neelamrprakash@pec.ac.in
OI LADDI, AMIT/0000-0002-5391-6624
CR Burgos-Artizzu XP, 2013, P 2013 IE INT C COMP
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Han ZC, 2014, MULTIMED TOOLS APPL, V68, P931, DOI 10.1007/s11042-012-1090-4
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Leo M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033033
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
NR 12
TC 10
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7129
EP 7139
DI 10.1007/s11042-016-3361-y
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400045
DA 2024-07-18
ER

PT J
AU Marfia, G
   Roccetti, M
AF Marfia, Gustavo
   Roccetti, Marco
TI A practical computer based vision system for posture and movement
   sensing in occupational medicine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Computer system; Computer vision; Occupational injury;
   Injury risk detection technology; Well being; kinect
ID MUSCULOSKELETAL DISORDERS; BIOMECHANICAL ANALYSIS; RISK-FACTORS; PAIN;
   INJURIES; MOTION
AB Back pain and upper extremities injuries due to overexertion account for over twenty percent of leave days from work in the US. This explains why a vast amount of initiatives have been, to this date, carried out aiming at reducing the occurrence of such type of injuries. However, although such type of lesions are among the most studied in occupational medicine, no automatic detection and prevention technologies are pervasively available, to this date, at workplaces. Such deficiency is ascribable to the absence of any flexible and cost-effective tectaphnology that may play such role. This work aims at filling such gap: the contribution of this paper is the design and implementation of a movement-posture computervision based system that, performing as a sensor, can detect overexertion movements, helping avoid the most common injuries that these cause. Such tasks are carried out with the use of a simple webcam, thus not requiring any expensive or specialized (e.g., Microsoft Kinect) hardware device. The proposed technology is, hence, easily affordable by any type of company and production plant throughout the world and easy adaptable to recognize and detect a wide set of movements and postures. The validity of such approach is demonstrated in realistic settings through a wide set of experiments.
C1 [Marfia, Gustavo; Roccetti, Marco] Univ Bologna, Mura Anteo Zamboni 7, I-40127 Bologna, Italy.
C3 University of Bologna
RP Roccetti, M (corresponding author), Univ Bologna, Mura Anteo Zamboni 7, I-40127 Bologna, Italy.
EM roccetti@cs.unibo.it
RI Marfia, Gustavo/D-1347-2010
OI MARFIA, GUSTAVO/0000-0003-3058-8004; ROCCETTI, MARCO/0000-0003-1264-8595
CR Agustin HC, 1992, U. S. Patent, Patent No. [5,168,264, 5168264]
   Andreoni G, 2009, LECT NOTES COMPUT SC, V5620, P591, DOI 10.1007/978-3-642-02809-0_62
   [Anonymous], 2013, AUT FAC GEST REC FG
   [Anonymous], 2011, P 19 ACM INT C MULTI, DOI DOI 10.1145/2072298.2072412
   Bernard B.P., 1997, MUSCULOSKELETAL DISO
   Bernmark E, 2002, APPL ERGON, V33, P541, DOI 10.1016/S0003-6870(02)00072-8
   Como JJ, 2012, ESSENTIALS OF TRAUMA ANESTHESIA, P1
   Côté JN, 2005, CLIN BIOMECH, V20, P581, DOI 10.1016/j.clinbiomech.2005.02.012
   da Costa BR, 2010, AM J IND MED, V53, P285, DOI 10.1002/ajim.20750
   Da Gama A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2012.6184203
   David GC, 2005, OCCUP MED-OXFORD, V55, P190, DOI 10.1093/occmed/kqi082
   Fimland MS, 2014, BMC PUBLIC HEALTH, V14, DOI 10.1186/1471-2458-14-368
   Freivalds A., 2000, Proceedings of the Hu- man Factors and Ergonomics Society Annual Meeting, V44, P5
   Gatchel R J., 2014, Handbook of Musculoskeletal Pain and Disability Disorders in the Workplace, P3
   Gerr F, 2013, HUMAN FACTORS J HUMA
   González-Ortega D, 2014, COMPUT METH PROG BIO, V113, P620, DOI 10.1016/j.cmpb.2013.10.014
   HERRIN GD, 1986, AM IND HYG ASSOC J, V47, P322, DOI 10.1080/15298668691389829
   HOLLERBACH JM, 1982, BIOL CYBERN, V44, P67, DOI 10.1007/BF00353957
   Kar A., 2010, METHODOLOGY-EUR
   Knauf M.T., 2014, Work and Disability, P431
   Machado SM, 2010, MED BIOL ENG COMPUT, V48, P573, DOI 10.1007/s11517-010-0608-z
   Marfia G, 2012, ACM SIGGRAPH 2012 PO, P81
   Massey T, 2011, IEEE T INF TECHNOL B, V15, P491, DOI 10.1109/TITB.2010.2087414
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Miedema HS, 2014, EUR J PAIN, V18, P873, DOI 10.1002/j.1532-2149.2013.00430.x
   Mullineaux DR, 2012, APPL ERGON, V43, P109, DOI 10.1016/j.apergo.2011.04.003
   Mustard CA, 2014, OCCUP ENVIRON MED
   Nordander C, 2009, ERGONOMICS, V52, P1226, DOI 10.1080/00140130903056071
   Osborne A, 2012, AM J IND MED, V55, P143, DOI 10.1002/ajim.21033
   RADWIN RG, 1993, ERGONOMICS, V36, P379, DOI 10.1080/00140139308967895
   Rainville J, 2011, SPINE J, V11, P895, DOI 10.1016/j.spinee.2011.08.006
   Rajakumar R., 2014, PRIM HLTH CARE RES D, P1
   Ray SJ, 2012, ADV ENG INFORM, V26, P439, DOI 10.1016/j.aei.2012.02.011
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Spyropoulos Elias, 2013, Occupational Ergonomics, V11, P45, DOI 10.3233/OER-130206
   van den Bogert AJ, 2013, MED BIOL ENG COMPUT, V51, P1069, DOI 10.1007/s11517-013-1076-z
   Vignais N, 2013, APPL ERGON, V44, P566, DOI 10.1016/j.apergo.2012.11.008
   Wang KZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P97, DOI 10.1145/2647868.2654912
   Yoon J, 2012, APPL ERGON, V43, P1044, DOI 10.1016/j.apergo.2012.03.004
   Yu WZ, 2012, ACCIDENT ANAL PREV, V48, P457, DOI 10.1016/j.aap.2012.03.001
   Zhang SM, 2008, MED BIOL ENG COMPUT, V46, P241, DOI 10.1007/s11517-007-0295-6
   Zheng H, 2005, MED BIOL ENG COMPUT, V43, P413, DOI 10.1007/BF02344720
NR 42
TC 10
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8109
EP 8129
DI 10.1007/s11042-016-3469-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800023
DA 2024-07-18
ER

PT J
AU Tan, GH
   Zhu, XY
   Liu, XF
AF Tan, Guanghua
   Zhu, Xianyi
   Liu, Xuefei
TI A free shape 3d modeling system for creative design based on modified
   catmull-clark subdivision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Catmull-Clark; B-spline surface; Creative design; 3dmodeling system;
   Free shape
AB How to express the designer's creative intent in a simple and intuitive way is the main problem in 3d modeling, especially for novice designers. This paper presents a free shape 3d modeling system for creative design based on modified Catmull-Clark subdivision. The system contains a series of easy but novel operations which can be used to change the topology of models, such as creating holes and handles. In order to create sharp features, feature marking operations are provided to specify where the sharp feature is. This system also provides surface conversion function to make the modeling results be compatible with the traditional CAD systems. Firstly, a simple but efficient quad domain division scheme is adopted to generate quad sub-meshes. In order to improve the smoothness at the regular vertices, long boundary curves which across multiple sub-meshes are used to be the boundary constraints while fitting. In this way, the smoothness at regular vertex can be C-2 continuous. We perform experiments for both skilled and novice designers. Results show that our system is easy to operate and can be used to construct complex models with less time.
C1 [Tan, Guanghua; Zhu, Xianyi; Liu, Xuefei] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Zhu, XY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM guanghuatan@gmail.com; yinweizhuzhu@sina.com; ml0428539@163.com
FU Fundamental Research Funds for the Central Universities; Science and
   Technology Planning Project of Hunan Province [2014WK3002]
FX This paper is supported by "the Fundamental Research Funds for the
   Central Universities" and "the Science and Technology Planning Project
   of Hunan Province (2014WK3002)". Thanks to Qinghong Cai's help.
CR CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   De Araújo BR, 2013, COMPUT GRAPH-UK, V37, P165, DOI 10.1016/j.cag.2012.12.005
   DeRose T., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P85, DOI 10.1145/280814.280826
   Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Igarashi T., 2007, ACM SIGGRAPH 2007 courses, P21
   Jiang Yue-hua, 2008, Journal of Zhejiang University, V42, P2068, DOI 10.3785/j.issn.1008-973X.2008.12.006
   Lars-Erik A, 2010, INTRO MATH SUBDIVISI
   Les Piegl, 1997, MONOGRAPHS VISUAL CO
   Loop C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330519
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276429
   Niessner M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077347
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Pakdel HR, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P95, DOI 10.1109/3DIM.2005.56
   PETERS J, 1995, SIAM J NUMER ANAL, V32, P645, DOI 10.1137/0732029
   Peters J, 2000, COMP GRAPH, P255, DOI 10.1145/344779.344908
   Schmidt R, 2008, COMPUT GRAPH FORUM, V27, P301, DOI 10.1111/j.1467-8659.2008.01127.x
   Shtof A, 2013, COMPUT GRAPH FORUM, V32, P245, DOI 10.1111/cgf.12044
   Yuki I, 2012, ACM T GRAPHIC, V31, P49
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 22
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6429
EP 6446
DI 10.1007/s11042-016-3305-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400016
DA 2024-07-18
ER

PT J
AU Wang, X
   Zhao, ZL
   Capps, AG
   Hamann, B
AF Wang, Xin
   Zhao, Zhen-Long
   Capps, Arlie G.
   Hamann, Bernd
TI An iterative closest point approach for the registration of volumetric
   human retina image data obtained by optical coherence tomography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume data registration; Optical coherence tomography; Retinal image;
   Iterative closest point; Point cloud
AB This paper introduces an improved approach for the volume data registration of human retina. Volume data registration refers to calculating out a near-optimal transformation between two volumes with overlapping region and stitching them together. Iterative closest point (ICP) algorithm is a registration method that deals with registration between points. Classical ICP is time consuming and often traps in local minimum when the overlapping region is not big enough. Optical Coherence Tomography (OCT) volume data are several separate, partially overlapping tiles. To stitch them together is a technology in computer aided diagnosis. In this paper, a new 3D registration algorithm based on improved ICP is presented. First, the Canny edge detector is applied to generate the point cloud set of OCT images. After the detection step, an initial registration method based on the feature points of the point cloud is proposed to determine an initial transformation matrix by using singular value decomposition (SVD) method. Then, an improved ICP method is presented to accomplish fine registration. Corresponding point in the point cloud is weighted to reduce the iteration times of ICP algorithm. Finally, M-estimation is used as the objective function to decrease the impact of outliers. This registration algorithm is used to process human retinal OCT volume pairs that contain an overlapping region of 75 x 500 x 375 voxels approximately. Then a comparative experiment is conducted on some public-available datasets. The experimental results show that the proposed method outperforms the classical method.
C1 [Wang, Xin; Zhao, Zhen-Long] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Wang, Xin] Jilin Univ, Key Lab Symbol Computat & Knowledge Engineer, Minist Educ, Changchun 130012, Peoples R China.
   [Capps, Arlie G.; Hamann, Bernd] Univ Calif Davis, Dept Comp Sci, IDAV, Davis, CA 95616 USA.
C3 Jilin University; Jilin University; University of California System;
   University of California Davis
RP Wang, X (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Wang, X (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engineer, Minist Educ, Changchun 130012, Peoples R China.
EM w_x@jlu.edu.cn
FU National Natural Science Foundation of China [60905022]; Jilin
   Provincial Research Foundation for Basic Research, China [201105016]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60905022) and the Jilin Provincial Research Foundation for
   Basic Research, China (No. 201105016). We thank the members of the
   Institute for Data Analysis and Visualization (IDAV) at the University
   of California, Davis. We also thank Jack Werner and Robert Zawadzki of
   the Vision Science and Advanced Retinal Imaging Laboratory at the
   University of California, Davis.
CR Datteri RD, 2015, IEEE T MED IMAGING, V34, P86, DOI 10.1109/TMI.2014.2344911
   Emmenlauer M, 2009, J MICROSC-OXFORD, V233, P42, DOI 10.1111/j.1365-2818.2008.03094.x
   HEMLER PF, 1995, MED PHYS, V22, P1049, DOI 10.1118/1.597591
   Huber P., 2009, Wiley Series in Probability and Statistics, V2nd, DOI DOI 10.1002/9780470434697.CH7
   Kim DY, 2011, BIOMED OPT EXPRESS, V2, P1504, DOI 10.1364/BOE.2.001504
   Li Y, 2011, OPT EXPRESS, V19, P26239, DOI 10.1364/OE.19.026239
   Li Y, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023013
   Liu B, 2014, BIO-MED MATER ENG, V24, P1149, DOI 10.3233/BME-130915
   Lu M, 2014, BIO-MED MATER ENG, V24, P1109, DOI 10.3233/BME-130910
   Pan MS, 2014, MULTIMED TOOLS APPL, V70, P1585, DOI 10.1007/s11042-012-1180-3
   Preibisch S, 2009, BIOINFORMATICS, V25, P1463, DOI 10.1093/bioinformatics/btp184
   Riffi J, 2013, IET IMAGE PROCESS, V7, P567, DOI 10.1049/iet-ipr.2012.0034
   Sharma K., 2013, Proc. of 2013 Fourth Int. Conf. Comput. Commun. Netw. Technol, P1, DOI DOI 10.1109/ICCCNT.2013.6726741
   Surucu M, 2013, MED PHYS, V40, DOI 10.1118/1.4814322
   Vignali L, 2014, CURR CARDIOL REV, V10, P369, DOI 10.2174/1573403X10666140604120753
   Ying SH, 2013, PROC CVPR IEEE, P2323, DOI 10.1109/CVPR.2013.301
   Yu Y, 2011, I S BIOMED IMAGING, P238, DOI 10.1109/ISBI.2011.5872396
   Zawadzki RJ, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2288302
NR 18
TC 10
Z9 11
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6843
EP 6857
DI 10.1007/s11042-016-3302-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400034
DA 2024-07-18
ER

PT J
AU Barra, S
   Casanova, A
   Fraschini, M
   Nappi, M
AF Barra, Silvio
   Casanova, Andrea
   Fraschini, Matteo
   Nappi, Michele
TI Fusion of physiological measures for multimodal biometric systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG signal; ECG signal; Biometric; Multimodal system; Physiological
   measures
ID RECOGNITION; IDENTIFICATION; VARIABILITY; SIGNALS
AB Physiological measures are widely studied from a medical point of view. Most applications lie in the field of diagnosis of heart attacks, as regards the ECG, or the detection of epileptic events, in the case of the EEG. In the last ten years, these signals are being investigated also from a biometric point of view, in order to exploit the discriminative capability provided by these measures in recognizing individuals. The present work proposes a multimodal biometric recognition system based on the fusion of the first lead (i) of the electrocardiogram (ECG) with six different bands of the electroencephalogram (EEG). The proposed approach is based on the extraction of fiducial features (peaks) from the ECG combined with spectrum features of the EEG. A dataset has been created, by composing the signals of two well-known databases. The results, reported by means of EER values, AUC values and ROC curves, show good recognition performances.
C1 [Barra, Silvio; Casanova, Andrea] Univ Cagliari, Dept Math & Comp Sci, Via Osped 40, I-09124 Cagliari, Italy.
   [Fraschini, Matteo] Univ Cagliari, Dept Elect & Elect Engn DIEE, I-09123 Cagliari, Italy.
   [Nappi, Michele] Univ Salerno, Via San Giovanni Paolo 2 132, I-84084 Salerno, Italy.
C3 University of Cagliari; University of Cagliari; University of Salerno
RP Barra, S (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 40, I-09124 Cagliari, Italy.
EM barra.silvio@gmail.com; casanova@unica.it; fraschini@unica.it;
   mnappi@unisa.it
RI Barra, Silvio/J-8577-2019; Fraschini, Matteo/K-3399-2019; Nappi,
   Michele/X-3089-2019
OI Barra, Silvio/0000-0003-4042-3000; Nappi, Michele/0000-0002-2517-2867;
   Fraschini, Matteo/0000-0003-2784-6527
CR Agratioti F, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1542, DOI 10.1109/ISCCSP.2008.4537472
   [Anonymous], P 12 EUR SIGN PROC C
   [Anonymous], 2008, P INT WORKSH WEAR MI
   [Anonymous], 2014, PRESENTED CORROSION
   Barra S, 2015, EEG ECG SIGNAL FUSIO
   Bermudez T., 2009, 2009 16 INT C DIGITA, P1
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Boulgouris N, 2010, MULTIMODAL PHYSL BIO, P461, DOI [10.1002/9780470522356.ch18, DOI 10.1002/9780470522356.CH18]
   Bousseljot R., 1995, INTERNET, V40, P317, DOI [DOI 10.1515/BMTE.1995.40.S1.317, 10.1515/bmte.1995.40.s1.317]
   Campisi P, 2014, IEEE T INF FOREN SEC, V9, P782, DOI 10.1109/TIFS.2014.2308640
   da Silva FL, 2013, NEURON, V80, P1112, DOI 10.1016/j.neuron.2013.10.017
   Del Pozo-Banos M, 2014, EXPERT SYST APPL, V41, P6537, DOI 10.1016/j.eswa.2014.05.013
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DelPozo-Banos M, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/5/056019
   DRAPER HW, 1964, CIRCULATION, V30, P853, DOI 10.1161/01.CIR.30.6.853
   Fraschini M, 2015, IEEE SIGNAL PROC LET, V22, P666, DOI 10.1109/LSP.2014.2367091
   Fratini A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0072-y
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hoekema R, 2001, IEEE T BIO-MED ENG, V48, P551, DOI 10.1109/10.918594
   Jayasree K., 2015, P IEEE 9 INT C INT S, P1
   Koné C, 2015, LECT NOTES COMPUT SC, V9102, P301, DOI 10.1007/978-3-319-19312-0_26
   KOZMANN G, 1989, CIRCULATION, V79, P1077, DOI 10.1161/01.CIR.79.5.1077
   Kyoso M, 2001, P ANN INT IEEE EMBS, V23, P3721, DOI 10.1109/IEMBS.2001.1019645
   La Rocca D, 2014, IEEE T BIO-MED ENG, V61, P2406, DOI 10.1109/TBME.2014.2317881
   Matos AC, 2014, PROCEDIA TECHNOLOGY, V17
   Odinaka I, 2012, IEEE T INF FOREN SEC, V7, P1812, DOI 10.1109/TIFS.2012.2215324
   Pan YZ, 2008, CONF CYBERN INTELL S, P822
   Plataniotis Konstantinos N., 2006, Biometrics Symposium: Special Session on Research at the Biometric Consortium Conference, P1
   Ravish DK, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1, DOI 10.1109/IC3I.2014.7019580
   Riera A., 2009, Biometrics: Theory, Methods, and Applications, P461, DOI DOI 10.1002/9780470522356
   Sakai M, 2008, 2008 IEEE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P538, DOI 10.1109/CIT.2008.4594732
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Shahid S, 2011, I IEEE EMBS C NEUR E, P48, DOI 10.1109/NER.2011.5910486
   Shantha Selva Kumari R., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P626, DOI 10.1109/ICETECT.2011.5760193
   Shen TW, 2002, P ANN INT IEEE EMBS, P62
   Soria-Frisch A., 2010, P 2010 IEEE INT C FU, P1, DOI DOI 10.1109/FUZZY.2010.5584121
   Verma GK, 2014, NEUROIMAGE, V102, P162, DOI 10.1016/j.neuroimage.2013.11.007
   Yun-Hong Noh, 2011, Proceedings of the 2011 6th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2011), P111
NR 38
TC 32
Z9 32
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4835
EP 4847
DI 10.1007/s11042-016-3796-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500009
DA 2024-07-18
ER

PT J
AU Chen, XJ
   An, L
   Yang, SF
   Wu, WM
AF Chen, Xiaojing
   An, Le
   Yang, Songfan
   Wu, Weimin
TI Kinship verification in multi-linear coherent spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Multi-linear coherent space learning; Patch
   selection
ID FACE; GRAPH; AGE
AB Discovering kinship relations from face images in the wild has become an interesting and important problem in multimedia and computer vision. Despite the rapid advances in face analysis in unconstrained environment, kinship verification still remains a challenging problem as the subtle kinship relation is difficult to discover and changes in pose and lighting condition further complicate this task. In this paper, we propose a kinship verification approach based on multi-linear coherent space learning. Local image patches at different scales are independently projected into their corresponding coherent spaces learned by robust canonical correlation analysis such that patch pairs with kinship relations have improved correlation. In addition, most discriminative patches for verification are selected via constrained linear programming. Experimental results on two widely used kinship verification datasets show that the proposed method can effectively identify different kinship relations in image pairs. Compared to state-of-the-art techniques, the proposed method achieves very competitive performance with the use of simple feature descriptors.
C1 [Chen, Xiaojing] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
   [An, Le] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA.
   [Yang, Songfan] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
   [Wu, Weimin] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
C3 University of California System; University of California Riverside;
   University of California System; University of California Riverside;
   Sichuan University; Huazhong University of Science & Technology
RP Wu, WM (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
EM xchen010@ucr.edu; lan004@ucr.edu; syang@scu.edu.cn; wuwm@hust.edu.cn
RI An, Le/M-2791-2015
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alvergne A, 2009, J VISION, V9, DOI 10.1167/9.6.23
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   An L, 2014, SIGNAL PROCESS, V103, P184, DOI 10.1016/j.sigpro.2013.10.004
   [Anonymous], AS C COMP VIS ACCV
   [Anonymous], 2014, IEEE T INF FORENSICS
   Arashloo SR, 2014, IEEE T INF FOREN SEC, V9, P2100, DOI 10.1109/TIFS.2014.2359587
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chen BC, 2013, IEEE T MULTIMEDIA, V15, P1163, DOI 10.1109/TMM.2013.2242460
   Chen XJ, 2013, IEEE IMAGE PROC, P4367, DOI 10.1109/ICIP.2013.6738900
   Chen YL, 2010, IEEE T SIGNAL PROCES, V58, P5016, DOI 10.1109/TSP.2010.2053029
   Chi Ho Chan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P633, DOI 10.1109/ICCVW.2009.5457642
   Dal Martello MF, 2010, J VISION, V10, DOI 10.1167/10.8.9
   Dal Martello MF, 2006, J VIS, V6
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P5400, DOI 10.1109/TIP.2014.2364536
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   Kafai M, 2014, IEEE T INF FOREN SEC, V9, P2132, DOI 10.1109/TIFS.2014.2359548
   Kafai M, 2014, IEEE T MULTIMEDIA, V16, P1090, DOI 10.1109/TMM.2014.2305633
   Kaminski G, 2009, P ROY SOC B-BIOL SCI, V276, P3193, DOI 10.1098/rspb.2009.0677
   Kan M., 2011, P BRIT MACH VISION, V11, P1
   Ledoit O, 2012, ANN STAT, V40, P1024, DOI 10.1214/12-AOS989
   Lei Z, 2012, PATTERN RECOGN LETT, V33, P1761, DOI 10.1016/j.patrec.2012.06.005
   Lu JW, 2015, IEEE INT CONF AUTOMA
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Lu JW, 2012, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2012.6247978
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Wang HX, 2010, IEEE SIGNAL PROC LET, V17, P921, DOI 10.1109/LSP.2010.2071863
   Wilson D.B., 2011, Campbell Systematic Reviews, V7
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yan Huimin, 2014, ISRN Endocrinol, V2014, P864897, DOI 10.1155/2014/864897
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Yang W, 2009, IET RENEW POWER GEN, V3, P1, DOI 10.1049/iet-rpg:20080006
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zheng LL, 2015, IEEE INT CONF AUTOMA
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhou X., 2011, ACM Multimedia, P953
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 48
TC 12
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4105
EP 4122
DI 10.1007/s11042-015-2930-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200044
DA 2024-07-18
ER

PT J
AU Orso, V
   Spagnolli, A
   Gamberini, L
   Ibañez, F
   Fabregat, ME
AF Orso, Valeria
   Spagnolli, Anna
   Gamberini, Luciano
   Ibanez, Francisco
   Fabregat, Maria Elena
TI Interactive multimedia content for older adults: the case of
   SeniorChannel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive TV; Older adults; Active audience; Usability
ID SOCIAL-ISOLATION; PEOPLE; LONELINESS; DESIGN; USERS
AB Interactive multimodal content fruition is increasingly available on platforms accessible via smart televisions (TVs), personal computers (PCs), or tablets. Based on the case of SeniorChannel TV, this paper contributes to understanding whether this format can meet the needs of older users. The paper first describes SeniorChannel TV and the usability guidelines according to which it was designed. It then reports two user studies, one of which was carried out in the field with seven test households and focused on usability. The second study was carried out in experience labs in Italy and Spain with 20 participants and assessed users' satisfaction and an active audience's experience with the final prototype. The paper offers encouraging results on the potential of interactive multimodal content to support an active audience experience, and it describes the double-level at which accessibility can be ensured.
C1 [Orso, Valeria; Spagnolli, Anna; Gamberini, Luciano] Univ Padua, Dept Gen Psychol, HTLab, Via Venezia 8, I-35131 Padua, Italy.
   [Ibanez, Francisco] Brainstorm, Valencia, Spain.
   [Fabregat, Maria Elena] Univ Alicante, Alicante, Spain.
C3 University of Padua; Universitat d'Alacant
RP Spagnolli, A (corresponding author), Univ Padua, Dept Gen Psychol, HTLab, Via Venezia 8, I-35131 Padua, Italy.
EM anna.spagnolli@unipd.it
RI Orso, Valeria/KUD-5651-2024; Spagnolli, Anna/D-1868-2014; de Mendoza,
   Francisco Ruiz/ABG-4159-2020; Fabregat-Cabrera, Maria-Elena/O-8049-2015
OI de Mendoza, Francisco Ruiz/0000-0002-1200-2850; Fabregat-Cabrera,
   Maria-Elena/0000-0002-0147-7025; Ibanez, Francisco/0000-0002-9496-0955
FU European Ambient Assisted Living Joint Program through the SeniorChannel
   project [AAL-2009-2-090]
FX The study was partially funded by the European Ambient Assisted Living
   Joint Program through the SeniorChannel project (AAL-2009-2-090).
CR Bondad-Brown BA, 2012, J BROADCAST ELECTRON, V56, P471, DOI 10.1080/08838151.2012.732139
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Capece G, 2013, BEHAV INFORM TECHNOL, V32, P438, DOI 10.1080/0144929X.2011.610825
   Carmichael A., 1999, STYLE GUIDE DESIGN I
   Carpentier N., 2012, FRONTEIRAS ESTUDOS M, V14, P164
   Cattan M, 2005, AGEING SOC, V25, P41, DOI 10.1017/S0144686X04002594
   Commission of the European Communities, BARR WID ACC NEW SER
   Dickinson A, 2007, BEHAV INFORM TECHNOL, V26, P343, DOI 10.1080/01449290601176948
   Dodero G., 2015, P 11 BIANN C IT SIGC, V28, P10, DOI [10.1145/2808435.2808436, DOI 10.1145/2808435.2808436]
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   Findlay RA, 2003, AGEING SOC, V23, P647, DOI 10.1017/S0144686X03001296
   Fisk AD, 2009, Designing for older adults: Principles and creative human factors approaches
   Forsman AK, 2013, AGEING SOC, V33, P804, DOI 10.1017/S0144686X12000256
   Garcia-Aviles J.A., 2012, J AUDIENCE RECEPTION, V9, P429
   Gill John., 2003, Proceedings of the 1st European conference on interactive television: from viewers to actors, P83
   Gordon-Salant S, 2009, AGING AUDITORY SYSTE, V34
   Hess J, 2014, BEHAV INF TECHNOL, V33
   Holmes Su., 2004, INT J CULTURAL STUD, V7, P213, DOI [DOI 10.1177/1367877904043238, 10.1177/1367877904043238]
   Jensen J.F., 2005, Proc. the Second Australasian Conference on Interactive entertaINPent, P89
   Jung YB, 2012, COMPUT HUM BEHAV, V28, P1626, DOI 10.1016/j.chb.2012.04.001
   Lee M, 2013, MEDIA PSYCHOL, V16, P412, DOI 10.1080/15213269.2013.826119
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Livingstone Sonia., 2003, COMPANION MEDIA STUD, P337
   Lund A. M., 2001, Usability User Exp. Newsl. STC Usability SIG, V8, P1
   Newell AF, 2011, UNIVERSAL ACCESS INF, V10, P235, DOI 10.1007/s10209-010-0203-y
   Nunes F., 2012, Proceedings of the 14th international ACM SIGACCESS conference on Computers and accessibility - ASSETS'12, P41, DOI DOI 10.1145/2384916.2384924
   Orso V., 2015, Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter, V28, P102, DOI [DOI 10.1145/2808435.2808464, 10.1145/2808435.2808464]
   Pak R., 2010, Designing displays for older adults
   Piccolo LSG, 2007, LECT NOTES COMPUT SC, V4662, P361
   Spagnolli A, 2012, STUD HEALTH TECHNOL, V181, P233, DOI 10.3233/978-1-61499-121-2-233
   Sperring S, 2008, INT J HUM-COMPUT INT, V24, P214, DOI 10.1080/10447310701821590
   Zaphiris P., 2005, Proceedings of CHI '05 Human Factors in Computing Systems, P1897, DOI [DOI 10.1145/1056808.1057050, 10.1145/1056808.1057050]
NR 32
TC 6
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5171
EP 5189
DI 10.1007/s11042-016-3553-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500022
DA 2024-07-18
ER

PT J
AU Singh, P
   Raman, B
   Roy, PP
AF Singh, Priyanka
   Raman, Balasubramanian
   Roy, Partha Pratim
TI A multimodal biometric watermarking system for digital images in
   redundant discrete wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rightful ownership; Multimodal biometric systems; Redundant discrete
   wavelet transform(RDWT); Impostor attacks; Nonlinear chaotic maps;
   Hessenberg decomposition; Arnold scrambling; False acceptance rate;
   False rejection rate; Area under curve; Equal error rate
ID ROBUST WATERMARKING; DCT
AB The traditional watermarking algorithms prove the rightful ownership via embedding of independent watermarks like copyright logos, random noise sequences, text etc into the cover images. Coupling biometrics with watermarking evolved as new and secure approach as it embeds user specific biometric traits and thus, narrows down the vulnerability to impostor attacks. A multimodal biometric watermarking system has been proposed in this paper in the redundant discrete wavelet transform(RDWT). Two biometric traits of the user i.e. the iris and facial features are embedded independently into the sub-bands of the RDWT of cover image taking advantage of its translation invariant property and sufficient embedding capacity. The ownership verification accuracy of the proposed system is tested based on the individual biometric traits as well as the fused trait. The accuracy was enhanced while using the fused score for evaluation. The security of the scheme is strengthened with usage of non-linear chaotic maps, randomization via Hessenberg decomposition, Arnold scrambling and multiple secret keys. The robustness of the scheme has been tested against various attacks and the verification accuracy evaluated based on false acceptance rate, false rejection rate, area under curve and equal error rate to validate the efficacy of the proposed scheme.
C1 [Singh, Priyanka; Raman, Balasubramanian; Roy, Partha Pratim] Indian Inst Technol, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Singh, P (corresponding author), Indian Inst Technol, Roorkee, Uttar Pradesh, India.
EM priyankiitr@iitr.ac.in; balarfma@iitr.ac.in; proy.fcs@iitr.ac.in
RI Singh, Priyanka/GRF-6098-2022; singh, priyanka/JWP-2636-2024; Singh,
   Priyanka/N-1372-2018; Roy, Partha Pratim/AAV-9061-2020; Roy, Partha
   Pratim/GPF-4253-2022; Roy, Partha Pratim/AAW-2994-2020
OI Singh, Priyanka/0000-0001-7874-7778; Singh,
   Priyanka/0000-0003-0841-1544; Roy, Partha Pratim/0000-0002-5735-5254;
   SINGH, PRIYANKA/0000-0001-5002-8800
CR Amirgholipour S, 2014, INT ARAB J INF TECHN, V11, P178
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Barni M., 1998, P POWER ELECT VARIAB, P17
   Bohra A, 2009, AEU-INT J ELECTRON C, V63, P703, DOI 10.1016/j.aeue.2008.05.010
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Ching-Yu Yang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.209
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Consultants T, 2010, BUILDING DIGITAL EC
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2002, HIDING FACE FINGERPR
   Jiang GY, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1580, DOI 10.1109/ICOSP.2002.1180099
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Lu ZM, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P241
   Maity SP, 2010, AEU-INT J ELECTRON C, V64, P243, DOI 10.1016/j.aeue.2008.10.004
   Mohanty SP, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P183
   Morita Y, 2009, MIDWEST SYMP CIRCUIT, P683, DOI 10.1109/MWSCAS.2009.5236002
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Ratha N.K., 2000, P ACM MULTIMEDIA, P127
   Rawat S, 2012, AEU-INT J ELECTRON C, V66, P955, DOI 10.1016/j.aeue.2012.04.004
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Soutar C., 1999, Biometric Encryption, ICSA Guide to Cryptography
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Vatsa M., 2004, P WORKSHOP BIOMETRIC, P5
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
   Zhen Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2757, DOI 10.1109/ICIP.2011.6116241
NR 32
TC 22
Z9 25
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3871
EP 3897
DI 10.1007/s11042-016-4048-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200034
DA 2024-07-18
ER

PT J
AU Anusudha, K
   Venkateswaran, N
   Valarmathi, J
AF Anusudha, K.
   Venkateswaran, N.
   Valarmathi, J.
TI Secured medical image watermarking with DNA codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Discrete Wavelet Transform; Chaotic Sequence;
   Deoxyribonucleic acid (DNA); Genetic algorithm (GA)
ID FIN HEAT-EXCHANGERS; REVERSIBLE WATERMARKING; SEQUENCE OPERATION;
   GENETIC ALGORITHM; ENCRYPTION; AUTHENTICATION; OPTIMIZATION; DESIGN
AB Modern healthcare systems are based on managing diagnostic information of patients through E-health. E-health refers to the Internet enabled healthcare applications involving transacting personal health records or information and other internet based services including e-Pharmacy where security threats is a major concern . This paper introduces a hybrid watermarking and encryption technique for copyright protection and authentication of medical images. The medical image is watermarked in wavelet domain where in the Electronic Health Record (EHR) is used as watermark and hospital logo as the reference image. Embedding of the EHR data is based on energy band selection and in reference to the bit location in the reference image A Composite algorithm for improved image security is proposed by taking the advantages of DNA based image encryption and genetic algorithms (GA). A number of deoxyribonucleic acid (DNA) masks are created using logistic map function and DNA conversion rules. Then encryption is performed on the watermarked image to generate a number of cipher images. Genetic algorithm (GA) is applied to find the best DNA mask in iterative manner until the condition is met. The experimental results demonstrate the capability of the proposed scheme to the available security attributes in both frequency and encryption domain while minimizing image distortion and also resists to various attacks.
C1 [Anusudha, K.; Valarmathi, J.] VIT Univ, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
   [Venkateswaran, N.] SSN Coll Engn, Dept Elect & Commun Engn, Madras 603110, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; SSN College of
   Engineering
RP Anusudha, K (corresponding author), VIT Univ, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM anusudhak@yahoo.co.in
RI J, Valarmathi/AAB-5553-2019; N, Venkateswaran/AGR-2157-2022
OI J, Valarmathi/0000-0001-9165-5886; N, Venkateswaran/0000-0002-6789-4112;
   , ANUSUDHA/0009-0003-1559-1704
FU University Grants Commission (UGC), India [42-1017/2013 (SR)]
FX This research was supported by the research fund of University Grants
   Commission (UGC), India. (Project No: 42-1017/2013 (SR)).
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Ali Hajjaji Mohamed, 2011, J EMERGING TRENDS CO, V2, P714
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Blumenthal D, 2010, NEW ENGL J MED, V363, P501, DOI 10.1056/NEJMp1006114
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Cox I. J., 2002, DIGITAL WATERMARKING, P41
   Desai D., 2012, INT J COMPUTER SCI I, V3, P4809
   Drezner Z, 2013, COMPUT OPER RES, V40, P1038, DOI 10.1016/j.cor.2012.10.014
   Dyer JD, 2012, APPL MATH COMPUT, V218, P4710, DOI 10.1016/j.amc.2011.07.038
   Enayatifar R, 2013, ENERG CONVERS MANAGE, V76, P1104, DOI 10.1016/j.enconman.2013.08.039
   Enayatifar R, 2013, COMMUN NONLINEAR SCI, V18, P3481, DOI 10.1016/j.cnsns.2013.04.028
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Enayatifar R, 2013, APPL MATH COMPUT, V219, P8829, DOI 10.1016/j.amc.2013.03.099
   Gehani A, 2000, INT J COMPUTER APPL, V70, P233
   Höglund H, 2013, EXPERT SYST APPL, V40, P2366, DOI 10.1016/j.eswa.2012.10.048
   Hsu W, 2012, IEEE T INF TECHNOL B, V16, P228, DOI 10.1109/TITB.2012.2186149
   Hu JK, 2010, COMPUT STAND INTER, V32, P274, DOI 10.1016/j.csi.2009.04.005
   Khan M, 2014, J 3D RES, P28
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kuo HC, 2013, APPL MATH COMPUT, V219, P7348, DOI 10.1016/j.amc.2012.12.046
   Leier A, 1997, BIOSYSTEMS, V57, P9
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Lipton RJ., 1995, J COMPUT SYST SCI, V268, P542
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pember M, 2015, HLTH INFORM SERIES, P53
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Ulutas M, 2011, J SYST SOFTWARE, V84, P341, DOI 10.1016/j.jss.2010.11.928
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xue XL, 2010, J COMPUT THEOR NANOS, V7, P397, DOI 10.1166/jctn.2010.1372
   Yousefi M, 2012, INT COMMUN HEAT MASS, V39, P258, DOI 10.1016/j.icheatmasstransfer.2011.11.011
   Yousefi M, 2013, APPL THERM ENG, V50, P877, DOI 10.1016/j.applthermaleng.2012.05.038
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2012, SCI WORLD J, DOI 10.1100/2012/286741
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 45
TC 11
Z9 12
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2911
EP 2932
DI 10.1007/s11042-015-3213-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000058
DA 2024-07-18
ER

PT J
AU Dong, L
   Yan, Q
   Lv, Y
   Deng, SY
AF Dong, Luan
   Yan, Qin
   Lv, Yong
   Deng, Shuyu
TI Full band watermarking in DCT domain with Weibull model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; DCT; Weibull distribution; Signal detection
ID OPTIMUM DETECTION; IMAGE WATERMARKING
AB In the framework of maximum-likelihood detection for image watermarking schemes, the conventional Generalized Gaussian Distribution (GGD), Cauchy and Student's t distributions often fail to model the pulse-like distributions, such as Discrete Cosine Transform (DCT) coefficient distribution. Meanwhile DCT DC coefficients are often neglected in the image watermarking schemes. In this paper an improved full band image watermarking algorithm with utilization of Weibull distribution modeling the DCT AC and DC coefficients is proposed. Experiments indicate that compared with other popluar distributions such as the GGD, the Weibull model gives a closer fit on the distribution of AC coefficients in absolute domain with a smaller Kullback-Leibler (KL) divergence and lower Mean Square Error (MSE). The watermarking scheme with Weibull modeling the DCT AC coefficients (Weibull-AC) exhibits strong robustness under the attack of scaling and median filtering. The watermarking scheme with Weibull modeling the DCT DC coefficients (Weibull-DC) yields a better detection accuracy for bright and more detailed images. Combining the above two advantages, the proposed Weibull based full band watermarking in DCT domain (Weibull-FB) further improves its robustness under the attack of JPEG compression and achieves 10.47 % overall increment in the detection accuracy compared with the baseline system while maintaining good invisibility in the view of structural similarity (SSIM).
C1 [Dong, Luan; Yan, Qin; Lv, Yong; Deng, Shuyu] Hohai Univ, Coll Comp & Informat, 8 Focheng West Rd, Nanjing 211100, Jiangsu, Peoples R China.
   [Dong, Luan] Xinjiang Agr Univ, Coll Comp & Informat Engn, 311 Nongda East Rd, Urumqi 830052, Peoples R China.
C3 Hohai University; Xinjiang Agricultural University
RP Yan, Q (corresponding author), Hohai Univ, Coll Comp & Informat, 8 Focheng West Rd, Nanjing 211100, Jiangsu, Peoples R China.
EM phd.luan.dong@gmail.com; yan_qin@hhu.edu.cn; yonglu@hhu.edu.cn;
   dsyhhu@gmail.com
RI Dong, Luan/GSN-8665-2022
FU National Natural Science Foundation of China [61170297, 61301218]; Qing
   Lan Project of Jiangsu Province of China
FX This research was supported by National Natural Science Foundation of
   China (No.61170297, 61301218) and Qing Lan Project of Jiangsu Province
   of China.
CR Achatz RJ, 2004, 80215 NTIAITS US
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   [Anonymous], 2013, J DATA SCI, DOI [DOI 10.1016/B978-0-12-386932-6.09988-9, DOI 10.6339/JDS.2013.11(3).1110]
   [Anonymous], 1994, INTRO SIGNAL DETECTI, DOI DOI 10.1007/978-1-4757-2341-0
   [Anonymous], SIPI IM DAT
   Balakrishnan N, 2008, STAT PROBABIL LETT, V78, P2971, DOI 10.1016/j.spl.2008.05.019
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Briassouli A, 2004, IEEE T IMAGE PROCESS, V13, P1604, DOI 10.1109/TIP.2004.837516
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Dong L, 2014, IEEE REGION 10 SYMP, P196, DOI 10.1109/TENCONSpring.2014.6863024
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Ghouti L, 2012, IET C IM PROC, P1, DOI DOI 10.1049/CP.2012.0456
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   LIU CH, 1995, STAT SINICA, V5, P19
   Liu W, 2007, IEEE T INF FOREN SEC, V2, P645, DOI 10.1109/TIFS.2007.908226
   Mairgiotis A., 2013, P 18 INT C DIG SIGN, P1, DOI DOI 10.1109/ICDSP.2013.6622794
   Ng TM, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P1680
   Schuster S., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P350
   Singh J, 2014, MULTIMED TOOLS APPL, V71, P1431, DOI 10.1007/s11042-012-1282-y
   Song KS, 2006, IEEE T INFORM THEORY, V52, P510, DOI 10.1109/TIT.2005.860423
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Valizadeh A, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-88
NR 29
TC 37
Z9 40
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1983
EP 2000
DI 10.1007/s11042-015-3115-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000018
DA 2024-07-18
ER

PT J
AU Tran, HTT
   Won, Y
   Kim, J
AF Ha Thi Thu Tran
   Won, Yonggwan
   Kim, Jinsul
TI An efficient hybrid push-pull methodology for peer-to-peer video live
   streaming system on mobile broadcasting social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer; Live video streaming; File sharing; Broadcasting; Pull and
   push
AB With the rapid growth of wireless communication technology, the availability of highly flexible and video-friendly mobile terminal platforms (such as smartphones and tablets), the emergence of major video content providers (like YouTube, Ustream, and PPTV, which provide a large catalog of attractive contents), Peer-to-Peer (P2P) live video streaming over the wireless and Internet is becoming more and more attractive to users. One of the main challenges is to provide a good quality of service though the dynamic behavior of the network. Traditionally, tree-based model uses a push method, that broadcaster transfers data to other users. This model has low start-up delay. However, there are two main problems in this method: if the bandwidth of an internal node is low, children nodes may lose data and when an internal node failure, other nodes can't receive data until completing the recovery of the tree. On the other hand, mesh-based model uses a pull method, has low bandwidth of a neighbor node by pulling necessary data from a number of neighbor nodes. However, mesh-based model requires large buffers to support pull data from neighbor peers and there is an adjustment between minimum delay by sending pull request and overhead of whole system. So, both models have their own strengths and weaknesses. This paper proposes a new hybrid push-pull live P2P video streaming protocol called MobileCast that combines the benefits of pull and push mechanisms for live video delivery. We present new topology for P2P network with more stable and provide better video streaming quality. Our main goal is to minimize the network end-to-end delay, startup time, overhead, packet loss compared to the pure mesh networks, pure tree networks and provide a good quality of service though the dynamic behavior of the network.
C1 [Ha Thi Thu Tran; Won, Yonggwan; Kim, Jinsul] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju, South Korea.
C3 Chonnam National University
RP Kim, J (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju, South Korea.
EM thuhabkhn@gmail.com; ykwon@jnu.ac.kr; jsworld@jnu.ac.kr
FU Chonnam National University; National Research Foundation of Korea (NRF)
   - Ministry of Education, Science and Technology [NRF-2013R1A1A2013740];
   IT R&D program of MSIP(Ministry of Science, ICT and Future Planning) /
   IITP(Institute for Information & Communications Technology Promotion)
   [12221-14-1001]
FX This research was supported by Chonnam National University and Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (NRF-2013R1A1A2013740) and was partially supported by the IT R&D program
   of MSIP(Ministry of Science, ICT and Future Planning) / IITP(Institute
   for Information & Communications Technology Promotion) [12221-14-1001,
   Next Generation Network Computing Platform Testbed].
CR Chang HS, 2011, IEEE ACM T NETWORK, V19, P55, DOI 10.1109/TNET.2010.2056382
   CHENG X, 2012, ACM TRANSACTIONS MUL, V8, P1
   Cheng X, 2012, IEEE T MULTIMEDIA, V14, P1558, DOI 10.1109/TMM.2012.2217735
   Cho Changhee, 2014, INT J SOFTWARE ENG I, V8, P151
   Fan B, 2009, IEEE ACM T NETWORK, V17, P365, DOI 10.1109/TNET.2008.2002553
   Liu B, 2009, IEEE T MULTIMEDIA, V11, P361, DOI 10.1109/TMM.2009.2012911
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Sanna M, 2013, IEEE LAT AM T, V11, P962, DOI 10.1109/TLA.2013.6568840
   Ha TTT, 2014, INT C INFO SCI APPL
   Venkataraman V., 2006, P IEEE ICNP
   Wu D, 2013, IEEE T CIRC SYST VID, V23, P1029, DOI 10.1109/TCSVT.2013.2249020
   Zhang X, 2005, P INF
NR 12
TC 8
Z9 9
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2557
EP 2568
DI 10.1007/s11042-016-3249-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000042
DA 2024-07-18
ER

PT J
AU He, YF
   Zhang, ZY
   Nan, XM
   Zhang, N
   Guo, F
   Rosales, E
   Guan, L
AF He, Yifeng
   Zhang, Ziyang
   Nan, Xiaoming
   Zhang, Ning
   Guo, Fei
   Rosales, Edward
   Guan, Ling
TI vConnect: perceive and interact with real world from CAVE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cave Automatic Virtual Environment (CAVE); Virtual reality;
   Human-Computer Interaction (HCI); Cloud computing; Wireless sensor
   networks; Optimal resource allocation; Quality of Service (QoS)
AB The Cave Automatic Virtual Environment (CAVE) is a fully immersive Virtual Reality (VR) system. CAVE systems have been widely used in many applications, such as architectural and industrial design, medical training and surgery plan, museums and education. However, one limitation for most of the current CAVE systems is that they are separated from the real world. The user in the CAVE is not able to sense the real world around him or her. In this paper, we propose a vConnect architecture, which aims to establish real-time bidirectional information exchange between the virtual world and the real world by utilizing the advanced technologies in cloud computing, mobile communications, wireless sensor networks, and computer vision. Specifically, we address three technical challenges in the proposed vConnect architecture. First, we propose an optimal allocation scheme for the wireless sensor networks to ensure that the data streams captured by the sensors can be delivered to the cloud servers in a reliable and prompt way. Second, we optimize the allocation of the cloud resources to ensure that the data streams sent from the clients can be processed promptly by the cloud servers at a minimal resource cost. Third, we propose to use marker-based finger interactions such that the user in the CAVE can manipulate the information in a natural and intuitive way. Fourth, we implemented a vHealth prototype, a CAVE-based real-time health monitoring system, to validate the proposed vConnect architecture. We demonstrated in the vHealth prototype that the user in the CAVE can visualize and manipulate the real-time physiological data of the patient who is being monitored, and interact with the patient.
C1 [He, Yifeng; Zhang, Ziyang; Nan, Xiaoming; Zhang, Ning; Guo, Fei; Rosales, Edward; Guan, Ling] Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON, Canada.
C3 Toronto Metropolitan University
RP He, YF (corresponding author), Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM yhe@ee.ryerson.ca
OI Zhang, Ning/0000-0003-0497-1966
FU Natural Science and Engineering Council of Canada [238813/2010]; Key
   International Collaboration Grant of National Natural Science Foundation
   of China [61210005]
FX This work is partially supported by the Discovery Grant of Natural
   Science and Engineering Council of Canada (No. 238813/2010) and the Key
   International Collaboration Grant of National Natural Science Foundation
   of China (No. 61210005).
CR Abramyan L, 2012, AEROSP CONF PROC
   Akpan IJ, 2014, DECISION SUPPORT SYS
   Al-Khalifah A, 2005, PROC SPIE, V5669, P350, DOI 10.1117/12.587633
   [Anonymous], 2004, PROBABILITY STOCHAST
   [Anonymous], J VIRTUAL WORLDS RES
   Ardagna D., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P163, DOI 10.1109/CLOUD.2011.32
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cheng L, 2014, IEEE T PARALL DISTR, V25, P1864, DOI 10.1109/TPDS.2013.240
   Creagh H, 2003, PROCEEDINGS: ELECTRICAL INSULATION CONFERENCE AND ELECTRICAL MANUFACTURING & COIL WINDING TECHNOLOGY CONFERENCE, P499, DOI 10.1109/EICEMC.2003.1247937
   Gieser SN, 2013, P ACM INT C PERV TEC
   Gross D., 2009, Fundamentals of Queueing Theory, V4th
   Kim JS, 2010, LECT NOTES COMPUT SC, V6133, P56
   Koike M, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P634, DOI 10.1109/ICIG.2009.80
   LI Y, 2010, PROCEEDINGS OF IEEE, P500
   Lin Albert Yu-Min, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P229, DOI 10.1007/978-3-642-24031-7_23
   Mizutori M., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P79, DOI 10.1109/VSMM.2012.6365910
   Nan XM, 2013, IEEE INT SYMP CIRC S, P2872, DOI 10.1109/ISCAS.2013.6572478
   Nan XM, 2013, INT CONF ACOUST SPEE, P3771, DOI 10.1109/ICASSP.2013.6638363
   Nan XM, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Nancel M., 2011, P SIGCHI C HUM FACT, DOI [DOI 10.1145/1978942.1978969, 10.1145/1978942.1978969]
   Prachyabrued Mores, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P45, DOI 10.1007/978-3-642-24031-7_5
   Riva G, 2003, METHOD INFORM MED, V42, P524
   Roberts DJ, 2005, COMPUT INFORM, V24, P7
   Schaeffer B., 2003, P ACM S VIRT REAL SO, P108
   Shah GA, 2012, IEEE T MULTIMEDIA, V14, P1442, DOI 10.1109/TMM.2012.2196510
   Shu T, 2006, IEEE T WIREL COMMUN, V5, P3109, DOI 10.1109/TWC.2006.04738
   Song P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1333
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Sutcliffe A., 2006, ACM Transactions on Computer-Human Interaction, V13, P235, DOI 10.1145/1165734.1165738
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   von Kapri A, 2011, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2011.5759443
   Vote E, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1028725
   Wijayasekara D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2471, DOI 10.1109/IJCNN.2011.6033540
   Wu Q., 2010, P 2010 ACM WORKSH SU, P3, DOI [10.1145/1878083.1878087, DOI 10.1145/1878083.1878087]
   Xiaoming Nan, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P461, DOI 10.1109/ChinaSIP.2013.6625382
   Zhang DG, 2014, IEEE T IND INFORM, V10, P766, DOI 10.1109/TII.2013.2250910
NR 36
TC 6
Z9 6
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1479
EP 1508
DI 10.1007/s11042-015-3121-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000065
DA 2024-07-18
ER

PT J
AU Jarrah, M
   Al-Quraan, M
   Jararweh, Y
   Al-Ayyoub, M
AF Jarrah, Moath
   Al-Quraan, Muneera
   Jararweh, Yaser
   Al-Ayyoub, Mahmoud
TI MedGraph: a graph-based representation and computation to handle large
   sets of images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Region of interest (ROI); Medical images; Graph-based
   computation; Big data
AB In order to process and analyze very large volumes of images, efficient representation and structuring techniques are required. Since, current computing machines can provide large memory size, trading off reasonable amount of memory in order to achieve efficient and parallelizable representation of images is preferable. In this paper, we propose a new structure to represent and store images based on in-memory graph concept. Our method of computation provides a faster execution time than the traditional array-based representation. Each pixel of an image is represented as a one node in the graph. In addition, nodes have pointers to other neighboring nodes (pixels). The structure represents an image as a grid of connected linked lists and each grid is connected to other grids. Using our method, an image can be represented in one of three different representations which are: octal linked list, quadratic linked list, and dual linked list representations. We provide experiments and evaluations using the dual linked list representation as it requires less memory space. We apply our methodology for medical images as a proof of the concept to find a region of interest in an image. We have collected and used real medical images to build and process the graph which we call MedGraph. Our experimental results show that the proposed MedGraph technique improves the searching time for finding a region of interest when compared to the traditional representation. It is worth mentioning here that MedGraph is a generic representation strategy that can be applied to any type of images, although this paper uses medical images as a proof of the concept.
C1 [Jarrah, Moath] Jordan Univ Sci & Technol, Dept Comp Engn, Irbid 22110, Jordan.
   [Al-Quraan, Muneera; Jararweh, Yaser; Al-Ayyoub, Mahmoud] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology
RP Jarrah, M (corresponding author), Jordan Univ Sci & Technol, Dept Comp Engn, Irbid 22110, Jordan.
EM mjarrah@just.edu.jo; maalquraan12@cit.just.edu.jo;
   yijararweh@just.edu.jo; maalshbool@just.edu.jo
RI Jararweh, Yaser/JCO-2836-2023; Jararweh, Yaser/ABE-6543-2021
OI Jarrah, Moath/0000-0002-5619-1032; Jararweh, Yaser/0000-0002-4403-3846
FU Deanship of Research at the Jordan University of Science and Technology
   [20150050]
FX The authors would like to thank the Deanship of Research at the Jordan
   University of Science and Technology for funding this work, grant number
   20150050.
CR Andrews S, 2015, ARXIV150907244 CORR
   Beckwith R., 2011, J PET TECH, V63, P42
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Bryant R., 2008, BIG-DATA COMPUTING: CREATING REVOLUTIONARY BREAKTHROUGHS IN COMMERCE, SCIENCE, AND SOCIETY
   Castleman K.R., 1995, DIGITAL IMAGE PROCES
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   DataStax, 2012, CISC VIS NETW IND GL
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Douglas CC, 2014, PROCEDIA COMPUT SCI, V29, P1246, DOI 10.1016/j.procs.2014.05.112
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Frieze A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1522
   Gantz J., 2011, EXTRACTING VALUE CHA
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   GIRSHICK RB, 2015, ARXIV150408083 CORR
   Global Pulse, 2012, CISC VIS NETW IND GL
   Gonzalez Joseph E., 2012, 10 USENIX S OP SYST, P17
   Huang J, 2015, J MED BIOL ENG, V35
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Li JZ, 2011, IEEE T KNOWL DATA EN, V23, P1388, DOI 10.1109/TKDE.2010.249
   Liu Y, 2008, PROC INT CONF DATA, P903, DOI 10.1109/ICDE.2008.4497499
   Lumpkin G, 2015, CISC VIS NETW IND GL
   Matti M., 2012, ERICSSON REV, V284, P23
   Samih A, 2014, LECT NOTES COMPUT SC, V8360, P17, DOI 10.1007/978-3-642-54212-1_2
   Shao B., 2012, Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, P589
   Stonebraker M, 2013, SIGMOD REC, V42, P44
   Thomsen J.R., 2012, SIGMOD, P313, DOI DOI 10.1145/2213836.2213872
   Vavilapalli V.K., P 4 ANN S CLOUD COMP
   Villars R.L., 2011, IDC WHITE PAPER
   Walder R, 2005, ASTRON J, V626
   Xin Reynold S, 2013, INT WORKSH GRAPH DAT, P1, DOI DOI 10.1145/2484425.2484427
   Young I.T., 1995, FUNDAMENTALS IMAGE P
   Zhou C, 2014, PROC VLDB ENDOW, V8, P377, DOI 10.14778/2735496.2735501
   Zhou Q, 2005, MULTIMED TOOLS APPL, V27, P251, DOI 10.1007/s11042-005-2577-z
NR 34
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2769
EP 2785
DI 10.1007/s11042-016-3262-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000052
DA 2024-07-18
ER

PT J
AU Mizuno, S
   Tsukada, M
   Uehara, Y
AF Mizuno, Shinji
   Tsukada, Mami
   Uehara, Yuto
TI Developing a stereoscopic CG system with motion parallax and interactive
   digital contents on the system for science museums
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Morion parallax; Stereoscopic; 3DCG; Interaction; Science museum; Kinect
AB As we watch 3D objects and move around them, the appearance of the objects would change. This is called motion parallax and it is one of important depth cues. We develop an interactive stereoscopic CG system using motion parallax. This system follows the position of a user's view point, and generates 3DCG images for the view point every moment. As a result, the system can reproduce motion parallax and can synthesize stereoscopy without special equipments. Based on this system, we develop two interactive stereoscopic contents which would be used in science museums. One is a constellation viewer, in which we can observe constellations and planets from any positions, and can grasp positional relationships and 3D shapes of them. It is also possible to control the content with gestures. The other is a virtual 3D photocopy system. When we put physical 3D objects on a desk and remove them, we can observe virtual objects from any points as a stereoscopic 3DCG image based on motion parallax. We can feel the removed objects being left as they were. When the system scans moving objects, a stereoscopic 3DCG animation is synthesized and the user can observe it from any positions. It is also possible to interact with the 3DCG objects such as touching and deforming the 3DCG objects.
C1 [Mizuno, Shinji; Tsukada, Mami; Uehara, Yuto] Aichi Inst Technol, Fac Informat Sci, Toyota, Japan.
RP Mizuno, S (corresponding author), Aichi Inst Technol, Fac Informat Sci, Toyota, Japan.
EM s_mizuno@aitech.ac.jp; m109m@hotmail.co.jp; ue.to120@gmail.com
FU Ministry of Education, Science, Sports and Culture of Japan [23500139,
   25280131]; Grants-in-Aid for Scientific Research [23500139, 26330420,
   25280131] Funding Source: KAKEN
FX The authors would like to thank Prof. Takami Yasuda (Nagoya University),
   Dr. Katsuhiro Mouri (Nagoya City Science Museum), and all the members of
   Zakkyo seminar for providing valuable advices. This work has been
   supported by Ministry of Education, Science, Sports and Culture of
   Japan, Grant-in-Aid for Scientific Research (C)(23500139) and
   (B)(25280131).
CR [Anonymous], T VIRTUAL REALITY SO
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Cutting JE, 1995, PERCEPTION SPACE MOT, P69, DOI [DOI 10.1016/B978-012240530-3/50005-5, 10.1016/B978-012240530-3/50005-5]
   Fei Y, 2012, SIGGRAPH 2012
   Harada K, 2012, P IPSJ INT 2012, P795
   Ishii R, 2011, P IPSJ INT 2011
   Kajinami T., 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P230, DOI 10.1109/VSMM.2010.5665979
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Nakazawa A, 2002, P VSMM2002 8 INT C V, P138
   ROGERS B, 1982, VISION RES, V22, P261, DOI 10.1016/0042-6989(82)90126-2
   ROGERS B, 1979, PERCEPTION, V8, P125, DOI 10.1068/p080125
   [No title captured]
NR 12
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2515
EP 2533
DI 10.1007/s11042-015-3236-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000040
DA 2024-07-18
ER

PT J
AU Zhao, YN
   Zhao, X
   Xiang, ZJ
   Liu, YC
AF Zhao, Yanna
   Zhao, Xu
   Xiang, Zongjie
   Liu, Yuncai
TI Online learning of dynamic multi-view gallery for person
   Re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Dynamic gallery learning; Feature
   correspondence; Clustering
AB Person re-identification receives increasing attentions in computer vision due to its potential applications in video surveillance. In order to alleviate wrong matches caused by misalignment or missing features among cameras, we propose to learn a multi-view gallery of frequently appearing objects in a relatively closed environment. The gallery contains appearance models of these objects from different cameras and viewpoints. The strength of the learned appearance models lies in that they are invariant to viewpoint and illumination changes. To automatically estimate the number of frequently appearing objects in the environment and update their appearance models online, we propose a dynamic gallery learning algorithm. We specifically build up two datasets to validate the effectiveness of our approach in realistic scenarios. Comparisons with benchmark methods demonstrate promising performance in accuracy and efficiency of re-identification.
C1 [Zhao, Yanna] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Zhao, Yanna; Zhao, Xu; Xiang, Zongjie; Liu, Yuncai] Shanghai Jiao Tong Univ, Sch Automat, Shanghai, Peoples R China.
C3 Shandong Normal University; Shanghai Jiao Tong University
RP Zhao, YN (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.; Zhao, YN; Zhao, X (corresponding author), Shanghai Jiao Tong Univ, Sch Automat, Shanghai, Peoples R China.
EM yannazhao@outlook.com; zhaoxu@sjtu.edu.cn;
   zongzong_1984_111@hotmail.com; whomliu@sjtu.edu.cn
FU China 973 project [2011CB302203, NSFC 61375019, NSFC 61273285]
FX This research has been partially supported by the grants of China 973
   project 2011CB302203, NSFC 61375019 and NSFC 61273285.
CR [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], 2013, MULTIMEDIA TOOLS APP
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2010, Asian Conference on Computer Vision
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P179, DOI 10.1109/AVSS.2011.6027316
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Chen KJ, 2008, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE OF MODELLING AND SIMULATION, VOL V, P1
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdoun O, 2008, INT C DISTRIBUTED SM, P1
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Javed O, 2005, PROC CVPR IEEE, P26
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Kaufman L., 2009, FINDING GROUPS DATA
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Makris D, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P183, DOI 10.1109/AVSS.2003.1217920
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Xiang Z, 2012, MULTIMED TOOLS APPL, P1
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 35
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 217
EP 241
DI 10.1007/s11042-015-3015-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000011
DA 2024-07-18
ER

PT J
AU AlQaralleh, EA
   Abu-Sharkh, OF
AF AlQaralleh, Esam A.
   Abu-Sharkh, OsamaM. F.
TI Low-complexity motion estimation design using modified XOR function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Motion estimation; XOR SAD; FPGA implementation
ID ESTIMATION ALGORITHM; BIT TRANSFORM; ARCHITECTURE; COMPUTATION; SEARCH;
   IMAGE; MPEG2
AB Video coding techniques which are characterized by huge computational burden extensively consume power. Motion estimation with block matching criterion utilizing sum of absolute differences (SAD) with variable block size is the main source for such complexity and huge power consumption. In this work, we introduce a modified matching criterion in bit-level that lowers the computational complexity and hardware implementation when compared with the many SAD implementations introduced in the literature. We show that the number of hardware resources illustrated by the number of logic gates that are used in our design is much less than the number of the gates that are used in the traditional SAD and others in the literature. This leads in turn to a reduction in hardware complexity and consumed power. These are achieved by making our design rely on reusing the partial SAD values of smaller sub-blocks and then providing them to the compare and select unit as early as they are ready. Moreover, the final 41 motion vectors of motion estimation overlap in time and hence lower the number of output buses of the hardware implementation which results in a reduction in complexity as well. The video quality is only reduced by 0.17 dB while the bit-rate is increased only by 0.58 % in our simplified hardware architecture. The system logic synthesis is performed using the widely used FPGA platform. It produces 6.2 k LUT with a maximum operating frequency of 293 MHz (180 fps@CIF).
C1 [AlQaralleh, Esam A.; Abu-Sharkh, OsamaM. F.] Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
C3 Princess Sumaya University for Technology
RP AlQaralleh, EA (corresponding author), Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
EM qaralleh@psut.edu.jo; osama@psut.edu.jo
OI Qaralleh, Esam/0000-0001-7245-7964
CR Al-Najdawi N, 2014, INFORM SCIENCES, V268, P425, DOI 10.1016/j.ins.2013.08.009
   [Anonymous], IET 8 INT C ADV POW
   [Anonymous], 2014, ITU T RECOM IN PRESS
   Asano S., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P399, DOI 10.1109/FPT.2010.5681445
   Baek Y, 1996, IEEE T CONSUM ELECTR, V42, P885, DOI 10.1109/30.555764
   Bahari A, 2007, IEEE INT SOC CONF, P59, DOI 10.1109/SOCC.2007.4545426
   Bahari A, 2009, IEEE T CIRC SYST VID, V19, P1251, DOI 10.1109/TCSVT.2009.2022779
   Bergmann HC, 1982, INT C EL IM PROC
   Çelebi A, 2010, IEEE T CONSUM ELECTR, V56, P1625, DOI 10.1109/TCE.2010.5606306
   Çelebi A, 2009, IEEE SIGNAL PROC LET, V16, P513, DOI 10.1109/LSP.2009.2017222
   Chatterjee SK, 2011, IEEE T CONSUM ELECTR, V57, P1782, DOI 10.1109/TCE.2011.6131154
   Chen CY, 2006, IEEE T CIRCUITS-I, V53, P578, DOI 10.1109/TCSI.2005.858488
   Ertürk S, 2007, IEEE SIGNAL PROC LET, V14, P109, DOI 10.1109/LSP.2006.882088
   Ertürk A, 2005, IEEE T CIRC SYST VID, V15, P938, DOI 10.1109/TCSVT.2005.848340
   Gu M, 2011, J COMPUT INF SYST, V7, P1310
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jian Feng, 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P496, DOI 10.1109/ICIP.1995.537680
   Kalaycioglu C, 2009, I C FIELD PROG LOGIC, P180, DOI 10.1109/FPL.2009.5272508
   Le TM, 2000, J ELECTRON IMAGING, V9, P110, DOI 10.1117/1.482732
   Lee JH, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P957, DOI 10.1109/ICIP.2001.958654
   Lee S, 1998, IEEE T CIRC SYST VID, V8, P734, DOI 10.1109/76.728416
   Li BMH, 2008, J SIGNAL PROCESS SYS, V51, P77, DOI 10.1007/s11265-007-0143-9
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Luo JH, 2002, IEEE T CIRC SYST VID, V12, P700, DOI 10.1109/TCSVT.2002.800859
   Muralidhar P, 2014, EFFICIENT ARCHITECTU
   Natarajan B, 1997, IEEE T CIRC SYST VID, V7, P702, DOI 10.1109/76.611181
   Olivares J, 2006, MICROPROCESS MICROSY, V30, P250, DOI 10.1016/j.micpro.2005.12.006
   Patras I, 2007, IEEE T CIRC SYST VID, V17, P988, DOI 10.1109/TCSVT.2007.903121
   Porto M., 2011, S INT CIRC SYST DES, p119 
   Richmond RS, 2001, ISLPED'01: PROCEEDINGS OF THE 2001 INTERNATIONAL SYMPOSIUM ON LOWPOWER ELECTRONICS AND DESIGN, P60, DOI 10.1109/LPE.2001.945373
   Rong Y, 2013, SIGN INF PROC ASS AN, P1
   Sampaio F, 2013, DES AUT TEST EUROPE, P665
   Song CM, 2013, SIGNAL PROCESS-IMAGE, V28, P1435, DOI 10.1016/j.image.2013.09.007
   Song XD, 2000, IEEE T CIRC SYST VID, V10, P1015, DOI 10.1109/76.875506
   Tran TH, 2009, LECT NOTES COMPUT SC, V5754, P396, DOI 10.1007/978-3-642-04070-2_45
   Vanne J, 2006, IEEE T CIRC SYST VID, V16, P876, DOI 10.1109/TCSVT.2006.877150
   Vanne J, 2009, IEEE T CIRC SYST VID, V19, P466, DOI 10.1109/TCSVT.2009.2014012
   Yeo HG, 1996, VLSI SIGNAL PROCESSING, IX, P448, DOI 10.1109/VLSISP.1996.558378
   Zhu C, 2001, INT CONF ACOUST SPEE, P1593, DOI 10.1109/ICASSP.2001.941239
NR 40
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16809
EP 16834
DI 10.1007/s11042-015-2948-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600005
DA 2024-07-18
ER

PT J
AU Ayoup, AM
   Hussein, AH
   Attia, MAA
AF Ayoup, Ahmed M.
   Hussein, Amr H.
   Attia, Mahmoud A. A.
TI Efficient selective image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pseudo random number (PRN); Advanced encryption standard (AES); Arnold
   transformation; Linear feedback shift register LFSR)
AB Selective image encryption has a significant importance in many applications as it offers significant savings in computations, cost, and time. Many attempts are exerted for this purpose as the traditional full image encryption/decryption algorithms may be too massive. In this paper, a new technique for selective image encryption is developed. The algorithm is based on a combination between the pseudo random number sequences, Arnold permutation, and the advanced encryption standard technique. The proposed technique is intended to reduce the execution time of the encryption process and increase the robustness of the encrypted image.
C1 [Ayoup, Ahmed M.; Hussein, Amr H.; Attia, Mahmoud A. A.] Tanta Univ, Fac Engn, Elect & Elect Commun Engn Dept, 26 Mustafa Hashim, Tanta, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University
RP Ayoup, AM (corresponding author), Tanta Univ, Fac Engn, Elect & Elect Commun Engn Dept, 26 Mustafa Hashim, Tanta, Egypt.
EM ayoup.2012@hotmail.com; mahmoudahmedattia@yahoo.com
RI ali, mahmoud/AAH-7129-2019; Attia, Mahmoud/JSK-2256-2023; Hussein,
   Amr/AAA-3812-2019
OI Attia, Mahmoud/0009-0002-3160-6091; Hussein, Amr/0000-0002-9685-2528
CR Ahmed HEDH, 2007, INFORM-J COMPUT INFO, V31, P121
   [Anonymous], IEEE INN SMART GRID
   [Anonymous], FED INF PROC STAND P
   Attar A, 2012, P IEEE, V100, P3172, DOI 10.1109/JPROC.2012.2208211
   El-Ashry I, 2010, THESIS
   Fadlullah ZM, 2010, IEEE ACM T NETWORK, V18, P1234, DOI 10.1109/TNET.2009.2039492
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Naveenkumar SK, 2013, INT CONF RECENT, P126, DOI 10.1109/ICRTIT.2013.6844192
   Ravishankar K. C., 2006, Proceedings of the 2006 International Conference on Computing & Informatics. ICOCI 2006, DOI 10.1109/ICOCI.2006.5276550
   Riad AM, 2012, P 8 INT C INF SYST I, P36
   Schindler W., 1999, ANWENDUNGSHINWEISE I, V2, P5
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Wei LF, 2014, INFORM SCIENCES, V258, P371, DOI 10.1016/j.ins.2013.04.028
   Yang HM, 2014, COMPUT NETW, V58, P29, DOI 10.1016/j.comnet.2013.08.020
   Yuanmei Wang, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P449, DOI 10.1109/ISDEA.2010.198
NR 16
TC 23
Z9 23
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17171
EP 17186
DI 10.1007/s11042-015-2985-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600021
DA 2024-07-18
ER

PT J
AU Chen, S
   Huang, BX
AF Chen, Shu
   Huang, Benxiong
TI The location selection of ground-based promotion in city using human
   mobility data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban computing; Human traffic; Location selection problem; Ground-based
   promotion
AB With the rapid development of urbane-centered economy, today swelling cities is being filled with massive socioeconomic activities, and urban area have gone through strong but heterogeneous sprawl. Marketer has to put more resources for the ground-based promotion of their products in such metropolis. Therefore, it is very significance to help marketer choose a number of more-suited districts in urban area for promotion. This paper investigates location selection problem of ground-based promotion in city with urban computing's perspective. In a provincial capital of China, massive call logs from millions of people have been used to abstract human mobility patterns and urban area have been segmented to hundreds of districts so that we model this problem with two essential cases and give corresponding solutions via greedy algorithms. Our theoretical analysis and experimental evolution show the algorithm is effectiveness. This application framework can be used in ground-based promotion of many application scenarios such as o2o applications that fusing of multisource mobility data.
C1 [Chen, Shu; Huang, Benxiong] Huazhong Univ Sci & Technol, Sch EIC, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology
RP Chen, S (corresponding author), Huazhong Univ Sci & Technol, Sch EIC, Wuhan, Peoples R China.
EM chenshu_std@163.com
CR Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   [Anonymous], 2016, UNDERSTANDI IN PRESS
   [Anonymous], 2014, METALLOGENIC REGULAR
   Calabrese F, 2011, IEEE T INTELL TRANSP, V12, P141, DOI 10.1109/TITS.2010.2074196
   Caughlin TT, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056057
   Chaffey D., 2000, The Marketing Review, V1, P35
   Deville P, 2014, P NATL ACAD SCI USA, V111, P15888, DOI 10.1073/pnas.1408439111
   Ge Y., 2010, P 16 ACM SIGKDD INT, P899, DOI [DOI 10.1145/1835804.1835918, 10.1145/1835804.1835918]
   González MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang S., 2012, P ACM SIGKDD INT WOR, P95
   Jiang S, 2012, DATA MIN KNOWL DISC, V25, P478, DOI 10.1007/s10618-012-0264-z
   Li X, 2016, ASSESSMENT URBAN FAB
   Li XM, 2016, ADV ENG SOFTW, V93, P1, DOI 10.1016/j.advengsoft.2015.11.003
   Li X, 2015, SHOCK VIB, V2015, DOI 10.1155/2015/431476
   Lv Z., 2012, Advanced Science Letters, V7, P215
   Lv Z., 2016, MANAGING BIG CITY IN
   Ma H, 2008, P 17 ACM C INF KNOWL, P233, DOI DOI 10.1145/1458082.1458115
   MAHAJAN V, 1990, J MARKETING, V54, P1, DOI 10.2307/1252170
   Ratti C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014248
   Richardson M., 2002, P 8 ACM SIGKDD INT C, P61, DOI DOI 10.1145/775047.775057
   Roth C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0015923
   Song X., 2007, P 16 INT C WORLD WID, P191, DOI DOI 10.1145/1242572.1242599
   Song Xiaodan., 2006, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, P509, DOI [10.1145/1148170.1148258, DOI 10.1145/1148170.1148258>(2006)]
   Wang WX, 2015, LECT NOTES COMPUT SC, V9490, P638, DOI 10.1007/978-3-319-26535-3_73
   Wang YP, 2015, ADV INTEL SYS RES, V117, P1275
   Yuan J., 2012, P 18 ACM SIGKDD INT, P186
   Yuan Jing., 2011, 17 ACM SIGKDD INT C, DOI DOI 10.1109/ICDM.2016.0061
   Yuan NJ, 2015, IEEE T KNOWL DATA EN, V27, P712, DOI 10.1109/TKDE.2014.2345405
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
   Zhao SR, 2014, PHYS STATUS SOLIDI C, V11, P412, DOI 10.1002/pssc.201300556
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
   Zhong C., 2013, COMP 2013 ACM SIGSPA, P28, DOI [10.1145/2534848.2534855, DOI 10.1145/2534848.2534855]
   Zhu WY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1573, DOI 10.1145/2783258.2783331
NR 35
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17745
EP 17760
DI 10.1007/s11042-016-3488-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600046
DA 2024-07-18
ER

PT J
AU Jun, W
   Lee, Y
   Jun, BM
AF Jun, Woogyoung
   Lee, Yillbyung
   Jun, Byoung-Min
TI Duplicate video detection for large-scale multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video detection; Duplicate video; Block histogram; Dynamic matching;
   Copy video detection; Duplicate video detection; Pattern recognition
ID COPY DETECTION; INTEREST POINTS; RETRIEVAL; SEARCH
AB Since rapid growth of IT technologies, the use of multimedia data such as image and videos are explosively increasing. It is an important aspect of not only for users but also researchers. Duplicate images and videos are rapidly increasing and it causes difficulties in retrieval and management as well. It also causes copyright problems. In this paper, we discus prior duplicate video detection techniques and overcome previous research problems using block histogram and dynamic matching approach duplicate video detection method. We improved excessive abstract of previous block mean-value based feature extraction method to be robust in various video transformations. Also, we created feature vector of timely histogram by unit of blocks to reflect video features. We proposed dynamic matching algorithm to match videos which is suitable for large-scale video data. To evaluate our proposal, we used VIREO video datasets which is provided by Hong Kong City University and Carnegie Mellon University and MUSCLE-VCD-2007 dataset which is provided by INRIA. Our method showed 90 % of accuracy on duplicate video detection. Our proposed method showed robustness especially in various video transformations. Also, we tested video clustering test to prove our method and dynamic matching method showed 5 times fast compare to existing method which is suitable for real-time and large-scale video detection process.
C1 [Jun, Woogyoung; Lee, Yillbyung] Yonsei Univ, Dept Comp Sci, 50 Sungsan Rd, Seoul, South Korea.
   [Jun, Byoung-Min] Chungbuk Natl Univ, Dept Comp Engn, 52 Naesudong Rd, Heungduk, Cheongju, South Korea.
C3 Yonsei University; Chungbuk National University
RP Jun, BM (corresponding author), Chungbuk Natl Univ, Dept Comp Engn, 52 Naesudong Rd, Heungduk, Cheongju, South Korea.
EM woogyoung@yonsei.ac.kr; yillbyunglee@yonsei.ac.kr; bmjun@cbnu.ac.kr
CR [Anonymous], 2009, ACM INT C IM VID RET
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Dawei Liu, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P481, DOI 10.1007/978-3-319-14442-9_53
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Fassold H, 2015, PROC SPIE, V9400, DOI 10.1117/12.2083201
   Forecast, 2011, CISC VIS NETW IND FO
   Huang Z, 2010, IEEE T MULTIMEDIA, V12, P386, DOI 10.1109/TMM.2010.2050737
   Husain F, 2015, IEEE T CYBERNETICS, V45, P266, DOI 10.1109/TCYB.2014.2324815
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Kim J, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P1667
   Kim YT, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P68
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Law-To J., 2006, P ACM INT C MULTIMED, P835
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Leon G, 2009, IEEE INT CON MULTI, P1030, DOI 10.1109/ICME.2009.5202673
   Liu A, 2009, AT T RES TRECVID 200
   Maani E, 2008, IEEE IMAGE PROC, P1716, DOI 10.1109/ICIP.2008.4712105
   Mauceri C, 2015, INT J HUM-COMPUT ST, V77, P10, DOI 10.1016/j.ijhcs.2014.12.009
   Ngo CW, 2002, IEEE T MULTIMEDIA, V4, P446, DOI 10.1109/TMM.2002.802022
   Hai NCT, 2012, J INF PROCESS SYST, V8, P389, DOI 10.3745/JIPS.2012.8.3.389
   Pan R., 2012, J CONVERGENCE, V3, P13
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Valêncio CR, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-4
   Wu A. G., 2007, P ACM MM, P218
   Wu X, 2010, VIREO NEAR DUPLICATE
   Wu ZP, 2009, IEEE INT CON MULTI, P554, DOI 10.1109/ICME.2009.5202556
   Yeh M-C, 2009, P 17 ACM INT C MULT, P635
   Yuan J., 2004, PROC ACM MULTIMEDIA, P61, DOI DOI 10.1145/1026711.1026722
   Zhou XM, 2009, IEEE T MULTIMEDIA, V11, P879, DOI 10.1109/TMM.2009.2021794
NR 31
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15665
EP 15678
DI 10.1007/s11042-015-2724-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700034
DA 2024-07-18
ER

PT J
AU Kang, XG
   Liu, JX
   Liu, HM
   Wang, ZJ
AF Kang, Xiangui
   Liu, Jingxian
   Liu, Hongmei
   Wang, Z. Jane
TI Forensics and counter anti-forensics of video inter-frame forgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Inter-frame forgery; Counter anti-forensics; Mixed
   strategy Nash equilibrium
ID SOURCE IDENTIFICATION; COMPRESSION; MOTION
AB Among different types of video manipulations, video inter-frame forgery is a powerful and common tampering operation. Several forensic and anti-forensic techniques have been proposed to deal with this challenge. In this paper, we first improve an existing video frame deletion detection algorithm. The improvement is attributed to the combination of two properties resulted from video frame deletion, the periodicity and the magnitude of the fingerprint in the P-frame prediction error. We then analyze a typical anti-forensic method of video frame deletion, and prove that the fingerprint of frame deletion still can be discovered after being anti-forensically modified. We thus further propose a counter anti-forensics approach by estimating the true prediction error and comparing it with the prediction error stored in videos. We show that the detection algorithm is not only useful in detecting video frame deletion, but also useful for detecting video frame insertion. Compared with the existing counter anti-forensics, our proposed approach is robust when different motion estimation algorithms are used in the initial compression. Furthermore, the forensics and counter anti-forensics are combined to perform a two-phase test to detect video inter-frame forgery. A Video Inter-frame Forgery (VIF) game, which is zero-sum, simultaneous-move, is defined to analyze the interplay between the forger and the investigator. Mixed strategy Nash equilibrium is introduced to solve the VIF game and we can obtain the optimal strategies for both players. Experimental results show that the proposed forensic and counter anti-forensic methods not only outperform existing methods in detecting frame deletion and anti-forensics, but also outperform them in the VIF game.
C1 [Kang, Xiangui] Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Nanjing 210044, JS, Peoples R China.
   [Kang, Xiangui; Liu, Jingxian; Liu, Hongmei] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Informat Sci & Technol, Guangzhou 510006, GD, Peoples R China.
   [Wang, Z. Jane] Univ British Columbia, Elect & Comp Engn Dept, Vancouver, BC, Canada.
C3 Nanjing University of Information Science & Technology; Sun Yat Sen
   University; University of British Columbia
RP Kang, XG (corresponding author), Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Nanjing 210044, JS, Peoples R China.; Kang, XG (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Informat Sci & Technol, Guangzhou 510006, GD, Peoples R China.
EM isskxg@mail.sysu.edu.cn; liujx3@mail2.sysu.edu.cn;
   isslhm@mail.sysu.edu.cn; zjanew@ece.ubc.edu
RI Kang, Xiangui/AAO-5527-2020; Wang, Qian/GRF-2696-2022
FU NSFC [61379155, U1405254, 61232016]; 973 Program [2011CB302204];
   Research Fund for the Doctoral Program of Higher Education of China
   [20110171110042]; NSF of Guangdong province [S2013020012788]
FX This work was supported by the NSFC (Grant nos. 61379155, U1405254 and
   61232016), the 973 Program (Grant no. 2011CB302204), the Research Fund
   for the Doctoral Program of Higher Education of China (Grant no.
   20110171110042) and the NSF of Guangdong province (Grant no.
   S2013020012788).
CR [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Barni M, 2012, INT CONF ACOUST SPEE, P1745, DOI 10.1109/ICASSP.2012.6288236
   Bestagini P, 2012, INT CONF ACOUST SPEE, P2257, DOI 10.1109/ICASSP.2012.6288363
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7
   Hespanha JoaoP., 2011, INTRO COURSE NONCOOP
   ISO, 2009, 144962 ISO ISOIEC
   ISO, 2008, 138182 ISO ISOIEC
   ISO, 2010, 1449610 ISO ISOIEC
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Liu H, 2013, P ISPEC, P262
   Liu LS, 2010, BOUND VALUE PROBL, DOI 10.1155/2010/236560
   Luo W, 2008, P SOC PHOTO-OPT INS, P1
   Milani S, 2012, IEEE INT WORKSH MULT, P112, DOI 10.1109/MMSP.2012.6343425
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Osborne Martin J, 1994, COURSE GAME THEORY
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Stamm MC, 2012, INT CONF ACOUST SPEE, P1749, DOI 10.1109/ICASSP.2012.6288237
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Stamm MC, 2011, INT CONF ACOUST SPEE, P1876
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Xu JY, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413540013
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zeng H, 2013, P INT WORKSH DIG DOR
   Zeng H, 2013, IEEE IMAGE PROC, P4472, DOI 10.1109/ICIP.2013.6738921
NR 27
TC 23
Z9 24
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13833
EP 13853
DI 10.1007/s11042-015-2762-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800044
DA 2024-07-18
ER

PT J
AU Kim, D
   Kwon, H
   Hahn, C
   Hur, J
AF Kim, Daeyeong
   Kwon, Hyunsoo
   Hahn, Changhee
   Hur, Junbeom
TI Privacy-preserving public auditing for educational multimedia data in
   cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy preserving auditing; Fully dynamic auditing; Cloud computing;
   Homomorphic hash; Educational multimedia
AB Nowadays, as distance learning is being widly used, multimedia data becomes an effective way for delivering educational contents in online educational systems. To handle the educational multimedia data efficiently, many distance learning systems adopt a cloud storage service. Cloud computing and storage services provide a secure and reliable access to the outsourced educational multimedia contents for users. However, it brings challenging security issues in terms of data confidentiality and integrity. The straightforward way for the integrity check is to make the user download the entire data for verifying them. But, it is inefficient due to the large size of educational multimedia data in the cloud. Recently many integrity auditing protocols have been proposed, but most of them do not consider the data privacy for the cloud service provider. Additionally, the previous schemes suffer from dynamic management of outsourced data. In this paper, we propose a public auditing protocol for educational multimedia data outsourced in the cloud storage. By using random values and a homomorphic hash function, our proposed protocol ensures data privacy for the cloud and the third party auditor (TPA). Also, it is secure against lose attack and temper attack. Moreover, our protocol is able to support fully dynamic auditing. Security and performance analysis results show that the proposed scheme is secure while guaranteeing minimum extra computation costs.
C1 [Kim, Daeyeong; Kwon, Hyunsoo; Hahn, Changhee] Chung Ang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Hur, Junbeom] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University; Korea University
RP Hur, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM rlaeod@cau.ac.kr; khs910504@cau.ac.kr; Mckinsey@cau.ac.kr;
   jbhur@korea.ac.kr
RI 권, 현수/HPG-4730-2023; Hahn, Changhee/HTR-0677-2023
OI Hahn, Changhee/0000-0003-4334-0411
FU National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [2013R1A2A2A01005559]; Chung-Ang University
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP) (No.
   2013R1A2A2A01005559). This research was supported by the Chung-Ang
   University Research Scholarship Grants in 2014.
CR [Anonymous], P IEEE S SEC PRIV
   [Anonymous], 2001, Advances in Cryptology-ASIACRYPT 2001 (Lecture Notes in Computer Science, DOI [DOI 10.1007/3-540-45682-1_30, DOI 10.1007/3-540-45682-130]
   Ateniese G., 2008, P 4 INT C SEC PRIV C, P1, DOI 10.1145/1460877.1460889
   Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Bao F, 2003, LECT NOTES COMPUT SC, V2836, P301
   Erway CC, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P213
   Gennaro R, 2010, LECT NOTES COMPUT SC, V6056, P142
   Hongwei Liu, 2013, Journal of Networks, V8, P373, DOI 10.4304/jnw.8.2.373-380
   Juels A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P584
   Li J, 2010, P 2010 IEEE INT S AP, P3, DOI [DOI 10.1109/ICIECS.2010.5678245, 10.1109/ISAF.2010.5712271, DOI 10.1109/ISAF.2010.5712271, 10.1145/1852786.1852804, DOI 10.1145/1852786.1852804]
   Masud Md Anwar Hossain, 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P37, DOI 10.1109/ICIS.2012.10
   Nan XF, 2010, IEEE INT C BIOINFORM, P520, DOI 10.1109/BIBM.2010.5706621
   Ramaiah YG, 2013, IEEE INT CONF TRUST, P1559, DOI 10.1109/TrustCom.2013.191
   Shacham H, 2008, LECT NOTES COMPUT SC, V5350, P90, DOI 10.1007/978-3-540-89255-7_7
   Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183
   Yang K, 2013, IEEE T PARALL DISTR, V24, P1717, DOI 10.1109/TPDS.2012.278
   Yu HQ, 2012, IEEE T LEARN TECHNOL, V5, P130, DOI 10.1109/TLT.2012.1
   Zeng K, 2008, LECT NOTES COMPUT SC, V5308, P419, DOI 10.1007/978-3-540-88625-9_28
   Zhu Y., 2011, Proceedings of the 2011 ACM Symposium on Applied Computing, P1550, DOI DOI 10.1145/1982185.1982514
   Zhu Y, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P756, DOI 10.1145/1866307.1866421
NR 20
TC 9
Z9 10
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13077
EP 13091
DI 10.1007/s11042-015-2594-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800006
DA 2024-07-18
ER

PT J
AU Park, H
   Kim, EJ
AF Park, Hyunhee
   Kim, Eui-Jik
TI Location-oriented multiplexing transmission for capillary
   machine-to-machine systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capillary machine-to-machine; mmWave WPAN; Multiplexing transmission;
   Sum-rate maximization
ID WIRELESS NETWORKS; ANTENNAS; DELIVERY; SCHEME; WPANS
AB This paper presents a location-oriented multiplexing transmission (LOT) strategy for use with a capillary machine-to-machine (M2M) system based on a millimeter wave (mmWave) wireless personal area network (WPAN). Omni-directional or directional antennas are used depending on the multicast groups and the data rate that is achievable in order to maximize the normalized throughput. Specifically, the devices that are closer to the access point (AP) are served with a high-rate omni-directional antenna. In contrast, devices that are distant to the AP are treated with a high-rate directional-antenna. We exploit the optimal transmission strategy with sum rate maximization to show that the normalized throughput can be maximized. The IEEE 802.15.3c WPAN standard is used to demonstrate that the LOT strategy improves the normalized throughput by 39-62 % relative to other multicast schemes.
C1 [Park, Hyunhee] LG Elect, Adv Stand R&D Lab, Seoul, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
C3 LG Electronics; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
RI Park, Hyunhee/F-5289-2017
OI Park, Hyunhee/0000-0003-3810-7367
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2014R1A1A2057641]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2014R1A1A2057641).
CR [Anonymous], 2009, IEEE 802 15 WPAN MIL
   Cai LX, 2010, IEEE T WIREL COMMUN, V9, P113, DOI 10.1109/TWC.2010.01.070503
   Chen M, 2013, MULTIMED TOOLS APPL, V67, P167, DOI 10.1007/s11042-012-1013-4
   Esnaashari M, 2008, SENSOR LETT, V6, P723, DOI 10.1166/sl.2008.m146
   Kim T, 2015, MULTIMED TOOLS APPL, V74, P1697, DOI 10.1007/s11042-014-2215-8
   Kwon JH, 2015, MULTIMED TOOLS APPL, V74, P1593, DOI 10.1007/s11042-013-1752-x
   Park H, 2016, J SUPERCOMPUT, V72, P3387, DOI 10.1007/s11227-015-1450-8
   Park H, 2015, MULTIMED TOOLS APPL, V74, P1627, DOI 10.1007/s11042-014-1959-5
   Park H, 2013, IEEE COMMUN LETT, V17, P616, DOI 10.1109/LCOMM.2013.011513.122519
   Paul A, 2014, MULTIMED TOOLS APPL, V71, P235, DOI 10.1007/s11042-013-1490-0
   Sen S, 2008, I C NETWORK PROTOCOL, P53, DOI 10.1109/ICNP.2008.4697024
   Sundaresan K, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P205
   Tan CW, 2009, IEEE INFOCOM SER, P1350, DOI 10.1109/INFCOM.2009.5062050
   Zhang HH, 2011, IEEE INFOCOM SER, P1107, DOI 10.1109/INFCOM.2011.5934886
NR 14
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14707
EP 14719
DI 10.1007/s11042-015-2833-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500041
DA 2024-07-18
ER

PT J
AU Jiang, F
   Rho, S
   Chen, BW
   Li, K
   Zhao, DB
AF Jiang, Feng
   Rho, Seungmin
   Chen, Bo-Wei
   Li, Kun
   Zhao, Debin
TI Big data driven decision making and multi-prior models collaboration for
   media restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prior models; Image restoration; Big data; Data driven
ID SPARSE; RECOVERY; ALGORITHMS
AB Aiming at the restoration of degraded social network services media, this paper proposed a novel multi-prior models collaboration framework for image restoration with big data. Different from the traditional non-reference media restoration strategies, a big reference image set is adopted to provide the references and predictions of different popular prior models and accordingly guide the further prior collaboration. With these cues, the collaboration of multi-prior models is mathematically formulated as a ridge regression problem in this paper. Due to the computation complexity of dealing big reference data, scatter-matrix-based KRR is proposed which can achieve high accuracy and low complexity in big data related decision making task. Specifically, an iterative pursuit is proposed to obtain further refined and robust estimation. Five popular prior methods are applied to evaluate the effectiveness of the proposed multi-prior models collaboration. Compared with the traditional restoration strategies, the proposed framework improves the restoration performance significantly and provides a reasonable method for the relative exploration of big data driven decision making.
C1 [Jiang, Feng; Li, Kun; Zhao, Debin] Harbin Inst Technol, Sch Comp Sci, Harbin 150001, Peoples R China.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
   [Chen, Bo-Wei] Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
C3 Harbin Institute of Technology; Sungkyul University; National Cheng Kung
   University
RP Jiang, F (corresponding author), Harbin Inst Technol, Sch Comp Sci, Harbin 150001, Peoples R China.
EM fiang@hit.edu.cn; korea.smrho@gmail.com; dennisbwc@gmail.com;
   kli@hit.edu.cn; dbzhao@hit.edu.cn
RI Zhao, Debin/JEP-0204-2023; Chen, Bowei/AAB-7002-2021; JIANG,
   Feng/HTP-2862-2023; Rho, Seungmin/HTP-6683-2023
OI Chen, Bowei/0000-0002-4045-3253; 
FU National Science Council of the Republic of China [103-2917-I-564-058];
   National Research Foundation of Korea (NRF) - Ministry of Education
   [2013R1A1A2061978]; National Natural Science Foundation of China
   [61272386, 61100096]
FX We would like to thank the authors of [2, 3, 11, 33] and [32] for kindly
   providing their codes. This work was supported in part by the National
   Science Council of the Republic of China under Grant No.
   103-2917-I-564-058, the Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2013R1A1A2061978), the National Natural Science Foundation of
   China under Grant No. 61272386 and 61100096.
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, 22 CMLA
   [Anonymous], ARXIV11060257
   [Anonymous], 1950, INVERTING MODIFIED M
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chan RH, 2010, IEEE T IMAGE PROCESS, V19, P1731, DOI 10.1109/TIP.2010.2045148
   Chen C., 2012, P INT C ADV NEUR INF, V25, P1115
   Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288
   Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Efros A.A., 1999, Proc. Int. Conf. Computer Vision, V2, P1022
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Gilboa G, 2007, 23 CMLA
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   James W., 1961, P 4 BERKELEY S MATH, VI, P361
   Jegou H., 2008, INRIA HOLIDAYS DATAS
   Jung MY, 2011, IEEE T IMAGE PROCESS, V20, P1583, DOI 10.1109/TIP.2010.2092433
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mavridis N., 2010, FRIENDS FACES SOCIAL
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Roth S, 2005, PROC CVPR IEEE, P860
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zhang J, 2013, IEEE INT SYMP CIRC S, P2836
   Zhang J, 2011, INT J REMOTE SENS, V32, P7557, DOI 10.1080/01431161.2010.524677
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 39
TC 4
Z9 4
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12967
EP 12982
DI 10.1007/s11042-014-2240-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700039
DA 2024-07-18
ER

PT J
AU Ju, ZJ
   Gao, DX
   Cao, JT
   Liu, HH
AF Ju, Zhaojie
   Gao, Dongxu
   Cao, Jiangtao
   Liu, Honghai
TI A novel approach to extract hand gesture feature in depth images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gestures; Feature extraction; Kinect sensor; EMD
AB This paper proposes a novel approach to extract human hand gesture features in real-time from RGB-D images based on the earth mover's distance and Lasso algorithms. Firstly, hand gestures with hand edge contour are segmented using a contour length information based de-noise method. A modified finger earth mover's distance algorithm is then applied applied to locate the palm image and extract fingertip features. Lastly and more importantly, a Lasso algorithm is proposed to effectively and efficiently extract the fingertip feature from a hand contour curve. Experimental results are discussed to demonstrate the effectiveness of the proposed approach.
C1 [Ju, Zhaojie; Gao, Dongxu] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
   [Ju, Zhaojie] Univ Portsmouth, Intelligent Syst & Biomed Robot Grp, Portsmouth, Hants, England.
   [Ju, Zhaojie] State Key Lab Mech Syst & Vibrat, Shanghai, Peoples R China.
   [Cao, Jiangtao] Liaoning Shihua Univ, Sch Informat & Control Engn, Fushun, Peoples R China.
   [Liu, Honghai] Univ Portsmouth, Intelligent Syst, Portsmouth, Hants, England.
C3 University of Portsmouth; University of Portsmouth; Liaoning
   Petrochemical University; University of Portsmouth
RP Liu, HH (corresponding author), Univ Portsmouth, Intelligent Syst, Portsmouth, Hants, England.
EM zhaojie.ju@port.ac.uk; dongxu.gao@port.ac.uk; cigroup@123.com;
   Honghai.liu@port.ac.uk
RI , DONGXU/AAO-5942-2020; Ju, Zhaojie/AAA-5872-2019
OI , DONGXU/0000-0001-7008-0737; Ju, Zhaojie/0000-0002-9524-7609; Liu,
   Honghai/0000-0002-2880-4698
FU DREAM project of EU [FP7-ICT 611391]; Research Project of State Key
   Laboratory of Mechanical System and Vibration China [MSV201508]; EPSRC
   [EP/G041377/1] Funding Source: UKRI
FX The authors would like to acknowledge support from DREAM project of EU
   FP7-ICT 611391 and Research Project of State Key Laboratory of
   Mechanical System and Vibration China MSV201508.
CR Alexiadis Dimitrios S., 2011, P 19 ACM INT C MULT
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farid H., 1997, Computer Analysis of Images and Patterns. 7th International Conference, CAIP '97. Proceedings, P207, DOI 10.1007/3-540-63460-6_119
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Ju Z., 2013, P INT C MACH LEARN C, P1
   Ju ZJ, 2012, PATTERN RECOGN, V45, P1146, DOI 10.1016/j.patcog.2011.08.028
   Ju ZJ, 2011, IEEE T FUZZY SYST, V19, P901, DOI 10.1109/TFUZZ.2011.2150756
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Li C, 2014, IEEE INT FUZZY SYST, P1469, DOI 10.1109/FUZZ-IEEE.2014.6891887
   Liang H., 2012, P 20 ACM INT C MULT
   Matyunin S, 2011, 3DTV CONF
   Reddivari H., 2014, Multisensor Fusion and Information Integration for Intelligent Systems (MFI), 2014 International Conference on, P1, DOI DOI 10.1109/MFI.2014.6997722
   Tang M., 2011, Recognizing hand gestures with microsofts kinect
   Tara R., 2012, INT J SCI ENG RES, V3, P1
   Wang BC, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3903, DOI 10.1109/WCICA.2012.6359124
   Zhou R, 2011, COMP VIS ICCV 2011 I
   Zhou R, 2013, IEEE T MULTIMEDIA, V15
   Zhou R, 2011, P 19 ACM INT C MULT
   Zhu H.-M., 2011, P 10 INT C VIRT REAL, P273
NR 21
TC 10
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11929
EP 11943
DI 10.1007/s11042-015-2609-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200019
DA 2024-07-18
ER

PT J
AU Yun, NY
   Lee, SW
AF Yun, Nam-Yi
   Lee, Seok-Won
TI Analysis of effectiveness of tsunami evacuation principles in the 2011
   Great East Japan tsunami by using text mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The 2011 Great East Japan earthquake and tsunami; Disaster mitigation;
   Evacuation principle; Human impact; Text Mining; Naive Bayes classifier
ID NAIVE BAYES; NETWORKS
AB Evacuation of the 2011 Great East Japan Earthquake and Tsunami was a large-scale evacuation of over thousands of people escaping from the earthquake-induced tsunami. The survivors' evacuation experiences provided valuable insights into the factors that helped with survival and some very important practical issues regarding tsunami evacuation. Therefore, this article analyzes an effectiveness of tsunami evacuation principles from descriptive comments from the survivors and the non-survivors in the 2011 disaster using text mining method. As a result using the Na < ve Bayesian classifier, it identifies some of the evacuation behaviors differences taken by the survivors or by the non-survivors under the disaster as an effectiveness of the evacuation principles, and attempts to understand how to provide more practical instructions. Therefore, these results give effective recommendations for evacuation preparation against catastrophic earthquake and tsunami disasters in the future.
C1 [Yun, Nam-Yi] Waseda Univ, Grad Sch Creat Sci & Engn, Dept Civil & Environm Engn, Tokyo, Japan.
   [Lee, Seok-Won] Ajou Univ, Div Informat & Comp Engn, Dept Software Convergence Technol, Suwon, South Korea.
C3 Waseda University; Ajou University
RP Lee, SW (corresponding author), Ajou Univ, Div Informat & Comp Engn, Dept Software Convergence Technol, Suwon, South Korea.
EM namyiyun@aoni.waseda.jp; leesw@ajou.ac.kr
RI Yun, Nam-Yi/ISU-7803-2023
OI Yun, Nam-Yi/0009-0008-4887-5814
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [2013R1A1A2009801]
FX We thank Weathernews for making necessary data available. This study
   could have been completed because Mr. Norio Doi in Development Division
   of Systems Engineering Consultants Co., LTD. who assisted us. We express
   our heartfelt gratitude towards Doctor Masanori Hamada for his kind help
   and inspiring discussions during the data analysis. Dr. Lee's research
   was supported by Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Education
   (2013R1A1A2009801).
CR Chulani S, 1999, IEEE T SOFTWARE ENG, V25, P573, DOI 10.1109/32.799958
   Cova TJ, 2003, TRANSPORT RES A-POL, V37, P579, DOI 10.1016/S0965-8564(03)00007-7
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gerard E, 2000, P JOINT SIGDAT C EMP
   Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283
   Hamada M, 2011, 4 JAP GREEC WORKSH S
   Higuchi K, 2013, KH CODER 2 X REFEREN
   Janjanam D, 2012, NAT HAZARDS REV, V13, P247, DOI 10.1061/(ASCE)NH.1527-6996.0000076
   Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457, DOI 10.1109/TKDE.2006.180
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Metsis V., 2006, CEAS 2006 - Third Conference on Email and Anti-Spam, P27
   Mooney R.J., 1996, COMP EXPT DISAMBIGUA, P82
   Ozaki T, 2012, J DISASTER RES, V7, P439, DOI 10.20965/jdr.2012.p0439
   Peng FC, 2004, INFORM RETRIEVAL, V7, P317, DOI 10.1023/B:INRT.0000011209.19643.e2
   Sahami M., 1998, Learning for Text Categorization: Papers from the 1998 workshop, V62, P98
   Schneider KM, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P307
   Tanabe L, 1999, BIOTECHNIQUES, V27, P1210, DOI 10.2144/99276bc03
   Ting SL, 2011, International Journal of Software Engineering and Its Applications, P37
   Weathernews Corp, 2011, REP SURV 2011 GREAT
   Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6
   Wegscheider S, 2011, NAT HAZARD EARTH SYS, V11, P249, DOI 10.5194/nhess-11-249-2011
   Xu XJ, 2004, FEBS LETT, V578, P297, DOI 10.1016/j.febslet.2004.11.019
   Yun NY, 2012, J DISASTER RES, V7, P458, DOI 10.20965/jdr.2012.p0458
   Yun NY, 2014, EARTHQUAKE IN PRESS
   Zhang H., 2004, AA, V1, P3
NR 25
TC 7
Z9 7
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12955
EP 12966
DI 10.1007/s11042-014-2326-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700038
DA 2024-07-18
ER

PT J
AU Chen, M
   Gong, LY
   Wang, TJ
   Liu, F
   Feng, Q
AF Chen, Meng
   Gong, Liyu
   Wang, Tianjiang
   Liu, Fang
   Feng, Qi
TI Modeling spatio-temporal layout with Lie Algebrized Gaussians for action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Local spatio-temporal feature; Gaussian Mixture
   Model; Lie Algebrized Gaussians; Spatio-temporal layout
AB We propose a novel approach to model spatio-temporal distribution of local features for action recognition in videos. The proposed approach is based on the Lie Algebrized Gaussians (LAG) which is a feature aggregation approach and yields high-dimensional video signature. In the framework of LAG, local features extracted from a video are aggregated to train a video-specific Gaussian Mixture Model (GMM). Then the video-specific GMM is encoded as a vector based on Lie group theory and this step is also referred to as GMM vectorization. As the video-specific GMM gives a soft partition of the feature space, for each cell of the feature space (i.e. each Gaussian component), we use a GMM to model the spatio-temporal locations of the local features assigned to the Gaussian component. The location GMMs are encoded as vectors just like the local feature GMM. We term those vectors of location GMMs spatio-temporal LAG (STLAG). In addition, although the LAG and the popular Fisher Vector (FV) are derived from distinct theory perspectives, we find that they are closely related. Hence the power and l(2) normalization proposed for the FV are also beneficial to the LAG. Experimental results show that STLAG is very effective to model spatio-temporal layout compared with other techniques such as spatio-temporal pyramid and feature augmentation. Using the state-of-the-art dense trajectory features, our approach achieves state-of-the-art performance on two challenging datasets: Hollywood2 and HMDB51.
C1 [Chen, Meng; Wang, Tianjiang; Liu, Fang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Gong, Liyu] Eedoo Inc, Beijing 100085, Peoples R China.
C3 Huazhong University of Science & Technology
RP Feng, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM fengqi@hust.edu.cn
FU National Natural Science Foundation of China [U1233119]; Wuhan Key
   Science and Technology Project [2014010202010110]
FX This work was supported by grants from the National Natural Science
   Foundation of China (No. U1233119) and the Wuhan Key Science and
   Technology Project (No. 2014010202010110).
CR [Anonymous], 2011, P CVPR 2011 PROV RI
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2014, CVPR
   [Anonymous], IEEE C COMP VIS PATT
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen M, 2015, MULTIMED TOOLS APPL, V74, P2127, DOI 10.1007/s11042-013-1746-8
   Gong L, 2013, ARXIV13040823V1CSCV
   Hu CL, 2015, MULTIMED TOOLS APPL, V74, P4139, DOI 10.1007/s11042-013-1815-z
   Hu CL, 2014, MULTIMED TOOLS APPL, V73, P1863, DOI 10.1007/s11042-013-1676-5
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Kihl O, 2014, MACH VISION APPL, P1
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Marszalek M., 2009, IEEE C COMP VIS PATT
   McCann S, 2012, P AS C COMP VIS
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Perronnin F, 2008, IEEE T PATTERN ANAL
   Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sanchez J., 2013, International Journal on Computer Vision
   Sánchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang X., 2012, ACCV, P572
   Wu J, 2014, IEEE C COMP VIS PATT
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang XD, 2014, LECT NOTES COMPUT SC, V8690, P727, DOI 10.1007/978-3-319-10605-2_47
   Zhou X., 2008, ACM INT C MULT
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442
NR 44
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10335
EP 10355
DI 10.1007/s11042-015-3008-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800012
DA 2024-07-18
ER

PT J
AU Tan, GH
   Chen, H
   Qi, J
AF Tan, Guanghua
   Chen, Hui
   Qi, Jun
TI A novel image matting method using sparse manual clicks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural image matting; Spectral clustering; Foreground extraction
AB Traditional image matting methods often have strict requirements on user input. This paper proposes a new matting method based on spectral clustering, which generates a well matte using a sparse user input. Firstly, connected components are obtained using spectral clustering, which actually utilizes a linear transformation of the smallest eigenvectors of the matting Laplacian matrix. An accurate trimap is obtained via user input and threshold segmentation. Secondly, sample sets are gathered by two-level hierarchical clustering and Fast Approximate Nearest Neighbors algorithm and unknown pixels are evaluated by the samples. Finally, an optimal matte is obtained by constructing an energy function with local smoothness constraint. Experiments show that the proposed method outperforms most of the state-of-the-art methods with a sparse user input and our method has fewer requirements to get a robust matte.
C1 [Tan, Guanghua; Qi, Jun] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Chen, Hui] Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang 330012, Peoples R China.
C3 Hunan University; Jiangxi University of Finance & Economics
RP Chen, H (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang 330012, Peoples R China.
EM guanghuatan@gmail.com; comdoc@126.com; qijun648795307@sina.com
FU Fundamental Research Funds for the Central Universities; Science and
   Technology Planning Project of Hunan Province [2014WK3002]; National
   Science Foundation of China [61262033, 61262009]; Natural Science
   Foundation of Jiangxi Province, China [20142BAB207009]; Science
   Foundation of Jiangxi Provincial Department of Education, China
   [GJJ13303]
FX This paper is supported by "the Fundamental Research Funds for the
   Central Universities" and "the Science and Technology Planning Project
   of Hunan Province (2014WK3002)".r This work was partly supported by the
   National Science Foundation of China under grant No. 61262033,61262009;
   the Natural Science Foundation of Jiangxi Province, China under grant
   No. 20142BAB207009; the Science Foundation of Jiangxi Provincial
   Department of Education, China under grant No. GJJ13303.
CR [Anonymous], [No title captured]
   [Anonymous], IMAGE VIDEO MATTING
   Chen Q, 2012, CVPR, P2175
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x
   He B, 2013, IEEE IMAGE PROC, P4282, DOI 10.1109/ICIP.2013.6738882
   He B, 2012, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2012.6466851
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Kim BK, 2014, IEICE T FUND ELECTR, VE97A, P1814, DOI 10.1587/transfun.E97.A.1814
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Rhemann C, 2010, PROC CVPR IEEE, P2149, DOI 10.1109/CVPR.2010.5539894
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Shahrian E, 2013, P 2013 IE C COMP VIS
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Tseng CY, 2012, IEEE IMAGE PROC, P945, DOI 10.1109/ICIP.2012.6467017
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Xiang SM, 2010, IEEE T PATTERN ANAL, V32, P2039, DOI 10.1109/TPAMI.2010.35
   Zhang ZP, 2012, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2012.6467308
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
NR 27
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10213
EP 10225
DI 10.1007/s11042-015-3160-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800006
DA 2024-07-18
ER

PT J
AU Luo, YM
   Huang, DT
   Liu, PZ
   Feng, HM
AF Luo, Yan-Min
   Huang, De-Tian
   Liu, Pei-Zhong
   Feng, Hsuan-Ming
TI An novel random forests and its application to the classification of
   mangroves remote sensing image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Random forests; Integrated learning; Remote sensing
   image; Mangroves
ID FUTURE
AB The novel random forests algorithm with variables random input and random combination (Forest_RI_RC) machine was proposed to improve the weakness of low accuracy and over-fitting phenomenon in single decision tree. The proposed method produces more and more selections and combinations to increase the possibility of the best decision-making features. This way reduces the correlation coefficient of the random forests, which efficiently lead to the lower generalization error and approach the higher classification accuracy. The standard machine learning datasets were used to verify the validity of the classification. The simulation results showed that the novel algorithm with the multiple classifiers to concurrently segment the objects and achieve the smaller generalization error. Finally, the algorithm was applied to the classified problems of mangrove remote sensing image. Software simulations presents that the classification accuracy is basically stable at around 90 %. This performance is better than the other two decision tree and bagging methods.
C1 [Luo, Yan-Min] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Huang, De-Tian; Liu, Pei-Zhong] Huaqiao Univ, Coll Engn, Quanzhou 362021, Fujian, Peoples R China.
   [Feng, Hsuan-Ming] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen, Taiwan.
C3 Huaqiao University; Huaqiao University
RP Feng, HM (corresponding author), Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen, Taiwan.
EM hmfeng@nqu.edu.tw
OI Feng, Hsuan-Ming/0000-0002-6498-7006
FU Talent project of Huaqiao University [14BS215]; Quanzhou scientific and
   technological planning projects of Fujian, China [2015Z120]
FX This work was supported by the Talent project of Huaqiao University (No.
   14BS215) and Quanzhou scientific and technological planning projects of
   Fujian, China (2015Z120).
CR Alongi DM, 2002, ENVIRON CONSERV, V29, P331, DOI 10.1017/S0376892902000231
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Carreras X., 2001, P 4 INT C RECENT ADV, P58
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Ghimire B, 2010, REMOTE SENS LETT, V1, P45, DOI 10.1080/01431160903252327
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heumann BW, 2011, REMOTE SENS-BASEL, V3, P2440, DOI 10.3390/rs3112440
   Heumann BW, 2011, PROG PHYS GEOG, V35, P87, DOI 10.1177/0309133310385371
   Lee S, 2010, COMPUT MED IMAGING G, V34
   Liu K, 2008, WETLANDS, V28, P336, DOI 10.1672/06-91.1
   Luo YM, 2013, IEEE GEOSCI REMOTE S, V10, P751, DOI 10.1109/LGRS.2012.2221675
   McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   PEDDLE DR, 1991, PHOTOGRAMM ENG REM S, V57, P413
   Rogan J, 2002, REMOTE SENS ENVIRON, V80, P143, DOI 10.1016/S0034-4257(01)00296-6
   Smith A, 2010, WATER RES, V44, P4067, DOI 10.1016/j.watres.2010.05.019
   Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
NR 21
TC 15
Z9 15
U1 2
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9707
EP 9722
DI 10.1007/s11042-015-2906-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500012
DA 2024-07-18
ER

PT J
AU Su, CH
AF Su, Chung-Ho
TI The effects of students' motivation, cognitive load and learning anxiety
   in gamification software engineering education: a structural equation
   modeling study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamification; Learning motivation; Cognitive load; Academic performance;
   Learning anxiety; Software engineering education
ID MATHEMATICS ANXIETY; USER ACCEPTANCE; PERCEIVED EASE; MATH ANXIETY; GAME
   DESIGN; STRATEGIES; PLS; ENVIRONMENTS; ACHIEVEMENT; PERFORMANCE
AB Past research has proven the significant effects of game-based learning on learning motivation and academic performance, and described the key factors in game-based design. Nonetheless, research on the correlations among learning motivation, cognitive load, learning anxiety and academic performance in gamified learning environments has been minimal. This study, therefore, aims to develop a Gamification Software Engineering Education Learning System (GSEELS) and evaluate the effects of gamification, learning motivation, cognitive load and learning anxiety on academic performance. By applying Structural Equation Modeling (SEM) to the empirical research, the questionnaire contains: 1. a Gamification Learning Scale; 2. a Learning Motivation Scale; 3. a Cognitive Load Scale; 4. a Learning Anxiety Scale; and 5. an Academic Performance Scale. A total of 107 undergraduates in two classes participated in this study. The Structural Equation Modeling (SEM) analysis includes the path directions and relationship between descriptive statistics, measurement model, structural model evaluation and five variables. The research results support all nine hypotheses, and the research findings also show the effects of cognitive load on learning anxiety, with strong learning motivation resulting from a low learning anxiety. As a result, it is further proven in this study that a well-designed GSEELS would affect student learning motivation and academic performance. Finally, the relationship model between gamification learning, learning motivation, cognitive load, learning anxiety and academic performance is elucidated, and four suggestions are proffered for instructors of software engineering education courses and for further research, so as to assist instructors in the application of favorable gamification teaching strategies.
C1 [Su, Chung-Ho] Shu Te Univ, Dept Animat & Game Design, Kaohsiung, Taiwan.
C3 Shu-Te University
RP Su, CH (corresponding author), Shu Te Univ, Dept Animat & Game Design, Kaohsiung, Taiwan.
EM mic6033@stu.edu.tw
RI Hidayat, Ima Kusumawati/ABF-6870-2021
OI Hidayat, Ima Kusumawati/0000-0002-3387-9213
FU National Science Council of the Republic of China [NSC 104-2410-H-366
   -003 -, NSC 104-2622-H-366 -001 -CC3]
FX This study is supported in part by the National Science Council of the
   Republic of China under contract numbers NSC 104-2410-H-366 -003 - and
   NSC 104-2622-H-366 -001 -CC3.
CR ALAVI M, 1994, MIS QUART, V18, P159, DOI 10.2307/249763
   Ang CS, 2007, INTERACT COMPUT, V19, P167, DOI 10.1016/j.intcom.2006.08.006
   Asgari M, 2005, DIG GAM RES C DIGRA
   ASHCRAFT MH, 1994, COGNITION EMOTION, V8, P97, DOI 10.1080/02699939408408931
   Bagozzi RP, 1998, Journal of the academy of marketing science, V16, P76
   Bekdemir M, 2010, EDUC STUD MATH, V75, P311, DOI 10.1007/s10649-010-9260-7
   Belanich J., 2004, INSTRUCTIONAL CHARAC
   Black W., 1998, Multivariate data analysis: With readings
   Bollen K. A., 1993, Testing structural equation models, V154
   Bontis N., 1998, Management Decision, V36, P63, DOI [DOI 10.13189/UJAF.2021.090610, 10.1108/00251749810204142, DOI 10.1108/00251749810204142]
   Bontis N, 2009, J INTELLECT CAP, V10, P53, DOI 10.1108/14691930910922897
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Caine R.N., 1994, Making connections: Teaching and the human brain
   Chang SL, 2006, J INTERACT ONLINE LE, V5, P104
   Chang WC, 2009, IEEE INTERNET COMPUT, V13, P26, DOI 10.1109/MIC.2009.81
   Chin W.W., 2009, HDB PARTIAL LEAST SQ, P655, DOI DOI 10.1007/978-3-540-32827-8_29
   CHIN W. W., STAT STRATEGIES SMAL, P307
   Chin WW, 2008, J MARKET THEORY PRAC, V16, P287, DOI 10.2753/MTP1069-6679160402
   Chinn S, 2009, DYSLEXIA, V15, P61, DOI 10.1002/dys.381
   COOL K, 1988, STRATEGIC MANAGE J, V9, P207, DOI 10.1002/smj.4250090302
   Credé M, 2011, LEARN INDIVID DIFFER, V21, P337, DOI 10.1016/j.lindif.2011.03.002
   Csikszentmihalyi M., 1990, Finding flow: The psychology of engagement with everyday life
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DeLeeuw KE, 2008, J EDUC PSYCHOL, V100, P223, DOI 10.1037/0022-0663.100.1.223
   Deterding S., 2011, GAMIFICATION USING G
   Dickey MD, 2007, ETR&D-EDUC TECH RES, V55, P253, DOI 10.1007/s11423-006-9004-7
   Dickey MD, 2005, ETR&D-EDUC TECH RES, V53, P67, DOI 10.1007/BF02504866
   Duncan TG, 2005, EDUC PSYCHOL-US, V40, P117, DOI 10.1207/s15326985ep4002_6
   FORNELL C, 1982, J MARKETING RES, V19, P440, DOI 10.2307/3151718
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   FORNELL C, 1990, MANAGE SCI, V36, P1246, DOI 10.1287/mnsc.36.10.1246
   FREDERICKSON K, 1989, HEART LUNG, V18, P617
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Gee J.P., 2005, E-LEARNING DIGITAL M, V2, P5, DOI [10.2304/elea.2005.2.1.5, DOI 10.2304/ELEA.2005.2.1.5, https://doi.org/10.2304/elea.2005.2.1.5]
   Gerjets P, 2003, EDUC PSYCHOL-US, V38, P33, DOI 10.1207/S15326985EP3801_5
   Hair JF, 2011, J MARKET THEORY PRAC, V19, P139, DOI 10.2753/MTP1069-6679190202
   Hays R., 2005, The Effectiveness of Instructional Games: A Literature Review and Discussion
   HEMBREE R, 1990, J RES MATH EDUC, V21, P33, DOI 10.2307/749455
   Ho HZ, 2000, J RES MATH EDUC, V31, P362, DOI 10.2307/749811
   Huang YM, 2010, COMPUT EDUC, V54, P47, DOI 10.1016/j.compedu.2009.07.006
   Huang YM, 2009, EDUC TECHNOL SOC, V12, P163
   Hulland J, 1999, STRATEGIC MANAGE J, V20, P195, DOI 10.1002/(SICI)1097-0266(199902)20:2<195::AID-SMJ13>3.3.CO;2-Z
   Jansson B, 2009, J ANXIETY DISORD, V23, P374, DOI 10.1016/j.janxdis.2008.12.001
   Kasvi JJJ, 2000, COSIGA LEARNING COMP, P23
   Keller J., 1983, INSTRUCTIONAL DESIGN, P383
   Kelly MM, 2008, J BEHAV THER EXP PSY, V39, P87, DOI 10.1016/j.jbtep.2007.02.003
   Krinzinger H, 2009, J PSYCHOEDUC ASSESS, V27, P206, DOI 10.1177/0734282908330583
   Laidra K, 2007, PERS INDIV DIFFER, V42, P441, DOI 10.1016/j.paid.2006.08.001
   Land SM, 1996, ETR&D-EDUC TECH RES, V44, P37, DOI 10.1007/BF02300424
   Lee J., 2011, Academic Exchange Quarterly, V15, P146
   Liu HC, 2011, BRIT J EDUC TECHNOL, V42, P598, DOI 10.1111/j.1467-8535.2009.01047.x
   Ma X, 1999, J RES MATH EDUC, V30, P520, DOI 10.2307/749772
   Mahmood S., 2011, British Journal of Arts and Social Sciences, V2, P169
   McGrenere J., 1996, Design: Educational electronic multi-player games a literature review
   Mead NR, 2009, J SYST SOFTWARE, V82, P571, DOI 10.1016/j.jss.2008.12.038
   MEDALIE JH, 1976, AM J MED, V60, P910, DOI 10.1016/0002-9343(76)90921-9
   Michael Pressley CM, 1995, ADV ED PSYCHOL ED RE
   Moreno-Ger P, 2008, COMPUT HUM BEHAV, V24, P2530, DOI 10.1016/j.chb.2008.03.012
   Munn N.L., 1969, Introduction to psychology
   Pavlou PA, 2006, MIS QUART, V30, P115
   Peterson ER, 2010, LEARN INDIVID DIFFER, V20, P167, DOI 10.1016/j.lindif.2009.12.004
   Piccoli G, 2001, MIS QUART, V25, P401, DOI 10.2307/3250989
   Prensky M, 2003, ED TECHNOLOGY
   Prensky M., 2001, Digital game-based learning, P11
   Quintero MM, 2007, J COMPUT INFORM SYST, V48, P44
   Reigeluth C., 1983, INSTRUCTIONAL DESIGN, DOI DOI 10.4324/9780203824283
   Rieber LP, 2008, EDUC MEDIA INT, V45, P77, DOI 10.1080/09523980802107096
   Ringle C.M., 2005, SMARTPLS 2 0 M3 BETA
   Rooji SW, 2009, COMPUT EDUC, V52, P210
   Rubinsten O, 2010, BEHAV BRAIN FUNCT, V6, DOI 10.1186/1744-9081-6-46
   Sandberg J, 2011, COMPUT EDUC, V57, P1334, DOI 10.1016/j.compedu.2011.01.015
   Sandberg K, 2010, CONSCIOUS COGN, V19, P1069, DOI 10.1016/j.concog.2009.12.013
   Schnotz W, 2010, INSTR SCI, V38, P315, DOI 10.1007/s11251-009-9104-y
   Schutte J., 1997, Virtual teaching in higher education
   Shapiro A., 2004, HDB RES ED COMMUNICA, V2nd, P605
   SNAITH RP, 1982, BRIT J PSYCHIAT, V141, P518, DOI 10.1192/bjp.141.5.518
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Spielberger C. D., 1989, State-trait anxiety inventory: a comprehensive bibliography, DOI DOI 10.1016/J.COGNITION.2007.03.002
   Su CH, 2015, J COMPUT ASSIST LEAR, V31, P268, DOI 10.1111/jcal.12088
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   van Bruggen JM, 2002, LEARN INSTR, V12, P121, DOI 10.1016/S0959-4752(01)00019-6
   van der Duim L, 2007, P 29 INT C SOFTW ENG
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   van Vliet H, 2006, IEEE SOFTWARE, V23, P55, DOI 10.1109/MS.2006.80
   Venkatesh V, 2000, INFORM SYST RES, V11, P342, DOI 10.1287/isre.11.4.342.11872
   von Wangenheim CG, 2009, IEEE SOFTWARE, V26, P92, DOI 10.1109/MS.2009.54
   WEBSTER J, 1992, MIS QUART, V16, P201, DOI 10.2307/249576
   Wixom BH, 2001, MIS QUART, V25, P17, DOI 10.2307/3250957
   Wu WH, 2008, INT J ENG EDUC, V24, P681
   YOUNG DJ, 1991, MOD LANG J, V75, P426, DOI 10.2307/329492
   Zichermann G., 2011, GAMIFICATION DESIGN
NR 91
TC 56
Z9 69
U1 16
U2 246
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 10013
EP 10036
DI 10.1007/s11042-015-2799-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500027
DA 2024-07-18
ER

PT J
AU Bao, L
   Zhang, XW
   Zheng, YF
   Li, Y
AF Bao, Lei
   Zhang, Xiongwei
   Zheng, Yunfei
   Li, Yang
TI Video saliency detection using 3D shearlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video saliency detection; 3D discrete shearlet transform; Feature
   blocks; Global probability density
AB Recently, visual saliency detection has received great interest. As most video saliency detection models are based on spatiotemporal mechanism, we firstly give a simple introduction of it in this paper. After discussing issues to be addressed, we present a novel framework for video saliency detection based on 3D discrete shearlet transform. Instead of measuring saliency by fusing spatial and temporal saliency maps, the proposed model regards video as three-dimensional data. By decomposing the video with 3D discrete shearlet transform and reconstructing it on multi-scales, this multi-scale saliency detection model obtains a number of feature blocks to describe the video. Based on each feature block, every a number of successive feature maps are taken as a whole, and the global contrast is calculated to obtain the saliency maps. By fusing all the saliency maps of different levels, the saliency map is generated for each video frame. This novel framework is very simple, and experimental results on ten videos show that the proposed model outperforms lots existing models.
C1 [Bao, Lei; Zhang, Xiongwei; Li, Yang] PLA Univ Sci & Technol, Coll Command Informat Syst, Nanjing 210000, Jiangsu, Peoples R China.
   [Zheng, Yunfei] Acad Army, Key Lab Polarizat Imaging & Detect, Hefei 230000, Peoples R China.
C3 Army Engineering University of PLA
RP Bao, L (corresponding author), PLA Univ Sci & Technol, Coll Command Informat Syst, Nanjing 210000, Jiangsu, Peoples R China.
EM lbaodong001@gmail.com
RI Li, Yang/M-3902-2019
OI Li, Yang/0000-0003-1682-0284
CR [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2001, PROC 18 INT C MACH L
   Bao L, 2015, MULTIMEDIA TOOLS APP, V74
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Duncan K, 2012, IEEE IMAGE PROC, P1093, DOI 10.1109/ICIP.2012.6467054
   Duncan Kester, 2010, P 7 IND C COMP VIS G, P40
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo K., 2006, Wavelets and Splines, P189
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L., 2000, MODELS BOTTOM UP TOP
   Kim W, 2014, IEEE T CIRC SYST VID, V24, P646, DOI 10.1109/TCSVT.2013.2290579
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li WT, 2013, IEEE T IMAGE PROCESS, V22, P2600, DOI 10.1109/TIP.2013.2253483
   Li Y, 2013, IEEE T CIRC SYST VID, V23, P2067, DOI 10.1109/TCSVT.2013.2270367
   Negi PS, 2012, IEEE T IMAGE PROCESS, V21, P2944, DOI 10.1109/TIP.2012.2183883
   Rapantzikos K, 2009, SIGNAL PROCESS-IMAGE, V24, P557, DOI 10.1016/j.image.2009.03.002
   Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152
   Tapu R, 2012, EUR SIGNAL PR CONF, P1583
   Wu B, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-16
   Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429
NR 26
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7761
EP 7778
DI 10.1007/s11042-015-2692-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600015
DA 2024-07-18
ER

PT J
AU Jana, S
   Chan, A
   Pande, A
   Mohapatra, P
AF Jana, Shraboni
   Chan, An
   Pande, Amit
   Mohapatra, Prasant
TI QoE prediction model for mobile video telephony
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile video telephony; Perceptual video quality; Quality of experience;
   Support vector regression
AB Interactive online video applications, such as video telephony, are known for their vulnerability to network condition. With the increasing usage of hand-held wireless mobile devices, which are capable of capturing and processing good quality videos, combined with the flexibility in an end-user movements have added new challenging factors for application providers and network operators. These factors affect the perceived video quality of mobile video telephony applications, unlike conventional video telephony over desktop computers. We investigate this impact on video quality of mobile video telephony in varying network conditions and end-users movement scenarios. Based on 312 live traces, we quantitatively derive the correlation between the perceived video quality and the network Quality of Service (QoS) and user mobility. With the results, we develop a Quality of Experience (QoE) prediction model for mobile video telephony using Support Vector Regression techniques. The prediction models display a parts per thousand 0.8 pearson correlation with experimental data. Our methodology and findings can be used to guide the video telephony application providers and network operators to work towards satisfying end-user experience.
C1 [Jana, Shraboni] Univ Calif Davis, Dept Elect & Comp Engn, Davis, CA 95616 USA.
   [Chan, An; Mohapatra, Prasant] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Pande, Amit] Indian Inst Technol Delhi, Dept Comp Sci & Engn, Hauz Khas, New Delhi 110016, India.
C3 University of California System; University of California Davis;
   University of California System; University of California Davis; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Jana, S (corresponding author), Univ Calif Davis, Dept Elect & Comp Engn, Davis, CA 95616 USA.
EM sjana@ucdavis.edu; anch@ucdavis.edu; pande@iitd.ac.in;
   pmohapatra@ucdavis.edu
CR [Anonymous], P BRIT MACH VIS C LE
   [Anonymous], INFOCOM
   [Anonymous], PEVQ ADV PERC EV VID
   [Anonymous], BT50011 ITU
   [Anonymous], P ACM SIGCOMM 06
   [Anonymous], 2007, NEURAL INF PROCESS L
   [Anonymous], IEEE COMMUN MAG
   [Anonymous], COMPUT NETW
   [Anonymous], 2011, Cisco visual networking index: Global mobile data traffic forecast update, 2011 - 2016
   [Anonymous], MULT EXP 2006 IEEE I
   [Anonymous], P IEEE SECON
   [Anonymous], P ICCCN
   [Anonymous], IMAGE PROCESSING
   [Anonymous], NOSSDAV
   [Anonymous], SYNTH LECT IM VID MU
   [Anonymous], 2005, PEVQ ADV PERC EV VID
   [Anonymous], IMAG PROC 2000 P 200
   [Anonymous], P MOB 10
   [Anonymous], IEEE ACM T NETW
   [Anonymous], MULT EXP 2006 IEEE I
   [Anonymous], P ACM MOB
   Chapelle O., 1999, Advances in Neural Information Processing Systems, V12
   ITU, 2002, TECH REP
   ITU, 2002, BT50011 ITU
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
NR 27
TC 12
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7957
EP 7980
DI 10.1007/s11042-015-2711-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600024
DA 2024-07-18
ER

PT J
AU Bilal, M
   Mujtaba, H
   Jaffar, MA
AF Bilal, Mohsin
   Mujtaba, Hasan
   Jaffar, Muhammad Arfan
TI Modified particle swarm optimization and fuzzy regularization for pseudo
   de-convolution of spatially variant blurs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ill-posed inverse problem; Space variant degradation; Pseudo
   de-convolution; Fuzzy regularization; Particle swarm optimization;
   Mathematical morphology
ID IMAGE-RESTORATION
AB We propose a modified particle swarm optimization (MPSO) based method for Pseudo De-convolution of the ill-posed inverse problem namely, the space-variant image degradation (SVD). In this paper, SVD is simulated by the pseudo convolution of different sub-regions of the image with different known blurring kernels and additive random noise with unknown variance. Two heuristic modifications are proposed in PSO: 1) Initialization of the swarm and 2) Mutation of the global best. Fuzzy logic is applied for the computation of regularization parameter (RP) to cater for the sensitivity of the problem. The computation of RP is crucial due to the additive noise in the SVD image. Thus mathematical morphology (MM) is applied for better extraction of spatial activity from the distorted image. The performance of the proposed method is evaluated with different test images and noise powers. Comparative analysis demonstrates the superiority of proposed restoration, in terms of quantitative measures, over well-known existing and state-of-the-art SVD approaches.
C1 [Bilal, Mohsin; Mujtaba, Hasan] Natl Univ Comp & Emerging Sci, Dept Comp Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
   [Jaffar, Muhammad Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Syst, Riyadh, Saudi Arabia.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Bilal, M (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
EM mohsin.bilal@nu.edu.pk; hasan.mujtaba@nu.edu.pk;
   arfan.jaffar@ccis.imamu.edu.sa
RI Jaffar, Arfan/GQB-2768-2022; bilal, Mohsin/AAN-6349-2020
OI bilal, Mohsin/0000-0001-8632-2729
FU Higher Education Commission (HEC) of Pakistan
FX Authors would acknowledge Higher Education Commission (HEC) of Pakistan,
   for its continuous financial support in the meritorious role of
   scholarship for higher education.
CR [Anonymous], PUSH LIMITS EVOLVED
   [Anonymous], SMART COMPUT REV
   [Anonymous], THESIS
   [Anonymous], DIGITAL IMAGE PROCES
   Bar L, 2007, LECT NOTES COMPUT SC, V4485, P533
   Bardsley J, 2006, OPT EXPRESS, V14, P1767, DOI 10.1364/OE.14.001767
   Biggs DSC, 1997, APPL OPTICS, V36, P1766, DOI 10.1364/AO.36.001766
   Bilal M, 2014, MULTIMED TOOLS APPL, V69, P1067, DOI 10.1007/s11042-012-1172-3
   Boden AF, 1996, ASTR SOC P, V101, P131
   Dash R, 2009, WOR CONG NAT BIOL, P1252
   FAISAL M, 1995, J OPT SOC AM A, V12, P2593, DOI 10.1364/JOSAA.12.002593
   Gu XJ, 2009, J COMPUT APPL MATH, V225, P478, DOI 10.1016/j.cam.2008.08.013
   Hansen P.C., 2006, DEBLURRING IMAGES MA
   Klapp I, 2012, LECT NOTES COMPUT SC, V6667, P157, DOI 10.1007/978-3-642-24785-9_14
   Kober V, 2007, LECT NOTES COMPUT SC, V4673, P903
   Lucena M, 2016, MULTIMED TOOLS APPL, V75, P3677, DOI 10.1007/s11042-014-2063-6
   Masood S, 2013, MULTIMED TOOLS APPL, V63, P93, DOI 10.1007/s11042-012-1015-2
   Mignotte M, 2006, IEEE T IMAGE PROCESS, V15, P1973, DOI 10.1109/TIP.2006.873446
   Nagy JG, 1998, SIAM J SCI COMPUT, V19, P1063, DOI 10.1137/S106482759528507X
   Paik JK, 1992, IEEE T IMAGE PROCESS, V1, P49, DOI 10.1109/83.128030
   Perry SW, 2000, IEEE T NEURAL NETWOR, V11, P156, DOI 10.1109/72.822518
   Qian Zhenchao., 2005, Educational Attainment and Intermarriage: Asian Indian and Filipino Americans Compared, P1
   Sharif M, 2015, MULTIMED TOOLS APPL, V74, P5533, DOI 10.1007/s11042-014-1867-8
   Welk M, 2005, LECT NOTES COMPUT SC, V3663, P485
   Zhenhe Sun, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P725, DOI 10.1109/IFOST.2011.6021125
   ZHOU YT, 1988, IEEE T ACOUST SPEECH, V36, P1141, DOI 10.1109/29.1641
   Zia S, 2014, MULTIMED TOOLS APPL, V72, P1, DOI 10.1007/s11042-012-1253-3
NR 27
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6533
EP 6548
DI 10.1007/s11042-015-2587-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700023
DA 2024-07-18
ER

PT J
AU Du, XL
   Ye, YM
   Lau, RYK
   Li, YP
   Huang, XH
AF Du, Xiaolin
   Ye, Yunming
   Lau, Raymond Y. K.
   Li, Yueping
   Huang, Xiaohui
TI Multi-opinion Ring: visualizing and predicting multiple opinion
   orientations in online social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion analysis; Opinion visualization; Opinion prediction;
   Multi-opinion network; Social media
ID SENTIMENT ANALYSIS
AB In the era of the Social Web, actors (e.g. people, organizations, nations, etc) of online social media often voice out their opinions towards a variety of opinion targets. Extracting and visualizing distributions of multiple opinions among actors facilitates individuals or organizations to extract valuable social intelligence from online social media. The main contribution of our research reported in this paper is the development of a novel opinion analysis methodology named Multi-opinion Ring for visualizing and predicting multiple opinion orientations held by different groups of actors in online social media. In particular, the proposed Multi-opinion Ring method combines visualization techniques with machine learning methods to predict the opinion inclinations of actors who are originally neutral to different opinion targets. A series of controlled experiments, user-based evaluations, and case studies show that the proposed Multi-opinion Ring method significantly outperforms classical visualization methods in terms of the cohesiveness of the graphical layout and the informativeness of the visualized contents.
C1 [Du, Xiaolin; Ye, Yunming; Huang, Xiaohui] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen Key Lab Internet Informat Collaborat, Shenzhen, Peoples R China.
   [Lau, Raymond Y. K.] City Univ Hong Kong, Dept Informat Syst, Hong Kong, Hong Kong, Peoples R China.
   [Li, Yueping] Shenzhen Polytech, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; City University of Hong Kong; Shenzhen
   Polytechnic University
RP Ye, YM (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen Key Lab Internet Informat Collaborat, Shenzhen, Peoples R China.
EM duxiaolinhitsz@gmail.com; yeyunming@hit.edu.cn; raylau@cityu.edu.hk;
   leeyueping@gmail.com; hxh016@gmail.com
RI huang, xiaohui/KRP-2903-2024; li, yue/IXD-9935-2023; li,
   yueyue/IVH-9846-2023
OI Lau, Raymond/0000-0002-5751-4550
FU NSFC [61272538, 61303103]; Shenzhen Science and Technology Program
   [JCYJ20140417172417128, JCY20130331150354073]; Shenzhen Strategic
   Emerging Industries Program [JCYJ20130329142551746]; Research Grants
   Council of the Hong Kong Special Administrative Region China [CityU
   145712]; Shenzhen Municipal Science and Technology R&D Fund-Basic
   Research Program [JCYJ20130401145617281, JCYJ20140419115614350]
FX Yunming Ye's work was supported in part by NSFC under Grant No.
   61272538, Shenzhen Science and Technology Program under Grant No.
   JCYJ20140417172417128, and the Shenzhen Strategic Emerging Industries
   Program under Grant No. JCYJ20130329142551746. Raymond Y.K. Lau's work
   was supported in part by Research Grants Council of the Hong Kong
   Special Administrative Region China under Grant No. CityU 145712, and
   the Shenzhen Municipal Science and Technology R&D Fund-Basic Research
   Program (JCYJ20130401145617281 and JCYJ20140419115614350). Yueping Li's
   work was supported in part by NSFC under Grant No. 61303103, and the
   Shenzhen Science and Technology Program under Grant No.
   JCY20130331150354073.
CR [Anonymous], 2003, ICML
   [Anonymous], 2003, TECHNICAL REPORT
   [Anonymous], 2009, Visual Analytics Science and Technology
   [Anonymous], 2010, ENCY MACHINE LEARNIN, DOI DOI 10.1007/978-0-387-30164-8_140
   [Anonymous], 2002, P 18 C UNCERTAINTY A
   [Anonymous], IEEE S INF VIS
   Bagheri A, 2013, KNOWL-BASED SYST, V52, P201, DOI 10.1016/j.knosys.2013.08.011
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Brandes U, 2003, IEEE T VIS COMPUT GR, V9, P241, DOI 10.1109/TVCG.2003.1196010
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Chen CM, 2006, IEEE CONF VIS ANAL, P59
   Chen L, 2014, KNOWL-BASED SYST, V64, P44, DOI 10.1016/j.knosys.2014.03.020
   Eades P., 2000, Journal of Graph Algorithms and Applications, V4, DOI 10.7155/jgaa.00029
   Farrugia M, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS (ACHI 2011), P79
   Freeman LintonC., 2000, J SOCIAL STRUCTURE, V1, P1
   Gansner ER, 2007, LECT NOTES COMPUT SC, V4372, P386
   Gao J, 2012, DECIS SUPPORT SYST, V53, P772, DOI 10.1016/j.dss.2012.05.011
   Gilks W.R., 1996, MARKOV CHAIN MONTE C, V2
   Gregory MichelleL., 2006, PROC WORKSHOP SENTIM, P23
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jensen D., 2004, Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P593, DOI [10.1145/1014052.1014125, DOI 10.1145/1014052.1014125]
   Kim K, 2014, PATTERN RECOGN, V47, P758, DOI 10.1016/j.patcog.2013.07.022
   Kim S., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220555
   Koren Y, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P137, DOI 10.1109/INFVIS.2002.1173159
   Li YM, 2013, DECIS SUPPORT SYST, V55, P206, DOI 10.1016/j.dss.2013.01.023
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.2200/S00416ED1V01Y201204HLT016, 10.2200/s00416ed1v01y201204hlt016]
   Liu B., 2005, Proceedings of 14th International Conference of World Wide Web, P342
   Liu B, 2010, IEEE INTELL SYST, V25, P76
   Liu Bing., 2009, Encyclopedia of Database Systems, P1986, DOI DOI 10.1007/978-0-387-39940-9_257
   Loia V, 2014, KNOWL-BASED SYST, V58, P75, DOI 10.1016/j.knosys.2013.09.024
   Macskassy S.A., 2007, AAAI, P590
   Macskassy SA, 2007, J MACH LEARN RES, V8, P935
   McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988
   McDowell LK, 2009, J MACH LEARN RES, V10, P2777
   Meng X, 2012, P 18 ACM SIGKDD INT, P379, DOI [DOI 10.1145/2339530.2339592, 10.1145/2339530.2339592]
   Montoyo A, 2012, DECIS SUPPORT SYST, V53, P675, DOI 10.1016/j.dss.2012.05.022
   Morinaga S., 2002, P 8 ACM SIGKDD INT C, P341, DOI [DOI 10.1145/775047.775098, 10.1145/775047.775098]
   Nan Cao, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P101, DOI 10.1109/ICDM.2011.135
   Neville J, 2007, J MACH LEARN RES, V8, P653
   Northway ML, 1940, SOCIOMETRY, V3, P144, DOI 10.2307/2785439
   Pak A, 2010, P 7 C INT LANG RES E, DOI DOI 10.17148/IJARCCE.2016.51274
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Perer A, 2006, IEEE T VIS COMPUT GR, V12, P693, DOI 10.1109/TVCG.2006.122
   Petz Gerald, 2013, Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data. Third International Workshop, HCI-KDD 2013. Held at SouthCHI 2013. Proceedings: LNCS 7947, P35, DOI 10.1007/978-3-642-39146-0_4
   Petz Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P618, DOI 10.1007/978-3-642-35236-2_62
   Petz G, 2014, INFORM PROCESS MANAG, V50, P899, DOI 10.1016/j.ipm.2014.07.005
   Popescu A.-M., 2007, NATURAL LANGUAGE PRO, P9, DOI DOI 10.1007/978-1-84628-754-1_2
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Therón R, 2006, LECT NOTES COMPUT SC, V4073, P70
   Valdez Andre Calero, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P606, DOI 10.1007/978-3-642-35236-2_61
   Wu YC, 2010, IEEE T VIS COMPUT GR, V16, P1109, DOI 10.1109/TVCG.2010.183
NR 53
TC 1
Z9 1
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7159
EP 7186
DI 10.1007/s11042-015-2640-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400023
DA 2024-07-18
ER

PT J
AU Lai, TT
   Wang, HZ
   Yan, Y
   Wang, DH
   Xiao, GB
AF Lai, Taotao
   Wang, Hanzi
   Yan, Yan
   Wang, Da-Han
   Xiao, Guobao
TI Rapid hypothesis generation by combining residual sorting with local
   constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust model fitting; Hypothesis generation; Multi-structure data;
   Residual sorting; Local constraints
ID SEGMENTATION
AB Efficient hypothesis generation plays an important role in robust model fitting. In this study, based on the combination of residual sorting and local constraints, we propose an efficient guided hypothesis generation method, called Rapid Hypothesis Generation (RHG). By exploiting the local constraints to guide the hypothesis generation process, RHG raises the probability of generating promising hypotheses and reduces the computational cost during hypotheses generation. Experimental results on homography and fundamental matrix estimation show that RHG can effectively guide hypothesis generation process and rapidly generate promising hypotheses for heavily contaminated multi-structure data.
C1 [Lai, Taotao; Wang, Hanzi; Yan, Yan; Xiao, Guobao] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Fujian, Peoples R China.
   [Wang, Da-Han] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen, Fujian, Peoples R China.
C3 Xiamen University; Xiamen University of Technology
RP Wang, HZ (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Fujian, Peoples R China.
EM wang.hanzi@gmail.com
RI Wang, Hui/HMU-9512-2023; wang, hao/HSE-7975-2023; wang,
   handong/HLH-5739-2023; Wang, Han/GPW-9809-2022; Lai, taozi/JAH-6160-2023
FU National Natural Science Foundation of China [61472334, 61305004,
   61571379]
FX The authors want to thank Dr. Tat-Jun Chin of Adelaide university for
   providing some competing methods. This work was supported by the
   National Natural Science Foundation of China under Grants 61472334,
   61305004, and 61571379.
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Chin TJ, 2012, IEEE T PATTERN ANAL, V34, P625, DOI 10.1109/TPAMI.2011.169
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fragoso V, 2013, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2013.307
   Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768
   Hesami R, 2010, COMPUT VIS IMAGE UND, V114, P475, DOI 10.1016/j.cviu.2009.12.004
   Hevia-Montiel N, 2007, P ANN INT IEEE EMBS, P2102, DOI 10.1109/IEMBS.2007.4352736
   Isack H, 2014, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2014.150
   Jung H, 2014, PROC CVPR IEEE, P1210, DOI 10.1109/CVPR.2014.158
   Kanazawa Y., 2004, Procedings of the British Machine Vision Conference, P247
   Lai TT, 2014, I C CONT AUTOMAT ROB, P1057, DOI 10.1109/ICARCV.2014.7064452
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lee KH, 2013, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2013.12
   Lucena M, 2010, MULTIMED TOOLS APPL, V49, P371, DOI 10.1007/s11042-009-0376-7
   Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505
   Mittal S, 2012, IEEE T PATTERN ANAL, V34, P2351, DOI 10.1109/TPAMI.2012.52
   Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458
   Poling B, 2014, INT J COMPUT VISION, V108, P165, DOI 10.1007/s11263-013-0694-0
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199
   Wang HZ, 2012, IEEE T PATTERN ANAL, V34, P1177, DOI 10.1109/TPAMI.2011.216
   Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109
   Wong HS, 2013, PATTERN RECOGN, V46, P257, DOI 10.1016/j.patcog.2012.07.005
   Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350
   Zuliani M, 2005, IEEE IMAGE PROC, P2969
NR 27
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7445
EP 7464
DI 10.1007/s11042-016-3365-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400035
DA 2024-07-18
ER

PT J
AU Liu, TG
   Miao, QG
   Xu, PF
   Song, JF
   Quan, YN
AF Liu, Tiange
   Miao, Qiguang
   Xu, Pengfei
   Song, Jianfeng
   Quan, Yining
TI Color topographical map segmentation Algorithm based on linear element
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color map segmentation; Linear element; Color features; Fuzzy c-means
   (FCM)
ID COUPLED NEURAL-NETWORKS; IMAGE SEGMENTATION; CLUSTERING ALGORITHMS
AB In order to overcome the discontinuity of geographic elements during the digitization of scanned topographic maps, a color map segmentation algorithm, which is used to segment color maps into different layers based on linear element features, is proposed in this paper. Linear elements are regarded as the elementary units in this method. We use background removal, thinning, nodes disconnection, labeling and dilation to get the elementary units. Then the main color, which could accurately represent the color feature of linear element, is extracted for clustering on the basis of Fuzzy c-means algorithm. At last, disconnected nodes are merged into the corresponding layers to keep the continuity of the results. The experimental results show that the proposed algorithm outperforms other segmentation approaches that regarding pixels as the elementary units.
C1 [Liu, Tiange; Miao, Qiguang; Xu, Pengfei; Song, Jianfeng; Quan, Yining] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Miao, QG (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM xidianltg@126.com; qgmiao@126.com; xpf1987071500@126.com;
   jfsong@mail.xidian.edu.cn; ynquan@mail.xidian.edu.cn
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundations of China [61272280, 41271447,
   61272195, 61472302]; Program for New Century Excellent Talents in
   University [NCET-12-0919]; Fundamental Research Funds for the Central
   Universities [K5051203020, K5051303016, K5051303018, BDY081422,
   K50513100006]; Creative Project of the Science and Technology State of
   xi'an [CXY1341(6)]; State Key Laboratory of Geo-information Engineering
   [SKLGIE2014-M-4-4]
FX The work was jointly supported by the National Natural Science
   Foundations of China under grant No. 61272280, 41271447, 61272195 and
   61472302, the Program for New Century Excellent Talents in University
   (NCET-12-0919), the Fundamental Research Funds for the Central
   Universities under grant No. K5051203020, K5051303016, K5051303018,
   BDY081422, and K50513100006, the Creative Project of the Science and
   Technology State of xi'an under grant No. CXY1341(6), The State Key
   Laboratory of Geo-information Engineering under grant No.
   SKLGIE2014-M-4-4.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 1997, Inter. Arch. Photogramm. Remote Sens.
   Blosca JM, 2008, ISPRS J PHOTOGRAMM, V63, P84, DOI 10.1016/j.isprsjprs.2007.07.010
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Campadelli P, 1997, IMAGE VISION COMPUT, V15, P161, DOI 10.1016/S0262-8856(96)01121-3
   CELENK M, 1990, COMPUT VISION GRAPH, V52, P145, DOI 10.1016/0734-189X(90)90052-W
   Chen H., 2010, J IMAGE GRAPH, V9
   Chen Y, 2006, IEEE T GEOSCI REMOTE, V44, P1048, DOI 10.1109/TGRS.2005.861478
   Gonzalez RC, 2007, DIGITAL IMAGE PROCES, P423
   Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035
   HUANG CL, 1992, PATTERN RECOGN LETT, V13, P345, DOI 10.1016/0167-8655(92)90032-U
   Khotanzad A, 2003, IEEE T PATTERN ANAL, V25, P18, DOI 10.1109/TPAMI.2003.1159943
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Kurugollu F, 2001, IMAGE VISION COMPUT, V19, P915, DOI 10.1016/S0262-8856(01)00052-X
   Leyk S, 2010, LECT NOTES COMPUT SC, V6020, P231
   Leyk S, 2010, GEOINFORMATICA, V14, P1, DOI 10.1007/s10707-008-0074-z
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   Ong SH, 2002, IMAGE VISION COMPUT, V20, P279, DOI 10.1016/S0262-8856(02)00021-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Stewart RD, 2002, IEEE T NEURAL NETWOR, V13, P1557, DOI 10.1109/TNN.2002.804229
   Sun Ji-Gui, 2008, Journal of Software, V19, P48, DOI 10.3724/SP.J.1001.2008.00048
   TOMBRE K, 1995, PATTERN RECOGN LETT, V16, P883, DOI 10.1016/0167-8655(95)00063-M
   Wei S, 2011, NEUROCOMPUTING, V74, P1485, DOI 10.1016/j.neucom.2011.01.005
   Wiedemann C., 1998, Empirical Evaluation Techniques in Computer Vision, P172
   Xin D., 2006, J INFORM COMPUTING S, V1, P275
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zheng H, 2003, J COMPUT AIDED DES C, V1
   Zhuang HL, 2012, IEEE T IND ELECTRON, V59, P3299, DOI 10.1109/TIE.2011.2165451
NR 31
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5417
EP 5438
DI 10.1007/s11042-015-2510-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600003
DA 2024-07-18
ER

PT J
AU Zhang, P
   Zhuo, T
   Zhang, YN
   Huang, HQ
   Chen, KL
AF Zhang, Peng
   Zhuo, Tao
   Zhang, Yanning
   Huang, Hanqiao
   Chen, Kangli
TI Bayesian tracking fusion framework with online classifier ensemble for
   immersive visual applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayesian framework; Tracking fusion; Online; Ensemble; Immersive; Visual
   applications
ID OBJECT TRACKING
AB During the last decade, the development of the immersive virtual reality (VR) has achieved a great progress in different application areas. For more advanced large-scale immersive VR environments or systems, one of the most challenge is to accurately track the position of the user's body part such as head when he/she is immersived in the environment to feel the changes among the synthetic stereoscopic image sequences. Unfortunately, accurate tracking is not easy in the virtual reality scenarios due to the variety types of existing intrinsic and extrinsic changes when tracking is on-the-fly. Especially for the single tracker, a long time accurate tracking is usually not possible because of the model adaption problem in different environments. Recent trend of research in tracking is to incorporate multiple trackers into a compositive learning framework and utilize the advantages of different trackers for more effective tracking. Therefore, in this paper, we propose a novel Bayesian tracking fusion framework with online classifier ensemble strategy. The proposed tracking formulates a fusion framework for online learning of multiple trackers by modeling a cumulative loss minimization process. With an optimal pair-wise sampling scheme for the SVM classifier, the proposed fusion framework can achieve more accurate tracking performance when compared with the other state-of-art trackers. In addition, the experiments on the standard benchmark database also verify that the proposed tracking is able to handle the challenges in many immersive VR applications and environments.
C1 [Zhang, Peng; Zhuo, Tao; Zhang, Yanning; Chen, Kangli] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Huang, Hanqiao] Air Force Engn Univ, Sch Aeronaut & Astronaut Engn, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Air Force Engineering University
RP Zhang, P; Zhuo, T (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM zh0036ng@nwpu.edu.cn; zhuotao@mail.nwpu.edu.cn; ynzhang@nwpu.edu.cn;
   cnxahhq@gmail.com; chenkangli@mail.nwpu.edu.cn
RI Zhang, Penghui/HGB-7353-2022; zhang, yueqi/JXM-4287-2024
OI Zhang, Penghui/0000-0002-9518-7079; 
FU Research Fund for the Doctoral Program of Higher Education of China
   [20126102120055]; National Natural Science Foundation of China
   [61301194, 61231016]; NWPU [3102014JSJ0014]
FX This research is supported by Research Fund for the Doctoral Program of
   Higher Education of China 20126102120055, National Natural Science
   Foundation of China 61301194 & 61231016, foundation grant from NWPU
   3102014JSJ0014.
CR [Anonymous], EUR C COMP VIS ECCV
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2009.5459264
   Bai Q, 2014, IEEE INT C MACH LEAR
   Bailer C, 2014, EUR C COMP VIS ECCV
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   CHEN CF, 1985, J ROY STAT SOC B MET, V47, P540
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chu CW, 2007, LECT NOTES COMPUT SC, V4796, P146
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dinh TB, 2011, IEEE INT C COMP VIS
   Fan R, 2008, J MACH LEARN RES JML
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Grabner H, 2008, EUR C COMP VIS ECCV
   Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006
   Gu S, 2011, IEEE I CONF COMP VIS, P1840, DOI 10.1109/ICCV.2011.6126451
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Hua Y, 2014, EUR C COMP VIS ECCV
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim BG, 2011, IEEE IC COMP COM NET
   Kwon J., 2010, IEEE INT C COMP VIS
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Liu YL, 2012, IEEE T VIS COMPUT GR, V18, P573, DOI 10.1109/TVCG.2012.53
   Manen S, 2014, EUR C COMP VIS ECCV
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oron S., 2012, IEEE INT C COMP VIS
   Pawan Kumar M., 2010, NIPS
   Saffari A., 2010, EUR C COMP VIS ECCV
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Sevilla-Lara L, 2012, IEEE INT C COMP VIS
   Shalev-Shwartz S, 2007, IEEE INT C MACH LEAR
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tian XH, 2011, IEEE ICC
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wagner D, 2014, INT SYM MIX AUGMENT, P383
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang H, 2013, NEUROCOMPUTING
   Yao R, 2008, IEEE C COMP VIS PATT
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoon JH, 2012, EUR C COMP VIS ECCV
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
NR 48
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5075
EP 5092
DI 10.1007/s11042-015-2827-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700015
DA 2024-07-18
ER

PT J
AU Karaman, S
   Bagdanov, AD
   Landucci, L
   D'Amico, G
   Ferracani, A
   Pezzatini, D
   Del Bimbo, A
AF Karaman, Svebor
   Bagdanov, Andrew D.
   Landucci, Lea
   D'Amico, Gianpaolo
   Ferracani, Andrea
   Pezzatini, Daniele
   Del Bimbo, Alberto
TI Personalized multimedia content delivery on an interactive table by
   passive observation of museum visitors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Video surveillance; Cultural heritage; Multimedia
   museum; Personalization; Natural interaction; Passive profiling
ID REALITY; SYSTEM
AB The amount of multimedia data collected in museum databases is growing fast, while the capacity of museums to display information to visitors is acutely limited by physical space. Museums must seek the perfect balance of information given on individual pieces in order to provide sufficient information to aid visitor understanding while maintaining sparse usage of the walls and guaranteeing high appreciation of the exhibit. Moreover, museums often target the interests of average visitors instead of the entire spectrum of different interests each individual visitor might have. Finally, visiting a museum should not be an experience contained in the physical space of the museum but a door opened onto a broader context of related artworks, authors, artistic trends, etc. In this paper we describe the MNEMOSYNE system that attempts to address these issues through a new multimedia museum experience. Based on passive observation, the system builds a profile of the artworks of interest for each visitor. These profiles of interest are then used to drive an interactive table that personalizes multimedia content delivery. The natural user interface on the interactive table uses the visitor's profile, an ontology of museum content and a recommendation system to personalize exploration of multimedia content. At the end of their visit, the visitor can take home a personalized summary of their visit on a custom mobile application. In this article we describe in detail each component of our approach as well as the first field trials of our prototype system built and deployed at our permanent exhibition space at LeMurate (http://www.lemurate.comune.fi.it/lemurate/) in Florence together with the first results of the evaluation process during the official installation in the National Museum of Bargello (http://www.uffizi.firenze.it/musei/?m=bargello).
C1 [Karaman, Svebor; Landucci, Lea; D'Amico, Gianpaolo; Ferracani, Andrea; Pezzatini, Daniele; Del Bimbo, Alberto] Univ Florence, MICC, Florence, Italy.
   [Bagdanov, Andrew D.] Comp Vis Ctr, Barcelona, Spain.
C3 University of Florence; Centre de Visio per Computador (CVC)
RP Karaman, S (corresponding author), Univ Florence, MICC, Florence, Italy.
EM svebor.karaman@unifi.it; bagdanov@cvc.uab.es; lea.landucci@unifi.it;
   gianpaolo.damico@unifi.it; andrea.ferracani@unifi.it;
   daniele.pezzatini@unifi.it; alberto.delbimbo@unifi.it
RI Karaman, Svebor/I-4929-2019; Bagdanov, Andrew/K-3932-2014
OI Karaman, Svebor/0000-0002-2496-5822; Bagdanov,
   Andrew/0000-0001-6408-7043
FU Thales Italia; MNEMOSYNE project (POR-FSE) [A.IV-OB.2]; Ramon y Cajal
   Fellowship [RYC-2012-11776]
FX This work was partially supported by Thales Italia and the MNEMOSYNE
   project (POR-FSE 2007-2013, A.IV-OB.2). Andrew D. Bagdanov acknowledges
   the support of Ramon y Cajal Fellowship RYC-2012-11776.
CR Anderson P., 2004, JISC TECHNOLOGY STAN, V4, P3
   [Anonymous], 1998, AAAI WORKSH REC SYST
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], 2011, BRIT MACH VIS C DUND
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1996, DIGITAL
   [Anonymous], 2006, P 1 INT WORKSH MOB V
   [Anonymous], 2010, P BMVC
   Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38
   Baber C, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P439
   Bagdanov AD, 2011, MULTIMEDIA CULTURAL, P39
   Bagdanov AD, 2013, LECT NOTES COMPUT SC, V8157, P239, DOI 10.1007/978-3-642-41184-7_25
   Ballagas R, 2004, UBICOMP 2004 WORKSH
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bartoli F, 2014, P 22 INT C PATT REC
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Bimbo A. D., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3886, DOI 10.1109/ICPR.2010.946
   Bowen J. P., 2010, RUTHERFORD J, V3
   Bowen JP, 2004, P MES WEB C MW 2004
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Bruns E, 2007, IEEE MULTIMEDIA, V14, P16, DOI 10.1109/MMUL.2007.33
   Brusilovsky P, 2002, COMMUN ACM, V45, P30
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Hatala M, 2005, USER MODEL USER-ADAP, V15, P339, DOI 10.1007/s11257-005-2304-5
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Hyvonen E., 2009, HDB ONTOLOGIES, P757, DOI DOI 10.1007/978-3-540-92673-3_34
   Jin CM, 2006, LECT NOTES ARTIF INT, V4253, P197
   Karaman S, 2014, ADV COMPUT VIS PATT, P287, DOI 10.1007/978-1-4471-6296-4_14
   Karaman S, 2014, PATTERN RECOGN, V47, P3767, DOI 10.1016/j.patcog.2014.06.003
   Karaman S, 2013, LECT NOTES COMPUT SC, V8158, P247, DOI 10.1007/978-3-642-41190-8_27
   Karaman S, 2012, LECT NOTES COMPUT SC, V7583, P443, DOI 10.1007/978-3-642-33863-2_44
   Kuflik Tsvi., 2011, Journal on Computing and Cultural Heritage, V3, P11, DOI DOI 10.1145/1921614.1921618
   Kumar R, 1998, ANN IEEE SYMP FOUND, P664, DOI 10.1109/SFCS.1998.743517
   Leibe B, 2005, PROC CVPR IEEE, P878
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Norman D.A., 1999, INVISIBLE COMPUTER W, V2nd
   Papageorgiou C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P35, DOI 10.1109/ICIP.1999.819462
   Pechenizkiy Mykola, 2007, P WORKSH PERS ACC CU, P11
   POPESCUL A., 2001, P 17 C UNCERTAINTY A, P437
   Rashid A. L., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P127
   Rukzio E, 2004, WORKSH UB DISPL ENV
   Sakamura K, 2003, PERSONALIZED DIGITAL
   SAMPAIO I, 2006, P ECAI 2006 WORKSH R, P107
   Savia E, 2005, P UAI 05 CIT
   Sparacino F, 2002, P MUS WEB MW2002
   SPARACINO F, 2004, P 12 ANN ACM INT C M, P72, DOI DOI 10.1145/1027527.1027541
   Starner T, 1997, PRESENCE-VIRTUAL AUG, V6, P386, DOI 10.1162/pres.1997.6.4.386
   Stock O, 2005, TEXT SPEECH LANG TEC, V27, P95
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y, 2008, P MUS WEB C MW2008
   Wang YW, 2009, INTERDISCIPL SCI REV, V34, P139, DOI 10.1179/174327909X441072
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Zancanaro M, 2003, P MUS WEB 2003
NR 57
TC 28
Z9 29
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3787
EP 3811
DI 10.1007/s11042-014-2192-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200012
DA 2024-07-18
ER

PT J
AU Li, JM
   Qu, YY
   Li, CH
   Xie, Y
AF Li, Jianmin
   Qu, Yanyun
   Li, Cuihua
   Xie, Yuan
TI Image super-resolution base on multi-kernel regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Kernel regression; Multi kernel learning
AB In this paper, a novel approach to single image super-resolution based on the multi-kernel regression is presented. This approach focuses on learning the map between the space of high-resolution image patches and the space of blurred high-resolution image patches, which are the interpolation results generated from the corresponding low-resolution images. Kernel regression based super-resolution approaches are promising, but kernel selection is a critical problem. In order to avoid demanding and time-consuming cross validation for kernel selection, we propose multi-kernel regression (MKR) model for image Super-Resolution (SR). Considering the multi-kernel regression model is prohibited when the training data is large-scale, we further propose a prototype MKR algorithm which can reduce the computational complexity. Extensive experimental results demonstrate that our approach is effective and achieves a high quality performance in comparison with other super-resolution methods.
C1 [Li, Jianmin; Qu, Yanyun; Li, Cuihua] Xiamen Univ, Dept Comp Sci, Xiamen, Peoples R China.
   [Xie, Yuan] Chinese Acad Sci, Inst Automat, State Key Lab Complex Syst & Intelligence Sci, Beijing, Peoples R China.
C3 Xiamen University; Chinese Academy of Sciences; Institute of Automation,
   CAS
RP Qu, YY (corresponding author), Xiamen Univ, Dept Comp Sci, Xiamen, Peoples R China.
EM yyqu@xmu.edu.cn
RI LI, JIAN/JAX-3092-2023; LI, JIAN/GRY-2197-2022; li, jian/GSE-0245-2022
FU National Natural Science Foundation of China [61373077, 61402480];
   Natural Science Foundation of Fujian Province of China [2013J01257];
   Scientific Research Foundation for the Introduction of Talent at Xiamen
   University of Technology [YKJ12023R]
FX This research work is support by the National Natural Science Foundation
   of China Under Grant No. 61373077 and Grant No.61402480, the Natural
   Science Foundation of Fujian Province of China Under Grant No.
   2013J01257, and the Scientific Research Foundation for the Introduction
   of Talent at Xiamen University of Technology No. YKJ12023R.
CR Chang H., 2004, COMP VIS PATT REC 20
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
NR 16
TC 3
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4115
EP 4128
DI 10.1007/s11042-015-3016-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200026
DA 2024-07-18
ER

PT J
AU Xiang, T
   Sun, JL
   Fu, XW
AF Xiang, Tao
   Sun, Jianglin
   Fu, Xinwen
TI On the security of binary arithmetic coding based on interval shrinking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arithmetic coding; Joint compression and encryption; Cryptanalysis;
   Interval shrinking
ID ENCRYPTION; COMPRESSION; CRYPTANALYSIS; IMAGES
AB Arithmetic coding (AC) is often chosen for joint compression and encryption. In this paper, we conduct a careful analysis of secure binary AC schemes based on interval shrinking regarding its security. We first give theoretical conditions for our attacks, then under these conditions we are able to recover the plaintext using traditional AC decoder without knowing any shrinking information. The attacks are feasible to uni-shrinking and symmetric bi-shrinking in different AC models. Extensive simulations are carried out and experimental results have validated our theoretical analysis. Effective remedy is also given in the end.
C1 [Xiang, Tao; Sun, Jianglin] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Fu, Xinwen] Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA 01854 USA.
C3 Chongqing University; University of Massachusetts System; University of
   Massachusetts Lowell
RP Xiang, T (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM txiang@cqu.edu.cn
RI Fu, Xinwen/AAP-8640-2021; Xiang, Tao/N-3706-2016
OI Fu, Xinwen/0000-0003-2391-7789; Xiang, Tao/0000-0002-9439-4623
FU Program for New Century Excellent Talents in University [NCET-12-0589];
   National Natural Science Foundation of China [61302161]
FX The work in this paper was supported by the Program for New Century
   Excellent Talents in University (No. NCET-12-0589) and the National
   Natural Science Foundation of China (No. 61302161).
CR [Anonymous], 2007, Introduction to Modern Cryptography: Principles and Protocols
   Asghar MN, 2015, MULTIMED TOOLS APPL, V74, P10215, DOI 10.1007/s11042-014-2160-6
   Bergen H. A., 1992, Computers & Security, V11, P445, DOI 10.1016/0167-4048(92)90011-F
   Bergen H. A., 1993, Computers & Security, V12, P157, DOI 10.1016/0167-4048(93)90099-Q
   Bose R, 2006, IEEE T CIRCUITS-I, V53, P848, DOI 10.1109/TCSI.2005.859617
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   CLEARY JG, 1995, COMPUT SECUR, V14, P167, DOI 10.1016/0167-4048(95)97050-K
   Duan LL, 2011, COMMUN NONLINEAR SCI, V16, P2554, DOI 10.1016/j.cnsns.2010.09.012
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Irvine SA, 1995, WORKING PAPERS U WAI, V95, P1
   Ishibashi H, 2001, P SOC PHOTO-OPT INS, V4475, P222, DOI 10.1117/12.449585
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Katti RS, 2011, IEEE T INF FOREN SEC, V6, P19, DOI 10.1109/TIFS.2010.2096809
   Katti RS, 2012, IEEE T INF FOREN SEC, V7, P895, DOI 10.1109/TIFS.2012.2187514
   Kim H, 2007, IEEE T SIGNAL PROCES, V55, P2263, DOI 10.1109/TSP.2007.892710
   Li HJ, 2009, COMMUN NONLINEAR SCI, V14, P4304, DOI 10.1016/j.cnsns.2009.03.003
   Lian SG, 2008, MULTIMED TOOLS APPL, V38, P75, DOI 10.1007/s11042-007-0150-7
   Lim J, 1997, LECT NOTES COMPUT SC, V1270, P216, DOI 10.1007/BFb0027929
   Liu X, 1997, LECT NOTES COMPUT SC, V1355, P199, DOI 10.1007/BFb0024465
   Liu X, 1999, LECT NOTES COMPUT SC, V1746, P84
   Mi B, 2008, CHAOS SOLITON FRACT, V38, P1523, DOI 10.1016/j.chaos.2007.01.133
   Moffat A, 1998, ACM T INFORM SYST, V16, P256, DOI 10.1145/290159.290162
   Moo PW, 1999, IEEE DATA COMPR CONF, P540, DOI 10.1109/DCC.1999.785697
   Ou SC, 2006, MULTIMED TOOLS APPL, V28, P5, DOI 10.1007/s11042-006-5117-6
   Sun HM, 2009, IEEE T INF FOREN SEC, V4, P781, DOI 10.1109/TIFS.2009.2031944
   Varalakshmi LM, 2013, MULTIMED TOOLS APPL, V64, P717, DOI 10.1007/s11042-011-0963-2
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Witten I. H., 1988, Computers & Security, V7, P397, DOI 10.1016/0167-4048(88)90580-9
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wong KW, 2010, IEEE T CIRCUITS-II, V57, P146, DOI 10.1109/TCSII.2010.2040315
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
   Zhou JT, 2008, INT CONF ACOUST SPEE, P1769
   Zhou JT, 2008, IEEE IMAGE PROC, P3120, DOI 10.1109/ICIP.2008.4712456
   Zhou JT, 2008, IEEE T CIRCUITS-I, V55, P3368, DOI 10.1109/TCSI.2008.924117
   Zhou JT, 2009, IEEE T SIGNAL PROCES, V57, P1825, DOI 10.1109/TSP.2009.2013901
NR 36
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4245
EP 4258
DI 10.1007/s11042-015-2468-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700004
DA 2024-07-18
ER

PT J
AU Chen, Z
   Ma, L
   Xu, L
   Tan, CM
   Yan, YH
AF Chen, Zhuo
   Ma, Lin
   Xu, Long
   Tan, Chengming
   Yan, Yihua
TI Imaging and representation learning of solar radio spectrums for
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Solar radio astronomy; Feature learning; Classification
AB In this paper, the authors make the first attempt to employ the deep learning method for the representation learning of the solar radio spectrums. The original solar radio spectrums are pre-processed, including normalization, enhancement and etc., to generate new images for the next processing. With the expertise of solar radio astronomy for identifying solar radio activity, we build a solar radio activity database, which contains solar radio spectrums as well as their labels indicating the types of solar radio bursts. The employed deep learning network is firstly pre-trained based on the available massive of unlabeled radio solar images. Afterwards, the weights of the network are further fined-tuned based on the labeled data. Experimental results have demonstrated that the employed network can effectively classify the solar radio image into the labeled categories. Moreover, the pre-training process can help improve the classification accuracy.
C1 [Chen, Zhuo; Xu, Long; Tan, Chengming; Yan, Yihua] Chinese Acad Sci, Natl Astron Observ, Key Lab Solar Act, Beijing, Peoples R China.
   [Ma, Lin] Huawei Noahs Ark Lab, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; National Astronomical Observatory, CAS;
   Huawei Technologies
RP Xu, L (corresponding author), Chinese Acad Sci, Natl Astron Observ, Key Lab Solar Act, Beijing, Peoples R China.
EM lxu@nao.cas.cn
RI Yan, Yihua/AGY-9819-2022; Xu, Long/AAH-9908-2019
OI Yan, Yihua/0000-0002-7106-6029; Xu, Long/0000-0002-9286-2876
FU National Natural Science Foundation of China [61202242]; 100-Talents
   Program of Chinese Academy of Sciences [Y434061V01]
FX This work was partially supported by the National Natural Science
   Foundation of China under Grant 61202242, 100-Talents Program of Chinese
   Academy of Sciences (No. Y434061V01).
CR [Anonymous], 2008, ICML
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], NIPS
   [Anonymous], 2012, ICML
   [Anonymous], 2012, 29 INT C MACH LEARN
   [Anonymous], ICCV
   [Anonymous], ICML
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Deng L., 2012, APSIPA transactions on signal and information processing
   Dong J, 2009, IEEE T CIRC SYST VID, V19, P1462, DOI 10.1109/TCSVT.2009.2026792
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fu QJ, 2004, SOL PHYS, V222, P167, DOI 10.1023/B:SOLA.0000036876.14446.dd
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton Geoffrey., 2010, Mo- mentum, V9
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
NR 17
TC 15
Z9 17
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2859
EP 2875
DI 10.1007/s11042-015-2528-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000028
DA 2024-07-18
ER

PT J
AU Ren, TW
   Liu, Y
   Ju, R
   Wu, GS
AF Ren, Tongwei
   Liu, Yan
   Ju, Ran
   Wu, Gangshan
TI How important is location information in saliency detection of natural
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Location information; Patch representation; Saliency
   propagation
ID MODEL; SCALE
AB Location information, i.e., the position of content in image plane, is considered as an important supplement in saliency detection. The effect of location information is usually evaluated by integrating it with the selected saliency detection methods and measuring the improvement, which is highly influenced by the selection of saliency methods. In this paper, we provide direct and quantitative analysis of the importance of location information for saliency detection in natural images. We firstly analyze the relationship between content location and saliency distribution on four public image datasets, and validate the distribution by simply treating location based Gaussian distribution as saliency map. To further validate the effectiveness of location information, we propose a location based saliency detection approach, which completely initializes saliency maps with location information and propagate saliency among patches based on color similarity, and discuss the robustness of location information's effect. The experimental results show that location information plays a positive role in saliency detection, and the proposed method can outperform most state-of-the-art saliency detection methods and handle natural images with different object positions and multiple salient objects.
C1 [Ren, Tongwei; Ju, Ran; Wu, Gangshan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Liu, Yan] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
C3 Nanjing University; Hong Kong Polytechnic University
RP Wu, GS (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM rentw@nju.edu.cn; csyliu@comp.polyu.edu.hk; juran@smail.nju.edu.cn;
   gswu@nju.edu.cn
RI liu, yan/HGV-1365-2022
OI LIU, Yan/0000-0003-4242-4840
FU National Science Foundation of China [61321491, 61202320]; Research
   Project of Excellent State Key Laboratory [61223003]; Natural Science
   Foundation of Jiangsu Province [BK2012304]; National Special Fund
   [2011ZX05035-004-004HZ]
FX The authors would like to thank the anonymous reviewers for the
   associate editor for their valuable comments, which have greatly helped
   us to make improvements, and Jingfan Guo for his contribution in
   experiment. This paper is supported by the National Science Foundation
   of China (No. 61321491, 61202320), Research Project of Excellent State
   Key Laboratory (No. 61223003), Natural Science Foundation of Jiangsu
   Province (No. BK2012304), and National Special Fund (No.
   2011ZX05035-004-004HZ).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], INT C INT MULT COMP
   [Anonymous], 2011, P IEEE MTT S INT MIC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P CIVR
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], MULTIMEDIA SYSTEMS
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2014, COMPUT VISUAL MEDIA
   [Anonymous], 2013, P 5 INT C INT MULT C
   Bao BK, 2012, IEEE T MULTIMEDIA, V14, P199, DOI 10.1109/TMM.2011.2170557
   Barnbaum Bruce., 2010, The Art of Photography: An Approach to Personal Expression
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Ju R., 2014, IEEE INT C IM PROC
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu TS, 2003, CEREB CORTEX, V13, P1334, DOI 10.1093/cercor/bhg080
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Ran Ju, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P418, DOI 10.1007/978-3-319-03731-8_39
   Ren TW, 2009, IEEE INT CON MULTI, P406, DOI 10.1109/ICME.2009.5202520
   Schauerte B, 2013, IEEE IMAGE PROC, P74, DOI 10.1109/ICIP.2013.6738016
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Zha Z. -J., 2008, IEEE C COMPUTER VISI, P1
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhongyan Qiu, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P200, DOI 10.1007/978-3-319-03731-8_19
   Zhou WG, 2011, PATTERN RECOGN, V44, P2263, DOI 10.1016/j.patcog.2010.08.016
NR 50
TC 13
Z9 14
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2543
EP 2564
DI 10.1007/s11042-015-2875-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000009
DA 2024-07-18
ER

PT J
AU Nikolaidis, A
AF Nikolaidis, Athanasios
TI Low overhead reversible data hiding for color JPEG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; JPEG compression; Quantized coefficients;
   Coefficient histogram
ID WATERMARKING; SCHEME
AB The current paper describes a new technique for embedding secret data in JPEG compressed color digital images. Emphasis is given in improving effective payload percentage over file size increase while retaining low distortion levels. The proposed technique is based on modification of non-zero quantized coefficients. In contrast to previously proposed techniques, the present one does not require the use of non-standard Huffman tables. Apart from that, no side information needs to be included in a JPEG header to assist the decoder in extracting the hidden message. The main idea behind the technique is to create zero population bins in the coefficient histogram in order to accommodate the secret message bits. Specifically, all coefficients whose absolute value is L are modified by 1 in the direction of their sign when a bit 1 is to be embedded or are not modified when a bit 0 is to be embedded. Coefficients with absolute values greater than L are also incremented by one in the direction of their sign, so that they are not confused with coefficients where embedding has occurred. At the side of the decoder, both the message bits can be extracted from coefficients with absolute values L and L+1, and the original image can be restored by shifting all coefficients with absolute value greater than L in the opposite direction of their sign. The results show significant improvement in comparison with representative state-of-the-art techniques, in terms of ratio of payload over file size increase.
C1 [Nikolaidis, Athanasios] Technol Educ Inst Cent Macedonia, Dept Comp Engn, Terma Magnesias Str, Serres 62124, Greece.
RP Nikolaidis, A (corresponding author), Technol Educ Inst Cent Macedonia, Dept Comp Engn, Terma Magnesias Str, Serres 62124, Greece.
EM nikolaid@teiser.gr
RI Nikolaidis, Athanasios/T-7349-2019
OI Nikolaidis, Athanasios/0000-0002-8732-4475
FU Research Committee of the Technological Educational Institute of Central
   Macedonia, Greece [SAT/IC/15-5-13-86/2]
FX A. Nikolaidis wishes to acknowledge financial support provided by the
   Research Committee of the Technological Educational Institute of Central
   Macedonia, Greece, under grant SAT/IC/15-5-13-86/2.
CR [Anonymous], IEEE T CONSUM ELECTR
   [Anonymous], P IEEE INT C IM PROC
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen B, 2013, MULTIMED TOOLS APPL, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Efimushkina T, 2013, EUVIP 13, P94
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Huang SC, 2010, J MED BIOL ENG, V30, P289, DOI 10.5405/jmbe.30.5.04
   Kuo W., 2012, Importance Measures in Reliability, Risk, and Optimization: Principles and Applications, V1st, P1
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Liao GL, 2012, ADV MATER RES-SWITZ, V433-440, P4615, DOI 10.4028/www.scientific.net/AMR.433-440.4615
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin CH, 2009, PR ELECTROMAGN RES S, P327, DOI 10.1145/1516241.1516298
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Saha B, 2012, DEF SCI J, V62
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2004, INFORMATICA-LITHUAN, V15, P127
   Wong PHW, 2001, PROC SPIE, V4314, P309, DOI 10.1117/12.435412
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 22
TC 14
Z9 15
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1869
EP 1881
DI 10.1007/s11042-014-2377-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000006
DA 2024-07-18
ER

PT J
AU Zhang, SL
   Zhang, JF
   Guo, P
   Chu, M
   Chang, KH
AF Zhang, Sulan
   Zhang, Jifu
   Guo, Ping
   Chu, Meng
   Chang, Kai H.
TI A FWCL-based method for visual vocabulary formation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BOV(bag-of-visterms); Visual vocabulary; Frequency weighted concept
   lattice (FWCL); Scene classification
ID CONCEPT LATTICES; CLASSIFICATION
AB Traditional BOV (bag-of-visterms) constructing methods ignore different visual words' contributions to image representation. Moreover, the size of visual vocabulary is generally set according to experience. Frequent weighted concept lattice (FWCL) is an interesting version of the concept lattice, and helps realize knowledge extraction in a more efficient way. In this paper, we present a dynamic refinement method for visual vocabulary formation based on frequency weighted concept lattice (FWCL) by using its characteristic of hierarchical data analysis and reduction. The original visual words' weight value is assigned with information entropy, and FWCLs of each semantic category are constructed. According to the extent thresholds, each category of visual vocabulary is built and combined to generate the reduced global visual vocabulary for image representation. By adjusting the extent thresholds, different sizes of reduced visual vocabularies are dynamically extracted from this type of hierarchical structure. Lastly, experiments are carried on the two commonly used datasets, and experimental results show the effectiveness of our method on the scene classification.
C1 [Zhang, Sulan; Zhang, Jifu; Chu, Meng] Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Peoples R China.
   [Guo, Ping] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Chang, Kai H.] Auburn Univ, Dept Comp Sci & Software Engn, Auburn, AL 36849 USA.
C3 Taiyuan University of Science & Technology; Beijing Institute of
   Technology; Auburn University System; Auburn University
RP Zhang, SL (corresponding author), Taiyuan Univ Sci & Technol, Sch Comp Sci & Technol, Taiyuan 030024, Peoples R China.
EM zhsulan@126.com
RI guo, peng/AAG-4052-2019; GUO, Ping/AAG-2160-2019; Guo,
   Peng/IZQ-0331-2023; Guo, Peng/GWC-0572-2022; GUO, Ping/A-3482-2015
OI GUO, Ping/0000-0002-7122-1084; GUO, Ping/0000-0002-7122-1084
FU National Science Foundation of PR China [61373099, 60773014, 61073145,
   58260910306052]; Natural Science Foundation of Shanxi Province, of P.R.
   China [2010011021-2]
FX This work was partially supported by the National Science Foundation of
   PR China (grant nos. 61373099, 60773014, 61073145, 58260910306052), the
   Natural Science Foundation of Shanxi Province, of P.R. China (grant no.
   2010011021-2).
CR [Anonymous], 2007, CIVR '07
   Bai S, 2013, MACH VISION APPL, V24, P959, DOI 10.1007/s00138-012-0473-x
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bo L., 2011, Neural Information Processing Systems, P2115
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Cai HP, 2010, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2010.5539918
   Chen YH, 2008, INFORM SCIENCES, V178, P1, DOI 10.1016/j.ins.2007.08.011
   Cimiano P, 2005, J ARTIF INTELL RES, V24, P305, DOI 10.1613/jair.1648
   de Campos T, 2012, COMPUT VIS IMAGE UND, V116, P68, DOI 10.1016/j.cviu.2011.07.011
   Fan WT, 2013, PATTERN RECOGN, V46, P2754, DOI 10.1016/j.patcog.2013.03.026
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Formica A, 2006, INFORM SCIENCES, V176, P2624, DOI 10.1016/j.ins.2005.11.014
   Fu ZY, 2012, MULTIMED TOOLS APPL, V56, P535, DOI 10.1007/s11042-010-0616-x
   Gély A, 2009, INFORM SCIENCES, V179, P2729, DOI 10.1016/j.ins.2009.03.018
   Gosselin PH, 2011, PATTERN RECOGN, V44, P2244, DOI 10.1016/j.patcog.2010.12.006
   Gu GH, 2011, EXPERT SYST APPL, V38, P11273, DOI 10.1016/j.eswa.2011.02.174
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hou J, 2013, PATTERN RECOGN, V46, P3129, DOI 10.1016/j.patcog.2013.04.005
   Kumar CA, 2010, EXPERT SYST APPL, V37, P2696, DOI 10.1016/j.eswa.2009.09.026
   Kwon O, 2009, EXPERT SYST APPL, V36, P1893, DOI 10.1016/j.eswa.2007.12.064
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6
   Li TQ, 2008, INT OFFSHORE POLAR E, P1
   Liu JG, 2007, IEEE I CONF COMP VIS, P298
   Liu L, 2012, PATTERN RECOGN, V45, P2405, DOI 10.1016/j.patcog.2011.10.027
   Liu NN, 2013, COMPUT VIS IMAGE UND, V117, P493, DOI 10.1016/j.cviu.2012.10.009
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallapragada PK, 2010, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2010.5540062
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Shi MJ, 2013, IEEE T IMAGE PROCESS, V22, P1209, DOI 10.1109/TIP.2012.2228494
   Stumme G, 2002, DATA KNOWL ENG, V42, P189, DOI 10.1016/S0169-023X(02)00057-5
   Uijlings JRR, 2012, INT J COMPUT VISION, V96, P46, DOI 10.1007/s11263-011-0443-1
   WILLE R, 1982, ORDERED SETS, P415
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Zhang S., 2011, P 2011 IEEE INT C CO, P1
   Zhang SL, 2012, DATA KNOWL ENG, V81-82, P104, DOI 10.1016/j.datak.2012.08.002
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
NR 40
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 647
EP 665
DI 10.1007/s11042-014-2313-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500029
DA 2024-07-18
ER

PT J
AU Hasan, MA
   Xu, M
   He, XJ
   Wang, Y
AF Hasan, Muhammad Abul
   Xu, Min
   He, Xiangjian
   Wang, Yi
TI A camera motion histogram descriptor for video shot classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera motion descriptor; Motion characterization; Shot classification;
   Singular value decomposition
ID MODEL; FRAMEWORK
AB In this paper, a novel camera motion descriptor is proposed for video shot classification. In the proposed method, raw motion information of consecutive video frames are extracted by computing the motion vector of each macroblock to form motion vector fields (MVFs). Next, a motion consistency analysis is applied on MVFs to eliminate the inconsistent motion vectors. Then, MVFs are divided into nine (3 x 3) local regions and the singular value decomposition (SVD) technique is applied on the motion vectors extracted from each local region in the temporal direction. Consistent motion vectors of a number of MVFs are compactly represented at a time to characterize temporal camera motion. Accordingly, each local region of the whole video shot is represented using a sequence of compactly represented vectors. Finally, the sequence of vectors is converted into a histogram to describe the camera motions of each local region. Combination of all the local histograms is considered as the camera motion descriptor of a video shot. The shot descriptors are used in a classifier to classify video shots. In this work, we use support vector machine (SVM) for performing classification tasks. The experimental results show that the proposed camera motion descriptor has strong discriminative capability to classify different camera motion patterns in professionally captured video shots effectively. We also show that our proposed approach outperforms two state-of-the-art video shot classification methods.
C1 [Hasan, Muhammad Abul; Xu, Min; He, Xiangjian] Univ Technol Sydney, Res Ctr Innovat IT Serv & Applicat iNEXT, Sydney, NSW 2007, Australia.
   [Wang, Yi] Dalian Univ Technol, Sch Software, Dalian, Peoples R China.
C3 University of Technology Sydney; Dalian University of Technology
RP He, XJ (corresponding author), Univ Technol Sydney, Res Ctr Innovat IT Serv & Applicat iNEXT, Sydney, NSW 2007, Australia.
EM muhammadabul.hasan@student.uts.edu.au; min.xu@uts.eud.au;
   xiangjian.he@uts.edu.au; wangyi_dlut@126.com
RI Hasan, Muhammad Hasibul/KRP-2193-2024; He, Xiangjian/CAA-1461-2022
OI Xu, Min/0000-0001-9581-8849; He, Xiangjian/0000-0001-8962-540X
FU UTS International Research Scholarship; Specialized Research Fund for
   the Doctoral Program of Higher Education of China [20120041120050]
FX We would like to thank the reviewers for the valuable comments. This
   work is partly supported by a UTS International Research Scholarship,
   and the Specialized Research Fund for the Doctoral Program of Higher
   Education of China (20120041120050).
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Almeida J, 2009, LECT NOTES COMPUT SC, V5875, P435, DOI 10.1007/978-3-642-10331-5_41
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bhattacharya S, 2014, IEEE T MULTIMED
   Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Canini L, 2013, MULTIMED TOOLS APPL, V62, P51, DOI 10.1007/s11042-011-0916-9
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Duan LY, 2006, IEEE T MULTIMEDIA, V8, P323, DOI 10.1109/TMM.2005.864344
   Duric Z, 1996, REAL-TIME IMAGING, V2, P271, DOI 10.1006/rtim.1996.0029
   Ewerth R, 2004, INT C PATT RECOG, P512, DOI 10.1109/ICPR.2004.1334181
   Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674
   Friedman Jerome H., 1996, Technical Report
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Jin R, 2002, INT C PATT RECOG, P859, DOI 10.1109/ICPR.2002.1048160
   Kim JG, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1171, DOI 10.1109/ICME.2000.871569
   Lan DJ, 2003, IEEE IMAGE PROC, P289
   Lee S, 2002, INT CONF ACOUST SPEE, P3664
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Minetto R, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P435
   Ngo CW, 2003, IEEE T IMAGE PROCESS, V12, P341, DOI 10.1109/TIP.2003.809020
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Nhat-Tan Nguyen, 2010, International Journal of Intelligent Systems Technologies and Applications, V9, P228, DOI 10.1504/IJISTA.2010.036578
   Oh JH, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P81, DOI 10.1109/ICME.2002.1035723
   Shugao Ma, 2010, 2010 International Conference on Networking, Sensing and Control (ICNSC 2010), P111, DOI 10.1109/ICNSC.2010.5461530
   Sun XD, 2001, LECT NOTES COMPUT SC, V2195, P450
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Tok M, 2013, IEEE T CIRC SYST VID, V23, P607, DOI 10.1109/TCSVT.2012.2211173
   Vapnik V., 1999, NATURE STAT LEARNING
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yao Y-S, 1995, DTIC DOCUMENT
NR 36
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11073
EP 11098
DI 10.1007/s11042-014-2218-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600006
DA 2024-07-18
ER

PT J
AU Karimi, N
   Samavi, S
   Amraee, S
   Shirani, S
AF Karimi, N.
   Samavi, S.
   Amraee, S.
   Shirani, S.
TI Use of symmetry in prediction-error field for lossless compression of 3D
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; 3D MRI; Compression; Lossless; Context modeling
AB Three dimensional MRI images which are powerful tools for diagnosis of many diseases require large storage space. A number of lossless compression schemes exist for this purpose. In this paper we propose a new approach for lossless compression of these images which exploits the inherent symmetry that exists in 3D MRI images. First, an efficient pixel prediction scheme is used to remove correlation between pixel values in an MRI image. Then a block matching routine is employed to take advantage of the symmetry within the prediction error image. Inter-slice correlations are eliminated using another block matching. Results of the proposed approach are compared with the existing standard compression techniques.
C1 [Karimi, N.; Samavi, S.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, S.; Shirani, S.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Amraee, S.] Univ Isfahan, Dept Comp Engn, Esfahan, Iran.
C3 Isfahan University of Technology; McMaster University; University of
   Isfahan
RP Shirani, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM nader_karimi_80@yahoo.com; samavi1996@gmail.com;
   somaie.amraee@gmail.com; shirani@mcmaster.ca
RI Karimi, Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607
CR Amraee S, 2011, IEEE INT CON MULTI
   [Anonymous], 2007, 1544410 ISOIEC JTC1S
   [Anonymous], DICOM SAMPL IM SETS
   Bilgin A, 2000, APPL OPTICS, V39, P1799, DOI 10.1364/AO.39.001799
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533
   Kim Y., 1998, P SPIE APPL DIGITAL, P305
   Klappenecker A, 1998, P SPIE WAVELET APPL, V3458
   Memon N, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P309, DOI 10.1109/ISCAS.1996.541708
   Memon N, 1997, COMPUT J, V40, P127, DOI 10.1093/comjnl/40.2_and_3.127
   Nosratinia A, 1996, IEEE T MED IMAGING, V15, P639, DOI 10.1109/42.538941
   Qi XJ, 2005, INFORM SCIENCES, V175, P217, DOI 10.1016/j.ins.2005.01.008
   Sanchez V, 2009, IEEE T MED IMAGING, V28, P1062, DOI 10.1109/TMI.2009.2012899
   Speck D., 1995, ISO Working Document ISO/IEC JTCI/SC29/WGl N198
   Speck D, 1995, P IEEE AS C SIGN SYS, V1, P234, DOI 10.1109/ACSSC.1995.540547
   Srikanth R, 2005, IEEE T MED IMAGING, V24, P1199, DOI 10.1109/TMI.2005.853638
   Van Assche S., 2000, Proceedings DCC 2000. Data Compression Conference, DOI 10.1109/DCC.2000.838222
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wong YF, 1996, INT CONF ACOUST SPEE, P2128, DOI 10.1109/ICASSP.1996.545736
   Wu D, 2000, ELECTRON LETT, V36, P207, DOI 10.1049/el:20000227
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Yodchanan W, 2008, P INT C AUD LANG IM, P1560
NR 23
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11007
EP 11022
DI 10.1007/s11042-014-2214-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600003
DA 2024-07-18
ER

PT J
AU Chen, CM
   Chen, LH
AF Chen, Chun-Min
   Chen, Ling-Hwei
TI A novel method for slow motion replay detection in broadcast basketball
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Basketball; Broadcast video; Slow motion replay detection; Sports video
   summarization
AB Slow motion replays are valuable for sports video analysis. Many methods for slow motion replay detection have been proposed, and they are classified into two categories. One assumes that a replay is sandwiched by a pair of visually similar special digital video effects, but the assumption is not always true in basketball videos. The other analyzes replay features to distinguish replay segments from non-replay segments. The results are not satisfactory since some features (e.g. dominant color of sports field) are not applicable for basketball. Most replay detectors focus on soccer videos. In this paper, we propose a novel idea to detect slow motion replays in basketball videos. The existence of scoreboard is referred to filter large amount of non-replay frames, this improves detection accuracy. After scoreboard frame filtering, every consecutive non-scoreboard frame sequence bounded by scoreboard frames are considered as a non-scoreboard segment. Characteristics of replays and non-replays are observed to create features, which can be used to detect replays and prune non-replays from non-scoreboard segments. Experimental results show that the proposed replay detection method is applicable for both kinds of basketball videos with/without TV commercials. As compared with previous researches for basketball videos, our method presents the superior performance.
C1 [Chen, Chun-Min; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 30010, Taiwan.
EM cmchen.nctu@gmail.com; lhchen@cc.nctu.edu.tw
FU National Science Council of Republic of China
   [NSC-100-2221-E-009-140-MY2]
FX This work is supported in part by National Science Council of Republic
   of China under grant NSC-100-2221-E-009-140-MY2.
CR [Anonymous], 2009, ACM INT C MULT
   Chen F, 2011, IEEE T CIRC SYST VID, V21, P193, DOI 10.1109/TCSVT.2011.2106271
   Chen F, 2010, IEEE IMAGE PROC, P565, DOI 10.1109/ICIP.2010.5652750
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Farn EJ, 2003, INT J PATTERN RECOGN, V17, P1467, DOI 10.1142/S0218001403002964
   Huang Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1695
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Satterwhite B, 2004, IEEE POTENTIALS, V23, P9, DOI 10.1109/MP.2004.1309790
   Su YM, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1829, DOI 10.1109/ICME.2006.262909
   Wang L, 2004, IEEE IMAGE PROC, P1585
   Xiaofeng Tong, 2004, Proceedings. Third International Conference on Image and Graphics, P337
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   Zhao F, 2012, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2012.6288154
NR 13
TC 11
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9573
EP 9593
DI 10.1007/s11042-014-2137-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200024
DA 2024-07-18
ER

PT J
AU Yilmazyildiz, S
   Verhelst, W
   Sahli, H
AF Yilmazyildiz, Selma
   Verhelst, Werner
   Sahli, Hichem
TI Gibberish speech as a tool for the study of affective expressiveness for
   robotic agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vocal emotion expression; Speech without semantic information; Human
   robot interaction; Expressive speech; Expressive gibberish speech; Voice
   modification
AB Recent technological advancements bring virtual agents, avatars, and social robotic characters into our daily lives. These characters must acquire the ability to express (simulated) emotions vocally and gesturally. In the vocal channel, Natural Language Interaction technologies today have some limitations when used in real-world natural environments and the models of expressivity of text to speech synthesis engines are not yet mature enough. To address these limitations, an alternative form of vocal communication - gibberish speech - is introduced in this paper. Gibberish speech consists of vocalizations of meaningless strings of speech sounds, and thus has no semantic meaning. It is occasionally used by performing artists or for cartoon animations and games to express intended emotions (e.g. Teletubbies and The Sims). In this paper, our approach for constructing expressive gibberish speech is described and the experimental evaluations with its intended robotic agents are reported. It is shown that the generated gibberish speech can contribute to a significant extent to studies concerning emotion expression for robotic agents and can be further utilized in affective human-robot interaction studies.
C1 [Yilmazyildiz, Selma; Verhelst, Werner; Sahli, Hichem] Vrije Univ Brussel, Dept Elect & Informat, Brussels, Belgium.
   [Verhelst, Werner] iMinds, Future Media & Imaging Dept, Ghent, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
C3 Vrije Universiteit Brussel; IMEC; IMEC
RP Yilmazyildiz, S (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, Brussels, Belgium.
EM syilmazy@etro.vub.ac.be; wverhels@etro.vub.ac.be; hsahli@vub.ac.be
RI YILMAZYILDIZ KAYAARMA, Selma/IWE-0237-2023
OI YILMAZYILDIZ KAYAARMA, Selma/0000-0001-7315-3639; Sahli,
   Hichem/0000-0002-1774-2970
FU Research counsel of the Vrije Universiteit Brussel [HOA16]; European
   Commission (EU) [ICT-248116]
FX The research reported in this paper was supported in part by the
   Research counsel of the Vrije Universiteit Brussel with horizontale
   onderzoeksactie HOA16 and by the European Commission (EU-FP7 project
   ALIZ-E, ICT-248116).
CR [Anonymous], 2008, ARXIV08073223 CS
   [Anonymous], ICGST INT J AUT ROB
   [Anonymous], 2000, SOCIABLE MACHINES EX
   [Anonymous], 2008, J PHYS AGENTS, DOI DOI 10.14198/JoPha.2008.2.2.02
   Argyrous George., 2005, STAT RES
   Bamidis PD, 2007, MEDINFO 2007
   Breazeal C, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1388, DOI 10.1109/IROS.2001.977175
   BURLESON W, 2006, THESIS MIT
   Busso C., 2008, Second International Workshop on Emotion: Corpora for Research on Emotion and Affect, International Conference on Language Resources and Evaluation (LREC 2008), P17
   Carlson R, 1991, ESCA WORKSH SPEECH S
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Corveleyn S, 2002, IEEE BEN WORKSH MOD
   Goodrich Michael A., 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Jee ES, 2010, INTEL SERV ROBOT, V3, P199, DOI 10.1007/s11370-010-0070-7
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Latacz L, 2008, P INT BLIZZ CHALL
   Libin AV, 2004, P IEEE, V92, P1789, DOI 10.1109/JPROC.2004.835366
   Lisetti C, 2003, INT J HUM-COMPUT ST, V59, P245, DOI 10.1016/S1071-5819(03)00051-X
   Luneski A, 2010, METHOD INFORM MED, V49, P207, DOI 10.3414/ME0617
   Mubin O, 2009, SPOK DIAL HUM ROB IN
   Nijholt A, 2007, P INT C ADV COMP ENT
   Olive J, 1987, CHANGING VOICE CHARA
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Prendinger H, 2004, P WORKSH HCI HOM CIT
   Project Gutenberg, 1971, Project gutenberg
   Read R, 2012, ACMIEEE INT CONF HUM, P219
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek
   Saldien J, 2010, INT J SOC ROBOT, V2, P377, DOI 10.1007/s12369-010-0067-6
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Schroder M., 2001, Proceedings: 7th European Conference on Speech Communication and Technology (EUROSPEECH), P87
   Schroder M, 2003, THESIS U SAARLAND
   Schröder M, 2009, AFFECTIVE INFORMATION PROCESSING, P111, DOI 10.1007/978-1-84800-306-4_7
   Smith R. N., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P843
   Verhelst W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P554, DOI 10.1109/ICASSP.1993.319366
   Wang W, 2014, NATURAL EMO IN PRESS
   Winters RM, 2013, P 3 INT C MUS EM ICM
   Yang PF, 1998, P ICSLP CIT SYDN AUS, P1667
   Yilmazyildiz S, 2013, WORKSH AFF SOC SPEEC
   Yilmazyildiz S, 2006, LECT NOTES COMPUT SC, V4261, P1
   Yilmazyildiz S, 2011, LECT NOTES COMPUT SC, V6975, P163, DOI 10.1007/978-3-642-24571-8_17
   Yilmazyildiz S, 2010, LECT NOTES ARTIF INT, V6231, P584, DOI 10.1007/978-3-642-15760-8_74
NR 41
TC 5
Z9 5
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9959
EP 9982
DI 10.1007/s11042-014-2165-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400008
DA 2024-07-18
ER

PT J
AU Lin, PJ
   Chen, SC
   Yeh, CH
   Chang, WC
AF Lin, Pei-Jung
   Chen, Sheng-Chang
   Yeh, Chuan-Heng
   Chang, Wei-Cheng
TI Implementation of a smartphone sensing system with social networks: a
   location-aware mobile application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-aware service; Mobile social networks; Smart phone; Social game
ID PHONE
AB This study designed a web-integrated, cross-platform communications interface based on smartphone technology to overcome many of the difficulties inherent in visiting crowded public spaces, events, or exhibitions. The goal was to provide an alternative to the standard tour itinerary with a location-specific, customized tour guide system that also makes use of social networks to locate friends. The proposed mobile application features are a photo sharing platform, a friend-finder radar system (linked to Facebook), an interactive game, and a location-based services (LBS) mobile advertising filter. The Taipei International Flora Exposition was used as an example of a public space to evaluate the proposed system.
C1 [Lin, Pei-Jung] Hungkuang Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Chen, Sheng-Chang] Ursa Pictor Co, Taichung, Taiwan.
   [Yeh, Chuan-Heng; Chang, Wei-Cheng] RAI Co, Taichung, Taiwan.
C3 Hungkuang University
RP Chen, SC (corresponding author), Ursa Pictor Co, Taichung, Taiwan.
EM pjlin@sunrise.hk.edu.tw; jack.scchen@gmail.com; adam@rai.dscloud.me;
   bang@rai.dscloud.me
OI Lin, Pei-Jung/0000-0002-4451-7533
FU National Science Council (NSC) of the Republic of China, Taiwan
   [NSC102-2622-E-241-003-CC3, NSC 102-2221-E-241-012]
FX The authors would like to thank the National Science Council (NSC) of
   the Republic of China, Taiwan, for financially supporting this research
   under Contract No. NSC102-2622-E-241-003-CC3 and NSC 102-2221-E-241-012.
CR Ballagas R, 2006, IEEE PERVAS COMPUT, V5, P70, DOI 10.1109/MPRV.2006.18
   Cheng R, 2010, P 3 INT S PAR ARCH A
   Freyne J, 2009, P IEEE INT C SOC COM
   Han Y, 2012, IEEE COMMUN MAG, V50, P106, DOI 10.1109/MCOM.2012.6178842
   Huang JC, 2009, P 2009 C INF TECHN A
   Jain A, 2011, IEEE WIREL COMMUN, V18, P4, DOI 10.1109/MWC.2011.5999758
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Park F, 2010, P 10 IEEE IPSJ INT S, P145
   Roh JH, 2012, P 14 INT C ADV COMM, P1300
   Swanson S, 2011, IEEE COMMUN MAG, V49, P112, DOI 10.1109/MCOM.2011.5741155
   Tsai AG, 2009, THESIS NATL TAIPEI U
   XIN C, 2009, P INT JOINT C ART IN, P50, DOI DOI 10.1109/JCAI.2009.203
   Yu XX, 2007, THESIS NATL KAOHSIUN
NR 13
TC 4
Z9 4
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8313
EP 8324
DI 10.1007/s11042-013-1782-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600005
DA 2024-07-18
ER

PT J
AU Li, HD
   Luo, WQ
   Huang, JW
AF Li, Haodong
   Luo, Weiqi
   Huang, Jiwu
TI Anti-forensics of double JPEG compression with the same quantization
   matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double JPEG compression; Anti-forensics; Digital forensics
ID STEGANALYSIS
AB Double JPEG compression detection plays an important role in digital image forensics. Recently, Huang et al. (IEEE Trans Inf Forensics Security 5(4):848-856, 2010) first pointed out that the number of different discrete cosine transform (DCT) coefficients would monotonically decrease when repeatedly compressing a JPEG image with the same quantization matrix, and a strategy based on random permutation was developed to expose such an operation successfully. In this paper, we propose an anti-forensic method to fool this method. The proposed method tries to slightly modify the DCT coefficients for confusing the traces introduced by double JPEG compression with the same quantization matrix. By investigating the relationship between the DCT coefficients of the first compression and those of the second one, we determine the quantity of modification by constructing a linear model. Furthermore, in order to improve the security of anti-forensics, the locations of modification are adaptively selected according to the complexity of the image texture. The extensive experiments evaluated on 10,000 natural images have shown that the proposed method can effectively confuse the detector proposed in Huang et al. (IEEE Trans Inf Forensics Security 5(4):848-856, 2010), while keeping higher visual quality and leaving fewer other detectable statistical artifacts.
C1 [Li, Haodong] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Weiqi] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Shenzhen University
RP Luo, WQ (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM lihaod@mail2.sysu.edu.cn; weiqi.luo@yahoo.com; jwhuang@szu.edu.cn
RI huang, jw/KVY-9917-2024; Li, Haodong/AAG-7592-2019
OI Li, Haodong/0000-0003-0532-9481
FU National Science & Technology Pillar Program [2012BAK16B06]; NSFC
   [U1135001, 61332012, 61272191]; Zhujiang Science and Technology
   [2011J2200091]; Guangdong NSF [S2013010012039]
FX This work is supported in part by National Science & Technology Pillar
   Program (No:2012BAK16B06), NSFC (U1135001, 61332012, 61272191), the
   funding of Zhujiang Science and Technology (2011J2200091) and the
   Guangdong NSF (S2013010012039). The authors would like to thank the
   reviewers for their valuable comments.
CR [Anonymous], 2011, SOFTWARE STAT PATTER
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 2011, P 13 INF HID C PRAG
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Feng CH, 2012, INT CONF INFORM SCI, P159, DOI 10.1109/ISISE.2012.41
   Huang F, 2011, IET INFORM SECUR, V5, P10, DOI 10.1049/iet-ifs.2009.0080
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li HD, 2012, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2012.6466840
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Milani S, 2013, INT CONF ACOUST SPEE, P3053, DOI 10.1109/ICASSP.2013.6638219
   Pasquini C, 2013, IEEE INT WORKSH MULT, P500, DOI 10.1109/MMSP.2013.6659339
   Qian ZX, 2013, J COMPUT, V8, P2483, DOI 10.4304/jcp.8.10.2483-2488
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Sutthiwan Patchara, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P411, DOI 10.1007/978-3-642-32205-1_33
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
NR 24
TC 9
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6729
EP 6744
DI 10.1007/s11042-014-1927-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800008
DA 2024-07-18
ER

PT J
AU Kang, SJ
   Kim, SK
AF Kang, Shin Jin
   Kim, Soo Kyun
TI Automated spatio-temporal analysis techniques for game environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game analytics; Data mining; Online game
AB This paper introduces spatio-temporal analysis techniques for games. Game analytics is emerging field in Business Insight (BI) area. The benefits of adopting game analytics technique in commercial game development can help decision making in game design and quality assurance which are not quantified yet. For last 10 years, researchers in game user research area have proposed the frontier of techniques in game analytic field. Among them, spatio-temporal analysis field is most important for understanding of users in game environments intuitively. In this paper, we summarize four key areas of spatio-temporal analysis: visualization techniques, trajectory analysis, in-house telemetry system, and web-based middlewares in detail.
C1 [Kang, Shin Jin] Hongik Univ, Sch Games, Seoul, South Korea.
   [Kim, Soo Kyun] Paichai Univ, Dept Game Engn, Taejon 302735, South Korea.
C3 Hongik University; Pai Chai University
RP Kim, SK (corresponding author), Paichai Univ, Dept Game Engn, 1 14 Yeon Ja 1Gil Seo Gu, Taejon 302735, South Korea.
EM directx@hongik.ac.kr; kimsk@pcu.ac.kr
OI Kim, Soo Kyun/0000-0001-6071-8231
FU National Research Foundation of Korea - Korean Government
   [2012R1A1A1012895]
FX This work was supported by National Research Foundation of Korea Grant
   funded by the Korean Government (No. 2012R1A1A1012895)
CR Borner K., 2003, Information Visualization, V2, P182, DOI 10.1057/palgrave.ivs.9500050
   Chen KT, 2008, P ACM NETGAMES
   Chittaro L, 2006, IEEE T VIS COMPUT GR, V12, P1475, DOI 10.1109/TVCG.2006.109
   DeRosa, TRACK PLAY FEEDB IMP
   Drachen Anders, 2009, 2009 IEEE Symposium on Computational Intelligence and Games (CIG), P1, DOI 10.1109/CIG.2009.5286500
   Hoobler N, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P163, DOI 10.1109/VISUAL.2004.120
   Kang S.J., 2012, MULTIMED TOOLS APPL, V58, P1
   Kim JH, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P443
   Medler B, 2011, P CHI
   Oda Junichi, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1134, DOI 10.1109/IIH-MSP.2009.288
   Thawonmas R, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/906931
   Thawonmas Ruck., 2007, The International Journal of Virtual Reality, V6, P11
   Zoeller Georg, 2010, GDC 2010
NR 13
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6323
EP 6329
DI 10.1007/s11042-014-2121-0
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700013
DA 2024-07-18
ER

PT J
AU Goswami, K
   Kim, BG
   Lee, JB
   Jun, DS
   Choi, JS
AF Goswami, Kalyan
   Kim, Byung-Gyu
   Lee, Jeong-Bae
   Jun, Dong-San
   Choi, Jin Soo
TI Fast video encoding algorithm for efficient social media service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Early skip; HEVC; Fast mode decision; Social media; Adaptive
   thresholding
AB The Semantic Web, or web 3.0, is driving the evolution of internet by enabling more interaction with users of multimedia data. ITU-T/VCEG and ISO/IEC MPEG have recently completed a new joint standardization activity on video coding, called High Efficiency Video Coding (HEVC). In order to achieve the promise of Semantic Web, HEVC needs to provide good video data quality to end user in real time. This new standard contains significant improvements in picture quality for high resolution video. Main challange in this standard is the required computational time. In this paper, a novel early skip detection technique to reduce the encoder time is proposed based on statistical modeling. The proposed method was implemented on HM 7.0 reference software and experimental results show that the technique provides superior results for time reduction with only a marginal quality loss with all fast options set to "ON".
C1 [Goswami, Kalyan; Kim, Byung-Gyu; Lee, Jeong-Bae] SunMoon Univ, Dept Comp Engn, Asan, South Korea.
   [Jun, Dong-San; Choi, Jin Soo] ETRI, Visual Media Res Lab, Taejon, South Korea.
C3 Sun Moon University; Electronics & Telecommunications Research Institute
   - Korea (ETRI)
RP Kim, BG (corresponding author), SunMoon Univ, Dept Comp Engn, Asan, South Korea.
EM kalyan_goswami@mpcl.sunmoon.ac.kr; bg.kim@mpcl.sunmoon.ac.kr;
   jblee@mpcl.sunmoon.ac.kr; dschun@etri.re.kr; jschoi@etri.re.kr
FU KCC (Korea Communications Commission), Korea, under the ETRI R&D support
   program [KCA-2012-11921-02001]
FX This research was supported by the KCC (Korea Communications
   Commission), Korea, under the ETRI R&D support program supervised by the
   KCA (Korea Communications Agency) (KCA-2012-11921-02001).
CR [Anonymous], INT C MULT SIGN PROC
   Brahami M, 2013, J INF PROCESS SYST, V9, P1, DOI 10.3745/JIPS.2013.9.1.001
   Budagavi M, 2011, INT C IM PROC ICIP B
   Chen WJ, 2011, INT S INT SIGN PROC
   Choi K., 2011, document JCTVC-F092 of JCT-VC
   Fu CM, 2011, IEEE INT WORKSH MULT
   Jang E. S., 2012, OPT ENG LETT
   Kim J, 2012, INT C CONS EL ICCE L
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Lee B, 2011, IEEE SIGNAL PROC LET, V18, P571, DOI 10.1109/LSP.2011.2163935
   Lee C-L, 2011, INT C IM PROC ICIP B
   Lee Y-L, JCTVCF045, P14
   Lin JL, 2011, IEEE INT WORKSH MULT
   Naccari M, 2011, INT C IM PROC ICIP B
   Peng X, 2011, INT C VIS COMM IM PR
   Sharma MJ, 2012, HUMAN CENTRIC COMPUT
   Sullivan G. J., 2012, IEEE T CIRC SYST VID
   Tan YH, 2011, IEEE INT WORKSH MULT
   Teng S-W, 2011, INT C VIS COMM IM PR
   Van Wallendael G, 2011, IEEE INT CON MULTI
   Werth D, 2012, J CONVERG JOC, V3
   Winken M, 2011, IEEE IMAGE PROC
   Yang J., 2011, JCTVCG543
   Yeo C, 2011, INT C IM PROC ICIP B
   Zhao L, 2011, INT C VIS COMM IM PR
   Zou F, 2011, INT C VIS COMM IM PR
NR 26
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5157
EP 5171
DI 10.1007/s11042-013-1728-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900011
DA 2024-07-18
ER

PT J
AU Kim, C
   Yang, CN
AF Kim, Cheonshik
   Yang, Ching-Nung
TI Watermark with DSA signature using predictive coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; DSA signature; Predictors
ID SCHEME; EFFICIENT; CODES
AB This paper presents a predictor-based watermark scheme that embeds secret bit streams and a DSA signature into an image. For the copyrighting of digital media, a DSA signature is appropriate as a watermarking technique. To improve security, we apply an Arnold transform (AT) to secret messages. We propose new predictors, Left-Top, which the predict current pixel values using neighboring pixel values. Our proposed scheme conceals secret messages by using the difference between current pixel values and predictive pixel values. Experimental results show that our method has low complexity and achieves a higher embedding performance with good perceptual quality compared to the earlier arts. Experimental results verified our proposed watermark method in multimedia communications.
C1 [Kim, Cheonshik] Anyang Univ, Dept Digital Media Engn, Anyang 430714, Kyonggi Do, South Korea.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien 9701, Taiwan.
C3 Anyang University; National Dong Hwa University
RP Kim, C (corresponding author), Anyang Univ, Dept Digital Media Engn, 708-113 Anyang 5 Dong, Anyang 430714, Kyonggi Do, South Korea.
EM mipsan@paran.com; cnyang@mail.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
OI Kim, Cheonshik/0000-0002-5847-6736; Yang, Ching-Nung/0000-0002-3881-7329
FU National Research Foundation of Korea (NRF) by the Ministry of
   Education, Science and Technology [20120192]
FX This research was supported by the Basic Science Research Program
   Through the National Research Foundation of Korea (NRF) by the Ministry
   of Education, Science and Technology (20120192).
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bierbrauer J., 2005, INTRO CODING THEORY
   BIERBRAUER J, 2006, CONSTRUCTING GOOD CO
   Chan PW, 2003, LECT NOTES COMPUT SC, V2836, P202
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Chen C. W., 2012, JOC J CONVERGENCE, V3, P29
   Crandall R., 1998, SOME NOTES STEGANOGR
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   GALAND F, 2004, P IEEE INF THEOR WOR, P151
   Han WY, 2012, LECT NOTES ELECT E 5, V138, P613
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Luo Y, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-2
   Meenu Sharma Meenu Sharma, 2012, Acta Chimica and Pharmaceutica Indica, V2, P1
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nenadic A, 2004, IEEE SYMP COMP COMMU, P412
   Peng K, 2012, J INF PROCESS SYST, V8, P375, DOI 10.3745/JIPS.2012.8.2.375
   Peng K, 2013, J INF PROCESS SYST, V9, P247, DOI 10.3745/JIPS.2013.9.2.247
   Schonfeld D., 2006, P 8 WORKSH MULT SEC, P214
   Singh B, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-13
   Sujatha SS, 2010, COMM COM INF SC, V101, P78
   Truong T.-T., 2012, J CONVERGENCE, V3, P25
   Tsai C. L., 2012, J CONVERGENCE, V3, P23
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Verma OP, 2013, J INF PROCESS SYST, V9, P271, DOI 10.3745/JIPS.2013.9.2.271
   Willems FMJ, 2005, IEEE T INFORM THEORY, V51, P1209, DOI 10.1109/TIT.2004.842707
   Wu HC, 2006, LECT NOTES COMPUT SC, V3982, P406
   Yang CN, 2011, KSII T INTERNET INF, V5, P457, DOI 10.3837/tiis.2011.02.013
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 30
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5189
EP 5203
DI 10.1007/s11042-013-1667-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900013
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, L
   Huang, XD
   Zhang, CY
   Shepherd, J
   Wang, Y
AF Wu, Lin
   Huang, Xiaodi
   Zhang, Chengyuan
   Shepherd, John
   Wang, Yang
TI An efficient framework of Bregman divergence optimization for co-ranking
   images and tags in a heterogeneous network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-ranking; Random walks; Heterogeneous network; Bregman divergence
AB Graph-based ranking is an effective way of ranking images by making use of the graph structure. However, its applications are usually limited to individual image graphs, which are derived from self-contained features of images. Nowadays, many images in social web sites are often associated with semantic information (i.e., tags). Ranking of these orderless tags is helpful in understanding and retrieving images, thus, improving the overall ranking performance if their mutual reinforcement is considered. Unlike previous work only focusing on individual image or tag graphs, in this paper, we investigate the problem of co-ranking images and tags in a heterogeneous network. Considering that ranking on images and tags can be conducted simultaneously, we present a novel co-ranking method with random walks that is able to significantly improve the ranking effectiveness on both images and tags. We further improve the performance of our algorithm in computational complexity and the out-of-sample problem. This is achieved by casting the co-ranking as a Bregman divergence optimization, under which we transform the original random walks into an equivalent optimal kernel matrix learning problem. Extensive experiments conducted on three benchmarks show that our approach outperforms the state-of-the-art local ranking approaches and scales on large-scaled databases.
C1 [Wu, Lin; Zhang, Chengyuan; Shepherd, John; Wang, Yang] Univ New S Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
   [Huang, Xiaodi] Charles Sturt Univ, Sch Comp & Math, Albury, NSW 2640, Australia.
C3 University of New South Wales Sydney; Charles Sturt University
RP Zhang, CY (corresponding author), Univ New S Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
EM linw@cse.unsw.edu.au; xhuang@csu.edu.au; zhangc@cse.unsw.edu.au;
   jas@cse.unsw.edu.au; wangy@cse.unsw.edu.au
RI Huang, Xiaodi/E-9204-2012; Huang, Xiaodi/ABE-6432-2020; Wu, Lin
   Yuanbo/HME-1691-2023; Shepherd, John/A-5941-2016
OI Huang, Xiaodi/0000-0002-6084-1851; Wu, Lin Yuanbo/0000-0001-6119-058X;
   Shepherd, John/0000-0003-1241-4182
FU Charles Sturt University, Australia [A541-2003-xxx-25242]
FX This research was supported in part by round 4 compact funding
   A541-2003-xxx-25242, Charles Sturt University, Australia.
CR Agarwal Sameer, 2005, CVPR
   Ames M, 2007, SIG CHI
   [Anonymous], 2010, CVPR
   [Anonymous], 2009, Computer Vision and Pattern Recognition
   [Anonymous], NIPS
   [Anonymous], WWW
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], NIPS
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], ACM MULTIMEDIA
   Bay H, 2007, INT C IM VID RETR
   Bay H., 2006, P EUROPEAN C COMPUTE
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Berkhin P, 2005, INTERNET MATH, V2, P73, DOI 10.1080/15427951.2005.10129098
   Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Gao W, 2010, ACM SIGIR
   Guan Z., 2009, SIGIR
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Hoi SCH, 2010, ACM T MULTIMED COMPU, V6
   Hsu Win- ston H., 2008, ACM MULTIMEDIA
   Huang YC, 2011, IEEE T PATTERN ANAL, V33, P1266, DOI 10.1109/TPAMI.2011.25
   Jeon J., 2003, ACM SIGIR
   Jing Y., 2008, WWW
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Kulis B., 2006, ICML
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Langville A., 2004, INTERNET MATH, V1, P335, DOI DOI 10.1080/15427951.2004.10129091
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Nikolopoulos S, 2013, SIGNAL PROCESS, V93, P2212, DOI 10.1016/j.sigpro.2012.08.004
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Richter F, 2012, MULTIMED TOOLS APPL, V56, P35, DOI 10.1007/s11042-010-0554-7
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Shen Y, 2010, ACM MULTIMEDIA
   Shlens J., 2005, TECHNICAL REPORT
   van Gemert JC., 2008, ECCV
   Wan X, 2007, IJCAI
   Wang Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P805, DOI 10.1145/2505515.2505591
   Wu L, 2013, ACM MULTIMEDIA
   Wu L, 2013, MULTIMEDIA MODELING
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Yang Wang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P449, DOI 10.1007/978-3-642-37456-2_38
   YUAN X, 2006, ACM MULTIMEDIA
   Zhang H., 2012, ACM MULTIMEDIA
   Zhou D, 2007, IEEE DATA MINING, P739, DOI 10.1109/ICDM.2007.57
NR 50
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5635
EP 5660
DI 10.1007/s11042-014-1873-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100013
DA 2024-07-18
ER

PT J
AU Daoudi, I
   Idrissi, K
AF Daoudi, Imane
   Idrissi, Khalid
TI A fast and efficient fuzzy approximation-based indexing for CBIR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-dimensional vector space; CBIR; Fuzzy clustering;
   Approximation-based indexing; K-NN search
ID C-MEANS ALGORITHM; OBJECT; KERNEL; RETRIEVAL; ISSUES
AB Crisp index structures introduce the problem of having sharp decision boundaries which may not be found in the real life clustering problems. In real world, specifically in the CBIR context, each data may not be fully assigned to one cluster and it may partially belong to other clusters, as opposed to the crisp index structures which fully affect data to clusters according to their proximity in terms of distance in the high-dimensional vector space. Based on kernel-fuzzy C-means clustering (KFCM) mechanism, this paper presents a fast and efficient index structure to support high-dimensional indexing for both crisp and fuzzy data. The proposed index structure offers a number of advantages such as a compact and efficient fuzzy data clustering. The experimental study demonstrates the efficiency and effectiveness of our method.
C1 [Daoudi, Imane] Univ Hassan II Ain Chock, ENSEM Casablanca, LISER GREENTIC, Casablanca, Morocco.
   [Idrissi, Khalid] Univ Lyon, CNRS, INSA Lyon, LIRIS,UMR5205, F-69621 Lyon, France.
C3 Hassan II University of Casablanca; Centre National de la Recherche
   Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon -
   INSA Lyon
RP Daoudi, I (corresponding author), Univ Hassan II Ain Chock, ENSEM Casablanca, LISER GREENTIC, BP 8118 Oasis Maroc, Casablanca, Morocco.
EM i.daoudi@ensem.ac.ma; kidrissi@liris.cnrs.fr
CR Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], INTERNET SOC OPT ENG
   [Anonymous], P 2002 IEEE INT C MU
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2002 INT C CONTR AUT
   [Anonymous], J ELECT CHINA
   [Anonymous], J APPL REMOTE SENS
   [Anonymous], KNOWL DATA ENG
   [Anonymous], INTRO MPEG 7 MULTIME
   [Anonymous], MULT INF NETW SEC MI
   [Anonymous], APPROXIMATE NEAREST
   [Anonymous], P 2009 ACM SIGMOD IN
   [Anonymous], P 2005 IEEE INT C MU
   [Anonymous], P 18 INT C DAT ENG
   [Anonymous], P 2010 INT C MULT IN
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], VLDB
   [Anonymous], P 4 INT C FUZZ SYST
   [Anonymous], PATTERN ANAL APPL
   [Anonymous], INT SERIES INTELLIGE
   [Anonymous], P 1 WORKSH NEW TREND
   Barranco CD, 2008, FUZZY SET SYST, V159, P1431, DOI 10.1016/j.fss.2008.01.006
   Bayer R., 1972, Acta Informatica, V1, P173, DOI 10.1007/BF00288683
   BERTINO E, 1994, DATA KNOWL ENG, V12, P1, DOI 10.1016/0169-023X(94)90020-5
   Bezdek James C., 1981, PATTERN RECOGN
   BOSC P, 1989, INFORM SYST, V14, P493, DOI 10.1016/0306-4379(89)90017-3
   Chen L., 2005, P 2005 ACM SIGMOD IN, P491
   Cheng R, 2004, IEEE T KNOWL DATA EN, V16, P1112, DOI 10.1109/TKDE.2004.46
   Chiang JH, 2003, IEEE T FUZZY SYST, V11, P518, DOI 10.1109/TFUZZ.2003.814839
   COMER D, 1979, COMPUT SURV, V11, P121, DOI 10.1145/356770.356776
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daoudi I., 2008, Engineering Letters, V16, P210
   Daoudi I, 2009, SIGNAL PROCESS-IMAGE, V24, P775, DOI 10.1016/j.image.2009.09.001
   George R, 1996, IEEE T FUZZY SYST, V4, P179, DOI 10.1109/91.493911
   Graves D, 2007, ELECTRON LETT, V43, P1445, DOI 10.1049/el:20073093
   Graves D, 2010, FUZZY SET SYST, V161, P522, DOI 10.1016/j.fss.2009.10.021
   Gunnemann S., 2011, Proceedings of the 14th International Conference on Extending Database Technology, P237
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   Heisterkamp DR, 2005, MULTIMED TOOLS APPL, V26, P175, DOI 10.1007/s11042-005-0454-4
   Idrissi K, 2004, COMPUT VIS IMAGE UND, V94, P271, DOI 10.1016/j.cviu.2003.10.014
   Koyuncu M, 2003, IEEE T KNOWL DATA EN, V15, P1137, DOI 10.1109/TKDE.2003.1232269
   Mehta M., 1996, P 5 INT C EXTENDING, P18
   Pang L, 2012, LECT NOTES COMPUT SC, V7208, P231
   Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Yazici A, 1998, INFORM SCIENCES, V108, P241, DOI 10.1016/S0020-0255(97)10065-2
   Yazici A, 2008, IEEE T FUZZY SYST, V16, P942, DOI 10.1109/TFUZZ.2008.917304
   Yih JM, 2008, REC ADV COMPUT ENG, P326
   Zadeh LotfiA., 1992, FUZZY LOGIC MANAGEME
   Zhou SM, 2004, LECT NOTES COMPUT SC, V3177, P613
NR 50
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4507
EP 4533
DI 10.1007/s11042-013-1820-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400003
DA 2024-07-18
ER

PT J
AU Wu, JY
   Shang, YL
   Qiao, XQ
   Cheng, B
   Chen, JL
AF Wu, Jiyan
   Shang, Yanlei
   Qiao, Xiuquan
   Cheng, Bo
   Chen, Junliang
TI Robust bandwidth aggregation for real-time video delivery in integrated
   heterogeneous wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous wireless networks; Bandwidth aggregation; Streaming video;
   Forward error correction; Path interleaving
ID PERFORMANCE ANALYSIS; RATE ALLOCATION; TRANSMISSION; SELECTION; ACCESS
AB Bandwidth aggregation is the process of integrating the limited channel resources available in heterogeneous wireless networks. Optimizing this process is an important step towards improving the throughput and reliability for the bandwidth-demanding video applications. In this paper, we investigate the bandwidth aggregation for real-time video delivery in heterogeneous wireless networks from a video server to a multihomed client. Forward Error Correction (FEC) coding is commonly adopted for data protection in implementing loss-resilient wireless video transmission systems. However, the inherent channel unreliability, along with the video traffic variability, can significantly degrade the FEC performance. To address the critical issues, we propose a ROBust BandwIdth Aggregation (ROBBIA) scheme that includes three phases: (1) FEC redundancy adaption, (2) transmission rate assignment, and (3) path interleaving. We present a mathematical formulation of the transmission scheduling to minimize end-to-end video distortion and provide comprehensive analysis for the channel distortion. We conduct the performance evaluation in the Exata and simulation results show that ROBBIA outperforms existing bandwidth aggregation approaches in improving video quality in terms of PSNR (Peak Signal-to-Noise Ratio).
C1 [Wu, Jiyan; Shang, Yanlei; Qiao, Xiuquan; Cheng, Bo; Chen, Junliang] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wu, JY (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM wujiyan@bupt.edu.cn; shangyl@bupt.edu.cn; qiaoxq@bupt.edu.cn;
   chengbo@bupt.edu.cn; chjl@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU National Grand Fundamental Research 973 Program of China [2011CB302506,
   2012CB315802]; National Key Technology Research and Development Program
   of China [2012BAH94F02]; Novel Mobile Service Control Network
   Architecture and Key Technologies [2010ZX03004-001-01]; National
   High-tech R&D Program of China (863 Program) [2013AA102301]; National
   Natural Science Foundation of China [61003067, 61171102, 61001118,
   61132001]; Program for New Century Excellent Talents in University
   [NCET-11-0592]; Project of New Generation Broadband Wireless Network
   [2011ZX03002-002-01]; Beijing Nova Program [2008B50]
FX This research is supported by the National Grand Fundamental Research
   973 Program of China under Grant No. 2011CB302506, 2012CB315802;
   National Key Technology Research and Development Program of China
   "Research on the mobile community cultural service aggregation
   supporting technology" (Grant No. 2012BAH94F02); Novel Mobile Service
   Control Network Architecture and Key Technologies (2010ZX03004-001-01);
   National High-tech R&D Program of China (863 Program) under Grant No.
   2013AA102301; National Natural Science Foundation of China under Grant
   No. 61003067, 61171102, 61001118, 61132001; Program for New Century
   Excellent Talents in University (Grant No. NCET-11-0592); Project of New
   Generation Broadband Wireless Network under Grant No.
   2011ZX03002-002-01; Beijing Nova Program under Grant No. 2008B50.
CR Alpcan T, 2009, IEEE T MOBILE COMPUT, V8, P41, DOI 10.1109/TMC.2008.85
   [Anonymous], 2013, White Paper
   Chebrolu K, 2006, IEEE T MOBILE COMPUT, V5, P388, DOI 10.1109/TMC.2006.1599407
   Chow ALH, 2010, P IEEE ICNP
   Fashandi S, 2010, IEEE ACM T NETWORK, V18, P1373, DOI 10.1109/TNET.2010.2043368
   Fiandrotti A, 2008, P IEEE
   Fraleigh C, 2003, IEEE NETWORK, V17, P6, DOI 10.1109/MNET.2003.1248656
   Freris NM, 2013, IEEE ACM T NETWORK, V21, P469, DOI 10.1109/TNET.2012.2203608
   Frossard P, 2001, IEEE COMMUN LETT, V5, P122, DOI 10.1109/4234.913160
   Han SC, 2011, IEEE J SEL AREA COMM, V29, P1032, DOI 10.1109/JSAC.2011.110513
   Heinzelman W, 1999, P IEEE ICIP
   Horn U, 1999, SIGNAL PROCESS-IMAGE, V15, P77, DOI 10.1016/S0923-5965(99)00025-9
   Ismail M, 2012, IEEE T WIREL COMMUN, V11, P4085, DOI 10.1109/TWC.2012.091812.120329
   Jain M, 2003, IEEE ACM T NETWORK, V11, P537, DOI 10.1109/TNET.2003.815304
   Jain M., 2002, PAM WORKSH
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P629, DOI 10.1109/TMM.2006.888017
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P1227, DOI 10.1109/TMM.2007.902852
   Kompella S, 2009, IEEE ACM T NETWORK, V17, P212, DOI 10.1109/TNET.2008.925942
   Nightingale J, 2012, MULTIMED TOOLS APPL, P1
   Oliveira T., 2011, P IEEE INFOCOM
   Piamrat K, 2011, COMPUT COMMUN, V34, P9
   Ribeiro V., 2003, PASSIVE ACTIVE MEASU
   Sharma V, 2009, P IEEE INFOCOM
   Si PB, 2010, WIREL NETW, V16, P1277, DOI 10.1007/s11276-009-0202-1
   Song W, 2012, IEEE T WIREL COMMUN, V11, P1554, DOI 10.1109/TWC.2012.021512.111397
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Van der Auwera G, 2009, IEEE T BROADCAST, V55, P541, DOI 10.1109/TBC.2009.2027399
   Wallace TD, 2012, IEEE COMMUN SURV TUT, V14, P565, DOI 10.1109/SURV.2011.051111.00096
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Yooon J, 2012, P ACM MOBICOM
   Zhou A, 2008, P IEEE GLOBECOM
   Zhuang WH, 2012, IEEE WIREL COMMUN, V19, P10, DOI 10.1109/MWC.2012.6189408
NR 32
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4117
EP 4138
DI 10.1007/s11042-013-1813-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800023
DA 2024-07-18
ER

PT J
AU Im, KH
   Lee, SC
   Park, SC
AF Im, Kwang Hyuk
   Lee, Sang Chul
   Park, Sang Chan
TI A personalized display technology integrating the technologies of
   bio-signal measurements and multi-view 3D display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized display technologies; 3D display; Bio-signal measurement;
   Multi-view 3D display; Autostereoscope display
AB Traditionally, 3D display technologies and bio-signal measurement technologies have been studied separately. If both technologies will be integrated, however, it is projected not only to maximize the effectiveness of 3D display but also to create a new market for personalized display. The purpose of this research is to suggest SMART (i.e., Specific, Measurable, Action oriented, Reliable, and Timely), which is the criteria for developing and applying personalized 3D display technologies. This research analyzes the existing multi-view 3D display and acquisition technologies, determines the technologies suitable for integration with bio-signal measurement technologies, and identifies the types of bio-signals that could create synergy with multi-view 3D display technologies. To test and apply the suggested SMART, this research conducts case study in health care field.
C1 [Im, Kwang Hyuk] PaiChai Univ, Dept Elect Commerce, Taejon, South Korea.
   [Lee, Sang Chul] Korea Christian Univ, Dept Business Adm, Seoul, South Korea.
   [Park, Sang Chan] Kyung Hee Univ, Sch Management, Dept Hlth Serv Management, Seoul, South Korea.
C3 Pai Chai University; Kyung Hee University
RP Park, SC (corresponding author), Kyung Hee Univ, Sch Management, Dept Hlth Serv Management, Seoul, South Korea.
EM khim@pcu.ac.kr; leecho@kcu.ac.kr; sangchan@khu.ac.kr
RI park, sangchan/AAH-9432-2020
OI Park, Sangchan/0000-0003-4488-3258
FU National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [20131261]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (grant number: 20131261)
CR [Anonymous], INT J COMPUT SCI MAN
   Evans D, 2001, INT J NURS STUD, V38, P643, DOI 10.1016/S0020-7489(00)00119-X
   Ha SR, 2007, J KOREA I ORIENT MED, V11, P157
   Howard P, 1995, OXFORD PSYCHOL SERIE, V29
   Jung SM, 2009, 2009 SID INTERNATIONAL SYMPOSIUM DIGEST OF TECHNICAL PAPERS, VOL XL, BOOKS I - III, P348
   Kim DW, 2008, J KOREA I ORIENT MED, V12, P84
   Kim SS, 2009, 2009 SID INTERNATIONAL SYMPOSIUM DIGEST OF TECHNICAL PAPERS, VOL XL, BOOKS I - III, P424
   KIM Y, 2008, IEEE CVPR WORKSH TIM
   Lee SH, 2009, J KOREAN INF DISP SO, V10, P15
   Leuvan Chris H Van, 2008, Crit Care Resusc, V10, P111
   MOTOKI T, 1995, P IEEE, V83, P1009, DOI 10.1109/5.390119
   Oem KM, 2011, MULTIVIEW 3D IMAGING
   Park JH, 2009, J KOREAN INF DISP SO, V10, P2
   Suzuki D, 2009, 2009 SID INTERNATIONAL SYMPOSIUM DIGEST OF TECHNICAL PAPERS, VOL XL, BOOKS I - III, P428
   Yang DH, 2007, J KOREA I ORIENT MED, V11, P146
   Yoo SY, 2008, J KOREA I ORIENT MED, V12, P74
   김신미, 2010, Annals of Pediatirc Endocrinology & Metabolism, V15, P100
NR 17
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3387
EP 3399
DI 10.1007/s11042-014-2046-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000010
DA 2024-07-18
ER

PT J
AU Seal, A
   Bhattacharjee, D
   Nasipuri, M
   Basu, DK
AF Seal, Ayan
   Bhattacharjee, Debotosh
   Nasipuri, Mita
   Basu, Dipak Kr.
TI UGC-JU face database and its benchmarking using linear regression
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal face images; Visual images; Face database; GappyPCA; LRC
   classifier; Decision level fusion
ID RECOGNITION; SYSTEM; EIGENFACES; GENDER
AB In this paper, a new face database has been presented which will be freely available to academicians and research community for research purposes. The face database consists of both visual and thermal face images of 84 persons with varying poses, expressions and occlusions (39 different variations for each type, visual or thermal). A new thermal face image recognition technique based on Gappy Principal Component Analysis and Linear Regression Classifier has also been presented here. The recognition performance of this technique on the thermal face images of this database is found to be 98.61 %, which can be considered as the initial benchmark recognition performance this database.
C1 [Seal, Ayan; Bhattacharjee, Debotosh; Nasipuri, Mita; Basu, Dipak Kr.] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Seal, A (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM ayanseal30@ieee.org; debotoshb@hotmail.com; mitanasipuri@yahoo.com;
   dipakkbasu@gmail.com
RI Bhattacharjee, Debotosh/Q-4065-2019; Seal, Ayan/AAI-1929-2020; Seal,
   Ayan/AAZ-9020-2020; Bhattacharjee, Debotosh/L-8521-2015
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Seal,
   Ayan/0000-0002-9939-2926; Bhattacharjee, Debotosh/0000-0002-1163-6413;
   Bhattacharjee, Debotosh/0000-0002-4483-706X
FU Deity, Govt. of India; "DST-PURSE Programme" at Department of Computer
   Science and Engineering, Jadavpur University, India; Department of
   Science & Technology (DST), Govt. of India [IF110591]
FX Authors are thankful to a project entitled "Development of 3D Face
   Recognition Techniques Based on Range Images," funded by Deity, Govt. of
   India and "DST-PURSE Programme" at Department of Computer Science and
   Engineering, Jadavpur University, India for providing necessary
   infrastructure to conduct experiments relating to this work. Ayan Seal
   is grateful to Department of Science & Technology (DST), Govt. of India
   for providing him Junior Research Fellowship-Professional
   (JRF-Professional) under DST-INSPIRE Fellowship programme [No:
   IF110591].
CR [Anonymous], INT J INNOV MANAG TE
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], COMPUT INTELL NEUROS
   [Anonymous], 0201 EQ CORP
   [Anonymous], P 3 IEEE C IND INF S
   [Anonymous], P CVPR 05 P 2005 IE
   [Anonymous], 2001, TECHNICAL REPORT
   [Anonymous], 2010, ROBOT SOCCER WORLD C
   [Anonymous], 1 COST 2101 WORKSH B
   [Anonymous], P 2004 IE COMP SOC C
   [Anonymous], 1990, Robust estimation and testing
   [Anonymous], LECTURE
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE INT WORKSH AN
   Balci K, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047869
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Brunelli R., 1992, P DARPA IMAGE UNDERS, P311
   Cutler Ross., 1996, FACE RECOGNITION USI
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   EVERSON R, 1995, J OPT SOC AM A, V12, P1657, DOI 10.1364/JOSAA.12.001657
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, DOI DOI 10.1007/978-0-387-84858-7
   Gong S., 2000, Dynamic vision from images to face recognition
   Gonzalez RC., Digital image processing third edition Pearson international edition prepared by Pearson Education
   Hearn D. P., Computer graphics, C version
   Kim K, 2005, LECT NOTES COMPUT SC, V3497, P147
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792
   Liu JNK, 2005, IEEE T SYST MAN CY C, V35, P97, DOI 10.1109/TSMCC.2004.840051
   Martinez A., 1998, AR FACE DATABASE
   Martinez Brais., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010, P48
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Moon H, 2004, LECT NOTES COMPUT SC, V3072, P207
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prokoski F, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P5, DOI 10.1109/CVBVS.2000.855245
   Prokoski F. J., 1992, Proceedings. The Institute of Electrical and Electronics Engineers 1992 International Carnahan Conference on Security Technology: Crime Countermeasures (Cat. No.CH3119-5/92), P120, DOI 10.1109/CCST.1992.253768
   Ryan T.P., 1997, Modern regression methods
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Seal Ayan, 2013, International Journal of Computational Intelligence Studies, V2, P133
   Seber G. A., 2003, Linear Regression Analysis
   Shinohara Y, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P499, DOI 10.1109/AFGR.2004.1301582
   SOCOLINSKY DA, 2001, PROC CVPR IEEE, P527
   Trujillo L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P14
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yoshitomi Y, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P374, DOI 10.1109/ROMAN.1997.647015
   Yuan-Tsung Chen, 2002, Journal of Medical and Biological Engineering, V22, P97
NR 50
TC 14
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2913
EP 2937
DI 10.1007/s11042-013-1754-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800004
DA 2024-07-18
ER

PT J
AU Seo, S
   Lee, H
AF Seo, SangHyun
   Lee, HunJoo
TI Pixel based stroke generation for painterly effect using maximum
   homogeneity neighbor filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Stroke generation; Painterly effect;
   Maximum homogeneity neighbor filter; Least square approximation
AB In this paper, we introduce a new brush stroke generation method for painterly effect. Instead of using the gradient of the source image to determine the stroke direction, we extract regions that can be drawn in one stroke using Maximum Homogeneity Neighbor filtering followed by identification of connected components considering the homogeneity of pixels. We can make a brush stroke from each component based on a least squares approximation to the medial axis. This method results in realistic looking brush strokes of varying width that have irregular directions where necessary.
C1 [Seo, SangHyun; Lee, HunJoo] Elect & Telecommun Res Inst, Taejon 305606, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Lee, H (corresponding author), Elect & Telecommun Res Inst, Taejon 305606, South Korea.
EM shseo@etri.re.kr; hjoo@etri.re.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Ministry of Culture, Sports and Tourism(MCST); Korea Creative Content
   Agency(KOCCA) in the Culture Technology(CT) and Research Development
   Program
FX This work was supported by Ministry of Culture, Sports and Tourism(MCST)
   and Korea Creative Content Agency(KOCCA) in the Culture Technology(CT)
   and Research Development Program 2013.
CR [Anonymous], 2010, NUMERICAL ANAL
   Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   GARNICA C, 2000, INT ARCH PHOTOGRAM 3, V33, P320
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang H, 2010, COMPUT GRAPH FORUM, V29, P2055, DOI 10.1111/j.1467-8659.2010.01792.x
   Kim KI, 2013, ETRI J, V35, P960, DOI 10.4218/etrij.13.2013.0076
   Lee H, 2011, COMPUT GRAPH-UK, V35, P81, DOI 10.1016/j.cag.2010.11.008
   Lin L., 2010, Proc. NPAR '10, P73, DOI DOI 10.1145/1809939.1809948
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3
   O'Donovan P, 2012, IEEE T VIS COMPUT GR, V18, P475, DOI 10.1109/TVCG.2011.51
   Ramesh J, 1995, MACHING VISION
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Seo S, 2013, MULTIMED TOOLS APPL, V65, P221, DOI 10.1007/s11042-011-0796-z
   Seo S, 2010, VISUAL COMPUT, V26, P421, DOI 10.1007/s00371-010-0505-3
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   Zhao M., 2011, Proc. NPAR '11, P137, DOI DOI 10.1145/2024676.2024698
NR 21
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3317
EP 3328
DI 10.1007/s11042-013-1835-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000005
DA 2024-07-18
ER

PT J
AU Pham, HT
   Kim, JJ
   Nguyen, TL
   Won, Y
AF Hai-Trieu Pham
   Kim, Jung-Ja
   Tan Loc Nguyen
   Won, Yonggwan
TI 3D motion matching algorithm using signature feature descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion analysis; Microsoft Kinect; 3D motion trajectory; Trajectory
   descriptor; Similarity of trajectory; Sign word recognition
AB This paper introduces a basic frame for rehabilitation motion practice system which detects 3D motion trajectory with the Microsoft Kinect (MSK) sensor system and proposes a cost-effective 3D motion matching algorithm. The rehabilitation motion practice system displays a reference 3D motion in the database system that the player (patient) tries to follow. The player's motion is traced by the MSK sensor system and then compared with the reference motion to evaluate how well the player follows the reference motion. In this system, 3D motion matching algorithm is a key feature for accurate evaluation for player's performance. Even though similarity measurement of 3D trajectories is one of the most important tasks in 3D motion analysis, existing methods are still limited. Recent researches focus on the full length 3D trajectory data set. However, it is not true that every point on the trajectory plays the same role and has the same meaning. In this situation, we developed a new cost-effective method that only uses the less number of features called 'signature' which is a flexible descriptor computed from the region of 'elbow points'. Therefore, our proposed method runs faster than other methods which use the full length trajectory information. The similarity of trajectories is measured based on the signature using an alignment method such as dynamic time warping (DTW), continuous dynamic time warping (CDTW) or longest common sub-sequence (LCSS) method. In the experimental studies, we applied the MSK sensor system to detect, trace and match the 3D motion of human body. This application was assumed as a system for guiding a rehabilitation practice which can evaluate how well the motion practice was performed based on comparison of the patient's practice motion traced by the MSK system with the pre-defined reference motion in a database. In order to evaluate the accuracy of our 3D motion matching algorithm, we compared our method with two other methods using Australian sign word dataset. As a result, our matching algorithm outperforms in matching 3D motion, and it can be exploited for a base framework for various 3D motion-based applications at low cost with high accuracy.
C1 [Hai-Trieu Pham] Deakin Univ, Fac Sci Engn & Build Environm, Geelong, Vic 3216, Australia.
   [Tan Loc Nguyen; Won, Yonggwan] Chonnam Natl Univ, Sch Elect & Comp Engn, Kwangju 500757, South Korea.
   [Kim, Jung-Ja] Chonbuk Natl Univ, Div Biomed Engn, Jeonju Si 570752, Jeollabuk Do, South Korea.
C3 Deakin University; Chonnam National University; Jeonbuk National
   University
RP Won, Y (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, 300 Yongbong Dong, Kwangju 500757, South Korea.
EM haitrieupham1@gmail.com; jungjakim@jbnu.ac.kr;
   nguyentanloc032003@gmail.com; ykwon@jnu.ac.kr
FU Chonnam National University; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Educations,
   Science and Technology [NRF-2013R1A2A2A04016782]
FX This study was financially supported by Chonnam National University
   2011, and was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Educations, Science and Technology (NRF-2013R1A2A2A04016782).
CR Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495
   [Anonymous], 1999, AUSTR SIGN LANGUAGE
   [Anonymous], 2003, KDD
   Balteanu M. S, 2010, P INT C RISK MAN ASS, P51
   Bashir F, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1533
   Croitoru A., 2005, P 13 ANN ACM INT WOR, P153
   Fitzgerald D, 2007, P ANN INT IEEE EMBS, P4870, DOI 10.1109/IEMBS.2007.4353431
   HUMM JR, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P374, DOI 10.1109/IEMBS.1994.411997
   Jianyu Yang, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P37, DOI 10.1109/ICAL.2010.5585379
   KEHTARNAVAZ N, 1988, IEEE T PATTERN ANAL, V10, P707, DOI 10.1109/34.6780
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Pallejà T, 2013, TELECOMMUN SYST, V52, P1479, DOI 10.1007/s11235-011-9625-y
   Singh R, 2009, TELECOMMUN SYST, V40, P5, DOI 10.1007/s11235-008-9141-x
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Vrani D.V., 2001, P ECMCS 2001 3 EURAS, P271
   Wang R., 2008, 2008 2nd annual IEEE systems conference, P1, DOI [10.1109/systems.2008. 4518997, DOI 10.1109/SYSTEMS.2008.4518997, DOI 10.1109/CVPR.2008.4587719]
   Wu S, 2009, PATTERN RECOGN, V42, P194, DOI 10.1016/j.patcog.2008.06.023
   Zetu D, 2000, IEEE T ROBOTIC AUTOM, V16, P281, DOI 10.1109/70.850646
NR 18
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1125
EP 1136
DI 10.1007/s11042-014-2103-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400022
DA 2024-07-18
ER

PT J
AU Balasubramanian, C
   Selvakumar, S
   Geetha, S
AF Balasubramanian, C.
   Selvakumar, S.
   Geetha, S.
TI High payload image steganography with reduced distortion using octonary
   pixel pairing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; High capacity; Adaptive data hiding; Octonary PVD;
   Statistical undetectability
ID STEGANALYSIS
AB The crucial challenge that decides the success of any steganographic algorithm lies in simultaneously achieving the three contradicting objectives namely-higher payload capacity, with commendable perceptual quality and high statistical un-detectability. This work is motivated by the interest in developing such a steganographic scheme, which is aimed for establishing secure image covert channel in spatial domain using Octonary PVD scheme. The goals of this paper are to be realized through: (1) pairing a pixel with all of its neighbors in all the eight directions, to offer larger embedding capacity (2) the decision of the number of bits to be embedded in each pixel based on the nature of its region and not done universally same for all the pixels, to enhance the perceptual quality of the images (3) the re-adjustment phase, which sustains anymodified pixel in the same level in the stego-image also, where the difference between a pixel and its neighbor in the cover image belongs to, for imparting the statistical un-detectability factor. An extensive experimental evaluation to compare the performance of the proposed system vs. other existing systems was conducted, on a database containing 3338 natural images, against two specific and four universal steganalyzers. The observations reported that the proposed scheme is a state-of-the-art model, offering high embedding capacity while concurrently sustaining the picture quality and defeating the statistical detection through steganalyzers.
C1 [Geetha, S.] Thiagarajar Coll Engn, Dept Informat Technol, Madurai, Tamil Nadu, India.
   [Balasubramanian, C.] PSR Rengasamy Coll Engn, CSE, Sivakasi, India.
   [Selvakumar, S.] GKM Coll Engn, Madras, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Geetha, S (corresponding author), Thiagarajar Coll Engn, Dept Informat Technol, Madurai, Tamil Nadu, India.
EM bala@psrr.edu.in; sselvakumar@yahoo.com; geethabaalan@gmail.com
RI Chellaiah, Balasubramanian/Y-9460-2019; , Dr.S.Geetha/ABI-7036-2020;
   Kamaraj, N./AAS-2531-2020; Subramanian, Selvakumar/AEO-1935-2022
OI Chellaiah, Balasubramanian/0000-0001-9066-7287; Kamaraj,
   N./0000-0002-0424-5529; S, Geetha/0000-0002-6850-9423; S, Dr.
   Selvakumar/0000-0001-9795-3569
FU All India Council for Technical Education - Research Promotion Scheme
   [20/AICTE/RIFD/RPS(POLICY-II)65/2012-13]
FX This paper is based upon work supported by the All India Council for
   Technical Education - Research Promotion Scheme under Grant No.
   20/AICTE/RIFD/RPS(POLICY-II)65/2012-13.
CR Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bui CN, 2010, INT J INNOV COMPUT I, V6, P3193
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Geetha S, 2010, INT J AUTOM COMPUT, V7, P531, DOI 10.1007/s11633-010-0537-1
   Goljan M, 2006, P SPIE SECUR FORENSI, V6072, P1
   Hempstalk K, 2006, P COMP WOM C HAM NZ
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Jung KH, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P355, DOI 10.1109/ICHIT.2008.279
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li XL, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P133
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Sabeti V, 2009, ISECURE-ISC INT J IN, V1, P17
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang C.H., 2006, P INT COMP S TAIP TA, P831
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 30
TC 38
Z9 39
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2223
EP 2245
DI 10.1007/s11042-013-1640-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200050
DA 2024-07-18
ER

PT J
AU Wu, B
   Xu, LF
AF Wu, Bo
   Xu, Linfeng
TI Integrating bottom-up and top-down visual stimulus for saliency
   detection in news video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Bottom-up attention; Top-down attention; News video
ID FACE SEGMENTATION; ATTENTION; MODEL
AB This paper presents a new attention model for detecting visual saliency in news video. In the proposed model, bottom-up (low level) features and top-down (high level) factors are used to compute bottom-up saliency and top-down saliency respectively. Then, the two saliency maps are fused after a normalization operation. In the bottom-up attention model, we use quaternion discrete cosine transform in multi-scale and multiple color spaces to detect static saliency. Meanwhile, multi-scale local motion and global motion conspicuity maps are computed and integrated into motion saliency map. To effectively suppress the background motion noise, a simple histogram of average optical flow is adopted to calculate motion contrast. Then, the bottom-up saliency map is obtained by combining the static and motion saliency maps. In the top-down attention model, we utilize high level stimulus in news video, such as face, person, car, speaker, and flash, to generate the top-down saliency map. The proposed method has been extensively tested by using three popular evaluation metrics over two widely used eye-tracking datasets. Experimental results demonstrate the effectiveness of our method in saliency detection of news videos compared to several state-of-the-art methods.
C1 [Wu, Bo; Xu, Linfeng] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610073, Peoples R China.
   [Wu, Bo] Henan Normal Univ, Coll Phys & Informat Engn, Xinxiang 453007, Peoples R China.
C3 University of Electronic Science & Technology of China; Henan Normal
   University
RP Wu, B (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610073, Peoples R China.
EM bo.wu.cv@gmail.com
RI Xu, Linfeng/HME-1913-2023
OI Xu, Linfeng/0000-0002-9934-0958
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], BMVC
   [Anonymous], P 2011 JOINT ACM WOR
   [Anonymous], COLL RES COMP NEUR A
   Benoit A, 2010, COMPUT VIS IMAGE UND, V114, P774, DOI 10.1016/j.cviu.2010.01.010
   Bian P, 2010, COGN NEURODYNAMICS, V4, P189, DOI 10.1007/s11571-010-9122-0
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Bur A, 2007, LECT NOTES COMPUT SC, V4528, P109
   Cerf M., 2008, ADV NEURAL INFORM PR, V20
   Cevikalp H., 2012, P IEEE C COMP VIS PA
   Chang CH, 2010, J VIS COMMUN IMAGE R, V21, P595, DOI 10.1016/j.jvcir.2010.03.006
   Chen DY, 2011, MULTIMED TOOLS APPL, V53, P271, DOI 10.1007/s11042-010-0511-5
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Feng W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P252, DOI 10.1109/CISP.2008.61
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Ho SS, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1912
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Lang CY, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL I, P336, DOI 10.1109/CINC.2009.220
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li HL, 2011, IEEE T CIRC SYST VID, V21, P1571, DOI 10.1109/TCSVT.2011.2129150
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Mahadevan Vijay., 2008, Computer Vision and Pattern Recognition, IEEE Computer Society Conference on, P1, DOI 10.1109/CVPR.2008.4587576
   Miyazato K, 2009, IEEE INT CON MULTI, P250, DOI 10.1109/ICME.2009.5202483
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   RAPANTZIKOS K, 2005, INT WORKSH CONT BAS
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   Schauerte B., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P137, DOI 10.1109/WACV.2012.6163035
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Wu B, 2013, IEEE INT SYMP CIRC S, P941, DOI 10.1109/ISCAS.2013.6572003
   Wu B, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-16
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhang D, 2001, LECT NOTES COMPUT SC, V2195, P63
NR 53
TC 11
Z9 13
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1053
EP 1075
DI 10.1007/s11042-013-1530-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200001
DA 2024-07-18
ER

PT J
AU Hermassi, H
   Belazi, A
   Rhouma, R
   Belghith, SM
AF Hermassi, Houcemeddine
   Belazi, Akram
   Rhouma, Rhouma
   Belghith, Safya Mdimegh
TI Security analysis of an image encryption algorithm based on a DNA
   addition combining with chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Cryptanalysis; Chaos; DNA encoding
ID STANDARD
AB In this paper, we propose to cryptanalyse an encryption algorithm which combines a DNA addition and a chaotic map to encrypt a gray scale image. Our contribution consists on, at first, demonstrating that the algorithm, as it is described, is non-invertible, which means that the receiver cannot decrypt the ciphered image even if he posses the secret key. Then, a chosen plaintext attack on the invertible encryption block is described, where, the attacker can illegally decrypt the ciphered image by a temporary access to the encryption machinery.
C1 [Hermassi, Houcemeddine; Belazi, Akram; Rhouma, Rhouma; Belghith, Safya Mdimegh] ENIT, SysCom Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Hermassi, H (corresponding author), ENIT, SysCom Lab, Tunis, Tunisia.
EM houcemeddine.hermassi@enit.rnu.tn
RI Rhouma, Rhouma/B-8018-2010; hermassi, houcemeddine/ADK-4317-2022;
   Hermassi, Houcemeddine/J-2352-2012
OI Rhouma, Rhouma/0000-0002-5715-4110; Belghith, Safya/0000-0001-7408-7848;
   Hermassi, houcemeddine/0000-0002-4681-4312
CR Adleman LM, 1999, J COMPUT BIOL, V6, P53, DOI 10.1089/cmb.1999.6.53
   Guglielmi V, 2009, CHAOS SOLITON FRACT, V42, P2135, DOI 10.1016/j.chaos.2009.03.160
   Hermassi H, 2010, COMMUN NONLINEAR SCI, V15, P2987, DOI 10.1016/j.cnsns.2009.11.022
   Leier A, 2000, BIOSYSTEMS, V57, P13, DOI 10.1016/S0303-2647(00)00083-6
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mansuripur M., 2003, Technical Report
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Rhouma R, 2011, COMMUN NONLINEAR SCI, V16, P876, DOI 10.1016/j.cnsns.2010.05.017
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tanaka K, 2005, BIOSYSTEMS, V81, P25, DOI 10.1016/j.biosystems.2005.01.004
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   X952 A, 1998, DROP
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 16
TC 60
Z9 64
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2211
EP 2224
DI 10.1007/s11042-013-1533-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300008
DA 2024-07-18
ER

PT J
AU Kim, HJ
   Choi, SG
AF Kim, Hyun Jong
   Choi, Seong Gon
TI QoE assessment model for multimedia streaming services using QoS
   parameters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoS; QoE; Multimedia; Streaming; Assessment; IPTV; Video
ID QUALITY
AB This paper proposes a video QoE (Quality of Experience) assessment model which can assess video quality of experience with only QoS (Quality of Service) parameters and their relative importance at network layer. Since network or service providers can forecast whether to provide multimedia services above a certain level of service quality using the proposed model, they can offer and maintain optimum network environment for multimedia service such as IPTV. Through an experiment of video quality comparison we show that our QoS/QoE correlation model is closely related with video quality degradation patterns to network environmental change.
C1 [Kim, Hyun Jong] Elect & Telecommun Res Inst, LED Commun Res Team, Taejon, South Korea.
   [Choi, Seong Gon] Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju, Chungbuk, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Chungbuk National University
RP Choi, SG (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, 52 Naesudong Ro, Cheongju, Chungbuk, South Korea.
EM hjkim23@etri.re.kr; sgchoi@cbnu.ac.kr
FU MKE(The Ministry of Knowledge Economy), Korea, under the
   ITRC(Information Technology Research Center) [NIPA-2012-H0301-12-1004];
   ICT Standardization program of KCC
FX "This research was supported by the MKE(The Ministry of Knowledge
   Economy), Korea, under the ITRC(Information Technology Research Center)
   support program supervised by the NIPA(National IT Industry Promotion
   Agency)" (NIPA-2012-H0301-12-1004) and "This research was supported by
   the ICT Standardization program of KCC(Korea Communications Commission)"
CR [Anonymous], Y1541 ITUT
   [Anonymous], 2003, P800 ITUT
   [Anonymous], G107 ITUT
   [Anonymous], 2001, REC ITU T P 862
   Cano MD, 2010, ETRI J, V32, P843, DOI 10.4218/etrij.10.0109.0645
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   CS MSU Graphics & Media Lab Video Group, 2006, MSU SUBJ COMP MOD VI
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   *ITU T, 1998, P861 ITUT
   Joung J, 2008, ETRI J, V30, P238, DOI 10.4218/etrij.08.1107.0006
   Khirman S, 2002, P PAM2002
   Kim HL, 2010, INT CONF ADV COMMUN, P1377
   Kim K-J, 2008, P INFORMS2008 SERV S
   Kim KJ, 2008, IN C IND ENG ENG MAN, P595, DOI 10.1109/IEEM.2008.4737938
   Kishigami J, 2007, P 9 IEEE INT S MULT, P11
   Li-yuan L, 2006, P PCA2006
   Lloret J, 2010, T INT J COMMUNICATIO, P118
   Malamos AG, 2002, MULTIMED TOOLS APPL, V16, P207, DOI 10.1023/A:1013956019587
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Recommendation ITU-T P.910, 1999, P910 ITUT
   WANG Yubing., 2006, SURVEY OBJECTIVE VID
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   2006, TR126 DSL FOR
NR 23
TC 23
Z9 24
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2163
EP 2175
DI 10.1007/s11042-013-1507-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300005
DA 2024-07-18
ER

PT J
AU Battiato, S
   Farinella, GM
   Puglisi, G
   Ravì, D
AF Battiato, Sebastiano
   Farinella, Giovanni Maria
   Puglisi, Giovanni
   Ravi, Daniele
TI Aligning codebooks for near duplicate image detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Near duplicate images; Image retrieval; Bags of visual
   words; Bags of visual phrases; Codebooks alignment
ID OBJECT RECOGNITION; SCALE; IDENTIFICATION; FEATURES
AB The detection of near duplicate images in large databases, such as the ones of popular social networks, digital investigation archives, and surveillance systems, is an important task for a number of image forensics applications. In digital investigation, hashing techniques are commonly used to index large quantities of images for the detection of copies belonging to different archives. In the last few years, different image hashing techniques based on the Bags of Visual Features paradigm appeared in literature. Recently, this paradigm has been augmented by using multiple descriptors (e.g., Bags of Visual Phrases) in order to exploit the coherence between different feature spaces. In this paper we propose to further improve the Bags of Visual Phrases approach considering the coherence between feature spaces not only at the level of image representation, but also during the codebook generation phase. Also we introduce a novel image database specifically designed for the development and benchmarking of near duplicate image retrieval techniques. The dataset consists of more than 3,300 images depicting more than 500 different scenes having at least three real near duplicates. The dataset has a huge variability in terms of geometric and photometric transformations between scenes and their corresponding near duplicates. Finally, we suggest a method to compress the proposed image representation for storage purposes. Experiments show the effectiveness of the proposed near duplicate retrieval technique, which outperforms the original Bags of Visual Phrases approach.
C1 [Battiato, Sebastiano; Farinella, Giovanni Maria; Puglisi, Giovanni; Ravi, Daniele] Univ Catania, Dept Math & Comp Sci, Image Proc Lab, I-95125 Catania, Italy.
C3 University of Catania
RP Farinella, GM (corresponding author), Univ Catania, Dept Math & Comp Sci, Image Proc Lab, Viale A Doria 6, I-95125 Catania, Italy.
EM battiato@dmi.unict.it; gfarinella@dmi.unict.it; puglisi@dmi.unict.it;
   ravi@dmi.unict.it
RI Battiato, Sebastiano/ABI-1584-2020; Battiato, Sebastiano/O-7799-2019;
   Ravì, D./AAM-3497-2020; FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; Ravì, D./0000-0003-0372-2677;
   FARINELLA, Giovanni Maria/0000-0002-6034-0432
FU ENIAC
FX Part of this work has been performed in the project PANORAMA, co-funded
   by grants from Belgium, Italy, France, the Netherlands, the United
   Kingdom, and the ENIAC Joint Undertaking. The authors would like to
   thank Giuseppe Claudio Guarnera, Tony Meccio and Rosetta Rizzo who have
   given some help at the beginning of this work.
CR [Anonymous], P INT C COMP VIS PAT
   [Anonymous], 1982, COMBINATORIAL OPTIMI
   [Anonymous], 2010, P 2 ACM WORKSH MULT, DOI DOI 10.1145/1877972.1877991
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], ACM MULTIMEDIA, DOI DOI 10.1145/1027527.1027729
   [Anonymous], COMP VIS WINT WORKSH
   [Anonymous], 2005, P INT C COMP VIS
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng XG, 2011, COMPUT VIS IMAGE UND, V115, P750, DOI 10.1016/j.cviu.2011.02.003
   Chum O., 2008, P BMVC
   Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531
   De Oliveira R, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823749
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Eastlake D, 2001, Technical Report
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hu YQ, 2009, IEEE T MULTIMEDIA, V11, P1434, DOI 10.1109/TMM.2009.2032676
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Lejsek H, 2010, P ACM WORKSH MULT FO, P1
   Leung T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1010, DOI 10.1109/ICCV.1999.790379
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Rivest R., 1992, Tech. Rep.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang Y, 2011, INT CONF ACOUST SPEE, P1209
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Xu D, 2007, P IEEE INT C COMP VI
   Xu D, 2010, IEEE T CIRC SYST VID, V20, P1068, DOI 10.1109/TCSVT.2010.2051286
   ZHANG D.-Q., 2004, PROC ACM INT C MULTI, P877, DOI DOI 10.1145/1027527.1027730
   Zhao W-L, 2011, MANUAL SOTU VERSION
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
   Zhu Jianke., 2008, P 16 ACM INT C MULTI, P41
NR 51
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1483
EP 1506
DI 10.1007/s11042-013-1470-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300021
DA 2024-07-18
ER

PT J
AU Hafidh, B
   Al Osman, H
   Karime, A
   Alja'am, JM
   El Saddik, A
AF Hafidh, Basim
   Al Osman, Hussein
   Karime, Ali
   Alja'am, Jihad Mohamad
   El Saddik, Abdulmotaleb
TI SmartPads: a plug-N-play configurable tangible user interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tangible user interface; Dynamic TUIs; Exergaming
AB One common concern with video games today is the lack of physical activity they demand from the user. The design of games and tangible user interfaces (TUIs) that stimulate players and engage them into fun exercising activities is starting to attract the attention of many researchers and companies. This paper presents the software and hardware design and development of a TUI intended for exercise-based games targeted mostly towards children. The proposed TUI, SmartPads, can be constructed using elemental building blocks (pads) into numerous shapes. The pads-which are individually controlled by microcontrollers-are mapped onto a computer screen in real-time. A user interacts with the TUI by stepping on the pads. To evaluate the functionality and efficiency of the TUI, we developed three games in the field of exergaming. The games also have an educational value and are integrated with multimedia output modalities to enrich children's playing experience.
C1 [Hafidh, Basim; Al Osman, Hussein; Karime, Ali; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON K1N 6N5, Canada.
   [Alja'am, Jihad Mohamad] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
C3 University of Ottawa; Qatar University
RP Hafidh, B (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON K1N 6N5, Canada.
EM bhafi014@uottawa.ca; halos072@uottawa.ca; akari049@uottawa.ca;
   jaam@qu.edu.qa; elsaddik@uottawa.ca
RI ; /D-4159-2009
OI Karime, Ali/0000-0001-7826-1540; /0000-0002-7690-8547
FU Qatar National Research Fund NPRP [09 - 052 - 5 - 003]
FX This work is funded by a grant from the Qatar National Research Fund
   NPRP 09 - 052 - 5 - 003. Its contents are solely the responsibility of
   the authors and do not necessarily represent the official views of the
   QNRF.
CR Baihua L., 2011, 4th Annual International Conference on Computer Games, Multimedia and Allied Technology, P103
   Benford S., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P556, DOI 10.1145/332040.332502
   Bisbarrow J, 1993, ONTARIO COMMUNITY AC
   Bolas M, 2005, CHI 05 EXT ABSTR HUM, P2051
   Hasikin K, 2012, MED MEAS APPL P MEME, P1, DOI DOI 10.1007/S11042-011-0985-9
   Hoysniemi Johanna., 2006, Comput. Entertain, V4, P8, DOI [10.1145/1129006.1129019, DOI 10.1145/1129006.1129019]
   Ichida H., 2004, IEEE VR, P2
   Inkpen K., 1995, Conference companion on Human factors in computing systems, P258
   Jackson AS, 2007, MED SCI SPORT EXER, V39, P821, DOI 10.1249/mss.0b013e318054d3ca
   Karime A., 2011, IEEE Workshop on Multimedia Services and Technologies for E-Health (ICME), Barcelona, Spain, P1, DOI DOI 10.1109/ICME.2011.6011852
   Karime A, 2012, IEEE IMTC P, P2563
   KARVONEN MJ, 1957, ANN MED EXP BIOL FEN, V35, P307
   Kostomaj M, 2011, MULTIMED TOOLS APPL, V54, P499, DOI 10.1007/s11042-010-0549-4
   Lund HH, 2005, ARTIF LIFE ROBOT, V9, P165, DOI 10.1007/s10015-005-0350-z
   Richardson Bruce, 2004, CHI'04 extended abstracts on Human factors in computing systems, P1529, DOI DOI 10.1145/985921.986107
   Sell T.C., 2008, SCI GOLF, P128
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Xu D., 2005, Proceedings of the SIXTH Conference in the Department of Computing, P579
NR 18
TC 6
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1507
EP 1530
DI 10.1007/s11042-013-1459-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300022
DA 2024-07-18
ER

PT J
AU Li, B
   Godil, A
   Johan, H
AF Li, Bo
   Godil, Afzal
   Johan, Henry
TI Hybrid shape descriptor and meta similarity generation for non-rigid and
   partial 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Non-rigid models; Partial similarity retrieval;
   Hybrid shape descriptor; Meta similarity
ID FEATURES
AB Non-rigid and partial 3D model retrieval are two significant and challenging research directions in the field of 3D model retrieval. Little work has been done in proposing a hybrid shape descriptor that works for both retrieval scenarios, let alone the integration of the component features of the hybrid shape descriptor in an automatic way. In this paper, we propose a hybrid shape descriptor that integrates both geodesic distance-based global features and curvature-based local features. We also develop an automatic algorithm to generate meta similarity resulting from different component features of the hybrid shape descriptor based on Particle Swarm Optimization. Experimental results demonstrate the effectiveness and advantages of our framework, as well as the significant improvements in retrieval performances. The framework is general and can be applied to similar approaches that integrate more features for the development of a single algorithm for both non-rigid and partial 3D model retrieval.
C1 [Li, Bo; Godil, Afzal] NIST, Gaithersburg, MD 20899 USA.
   [Johan, Henry] Fraunhofer IDM NTU, Singapore, Singapore.
C3 National Institute of Standards & Technology (NIST) - USA; Nanyang
   Technological University
RP Li, B (corresponding author), NIST, Gaithersburg, MD 20899 USA.
EM li.bo.ntu0@gmail.com; afzal.godil@nist.gov; henryjohan@ntu.edu.sg
CR Akbar S, 2006, 2006 INT C COMPUTING, P1
   [Anonymous], LNCS
   [Anonymous], 2006, P EUR IT CHAPT C
   [Anonymous], 2011, Proceedings of the 4th Eurographics conference on 3D Object Retrieval, EG 3DOR'11, DOI DOI 10.2312/3DOR/3DOR11/049-056
   [Anonymous], EVALUATION LOCAL SHA
   [Anonymous], UUCS2007015 UTR U DE
   [Anonymous], EUR WORKSH 3D OBJ RE
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], INT J SHAPE MODEL
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Ben Hamza A, 2003, LECT NOTES COMPUT SC, V2886, P378
   Ben-Chen M., 2008, Proceedings of the 1st Eurographics Conference on 3D Object Retrieval, P1
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bustos B, 2012, MULTIMED TOOLS APPL, V58, P81, DOI 10.1007/s11042-010-0689-6
   Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   Eberhart R. C., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1927, DOI 10.1109/CEC.1999.785508
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gatzke T, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/SMI.2005.13
   Groenen P.J. F., 2004, Multidimensional scaling
   Hien Van Nguyen, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2893, DOI 10.1109/ICIP.2011.6116153
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Laga H, 2008, LECT NOTES ARTIF INT, V4938, P210, DOI 10.1007/978-3-540-78159-2_20
   Lavoue G., 2011, Eurographics Conference on 3D Object Retrieval, P41, DOI DOI 10.2312/3DOR/3DOR11/041-048
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li XY, 2009, MODELLING SIMULATION, P437, DOI 10.1109/ICIP.2009.5414415
   Lian Z., 2010, Eurographics Workshop on 3D Object Retrieval, V10, P101, DOI [10.2312/3DOR/3DOR10/101-108, 10.1109/CVPR.2014.491, DOI 10.2312/3DOR/3DOR10/101-108]
   Lian ZH, 2013, INT J COMPUT VISION, V102, P221, DOI 10.1007/s11263-012-0548-1
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Lian ZH, 2010, IEEE IMAGE PROC, P3181, DOI 10.1109/ICIP.2010.5654226
   Liu Y., 2006, Computer Vision and Pattern Recognition, P2025, DOI DOI 10.1109/CVPR.2006.278
   Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maes C., 2010, BIOMETRICS THEORY AP, DOI [DOI 10.1109/BTAS.2010.5634543, 10.1109/BTAS.2010.5634543]
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   Raviv D., 2010, ACM WORKSHOP 3D OBJE, P39
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506
   Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Smeets D, 2010, LECT NOTES COMPUT SC, V6169, P162, DOI 10.1007/978-3-642-14061-7_16
   Smeets D, 2009, LECT NOTES COMPUT SC, V5702, P757, DOI 10.1007/978-3-642-03767-2_92
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Toldo R, 2010, VISUAL COMPUT, V26, P1257, DOI 10.1007/s00371-010-0519-x
   Villani C., 2003, TOPICS OPTIMAL TRANS
   Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180
   ZHANG H., 2007, P EUROGRAPHICS STATE, P1, DOI DOI 10.1109/IPDPS.2007.370248
   Zhouhui Lian, 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P116, DOI 10.1109/3DIMPVT.2011.22
   Zhouhui Lian, 2010, Proceedings of the Shape Modeling International (SMI 2010), P25, DOI 10.1109/SMI.2010.20
NR 74
TC 20
Z9 23
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1531
EP 1560
DI 10.1007/s11042-013-1464-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300023
DA 2024-07-18
ER

PT J
AU Li, Y
   Liang, S
   Bai, BD
   Feng, D
AF Li, Ying
   Liang, Shi
   Bai, Bendu
   Feng, David
TI Detecting and tracking dim small targets in infrared image sequences
   under complex backgrounds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dim small target detection and tracking; Variance weighted information
   entropy (variance WIE); Local binary pattern (LBP); Mean shift
ID POINT TARGET; FILTERS
AB This paper presents a unified framework for automatically detecting and tracking dim small targets in infrared (IR) image sequence under complex backgrounds. Firstly, the variance weighted information entropy (variance WIE) followed by a region growing technique is introduced to segment the candidate targets in a single-frame IR image after background suppression. Then the pipeline filter is used to verify the real targets. The position and the size of the detected target are then obtained to initialize the tracking algorithm. Secondly, we adopt an improved local binary pattern (LBP) scheme to represent the target texture feature and propose a joint gray-texture histogram method for a more distinctive and effective target representation. Finally, target tracking is accomplished by using the mean shift algorithm. Experimental results indicate that the proposed method can effectively detect the dim small targets under complex backgrounds and has better tracking performance compared with the gray histogram based tracking methods such as the mean shift and the particle filtering.
C1 [Li, Ying; Liang, Shi] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.
   [Bai, Bendu] Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
   [Feng, David] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
C3 Northwestern Polytechnical University; Xi'an University of Posts &
   Telecommunications; University of Sydney
RP Li, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.
EM lybyp@nwpu.edu.cn
OI Feng, Dagan/0000-0002-3381-214X
FU National Natural Science Foundation of China [60873086]; Aeronautics
   Science Foundation of China [2011ZD53049]
FX We are very grateful to the anonymous reviewers for their constructive
   comments and suggestions that help improve the quality of this
   manuscript. We also appreciate the providers of the test sequences. This
   works was supported by the National Natural Science Foundation of China
   (No. 60873086), and the Aeronautics Science Foundation of China (No.
   2011ZD53049).
CR [Anonymous], 2012, MULTIM TOOLS APPL
   [Anonymous], OPT ENG
   [Anonymous], P 2006 IEEE POW ENG
   [Anonymous], INFRARED PHYS TECHNO
   Bai XZ, 2010, SIGNAL PROCESS, V90, P1643, DOI 10.1016/j.sigpro.2009.11.014
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Deng H, 2011, INFRARED PHYS TECHN, V54, P100, DOI 10.1016/j.infrared.2011.01.003
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Huang K, 2010, INFRARED PHYS TECHN, V53, P208, DOI 10.1016/j.infrared.2009.12.001
   Kerekes R, 2009, IEEE T AERO ELEC SYS, V45, P289, DOI 10.1109/TAES.2009.4805280
   Li Y, 2011, SIGNAL PROCESS, V91, P1216, DOI 10.1016/j.sigpro.2010.12.003
   Liu RM, 2007, MEAS SCI TECHNOL, V18, P3025, DOI 10.1088/0957-0233/18/9/038
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Peng GH, 2012, ADV MATER RES-SWITZ, V346, P615, DOI 10.4028/www.scientific.net/AMR.346.615
   Polat E, 2006, IEEE T MULTIMEDIA, V8, P1156, DOI 10.1109/TMM.2006.884624
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Soni T, 1993, IEEE T IMAGE PROCESS, V2, P327, DOI 10.1109/83.236534
   Valtteri V, 2007, PROC IEEE COMPUT VIS, P1
   Wang P, 2009, ELECTRON LETT, V45, P156, DOI 10.1049/el:20092206
   Wang S., 2010, 2010 IEEE 37th International Conference on Plasma Sciences (ICOPS 2010), DOI 10.1109/PLASMA.2010.5534027
   Yang L, 2006, ELECTRON LETT, V42, P857, DOI 10.1049/el:20060827
   Yang L, 2004, ELECTRON LETT, V40, P1083, DOI 10.1049/el:20045204
   Yilmaz A, 2003, IMAGE VISION COMPUT, V21, P623, DOI 10.1016/S0262-8856(03)00059-3
   Zhang B, 2007, IEEE AERO EL SYS MAG, V22, P20, DOI 10.1109/MAES.2007.4301021
   Zhang F, 2005, INFRARED PHYS TECHN, V46, P323, DOI 10.1016/j.infrared.2004.06.001
   Zhang TX, 2007, PATTERN RECOGN LETT, V28, P246, DOI 10.1016/j.patrec.2006.07.006
NR 32
TC 26
Z9 29
U1 0
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1179
EP 1199
DI 10.1007/s11042-012-1258-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000010
DA 2024-07-18
ER

PT J
AU Yoon, JC
   Lee, SY
   Lee, IK
   Kang, H
AF Yoon, Jong-Chul
   Lee, Sun-Young
   Lee, In-Kwon
   Kang, Henry
TI Optimized image resizing using flow-guided seam carving and an
   interactive genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image resizing; Structure-aware energy field; Interactive genetic
   algorithm
AB In this paper, we introduce a novel method for content-aware image resizing based on flow-guided seam carving. It extends the existing seam carving framework by replacing the conventional energy field with a "structure-aware" energy field that takes into account the feature orientations in the image. Guided by this new energy field, our approach excels in preserving (i.e., avoiding the distortion of) important structures in the image, such as shape boundaries. We also present a simple user interface to further optimize the resizing result based on the genetic selection process among multiple resizing operators such as scaling, cropping, and flow-guided seam carving. We show that such simple user interaction, coupled with the genetic algorithm, dramatically increases the chances of producing the user-desired outcome.
C1 [Yoon, Jong-Chul] Kangwon Natl Univ, Dept Broadcasting Visual Arts Technol & Entertain, Samcheok, South Korea.
   [Lee, Sun-Young; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
   [Kang, Henry] Univ Missouri, Dept Comp Sci, St Louis, MO 63121 USA.
C3 Kangwon National University; Yonsei University; Washington University
   (WUSTL); University of Missouri System; University of Missouri Saint
   Louis
RP Yoon, JC (corresponding author), Kangwon Natl Univ, Dept Broadcasting Visual Arts Technol & Entertain, Samcheok, South Korea.
EM media19@kangwon.ac.kr; shepherd@cs.yonsei.ac.kr; iklee@yonsei.ac.kr;
   kang@cs.umsl.edu
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882
FU Kangwon National University; National Research Foundation of Korea (NRF)
   - Korea government (MEST) [2011-0028568]
FX This study was supported by 2011 Research Grant form Kangwon National
   University and the National Research Foundation of Korea (NRF) grant
   funded by the Korea government (MEST) (No. 2011-0028568).
CR [Anonymous], SHAR YOUR PHOT WATCH
   [Anonymous], ACM T GRAPH
   [Anonymous], INTRO GENETIC ALGORI
   [Anonymous], 1996, ANISOTROPIC DIFFUSIO
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Hays J., 2004, PROC NPAR 01, P113
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P615, DOI 10.1109/TCE.2011.5955199
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195
   Pham T.Q., 2006, Spatiotonal adaptivity in superresolution of undersampled image sequences
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Tschumperlé D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Y- S, 2008, P ACM SIGGRAPH ASIA, P1
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yoon JC, 2012, IEEE T VIS COMPUT GR, V18, P58, DOI 10.1109/TVCG.2011.47
NR 26
TC 7
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1013
EP 1031
DI 10.1007/s11042-012-1242-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000003
DA 2024-07-18
ER

PT J
AU Kim, YH
   Park, WH
AF Kim, Yong-Ho
   Park, Won Hyung
TI A study on cyber threat prediction based on intrusion detection event
   for APT attack detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber threat; Intrusion detection event; APT malware
AB A number of APT(Advanced Persistent Threat) attack malwares are being detected as of late together with attempts by the state and enterprises to leak personal information. To detect and respond to them, malwares must first be detected by security monitoring system. In particular, availability of a method to detect and predict such malwares in advance will lead to preventing security incidents. This study will propose a method of prediction based on intrusion detection event and a functional configuration to realize the method and will assess the prediction model based on intrusion detection events proposed through a test consisting of the stages of learning, prediction and evaluation.
C1 [Kim, Yong-Ho] Sungkyunkwan Univ, Dept Informat & Commun Engn, Seoul 142816, South Korea.
   [Park, Won Hyung] Far East Univ, Dept Informat Management, Chungbuk 369700, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Park, WH (corresponding author), Far East Univ, Dept Informat Management, Chungbuk 369700, South Korea.
EM porsche0911@paran.com; whpark@kdu.ac.kr
CR AMMANN D, 2002, P 9 ACM C COMP COMM
   Cuppens F, 2002, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2002.1004372
   Lee W, 1998, PROCEEDINGS OF THE SEVENTH USENIX SECURITY SYMPOSIUM, P79
   Ning P., 2004, ACM Transactions on Information and Systems Security, V7, P274, DOI 10.1145/996943.996947
   PHILLIPS C, 1998, P 1998 WORKSH NEW SE
   Qin XZ, 2003, LECT NOTES COMPUT SC, V2820, P73
   Sheyner O, 2002, P IEEE S SECUR PRIV, P273, DOI 10.1109/SECPRI.2002.1004377
   Thurimella J. J. T., 2006, P INT S REC ADV INTR, P1
   Xinming Ou WFB, 2006, ACM C COMP COMM SEC
NR 9
TC 33
Z9 46
U1 0
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 685
EP 698
DI 10.1007/s11042-012-1275-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400019
DA 2024-07-18
ER

PT J
AU Wang, RM
   Du, H
   Zhou, F
   Deng, DG
   Liu, Y
AF Wang, Ruomei
   Du, Heng
   Zhou, Fan
   Deng, Daiguo
   Liu, Yu
TI An adaptive neural fuzzy network clothing comfort evaluation model and
   application in digital home
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive fuzzy neural network; Clothing comfort evaluation
ID FABRICS
AB With the development of digital TV, especially 3D technologies, some applications in the digital home industry have been reported to meet and even exceed customer expectation in the market place for enterprise. In order to evaluate the clothing comfort performance in the digital e-commerce service, the clothing comfort model is very important. Considered the physical, physiological and psychological factors, a theoretical clothing comfort evaluation model is presented based on the adaptive fuzzy neural network in this paper. According to the characters of clothing comfort, Fuzzy Neural Networks (FNN) can provide a very human machine knowledge representation scheme friendly for acquiring, representing and using the knowledge of the domain expert. This is a significant advantage for clothing comfort evaluation where the exact system transfer functions cannot be well modeled and adequate training data sets are not available. The experiment results shown that there has the same prediction trend about the experiment result and simulation result. This clothing comfort evaluation model is used as a component in the smart clothing function user experience system.
C1 [Wang, Ruomei; Du, Heng; Zhou, Fan; Deng, Daiguo; Liu, Yu] Sun Yat Sen Univ, Sch Informat Sci & Technol, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Guangzhou 510006, Guangdong, Peoples R China.
   [Wang, Ruomei; Zhou, Fan] Sun Yat Sen Univ, Shenzhen Digital Home Key Technol Engn Lab, Shenzhen 518057, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Du, H (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Guangzhou 510006, Guangdong, Peoples R China.
EM duheng0522@gmail.com; isszf@mail.sysu.edu.cn
RI Zhou, fan/KIL-4066-2024
FU National Natural Science Foundation of China [61073131]; NSFC-Guangdong
   Joint Fund [U1135003, U0935004]; National Key Technology RD Program
   [2011BAH27B01, 2011BHA16B08]; Industry-academy-research Project of
   Guangdong [2011A091000032]
FX This research is supported by the National Natural Science Foundation of
   China(61073131), NSFC-Guangdong Joint Fund (No. U1135003, U0935004), the
   National Key Technology R&D Program (No. 2011BAH27B01, 2011BHA16B08),
   the Industry-academy-research Project of Guangdong (No. 2011A091000032).
CR Alahmer A, 2012, BUILD ENVIRON, V48, P146, DOI 10.1016/j.buildenv.2011.08.013
   DUBOIS D, 1997, P EUFIT 97 AACH GERM, P975
   Ertugrul I, 2009, J INTELL MANUF, V20, P139, DOI 10.1007/s10845-008-0230-1
   Havenith G, 2004, APPL ERGON, V35, P3, DOI 10.1016/j.apergo.2003.11.001
   Huang JH, 2007, J TEST EVAL, V35, P455
   Jain V., 2004, Journal of Manufacturing Technology Management, V15, P735, DOI 10.1108/17410380410565320
   Kwak C, 2000, J INTELL MANUF, V11, P485, DOI 10.1023/A:1008974314490
   Li J, 2011, ADV MATER RES-SWITZ, V187, P448, DOI 10.4028/www.scientific.net/AMR.187.448
   Li Y, 2001, SCI CLOTHING COMFORT, P188
   Liu H, 2011, TEXT RES J, V81, P1307, DOI 10.1177/0040517510399961
   Liu WW, 2007, ENERG BUILDINGS, V39, P1115, DOI 10.1016/j.enbuild.2006.12.005
   Marszalek A, 1999, INT J IND ERGONOM, V25, P195, DOI 10.1016/S0169-8141(98)00107-3
   Nawaz N, 2011, ADV MATER RES-SWITZ, V331, P184, DOI 10.4028/www.scientific.net/AMR.331.184
   Seo H., 2007, P 2007 ACM S SOLID P, P431, DOI DOI 10.1145/1236246.1236308
   Wang G, 2003, TEXT RES J, V73, P113, DOI 10.1177/004051750307300204
   Wang Z, 2003, SEN-I GAKKAISHI, V59, P187
   Wong A.S. W., 2002, Prediction of Clothing Sensory Comfort Using Neural Networks and Fuzzy Logic
   Wong ASW, 2004, SEN-I GAKKAISHI, V60, P293
   Wong ASW, 2004, TEXT RES J, V74, P13, DOI 10.1177/004051750407400103
   Wong ASW, 2003, TEXT RES J, V73, P31, DOI 10.1177/004051750307300106
   Wong WK, 2006, J INTELL MANUF, V17, P341, DOI 10.1007/s10845-005-0007-8
   Yu Y, 2011, ADV MATER RES-SWITZ, V156-157, P717, DOI 10.4028/www.scientific.net/AMR.156-157.717
NR 22
TC 10
Z9 11
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 395
EP 410
DI 10.1007/s11042-013-1519-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400002
DA 2024-07-18
ER

PT J
AU Louro, A
   Machado, W
   Gonzaga, A
AF Louro, Antonio
   Machado, Will
   Gonzaga, Adilson
TI Smoothing: A natural way to detect contour features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dominant points; Corners; Smoothing; Entropy; Multi-scale
ID CORNER DETECTION; DOMINANT POINTS; ALGORITHMS
AB This work presents a dominant point detector. The angles of the contour are characterized through local entropy produced by a rotationally symmetric smoothing. The proposed scheme uses a punctual multi-scale approach in which only the candidates are analyzed in higher scales. To preserve the angle-entropy relationship in higher scales, we propose a smoothing kernel which presents special features that ensure its steepness in every scale. It is built from the sum of two Gaussians with different openings resembling center-surround receptive fields. The outputs of the proposed method are confronted to a ground-truth found in the literature, and to popular boundary based corner detectors that used the same set of images. Results reveal that the proposed detector performs extremely well.
C1 [Louro, Antonio] Univ Estadual Santa Cruz, Ilheus, BA, Brazil.
   [Machado, Will] PUC Minas Pocos de Caldas, Pocos De Caldas, MG, Brazil.
   [Gonzaga, Adilson] Univ Sao Paulo, Dept Engn Eletr EESC, Sao Carlos, SP, Brazil.
C3 Universidade Estadual de Santa Cruz; Universidade de Sao Paulo
RP Gonzaga, A (corresponding author), Univ Sao Paulo, Dept Engn Eletr EESC, Ave Trabalhador Sao Carlense 400, Sao Carlos, SP, Brazil.
EM louro@uesc.br; will@pucpcaldas.br; agonzaga@sc.usp.br
RI Gonzaga, Adilson/B-4883-2010
OI Gonzaga, Adilson/0000-0003-2193-9394
CR [Anonymous], 1977, TECHNIQUES AUTOMATIC
   [Anonymous], 2004, DISTINCTIVE IMAGE FE
   [Anonymous], 2008, INTERACTIVE CURVE MO
   ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C
   ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   BEUS HL, 1987, PATTERN RECOGN, V20, P291, DOI 10.1016/0031-3203(87)90004-5
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Chetverikov D., 1999, 23 WORKSHOP AUSTRIAN, P175
   Cornic P, 1997, PATTERN RECOGN LETT, V18, P13, DOI 10.1016/S0167-8655(96)00116-X
   Dutta A, 2008, IETE TECH REV, V25, P123
   FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825
   Guru DS, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P417, DOI 10.1109/CCCRV.2004.1301477
   Harris C., 1988, ALVEY VISION C, P147151
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   LEE JS, 1993, PATTERN RECOGN, V26, P853, DOI 10.1016/0031-3203(93)90051-W
   Li BC, 1996, PATTERN RECOGN, V29, P1049, DOI 10.1016/0031-3203(95)00134-4
   Li ZL, 1995, CARTOGR J, V32, P121, DOI 10.1179/caj.1995.32.2.121
   LIU HC, 1990, PATTERN RECOGN, V23, P51, DOI 10.1016/0031-3203(90)90048-P
   Mokhtarian F, 2006, COMPUT VIS IMAGE UND, V102, P81, DOI 10.1016/j.cviu.2005.11.001
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   PEI SC, 1992, PATTERN RECOGN, V25, P1307, DOI 10.1016/0031-3203(92)90143-7
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sobania A, 2005, PATTERN RECOGN, V38, P1087, DOI 10.1016/j.patcog.2004.10.009
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
NR 31
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2111
EP 2124
DI 10.1007/s11042-012-1237-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500032
DA 2024-07-18
ER

PT J
AU Zhang, HB
   Li, SA
   Chen, SY
   Su, SZ
   Duh, DJ
   Li, SZ
AF Zhang, Hong-Bo
   Li, Shang-An
   Chen, Shu-Yuan
   Su, Song Zhi
   Duh, Der-Jyh
   Li, Shao Zi
TI Adaptive photograph retrieval method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photograph retrieval; Graphics retrieval; Image retrieval; Histogram of
   oriented gradient; Pixel-based retrieval; Graphics/image classification
ID IMAGE RETRIEVAL
AB Access to electronic books, electronic journals, and web portals, which may contain graphics (drawings or diagrams) and images, is now ubiquitous. However, users may have photographs that contain graphics or images and want to access an electronic database to retrieve this information. Hence, an effective photograph retrieval method is needed. Although many content-based retrieval methods have been developed for images and graphics, few are designed to retrieve graphics and images simultaneously. Moreover, existing graphics retrieval methods use contour-based rather than pixel-based approaches. Contour-based methods, which are concerned with lines or curves, are inappropriate for images. To retrieve graphics and images simultaneously, this work applies an adaptive retrieval method. The proposed method uses histograms of oriented gradient (HOG) as pixel-based features. However, the characteristics of graphics and images differ, and this affects feature extraction and retrieval accuracy. Thus, an adaptive method is proposed that selects different HOG-based features for retrieving graphics and images. Experimental results demonstrate the proposed method has high retrieval accuracy even under noisy conditions.
C1 [Zhang, Hong-Bo; Su, Song Zhi; Li, Shao Zi] Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Fujian, Peoples R China.
   [Zhang, Hong-Bo; Su, Song Zhi; Li, Shao Zi] Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Fujian, Peoples R China.
   [Li, Shang-An; Chen, Shu-Yuan] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
   [Duh, Der-Jyh] Chien Hsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Xiamen University; Xiamen University; Yuan Ze University; Chien Hsin
   University of Science & Technology
RP Chen, SY (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
EM cschen@saturn.yzu.edu.tw
RI Li, SZ/G-3959-2010
FU National Science Council of Taiwan [NSC-100-2221-E-155-086]; National
   Nature Science Foundation of China [61202143]
FX This work was partially supported by National Science Council of Taiwan,
   under Grant No. NSC-100-2221-E-155-086 and National Nature Science
   Foundation of China, under Grant No. 61202143.
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chi YL, 2007, PATTERN RECOGN, V40, P244, DOI 10.1016/j.patcog.2006.06.009
   Chio JW, 2012, J PATTERN RECOGNIT R, V7, P56, DOI 10.13176/11.151
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Huang Y-W, 2007, ASIAN J HLTH INFORM, V2, P79
   Kahn CE, 2012, J DIGIT IMAGING, V25, P37, DOI 10.1007/s10278-011-9399-5
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu RJ, 2010, PATTERN RECOGN, V43, P1907, DOI 10.1016/j.patcog.2009.11.022
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muller H, OVERVIEW CLEF 2010 M
   Qi H, 2010, PATTERN RECOGN, V43, P2017, DOI 10.1016/j.patcog.2010.01.007
   Sidiropoulos P, 2011, PATTERN RECOGN, V44, P739, DOI 10.1016/j.patcog.2010.09.014
   Su SZ, 2010, ELECTRON LETT, V46, P996, DOI 10.1049/el.2010.1104
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Vrochidis S, 2010, WORLD PAT INF, V32, P94, DOI 10.1016/j.wpi.2009.05.010
NR 22
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2189
EP 2209
DI 10.1007/s11042-012-1233-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500036
DA 2024-07-18
ER

PT J
AU Qu, YY
   Wu, SJ
   Liu, H
   Xie, Y
   Wang, HZ
AF Qu, Yanyun
   Wu, Shaojie
   Liu, Han
   Xie, Yi
   Wang, Hanzi
TI Evaluation of local features and classifiers in BOW model for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of words; MSER; Hessian-Laplace; SIFT; EMD spatial kernel; Keypoint
   detector; Keypoint descriptor
ID OBJECT CATEGORIES; TEXTURE; SCALE
AB Bag-of-word (BOW) is used in many state-of-the-art methods of image classification, and it is especially suitable for multi-class classification. Many kinds of local features and classifiers are applicable for the BOW model. However, it is unclear which kind of local feature is the most distinctive and meanwhile robust, and which classifier can optimize classification performance. In this paper, we discuss the implementation choices in the BOW model. Further, we evaluate the influences of local features and classifiers on object and texture recognition methods in the framework of the BOW model. To evaluate the implementation choices, we use two popular datasets: the Xerox7 dataset and the UIUCTex dataset. Extensive experiments are carried out to compare the performance of different detectors, descriptors and classifiers in term of classification accuracy on the object category dataset and the texture dataset. We find that the combinational detector which combines the MSER detector with the Hessian-Laplacian detector is efficient to find discriminative regions. We also find that the SIFT descriptor performs better than the other descriptors for image classification, and that the SVM classifier with the EMD kernel is superior to other classifiers. More than that, we propose an EMD spatial kernel to encode the spatial information of local features. The EMD spatial kernel is implemented on the Xerox7 dataset, the 4-class VOC2006 dataset and the 4-class Caltech101 dataset. The experimental results show that the proposed kernel outperforms the EMD kernel which does not consider the spatial information in image classification.
C1 [Qu, Yanyun; Wu, Shaojie; Liu, Han; Xie, Yi] Xiamen Univ, Dept Comp Sci, Xiamen, Peoples R China.
   [Wang, Hanzi] Xiamen Univ, Ctr Pattern Anal & Machine Intelligence, Xiamen, Peoples R China.
C3 Xiamen University; Xiamen University
RP Wang, HZ (corresponding author), Xiamen Univ, Ctr Pattern Anal & Machine Intelligence, Xiamen, Peoples R China.
EM yyqu@xmu.edu.cn; hanzi.wang@ieee.org
RI wang, hao/HSE-7975-2023; wang, handong/HLH-5739-2023; Wang,
   Han/GPW-9809-2022
FU Fundamental Research Funds for the Central Universities [2010121067];
   National Defense Basic Scientific Research program of China
   [B1420110155]; National Natural Science Foundation of China [61170179];
   Special Research Fund for the Doctoral Program of Higher Education of
   China [20110121110033]; Xiamen Science & Technology Planning Project
   Fund of China [3502Z20116005]
FX The authors would like to thank the reviewers for their valuable
   comments, which greatly helped to improve the quality of the paper. The
   research work was supported by the Fundamental Research Funds for the
   Central Universities (2010121067), National Defense Basic Scientific
   Research program of China under Grant (B1420110155), National Natural
   Science Foundation of China (61170179), the Special Research Fund for
   the Doctoral Program of Higher Education of China under Project
   (20110121110033), and Xiamen Science & Technology Planning Project Fund
   (3502Z20116005) of China.
CR [Anonymous], 2004, P ECCV WORKSH STAT L
   [Anonymous], 2006, P EUR C COMP VIS
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Cheng YY, 2010, P 2 INT C INT MULT C, P73
   Farquhar J, 2005, D91 SECURESCM
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   LARLUS D, 2006, P BRIT MACH VIS C
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Li Y., 2008, 4 INT C WIRELESS COM, P1
   Ling HB, 2005, IEEE I CONF COMP VIS, P1466
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moosmann F., 2006, Advances in neural information processing systems, V19
   NOWAK E, 2006, P EUR C COMP VIS
   PERRONNIN F, 2006, P EUR C COMP VIS
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang SG, 2010, PROCEEDINGS OF THE ASME JOINT RAIL CONFERENCE, VOL 2, P501, DOI 10.1145/1873951.1874018
NR 28
TC 7
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 605
EP 624
DI 10.1007/s11042-012-1107-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900002
DA 2024-07-18
ER

PT J
AU Strat, ST
   Benoit, A
   Lambert, P
   Caplier, A
AF Strat, Sabin Tiberius
   Benoit, Alexandre
   Lambert, Patrick
   Caplier, Alice
TI Retina enhanced SURF descriptors for spatio-temporal concept detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag ofWords; Retina enhancement; Low-level saliency; Semantics; SURF;
   Video indexation
ID MODEL
AB This paper proposes to investigate the potential benefit of the use of low-level human vision behaviors in the context of high-level semantic concept detection. A large part of the current approaches relies on the Bag-of-Words (BoW) model, which has proven itself to be a good choice especially for object recognition in images. Its extension from static images to video sequences exhibits some new problems to cope with, mainly the way to use the temporal information related to the concepts to detect (swimming, drinking...). In this study, we propose to apply a human retina model to preprocess video sequences before constructing the State-Of-The-Art BoW analysis. This preprocessing, designed in a way that enhances relevant information, increases the performance by introducing robustness to traditional image and video problems, such as luminance variation, shadows, compression artifacts and noise. Additionally, we propose a new segmentation method which enables a selection of low-level spatio-temporal potential areas of interest from the visual scene, without slowing the computation as much as a high-level saliency model would. These approaches are evaluated on the TrecVid 2010 and 2011 Semantic Indexing Task datasets, containing from 130 to 346 high-level semantic concepts. We also experiment with various parameter settings to check their effect on performance.
C1 [Strat, Sabin Tiberius; Benoit, Alexandre; Lambert, Patrick] Univ Savoie, LISTIC, Annecy Le Vieux, France.
   [Strat, Sabin Tiberius] Univ Politech Bucharest, LAPI, Bucharest, Romania.
   [Caplier, Alice] Univ Grenoble, Gipsa Lab, St Martin Dheres, France.
C3 Universite Savoie Mont Blanc; National University of Science &
   Technology POLITEHNICA Bucharest; Communaute Universite Grenoble Alpes;
   Institut National Polytechnique de Grenoble; Universite Grenoble Alpes
   (UGA); Centre National de la Recherche Scientifique (CNRS)
RP Benoit, A (corresponding author), Univ Savoie, LISTIC, Annecy Le Vieux, France.
EM sabin-tiberius.strat@univ-savoie.fr; alexandre.benoit@univ-savoie.fr;
   patrick.lambert@univ-savoie.fr; alice.caplier@gipsa-lab.grenoble-inp.fr
OI benoit, alexandre/0000-0002-0627-4948
CR Ali WBH, 2011, KDIR 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND INFORMATION RETRIEVAL, P277
   [Anonymous], 2008, C COMP VIS PATT REC
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], P 2011 JOINT ACM WOR
   [Anonymous], P TRECVID 2011 NIST
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Benoit A, 2010, COMPUT VIS IMAGE UND, V114, P758, DOI 10.1016/j.cviu.2010.01.011
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Gorisse D., 2010, TREC ONL P GAITH ET
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herault J., 2009, PROGR NEURAL PROCESS
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Mantiuk R, 2005, PROC SPIE, V5666, P204, DOI 10.1117/12.586757
   Niaz U, 2011, 2011 15 INT WORKSH V
   Redi M, 2011, ICMR 2011, DOI [10.1145/1991996.1992035, DOI 10.1145/1991996.1992035.HTTP://WWW.EUREC0M.FR/PUBLICATI0N/3360]
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   SPRAGUE JM, 1965, EXP NEUROL, V11, P115, DOI 10.1016/0014-4886(65)90026-9
   van de Sande K.E. A., 2008, CIVR, P141, DOI DOI 10.1145/1386352.1386376
   Yilmaz E., 2008, P 31 ANN INT ACM SIG
   Yilmaz Emine, 2006, Proceedings of the 2006 ACM CIKM International Conference on Information and Knowledge Management, Arlington, Virginia, USA, November 6-11, 2006, P102, DOI [10.1145/1183614.1183633 (cit. on p. 34, DOI 10.1145/1183614.1183633(CIT.ONP.34]
NR 27
TC 6
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 443
EP 469
DI 10.1007/s11042-012-1280-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400012
DA 2024-07-18
ER

PT J
AU Janowski, L
   Kozlowski, P
   Baran, R
   Romaniak, P
   Glowacz, A
   Rusc, T
AF Janowski, Lucjan
   Kozlowski, Piotr
   Baran, Remigiusz
   Romaniak, Piotr
   Glowacz, Andrzej
   Rusc, Tomasz
TI Quality assessment for a visual and automatic license plate recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience; License plate recognition; Automatic plate
   recognition; Compression influence
AB Video transmission and analysis is often utilized in applications outside of the entertainment sector, and generally speaking this class of video is used to perform specific tasks. Examples of these applications include security and public safety. The Quality of Experience (QoE) concept for video content used for entertainment differs significantly from the QoE of surveillance video used for recognition tasks. This is because, in the latter case, the subjective satisfaction of the user depends on achieving a given functionality. Recognizing the growing importance of video in delivering a range of public safety services, we focused on developing critical quality thresholds in license plate recognition tasks based on videos streamed in constrained networking conditions. Since the number of surveillance cameras is still growing it is obvious that automatic systems will be used to do the tasks. Therefore, the presented research includes also analysis of automatic recognition algorithms.
C1 [Janowski, Lucjan; Kozlowski, Piotr; Glowacz, Andrzej] AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
   [Baran, Remigiusz] Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, PL-25314 Kielce, Poland.
   [Romaniak, Piotr] AGH Univ Sci & Technol, CYFRONET AGH, Acad Comp Ctr, PL-30950 Krakow, Poland.
   [Rusc, Tomasz] Jan Kochanowski Univ, Inst Phys, PL-25406 Kielce, Poland.
C3 AGH University of Krakow; Kielce University of Technology; AGH
   University of Krakow; Jan Kochanowski University
RP Janowski, L (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM janowski@kt.agh.edu.pl
RI Janowski, Lucjan/B-2264-2013; Romaniak, Piotr/C-7763-2011; Baran,
   Remigiusz/E-5457-2014
OI Baran, Remigiusz/0000-0002-3643-5642; Janowski,
   Lucjan/0000-0002-3151-2944
FU European Commission under Grant INDECT [FP7-218086]; European Regional
   Development Fund within INSIGMA project [POIG.01.01.02-00-062/09];
   National Centre for Research and Development (NCBiR) [SP/I/1/77065/10];
   EU Operational Programme Innovative Economy [POIG.02.02.00-26-023/09-00,
   POPW.01.03.00-26-016/09-00]
FX The work presented was supported by the European Commission under Grant
   INDECT No. FP7-218086. Preparation of source video sequences and
   subjective tests was supported by European Regional Development Fund
   within INSIGMA project no. POIG.01.01.02-00-062/09. Analysis of video
   quality was financed by The National Centre for Research and Development
   (NCBiR) within project no. SP/I/1/77065/10.; The numerical experiments
   reported in this paper and related to Matrox Imaging Library software
   have been performed using computational equipment purchased in the
   framework of the EU Operational Programme Innovative Economy
   (POIG.02.02.00-26-023/09-00) and the EU Operational Programme
   Development of Eastern Poland (POPW.01.03.00-26-016/09-00).
CR Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469
   AGRESTI A., 2002, Categorical Data Analysis, DOI [10.1002/0471249688, DOI 10.1002/0471249688]
   [Anonymous], 2012, MATROX IMAGING SOFTW
   Baran Remigiusz, 2011, Pomiary Automatyka Kontrola, V57, P94
   Baran R, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P218, DOI 10.1109/MMET.2000.888560
   Belgassem F, 1998, P INT WORKSH SYST SI
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dziech A., 1997, 4th International Workshop on Systems, Signals and Image Processing. Proceedings, P203
   Dziech A, 2009, PRZEGLAD TELEKOMUNIK, V8-9, P1417
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Ford C, 2010, 3 INDECT IEEE INT C, P5
   Ford CG, 2009, SPIE P HUMAN VISION, V7240, P72400
   Honess T., 1992, Closed Circuit Television in Public Places: Its Acceptability and Perceived Effectiveness
   Hough P. V. C., 1959, Conf. Proc. C, P554
   Janowski L, 2010, LECT NOTES COMPUT SC, V6157, P34, DOI 10.1007/978-3-642-13789-1_4
   Lin D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P296
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Romaniak P, 2010, LECT NOTES COMPUT SC, V6157, P46, DOI 10.1007/978-3-642-13789-1_5
   TADEUSIEWICZ R, 1997, KOMPUTEROWA ANALIZA
   VQiPS, 2011, VID QUAL PUBL SAF WO
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Zeadally S, 2010, LECT NOTES COMPUTER, V6157
NR 22
TC 28
Z9 29
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 23
EP 40
DI 10.1007/s11042-012-1199-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, JH
   Choi, E
   Song, M
   Shin, BS
AF Lee, Jin-Hee
   Choi, Eikyu
   Song, Minseok
   Shin, Byeong-Seok
TI Dreamware: edutainment system for children with developmental disability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edutainment system; Multimedia system; Embedded system; Developmental
   disability; Authoring tool; Sensory integration
ID AUTISM; PLAY
AB We designed and implemented an edutainment platform, Dreamware. It effectively helps education, sensibility treatment and intelligence training for children with developmental disability. We developed special toy-like hardware and software tools: a content authoring tool that makes a variety of multimedia content operating on the hardware, a management tool that provides training results to instructors, and a real-time monitoring tool to observe the current state of learning. The hardware is designed to consider the characteristics of children with developmental disability. It can provide sensibility training, such as visual, auditory, and tactile senses to them. The easy-to-use authoring tool enables teachers and non-specialists to make educational content conveniently. In addition, the real-time monitoring tool helps observe the user's status, even outside the classroom. The management tool stores training results and provides the result for further steps. Efficient repetitive training is possible without restriction of time and location using this platform. We can recognize that our system is effective in improving their concentration and learning.
C1 [Lee, Jin-Hee; Choi, Eikyu; Song, Minseok; Shin, Byeong-Seok] Inha Univ, Dept Comp Sci & Informat Engn, Inchon 402751, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, 253 Yonghyun Dong, Inchon 402751, South Korea.
EM jhlee07@inhaian.net; luciel95@hanmail.net; mssong@inha.ac.kr;
   bsshin@inha.ac.kr
FU IT R&D program of MKE/KEIT [10035243]
FX This work was supported by the IT R&D program of MKE/KEIT. [10035243,
   Component based Design Theory and Control Kernel for CPS].
CR Ayres J.A., 1979, SENSORY INTEGRATION
   Bovet DanielP., 2006, UNDERSTANDING LINUX
   Cook AM, 2002, IEEE T NEUR SYS REH, V10, P178, DOI 10.1109/TNSRE.2002.802877
   DUBE WV, 1991, J APPL BEHAV ANAL, V24, P305, DOI 10.1901/jaba.1991.24-305
   Hsieh HC, 2008, RES DEV DISABIL, V29, P459, DOI 10.1016/j.ridd.2007.08.004
   Kinney EM, 2003, J POSIT BEHAV INTERV, V5, P22, DOI 10.1177/10983007030050010301
   Learner JW, 1981, LEARNING DISABILITIE
   Lewis V, 2000, INT J LANG COMM DIS, V35, P117
   Malone M., 1999, INT J DISABIL DEV ED, V46, P307, DOI [https://doi.org/10.1080/103491299100524, DOI 10.1080/103491299100524]
   Nadel J, 2002, 2 DAY INT WORKSH HOS
   Newland P, 2006, MEDIATE STEPS SELF O, P53
   O'Connor K., 1997, PLAY THERAPY THEORY
   Parés N, 2005, IEEE T VIS COMPUT GR, V11, P734, DOI 10.1109/TVCG.2005.88
   Pierce-Jordan S, 2005, TOP EARLY CHILD SPEC, V25, P34, DOI 10.1177/02711214050250010401
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rose FD, 1999, DISABIL REHABIL, V21, P548
   Rutherford MD, 2003, J AUTISM DEV DISORD, V33, P289, DOI 10.1023/A:1024406601334
   Stromer R., 2006, Focus on Autism and Other Developmental Disabilities, V21, P14, DOI DOI 10.1177/10883576060210010301
   Vedora J, 2007, RES DEV DISABIL, V28, P489, DOI 10.1016/j.ridd.2006.06.006
NR 19
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 305
EP 319
DI 10.1007/s11042-012-1089-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400008
DA 2024-07-18
ER

PT J
AU Chen, M
AF Chen, Min
TI Towards smart city: M2M communications with software agent intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Machine to machine; IoT; Mobile agent; RFID
AB Recent advances in the fields of wireless technology have exhibited a strong potential and tendency on improving human life by means of ubiquitous communications devices that enable smart, distributed services. In fact, traditional human to human (H2H) communications are gradually falling behind the scale of necessity. Consequently, machine to machine (M2M) communications have surpassed H2H, thus drawing significant interest from industry and the research community recently. This paper first presents a four-layer architecture for internet of things (IoT). Based on this architecture, we employ the second generation RFID technology to propose a novel intelligent system for M2M communications.
C1 [Chen, Min] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Huazhong, Peoples R China.
   [Chen, Min] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Huazhong University of Science & Technology; Seoul National University
   (SNU)
RP Chen, M (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Huazhong, Peoples R China.
EM minchen@ieee.org
RI Chen, Min/N-9350-2015
OI Chen, Min/0000-0002-0960-4447
FU National Research Foundation of Korea (NRF); Korean government (MEST)
   [2011-0009454]; Program for New Century Excellent Talents in University
   (NCET)
FX Min Chen's work was supported in part by the National Research
   Foundation of Korea (NRF) grant funded by the Korean government (MEST)
   (No. 2011-0009454), and Program for New Century Excellent Talents in
   University (NCET).
CR [Anonymous], NY TIMES
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Chen M, 2007, IEEE WIREL COMMUN, V14, P20, DOI 10.1109/MWC.2007.4407223
   Chen M, 2012, KSII T INTERNET INF, V6, P480, DOI 10.3837/tiis.2012.02.002
   Mahajan Ratul., 2005, P NSDI
   Mahmoud MMEAA, 2010, P IEEE INF 10
   Min Chen, 2011, Mobile Networks and Applications, V16, P171, DOI 10.1007/s11036-010-0260-8
   Runhe Huang, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P318, DOI 10.1109/CSE.2009.326
   Vermesan O, 2009, TECHNICAL REPORT
   Zhong S, 2005, P MOBICOM 05
NR 10
TC 78
Z9 80
U1 0
U2 159
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 167
EP 178
DI 10.1007/s11042-012-1013-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800009
OA hybrid
DA 2024-07-18
ER

PT J
AU Su, PC
   Lu, MT
   Wu, CY
AF Su, Po-Chyi
   Lu, Ming-Tse
   Wu, Ching-Yu
TI A practical design of high-volume steganography in digital video files
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; H.264/AVC; MPEG AAC; Information hiding
ID WATERMARKING; IMAGE
AB In this research, we consider exploiting the large volume of audio/video data streams in compressed video clips/files for effective steganography. By observing that most of the distributed video files employ H.264 Advanced Video Coding (AVC) and MPEG Advanced Audio Coding (AAC) for video/audio compression, we examine the coding features in these data streams to determine appropriate data for modification so that the reliable high-volume information hiding can be achieved. Such issues as the perceptual quality, compressed bit-stream length, payload of embedding, effectiveness of extraction and efficiency of execution will be taken into consideration. First, the effects of using different coding features are investigated separately and three embedding profiles, i.e. High, Medium and Low, which indicate the amount of payload, will then be presented. The High profile is used to embed the maximum amount of hidden information when the high payload is the only major concern in the target application. The Medium profile is recommended since it is designed to achieve a good balance among several requirements. The Low profile is an efficient implementation for faster information embedding. The performances of these three profiles are reported and the suggested Medium profile can hide more than 10% of the compressed video file size in common Flash Video (FLV) files.
C1 [Su, Po-Chyi; Lu, Ming-Tse; Wu, Ching-Yu] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
EM pochyisu@csie.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022
OI Su, Po-Chyi/0000-0002-7457-8409
FU National Science Council in Taiwan, R.O.C. [NSC99-2221-E-008-089]
FX This research was supported by the National Science Council in Taiwan,
   R.O.C., under Grant NSC99-2221-E-008-089.
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bhaumik AK, 2009, INT J DATABASE THEOR
   Budhia U, 2006, IEEE T INF FOREN SEC, V1, P502, DOI 10.1109/TIFS.2006.885020
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Kapotas SK, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P373, DOI 10.1109/MMSP.2007.4412894
   Kirbiz S, 2007, IEEE T INF FOREN SEC, V2, P683, DOI 10.1109/TIFS.2007.908194
   Liu Z, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2358
   Wang HX, 2005, LECT NOTES ARTIF INT, V3682, P580
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Yang G, 2010, AEU INT J ELECT COMM
NR 12
TC 7
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 247
EP 266
DI 10.1007/s11042-011-0799-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000007
DA 2024-07-18
ER

PT J
AU Messelodi, S
   Modena, CM
AF Messelodi, Stefano
   Modena, Carla Maria
TI Scene text recognition and tracking to identify athletes in sport videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedded text detection; Text tracking; Sport video analysis; Athlete
   identification; Text reading; Information extraction
ID IMAGES; IDENTIFICATION; OCR
AB We present an athlete identification module forming part of a system for the personalization of sport video broadcasts. The aim of this module is the localization of athletes in the scene, their identification through the reading of names or numbers printed on their uniforms, and the labelling of frames where athletes are visible. Building upon a previously published algorithm we extract text from individual frames and read these candidates by means of an optical character recognizer (OCR). The OCR-ed text is then compared to a known list of athletes' names (or numbers), to provide a presence score for each athlete. Text regions are tracked in subsequent frames using a template matching technique. In this way blurred or distorted text, normally unreadable by the OCR, is exploited to provide a denser labelling of the video sequences. Extensive experiments show that the method proposed is fast, robust and reliable, out-performing results of other systems in the literature.
C1 [Messelodi, Stefano; Modena, Carla Maria] FBK Irst, I-38123 Povo, Trento, Italy.
C3 Fondazione Bruno Kessler
RP Modena, CM (corresponding author), FBK Irst, Via Sommarive 18, I-38123 Povo, Trento, Italy.
EM messelod@fbk.eu; modena@fbk.eu
RI Modena, Carla Maria/M-3806-2019; Messelodi, Stefano/C-4370-2013
OI Modena, Carla Maria/0000-0001-7015-8768; 
FU European Union [FP7 215248]
FX This work has been supported by the European Union under the Strep
   Project FP7 215248: My eDirector 2012. The authors would like to thank
   Paul Chippendale for his careful reading of the manuscript.
CR Andrade E. L., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P57, DOI 10.1049/cp:20030486
   [Anonymous], P ACM MULT INT WORKS
   [Anonymous], 2007, P CBDAR
   [Anonymous], 2011, REAL TIM CONT AW PER
   Bertini M., 2005, Proceedings of the 7th ACM SIGMM International Workshop on Multimedia Information Retrieval, MIR'05, (New York, NY, USA), P25
   Bertini M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P537, DOI 10.1109/ICME.2006.262444
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Desolneux A., 2008, From gestalt theory to image analysis a probabilistic approach
   Ezaki N, 2004, INT C PATT RECOG, P683, DOI 10.1109/ICPR.2004.1334351
   Jia WJ, 2004, CISST '04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, P43
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   Lienhart R, 2003, INT SER VIDEO COMPUT, V6, P155
   Mancas-Thillou Celine, 2007, Vision Systems - Segmentation and Pattern Recognition, P307
   Messelodi S, 1999, PATTERN RECOGN, V32, P791, DOI 10.1016/S0031-3203(98)00108-3
   Mirmehdi M, 2005, INT J DOC ANAL RECOG, V7, P83
   Myers EW, 1986, ALGORITHMICA, V1, P251, DOI 10.1007/BF01840446
   Myers G. K., 2005, International Journal on Document Analysis and Recognition, V7, P147, DOI 10.1007/s10032-004-0133-4
   Myers GK, 2005, 1 INT WORKSH CAM BAS, P30
   Patrikakis C, 2010, IEEE MULTIMEDIA
   Rice SV, 1995, TR9503 U NEV INF SCI
   Saric M, 2009, REC ADV ELECTR ENG, P175
   Sato T, 1999, MULTIMEDIA SYST, V7, P385, DOI 10.1007/s005300050140
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Shen HY, 2006, INT C PATT RECOG, P113
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38
   Wu W, 2005, IEEE T INTELL TRANSP, V6, P378, DOI 10.1109/TITS.2005.858619
   Yang J, 2004, LECT NOTES COMPUT SC, V3115, P270
   Ye QX, 2005, P SOC PHOTO-OPT INS, V5960, P1599, DOI 10.1117/12.632735
   Zhang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P5, DOI 10.1109/DAS.2008.49
NR 34
TC 14
Z9 17
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 521
EP 545
DI 10.1007/s11042-011-0878-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200011
DA 2024-07-18
ER

PT J
AU Park, JH
   Rho, S
   Jeong, CS
   Kim, J
AF Park, Jin-hyung
   Rho, Seungmin
   Jeong, Chang-sung
   Kim, Jongik
TI Multiple 3D object position estimation and tracking using double
   filtering on multi-core processor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augment reality; Kalman filter; Object tracking; Parallel processing;
   Robust filtering; 3D estimation
AB We present a new algorithm to tracking multiple 3D objects that has robustness, real-time processing ability and fast object registration. Usually, many augmented reality applications want to track 3D object using natural features in real-time, more accuracy and want to register target object immediately in few seconds. Prevalent object tracking algorithm uses FERN for feature extraction that takes long time to register and learning target object for high quality performance. Our method provides not only high accuracy but also fast target object registering time about 0.3 ms in same environment and real-time processing. These features are presented by using SURF, ROI, double robust filtering and optimized multi-core parallelization. Using our methods, tracking multiple 3D objects with fast and high accuracy is available.
C1 [Park, Jin-hyung; Jeong, Chang-sung] Korea Univ, Sch Elect Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Baekseok Univ, Informat & Commun Div, Cheonan, South Korea.
   [Kim, Jongik] Chonbuk Natl Univ, Div Comp Sci & Engn, Jeonju, South Korea.
C3 Korea University; Baekseok University; Jeonbuk National University
RP Jeong, CS (corresponding author), Korea Univ, Sch Elect Elect Engn, Seoul, South Korea.
EM korea.smrho@gmail.com; csjeong@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU Samsung Electronics; MKE(Ministry of Knowledge Economy), Korea, under
   the ITRC (Information Technology Research Center)
   [NIPA-2010-C1090-1001-0008]; Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF); Ministry of Education, Science and Technology [2011-0020522]
FX This research was supported by Samsung Electronics, MKE(Ministry of
   Knowledge Economy), Korea, under the ITRC (Information Technology
   Research Center) support program supervised by the NIPA (National IT
   Industry Promotion Agency) (NIPA-2010-C1090-1001-0008) and
   Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science and Technology (2011-0020522).
CR Alzaabi M, 2011, J INF PROCESS SYST, V7, P121, DOI 10.3745/JIPS.2011.7.1.121
   [Anonymous], 2008, TECHNICAL REPORT
   [Anonymous], 2009, International Journal Computer Vision
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2003, MULTIPLE VIEW GEOMET
   Bastinan J, 2010, INT S MIX AUGM REAL
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Carmingniani J, 2010, AUGMENTED REALITY TE
   Chen JH, 2011, J INF PROCESS SYST, V7, P17, DOI 10.3745/JIPS.2011.7.1.017
   Chong RM, JOC, V1, P49
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frintrop S, 2010, ICRA 2010
   Gordon NJ, 2009, IEE P F, V140, P107
   Gossow D, EVALUATION OPEN SOUR
   Grunert JA., 1841, Grunerts Archiv fur Mathematik und Physik, V1, P238
   Halim Z, IJITCC, V1, P92
   Haralick RM, 1991, P IEEE INT C COMP VI
   Kalman RE, 2008, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552.KUVSHIN0V
   Karlekar J., 2010, INT S MIX AUGM REAL
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Klein G., 2006, Visual Tracking for Augmented Reality
   Kryvinska N, IJITCC, V1, P77
   Ku MS, 2011, JCICT YES ICUC
   Lin L, 2008, MULTIMED TOOLS APPL
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marimon D, 2011, CVPR
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Park J, 2009, IEEK C FALL
   Park Y, 2009, ISMAR
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Sale RA, JOC, V1, P9
   Song HJ, 2011, MULTIMED TOOLS APPL, V52, P121, DOI 10.1007/s11042-010-0464-8
   Wang D, 2010, MULTIMED TOOLS APPLE
NR 34
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 161
EP 180
DI 10.1007/s11042-012-1029-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400011
DA 2024-07-18
ER

PT J
AU Campos, P
   Campos, M
   Freitas, P
   Jorge, J
AF Campos, Pedro
   Campos, Miguel
   Freitas, Paulo
   Jorge, Joaquim
TI <i>Foot-turistic</i> multimedia: designing interactive multimedia
   installations for shoe shops
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive spaces; Interactive multimedia; Applications; Shoe shop;
   Multimedia installations
ID DISPLAYS
AB The amount of money spent in a store is positively correlated with the amount of time spent inside. We argue this is an opportunity for multimedia installations that can entertain shoppers and promote interaction with the shop's products. This was the main principle behind our design idea for two interactive installations specifically conceived for shoe shops. We present two applications of interactive multimedia to shoe shopping: an interactive semantic mirror and an interactive window logo. We also describe the results of ethnographic studies, before and after the design process. Our contribution is two-fold: (i) we develop and apply a new multimedia architecture that combines RFID in-store technology with high-end motion detection algorithms, and (ii) we describe one of the first few studies about multimedia installations for improving the shoe shopping experience, in what we call "foot-turistic" interactions.
C1 [Campos, Pedro] Univ Madeira, Funchal, Portugal.
   [Campos, Pedro; Jorge, Joaquim] Univ Tecn Lisboa, Sch Engn IST, Comp Sci & Engn Dept DEI, Lisbon, Portugal.
   [Campos, Miguel; Freitas, Paulo] WowSystems, Madeira, Portugal.
C3 Universidade da Madeira; Universidade de Lisboa
RP Campos, P (corresponding author), Univ Madeira, Funchal, Portugal.
EM pcampos@uma.pt
RI Campos, Pedro/I-8286-2019; Jorge, Joaquim/C-5596-2008
OI Campos, Pedro/0000-0001-7706-5038; Jorge, Joaquim/0000-0001-5441-4637
CR Aarts E., 2003, The New Everyday: Views on Ambient Intelligence. 010
   Andres del Valle AC, 2009, P 27 INT C HUM FACT, P3035
   [Anonymous], BUSINESS 2 0
   [Anonymous], 1998, MEDIA EQUATION MEDIA
   Choi HS, 2008, ROBOTICA, V26, P55, DOI 10.1017/S026357470700358X
   Fogg B. J., 2003, PERSUASIVE TECHNOLOG, P89
   Kourouthanassis P, 2003, IEEE PERVAS COMPUT, V2, P32, DOI 10.1109/MPRV.2003.1203751
   Kourouthanassis P, 2006, COMPUT COMMUN NETW S, P133, DOI 10.1007/1-84628-321-3_8
   Lewison D.M., 1997, RETAILING, V6th
   Li M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1215
   Liu W, 2007, P 2 WORKSH DIG MED I, P389
   Luximon A, 2009, COMPUT IND, V60, P621, DOI 10.1016/j.compind.2009.05.015
   Melder W. A., 2007, P INT WORKSH HUM CTR, P31, DOI DOI 10.1145/1290128.1290134
   Meschtscherjakov A, 2009, P 4 INT C PERS TECHN, V350, P1
   Müller J, 2007, LECT NOTES ARTIF INT, V4511, P395
   Narayanaswami C., 2008, P 9 WORKSHOP MOBILE, P80
   Russell MG, 2008, LECT NOTES COMPUT SC, V5033, P94, DOI 10.1007/978-3-540-68504-3_9
   Sorensen Herb., 2009, INSIDE MIND SHOPPER
   Underhill P., 2000, Why We Buy? The science of shopping
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Wisneski C, 1998, LECT NOTES COMPUT SC, V1370, P22
   Xu Y, 2008, P 5 NORD C HUM COMP, V358, P393
NR 22
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 471
EP 487
DI 10.1007/s11042-011-0854-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600009
DA 2024-07-18
ER

PT J
AU Inoue, M
   Ogihara, M
   Hanada, R
   Furuyama, N
AF Inoue, Masashi
   Ogihara, Mitsunori
   Hanada, Ryoko
   Furuyama, Nobuhiro
TI Gestural cue analysis in automated semantic miscommunication annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic indexing; Gesture; Psychotherapy; Face-to-face
ID HUMAN-COMPUTER INTERACTION
AB The automated annotation of conversational video by semantic miscommunication labels is a challenging topic. Although miscommunications are often obvious to the speakers as well as the observers, it is difficult for machines to detect them from the low-level features. We investigate the utility of gestural cues in this paper among various non-verbal features. Compared with gesture recognition tasks in human-computer interaction, this process is difficult due to the lack of understanding on which cues contribute to miscommunications and the implicitness of gestures. Nine simple gestural features are taken from gesture data, and both simple and complex classifiers are constructed using machine learning. The experimental results suggest that there is no single gestural feature that can predict or explain the occurrence of semantic miscommunication in our setting.
C1 [Inoue, Masashi] Yamagata Univ, Grad Sch Sci & Engn, Yonezawa, Yamagata, Japan.
   [Inoue, Masashi] Natl Inst Informat, Collaborat Res Unit, Tokyo, Japan.
   [Ogihara, Mitsunori] Univ Miami, Dept Comp Sci, Ctr Computat Sci, Miami, FL USA.
   [Hanada, Ryoko] Kyoto Univ Educ, Grad Sch Clin Psychol, Ctr Clin Psychol & Educ, Dept Clin Psychol, Kyoto 612, Japan.
   [Furuyama, Nobuhiro] Natl Inst Informat, Informat & Soc Res Div, Tokyo, Japan.
   [Furuyama, Nobuhiro] Tokyo Inst Technol, Dept Computat Intelligence & Syst Sci, Tokyo 152, Japan.
C3 Yamagata University; Research Organization of Information & Systems
   (ROIS); National Institute of Informatics (NII) - Japan; University of
   Miami; Kyoto University of Education; Research Organization of
   Information & Systems (ROIS); National Institute of Informatics (NII) -
   Japan; Tokyo Institute of Technology
RP Inoue, M (corresponding author), Yamagata Univ, Grad Sch Sci & Engn, Yonezawa, Yamagata, Japan.
EM mi@yz.yamagata-u.ac.jp; ogihara@cs.miami.edu; hanada@kyokyo-u.ac.jp;
   furuyama@nii.ac.jp
RI Inoue, Masashi/AAQ-9082-2021; Ogihara, Mitsunori/AAB-8275-2020
OI Inoue, Masashi/0000-0002-9364-3114; Ogihara,
   Mitsunori/0000-0002-5690-7854
FU National Science Foundations [CCF-0958490]; National Institute of Health
   [1-RC2-HG005668-01]; Function and Induction Research Project,
   Transdisciplinary Research Integration Center of the Research
   Organization of Information and Systems;  [19530620];  [21500266];
   Grants-in-Aid for Scientific Research [24500321, 21500266, 22530737]
   Funding Source: KAKEN
FX We would like to thank the m-project members especially Kunio Tanabe and
   Tomoko Matsui for commenting on an earlier version of this paper. This
   research was partially supported by the Grant-in-Aid for Scientific
   Research 19530620, 21500266, the National Science Foundations under
   Grant CCF-0958490 and the National Institute of Health under Grant
   1-RC2-HG005668-01, and the Function and Induction Research Project,
   Transdisciplinary Research Integration Center of the Research
   Organization of Information and Systems.
CR Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   Brown D, 1972, REHABILITATION COUNS, V15, P176
   Burgoon J., 2005, Proceedings of the 38th Annual Hawaii International Conference on System Sciences, p21a
   Buttny R., 2004, Talking problems
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Freedman N, 1977, HANDS WORD MIND STRU, P219
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Heath C., 1986, Body movement and speech in medical interaction
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   McNeill D, 2008, ANNOTATIVE PRACTICE
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Meservy TO, 2005, IEEE INTELL SYST, V20, P36, DOI 10.1109/MIS.2005.85
   Mortensen C.D., 2006, HUMAN CONFLICT
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Rahman A., 2009, MM '09: Proceedings of the seventeen ACM international conference on Multimedia, P761
   SUCHMAN L, 1990, J AM STAT ASSOC, V85, P232, DOI 10.2307/2289550
   Takeuchi H, 2009, INFORM SCIENCES, V179, P1584, DOI 10.1016/j.ins.2008.11.026
NR 18
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 7
EP 20
DI 10.1007/s11042-010-0701-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000002
PM 23585724
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kumar, RA
   Kaliyaperumal, G
AF Kumar, R. Ashok
   Kaliyaperumal, Ganesan
TI Optimal fingerprint scheme for video on demand using block designs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-on-demand; Peer-to-peer; Segments; Fingerprint; Collusion;
   Digital-right-management
ID PEER-TO-PEER; WATERMARKING; CODE
AB Video fingerprint is a mechanism to protect movie from the traitors and also have the capability to identify the traitors. The problem arises in video fingerprint when several traitors having the same copies of a movie with different fingerprints collude together. During the collusion the original fingerprints in the movie will be removed or attenuated. Due to this the traitors can illegally copy, duplicate, record or redistribute the movie without having legitimate permissions. To avoid illegitimate acts of the traitors, a new Video on Demand architecture is proposed in this paper. This new architecture combines the proxy caching mechanisms in the peer to peer network to support larger users group. A new video fingerprinting scheme is proposed for this architecture, which can strongly resist against collusion attacks from the traitors. To check the appropriateness of our scheme, we have analyzed some of the existing schemes. The appropriateness is analyzed in terms of efficiency, effectivity and performance. To evaluate the optimality of these schemes, we have carried out simulation for our architecture. The results from the simulation show the optimal outcome for our scheme than any existing schemes.
C1 [Kumar, R. Ashok; Kaliyaperumal, Ganesan] VIT Univ, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, RA (corresponding author), VIT Univ, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
EM rak_bms@hotmail.com; kganesan@vit.ac.in
CR [Anonymous], 1996, The CRC Handbook of Combinatorial Designs, CRC Press Series on Discrete Mathematics and its Applications
   Camp LJ, 2003, IEEE INTERNET COMPUT, V7, P59, DOI 10.1109/MIC.2003.1200302
   Changchang Wu, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563037
   Choi CH, 1993, P INT C SIGN PROC, V2, P796
   Dinitz J. H., 1992, CONT DESIGN THEORY C
   He S, 2007, IEEE T INF FOREN SEC, V2, P697, DOI 10.1109/TIFS.2007.908179
   He S, 2006, IEEE T INF FOREN SEC, V1, P231, DOI 10.1109/TIFS.2006.873597
   Ho KM, 2008, INT C INF NETW 23 25, P1, DOI DOI 10.1109/ICOIN.2008.4472804
   Iwata T, 2003, APCC 2003: 9TH ASIA-PACIFIC CONFERENCE ON COMMUNICATION, VOLS 1-3, PROCEEDINGS, P806, DOI 10.1109/APCC.2003.1274471
   Kang I, 2006, IEICE T FUND ELECTR, VE89A, P3732, DOI 10.1093/ietfec/e89-a.12.3732
   Kumar R. Ashok, 2010, International Journal of Advanced Media and Communication, V4, P274, DOI 10.1504/IJAMC.2010.034661
   Kumar RA, 2012, MULTIMED TOOLS APPL, V58, P613, DOI 10.1007/s11042-011-0750-0
   Kumar R, 2009, CANCER METAST REV, V28, P3, DOI 10.1007/s10555-008-9164-5
   Liu JC, 2008, P IEEE, V96, P11, DOI 10.1109/JPROC.2007.909921
   Liu XY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P899
   Liu ZM, 2009, IEEE INFOCOM SER, P82, DOI 10.1109/INFCOM.2009.5061909
   Narsimha C, 2008, P IEEE REG 10 C HCU
   Nikolaidis N, 2006, INT S INTELL SIGNAL, V801-807, P12
   Park HJ, 2008, IEEE ICC, P1777, DOI 10.1109/ICC.2008.341
   Puri A, 1991, IEEE T CIRC SYST VID, V1, P351, DOI 10.1109/76.120774
   Rodriguez P, 2006, ACM SIGCOMM COMP COM, V36, P75, DOI 10.1145/1111322.1111339
   Seol JM, 2006, LECT NOTES COMPUT SC, V4096, P560
   Tan SH, 1996, IEEE T CIRC SYST VID, V6, P375, DOI 10.1109/76.510930
   Thouin F, 2007, IEEE NETWORK, V21, P42, DOI 10.1109/MNET.2007.334311
   Trappe W, 2002, INT CONF ACOUST SPEE, P3309
   Wong PHW, 2000, PROC SPIE, V3971, P237, DOI 10.1117/12.384978
   Wu C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386112
   Wu M, 2004, IEEE SIGNAL PROC MAG, V21, P15
   Yang J, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P996
   Yu Yongsheng., 2010, e-Business and Information System Security (EBISS), 2010 2nd International Conference on, P1
   Zhu G., 2008, WORLD ACAD SCI ENG T, V45, P38
   Zou DK, 2009, IEEE INT CON MULTI, P1390, DOI 10.1109/ICME.2009.5202763
NR 32
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 389
EP 418
DI 10.1007/s11042-011-0843-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600006
DA 2024-07-18
ER

PT J
AU Gupta, VN
   Boulianne, G
   Cardinal, P
AF Gupta, Vishwa Nath
   Boulianne, Gilles
   Cardinal, Patrick
TI CRIM's content-based audio copy detection system for TRECVID 2009
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio copy detection; Copy detection; Energy difference; Nearest
   neighbor
AB We report results on audio copy detection for TRECVID 2009 copy detection task. This task involves searching for transformed audio queries in over 385 h of test audio. The queries were transformed in seven different ways, three of them involved mixing unrelated speech to the original query, making it a much more difficult task. We give results with two different audio fingerprints and show that mapping each test frame to the nearest query frame (nearest-neighbor fingerprint) results in robust audio copy detection. The most difficult task in TRECVID 2009 was to detect audio copies using predetermined thresholds computed from 2008 data. We show that the nearest-neighbor fingerprints were robust to even this task and gave actual minimal normalized detection cost rate (NDCR) of around 0.06 for all the transformations. These results are close to those obtained by using the optimal threshold for each transform. This result shows the robustness of the nearest-neighbor fingerprints. These nearest-neighbor fingerprints can be efficiently computed on a graphics processing unit, leading to a very fast search.
C1 [Gupta, Vishwa Nath; Boulianne, Gilles; Cardinal, Patrick] CRIM, Bur 101, Montreal, PQ H3N 1M3, Canada.
C3 Universite de Montreal
RP Gupta, VN (corresponding author), CRIM, Bur 101, 405 Ave Ogilvy, Montreal, PQ H3N 1M3, Canada.
EM Vishwa.Gupta@crim.ca; Gilles.Boulianne@crim.ca; Patrick.Cardinal@crim.ca
RI Boulianne, Gilles/AAP-9447-2021
OI Boulianne, Gilles/0000-0001-9383-6189
FU Natural Science and Engineering Research Council of Canada (NSERC)
FX This work was supported in part by the Natural Science and Engineering
   Research Council of Canada (NSERC).
CR [Anonymous], TRECVID 2008 CONTENT
   [Anonymous], 2010, IFPI DIGITAL MUSIC R
   [Anonymous], 2006, P 8 ACM INT WORKSH M
   [Anonymous], HIGHLY ROBUST AUDIO
   Cardinal P, 2010, P INTERSPEECH 2010
   Covell M, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P461, DOI 10.1109/MMSP.2006.285351
   Doets P, 2005, EXTRACTING QUALITY P
   Duygulu P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1267, DOI 10.1109/ICME.2004.1394454
   Gupta V, 2008, P INTERSPEECH 2008 B
   Heritier M, 2008, P TRECVID 2009 GAITH
   Hurley N, 2007, PERFORMANCE PHILLIPS
   KE Y, 2005, P COMP VIS PATT REC
   Saracoglu A, 2009, INT WORK CONTENT MUL, P213, DOI 10.1109/CBMI.2009.12
   Shrestha P, 2004, AUDIO FINGERPRINTING
   2008, FINAL CBCD EVALUATIO
NR 15
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 371
EP 387
DI 10.1007/s11042-010-0608-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400007
DA 2024-07-18
ER

PT J
AU Kwon, GR
   Wang, C
   Lian, S
   Hwang, SS
AF Kwon, Goo-Rak
   Wang, Chuntao
   Lian, Shiguo
   Hwang, Suk-seung
TI Advanced partial encryption using watermarking and scrambling in MP3
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio scrambling; Encryption; HAS; MPEG-1/Audio Layer III
AB In this paper, we propose an advanced partial encryption of watermarking and scrambling using the magnitude information of Modifed Discrete Cosine Transform (MDCT). In MPEG-1/Audio Layer III (MP3), the magnitude and phase information of modified discrete cosine transform (MDCT) coefficients is encrypted. The proposed method uses both watermarking and scrambling, and aims at protecting the contents against eavesdropping and moreover against illegal mass distribution after descrambled. Experimental results show that the proposed method can achieve higher security and less computational complexity by reusing the MDCT coefficients obtained in MP3.
C1 [Kwon, Goo-Rak; Wang, Chuntao; Lian, Shiguo; Hwang, Suk-seung] Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
C3 Chosun University
RP Hwang, SS (corresponding author), Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
EM hwangss@chosun.ac.kr
FU Chosun University
FX This study was supported by research funds from Chosun University, 2008.
CR Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Borujeni SE, 2000, ICECS 2000: 7TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS & SYSTEMS, VOLS I AND II, P290, DOI 10.1109/ICECS.2000.911539
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Farkash S., 1991, 17th Convention of Electrical and Electronics Engineers in Israel. Proceedings (Cat. No.90TH0360-8), P365, DOI 10.1109/EEIS.1991.217693
   Li W, 2004, IEEE T AERO ELEC SYS, V40, P12, DOI 10.1109/TAES.2004.1292139
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   MATSUNAGA A, 1989, IEEE J SEL AREA COMM, V7, P540, DOI 10.1109/49.17718
   Milosevic V, 1997, DSP 97: 1997 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P361, DOI 10.1109/ICDSP.1997.628102
   Neubauer C, 1998, LECT NOTES COMPUT SC, V1525, P208
   Park Y-J, 2006, P IWAIT2006, V90
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Piva A, 2002, IEEE INTERNET COMPUT, V6, P18, DOI 10.1109/MIC.2002.1003126
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Yeh C. H., 1999, 1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461), P456, DOI 10.1109/SIPS.1999.822351
NR 16
TC 8
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 885
EP 895
DI 10.1007/s11042-011-0771-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900007
DA 2024-07-18
ER

PT J
AU Alepis, E
   Virvou, M
AF Alepis, Efthymios
   Virvou, Maria
TI Multimodal object oriented user interfaces in mobile affective
   interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interaction; Affective computing; Mobile interaction; Object
   oriented programming
ID EMOTIONAL INTELLIGENCE; RECOGNITION; STEREOTYPES
AB In this paper, we investigate an object oriented (OO) architecture for multimodal emotion recognition in interactive applications through mobile phones or handheld devices. Mobile phones are different from desktop computers since mobile phones are not performing any processing involving emotion recognition whereas desktop computers can perform such processing. In fact, in our approach, mobile phones have to pass all data collected to a server and then perform emotion recognition. The object oriented architecture that we have created, combines evidence from multiple modalities of interaction, namely the mobile device's keyboard and the mobile device's microphone, as well as data from emotion stereotypes. Moreover, the OO method classifies them into well structured objects with their own properties and methods. The resulting emotion detection server is capable of using and handling transmitted information from different mobile sources of multimodal data during human-computer interaction. As a test bed for the affective mobile interaction we have used an educational application that is incorporated into the mobile system.
C1 [Alepis, Efthymios; Virvou, Maria] Univ Piraeus, Dept Informat, Piraeus 18534, Greece.
C3 University of Piraeus
RP Virvou, M (corresponding author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.
EM talepis@unipi.gr; mvirvou@unipi.gr
RI Tsihrintzis, George/AAR-1626-2021; VIRVOU, Maria/AAR-1415-2021
OI VIRVOU, MARIA/0000-0002-4008-4654
CR Alepis E, 2006, LECT NOTES ARTIF INT, V4251, P435
   Alepis E, 2010, INTELL DECIS TECHNOL, V4, P171, DOI 10.3233/IDT-2010-0078
   Alepis E, 2008, FRONT ARTIF INTEL AP, V180, P305, DOI 10.3233/978-1-58603-900-4-305
   Alepis E, 2008, STUD COMPUT INTELL, V104, P9
   Alepis E, 2009, STUD COMPUT INTELL, V226, P349
   [Anonymous], 2010, CHI 10 EXTENDED ABST
   [Anonymous], 1981, Lect. Notes Econ. Math. Syst.
   [Anonymous], 1981, MULTIPLE ATTRIBUTE D
   [Anonymous], ATR WORKSH VIRT COMM
   [Anonymous], Free Encyclopedia
   Armstrong DJ, 2006, COMMUN ACM, V49, P123, DOI 10.1145/1113034.1113040
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bernhardt Daniel, 2008, CHI 08 EXTENDED ABST, P3117, DOI 10.1145/1358628.1358817
   Booch G., 1996, Unix Review, V14, P41
   Busso C., 2004, ICMI
   Cacioppo J.T., 2000, Handbook of Emotions, P173
   Caridakis G, 2010, J MULTIMODAL USER IN, V3, P49, DOI [10.1007/s12193-009-0030, 10.1007/s12193-009-0030-8]
   Chiu PH, 2009, J UNIVERS COMPUT SCI, V15, P1970
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   De Silva LC, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P397, DOI 10.1109/ICICS.1997.647126
   Esposito A, 2009, COGN COMPUT, V1, P268, DOI 10.1007/s12559-009-9017-8
   Fishburn PC., 1967, Additive utilities with incomplete product set: Applications to priorities and assignments
   Goleman D, 2020, Emotional intelligence: Why it can matter more than IQ
   Jascanu N, 2008, LECT NOTES ARTIF INT, V5177, P202, DOI 10.1007/978-3-540-85563-7_30
   Kay J, 2000, LECT NOTES COMPUT SC, V1839, P19
   Liao WH, 2006, INT J HUM-COMPUT ST, V64, P847, DOI 10.1016/j.ijhcs.2006.04.001
   Lim MY, 2007, LECT NOTES ARTIF INT, V4722, P317
   Moriyama T, 2001, SYST COMPUT JPN, V32
   Nasoz F, 2006, J VISUAL LANG COMPUT, V17, P430, DOI 10.1016/j.jvlc.2006.05.001
   Oviatt S, 2003, P IEEE, V91, P1457, DOI 10.1109/JPROC.2003.817127
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pastor O, 2001, INFORM SYST, V26, P507, DOI 10.1016/S0306-4379(01)00035-7
   Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1
   *PLAT TECHN INC, 1997, PAR PLUS ROUND TRIP
   *RAT SOFTW CORP, 1997, RAT ROS US MAN
   RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8
   Shieh CK, 1996, J SYST SOFTWARE, V32, P215, DOI 10.1016/0164-1212(95)00126-3
   Stathopoulou IO, 2010, KNOWL-BASED SYST, V23, P350, DOI 10.1016/j.knosys.2009.11.007
   Tsihrintzis George A., 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P810, DOI 10.1109/WIIAT.2008.282
   Vincent J, 2009, LECT NOTES COMPUT SC, V5641, P28, DOI 10.1007/978-3-642-03320-9_4
   Virvou M, 2007, LECT NOTES ARTIF INT, V4693, P1130
   Virvou M, 2004, IEEE SYS MAN CYBERN, P48
   Virvou M, 2005, COMPUT EDUC, V44, P53, DOI 10.1016/j.compedu.2003.12.020
   Yoon WJ, 2007, LECT NOTES COMPUT SC, V4611, P758
   Zeng ZH, 2007, IEEE T MULTIMEDIA, V9, P424, DOI 10.1109/TMM.2006.886310
NR 45
TC 6
Z9 6
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 41
EP 63
DI 10.1007/s11042-011-0744-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800004
DA 2024-07-18
ER

PT J
AU Lombardo, V
   Damiano, R
AF Lombardo, Vincenzo
   Damiano, Rossana
TI Semantic annotation of narrative media objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Narrative media object; Multimedia corpus annotation; Automatic video
   editing
ID CANONICAL PROCESSES; GENERATION
AB This paper addresses the annotation of the narrative features of media objects. Based on a relevant narratological and computational background, we introduce an ontology-based model called Drammar, an annotation schema for the narrative features of media objects based on Drammar and a software tool, Cinematic, for annotating these objects and validating the annotation. Annotated media objects can also be automatically edited into sequences, with the twofold goal of testing the validity of the annotation-through the reconstruction of the baseline sequence-and exploring the possibility of alternative sequences. The software tool encodes both the narrative model and the annotation itself in ontological format, and relies on external ontologies for representing world knowledge and limit the arbitrariness of the annotation. The paper opens the way to the design of a general annotation schema for narrative multimedia with the long term goal of building large corpora of annotated video material and of bridging the gap between the low-level signal analysis and the high-level semantic representation of the narrative content of the media objects. Finally, the paper illustrates a few projects elaborated with the Drammar annotation and the Cinematic tool, with purposes of artistic research and cross-media analysis, that provide an empirical validation of the annotation process.
C1 [Lombardo, Vincenzo; Damiano, Rossana] Univ Turin, CIRMA, Turin, Italy.
   [Lombardo, Vincenzo; Damiano, Rossana] Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
C3 University of Turin; University of Turin
RP Damiano, R (corresponding author), Univ Turin, CIRMA, Cso Svizzera 185, Turin, Italy.
EM vincenzo@di.unito.it; rossana@di.unito.it
RI snaith, melissa/E-8935-2012; Lombardo, Vincenzo/ABE-2078-2021; Damiano,
   Rossana/C-6288-2011
OI Lombardo, Vincenzo/0000-0002-8166-9827; Damiano,
   Rossana/0000-0001-9866-2843
FU CADMOS Project (Character-centered Annotation of Dramatic Media
   ObjectS); Regione Piemonte, Pole of Innovation for the Digital
   Creativity and Multimedia
FX This work is partially supported by the CADMOS Project (Character
   centered Annotation of Dramatic Media ObjectS), funded by Regione
   Piemonte, Pole of Innovation for the Digital Creativity and Multimedia,
   2010-2012.
CR [Anonymous], 2004, P AUSTR WORKSH INT E
   [Anonymous], ESTHETICS PHILOS ESS
   [Anonymous], 1994, DRAMATURGIE CLOWN EN
   [Anonymous], P SIGIR WORKSH MUTL
   Arndt R, 2007, COMM DESIGNING WELL, P30
   Bates J, 1994, LNAI, V830
   Bocconi S, 2008, J WEB SEMANT, V6, P139, DOI 10.1016/j.websem.2008.01.004
   Bratman M. E., 1988, Computational Intelligence, V4, P349, DOI 10.1111/j.1467-8640.1988.tb00284.x
   Butler S, 1997, APPL ARTIF INTELL, V11, P367, DOI 10.1080/088395197118190
   Campbell Joseph., 1949, HERO THOUSAND FACES
   Cavazza M, 2002, P 1 INT JOINT C AUT
   Coleridge SamuelTaylor., 1985, Biographia Literaria, or, Biographical Sketches of My Literary Life and Opinions
   Cua J., 2010, P NAACL HLT 2 WORKSH, P40
   Damiano R, 2008, AAAI SPRING S EM PER
   Damiano R, 2011, AGENTS GAMES SIMULAT, P76
   Damiano R, 2009, LNCS, V5883-0441
   Damiano R, 2008, USER MODEL USER-ADAP, V18, P417, DOI 10.1007/s11257-008-9053-1
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   Davenport G, 1994, VIDEO DATABASE DESIN
   Davis M, 2003, IEEE MULTIMEDIA, V10, P54, DOI 10.1109/MMUL.2003.1195161
   Dennett Daniel Clement, 1987, The intentional stance
   Egri L., 1946, ART DRAMATIC WRITING
   Feagin SL, 2007, PHILOS STUD, V135, P17, DOI 10.1007/s11098-007-9098-8
   Freytag Gustav, 1863, Die Technik des Dramas
   Genette Gerard, 1980, Narrative discourse: An essay in method
   GREIMAS AJ, 1977, DIACRITICS, V7, P23, DOI 10.2307/464872
   Hardman L, 2008, MULTIMEDIA SYST, V14, P327, DOI 10.1007/s00530-008-0134-0
   Hartmann K, 2005, LECT NOTES COMPUT SC, V3805, P158, DOI 10.1007/11590361_18
   Jung B, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230817
   Levesque H.J., 1998, Electron. Trans. Artif. Intell., V2, P159
   Lohse L, 2005, LNCS, V3805/2005
   Lombardo V, 2010, LECT NOTES COMPUT SC, V6432, P62, DOI 10.1007/978-3-642-16638-9_10
   Lombardo V, 2008, MULTIMEDIA SYST, V14, P385, DOI 10.1007/s00530-008-0137-x
   Madhwacharyula CL, 2006, ACM T MULTIM COMPUT, V2, P358, DOI 10.1145/1201730.1201736
   Manovich Lev, 2001, The Language of new media
   Mateas M, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P236
   Mateas M., 2005, P ART INT INT DIG EN
   Mateas M., 2003, TIDSE 03
   McKee R., 1997, Story
   Nack F, 1999, IEEE MULTIMEDIA, V6, P65, DOI 10.1109/93.790612
   Nack F., 1996, THESIS LANCASTER U
   Nack F, 2001, P 9 ACM INT C MULT, P251
   Ortony A., 1988, COGNITIVE STRUCTURE
   Peinado F, 2008, P ICIDIS08 ERF GERM
   Peinado F, 2004, P 2 INT C TECHN INT
   Pizzi D, 2007, 2 INT C AFF COMP INT
   Polti G., 1895, Les 36 situations dramatiques
   Prince G., 1987, A dictionary of narratology
   Propp V., 1968, Morphology of the Folktale, V2 nd
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   Rimmon-Kenan Shlomith, 2002, NARRATIVE FICTION CO, V2nd
   Ryan Marie-Laure., 2004, NARRATIVE MEDIA, P1
   Schank Roger C., 1977, SCRIPTS PLANS GOALS
   Seger Linda., 1990, CREATING UNFORGETTAB
   Sgouros NM, 1999, ARTIF INTELL, V107, P29, DOI 10.1016/S0004-3702(98)00106-4
   Smith TGA, 1992, ACM WORKSH NETW OP S
   Spierling U, 2007, LECT NOTES COMPUT SC, V4871, P13
   Swartjes I, 2006, LNCS, V4326, P95
   SZILAS N, 2003, P 1 INT C TECHN INT
   Theune M., 2003, P 1 INT C INTERACTIV, P204
   Ursu MF, 2008, MULTIMEDIA SYST, V14, P115, DOI 10.1007/s00530-008-0119-z
   van Fraassen B.C., 1973, Journa; of Philosophical Logic, V70, P5, DOI DOI 10.2307/2024762
NR 62
TC 14
Z9 16
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 407
EP 439
DI 10.1007/s11042-011-0813-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, HY
   Bao, DW
   Wang, XY
   Niu, PP
AF Yang, Hong-ying
   Bao, De-wang
   Wang, Xiang-yang
   Niu, Pan-pan
TI A robust content based audio watermarking using UDWT and invariant
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Desynchronization attack; Histogram; Undecimated
   wavelet transform
AB Desynchronization attack is known as one of the most difficult attacks to resist, for it can desynchronize the location of the watermark and hence causes incorrect watermark detection. It is a challenging work to design a robust audio watermarking scheme against desynchronization attacks. Based on undecimated discrete wavelet transform (UDWT) and invariant histogram, we propose a new content based audio watermarking algorithm with good audible quality and reasonable resistance toward desynchronization attacks in this paper. Firstly, the undecimated discrete wavelet transform (UDWT) is performed on original host audio. Secondly, the invariant histogram is extracted from a selected wavelet coefficients range in the low frequency subband. Then, the bin of histogram is divided into many groups, each group including four consecutive bins. For each group, one watermark bit is embedded by reassigning the number of wavelet coefficients in this group of four bins. Finally, the digital watermark is embedded into the original audio signal in UDWT domain by modifying a small set of wavelet coefficients. Simulation results show that the proposed watermarking scheme is not only inaudible and robust against common signal processing operations such as MP3 compression, noise addition, and low-pass filtering etc, but also robust against the desynchronization attacks such as random cropping, time-scale modification, pitch shifting, and jittering etc.
C1 [Yang, Hong-ying; Bao, De-wang; Wang, Xiang-yang; Niu, Pan-pan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-yang] Network & Data Secur Key Lab Sichuan Prov, Chengdu 611731, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, 850 Huanghe Rd, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of Network and Data Security Key Laboratory of Sichuan
   Province; Open Foundation of State Key Laboratory of Networking and
   Switching Technology of China [SKLNST-2008-1-01]; Open Foundation of Key
   Laboratory of Modern Acoustics Nanjing University [08-02]; Open
   Foundation of Key Laboratory of Advanced Design and Intelligent
   Computing, Ministry of Education; Liaoning Research Project for
   Institutions of Higher Education of China [L2010230, 2008351]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 60773031 & 60873222; the Open Foundation of
   Network and Data Security Key Laboratory of Sichuan Province; the Open
   Foundation of State Key Laboratory of Networking and Switching
   Technology of China under Grant No. SKLNST-2008-1-01; the Open
   Foundation of Key Laboratory of Modern Acoustics Nanjing University
   under Grant No. 08-02; the Open Foundation of Key Laboratory of Advanced
   Design and Intelligent Computing, Ministry of Education; and Liaoning
   Research Project for Institutions of Higher Education of China under
   Grant No. L2010230 & 2008351.
CR Arnold M, 2009, LECT NOTES COMPUT SC, V5806, P102, DOI 10.1007/978-3-642-04431-1_8
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Coltuc D, 1999, P SOC PHOTO-OPT INS, V3657, P252, DOI 10.1117/12.344674
   Coltuc D, 2002, PROC SPIE, V4675, P701, DOI 10.1117/12.465331
   Cox IJ., 2007, DIGITAL WATERMARKING
   Cvejic N, 2007, DIGITAL AUDIO WATERM
   Erçelebi E, 2009, DIGIT SIGNAL PROCESS, V19, P265, DOI 10.1016/j.dsp.2008.11.007
   Huang JW, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P627
   Kalantari NK, 2009, IEEE T AUDIO SPEECH, V17, P1133, DOI 10.1109/TASL.2009.2019259
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   LIAN S, 2009, INFORMATICA, V33, P3
   Lin CH, 2006, IEE P-VIS IMAGE SIGN, V153, P483, DOI 10.1049/ip-vis:20050107
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mansour MF, 2005, IEEE T SPEECH AUDI P, V13, P432, DOI 10.1109/TSA.2005.845816
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Wang HQ, 2008, APPL ACOUST, V69, P868, DOI 10.1016/j.apacoust.2007.06.001
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2007, IEEE T AUDIO SPEECH, V15, P2270, DOI 10.1109/TASL.2007.906192
   Wei FS, 2005, IEEE INT SYMP CIRC S, P4409
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2007, LECT NOTES COMPUT SC, V4437, P93
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiaoming Zhang, 2008, Journal of Software, V3, P3
   Yang R, 2009, LECT NOTES COMPUT SC, V5450, P124, DOI 10.1007/978-3-642-04438-0_11
   Zhang L, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P381
   Zhang XM, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P951, DOI 10.1109/ISECS.2008.161
NR 30
TC 11
Z9 12
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 453
EP 476
DI 10.1007/s11042-010-0644-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900001
DA 2024-07-18
ER

PT J
AU Fujinami, K
   Inagawa, N
   Nishijo, K
   Sokan, A
AF Fujinami, Kaori
   Inagawa, Nobuhiro
   Nishijo, Kosuke
   Sokan, Akifumi
TI A middleware for a tabletop procedure-aware information display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Middleware; Procedure-awareness; Augmented reality; Tabletop
   applications
AB In this article, we propose a middleware that supports a developer to build tabletop information display systems. We focus on an application that projects information close to a particular object on a table. To let a user focus on his/her primary task, the information is presented based on a current phase in a procedure, which we call procedure-awareness. Here, a current phase is recognized through the utilization of objects. The proposed middleware separates information from acquisition and presentation mechanisms: sensors for operational context recognition, sensors for object identification/tracking for "nearby presentation", and projecting information near an object. A developer just needs to write a set of rules, i.e. application logic, that represent contents for particular operational contexts. Also, by implementing appropriate handlers, any content can be provided. We present the design and the implementation of the middleware and validate the expressiveness of application logics through prototype development.
C1 [Fujinami, Kaori; Inagawa, Nobuhiro; Nishijo, Kosuke; Sokan, Akifumi] Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Tokyo, Japan.
C3 Tokyo University of Agriculture & Technology
RP Fujinami, K (corresponding author), Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Tokyo, Japan.
EM fujinami@cc.tuat.ac.jp
RI Fujinami, Kaori/B-9930-2013
OI Fujinami, Kaori/0000-0002-5294-2812
FU MEXT [21500117]; Grants-in-Aid for Scientific Research [21500117]
   Funding Source: KAKEN
FX We thank Mr. Shogo Hashimoto for developing the AR-Cooking system. This
   work has been supported by MEXT funds for Grant-in-Aid for Division of
   Young Researchers and for Scientific Research (C) No. 21500117.
CR [Anonymous], JENA SEMANTIC WEB FR
   [Anonymous], INT J SMART HOME
   [Anonymous], ARTOOLKIT
   Ballagas R, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P241, DOI 10.1109/PERCOM.2004.1276862
   Beigl M, 2001, COMPUT NETW, V35, P401, DOI 10.1016/S1389-1286(00)00180-8
   Cho Y, 2007, LECT NOTES COMPUT SC, V4489, P236
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Harter A., 1999, MobiCom'99. Proceedings of Fifth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P59, DOI 10.1145/313451.313476
   Hashimoto A., 2008, P INF PROCESS MANAGE, P848
   Herrmann K, 2008, SASOW 2008: SECOND IEEE INTERNATIONAL CONFERENCE ON SELF-ADAPTIVE AND SELF-ORGANIZING SYSTEMS WORKSHOPS, PROCEEDINGS, P108, DOI 10.1109/SASOW.2008.25
   Hong JY, 2009, EXPERT SYST APPL, V36, P8509, DOI 10.1016/j.eswa.2008.10.071
   Intille SS, 2003, ADJ P UBICOMP 03, P265
   Kaltenbrunner M., 2007, TEI'07 Proceedings, P69
   Lassila Ora, 1998, W3C Recommendation
   Nakajima T., 2005, P 2 INT S UB INT SMA, P335
   Nintendo, 2006, SHAB DS RYOUR NAV
   *OASIS, WEB SERV BUS PROC EX
   Raskar R, 2003, ACM T GRAPHIC, V22, P809, DOI 10.1145/882262.882349
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Sokan A, 2010, LECT NOTES COMPUT SC, V6406, P151, DOI 10.1007/978-3-642-16355-5_14
   Wieland M, 2007, P 19 INT C ADV INF S
   Wolf H, 2009, LECT NOTES COMPUT SC, V5872, P98, DOI 10.1007/978-3-642-05290-3_19
NR 22
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 269
EP 293
DI 10.1007/s11042-011-0759-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700003
DA 2024-07-18
ER

PT J
AU Vermeirsch, K
   De Cock, J
   Notebaert, S
   Lambert, P
   Barbarien, J
   Munteanu, A
   Van de Walle, R
AF Vermeirsch, Kenneth
   De Cock, Jan
   Notebaert, Stijn
   Lambert, Peter
   Barbarien, Joeri
   Munteanu, Adrian
   Van de Walle, Rik
TI Efficient adaptive-shape partitioning of video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Partitioning; Motion compensation; Complexity;
   Shape-adaptive transformation
ID MOTION-COMPENSATED PREDICTION; COMPRESSION; OPTIMIZATION; STANDARD; DCT
AB While many recent international video coding standards, especially H.264/MPEG-4 AVC, leverage block size adaptivity in motion estimation, the rate-distortion boundary can be pushed further by allowing even more freedom in the partitioning process of inter pictures. Adaptive-shape partitioning, which allows blocks to be partitioned along a straight line that runs through the block at a freely chosen angle and position, complements the regular subblock partitioning, allowing the encoder to better adapt to the local characteristics of the motion activity in a video sequence. However, the technique demands excessive encoder resources to exhaust the large search space. This paper is the result of an investigation into the relative rate-distortion importance of the various adaptive-shape modes, both in terms of the angle of the partition boundary and of its location within a block. We find that a significant reduction of the search space with a factor of up to 40 can be accomplished, while retaining 50 to 90% of the compression gain obtained in the state of the art. This allows encoders to operate at much lower complexity levels and also reduces the signaling overhead associated with adaptive-shape partitioning. Based on our observations, we formulate a number of approaches to trade off compression performance against encoder complexity. Furthermore we discuss the use of various schemes of overlapping motion estimation along the partition boundary, an aspect which is currently left unaddressed in the literature on adaptive-shape partitioning. We introduce the use of shape-adaptive transforms for the motion compensated signal, to avoid the condition that arises with adaptive-shape partitioning where a partition boundary lies inside a transform block. The result is a reduction in ringing artifacts while maintaining objective quality.
C1 [Vermeirsch, Kenneth; De Cock, Jan; Notebaert, Stijn; Lambert, Peter; Van de Walle, Rik] Ghent State Univ, Multimedia Lab, Dept Elect & Informat Syst, Ghent, Belgium.
   [Barbarien, Joeri; Munteanu, Adrian] Vrije Univ Brussel, Dept Elect & Informat Proc ETRO, Brussels, Belgium.
C3 Ghent University; Vrije Universiteit Brussel
RP Vermeirsch, K (corresponding author), Ghent State Univ, Multimedia Lab, Dept Elect & Informat Syst, Ghent, Belgium.
EM kenneth.vermeirsch@elis.ugent.be
RI Munteanu, Adrian/HKO-9955-2023; Lambert, Peter/D-7776-2016
OI Munteanu, Adrian/0000-0001-7290-0428; Lambert, Peter/0000-0001-5313-4158
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR [Anonymous], 2005, H264 ITUT
   [Anonymous], 2005, H263 ITUT
   [Anonymous], Q616 ITUT VCEG
   Bjontegaard G, 2001, Q616 ITUT VCEG
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Cheong HY, 2003, P INT C MULT EXP ICM
   Divorra Escoda O, 2007, INT C AC SPEECH SIGN
   Divorra O, 2007, Q616 ITUT VCEG
   Flierl M, 2002, IEEE T CIRC SYST VID, V12, P957, DOI 10.1109/TCSVT.2002.805490
   Flierl M, 2001, P DAT COMPR C, P27
   Fukuhara T, 1997, IEEE T CIRC SYST VID, V7, P212, DOI 10.1109/76.554432
   Girod B, 2000, IEEE T IMAGE PROCESS, V9, P173, DOI 10.1109/83.821595
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Hung EM, 2006, P IEEE INT C IM PROC
   Kato S, 2004, P IEEE INT C IM PROC
   Kato S, 2002, P IEEE INT C IM PROC
   Kondo S, 2005, P IEEE INT C IM PROC
   Kondo S, 2005, VISUAL COMMUNICATION
   Kordasiewicz RC, 2007, IEEE T CIRC SYST VID, V17, P86, DOI 10.1109/TCSVT.2006.887080
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Puri A., 1998, Mobile Networks and Applications, V3, P5, DOI 10.1023/A:1019160312366
   Rajagopalan R, 1998, IEEE T CIRC SYST VID, V8, P119, DOI 10.1109/76.664094
   Ribas-Corbera J, 1998, J ELECTRON IMAGING, V7, P155, DOI 10.1117/1.482636
   Shen J, 1999, P IEEE INT C IM PROC
   SIKORA T, 1995, SIGNAL PROCESS-IMAGE, V7, P381, DOI 10.1016/0923-5965(95)00009-9
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P59, DOI 10.1109/76.350781
   Sullivan G, 1993, IEEE INT C AC SPEECH, V5, P437
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tan TK, 2008, Q616 ITUT VCEG
   Tao B, 2001, IEEE T IMAGE PROCESS, V10, P341, DOI 10.1109/83.908497
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Vermeirsch K, 2008, P INT S MULT SIG P M
   Wedi T, 2006, IEEE T CIRC SYST VID, V16, P484, DOI 10.1109/TCSVT.2006.870856
   Wiegand T, 1999, IEEE T CIRC SYST VID, V9, P70, DOI 10.1109/76.744276
   Wiegand T, 2005, IEEE T CIRC SYST VID, V15, P197, DOI 10.1109/TCSVT.2004.841690
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang K, 1997, IEEE J SEL AREA COMM, V15, P1704, DOI 10.1109/49.650044
   Zhang K, 1996, P IEEE INT C IM PROC
   Zhang K, 1995, P SPIE DIGITAL VIDEO
NR 40
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 385
EP 417
DI 10.1007/s11042-010-0593-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700001
OA Green Published
DA 2024-07-18
ER

PT J
AU Sevindik, V
   Bayat, O
   Weitzen, J
AF Sevindik, Volkan
   Bayat, Oguz
   Weitzen, Jay
TI Traffic differentiation for BE users in CDMA 1xEVDO networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless resource management; CDMA2000 1xEVDO; Best Effort; Inter-User
   Best Effort; Scheduling; Measurement; Real network data
AB Different traffic types have different Quality of Service (QoS) requirements, which necessitate traffic prioritization enhancements in cellular networks. In CDMA2000 Evolution Data Optimized (EVDO) network, initial applications have been mainly focused on Best Effort (BE) traffic. Network operators observed that even though BE traffic users were the lowest priority users paying small subscription fees, they were heavily consuming the network resources. Therefore, operators demanded to charge BE users depending on their different levels of data usage. In this paper, we have designed a novel forward link (FL) scheduler to differentiate BE traffic users, and created new BE user classes with different throughput characteristics. Our new approach is called Inter-User Best Effort (IUBE) traffic classification and is implemented in CDMA2000 1xEVDO networks. The performance and characterization of designed scheduler is investigated through real network experiments conducted in live CDMA2000 1xEVDO network. TCP (Transmission Control Protocol) throughput measurements, received mobile terminal power, and signal-to-noise-plus-interference ratio (SNIR) were evaluated in the experiments. In conclusion, experimental data reveals that the average throughput value of a particular IUBE class user matches with its targeted IUBE class throughput value, and IUBE feature of CDMA2000 1xEVDO provides accurate traffic classification among BE traffic users in the cellular network.
C1 [Sevindik, Volkan; Bayat, Oguz] Airvana Inc, Ericsson Unit, Chelmsford, MA 01824 USA.
   [Sevindik, Volkan; Weitzen, Jay] Univ Massachusetts, Lowell, MA 01854 USA.
   [Bayat, Oguz] Yeni Yuzyil Univ, Istanbul, Turkey.
C3 Ericsson; University of Massachusetts System; University of
   Massachusetts Lowell; Yeni Yuzyil University
RP Sevindik, V (corresponding author), Airvana Inc, Ericsson Unit, Chelmsford, MA 01824 USA.
EM vsevindik@airvana.com; obayat@airvana.com; jweitzen@airvana.com
CR 3GPP2 C.50024-A Std, 2005, CS0024A 3GPP2
   Andrews M, 2001, IEEE COMMUN MAG, V39, P150, DOI 10.1109/35.900644
   Bender P, 2000, IEEE COMMUN MAG, V38, P70, DOI 10.1109/35.852034
   HUI J, 2004, P IEEE GLOBEC 04
   KNOPP R, 1995, ICC '95 - 1995 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONFERENCE RECORD, VOLS 1-3, P331, DOI 10.1109/ICC.1995.525188
   *QUALCOMM INC, 2000, ENS QOS CDMA 2000 EV
   Rentel CH, 2002, IEEE VTS VEH TECHNOL, P160, DOI 10.1109/VTC.2002.1002684
   Tse D., 2005, Fundementals of Wireless Communications
   YANG SC, 1999, CDMA RF SYSTEM ENG
NR 9
TC 1
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 507
EP 523
DI 10.1007/s11042-010-0563-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600007
DA 2024-07-18
ER

PT J
AU Favalli, L
   Folli, M
AF Favalli, Lorenzo
   Folli, Marco
TI ILPS: a scalable multiple description coding scheme for H.264
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/SVC; Multiple description coding; Scalability; Inter layer
   prediction
ID VIDEO; COMPRESSION; CHANNEL; IMAGE
AB The most recent literature indicates multiple description coding (MDC) as a promising coding approach to handle the problem of video transmission over unreliable networks with different quality and bandwidth constraints. In this work, we describe an approach that moves from the concept of spatial MDC and improves coding efficiency by exploiting some form of scalability. In the algorithm, we first generate four subsequences by sub-sampling, these subsequences are then taken in pairs that will form each of the two descriptions. For each description, one of the original subsequences is predicted from the other one via some scalable algorithms, focusing on the inter layer prediction scheme. The proposed algorithm has been implemented as pre- and post- processing of the standard H.264/SVC coder. The experimental results presented show that the algorithm provides excellent results in several conditions including 3D video sequences.
C1 [Favalli, Lorenzo; Folli, Marco] Univ Pavia, Dipartimento Elettron, I-27100 Pavia, Italy.
C3 University of Pavia
RP Favalli, L (corresponding author), Univ Pavia, Dipartimento Elettron, Via Ferrata 1, I-27100 Pavia, Italy.
EM lorenzo.favalli@unipv.it; marco.folli@unipv.it
CR AKYOL E, 2005, IEEE INT C IM PROC I, V3, P712
   Apostolopoulos JG, 2004, IEEE COMMUN MAG, V42, P80, DOI 10.1109/MCOM.2004.1321395
   BACCAGLINI E, 2004, IEEE INT C IM PROC G, P936
   BAI H, 2006, 1 INT C INN COMP INF, V2, P241
   CARAMMA M, 2001, SPIE 2001 VISUAL COM, P545
   CHEN CW, 2008, RECENT ADV DISTRIBUT, V96, P131
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   FEHN C, 2003, SIGN SYST COMP 2003, V2, P9
   Flierl M, 2007, IEEE SIGNAL PROC MAG, V24, P66, DOI 10.1109/MSP.2007.905699
   FOLLI M, 2008, P MOB 08 OUL FINL
   FOLLI M, 2007, P MOB 07 NAFP GREEC
   Franchi N, 2005, IEEE T CIRC SYST VID, V15, P321, DOI 10.1109/TCSVT.2004.842606
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   *ISO IEC, 1995, 138182 ISOIECJTCSC29
   JAYANT NS, 1981, AT&T TECH J, V60, P501, DOI 10.1002/j.1538-7305.1981.tb03069.x
   Kamolrat B, 2008, IEEE T CONSUM ELECTR, V54, P887, DOI 10.1109/TCE.2008.4560175
   Karim HA, 2008, IEEE T CONSUM ELECTR, V54, P745, DOI 10.1109/TCE.2008.4560156
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Liu ML, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1367
   Mansour H, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P519, DOI 10.1109/ISSPIT.2006.270856
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   SCHAFER R, 2005, VISUAL COMMUNICATION
   SCHWARZ H, 2004, P PCS 2004 SAN FRANC
   SCHWARZ H, 2004, M11244 ISOIEC JTC1SC
   SCHWARZ H, 2005, P IWSSIP 2005 CHALK
   Setton E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P509
   Setton E, 2008, P IEEE, V96, P25, DOI 10.1109/JPROC.2007.909925
   Tillo T, 2004, IEEE SIGNAL PROC LET, V11, P908, DOI 10.1109/LSP.2004.836949
   van der Schaar M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P489
   van der Schaar M., 2007, MULTIMEDIA IP WIRELE
   VANMOORSEL A, 2001, 5 PERF WORKSH
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wei Z, 2006, I S INTELL SIG PROC, P135
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WOLF JK, 1980, AT&T TECH J, V59, P1417, DOI 10.1002/j.1538-7305.1980.tb03372.x
   YU M, 2005, IEEE INT WORKSH VLSI, P191
NR 37
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2011
VL 54
IS 3
SI SI
BP 609
EP 634
DI 10.1007/s11042-010-0577-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 790CH
UT WOS:000292565600005
DA 2024-07-18
ER

PT J
AU Chen, J
   Ren, JC
   Jiang, JM
AF Chen, Juan
   Ren, Jinchang
   Jiang, Jianmin
TI Modelling of content-aware indicators for effective determination of
   shot boundaries in compressed MPEG videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Content-aware modelling; Decision-tree; Finite
   state machine (FSM); Compressed domain video processing
ID TRANSITION DETECTION; CUT DETECTION; EFFICIENT; SEGMENTATION
AB In this paper, a content-aware approach is proposed to design multiple test conditions for shot cut detection, which are organized into a multiple phase decision tree for abrupt cut detection and a finite state machine for dissolve detection. In comparison with existing approaches, our algorithm is characterized with two categories of content difference indicators and testing. While the first category indicates the content changes that are directly used for shot cut detection, the second category indicates the contexts under which the content change occurs. As a result, indications of frame differences are tested with context awareness to make the detection of shot cuts adaptive to both content and context changes. Evaluations announced by TRECVID 2007 indicate that our proposed algorithm achieved comparable performance to those using machine learning approaches, yet using a simpler feature set and straightforward design strategies. This has validated the effectiveness of modelling of content-aware indicators for decision making, which also provides a good alternative to conventional approaches in this topic.
C1 [Ren, Jinchang] Univ Bradford, Sch Comp Informat & Media EIMC, Bradford BD7 1DP, W Yorkshire, England.
   [Chen, Juan] Univ Elect Sci & Technol, Sch Engn & Comp Sci, Chengdu, Peoples R China.
   [Ren, Jinchang; Jiang, Jianmin] Univ Bradford, Digital Media & Syst Res Inst, Sch Informat, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford; University of Electronic Science & Technology of
   China; University of Bradford
RP Ren, JC (corresponding author), Univ Bradford, Sch Comp Informat & Media EIMC, Richmond Rd, Bradford BD7 1DP, W Yorkshire, England.
EM chenjuan@hotmail.co.uk; j.ren@bradford.ac.uk; J.Jiang1@bradford.ac.uk
RI xia, yu/E-6596-2012
OI Ren, Jinchang/0000-0001-6116-3194
FU EU [IST-216709]
FX The authors wish to acknowledge the financial support from EU IST FP-7
   Research Programme under the STREP project HERMES (Contract No.
   IST-216709).
CR [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Bescós J, 2005, IEEE T MULTIMEDIA, V7, P293, DOI 10.1109/TMM.2004.840598
   Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603
   Cao JR, 2007, PATTERN RECOGN LETT, V28, P1534, DOI 10.1016/j.patrec.2007.03.011
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Fang H, 2006, PATTERN RECOGN, V39, P2092, DOI 10.1016/j.patcog.2006.04.044
   Ford RM, 2000, MULTIMEDIA SYST, V8, P37, DOI 10.1007/s005300050003
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Grana C, 2007, IEEE T CIRC SYST VID, V17, P483, DOI 10.1109/TCSVT.2006.888818
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hoey J, 2007, IEEE T PATTERN ANAL, V29, P1118, DOI 10.1109/TPAMI.2007.1145
   Lefèvre S, 2007, J REAL-TIME IMAGE PR, V2, P23, DOI 10.1007/s11554-007-0033-1
   Li DG, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P445, DOI 10.1109/MMCS.1999.779243
   Li S, 2007, IEEE T CIRC SYST VID, V17, P1383, DOI 10.1109/TCSVT.2007.903798
   Liu TY, 2004, J VIS COMMUN IMAGE R, V15, P132, DOI 10.1016/j.jvcir.2003.10.001
   LIU Z, 2006, AT T RES TRECVID
   MATSUMOTO K, 2005, SHOT BOUNDARY DETECT
   MENG JH, 1995, P SOC PHOTO-OPT INS, V2419, P14, DOI 10.1117/12.206359
   Patel K., 1993, Proceedings ACM Multimedia 93, P75, DOI 10.1145/166266.166274
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Porter S, 2003, IMAGE VISION COMPUT, V21, P1097, DOI 10.1016/j.imavis.2003.08.014
   Qiu KJ, 2006, LECT NOTES COMPUT SC, V4141, P673
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Urhan O, 2006, IEEE T CIRC SYST VID, V16, P753, DOI 10.1109/TCSVT.2006.875210
   Yang KC, 2007, IEEE T MULTIMEDIA, V9, P1528, DOI 10.1109/TMM.2007.906576
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
NR 29
TC 12
Z9 12
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 219
EP 239
DI 10.1007/s11042-010-0518-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700002
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Wu, ZD
   Cao, ZS
   Wang, YZ
AF Wu, Zongda
   Cao, Zhongsheng
   Wang, Yuanzhen
TI Multimedia selection operation placement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia database; Query optimization; Multimedia operation; UMQL;
   UMQA
ID OPTIMIZATION; QUERIES
AB Based on the assumption that selections are zero-expense operations, "selection pushdown" rules, which apply selections in random order before as many joins as possible in order to reduce subsequent join costs, have been widely applied in traditional query optimization methods. However, in multimedia information systems, selections generally contain expensive multimedia operations, making "pushdown" rules no longer able to produce optimal query execution plan. Therefore, we in this paper develop a theory for optimizing queries with expensive multimedia operations, which can establish the optimal placement of each multimedia operation in a query plan by the comprehensive consideration of selectivity and unit execution cost of each operation. Then we present an algorithm for the theory and implement it in a prototype system. Experimental results show that, compared with traditional optimization algorithms, our algorithm not only has the modest time complexity that is polynomial in the number of multimedia operations in a query plan, but also can reduce the execution cost of a query plan by orders of magnitude.
C1 [Wu, Zongda] Wenzhou Univ, Oujiang Coll, Wenzhou 325035, Zhejiang, Peoples R China.
   [Cao, Zhongsheng; Wang, Yuanzhen] Huazhong Univ Sci & Technol, Coll Comp Sci & Technol, Inst Database & Multimedia, Wuhan 430074, Peoples R China.
C3 Wenzhou University; Wenzhou University of Technology; Huazhong
   University of Science & Technology
RP Wu, ZD (corresponding author), Wenzhou Univ, Oujiang Coll, Wenzhou 325035, Zhejiang, Peoples R China.
EM zongda1983@163.com; caozhongsheng@163.com
FU National High-Tech Research and Development Plan of China [2006AA01Z430]
FX This research is supported in part by the National High-Tech Research
   and Development Plan of China under Grant Nos. 2006AA01Z430. We thank
   Wu-Jie Su for his careful revision of this paper, and also thank
   anonymous reviewers for their useful suggestions.
CR [Anonymous], 1956, Naval Research Logistics Quarterly, DOI DOI 10.1002/NAV.3800030106
   [Anonymous], PROCEEDINGS OF THE 1
   CAO ZS, 2007, P 3 IEEE INT C SIGN, P101
   CAO ZS, 2009, IT J, V8, P411
   CAO ZS, 2008, J ELECT SCI TECHNOL, V6, P87
   Chaudhuri S, 1999, ACM T DATABASE SYST, V24, P177, DOI 10.1145/320248.320249
   Chimenti D., 1989, Proceedings of the Fifteenth International Conference on Very Large Data Bases, P195
   Haas P. J., 1995, P 21 INT C VER LARG
   Hellerstein JM, 1998, ACM T DATABASE SYST, V23, P113, DOI 10.1145/292481.277627
   HELLERSTEIN JM, 1993, P ACM SIGMOD INT C M, P267
   HELLERSTEIN JM, 1994, P ACM SIGMOD INT C M, P325
   Hou W.-C., 1988, Proceedings of the Seventh ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P276, DOI 10.1145/308386.308455
   HUANG DW, 2008, THESIS HUAZHONG U SC
   Kemper A., 1994, P ACM SIGMOD C MAN D, P336, DOI 10.1145/191839.191906
   LAZARIDIS L, 2007, P ACM SIGMOD INT C M, P797
   Monma C. L., 1979, Mathematics of Operations Research, V4, P215, DOI 10.1287/moor.4.3.215
   RAVI K, 1986, P 12 INT C VER LARG, P128
   STONEBRAKER M, 1991, P ACM SIGMOD INT C M, P2
   Swami A. N., 1993, Proceedings. Ninth International Conference on Data Engineering (Cat. No.92CH3258-1), P345, DOI 10.1109/ICDE.1993.344047
   Wu Zongda, 2008, Journal of Huazhong University of Science and Technology, V36, P45
   YAJIMA K, 1991, P 2 INT S DAT SYST A, P366
   YANG GG, 2001, ACTA ELECT SINICA, V29, P181
NR 22
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 69
EP 96
DI 10.1007/s11042-010-0528-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100005
DA 2024-07-18
ER

PT J
AU Palau, CE
   Mares, J
   Molina, B
   Esteve, M
AF Palau, Carlos Enrique
   Mares, Joaquin
   Molina, Benjamin
   Esteve, Manuel
TI Wireless CDN video streaming architecture for IPTV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; CDN; Streaming; Mobile; WiMAX; 3G
AB Wireless IPTV (Internet Protocol TeleVision) aims to make the traditional IPTV and related services available to users anywhere, anytime, on any device, and through any network. Mobile streaming TV is one of the alternatives to deploy such a system; others are DVB-H or MediaFLO. In this paper we propose an alternative CDN-based architecture to distribute contents to different access networks, in order to create a triple screen platform. The core elements of the system are the video streamers, acting as surrogates of the mobile CDN-based architecture, installed in the access networks (including mobile), and the transcoding servers in the premises of the content providers. The paper focused on the wireless part of the system, analyzing the architecture and performance results related with the video coding and the efficiency obtained due to the placement of the streaming servers. The system has been deployed by a Spanish media company for its use with different Telcos, ISPs and media companies.
C1 [Palau, Carlos Enrique; Mares, Joaquin; Molina, Benjamin; Esteve, Manuel] Univ Politecn Valencia, Dept Comunicaciones, Distributed Real Time Syst Res Grp, E-46071 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Palau, CE (corresponding author), Univ Politecn Valencia, Dept Comunicaciones, Distributed Real Time Syst Res Grp, E-46071 Valencia, Spain.
EM cpalau@upvnet.upv.es; jamarno@upvnet.upv.es; benmomo@upvnet.upv.es;
   mesteve@upvnet.upv.es
RI Molina, Benjamin/AAH-9866-2021
OI Molina, Benjamin/0000-0002-1995-4192; Esteve,
   Manuel/0000-0002-7985-3270; Palau, Carlos E./0000-0002-3795-5404
FU Ministerio de Industria, Turismo y Comercio; Fondo Europeo de Desarrollo
   Regional (FEDER)
FX The authors would like to thank their colleagues of ITEA2 EXPESHARE and
   CELTIC SERVERY projects, who have shaped their work with active
   participation in discussions and cooperation regarding the topics
   discussed in this paper. This document is a by-product of both projects,
   funded by the Ministerio de Industria, Turismo y Comercio through Plan
   AVANZA and Fondo Europeo de Desarrollo Regional (FEDER).
CR *AG, 2006, IPTV QOE UND INT MDI
   Ahmed T, 2005, IEEE J SEL AREA COMM, V23, P385, DOI 10.1109/JSAC.2004.839425
   [Anonymous], P INT WORKSH PEER TO
   BONASTRE O, 2009, 10 C TEL ZAGR CROAT
   Braet Olivier, 2008, Telematics and Informatics, V25, P216, DOI 10.1016/j.tele.2007.03.003
   CHA M, 2006, P INT WORKSH IPTV SE
   Etoh M, 2005, P IEEE, V93, P111, DOI 10.1109/JPROC.2004.839605
   *EUR COM, 2007, FUT INT CREAT MED WO
   *FFMPEG, 2008, FFMPEG MULT SYST
   Fortino G, 2007, IEEE MULTIMEDIA, V14, P60, DOI 10.1109/MMUL.2007.29
   Fröjdh P, 2006, IEEE NETWORK, V20, P34, DOI 10.1109/MNET.2006.1607894
   HANDS D, 2006, ITU T WKSP END TO EN
   HEI X, 2006, WWW 06, P6
   Hjelm Johan., 2008, Why IPTV? Interactivity, Technologies and Services, V1
   *ITU, 2009, MECH SERV DISC SEL I
   Jain R, 2005, IEEE MULTIMEDIA, V12, P96, DOI 10.1109/MMUL.2005.47
   Jenkac H, 2006, IEEE NETWORK, V20, P14, DOI 10.1109/MNET.2006.1607891
   Kerpez K, 2006, IEEE COMMUN MAG, V44, P166, DOI 10.1109/MCOM.2006.1705994
   KOTHARI R, 2005, IEEE INT C WIR MOB C
   LARRIBEAU B, 2006, 2006 IPTV STANDARDS
   LAZARO O, 2007, 16 IST MOB WIR COMM
   Lee YJ, 2005, FOURTH ANNUAL ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P414
   Li Y, 2008, IEEE T MULTIMEDIA, V10, P885, DOI 10.1109/TMM.2008.922860
   Más I, 2008, IEEE COMMUN MAG, V46, P156, DOI 10.1109/MCOM.2008.4689259
   MOLINA B, 2006, COMPUT COMMUN, V29, P396
   MONTPETIT MJ, 2009, MOBILE TV
   *QUALC, 2009, WIMAX VS 3G
   RETNASOTHIE FE, 2006, IEEE WAMICON CLEARW
   SCHATZ R, 2008, P IEEE INT S BROADB
   SCHORR A, 2004, IEEE MULTIMEDIA SIGN, P506
   Sentinelli A, 2007, IEEE COMMUN MAG, V45, P86, DOI 10.1109/MCOM.2007.374424
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   Taniuchi K, 2009, IEEE COMMUN MAG, V47, P112, DOI 10.1109/MCOM.2009.4752687
   TURAGA DS, 2005, INT C MULT EXP
   Vanhastel S, 2008, IEEE COMMUN MAG, V46, P90, DOI 10.1109/MCOM.2008.4597110
   VASSILIOU V, 2006, ICANN 2006 ATH GREEC
   WALES C, 2008, IPTV REVOLUTION HERE
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao Y, 2007, IEEE COMMUN MAG, V45, P126, DOI 10.1109/MCOM.2007.4378332
   Zhou JH, 2009, IEEE MULTIMEDIA, V16, P60, DOI 10.1109/MMUL.2009.7
NR 40
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2011
VL 53
IS 3
SI SI
BP 591
EP 613
DI 10.1007/s11042-010-0516-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 758OK
UT WOS:000290174100006
DA 2024-07-18
ER

PT J
AU Doncel, VR
   Delgado, J
   Chiariglione, F
   Preda, M
   Timmerer, C
AF Rodriguez Doncel, Victor
   Delgado, Jaime
   Chiariglione, Filippo
   Preda, Marius
   Timmerer, Christian
TI Interoperable digital rights management based on the MPEG Extensible
   Middleware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Middleware; DRM; Content management; MPEG-21
AB This paper describes an interoperable Digital Rights Management architecture promoted by the MPEG standardization group in its new standard known as MPEG-M or MPEG Extensible Middleware (MXM). The goal of this standard is to promote the packaging and reusability of MPEG technologies, and for this it specifies a software middleware platform and a complete set of APIs and protocols. These APIs allow uniformly handling digital content and developing generic multimedia applications, through a set of modules communicated with standard protocols. The MXM standard provides the necessary mechanisms to digitally manage the rights over Intellectual Property, the tools to protect the media and the means to grant the rights enforcement, besides a rich set of libraries to reproduce the content.
C1 [Rodriguez Doncel, Victor; Delgado, Jaime] Univ Politecn Cataluna, Barcelona, Spain.
   [Chiariglione, Filippo] CEDEO Net, Turin, Italy.
   [Preda, Marius] TELECOM & Management SudParis, F-91011 Evry, France.
   [Timmerer, Christian] Univ Klagenfurt, Klagenfurt, Austria.
C3 Universitat Politecnica de Catalunya; IMT - Institut Mines-Telecom;
   Institut Mines-Telecom Business School; Institut Polytechnique de Paris;
   Telecom SudParis; University of Klagenfurt
RP Doncel, VR (corresponding author), Univ Politecn Cataluna, Barcelona, Spain.
EM victorr@ac.upc.edu
RI Preda, Marius/HDM-2040-2022; Delgado, Jaime/AAA-8489-2019;
   Rodriguez-Doncel, Victor/J-5779-2012
OI Preda, Marius/0000-0003-2288-0291; Delgado, Jaime/0000-0003-1366-663X;
   Rodriguez-Doncel, Victor/0000-0003-1076-2511
CR [Anonymous], 2004, IEEE MULTIMEDIA
   Chen XF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P907
   *DIG MED PROJ GROU, 2003, DIG MED MAN
   EBRAHIMI T, 2003, P IEEE INT C AC SPEE, V4, P716
   Hogab Kang, 2009, IEEE Multimedia, V16, P94, DOI 10.1109/MMUL.2009.14
   *ISO IEC, 2009, 291161 ISOIEC
   *ISO IEC, 2009, 230063 ISOIEC
   *ISO IEC, 2009, 230062 ISOIEC
   *ISO IEC, 2008, 1593812 ISOIEC
   *ISO IEC, 2009, 230061 ISOIEC
   Koenen RH, 2004, P IEEE, V92, P883, DOI 10.1109/JPROC.2004.827357
   LEBONHOMME B, 2008, MULTIMEDIA SEMANTICS
   RANSBURG M, 2008, MULTIMEDIA SEMANTICS
   Rodriguez-Doncel V, 2009, IEEE MULTIMEDIA, V16, P44, DOI 10.1109/MMUL.2009.78
   Serrao C, 2006, INT J COMPUT SCI NET, V6, P291
   Thomas-Kerr J, 2008, IEEE T MULTIMEDIA, V10, P514, DOI 10.1109/TMM.2008.917337
   Tokmakoff A, 2005, IEEE MULTIMEDIA, V12, P50, DOI 10.1109/MMUL.2005.77
   Torres V, 2004, LECT NOTES COMPUT SC, V3311, P252
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   2009, MPEG EXTENSIBLE MIDD
NR 20
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 303
EP 318
DI 10.1007/s11042-010-0513-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700014
DA 2024-07-18
ER

PT J
AU Lu, YJ
   Sebe, N
   Hytnen, R
   Tian, Q
AF Lu, Yijuan
   Sebe, Nicu
   Hytnen, Ross
   Tian, Qi
TI Personalization in multimedia retrieval: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalization; Information Access; Multimedia
ID IMAGE RETRIEVAL; OBJECT; MPEG-7; VISUALIZATION; RECOGNITION; SEMANTICS;
   SCALE
AB With the explosive broadcast of multimedia (text documents, image, video etc.) in our life, how to annotate, search, index, browse and relate various forms of information efficiently becomes more and more important. Combining these challenges by relating them to user preference and customization only complicates the matter further. The goal of this survey is to give an overview of the current situation in the branches of research that are involved in annotation, relation and presentation to a user by preference. This paper will present some current models and techniques being researched to model ontology, preference, context, and presentation and bring them together in a chain of ideas that leads from raw uninformed data to an actual usable user interface that adapts with user preference and customization.
C1 [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
   [Sebe, Nicu] Univ Trent, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
   [Lu, Yijuan; Hytnen, Ross] SW Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
C3 University of Texas System; University of Texas at San Antonio (UTSA);
   University of Trento; Texas State University System; Texas State
   University San Marcos
RP Tian, Q (corresponding author), Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
EM yl12@txstate.edu; sebe@disi.unitn.it; r.hytnen@gmail.com;
   qitian@cs.utsa.edu
RI chen, mingang/C-7691-2011; Sebe, Niculae/KEC-2000-2024; LU,
   YIJUAN/GNM-8769-2022
OI Sebe, Niculae/0000-0002-6597-7248; LU, YIJUAN/0000-0002-9855-8365
FU Research Enhancement Program (REP); Texas State University; FP7 IP
   GLOCAL european project; FIRB S-PATTERN project
FX We would like to thank Dick Bulterman, Stavros Christodoulakis, Chabane
   Djeraba, Daniel Gatica-Perez, Thomas Huang, Alex Jaimes, Ramesh Jain,
   Mike Lew, Andy Rauber, Pasquale Savino, Arnold Smeulders, and the whole
   FACS consortium for excellent suggestions and discussions. The work of
   Nicu Sebe has been supported by the FP7 IP GLOCAL european project and
   by the FIRB S-PATTERN project. The work of Yijuan Lu was supported in
   part by the Research Enhancement Program (REP) and start-up funding from
   the Texas State University.
CR Agius H, 2007, MULTIMEDIA SYST, V13, P155, DOI 10.1007/s00530-007-0088-7
   Aizawa Kiyoharu., 2004, CARPE 04 P THE 1 ACM, P22, DOI DOI 10.1145/1026653.1026656
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 4 HELL DAT MAN S HDM
   [Anonymous], ACM MULT INF RETR WO
   [Anonymous], INT C IM VID RETR
   [Anonymous], INT C MUS INF RETR I
   [Anonymous], ISIRR89242
   [Anonymous], USER MODEL USER ADAP
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2003, Proceedings of the International Symposium on Music Information Retrieval
   [Anonymous], 2002, PROC 10 ACM INT C MU
   [Anonymous], INT WORKSH MULT DAT
   [Anonymous], ACM INT WORKSH MULT
   [Anonymous], HPL2008197
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], INT C MULT MOD
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], SMIL 2 0 INTERACTIVE
   [Anonymous], COMPUT NETW ISDN SYS
   [Anonymous], ACM C DIG LIBR
   [Anonymous], INT C COMP LING
   [Anonymous], IJCAI 2001
   [Anonymous], IEEE C MULT EXP
   [Anonymous], ACM MULT INF RETR WO
   [Anonymous], SPIE MULTIMED STORAG
   [Anonymous], SIGCHI C HUM FACT CO
   [Anonymous], IEEE COMPUTER
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], INT C PRACT ASP KNOW
   [Anonymous], INT C MULT MOD
   [Anonymous], INT C WWW
   [Anonymous], INT C COMP SYST TECH
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], J VIS COMMUN IMAGE R
   [Anonymous], INT C AC SPEECH SIGN
   [Anonymous], 2001, P 1 EUNITE S
   [Anonymous], P INFORMATIK 2003 IN
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], ACM MULTIMEDIA
   Battelle John, 2005, The search: How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture
   Belotti R, 2004, LECT NOTES COMPUT SC, V3272, P43
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Brewer E, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.204
   Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, P132, DOI 10.1145/280765.280789
   Crystal David., 1991, DICT LINGUISTICS PHO, V3rd
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Ghidini C, 2001, ARTIF INTELL, V127, P221, DOI 10.1016/S0004-3702(01)00064-9
   GIUNCHIGLIA F, 1994, ARTIF INTELL, V65, P29, DOI 10.1016/0004-3702(94)90037-X
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Hirsh H, 2000, COMMUN ACM, V43, P102, DOI 10.1145/345124.345159
   HUA XS, 2004, ACM MULTIMEDIA 04, P172
   Jaimes A., 2006, ACM INT C MULTIMEDIA, P855
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jaimes A, 2007, COMPUTER, V40, P30, DOI 10.1109/MC.2007.169
   Jain R, 2003, COMMUN ACM, V46, P27, DOI 10.1145/641205.641223
   Lang Peter., 1993, PERSPECTIVES ANGER E, P109
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li X, 2009, ACM T INTERNET TECHN, V9, DOI 10.1145/1552291.1552292
   Liu DX, 2008, IEEE ANTENNAS PROP, P169
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Magnini B, 2004, USER MODEL USER-ADAP, V14, P239, DOI 10.1023/B:USER.0000028980.13669.44
   Maybury M.T., 1997, Intelligent multimedia information retrieval
   MCCARTHY J, 1987, COMMUN ACM, V30, P1030, DOI 10.1145/33447.33448
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   Nister David, 2006, CVPR
   Oviatt S, 2003, P IEEE, V91, P1457, DOI 10.1109/JPROC.2003.817127
   Parsons S, 1998, J LOGIC COMPUT, V8, P261, DOI 10.1093/logcom/8.3.261
   Rauber A, 2003, J NEW MUSIC RES, V32, P193, DOI 10.1076/jnmr.32.2.193.16745
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Savarese S., 2006, P 2006 IEEE COMPUTER, V2, P2033, DOI DOI 10.1109/CVPR.2006.102
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   Tsinaraki C, 2005, MULTIMED TOOLS APPL, V26, P299, DOI 10.1007/s11042-005-0894-x
   Venkatesh S, 2008, P IEEE, V96, P697, DOI 10.1109/JPROC.2008.916378
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Wang FS, 2008, INT C PATTERN RECOGN, P1
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Xu M, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P622
   Yang L, 2007, INT J ROTATING MACH, V2007, DOI 10.1155/2007/85275
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhou M. X., 2006, 2006 International Conference on Intelligent User Interfaces, P116, DOI 10.1145/1111449.1111479
   Zhou MX, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P634
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 109
TC 17
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 247
EP 277
DI 10.1007/s11042-010-0621-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800010
DA 2024-07-18
ER

PT J
AU Tang, ZY
   Guo, XH
   Prabhakaran, B
AF Tang, Ziying
   Guo, Xiaohu
   Prabhakaran, Balakrishnan
TI Receiver-based loss tolerance method for 3D progressive streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Progressive compression; 3D streaming; Loss tolerance
ID ERROR; TRANSMISSION; COMPRESSION
AB While progressive compression techniques were proposed long time ago, fast and efficient streaming of detailed 3D models over lossy networks still remains a challenge. A primary reason is that packet loss occurring in unreliable networks is highly unpredictable, leading to connectivity inconsistency and distortions of decompressed meshes. Although prior researches have proposed various methods to handle errors caused by transmission loss, they are always accompanied by additional costs such as redundant transmission data, bandwidth overloads, and result distortions. In this paper, we address this problem from a receiver's point of view and propose a novel receiver-based loss tolerance scheme which is capable of recovering the lost data when streaming 3D progressive meshes over lossy networks. Specifically, we use some constraints during the model compression procedure on the server side, and suggest a prediction method to handle loss of structural and geometric data on the client/receiver side. Our algorithm works without any data retransmission or introducing any unnecessary protection bits. We stream mesh refinement data on reliable and unreliable networks separately so as to reduce the transmission delay as well as to obtain a satisfactory decompression result. The experimental results indicate that the decompression procedure can be accomplished quickly, suggesting that it is an efficient and practical solution. It is also shown that the proposed prediction technique achieves a very good approximation of the original mesh with low distortions, and in the mean time, error propagations are also well controlled.
C1 [Tang, Ziying; Guo, Xiaohu; Prabhakaran, Balakrishnan] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Dallas
RP Tang, ZY (corresponding author), Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
EM zxt061000@utdallas.edu; xguo@utdallas.edu; praba@utdallas.edu
CR Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   Alregib G, 2005, ACM T GRAPHIC, V24, P182, DOI 10.1145/1061347.1061349
   ALREGIB G, 2004, P 9 INT C 3D WEB TEC, P155
   AlRegib G., 2002, Proceedings of the IEEE International Conference, V2, P2041
   Bischoff S, 2002, COMPUT GRAPH-UK, V26, P665, DOI 10.1016/S0097-8493(02)00122-X
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Devillers O, 2000, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2000.885711
   Guan W, 2008, IEEE T MULTIMEDIA, V10, P724, DOI 10.1109/TMM.2008.922785
   Guo YH, 2007, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HEALTH MONITORING OF STRUCTURE, MATERIALS AND ENVIRONMENT, VOLS 1 AND 2, P738
   Hoppe H., 1996, Proceedings of SIGGRAPH'96, P77
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   [Краевский В.В. Kraevsky V.V.], 2005, [Педагогика, Pedagogika], P13
   Li H, 2006, ACM T MULTIM COMPUT, V2, P282, DOI 10.1145/1201730.1201733
   LI H, 2007, THESIS U TEXAS DALLA
   Li H., 2004, Proceedings of DMS/VLC'04, P275
   Li H, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P501, DOI 10.1109/ICME.2008.4607481
   MARTIN I, 2000, 21722 RC IBM TJ WATS
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Pfeifle R, 1996, PROC GRAPH INTERF, P186
   SOUTHERN R, 2001, P WEB3D S
   TANG Z, 2009, P IEEE INT S MULT IS, P263
   TAUBIN G, 1998, P SIGGRAPH 98, P123
   Yan ZD, 2001, IEEE T CIRC SYST VID, V11, P860, DOI 10.1109/76.931112
   Yang B., 2008, Proceeding of Computer Graphics International, P18
NR 25
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 779
EP 799
DI 10.1007/s11042-010-0634-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300015
DA 2024-07-18
ER

PT J
AU Samangooei, S
   Nixon, MS
AF Samangooei, Sina
   Nixon, Mark S.
TI Performing content-based retrieval of humans using gait biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based video retrieval; Latent semantic indexing; Gait
   biometrics; Anthropometry; Semantic enrichment
ID RECOGNITION; MOTION; PSYCHOLOGY; MODEL
AB In order to analyse surveillance video, we need to efficiently explore large datasets containing videos of walking humans. Effective analysis of such data relies on retrieval of video data which has been enriched using semantic annotations. A manual annotation process is time-consuming and prone to error due to subject bias however, at surveillance-image resolution, the human walk (their gait) can be analysed automatically. We explore the content-based retrieval of videos containing walking subjects, using semantic queries. We evaluate current research in gait biometrics, unique in its effectiveness at recognising people at a distance. We introduce a set of semantic traits discernible by humans at a distance, outlining their psychological validity. Working under the premise that similarity of the chosen gait signature implies similarity of certain semantic traits we perform a set of semantic retrieval experiments using popular Latent Semantic Analysis techniques. We perform experiments on a dataset of 2000 videos of people walking in laboratory conditions and achieve promising retrieval results for features such as Sex (mAP = 14% above random), Age (mAP = 10% above random) and Ethnicity (mAP = 9% above random).
C1 [Samangooei, Sina; Nixon, Mark S.] Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 University of Southampton
RP Samangooei, S (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
EM ss06r@ecs.soton.ac.uk; msn@ecs.soton.ac.uk
OI Nixon, Mark/0000-0002-9174-5934
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2003, P 11 ACM INT C MULT
   Barbujani G, 2005, CURR GENOMICS, V6, P215, DOI 10.2174/1389202054395973
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   BENNETTO J, 2006, INDEPENDENT
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   Bertillon A., 1896, Signaletic Instructions Including the Theory and Practice of Anthropometrical Identification
   Bhanu B, 2003, LECT NOTES COMPUT SC, V2688, P600
   BOUCHRIKA I, 2009, P ICB
   Chapman G.B., 2002, Heuristics and Biases: The Psychology of Intuitive Judgment, P120, DOI 10.1017/CBO9780511808098.008
   Davies AC, 2005, INT WORKSH INT DATA, P417, DOI 10.1109/IDAACS.2005.283015
   Dawes R.M., 1977, APPL PSYCH MEAS, V1, P267, DOI DOI 10.1177/014662167700100213
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DUMAIS S, 1991, INSTRUMENTS COMPUTER, P229
   ELLIS H.D., 1984, EYEWITNESS TESTIMONY, P12
   FLIN RH, 1986, HUM LEARN, V5, P29
   GOFFREDO M, 2008, P IEEE FG
   Gould StephenJay., 1994, DISCOVER MAGAZINE
   GROSKY WI, 2001, P C CURR TRENDS THEO, P33
   Han J, 2004, PROC CVPR IEEE, P842
   HARE JS, 2006, P CIVR, P31
   Hare JS., 2008, Proceedings of the 2008 International Conference on Content-Based Image and Video Retrieval, P359
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   *INT, 2008, DIS VICT ID FORM YEL
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kale A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P901
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   LINDSAY RCL, 1994, LAW HUMAN BEHAV, V18, P527, DOI 10.1007/BF01499172
   LITTLE J, 1995, P ISCV, pA5
   Liu ZY, 2007, IMAGE VISION COMPUT, V25, P817, DOI 10.1016/j.imavis.2006.05.022
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   MACLEOD MD, 1994, ADULT EYEWITNESS TES, pCH6
   Macrae CN, 2000, ANNU REV PSYCHOL, V51, P93, DOI 10.1146/annurev.psych.51.1.93
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   NANDAKUMAR K, 2004, P ICBA, P731
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   OTOOLE A, 2004, HDB FACE RECOGNITION
   PAPADIMITRIOU CH, 1998, COMPUT SYST SCI, V61, P217
   PECENOVIC Z, 1997, THESIS AUDIOVISUAL C
   Ponterotto JG, 2007, J COUNS PSYCHOL, V54, P219, DOI 10.1037/0022-0167.54.3.219
   Rosse C, 2003, J BIOMED INFORM, V36, P478, DOI 10.1016/j.jbi.2003.11.007
   Sadr J, 2006, VIS COGN, V14, P119
   SAMANGOOEI S, 2008, P IEEE BTAS
   SEELY RD, 2008, P IEEE BTAS
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Shutler J.D., 2002, 4th International Conference on Recent Advances in Soft Computing, P66
   TAJFEL H, 1982, ANNU REV PSYCHOL, V33, P1, DOI 10.1146/annurev.ps.33.020182.000245
   vanKoppen PJ, 1997, LAW HUMAN BEHAV, V21, P661, DOI 10.1023/A:1024812831576
   Veres GV, 2004, PROC CVPR IEEE, P776
   Vrusias B., 2007, 8 INT WORKSHOP IMAGE, P5
   Wells GL, 2003, ANNU REV PSYCHOL, V54, P277, DOI 10.1146/annurev.psych.54.101601.145028
   Yarmey AD, 1997, J APPL SOC PSYCHOL, V27, P330, DOI 10.1111/j.1559-1816.1997.tb00635.x
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 56
TC 22
Z9 24
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 195
EP 212
DI 10.1007/s11042-009-0391-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chang, JH
   Lai, CF
   Huang, YM
   Chao, HC
AF Chang, Jui-Hung
   Lai, Chin-Feng
   Huang, Yueh-Min
   Chao, Han-Chieh
TI 3PRS: a personalized popular program recommendation system for digital
   TV for P2P social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video broadcasting-terrestrial (DVB-T); Electronic program guide
   (EPG); Information retrieval (IR); K-nearest neighbo (kNN); k-means
AB Digital TV channels require users to spend more time to choose their favorite TV programs. Electronic Program Guides (EPG) cannot be used to find popular TV programs. Hence, this paper proposes a personalized Digital Video Broadcasting - Terrestrial (DVBT) Digital TV program recommendation system for P2P social networks. From the DVB-T signal, we obtain EPG of TV programs. The frequency and duration of the programs that users have watched are used to extract programs that users are interested in. The information is collected and weighted by Information Retrieval (IR). The program information is then clustered by k-means. Clusters of users are also grouped by k-means to find cluster relationships. In each group, we decide the most popular program in the group according to the program weight of the channel. When a new user begins to watch the TV program, the K-Nearest Neighbor (kNN) classification method is used to determine the user's predicted cluster label. Then, our system recommends popular programs in the predicted cluster and similar clusters.
C1 [Chang, Jui-Hung; Lai, Chin-Feng; Huang, Yueh-Min] Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
   [Chao, Han-Chieh] Natl Ilan Univ, Inst Comp Sci & Informat Engn, Ilan 260, Taiwan.
   [Chao, Han-Chieh] Natl Ilan Univ, Dept Elect Engn, Ilan 260, Taiwan.
   [Chao, Han-Chieh] Natl Dong Hwa Univ, Dept Elect Engn, Hualien 974, Taiwan.
C3 National Cheng Kung University; National Ilan University; National Ilan
   University; National Dong Hwa University
RP Chang, JH (corresponding author), Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
EM changrh@mail.ncku.edu.tw; cinfon@www.mmn.es.ncku.edu.tw;
   huang@mail.ncku.edu.tw; hcc@mail.niu.edu.tw
RI Huang, Yueh-Min/B-4563-2009; Lai, Chin-Feng/IAP-5353-2023
OI Lai, Chin-Feng/0000-0001-7138-0272
CR Alpaydin E, 2004, INTRO MACHINE LEARNI
   Baoli L., 2004, ACM Trans. Asian Lang. Inf. Process., V3, P215, DOI DOI 10.1145/1039621.1039623
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Ehrmantraut M., 1996, Proceedings of the 1996 ACM CIKM. International Conference on Information and Knowledge Management, P243, DOI 10.1145/238355.238505
   *ETSI EN, 2005, 300468 ETSI EN
   Han E. H., 2001, P 5 PAC AS C KNOWL D, P53
   Jacques Ferber., 1999, MULTIAGENT SYSTEMS I
   Jagannathan G., 2005, ACM KDD C, P593, DOI DOI 10.1145/1081870.1081942
   JOHAN P, 2005, P PERS 2005 SAN DIEG, P66
   KHARSIKAR S, 2007, P 2 INT MULT COMP CO, P25
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   KO M, 1996, OVERVIEW INTERACTIVE
   Kuo RJ, 2002, COMPUT OPER RES, V29, P1475, DOI 10.1016/S0305-0548(01)00043-0
   Kwon O.-W., 2000, Proceedings of the 5th International Workshop on Information Retrieval with Asian Languages, P9
   Kwon OW, 2003, INFORM PROCESS MANAG, V39, P25, DOI 10.1016/S0306-4573(02)00022-5
   MARROQUIN JL, 1993, AIM1390
   MICHAEL E, 1996, P 5 INT C INF KNOWL, P243
   Nhat VDM, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1187
   PATRICK B, 2005, LECT NOTES COMPUTER, P299
   PAUL C, 2000, P 17 NAT C ART INT 1, P957
   Qi YN, 2008, INT CON DISTR COMP S, P311, DOI 10.1109/ICDCS.2008.79
   TADASHI I, 2005, IEEE T CONSUM ELECTR, V51, P665
   van Ginneken B, 2006, INT C PATT RECOG, P603
   XU JA, 2005, PERSONALIZED RECOMME, P1146
   Xu JS, 2002, FOURTH INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P82, DOI 10.1109/MMSE.2002.1181599
   Yu ZW, 2004, IEEE T CONSUM ELECTR, V50, P393, DOI 10.1109/TCE.2004.1277889
NR 27
TC 17
Z9 22
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 31
EP 48
DI 10.1007/s11042-009-0405-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400003
DA 2024-07-18
ER

PT J
AU Kim, SK
   An, SO
   Hong, M
   Park, DS
   Kang, SJ
AF Kim, Soo-Kyun
   An, Syung-Og
   Hong, Min
   Park, Doo-Soon
   Kang, Shin-Jin
TI Decimation of human face model for real-time animation in intelligent
   multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial animation; Feature preserving simplification; Intelligent
   multimedia system
ID HEAD MOTION
AB Animating a complex human face model in real-time is not a trivial task in intelligent multimedia systems for next generation environments. This paper proposes a generation scheme of a simplified model for real-time human face animation in intelligent multimedia systems. Previous work mainly focused on the geometric features when generating a simplified human face model. Such methods may lose the critical feature points for animating human faces. The proposed method can find those important feature points and can generate the feature-preserved low-level models busing our new quadrics. The new quadrics consist of basic error metrics and feature edge quadrics. The quality of facial animation with a lower-level model is as good as that of a computationally expansive original model. In this paper, we prove that our decimated facial model is effective in facial animation using a well-known expression-retargeting technique.
C1 [Hong, Min; Park, Doo-Soon] Soonchunhyang Univ, Div Comp Sci & Engn, Asan, South Korea.
   [Park, Doo-Soon] Soonchunhyang Univ, KIPS, Asan, South Korea.
   [Park, Doo-Soon] Soonchunhyang Univ, Coll Engn, Asan, South Korea.
   [Park, Doo-Soon] Soonchunhyang Univ, Healthcare Res Ctr, Asan, South Korea.
   [Kim, Soo-Kyun; An, Syung-Og] Paichai Univ, Dept Game Engn, Taejon, South Korea.
   [Kang, Shin-Jin] Hongik Univ, Sch Games, Seoul, South Korea.
C3 Soonchunhyang University; Soonchunhyang University; Soonchunhyang
   University; Soonchunhyang University; Pai Chai University; Hongik
   University
RP Hong, M (corresponding author), Soonchunhyang Univ, Div Comp Sci & Engn, Asan, South Korea.
EM kimsk@pcu.ac.kr; sungohk@pcu.ac.kr; mhong@sch.ac.kr; parkds@sch.ac.kr;
   kacias@daum.net
RI park, doo-soon/AAM-7730-2020
OI park, doo-soon/0000-0002-2776-8832; Kim, Soo Kyun/0000-0001-6071-8231
CR [Anonymous], 2003, LEVEL DETAIL 3D GRAP
   [Anonymous], P 2004 ACM SIGMM WOR
   Busso C, 2005, COMPUT ANIMAT VIRT W, V16, P283, DOI 10.1002/cav.80
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Deng Z., 2007, COMPUTER FACIAL ANIM
   Garland M, 1998, VISUALIZATION '98, PROCEEDINGS, P263, DOI 10.1109/VISUAL.1998.745312
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   Ho T.-C., 2006, VRCIA, P59
   Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869
   Hubeli A, 2001, IEEE VISUAL, P287, DOI 10.1109/VISUAL.2001.964523
   Kho Y., 2003, P S INTERACTIVE 3D G, P123
   Kim SJ, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P276, DOI 10.1109/PCCGA.2002.1167871
   Lee Y., 1995, SIGGRAPH, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]
   Li WD, 2007, COMPUT IND, V58, P211, DOI 10.1016/j.compind.2006.05.003
   Lindstrom P, 2001, IEEE VISUAL, P121, DOI 10.1109/VISUAL.2001.964502
   Lindstrom P, 1998, VISUALIZATION '98, PROCEEDINGS, P279, DOI 10.1109/VISUAL.1998.745314
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   PARKE FI, 1982, IEEE COMPUT GRAPH, V2, P61
   Pojar Erik., 2003, Proceedings of the 2003 symposium on Interactive 3D graphics, P127
   Ronfard R., 1996, Computer Graphics Forum, V15, pC67, DOI 10.1111/1467-8659.1530067
   ROSSIGNAC J, 1993, P GEOM MOD COMP GRAP, P455
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Ulgen F, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P358, DOI 10.1109/ROMAN.1997.647012
   Watanabe K, 2001, COMPUT GRAPH FORUM, V20, pC385, DOI 10.1111/1467-8659.00531
   WATERS K, 1995, GRAPH INTER, P163
NR 26
TC 4
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 147
EP 162
DI 10.1007/s11042-009-0411-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400009
DA 2024-07-18
ER

PT J
AU Bezerra, CEB
   Geyer, CFR
AF Benevides Bezerra, Carlos Eduardo
   Resin Geyer, Claudio Fernando
TI A load balancing scheme for massively multiplayer online games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMOGs; Load balancing; Distributed server; Graph partitioning
AB In a distributed MMOG (massively multiplayer online game) server architecture, the server nodes may become easily overloaded by the high demand from the players for state updates. Many works propose algorithms to distribute the load on the server nodes, but this load is usually defined as the number of players on each server, what is not an ideal measure. Also, the possible heterogeneity of the system is frequently overlooked. We propose a balancing scheme with two main goals: allocate load on server nodes proportionally to each one's power and reduce the inter-server communication overhead, considering the load as the occupied bandwidth of each server. Four algorithms were proposed, from which ProGReGA is the best for overhead reduction and ProGReGA-KF is the most suited for reducing player migrations between servers. We also make a review of related works and some comparisons were made, where our approach performed better.
C1 [Benevides Bezerra, Carlos Eduardo; Resin Geyer, Claudio Fernando] Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Bezerra, CEB (corresponding author), Univ Fed Rio Grande do Sul, Av Bento Goncalves 9500, Porto Alegre, RS, Brazil.
EM carlos.bezerra@inf.ufrgs.br; geyer@inf.ufrgs.br
FU National Research Council (CNPq); Coordination of Improvement of Higher
   Education (CAPES)
FX This work was supported by the National Research Council (CNPq) and by
   the Coordination of Improvement of Higher Education (CAPES), both
   Brazilian research funding agencies.
CR AHMED D, 2008, P IEEE C VIRT ENV HU, P86
   [Anonymous], P ACM S VIRT REAL SO
   [Anonymous], 1982, DES AUT C P, DOI DOI 10.1109/DAC.1982.1585498
   Bettstetter C., 2002, Proceedings of the 5th ACM International Workshop on Modeling Analysis and Simulation of Wireless and Mobile Systems, P7, DOI 10.1145/570758.570761
   Bezerra CEB, 2008, IEEE ACM DIS SIM, P35, DOI 10.1109/DS-RT.2008.11
   Chen Jin., 2005, PPOPP 05, P289
   Chen KT, 2006, COMPUT NETW, V50, P3002, DOI 10.1016/j.comnet.2005.11.005
   DEVLEESCHAUWER B, 2005, P ACM SIGCOMM WORKSH, V4, P1
   Duong TNB, 2003, ICON 2003: 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, P131
   FEDER T, 1999, P ACM S THEOR COMP S, V31, P464
   FENG W, 2007, COMMUNICATION    NOV
   HENDRICKSON B, 1995, SIAM J SCI COMPUT, V16, P452, DOI 10.1137/0916028
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kernighan B. W., 1970, The Bell System Technical Journal, V49, P291, DOI [10.1002/j.1538-7305.1970.tb01770.x, DOI 10.1002/J.1538-7305.1970.TB01770.X]
   Lu F., 2006, P 5 ACM SIGCOMM WORK
   Microsoft, 1997, AG EMP
NR 16
TC 15
Z9 21
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 263
EP 289
DI 10.1007/s11042-009-0302-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900012
DA 2024-07-18
ER

PT J
AU Agius, H
   Angelides, MC
AF Agius, Harry
   Angelides, Marios C.
TI From MPEG-7 user interaction tools to hanging basket models: bridging
   the gap
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-7; Personalization; Metadata; Content model; User model;
   Multimedia; Video
AB The content-user gap is the difference between the limited range of content-relevant preferences that may be expressed using the MPEG-7 user interaction tools and the much wider range of metadata that may be represented using the MPEG-7 content tools. One approach for closing this gap is to make the user and content metadata isomorphic by using the existing MPEG-7 content tools to represent user (as well as content) metadata (Agius and Angelides 2006, 2007). Subsequently, user preferences may be specified for all content, without omission. Since there is a wealth of user preference and history metadata within the MPEG-7 user interaction tools that can usefully complement these specific content preferences, in this paper we develop a method by which all user and content metadata may be bridged.
C1 [Agius, Harry; Angelides, Marios C.] Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Agius, H (corresponding author), Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
EM harryagius@acm.org; marios.angelides@bcs.org
FU UK Engineering and Physical Sciences Research Council [EP/E034578/1];
   EPSRC [EP/E034578/1] Funding Source: UKRI
FX This research is supported by the UK Engineering and Physical Sciences
   Research Council, grant no. EP/E034578/1.
CR Agius H, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P147, DOI 10.1109/SMAP.2007.33
   Agius H, 2006, FIRST INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P151
   Agius H, 2007, MULTIMEDIA SYST, V13, P155, DOI 10.1007/s00530-007-0088-7
   Agius HW, 2001, MULTIMED TOOLS APPL, V15, P5, DOI 10.1023/A:1011386102507
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Andric A, 2006, MULTIMED TOOLS APPL, V29, P127, DOI 10.1007/s11042-006-0003-9
   Annesley J, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P482, DOI 10.1109/AVSS.2007.4425358
   Aroyo L, 2008, MULTIMED TOOLS APPL, V36, P71, DOI 10.1007/s11042-006-0078-3
   Bailly D, 2008, EXPERT OPIN DRUG SAF, V7, P9, DOI [10.1517/14740338.7.1.9, 10.1517/14740338.7.1.9 ]
   BRACHMAN RJ, 1983, COMPUTER, V16, P30, DOI 10.1109/MC.1983.1654194
   *CONT ID FOR, 2007, CIDF SPEC 2 0 REV 1
   Rego ASD, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1074, DOI 10.1145/1244002.1244236
   Falchi F, 2008, IEEE MULTIMEDIA, V15, P52, DOI 10.1109/MMUL.2008.6
   GENCPINAR E, 2007, P 3 INT C MOB MULT C
   Goren-Bar D, 2004, COMPUT GRAPH-UK, V28, P149, DOI 10.1016/j.cag.2003.12.003
   HAJDU A, 2007, P 2007 INT S SIGN CI, V2, P1
   Hammiche S, 2005, IEEE INT SYM MULTIM, P241
   *ISO IEC, 2003, 159385 ISOIEC 5
   *ISO IEC, 2005, 159385AMD2 ISOIEC 5
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jin SH, 2006, EXPERT SYST APPL, V31, P164, DOI 10.1016/j.eswa.2005.09.021
   Lyu J, 2007, INT C ADV COMMUNICAT, V1, P305
   MULTIMEDIA, 2005, MULTIMEDIA, P856
   POGACNIK M, 2003, COMPUTER, V2003, P30
   RAHMAN MA, 2006, ENGINEERING, V2006, P291
   SCHUBERT LK, 1983, COMPUTER, V16, P53, DOI 10.1109/MC.1983.1654198
   Smyth B, 2000, COMMUN ACM, V43, P107, DOI 10.1145/345124.345161
   TJONDRONEGORO D, 2008, COMPUTING, V40, P11
   TSEKERIDOU S, 2005, P IEEE INT C IM PROC, V3, P1236
   TSEKERIDOU S, 2005, P IEEE INT C, P7
   TSINARAKI C, 2005, DATA MANAGE, V4, P7
   TSINARAKI C, 2006, INT WORKSHOP SEMANTI, V6, P121
   TSINARAKI C, 2006, INT MULTIMEDIA MODEL, V12, P7
   Vallet D, 2007, IEEE T CIRC SYST VID, V17, P336, DOI 10.1109/TCSVT.2007.890633
   XU MLIJ, 2006, ACM MULTIMEDIA, V6, P921
   YOON J, 2006, INT S CONSUMER ELECT, V2006, P1
   ZUO Q, 2008, INT C MULTIMEDIA UBI, V2008, P155
NR 38
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2009
VL 41
IS 3
SI SI
BP 375
EP 406
DI 10.1007/s11042-008-0238-8
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 395EL
UT WOS:000262506300003
DA 2024-07-18
ER

PT J
AU Yaslan, Y
   Gunsel, B
AF Yaslan, Yusuf
   Gunsel, Bilge
TI An integrated on-line audio watermark decoding scheme for broadcast
   monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE broadcast monitoring; on-line audio watermark decoding
ID SPREAD-SPECTRUM
AB This paper proposes an on-line audio watermarking system for broadcast monitoring. The designed watermark (WM) encoder is a nonlinear data adaptive system that performs perceptual embedding. It allows working at very low watermark-to-signal ratio (WSR) levels thus preserves the inaudibility. The developed decoder adopts wavelet de-noising for blind watermark extraction and it is capable of watermark decoding while establishing the synchronization between the transmitter and the receiver. Unlike the published watermarking schemes, it is shown that the introduced WM embedding scheme minimizes false alarm ratio by adaptively controlling the WSR. Furthermore it integrates synchronization and WM extraction into one processing step resulting in an on-line decoding scheme suitable to audio broadcast monitoring. The proposed system is robust to Digital-to-Analog (D/A), Analog-to-Digital (A/D) conversions, compression and noise as well as the attenuations that arise from FM broadcasting and acoustic transmission. Performance under Stirmak attacks is also reported. It is shown that error free transmission of 24 bps is achieved at around WSR=-32 dB when the PSNR is around 50 dB. Granularity of the system is 0.6 s thus it is capable of tracking short audio clips i.e. commercials.
C1 [Yaslan, Yusuf; Gunsel, Bilge] Istanbul Tech Univ, Multimedia Signal Proc & Pattern Recognit Lab, Elect Elect Engn Fac, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University
RP Yaslan, Y (corresponding author), Istanbul Tech Univ, Dept Comp Engn, TR-34469 Istanbul, Turkey.
EM yyaslan@itu.edu.tr; gunselb@itu.edu.tr
RI Yaslan, Yusuf/ABA-8190-2020; Günsel, Bilge/ABA-7531-2020
OI Yaslan, Yusuf/0000-0001-8038-948X; Günsel, Bilge/0000-0003-3628-3316
CR Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Depovere G., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P202, DOI 10.1109/ICIP.1999.822884
   DONOHO DL, 1994, P 16 ANN INT C IEEE, V1, pA24
   Furht B., 2005, MULTIMEDIA SECURITY
   Gomes LDT, 2003, J NEW MUSIC RES, V32, P65, DOI 10.1076/jnmr.32.1.65.16803
   GUNSEL B, 2006, P INT C PATT REC ICP
   GUNSEL B, 2006, P MULT CONT REPR CLA
   HAITSMA J, 2002, P 3 INT S MUS INF RE, P144
   HERNANDEZ JJG, 2006, P 8 IEEE INT S MULT
   KIRBIZ S, 2005, P 13 EUSIPCO TURK 4
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   LIU J, 2005, P 1 INT C INF COMM T
   LOYTYNOJA M, 2006, P IEEE INT C CONS EL
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   NAKAMURA T, 2002, SPIE, V4675, P170
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   Steinebach M, 2002, P SOC PHOTO-OPT INS, V4675, P79, DOI 10.1117/12.465333
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Tachibana R, 2003, PROC SPIE, V5020, P32, DOI 10.1117/12.476832
   Yaslan Y, 2004, INT C PATT RECOG, P879, DOI 10.1109/ICPR.2004.1334399
NR 21
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 1
EP 21
DI 10.1007/s11042-007-0182-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700001
DA 2024-07-18
ER

PT J
AU El Saddik, A
   Rahman, A
   Abdala, S
   Solomon, B
AF El Saddik, Abdulmotaleb
   Rahman, Abdur
   Abdala, Souhail
   Solomon, Bogdan
TI PECOLE: P2P multimedia collaborative environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE collaborative multimedia; java media framework; JXTA socket;
   peer-to-peer; SWT
AB PECOLE (Peer-to-pEer COLlaborative Environment) is a fully decentralized multimedia collaborative environment that supports a wide range of collaborative multimedia applications, including chat, shared browsing, shared telepointer, multipoint-to-multipoint audio/video conferencing and multilingual collaboration. PECOLE can intelligently run on very constrained resources, is highly resilient, scalable and does not rely on dedicated servers. Instead, PECOLE is built upon a Peer-to-Peer (P2P) overlay network, using SUN's JXTA framework and SWT technology. In this paper, we present the architecture and implementation of PECOLE with the performance results of the tests we conducted.
C1 [El Saddik, Abdulmotaleb; Rahman, Abdur; Abdala, Souhail; Solomon, Bogdan] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
C3 University of Ottawa
RP El Saddik, A (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
EM abed@mcrlab.uottawa.ca; rahman@mcrlab.uottawa.ca;
   sabdala@mcrlab.uottawa.ca; bsolomon@mcrlab.uottawa.ca
RI Rahman, Abdur/AAG-9302-2019; /D-4159-2009
OI Rahman, Abdur/0000-0002-4105-0368; /0000-0002-7690-8547
CR AGUDELO A, 2004, P 7 IASTED INT C COM, P438
   Baldi M, 2000, IEEE ACM T NETWORK, V8, P479, DOI 10.1109/90.865076
   BAROLLI L, 2006, P 4 INT S PRINC PRAC, P224
   de Oliveira JC, 2003, IEEE MULTIMEDIA, V10, P18, DOI 10.1109/MMUL.2003.1218253
   Dyck J., 2004, P 2004 ACM C COMPUTE, DOI [10.1145/1031607.1031636, DOI 10.1145/1031607.1031636]
   El Saddik A, 2007, MULTIMED TOOLS APPL, V33, P217, DOI 10.1007/s11042-006-0057-8
   GONG F, 1994, P ACM MULT C, P425
   Gutwin Carl., 2003, Proceedings of the 2003 International ACM SIGGROUP Conference on Supporting Group Work, P294
   Halepovic E, 2005, FUTURE GENER COMP SY, V21, P377, DOI 10.1016/j.future.2004.04.016
   Hayne S., 1993, Journal of Management Information Systems, V10, P43
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Kawashima T, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P85, DOI 10.1109/ICDCSW.2004.1284013
   Kim O, 1997, HIGH PERFORMANCE NETWORKING VII, P115
   Kuhmunch C., 1998, P ED MED ED TEL 98 A, P70
   Ma JH, 2003, 2003 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P54, DOI 10.1109/CYBER.2003.1253435
   Margaritis M., 2003, P PANHELLENIC C INFO, P231
   Seigneur J.-M., 2003, P 2 INT C PRINC PRAC, P207
   Shirane M, 2003, NAT CELL BIOL, V5, P28, DOI 10.1038/ncb894
   STEINMETZ R, 2004, MULTIMEDIA SYSTEMS
   TSUCHIYA T, 2004, P ACM WORKSH NEXT GE, P57
   WAHAB HMA, 1999, J NETW INF SYST, V2, P63
   Wilcox J.R., 2000, VIDEOCONFERENCING WH, V3rd ed.
   [No title captured]
NR 23
TC 7
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 3
BP 353
EP 377
DI 10.1007/s11042-007-0165-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 328BF
UT WOS:000257771600003
DA 2024-07-18
ER

PT J
AU Naturel, X
   Gros, P
AF Naturel, Xavier
   Gros, Patrick
TI Detecting repeats for video structuring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Computer Vision Meets Databases
CY JUN   17, 2005
CL Baltimore, MD
DE video structuring; commercial; television; repetitions
ID HISTOGRAM; DISTANCE
AB Television daily produces massive amounts of videos. Digital video is unfortunately an unstructured document in which it is very difficult to find any information. Television streams have however a strong and stable but hidden structure that we want to discover by detecting repeating objects in the video stream. This paper shows that television streams are actually highly redundant and that detecting repeats can be an effective way to detect the underlying structure of the video. A method for detecting these repetitions is presented here with an emphasis on the efficiency of the search in a large video corpus. Very good results are obtained both in terms of effectiveness (98% in recall and precision) as well as efficiency since one day of video is queried against a 3 weeks dataset in only 1 s.
C1 [Naturel, Xavier; Gros, Patrick] IRISA INRIA Rennes, F-35042 Rennes, France.
C3 Universite de Rennes
RP Naturel, X (corresponding author), IRISA INRIA Rennes, Campus Beaulieu, F-35042 Rennes, France.
EM xnaturel@yahoo.fr; patrick.gros@irisa.fr
CR Adjeroh DA, 1999, COMPUT VIS IMAGE UND, V75, P25, DOI 10.1006/cviu.1999.0764
   BARR J, 2003, ICASSP IEEE PISC
   *CONS SUP AUD, 2002, PUBL PARR TEL TEL RA
   COSKUN B, 2004, EUSIPCO EUR C SIGN P
   DUYGULU P, 2004, ICME ACM NEW YORK
   FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868
   Harman D., 1992, DATA STRUCTURES ALGO
   Jain A. K., 1989, PRENTICE HALL INFORM
   JOLY A, 2005, THESIS U ROCHELLE
   JOLY A, 2003, LECT NOTES COMPUTER, V2728, P398
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   KIM YT, 2005, INT MULT MOD C
   LEE A, 2007, VIRTUALDUB ORG
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078
   NATUREL X, 2006, 4 INT WORKSH AD MULT
   OOSTVEEN J, 2002, VISUAL, P117
   Pua KM, 2004, COMPUT VIS IMAGE UND, V93, P310, DOI 10.1016/j.cviu.2003.10.005
   Sánchez JM, 2002, MULTIMED TOOLS APPL, V18, P233, DOI 10.1023/A:1019996817159
   TRUONG BT, 2000, MULTIMEDIA 00, P219
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YUAN J, 2004, MIR 04, P61
NR 22
TC 19
Z9 22
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2008
VL 38
IS 2
BP 233
EP 252
DI 10.1007/s11042-007-0180-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 301NV
UT WOS:000255903800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, YF
   Huang, CY
AF Huang, Yin-Fu
   Huang, Chui-Yi
TI Dynamically adjusting MPEG4 video streams based on network bandwidth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-4 standard; streaming; video on demand; dynamically adjusting
   algorithm
AB In the paper, we try to find a method that can service more users in a video-on-demand (VoD) system, based on MPEG-4 object streams. The characteristics of object segmentation made on MPEG-4 videos can be utilized to reduce re-transmission of the same objects, and then the saved bandwidth can be used to service more users. However, some thresholds must be analyzed first to maintain the acceptable quality of services (QoS) requested by users, when reducing unnecessary object transmission on one side. Thus, according to the defined thresholds, we propose a dynamically adjusting algorithm to coordinate the object streams between the server and clients. The server not only allocates network bandwidth, but also adjusts ever-allocated QoS appropriately using a degrading and upgrading strategy, based on the current network status. Lastly, through the simulation, we found that our method has better performance than the other three methods owing to its flexibility to the network status.
C1 [Huang, Yin-Fu; Huang, Chui-Yi] Natl Yunlin Univ Sci & Technol, Inst Elect & Informat Engn, Touliu 640, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Huang, YF (corresponding author), Natl Yunlin Univ Sci & Technol, Inst Elect & Informat Engn, 123 Univ Rd,Sect 3, Touliu 640, Yunlin, Taiwan.
EM huangyf@el.yuntech.edu.tw
CR Abbasi S, 2001, IEEE T IMAGE PROCESS, V10, P131, DOI 10.1109/83.892449
   Ahmed T, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P317
   Brady N, 1999, IEEE T CIRC SYST VID, V9, P1170, DOI 10.1109/76.809154
   Chen M, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1723
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Furini M, 2001, IEEE T MULTIMEDIA, V3, P33, DOI 10.1109/6046.909592
   Goto H, 2000, INT C PATT RECOG, P430, DOI 10.1109/ICPR.2000.902950
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kung HY, 2005, IEEE ICCE, P373, DOI 10.1109/ICCE.2005.1429873
   Kwon JB, 2002, IEEE T CONSUM ELECTR, V48, P41, DOI 10.1109/TCE.2002.1010090
   Lin CW, 2001, IEEE T CIRC SYST VID, V11, P415, DOI 10.1109/76.911165
   Liu S, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P225
   Lotfallah OA, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P872
   LU MT, 2005, P IEEE INT C IM PROC, P193
   Merz M, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P283, DOI 10.1145/266180.266379
   *MPEG VID GROUP, 1996, JTCISC29WH11 ISOIEC
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Su GM, 2005, IEEE T CIRC SYST VID, V15, P1124, DOI 10.1109/TCSVT.2005.852626
   Sung WR, 1999, IEEE T CONSUM ELECTR, V45, P753, DOI 10.1109/30.793590
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
NR 20
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 267
EP 284
DI 10.1007/s11042-007-0146-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600005
DA 2024-07-18
ER

PT J
AU Aroyo, L
   Bellekens, P
   Björkman, M
   Houben, GJ
AF Aroyo, Lora
   Bellekens, Pieter
   Bjorkman, Martin
   Houben, Geert-jan
TI Semantic-based framework for personalised ambient media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital broadcast; Blu-ray disc; semantic-based metadata framework
AB The paper proposes a semantic-based metadata framework for personalised interaction with TV media in a connected home context. Our approach allows the current home media centres to go beyond the simple concept of electronic programme guides and to offer the users a personalised media experience in an ambient home environment. The user's characteristics, preferences and context are used to personalise the user's experience of viewing and interacting with multimedia content on different heterogeneous devices. The TV-Anytime specification provides the basis for the metadata framework for handling content from IP, digital broadcast, and Blu-ray disc sources.
C1 [Aroyo, Lora; Bellekens, Pieter; Bjorkman, Martin; Houben, Geert-jan] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 MB Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Aroyo, L (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM l.m.aroyo@tue.nl; p.a.e.bellekens@tue.nl; m.bjorkman@tue.nl;
   g.j.houben@tue.nl
RI Houben, Geert-Jan/C-3934-2008
OI Houben, Geert-Jan/0000-0001-6827-9739; Aroyo, Lora/0000-0001-9402-1133
CR Ardissono L, 2004, HUM-COMPUT INT-SPRIN, P3
   Ben Necib C, 2005, LECT NOTES COMPUT SC, V3520, P167
   BERMAN SJ, 2005, MEDIA ENTERTAINMENT
   Berners-Lee T., 2001, The Semantic Web
   BORMANS J, 2005, MPEG21 OVERVIEW V 5
   CHORIANOPOULOS K, 2004, WHAT WRONG ELECT PRO
   EAMSHAW N, 2005, TV ANYTIME CONTENT R
   Goren-Bar D, 2004, COMPUT GRAPH-UK, V28, P149, DOI 10.1016/j.cag.2003.12.003
   HOBBS J, 2004, ACM T ASIAN LANGUAGE, V1
   Hong C, 2005, LECT NOTES COMPUT SC, V3483, P138
   Kobsa A., 1990, AI & Society, V4, P214, DOI 10.1007/BF01889941
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   McGuinnes DL, 2004, OWL WEB ONTOLOGY LAN
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MURUGESAN S, 2001, WEB ENG, V2016
   O'Sullivan D, 2004, USER MODEL USER-ADAP, V14, P5, DOI 10.1023/B:USER.0000010131.72217.12
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Ruyter B.D., 2004, P WORKING C ADV VISU, P203, DOI DOI 10.1145/989863.989897
   Setten M. van, 2005, TELEMATICA I FUNDAME
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Stamou G, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.15
   Yu ZW, 2004, IEEE T CONSUM ELECTR, V50, P393, DOI 10.1109/TCE.2004.1277889
NR 22
TC 7
Z9 8
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 71
EP 87
DI 10.1007/s11042-006-0078-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lim, J
   Kim, M
   Lee, B
   Kim, M
   Lee, H
   Lee, HK
AF Lim, Jeongyeon
   Kim, Munjo
   Lee, Bumshik
   Kim, Munchurl
   Lee, Heekyung
   Lee, Han-Kyu
TI A target advertisement system based on TV viewer's profile reasoning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE target advertisement; personalcasting; user profile reasoning
AB The traditional broadcasting services such as terrestrial, satellite and cable broadcasting have been unidirectional mass media regardless of TV viewer's preferences. Recently rich media streaming has become possible via the broadband networks. Furthermore, since bidirectional communication is possible, personalcasting such as personalized streaming service has been emerging by taking into account the user's preference on content genres, viewing times and actors/actresses etc. Accordingly personal media becomes an important means for content provision service in addition to the traditional broadcasting service as mass media. In this paper, we introduce a user profile reasoning method for TV viewers. The user profile reasoning is made in terms of genre preference and TV viewing times for TV viewer's groups in different genders and ages. For user profiling reasoning, the TV viewing history data is used to train the proposed user profiling reasoning algorithm which allows for target advertisement for different age/gender groups. To show the effectiveness of our proposed user profile reasoning method, we present plenty of the experimental results by using real TV usage history.
C1 [Lim, Jeongyeon; Kim, Munjo; Lee, Bumshik; Kim, Munchurl] Informat & Commun Univ, Taejon 305732, South Korea.
   [Lee, Heekyung; Lee, Han-Kyu] Elect & Telecommun Res Inst, Taejon 305606, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Lim, J (corresponding author), Informat & Commun Univ, 119 Munji St, Taejon 305732, South Korea.
EM jylim@icu.ac.kr; kimmj@icu.ac.kr; bslee@icu.ac.kr; mkim@icu.ac.kr;
   lhk95@etri.re.kr; hkl@etri.re.kr
RI Kim, Munchurl/AAQ-9591-2020; Kim, Munchurl/C-1759-2011
CR Bozios Theodoros., 2001, Proceedings of the eBusiness and eWork Conference, P1025
   Katsaros D, 2004, DATA KNOWL ENG, V49, P1, DOI 10.1016/j.datak.2003.07.001
   *KOR BROADC ADV CO, 2005, MED CONS RES 2004 SU
   MIYAHARA K, 2004, P 6 PAC RIM INT C AR, P679
   SHAHABI C, 2000, P 26 INT C VER LARG, P635
   Yu ZW, 2004, IEEE T CONSUM ELECTR, V50, P393, DOI 10.1109/TCE.2004.1277889
   Yuan W, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2836, DOI 10.1109/ICMLC.2004.1378515
NR 7
TC 8
Z9 10
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 11
EP 35
DI 10.1007/s11042-006-0079-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600002
DA 2024-07-18
ER

PT J
AU Yang, J
   Li, Q
   Liu, WY
   Zhuang, YT
AF Yang, Jun
   Li, Qing
   Liu, Wenyin
   Zhuang, Yueting
TI Content-based retrieval of Flash™ movies:: research issues, generic
   framework, and future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flash animation; content-based retrieval; multimedia information
   retrieval
ID IMAGE RETRIEVAL
AB As a prevailing web media format, nowadays Flash(TM) movies are created, delivered, and viewed by over millions of users in their daily experiences with the Internet. However, issues regarding the indexing and retrieval of Flash movies are unfortunately overlooked by the research community, which severely restrict the utilization of the extremely valuable Flash resource. A close examination reveals that the intrinsic complexity of a Flash movie, including its heterogeneous media components, its dynamic nature, and user interactivity, makes content-based Flash retrieval a host of research issues not thoroughly addressed by the existing techniques. As the first endeavor in this area, we propose a generic framework termed as FLAME (FLash Access and Management Environment) embodying a 3-layer structure that addresses the representation, indexing, and retrieval of Flash movies by mining and understanding of the movie content. An experimental prototype for Flash retrieval is implemented to verify the feasibility and effectiveness of FLAME, and future research directions on Flash management and retrieval are discussed in details.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
   Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Peoples R China.
C3 City University of Hong Kong; Carnegie Mellon University; City
   University of Hong Kong; Zhejiang University
RP Li, Q (corresponding author), City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
EM juny@cs.cmu.edu; itqli@cityu.edu.hk
RI Li, Qing/JMH-1365-2023; LIU, Wenyin/C-1345-2012
OI Li, Qing/0000-0003-3370-471X; 
CR Adali S, 2000, MULTIMEDIA SYST, V8, P212, DOI 10.1007/s005300000046
   Al-Khatib W, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P215, DOI 10.1145/319463.319609
   [Anonymous], IEEE COMPUT
   Chan SSM, 1999, LECT NOTES COMPUT SC, V1728, P47
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   ELMASRI R, 1994, FUNDAMENTALS DATABAS
   Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106
   FURHT B, 1998, CRC              SEP
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   HAUPTMANN A, 2002, TEXT RETR C GAITH MA
   Hjelsvold Rune., 1994, VLDB 94 P 20 INT C V, P686
   Lee TY, 1999, IEEE T KNOWL DATA EN, V11, P361, DOI 10.1109/69.774099
   LIU WY, 2001, P 9 ACM INT C MULT S, P519
   NIBLACK W, 1999, IEEE WORKSH CONT BAS
   OZSOYOGLU G, 1995, IEEE T KNOWL DATA EN, V7, P4
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   SALTON G, 1983, INTRO MODERN INFORMA
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Woods S., 1995, Proceedings. Second Working Conference on Reverse Engineering (Cat. No.95TB8101), P314, DOI 10.1109/WCRE.1995.514719
NR 23
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2007
VL 34
IS 1
BP 1
EP 23
DI 10.1007/s11042-006-0058-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 169VE
UT WOS:000246619400001
DA 2024-07-18
ER

PT J
AU Akanksha
   Huang, ZY
   Prabhakaran, B
   Ruiz, CR
AF Akanksha
   Huang, Zhiyong
   Prabhakaran, B.
   Ruiz, Conrado R., Jr.
TI Animation toolkit based on a database approach for reusing motions and
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE animation; toolkit; database; metadata; multimedia presentations; reuse
AB As animations become more readily available, simultaneously the complexity of creating animations has also increased. In this paper, we address the issue by describing an animation toolkit based on a database approach for reusing geometric animation models and their motion sequences. The aim of our approach is to create a framework aimed for novice animators. Here, we use an alternative notion of a VRML scene graph to describe a geometric model, specifically intended for reuse. We represent this scene graph model as a relational database. A set of spatial, temporal, and motion operations are then used to manipulate the models and motions in an animation database. Spatial operations help in inserting/deleting geometric models in a new animation scene. Temporal and motion operations help in generating animation sequences in a variety of ways. For instance, motion information of one geometric model can be applied to another model or a motion sequence can be retargeted to meet additional constraints (e.g., wiping action on a table can be retargeted with constraints that reduce the size of the table). We present the design and implementation of this toolkit along with several interesting examples of animation sequences that can be generated using this toolkit.
C1 Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
   ASTAR Inst Infocomm Res I2R, Media Div, Singapore, Singapore.
   Univ Texas, Dept Comp Sci, Dallas, TX 75230 USA.
   De La Salle Univ, Coll Comp Studies, Manila, Philippines.
C3 National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R);
   University of Texas System; University of Texas Dallas; De La Salle
   University
RP Huang, ZY (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
EM akanksha@comp.nus.edu.sg; huangzy@comp.nus.edu; praba@utdallas.edu;
   ruizc@ccs.dlsu.edu.ph
OI Ruiz, Conrado Jr./0000-0002-0956-7201
CR AKIHIRO K, 1997, THESIS KYOTO U
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   AYADIN Y, 1997, P MULT MOD 97, P213
   BALLREICH C, 1997, NANCY 3D MODEL 3NAME
   BRAUN N, 1999, ASS ADV COMP ED WEBN
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   BRUTZMAN D, 2000, COMPOSING SCENE GRAP
   *DISCR AUT INC, 3D STUD MAX
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Grünvogel S, 2002, COMP ANIM CONF PROC, P98, DOI 10.1109/CA.2002.1017514
   HODGINS JK, 1997, P SIGGRAPH 97, P153
   Kakizaki K., 1998, Proceedings ACM Multimedia 98, P139, DOI 10.1145/290747.290765
   KAUFMAN D, 1999, COMMUNICATION
   LEE GCS, 1983, TUTORIAL ROBOTICS, P47
   LEE WM, 2000, IEEE COMPUT GRAPH, P11
   *MICR INC, PROD MICR SIMPL 3D P
   MONZANI JS, 2000, P EUR 2000
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   REITEMEYER A, BARMAID BOT
   ROHLF J, P ACM SIGGRAPH 95, P550
   SHATKIN E, 1999, SPOTLIGHT ASSET MANA
   THALMANN D, 1999, P INT S DAT APPL NON
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   *VCOM3D INC, 1998, SEAML SOL AND H AN W
   *VRML CONS INC, 1997, 147721 ISOIEC VRML C
   WALCZAK K, 1996, MULTIMEDIA DATABASE, P80
   WANG CS, 2003, P 17 INT C ADV INF N
NR 27
TC 1
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2007
VL 32
IS 3
BP 293
EP 327
DI 10.1007/s11042-006-0054-y
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137TK
UT WOS:000244314900004
DA 2024-07-18
ER

PT J
AU Veeravalli, B
   Chen, CY
   Prasanna, VK
AF Veeravalli, Bharadwaj
   Chen, Chaoyang
   Prasanna, Viktor K.
TI Fault-tolerant analysis for multiple servers movie retrieval strategy
   for distributed multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE bandwidth; MTTF; MTTR; retrieval schedule; access time; reliability;
   availability; failure rate; repair rate
ID VIDEO; ALLOCATION; DESIGN
AB In this paper, we address the problem of retrieving a movie from a set of multimedia(MM) servers by the clients on a network. We consider a strategy in which multiple MM servers are deployed by the service provider (SP) to retrieve a requested MM movie to the clients, for minimizing the access time (the waiting time of the client before initiating the playback) and maximizes the system reliability. We design a movie retrieval strategy that explicitly considers issues such as reliability and/or availability factors of the multimedia servers and the communication channels in the problem formulation. We develop a mathematical model for this retrieval strategy and derive an optimal size of each movie portion that is expected to be rendered by each server. We then derive a closed-form expression for the access time of the MM document and the system reliability which gives a trade-off relationship between access time and reliability (availability) of the service by our strategy. We extend our study to investigate on the effect of sequencing of the servers, the order in which movie portions are to be retrieved, to minimize the access time and to maximize the system reliability. With system reliability factors, we identify an optimal sequence, which maximizes system reliability out of all possible retrieval sequences. We then propose two methods to retrieve any missing movie portions upon a server failure during the retrieval process. In order to measure the quality of service provided by the service provider to its customers, we introduce a QoS parameter that can tune the playback rate to avoid any data underflow or overflow situations. Then, from probabilistic perspective, we obtain an estimate of the failure time of a single server and its resulting missing movie portion caused by this server failure. We conduct rigorous simulation experiments to testify all the theoretical findings reported. Illustrative examples are provided for the ease of understanding.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Open Source Software Lab, Singapore 117576, Singapore.
   Univ So Calif, Dept Elect Engn Syst, Los Angeles, CA 90089 USA.
C3 National University of Singapore; University of Southern California
RP Veeravalli, B (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Open Source Software Lab, 4 Engn Dr 3, Singapore 117576, Singapore.
EM engp0578@nus.edu.sg; elebv@nus.edu.sg; prasanna@ganges.usc.edu
CR Aggarwal CC, 1999, MULTIMEDIA SYST, V7, P439, DOI 10.1007/s005300050144
   Bai P, 2000, MULTIMEDIA SYST, V8, P146, DOI 10.1007/s005300050157
   Bisdikian CC, 1996, IEEE MULTIMEDIA, V3, P62, DOI 10.1109/93.556540
   Dan A, 1997, MULTIMED TOOLS APPL, V4, P279, DOI 10.1023/A:1009637022889
   Dong LG, 2003, MULTIMED TOOLS APPL, V20, P99, DOI 10.1023/A:1023654818590
   EBELING CE, 1997, INTRO RELIABILITY MA, P254
   Fahmi H, 1999, MULTIMED TOOLS APPL, V8, P91, DOI 10.1023/A:1009651431672
   Ghose D, 2000, MULTIMED TOOLS APPL, V11, P167, DOI 10.1023/A:1009681521536
   Gibson GA, 1996, ACM COMPUT SURV, V28, P779, DOI 10.1145/242223.242300
   HU A, 2001, P IEEE INFOCOM, V1, P508
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Jadav D, 1999, IEEE T KNOWL DATA EN, V11, P284, DOI 10.1109/69.761664
   Lau SW, 1997, MULTIMEDIA SYST, V5, P310, DOI 10.1007/s005300050063
   Lee BB, 2005, PHLEBOLOGY, V20, P28, DOI 10.1258/0268355053300875
   Lee JYB, 2000, IEEE T PARALL DISTR, V11, P1217, DOI 10.1109/71.895790
   Lee JYB, 1999, IEEE T CIRC SYST VID, V9, P467, DOI 10.1109/76.754776
   LINDEMANN C, 2000, EVALUATING HARDWARE
   OZDEN B, 1995, INFORM SYST, V20, P465, DOI 10.1016/0306-4379(95)00025-Y
   Pang HW, 1999, IEEE T KNOWL DATA EN, V11, P303, DOI 10.1109/69.761665
   PAPADIMITRIOU C, 1995, COMPUT COMMUN, V18, P204, DOI 10.1016/0140-3664(95)98543-E
   RANGAN PV, 1993, IEEE T KNOWL DATA EN, V5, P564, DOI 10.1109/69.234769
   Roberts AF, 2000, AFR ARTS, V33, P1, DOI 10.2307/3337744
   Shi WF, 2004, MULTIMED TOOLS APPL, V23, P131, DOI 10.1023/B:MTAP.0000026844.21853.03
   Srivastava A, 1997, MULTIMEDIA SYST, V5, P238, DOI 10.1007/s005300050058
   Veeravalli B, 2000, MULTIMED TOOLS APPL, V12, P235, DOI 10.1023/A:1009623825393
   VIN HM, 1995, COMPUT COMMUN, V18, P192, DOI 10.1016/0140-3664(95)98542-D
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Wang YW, 1997, MULTIMEDIA SYST, V5, P283, DOI 10.1007/s005300050061
   Won Y, 2000, MULTIMEDIA SYST, V8, P105, DOI 10.1007/s005300050154
   Won YJ, 1999, MULTIMED TOOLS APPL, V8, P249, DOI 10.1023/A:1009690002658
NR 31
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 1
EP 27
DI 10.1007/s11042-006-0052-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400001
DA 2024-07-18
ER

PT J
AU De Vrieze, P
   Van Bommel, P
   Van der Weide, T
   Klok, J
AF De Vrieze, P
   Van Bommel, P
   Van der Weide, T
   Klok, J
TI Adaptation in multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia adaptation; user modeling; adaptive systems; adaptation
   models; hybrid adaptation
AB Multimedia systems can profit a lot from personalization. Such a personalization is essential to give users the feeling that the system is easily accessible especially if it is done automatically. The way this adaptive personalization works is very dependent on the adaptation model that is chosen.
   We introduce a generic two-dimensional classification framework for user modeling systems. This enables us to clarify existing as well as new applications in the area of user modeling. In order to illustrate our framework we evaluate push and pull based user modeling in user modeling systems.
C1 Radboud Univ Nijmegen, Nijmegen Inst Comp & Informat Sci, NL-6500 GL Nijmegen, Netherlands.
C3 Radboud University Nijmegen
RP Radboud Univ Nijmegen, Nijmegen Inst Comp & Informat Sci, POB 9010, NL-6500 GL Nijmegen, Netherlands.
EM pauldv@cs.kun.nl; pvb@cs.kun.nl; tvdw@cs.kun.nl; klok@oce.nl
RI de Vrieze, Paul/N-8727-2019
OI de Vrieze, Paul/0000-0002-9612-8951
CR *ACM, 2003, COMMUN ACM, V46, P30
   Boll S, 2001, IEEE T KNOWL DATA EN, V13, P361, DOI 10.1109/69.929895
   BRUSILOVSKY P, 2002, P 7 INT C INT US INT, P23
   Bull S, 2002, INSTR SCI, V30, P497, DOI 10.1023/A:1020570928993
   DE BRA P., 2000, Procedings of the WebNet Conference, P117
   Fink J, 2002, ARTIF INTELL REV, V18, P33, DOI 10.1023/A:1016383418977
   Fleming M, 1999, CISM COUR L, P67
   Linton F, 1999, CISM COURSES LECT, P129
   MAGLIO PP, 1997, US MOD P 6 INT C UM9
   Montaner M, 2003, ARTIF INTELL REV, V19, P285, DOI 10.1023/A:1022850703159
   VANBOMMEL P, 1998, INT FOR MULT IM PROC
   VIRVOU M, ARTIFICIAL INTELLIGE, V14, P23
   Wu H., 2002, REFERENCE ARCHITECTU
NR 13
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 333
EP 343
DI 10.1007/s11042-005-6538-3
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400002
DA 2024-07-18
ER

PT J
AU Shi, WF
   Ghandeharizadeh, S
AF Shi, WF
   Ghandeharizadeh, S
TI Controlled buffer sharing in continuous media servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB Continuous media servers manage delay sensitive data such as audio and video clips. Once a server initiates the display of a clip on behalf of a client, it must deliver the data to the client in a manner that prevents data starvation. Otherwise, its display may suffer from disruptions and delays, termed hiccups. A hiccup-free display is important to a number of applications such as video-on-demand for entertainment, distance learning, news dissemination, etc. Buffer sharing enables a server to trade memory for disk bandwidth to service multiple clients by sharing data in memory, using a single disk stream. However, an uncontrolled buffer sharing scheme may reduce system performance.
   This paper presents Controlled Buffer Sharing (CBS) as a novel framework that facilitates sharing and supports both a hiccup-free display and VCR operations. It includes a configuration planner and a buffer pool management technique (applied at run time). CBS trades memory for disk bandwidth in order to meet the performance objectives of an application and minimize cost per stream. It uses bridging and merges two displays referencing the same clip when they are d(t) blocks apart. One insight of this framework is that dt is determined by market forces (cost of memory and disk bandwidth) and is independent of a clip's frequency of access. We use both analytical and simulation models to quantify the characteristics of CBS.
C1 Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Shi, WF (corresponding author), Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
EM wshi@cs.usc.edu; shahram@cs.usc.edu
CR ANDERSEN D, 1996, P 12 INT C DAT ENG F
   Chen M.-S., 1994, P ACM MULT OCT
   CHRISTODOULAKIS S, 1991, P IEEE DAT ENG SEPT
   DAN A, 1994, RC19588 IBM
   DAN A, 1995, P COMPCON
   DAN A, 1994, P 2 ACM INT C MULT O
   DAN A, 1996, Patent No. 5572645
   Dan Asit, 1994, P ACM MULT, P391
   DEYSIRCAR JK, 1994, P ACM MULT OCT
   GHANDEHARIZADEH S, 1997, P 7 ANN WORKSH INF T, P209
   GHANDEHARIZADEH S, 1995, 95610 U SO CAL
   GHANDEHARIZADEH S, 1997, KLUWER MULTIMEDI JUL, P79
   GHANDEHARIZADEH S, 1994, ACM MULTIMEDIA
   Ghandeharizadeh SA, 1998, PARALLEL COMPUT, V24, P91, DOI 10.1016/S0167-8191(97)00118-X
   Golubchik L., 1995, P ACM SIGMETRICS JOI, P25
   GRAY J, 2000, ICDE, P3
   KAMATH M, 1995, P 4 INT C DAT SYST A, P79
   KAMATH M, 1994, 9411 U MASS
   KAMATH M, 1995, P 4 INT C DAT SYST A
   KLEINROCK L, 1975, QUEUEING SYST, V1, P107
   LEE D, 1999, P ACM SIGMETRICS JUN
   MOSER F, 1995, P VLDB SEPT
   ONEIL EJ, 1993, P ACM SIGMOD INT C M, P297
   OZDEN B, 1996, IEEE INT C MULT COMP
   OZDEN B, 1995, IEEE INT C MULT COMP
   OZDEN B, 1994, P 20 INT C VER LARG
   REJAIE R, 1999, 4 INT WEB CACH WORKS
   ROTEM D, 1995, PROC INT CONF DATA, P439, DOI 10.1109/ICDE.1995.380353
   SEN S, 1999, P IEEE INF
   SHENOY PJ, 1995, P ACM MULT NOV
   SHI W, 1997, ACM SIGMETRICS PERFO, V25, P13
   SHI W, 1998, P 13 ACM S APPL COMP
   TOBAGI FA, 1993, 1 ACM C MULT AUG
   WOLF J, 1995, P ACM SIGMETRICS PER
   YU PS, 1993, MULTIMEDIA SYSTEMS, V1, P99
   ZHOAO W, 1999, P ACM SIGMETRICS JUN
   [No title captured]
NR 37
TC 3
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2004
VL 23
IS 2
BP 131
EP 159
DI 10.1023/B:MTAP.0000026844.21853.03
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 818LV
UT WOS:000221247500003
DA 2024-07-18
ER

PT J
AU Mittal, A
   Cheong, LF
AF Mittal, A
   Cheong, LF
TI Framework for synthesizing semantic-level indices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content based retrieval; syntactic features; Bayesian Network; semantic
   level indices; meaningful-feature selection
AB Extraction of the syntactic features is a well-defined problem thereby lending them to be exclusively employed in most of the content-based retrieval systems. However, semantic-level indices are more appealing to user as they are closer to the user's personal space. Most of the work done at semantic level is confined to a limited domain as the features developed and employed therein apply satisfactorily only to that particular domain. Scaling up such systems would inevitably result in large numbers of features. Currently, there exists a lacuna in the availability of a framework that can effectively integrate these features and furnish semantic level indices. The objective of this paper is to highlight some of the issues in the design of such a framework and to report on the status of its development. In our framework, construction of a high-level index is achieved through the synthesis of its large set of elemental features. From the large collection of these features, an image/video class is characterized by selecting automatically only a few principal features. By properly mapping the constrained multi-dimensional feature space constituted by these principal features, with the semantics of the data, it is feasible to construct high level indices. The problem remains, however, to automatically identify the principal or meaningful subset of features. This is done through the medium of Bayesian Network that discerns the data into cliques by training with pre-classified data. The Bayesian Network associates each clique of data points in the multi-dimensional feature space to one of the classes during training that can later be used for evaluating the most probable class to which that partition of feature space belongs. This framework neither requires normalization of different features or the aid of an expert knowledge base. The framework enables a stronger coupling between the feature extraction and meaningful high-level indices and yet the coupling is sufficiently domain independent, as shown by the experiments. The experiments were conducted over real video consisting of seven diverse classes and the results show its superiority over some of the standard classification tools.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.
C3 National University of Singapore
RP Mittal, A (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.
CR [Anonymous], 1995, PROC ICJAI, DOI DOI 10.1145/217279.215068
   [Anonymous], 1990, Abductive inference models for diagnostic problem solving
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Aslandogan YA, 1999, IEEE T KNOWL DATA EN, V11, P56, DOI 10.1109/69.755615
   CASCIA ML, 1996, IEEE INT C AC SPEECH
   CHANG CC, LIBSVM INTRO BENCHMA
   COOPER GF, KSL8727 STANF U
   DEMSAR J, 1996, INT C PATT REC, V3
   DOULAMIS ND, 1999, INT C IM PROC, V2
   FISCHER S, 1995, ACM MULTIMEDIA 95 EL
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   GUDIVADA VN, 1995, IEEE COMPUTER    SEP
   HAMPAPUR A, 1995, THESIS U MICHIGAN
   Haykin S., 1999, Neural Networks: A Comprehensive Foundation, V2nd, P178
   HENRION M, 1990, EFFICIENT PROBABILIS, P385
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   KELLY P., 1995, STORAGE RETRIEVAL IM, V2420, P238
   Lauritzen SteffenL., 1988, LOCAL COMPUTATIONS P, P157
   LENDIS S, CONTENT BASED IMAGE
   Mitchell T. M., 1997, MACH LEARN, P230
   Mufit Ferman A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P91, DOI 10.1109/ICIP.1999.822861
   NACK F, 1997, APPL VIDEO SEMANTICS, P57
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   PAZZANI M, 1994, INT C MACH LEARN
   PAZZANI M, 1995, INT C KNOWL DISC DAT, P228
   Pearl J., 1988, PROBABILISTIC REASON
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Raudys S, 2000, NEURAL NETWORKS, V13, P17, DOI 10.1016/S0893-6080(99)00097-0
   SHANNON XJ, 1997, IEEE INT C COMP VIS, P595
   SMITH J, 1996, ACM MULTIMEDIA   NOV
   SOBCHACK V, 1982, SEMIOTICA, V41, P317, DOI 10.1515/semi.1982.41.1-4.317
   STRICKER MA, 1994, P SOC PHOTO-OPT INS, V2185, P15, DOI 10.1117/12.171784
   Sudhir G., 1998, IEEE WORKSH CONT BAS
   TODD BS, 1993, INT J BIOMEDICAL COM, P129
   Tonomura Y., 1994, Multimedia Systems, V1, P205
   VASCONCELOS N, 1997, P INT C IM PROC
   YANG Z, 1999, INT C IMAGE PROCESSI, V1
   YOW D, 1995, 2 AS C COMP VIS ACCV
   Zabih R, 1996, PROC CVPR IEEE, P439, DOI 10.1109/CVPR.1996.517109
   ZHANG H, 1994, P INT C MULT COMP SY, P45
NR 41
TC 9
Z9 9
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2003
VL 20
IS 2
BP 135
EP 158
DI 10.1023/A:1023627404478
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 675WP
UT WOS:000182720800002
DA 2024-07-18
ER

PT J
AU Xiang, J
   Zhang, N
   Pan, RR
AF Xiang, Jun
   Zhang, Ning
   Pan, Ruru
TI Cross-modal fabric image-text retrieval based on convolutional neural
   network and TinyBERT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fabric retrieval; Cross-modal retrieval; Word embedding; Deep learning;
   Deep hashing
ID ATTENTION
AB The repaid renewal of fabric products increases the difficulty of retrieving existing products in enterprises. The unimodal retrieval methods can take advantage of historical production experiences, but they cannot meet the user's variable retrieval requests. Cross-modal image-text retrieval can quickly obtain technical descriptions or intentional images, which is an urgent demand in textile industries. In this paper, a novel cross-modal fabric image-text retrieval is proposed based on the fabric characteristics. A convolutional neural network with a compact structure and cross-domain connection is designed to represent the visual content of the fabric images. Then, the fine-tuned TinyBERT is applied to embed the textual description into a vector. The representations of the two modalities are aligned in the same Hamming space. Finally, a cross-modal retrieval strategy is designed based on the features of different modes. A fabric dataset that contains over 40000 pairs of images and texts is built as the benchmark to verify the proposed cross-modal image-text retrieval method. Extensive experiments have been performed on the built dataset. Results indicate that the proposed scheme is feasible and effective, being superior to the existing methods proposed for public datasets. The proposed method can provide referential assistance for the production crew in the fabric factory.
C1 [Xiang, Jun; Zhang, Ning; Pan, Ruru] Jiangnan Univ, Key Lab Ecotext, Minist Educ, Wuxi, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Zhang, N (corresponding author), Jiangnan Univ, Key Lab Ecotext, Minist Educ, Wuxi, Jiangsu, Peoples R China.
EM skyjun12@163.com; 15251635269@163.com; prrsw@163.com
OI Zhang, Ning/0000-0003-3605-7984
FU National Natural Science Foundation of China
FX No Statement Available
CR Bi MW, 2023, ARTIF INTELL REV, V56, P7597, DOI 10.1007/s10462-022-10364-5
   Chen YX, 2020, IEEE T GEOSCI REMOTE, V58, P7049, DOI 10.1109/TGRS.2020.2979273
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Cui Z, 2022, MULTIMED TOOLS APPL, V81, P23615, DOI 10.1007/s11042-022-12444-8
   Dong XF, 2022, IEEE T CIRC SYST VID, V32, P6437, DOI 10.1109/TCSVT.2022.3164230
   Farruggia A, 2014, FUTURE GENER COMP SY, V37, P243, DOI 10.1016/j.future.2014.02.008
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Jiang QY, 2019, IEEE T IMAGE PROCESS, V28, P3490, DOI 10.1109/TIP.2019.2897944
   Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163
   Karpathy A, 2014, ADV NEUR IN, V27
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li WH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102432
   Liu YX, 2023, IEEE T MULTIMEDIA, V25, P2851, DOI 10.1109/TMM.2022.3152086
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Ma L, 2019, NEUROCOMPUTING, V345, P36, DOI 10.1016/j.neucom.2018.11.089
   Ou WH, 2020, MULTIMED TOOLS APPL, V79, P14733, DOI 10.1007/s11042-019-7343-8
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Pu T, 2023, NEUROCOMPUTING, V526, P121, DOI 10.1016/j.neucom.2023.01.018
   Qi JW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P892
   Qu LG, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1104, DOI 10.1145/3404835.3462829
   Rubio A, 2017, IEEE IMAGE PROC, P400, DOI 10.1109/ICIP.2017.8296311
   Sharaff A, 2021, INT J SEMANT WEB INF, V17, P18, DOI 10.4018/IJSWIS.2021070102
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang Y, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103280
   Wang YD, 2022, INFORM SCIENCES, V609, P727, DOI 10.1016/j.ins.2022.07.109
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wen KY, 2021, IEEE T CIRC SYST VID, V31, P2866, DOI 10.1109/TCSVT.2020.3030656
   Xiang J, 2021, COMPUT GRAPH-UK, V101, P93, DOI 10.1016/j.cag.2021.10.004
   Xiang J, 2021, IEEE T IMAGE PROCESS, V30, P1570, DOI 10.1109/TIP.2020.3043877
   Xie ZW, 2022, IEEE T SERV COMPUT, V15, P3304, DOI 10.1109/TSC.2021.3098834
   Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI 10.1109/TCYB.2019.2928180
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yu J, 2020, PATTERN RECOGN LETT, V130, P189, DOI 10.1016/j.patrec.2018.08.017
   Zhang DL, 2022, IEEE T SYST MAN CY-S, V52, P7014, DOI [10.1109/TSMC.2021.3130939, 10.1109/IECON49645.2022.9968873]
   Zhang DL, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108343
   Zhang J, 2022, MULTIMED TOOLS APPL, V81, P12005, DOI 10.1007/s11042-020-10466-8
   Zhang N, 2023, TEXT RES J, V93, P1401, DOI 10.1177/00405175221128524
   Zhang N, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116229
   Zhang N, 2022, TEXT RES J, V92, P434, DOI 10.1177/00405175211037186
   Zhang YF, 2021, IEEE T IMAGE PROCESS, V30, P617, DOI 10.1109/TIP.2020.3038354
   Zhang Y, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2021.107673
   Zhao ZQ, 2019, NEUROCOMPUTING, V335, P251, DOI 10.1016/j.neucom.2018.09.090
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 45
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17903-4
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500009
DA 2024-07-18
ER

PT J
AU Chang, XY
   Wu, YH
   Deng, SZ
   Jia, T
   Chen, DY
AF Chang, Xingya
   Wu, Yunhe
   Deng, Shizhuo
   Jia, Tong
   Chen, Dongyue
TI Conjoined triple deep network for video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video anomaly detection; Triple network; Dual learning; Local
   probability model; Regional score
AB The video anomaly detection task typically involves identifying anomalous targets, behaviors, and events in surveillance using only normal samples. Most mainstream anomaly detection models train an encoder-decoder network exclusively with normal samples, identifying frames with larger reconstruction errors as anomalies. The challenge with such methods lies in controlling the generalization ability of the reconstruction model on anomaly samples and the bias of reconstruction maps towards small-scale anomalies. To address these issues, we propose a triple-stream framework for anomaly detection, combining cross-prediction agent tasks and multiple local probabilistic models. We incorporate a dual learning mechanism in both the appearance and motion channels, allowing mutual feedback to make the model overfit to normal samples and correspondingly weaken its generalization on anomalous samples. Additionally, we apply the attention mechanism to the network, design a feature consistency function to constrain bias to local features, and construct a probability model for each local region to detect larger-scale anomalies. Finally, we design a fusion scheme to evaluate anomaly scores for video frames. Evaluations on popular benchmark datasets, including UCSD, Avenue, and Street Scene, demonstrate that our proposed model achieves competitive performance compared to state-of-the-art methods.
C1 [Chang, Xingya; Wu, Yunhe; Deng, Shizhuo; Jia, Tong; Chen, Dongyue] Northeastern Univ, Coll Informat Sci & Engn, 11 Heping Reg Wenhua St, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Chen, DY (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, 11 Heping Reg Wenhua St, Shenyang 110819, Peoples R China.
EM 1810338@stu.neu.edu.cn; wuyunhe05@163.com; dengshizhuo@mail.neu.edu.cn;
   jiatong@ise.neu.edu.cn; chendongyue@ise.neu.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Allison PD, 1999, Logistic regression using the sas system: theory and application, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cui Y., 2021, P IEEECVF INT C COMP, P8138
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Doshi K, 2020, IEEE COMPUT SOC CONF, P4037, DOI 10.1109/CVPRW50498.2020.00475
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kingma D. P., 2014, arXiv
   Li Q, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109348
   Li S, 2021, IEEE T CIRC SYST VID, V31, P1283, DOI 10.1109/TCSVT.2020.2984783
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu Yue, 2022, IEEE Trans Circuits Syst Video Technol, P2
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mo X, 2013, IEEE Trans Circuits Syst Video Technol, V4, P631
   Nguyen MN, 2019, LECT NOTES ARTIF INT, V11051, P157, DOI 10.1007/978-3-030-10925-7_10
   Nguyen TN, 2019, Arxiv, DOI arXiv:1908.06347
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Rao A., 2014, IEEE Aerospace Conference Proceedings, P1, DOI DOI 10.1109/DICTA.2014.7008100
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wang T, 2013, IEEE INT W PERFORM, P45, DOI 10.1109/PETS.2013.6523794
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan LQ, 2023, IEEE T CIRC SYST VID, V33, P393, DOI 10.1109/TCSVT.2022.3202574
   Yan LQ, 2022, IEEE T CIRC SYST VID, V32, P6642, DOI [10.1109/TCSVT.2022.3177320, 10.1109/tcsvt.2022.3177320]
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhong YH, 2022, IEEE T CIRC SYST VID, V32, P8285, DOI 10.1109/TCSVT.2022.3190539
   Zong B., 2018, P 6 INT C LEARN REPR
NR 55
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17842-0
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ3E1
UT WOS:001131620700001
DA 2024-07-18
ER

PT J
AU Wang, S
   Lv, WJ
   Zhao, XY
   Zhang, XY
   Su, JY
   Zeng, L
AF Wang, Shuo
   Lv, Weijie
   Zhao, Xinyuan
   Zhang, Xinyu
   Su, Junyu
   Zeng, Long
TI Refined-mask guided multi-stream blending network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image blending; Image composition; Boundary artifacts; Mask refine
AB Image composition is a challenging image editing operation that targets the compositing of a new image by combining cropped regions from different images. A common application is background replacement of portrait images. Existing composition methods usually result in undesirable artifacts along the boundaries of pasted regions due to imprecise extraction. To address this problem, we propose a refined-mask guided multi-stream blending network (MGMB-Net), which consists of a multi-stream block (MSB), reconstructing the foreground boundary of composited image, mask-refine blocks (MRBs), providing better location information and refined-mask guided blocks (MGBs), guiding the reconstruction of composited image to eliminate boundary artifacts. MGMB-Net can generate more harmonious and realistic images by fusing multi-stream features and refining input coarse masks. We propose two data-generation methods to construct new datasets on image blending, and two evaluation metrics, PSNR (Peak signal-to-noise ratio)-Sobel and PSNR-Boundary, to decouple the performance of blending and harmonization. Compared with state-of-the-art methods, our method achieves the best performance on portrait images without additional refinements or prior information. Our code and model are available at https://github.com/Wekect/MGMB-Net.
C1 [Wang, Shuo; Zhang, Xinyu; Su, Junyu; Zeng, Long] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.
   [Lv, Weijie] Tsinghua Univ, Dept Mech Engn, Beijing 100084, Peoples R China.
   [Zhao, Xinyuan] Huawei Technol, Shenzhen, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University;
   Tsinghua University; Huawei Technologies
RP Zeng, L (corresponding author), Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.
EM wangshuo20@mails.tsinghua.edu.cn; lwj19@mails.tsinghua.edu.cn;
   zhaoxinyuan1@huawei.com; zhangxy20@mails.tsinghua.edu.cn;
   sujy20@mails.tsinghua.edu.cn; zenglong@sz.tsinghua.edu.cn
FU Guangdong Natural Science Fund-General Programme [2022A1515011234];
   Shenzhen Science and Technology Innovation Commission
   [No.WDZC20200821140447001]
FX This work was funded by the Guangdong Natural Science Fund-General
   Programme Grand No. 2022A1515011234, University Key Projects stablely
   funded by Shenzhen Science and Technology Innovation Commission (Grant
   No.WDZC20200821140447001).
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Chen Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P618, DOI 10.1145/3240508.3240610
   Farid MS, 2014, MULTIMED TOOLS APPL, V71, P1699, DOI 10.1007/s11042-012-1303-x
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Gao Z, 2023, IEEE T KNOWL DATA EN, V35, P7541, DOI 10.1109/TKDE.2022.3187091
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou QQ, 2019, IEEE I CONF COMP VIS, P4129, DOI 10.1109/ICCV.2019.00423
   Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746
   Kazhdan M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360620
   Ke ZH, 2022, Arxiv, DOI arXiv:2011.11961
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Ling J, 2021, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR46437.2021.00924
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Niu L, 2024, Arxiv, DOI arXiv:2106.14490
   Peng B, 2020, MULTIMED TOOLS APPL, V79, P32833, DOI 10.1007/s11042-020-09346-y
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Porter T., 1984, Computers & Graphics, V18, P253
   Rao A, 2022, IEEE Transactions on Multimedia
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szeliski R, 2011, 2011 IEEE INT C COMP, P1
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   Tao AD, 2020, Arxiv, DOI [arXiv:2005.10821, DOI 10.48550/ARXIV.2005.10821]
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wenyan Cong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8391, DOI 10.1109/CVPR42600.2020.00842
   Wu HK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2487, DOI 10.1145/3343031.3350944
   Xing YZ, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2296, DOI 10.1145/3503161.3548031
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu QH, 2021, PROC CVPR IEEE, P1154, DOI 10.1109/CVPR46437.2021.00121
   Zhang H, 2021, IEEE WINT CONF APPL, P365, DOI 10.1109/WACV48630.2021.00041
   Zhang LZ, 2020, IEEE WINT CONF APPL, P231, DOI [10.1109/wacv45572.2020.9093632, 10.1109/WACV45572.2020.9093632]
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhao YB, 2022, IEEE T IMAGE PROCESS, V31, P4746, DOI 10.1109/TIP.2022.3182866
   Zhu SJ, 2023, Arxiv, DOI arXiv:2304.03372
   Zoph B, 2020, Arxiv, DOI arXiv:2006.06882
NR 43
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17793-6
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200002
DA 2024-07-18
ER

PT J
AU Kumar, PG
   Vijay, SAA
   Prakash, VJ
   Paul, A
   Nayyar, A
AF Kumar, P. Ganesh
   Vijay, S. Arul Antran
   Prakash, V. Jothi
   Paul, Anand
   Nayyar, Anand
TI A context-sensitive multi-tier deep learning framework for multimodal
   sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Gated recurrent unit; Information retrieval; Multimedia
   analysis; Multimodal sentiment analysis; Sentiment analysis
AB One of the most appealing multidisciplinary research areas in Artificial Intelligence (AI) is Sentiment Analysis (SA). Due to the intricate and complementary interactions between several modalities, Multimodal Sentiment Analysis (MSA) is an extremely difficult work that has a wide range of applications. In the subject of multimodal sentiment analysis, numerous deep learning models and different techniques have been suggested, but they do not investigate the explicit context of words and are unable to model diverse components of a sentence. Hence, the full potential of such diverse data has not been explored. In this research, a Context-Sensitive Multi-Tier Deep Learning Framework (CS-MDF) is proposed for sentiment analysis on multimodal data. The CS-MDF uses a three-tier architecture for extracting context-sensitive information. The first tier utilizes Convolutional Neural Network (CNN) for extracting text-based features, 3D-CNN model for extracting visual features and open-Source Media Interpretation by Large feature-space Extraction (openSMILE) tool kit for audio feature extraction.The first tier focuses on extracting the unimodal features from the utterances. This level of extraction ignores context-sensitive data while determining the feature.CNNs are suitable for text data because they are particularly useful for identifying local patterns and dependencies in data.The second tier uses the features extracted from the first tier.The context-sensitive unimodal characteristics are extracted in this tier using the Bi-directional Gated Recurrent Unit (BiGRU), which is used to comprehend inter-utterance links and uncover contextual evidence.The output from tier two is combined and passed to the third tier, which fuses the features from different modalities and trains a single BiGRU model that provides the final classification.This method applies the BiGRU model to sequential data processing, using the advantages of both modalities and capturing their interdependencies.Experimental results obtained on six real-life datasets (Flickr Images dataset, Multi-View Sentiment Analysis dataset, Getty Images dataset, Balanced Twitter for Sentiment Analysis dataset, CMU-MOSI Dataset) show that the proposed CS-MDF model has achieved better performance compared with ten state-of-the-art approaches, which are validated by F1 score, precision, accuracy, and recall metrics.An ablation study is carried out on the proposed framework that demonstrates the viability of the design. The GradCAM visualization technique is applied to visualize the aligned input image-text pairs learned by the proposed CS-MDF model.
C1 [Kumar, P. Ganesh] Anna Univ, Coll Engn Guindy, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Vijay, S. Arul Antran; Prakash, V. Jothi] Karpagam Coll Engn, Coimbatore, Tamil Nadu, India.
   [Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Sch Comp Sci, Da Nang, Vietnam.
C3 Anna University; Anna University Chennai; College of Engineering Guindy;
   Karpagam College of Engineering; Kyungpook National University; Duy Tan
   University
RP Vijay, SAA; Prakash, VJ (corresponding author), Karpagam Coll Engn, Coimbatore, Tamil Nadu, India.
EM ganesh23508@gmail.com; arulantranvijay@gmail.com;
   jothiprakashv@gmail.com; paul.editor@gmail.com;
   anandnayyar@duytan.edu.vn
RI S, Arul Antran Vijay/AAM-8297-2020; Nayyar, Anand/F-3732-2015
OI S, Arul Antran Vijay/0000-0002-5543-7547; Nayyar,
   Anand/0000-0002-9821-6146; V, Jothi Prakash/0000-0002-5427-9460
FU National Research Foundation (NRF) of Korea [2020R1A2C1012196]; National
   Research Foundation (NRF) of Korea
FX This work is supported by National Research Foundation (NRF) of Korea.
   Grant number: 2020R1A2C1012196.
CR Abd El-Jawad MH, 2018, INT COMPUT ENG CONF, P174, DOI 10.1109/ICENCO.2018.8636124
   Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Akhtar MM, 2019, METHODS MOL BIOL, V1970, P1, DOI 10.1007/978-1-4939-9207-2_1
   Andrew G., 2013, ICML, P1247
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen M., 2017, P 19 ACM INT C MULT, P163, DOI 10.1145/3136755.3136801
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Sánchez-Rada JF, 2019, INFORM FUSION, V52, P344, DOI 10.1016/j.inffus.2019.05.003
   Gu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P537, DOI 10.1145/3240508.3240714
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Pham H, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), P53
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu GS, 2017, IEEE I CONF COMP VIS, P3764, DOI 10.1109/ICCV.2017.404
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Jiang T, 2020, LECT NOTES ARTIF INT, V12085, P785, DOI 10.1007/978-3-030-47436-2_59
   Liu Y, 2020, MATH BIOSCI ENG, V17, P7819, DOI 10.3934/mbe.2020398
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Mai SJ, 2020, AAAI CONF ARTIF INTE, V34, P164
   Niu T., 2016, SENTIMENT ANAL MULTI, DOI DOI 10.1007/978-3-319-27674-8_2
   Park G, 2016, Image-text multi-modal representation learning by adversarial backpropagation, P1
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Pham H, 2019, AAAI CONF ARTIF INTE, P6892
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Sun ZK, 2020, AAAI CONF ARTIF INTE, V34, P8992
   Taeyong Kim, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P436, DOI 10.1145/3372278.3390698
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wang ZH, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P562, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00100
   Wei Han, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P6, DOI 10.1145/3462244.3479919
   Xu J, 2019, KNOWL-BASED SYST, V178, P61, DOI 10.1016/j.knosys.2019.04.018
   Xu N, 2018, ACM/SIGIR PROCEEDINGS 2018, P929, DOI 10.1145/3209978.3210093
   Xu N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2399, DOI 10.1145/3132847.3133142
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Yang KC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P521, DOI 10.1145/3394171.3413690
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   Zadeh A, 2017, Tensor fusion network for multimodal sentiment analysis, P1
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zhu QN, 2021, IEEE ACCESS, V9, P149077, DOI 10.1109/ACCESS.2021.3118537
NR 52
TC 1
Z9 1
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17601-1
EA DEC 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100002
DA 2024-07-18
ER

PT J
AU Singh, LK
   Khanna, M
   Mansukhani, D
   Thawkar, S
   Singh, R
AF Singh, Law Kumar
   Khanna, Munish
   Mansukhani, Dheeraj
   Thawkar, Shankar
   Singh, Rekha
TI Features fusion based novel approach for efficient blood vessel
   segmentation from fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Imaging informatics; Retinal blood vessel segmentation; Feature
   extraction; Machine learning
ID RETINAL IMAGES; REGISTRATION; OPERATORS; WAVELET; MODEL
AB Insufficient blood flow within the retinal vessels is believed to be the root cause of several optical problems, including partial vision loss and blindness. The appearance and growth of veins in retinal images are crucial for identifying ocular contamination. It is therefore a significant task for the research community to explore and segment these retinal blood vessels. For a wide range of purposes, including biometric authentication, computer-assisted laser surgery, automated screening, and the detection of ophthalmic pathologies like diabetic retinopathy (DR), age-related macular degeneration, and hypertensive retinopathy, among others, accurate blood vessel delineation in retinal images is used. Stroke and cardiovascular disease are severe illnesses that are preceded by changes in the properties of retinal blood vessels. There are many alternatives to identifying an infection a person has through their eyes in the broad development of innovation, such as diabetes, hypertension, heart disease, rheumatoid arthritis, etc. Examining retinal vascular features can therefore help to spot these changes and allow a person to respond quickly while the illness is still in its early stages. The use of computer-based automation in this procedure would reduce the costs associated with hiring qualified graders and solve the issue of inconsistency that results from manual grading. Numerous tasks involving retinal analysis require the segmentation of retinal vessels because it facilitates the execution of subsequent measures. As a result, segmentation is crucial to the study of retinal images. In the current study, a successful method for automatically extracting blood vessels from coloured retinal pictures is described. In order to solve the retinal blood vessel segmentation problem, we applied feature extraction methodologies and machine learning (ML) techniques in this research. This method uses pixel-based feature extraction, where each pixel has its own feature vector. Five distinct feature groups are employed for feature extraction: the basic line detector for line strength, the orthogonal line detector, the frangi filter, the average grey level features, and the gabor filter. The four machine learning classifiers-K-Nearest Neighbour (KNN), Support Vector Machine (SVM), Naive Bayes, and Decision Tree-are trained using the training data. A DRIVE dataset is used to test the system; it is a benchmark, standard, widely accepted, and openly accessible to the general public. Blood vessel segmentation from fundus pictures is measured using performance metrics like precision, sensitivity, specificity, area under the curve (AUC), and accuracy as success indicators. With the given method, the maximum accuracy achieved is 0.9623 using KNN, 0.9463 using SVM, 0.9459 using Naive Bayes, and 0.9624 using Decision Tree. The findings of previously published extremely efficient approaches are comparable to the performance of the suggested strategy, which has demonstrated great performance. The recommended method can be used as an alternate automated tool for segmenting retinal blood vessels.
C1 [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Khanna, Munish] Galgotias Univ, Sch Comp Sci & Engn, Gautam Buddh Nagar, Uttar Pradesh, India.
   [Mansukhani, Dheeraj] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura, India.
   [Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Informat Technol, Mathura, India.
   [Singh, Rekha] Uttar Pradesh Rajarshi Tandon Open Univ, Dept Phys, Prayagraj, Uttar Pradesh, India.
C3 GLA University; Galgotias University
RP Singh, LK (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM lawkumarcs1@gmail.com; munishkhanna.official@rocketmail.com;
   dheerajmanuskhani11@gmail.com; Shankar.thawkar@gmail.com;
   singh.rekha70@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852
CR Adapa D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229831
   Agrawal OP, 2012, FRACT CALC APPL ANAL, V15, P700, DOI 10.2478/s13540-012-0047-7
   Ahmad I., 2022, Machine intelligence and smart systems: proceedings of MISS 2021, P223, DOI [10.1007/978-981-16-9650-3_17, DOI 10.1007/978-981-16-9650-3_17]
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   An L, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3369811
   Annunziata R, 2016, IEEE J BIOMED HEALTH, V20, P1129, DOI 10.1109/JBHI.2015.2440091
   Aslani S, 2016, BIOMED SIGNAL PROCES, V30, P1, DOI 10.1016/j.bspc.2016.05.006
   Atli I, 2021, ENG SCI TECHNOL, V24, P271, DOI 10.1016/j.jestch.2020.07.008
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Budai A., 2010, Bildverarbeitung fur die Medizin, V574, P261
   Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088
   Candrilli SD, 2007, J DIABETES COMPLICAT, V21, P306, DOI 10.1016/j.jdiacomp.2006.08.002
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Chen DL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071067
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   Fan Z., 2019, arXiv
   Fathi A, 2013, BIOMED SIGNAL PROCES, V8, P71, DOI 10.1016/j.bspc.2012.05.005
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Garg S, 2007, I S BIOMED IMAGING, P344, DOI 10.1109/ISBI.2007.356859
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Gulati Seema, 2022, 2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1, DOI 10.1109/ICRITO56286.2022.9964524
   Hamghalam M, 2020, I S BIOMED IMAGING, P1499, DOI [10.1109/ISBI45749.2020.9098347, 10.1109/isbi45749.2020.9098347]
   Hamghalam M, 2020, LECT NOTES COMPUT SC, V11992, P3, DOI 10.1007/978-3-030-46640-4_1
   Han Z, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P960, DOI 10.1109/ICDMW.2014.16
   Hemelings R, 2019, COMPUT MED IMAG GRAP, V76, DOI 10.1016/j.compmedimag.2019.05.004
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Imran A, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2935912
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Khan M A U, 2019, Procedia Comput Sci, V163, P618, DOI [10.1016/j.procs.2019.12.144, DOI 10.1016/J.PROCS.2019.12.144]
   Khanna M, 2023, Multimed Tools Appl, P1
   Kharghanian A., 2012, Int. J. Mach. Learn. Comput., V2, P593, DOI DOI 10.7763/IJMLC.2012.V2.196
   Khomri B, 2018, IET IMAGE PROCESS, V12, P2163, DOI 10.1049/iet-ipr.2018.5425
   Kushol R, 2020, MATH BIOSCI ENG, V17, P7751, DOI 10.3934/mbe.2020394
   Li KQ, 2021, IEEE J BIOMED HEALTH, V25, P2071, DOI 10.1109/JBHI.2020.3028180
   Lin Y, 2019, IEEE ACCESS, V7, P57717, DOI 10.1109/ACCESS.2018.2844861
   Maharjan A, 2016, Blood vessel segmentation from retinal images
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Mudrova Martina., 2005, Principal component analysis in image processing
   Na T, 2018, MED PHYS, V45, P3132, DOI 10.1002/mp.12953
   Nasr-Esfahani E, 2018, BIOMED SIGNAL PROCES, V40, P240, DOI 10.1016/j.bspc.2017.09.012
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Palomera-Pérez MA, 2010, IEEE T INF TECHNOL B, V14, P500, DOI 10.1109/TITB.2009.2036604
   Rangayyan R.M., 2011, Color image processing with biomedical applications, DOI DOI 10.1117/3.887920
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Rodrigues LC, 2017, BIOMED SIGNAL PROCES, V36, P39, DOI 10.1016/j.bspc.2017.03.014
   Roychowdhury S, 2015, IEEE T BIO-MED ENG, V62, P1738, DOI 10.1109/TBME.2015.2403295
   Saffarzadeh Vahid Mohammadi, 2014, J Med Signals Sens, V4, P122
   Saha SK, 2019, BIOMED SIGNAL PROCES, V47, P288, DOI 10.1016/j.bspc.2018.08.034
   Samuel PM, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070946
   Sazak Ç, 2019, PATTERN RECOGN, V88, P739, DOI 10.1016/j.patcog.2018.10.011
   Septiarini A, 2018, BIOMED SIGNAL PROCES, V45, P151, DOI 10.1016/j.bspc.2018.05.028
   Shukla AK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101883
   Shukla AK, 2020, CIRC SYST SIGNAL PR, V39, P363, DOI 10.1007/s00034-019-01186-y
   Singh LK, 2023, Multimedia Tools and Applications, P1
   Singh NP, 2020, TRAIT SIGNAL, V37, P855, DOI 10.18280/ts.370519
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Soleymanifard M, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P739, DOI [10.1109/kbei.2019.8735050, 10.1109/KBEI.2019.8735050]
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Thangaraj S, 2018, IET IMAGE PROCESS, V12, P669, DOI 10.1049/iet-ipr.2017.0284
   Tiwari AK, 2016, Doctoral dissertation
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Toptas B, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103053
   Tuba E., 2017, 2017 27th International Conference Radioelektronika (RADIOELEKTRONIKA), P1
   Tyagi A, 2023, MULTIMED TOOLS APPL, V82, P20343, DOI 10.1007/s11042-022-13809-9
   Xiancheng W, 2018, PROCEDIA COMPUTER SC, P8
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yue KJ, 2018, IET IMAGE PROCESS, V12, P1450, DOI 10.1049/iet-ipr.2017.1071
   Zhang J, 2016, IEEE T MED IMAGING, V35, P2631, DOI 10.1109/TMI.2016.2587062
   Zhao H, 2019, IEEE T MED IMAGING, V38, P46, DOI 10.1109/TMI.2018.2854886
   Zhao JL, 2018, DIGIT SIGNAL PROCESS, V81, P26, DOI 10.1016/j.dsp.2018.06.006
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
NR 81
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17621-x
EA DEC 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100004
DA 2024-07-18
ER

PT J
AU Ahmed, I
   Irfan, MA
   Iqbal, A
   Khalil, A
   Siddiqui, SI
AF Ahmed, Irfan
   Irfan, Muhammad Abeer
   Iqbal, Abid
   Khalil, Amaad
   Siddiqui, Salman Ilahi
TI Efficient feature extraction and classification for the development of
   Pashto speech recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic speech recognition (ASR); Machine learning (ML); Feature
   extraction; MFCC; DWT; SVM; k-NN
AB In this work, a novel framework for the efficient feature extraction and recognition of Pashto speech signals is proposed. The targeted language is one of the low-resource languages and prone to higher Automatic Speech Recognition (ASR) errors due to the availability of its colloquial dialects. We devised a framework which not only employed classical Machine Learning (ML) models for speech recognition tasks, but also achieved a higher level of performance accuracy by using the optimal feature extraction techniques. The designed frameworks for feature extraction are based on two well-know feature extraction techniques: Discrete Wavelet Transform (DWT )coefficients and Mel-Frequency Cepstral Coefficients (MFCC). In our work, we deployed classical ML models i.e., Support Vector Machine (SVM) and K-Nearest Neighbors (k-NN), due to their efficiency in terms of computation complexity, energy efficiency, and higher accuracy as compared to other ML and Deep Learning (DL) model. Hence, our proposed framework exhibited improved performance level when trained on a Pashto isolated words dataset.
C1 [Ahmed, Irfan; Iqbal, Abid; Siddiqui, Salman Ilahi] Univ Engn & Technol Peshawar, Dept Elect Engn, Jalozai Campus, Nowshera, Khyber Pakhtunk, Pakistan.
   [Irfan, Muhammad Abeer; Khalil, Amaad] Univ Engn & Technol Peshawar, Dept Comp Syst Engn, Peshawar, Pakistan.
C3 University of Peshawar
RP Ahmed, I (corresponding author), Univ Engn & Technol Peshawar, Dept Elect Engn, Jalozai Campus, Nowshera, Khyber Pakhtunk, Pakistan.
EM irfanahmed@uetpeshawar.edu.pk; abeer.irfan@polito.it;
   abid.iqbal@uetpeshawar.edu.pk; amaadkhalil@uetpeshawar.edu.pk;
   salman.ilahi@uetpeshawar.edu.pk
RI Iqbal, Abid/AAJ-4235-2021
OI Iqbal, Abid/0000-0002-6371-7020; Ahmed, Irfan/0000-0002-3489-3519
CR Ahmed I., 2012, 18 INT C AUT COMP IC, P1
   Ahmed I, 2022, Multimed Tools Appl, P1
   Ahmed I, 2023, MULTIMED TOOLS APPL, V82, P15327, DOI 10.1007/s11042-022-14003-7
   Ahmed I, 2022, IEEE ACCESS, V10, P85002, DOI 10.1109/ACCESS.2022.3197594
   Ahmed I, 2021, MULTIMED TOOLS APPL, V80, P20327, DOI 10.1007/s11042-021-10657-x
   Ahmed I, 2020, ARAB J SCI ENG, V45, P1567, DOI 10.1007/s13369-019-04080-6
   Ahmed I, 2012, INT CONF ROBOT ARTIF, P139, DOI 10.1109/ICRAI.2012.6413380
   [Anonymous], 2007, INTERSPEECH
   Baroi, 2020, INT J IMAGE GRAPH SI, V12, P1, DOI DOI 10.5815/IJIGSP.2020.01.01
   Boussaid L, 2018, INT J SPEECH TECHNOL, V21, P29, DOI 10.1007/s10772-017-9480-7
   Gruhn RE, 2011, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-642-19586-0
   Iqbal S, 2022, J INTERNET TECHNOL, V23, P1669, DOI 10.53106/160792642022122307021
   Kathol A, 2005, 9 EUR C SPEECH COMM
   Khan AA, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3280952
   Khan S, 2017, 2017 INT C INN EL EN, P1
   Kumar Kuldeep, 2011, Int J Comput Bus Res, V2, P2229
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Prasad R, 2010, INT CONF ACOUST SPEE, P5086, DOI 10.1109/ICASSP.2010.5495052
   Schultz T., 2006, 2006 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE Cat. No. 06CH37812C), pV
   Srivastava Swati, 2022, 2022 International Conference on Edge Computing and Applications (ICECAA), P1136, DOI 10.1109/ICECAA55415.2022.9936549
   Wikipedia, 2022, Pashto
   Zada B, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03372
   Zhou BW, 2005, INT CONF ACOUST SPEE, P1017
NR 23
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17684-w
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700011
DA 2024-07-18
ER

PT J
AU Ben Said, A
   Abdel-Salam, ASG
   Hazaa, KA
AF Ben Said, Ahmed
   Abdel-Salam, Abdel-Salam G.
   Hazaa, Khalifa A.
TI Performance prediction in online academic course: a deep learning
   approach with time series imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Online learning; Student performance; Deep learning; Gramian Angular
   Field
ID EDUCATION
AB With the COVID-19 outbreak, schools and universities have massively adopted online learning to ensure the continuation of the learning process. However, in such setting, instructors lack efficient mechanisms to evaluate the learning gains and get insights about difficulties learners encounter. In this research work, we tackle the problem of predicting learner performance in online learning using a deep learning-based approach. Our proposed solution allows stakeholders involved in the online learning to anticipate the learner outcome ahead of the final assessment hence offering the opportunity for proactive measures to assist the learners. We propose a two-pathway deep learning model to classify learner performance using their interaction during the online sessions in the form of clickstreams. We also propose to transform these time series of clicks into images using the Gramian Angular Field. The learning model makes use of the available extra demographic and assessment information. We evaluate our approach on the Open University Learning Analytics Dataset. Comprehensive comparative study is conducted with evaluation against state-of-art approaches under different experimental settings. We also demonstrate the importance of including extra demographic and assessment data in the prediction process.
C1 [Ben Said, Ahmed; Abdel-Salam, Abdel-Salam G.] Qatar Univ, Student Experience Dept, Doha 2713, Qatar.
   [Abdel-Salam, Abdel-Salam G.; Hazaa, Khalifa A.] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Doha, Qatar.
C3 Qatar University; Qatar University
RP Ben Said, A (corresponding author), Qatar Univ, Student Experience Dept, Doha 2713, Qatar.
EM abensaid@qu.edu.qa; abdo@qu.edu.qa; khalifa.alhazaa@qu.edu.qa
RI Abdel-Salam, AbdelSalam G./AFT-6676-2022
OI Abdel-Salam, AbdelSalam G./0000-0003-4905-6489; Ben Said,
   Ahmed/0000-0002-7760-8132
FU Qatar National Research Fund [0825-210045]; Qatar National Research Fund
   (a member of Qatar Foundation)
FX This publication was made possible by RRC02 grant #0825-210045 from the
   Qatar National Research Fund (a member of Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.
CR AL-Shabandar R, 2017, IEEE IJCNN, P713, DOI 10.1109/IJCNN.2017.7965922
   Ali S, 2021, MULTIMED TOOLS APPL, V80, P33329, DOI 10.1007/s11042-021-11414-w
   Aljohani NR, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11247238
   [Anonymous], 2011, P ICML
   Ashenafi MM, 2015, PROC FRONT EDUC CONF, P372
   Azizah EN, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON EDUCATION AND TECHNOLOGY (ICET), P18, DOI 10.1109/ICEAT.2018.8693928
   Baker R.S. J. D., 2010, INT ENCY ED, V7, P112, DOI [10.1016/B978-0-08-044894-7.01318-X, DOI 10.1016/B978-0-08-044894-7.01318-X]
   Benson AM, 2017, ROUTL RES SPORT CULT, P1
   De Santo A, 2022, Expert Syst Appl, V210
   Ding C, 2022, SUSTAIN ENERGY GRIDS, V32, DOI 10.1016/j.segan.2022.100888
   Du J, 2022, ENERGY, V257, DOI 10.1016/j.energy.2022.124689
   Dyment J, 2018, J ADVENTURE EDUC OUT, V18, P70, DOI 10.1080/14729679.2017.1341327
   ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Hamann K, 2017, POLITICS-OXFORD, V37, P229, DOI 10.1177/0263395716632384
   Hatami N, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309486
   He YB, 2020, INFORMATION, V11, DOI 10.3390/info11100474
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong YY, 2022, ENERGY, V246, DOI 10.1016/j.energy.2022.123391
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jha N.I., 2019, P 11 INT C COMP SUPP, P154
   Jordan K, 2015, INT REV RES OPEN DIS, V16, DOI 10.19173/irrodl.v16i3.2112
   Karimi H, 2020, 34 AAAI C ART INT AA
   Kingma D. P., 2014, arXiv
   Kong X, 2022, INT J INTELL SYST, V37, P8855, DOI 10.1002/int.22971
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuzilek J, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.171
   Kuzmanovic M, 2019, INT J COGNITIVE RES, V7, P37, DOI 10.5937/IJCRSEE1903037K
   Peach RL, 2019, Arxiv, DOI arXiv:1902.04047
   Li XX, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113680
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohamad SK, 2013, PROCD SOC BEHV, V97, P320, DOI 10.1016/j.sbspro.2013.10.240
   Ngiam J., 2010, ADV NEURAL INFORM PR, P1279, DOI DOI 10.1561/2200000006
   Pandey M., 2016, Perspectives in Science, V8, P364, DOI DOI 10.1016/J.PISC.2016.04.076
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qi YF, 2022, ANAL CHEM, V94, P6491, DOI 10.1021/acs.analchem.1c05098
   Qiao C, 2020, J ASSOC INF SCI TECH, V71, P1192, DOI 10.1002/asi.24322
   Quinlan J., 1994, The Morgan Kaufmann Series in Machine Learning, V16, P235
   Semliko DOSSOU, 2020, J Public Adm Governance, V10
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tannenbaum D, 2019, about us
   Toquero CM., 2020, PEDAGOGICAL RES, V5, pem0063, DOI DOI 10.29333/PR/7947
   Waheed H, 2020, COMPUT HUM BEHAV, V104, DOI 10.1016/j.chb.2019.106189
   Wang ZG, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3939
   Yang CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010168
NR 45
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 23
PY 2023
DI 10.1007/s11042-023-17596-9
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AX8H4
UT WOS:001121833800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Sinha, KP
   Kumar, P
AF Sinha, Kumari Priyanka
   Kumar, Prabhat
TI Human activity recognition from uav videos using an optimized hybrid
   deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human Activity Recognition (HAR); Contrast enhancement; Bag of Visual
   Words (BoVW); Improved LGTP features; Convolutional neural network; Blue
   Monkey Standardized Aquila Optimization (BMSAO)
ID NETWORK; FEATURES; SENSORS
AB Human activity recognition (HAR) is an important research area in both machine learning and human-computer interactions. Unfortunately, it remains an extremely difficult process owing to unsolvable issues, such as sensor movement, sensor positioning, crowded background, and inherent diversity in task performances by distinct humans. In this study, we developed an ensemble of classification models for the HAR. The proposed HAR has four working phases-preprocessing, segmentation, feature extraction, and classification. The pre-processing phase includes processes such as frame conversion and contrast enhancement. We developed an improved balanced iterative reducing and clustering utilising hierarchies (BIRCH) algorithm, that provides efficient segmentation by utilizing only minimal resources. These segmented images are subjected to feature extraction, in which grey level co-occurrence matrix (GLCM) features, and improved local gradient threshold pattern (LGTP) features are extracted along with conventional bag of visual words (BoVW) to provide better results. An ensemble classification model with classifiers such as Bi-GRU, CNN, and LSTM was developed in this study to provide an accurate classification. To enhance the performance of the proposed model, we developed a blue monkey standardized aquila optimization (BMSAO) approach. Conventional techniques are contrasted with the proposed framework. The proposed mechanism was found to have higher efficiency in HAR after it was experimentally evaluated.
C1 [Sinha, Kumari Priyanka] Nalanda Coll Engn, Dept CSE, Chandi, India.
   [Kumar, Prabhat] Natl Inst Technol Patna, Dept CSE, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Sinha, KP (corresponding author), Nalanda Coll Engn, Dept CSE, Chandi, India.
EM kumaripriyankasinka@gmail.com; prabhat@nitp.ac.in
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Agustí P, 2014, PATTERN RECOGN LETT, V49, P224, DOI 10.1016/j.patrec.2014.07.014
   Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahsan T, 2013, IETE TECH REV, V30, P47, DOI 10.4103/0256-4602.107339
   Al-Ani M, 2002, J ARTIF INTELL RES, V17, P333, DOI 10.1613/jair.1026
   AlDahoul N, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/1639561
   Ashry S, 2020, IEEE SENS J, V20, P8757, DOI 10.1109/JSEN.2020.2985374
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Burghouts GJ, 2014, PROC SPIE, V9249, DOI 10.1117/12.2067569
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Demrozi F, 2020, IEEE ACCESS, V8, P210816, DOI [10.1109/ACCESS.2020.3037715, 10.1109/access.2020.3037715]
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Garcia KD, 2021, NEUROCOMPUTING, V439, P271, DOI 10.1016/j.neucom.2020.01.125
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Islam MM, 2021, IEEE ROBOT AUTOM LET, V6, P1729, DOI 10.1109/LRA.2021.3059624
   Khan ZN, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107671
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Li WH, 2018, IEEE ACCESS, V6, P44211, DOI 10.1109/ACCESS.2018.2863943
   Li Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020635
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Mahmood M., 2019, Periodicals of Engineering and Natural Sciences (PEN), V7, P1054, DOI DOI 10.21533/PEN.V7I3.621
   Mekruksavanich S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051636
   Mliki H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107140
   Nagendran A, 2010, University of Central Florida
   Popko M, arXiv
   Ramanujam E, 2021, IEEE SENS J, V21, P13029, DOI 10.1109/JSEN.2021.3069927
   Rashid N, 2021, IEEE Internet of Things J, P1
   Ronald M, 2021, IEEE ACCESS, V9, P68985, DOI 10.1109/ACCESS.2021.3078184
   Sinha KP, 2023, IMAGE VISION COMPUT, V134, DOI 10.1016/j.imavis.2023.104674
   Soomro K., 2012, CoRR, V2
   Stergiou A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10337, DOI 10.1109/ICCV48922.2021.01019
   Stergiou A, 2021, PATTERN RECOGN LETT, V141, P1, DOI 10.1016/j.patrec.2020.11.012
   Straczkiewicz M, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00514-4
   Subramaniam RR, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103132
   Thambusamy V., 2018, IntJPureApplMath, V118, P3681, DOI DOI 10.3390/CANCERS14092132
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   Ullah A, 2019, IEEE T IND ELECTRON, V66, P9692, DOI 10.1109/TIE.2018.2881943
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Xiao ZW, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107338
   Xiaomin Ouyang, 2021, MobiSys '21: Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services, P54, DOI 10.1145/3458864.3467681
   Xin M, 2016, NEUROCOMPUTING, V178, P87, DOI 10.1016/j.neucom.2015.09.112
   Yang HD, 2019, J INTELL FUZZY SYST, V36, P775, DOI 10.3233/JIFS-18209
   Yang X, 2021, J ARTIFICIAL INTELLI, V1, P51, DOI [DOI 10.37965/JAIT.2020.0051, 10.37965/jait.2020.0051]
   Zhang SB, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041476
   Zhao H, 2019, IEEE I CONF COMP VIS, P8667, DOI 10.1109/ICCV.2019.00876
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17289-3
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900004
DA 2024-07-18
ER

PT J
AU Deepa, R
   Sharmila, TS
   Niruban, R
AF Deepa, R.
   Sharmila, T. Sree
   Niruban, R.
TI Dynamic graph neural network-based computational paradigm for video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video summarization; Dynamic graph neural network; Video summary;
   Spectral filter; Autoregressive moving average filter
AB In recent times, there has been a significant amount of interest in video summary technology. The reason behind video summarizing is to condense the information from the original video into a concise yet comprehensive summary, resulting in a brief and easy-to-understand version. In this study, looking at video summarization as an examination of graph issues and proposing a dynamic graph neural network to quantify the significance of individual videos and their overall contribution to the collection are covered. In prior graph network-based techniques, a single graph neural network (GNN) had often been used. The advantages of various graph filters or graph neural networks have not been fully exploited. The problem of oversmoothing still exists with traditional GNNs. To address issues like the one mentioned above, a spectral filter and an autoregressive moving average filter for the dynamic graph neural network have been proposed. In addition, a regularization of diversity to promote the model and provide a diverse summary has been recommended. Numerous tests have been run, and innovative and conventional graph models have been compared with the most advanced video summarizing techniques. The F-score for the two datasets got a big boost from 1.9 to 3.1% when the proposed method was used.
C1 [Deepa, R.] Anand Inst Higher Technol, Dept Artificial Intelligence & Data Sci, Chennai 603103, Tamil Nadu, India.
   [Sharmila, T. Sree] Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai 600025, Tamil Nadu, India.
   [Niruban, R.] St Josephs Coll Engn, OMR, Dept Elect & Commun Engn, Chennai 600119, India.
C3 Anna University; Anna University Chennai; St. Joseph's College of
   Engineering, Chennai
RP Deepa, R (corresponding author), Anand Inst Higher Technol, Dept Artificial Intelligence & Data Sci, Chennai 603103, Tamil Nadu, India.
EM deepar.cse.89@gmail.com
RI R, Niruban/AAH-7599-2020
OI R, Niruban/0000-0001-9048-9695; T, Sree Sharmila/0009-0009-1736-2669
CR [Anonymous], 2013, Iberoamerican Congress on Pattern Recognition
   Cahuina Edward J. Y. Cayllahua, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P226, DOI 10.1109/SIBGRAPI.2013.39
   Chellaswamy C, 2018, MEAS SCI TECHNOL, V29, DOI 10.1088/1361-6501/aabe48
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Defferrard M, 2016, ADV NEUR IN, V29
   Demir M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1071, DOI 10.1109/ICCVW.2015.140
   Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582
   Fei MJ, 2018, NEUROCOMPUTING, V275, P1911, DOI 10.1016/j.neucom.2017.10.030
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   Feng H, 2022, OCEAN ENG, V266, DOI 10.1016/j.oceaneng.2022.112960
   Gao GY, 2023, NEURAL NETWORKS, V158, P121, DOI 10.1016/j.neunet.2022.11.009
   Ghorvei M, 2023, NEUROCOMPUTING, V517, P44, DOI 10.1016/j.neucom.2022.10.057
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hannane R, 2018, J VIS COMMUN IMAGE R, V55, P179, DOI 10.1016/j.jvcir.2018.06.002
   Hannane R, 2016, I C COMP GRAPH IM VI, P312, DOI 10.1109/CGiV.2016.67
   Harakannanavar S S., 2022, Glob. Transit. Proc, V3, P131, DOI DOI 10.1016/J.GLTP.2022.04.009
   He XF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2296, DOI 10.1145/3343031.3351056
   Huang WC, 2023, INFORM FUSION, V91, P261, DOI 10.1016/j.inffus.2022.10.006
   Ji Z, 2019, INFORM SCIENCES, V478, P152, DOI 10.1016/j.ins.2018.09.050
   Jiang JJ, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107707
   Jung Y, 2019, AAAI CONF ARTIF INTE, P8537
   Kannappan S, 2019, PATTERN RECOGN LETT, V120, P8, DOI 10.1016/j.patrec.2018.12.017
   Karnyoto AS, 2022, INT J MACH LEARN CYB, V13, P2033, DOI 10.1007/s13042-021-01503-5
   Li P, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107677
   Liu JL, 2022, IEEE T INTELL TRANSP, V23, P1755, DOI 10.1109/TITS.2020.3026025
   Ma MY, 2019, IEEE ACCESS, V7, P11763, DOI 10.1109/ACCESS.2019.2891834
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Qiu MY, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106177
   Wu DS, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109849
   Yoon UN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134562
   Zang SS, 2023, NEUROCOMPUTING, V519, P26, DOI 10.1016/j.neucom.2022.11.028
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang M, 2023, MEASUREMENT, V207, DOI 10.1016/j.measurement.2022.112378
   Zhao M, 2022, INFORM SCIENCES, V600, P73, DOI 10.1016/j.ins.2022.03.082
   Zhou K, 2018, Video summarisation by classification with deep reinforcement learning, ppp1, DOI [10.48550/arXiv.1807.03089, DOI 10.48550/ARXIV.1807.03089]
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17412-4
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100008
DA 2024-07-18
ER

PT J
AU Alghamdi, J
   Luo, SH
   Lin, YQ
AF Alghamdi, Jawaher
   Luo, Suhuai
   Lin, Yuqing
TI A comprehensive survey on machine learning approaches for fake news
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake news; Fake news detection; Misinformation
ID FALSE NEWS; MISINFORMATION; LANGUAGE; DECEPTION; REPRESENTATIONS;
   DISINFORMATION; NETWORK; WORDS; MODEL; CUES
AB The proliferation of fake news on social media platforms poses significant challenges to society and individuals, leading to negative impacts. As the tactics employed by purveyors of fake news continue to evolve, there is an urgent need for automatic fake news detection (FND) to mitigate its adverse social consequences. Machine learning (ML) and deep learning (DL) techniques have emerged as promising approaches for characterising and identifying fake news content. This paper presents an extensive review of previous studies aiming to understand and combat the dissemination of fake news. The review begins by exploring the definitions of fake news proposed in the literature and delves into related terms and psychological and scientific theories that shed light on why people believe and disseminate fake news. Subsequently, advanced ML and DL techniques for FND are dicussed in detail, focusing on three main feature categories: content-based, context-based, and hybrid-based features. Additionally, the review summarises the characteristics of fake news, commonly used datasets, and the methodologies employed in existing studies. Furthermore, the review identifies the challenges current FND studies encounter and highlights areas that require further investigation in future research. By offering a comprehensive overview of the field, this survey aims to serve as a guide for researchers working on FND, providing valuable insights for developing effective FND mechanisms in the era of technological advancements.
C1 [Alghamdi, Jawaher; Luo, Suhuai; Lin, Yuqing] Univ Newcastle, Sch Informat & Phys Sci, Newcastle, Australia.
   [Alghamdi, Jawaher] King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
C3 University of Newcastle; King Khalid University
RP Alghamdi, J (corresponding author), Univ Newcastle, Sch Informat & Phys Sci, Newcastle, Australia.; Alghamdi, J (corresponding author), King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
EM jawaher.alghamdi@uon.edu.au; suhuai.luo@newcastle.edu.au;
   yuqing.lin@newcastle.edu.au
OI Alghamdi, Jawaher/0000-0003-3242-2841
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. This study was not funded by any organization.
CR AGE JITD, 2022, Journalism in the digital age, the echo chamber effect
   Aggarwal A, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.163973
   Ahmad I, 2020, Complexity 2020
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Alghamdi Jawaher, 2022, 2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR), P354, DOI 10.1109/MIPR54900.2022.00069
   Alghamdi J, 2022, 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, ICMLA, P148, DOI 10.1109/ICMLA55696.2022.00028
   Alghamdi J, 2023, KNOWL-BASED SYST, V274, DOI 10.1016/j.knosys.2023.110642
   Alghamdi J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053345
   Alghamdi J, 2022, INFORMATION, V13, DOI 10.3390/info13120576
   Alhindi Tariq, 2018, P 1 WORKSH FACT EXTR, P85, DOI 10.18653/v1/W18-5513
   Ali M, 2008, COMMUN REP, V21, P82, DOI 10.1080/08934210802381862
   Allcott H, 2019, RES POLITICS, V6, DOI 10.1177/2053168019848554
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2000, Detecting lies and deceit: the psychology of lying and implications for professional practice
   Arun AS, 2022, COMPUTATIONAL METHOD, P379
   Asch SE, 1961, Documents of gestalt psychology, P222, DOI 10.1525/9780520313514-017
   ASHFORTH BE, 1989, ACAD MANAGE REV, V14, P20, DOI 10.2307/258189
   Azzimonti M, 2018, NBER Working Papers, V24462
   Bajaj S, 2017, fake news detection using deep learning
   Bakir V, 2018, DIGIT JOURNAL, V6, P154, DOI 10.1080/21670811.2017.1345645
   Balint Peter, 2009, Orv Hetil, V150, P1430, DOI 10.1556/OH.2009.HO2256
   Bandyopadhyay S, 2020, Xeno J Biomed Sci, V1, P1, DOI [10.20944/preprints202006.0243.v1, DOI 10.20944/PREPRINTS202006.0243.V1]
   Baruah A, 2020, CLEF
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Basu S, 1997, J ACCOUNT ECON, V24, P3, DOI 10.1016/S0165-4101(97)00014-1
   Ben Veyseh AP, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P113, DOI 10.1145/3341161.3342896
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bergmann J., 1993, DISCREET INDISCRETIO
   Bessi A., 2016, First Monday, V21, DOI 10.5210/fm.v21i11.7090
   Bharadwaj P, 2019, Int J Nat Language Comput (IJNLC), V8
   Bode L, 2015, J COMMUN, V65, P619, DOI 10.1111/jcom.12166
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   BUCKNER HT, 1965, PUBLIC OPIN QUART, V29, P54, DOI 10.1086/267297
   Burgoon JK, 2003, LECT NOTES COMPUT SC, V2665, P91
   Burlot F, 2017, TRAIT AUTOM LANG, V58, P98
   Carson J, 2018, Telegraph, V28
   Castelo S, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P975, DOI 10.1145/3308560.3316739
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Centre FH, 2022, How is facebook addressing false information through independent fact-checkers?
   Chaudhari S, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465055
   Chen WL, 2016, 7TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE IEEE IEMCON-2016
   Chen Y., 2015, Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection, P15, DOI 10.1145/2823465.2823467
   Cheng Chang, 2016, Advanced Data Mining and Applications. 12th International Conference, ADMA 2016. Proceedings: LNAI 10086, P751, DOI 10.1007/978-3-319-49586-6_54
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Chua Alton Y. K., 2016, International Multiconference of Engineers and Computer Scientists 2016 (IMECS). Proceedings, P387
   Cohen M., 2017, Business Information Review, V34, P81
   Coleman K, 2022, Introducing Birdwatch, a community-based approach to misinformation
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Cunha Evandro, 2018, Social Informatics. 10th International Conference, SocInfo 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11185), P151, DOI 10.1007/978-3-030-01129-1_10
   DAMASHEK M, 1995, SCIENCE, V267, P843, DOI 10.1126/science.267.5199.843
   de Oliveira NR, 2021, INFORMATION, V12, DOI 10.3390/info12010038
   Del Vicario M, 2016, SCI REP-UK, V6, DOI 10.1038/srep37825
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Derczynski L, 2014, EUR SEM WEB C ESWC
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Dictionary C, 2022, Collins 2017 word of the year shortlist
   DiFranzo D., 2017, XRDS: crossroads, the ACM magazine for students, V23, P32, DOI [10.1145/3055153, DOI 10.1145/3055153]
   Dizikes P, 2018, Study: On Twitter, false news travels faster than true stories
   Domonoske C., 2016, Students have "dismaying" inability to tell fake news from real, study finds
   Dou YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2051, DOI 10.1145/3404835.3462990
   Edkins B, 2016, Studies show they can't
   Elhadad Mohamed K., 2020, Advances on P2P, Parallel, Grid, Cloud and Internet Computing. Proceedings of the 14th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC-2019). Lecture Notes in Networks and Systems (LNNS 96), P914, DOI 10.1007/978-3-030-33509-0_86
   Enayet Omar, 2017, P 11 INT WORKSH SEM, P470, DOI 10.18653/v1/S17-2082
   Fallis D, 2014, ICONFERENCE 2014 P
   Fallis D, 2009, Proceedings of the iConference
   Ferrara Emilio, 2018, First Monday, V22, DOI 10.5210/fm.v22i18.8005
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Fetzer JH, 2004, MIND MACH, V14, P231, DOI 10.1023/B:MIND.0000021683.28604.5b
   FISHER RJ, 1993, J CONSUM RES, V20, P303, DOI 10.1086/209351
   FREEDMAN JL, 1965, ADV EXP SOC PSYCHOL, V2, P57
   Friggeri Adrien, 2014, 8 INT AAAI C WEBL SO
   Fuller CM, 2009, DECIS SUPPORT SYST, V46, P695, DOI 10.1016/j.dss.2008.11.001
   Funke D, 2017, Poynter
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Gautam AVV, 2021, arXiv, DOI [10.48550/ARXIV.2101.11425, DOI 10.48550/ARXIV.2101.11425]
   Gelfert A, 2013, Rumor and communication in Asia in the internet age, P34
   Gelfert A, 2018, INFORMAL LOG, V38, P84, DOI 10.22329/il.v38i1.5068
   Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Goldman Alving., 2008, Information Technology and Moral Philosophy, P111
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Graves A, 2014, Arxiv, DOI arXiv:1308.0850
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Gupta A, 2012, Technical Report
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Gupta M., 2012, P 2012 SIAM INT C DA, DOI [10.1137/1.9781611972825.14, DOI 10.1137/1.9781611972825.14]
   Gururangan S, 2020, Arxiv, DOI [arXiv:2004.10964, DOI 10.48550/ARXIV.2004.10964]
   Hancock JT, 2008, DISCOURSE PROCESS, V45, P1, DOI 10.1080/01638530701739181
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   HERNON P, 1995, GOV INFORM Q, V12, P133, DOI 10.1016/0740-624X(95)90052-7
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horne Benjamin, 2017, This Just in: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire Than Real News, V11, P759
   Horne L, 2020, P 1 C AS PAC CHAPT A, P130
   Hosseinzadeh S, 2019, POLYM BULL, V76, P4827, DOI 10.1007/s00289-018-2618-1
   Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146, 10.48550/arXiv.1801.06146]
   Hu X, 2013, 23 INT JOINT C ART I, P2633
   HUFFPOST, 2022, 1,000 paid russian trolls spread fake news on hillary clinton, senate intelligence heads told
   INDEPENDENT, 2022, Twitter to delete 6% of all accounts in huge cull
   Institute OI, 2022, Resource for understanding political bots
   Jain S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2015, DOI 10.1109/ICACCI.2016.7732347
   Jamieson K. H., 2008, ECHO CHAMBER RUSH LI
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2016, AAAI CONF ARTIF INTE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Joachims T., 1997, International conference on machine learning, P143, DOI DOI 10.1016/J.ESWA.2016.09.009
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   JOHNSON MK, 1981, PSYCHOL REV, V88, P67, DOI 10.1037/0033-295X.88.1.67
   Jones E.E., 1976, New directions in attribution research, V1, P389
   Jones M., 1990, FAKE ART DECEPTION
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Kapferer Jean-Noel., 1990, RUMORS USES INTERPRE
   Khan JY., 2021, Mach Learn App, V4
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Klein DO, 2018, Australasian Policing, V10
   Knapp M.L., 1974, HUM COMMUN RES, V1, P15, DOI [10.1111/j.1468-2958.1974.tb00250.x, DOI 10.1111/J.1468-2958.1974.TB00250.X]
   Koloski B, 2022, Arxiv, DOI [arXiv:2110.10457, DOI arXiv:2110.10457.v1, DOI 10.1016/J.NEUCOM.2022.01.096]
   Kshetri N, 2017, IT PROF, V19, P8, DOI 10.1109/MITP.2017.4241459
   Kucharski A, 2016, NATURE, V540, P525, DOI 10.1038/540525a
   Kula Sebastian, 2021, 13th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2020). Advances in Intelligent Systems and Computing (AISC 1267), P239, DOI 10.1007/978-3-030-57805-3_23
   Kumar S, 2018, Arxiv, DOI [arXiv:1804.08559, 10.48550/arXiv.1804.08559]
   Kumar S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P591, DOI 10.1145/2872427.2883085
   Kwak Haewoon, 2010, WWW 10 P 19 INT C WO, P591, DOI DOI 10.1145/1772690.1772751
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Langin K, 2018, Science magazine
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lendvai P, 2016, Arxiv, DOI arXiv:1611.02588
   Li CL, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4281
   Li Q, 2016, P INT AAAI C WEB SOC
   Li Q., 2019, P NAACL HLT 2019 INT, P855, DOI [10.18653/v1/s19-2148, DOI 10.18653/V1/S19-2148]
   Lilleker D, 2017, Evidence to the Culture, Media and Sport Committee 'Fake news' inquiry presented by the Faculty for Media Communication
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Long Q., 2017, P INT JOINT C NAT LA, P252
   Ma J., 2018, Rumor Detection on Twitter with Tree-Structured Recursive Neural Networks
   Ma J., 2015, P 24 ACM INT C INF K, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   MAGAZINE P, 2022, The long and brutal history of fake news
   MarketWatch, 2022, This day in history: Hacked ap tweet about white house explosions triggers panic
   Markines B, 2009, P 5 INT WORKSHOP ADV, P41, DOI 10.1145/1531914.1531924
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   McCornack SA, 2014, J LANG SOC PSYCHOL, V33, P348, DOI 10.1177/0261927X14534656
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mitra T, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P126, DOI 10.1145/2998181.2998351
   Mitra Tanushree., 2015, CREDBANK LARGE SCALE
   Molina MD, 2021, AM BEHAV SCI, V65, P180, DOI 10.1177/0002764219878224
   Mukherjee Arjun, 2013, P INT AAAI C WEB SOC, DOI DOI 10.1609/ICWSM.V7I1.14389
   Muller M., 2020, arXiv
   Mustafaraj E, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P235, DOI 10.1145/3091478.3091523
   Myslinski LJ, 2012, Google Patents, Patent No. [8,185,448, 8185448]
   Howard PN, 2018, Arxiv, DOI arXiv:1802.03573
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   News B, Coronavirus: PM says everyone should avoid office, pubs and travelling
   News B, 2022, China investigates search engine baidu after student's death
   News U, 2022, During this coronavirus pandemic, 'fake news' is putting lives at risk: Unesco
   Vo N, 2018, ACM/SIGIR PROCEEDINGS 2018, P275, DOI 10.1145/3209978.3210037
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175, DOI DOI 10.1037/1089-2680.2.2.175
   Nyhan B, 2010, POLIT BEHAV, V32, P303, DOI 10.1007/s11109-010-9112-2
   O'Donovan J, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P293, DOI 10.1109/SocialCom-PASSAT.2012.128
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   Oremus W, 2016, Stop calling everything fake news
   Pal A, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER COMMUNICATIONS (ITCC 2019), P66, DOI 10.1145/3355402.3355415
   Papadopoulou O, 2017, Arxiv, DOI arXiv:1710.08528
   Pariser E., 2011, FILTER BUBBLE WHAT I, DOI DOI 10.3139/9783446431164
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Patwa P., 2021, COMBATING ONLINE HOS, P21, DOI DOI 10.1007/978-3-030-73696-5_3
   Pauca VP, 2004, SIAM PROC S, P452
   Paul C, 2016, Rand Corporation, V2, P1
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pennycook G., 2017, Journal of Personality, V88, P1, DOI [10.2139/ssrn.3023545, DOI 10.2139/SSRN.3023545]
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Pierri F, 2019, SIGMOD REC, V48, P18, DOI 10.1145/3377330.3377334
   Pisarevskaya D, 2017, P 2017 EMNLP WORKSH, P74
   Plothow R, 2017, Post-Register, P5
   Popat K, 2018, Arxiv, DOI arXiv:1809.06416
   Potthast M, 2017, Arxiv, DOI [arXiv:1702.05638, DOI 10.48550/ARXIV.1702.05638]
   Poynter, 2022, Fighting the infodemic: The #coronavirusfacts alliance
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Qazvinian V., 2011, RUMOR HAS IT IDENTIF
   Qian F, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3834
   Qian SS, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P153, DOI 10.1145/3404835.3462871
   Qin YM, 2016, Arxiv, DOI [arXiv:1611.06322, DOI 10.48550/ARXIV.1611.06322]
   Quattrociocchi W, 2016, Echo chambers on facebook
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Research P, 2022, News use across social media platforms 2016
   Rich PR, 2016, J EXP PSYCHOL LEARN, V42, P62, DOI 10.1037/xlm0000155
   Riedel B, 2018, Arxiv, DOI arXiv:1707.03264
   Rini R, 2017, KENNEDY INST ETHIC J, V27, P43, DOI 10.1353/ken.2017.0025
   Ross L, 1996, J PIAGET SY, P103
   Roth Y, 2022, Updating our approach to misleading information
   Rowe M, 2009, SPOT ESWC
   Roy A, 2018, Arxiv, DOI arXiv:1811.04670
   Rubin Victoria L., 2017, Deception Detection and Rumor Debunking for Social Media, book section 21
   Rubin Victoria L., 2015, Proceedings of the Association for Information Science and Technology, V52, P1, DOI [10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Rubin VL, 2016, P 2 WORKSH COMP APPR, P7
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sadeghi F, 2020, Fake news detection on social media using a natural language inference approach, DOI [10.21203/rs.3.rs-107893/v1, DOI 10.21203/RS.3.RS-107893/V1]
   Salton G., 1986, Mcgill, Michael
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Sardelich M, 2018, Arxiv, DOI [arXiv:1812.10479, 10.48550/ARXIV.1812.10479]
   Shao CC, 2018, Arxiv, DOI arXiv:1707.07592
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shifath SMSUR, 2021, arXiv
   Shu K, 2018, FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media
   Shu K, 2017, arXiv:1712.07709, V8
   Shu K, 2017, Arxiv, DOI [arXiv:1708.01967, DOI 10.48550/ARXIV.1708.01967]
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Shushkevich E, 2021, Arxiv, DOI arXiv:2101.05701
   Silverman C., 2016, This Analysis Shows How Viral Fake Election News StoriesOutperformed Real News on Facebook
   Singh Bali Arvinder Pal., 2019, International conference on advances in computing and data sciences, P420, DOI 10.1007/978-981-13-9942-8_40
   Singh V, 2017, INT C SOC COMP BEH C, P1
   Singh VK, 2021, J ASSOC INF SCI TECH, V72, P3, DOI 10.1002/asi.24359
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437
   Southwell BG, 2017, AM SCI, V105, P372
   Stone R, 2022, Anatomy of a fake news scandal
   Sundar SS, 2001, J COMMUN, V51, P52, DOI 10.1111/j.1460-2466.2001.tb02872.x
   Sunstein CassR., 2014, On Rumors
   Sunstein CR, 2001, Echo chambers: Bush v. Gore, impeachment, and beyond
   Tacchini E, 2017, Arxiv, DOI arXiv:1704.07506
   Tajfel H., 1986, Psychology of intergroup relations, P7
   Tajfel H., 1979, The social psychology of intergroup relations, P33
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Thorne J, 2018, Arxiv, DOI arXiv:1803.05355
   Trends G, 2022, fake news-explore-google trends
   Trstenjak B, 2014, PROCEDIA ENGINEER, V69, P1356, DOI 10.1016/j.proeng.2014.03.129
   TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574
   Undeutsch, 1967, HDB PSYCHOL, V11, P26
   Vlachos A., 2014, P ACL 2014 WORKSH LA, P18, DOI [DOI 10.3115/V1/W14-2508, 10.3115/v1/W14-2508]
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S., 2015, Automatic Detection and Verification of Rumors on Twitter
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wallach H. M., 2006, P 23 INT C MACH LEAR, V23, P977, DOI DOI 10.1145/1143844.1143967
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wani A., 2021, CombatingOnline Hostile Posts in Regional Languages During Emergency Situation, P153
   Wardle C., 2017, FAKE NEWS ITS COMPLI, V16, P1
   Weedon J, 2017, Information operations and Facebook
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu L., 2016, Big Data Complex Soc. Netw., P135
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2560
   Wynne HE, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P669, DOI 10.1145/3366030.3366116
   Yang F., 2012, P ACM SIGKDD WORKSHO, P1
   Wang WY, 2017, Arxiv, DOI arXiv:1705.00648
   Yang Y, 2018, arXiv:1806.00749, P2
   Ying L, 2021, IEEE ACCESS, V9, P132363, DOI 10.1109/ACCESS.2021.3114093
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zafarani Reza, 2014, Social Media Mining, DOI [DOI 10.1017/CBO9781139088510, 10.1017/CBO9781139088510]
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
   Zajonc RB, 2001, CURR DIR PSYCHOL SCI, V10, P224, DOI 10.1111/1467-8721.00154
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zhang HL, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2885494
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f
   Zhou XY, 2019, Arxiv, DOI arXiv:1906.04210
   Zhou XY, 2020, Arxiv, DOI arXiv:1904.11679
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
   Zubiaga A., 2017, P INT C SOCIAL INFOR, P109, DOI [10.1007/978-3-319-67217-5_8SeriesTitle:LectureNotesinComputerScience, DOI 10.1007/978-3-319-67217-5_8SERIESTITLE:LECTURENOTESINCOMPUTERSCIENCE, 10.1007/978-3-319-67217-58]
   Zubiaga A, 2016, Arxiv, DOI arXiv:1609.09028
   Zubiaga A, 2016, Arxiv, DOI arXiv:1610.07363
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
   Zuckerman M., 1981, Advances in experimental social psychology, V14, P1, DOI DOI 10.1016/S0065-2601(08)60369-X
NR 287
TC 2
Z9 2
U1 27
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17470-8
EA NOV 2023
PG 59
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700007
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, WJ
   Ding, YJ
   Zhang, MH
   Zhang, YH
   Cao, L
   Huang, ZQ
   Wang, J
AF Zhang, Wanjun
   Ding, Yujie
   Zhang, Miaohui
   Zhang, Yonghua
   Cao, Lvchen
   Huang, Ziqing
   Wang, Jun
TI TCPCNet: a transformer-CNN parallel cooperative network for low-light
   image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light image enhancement; Transformer; Transformer-CNN
ID ILLUMINATION
AB Recently, deep learning has made impressive achievements in low-light image enhancement. Most existing deep learning-based methods use convolutional neural networks (CNN) by stacking network depth and modifying network architecture to improve feature extraction capabilities and restore degraded images. However, these methods have obvious defects. Although CNN excels at extracting local features, its small receptive field is unable to capture the global brightness, leading to overexposure. The Transformer model from natural language processing has recently produced positive outcomes in a variety of computer vision issues thanks to its excellent global modeling capabilities. However, its complex modeling method makes it difficult to capture local details and takes up many computing resources, making it challenging to apply to the enhancement of low-light images, especially high-resolution images. Based on deep convolution and Transformer characteristics, this paper proposes a Transformer-CNN Parallel Cooperative Network (TCPCNet), which supplements image details and local brightness while ensuring global brightness control. We also changed the calculation method of the traditional Transformer to be applied to enhance high-resolution low-light images without affecting performance. Extensive experiments on public datasets show that the proposed TCPCNet achieves comparable performance against the state-of-the-art approaches.
C1 [Zhang, Wanjun] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475001, Peoples R China.
   [Ding, Yujie; Zhang, Miaohui; Zhang, Yonghua; Cao, Lvchen; Huang, Ziqing; Wang, Jun] Henan Univ, Sch Artificial Intelligence, Zhengzhou 450046, Peoples R China.
C3 Henan University; Henan University
RP Wang, J (corresponding author), Henan Univ, Sch Artificial Intelligence, Zhengzhou 450046, Peoples R China.
EM auwangjun@henu.edu.cn
FU This work was supported in part by the National Natural Science
   Foundation of China (No. 62002100, No. 62202142), Key Scientific
   Research Projects of Colleges and Universities in Henan Province (No.
   23A520011),Key Research and Promotion Projects of Henan P [62002100,
   62202142]; National Natural Science Foundation of China [23A520011]; Key
   Scientific Research Projects of Colleges and Universities in Henan
   Province [212102311014, 222102210215, 232102211089, 232102320061]; Key
   Research and Promotion Projects of Henan Province
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 62002100, No. 62202142), Key Scientific
   Research Projects of Colleges and Universities in Henan Province (No.
   23A520011),Key Research and Promotion Projects of Henan Province (No.
   212102311014, No.222102210215, No.232102211089, No. 232102320061 ).
CR Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan MH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2317, DOI 10.1145/3394171.3413757
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hu JJ, 2019, IEEE I CONF COMP VIS, P3868, DOI 10.1109/ICCV.2019.00397
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F., 2018, P BMVC, V220, P4
   Lv FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1450, DOI 10.1145/3394171.3413925
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Milan A, 2018, IEEE INT CONF ROBOT, P1908
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nakai K, 2013, I S INTELL SIG PROC, P445, DOI 10.1109/ISPACS.2013.6704591
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2015, DOI 10.1145/3343031.3350983
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Wu WH, 2022, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR52688.2022.00581
   Zhang HC, 2019, IEEE I CONF COMP VIS, P8798, DOI 10.1109/ICCV.2019.00889
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
NR 40
TC 0
Z9 0
U1 9
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17527-8
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500010
DA 2024-07-18
ER

PT J
AU Girdhar, N
   Doucet, A
AF Girdhar, Nancy
   Doucet, Antoine
TI <i>Can we please everyone?</i> Group recommendations in signed social
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Signed social networks; Group recommender systems; Status theory; Status
   factor; Genetic algorithm; GA k-means
ID CHALLENGES; SYSTEMS; TRUST
AB The ubiquity of social networks and the unprecedented growth in web data have generated an ample resource of information for researchers as well as for market analysts to generate user-oriented recommendations. While many social recommender systems have been designed for individual users, some have been proposed for a group of users intended to handle the data overload and mine useful insights for them. Nevertheless, most of these systems consider all relations to be equal and friendly, disregarding the fact that relations can be unfriendly and varying in strength as in signed social networks. Very limited literature deals with recommender systems for these networks which imitate real-world situations where users have both positive and negative relations, and none have yet been developed for group recommender systems for signed social networks. To address this gap, this work proposes a novel group recommender system for signed social networks that employ the GA k-means approach to combine users' personality and demographic features to identify circles, incorporate a status factor to estimate the influence of other users in group decision-making, and generate circle-based recommendations for the identified groups. Performance analysis conducted on the Epinions dataset using F1_score (similar to 87%), nDCG (similar to 97%), and user satisfaction (similar to 83%) performance indicators on varying homogenous and heterogenous group sizes, confirms the efficacy of the proposed approach.
C1 [Girdhar, Nancy; Doucet, Antoine] Univ La Rochelle, L3i Lab, Ave Michel Crepeau, F-17000 La Rochelle, France.
C3 La Rochelle Universite
RP Girdhar, N (corresponding author), Univ La Rochelle, L3i Lab, Ave Michel Crepeau, F-17000 La Rochelle, France.
EM nancy.gr1991@gmail.com; antoine.doucet@univ-lr.fr
OI Girdhar, Nancy/0000-0002-1009-3875
CR Abbasi-Moud Z, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114324
   Bawack Ransome Epie, 2021, Responsible AI and Analytics for an Ethical and Inclusive Digitized Society: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12896), P681, DOI 10.1007/978-3-030-85447-8_56
   Boratto L, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103208
   Chang Y, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103353
   Chao D. L., 2005, P 2005 INT ACM SIGGR, P120, DOI DOI 10.1145/1099203.1099224
   Christensen I, 2016, J INTELL INF SYST, V47, P209, DOI 10.1007/s10844-016-0400-0
   Dhelim S, 2022, ARTIF INTELL REV, V55, P2409, DOI 10.1007/s10462-021-10063-7
   Garcia I, 2012, INFORM SCIENCES, V189, P155, DOI 10.1016/j.ins.2011.11.037
   Gasparetti F, 2021, APPL INTELL, V51, P3975, DOI 10.1007/s10489-020-01962-3
   Girdhar N, 2019, J ASSOC INF SCI TECH, V70, P788, DOI 10.1002/asi.24164
   Girdhar N, 2019, SOFT COMPUT, V23, P12123, DOI 10.1007/s00500-019-03768-z
   Girdhar N, 2019, ADV INTELL SYST, V698, P225, DOI 10.1007/978-981-13-1819-1_22
   Girdhar N, 2019, STUD COMPUT INTELL, V771, P49, DOI 10.1007/978-981-10-8797-4_6
   Girdhar N, 2018, LECT NOTES COMPUT SC, V11278, P306, DOI 10.1007/978-3-030-04021-5_28
   Girdhar N, 2017, COMM COM INF SC, V721, P326, DOI 10.1007/978-981-10-5427-3_35
   Guha R., 2004, P 13 INT C WORLD WID, P403, DOI DOI 10.1145/988672.988727
   Gunawardana Asela, 2012, Recommender systems handbook, P547
   Guo L, 2016, Arxiv, DOI arXiv:1604.04064
   Hamedani MR, 2021, COMPUT SCI INF SYST, V18, P93, DOI 10.2298/CSIS200608039H
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Kim HN, 2015, INFORM SYST, V50, P76, DOI 10.1016/j.is.2014.10.002
   Kim JK, 2010, INT J INFORM MANAGE, V30, P212, DOI 10.1016/j.ijinfomgt.2009.09.006
   Kou HZ, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106942
   Leskovec J., 2010, P 19 INT C WORLD WID, P641, DOI [10.1145/1772690.1772756, DOI 10.1145/1772690.1772756]
   Liao M, 2022, P 2022 CHI C HUM FAC, P1
   Mahyar H, 2017, P 26 INT C WORLD WID, P1187, DOI [10.1145/3041021.3055363, DOI 10.1145/3041021.3055363]
   Márquez JOA, 2016, LECT NOTES COMPUT SC, V9848, P151, DOI 10.1007/978-3-319-44799-5_12
   Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17
   Masthoff Judith, 2012, Recommender Systems Handbook, P381
   McAuley J, 2014, ACM T KNOWL DISCOV D, V8, P73, DOI 10.1145/2556612
   McCarthy J. F., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P363, DOI 10.1145/289444.289511
   McCarthy Joseph F, 2002, WORKSH MOB AD HOC CO, V8
   McCarthy K., 2006, FLAIRS Conference, P86
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Palomares I, 2021, INFORM FUSION, V69, P103, DOI 10.1016/j.inffus.2020.12.001
   Patibandla RL, 2021, Recommender systems, P121
   Pera MS, 2013, INFORM PROCESS MANAG, V49, P673, DOI 10.1016/j.ipm.2012.07.007
   Pérez-Almaguer Y, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115444
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Quijano-Sánchez L, 2015, LECT NOTES ARTIF INT, V9343, P320, DOI 10.1007/978-3-319-24586-7_22
   Quijano-Sanchez L, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414433
   Seo YD, 2017, EXPERT SYST APPL, V69, P135, DOI 10.1016/j.eswa.2016.10.024
   Sojahrood ZB, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119681
   Sojahrood ZB, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114593
   Bin Suhaim A, 2021, IEEE ACCESS, V9, P57440, DOI 10.1109/ACCESS.2021.3072165
   Tang JL, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P31, DOI 10.1145/2872427.2882971
   Teoman HA, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1779, DOI 10.1145/3477314.3507154
   Wang G, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107631
   Wang SL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103031
   Wei Y., 2022, Adv Comput Intell, V2, P1, DOI [10.1007/s43674-021-00019-3, DOI 10.1007/S43674-021-00019-3]
   Xu B., 2013, ICIMCS 2013, P139, DOI DOI 10.1145/2499788.2499827
   Yang Xiwang., 2012, P 18 ACM SIGKDD INT, P1267, DOI [10.1145/2339530.2339728, DOI 10.1145/2339530.2339728]
   Yin HZ, 2019, PROC INT CONF DATA, P566, DOI 10.1109/ICDE.2019.00057
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
   Zeebaree D. Q., 2017, International Journal of Applied Engineering Research, V12, P14238
   Zheng Y, 2022, NEUROCOMPUTING, V474, P141, DOI 10.1016/j.neucom.2021.11.041
   Zuva Tranos, 2021, International Conference on Communication, Computing and Electronics Systems. Proceedings of ICCCES 2020. Lecture Notes in Electrical Engineering (LNEE 733), P325, DOI 10.1007/978-981-33-4909-4_24
NR 57
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17422-2
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900010
DA 2024-07-18
ER

PT J
AU Bayir, T
   Akel, G
AF Bayir, Talha
   Akel, Gokhan
TI Gamification in mobile shopping applications: A review in terms of
   technology acceptance model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Gamification; Mobile shopping applications; Technology acceptance model
ID E-COMMERCE; CONSUMER ACCEPTANCE; USER ACCEPTANCE; PERCEIVED USEFULNESS;
   CUSTOMER EXPERIENCE; SERIOUS GAMES; ONLINE; ADVERGAMES; BRAND; FLOW
AB Businesses add gamification to their mobile shopping applications to increase customer interaction and their continuance intention. It has been observed that, with gamification based mobile shopping activities, consumers have positive experiences, and their customer loyalty has increased. Therefore, it is crucial to research the effects of gamification content used in mobile shopping applications on consumers' tendencies to use or not use technology. This research aims to determine the effect of gamification activities offered in mobile shopping applications on users' perceived ease of use, perceived usefulness, attitude, and intention using the Technology Acceptance Model (TAM). The research used a convenience sample of 442 mobile shopping applications users living in Turkey and an online survey method was used to collect the research data. Considering the analyses of the research, the relationship levels between the variables were determined. There are significant relationships between PEOU and GAM (r = .939), PU and PEOU (r = .874), ATT and PU (r = .827), INT and ATT (r = .969). Reliability and validity analyses were applied. The factor loadings of the scales, and AVE value above .50, Cronbach's Alpha (C alpha), and CR value above .70 were considered statistically reliable and valid. The technique of structural equation modeling (SEM) was used to estimate the variables' effect and mediation levels. Then, it was found that perceived ease of use had a positive and significant mediating effect (beta = .339) between gamification and attitude variables. Similarly, perceived usefulness had a positive and significant (beta = .827) mediating effect between gamification and attitude variables.
C1 [Bayir, Talha] Sirnak Univ, Dept Mkt, Sirnak, Turkiye.
   [Akel, Gokhan] Antalya Akev Univ, Dept Management Informat Syst, Antalya, Turkiye.
C3 Sirnak University; Antalya Akev Universitesi
RP Akel, G (corresponding author), Antalya Akev Univ, Dept Management Informat Syst, Antalya, Turkiye.
EM talhabayir@sirnak.edu.tr; gokhan.akel@belek.edu.tr
RI Akel, Gökhan/IQW-2719-2023
OI Akel, Gökhan/0000-0003-4353-7855
CR Abou-Shouk M, 2021, J DESTIN MARK MANAGE, V20, DOI 10.1016/j.jdmm.2021.100559
   Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   An S, 2011, J ADVERTISING, V40, P43, DOI 10.2753/JOA0091-3367400103
   Aparicio M, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06383
   Ashraf AR, 2016, ELECTRON COMMER R A, V20, P69, DOI 10.1016/j.elerap.2016.10.001
   Aydin C, 2021, Gaziantep Univ J Soc Sci, V20, P1741
   Aydin G, 2015, INT J ONLINE MARKET, V5, P18, DOI 10.4018/IJOM.2015070102
   Azmi L.F., 2021, 2021 INT C ADV TECHN, P1
   Bagozzi RP, 2007, J ASSOC INF SYST, V8, P243
   Baptista G, 2019, COMPUT HUM BEHAV, V92, P306, DOI 10.1016/j.chb.2018.11.030
   Bartoli E., 2018, PSYCHOL BEHAV SCI, V8, P93
   Bayuk J, 2019, INT J BANK MARK, V37, P951, DOI 10.1108/IJBM-04-2018-0086
   Behl A, 2020, J ELECTRON COMMER OR, V18, P1, DOI 10.4018/JECO.2020040101
   Bilgihan A, 2016, INT J QUAL SERV SCI, V8, P102, DOI 10.1108/IJQSS-07-2015-0054
   Bilgihan A, 2014, INF TECHNOL TOUR, V14, P49, DOI 10.1007/s40558-013-0003-3
   Bitrián P, 2021, INT J BANK MARK, V39, P1310, DOI 10.1108/IJBM-02-2021-0074
   Biucky S.T., 2017, INT J ELECT COMMERCE, V8, P173, DOI [10.7903/ijecs.1538, DOI 10.7903/IJECS.1538]
   Browne MW, 1993, Testing structural equation models, DOI DOI 10.1177/0049124192021002005
   Bruner GC, 2005, J BUS RES, V58, P553, DOI 10.1016/j.jbusres.2003.08.002
   Buhalis D, 2020, TOUR REV, V75, P267, DOI 10.1108/TR-06-2019-0258
   Buhalis D, 2019, J SERV MANAGE, V30, P484, DOI 10.1108/JOSM-12-2018-0398
   Bunchball I., 2010, White paper, V9, P1
   Jimenez IAC, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010122
   Catalán S, 2019, J PROD BRAND MANAG, V28, P502, DOI 10.1108/JPBM-07-2018-1929
   Celtek E., 2010, Journal of Vacation Marketing, V16, P267, DOI DOI 10.1177/1356766710380882
   Chau PYK, 2003, J ORG COMP ELECT COM, V13, P123, DOI 10.1207/S15327744JOCE1302_3
   Chen L., 2004, EUR MANAG J, V22, P74, DOI [10.1016/j.emj.2003.11.014, DOI 10.1016/J.EMJ.2003.11.014]
   Chen LD, 2002, INFORM MANAGE-AMSTER, V39, P705, DOI 10.1016/S0378-7206(01)00127-6
   Chen S, 2023, ENVIRON COMMUN, DOI 10.1080/17524032.2023.2213850
   Cho YC., 2015, INT J MANAGEMENT INF, V19, P21, DOI [10.19030/ijmis.v19i1.9086, DOI 10.19030/IJMIS.V19I1.9086]
   Christy KR, 2014, COMPUT EDUC, V78, P66, DOI 10.1016/j.compedu.2014.05.005
   DAVIS FD, 1993, INT J MAN MACH STUD, V38, P475, DOI 10.1006/imms.1993.1022
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Dicheva D, 2015, EDUC TECHNOL SOC, V18, P75
   Domínguez A, 2013, COMPUT EDUC, V63, P380, DOI 10.1016/j.compedu.2012.12.020
   Eagly AH, 2007, SOC COGNITION, V25, P582, DOI 10.1521/soco.2007.25.5.582
   Eisingerich AB, 2019, INT J RES MARK, V36, P200, DOI 10.1016/j.ijresmar.2019.02.003
   Evans NJ, 2019, INT J ADVERT, V38, P364, DOI 10.1080/02650487.2018.1474998
   Fathian M., 2019, Journal of Information Technology Management, V11, P1
   Fedorko I, 2018, MANAG MARK, V13, P1242, DOI 10.2478/mmcks-2018-0034
   Feng YY, 2018, COMPUT HUM BEHAV, V81, P124, DOI 10.1016/j.chb.2017.12.018
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Fishbein Martin., 1975, Attitude, Intention and Behavior: An Introduction to Theory and Research
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   García-Jurado A, 2019, KYBERNETES, V48, P1278, DOI 10.1108/K-07-2018-0350
   Gefen D., 2000, J ASSOC INF SYST, V1, DOI [10.17705/1jais.00008, DOI 10.17705/1JAIS.00008]
   George D, 2010, SPSS for Windows step by step: A simple guide and reference. 11.0 update
   Ghosh T, 2022, PSYCHOL MARKET, V39, P2328, DOI 10.1002/mar.21752
   Ghosh T, 2021, J INTERACT MARK, V55, P52, DOI 10.1016/j.intmar.2021.01.002
   Goh KY, 2014, J ASSOC INF SYST, V15, P388
   Gross ML, 2010, COMPUT HUM BEHAV, V26, P1259, DOI 10.1016/j.chb.2010.03.034
   Haider MJ, 2018, J ISLAMIC MARK, V9, P439, DOI 10.1108/JIMA-11-2016-0082
   Hamari J, 2017, COMPUT HUM BEHAV, V71, P469, DOI 10.1016/j.chb.2015.03.036
   Hamari J, 2015, INT J INFORM MANAGE, V35, P419, DOI 10.1016/j.ijinfomgt.2015.04.006
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Hamari Juho., 2015, The gameful world: Approaches, issues, applications
   Haque A., 2006, The journal of applied business research, V22, P119
   Hendrickson AR, 1996, DATA BASE ADV INF SY, V27, P61
   Hernandez M.D., 2004, J INTERACTIVE ADVERT, V4, P116, DOI [10.1080/15252019.2004.10722095, DOI 10.1080/15252019.2004.10722095]
   Herz M, 2019, TECHNOL FORECAST SOC, V138, P228, DOI 10.1016/j.techfore.2018.09.008
   Hsu CL, 2018, TECHNOL FORECAST SOC, V132, P118, DOI 10.1016/j.techfore.2018.01.023
   Hsu CL, 2016, TECHNOL FORECAST SOC, V108, P42, DOI 10.1016/j.techfore.2016.04.012
   Hsu CL, 2004, INFORM MANAGE-AMSTER, V41, P853, DOI 10.1016/j.im.2003.08.014
   Hsu CL, 2023, Decision Support Systems
   Huh J, 2015, J ADVERTISING, V44, P360, DOI 10.1080/00913367.2014.1003666
   Huseynli B, 2018, ISTANB BUS RES, V47, P64, DOI 10.26650/ibr.2018.47.1.0004
   Huseynov F., 2020, Digital innovations for customer engagement, management, and organizational improvement, P144
   Hwang J, 2020, J BUS RES, V106, P365, DOI 10.1016/j.jbusres.2019.01.031
   Insley V, 2014, INT J RETAIL DISTRIB, V42, P340, DOI 10.1108/IJRDM-01-2013-0030
   Jang S, 2018, J BUS RES, V92, P250, DOI 10.1016/j.jbusres.2018.07.056
   Johnson Daniel, 2016, Internet Interv, V6, P89, DOI 10.1016/j.invent.2016.10.002
   Jokar NK, 2017, J ETHNOPHARMACOL, V207, P203, DOI 10.1016/j.jep.2017.06.017
   Kalayci S., 2006, SPSS Applied Multivariate statistics techniques, V5
   Kamboj S, 2020, J ELECTRON COMMER OR, V18, P17, DOI 10.4018/JECO.2020040102
   Kang J.M., 2013, Journal of Customer Behavior, V12, P53
   Karac J, 2017, LECT NOTES COMPUT SC, V10294, P41, DOI 10.1007/978-3-319-58484-3_4
   Kasurinen J, 2018, COMPUT SCI REV, V27, P33, DOI 10.1016/j.cosrev.2017.10.003
   Kelloway E. K., 2015, Using LISREL for structural equation modeling: A researchers' guide, V2nd ed.).
   Khan S., 2021, Research anthology on e-commerce adoption, models, and applications for modern business, P1612
   Kim K, 2017, INT J ADVERT, V36, P227, DOI 10.1080/02650487.2015.1096100
   Kunkel T, 2023, EUR J MARKETING, V57, P2592, DOI 10.1108/EJM-06-2021-0388
   Larcker D.F., 1980, DECISION SCI, V11, P121, DOI DOI 10.1111/J.1540-5915.1980.TB01130.X
   Lee M, 2007, J ADVERTISING, V36, P75, DOI 10.2753/JOA0091-3367360406
   Legris P, 2003, INFORM MANAGE-AMSTER, V40, P191, DOI 10.1016/S0378-7206(01)00143-4
   Liao ZQ, 2001, INFORM MANAGE, V38, P299, DOI 10.1016/S0378-7206(00)00072-0
   Liu N, 2017, COMPUT HUM BEHAV, V70, P131, DOI 10.1016/j.chb.2016.12.073
   Liu SH, 2009, COMPUT EDUC, V52, P599, DOI 10.1016/j.compedu.2008.11.002
   Lule I., 2012, International Journal of Computing and ICT Research, V6, P31
   Majuri J., 2018, CEUR WORKSH P, P11, DOI DOI 10.1016/J.CHB.2015.08.048
   McEachern MG, 2007, J PROD BRAND MANAG, V16, P168, DOI 10.1108/10610420710751546
   Meydan CH., 2015, Yapisal esitlik modellemesi AMOS uygulamasi (2. Baski)
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Mullins JK, 2020, J BUS RES, V106, P304, DOI 10.1016/j.jbusres.2018.09.023
   Nart S., 2018, Van YYU IIBF J, V3, P48
   O'Cass A., 2003, J RETAIL CONSUM SERV, V10, P81, DOI [10.1016/S0969-6989, DOI 10.1016/S0969-6989]
   Panic K, 2013, J ADVERTISING, V42, P264, DOI 10.1080/00913367.2013.774605
   Parapanos D, 2023, TOUR PLAN DEV, V20, P162, DOI 10.1080/21568316.2022.2107563
   Pavlou PA, 2003, INT J ELECTRON COMM, V7, P101, DOI 10.1080/10864415.2003.11044275
   Perea T, 2004, INT J SERV IND MANAG, V15, P102, DOI 10.1108/09564230410523358
   Phillips L.A., 1994, Journal of Business and Industrial Marketing, V9, P16
   Pikkarainen T, 2004, INTERNET RES, V14, P224, DOI 10.1108/10662240410542652
   Putz L.M., 2019, GAMIFIN, P154
   Qingxiong Ma, 2004, Journal of Organizational and End User Computing, V16, P59, DOI 10.4018/joeuc.2004010104
   Raman P, 2021, YOUNG CONSUM, V22, P387, DOI 10.1108/YC-05-2020-1148
   Ramayah T, 2017, INT J MOB COMMUN, V15, P491, DOI 10.1504/IJMC.2017.086365
   Rapp A, 2019, INT J HUM-COMPUT ST, V127, P1, DOI 10.1016/j.ijhcs.2018.11.007
   Rodrigues LF, 2016, COMPUT HUM BEHAV, V63, P392, DOI 10.1016/j.chb.2016.05.063
   Sarkar JG, 2023, What is in a game? the impact of advergame design and reward elements on gamers' brand patronage
   Schermelleh-Engel K., 2003, METHODS PSYCHOL RES, V8, P23, DOI DOI 10.1002/0470010940
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Shahid A., 2021, Lahore Journal of Business, V10, P29
   Sima N., 2018, Van Yuz Yil Univ Ikt ve Idari Bil Fak Derg, V3, P48
   Suh B., 2003, ELECTRON COMMER R A, V1, P247, DOI [10.1016/s1567-4223(02)00017-0, DOI 10.1016/S1567-4223(02)00017-0]
   Sukmaningsih DW, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P812, DOI [10.1109/ICIMTech50083.2020.9211217, 10.1109/icimtech50083.2020.9211217]
   Sung YH, 2020, COMPUT HUM BEHAV, V106, DOI 10.1016/j.chb.2020.106244
   Terlutter R, 2013, J ADVERTISING, V42, P95, DOI 10.1080/00913367.2013.774610
   Theben A, 2022, APPETITE, V173, DOI 10.1016/j.appet.2022.105936
   Tian ZM, 2023, SOC BEHAV PERSONAL, V51, DOI 10.2224/sbp.12178
   Tuten T.L., 2016, Journal of Marketing Communications, V22, P236, DOI DOI 10.1080/13527266.2013.848821
   van Berlo ZMC, 2021, J ADVERTISING, V50, P179, DOI 10.1080/00913367.2020.1858462
   Van Reijmersdal E, 2009, J ADVERTISING RES, V49, P151, DOI 10.2501/S0021849909090199
   Vanwesenbeeck I, 2017, INT J ADVERT, V36, P520, DOI 10.1080/02650487.2016.1176637
   Vashisht D, 2017, INTERNET RES, V27, P52, DOI 10.1108/IntR-10-2014-0271
   Vashisht D, 2016, COMPUT HUM BEHAV, V63, P162, DOI 10.1016/j.chb.2016.05.022
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Wang QF, 2016, TECHNOL FORECAST SOC, V107, P59, DOI 10.1016/j.techfore.2015.10.024
   Wanick V, 2018, ENTERTAIN COMPUT, V27, P194, DOI 10.1016/j.entcom.2018.07.002
   Warmelink H, 2020, J BUS RES, V106, P331, DOI 10.1016/j.jbusres.2018.09.011
   Wong D, 2022, INFORM TECHNOL PEOPL, V35, P281, DOI 10.1108/ITP-09-2019-0456
   WRIGHT S, 1960, BIOMETRICS, V16, P189, DOI 10.2307/2527551
   Xu FF, 2017, TOURISM MANAGE, V60, P244, DOI 10.1016/j.tourman.2016.11.020
   Xu FF, 2016, J TRAVEL TOUR MARK, V33, P1124, DOI 10.1080/10548408.2015.1093999
   Yang Y, 2017, COMPUT HUM BEHAV, V73, P459, DOI 10.1016/j.chb.2017.03.066
   Yen YS, 2016, COMPUT HUM BEHAV, V65, P31, DOI 10.1016/j.chb.2016.08.017
   Yilmaz C., 2015, J Manag Econ, V22, P355
   Yilmaz V., 2017, Erciyes Univ IIBF J, V57, P1
   Yuan Gao, 2006, Data Base for Advances in Information Systems, V37, P42, DOI 10.1145/1161345.1161353
   Zhang C, 2017, J MARKETING, V81, P132, DOI 10.1509/jm.16.0038
   Zhou L., 2007, J ELECTRON COMMER RE, V8, P41, DOI DOI 10.1086/209376
NR 142
TC 0
Z9 0
U1 12
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-16823-7
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500007
DA 2024-07-18
ER

PT J
AU Bhimavarapu, U
AF Bhimavarapu, Usharani
TI Automatic liver tumor detection and classification using the hyper
   tangent fuzzy C-Means and improved fuzzy SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image Processing; Liver Tumor; Unsupervised clustering; Hyper tangent
ID SEGMENTATION
AB Globally liver diseases are the most life-threatening diseases, and according to global cancer statistics, liver cancer is the most common. Early detection of liver cancer can prevent millions of patients' mortality every year. Automatic liver cancer detection will help radiologists to determine the tumour identification and its severity, and it is also helpful to reduce the occurrence of errors which results in a reduction in the number of deaths from liver cancer. It gives more accurate results in less time, saving the radiologist's effort and time. The proposed model focused on improving the segmenting of liver images and then classifying the liver tumours from the CT images. The present study suggests the hyper tangent Fuzzy C-Means (HTFCM) to segment the liver images. It used Hyper tangent distance to calculate the data point distance from the cluster centres and obtained segmentation results almost closer to the ground truth liver images. Due to the fuzziness in the liver images, all state-of-the-art models except the proposed model cannot precisely locate the tumours. This study solved the issue of linear mapping using fuzzy logic, improved the classification accuracy, and reduced the processing time of early diagnosis of liver diseases. The proposed model improves the classification accuracy to 99.58% and reduces the processing time by 2-25 s to classify the liver tumours.
C1 [Bhimavarapu, Usharani] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bhimavarapu, U (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, India.
EM ushafdp1122@gmail.com
CR Acharya UR, 2018, COMPUT BIOL MED, V94, P11, DOI 10.1016/j.compbiomed.2017.12.024
   Ahmad M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2665283
   Alirr OI, 2018, INT J COMPUT ASS RAD, V13, P1169, DOI 10.1007/s11548-018-1801-z
   Almotairi S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051516
   Amritha M, 2023, 2023 5 INT C EL COMP, P01, DOI [10.1109/icecct56650.2023.10179731, DOI 10.1109/ICECCT56650.2023.10179731]
   [Anonymous], ABOUT LIVER CANCER
   [Anonymous], 2022, Lits-Liver Tumor Segmentation Challenge
   Chlebus G, 2017, Arxiv, DOI [arXiv:1706.00842, 10.48550/arXiv.1706.00842, DOI 10.48550/ARXIV.1706.00842]
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Christ PF, 2016, MED IMAGE COMPUTING
   Dahiya Sonika, 2023, Journal of Ambient Intelligence and Humanized Computing, P3793, DOI 10.1007/s12652-022-04022-5
   Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009
   Deshmukh SP., 2023, Comput Assist Methods Eng Sci, V30, P151, DOI [10.24423/cames.463, DOI 10.24423/CAMES.463]
   Devi RM, 2020, SOFT COMPUT, V24, P18591, DOI 10.1007/s00500-020-05094-1
   Dhruv B, 2023, COMP M BIO BIO E-IV, V11, P197, DOI 10.1080/21681163.2022.2061376
   Dong X, 2020, IEEE ACCESS, V8, P129889, DOI 10.1109/ACCESS.2020.3006362
   Ejegwa PA, 2023, INT J INTELL SYST, V2023, DOI 10.1155/2023/5540085
   Jahne B, 1995, Digit Image Processing, V1, P1
   Jansen MJA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217053
   Kadoury S, 2015, PHYS MED BIOL, V60, P6459, DOI 10.1088/0031-9155/60/16/6459
   Kaya Y, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.104023
   Ke Q, 2019, EXPERT SYST APPL, V126, P218, DOI 10.1016/j.eswa.2019.01.060
   Kozlov OV, 2023, Inartificial Intelligence In Control And Decision-Making Systems: Dedicated To Professor Janusz Kacprzyk, P127, DOI [10.1007/978-3-031-25759-9_7, DOI 10.1007/978-3-031-25759-9_7]
   Lebre MA, 2019, COMPUT BIOL MED, V110, P42, DOI 10.1016/j.compbiomed.2019.04.014
   Lou CL, 2023, NEUROCOMPUTING, V549, DOI 10.1016/j.neucom.2023.126458
   Ma PL, 2023, ARTIF INTELL REV, V56, P1627, DOI 10.1007/s10462-022-10209-1
   Macherla S, 2023, 2023 IEEE INT C INT, P01, DOI [10.1109/icicacs57338.2023.10099828, DOI 10.1109/ICICACS57338.2023.10099828]
   Midya A, 2023, IEEE J BIOMED HEALTH, V27, P2456, DOI 10.1109/JBHI.2023.3248489
   Mishra AP., 2023, Semicond Optoelectron, V42, P34, DOI [10.1109/42.712133, DOI 10.1109/42.712133]
   Othman E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145429
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099
   Phamtoan D, 2023, COMPUTATION STAT, V38, P25, DOI 10.1007/s00180-022-01215-6
   Rahman H, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9080368
   Shynu PG, 2020, 2020 INT C EM TRENDS, P1, DOI [10.1109/ic-ETITE47903.2020.244, DOI 10.1109/IC-ETITE47903.2020.244]
   Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763
   Soler L, 2012, Tech. Rep
   Sowparnika B., 2023, 2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC), P156, DOI 10.1109/ICAAIC56838.2023.10140207
   Suganeshwari G, 2023, BIOMEDICINES, V11, DOI 10.3390/biomedicines11051309
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Wang B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4886
   Yang P, 2020, INT J COMPUT SCI ENG, V22, P146, DOI 10.1504/IJCSE.2020.107266
   Zhou SS, 2021, IEEE T FUZZY SYST, V29, P2810, DOI 10.1109/TFUZZ.2020.3003441
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17430-2
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700002
DA 2024-07-18
ER

PT J
AU Mousavi, A
   Esmaeilpour, M
   Sheikhahmadi, A
AF Mousavi, Ali
   Esmaeilpour, Mansour
   Sheikhahmadi, Amir
TI Two efficient three-term conjugate gradient methods for impulse noise
   removal from medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image processing; Impulse noise removal; Unconstrained optimization;
   Conjugate gradient method; Wolfe line search method
ID CONVERGENCE; DESCENT
AB In this paper, we discuss two efficient three-term conjugate gradient methods (ECG) for impulse noise removal. The directions of ECG are first the direction of steepest descent and then spanned by the three terms: The steepest descent direction, the previous direction, and the gradient differences at the previous and current points. The second and third terms are scaled by two different step sizes called conjugate gradient parameters. Our goal is to generate and control these parameters such that they do not jointly dominate while preserving the effect of all terms, except near the optimizer where the first term dominates the other two terms. They are independent of the line search method and useful for finite precision arithmetic. The global convergence of ECG is proved. The efficiency (the lowest relative cost of function evaluations) and robustness (highest number of solved problems ) of ECG compared to known conjugate gradient methods are shown in terms of PSNR (peak signal noise ratio) and time in seconds.
C1 [Mousavi, Ali; Sheikhahmadi, Amir] Islamic Azad Univ, Dept Comp Engn, Sanandaj Branch, Sanandaj, Iran.
   [Esmaeilpour, Mansour] Islamic Azad Univ, Comp Engn Dept, Hamedan Branch, Hamadan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Esmaeilpour, M (corresponding author), Islamic Azad Univ, Comp Engn Dept, Hamedan Branch, Hamadan, Iran.
EM esmaeilpour@iauh.ac.ir
RI Mousavi, Ali/KOD-6511-2024; Esmaeilpour, Mansour/J-6458-2016
OI Esmaeilpour, Mansour/0000-0002-2475-518X; Mousavi,
   Ali/0009-0002-6835-4836
CR Anisha K.K., 2011, Int. J. Multimed. Appl., V3, P93
   Arman L., 2020, Pacific Journal of Optimization
   Beale E.M. L., 1972, Numerical Methods for Nonlinear Optimization, P39
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Cai JF, 2007, Mathematics and Visualization, P109, DOI [10.1007/978-3-540-33267-1_7, DOI 10.1007/978-3-540-33267-1_7]
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chan TF, 2006, J MATH IMAGING VIS, V25, P107, DOI 10.1007/s10851-006-5257-3
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chen JY, 2020, MULTIMED TOOLS APPL, V79, P23695, DOI 10.1007/s11042-020-09123-x
   Dai YH, 1999, SIAM J OPTIMIZ, V10, P177, DOI 10.1137/S1052623497318992
   Dolan ED, 2002, MATH PROGRAM, V91, P201, DOI 10.1007/s101070100263
   FLETCHER R, 1964, COMPUT J, V7, P149, DOI 10.1093/comjnl/7.2.149
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   Hager WW, 2005, SIAM J OPTIMIZ, V16, P170, DOI 10.1137/030601880
   Halder A, 2022, Advances in Intelligent Systems and Computing, V1349
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Karthikeyan K., 2011, INT J COMPUT APPL, V2, P8, DOI DOI 10.5120/2614-3646
   Kimiaei M, 2019, SOFT COMPUT, V23, P11901, DOI 10.1007/s00500-018-03745-y
   Kimiaei M, 2016, KYBERNETIKA, V52, P791, DOI 10.14736/kyb-2016-5-0791
   LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504
   Liu J, 2020, Numer Linear Algebra Appl, V28
   Nadeem M, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107403
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   POLAK E, 1969, REV FR INFORM RECH O, V3, P35
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Rytsar Y. B., 1997, Proceedings of the SPIE - The International Society for Optical Engineering, V3238, P45, DOI 10.1117/12.284817
   Shah AW, 2022, J KING SAUD UNIV-COM, V34, P505, DOI 10.1016/j.jksuci.2020.03.007
   Shukla HS., 2014, Int J Comput Appl, V107, P11
   Wang L, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102123
   Wang L, 2005, 2005 IEEE International Conference on Industrial Technology - (ICIT), Vols 1 and 2, P97
   WOLFE P, 1971, SIAM REV, V13, P185, DOI 10.1137/1013035
   Yu GH, 2010, SIGNAL PROCESS, V90, P2891, DOI 10.1016/j.sigpro.2010.04.017
   Yu GH, 2010, APPL MATH LETT, V23, P555, DOI 10.1016/j.aml.2010.01.010
   Zhang L, 2006, IMA J NUMER ANAL, V26, P629, DOI 10.1093/imanum/dr1016
   Zhou EL, 2022, APPL ACOUST, V188, DOI 10.1016/j.apacoust.2021.108511
   Zoutendijk G., 1970, Integer and Nonlinear Programming, P37
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17352-z
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000004
DA 2024-07-18
ER

PT J
AU Yang, JL
   Feng, Y
AF Yang, Jinlong
   Feng, Yu
TI An optimization high-resolution network for human pose recognition based
   on attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human pose estimation; Deep neural network; High resolution network
   (HRNet); Dilated convolution (DC); Attention mechanism
AB In the high-resolution network (HRNet), the low layer of low resolution part can adopt shallow parallel network structure to maintain the high-resolution features and highlight global features. However, the high-resolution human posture estimation network has the problems of large amount of network parameters, high complex calculation and low recognition precision of similar actions. To solve these problems, we proposed an optimized HRNet based on attention mechanism. Firstly, the dilated convolution (DC) module is introduced into cross-channel sampling to obtain global features by increasing the receptive field of the feature map, which ensures that the feature map can cover all the information of the original image; Secondly, the channel attention Squeeze-and-Excitation (SE) module is introduced in the process of cross-channel feature fusion to learn the correlations, which can recalibrate the features, highlight the information features selectively and suppress the secondary features, improving the recognition precision without changing the parameter quantity and operation complexity; Finally, the experiment results on KTH dataset show that the HRNet with channel attention mechanism and dilated convolution has better accuracy.
C1 [Yang, Jinlong; Feng, Yu] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Feng, Y (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
EM 1601242685@qq.com
FU This work is partially supported by the Natural Science Foundation of
   Jiangsu Province (No. BK20181340), and the National Natural Science
   Foundation of China (No. 61305017). [BK20181340]; Natural Science
   Foundation of Jiangsu Province [61305017]; National Natural Science
   Foundation of China
FX This work is partially supported by the Natural Science Foundation of
   Jiangsu Province (No. BK20181340), and the National Natural Science
   Foundation of China (No. 61305017).
CR [Anonymous], 2017, arXiv
   Bin X, 2018, P EUR C COMP VIS, P1208
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Geng Z, 2019, P IEEE DAT DRIV CONT, P174
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JJ, 2020, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR42600.2020.00574
   Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
   Jin Sheng, 2017, ICCV PoseTrack Workshop
   Liu CC, 2021, VISUAL COMPUT, V37, P1327, DOI 10.1007/s00371-020-01868-8
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Nazir S, 2018, COMPUT ELECTR ENG, V72, P660, DOI 10.1016/j.compeleceng.2018.01.037
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Patel CI, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247299
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Peng C, 2015, J Fiber Bioeng Informat, V8, P249, DOI [10.3993/jfbim00116, DOI 10.3993/JFBIM00116]
   Sang S, 2018, P INT C MACH LEARN C, P1330
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wu Y., 2021, Comput Intell, V99, P11
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yu F., 2015, ARXIV
   Yu F., 2016, Proc Int Conf Learn Represent, V11, P122
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 35
TC 0
Z9 0
U1 22
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-16793-w
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000001
DA 2024-07-18
ER

PT J
AU Zhou, XY
   Zhang, YJ
   Wang, Z
   Lu, MY
   Liu, XX
AF Zhou, Xiaoying
   Zhang, Yijia
   Wang, Zhuang
   Lu, Mingyu
   Liu, Xiaoxia
TI MAFN: multi-level attention fusion network for multimodal named entity
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Information extraction; Attention mechanism; Multimodal fusion; Visual
   filter gate; Multimodal learning
AB Multimodal named entity recognition (MNER) aims to use the modality information of images and text to identify named entities from free text and classify them into predefined types, such as Person, Location, Organization, etc. However, most existing MNER methods adopt simple splicing and attention mechanisms and fail to fully utilize the modal information to capture the intra-modal and inter-modal interactions. This simple fusion operation may bring bias to the prediction results of named entities. In this paper, we propose a novel Multi-level Attention Fusion Network (MAFN) to deal with this problem. Specifically, This paper introduce a multi-level attention mechanism to learn intra-modal and inter-modal interactions to obtain multimodal representations for each word. Furthermore, we introduce a visual filter gate to remove words that cannot be aligned with any visual block to control the contribution of visual features dynamically. Experimental results on two publicly available Twitter datasets demonstrate that our method outperforms other state-of-the-art baseline methods.
C1 [Zhou, Xiaoying; Zhang, Yijia; Wang, Zhuang; Lu, Mingyu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
   [Liu, Xiaoxia] Stanford Univ, Dept Neurol & Neurol Sci, Stanford, CA 94305 USA.
C3 Dalian Maritime University; Stanford University
RP Zhang, YJ (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
EM zhangyijia@dlmu.edu.cn
OI Zhang, Yijia/0000-0002-5843-4675
FU Social and Science Foundation of Liaoning Province [L20BTQ008]
FX This work is supported by a grant from Social and Science Foundation of
   Liaoning Province (No.L20BTQ008).
CR Arshad Omer, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P337, DOI 10.1109/ICDAR.2019.00061
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Athavale V, 2016, Arxiv, DOI [arXiv:1610.09756, 10.48550/arXiv.1610.09756]
   Cao PF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P182
   Chaudhari S, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465055
   Chinchor N, 1997, P 7 C MESS UND
   Chiu J., 2016, Trans Assoc Computat Linguist, V4, P357, DOI [10.1162/tacl_a_00104, DOI 10.1162/TACLA00104, DOI 10.1162/TACL_A_00104]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cortes C., 2015, P 29 ANN C NEUR INF
   Davis A, 2012, P 50 ANN M ASS COMP, V1, P815
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding N, 2021, Arxiv, DOI arXiv:2111.01998
   Fukui A., 2016, arXiv
   Hammerton J, 2003, P 7 C NAT LANG LEARN, V4, P172, DOI DOI 10.3115/1119176.1119202
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZH, 2015, Arxiv, DOI arXiv:1508.01991
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Ju XC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P512, DOI 10.1145/3394171.3413577
   Lample G, 2016, Arxiv, DOI [arXiv:1603.01360, DOI 10.48550/ARXIV.1603.01360]
   Liu MY, 2022, NEURAL PROCESS LETT, V54, P2433, DOI 10.1007/s11063-021-10737-x
   Liu X, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3794
   Lu D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1990
   Lu JS, 2019, ADV NEUR IN, V32
   Moon S, 2018, Arxiv, DOI arXiv:1802.07862
   Nazari M, 2018, ADV NEUR IN, V31
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Ritter A., 2011, P EMNLP, P1524
   Santos CND, 2015, Arxiv, DOI arXiv:1505.05008
   Sharaff A, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13153
   Su WJ, 2020, Arxiv, DOI arXiv:1908.08530
   Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]
   Wang X., 2022, 2022 IEEE INT C MULT, P01
   Yu J, 2020, ASS COMPUTATIONAL LI
   Zadeh A, 2017, Arxiv, DOI [arXiv:1707.07250, DOI 10.48550/ARXIV.1707.07250]
   Zhang D, 2021, AAAI CONF ARTIF INTE, V35, P14347
   Zhang Q, 2018, AAAI CONF ARTIF INTE, P5674
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
NR 37
TC 0
Z9 0
U1 8
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17376-5
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100001
DA 2024-07-18
ER

PT J
AU Liu, HX
   Fang, Z
   Lu, WJ
AF Liu, Hanxin
   Fang, Zhuang
   Lu, Wenjing
TI Noise level estimation based on eigenvalue learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Noise level estimation; Gaussian noise; Weak texture; Principal
   component analysis; Linear regression analysis
ID PRINCIPAL COMPONENTS; IMAGE; STATISTICS
AB At present, many algorithms use a single minimum eigenvalue to estimate the real noise level, and the levels estimated by these algorithms have been proven to be less than the real noise levels, this is known as underestimation. To address this problem, this paper uses multiple eigenvalues to obtain the relationship between eigenvalues and the real noise level through sample training, calculates the learning coefficients for different noise levels in the relationship expression by linear fitting, and then inputs the learning coefficients into the noise image for noise level estimation. Experiments demonstrate that the algorithm proposed in this paper can significantly improve the underestimation problem of the traditional algorithm and has better estimation accuracy for various noise levels in gray images, color images, and texture images of various scenes.
C1 [Liu, Hanxin; Fang, Zhuang; Lu, Wenjing] Hubei Minzu Univ, Sch Math & Stat, Enshi 445000, Hubei, Peoples R China.
C3 Hubei Minzu University
RP Fang, Z (corresponding author), Hubei Minzu Univ, Sch Math & Stat, Enshi 445000, Hubei, Peoples R China.
EM wdfangzhuang@163.com
FU This study was supported by the National Natural Science Foundation of
   China (Grant nos. 61763009, 61761030, and 62061016), the Doctoral
   Scientific Fund Project of Hubei Minzu University (Grant no. MD2020
   B024), the High-level Scientific Research Achieveme [61763009, 61761030,
   62061016]; National Natural Science Foundation of China [MD2020 B024];
   Doctoral Scientific Fund Project of Hubei Minzu University [4205003];
   High-level Scientific Research Achievement Cultivation Project of Hubei
   Minzu University
FX This study was supported by the National Natural Science Foundation of
   China (Grant nos. 61763009, 61761030, and 62061016), the Doctoral
   Scientific Fund Project of Hubei Minzu University (Grant no. MD2020
   B024), the High-level Scientific Research Achievement Cultivation
   Project of Hubei Minzu University (Grant no.4205003). We would like to
   express our gratitude to the anonymous reviewers and editors for their
   valuable comments and suggestions, which helped to improve the original
   manuscript.
CR Bin Zhou, 2021, Journal of Physics: Conference Series, V1871, DOI 10.1088/1742-6596/1871/1/012092
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai Q, 2022, IEEE T IMAGE PROCESS, V31, P43, DOI 10.1109/TIP.2021.3127848
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Corner BR, 2003, INT J REMOTE SENS, V24, P689, DOI 10.1080/01431160210164271
   De Stefano A, 2004, EURASIP J APPL SIG P, V2004, P2400, DOI 10.1155/S1110865704401218
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang Z, 2019, MULTIMED TOOLS APPL, V78, P17337, DOI 10.1007/s11042-018-7137-4
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Ghazi MM, 2017, MULTIMED TOOLS APPL, V76, P2379, DOI 10.1007/s11042-015-3169-1
   Gupta P, 2018, IEEE SW SYMP IMAG, P85, DOI 10.1109/SSIAI.2018.8470313
   Hashemi M, 2010, IEEE SIGNAL PROC LET, V17, P12, DOI 10.1109/LSP.2009.2030856
   Jiang P, 2020, IEEE T CIRC SYST VID, V30, P1987, DOI 10.1109/TCSVT.2019.2912319
   Jiang P, 2016, PATTERN RECOGN LETT, V78, P8, DOI 10.1016/j.patrec.2016.03.026
   Kancharla P, 2022, IEEE T IMAGE PROCESS, V31, P263, DOI 10.1109/TIP.2021.3130541
   Khmag A, 2018, VISUAL COMPUT, V34, P575, DOI 10.1007/s00371-017-1362-0
   Khosravanian A, 2022, MULTIMED TOOLS APPL, V81, P21719, DOI 10.1007/s11042-022-12445-7
   Ko K, 2022, IEEE T IMAGE PROCESS, V31, P1657, DOI 10.1109/TIP.2022.3145160
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lievin M., 2002, Bus Process Manag J, V7, P131
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu XH, 2012, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2012.6466947
   Muresan DD, 2003, IEEE IMAGE PROC, P101
   Peng H, 2020, J SYST ENG ELECTRON, V31, P1167, DOI 10.23919/JSEE.2020.000089
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Russo F, 2007, INSTRUMENTATION MEAS, P1
   Samann Fars, 2021, Current Directions in Biomedical Engineering, V7, P562, DOI 10.1515/cdbme-2021-2143
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Tasdizen T, 2008, IEEE IMAGE PROC, P1728, DOI 10.1109/ICIP.2008.4712108
   Walker JS, 2002, OPT ENG, V41, P1520, DOI 10.1117/1.1483086
   Witwit W, 2018, MULTIMED TOOLS APPL, V77, P27641, DOI 10.1007/s11042-018-5941-5
   [徐少平 Xu Shaoping], 2019, [电子学报, Acta Electronica Sinica], V47, P274
   Yadav S, 2021, MULTIMED TOOLS APPL, V80, P36491, DOI 10.1007/s11042-021-11442-6
   Yeap ZX, 2019, MICROSC RES TECHNIQ, V82, P402, DOI 10.1002/jemt.23181
   Yuan Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3071799
NR 37
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17403-5
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600019
DA 2024-07-18
ER

PT J
AU Saeed, AQ
   Abdullah, SNHS
   Che-Hamzah, J
   Ghani, ATA
   Abu-ain, WAK
AF Saeed, Ali Q.
   Abdullah, Siti Norul Huda Sheikh
   Che-Hamzah, Jemaima
   Ghani, Ahmad Tarmizi Abdul
   Abu-ain, Waleed Abdel karim
TI Synthesizing Retinal Images using End-To-End VAEs-GAN Pipeline-Based
   Sharpening and Varying Layer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image synthesis; Generative Adversarial Networks; Retinal fundus image;
   Variational Autoencoder; Deep learning
ID DIABETIC-RETINOPATHY; VESSEL SEGMENTATION; INFORMATION; ALGORITHM
AB This study attempts to synthesize a realistic-looking fundus image from a morphologically changed vessel structure using the newly proposed sharpening and varying vessels technique (SVV). This technique sharpens the reconstructed vessels and introduces variation to their structure to generate multiple images from a single input mask. This helps to reduce the reliance on expensive and scarce annotated medical data. The study also aims to overcome the limitations of current methods, such as unrealistic optic disc boundaries, extreme vessel tortuosity, and missed optic discs. This is mainly due to the fact that existing models penalize their weights based on the difference between real and synthetic images using only a single mask. Therefore, their emphasis is on generating the input mask while disregarding other important fundoscopic features. Inspired by the recent progress in Generative Adversarial Nets (GANs) and Variational Autoencoder (VAE), the proposed approach was able to preserve the geometrical shape of critical fundus characteristics. Visual and quantitative results indicate that the produced images are considerably distinct from the ones used for training. However, they also exhibit anatomical coherence and a reasonable level of visual. The data utilized in this study and the programming code necessary to recreate the experiment can be accessed at https://github.com/AliSaeed86/SVV_GAN.
C1 [Saeed, Ali Q.; Abdullah, Siti Norul Huda Sheikh; Ghani, Ahmad Tarmizi Abdul] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43650, Selangor, Malaysia.
   [Saeed, Ali Q.] Northern Tech Univ, Comp Ctr, Ninevah 41001, Iraq.
   [Che-Hamzah, Jemaima] Univ Kebangsaan Malaysia, Fac Med, Dept Ophthalmol, Kuala Lumpur 43650, Malaysia.
   [Abu-ain, Waleed Abdel karim] Taibah Univ, Appl Coll, Dept Comp Sci, Al Madinah Al Munawwara 46429, Saudi Arabia.
C3 Universiti Kebangsaan Malaysia; Northern Technical University;
   Universiti Kebangsaan Malaysia; Taibah University
RP Saeed, AQ; Abdullah, SNHS (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43650, Selangor, Malaysia.; Saeed, AQ (corresponding author), Northern Tech Univ, Comp Ctr, Ninevah 41001, Iraq.
EM ali.qasim@ntu.edu.iq; snhsabdullah@ukm.edu.my; jemaima@ppukm.ukm.edu.my;
   atag@ukm.edu.my; wabuain@taibahu.edu.sa
OI Abuain, Waleed/0000-0003-2186-5962; SAEED, ALI/0000-0002-2276-3776
FU We express our gratitude to Universiti Kebangsaan Malaysia for providing
   the research facility and environment for the Digital Forensics Lab. In
   addition to our grateful to the UKM hospital for granting the ethical
   approval referenced UKM PPI/111/8/JEP-202; Universiti Kebangsaan
   Malaysia [UKM PPI/111/8/JEP-2021-718]; UKM hospital
FX We express our gratitude to Universiti Kebangsaan Malaysia for providing
   the research facility and environment for the Digital Forensics Lab. In
   addition to our grateful to the UKM hospital for granting the ethical
   approval referenced UKM PPI/111/8/JEP-2021-718 on 1st Nov 2021.
CR Asperti A, 2023, NEURAL COMPUT APPL, V35, P3155, DOI 10.1007/s00521-022-07890-2
   Bellemo V, 2019, LECT NOTES COMPUT SC, V11367, P289, DOI 10.1007/978-3-030-21074-8_24
   Biswas S, 2019, IEEE ENG MED BIO, P2736, DOI [10.1109/EMBC.2019.8857857, 10.1109/embc.2019.8857857]
   Brock A., 2019, INT C LEARN REPR
   Chen XX, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102444
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Costa P, 2017, LECT NOTES COMPUT SC, V10317, P516, DOI 10.1007/978-3-319-59876-5_57
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Diaz-Pinto A, 2019, IEEE T MED IMAGING, V38, P2211, DOI 10.1109/TMI.2019.2903434
   Diaz-Pinto A, 2018, LECT NOTES COMPUT SC, V11314, P224, DOI 10.1007/978-3-030-03493-1_24
   Doersch Carl, 2016, ARXIV160605908
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guibas JT, 2017, 31 C NEUR INF PROC S
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   HaoQi G, 2020, 2020 THE 5TH INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING (ICCRE 2020), P218, DOI [10.1109/ICCRE49379.2020.9096438, 10.1109/iccre49379.2020.9096438]
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kingma DP, 2013, ARXIV
   Köhler T, 2013, COMP MED SY, P95, DOI 10.1109/CBMS.2013.6627771
   Kumar J, 2012, INT C PATT RECOG, P3292
   Kumaraswamy E, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111977
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Lamb A., 2016, Discriminative Regularization for Generative Models
   Larkin KG, 2015, Occas Texts Purs Clarity Simplicity Res Ser, V1
   Larsen ABL, 2016, 33 INT C MACH LEARN, P2341
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Menti E, 2016, LECT NOTES COMPUT SC, V9968, P167, DOI 10.1007/978-3-319-46630-9_17
   Metz L, 2017, ICLR C PAP
   Niemeijer M, 2006, MED IMAGE ANAL, V10, P888, DOI 10.1016/j.media.2006.09.006
   Osuala R, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102704
   Pirahansiah F, 2015, Camera calibration for multi-modal robot vision based on image quality assessment, P1, DOI [10.1109/ascc.2015.7360336, DOI 10.1109/ASCC.2015.7360336]
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Radford A., 2016, INT C LEARN REPR
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Saeed AQ, 2021, J MED INTERNET RES, V23, DOI 10.2196/27414
   Salimans T, 2016, ADV NEUR IN, V29
   Senan MFEM, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P649, DOI 10.1109/CONFLUENCE.2017.7943232
   Sharma M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03256-z
   Sharma M, 2019, HEALTH TECHNOL-GER, V9, P877, DOI 10.1007/s12553-019-00375-8
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Son J, 2019, J DIGIT IMAGING, V32, P499, DOI 10.1007/s10278-018-0126-3
   Song M, 2023, arXiv
   Soomro TA, 2019, 2018 INT C DIG IM CO
   Soomro TA., 2017, 2017 INT C DIG IM CO, P1, DOI [10.1109/dicta.2017.8227413, DOI 10.1109/DICTA.2017.8227413]
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Xiancheng W, 2018, INT C DAT SCI, P1
   Xie XZ, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101985
   Yahya SR, 2018, International Journal on Advanced Science, Engineering and Information Technology, P1552
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yu ZK, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0682-x
   Zamani NA, 2012, INT CONF INTELL SYST, P921, DOI 10.1109/ISDA.2012.6416661
   Zhao H, 2018, MED IMAGE ANAL, V49, P14, DOI 10.1016/j.media.2018.07.001
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 56
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17058-2
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400005
OA hybrid
DA 2024-07-18
ER

PT J
AU Bagade, S
   Kumar, BA
   Rao, LK
AF Bagade, Shilpa
   Kumar, Budati Anil
   Rao, L. Koteswara
TI Efficient data transmission over 5G Networks with improved accuracy
   using 802.11p
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 5G; Lagrangian Encoder; H.265; Video streaming; Optimization; Markov
   model,802.11p
AB High-quality data traffic management providing ultra-low latency and less circuit complexity are the technical challenges for 5G cellular networks in recent years. To address the increased data rate traffic and enhance the user experience, buffer management with effective utilization of resources are 5G networks. The existing research contains uncompressed or raw video data transmission over a double buffer system. The spectrum is always busy with information if uncompressed data is sent. Transmission delays occur while packet transmission and receiver systems result in video buffering. The authors proposed an optimized resource framework in this research paper by compressing data using a modified H.265 Lagrangian Encoder and transmitting data using a single buffer technique. The transmission delays are mitigated, and data buffering is minimized with reduced transmission errors. The proposed method is tested and verified with various errors like collision error, propagation error, sensing error, and accuracy. The proposed model gives an improvement in accuracy when compared with the existing model.
C1 [Bagade, Shilpa; Kumar, Budati Anil; Rao, L. Koteswara] Koneru Lakshmaiah Educ Fdn, Dept ECE, Hyderabad, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bagade, S (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept ECE, Hyderabad, India.
EM shilpa.me1437@gmail.com; anilbudati@gmail.com; koteswararao@klh.edu.in
RI B, Shilpa/KEZ-9804-2024; Budati, Anil Kumar/U-4960-2018; Bagade,
   shilpa/ABC-4004-2021
OI Budati, Anil Kumar/0000-0002-5118-2284; Bagade,
   shilpa/0000-0002-2792-6108
CR Bisdikian C, 1996, TELECOMMUN SYST, V6, P127, DOI 10.1007/BF02114290
   Burger V, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183511
   Busari SA, 2019, IET INTELL TRANSP SY, V13, P983, DOI 10.1049/iet-its.2018.5492
   Dou ZF, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/1955948
   Fu Y, 2018, IEEE NETWORK, V32, P58, DOI 10.1109/MNET.2018.1800115
   Golaghazadeh F, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116597
   Hussein HH, 2020, WIREL NETW, V26, P3183, DOI 10.1007/s11276-019-02131-2
   Islam S., 2023, Sustain Energy Technol Assess, V57, P103278
   Li Suoping, 2023, Security and Communication Networks, DOI 10.1155/2023/5476836
   Liang L, 2017, IEEE T COMMUN, V65, P3186, DOI 10.1109/TCOMM.2017.2699194
   Ma C., 2022, J Sensors, V2022, P1
   Marinsek A, 2021, arXiv, DOI [10.48550/arXiv.2105.13147, DOI 10.48550/ARXIV.2105.13147]
   Mezzavilla M, 2018, IEEE COMMUN SURV TUT, V20, P2237, DOI 10.1109/COMST.2018.2828880
   Nie HL, 2020, MULTIMED TOOLS APPL, V79, P10781, DOI 10.1007/s11042-019-08479-z
   O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370
   Ramesh S, 2020, MULTIMED TOOLS APPL, V79, P10157, DOI 10.1007/s11042-019-7585-5
   Roy A, 2021, COMPUTING, V103, P2361, DOI 10.1007/s00607-021-00973-3
   Sepulcre M, 2022, IEEE T VEH TECHNOL, V71, P713, DOI 10.1109/TVT.2021.3124708
   Shilpa B, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108164
   Tahir MN, 2022, ENG REP, V4, DOI 10.1002/eng2.12467
   Vivekananda G. N., 2023, International Journal of Advanced Intelligence Paradigms, P248, DOI 10.1504/IJAIP.2023.132371
   Wang JL, 2020, ENERGY ENVIRON MATER, V3, P80, DOI 10.1002/eem2.12041
   Zhang BT, 2019, IEEE T VEH TECHNOL, V68, P5606, DOI 10.1109/TVT.2019.2907487
   Zhang P, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4379
NR 24
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17156-1
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600021
DA 2024-07-18
ER

PT J
AU Jawahar, M
   Anbarasi, LJ
   Anand, SM
   Ravi, V
AF Jawahar, Malathy
   Anbarasi, L. Jani
   Anand, S. Mahesh
   Ravi, Vinayakumar
TI Intelligent leather defect classification using Fourier angular radial
   partitioning algorithm with ensemble classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Leather defect; Classification; Machine learning; Ensemble classifier;
   Fourier angular radial partitioning
ID AUTOMATED INSPECTION; NEURAL-NETWORK; VISION SYSTEM; CERAMIC TILES;
   SEGMENTATION; SURFACE; COLOR; RECOGNITION; REGRESSION; HIDE
AB Leather quality inspection is essential in determining the usable area of the material. As leather is a natural substance, surface defects can have a significant impact on its overall quality and reduce its usability. The automatic identification of surface defects in leather holds great importance in the inspection process. This study presents an innovative method called the Fourier Angular Radial Partitioning (FARP) algorithm for extracting features, specifically tailored for the identification of surface defects in leather. A cutting-edge industrial prototype machine vision system is designed with innovative capabilities to acquire high-quality entire leather surface image accurately. The FARP algorithm leverages a combination of spatial and radial distributed invariant feature descriptors obtained from the magnitude of the Fourier Transform. Furthermore, by partitioning the image into multiple sub-regions enables the FARP to extract features to effectively analyze both prominent flaws like cuts, scars and subtle imperfections like pinholes. The performance of the proposed FARP algorithm is compared to Gray Level Co-occurrence method and Spatial domain features. Correlation analysis is conducted on the extracted features from these three methods to identify the optimal feature set. Leather defects are classified using a multinomial logistic regression model and an ensemble classifier approach with random forest. Various measures, including accuracy, specificity, sensitivity, F-score, Mathew Correlation Coefficient, and ROC analysis using Z-test, are employed for a comprehensive evaluation. The experimental results indicate that the random forest and the proposed FARP feature set, achieves a remarkable classification accuracy of 88.67% and a notable area under the ROC curve of 0.875. This intelligent solution, which integrates FARP with the Random Forest classifier, surpasses the performance of manual expert leather defect classification, highlighting its superior effectiveness.
C1 [Jawahar, Malathy] CSIR Cent Leather Res Inst, Leather Proc Technol Div, Chennai 600020, India.
   [Anbarasi, L. Jani] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
   [Anand, S. Mahesh] Sci Comp Solut, Chennai, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Leather Research Institute (CLRI); Vellore Institute of
   Technology (VIT); VIT Chennai; Prince Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM vravi@pmu.ed.sa
RI l, j/JVZ-8480-2024; Ravi, Vinayakumar/L-4202-2018
OI Ravi, Vinayakumar/0000-0001-6873-6469
FU The authors acknowledge the financial support from CSIR, New Delhi under
   the Supra Institutional Project Samp;T Revolution in Leather with a
   Green Touch (STRAIT) A/2021/LPT/STRAIT/1544. [A/2021/LPT/STRAIT/1544];
   CSIR, New Delhi under the Supra Institutional Project Samp;T Revolution
   in Leather with a Green Touch (STRAIT)
FX The authors acknowledge the financial support from CSIR, New Delhi under
   the Supra Institutional Project S&T Revolution in Leather with a Green
   Touch (STRAIT) A/2021/LPT/STRAIT/1544.
CR Abdullah MZ, 2004, J FOOD ENG, V61, P125, DOI 10.1016/S0260-8774(03)00194-8
   Abouelela A, 2005, PATTERN RECOGN LETT, V26, P1435, DOI 10.1016/j.patrec.2004.11.016
   Amiri MD, 2009, IEEE INT SYMP SIGNAL, P574, DOI 10.1109/ISSPIT.2009.5407515
   Anil KJ, 1998, Texture analysis. The handbook of pattern recognition and computer vision, P207
   [Anonymous], 2004, Energy
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bowman CC, 1996, P SOC PHOTO-OPT INS, V2908, P33, DOI 10.1117/12.257274
   Branca A., 1997, Computer Analysis of Images and Patterns. 7th International Conference, CAIP '97. Proceedings, P223, DOI 10.1007/3-540-63460-6_121
   Branca A, 1996, P SOC PHOTO-OPT INS, V2908, P97, DOI 10.1117/12.257252
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   BRZAKOVIC D, 1990, PATTERN RECOGN, V23, P99, DOI 10.1016/0031-3203(90)90052-M
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chalechale A, 2004, IEE P-VIS IMAGE SIGN, V151, P93, DOI 10.1049/ip-vis:20040332
   Convery S., 1994, In J Cloth Sci Technol, V6, P15, DOI [10.1108/09556229410074574, DOI 10.1108/09556229410074574]
   Costa CE, 2000, MACH VISION APPL, V11, P225, DOI 10.1007/s001380050105
   Cui Y., 2004, IEEE, V5, P4124
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Elbehiery H, 2005, PROC WRLD ACAD SCI E, V5, P158
   Elbehiery HM, 2005, ICGST Int J Graph Vis Image Process, V5
   Gan YS, 2021, J AMB INTEL HUM COMP, V12, P9269, DOI 10.1007/s12652-020-02631-6
   Gan Y.S., 2021, J. Ambient Intell. Hum. Comput., P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hatcher DW, 2004, J FOOD ENG, V61, P109, DOI 10.1016/S0260-8774(03)00192-4
   He FQ, 2006, KEY ENG MATER, V326-328, P469, DOI 10.4028/www.scientific.net/KEM.326-328.469
   He Fuqiang, 2006, TECHNOLOGY INNOVATIO, P2024
   Hemdan AT, 2008, AUTEX Res J, V8, P21
   Hoang K, 1996, MACH VISION APPL, V9, P119, DOI 10.1007/BF01216817
   Hoang K, 1997, COMPUT IND, V34, P43, DOI 10.1016/S0166-3615(97)00019-5
   Bong HQ, 2018, PROCEEDINGS OF 2018 5TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS 2018), P300, DOI 10.1109/NICS.2018.8606836
   Jang-Woo K, 2001, TENCON 2004 IEEE REG
   Jawahar Malathy, 2020, 2020 5th International Conference on Communication and Electronics Systems (ICCES). Proceedings, P742, DOI 10.1109/ICCES48766.2020.9138024
   Jawahar M, 2021, MULTIMED TOOLS APPL, V80, P4203, DOI 10.1007/s11042-020-09727-3
   Kaloyan K, 2005, P INT C COMP SYST TE
   Kaloyan K, 2006, P INT C COMP SYST TE
   Kashif S, 2021, Arch. Comput. Methods, VEng, P1
   Kasi MK, 2014, HIGH PERF COMP APPL, P1
   Khurshid H, 2015, IEEE J-STARS, V8, P224, DOI 10.1109/JSTARS.2014.2362769
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar MP, 2020, Instrumentation, Mesures, Metrologies, V19
   Kwak C, 2000, J INTELL MANUF, V11, P485, DOI 10.1023/A:1008974314490
   Lerch A., 1991, Engineering Applications of Artificial Intelligence, V4, P433, DOI 10.1016/0952-1976(91)90032-2
   Li S, 2006, INT C POW SYST TECHN
   LIMASSERAFIM AF, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1357, DOI 10.1109/IECON.1993.339265
   Liong ST, 2019, Arxiv, DOI arXiv:1905.11731
   Liong ST, 2020, INT J COMPUT INTEG M, V33, P1105, DOI 10.1080/0951192X.2020.1795928
   Lovergine FP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P669, DOI 10.1109/ICIP.1997.638584
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Mery D, 2005, J FOOD ENG, V66, P353, DOI 10.1016/j.jfoodeng.2004.04.001
   Neto MM, 2005, INT FED INFO PROC, V159, P387
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Pazzaglia G, 2021, ICPR INT WORKSH CH 4
   Perez R, 2004, P VIS IM IM PROC
   Peters S, 2007, 7 INT C HYBR INT SYS, DOI [10.1109/HIS.2007.18, DOI 10.1109/HIS.2007.18]
   Pistori H, 2007, PROC MONOGR ENG WATE, P355
   POLZLEITNER W, 1994, P SOC PHOTO-OPT INS, V2347, P50, DOI 10.1117/12.188759
   Segnini S, 1999, FOOD SCI TECHNOL-LEB, V32, P216
   SERAFIM AFL, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P41, DOI 10.1109/ICPR.1992.201923
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Sharon JJ, 2018, 2018 FIFTH HCT INFORMATION TECHNOLOGY TRENDS (ITT): EMERGING TECHNOLOGIES FOR ARTIFICIAL INTELLIGENCE, P41, DOI 10.1109/CTIT.2018.8649511
   Smith ML, 2000, COMPUT IND, V43, P73, DOI 10.1016/S0166-3615(00)00052-X
   Sorwar G, 2004, Malaysian J Comput Sci, V17
   Svetnik V, 2004, LECT NOTES COMPUT SC, V3077, P334
   Tafuri M, P SPIE, VIV, P108
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tofang-Sazi K, 2001, Intell. Data Anal., V5, P355
   Uçar N, 2007, FIBRES TEXT EAST EUR, V15, P58
   Villar P, 2011, LECT NOTES COMPUT SC, V7042, P591, DOI 10.1007/978-3-642-25085-9_70
   Wang L, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1765
   Wang Q, 1992, P IEEE INT S C IND E
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   Yam KL, 2004, J FOOD ENG, V61, P137, DOI 10.1016/S0260-8774(03)00195-X
   Yang X, 2005, IEE P-VIS IMAGE SIGN, V152, P715, DOI 10.1049/ip-vis:20045131
   Yeh C, 2005, INT J ADV MANUF TECH, V25, P1197, DOI 10.1007/s00170-003-1945-y
   Yeh JCH, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P37, DOI 10.1109/ICNN.1995.487873
   ZWEIG MH, 1993, CLIN CHEM, V39, P561
NR 79
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16224-w
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200013
DA 2024-07-18
ER

PT J
AU Dwivedi, R
   Tiwari, A
   Bharill, N
   Ratnaparkhe, M
   Soni, R
   Mahbubani, R
   Kumar, S
AF Dwivedi, Rajesh
   Tiwari, Aruna
   Bharill, Neha
   Ratnaparkhe, Milind
   Soni, Rishabh
   Mahbubani, Rahul
   Kumar, Saket
TI An incremental clustering method based on multiple objectives for
   dynamic data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-objective optimization; Incremental clustering; Intra-cluster
   distance; Inter-cluster distance; Cluster density
AB Due to the advancement in big data and bioinformatics, the quantity and quality of raw data have exploded during the past two decades. Multiple sources contributed to the generation of very complex, diverse, and vast raw data. The generated data may conceal crucial patterns that need to be identified for data analysis. In the past few decades, a variety of clustering methods have been developed and have proven useful for data analysis. However, these methods are inappropriate for dynamic applications and only function with static data. To address this issue, we present a multi-objective incremental clustering method for processing dynamic data that generates and updates clusters in real-time. To improve the dynamic clustering process, the proposed method employs Euclidean distance to calculate the similarity between data points and constructs a fitness function with three primary clustering objective functions: inter-cluster distance, intra-cluster distance, and cluster density. The proposed method employs the concept of objective weighting, which allocates a weight to each objective in order to generate a single Pareto-optimal solution for the constructed fitness function. The proposed method outperforms other state-of-the-art methods on five benchmarks and three real-life plant genomics data sets.
C1 [Dwivedi, Rajesh; Tiwari, Aruna; Soni, Rishabh; Mahbubani, Rahul; Kumar, Saket] IIT Indore, Dept Comp Sci, Indore 453552, Madhya Pradesh, India.
   [Bharill, Neha] Mahindra Univ, Ecole Cent Sch Engn, Dept Comp Sci, Hyderabad 500043, Telangana, India.
   [Ratnaparkhe, Milind] Indian Inst Soybean Res Indore, ICAR, Indore 452001, Madhya Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore; Mahindra University
RP Dwivedi, R (corresponding author), IIT Indore, Dept Comp Sci, Indore 453552, Madhya Pradesh, India.
EM rajeshdwivedi@iiti.ac.in; artiwari@iiti.ac.in;
   neha.bharill@mahindrauniversity.edu.in; milind.ratnaparkhe@icar.gov.in;
   cse190001052@iiti.ac.in; cse190001050@iiti.ac.in;
   cse190001054@iiti.ac.in
RI Dwivedi, Rajesh/Q-5341-2018; Bharill, Dr. Neha/A-1250-2019
OI Dwivedi, Rajesh/0000-0001-6947-9054; 
FU Council of Scientific and Industrial Research (CSIR), Governmentof India
   [22(0853)/20/EMR-II]
FX This research is funded by The Council of Scientific and Industrial
   Research (CSIR), Governmentof India under grant no. 22(0853)/20/EMR-II.
CR Abernathy A, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117927
   Bejarano LA, 2022, COMPUTATION, V10, DOI 10.3390/computation10030037
   Balakrishna S, 2022, CLUSTER COMPUT, V25, P1441, DOI 10.1007/s10586-022-03549-8
   Bandillo N, 2013, RICE, V6, DOI 10.1186/1939-8433-6-11
   Bentley DR, 2000, MED RES REV, V20, P189, DOI 10.1002/(SICI)1098-1128(200005)20:3<189::AID-MED2>3.0.CO;2-#
   Bu FY, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/4356127
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   CAN F, 1993, ACM T INFORM SYST, V11, P143, DOI 10.1145/130226.134466
   Chen YW, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.032
   Deb K., 2016, Decision Sciences, P161, DOI DOI 10.1201/9781315183176-12/MULTI-OBJECTIVE-OPTIMIZATION-KALYANMOY-DEB-KARTHIK-SINDHYA-JUSSI-HAKANEN
   Dilla-Ermita CJ, 2017, RICE, V10, DOI 10.1186/s12284-017-0147-4
   Dwivedi R, 2023, ARAB J SCI ENG, V48, P10727, DOI 10.1007/s13369-023-07719-7
   Ezugwu AE, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104743
   Laohakiat S, 2021, INFORM SCIENCES, V547, P404, DOI 10.1016/j.ins.2020.08.052
   Li WM, 2022, INFORM FUSION, V79, P110, DOI 10.1016/j.inffus.2021.10.002
   Liu S, 2017, Mathematical Problems in Engineering, V2017
   Luscombe N M, 2001, Yearb Med Inform, P83
   Mansueto L, 2017, NUCLEIC ACIDS RES, V45, pD1075, DOI 10.1093/nar/gkw1135
   Nentwig M, 2018, INT CONF DAT MIN WOR, P531, DOI 10.1109/ICDMW.2018.00084
   Newman D., 1998, UCI REPOSITORY MACHI
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Tian Y, 2023, IEEE-CAA J AUTOMATIC, V10, P1048, DOI 10.1109/JAS.2022.105437
   Tian Y, 2020, IEEE T FUZZY SYST, V28, P2841, DOI 10.1109/TFUZZ.2019.2945241
   Wang L, 2021, FUZZY SET SYST, V421, P62, DOI 10.1016/j.fss.2021.01.002
   Zareizadeh Z, 2018, EXPERT SYST APPL, V113, P301, DOI 10.1016/j.eswa.2018.06.047
   Zhou P, 2019, KNOWL-BASED SYST, V174, P73, DOI 10.1016/j.knosys.2019.02.036
   Zhuo LL, 2019, IEEE ACCESS, V7, P74612, DOI 10.1109/ACCESS.2019.2918772
NR 29
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17134-7
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500003
DA 2024-07-18
ER

PT J
AU Aggarwal, A
   Kumar, M
AF Aggarwal, Akarsh
   Kumar, Manoj
TI An ensemble framework for detection of DNS-Over-HTTPS (DOH) traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNS; DNS over HTTPS; DNS Encryption; Machine Learning; Cybersecurity;
   Ensemble Learning
ID PRIVACY; EFFICIENT; SECURITY
AB Domain Name System (DNS) is a fundamental protocol and backbone of the internet that translates domain names to Internet Protocol (IP) addresses. Initially, it was only meant for mapping domain names, however, currently it is used to transfer data over the internet in the form of plain text. This attracts attackers to perform cyberattacks such as DNS spoofing, DNS amplification, and cache poisoning etc. Various solutions were proposed to protect DNS protocol from such attacks such as using DNS load balancers, OpenDNS by Cisco, DNSFilters etc. However, despite these security measures, the attackers can still easily modify the data packets over the network leading to security and privacy concerns. DNS-Over-HTTPS (DOH) is recently introduced protocol with encrypted DNS that defends against issues related to security and eavesdropping largely. However, some challenges are associated with it that need to be addressed for its proper functioning. In this work, an approach is presented to automatically detect DOH traffic using Ensemble-based machine learning framework. The proposed technique is tested on the CIRA-CIC-DoHBrw-2020 dataset and evaluated on classification metrics such as precision, recall, f-score, and confusion metrics. Further, to develop a reliable model that can detect anomalies efficiently, a detailed analysis of false positives and false negatives is done. The demonstrated results show that the presented ensembling techniques EL1 and EL2 outperform the existing approaches by achieving an overall accuracy score of 99.5% and 99.7% respectively and F-score of about 99.8% and 99.7% respectively.
C1 [Aggarwal, Akarsh] Syneos Hlth Pvt Ltd, Gurugram, India.
   [Kumar, Manoj] Univ Wollongong, Fac Engn & Informat Sci, Sch Comp Sci, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman, Jordan.
C3 University of Wollongong; Middle East University
RP Aggarwal, A (corresponding author), Syneos Hlth Pvt Ltd, Gurugram, India.
EM aakarsh.aggarwal2@gmail.com; wss.manojkumar@gmail.com
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280
CR Aggarwal A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6157
   Aggarwal A, 2021, MULTIMED TOOLS APPL, V80, P1289, DOI 10.1007/s11042-020-09520-2
   Ahmed J, 2020, IEEE T NETW SERV MAN, V17, P265, DOI 10.1109/TNSM.2019.2940735
   Aiello M, 2015, INT J COMMUN SYST, V28, P1987, DOI 10.1002/dac.2836
   Al-Dailami A, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/3107543
   Albahar M, 2019, SCI ENG ETHICS, V25, P993, DOI 10.1007/s11948-016-9864-0
   Alex S, 2021, INT J INTELL SYST, V36, P7153, DOI 10.1002/int.22584
   Almusawi A, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6137098
   [Anonymous], 2021, LASHK AH DOHLYZER
   Banadaki YM, 2020, J Comput Sci Appl, V8, P46, DOI DOI 10.12691/JCSA-8-2-2
   Cavalcanti GDC, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113269
   Chen SJ, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2020.102095
   Cheng JR, 2022, INT J INTELL SYST, V37, P10100, DOI 10.1002/int.22310
   D'Angelo G, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102930
   Guan ZT, 2019, IEEE CONSUM ELECTR M, V8, P61, DOI 10.1109/MCE.2018.2880824
   Halim Z, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102448
   Jalalzai MH, 2015, 2015 12TH INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES AND TECHNOLOGY (IBCAST), P280, DOI 10.1109/IBCAST.2015.7058517
   Kannari PR, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03077-0
   Lallie HS, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102248
   Lee J, 2014, COMPUT COMMUN, V49, P33, DOI 10.1016/j.comcom.2014.04.013
   Li J, 2019, ANN TELECOMMUN, V74, P373, DOI 10.1007/s12243-019-00718-6
   Li P, 2018, FUTURE GENER COMP SY, V87, P341, DOI 10.1016/j.future.2018.04.076
   Li YZ, 2021, INT J INTELL SYST, V36, P1053, DOI 10.1002/int.22330
   Mahmoud MS, 2019, NEUROCOMPUTING, V338, P101, DOI 10.1016/j.neucom.2019.01.099
   Mitsuhashi R, 2023, IEEE T NETW SERV MAN, V20, P2086, DOI 10.1109/TNSM.2022.3215681
   MontazeriShatoori M, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P63, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00026
   Nadler A, 2019, COMPUT SECUR, V80, P36, DOI 10.1016/j.cose.2018.09.006
   Niakanlahiji A, 2023, COMPUT SECUR, V124, DOI 10.1016/j.cose.2022.103001
   Peng Yang, 2020, WSSE 2020: The 2nd World Symposium on Software Engineering, P109, DOI 10.1145/3425329.3425336
   Qi C, 2013, PROCEDIA COMPUT SCI, V17, P852, DOI 10.1016/j.procs.2013.05.109
   Raja G, 2021, IEEE T VEH TECHNOL, V70, P7050, DOI 10.1109/TVT.2021.3082308
   Salim MM, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107859
   Shi Y, 2018, NEURAL PROCESS LETT, V48, P1347, DOI 10.1007/s11063-017-9666-7
   Singh M, 2019, DIGIT INVEST, V28, P14, DOI 10.1016/j.diin.2018.12.005
   Song F, 2021, INT J INTELL SYST, V36, P5210, DOI 10.1002/int.22510
   Tama BA, 2019, IEEE ACCESS, V7, P94497, DOI 10.1109/ACCESS.2019.2928048
   Tatang D., 2019, ARXIV
   unb, DOHBRW 2020 DAT RES
   Do VT, 2017, LECT NOTES ELECTR EN, V424, P221, DOI 10.1007/978-981-10-4154-9_26
   Varshney G, 2021, INT CONF COMMUN SYST, DOI 10.1109/COMSNETS51098.2021.9352935
   Vekshin D., 2020, P 15 INT C AV REL SE, P1, DOI DOI 10.1145/3407023.3409192
   Venkatraman S, 2019, J INF SECUR APPL, V47, P377, DOI 10.1016/j.jisa.2019.06.006
   Vinayakumar R, 2018, STUD BIG DATA, V44, P113, DOI 10.1007/978-981-10-8476-8_6
   Vinayakumar R, 2018, J INTELL FUZZY SYST, V34, P1355, DOI 10.3233/JIFS-169431
   Wang F, 2020, GEODERMA, V365, DOI 10.1016/j.geoderma.2020.114211
   Wang SM, 2022, COMPUT SECUR, V120, DOI 10.1016/j.cose.2022.102818
   Hoang XD, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10050043
   Yan GH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030731
   Zebin T, 2022, IEEE T INF FOREN SEC, V17, P2339, DOI 10.1109/TIFS.2022.3183390
   Zhao F, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6638134
   Zheng RF, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8824659
   Zhu L, 2015, P IEEE S SECUR PRIV, P171, DOI 10.1109/SP.2015.18
NR 52
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32945
EP 32972
DI 10.1007/s11042-023-16956-9
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400018
DA 2024-07-18
ER

PT J
AU Wu, YQ
   Han, F
   Zhang, DJ
   Zhang, TT
   Chen, YL
AF Wu, Yiqi
   Han, Fang
   Zhang, Dejun
   Zhang, Tiantian
   Chen, Yilin
TI Unsupervised non-rigid point cloud registration based on point-wise
   displacement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Point cloud; Non-rigid registration; Point displacement; Self attention;
   Deep learning
AB Registration of deformable objects is a fundamental prerequisite for many modern virtual reality and computer vision applications. However, due to the difficulties of acquiring labeled datasets and the inherent irregular deformation, non-rigid registration for 3D scanner-captured data remains challenging. This paper proposes an unsupervised non-rigid 3D point cloud registration network based on the self-attention mechanism. Specifically, considering the registration as the result of point drifts between the source and target shapes, a Transformer-based encoder-decoder module is utilized to estimate the point displacements. Additionally, a symmetric registration procedure is adopted with regularization loss to manage the regular deformation of points, ultimately producing reasonable registration results for real-world deformable objects. Experiments are conducted on public and synthesized datasets which simulate diversiform non-rigid 2D or 3D deformations. Numerical and qualitative experimental results demonstrate that the proposed network achieves outstanding performance and is robust in scenes with multiple interferences.
C1 [Wu, Yiqi; Han, Fang; Zhang, Dejun; Zhang, Tiantian] China Univ Geosci, Sch Comp Sci, 68 JinCheng St, Wuhan 430078, Hubei, Peoples R China.
   [Chen, Yilin] Wuhan Inst Technol, Hubei Key Lab Intelligent Robot, 206,Guanggu 1st Rd, Wuhan 430205, Hubei, Peoples R China.
C3 China University of Geosciences; Wuhan Institute of Technology
RP Zhang, DJ (corresponding author), China Univ Geosci, Sch Comp Sci, 68 JinCheng St, Wuhan 430078, Hubei, Peoples R China.
EM wuyq@cug.edu.cn; hfun@cug.edu.cn; zhangdejun@cug.edu.cn;
   zhangtiantian@cug.edu.cn; yilinchen@wit.edu.cn
RI ZHENG, YI/KAM-6536-2024; Li, Fan/KBB-8931-2024; Jing,
   Jing/JSK-6237-2023; li, rui/JVM-8999-2024; Wang, Zejun/KBB-8454-2024;
   li, mengyang/JWO-9551-2024; Liu, qi/JZT-5038-2024; yang,
   le/KFB-5420-2024; Zhang, Bo/JVD-9890-2024; Lin, Lin/JTU-1595-2023; Li,
   Xinyue/JVN-4601-2024; chen, gang/JRX-1197-2023; yang,
   zhou/KBB-6972-2024; xiao, wei/KCK-6954-2024; feng, feng/KBR-1814-2024;
   Liu, Zhe/KEJ-5299-2024; liu, feng/KCL-0778-2024; Li,
   Jiawei/JOJ-9277-2023; Zhang, yuxuan/JXM-9935-2024; Chen,
   Xiao/KBD-1464-2024; li, liu/JXN-7328-2024; LI, LI/KCJ-5600-2024; zhang,
   hao/JOJ-7093-2023; wang, xi/JNT-5162-2023; wang, wang/JQW-3034-2023;
   zhang, tiantian/AIE-2834-2022; LI, YUN/JTV-7108-2023
FU National Natural Science Foundation of China [61802355]; Hubei Key
   Laboratory of Intelligent Robot [61702350];  [HBIR 202105]
FX This work is supported by the National Natural Science Foundation of
   China (grant No. 61802355 and 61702350) and Hubei Key Laboratory of
   Intelligent Robot (HBIR 202105).
CR Agarwal S, 2017, IEEE IMAGE PROC, P2199, DOI 10.1109/ICIP.2017.8296672
   Atzmon M, 2018, Arxiv, DOI arXiv:1803.10091
   Balakrishnan G, 2018, PROC CVPR IEEE, P9252, DOI 10.1109/CVPR.2018.00964
   Bednarík J, 2018, INT CONF 3D VISION, P606, DOI 10.1109/3DV.2018.00075
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duan YQ, 2019, PROC CVPR IEEE, P949, DOI 10.1109/CVPR.2019.00104
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Kumar K, 2021, Multimedia Tools and Applications, V80, p11,079
   Li KQ, 2022, IEEE T INTELL TRANSP, V23, P15864, DOI 10.1109/TITS.2022.3146087
   Li X, 2019, INT CONF 3D VISION, P145, DOI 10.1109/3DV.2019.00025
   Li Y., 2018, Adv. Neural Inf. Process. Syst., V31
   Ma JY, 2017, AAAI CONF ARTIF INTE, P4218
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Qi CR, 2017, ADV NEUR IN, V30
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Saini P, 2023, ARTIF INTELL REV, V56, P12347, DOI 10.1007/s10462-023-10444-0
   Sarode V, 2019, Arxiv, DOI arXiv:1908.07906
   Shimada S, 2019, INT CONF 3D VISION, P27, DOI 10.1109/3DV.2019.00013
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma P, 2022, VISUAL COMPUT, V38, P2417, DOI 10.1007/s00371-021-02120-7
   Verma P, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102866
   Wang LJ, 2019, Arxiv, DOI arXiv:1906.03039
   Wang LJ, 2019, Arxiv, DOI arXiv:1904.01428
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZH, 2021, Arxiv, DOI arXiv:2105.02282
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiang R, 2021, PROC CVPR IEEE, P15925, DOI 10.1109/CVPR46437.2021.01567
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yao Y, 2020, P IEEE CVF C COMP VI, P7600
   Yew ZJ, 2022, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR52688.2022.00656
   Yin KX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201288
   Zhang DJ, 2020, INTEGR COMPUT-AID E, V27, P57, DOI 10.3233/ICA-190608
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P4005, DOI 10.1109/TPAMI.2021.3064850
   Zhang YS, 2022, IEEE T CIRC SYST VID, V32, P8500, DOI 10.1109/TCSVT.2022.3196679
   Zhang YS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3121671
   Zhang Z., 2020, Virtual Real Intell Hardw, V2, P222, DOI DOI 10.1016/J.VRIH.2020.05.002
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
NR 45
TC 0
Z9 0
U1 8
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 19
PY 2023
DI 10.1007/s11042-023-16854-0
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S1WZ2
UT WOS:001069156900022
DA 2024-07-18
ER

PT J
AU Anand, M
   Jain, A
   Shukla, MK
AF Anand, Mallekedi
   Jain, Anuj
   Shukla, Manoj Kumar
TI Deep learning: crop selection based on weather conditions in Tarakeswar
   village of Hooghly district in West Bengal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE West Bengal; Weather prediction; Crop selection; Tarakeswar region;
   Agriculture; India meteorological department
AB Crop selection is a necessary step to take before beginning a farming venture. In India, reliable weather information helps farmers to plan their labor schedules for maximizing crop productivity, and it has a chief influence on crop output. Several researchers enunciate, present variations in temperature, carbon dioxide levels, winds, humidity, and precipitation directly affect crop production. Any weather anomalies lead to atmospheric stresses, making these farmers more susceptible to financial losses. By these concerns, this manuscript proposes a novel Recalling Enhanced Sigmoid Recurrent Neural Network with Manta Ray optimization (RESRNN-MR) for weather prediction and Cycle Consistent Generative Adversarial Network with Color Harmony algorithm (CCGAN-CH) for crop selection of the chosen Tarakeswar village of Hooghly district in West Bengal (WB), India. The outcomes depict that the introduced model attains a higher accuracy (99%) than the traditional techniques. Tests such as the Chi-square test and Cochran's Q test are done to prove the statistical analysis of the proposed approach.
C1 [Anand, Mallekedi; Jain, Anuj] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144001, Punjab, India.
   [Shukla, Manoj Kumar] Constituent Symbiosis Int Deemed Univ, Symbiosis Inst Technol, Dept Robot & Automat, Pune 412115, Maharashtra, India.
C3 Lovely Professional University; Symbiosis International University;
   Symbiosis Institute of Technology (SIT)
RP Anand, M (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144001, Punjab, India.
EM svanand50@gmail.com; a1978jain@gmail.com; manoj.shukla@sitpune.edu.in
RI Shukla, Manoj Kumar/AGJ-8565-2022
OI Shukla, Manoj Kumar/0000-0002-7013-8801
CR Akhter J, 2021, THEOR APPL CLIMATOL, V145, P1089, DOI 10.1007/s00704-021-03679-w
   Al-Janabi S, 2020, SOFT COMPUT, V24, P555, DOI 10.1007/s00500-019-03972-x
   Alrashedy HHN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114297
   Bhullar A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-33840-6
   Bhuyan BP, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15010481
   Conradt T, 2022, INT J BIOMETEOROL, V66, P2287, DOI 10.1007/s00484-022-02356-5
   Feng JY, 2021, ENERGY REP, V7, P1068, DOI 10.1016/j.egyr.2021.02.028
   Gao T, 2020, INFORM SCIENCES, V519, P273, DOI 10.1016/j.ins.2020.01.045
   Gayle SS, 2010, SIMULATION STUDY SIZ
   Gopi PSS, 2024, MULTIMED TOOLS APPL, V83, P13159, DOI 10.1007/s11042-023-16113-2
   Grzyb A, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10121951
   Gupta A, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03685-w
   Hague FF, 2020, 2020 IEEE 6TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), DOI 10.1109/wf-iot48130.2020.9221298
   Kathole AB., 2023, Franklin Open, V3, DOI [10.1016/j.fraope.2023.100024, DOI 10.1016/J.FRAOPE.2023.100024]
   Khaki S, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00621
   Khan R., 2022, APPL MACHINE LEARNIN, P3, DOI DOI 10.1016/B978-0-323-90550-3.00003-5
   Lee S, 2020, INT CONF ACOUST SPEE, P6279, DOI [10.1109/ICASSP40776.2020.9053726, 10.1109/icassp40776.2020.9053726]
   Mahum R, 2023, HUM ECOL RISK ASSESS, V29, P303, DOI 10.1080/10807039.2022.2064814
   Mohan P., 2018, Int. J. Intell. Eng. Syst, V11, P167, DOI DOI 10.22266/IJIES2018.0831.17
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Raja SP, 2022, IEEE ACCESS, V10, P23625, DOI 10.1109/ACCESS.2022.3154350
   Rajak RK., 2017, Int Res J Eng Technol, V4, P950
   Rajesh P, 2022, TECHNOL ECON SMART G, V7, DOI 10.1007/s40866-022-00144-z
   Roodschild M, 2020, PROG ARTIF INTELL, V9, P351, DOI 10.1007/s13748-020-00218-y
   Samee NA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134938
   Suruliandi A, 2021, MATH COMP MODEL DYN, V27, P117, DOI 10.1080/13873954.2021.1882505
   Tiwari Preeti, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P585, DOI 10.1007/978-981-13-7166-0_58
   Ozsahin DU, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020292
   Voss-Fels KP, 2019, THEOR APPL GENET, V132, P669, DOI 10.1007/s00122-018-3270-8
   Wang J, 2023, COMPUT ELECTRON AGR, V206, DOI 10.1016/j.compag.2023.107705
   Wang YQ, 2022, PETROL SCI, V19, P147, DOI 10.1016/j.petsci.2021.09.038
   Weilandt F, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030799
   Zaeimi M, 2020, SOFT COMPUT, V24, P12027, DOI 10.1007/s00500-019-04646-4
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29715
EP 29740
DI 10.1007/s11042-023-16653-7
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001064737700002
DA 2024-07-18
ER

PT J
AU Liu, LJ
   Tang, D
   Li, XH
   Ouyang, Y
AF Liu, Lijue
   Tang, Duo
   Li, Xihong
   Ouyang, Yan
TI Automatic fetal ultrasound image segmentation of first trimester for
   measuring biometric parameters based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transvaginal ultrasonography; Automatic segmentation; Attention fusion;
   Guide filter
ID PREGNANCY OUTCOMES; PREDICTION
AB Transvaginal ultrasonography (TVS) is a common method used by doctors to monitor the embryonic development. In the early stage of pregnancy, doctors assess the growth and development of the embryo by measuring biological indicators such as gestational sac area (GSA), yolk sac diameter (YSD), and crown-rump length (CRL) in TVS images. Even though these indicators can be manually obtained by experienced physicians, the manual measurement process is time-consuming, inefficient, and heavily dependent on the sonographer's expertise. To improve this situation, we, here, aimed to establish a modified Unet model, namely AFG-net, which is capable of automatically obtaining the related clinical values required for measuring embryonic development. Using this method, the essential values, including gestational sac (GS), yolk sac (YS) and embryo region in the TVS image, were easily and accurately identified and located, which were further completely separated by image segmentation to obtain the corresponding measurement values. Notably, this model is able to achieve superior segmentation effect even when the input image with poor quality, low contrast, fuzzy region boundary and complex anatomical shape by applying some advanced methods such as attention fusion and guide filter. Consequently, our results showed our model demonstrated a higher average precision, Intersection Over Union (IOU), and Dice coefficient (Dice) of GS, YS and embryo compared to a normal Unet, with 94.75%, 86.15% and 92.11% versus 92.01%, 83.00%, and 90.00%, respectively. The absolute error between the biological indicators (GSA, YSD and CRL) automatically extracted from the segmentation results and the manual measurement results is 0.66mm. The automatic segmentation and measurement process significantly reduces the subjectivity of manual measurement and reduces the clinician workload. It also helps to improve diagnostic accuracy, enables repeatability and standardization in clinical practice, and provides a valuable tool for prenatal care and monitoring.
C1 [Liu, Lijue; Tang, Duo] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
   [Liu, Lijue] Xiangjiang Lab, Changsha 410205, Peoples R China.
   [Liu, Lijue] Hunan ZIXING Intelligent Med Technol Co Ltd, Changsha 410221, Peoples R China.
   [Li, Xihong; Ouyang, Yan] Reprod & Genet Hosp CIT Xiangya, Changsha 410078, Peoples R China.
   [Li, Xihong; Ouyang, Yan] Clin Res Ctr Reprod & Genet Hunan Prov, Changsha 410078, Peoples R China.
C3 Central South University
RP Li, XH (corresponding author), Reprod & Genet Hosp CIT Xiangya, Changsha 410078, Peoples R China.; Li, XH (corresponding author), Clin Res Ctr Reprod & Genet Hunan Prov, Changsha 410078, Peoples R China.
EM 214612175@csu.edu.cn
FU Hunan Provincial Natural Science Foundation of~China [2023JJ60491]; Open
   Project of Xiangjiang Laboratory [22XJ02005]
FX The authors gratefully acknowledge the financial support provided by
   Hunan Provincial Natural Science Foundation of~China (2023JJ60491) and
   the Open Project of Xiangjiang Laboratory (22XJ02005).
CR Bilagi A, 2017, PRENATAL DIAG, V37, P705, DOI 10.1002/pd.5069
   Blaszczyk K, 2000, Ginekol Pol, V71, P699
   Chakkarwar VA, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P304, DOI 10.1109/IADCC.2010.5422938
   Doubilet PM, 2013, NEW ENGL J MED, V369, P1443, DOI 10.1056/NEJMra1302417
   Ejbali R, 2018, MULTIMED TOOLS APPL, V77, P6149, DOI 10.1007/s11042-017-4523-2
   El-Mekkawi SF, 2015, MIDDLE EAST FERTIL S, V20, P16, DOI 10.1016/j.mefs.2014.04.006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu XB, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15112444
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Ibrahim DA, 2016, AUTOMATIC SEGMENTATI
   Islam MN, 2022, BMC PREGNANCY CHILDB, V22, DOI 10.1186/s12884-022-04594-2
   Jeve Y, 2011, ULTRASOUND OBST GYN, V38, P489, DOI 10.1002/uog.10108
   Khazendar S, 2014, ANN C MED IM UND AN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Papaioannou GI, 2011, HUM REPROD, V26, P1685, DOI 10.1093/humrep/der130
   Qiao DH, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P203, DOI 10.1109/cibcb48159.2020.9277667
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rueda S, 2014, IEEE T MED IMAGING, V33, P797, DOI 10.1109/TMI.2013.2276943
   Suguna B, 2019, J GYNECOL OBSTET HUM, V48, P159, DOI 10.1016/j.jogoh.2018.10.016
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Westin CF, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P19, DOI 10.1016/B978-012373904-9.50009-X
   Wu LY, 2017, I S BIOMED IMAGING, P663, DOI 10.1109/ISBI.2017.7950607
   Yi Y, 2016, FERTIL STERIL, V105, P1261, DOI 10.1016/j.fertnstert.2016.01.033
   Yin CH, 2022, J MED BIOL ENG, V42, P49, DOI 10.1007/s40846-021-00674-4
   Yu Z, 2018, IEEE J BIOMED HEALTH, V22, P874, DOI 10.1109/JBHI.2017.2705031
   Zhang SH, 2019, LECT NOTES COMPUT SC, V11764, P797, DOI 10.1007/978-3-030-32239-7_88
   Zhao H., 2017, ARXIV
NR 34
TC 2
Z9 2
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27283
EP 27304
DI 10.1007/s11042-023-16565-6
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300011
DA 2024-07-18
ER

PT J
AU Wang, B
   Ding, HR
   Chen, C
AF Wang, Bo
   Ding, Haoran
   Chen, Cheng
TI AC-YOLOv4: an object detection model incorporating attention mechanism
   and atrous convolution for contraband detection in x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE X-ray security screening; YOLOv4; Object detection; Attention mechanism;
   Atrous spatial pyramid pooling; Transfer learning
AB The complex background of X-ray security detection images and the overlapping of contraband items with each other and their different sizes and locations lead to a high leakage rate and false detection of contraband items during the security screening process. To address the above problems, this paper proposes a target detection algorithm based on the YOLOv4 model with fused attention mechanism and atrous spatial pyramidal pooling, and calls it AC-YOLOv4. First, the original spatial pyramid pooling in YOLOv4 is replaced by atrous spatial pyramid pooling, which can enlarge the image receptive field and extract the features of contraband under different sizes. Second, the attention mechanism module is added to the neck part of the model to improve the extraction of deeper features of contraband and reduce background interference. Before training, we use K-means clustering algorithm to obtain the Anchor box which is more suitable for the specific X-ray security image dataset, and use transfer learning to train the network to accelerate the training speed of the model and improve the detection accuracy. The proposed X-ray security contraband detection model improves the recognition accuracy by 5.56%, 6.83% and 12.24% on the X-ray security datasets SIXray, OPIXray and XDXray respectively compared to the excellent SOTA target detection model - YOLOv7. The experimental results show that AC-YOLOv4 has a significantly improved detection capability compared to YOLOv4 and can effectively reduce the rate of missed and false detections of contraband in X-ray security screening, while improving the generalisation of the model for detecting contraband of different shapes and sizes.
C1 [Wang, Bo; Ding, Haoran; Chen, Cheng] Xinjiang Univ, Sch Software, Urumqi 830000, Peoples R China.
C3 Xinjiang University
RP Chen, C (corresponding author), Xinjiang Univ, Sch Software, Urumqi 830000, Peoples R China.
EM wangbo@xju.edu.cn; 107552104346@stu.xju.edu.cn;
   chenchengoptics@gmail.com
RI Ding, HaoRan/JDC-2556-2023; xiao, ming/KHT-1774-2024
FU Xinjiang Autonomous Region Key RD Project [2021B01002]
FX this work was supported by the Xinjiang Autonomous Region Key R&D
   Project (2021B01002)
CR Akçay S, 2016, IEEE IMAGE PROC, P1057, DOI 10.1109/ICIP.2016.7532519
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chang A, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107916
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng ZW., 2023, RADIO ENG, V53, P1836
   Dai Y., 2023, SPIE, V12596, P302
   Fang C, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23084069
   Galvez RL, 2018, 2018 IEEE 10 INT C H, P1, DOI [10.1109/HNICEM.2018.8666344, DOI 10.1109/HNICEM.2018.8666344]
   Gao Q, 2021, 2021 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND COMPUTER SCIENCE (ACCTCS 2021), P43, DOI 10.1109/ACCTCS52002.2021.00017
   Gaus YFA, 2019, 2019 International Joint Conference on Neural Networks (IJCNN), P1, DOI [10.1109/IJCNN.2019.8851829, DOI 10.1109/IJCNN.2019.8851829]
   Guo RH., 2021, LASER OPTOELECTRON P, V58, P65
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Nguyen HD, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13040565
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Koci Jola, 2020, 2020 International Conference on Computing, Networking, Telecommunications & Engineering Sciences Applications (CoNTESA), P10, DOI 10.1109/CoNTESA50436.2020.9302863
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li M., 2022, P CECNET, V2022, P81
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   [刘俊明 Liu Junming], 2020, [航空兵器, Aero Weaponry], V27, P44
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma CJ, 2023, NEUROCOMPUTING, V519, P1, DOI 10.1016/j.neucom.2022.11.034
   Mery D, 2017, IEEE T SYST MAN CY-S, V47, P682, DOI 10.1109/TSMC.2016.2628381
   Miao CJ, 2019, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR.2019.00222
   Nan X, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.2.023019
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Ni Q, 2023, FEW SHOT XRAY PROHIB, DOI [10.21203/rs.3.rs-2897746/v1, DOI 10.21203/RS.3.RS-2897746/V1]
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song Bo, 2022, 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P169, DOI 10.1109/PRAI55851.2022.9904110
   Thuan D., 2021, Bachelors Thesis
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang ZS, 2022, 2022 2ND IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND ARTIFICIAL INTELLIGENCE (SEAI 2022), P20, DOI 10.1109/SEAI55746.2022.9832407
   Wei YL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P138, DOI 10.1145/3394171.3413828
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HB, 2021, CHIN OPT, V14, P1417, DOI 10.37188/CO.2021-0078
   Wu Xiru, 2022, Journal of Physics: Conference Series, V2216, DOI 10.1088/1742-6596/2216/1/012104
   Xiaoke Zhu, 2021, CSAI 2021: 2021 5th International Conference on Computer Science and Artificial Intelligence, P27, DOI 10.1145/3507548.3507552
   Yu Qinghe, 2022, 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), P736, DOI 10.1109/ICFTIC57696.2022.10075330
   Yuan J., 2022, J PHYS C SERIES, V2390
   Zhang YS, 2022, APPL OPTICS, V61, P6297, DOI 10.1364/AO.461627
   Zhao CR, 2022, IEEE T INF FOREN SEC, V17, P998, DOI 10.1109/TIFS.2022.3154287
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 50
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26485
EP 26504
DI 10.1007/s11042-023-16628-8
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300006
DA 2024-07-18
ER

PT J
AU Joshi, NS
   Raghuwanshi, R
   Agarwal, YM
   Annappa, B
   Sachin, DN
AF Joshi, Nisarg S.
   Raghuwanshi, Raghav
   Agarwal, Yash M.
   Annappa, B.
   Sachin, D. N.
TI ARIMA-PID: container auto scaling based on predictive analysis and
   control theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Virtual machines; Auto-scaling; Containerization
AB Containerization has become a widely popular virtualization mechanism alongside Virtual Machines (VMs) to deploy applications and services in the cloud. Containers form the backbone of the modern architectures around microservices and provide a lightweight virtualization mechanism for IoT and Edge systems. Elasticity is one of the key requirements of modern applications with various constraints ranging from Service Level Agreements (SLA) to optimization of resource utilization, cost management, etc. Auto Scaling is a technique used to attain elasticity by scaling the number of containers or resources. This work introduces a novel mechanism for auto-scaling containers in cloud environments, addressing the key elasticity requirement in modern applications. The proposed mechanism combines predictive analysis using the Auto-Regressive Integrated Moving Average (ARIMA) model and control theory utilizing the Proportional-Integral-Derivative (PID) controller. The major contributions of this work include the development of the ARIMA-PID algorithm for forecasting resource utilization and maintaining desired levels, comparing ARIMA-PID with existing threshold mechanisms, and demonstrating its superior performance in terms of CPU utilization and average response times. Experimental results showcase improvements of approximately 10% in CPU utilization and 30%
C1 [Joshi, Nisarg S.; Raghuwanshi, Raghav; Agarwal, Yash M.; Annappa, B.; Sachin, D. N.] Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Mangaluru, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Sachin, DN (corresponding author), Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Mangaluru, India.
EM njnisarg@gmail.com; raghavraghuwanshi0101@gmail.com;
   yashagarwal786@gmail.com; annappa@ieee.org;
   sachindn.207cs004@nitk.edu.in
RI Basava, Dr. Annappa/P-3077-2014
OI Basava, Dr. Annappa/0000-0002-4049-3677
CR Al-Dhuraibi Y, 2018, CLOSER: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND SERVICES SCIENCE, P322, DOI 10.5220/0006652403220329
   Al-Dhuraibi Y, 2017, IEEE INT CONF CLOUD, P472, DOI 10.1109/CLOUD.2017.67
   Berton L, 2023, ANSIBLE KUBERNETES E, P239
   Chouliaras S, 2022, SIMUL MODEL PRACT TH, V121, DOI 10.1016/j.simpat.2022.102654
   da Silva VG, 2018, APPL COMPUT SYST, V23, P21, DOI 10.2478/acss-2018-0003
   de Abranches MC, 2016, 15TH IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (IEEE NCA 2016), P343, DOI 10.1109/NCA.2016.7778639
   Ganne A, 2022, INT RES J MOD ENG TE, V4
   HANG CC, 1991, IEE PROC-D, V138, P111, DOI 10.1049/ip-d.1991.0015
   Hoenisch P, 2015, LECT NOTES COMPUT SC, V9435, P316, DOI 10.1007/978-3-662-48616-0_20
   Horovitz S, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2018), P85, DOI 10.1109/FiCloud.2018.00020
   Imdoukh M, 2020, NEURAL COMPUT APPL, V32, P9745, DOI 10.1007/s00521-019-04507-z
   Jorge-Martinez D, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01195-8
   Kukade PP., 2015, INT J SCI RES, V4, P1960
   Li GD, 2009, INT J INNOV COMPUT I, V5, P3457
   Li YC, 2016, PROCEEDINGS OF 2016 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P75, DOI 10.1109/ICCSNT.2016.8070122
   Meng Y, 2016, PR IEEE I C PROGR IN, P468, DOI 10.1109/PIC.2016.7949546
   Nardelli M, 2017, ZEUS, P59
   Pal D, 2015, CSI COMMUNICATIONS
   Rabiu S., 2022, INT J DATA SCI, V3, P80, DOI [10.18517/ijods.3.2.80-92.2022, DOI 10.18517/IJODS.3.2.80-92.2022]
   Rossi F, 2019, IEEE INT CONF CLOUD, P329, DOI 10.1109/CLOUD.2019.00061
   Sangpetch A, 2017, CLOSER: PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND SERVICES SCIENCE, P75, DOI 10.5220/0006254601030111
   Schuler L, 2021, 21ST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2021), P804, DOI 10.1109/CCGrid51090.2021.00098
   Sheganaku G, 2023, FUTURE GENER COMP SY, V138, P296, DOI 10.1016/j.future.2022.09.001
   Somma G, 2020, IEEE CONF COMPUT, P1153, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162876
   Sun L, 2021, ENGINEERING-PRC, V7, P1239, DOI 10.1016/j.eng.2021.04.020
   Wang X.-S., 2007, Journal of China University of Mining and Technology, V17, P40, DOI [10.1016/S1006-1266(07)60009-1, DOI 10.1016/S1006-1266(07)60009-1]
   Willis M., 1999, Proportional-integral-derivative control
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Zhang F, 2019, FUTURE GENER COMP SY, V98, P672, DOI 10.1016/j.future.2018.09.009
   ZIEGLER JG, 1993, J DYN SYST-T ASME, V115, P220, DOI 10.1115/1.2899060
NR 35
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26369
EP 26386
DI 10.1007/s11042-023-16587-0
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900003
DA 2024-07-18
ER

PT J
AU Yang, YP
   Yang, ZZ
   Le, J
   Li, JL
AF Yang, Yongpeng
   Yang, Zhenzhen
   Le, Jun
   Li, Jianlin
TI Nonconvex y-norm and Laplacian scale mixture with salient map for moving
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Moving object detection; Low-rank and sparse decomposition; Nonconvex
   ?-norm; Laplacian scale mixture; Alternating direction method of
   multipliers
ID LOW-RANK
AB Moving object detection which has attracted wide attention is the critical issue of computer vision. Consequently, the low-rank and sparse decomposition (LRSD) has been a powerful technology for extracting the moving object from videos which has achieved improvement for moving object detection. However, it still has some defaults such as the lower degree for approximating the low-rank and sparsity components, ignoring the spatial information of videos, being sensitive to noise, and so on. To address these problems mentioned above, we propose a new LRSD method which is named nonconvex norm and Laplacian scale mixture with salient map (NNLSMSM). It adopts the nonconvex ?-norm and the Laplacian scale mixture (LSM) to approximate the low-rank and sparsity components of traditional LRSD model for enhancing the degree of approximating. Meanwhile, a salient map mechanism which can effectively capture the spatial information from videos is introduced to NNLSMSM. In addition, we extend our proposed NNLSMSM method to a robust NNLSMSM (RNNLSMSM) method for enhancing its robustness via introducing a noise item. It can effectively solve the problem of being sensitive to noise. In addition, we adopt the alternating direction method of multipliers (ADMM) to solve our proposed NNLSMSM and RNNLSMSM methods. At last, extensive experiments which are performed on various popular datasets by some state-ofthe-art methods demonstrate the effectiveness and superiority of our proposed NNLSMSM and RNNLSMSM methods.
C1 [Yang, Yongpeng; Li, Jianlin] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng; Yang, Zhenzhen; Le, Jun] Nanjing Univ Posts & Telecommun, Minist Educ, Broadband Wireless Commun & Sensor Network Technol, Key Lab, Nanjing 210023, Peoples R China.
C3 Nanjing Vocational College of Information Technology; Nanjing University
   of Posts & Telecommunications
RP Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.; Yang, YP; Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Minist Educ, Broadband Wireless Commun & Sensor Network Technol, Key Lab, Nanjing 210023, Peoples R China.
EM yangyp@njcit.cn; yangzz@njupt.edu.cn
FU Outstanding Teaching Team of Qing Lan Project of Jiangsu in 2023;
   National Natural Science Foundation of China [62071242, 62171232];
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX22_0955, SJCX23_0251]; NUPTSF [NY220207]
FX This work is supported by the Outstanding Teaching Team of Qing Lan
   Project of Jiangsu in 2023, the National Natural Science Foundation of
   China (Nos.62071242, 62171232), the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (Nos.KYCX22_0955, SJCX23_0251),
   and the NUPTSF (No.NY220207).
CR Azghani M, 2019, IEEE Transactions on Circuits and Systems for Video Technology, P1
   Boukhriss RR, 2020, PATTERN RECOGN LETT, V129, P205, DOI 10.1016/j.patrec.2019.11.004
   Box G. E. P., 1992, Bayesian inference in statistical analysis, DOI DOI 10.1002/9781118033197.CH4
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Candes Emmanuel, 2010, 2010 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2010), P201, DOI 10.1109/SAM.2010.5606734
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Ce L, 2009, Massachusetts Institute of Technology, P153
   Chen XA, 2018, IEEE T NEUR NET LEAR, V29, P5380, DOI 10.1109/TNNLS.2018.2796606
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Fei LK, 2017, PATTERN RECOGN, V67, P252, DOI 10.1016/j.patcog.2017.02.017
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Hu ZX, 2020, IEEE ACCESS, V8, P41026, DOI 10.1109/ACCESS.2020.2977273
   Huang T, 2017, IEEE T IMAGE PROCESS, V26, P3171, DOI 10.1109/TIP.2017.2676466
   Kang B, 2019, OPTIK, V183, P232, DOI 10.1016/j.ijleo.2019.02.025
   Kang Z, 2015, IEEE DATA MINING, P211, DOI 10.1109/ICDM.2015.15
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liu QH, 2019, IEEE ACCESS, V7, P76131, DOI 10.1109/ACCESS.2019.2914461
   Liu S, 2021, COMPLEX INTELL SYST, V7, P1895, DOI 10.1007/s40747-020-00161-4
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Lorenz D, 2018, Computational Optimization and Applications, V4
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Tao P., 1997, Acta Mathematica, V22, P287
   Tianyi Zhou, 2012, Proceedings of the 2012 IEEE International Symposium on Information Theory - ISIT, P1286, DOI 10.1109/ISIT.2012.6283064
   Wang SJ, 2020, IET SIGNAL PROCESS, V14, P269, DOI 10.1049/iet-spr.2019.0365
   Wang YL, 2020, IEEE ACCESS, V8, P157493, DOI 10.1109/ACCESS.2020.3018705
   Wen F, 2018, IEEE ACCESS, V6, P69883, DOI 10.1109/ACCESS.2018.2880454
   Yang YP, 2020, IEEE ACCESS, V8, P84217, DOI 10.1109/ACCESS.2020.2992132
   Yang ZZ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107527
   Yang ZZ, 2019, J FRANKLIN I, V356, P10138, DOI 10.1016/j.jfranklin.2019.09.017
   Yang ZZ, 2018, IEEE ACCESS, V6, P56945, DOI 10.1109/ACCESS.2018.2872688
   Yano KH, 2018, J NUCL MATER, V502, P201, DOI 10.1016/j.jnucmat.2018.02.003
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Yin Li, 2018, Journal of Computer Applications, V38, P879, DOI 10.11772/j.issn.1001-9081.2017092198
   Yuan X, 2009, Pacific Journal of Optimization, V9
   Zhou T, 2020, IEEE C COMPUTER VISI, P6985
   Zhou T., 2011, P 28 INT C MACHINE L, P33
   Zhou T, 2023, IEEE Transactions on Pattern Analysis and Machine Intelligence, P1
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 40
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 29
PY 2023
DI 10.1007/s11042-023-16561-w
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R4AE6
UT WOS:001063783300003
DA 2024-07-18
ER

PT J
AU Singh, P
   Kamal, AE
   Bansal, A
   Kumar, S
AF Singh, Prabhat
   Kamal, Ahmed E.
   Bansal, Abhay
   Kumar, Sunil
TI Road pothole detection from smartphone sensor data using improved LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road abnormalities; Long short term memory (LSTM); One dimensional-local
   binary pattern (1D-LDP); Accelerometer; Gyroscope; Pothole detection
ID ACCELEROMETER; CLASSIFICATION
AB Road abnormalities can be caused by man-made and natural disasters that affect the safety of drivers and damage vehicles. Therefore, several automatic road monitoring approaches have been proposed to monitor the road surface and detect road abnormalities like potholes. However, low accuracy in detecting the pothole in low-light conditions is taken as the main problem in this work. To address this issue, we presented an Improved Long Short Term Memory model (ILSTM) that combines a three-layer deep LSTM with a One-Dimensional Local Binary Pattern (1D-LBP) layer to detect the presence of potholes during low-light conditions and extract features such as the number of neighbouring samples and pixel values. The proposed strategy collects the pothole data from accelerometer and gyroscope sensor data using a smart phone. This model is used to classify the sensor data and label it either as a pothole or normal. Besides, this makes classification possible and extracts the location of the pothole. Evaluation results demonstrate that the proposed ILSTM approach is also robust to low lighting conditions with a detection accuracy of 99% and requires less execution time in classifying potholes and non-pothole regions on the pothole dataset collected with the help of an accelerometer and a gyroscope.
C1 [Singh, Prabhat; Bansal, Abhay; Kumar, Sunil] Amity Sch Engn & Technol, Dept Comp Sci, Noida 201301, Uttar Pradesh, India.
   [Kamal, Ahmed E.] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA.
C3 Amity University Noida; Iowa State University
RP Singh, P (corresponding author), Amity Sch Engn & Technol, Dept Comp Sci, Noida 201301, Uttar Pradesh, India.
EM prabhatsinghwal@gmail.com
RI Kumar, Sunil/GYV-0347-2022
OI Kumar, Sunil/0000-0002-1953-6273
CR Agebure MA, 2022, J KING SAUD UNIV-COM, V34, P1718, DOI 10.1016/j.jksuci.2020.08.012
   Allouch A, 2017, IEEE SENS J, V17, P4231, DOI 10.1109/JSEN.2017.2702739
   Ameur S, 2020, ENTERTAIN COMPUT, V35, DOI 10.1016/j.entcom.2020.100373
   Anaissi A, 2019, J CIV STRUCT HEALTH, V9, P91, DOI 10.1007/s13349-019-00323-0
   Anand Sukhad, 2018, 2018 Digital Image Computing: Techniques and Applications (DICTA), DOI 10.1109/DICTA.2018.8615819
   Anandhalli Mallikarjun, 2022, International Journal of Information Technology, P3343, DOI 10.1007/s41870-022-00881-5
   Baek JW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196662
   Bansal K, 2020, INTERNET TECHNOL LET, V3, DOI 10.1002/itl2.156
   Bhamare L, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND INFORMATION ENGINEERING (ICEEIE 2021), P472, DOI 10.1109/ICEEIE52663.2021.9616755
   Bhatt U, 2017, ARXIV
   Cao MT, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101182
   Carlos MR, 2018, IEEE T INTELL TRANSP, V19, P3334, DOI 10.1109/TITS.2017.2773084
   Casas-Avellaneda Diego Andrés, 2016, Dyna rev.fac.nac.minas, V83, P156
   Celaya-Padilla JM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020443
   Chen HS, 2020, INT J MACH LEARN CYB, V11, P899, DOI 10.1007/s13042-020-01078-7
   Dey MR, 2019, TENCON IEEE REGION, P2491, DOI [10.1109/TENCON.2019.8929717, 10.1109/tencon.2019.8929717]
   Dhiman A, 2020, IEEE T INTELL TRANSP, V21, P3536, DOI 10.1109/TITS.2019.2931297
   Du RH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020451
   Fan R, 2020, IEEE T IMAGE PROCESS, V29, P897, DOI 10.1109/TIP.2019.2933750
   Fox A, 2015, 2015 12TH ANNUAL IEEE INTERNATIONAL CONFERENCE ON SENSING, COMMUNICATION, AND NETWORKING (SECON), P515, DOI 10.1109/SAHCN.2015.7338353
   Gupta S, 2020, MULTIMED TOOLS APPL, V79, P26265, DOI 10.1007/s11042-020-09293-8
   Kavitha D, 2021, J AMB INTEL HUM COMP, V12, P7417, DOI 10.1007/s12652-020-02419-8
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Lekshmipathy J, 2021, INT J PAVEMENT RES T, V14, P63, DOI 10.1007/s42947-020-0033-0
   Mednis A, 2011, 2011 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS AND WORKSHOPS (DCOSS)
   Motta G, 2015, 9TH IEEE INTERNATIONAL SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE 2015), P88, DOI 10.1109/SOSE.2015.15
   Hoang ND, 2019, ENG COMPUT-GERMANY, V35, P487, DOI 10.1007/s00366-018-0611-9
   Sagheer A, 2019, NEUROCOMPUTING, V323, P203, DOI 10.1016/j.neucom.2018.09.082
   Sathya R, 2022, WIRELESS PERS COMMUN, V126, P1241, DOI 10.1007/s11277-022-09790-z
   Singh P, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P63, DOI [10.1109/confluence47617.2020.9057829, 10.1109/Confluence47617.2020.9057829]
   Tan HX, 2019, GAIT POSTURE, V74, P128, DOI 10.1016/j.gaitpost.2019.09.007
   Tian Y, 2018, NEUROCOMPUTING, V318, P297, DOI 10.1016/j.neucom.2018.08.067
   Varona B, 2020, PERS UBIQUIT COMPUT, V24, P519, DOI 10.1007/s00779-019-01234-z
   Vi Nguyen Thanh Le, 2019, Information Processing in Agriculture, V6, P116, DOI 10.1016/j.inpa.2018.08.002
   Wang HJ, 2018, IEEE ACCESS, V6, P29078, DOI 10.1109/ACCESS.2018.2839765
   Wang LK, 2020, CIRC SYST SIGNAL PR, V39, P837, DOI 10.1007/s00034-019-01116-y
   Wu C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195564
   Wu HB, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100936
   Yun HS, 2019, J ELECTR ENG TECHNOL, V14, P2155, DOI 10.1007/s42835-019-00225-7
   Zantalis F, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040094
NR 40
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26009
EP 26030
DI 10.1007/s11042-023-16177-0
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500006
DA 2024-07-18
ER

PT J
AU Jaiswal, V
   Sharma, V
   Bisen, D
AF Jaiswal, Varshali
   Sharma, Varsha
   Bisen, Dhananjay
TI Modified Deep-Convolution Neural Network Model for Flower Images
   Segmentation and Predictions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Deep convolution neural network; Classification;
   Edge detection; Computer Vision; L*a*b color space
ID CLASSIFICATION
AB Nowadays, recognition of plant, leaf, and flower images is one of the most challenging issues due to the wide variety of classes on earth, which are based on amount of texture, color distinctiveness, shape distinctiveness, and different sizes. This paper proposes a hybrid method, known as Modified Deep-Convolution Neural Network Model (MDCNN) for the segmentation and recognition of flower images that employs Deep Convolution Neural Network with a combination of color model and image processing. Initially, L*a*b color space conversion is applied to reduce the multi-dimensions and geometry of images in which the red-green axis, blue-yellow axis, and luminosity are represented by chromaticity layers a*, b* and L* respectively. Moreover, the model also takes an input of different flower images and converts the RGB color model into the L*a*b color model while reducing the effort of image segmentation. That is performed by the canny edge detection algorithm. Moreover, a deep convolutional neural network with hidden layer is designed for classification and prediction of flowers with five different classes like daisy, dandelion, rose, tulip, and sunflower. This paper also represents the minimum computation time of MDCNN to detect flowers, along with the CPU and GPU. It is also compared with pre-trained convolutional neural networks such as VggNet-16, GoogleNet, AlexNet, and ResNet-50 in terms of f1-score, accuracy, precision, and sensitivity. Finally, the proposed method accurately recognised flower images with accuracy up to 98%, maximising up to + 1.89% from the state of the art while minimising the image segmentation error rate.
C1 [Jaiswal, Varshali] Avantika Univ, Sch Engn, Ujjain, India.
   [Sharma, Varsha] RGPV, Sch Informat Technol, Bhopal, India.
   [Bisen, Dhananjay] Madhav Inst Sci & Technol, Gwalior, India.
C3 Rajiv Gandhi Technological University; Madhav Institute of Technology &
   Science
RP Jaiswal, V (corresponding author), Avantika Univ, Sch Engn, Ujjain, India.
EM varshalijaiswal@gmail.com; varshasharma@rgtu.net; bisen.it2007@gmail.com
RI JAISWAL, VARSHALI/ADQ-9810-2022
OI JAISWAL, VARSHALI/0000-0002-5240-271X
CR Abbas T, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9359353
   Alipour N., 2021, P 2021 7 INT C WEB R, P1, DOI [10.1109/ICWR51868.2021.9443129, DOI 10.1109/ICWR51868.2021.9443129]
   Almogdady H., 2018, Int. J. Sci. Technol. Res., V7, P166
   Atrish A, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P103, DOI 10.1145/3177404.3177432
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Bisen D, 2022, MULTIMED TOOLS APPL, V81, P18011, DOI 10.1007/s11042-022-12775-6
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Chen Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131584
   Christenhusz MJM, 2016, PHYTOTAXA, V261, P201, DOI 10.11646/phytotaxa.261.3.1
   Donahue J, 2014, PR MACH LEARN RES, V32
   Gavai NR, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P154, DOI 10.1109/BID.2017.8336590
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gogul I., 2017, 2017 Fourth International Conference on Signal Processing, Communication and Networking (ICSCN), P1
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hiary H, 2018, IET COMPUT VIS, V12, P855, DOI 10.1049/iet-cvi.2017.0155
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ito S, 2010, LECT NOTES COMPUT SC, V6315, P701
   kaggle, FLOW DAT
   Kaur S, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P13, DOI 10.1109/ICSCCC.2018.8703350
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Li BX, 2014, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2014.6742916
   Lodh A, 2017, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON 2017 DEVICES FOR INTEGRATED CIRCUIT (DEVIC), P790, DOI 10.1109/DEVIC.2017.8074061
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu ZC, 2021, IEEE T PATTERN ANAL, V43, P2971, DOI 10.1109/TPAMI.2021.3052758
   Lukman A, 2021, MULTIMED TOOLS APPL, V80, P16059, DOI 10.1007/s11042-020-10312-x
   MATLAB, US
   Mete B.R., 2019, 2019 3 INT S MULT ST, P1, DOI [DOI 10.1109/ISMSIT.2019.8932908, 10.1109/ismsit.2019.8932908]
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Nguyen TN, 2016, AUN SEED NET REG  C, DOI [10.1049/iet-cvi.2017.0155, DOI 10.1049/IET-CVI.2017.0155]
   Ong ZY, 2021, INT C DIGITAL TRANSF, P121, DOI [10.56453/icdxa.2021.1012, DOI 10.56453/ICDXA.2021.1012]
   Sabeena M, 2021, MULTIMED TOOLS APPL, V80, P26333, DOI 10.1007/s11042-021-10925-w
   Sahota Kirti Kaur, 2017, 2017 International Conference on Intelligent Communication and Computational Techniques (ICCT), P228, DOI 10.1109/INTELCCT.2017.8324050
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Simonyan K, 2014, COMPUTER SCI, DOI DOI 10.48550/ARXIV.1409.1556
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
NR 37
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25713
EP 25739
DI 10.1007/s11042-023-16530-3
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100008
DA 2024-07-18
ER

PT J
AU Bandopadhaya, S
   Roy, A
AF Bandopadhaya, Shuvabrata
   Roy, Amarjit
TI Early detection of silent hypoxia in COVID-19 pneumonia using deep
   learning and IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Silent hypoxia; COVID-19 pneumonia; Internet of things;
   Time-series forecasting; LSTM encoder-decoder model
ID PREDICTION; SMART
AB Unlike normal pneumonia, in COVID-19 pneumonia, the shortfall of oxygen occurs without any noticeable breathing difficulties leads to multiple organ failure and death. The early detection of silent hypoxia in COVID-19 pneumonia is the key to save many lives from this deadly disease. This paper has proposed an e-health solution for early detection of the hypoxia condition of COVID-19 patients using internet of things (IoT) and deep learning techniques. The proposed solution has implemented an IoT framework to collect the percentage of oxygen saturation level in the blood (SpO(2)) of the patient on real-time basis. It has proposed a time-series forecasting model with deep learning, that being trained with the collected data, forecasts two upcoming SpO(2)readingsefficiently. The model is validated with the SpO(2) level data of 261 hospitalized COVID-19 infected patients with varying level of criticality updated in each 2 hours, and the absolute percentage of errors (APE) in the prediction process has been observed around similar to 1.56%. The proposed methodology has great potential to control fatality rate in COVID-19 as the early detection of hypoxia helps to initiate the necessary course of action at appropriate time.
C1 [Bandopadhaya, Shuvabrata] Banasthali Vidyapith, Radha Kishnpura, Rajasthan, India.
   [Roy, Amarjit] Ghani Khan Choudhury Inst Engn & Technol, Malda, India.
C3 Banasthali Vidyapith
RP Roy, A (corresponding author), Ghani Khan Choudhury Inst Engn & Technol, Malda, India.
EM royamarjit90@gmail.com
RI Roy, Amarjit/ABD-1033-2020
CR Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Alwadhi V, 2017, INDIAN PEDIATR, V54, P729
   Arora P, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110017
   Ashisha G. R., 2019, Advances in Big Data and Cloud Computing. Proceedings of ICBDCC18. Advances in Intelligent Systems and Computing (AISC 750), P401, DOI 10.1007/978-981-13-1882-5_34
   Barajas M, 2023, 45 MEX C BIOM ENG CN, V86, P459
   Chandra A, 2020, BMJ CASE REP, V13, DOI 10.1136/bcr-2020-237207
   Chatterjee P, 2015, INT CONF COMPUT INTE, P903, DOI 10.1109/CICN.2015.178
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Crilly PB, 1997, IEEE IMTC P, P102, DOI 10.1109/IMTC.1997.603924
   Elsworth S, 2020, Arxiv, DOI arXiv:2003.05672
   Gu K, 2018, IEEE T IND INFORM, V14, P3946, DOI 10.1109/TII.2018.2793950
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hammerla NY, 2016, PROC 25 INT JOINT C
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Hidayat Alfin, 2020, 2020 3rd International Conference on Computer and Informatics Engineering (IC2IE), P443, DOI 10.1109/IC2IE50715.2020.9274663
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Karthickraja R, 2022, INT J PERVASIVE COMP, V18, P499, DOI 10.1108/IJPCC-09-2020-0146
   Khattak MI, 2021, INT J INTERACT MULTI, V6, P15, DOI 10.9781/ijimai.2021.04.002
   Levitan R, 2020, INFECT THATS SILENTL
   Levitan RM, 2020, ACAD EMERG MED, V27, P785, DOI 10.1111/acem.14052
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Ma XQ, 2019, IEEE ACCESS, V7, P181721, DOI 10.1109/ACCESS.2019.2958962
   New W., 1987, US PATENT, V4
   Pap IA, 2018, IEEE INT CONF AUTO, DOI 10.1109/AQTR.2018.8402711
   Prada J, 2021, INT J INTERACT MULTI, V6, P7, DOI 10.9781/ijimai.2021.04.001
   Prasanth CP, 2021, 2021 INN POW ADV COM, P1
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Roy A, 2023, VISUAL COMPUT, V39, P5809, DOI 10.1007/s00371-022-02697-7
   Roy A, 2022, MULTIMED TOOLS APPL, V81, P34463, DOI 10.1007/s11042-021-11832-w
   Semwal N, 2019, J INFORM OPTIM SCI, V40, P1787, DOI 10.1080/02522667.2019.1703269
   Skrvan A., 2022, 2022 ELEKTRO (ELEKTRO), P1
   Teo J, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01587-6
   Tyagi S, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P503, DOI 10.1109/CONFLUENCE.2016.7508172
   Von Chong A, 2019, MICROELECTRON J, V88, P128, DOI 10.1016/j.mejo.2018.03.005
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
NR 35
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16473-9
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900006
DA 2024-07-18
ER

PT J
AU Soylu, E
   Soylu, T
AF Soylu, Emel
   Soylu, Tuncay
TI A performance comparison of YOLOv8 models for traffic sign detection in
   the Robotaxi-full scale autonomous vehicle competition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic sign detection; YOLOv8; Autonomous car; Deep learning
ID RECOGNITION
AB The ability to recognize traffic signs is a critical skill for safe driving, as traffic signs provide drivers with essential information about the road conditions, potential hazards, speed limits, and other important details that can impact their driving. By recognizing and understanding traffic signs, drivers can react quickly and appropriately to different situations on the road, which helps prevent accidents and ensures the safety of all road users. As part of the Robotaxi-Full Scale Autonomous Vehicle Competition, a project was undertaken to develop a traffic sign recognition system using YOLOv8, a state-of-the-art deep learning model that can detect and classify objects in real-time. The project team trained YOLOv8 on a dataset of traffic sign images to create a model that could accurately recognize and classify different types of traffic signs. This traffic sign recognition system has the potential to significantly improve road safety by helping autonomous vehicles and human drivers to better understand their surroundings and react appropriately to changing road conditions. The system can assist drivers by providing real-time alerts and warnings about potential hazards, speed limits, and other important information. Furthermore, this project demonstrates the power and potential of deep learning and artificial intelligence in improving transportation safety and efficiency. As AI technology continues to advance, we can expect to see more innovative applications in the automotive industry that will help improve the driving experience and make our roads safer for everyone.
C1 [Soylu, Emel] Samsun Univ, Fac Engn, Dept Software Engn, Samsun, Turkiye.
   [Soylu, Tuncay] Samsun Univ, Fac Engn, Dept Elect Elect Engn, Samsun, Turkiye.
C3 Samsun University; Samsun University
RP Soylu, E (corresponding author), Samsun Univ, Fac Engn, Dept Software Engn, Samsun, Turkiye.
EM emel.soylu@samsun.edu.tr; tuncay.soylu@samsun.edu.tr
OI SOYLU, Emel/0000-0003-2774-9778
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [895869]
FX This study received financial support from the Scientific and
   Technological Research Council of Turkey (TUBITAK) in 2023 as a project
   of the Samrobotik team with ID 895869.
CR Abdallah MKA, 2022, AUTONOMOUS SELF DRIV
   [Anonymous], 2023, PROPULSION SHAFTING
   Ansari S, 2022, IEEE T INTELL VEHICL, V7, P499, DOI 10.1109/TIV.2022.3154426
   Atif M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072683
   Bahlmann C, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P255
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen EH, 2019, IEEE INT C INTELL TR, P325, DOI [10.1109/itsc.2019.8917340, 10.1109/ITSC.2019.8917340]
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Dasgupta S, 2022, INTERNATIONAL CONFERENCE ON TRANSPORTATION AND DEVELOPMENT 2022: TRAFFIC OPERATIONS AND ENGINEERING, P72
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   Dumitriu A, RIP CURRENT SEGMENTA, P1261
   Eteifa S, 2021, TRANSPORT RES REC, V2675, P127, DOI 10.1177/03611981211000748
   Fang CY, 2003, IEEE T VEH TECHNOL, V52, P1329, DOI 10.1109/TVT.2003.810999
   Gad AF, 2023, EVALUATING OBJECT DE
   Gao B., 2019, P 2019 4 INT C AUTOM, P1
   Garg P, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944491
   github, 2023, BRIEF SUMMARY YOLOV8
   Gu Y, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040487
   Guo S, 2023, VISUAL COMPUT, V39, P1363, DOI 10.1007/s00371-022-02412-6
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   Hui J, 2023, MAP MEAN AVERAGE PRE
   Jiang PY, 2022, PROCEDIA COMPUT SCI, V199, P1066, DOI 10.1016/j.procs.2022.01.135
   Jiang Z., 2020, arXiv
   Jocher G., 2020, YOLOv5
   Karmakar S, 2022, AIJR ABSTR, V22
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., 2022, J FRANKLIN I
   Lou HT, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102323
   Malekzadeh M, 2022, IEEE INT C INTELL TR, P2393, DOI 10.1109/ITSC55140.2022.9921864
   Marques R, 2022, ICAART, P818, DOI 10.5220/0010914100003116
   Mehta S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1293, DOI [10.1109/ICCS45141.2019.9065537, 10.1109/iccs45141.2019.9065537]
   Nikitas A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072789
   Olugbade S, 2022, MATH COMPUT APPL, V27, DOI 10.3390/mca27050077
   Priscila SS, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/3379843
   Rajendran SP, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944890
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Satti SK, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7453
   Sestino A, 2022, TECHNOL SOC, V70, DOI 10.1016/j.techsoc.2022.102017
   Singh K., 2022, Adv. J. Graduate Res, V11, P23, DOI [10.21467/ajgr.11.1.23-33, DOI 10.21467/AJGR.11.1.23-33]
   Srinivas Rao P, 2022, REV SELF DRIVING CAR
   Sun Y, 2019, CHIN AUTOM CONGR, P2851, DOI [10.1109/CAC48633.2019.8997240, 10.1109/cac48633.2019.8997240]
   teknofest, 2023, ROBOTAXI FULL SCALE
   Tengilimoglu O, 2023, TRANSPORT RES E-LOG, V169, DOI 10.1016/j.tre.2022.102989
   Terven J, 2023, COMPREHENSIVE REV YO, P1
   Torbaghan ME, 2022, ACCIDENT ANAL PREV, V166, DOI 10.1016/j.aap.2021.106543
   ultralytics, 2023, YOLO BRIEF HIST
   van der Aalst W, 2022, ARXIV
   Vennelakanti A, 2019, I SYMP CONSUM ELECTR
   Wang W, 2022, Learning equivariant segmentation with instance-unique querying
   Yan Y, 2023, IEEE ACCESS
   Yasmin S, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.6.061806
   You S, 2020, INFORMATION, V11, DOI 10.3390/info11100475
   Zhai D, SHADOWS CAN BE DANGE, P15345
   Zhang HB, 2020, IEEE ACCESS, V8, P64145, DOI 10.1109/ACCESS.2020.2984554
   Zuo ZR, 2017, IEEE INT CON DIS, P286, DOI 10.1109/ICDCSW.2017.34
NR 57
TC 6
Z9 6
U1 16
U2 99
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-16451-1
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100007
DA 2024-07-18
ER

PT J
AU Pabba, C
   Bhardwaj, V
   Kumar, P
AF Pabba, Chakradhar
   Bhardwaj, Vishal
   Kumar, Praveen
TI A visual intelligent system for students' behavior classification using
   body pose and facial features in a smart classroom
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classroom video analytics; Student behavior; Human pose analysis; Facial
   features; Smart classroom; Multi-object tracking
AB Developing intelligent visual systems for next-generation smart classrooms has become an active area of research in computer vision. Advances in computer vision and deep learning technologies have enabled the development of such systems capable of automatically classifying students' behavior and providing feedback to teachers. Recently, some vision-based methods have been proposed for this purpose. However, most works do not integrate multiple visual cues like facial expressions and body poses, which can effectively improve classification accuracy. Moreover, these methods cannot be extended to get individual students' behavior feedback. This paper attempts to fill these research gaps by proposing a novel multiple visual cues-based automated system that monitors and reports individual students' and overall class behavior. First, the system detects and tracks each student from the input classroom video frames. Then, it extracts body pose, mobile proximity, and facial features using the Openpose and Py-Feat frameworks and combines them into a single feature vector. This vector is fed into the trained behavior model, classifying each student's behavior as "positive" or "negative." Subsequently, the individual labels are aggregated frame-by-frame to estimate the overall class behavior. The behavior model was developed by training a customized neural network architecture on our newly developed dataset, named "Classroom Spontaneous Student Behavior Dataset." The model trained on concatenated features achieved 91.30% and 90.80% training and validation accuracy, respectively, outperforming the models trained on individual features and other relevant methods. Additionally, we empirically analyzed the proposed system's computational complexity and demonstrated its output on a sample classroom video.
C1 [Pabba, Chakradhar; Bhardwaj, Vishal; Kumar, Praveen] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur 440010, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Pabba, C (corresponding author), Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur 440010, Maharashtra, India.
EM pck2507@gmail.com; vb.3596@gmail.com; praveen.kverma@gmail.com
RI Bhardwaj, Vishal/AAY-2841-2021
OI Pabba, Chakradhar/0000-0001-9135-8216
CR Ahuja Karan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351229
   Badiola-Bengoa A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185996
   Barquero G, 2022, UNDERSTANDING SOCIAL, V173, P139
   Behera A, 2020, INT J ARTIF INTELL E, V30, P236, DOI 10.1007/s40593-020-00195-2
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhutoria A., 2022, Computers and Education: Artificial Intelligence, V3, P100068, DOI DOI 10.1016/J.CAEAI.2022.100068
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bradbury NA, 2016, ADV PHYSIOL EDUC, V40, P509, DOI 10.1152/advan.00109.2016
   Anh BN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224729
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cheong JH, 2021, ARXIV, DOI [10.48550/arXiv.2014.03509, DOI 10.48550/ARXIV.2014.03509]
   Cicekci MA., 2019, Journal of Education and Learning, V8, P15, DOI [10.5539/jel.v8n6p15, DOI 10.5539/JEL.V8N6P15]
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Ekman P, 1978, FACIAL ACTION CODING
   Filntisis PP, 2019, IEEE ROBOT AUTOM LET, V4, P4011, DOI 10.1109/LRA.2019.2930434
   Fortes PC, 2010, PROCD SOC BEHV, V8, P272, DOI 10.1016/j.sbspro.2010.12.037
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Hwang DH, 2020, IEEE WINT CONF APPL, P468, DOI [10.1109/WACV45572.2020.9093595, 10.1109/wacv45572.2020.9093595]
   Jocher G., 2020, YOLOv5
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim Y, 2018, IEEE ACCESS, V6, P5308, DOI 10.1109/ACCESS.2018.2791861
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lamba S., 2014, IOSR Journal of Nursing Health Science, V3, P1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li W, 2019, INT CONF ACOUST SPEE, P7640, DOI 10.1109/ICASSP.2019.8683116
   Lin FC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165314
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo ZZ, 2022, INTERACT LEARN ENVIR, V30, P1117, DOI 10.1080/10494820.2019.1710852
   Madarkar J, 2020, MACHINE LEARNING IMA, P228, DOI [10.1007/978-981-15-6315-7_19, DOI 10.1007/978-981-15-6315-7_19]
   Nepal U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020464
   Nguyen D. D., 2021, 8 NAFOSTED C INF COM, P531
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Pervaiz Mahwish, 2022, 2022 International Conference on Electrical Engineering and Sustainable Technologies (ICEEST), P1, DOI 10.1109/ICEEST56292.2022.10077871
   Picard RW., 2000, AFFECTIVE COMPUTING, DOI [10.7551/mitpress/1140.001.0001, DOI 10.7551/MITPRESS/1140.001.0001]
   Ravikumar A, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.909
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Sharma V, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175699
   Stenum J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217315
   Su Kehua, 2021, Personal and Ubiquitous Computing, V25, P1081, DOI 10.1007/s00779-019-01286-1
   Terven JR, 2016, SCI COMPUT PROGRAM, V130, P97, DOI 10.1016/j.scico.2016.05.009
   Thati RP, 2023, MULTIMED TOOLS APPL, V82, P4787, DOI 10.1007/s11042-022-12315-2
   Thomas C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P542, DOI 10.1145/3242969.3264969
   Tonguç G, 2020, COMPUT EDUC, V148, DOI 10.1016/j.compedu.2019.103797
   Trabelsi Z, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010048
   Tu NA, 2021, J SUPERCOMPUT, V77, P14374, DOI 10.1007/s11227-021-03865-7
   Wei QL, 2017, SIGNAL PROCESS-IMAGE, V59, P168, DOI 10.1016/j.image.2017.08.012
   Wiley V., 2018, Int. J. Artif. Intell. Res, V2, P29, DOI DOI 10.29099/IJAIR.V2I1.42
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yadegaridehkordi E, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103649
   Zaidi SSA, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103514
   Zaletelj J, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0228-8
   Zhang YC, 2022, IEEE ACCESS, V10, P16134, DOI 10.1109/ACCESS.2022.3148735
   Zheng R, 2020, INT CONF ACOUST SPEE, P9244, DOI [10.1109/icassp40776.2020.9053457, 10.1109/ICASSP40776.2020.9053457]
   Zhi RC, 2020, VISUAL COMPUT, V36, P1067, DOI 10.1007/s00371-019-01707-5
   Zhou J, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/7049458
NR 59
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16388-5
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9TM0
UT WOS:001047169200001
DA 2024-07-18
ER

PT J
AU Fahimullah, M
   Ahvar, S
   Agarwal, M
   Trocan, M
AF Fahimullah, Muhammad
   Ahvar, Shohreh
   Agarwal, Mihir
   Trocan, Maria
TI Machine learning-based solutions for resource management in fog
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fog computing; Resource management; Machine learning; Resource
   provisioning; Application placement; Scheduling; Resource allocation;
   Task offloading; Load balancing
ID ARCHITECTURES; NETWORK
AB Fog computing is a paradigm that offers distributed and diverse resources at the network edge to fulfill the quality of service requirements. However, effectively managing these resources has become a significant challenge due to the dynamic nature of user demands and the distributed and heterogeneous characteristics of fog computing. Consequently, managing resources based on accurately predicting dynamic user demands and resource availability using machine-learning methods becomes demanding. In this study, we conduct a comprehensive analysis of existing literature that leverages machine learning-based approaches to address resource management challenges in fog computing. These challenges encompass resource provisioning, application placement, scheduling, resource allocation, task offloading, and load balancing. The examined literature is thoroughly compared based on their employed strategies, objective metrics, tools, datasets, and techniques. Furthermore, we identify research gaps in resource management issues and propose future directions for advancing the field.
C1 [Fahimullah, Muhammad; Agarwal, Mihir; Trocan, Maria] Inst Super Elect Paris ISEP, Paris, France.
   [Ahvar, Shohreh] Nokia, F-91620 Nozay, France.
C3 Nokia Corporation
RP Fahimullah, M; Trocan, M (corresponding author), Inst Super Elect Paris ISEP, Paris, France.
EM muhammad.fahimullah@ext.isep.fr; shohreh.ahvar@nokia.com;
   mihiragarwal1999@gmail.com; maria.trocan@isep.fr
CR Abdulkareem KH, 2019, IEEE ACCESS, V7, P153123, DOI 10.1109/ACCESS.2019.2947542
   Abdullah M, 2021, IEEE SYST J, V15, P1275, DOI 10.1109/JSYST.2020.2997518
   Ahvar E., 2021, NETWORK, V1, P28, DOI DOI 10.3390/NETWORK1010004
   Ahvar E, 2021, IEEE ACCESS, V9, P70192, DOI 10.1109/ACCESS.2021.3075973
   Albalawi M, 2022, J ENG APPL SCI TECHN, V138
   Alizadeh MR, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4583
   Alsadie D, 2022, INT J COMPUT SCI NET, V22, P310, DOI 10.22937/IJCSNS.2022.22.4.38
   Bacanin N, 2022, NEURAL COMPUT APPL, V34, P9043, DOI 10.1007/s00521-022-06925-y
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Bhatia M, 2019, COMPUT IND, V111, P51, DOI 10.1016/j.compind.2019.06.002
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Bukhari MM, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3606068
   Cho B, 2021, IEEE T VEH TECHNOL, V70, P11308, DOI 10.1109/TVT.2021.3115899
   Etemadi M, 2021, CLUSTER COMPUT, V24, P3277, DOI 10.1007/s10586-021-03307-2
   Etemadi M, 2021, J EXP THEOR ARTIF IN, V33, P1033, DOI 10.1080/0952813X.2020.1818294
   Eyckerman R, 2022, IEEE IFIP NETW OPER, DOI 10.1109/NOMS54207.2022.9789757
   Fahimullah M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073492
   Fahimullah M, 2022, COMM COM INF SC, V1716, P81, DOI 10.1007/978-981-19-8234-7_7
   Faraji-Mehmandar M, 2022, J SUPERCOMPUT, V78, P16997, DOI 10.1007/s11227-022-04521-4
   Faraji-Mehmandar M, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4342
   Farhat P, 2020, J SUPERCOMPUT, V76, P388, DOI 10.1007/s11227-019-03032-z
   Gao X, 2021, IEEE T GREEN COMMUN, V5, P1632, DOI 10.1109/TGCN.2021.3083426
   Ghobaei-Arani M, 2020, J GRID COMPUT, V18, P1, DOI 10.1007/s10723-019-09491-1
   Goudarzi M, 2023, IEEE T MOBILE COMPUT, V22, P2491, DOI 10.1109/TMC.2021.3123165
   Guevara JC, 2020, J NETW COMPUT APPL, V159, DOI 10.1016/j.jnca.2020.102596
   Habibi P, 2020, IEEE ACCESS, V8, P69105, DOI 10.1109/ACCESS.2020.2983253
   Hameed AR, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2020.100454
   Iftikhar S, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100674
   Iorga M., 2017, The nist definition of fog computing
   Jamil B, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3513002
   Jazayeri F, 2021, J AMB INTEL HUM COMP, V12, P8265, DOI 10.1007/s12652-020-02561-3
   Jiang F, 2021, EURASIP J ADV SIG PR, V2021, DOI 10.1186/s13634-021-00802-x
   Kansal P, 2022, J SUPERCOMPUT, V78, P13145, DOI 10.1007/s11227-022-04338-1
   Kashani MH, 2023, IEEE T SERV COMPUT, V16, P1505, DOI 10.1109/TSC.2022.3174475
   Kaur N, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6432
   Khumalo NN, 2021, IEEE ACCESS, V9, P12706, DOI 10.1109/ACCESS.2021.3051695
   Kim J, 2021, DES AUTOM EMBED SYST, V25, P265, DOI 10.1007/s10617-021-09253-x
   Lakhan A, 2022, AUTOMAT SOFTW ENG, V29, DOI 10.1007/s10515-021-00318-6
   Liao SY, 2022, IEEE T MOBILE COMPUT, V21, P1596, DOI 10.1109/TMC.2020.3026580
   Mahmud R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3403955
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Manasrah AM, 2019, CLUSTER COMPUT, V22, P1639, DOI 10.1007/s10586-017-1559-z
   Mijuskovic A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051832
   Mobasheri M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217053
   Murthy Bhargavi Krishna, 2021, 2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0435, DOI 10.1109/IEMCON53756.2021.9623085
   Naha R, 2022, COMPUT NETW, V216, DOI 10.1016/j.comnet.2022.109240
   Naha RK, 2018, IEEE ACCESS, V6, P47980, DOI 10.1109/ACCESS.2018.2866491
   Nair B, 2022, J SCHEDULING, V25, P547, DOI 10.1007/s10951-022-00725-x
   Nayeri ZM, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103078
   Pallewatta S., 2019, P 12 IEEE ACM INT C, P71
   Pallewatta S, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3592598
   Kumar DSNKPA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040608
   Poltronieri F, 2021, 2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2021), P466
   Rahimikhanghah A, 2022, CLUSTER COMPUT, V25, P911, DOI 10.1007/s10586-021-03467-1
   Razaq MM, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/4218696
   Reiss C., 2011, Technical report
   Ren YJ, 2021, IEEE T IND INFORM, V17, P4978, DOI 10.1109/TII.2020.3021024
   Samann F.E.F., 2021, International Journal of Interactive Mobile Technologies (iJIM), V15, P21, DOI 10.3991/ijim.v15i12.21313
   Sami H, 2022, IEEE T SERV COMPUT, V15, P2671, DOI 10.1109/TSC.2021.3075988
   Santos J., 2021, Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning, P147, DOI [10.1002/9781119675525.ch7, DOI 10.1002/9781119675525.CH7]
   Santos J, 2021, 2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2021), P431
   Sarkar I, 2022, J SUPERCOMPUT, V78, P15089, DOI 10.1007/s11227-022-04461-z
   Sellami B, 2022, COMPUT NETW, V210, DOI 10.1016/j.comnet.2022.108957
   Shakarami A, 2022, J SYST ARCHITECT, V122, DOI 10.1016/j.sysarc.2021.102362
   Shen YF, 2021, 2021 IEEE INTERNATIONAL MEDITERRANEAN CONFERENCE ON COMMUNICATIONS AND NETWORKING (IEEE MEDITCOM 2021), P252, DOI 10.1109/MeditCom49071.2021.9647580
   Shi JM, 2021, IEEE WCNC, DOI 10.1109/WCNC49053.2021.9417450
   Singh RM, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3494520
   Strumberger I, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224893
   Suryadevara NK, 2021, SUSTAIN COMPUT-INFOR, V31, DOI 10.1016/j.suscom.2021.100582
   Swarup S., 2021, Procedia Comput Sci, V191, P65, DOI [10.1016/j.procs.2021.07.012, DOI 10.1016/J.PROCS.2021.07.012]
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P39945, DOI 10.1007/s11042-022-13000-0
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2020, J AMB INTEL HUM COMP, V11, P4951, DOI 10.1007/s12652-020-01768-8
   Tan JR, 2022, ENG REP, V4, DOI 10.1002/eng2.12497
   Tang XY, 2021, CHINA COMMUN, V18, P175, DOI 10.23919/JCC.2021.02.011
   Vergara J, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23094413
   Yang M, 2021, IEEE INTERNET THINGS, V8, P1572, DOI 10.1109/JIOT.2020.3015522
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Zhang LL, 2022, IEEE INT CONF COMM, P97, DOI [10.1109/ICCWorkshops53468.2022.9814649, 10.1109/ICCWORKSHOPS53468.2022.9814649]
   Zheng Y., 2011, T drive trajectory data sample
NR 80
TC 3
Z9 3
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16399-2
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O5OY6
UT WOS:001044314000001
DA 2024-07-18
ER

PT J
AU Prakash, O
   Kumar, R
AF Prakash, Om
   Kumar, Rajeev
TI A unified generalization enabled ML architecture for manipulated
   multi-modal social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Social network; Manipulated content; Multimodal media; Deep learning;
   Generalization; Convolution NNs; Sequential NNs; BERT
ID FAKE NEWS; INFORMATION
AB With the emergence of online social networks (OSNs) incorporating multimodal media, it is challenging to differentiate manipulated multimedia content due to unseen patterns. Social media's lack of control and verification mechanism provides fertile ground for manipulated content. Hence, maintaining social networks' integrity is essential to identifying manipulated content that misleads and confuses social media users. In this work, we have proposed a deep-learning driven unified-generalized architecture for multimodal datasets with generalization ability. The proposed model uses a variant of a transformer-based sequential neural network with a combination of modified pre-trained CNN models to identify manipulated content from social platforms. The proposed model is configured with state-of-the-art generalization techniques with proper parametrization, optimized for (near-) optimal performance on unseen multimodal datasets. The proposed model seamlessly works on unimodal as well as multimodal datasets. We have considered Weibo multimodal and two unimodal datasets to assess the proposed model's performance. The critical challenge with the multimodal dataset is the concatenation of several different modalities that should work well for unseen multimodal datasets showing effective generalization. The proposed model's generalization ability is improved compared to the state-of-art models. This study aims to assess various feasible technologies that can be used to deal with unseen manipulated social media content for trust and reliability.
C1 [Prakash, Om; Kumar, Rajeev] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Data Knowledge Lab D2K, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Prakash, O (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Data Knowledge Lab D2K, New Delhi 110067, India.
EM omprak16_scs@jnu.ac.in; rajeevkumar.cse@gmail.com
RI Prakash, Om/JTT-0372-2023
OI Prakash, Om/0009-0003-1055-3637
CR Agrawal C, 2022, MULTIMED TOOLS APPL, V81, P24199, DOI 10.1007/s11042-022-12772-9
   Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Alnaim NM, 2023, IEEE ACCESS, V11, P16711, DOI 10.1109/ACCESS.2023.3246661
   Baarir N.F., 2021, P IEEE INT WORKSH HU, P125, DOI DOI 10.1109/IHSH51661.2021.9378748
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Boididou C., 2016, MEDIAEVAL
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Choudhury D, 2023, MULTIMED TOOLS APPL, V82, P9029, DOI 10.1007/s11042-022-12788-1
   Fang PF, 2022, IEEE T PATTERN ANAL, V44, P4626, DOI 10.1109/TPAMI.2021.3073512
   Fu T, 2022, MULTIMED TOOLS APPL, V81, P26345, DOI 10.1007/s11042-022-12661-1
   Galli A, 2022, J INTELL INF SYST, V59, P237, DOI 10.1007/s10844-021-00646-9
   Ghayoomi M, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13008
   Hua JH, 2023, APPL SOFT COMPUT, V136, DOI 10.1016/j.asoc.2023.110125
   Jahanbakhsh-Nagadeh Z, 2021, MULTIMED TOOLS APPL, V80, P35267, DOI 10.1007/s11042-020-10077-3
   Jarrahi A, 2023, MULTIMED TOOLS APPL, V82, P2913, DOI 10.1007/s11042-022-12668-8
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kalsnes B., 2018, OXFORD RES ENCY COMM, DOI [DOI 10.1093/ACREFORE/9780190228613.013.809, 10.1093/acrefore/9780190228613.013.80, DOI 10.1093/ACREFORE/9780190228613.013.80]
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kian Long Tan, 2021, 2021 9th International Conference on Information and Communication Technology (ICoICT), P606, DOI 10.1109/ICoICT52021.2021.9527469
   Kompatsiaris Yiannis, 2015, MediaEval, V3, P7
   Kumar A, 2022, MULTIMED TOOLS APPL, V81, P34615, DOI 10.1007/s11042-021-11340-x
   Lago F, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/9236910
   Li Q, 2020, MULTIMED TOOLS APPL, V79, P25023, DOI 10.1007/s11042-020-09227-4
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li X, 2022, MULTIMED TOOLS APPL, V81, P19341, DOI 10.1007/s11042-021-11065-x
   Martín-Gutiérrez D, 2021, IEEE ACCESS, V9, P54591, DOI 10.1109/ACCESS.2021.3068659
   Meel P, 2020, P IEEE C ADV COMP CO, P157, DOI [10.1109/ACCTHPA49271.2020.9213234, DOI 10.1109/ACCTHPA49271.2020.9213234]
   Mohapatra A, 2022, MULTIMED TOOLS APPL, V81, P18503, DOI 10.1007/s11042-022-12764-9
   Ni PK, 2023, APPL INTELL, V53, P6401, DOI 10.1007/s10489-022-03798-5
   Preiss J, 2023, MULTIMED TOOLS APPL, V82, P8791, DOI 10.1007/s11042-021-11621-5
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rashed KAN, 2014, MULTIMED TOOLS APPL, V70, P1069, DOI 10.1007/s11042-012-1103-3
   Rastogi S, 2022, MULTIMED TOOLS APPL, V81, P40675, DOI 10.1007/s11042-022-13129-y
   Raza S, 2022, INT J DATA SCI ANAL, V13, P335, DOI 10.1007/s41060-021-00302-z
   Reddy H, 2020, INT J AUTOM COMPUT, V17, P210, DOI 10.1007/s11633-019-1216-5
   Saleh H, 2021, IEEE ACCESS, V9, P129471, DOI 10.1109/ACCESS.2021.3112806
   Samadi M, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102723
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Shelke S, 2022, MULTIMED TOOLS APPL, V81, P17347, DOI 10.1007/s11042-022-12761-y
   Shrivastava G, 2020, IEEE T COMPUT SOC SY, V7, P1159, DOI 10.1109/TCSS.2020.3014135
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Singh B, 2022, NEURAL COMPUT APPL, V34, P21503, DOI 10.1007/s00521-021-06086-4
   Smitha N., 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P696, DOI 10.1109/ICIRCA48905.2020.9183072
   Tan L, 2023, MULTIMED TOOLS APPL, V82, P2941, DOI 10.1007/s11042-022-12800-8
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Viji D, 2022, MULTIMED TOOLS APPL, V81, P6131, DOI 10.1007/s11042-021-11771-6
   Xie JY, 2022, IEEE T PATTERN ANAL, V44, P4605, DOI 10.1109/TPAMI.2021.3083089
   Xu P, 2022, MULTIMED TOOLS APPL, V81, P13799, DOI 10.1007/s11042-022-12290-8
   Xu SZ, 2023, APPL INTELL, V53, P3136, DOI 10.1007/s10489-022-03592-3
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   Zhang T, 2022, MULTIMED TOOLS APPL, V81, P6259, DOI 10.1007/s11042-021-11733-y
NR 54
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16198-9
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600006
DA 2024-07-18
ER

PT J
AU Miao, YL
   Jia, HH
   Tang, KX
AF Miao, Yalin
   Jia, Huanhuan
   Tang, Kaixu
TI Artistic font generation network combining font style and glyph
   structure discriminators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artistic Font; Glyph Structure; Font Style; Generative Adversarial
   Network; Residual Dense Nnetwork
AB Artistic font plays an important practical value in advertising media and graphic design. The font is rendered to present a unique text effect, which is more ornamental and attractive. In order to explore more efficient font design method, this paper proposes artistic font generation network combining font style and glyph structure discriminators (ArtFontNet). We adopt the idea of generative adversarial network to obtain artistic fonts. The generator uses residual dense module to generate artistic fonts, and font style discriminator and glyph structure discriminator guide the generator together. The font style discriminator supervises the color and texture information of the entire font image. The glyph structure discriminator extracts the glyph structure and texture distribution of the generated image through the Canny edge detection operator. For the task of artistic font generation, our approach achieves significant performance compared to other existing methods. Compared with the font generation methods in the experiment, the PSNR value of the generated image in this paper is increased by 2.95 dB on average. The SSIM value is increased by 0.03 on average. The VIF value improved by 0.025 on average. The UV quantization results are maintained at 85%-90%. From both visual and objective evaluations, ArtFontNet enhances the detail fidelity and style accuracy of the generated artistic fonts.
C1 [Miao, Yalin; Tang, Kaixu] Xian Univ Technol, Xian 710048, Peoples R China.
   [Jia, Huanhuan] Southeast Univ, Nanjing 211189, Peoples R China.
C3 Xi'an University of Technology; Southeast University - China
RP Jia, HH (corresponding author), Southeast Univ, Nanjing 211189, Peoples R China.
EM bessie_jh@163.com
FU Chinese National Natural Science Foundation [62076200]; key research and
   development Project in Shaanxi Province [2023-YBGY-149]
FX This work was supported by the two funds. They are Research on the
   Inheritance Technology of Ancient Inscription Calligraphy Culture Based
   on Artificial Intelligence, 62076200, Chinese National Natural Science
   Foundation. And Research and Application of Key Technologies for
   Vectorization of Traditional Chinese Calligraphy Based on Artificial
   Intelligence, 2023-YBGY-149, key research and development Project in
   Shaanxi Province.
CR Gatys LA, 2015, Arxiv, DOI arXiv:1508.06576
   Arjovsky M, 2017, Arxiv, DOI [arXiv:1701.07875, DOI 10.48550/ARXIV.1701.07875]
   Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Baluja S, 2017, MACH VISION APPL, V28, P551, DOI 10.1007/s00138-017-0842-6
   Chang B, 2018, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2018.00028
   Gao Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356574
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu XF, 2017, I COMP CONF WAVELET, P197, DOI 10.1109/ICCWAMTIP.2017.8301478
   He K., 2016, P IEEE C COMP VIS PA, P770, DOI DOI 10.48550/ARXIV.1512.03385
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lyu PY, 2017, PROC INT CONF DOC, P1095, DOI 10.1109/ICDAR.2017.181
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Wang WJ, 2019, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2019.00604
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yang S, 2019, AAAI CONF ARTIF INTE, P1238
   Yang S, 2018, COMPUT VIS IMAGE UND, V174, P43, DOI 10.1016/j.cviu.2018.07.004
   Yang S, 2017, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR.2017.308
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 25
TC 0
Z9 0
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16396-5
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700002
DA 2024-07-18
ER

PT J
AU Mishra, S
   Chaurasiya, VK
AF Mishra, Sourav
   Chaurasiya, Vijay Kumar
TI Hybrid deep learning algorithm for smart cities security enhancement
   through blockchain and internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IoT devices; Min-max normalization; Weighted average filter; Reptile
   search algorithm; Block chain network; Hybrid LSTM-SVM
ID ARCHITECTURE
AB Internet of Things (IoT) usage is cherishing nowadays and it is widely used in variety of exciting application such as hospital, industry and cities. Security is found to be a major concern in IoT based application due to advancement made in the field of Information and software technology. Transactions using internet has become significantly in case of smart cities and it is frequently prone to various cyber security threats. For securing various transaction in smart cities hybrid deep learning LSTM-SVM algorithm is developed. Initially, data related to transaction in smart cities is gathered and pre-processed utilizing min-max normalization and weighted average filter. Min-max normalization is employed or normalizing the raw data to a certain range. Then, weighted average filter is used for removing noise in the data. After that, appropriate features from pre-processed data is selected using reptile search algorithm. Using industrial gateway, the selected features are provided to blockchain based distributed network. Function of blockchain is to verify the transaction process using trusted entities. Verifier check whether the transaction is genuine or fake through detecting the presence of attack. In case of genuine transaction request, the transaction is accomplished through creating a block on the blockchain. On the other hand, if an attack is detected the transaction is blocked and further types of attack is predicted using deep learning-based hybrid LSTM- SVM classifier. Simulation analysis on the proposed hybrid deep learning model showed 97% accuracy, 98% specificity, 91% F1 score and 82% sensitivity. Based on this proposed model fake transaction in IoT based blockchain is blocked and paved way for development of secure smart cities environment.
C1 [Mishra, Sourav; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol, Prayagraj 211015, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, S (corresponding author), Indian Inst Informat Technol, Prayagraj 211015, Uttar Pradesh, India.
EM srvmishra9@gmail.com
CR Abd El-Latif AA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102549
   Abualigah L, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116158
   Ahlawat S, 2020, PROCEDIA COMPUT SCI, V167, P2554, DOI 10.1016/j.procs.2020.03.309
   Alasbali Nada, 2020, IECC 2020: Proceedings of the 2020 2nd International Electronics Communication Conference, P17, DOI 10.1145/3409934.3409957
   Bacanin N, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275727
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Botello JV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164636
   El Majdoubi D, 2020, PROCEEDINGS OF 2020 5TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND ARTIFICIAL INTELLIGENCE: TECHNOLOGIES AND APPLICATIONS (CLOUDTECH'20), P117, DOI 10.1109/CloudTech49835.2020.9365905
   Elsaeidy AA, 2020, IEEE ACCESS, V8, P137825, DOI 10.1109/ACCESS.2020.3012411
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Fang SH, 2021, IEEE T IND ELECTRON, V68, P8963, DOI 10.1109/TIE.2020.3016268
   Gong S, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11143889
   Hakak S, 2020, IEEE NETWORK, V34, P8, DOI 10.1109/MNET.001.1900178
   Islam MJ, 2022, IEEE INTERNET THINGS, V9, P3850, DOI 10.1109/JIOT.2021.3100797
   kaggle, UNSW NB15
   Karthick S., 2018, 2021 IEEE INT C COMP, DOI [10.1109/icetietr.2018.8529016, DOI 10.1109/ICETIETR.2018.8529016]
   KARTHICK SUYAMBU, 2018, International Journal of Intelligent Engineering and Systems, V11, P76
   Keshk M, 2020, IEEE T IND INFORM, V16, P5110, DOI 10.1109/TII.2019.2957140
   Kim HJ, 2021, IEEE ACCESS, V9, P74802, DOI 10.1109/ACCESS.2021.3080180
   Kumar P. G., 2022, 2022 14 INT C COMMUN, P1, DOI DOI 10.1109/COMSNETS53615.2022.9668530
   Kumar P, 2021, IEEE T NETW SCI ENG, V8, P2326, DOI 10.1109/TNSE.2021.3089435
   Kumar P, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2020.101954
   Majeed U, 2021, J NETW COMPUT APPL, V181, DOI 10.1016/j.jnca.2021.103007
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Rathore S, 2019, J NETW COMPUT APPL, V143, P167, DOI 10.1016/j.jnca.2019.06.019
   Salim MM, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.021
   Serrano W, 2021, J NETW COMPUT APPL, V175, DOI 10.1016/j.jnca.2020.102909
   Singh SK, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.012
   Singh SK, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102252
   Vargas H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212662
NR 31
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16406-6
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700010
DA 2024-07-18
ER

PT J
AU Yadav, N
   Pal, S
   Singh, AK
AF Yadav, Naina
   Pal, Sukomal
   Singh, Anil Kumar
TI Diversified recommendation using implicit content node embedding in
   heterogeneous information network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Accuracy-diversity; Heterogeneous information
   network; Heterogeneous node embedding
AB Many approaches based on Graph Neural Networks (GNNs) have been proposed to identify relationships between users and items while modelling user preferences with significant improvements in recommendation quality. Besides accuracy, diversity in recommendation is often a desirable property for a better user experience in a real-world application. Recently many recommendation techniques based on heterogeneous information networks have been drawing attention to improvement in diversity. However, most such algorithms use re-ranking approaches or diversity regularization (ensemble learning) in a heterogeneous graph network. These approaches often compromise with accuracy to include diversity in the recommendation. The author proposed a novel technique involving both diversity and accuracy at the same time for recommendation generation. Our approach uses implicit user information to generate a low-dimensional embedding representation for each node. The model also includes derived user features for diversity to train the model for diversified recommendation generation. The proposed model iteratively finds infrequently recommended yet relevant items, adds them to the users' final recommendation lists, and balances the accuracy diversity tradeoff. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed model, Diverse Heterogeneous Node Embedding Model for Recommendation (Div-HetNEMRec), for diverse recommendations with substantially better coverage and reasonably good improvement in accuracy over the state-of-the-art techniques.
C1 [Yadav, Naina; Pal, Sukomal; Singh, Anil Kumar] Indian Inst Technol BHU, Varanasi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Yadav, N (corresponding author), Indian Inst Technol BHU, Varanasi, India.
EM nainayadav585@gmail.com
RI Singh, Anil/JUU-2219-2023
CR Abdollahpouri Himan, 2019, RMSE RECSYS CEUR WOR
   Adomavicius G, 2012, IEEE T KNOWL DATA EN, V24, P896, DOI 10.1109/TKDE.2011.15
   Anderson A, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2155, DOI 10.1145/3366423.3380281
   Aytekin T, 2014, J INTELL INF SYST, V42, P1, DOI 10.1007/s10844-013-0252-9
   Bao Y, 2014, 28 AAAI C ART INT
   Bradley K, 2001, P 12 IR C ART INT CO, V85
   Canakoglu E, 2021, INFORMS J COMPUT, V33, P300, DOI 10.1287/ijoc.2019.0952
   Cao Shaosheng, 2015, P 24 ACM INT C INF K, P891
   Chen C, 2021, P AAAI C ART INT, V35
   Darban ZZ, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116850
   Di Noia T, 2017, INFORM SCIENCES, V382, P234, DOI 10.1016/j.ins.2016.11.015
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Ekstrand MD, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P161, DOI 10.1145/2645710.2645737
   Fan SH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2478, DOI 10.1145/3292500.3330673
   Feng W., 2012, KDD
   Fu XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2331, DOI 10.1145/3366423.3380297
   Gao ZL, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2524, DOI 10.1145/3477495.3531890
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gu L, 2017, KNOWL-BASED SYST, V135, P1, DOI 10.1016/j.knosys.2017.07.004
   Hamilton W. L., 2017, B TECHNICAL COMMITTE, V40, P52
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   Helberger N, 2018, INFORM COMMUN SOC, V21, P191, DOI 10.1080/1369118X.2016.1271900
   Isufi E, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102459
   Jacobson K, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P373, DOI 10.1145/2959100.2959120
   Javari A, 2015, KNOWL INF SYST, V44, P609, DOI 10.1007/s10115-014-0779-2
   Jeong J, 2020, ARXIV
   Jin JR, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P75, DOI 10.1145/3394486.3403050
   Kunaver M, 2017, KNOWL-BASED SYST, V123, P154, DOI 10.1016/j.knosys.2017.02.009
   Li C., 2021, P 2021 SIAM INT C DA, P64
   Liang DW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P689, DOI 10.1145/3178876.3186150
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Logesh R, 2020, NEURAL COMPUT APPL, V32, P2487, DOI 10.1007/s00521-019-04128-6
   Nandanwar S, 2018, P 11 ACM INT C WEB S
   Pal S, 2016, IEEE MILIT COMMUN C, P588, DOI 10.1109/MILCOM.2016.7795391
   Panteli A, 2023, NEURAL COMPUT APPL, V35, P177, DOI 10.1007/s00521-020-05613-z
   Paudel B, 2021, ARXIV
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Rendle S., 2012, ARXIV
   Shi C., 2018, IEEE T KNOWL DATA EN, V31, P57
   Su YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P849, DOI 10.1145/3404835.3462833
   Sun JN, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2030, DOI 10.1145/3394486.3403254
   Tintarev Nava, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P190, DOI 10.1007/978-3-642-38844-6_16
   Vargas S, 2011, P 34 INT ACM SIGIR C
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Xia H., 2022, Comput. Intell. Neurosci., P1
   Xie R, 2021, ARXIV
   Yadav N, 2021, HYBRID INTELLIGENT S, V19
   Yadav N, 2020, FOR INF RETR EV
   Yadav N, 2022, J KING SAUD UNIV-COM, V34, P6385, DOI 10.1016/j.jksuci.2022.02.010
   Yadav N, 2022, COMPUT INTELL-US, V38, P1232, DOI 10.1111/coin.12501
   Yan SR, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114601
   Yan X, 2020, P 2020 SIAM INT C DA
   Yan XQ, 2020, INFORM FUSION, V56, P15, DOI 10.1016/j.inffus.2019.10.006
   Yang C., 2021, SYNTH LECT ARTIF INT, V15, P1
   Yang Liangwei, 2023, P 16 ACM INT C WEB S, P661
   Zheng Y, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P401, DOI 10.1145/3442381.3449835
   Zhu X, 2007, HUMAN LANGUAGE TECHN
NR 57
TC 0
Z9 0
U1 8
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20605
EP 20635
DI 10.1007/s11042-023-16135-w
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200003
DA 2024-07-18
ER

PT J
AU El-Shazly, EH
   Abdelhakim, A
   Zhang, XY
   Fares, A
AF El-Shazly, Ehab H.
   Abdelhakim, Assem
   Zhang, Xiaoyan
   Fares, Ahmed
TI Non-linear integration of loss terms for improved new view synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning applications; Loss function; View synthesize
AB New view synthesis problem can be tackled through different approaches, depending on the availability of either single or multiple images as input to the system. Previous methods for new view synthesis can be divided into image-based rendering methods (e.g., flow prediction) or pixel generation methods. While directly regressing pixels for new view synthesize generates structurally consistent results, it generates blurry images. On the other hand, flow prediction can generate realistic texture but it is unable to generate regions that are not available in the source image(s). We propose a deep framework that consist of a combination of both flow prediction module and recurrent pixel generator module to achieve improved performance via learning on both modules. While the flow prediction module estimates a dense flow field that is used to sample new target image from the given source image using spatial transform network, the pixel generation module is trained to directly synthesize a target image given a set of source images as it progressively refines and improves its prediction. In addition, we introduce a non-linear combination of loss terms to optimize the learning process. We highlight those parts of the scenes that are not common across two synthesized scenes and thus complete the fusion over all the learning modules.
C1 [El-Shazly, Ehab H.; Abdelhakim, Assem] Natl Ctr Radiat Res & Technol, Radiat Engn Dept, Egyptian Atom Energy Author, Cairo, Egypt.
   [El-Shazly, Ehab H.; Zhang, Xiaoyan] Shenzhen Univ, Res Inst Future Media Comp, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Fares, Ahmed] Benha Univ, Fac Engn Shoubra, Dept Elect Engn, Comp Syst Engn Program, Cairo, Egypt.
   [Fares, Ahmed] Egypt Japan Univ Sci & Technol E JUST, Fac Engn, Sch Elect Commun & Comr Engn ECCE, Dept Comp Sci & Engn, New Borg El Arab City, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   National Center for Radiation Research & Technology; Shenzhen
   University; Egyptian Knowledge Bank (EKB); Benha University; Egyptian
   Knowledge Bank (EKB); Egypt-Japan University of Science & Technology
RP El-Shazly, EH (corresponding author), Natl Ctr Radiat Res & Technol, Radiat Engn Dept, Egyptian Atom Energy Author, Cairo, Egypt.; El-Shazly, EH (corresponding author), Shenzhen Univ, Res Inst Future Media Comp, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM ehab.elshazly@ejust.edu.eg
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen X, 2019, Arxiv, DOI arXiv:1901.01880
   El-Shazly EH, 2019, ELECTRON LETT, V55, P264, DOI 10.1049/el.2018.7656
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Gal Y, 2016, PR MACH LEARN RES, V48
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hou YX, 2021, IEEE WINT CONF APPL, P3118, DOI 10.1109/WACV48630.2021.00316
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang JM, 2019, IEEE ACCESS, V7, P134718, DOI 10.1109/ACCESS.2019.2940755
   Kendall A, 2017, Arxiv, DOI arXiv:1703.04977
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Kim J, 2020, IEEE IMAGE PROC, P1616, DOI [10.1109/ICIP40778.2020.9191076, 10.1109/icip40778.2020.9191076]
   Kim T, 2017, PR MACH LEARN RES, V70
   Kinga D, 2015, INT C LEARNING REPRE
   Landreau G, 2022, PREPRINT
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu MY, 2017, ADV NEUR IN, V30
   Mingyu Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P87, DOI 10.1007/978-3-030-58604-1_6
   Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82
   Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093
   Ren Z, 2017, AAAI CONF ARTIF INTE, P1495
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Shi XJ, 2015, ADV NEUR IN, V28
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Sun SH, 2018, LECT NOTES COMPUT SC, V11207, P162, DOI 10.1007/978-3-030-01219-9_10
   Tatarchenko M, 2016, Arxiv, DOI arXiv:1511.06702
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Varley J, 2017, IEEE INT C INT ROBOT, P2442, DOI 10.1109/IROS.2017.8206060
   WOODFORD O.J., 2007, British Machine Vision Conference 2007, P1120
   Yang J., 2015, ADV NEURAL INFORM PR
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 31
PY 2023
DI 10.1007/s11042-023-16265-1
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O0PL1
UT WOS:001040925900002
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumbharkar, P
   Vanam, S
   Sharma, S
AF Kumar, Rakesh
   Kumbharkar, Pooja
   Vanam, Sandeep
   Sharma, Sanjeev
TI Medical images classification using deep learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Deep Learning models; Performance; Features;
   Medical imaging
ID CONVOLUTIONAL NEURAL-NETWORK; CHEST-X-RAY; BREAST-CANCER; LESION
   CLASSIFICATION; FEATURE FUSION; AUTOMATIC CLASSIFICATION; COVID-19
   DETECTION; LEFT-VENTRICLE; DIAGNOSIS; MODELS
AB Deep learning has made significant advancements in recent years. The technology is rapidly evolving and has been used in numerous automated applications with minimal loss. With these deep learning methods, medical image analysis for disease detection can be performed with minimal errors and losses. A survey of deep learning-based medical image classification is presented in this paper. As a result of their automatic feature representations, these methods have high accuracy and precision. This paper reviews various models like CNN, Transfer learning, Long short term memory, Generative adversarial networks, and Autoencoders and their combinations for various purposes in medical image classification. The total number of papers reviewed is 158. In the study, we discussed the advantages and limitations of the methods. A discussion is provided on the various applications of medical imaging, the available datasets for medical imaging, and the evaluation metrics. We also discuss the future trends in medical imaging using artificial intelligence.
C1 [Kumar, Rakesh; Kumbharkar, Pooja; Vanam, Sandeep; Sharma, Sanjeev] Indian Inst Informat Technol Pune, Pune, Maharashtra, India.
RP Sharma, S (corresponding author), Indian Inst Informat Technol Pune, Pune, Maharashtra, India.
EM rakeshkumar@cse.iiitp.ac.in; poojakumbharkar20@ece.iiitp.ac.in;
   vanamsandeep20@ece.iiitp.ac.in; sanjeevsharma@iiitp.ac.in
RI Kumar, Rakesh/JEP-3806-2023
OI Kumar, Rakesh/0000-0001-6313-4856; sharma, Dr.
   Sanjeev/0000-0001-9598-242X
CR Abdulkareem KH, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/5329014
   Abdullah SM, 2023, IEEE ACCESS, V11, P3511, DOI 10.1109/ACCESS.2023.3233969
   Abdulsahib AA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091295
   Al-Saffar ZA, 2020, IEEE ACCESS, V8, P52575, DOI 10.1109/ACCESS.2020.2980728
   Allaouzi I, 2019, IEEE ACCESS, V7, P64279, DOI 10.1109/ACCESS.2019.2916849
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 1992, WISCONSIN BREAST CAN
   [Anonymous], 2018, BLOOD CELL IMAGES
   [Anonymous], 2020, MELANOMA CANC CELL D
   [Anonymous], 2021, BRAIN TUMOR PROGR
   [Anonymous], 2018, NIH DEEPLESION DATAS
   [Anonymous], 2018, NIH CHEST XRAY DATAS
   [Anonymous], 2021, CT IMAGES COVID 19
   [Anonymous], 2018, COPD MACHINE LEARNIN
   [Anonymous], 2018, CHEST XRAY IMAGES PN
   [Anonymous], 2019, BRAIN MRI IMAGES BRA
   [Anonymous], 2018, RETINAL OCT IMAGES O
   [Anonymous], 2016, CAVY DATASET
   [Anonymous], 2020, COVID 19 RADIOGRAPHY
   [Anonymous], 2015, Diabetic retinopathy detection
   Ansingkar NP, 2022, MULTIMED TOOLS APPL, V81, P6539, DOI 10.1007/s11042-021-11786-z
   Arias-Garzón D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100138
   Ashraf R, 2020, IEEE ACCESS, V8, P105659, DOI 10.1109/ACCESS.2020.2998808
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Bank D., 2021, arXiv
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bian JX, 2021, IEEE ACCESS, V9, P66052, DOI 10.1109/ACCESS.2021.3076533
   Brima Y, 2021, ARXIV
   Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96
   Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273
   Chai YD, 2018, KNOWL-BASED SYST, V161, P147, DOI 10.1016/j.knosys.2018.07.043
   Charte D, 2018, INFORM FUSION, V44, P78, DOI 10.1016/j.inffus.2017.12.007
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chollet F., 2017, arXiv
   Chowdhary CL, 2016, INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION COMMUNICATION TECHNOLOGY & COMPUTING, 2016, DOI 10.1145/2979779.2979800
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Das AK, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110713
   Das K, 2020, IEEE ACCESS, V8, P213502, DOI 10.1109/ACCESS.2020.3040106
   Das PK, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115311
   Das V, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2019.2963712
   De Moura J, 2020, IEEE ACCESS, V8, P195594, DOI 10.1109/ACCESS.2020.3033762
   Demir F, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107160
   Diakite A, 2021, IET IMAGE PROCESS, V15, P1083, DOI 10.1049/ipr2.12087
   DRIVE, 2012, DIGITAL RETINAL IMAG
   Elazab A, 2020, NEURAL NETWORKS, V132, P321, DOI 10.1016/j.neunet.2020.09.004
   Elkorany AS, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166405
   Elmannai H, 2021, INT J COMPUT INT SYS, V14, P1003, DOI 10.2991/ijcis.d.210301.002
   Fan YQ, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108055
   Fradi M, 2022, MULTIMED TOOLS APPL, V81, P41711, DOI 10.1007/s11042-021-11268-2
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Goodfellow I. J., 2014, ARXIV
   Gu J, 2017, ARXIV
   Hasan MM, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010527
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XX, 2020, NEUROCOMPUTING, V405, P37, DOI 10.1016/j.neucom.2020.04.044
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Histology Image Collection Library, 1988, US
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J., 2019, arXiv
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Hu ZP, 2021, MULTIMED TOOLS APPL, V80, P33179, DOI 10.1007/s11042-021-11403-z
   Huang G, 2018, ARXIV
   Huang KK, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107744
   Huang LF, 2019, IEEE SIGNAL PROC LET, V26, P1026, DOI 10.1109/LSP.2019.2917779
   Huang QS, 2019, INTEGR ANAL SYST, P1, DOI [10.1007/978-981-32-9729-6_1, 10.1109/JBHI.2019.2905623]
   Huang XF, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106230
   Hussain E, 2020, TISSUE CELL, V65, DOI 10.1016/j.tice.2020.101347
   Hussain SM, 2022, IEEE ACCESS, V10, P122627, DOI 10.1109/ACCESS.2022.3223704
   Ibrahim DA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13010
   Indian Diabetic Retinopathy Image Dataset (IDRID), 2019, US
   Indolia Sakshi, 2018, Procedia Computer Science, V132, P679, DOI 10.1016/j.procs.2018.05.069
   Inthiyaz S, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103361
   Jammula R, 2020, ARXIV
   Jun TJ, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115211
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan HN, 2019, IEEE ACCESS, V7, P165724, DOI 10.1109/ACCESS.2019.2953318
   Khan MA, 2021, IEEE J BIOMED HEALTH, V25, P4267, DOI 10.1109/JBHI.2021.3067789
   Khan NM, 2019, IEEE ACCESS, V7, P72726, DOI 10.1109/ACCESS.2019.2920448
   Kim SH, 2021, MULTIMED TOOLS APPL, V80, P35941, DOI 10.1007/s11042-021-10551-6
   Kozegar E, 2020, ARTIF INTELL REV, V53, P1919, DOI 10.1007/s10462-019-09722-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang Y, 2020, IEEE ACCESS, V8, P77725, DOI 10.1109/ACCESS.2020.2987961
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Labhsetwar SR, 2020, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li C, 2021, KNOWL-BASED SYST, V218, DOI 10.1016/j.knosys.2021.106849
   Li YQ, 2019, IEEE ACCESS, V7, P21400, DOI 10.1109/ACCESS.2019.2898044
   Li Z, 2020, J ELECTROCARDIOL, V58, P105, DOI 10.1016/j.jelectrocard.2019.11.046
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Liao FZ, 2019, IEEE T CYBERNETICS, V49, P495, DOI 10.1109/TCYB.2017.2778799
   Liu XJ, 2022, MULTIMED TOOLS APPL, V81, P4979, DOI 10.1007/s11042-021-11472-0
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Ma YJ, 2022, APPL INTELL, V52, P766, DOI 10.1007/s10489-021-02196-7
   Mahmoudi R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12104825
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Mamalakis M, 2021, ARXIV
   Martinez AR, 2020, CLASSIFICATION COVID
   Masoudi S, 2021, IEEE ACCESS, V9, P87531, DOI [10.1109/access.2021.3074051, 10.1109/ACCESS.2021.3074051]
   Mehmood S, 2022, IEEE ACCESS, V10, P25657, DOI 10.1109/ACCESS.2022.3150924
   Mei KF, 2019, IET IMAGE PROCESS, V13, P591, DOI 10.1049/iet-ipr.2018.6057
   Meng D, 2017, IEEE ACCESS, V5, P5804, DOI 10.1109/ACCESS.2017.2689058
   Meng N, 2019, IEEE J BIOMED HEALTH, V23, P2091, DOI 10.1109/JBHI.2018.2878878
   Mercioni Marina-Adriana, 2022, Advances in Information and Communication: Proceedings of the 2022 Future of Information and Communication Conference (FICC). Lecture Notes in Networks and Systems (439), P198, DOI 10.1007/978-3-030-98015-3_13
   Mijwil MM, 2021, MULTIMED TOOLS APPL, V80, P26255, DOI 10.1007/s11042-021-10952-7
   Moslehi S, 2022, BMC MED RES METHODOL, V22, DOI 10.1186/s12874-022-01827-y
   Motamed S, 2020, ARXIV
   Mousavi Z, 2022, SLAS TECHNOL, V27, P63, DOI 10.1016/j.slast.2021.10.011
   Muhammad G, 2021, INFORM FUSION, V72, P80, DOI 10.1016/j.inffus.2021.02.013
   Navaneethakrishnan M, 2021, IET IMAGE PROCESS, V15, P337, DOI 10.1049/ipr2.12019
   Nigam B, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114883
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595
   Pezeshk A, 2019, IEEE J BIOMED HEALTH, V23, P2080, DOI 10.1109/JBHI.2018.2879449
   Poloni KM, 2021, NEUROCOMPUTING, V419, P126, DOI 10.1016/j.neucom.2020.07.102
   Pulgar FJ, 2020, INFORM FUSION, V54, P44, DOI 10.1016/j.inffus.2019.07.004
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Raj A, 2020, IEEE ACCESS, V8, P57810, DOI 10.1109/ACCESS.2020.2982588
   Rajaraman S, 2020, IEEE ACCESS, V8, P27318, DOI [10.1109/ACCESS.2020.2971257, 10.1109/access.2020.2971257]
   Reshi AA, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6621607
   Rong YB, 2019, IEEE J BIOMED HEALTH, V23, P253, DOI 10.1109/JBHI.2018.2795545
   Saha S, 2021, ARXIV
   Sakib S, 2020, IEEE ACCESS, V8, P171575, DOI 10.1109/ACCESS.2020.3025010
   Salama WM, 2022, MULTIMED TOOLS APPL, V81, P32705, DOI 10.1007/s11042-022-13005-9
   Salehinejad H, 2019, IEEE T MED IMAGING, V38, P1197, DOI 10.1109/TMI.2018.2881415
   Saxena A, 2022, DEEP LEARNING APPROA
   Schmid Volker S., 2014, Psyche (Cambridge), P396095
   Shahamat H, 2020, NEURAL NETWORKS, V126, P218, DOI 10.1016/j.neunet.2020.03.017
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shamim S, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6566982
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shi YH, 2013, APPL INTELL, V38, P16, DOI 10.1007/s10489-012-0354-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P1743, DOI 10.1007/s11042-021-11409-7
   Skin Cancer MNIST, 2018, HAM10000
   Soomro TA, 2022, ARTIF INTELL REV, V55, P1409, DOI 10.1007/s10462-021-09985-z
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Sun GP, 2023, OPHTHALMOL THER, V12, P895, DOI 10.1007/s40123-022-00627-3
   Sun LY, 2020, IEEE T MED IMAGING, V39, P898, DOI 10.1109/TMI.2019.2937271
   Suresh S, 2022, J KING SAUD UNIV-COM, V34, P1706, DOI 10.1016/j.jksuci.2019.11.013
   Szegedy C, 2014, INT C LEARN REPR
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   García-Ordás MT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041214
   Ting FF, 2019, EXPERT SYST APPL, V120, P103, DOI 10.1016/j.eswa.2018.11.008
   Trivizakis E, 2019, IEEE J BIOMED HEALTH, V23, P923, DOI 10.1109/JBHI.2018.2886276
   Tuberculosis (TB), 2021, CHEST XRAY DAT 8 2
   Turkoglu M, 2021, IRBM, V42, P207, DOI 10.1016/j.irbm.2021.01.004
   Ul Abideen Z, 2020, IEEE ACCESS, V8, P22812, DOI 10.1109/ACCESS.2020.2970023
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1
   Velasco M, 2014, APPL INTELL, V41, P594, DOI 10.1007/s10489-014-0548-7
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   WANG D, IEEE T CYBERNETICS, DOI DOI 10.1109/TSMC.2019.2933005
   Wang JB, 2020, IEEE ACCESS, V8, P140767, DOI 10.1109/ACCESS.2020.3007599
   Wang Q, 2023, MOL ECOL, V32, P2504, DOI 10.1111/mec.16618
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang W, 2020, APPL INTELL, V50, P4602, DOI 10.1007/s10489-020-01798-x
   Wang Y, 2020, SENSOR ACTUAT A-PHYS, V307, DOI 10.1016/j.sna.2020.111874
   Wang ZJ, 2019, IEEE ACCESS, V7, P134388, DOI 10.1109/ACCESS.2019.2941912
   Wu Y, 2020, KNOWL-BASED SYST, V200, DOI 10.1016/j.knosys.2020.105873
   Xie LZ, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106465
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Xu SJ, 2020, IEEE ACCESS, V8, P98693, DOI 10.1109/ACCESS.2020.2996217
   Xu YJ, 2021, NEUROCOMPUTING, V443, P96, DOI 10.1016/j.neucom.2021.03.034
   Yang X, 2019, IEEE ACCESS, V7, P84849, DOI 10.1109/ACCESS.2019.2925210
   Yang ZB, 2019, NEUROCOMPUTING, V366, P46, DOI 10.1016/j.neucom.2019.07.080
   Yu SX, 2021, IEEE ACCESS, V9, P32559, DOI 10.1109/ACCESS.2021.3060447
   Zagoruyko S, 2017, ARXIV
   Zeiler M.D., 2013, arXiv
   Zeimarani B, 2020, IEEE ACCESS, V8, P133349, DOI 10.1109/ACCESS.2020.3010863
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
   Zhao C, 2021, IEEE ACCESS, V9, P8659, DOI 10.1109/ACCESS.2021.3049600
   Zhao XH, 2022, IEEE ACCESS, V10, P27917, DOI 10.1109/ACCESS.2022.3156096
   Zhou LC, 2020, NEURAL NETWORKS, V121, P308, DOI 10.1016/j.neunet.2019.09.009
   Zhou LL, 2020, IEEE ACCESS, V8, P17527, DOI 10.1109/ACCESS.2020.2967820
   Zhou Q, 2022, MULTIMED TOOLS APPL, P1
   Zhu HB, 2021, FUTURE GENER COMP SY, V115, P475, DOI 10.1016/j.future.2020.09.020
NR 183
TC 1
Z9 1
U1 25
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19683
EP 19728
DI 10.1007/s11042-023-15576-7
EA JUL 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800011
DA 2024-07-18
ER

PT J
AU Wang, PH
   Wu, ZH
   Zhang, SH
   Zhang, H
AF Wang, Penghai
   Wu, Zihan
   Zhang, Shouhua
   Zhang, Hong
TI A GPU-free license plate detection based on fused color-edge and Retina
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate detection; Heuristic simple moving average search method;
   Support Vector Machine; Color saliency
ID RECOGNITION; LOCALIZATION
AB With the great success of deep learning and IoT techniques, many methods with GPU for License Plate Detection (LPD) have attracted remarkable attention in recent times. However, GPUs are not always equipped for video surveillance equipment due to device costs in a distributed edge-computing environment. Thereby, most methods of LPD on edge devices have poor running performance without GPUs. In this paper, we propose a novel hybrid methodology for license plate detection, which can accurately and quickly locate license plates in complex visual surveillance scenes without GPUs. As the background colors in China's license plates are specific, blue or green, a well-designed color filtering and Sobel detector are used to preprocess images to eliminate the complex background, which rapidly speed up the process of license plate detection. Then, we employ heuristic Simple Moving Average (SMA) search method to filter out the license plate area that meets the definite conditions from the candidate areas. In addition, Support Vector Machine(SVM) and trained Retina model are introduced to further detect the position of license plate for pictures without any candidate areas to improve the accuracy. Finally, we evaluate the proposed method on Chinese City Parking Dataset(CCPD), which is China's largest public license plate data set. Results demonstrate that our method is 312.37% faster than the original Retina model on devices without GPUs and still achieves the precision of 97.95%. These results show that the proposed method outperforms other methods on detecting Chinese blue license plates on CPU devices.
C1 [Wang, Penghai; Wu, Zihan; Zhang, Hong] Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.
   [Zhang, Shouhua] Univ Oulu, Informat Technol & Elect Engn, Oulu, Finland.
C3 Hebei University; University of Oulu
RP Zhang, H (corresponding author), Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.
EM wph@stumail.hbu.edu.cn; wuzihan1984@stumail.hbu.edu.cn;
   shouhua.zhang@oulu.fi; hzhang@hbu.edu.cn
RI Wang, Penghai/HGD-1854-2022
OI Wang, Penghai/0000-0002-6187-4858
FU Science and Technology Research Project of Hebei Higher Education
   Institutions [QN2020133]; Natural Science Foundation of Hebei Province
   of China [F2019201361]
FX AcknowledgementsThis work is supported by Science and Technology
   Research Project of Hebei Higher Education Institutions (No. QN2020133),
   the Natural Science Foundation of Hebei Province of China (No.
   F2019201361).
CR Abo Samra GA, 2014, IEEE T EVOLUT COMPUT, V18, P244, DOI 10.1109/TEVC.2013.2255611
   Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Asif MR, 2019, MULTIMED TOOLS APPL, V78, P35585, DOI 10.1007/s11042-019-08199-4
   Asif MR, 2017, J VIS COMMUN IMAGE R, V46, P176, DOI 10.1016/j.jvcir.2017.03.020
   Asif MR, 2016, IET INTELL TRANSP SY, V10, P535, DOI 10.1049/iet-its.2016.0008
   Chen C, 2021, IEEE T CIRC SYST VID
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dun JY, 2015, IEEE INTEL TRANSP SY, V7, P51, DOI 10.1109/MITS.2015.2412146
   Faradji F, 2007, IEEE IMAGE PROC, P57
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Hsu SC, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P1, DOI [10.1109/PLASMA.2017.8496316, 10.1109/IRC.2017.12]
   Hu L, 2018, IEEE INTERNET THINGS, V5, P747, DOI 10.1109/JIOT.2017.2705560
   Izidio DMF, 2020, DES AUTOM EMBED SYST, V24, P23, DOI 10.1007/s10617-019-09230-5
   Jia WJ, 2006, INT C PATT RECOG, P574
   Jia WJ, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P732
   Kessentini Y, 2019, EXPERT SYST APPL, V136, P159, DOI 10.1016/j.eswa.2019.06.036
   Khazaee Saeed, 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P425, DOI 10.1007/978-3-030-59830-3_37
   Kim S. G., 2017, Electronics Letters, V53, P1034, DOI 10.1049/el.2017.1373
   Lalimi MA, 2013, COMPUT ELECTR ENG, V39, P834, DOI 10.1016/j.compeleceng.2012.09.015
   Laxmi V, 2011, IET INTELL TRANSP SY, V5, P231, DOI 10.1049/iet-its.2010.0149
   Lazrus A., 2011, INT J MACHINE INTELL, V3, P134, DOI 10.9735/0975-2927.3.3.134-137
   이동석, 2016, [KIPS Transactions on Software and Data Engineering, 정보처리학회논문지. 소프트웨어 및 데이터 공학], V5, P511
   Li H, 2019, IEEE T INTELL TRANSP, V20, P1126, DOI 10.1109/TITS.2018.2847291
   Liu CS, 2019, IEEE T INTELL TRANSP, V20, P2122, DOI 10.1109/TITS.2018.2859348
   Montazzolli S, 2017, SIBGRAPI, P55, DOI 10.1109/SIBGRAPI.2017.14
   Omar N, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113280
   Qin SX, 2022, NEURAL COMPUT APPL, V34, P21551, DOI 10.1007/s00521-021-06147-8
   Rizvi STH, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040066
   Selmi Z, 2020, PATTERN RECOGN LETT, V129, P213, DOI 10.1016/j.patrec.2019.11.007
   Shapiro V, 2006, MACH VISION APPL, V17, P173, DOI 10.1007/s00138-006-0023-5
   Shi XF, 2005, LECT NOTES COMPUT SC, V3483, P1159
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Silva SM, 2018, LECT NOTES COMPUT SC, V11216, P593, DOI 10.1007/978-3-030-01258-8_36
   Tadic V, 2016, ENG APPL ARTIF INTEL, V48, P40, DOI 10.1016/j.engappai.2015.09.009
   Tian JM, 2013, PROC SPIE, V8921, DOI 10.1117/12.2031131
   Usmankhujaev S, 2019, 16 INT C DISTRIBUTED, P10
   Vardhana M, 2019, CLUSTER COMPUT, V22, P2495, DOI 10.1007/s10586-018-2152-9
   Wang G, 2021, ARXIV
   Wang RM, 2014, OPTIK, V125, P186, DOI 10.1016/j.ijleo.2013.06.008
   Wang WW, 2019, IEEE ACCESS, V7, P173875, DOI 10.1109/ACCESS.2019.2956357
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Xu ZB, 2018, LECT NOTES COMPUT SC, V11217, P261, DOI 10.1007/978-3-030-01261-8_16
   Yousaf U, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227696
   Yuan YL, 2017, IEEE T IMAGE PROCESS, V26, P1102, DOI 10.1109/TIP.2016.2631901
   Zhang SY, 2004, IEEE SYS MAN CYBERN, P4722
   Zhao Y, 2011, IEEE INT C INTELL TR, P314, DOI 10.1109/ITSC.2011.6082854
NR 49
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18649
EP 18666
DI 10.1007/s11042-023-16216-w
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900014
DA 2024-07-18
ER

PT J
AU Abbass, MY
AF Abbass, Mohammed Y. Y.
TI Homomorphic technique for image separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Homomorphic technique; RT; ICA; Blind source separation (BSS)
ID INDEPENDENT COMPONENT ANALYSIS; SHOW-THROUGH; ALGORITHM; TRANSFORM;
   MODEL
AB Signal Image separation is a significant processing task for accurate image reconstruction, which is increasingly applied to several medical imaging applications and communication areas. Most of classical separation approaches exploit frequency and time domains. These approaches, however are sensitive to noise, and thus often lead to undesirable results. In this paper, we propose a novel method of image separation. It incorporates the property of reflectance component extracted from the image and a Finite Ridgelet Transform (FRT) to obtain precise analysis of the images and thus correctly separate the images even in hardly noisy environment. We obtain the reflectance components of the target images by employing a homomorphic processing, which operates in the log domain, and thus can decompose the image into illumination and reflectance components. In addition, the homomorphic decomposition in the proposed method reduces information redundancy in the target image, and thus substantially improve the quality of image separation. We carried out extensive simulations, which demonstrate that the proposed homomorphic technique outperforms the conventional methods based on time domain and trigonometric transforms.
C1 [Abbass, Mohammed Y. Y.] Johannes Kepler Univ Linz, Inst Comp Graph, Linz, Austria.
   [Abbass, Mohammed Y. Y.] Nucl Res Ctr, Engn Dept, Atom Energy Author, Cairo, Egypt.
C3 Johannes Kepler University Linz; Egyptian Knowledge Bank (EKB); Egyptian
   Atomic Energy Authority (EAEA)
RP Abbass, MY (corresponding author), Johannes Kepler Univ Linz, Inst Comp Graph, Linz, Austria.; Abbass, MY (corresponding author), Nucl Res Ctr, Engn Dept, Atom Energy Author, Cairo, Egypt.
EM myehiaa@yahoo.com
CR Abbass MY, 2019, SIGNAL IMAGE VIDEO P, V13, P703, DOI 10.1007/s11760-018-1399-1
   Abbass MY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0276-8
   Abbass MY, 2022, J ELECTR ENG TECHNOL, V17, P2971, DOI 10.1007/s42835-022-01010-9
   Abbass MY, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2020.164926
   Abbass MY, 2021, MULTIMED TOOLS APPL, V80, P5403, DOI 10.1007/s11042-020-09824-3
   Abbass MY, 2021, VISUAL COMPUT, V37, P993, DOI 10.1007/s00371-020-01848-y
   Albera L, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P737, DOI 10.1016/B978-0-12-374726-6.00023-0
   Almeida MSC, 2012, SIGNAL PROCESS, V92, P872, DOI 10.1016/j.sigpro.2011.09.023
   Almeida MSC, 2008, NEUROCOMPUTING, V72, P57, DOI 10.1016/j.neucom.2007.12.048
   Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307
   Candes E. J., CURVELETS
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Cardoso JF, 1996, IEEE T SIGNAL PROCES, V44, P3017, DOI 10.1109/78.553476
   Elashry IF, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3167847
   Hammam H, 2010, INT J SPEECH TECHNOL, V13, P1, DOI 10.1007/s10772-010-9066-0
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Huang QG, 2016, DIGIT SIGNAL PROCESS, V52, P45, DOI 10.1016/j.dsp.2016.02.004
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Hyvarinen A., 1999, Neural Computing Surveys, V2
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kim S, 2009, IEEE T SIGNAL PROCES, V57, P2604, DOI 10.1109/TSP.2009.2017570
   Li XL, 2010, IEEE T SIGNAL PROCES, V58, P5151, DOI 10.1109/TSP.2010.2055859
   Özgen MT, 2009, DIGIT SIGNAL PROCESS, V19, P360, DOI 10.1016/j.dsp.2007.12.003
   Rao KR., 1990, DISCRETE COSINE TRAN, DOI [10.1016/B978-0-08-092534-9.50007-2, DOI 10.1016/B978-0-08-092534-9.50007-2]
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Walker J.S., 1999, ST ADV MATH
   Wei YJ, 2016, NEUROCOMPUTING, V185, P73, DOI 10.1016/j.neucom.2015.12.040
   Xiao LM, 2016, NEUROCOMPUTING, V195, P56, DOI 10.1016/j.neucom.2015.08.113
   Yu XC, 2013, SIGNAL PROCESS, V93, P288, DOI 10.1016/j.sigpro.2012.08.010
   Zhang HJ, 2014, NEUROCOMPUTING, V139, P261, DOI 10.1016/j.neucom.2014.02.033
   Zhang YJ, 2016, MULTIMED TOOLS APPL, V75, P12101, DOI 10.1007/s11042-016-3397-z
NR 32
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18639
EP 18648
DI 10.1007/s11042-023-15155-w
EA JUL 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000007
DA 2024-07-18
ER

PT J
AU Mohite, UL
   Patel, HG
AF Mohite, Utkarsha L. L.
   Patel, Hirenkumar G. G.
TI Non-linear kernel-based error function for extended Kalman filter
   oriented robust control of cancer chemotherapy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancer treatment; Chemotherapy; Robustness; Controlling model; Drug
   dosage
ID BREAST-CANCER; ADJUVANT CHEMOTHERAPY; SEVERITY; TRIAL; MODEL
AB Amongst the various treatment models, chemotherapy is the most significant and widely practiced to cure cancer. More computerized arithmetical schemes were introduced for controlling the growth of the tumor and also to maintain immune and normal cells at their preferred values by adjusting the drug dosages. Because of the inaccuracies of measurement and biological changes, a proper amount of modeling constraints is unavailable. Hence it is needed to model a controller such that should be robust over the parameter ambiguity and deviations. We introduce a new controller that manipulates the amount of the drug and does parameter assessment as well. Further, a NEF-EKF is established to estimate the cancer cells as it is complex to measure at the time of Vivo experiments. The presentation of proposed controller is contrasted over other conservative schemes, and the results show the proper effect of drug dose inoculation on cells. It is moreover guaranteed that the proposed controller performs well on uncertainties of parameters. Furthermore, it is proved that the projected improved Kalman Filter has the capacity on evaluating the cancer cells with high accurateness. The suggested NEF-EKF technique outperforms the existing EKF and AEKF methods by 9.52% and 4.47%, respectively, when taking into account the MARE measure of immune cells.
C1 [Mohite, Utkarsha L. L.] METs League Coll, Bhujbal Knowledge City, Nasik 422003, India.
   [Patel, Hirenkumar G. G.] Sardar Vallabhbhai Natl Inst Technol, Surat 395007, Gujarat, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology
RP Mohite, UL (corresponding author), METs League Coll, Bhujbal Knowledge City, Nasik 422003, India.
EM utkarshamohite@gmail.com
CR Abbasian M, 2018, INT J BIOL MACROMOL, V118, P1871, DOI 10.1016/j.ijbiomac.2018.07.036
   Akhlaghi S, 2017, IEEE POW ENER SOC GE, DOI 10.1109/PESGM.2017.8273755
   Bao T, 2018, EUR J CANCER, V101, P12, DOI 10.1016/j.ejca.2018.06.008
   Batmani Y, 2013, COMPUT BIOL MED, V43, P2089, DOI 10.1016/j.compbiomed.2013.09.026
   Chen T, 2012, COMPUT METH PROG BIO, V108, P973, DOI 10.1016/j.cmpb.2012.05.011
   Gajra A, 2018, J GERIATR ONCOL, V9, P221, DOI 10.1016/j.jgo.2018.02.003
   Gali V., 2021, J COMPUT MECH POWER, V4, P1, DOI [10.46253/jcmps.v4i2.a1, DOI 10.46253/JCMPS.V4I2.A1]
   Gibbons A, 2018, EUR J ONCOL NURS, V35, P85, DOI 10.1016/j.ejon.2018.06.003
   Glaa B, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED LOGISTICS & TRANSPORT (ICALT 2014), P189
   Jiang SF, 2018, EUR J PHARMACOL, V831, P46, DOI 10.1016/j.ejphar.2018.04.009
   Khalili P, 2022, CYBERNET SYST, DOI 10.1080/01969722.2022.2157608
   Kimmick GG, 2018, J GERIATR ONCOL, V9, P214, DOI 10.1016/j.jgo.2017.11.004
   Kuqi B, 2023, J SUSTAIN FINANC INV, V13, P92, DOI 10.1080/20430795.2021.1883986
   Kurt B, 2018, EUR J INTEGR MED, V22, P54, DOI 10.1016/j.eujim.2018.08.002
   Liang LZ, 2018, J CRANIO MAXILL SURG, V46, P605, DOI 10.1016/j.jcms.2017.12.016
   Mandala J., 2019, J NETWORKING COMMUNI, V2, P10, DOI DOI 10.1016/J.PROCS.2017.08.292
   Matsuda C, 2018, EUR J CANCER, V96, P54, DOI 10.1016/j.ejca.2018.03.009
   Paryad-Zanjani S, 2016, IFAC PAPERSONLINE, V49, P277, DOI 10.1016/j.ifacol.2016.12.138
   Peng F, 2018, J PHARMACEUT BIOMED, V154, P95, DOI 10.1016/j.jpba.2018.02.051
   Pouchol C, 2018, J MATH PURE APPL, V116, P268, DOI 10.1016/j.matpur.2017.10.007
   Rajakumar BR, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Rokhforoz Pegah, 2017, Informatics in Medicine Unlocked, V8, P1, DOI 10.1016/j.imu.2017.03.002
   Samson P, 2018, J THORAC CARDIOV SUR, V156, P1725, DOI 10.1016/j.jtcvs.2018.05.100
   Saneja A, 2018, EUR J PHARM SCI, V121, P47, DOI 10.1016/j.ejps.2018.05.012
   Schattler H, 2010, OPTIMAL CONTROL MATH
   Siket M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10249046
   Sugarbaker PH, 2018, INT J SURG CASE REP, V47, P25, DOI 10.1016/j.ijscr.2018.04.017
   Sun BJ, 2017, J CONTROL RELEASE, V264, P145, DOI 10.1016/j.jconrel.2017.08.034
   Sun X, 2018, CHEM ENG J, V350, P69, DOI 10.1016/j.cej.2018.05.157
   Takemoto S, 2017, J INFECT CHEMOTHER, V23, P752, DOI 10.1016/j.jiac.2017.07.003
   Toyooka S, 2018, J THORAC ONCOL, V13, P699, DOI 10.1016/j.jtho.2018.02.015
   Vinolin V., 2019, MULTIMEDIA RES, V2, P10, DOI DOI 10.46253/J.MR.V2I2.A2
   Wang FH, 2017, J CONTROL RELEASE, V267, P100, DOI 10.1016/j.jconrel.2017.09.026
   Wu HL, 2018, CHEM ENG J, V349, P129, DOI 10.1016/j.cej.2018.05.082
   Wu X, 2018, EUR J CONTROL, V42, P49, DOI 10.1016/j.ejcon.2018.02.004
NR 35
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17491
EP 17509
DI 10.1007/s11042-023-16141-y
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700007
DA 2024-07-18
ER

PT J
AU Xiao, T
   Wang, J
   Zheng, HY
   Yao, J
AF Xiao, Tao
   Wang, Jing
   Zheng, Huiyi
   Yao, Jie
TI Design and optimization of mobile learning applications based on
   Hierarchical Bayes conjoint models of user preferences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conjoint analysis; User-centered design; User research methods
ID ATTRIBUTES; STATISTICS; APP
AB When developing new mobile applications, it is critical to accurately understand the needs of the target users at the early stage, so that the designed products can better match user preferences and improve user experience. Using the powerful method of conjoint analysis and Hierarchical Bayes (HB) statistical estimation, this exploratory study sought to better model individual user needs and desired functions for a mobile English learning application, in comparison with traditional user research approaches. Participants in a Web-based conjoint experiment evaluated a series of hypothetical mobile applications for English learning, in which learning contents, duration of learning time, and frequency of study per week were found to have the biggest impacts on their choices. Based on HB models that better captured individual differences among users and therefore quantified the importance of each design attribute more accurately, an optimized mobile application was designed, which was predicted to maximize the share of preference among target consumers.
C1 [Xiao, Tao; Zheng, Huiyi] Shenzhen Univ, Coll Math & Stat, Shenzhen 518060, Peoples R China.
   [Wang, Jing; Yao, Jie] Harbin Inst Technol Shenzhen, Sch Humanities & Social Sci, Dept Design, Shenzhen 518055, Peoples R China.
C3 Shenzhen University; Harbin Institute of Technology
RP Yao, J (corresponding author), Harbin Inst Technol Shenzhen, Sch Humanities & Social Sci, Dept Design, Shenzhen 518055, Peoples R China.
EM taoxiao@szu.edu.cn; 1014738144@qq.com; yaojiejulie@hit.edu.cn
FU National Social Science Fund of China [20BTY120]
FX AcknowledgementsThis study was funded by the National Social Science
   Fund of China (General Grant 20BTY120). The authors would also like to
   thank Huanshu Jiang for her help in manuscript revision.
CR Annis DH., 2006, J AM STAT ASSOC, V101, P1732, DOI [10.1198/jasa.2006.s158, DOI 10.1198/JASA.2006.S158]
   Bauer H. H., 2007, International Journal of Mobile Communications, V5, P457, DOI 10.1504/IJMC.2007.012791
   Bor-Tyng Wang, 2017, International Journal of Information and Education Technology, V7, P279, DOI 10.18178/ijiet.2017.7.4.881
   Butcher M, 2020, LANGUAGE PLATFORM BU
   Chen CM, 2019, COMPUT ASSIST LANG L, V32, P237, DOI 10.1080/09588221.2018.1485708
   Chen YH, 2010, J BUS RES, V63, P1007, DOI 10.1016/j.jbusres.2009.01.023
   Cobb GW, 1997, AM MATH MON, V104, P801, DOI 10.2307/2975286
   Davis F D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results
   Do Bagus MR, 2016, PROCEEDINGS 2016 5TH IIAI INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS IIAI-AAI 2016, P1026, DOI 10.1109/IIAI-AAI.2016.86
   GOLDBERG SM, 1984, J BUS, V57, pS111, DOI 10.1086/296241
   Hao YW, 2019, COMPUT HUM BEHAV, V95, P208, DOI 10.1016/j.chb.2018.10.013
   Head M, 2012, COMPUT HUM BEHAV, V28, P2331, DOI 10.1016/j.chb.2012.07.003
   Hing N, 2017, J BEHAV ADDICT, V6, P658, DOI 10.1556/2006.6.2017.062
   Huertas-Garcia R, 2014, INT J TOUR RES, V16, P65, DOI 10.1002/jtr.1899
   Huyen NT, 2016, IEEE INT CONF ADV LE, P104, DOI 10.1109/ICALT.2016.137
   Ibrahim NK, 2019, IEEE ACCESS, V7, P146620, DOI 10.1109/ACCESS.2019.2941640
   Ketyi A., 2013, 20 Years of EUROCALL: Learning from the Past, Looking to the Future. Proceedings of the 2013 EUROCALL Conference, Evora, P129, DOI 10.14705/rpnet.2013.000150
   Ketyi A., 2015, CriticalCALL - Proceedings of the 2015 EUROCALL Conference, Padova, Italy, P306, DOI DOI 10.14705/RPNET.2015.000350
   KOHLI R, 1991, J MARKETING RES, V28, P347, DOI 10.2307/3172870
   Lee SM, 2020, COMPUT ASSIST LANG L, V33, P936, DOI 10.1080/09588221.2019.1602545
   Leib T, 2018, INT J HOSP TOUR ADM, V19, P361, DOI 10.1080/15256480.2017.1348923
   Liu HF, 2016, ADV SOC SCI EDUC HUM, V54, P208
   Liu TP, 2016, 2016 INTERNATIONAL CONFERENCE ON SUSTAINABLE ENERGY, ENVIRONMENT AND INFORMATION ENGINEERING (SEEIE 2016), P307
   LUCE RD, 1964, J MATH PSYCHOL, V1, P1, DOI 10.1016/0022-2496(64)90015-X
   Makoe M, 2018, INT REV RES OPEN DIS, V19, P208
   Malerba ML, 2015, EDEN 2015 ANN C EXP, P1
   McFadden D., 1974, Frontiers in econometrics, DOI DOI 10.1108/EB028592
   Na-Young Kim, 2019, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V22, P32
   Nikou Shahrokh, 2012, Info, V14, P21, DOI 10.1108/14636691211256287
   Ohkawa Y, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR), P584, DOI 10.1109/ICBIR.2018.8391265
   Orme B., 2013, SAWTOOTH SOFTWARE RE
   Orme BK., 2017, BECOMING EXPERT CONJ
   Orme Bryan K., 2010, Getting Started with Conjoint Analysis: Strategies for Product Design and Pricing Research, V2nd ed
   Pemba D., 2016, Open Journal of Social Sciences, V4, P85, DOI DOI 10.4236/JSS.2016
   Quan WS, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MECHATRONICS AND INFORMATION TECHNOLOGY (ICMIT 2017), P329
   Rivera M, 2016, INT J CONTEMP HOSP M, V28, P2721, DOI 10.1108/IJCHM-02-2015-0052
   Rosell-Aguilar F, 2018, COMPUT ASSIST LANG L, V31, P854, DOI 10.1080/09588221.2018.1456465
   Rossi PE, 2003, MARKET SCI, V22, P304, DOI 10.1287/mksc.22.3.304.17739
   Shih RC, 2015, PROCD SOC BEHV, V174, P2634, DOI 10.1016/j.sbspro.2015.01.945
   Shon M, 2021, TELEMAT INFORM, V56, DOI 10.1016/j.tele.2020.101476
   Silverman S, 2013, OSTEOPOROSIS INT, V24, P2067, DOI 10.1007/s00198-012-2241-1
   SRINIVASAN V, 1981, J MARKETING, V45, P157, DOI 10.2307/1251550
   Tseng CC, 2011, J IND PROD ENG, V28, P298, DOI 10.1080/10170669.2011.579477
   Wooliscroft B, 2014, TRANSPORT RES A-POL, V69, P11, DOI 10.1016/j.tra.2014.08.005
   Yao J, 2021, ACCIDENT ANAL PREV, V157, DOI 10.1016/j.aap.2021.106188
   Yao J, 2014, TRAFFIC INJ PREV, V15, P213, DOI 10.1080/15389588.2013.808338
   Yu-Chun Wang, 2020, International Journal of Information and Education Technology, V10, P110, DOI 10.18178/ijiet.2020.10.2.1348
   Zhang SH, 2016, INT J EMERG TECHNOL, V11, P4, DOI 10.3991/ijet.v11i12.6314
   Zinkhan FC., 1994, MANAGE FINANC, V20, P37, DOI [10.1108/eb018480, DOI 10.1108/EB018480]
   Zinkhan GM., 1994, MANAGE FINANC, V20, P2, DOI [10.1108/eb018478, DOI 10.1108/EB018478]
   Zou B, 2018, COMPUT ASSIST LANG L, V31, P694, DOI 10.1080/09588221.2018.1438474
NR 51
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17001
EP 17024
DI 10.1007/s11042-023-16229-5
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500004
DA 2024-07-18
ER

PT J
AU Pradhan, N
   Sagar, S
   Singh, AS
AF Pradhan, Nilanjana
   Sagar, Shrdhha
   Singh, Ajay Shankar
TI Analysis of MRI image data for Alzheimer disease detection using deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning (DL); Cerebrospinal fluid (CSF); Electronic health record
   (EHR); Single nucleotide polymorphisms (SNPs); Alzheimer's disease (AD)
ID DIAGNOSIS
AB Alzheimer's disease (AD) is the leading cause of dementia globally and one of the most serious future healthcare issue. AD is expected to rise from 27 million to 106 million cases in the next four decades impacting one in every 85 people on the planet. For the existing healthcare systems, the most frequent kind of dementia is a significant source of worry. AD usually refers to Untreated Schizophrenia, a degenerative neurological disorder defined by memory loss and disorientation. AD is the world's third greatest cause of mortality, after only heart disease and cancer. It has surpassed cancer as the most dreaded disease on the planet. AD is catastrophic in the long-term run since it slowly but gradually destroys the body's cells. A variety of efforts have been made to employ structural Magnetic Resonance Imaging (MRI) modalities to differentiate between people with AD and their healthy counterparts. These have also been examined as deep learning algorithms for the categorization of MRI data. It is difficult to find patients with modest cognitive decline who may acquire Alzheimer's. As a result, creating deep learning-based disease detection techniques to assist clinicians in detecting prospective Alzheimer's patients is crucial. The performance comparison of the Imaging, Electronic Health Record (EHR), and Single Nucleotide Polymorphisms (SNP) datasets are evaluated using the metrics Accuracy, Sensitivity, Specificity, and Multi Area. Different mistakes are added under the curves for gradient calculation. The research results are as follows: based on standard datasets the results show that the proposed feature selection algorithms discover a sub-optimal minimal level feature set from a larger input feature set for diagnosing Alzheimer's disease, with higher values for system performance in terms of Accuracy as well as losses against training and Accuracy and losses against validation. These results can demonstrate the model's suitability for the purpose.
C1 [Pradhan, Nilanjana; Sagar, Shrdhha; Singh, Ajay Shankar] Galgotias Univ, Greater Noida 203201, Uttar Pradesh, India.
C3 Galgotias University
RP Pradhan, N (corresponding author), Galgotias Univ, Greater Noida 203201, Uttar Pradesh, India.
EM nilanjana.pradhan@gmail.com; sagarshraddha@gmail.com;
   drajay.cse@gmail.com
OI Pradhan, Nilanjana/0000-0002-8082-5867
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Al-Shoukry S, 2020, IEEE ACCESS, V8, P77131, DOI 10.1109/ACCESS.2020.2989396
   Allioui H, 2019, INT J ADV COMPUT SC, V10, P365
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Ateeq T, 2018, COMPUT ELECTR ENG, V69, P768, DOI 10.1016/j.compeleceng.2018.02.021
   Billones CD, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3724, DOI 10.1109/TENCON.2016.7848755
   [常亮 Chang Liang], 2016, [自动化学报, Acta Automatica Sinica], V42, P1300
   Cui RX, 2018, I S BIOMED IMAGING, P1398, DOI 10.1109/ISBI.2018.8363833
   Ebrahimighahnavieh MA, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105242
   Gupta M, 2022, SOFT COMPUT, V26, P8025, DOI 10.1007/s00500-022-07047-2
   Hecht M, 2018, ACTA NEUROPATHOL, V135, P681, DOI 10.1007/s00401-018-1834-y
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Ji HH, 2019, ICCCV 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON CONTROL AND COMPUTER VISION, P87, DOI 10.1145/3341016.3341024
   Kumar K, 2018, BIOMED PHARMACOTHER, V98, P297, DOI 10.1016/j.biopha.2017.12.053
   Kumar N, 2022, ENG TECHNOL APPL SCI, V12, P7993, DOI 10.48084/etasr.4613
   Kumar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9983652
   Kundaram Swathi S., 2021, Proceedings of the Fourth International Conference on Microelectronics, Computing and Communication Systems. MCCS 2019. Lecture Notes in Electrical Engineering (LNEE 673), P587, DOI 10.1007/978-981-15-5546-6_50
   Martinez-Murcia FJ, 2020, IEEE J BIOMED HEALTH, V24, P17, DOI 10.1109/JBHI.2019.2914970
   Mehmood A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020084
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Ortiz A, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500258
   Park KH, 2016, IEEE T NEUR SYS REH, V24, P928, DOI 10.1109/TNSRE.2015.2481461
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarraf S, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P816, DOI 10.1109/FTC.2016.7821697
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Theofilas P, 2018, NEUROBIOL AGING, V61, P1, DOI 10.1016/j.neurobiolaging.2017.09.007
   Tyagi A, 2023, COMM COM INF SC, V1798, P423, DOI 10.1007/978-3-031-28183-9_30
   Tyagi A, 2023, MULTIMED TOOLS APPL, V82, P20343, DOI 10.1007/s11042-022-13809-9
   Venugopalan J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-74399-w
   Verma A, 2022, MULTIMED TOOLS APPL, V81, P37541, DOI 10.1007/s11042-022-13545-0
   Waddell Michael., 2005, BIOKDD 05, P21, DOI [DOI 10.1145/1134030.1134035, 10.1145/1134030.1134035]
   Wang CY, 2018, NEUROBIOL DIS, V109, P88, DOI 10.1016/j.nbd.2017.10.003
   Zhang F, 2019, NEUROCOMPUTING, V361, P185, DOI 10.1016/j.neucom.2019.04.093
NR 34
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17729
EP 17752
DI 10.1007/s11042-023-16256-2
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200004
DA 2024-07-18
ER

PT J
AU Olota, M
   Alsadoon, A
   Alsadoon, OH
   Dawoud, A
   Prasad, PWC
   Islam, R
   Jerew, OD
AF Olota, Mustapha
   Alsadoon, Abeer
   Alsadoon, Omar Hisham
   Dawoud, Ahmed
   Prasad, P. W. C.
   Islam, Rafiqul
   Jerew, Oday D. D.
TI Modified anisotropic diffusion and level-set segmentation for breast
   cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic diffusion; Thermography; Least square support Vector
   machine; Gaussian filter; Level-set segmentation; Canny edge detection
ID SUPPORT VECTOR MACHINE; PREDICTION; THERMOGRAPHY; FEATURES; IMAGES
AB Breast cancer is frequent among women and its early diagnosis using thermography is not been widely practiced in medical facilities due to its limitation in classification accuracy, sensitivity, and specificity. This research aims to improve the accuracy, sensitivity, and specificity of breast cancer classification in thermal images. The proposed system is composed of the Least Square Support Vector Machine (LSSVM) to improve the classification and prediction accuracy of breast thermography images using optimized hyperparameters. Multi-view breast thermal images are pre-processed using Gaussian Filtering (GF) with a standard deviation value of 1.4 which is followed by anisotropic diffusion while trying to enhance the image by removing noise. Interested regions are segmented by the level-set segmentation technique, and canny edge detection is applied to the segmented output to limit the amount of data and filter useless information. Texture features are extracted from 1370 healthy and 645 sick subjects fetched from Database for Mastology Research (DBR) which is an online free thermogram database. The features from different views of thermograms are later reduced with a t-test. Significant features are added together to obtain feature vector which produces vectors that are further supplied to the Vector Support Machine that utilizes optimized hyper-parameters for the breast thermogram classification. Compared to the state of art solution, the proposed system increased the accuracy by 9% while sensitivity and specificity get increased by 5.75% and 7.25% respectively. The proposed method focuses on modifying the anisotropic diffusion function and enhancing the segmentation of breast thermograms for classification analysis.
C1 [Olota, Mustapha; Alsadoon, Abeer; Prasad, P. W. C.; Islam, Rafiqul] Charles Sturt Univ CSU, Sch Comp Math & Engn, Bathurst, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.
   [Alsadoon, Abeer; Dawoud, Ahmed; Jerew, Oday D. D.] Asia Pacific Int Coll APIC, Sydney, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Inuvers, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Bathurst, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Islam, Rafiqul/0000-0001-8317-5727
CR Abdel-Nasser M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010100
   Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4
   Aghazadeh N, 2023, J SUPERCOMPUT, V79, P7337, DOI 10.1007/s11227-022-04948-9
   Figueiredo AAA, 2018, INFRARED PHYS TECHN, V95, P100, DOI 10.1016/j.infrared.2018.10.027
   Choi SI, 2018, IEEE ACCESS, V6, P13663, DOI 10.1109/ACCESS.2018.2812725
   Das S, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105273
   Guirro RRD, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0730-7
   Devi RR, 2019, J MED SYST, V43, P6
   Díaz-Cortés MA, 2018, INFRARED PHYS TECHN, V93, P346, DOI 10.1016/j.infrared.2018.08.007
   Gogoi UR, 2019, INFRARED PHYS TECHN, V99, P201, DOI 10.1016/j.infrared.2019.01.004
   Goncalves C., 2019, 15 INT WORKSH ADV IN, P45, DOI DOI 10.3390/PROCEEDINGS2019027045
   Gonzalez-Hernandez JL, 2019, INT J HEAT MASS TRAN, V131, P558, DOI 10.1016/j.ijheatmasstransfer.2018.11.089
   Guzman-Cabrera R, 2016, DESTECH T COMPUT SCI
   Hamidpour SSF, 2020, COMP M BIO BIO E-IV, V8, P103, DOI 10.1080/21681163.2019.1598895
   He L, 2022, SPIE, V12167, P417
   Jeyanathan JS, 2019, CIRC SYST SIGNAL PR, V38, P5734, DOI 10.1007/s00034-019-01148-4
   Jiang X, 2012, PHYSCS PROC, V33, P840, DOI 10.1016/j.phpro.2012.05.143
   Kisi O, 2016, J HYDROL, V534, P104, DOI 10.1016/j.jhydrol.2015.12.014
   Kumar L, 2018, J SYST SOFTWARE, V137, P686, DOI 10.1016/j.jss.2017.04.016
   Madhavi V, 2019, QUANT INFR THERM J, V16, P111, DOI 10.1080/17686733.2018.1544687
   Magalhaes C, 2019, J EUR ACAD DERMATOL, V33, P1700, DOI 10.1111/jdv.15611
   Maniatopoulos G, 2015, SOC SCI MED, V131, P98, DOI 10.1016/j.socscimed.2015.02.036
   Min SD, 2017, KSII T INTERNET INF, V11
   Morales-Cervantes A, 2018, EXCLI J
   Prabha S, 2018, INFRARED PHYS TECHN, V93, P316, DOI 10.1016/j.infrared.2018.08.018
   Radha MRM, 2017, KSII T INTERNET INF, V11
   Sarigoz T, 2018, INFRARED PHYS TECHN, V91, P214, DOI 10.1016/j.infrared.2018.04.019
   Sathish D, 2019, VISUAL COMPUT, V35, P57, DOI 10.1007/s00371-017-1447-9
   Saxena A, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103063
   Suradi SH, 2022, COMP M BIO BIO E-IV, V10, P67, DOI 10.1080/21681163.2021.1972344
   Torres-Galván JC, 2022, QUANT INFR THERM J, V19, P283, DOI 10.1080/17686733.2021.1918514
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Wong DJ, 2023, CLIN BREAST CANCER, V23, pE56, DOI 10.1016/j.clbc.2023.01.009
   Xu Y, 2017, PATTERN ANAL APPL, V20, P579, DOI 10.1007/s10044-016-0590-7
   Yao K, 2014, GASTRIC CANCER, V17, P669, DOI 10.1007/s10120-013-0332-0
NR 35
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13503
EP 13525
DI 10.1007/s11042-023-16021-5
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800005
DA 2024-07-18
ER

PT J
AU Garcia-Cuesta, E
   Salvador, AB
   Paez, DG
AF Garcia-Cuesta, Esteban
   Barba Salvador, Antonio
   Gachet Paez, Diego
TI EmoMatchSpanishDB: study of speech emotion recognition machine learning
   models in a new Spanish elicited database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective analysis; Speech emotion recognition; EmoMatchSpanishDB;
   Language resources; Machine learning
ID SOCIAL ANXIETY
AB In this paper we present a new speech emotion dataset on Spanish. The database is created using an elicited approach and is composed by fifty non-actors expressing the Ekman's six basic emotions of anger, disgust, fear, happiness, sadness, and surprise, plus neutral tone. This article describes how this database has been created from the recording step to the performed crowdsourcing perception test step. The crowdsourcing has facilitated to statistically validate the emotion of each collected audio sample and also to filter noisy data samples. Hence we obtained two datasets EmoSpanishDB and EmoMatchSpanishDB. The first includes those recorded audios that had consensus during the crowdsourcing process. The second selects from EmoSpanishDB only those audios whose emotion also matches with the originally elicited. Last, we present a baseline comparative study between different state of the art machine learning techniques in terms of accuracy, precision, and recall for both datasets. The results obtained for EmoMatchSpanishDB improves the ones obtained for EmoSpanishDB and thereof, we recommend to follow the methodology that was used for the creation of emotional databases.
C1 [Garcia-Cuesta, Esteban] Univ Politecn Madrid, Dept Inteligencia Artificial, Ave Monteprincipe S-N, Madrid 28660, Spain.
   [Barba Salvador, Antonio] Univ Europea Madrid, Dept Ciencia & Computac, C Tajo S-N, Madrid 28670, Spain.
   [Gachet Paez, Diego] Univ Francisco de Vitoria, Dept Automat, Av Majadahonda S-N, Madrid 28223, Spain.
C3 Universidad Politecnica de Madrid; European University of Madrid;
   Universidad Francisco de Vitoria
RP Garcia-Cuesta, E (corresponding author), Univ Politecn Madrid, Dept Inteligencia Artificial, Ave Monteprincipe S-N, Madrid 28660, Spain.
EM esteban.garcia@fi.upm.es; antonio.barba@universidadeuropea.es;
   diegogabriel.gachet@ufv.es
RI García-Cuesta, Esteban/C-7055-2008
OI García-Cuesta, Esteban/0000-0002-1215-3333; Barba,
   Antonio/0000-0001-8013-7450
CR Amer MR, 2014, ICASSP, P3752
   [Anonymous], 2014, Voice-enabled assistive robots for handling autism spectrum conditions: an examination of the role of prosody
   [Anonymous], 2008, P 2008 C EMPIRICAL M
   [Anonymous], 2005, P INTERSPEECH
   Rodríguez IA, 2016, LOQUENS, V3, DOI 10.3989/loquens.2016.029
   Attwood AS, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160855
   Calvo RA, 2012, IEEE INTELL SYST, V27, P86, DOI 10.1109/MIS.2012.110
   Cao H., 2014, COMPUT SPEECH LANG
   Cavanagh SR, 2011, EMOTION, V11, P241, DOI 10.1037/a0022572
   Chang-Hong L, 2014, SCI WORLD J, V2014
   Ekman P., 1984, APPROACHES EMOTION, V3, P319, DOI DOI 10.1017/CBO9781107415324.004
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Grichkovtsova I, 2012, SPEECH COMMUN, V54, P414, DOI 10.1016/j.specom.2011.10.005
   Iriondo I., 2000, ISCA TUT RES WORKSH
   Izard CE, 2010, EMOT REV, V2, P363, DOI 10.1177/1754073910374661
   Jadoul Y, 2018, J PHONETICS, V71, P1, DOI 10.1016/j.wocn.2018.07.001
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Lausen A, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0499-z
   Madhu N, 2009, ELECTRON LETT, V45, P1195, DOI 10.1049/el.2009.1977
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mehrabian A., 1971, Silent Messages, V8, P30
   Montero J.M., 1999, P INT C PHONETIC SCI, V2, P957
   Muhammadi J, 2013, CROWD LABELING SURVE
   Parada-Cabaleiro E, 2020, LANG RESOUR EVAL, V54, P341, DOI 10.1007/s10579-019-09450-y
   Peipei Shen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P621, DOI 10.1109/EMEIT.2011.6023178
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Poblet M, 2018, INFORM SYST FRONT, V20, P1363, DOI 10.1007/s10796-017-9734-6
   Polzehl T, 2010, SPEECH PROSODY 2010
   Poorna SS, 2019, INT J SPEECH TECHNOL, V22, P327, DOI 10.1007/s10772-019-09605-w
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Quadflieg S, 2007, BEHAV RES THER, V45, P3096, DOI 10.1016/j.brat.2007.08.003
   Real Academia Espanola y Asociacion de Academias de la Lengua Espanola, 2005, DICC PANH DUD
   Rozgic V, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P366
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2
   Scherer Klaus R., 2010, A Blueprint for Affective Computing: a Sourcebook and Manual
   Schuller B., 2009, The Role of Prosody in Affective Speech, P285
   Schuller B, 2016, INTERSPEECH, P2001, DOI 10.21437/Interspeech.2016-129
   Staugaard SR, 2010, CLIN PSYCHOL REV, V30, P669, DOI 10.1016/j.cpr.2010.05.001
   Sung-Woo Byun, 2016, Transactions of the Korean Institute of Electrical Engineers, V65, P116, DOI 10.5370/KIEE.2016.65.1.116
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tacconi D, 2008, 2008 2ND INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING TECHNOLOGIES FOR HEALTHCARE, P93
   Tremeau Fabien, 2006, Dialogues Clin Neurosci, V8, P59
   Tseng HH, 2017, COGN NEUROPSYCHIATRY, V22, P331, DOI 10.1080/13546805.2017.1330190
   Vaidyanathan P.P., 2008, The Theory of Linear Prediction, V1st
   Xu Z., 2018, SPEECH COMMUN, P1
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13093
EP 13112
DI 10.1007/s11042-023-15959-w
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001018739400001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Umale, A
   Lal, N
   Goel, C
AF Umale, Ankita
   Lal, Nidhi
   Goel, Charu
TI Vision-based outlier detection techniques in automated surveillance: a
   survey and future ideas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier detection; Motion patterns; Object detection; Noise
   interference; Camouflaged anomaly; Video surveillance
ID ANOMALY DETECTION; OBJECT DETECTION; VIDEO; NOISE; LOCALIZATION;
   CAMOUFLAGE; REMOVAL; NETWORK; PATTERN
AB Outlier detection is one of the emerging study topics influenced by video annotation. An outlier is anything odd or irregular that deviates from the norm. Outlier detection is subjective since it is influenced by a variety of contextual circumstances. Human mobility patterns and classification are explored in this survey to combine it for further anomaly detection. There is a possibility of noise interference in automated surveillance, which disturbs a video stream and makes it difficult to identify details, reducing its accuracy. The presence of such frequent noise-interference raises the error rate, particularly in real-time processing models. Aside from that, Motion Camouflage must be addressed in intelligent surveillance to obtain a clear view of the frame. This paper offers a focused survey, highlighting the three major issues in video anomaly detection: the inadequate utilization of Motion Patterns, the prolonged Noise Interference that affects accuracy and leads to an increased error rate, and the elevated false-alarm rate due to Motion Camouflage. A brief analysis of these techniques, as well as their limitations, is provided. This paper focuses on probable challenges in the field of video-based outlier detection in automated surveillance and ways to mitigate those challenges. Moreover, this survey draws attention to the promising directions of research.
C1 [Umale, Ankita] IIIT Nagpur, Dept Comp Sci & Engn, Nagpur, India.
   [Lal, Nidhi] VNIT Nagpur, Dept Comp Sci & Engn, Nagpur, India.
   [Goel, Charu] IIIT Nagpur, Dept Basic Sci, Nagpur, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Umale, A (corresponding author), IIIT Nagpur, Dept Comp Sci & Engn, Nagpur, India.
EM dtea20cse011@iiitn.ac.in; nidhilal@cse.vnit.ac.in; charugoel@iiitn.ac.in
CR Aggarwal A, 2020, SMART SUSTAIN BUILT, V9, P737, DOI 10.1108/SASBE-07-2019-0083
   Amato A, 2014, MOVING CAST SHADOWS, P23
   [Anonymous], 2015, PROC CVPR IEEE
   Bajaj Komal, 2020, Procedia Computer Science, V171, P1535, DOI 10.1016/j.procs.2020.04.164
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Camplani M, 2017, LECT NOTES COMPUT SC, V10590, P219, DOI 10.1007/978-3-319-70742-6_21
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Choudhary C, 2023, EXPERT SYST APPL, V216, DOI 10.1016/j.eswa.2022.119420
   Cuthill IC, 2019, CURR OPIN BEHAV SCI, V30, P109, DOI 10.1016/j.cobeha.2019.07.007
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Genovese M, 2013, J REAL-TIME IMAGE PR, V8, P389, DOI 10.1007/s11554-011-0238-1
   Haseeb M, 2012, LECT NOTES COMPUT SC, V7626, P467, DOI 10.1007/978-3-642-34166-3_51
   Havasi L, 2007, IEEE T IMAGE PROCESS, V16, P503, DOI 10.1109/TIP.2006.888339
   Huang ZY, 2019, IEEE T IND ELECTRON, V66, P9798, DOI 10.1109/TIE.2018.2870413
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kadu H, 2014, IEEE T MULTIMEDIA, V16, P2191, DOI 10.1109/TMM.2014.2360793
   Kavikuil K, 2018, LEVERAGING DEEP LEAR, V815
   Kumar M, 2022, ARTIF INTELL REV, V55, P2997, DOI 10.1007/s10462-021-10070-8
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P119, DOI 10.1080/00450618.2017.1356868
   Kumar MK., 2022, DEEP LEARNING BASED
   Lee SW, 2005, IEEE T CONSUM ELECTR, V51, P648, DOI 10.1109/TCE.2005.1468014
   Liu JX, 2021, VISUAL COMPUT, V37, P359, DOI 10.1007/s00371-020-01804-w
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Luo J, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107427
   Maggioni M, 2014, IEEE T IMAGE PROCESS, V23, P4282, DOI 10.1109/TIP.2014.2345261
   Moreau T., 2017, Proceedings of 5th International Conference on Learning Representations, P1
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nasaruddin N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00365-y
   Pang SC, 2017, ENG APPL ARTIF INTEL, V65, P406, DOI 10.1016/j.engappai.2017.08.010
   Peng X, 2018, IEEE T IMAGE PROCESS, V27, P5076, DOI 10.1109/TIP.2018.2848470
   Peng X, 2018, IEEE T NEUR NET LEAR, V29, P218, DOI 10.1109/TNNLS.2016.2608834
   Pop DO, 2019, IEEE ACCESS, V7, P149318, DOI 10.1109/ACCESS.2019.2944792
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Raheja S, 2021, SIMUL MODEL PRACT TH, V109, DOI 10.1016/j.simpat.2021.102281
   Rajeshdate A, 2018, 2017 INT C COMP COMM
   Rao CP, 2020, INT J SPEECH TECHNOL, V23, P327, DOI 10.1007/s10772-020-09699-7
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sedghi M, 2022, IEEE T KNOWL DATA EN, V34, P3057, DOI 10.1109/TKDE.2020.3024099
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Shi XJ, 2015, ADV NEUR IN, V28
   Shijila B, 2019, FUTURE GENER COMP SY, V90, P198, DOI 10.1016/j.future.2018.07.065
   Singh Sahajpreet, 2021, 2021 8th International Conference on Signal Processing and Integrated Networks (SPIN), P379, DOI 10.1109/SPIN52536.2021.9565990
   Singh SK, 2013, IERI PROC, V4, P351, DOI 10.1016/j.ieri.2013.11.050
   Singh V., 2020, Procedia Comput. Sci, V173, P254, DOI DOI 10.1016/J.PROCS.2020.06.030
   Preethaa KRS, 2020, SOFT COMPUT, V24, P12303, DOI 10.1007/s00500-020-04674-5
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun JY, 2019, MULTIMED TOOLS APPL, V78, P3633, DOI 10.1007/s11042-017-5244-2
   Tian Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4955, DOI 10.1109/ICCV48922.2021.00493
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Wang Q, 2020, CHAOS SOLITON FRACT, V131, DOI 10.1016/j.chaos.2019.109463
   Wang ZY, 2016, AAAI CONF ARTIF INTE, P2194
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu K, 2020, IEEE T MULTIMEDIA, V22, P394, DOI 10.1109/TMM.2019.2929931
   Yadav DK, 2017, COMM COM INF SC, V721, P471, DOI 10.1007/978-981-10-5427-3_49
   Yeh CH, 2017, IEEE T IND ELECTRON, V64, P4945, DOI 10.1109/TIE.2017.2669881
   Yuan Y, 2016, IEEE T CYBERNETICS, V46, P3123, DOI 10.1109/TCYB.2015.2497711
   Zhang X, 2020, IEEE T IMAGE PROCESS, V29, P5677, DOI 10.1109/TIP.2020.2984854
   Zheng YF, 2019, IEEE SIGNAL PROC LET, V26, P29, DOI 10.1109/LSP.2018.2825959
   Zhong FJ, 2021, NEUROCOMPUTING, V423, P327, DOI 10.1016/j.neucom.2020.11.003
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou JT, 2018, AAAI CONF ARTIF INTE, P4588
NR 68
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14565
EP 14607
DI 10.1007/s11042-023-15911-y
EA JUL 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200008
DA 2024-07-18
ER

PT J
AU Naik, D
   Jaidhar, CD
AF Naik, Dinesh
   Jaidhar, C. D.
TI Video Captioning using Sentence Vector-enabled Convolutional Framework
   with Short-Connected LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Context vector; CNN; LSTM; Multi-head attention; Video
   captioning
ID IMAGE
AB The principal objective of video/image captioning is to portray the dynamics of a video clip in plain natural language. Captioning is motivated by its ability to make the video more accessible to deaf and hard-of-hearing individuals, to help people focus on and recall information more readily, and to watch it in sound-sensitive locations. The most frequently utilized design paradigm is the revolutionary structurally improved encoder-decoder configuration. Recent developments emphasize the utilization of various creative structural modifications to maximize efficiency while demonstrating their viability in real-world applications. The utilization of well-known and well-researched technological advancements such as deep Convolutional Neural Networks (CNNs) and Sentence Transformers are trending in encoder-decoders. This paper proposes an approach for efficiently captioning videos using CNN and a short-connected LSTM-based encoder-decoder model blended with a sentence context vector. This sentence context vector emphasizes the relationship between the video and text spaces. Inspired by the human visual system, the attention mechanism is utilized to selectively concentrate on the context of the important frames. Also, a contextual hybrid embedding block is presented for connecting the two vector spaces generated during the encoding and decoding stages. The proposed architecture is investigated through well-known CNN architectures and various word embeddings. It is assessed using two benchmark video captioning datasets, MSVD and MSR-VTT, considering standard evaluation metrics such as BLEU, METEOR, ROUGH, and CIDEr. In accordance with experimental exploration, when the proposed model with NASNet-large alone is viewed across all three embeddings, the BERT findings on MSVD Dataset performed better than the results obtained with the other two embeddings. Inception-v4 outperformed VGG-16, ResNet-152, and NASNet-Large for feature extraction. Considering word embedding initiatives, BERT is far superior to ELMo and GloVe based on the MSR-VTT dataset.
C1 [Naik, Dinesh; Jaidhar, C. D.] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Naik, D (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
EM din_nk@nitk.edu.in; jaidharcd@nitk.edu.in
RI Naik, Dinesh/Z-4739-2019
OI Naik, Dinesh/0000-0002-8989-6282
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Amirian S, 2020, IEEE ACCESS, V8, P218386, DOI 10.1109/ACCESS.2020.3042484
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Cao PF, 2019, NEURAL PROCESS LETT, V50, P103, DOI 10.1007/s11063-018-09973-5
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen TM, 2019, LECT NOTES COMPUT SC, V11809, P105, DOI 10.1007/978-3-030-33982-1_9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Hao X, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1290, DOI [10.1109/itnec48623.2020.9084781, 10.1109/ITNEC48623.2020.9084781]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hemalatha M, 2020, IEEE WINT CONF APPL, P1576, DOI [10.1109/WACV45572.2020.9093344, 10.1109/wacv45572.2020.9093344]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jin-Cheng Lin, 2021, 2021 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC), P470, DOI 10.1109/SPAC53836.2021.9539903
   Kumar Krishan, 2022, IETE Journal of Education, P78, DOI 10.1080/09747338.2022.2044396
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Nabati M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102302
   Nabati M, 2020, COMPUT VIS IMAGE UND, V190, DOI 10.1016/j.cviu.2019.102840
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Data Science and Its Applications, P63
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Sah S, 2020, PATTERN ANAL APPL, V23, P147, DOI 10.1007/s10044-018-00770-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Su YS, 2021, NEURAL PROCESS LETT, V53, P4159, DOI 10.1007/s11063-021-10588-6
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vedantam R., 2014, ARXIV14115726
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vision OOSC, OPENCV OBJ DET
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wei R, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102751
   Xu J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124312
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu N, 2018, IEEE INTERNET THINGS, V5, P3419, DOI 10.1109/JIOT.2017.2779865
   Yadav N, 2021, 6 INT C CONVERGENCE, P1
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang Y, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104887
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang ZW, 2021, IEEE T MULTIMEDIA, V23, P1799, DOI 10.1109/TMM.2020.3003592
   Zheng Q., 2020, 2020 CVPR, P13093, DOI 10.1109/CVPR42600.2020.01311
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 52
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11187
EP 11213
DI 10.1007/s11042-023-15978-7
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900010
DA 2024-07-18
ER

PT J
AU Rautela, K
   Sharma, D
   Kumar, V
   Kumar, D
AF Rautela, Kamakshi
   Sharma, Dhruv
   Kumar, Vijay
   Kumar, Dinesh
TI Obscenity detection transformer for detecting inappropriate contents
   from videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transformer; Obscenity Detection; Pornography Detection; Deep-Learning;
   Obscenity Detection Transformer (ODT)
ID PORNOGRAPHY; REPRESENTATION; CLASSIFICATION; RECOGNITION; ATTENTION
AB With the availability of a wide range of images and videos on the Internet, classification and detection of inappropriate content has become a matter of serious concern. This type of content has a harmful impact on the minds of minors as well as on adults. Therefore, it is necessary to control and detect such content from images and videos. Recent research has focused on deep-learning-based automated pornographic detection, a bold move to replace humans in the time-consuming task of moderating online content. This paper is based on the idea that incorporating detailed information into a model helps solve the problem of mapping pornographic content. In this paper, a novel deep-learning transformer-based framework namely, Obscenity Detection Transformer (ODT) is proposed to detect and classify inappropriate or pornographic content from videos. The proposed transformer inputs video frames and leverages the vision transformer with the LSTM layer. LSTM embedding enables the network to extract more informative features. Also, GELU activation-based MLP is employed to classify pornographic and non-pornographic content. The advantage of leveraging transformer-based architecture is that these architectures improve efficiency and accuracy when compared with CNN-based models. To validate the efficiency and efficacy of the proposed model, extensive experiments are carried out on Pornography-2 k and Pornography-800 datasets. The proposed model outperforms the current state-of-the-art (CNN) in terms of computational efficiency and accuracy. The accuracies achieved for the two aforementioned datasets are 99.6% and 98.8%, respectively.
C1 [Rautela, Kamakshi; Sharma, Dhruv; Kumar, Dinesh] Delhi Technol Univ, Delhi, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Jalandhar, India.
C3 Delhi Technological University; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar
RP Kumar, V (corresponding author), Dr BR Ambedkar Natl Inst Technol, Jalandhar, India.
EM rautelakamakshi11@gmail.com; dhruv.0906@yahoo.in;
   vijaykumarchahar@gmail.com; dineshkumar@dtu.ac.in
RI Kumar, Dr Ashwani/GWZ-1380-2022; Kumar, Dinesh/AAA-7914-2021; Chahar,
   Vijay Kumar/A-2782-2015
OI Kumar, Dr Ashwani/0000-0001-9316-3236; Kumar,
   Dinesh/0000-0003-3485-6408; Sharma, Dhruv/0000-0001-9218-2515; Chahar,
   Vijay Kumar/0000-0002-3460-6989
CR Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Bhatt R, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/7359210
   Bouirouga Hajar, 2012, Journal of Theoretical and Applied Information Technology, V35, P7
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Chen JR, 2020, IEEE ACCESS, V8, P122709, DOI 10.1109/ACCESS.2020.2988736
   Farrelly B, 2017, C LOCAL COMPUT NETW, P518, DOI 10.1109/LCN.2017.119
   Fleck M M, 1996, P EUR C COMP VIS, P593, DOI DOI 10.1007/3-540-61123-1_173
   Forsyth DA, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P103, DOI 10.1109/ACV.1996.572010
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Gangwar A, 2021, NEUROCOMPUTING, V445, P81, DOI 10.1016/j.neucom.2021.02.056
   Gautam N, 2023, IEEE T COGN DEV SYST, V15, P310, DOI 10.1109/TCDS.2022.3158613
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Huang C, 2020, VIOLATION DETECTION, DOI [10.1155/2020/1895341, DOI 10.1155/2020/1895341]
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Lee S, 2009, IEEE T CONSUM ELECTR, V55, P677, DOI 10.1109/TCE.2009.5174439
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Moustafa M, 2015, ARXIV
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Quadra A, 2017, EFFECTS PORNOGRAPHY
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Samal S, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13230
   Samal S, 2023, MULTIMED TOOLS APPL, V82, P28739, DOI 10.1007/s11042-023-14437-7
   Song YD, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P489, DOI 10.1145/3341161.3342940
   Varges Silva Murilo, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P547, DOI 10.1007/978-3-030-13469-3_64
   Wang LY, 2020, PATTERN RECOGN LETT, V140, P150, DOI 10.1016/j.patrec.2020.09.027
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Wong C, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00661-8
   Yousaf K, 2022, IEEE ACCESS, V10, P16283, DOI 10.1109/ACCESS.2022.3147519
   Yu R, 2019, PROCEEDINGS OF THE 3RD NETWORK TRAFFIC MEASUREMENT AND ANALYSIS CONFERENCE (TMA 2019), P49, DOI [10.23919/tma.2019.8784688, 10.23919/TMA.2019.8784688]
   Zheng H., 2004, Electronic Letters on Computer Vision and Image Analysis, V4, P1
NR 31
TC 1
Z9 1
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10799
EP 10814
DI 10.1007/s11042-023-16078-2
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000001
DA 2024-07-18
ER

PT J
AU Suji, RJ
   Godfrey, WW
   Dhar, J
AF Suji, R. Jenkin
   Godfrey, W. Wilfred
   Dhar, Joydip
TI Exploring pretrained encoders for lung nodule segmentation task using
   LIDC-IDRI dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nodule segmentation; Deep learning; CAD
AB Deep learning has become ubiquitous in the field of computer vision for tasks such as image classification and segmentation. A Computer-Aided Diagnostic (CAD) system for lung cancer detection and diagnosis works by identifying lung nodules and characterizing the same. Transfer learning allows for pre-trained weights to be ported from one model to another. Replacement of pre-trained encoders in encoder-decoder networks opens up the number of possibilities of such networks and motivates us to check the possibility of each combination for a segmentation task of interest. This paper reports the experiments carried out using such combinations and presents the various observations as a result of the experiments for the nodule segmentation task on the LIDC-IDRI dataset. This work also examines the effect of network parameters on some of the deep learning semantic segmentation architectures in the context of the lung cancer dataset, LIDC-IDRI. The efficient network architecture, based on observations, is determined to be UNet with the backbone architecture, Efficientnet-b3 trained on the ImageNet dataset. This specific network presents an IoU score of 0.59 on the training dataset and 0.45 on the validation dataset. The architectures were compared and analyzed in terms of the time and space taken as well.
C1 [Suji, R. Jenkin; Godfrey, W. Wilfred; Dhar, Joydip] ABV IIITM, Gwalior, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Suji, RJ (corresponding author), ABV IIITM, Gwalior, India.
EM sujijenkin@gmail.com
RI Dhar, Joydip/L-6769-2013
FU Kiran Division, Department of Science and Technology, Govt. of India
   [SR/WOSA/ET-153/2017]
FX & nbsp;The authors would like to acknowledge the Kiran Division,
   Department of Science and Technology, Govt. of India, for funding this
   research work through the SR/WOSA/ET-153/2017 Research Grant. The
   authors also thank the anonymous reviewers for their encouraging reviews
   and recommendations.
CR Abedalla Ayat, 2021, PeerJ Comput Sci, V7, pe607, DOI 10.7717/peerj-cs.607
   Ali Z, 2022, J SUPERCOMPUT, V78, P1602, DOI 10.1007/s11227-021-03845-x
   Banu SF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110132
   Bianconi F, 2021, QUANT IMAG MED SURG, V11, P3286, DOI 10.21037/qims-20-1356
   Bizopoulos P, 2020, PREPRINT
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dhalla Sabrina, 2023, Procedia Computer Science, P328, DOI 10.1016/j.procs.2023.01.015
   Fernandez K, 2019, HEALTHC TECHNOL LETT, V6, P271, DOI 10.1049/htl.2019.0086
   Fernandez-Moral E, 2018, IEEE INT VEH SYM, P1051, DOI 10.1109/IVS.2018.8500497
   Banu SF, 2021, FRONT ARTIF INTEL AP, V339, P349, DOI 10.3233/FAIA210154
   Hammad M, 2022, MULTIMEDIA SYST, V28, P1373, DOI 10.1007/s00530-020-00728-8
   Handani Sitaresmi Wahyu, 2021, 2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE), P109, DOI 10.1109/ICITISEE53823.2021.9655879
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intisar Rizwan I. Haque, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2020.100297
   Jiao RH, 2021, IEEE T NETW SERV MAN, V18, P4019, DOI 10.1109/TNSM.2021.3110577
   Lalitha S, 2021, J INTELL FUZZY SYST, V40, P6355, DOI 10.3233/JIFS-189476
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loverdos K, 2019, ANN THORAC MED, V14, P226, DOI 10.4103/atm.ATM_110_19
   Martin C. H., 2019, ARXIV190108278
   Micikevicius M, 2023, THESIS VILNIAUS U
   Nagarkar H, 2020, EVALUATING MACHINE L
   Parmar V, 2020, PREPRINT
   Rajalakshmi TS., 2023, INT J ENG MANAG RES, V13, P40, DOI [10.31033/ijemr.13.1.5, DOI 10.31033/IJEMR.13.1.5]
   Rajesh MN., 2022, INT J ENG TRENDS TEC, V70, P252
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shariaty Faridoddin, 2019, Informatics in Medicine Unlocked, V15, P161, DOI 10.1016/j.imu.2019.100173
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singadkar G, 2020, J DIGIT IMAGING, V33, P678, DOI 10.1007/s10278-019-00301-4
   Singh A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102666
   Suji RJ, 2021, 2021 5 C INFORM COMM, P1, DOI DOI 10.1109/INCET51464.2021.9456110
   Sukegawa S, 2021, BIOMOLECULES, V11, DOI 10.3390/biom11060815
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang S, 2017, IEEE ENG MED BIO, P1752, DOI 10.1109/EMBC.2017.8037182
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Wang Z, 2021, Pattern Recogn, Patent No. 08023
   Zhang Y., 2021, PREPRINT
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 43
TC 0
Z9 0
U1 8
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9685
EP 9708
DI 10.1007/s11042-023-15871-3
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000003
DA 2024-07-18
ER

PT J
AU O'Brien, B
   Meunier, C
   Tomashenko, N
   Ghio, A
   Bonastre, JF
AF O'Brien, Benjamin
   Meunier, Christine
   Tomashenko, Natalia
   Ghio, Alain
   Bonastre, Jean-Francois
TI Evaluating the effects of task design on unfamiliar Francophone listener
   and automatic speaker identification performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice similarity; Perceptual speaker identification; Task design;
   Automatic speaker verification
ID SHORT UTTERANCES; SPEECH; DISCRIMINATION; RECOGNITION; EARWITNESSES;
   FAMILIAR; ACCENT
AB Many questions remain with regards to how context affects perceptual and automatic speaker identification performance. To examine the effects of task design on perceptual speaker identification performance, three tasks were developed, including lineup and binary tasks, as well as a novel clustering task. Speech recordings of native French speakers were compared similarly across tasks evaluated by unfamiliar Francophone listeners. True positive (sensitivity) and true negative (specificity) response rates across tasks were measured. Our results showed participants had similar sensitivity and specificity for binary (88%) and clustering (84%) tasks, but random selection rates for the lineup task. Pearson correlation procedures were used to evaluate the efficiency of scores produced by a state-of-the-art automatic speaker verification to model perceptual responses (equal error rate = 89%). Automatic scores modelled lineup (r(2) = 0.6) and clustering (r(2) = 0.5) task accuracy quite well, however, they were less robust when modelling binary task responses (r(2) = -0.2). The results underscore the role task design plays in shaping perceptual responses, which, in turn, affects the modelling effectiveness of automatic scores. As evidence points to humans and algorithms modelling speakers differently, our findings suggest automatic speaker identification performance might be improved with a greater understanding on how context shapes perceptual responses.
C1 [O'Brien, Benjamin; Tomashenko, Natalia; Bonastre, Jean-Francois] Avignon Univ, Lab Informat Avignon, EA 4128, Avignon, France.
   [O'Brien, Benjamin; Meunier, Christine; Ghio, Alain] Aix Marseille Univ, CNRS, UMR 7309, LPL, Aix En Provence, France.
C3 Avignon Universite; Centre National de la Recherche Scientifique (CNRS);
   CNRS - Institute for Humanities & Social Sciences (INSHS); Aix-Marseille
   Universite
RP O'Brien, B (corresponding author), Avignon Univ, Lab Informat Avignon, EA 4128, Avignon, France.; O'Brien, B (corresponding author), Aix Marseille Univ, CNRS, UMR 7309, LPL, Aix En Provence, France.
EM benjamin.o-brien@univ-avignon.fr
RI Tomashenko, Natalia/KBQ-9775-2024; O'Brien, Benjamin/AAW-5522-2020
OI O'Brien, Benjamin/0000-0002-1255-8410
FU French National Research Agency (ANR) [ANR-17-CE39-0016]; Agence
   Nationale de la Recherche (ANR) [ANR-17-CE39-0016] Funding Source:
   Agence Nationale de la Recherche (ANR)
FX AcknowledgmentsThis work was funded by the French National Research
   Agency (ANR) under the VoxCrim project (ANR-17-CE39-0016).
CR Andre C, 2007, INT C PHON SCI, P1421
   Audibert N, 2010, P NIST HASR 2010
   Baumann O, 2010, PSYCHOL RES-PSYCH FO, V74, P110, DOI 10.1007/s00426-008-0185-z
   Ben Amor I, 2022, I W BIOMETRIC FORENS, DOI 10.1109/IWBF55382.2022.9794542
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   BRICKER PD, 1966, J ACOUST SOC AM, V40, P1441, DOI 10.1121/1.1910246
   Chanclu A, 2020, 6E C CON JOURN ET PA, P73
   Chung JS, 2018, INTERSPEECH, P1086
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Dellwo V, 2006, SPEECH PROSODY
   Dufour S, 2007, J ACOUST SOC AM, V121, pEL131, DOI 10.1121/1.2710742
   Fleming D, 2014, P NATL ACAD SCI USA, V111, P13795, DOI 10.1073/pnas.1401383111
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Gerlach L, 2020, SPEECH COMMUN, V124, P85, DOI 10.1016/j.specom.2020.08.003
   Greenberg C, 2010, P SPEAK LANG REC WOR, P32
   Hautamäki V, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1473
   Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531
   Jenson D, 2021, NEUROPSYCHOLOGIA, V159, DOI 10.1016/j.neuropsychologia.2021.107947
   Johnson J, 2020, Q J EXP PSYCHOL, V73, P1537, DOI 10.1177/1747021820938659
   Jong G D, 2015, ICPHS
   Kahn J, 2011, INT CONF ACOUST SPEE, P5912
   Kelly F, 2016, INTERSPEECH
   Kerstholt JH, 2006, APPL COGNITIVE PSYCH, V20, P187, DOI 10.1002/acp.1175
   Kreiman Jody, 2011, Foundations of voice studies: An interdisciplinary approach to voice production and perception, DOI DOI 10.1002/9781444395068
   LaRiviere, 1971, P 7 INT C PHONETIC S, P558
   Lavan N., 2018, BRIT J PSYCHOL, V0, P110
   Lavan N, 2021, COGNITION, V215, DOI 10.1016/j.cognition.2021.104780
   Lavner Y, 2000, SPEECH COMMUN, V30, P9, DOI 10.1016/S0167-6393(99)00028-X
   Levi S, 2013, J SPEECH LANG HEAR R, DOI [10.1044/1092-4388(2012/12-0095, DOI 10.1044/1092-4388(2012/12-0095]
   Levi SV, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1483
   Lindh J, 2010, P FONETIK 2010, P63
   Lindh J, 2009, P FONETIK 2009 22 SW, P186
   M?hl C., 2017, BEHAV RES METHODS, V50, P1
   Mathias Samuel R, 2014, Front Biosci (Schol Ed), V6, P92
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McDougall K, 2015, PHONETICA, V72, P257, DOI 10.1159/000439385
   Mendoza E, 1996, J VOICE, V10, P59, DOI 10.1016/S0892-1997(96)80019-1
   Meunier C, 2018, ACTES 32 JOURNEES DE, P469, DOI [10.21437/JEP.2018-54, DOI 10.21437/JEP.2018-54]
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Naika R, 2018, OVERVIEW AUTOMATIC S
   Nolan F., 2011, P 17 ICPHS, P1506, DOI DOI 10.1016/S0926-6410(03)00079-X
   Nolan F., 2013, INT J SPEECH LANG LA, V0, P20
   O'Brien B, 2021, INTERSPEECH, P4623, DOI 10.21437/Interspeech.2021-1211
   OBrien B, 2022, DISCRIMINATING SPEAK, P97, DOI [10.17469/O2108AISV000005, DOI 10.17469/O2108AISV000005]
   OBrien B, 2021, INTERSPEECH, P3580, DOI 10.21437/Interspeech.2021-1588
   Öhman L, 2010, EUR J PSYCHOL APPL L, V2, P161
   Park SJ, 2018, J ACOUST SOC AM, V144, P375, DOI 10.1121/1.5045323
   Perrachione T. K., 2017, Speaker recognition across languages
   Poddar A, 2018, IET BIOMETRICS, V7, P91, DOI 10.1049/iet-bmt.2017.0065
   POLLACK I, 1954, J ACOUST SOC AM, V26, P403, DOI 10.1121/1.1907349
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Quené H, 2007, J PHONETICS, V35, P353, DOI 10.1016/j.wocn.2006.09.001
   Ramos D, 2011, INT CONF ACOUST SPEE, P5908
   Rietveld A C M, 1991, P 12 INT C PHON SCI, P46
   ROEBUCK R, 1993, APPL COGNITIVE PSYCH, V7, P475, DOI 10.1002/acp.2350070603
   Schwartz R, 2011, INT CONF ACOUST SPEE, P5904
   Schweinberger SR, 2014, WIRES COGN SCI, V5, P15, DOI 10.1002/wcs.1261
   Singh N., 2017, GLOB J ENTERP INF SY, V9, P38
   Smith HMJ, 2023, MEMORY, V31, P147, DOI 10.1080/09658211.2022.2129065
   Smith HMJ, 2020, MEMORY, V28, P2, DOI 10.1080/09658211.2019.1673427
   Snyder David, 2018, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   Stevenage SV, 2020, Q J EXP PSYCHOL, V73, P519, DOI 10.1177/1747021819888064
   Stevenage SV, 2018, NEUROPSYCHOLOGIA, V116, P162, DOI 10.1016/j.neuropsychologia.2017.07.005
   SUSSMAN JE, 1991, J SPEECH HEAR RES, V34, P671, DOI 10.1044/jshr.3403.671
   Titze I.R., 2000, Principles of Voice Production, P245
   Tomashenko N, ARXIV, DOI DOI 10.48550/ARXIV.2205.07123
   Tomashenko N, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101362
   VANLANCKER D, 1987, NEUROPSYCHOLOGIA, V25, P829, DOI 10.1016/0028-3932(87)90120-5
   Venezia JH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00157
   Whiteside SP, 1998, PERCEPT MOTOR SKILL, V86, P579, DOI 10.2466/pms.1998.86.2.579
   WU K, 1991, J ACOUST SOC AM, V90, P1828, DOI 10.1121/1.401663
   Yarmey AD, 2003, FORENSIC LINGUIST, V10, P62, DOI 10.1558/sll.2003.10.1.62
   Zetterholm E, 2004, COMP HUMAN PERCEPTIO
NR 75
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10615
EP 10635
DI 10.1007/s11042-023-15391-0
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500003
OA Green Published
DA 2024-07-18
ER

PT J
AU Seyfari, Y
   Meimandi, A
AF Seyfari, Yousef
   Meimandi, Akbar
TI A new approach to android malware detection using fuzzy logic-based
   simulated annealing and feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android malware detection; Adaptive neighborhood; Simulated annealing;
   Fuzzy logic; Machine learning; Feature selection
AB The use of smartphones with the Android operating system has been high in the last decade, with the transformation of works and services from traditional shape to mechanized and digitally, the percentage of use of smart devices will remain high. In such a situation, malware with malicious purposes will appear among the useful applications that will create insecure conditions for users of smart devices with the Android operating system. In this regard, to deal with malware and to improve malware detection, the simulated annealing algorithm has been used in the feature selection stage along with fuzzy logic in the neighbor generation stage to detect Android malware through machine learning algorithms. The proposed method has been tested in ten feature sets with 410 samples from the DREBIN dataset, 328 of which are benign apps and the rest are malware. The experimental results of this study show that the best result in feature selection with the proposed method with the KNN classifier and the set of permission features, with the number of features 1908, has been achieved 99.02% in the accuracy criterion. The results of the paper are better than many recent studies results are done.
C1 [Seyfari, Yousef] Univ Maragheh, Fac Engn, Maragheh, Iran.
C3 University of Maragheh
RP Seyfari, Y (corresponding author), Univ Maragheh, Fac Engn, Maragheh, Iran.
EM seyfari@maragheh.ac.ir; meimandi.akbar@yahoo.com
RI Meimandi, Akbar/AEE-7899-2022
OI Meimandi, Akbar/0000-0001-8324-4606
CR Ali W, 2019, INT J COMPUT SCI NET, V19, P15
   Allix K, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P468, DOI [10.1145/2901739.2903508, 10.1109/MSR.2016.056]
   android, PERM ANDR
   android, PLATF ARCH
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Bolón-Canedo V, 2016, PROG ARTIF INTELL, V5, P65, DOI 10.1007/s13748-015-0080-y
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Firdaus A, 2018, FRONT INFORM TECH EL, V19, P712, DOI 10.1631/FITEE.1601491
   Jadhav S. D., 2016, Int. J. Sci. Res, V5, P1842, DOI DOI 10.21275/V5I1.NOV153131
   Jhansi K. Santosh, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P795, DOI 10.1109/ICOEI48184.2020.9142929
   Karbab EB, 2021, ANDROID MALWARE DETE
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Laarhoven P. J. M., 1987, Simulated Annealing, DOI [10.1007/978-94-015-7744-1, DOI 10.1007/978-94-015-7744-1_2]
   Lalaoui M, 2018, P INT C LEARNING OPT, P1, DOI [10.1145/3230905.3230963, DOI 10.1145/3230905.3230963.Z]
   Lalaoui M, 2016, INT CONF MULTIMED, P558, DOI 10.1109/ICMCS.2016.7905557
   Mat SRT, 2022, ICT EXPRESS, V8, P424, DOI [10.1016/j.icte.2021.09.003, 10.1016/j.icte.2021.09.007]
   McDonald J. T., 2021, P 54 HAW INT C SYST, P6976, DOI DOI 10.24251/HICSS.2021.839
   Meike GB, 2021, INSIDE ANDROID OS BU
   Meimandi A, 2020, P 2020 IEEE 5 C TECH
   Moradi P, 2016, APPL SOFT COMPUT, V43, P117, DOI 10.1016/j.asoc.2016.01.044
   Posario F., 2016, INT J COMPUT TECHNOL, V15, P6471, DOI [10.24297/ijct.v15i2.565, DOI 10.24297/IJCT.V15I2.565]
   Sahin DÖ, 2023, NEURAL COMPUT APPL, V35, P4903, DOI 10.1007/s00521-021-05875-1
   securelist, 2021, IT THREAT EV Q2
   Suthaharan S., 2016, Integr Ser Inf Syst, V36, P1
   Tam K, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3017427
   Thangavelooa R., 2020, ENG INF TECHNOL, V10, P536, DOI [10.18517/ijaseit.10.2.10238, DOI 10.18517/IJASEIT.10.2.10238]
   Wen L, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992953
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yildiz O, 2019, INT J SOFTW ENG KNOW, V29, P245, DOI 10.1142/S0218194019500116
NR 29
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10525
EP 10549
DI 10.1007/s11042-023-16035-z
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500002
DA 2024-07-18
ER

PT J
AU Talaat, FM
   Gamel, SA
AF Talaat, Fatma M. M.
   Gamel, Samah A. A.
TI Machine learning in detection and classification of leukemia using
   C-NMC_Leukemia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Leukemia detection; C-NMC_Leukemia; Optimized CNN
   (OCNN)
ID BIG DATA; DIAGNOSIS
AB A significant issue in the field of illness diagnostics is the early detection and diagnosis of leukemia, that is, the accurate distinction of malignant leukocytes with minimal costs in the early stages of the disease. Flow cytometer equipment is few, and the methods used at laboratory diagnostic centers are laborious despite the high prevalence of leukemia. The present systematic review was carried out to review the works intending to identify and categories leukemia by utilizing machine learning. It was motivated by the potential of machine learning (machine learning (ML)) in disease diagnosis. Leukemia is a blood-forming tissues cancer that affects the bone marrow and lymphatic system. It can be treated more effectively if it is detected early. This work developed a new classification model for blood microscopic pictures that distinguishes between leukemia-free and leukemia-affected images. The general proposed method in this paper consists of three main steps which are: (i) Image_Preprocessing, (ii) Feature Extraction, and (iii) Classification. An optimized CNN (OCNN) is used for classification. OCNN is utilized to detect and classify the photo as "normal" or "abnormal". Fuzzy optimization is used to optimize the hyperparameters of CNN. It is a quite beneficial to use fuzzy logic in the optimization of CNN. As illustrated from results it is shown that, with the using of OCNN classifier and after the optimization of the hyperparameters of the CNN, it achieved the best results due to the enhancement of the performance of the CNN. The OCNN has achieved 99.99% accuracy with C-NMC_Leukemia dataset.
C1 [Talaat, Fatma M. M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
   [Gamel, Samah A. A.] Horus Univ, Fac Engn, Dumyat, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University
RP Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
EM fatma.nada@ai.kfs.edu.eg; sgamel@horus.edu.eg
RI M. Talaat, Fatma/IYS-7614-2023; Adel Gamel, Samah/AAZ-9335-2021
OI Adel Gamel, Samah/0000-0003-1753-030X; M. Talaat,
   Fatma/0000-0001-6116-2191
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB)
CR Alshathri S, 2022, CMC-COMPUT MATER CON, V73, P5863, DOI 10.32604/cmc.2022.026547
   [Anonymous], 2018, HEM TAS FACTS STAT
   [Anonymous], 2020, CLASS BLASTS AC LEUK
   [Anonymous], 2020, CHILDHOOD LEUKEMIAS, DOI [10.1056/NEJM199506153322407, DOI 10.1056/NEJM199506153322407]
   Ansari S, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020322
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Ehrenstein V, 2017, CLIN EPIDEMIOL, V9, P245, DOI 10.2147/CLEP.S129779
   El-Rashidy N, 2023, NEURAL COMPUT APPL, V35, P7423, DOI 10.1007/s00521-022-08007-5
   El-Rashidy N, 2022, SOFT COMPUT, V26, P11435, DOI 10.1007/s00500-022-07420-1
   Faivdullah L, 2015, J Med Bioeng, V4, P488, DOI [10.12720/jomb.4.6.488-491, DOI 10.12720/JOMB.4.6.488-491]
   Ghaderzadeh M., 2013, Applied Medical Informatics, V33, P45
   Hanaa S., 2022, Bioengineering, V10, P18, DOI [10.3390/bioengineering10010018, DOI 10.3390/BIOENGINEERING10010018]
   Hassan E, 2022, Review: Mask R-CNN Models, DOI [10.21608/njccs.2022.280047, DOI 10.21608/NJCCS.2022.280047]
   Hegde RB, 2020, J DIGIT IMAGING, V33, P361, DOI 10.1007/s10278-019-00288-y
   Hsu CY, 2021, MULTIMED TOOLS APPL, V80, P29643, DOI 10.1007/s11042-021-11100-x
   Kumar N, 2022, ENG TECHNOL APPL SCI, V12, P7993, DOI 10.48084/etasr.4613
   Kumar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9983652
   Kumar S., 2018, Advances in Computer and Computational Sciences, P655
   Kumari N, 2021, INT J CIRC THEOR APP, V49, P2812, DOI 10.1002/cta.3020
   Laosai J, 2014, 2014 INTERNATIONAL ELECTRICAL ENGINEERING CONGRESS (IEECON)
   Madhukar M, 2012, IEEE SYS MAN CYBERN, P433, DOI 10.1109/ICSMC.2012.6377762
   Maria IJ, 2020, INT J SCI TECHNOL RE, V9
   de Oliveira JEM, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P685, DOI 10.5220/0010257406850692
   Namayandeh Seyedeh Mahdieh, 2020, Asian Pac J Cancer Prev, V21, P1487, DOI 10.31557/APJCP.2020.21.5.1487
   Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Pan Y, 2019, LECT NOTES BIOENG
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Prellberg J, 2020, ARXIV
   PUI CH, 1995, NEW ENGL J MED, V332, P1618, DOI 10.1056/NEJM199506153322407
   Reader TW, 2009, CRIT CARE MED, V37, P1787, DOI 10.1097/CCM.0b013e31819f0451
   Setiawan Andika, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P45, DOI 10.1109/ICOIACT.2018.8350822
   Talaat Fatma M., 2023, Journal of Ambient Intelligence and Humanized Computing, P8499, DOI 10.1007/s12652-022-03882-1
   Talaat FM, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03788-y
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2022, KNOWL INF SYST, V64, P773, DOI 10.1007/s10115-021-01649-2
   Talaat FM, 2020, CLUSTER COMPUT, V23, P3309, DOI 10.1007/s10586-020-03089-z
   Talaat FM, 2020, J AMB INTEL HUM COMP, V11, P4951, DOI 10.1007/s12652-020-01768-8
   Talaat FM, 2022, MULTIMED TOOLS APPL, P1
   Vogado LHS, 2017, SIBGRAPI, P367, DOI 10.1109/SIBGRAPI.2017.55
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wolach O, 2017, CURR OPIN HEMATOL, V24, P139, DOI 10.1097/MOH.0000000000000322
   Xing Fuyong, 2016, IEEE Rev Biomed Eng, V9, P234, DOI 10.1109/RBME.2016.2515127
   Yu W, 2017, INT CONF ASIC, P1041, DOI 10.1109/ASICON.2017.8252657
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
NR 45
TC 3
Z9 3
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8063
EP 8076
DI 10.1007/s11042-023-15923-8
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004893200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, XB
AF Zhang, Xiaobo
TI A modified non-local means using bilateral thresholding for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Non-local means (NLM); Statistical nearest neighbors
   distance measurement (SNNDM); Bilateral thresholding; Gradient domain
   filter
AB In non-local means (NLM) method, weight of each pixel in the neighbor centered on the reference noisy pixel plays a different role for performance of NLM for image denoising. The reference noisy pixel is called center pixel. Usually, weight of each pixel including center pixel in the neighbor (neighbor pixel) is computed based on the distance between neighbor pixel and center pixel. This paper proposes a novel weight by studying the recent statistical nearest neighbors distance measurement (SNNDM) and gradient domain filter. The difference of each neighbor pixel including center pixel is considered sufficiently. The proposed weight is called the bilateral thresholding since it is similar to bilateral filtering in form. Test results show that the proposed method can deal with each neighbor pixel differently so that the desired performance is achieved.
C1 [Zhang, Xiaobo] Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
C3 Xianyang Normal University
RP Zhang, XB (corresponding author), Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
EM zhangxiaobo419@126.com
FU National Natural Science Foundation of China [61401383]; Basic Research
   Plan of Natural Science in Shaanxi Province [2021JM-518]; Qinglan Talent
   Program of Xianyang Normal University [XSYQL201503]
FX AcknowledgmentsThis work is partially supported by National Natural
   Science Foundation of China (Grant No. 61401383), Basic Research Plan of
   Natural Science in Shaanxi Province (Grant No. 2021JM-518) and Qinglan
   Talent Program of Xianyang Normal University (Grant No. XSYQL201503).
CR [Anonymous], 2008, NONLOCAL MEANS FILTE
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   de la Rosa JI, 2018, MULTIMED TOOLS APPL, V77, P1205, DOI 10.1007/s11042-016-4322-1
   Fedorov V, 2017, IEEE T IMAGE PROCESS, V26, P2137, DOI 10.1109/TIP.2017.2681421
   Foi A, 2016, INT J COMPUT VISION, V120, P78, DOI 10.1007/s11263-016-0898-1
   Ghosh S, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023026
   Goossens B., 2008, 2008 International Workshop on Local and Non-Local Approximation in Image Processing, P143
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Kumain SC, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P243, DOI 10.1109/ICSCCC.2018.8703305
   Kumar S, 2022, MULTIMED TOOLS APPL, V81, P31075, DOI 10.1007/s11042-022-12701-w
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Li XY, 2020, IEEE T IMAGE PROCESS, V29, P157, DOI 10.1109/TIP.2019.2928644
   Nguyen MP, 2017, IEEE T IMAGE PROCESS, V26, P1637, DOI 10.1109/TIP.2017.2658941
   Hue NM, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P370, DOI [10.1109/nics48868.2019.9023801, 10.1109/NICS48868.2019.9023801]
   Ou Y, 2022, SIGNAL PROCESS, V200, DOI 10.1016/j.sigpro.2022.108650
   Rosin I, 2019, IEEE T IMAGE PROCESS, V28, P723, DOI 10.1109/TIP.2018.2869685
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Thanh DNH, 2020, SIGNAL IMAGE VIDEO P, V14, P1189, DOI 10.1007/s11760-020-01657-9
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Vignesh R, 2010, IEEE SIGNAL PROC LET, V17, P277, DOI 10.1109/LSP.2009.2038956
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2022, IEEE T GEOSCI REMOTE, V15, P9293
   Wu Y, 2022, JAMES STEIN TYPE CTR
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
   Zhan Y, 2019, IEEE ACCESS, V7, P130246, DOI 10.1109/ACCESS.2019.2937966
   Zhang XB, 2022, MULTIDIM SYST SIGN P, V33, P341, DOI 10.1007/s11045-021-00802-y
   Zhang XB, 2021, OPTIK, V244, DOI 10.1016/j.ijleo.2021.167557
   Zhang XB, 2021, MULTIMED TOOLS APPL, V80, P29745, DOI 10.1007/s11042-021-11184-5
   Zhang XB, 2015, MULTIMED TOOLS APPL, V74, P10495, DOI 10.1007/s11042-014-2182-0
NR 31
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7395
EP 7416
DI 10.1007/s11042-023-15928-3
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003484200001
DA 2024-07-18
ER

PT J
AU Sakrani, K
   Elghoul, S
   Ghorbel, F
AF Sakrani, Khaoula
   Elghoul, Sinda
   Ghorbel, Faouzi
TI Optimized multi-scale affine shape registration based on an unsupervised
   Bayesian classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affine transformations; A normalised affine arc-length parametrization;
   ACM Algorithm; Multi-scale registrations; Multiclass Expectation
   Maximisation (Multiclass-EM); Unsupervised bayesian classification
ID CURVATURE SCALE-SPACE; INVARIANT DESCRIPTOR; NONRIGID SHAPES;
   RECOGNITION; REPRESENTATION; DISTANCE; SIGNATURE; ROTATION
AB Here, we intend to introduce an efficient, robust curve alignment algorithm with respect to the group of special affine transformations of the plane denoted by SA(2,R). Such a group of transformations is known to be well model the pose of 3D scene when objects are far from the visual sensor relatively to their seizes. Its numerical robustness lies in its multi-scale approach and its precision comes from the automatic and unsupervised Bayesian selection of the efficient scales in the sens of L-2 metric. In this work, We prove its high alignment performance on the most studied image databases such as MPEG-7, MCD, Kimia-99, Kimia216, ETH-80, and the Swedish leaf experimentally. The unsupervised Bayesian classification is based on the well-known multiclass Expectation-Maximization algorithm.
C1 [Sakrani, Khaoula; Elghoul, Sinda; Ghorbel, Faouzi] Manouba Univ, GRIFT Res Grp Natl Sch Comp Sci ENSI, CRISTAL Lab, Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Sakrani, K (corresponding author), Manouba Univ, GRIFT Res Grp Natl Sch Comp Sci ENSI, CRISTAL Lab, Manouba 2010, Tunisia.
EM sakrani.khaoula@gmail.com
OI Ghorbel, Faouzi/0000-0002-6364-1089
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   [Anonymous], 2014, 2014 12 INT WORKSHOP
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Bachelder IA, 1992, CONTOUR MATCHING USI
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BenKhlifa A, 2019, SIGNAL PROCESS-IMAGE, V75, P32, DOI 10.1016/j.image.2019.03.009
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Bryner D, 2014, PROC CVPR IEEE, P312, DOI 10.1109/CVPR.2014.47
   Bryner D, 2012, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2012.6247700
   Chuanju Liu, 2020, ICCPR 2020: Proceedings of the 2020 9th International Conference on Computing and Pattern Recognition, P439, DOI 10.1145/3436369.3436465
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377
   Cyganski D., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V848, P33
   Cyganski D, 1992, INTELLIGENT ROBOTS C, V1607, P98
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P646
   Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448
   El Rube I, 2006, IEEE T PATTERN ANAL, V28, P323, DOI 10.1109/TPAMI.2006.43
   El-ghazal A, 2012, J VIS COMMUN IMAGE R, V23, P622, DOI 10.1016/j.jvcir.2012.01.011
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Elghoul Sinda, 2021, New Approaches for Multidimensional Signal Processing. Proceedings of International Workshop, NAMSP 2020. Smart Innovation, Systems and Technologies (SIST 216), P73, DOI 10.1007/978-981-33-4676-5_5
   Elghoul S, 2022, INT J MULTIMED INF R, V11, P39, DOI 10.1007/s13735-021-00224-3
   Elghoul S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116058
   Ersi EF, 2006, P 3 CAN C COMP ROB V, P4, DOI DOI 10.1109/CRV.2006.48
   Felzenszwalb PF, 2007, PROC CVPR IEEE, P367
   Fu HJ, 2013, IET COMPUT VIS, V7, P279, DOI 10.1049/iet-cvi.2012.0123
   Genovese A., 2014, Touchless Palmprint Recognit. Syst., P49
   Genovese A, 2014, TOUCHLESS PALMPRINT, V60
   Ghorbel F., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P641, DOI 10.1109/ICPR.1996.546902
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Gope C, 2005, PATTERN RECOGN, V38, P125, DOI 10.1016/j.patcog.2004.06.005
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Hemamalini G., 2016, INT J ENG TECHNOL IJ, V8, P2234, DOI [10.21817/ijet/2016/v8i5/160805205, DOI 10.21817/IJET/2016/V8I5/160805205]
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171
   Huang XM, 2005, PATTERN RECOGN LETT, V26, P1244, DOI 10.1016/j.patrec.2004.11.006
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Kang EY, 2000, INT C PATT RECOG, P257, DOI 10.1109/ICPR.2000.905314
   Kaothanthong N, 2016, PATTERN RECOGN LETT, V78, P14, DOI 10.1016/j.patrec.2016.03.029
   Ke QH, 2014, PROC CVPR IEEE, P4146, DOI 10.1109/CVPR.2014.528
   Kovalsky SZ, 2010, IEEE T PATTERN ANAL, V32, P940, DOI 10.1109/TPAMI.2010.22
   Krotosky SJ, 2007, COMPUT VIS IMAGE UND, V106, P270, DOI 10.1016/j.cviu.2006.10.008
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Leibe B, 2003, PROC CVPR IEEE, P409
   Lin WS, 2007, PATTERN RECOGN, V40, P1921, DOI 10.1016/j.patcog.2006.03.021
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu HL, 2014, RESULTS MATH, V65, P235, DOI 10.1007/s00025-013-0343-5
   Ma JY, 2013, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2013.279
   Mai F, 2010, IEEE IMAGE PROC, P4605, DOI 10.1109/ICIP.2010.5651645
   Matulova J, 2022, J MATERN-FETAL NEO M, V35, P7571, DOI 10.1080/14767058.2021.1956458
   Mokhtarian F, 2001, PATTERN ANAL APPL, V4, P1, DOI 10.1007/PL00010984
   MOONS T, 1995, INT J COMPUT VISION, V14, P25, DOI 10.1007/BF01421487
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Pham N, 2018, IEEE IMAGE PROC, P3348, DOI 10.1109/ICIP.2018.8451013
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   PAUWELS EJ, 1995, INT J COMPUT VISION, V14, P49, DOI 10.1007/BF01421488
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   Pulli K., 1999, Proc.3DIM, P160
   Raviv D, 2015, INT J COMPUT VISION, V111, P1, DOI 10.1007/s11263-014-0728-2
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sakrani K, 2021, 2021 INT C VISUAL CO, P1
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sellami M, 2012, EUR SIGNAL PR CONF, P390
   Shekar BH, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P46, DOI 10.1145/2708463.2709062
   Shu X, 2015, J VIS COMMUN IMAGE R, V26, P161, DOI 10.1016/j.jvcir.2014.11.007
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Soderkvist O, 2001, COMPUTER VISION CLAS
   Spivak M., 1970, COMPREHENSIVE INTRO
   Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912
   Thorndike R.L., 1953, Psychometrika, DOI DOI 10.1007/BF02289263
   Tu ZW, 2008, COMPUT VIS IMAGE UND, V109, P290, DOI 10.1016/j.cviu.2007.04.004
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Wang G, 2017, KNOWL-BASED SYST, V136, P200, DOI 10.1016/j.knosys.2017.09.016
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wolter D, 2004, LECT NOTES ARTIF INT, V3157, P693
   Xu HR, 2016, IEEE IMAGE PROC, P644, DOI 10.1109/ICIP.2016.7532436
   Xu HR, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P96, DOI 10.1109/ROBIO.2015.7414630
   Yang BS, 2015, ISPRS J PHOTOGRAMM, V101, P262, DOI 10.1016/j.isprsjprs.2014.12.025
   Yang CZ, 2021, APPL MATH COMPUT, V403, DOI 10.1016/j.amc.2021.126096
   Yang CZ, 2019, SIGNAL PROCESS-IMAGE, V71, P110, DOI 10.1016/j.image.2018.11.004
   Yang CZ, 2018, NEUROCOMPUTING, V275, P1160, DOI 10.1016/j.neucom.2017.09.067
   Yang CZ, 2016, FRONT ARTIF INTEL AP, V285, P269, DOI 10.3233/978-1-61499-672-9-269
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yang K., 2019, DIGIT MED, V5, P76, DOI [10.4103/digm.digm_10_19, DOI 10.4103/DIGM.DIGM_10_19]
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
   Zheng Y, 2020, IEEE ACCESS, V8, P90141, DOI 10.1109/ACCESS.2020.2994234
   Zheng Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050693
   Zuliani M, 2004, IEEE IMAGE PROC, P3041
NR 98
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7057
EP 7083
DI 10.1007/s11042-023-14890-4
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700008
DA 2024-07-18
ER

PT J
AU Wang, YH
   Moghaddam, AG
AF Wang, Yanhui
   Moghaddam, Alireza Ghasemian
TI A new method for reduction of color in a carpet map using a deep belief
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Carpet map; Size reduction; Color reduction; Deep belief network
AB Most businesses, including the carpet industry, employ computers for accuracy expansion, quality improvement, reducing costs, and speed growth as computers become more common. Several colors are generally used in accurate color pictures, and each pixel is allocated 24 bits. These pictures are difficult to display, store, transmit, and process. As a result, color quantization is frequently employed as a preprocessing step for various images. Segmentation, compression, text identification, watermarking, color-texture analysis, and content-based retrieval are all applications of color quantization in image processing. The goal of this study is to minimize the colors in a carpet map to a single value. The Deep Belief Network (DBN) is suggested to solve these issues. DBN integrates low-level characteristics to find distributed feature representation and produces a more abstract high-level depiction as a typical representative of deep learning. DBN can extract high-level characteristics from low-level signals layer by layer by employing greedy learning. Traditional feature extraction adds complexity and uncertainty, while the DBN reduces it and improves recognizing intelligence. MATLAB, a sophisticated simulation tool, is used to test the suggested technique. The findings are compared to available techniques in terms of color quantization and size reduction. According to the findings, the suggested technique improves the accuracy of the color quantization and size reduction phases.
C1 [Wang, Yanhui] Hunan Univ Informat Technol, Sch Comp Sci & Engn, Changsha 410100, Hunan, Peoples R China.
   [Moghaddam, Alireza Ghasemian] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Wang, YH (corresponding author), Hunan Univ Informat Technol, Sch Comp Sci & Engn, Changsha 410100, Hunan, Peoples R China.
EM yanhuiwang@hnuit.edu.cn; ghasemianmoghaddama@gmail.com
RI WANG, Yanhui/AAS-3446-2020
OI WANG, Yanhui/0000-0002-3214-2711
FU Research Project of Teaching Reform in Colleges and Universities of
   Hunan Province in 2022: Research on the Construction and Practice of the
   First-class undergraduate course of Computer Foundation in the era of
   Big Data [NO: HNJG-2022-0383]
FX This work was supported by Research Project of Teaching Reform in
   Colleges and Universities of Hunan Province in 2022: Research on the
   Construction and Practice of the First-class undergraduate course of
   Computer Foundation in the era of Big Data (NO: HNJG-2022-0383)
CR Alamir Parina, 2016, Kybernetes, V45, P1505, DOI 10.1108/K-07-2015-0171
   Bharti S, 2022, KYBERNETES, V51, P2695, DOI 10.1108/K-01-2021-0061
   Celebi ME, 2013, 2013 INT C EL COMP C
   Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Chen KT, 2021, Arxiv, DOI arXiv:2107.04191
   Cui J, 2022, HYBRID METHOD REDUCT
   Di Martino F, 2014, INFORM SCIENCES, V266, P101, DOI 10.1016/j.ins.2014.01.014
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   García-Lamont F, 2020, PATTERN ANAL APPL, V23, P59, DOI 10.1007/s10044-018-0729-9
   Gill HK, 2022, LIBR HI TECH, V40, P1159, DOI 10.1108/LHT-02-2021-0063
   Hakim A, 2023, IETE J RES, V69, P4053, DOI 10.1080/03772063.2021.1958074
   Kaur M, 2020, CLUSTER COMPUT, V23, P1439, DOI 10.1007/s10586-019-02999-x
   Keyvanrad MA, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415510064
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   Li Z, 2020, J INTELL MANUF, V31, P1693, DOI 10.1007/s10845-017-1380-9
   Liu RJ, 2021, MOBILE NETW APPL, V26, P3, DOI 10.1007/s11036-020-01717-x
   Lüsi I, 2018, MULTIMED TOOLS APPL, V77, P30939, DOI 10.1007/s11042-018-6118-y
   Lv ZH, 2021, IEEE NETWORK, V35, P67, DOI 10.1109/MNET.011.2000229
   Roshani M, 2020, FLOW MEAS INSTRUM, V75, DOI 10.1016/j.flowmeasinst.2020.101804
   Shen L, 2016, KNOWL-BASED SYST, V96, P61, DOI 10.1016/j.knosys.2016.01.002
   Tuncer T., 2018, EUR J TECHN EJT, V8, P168, DOI [10.36222/ejt.457053, DOI 10.36222/EJT.457053]
   Wang MJ, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.105946
   Wang MJ, 2017, NEUROCOMPUTING, V267, P69, DOI 10.1016/j.neucom.2017.04.060
   Wang P, 2021, IEEE T GEOSCI REMOTE, V59, P2256, DOI 10.1109/TGRS.2020.3004353
   Wen Q, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-118
   Xiong ZG, 2021, J SIGNAL PROCESS SYS, V93, P139, DOI 10.1007/s11265-019-01508-y
   Xu ZL, 2019, COLOR RES APPL, V44, P526, DOI 10.1002/col.22361
   Yin P, 2020, KYBERNETES, V49, P3099, DOI 10.1108/K-10-2019-0688
   Zhang CW, 2021, STRUCT CONTROL HLTH, V28, DOI 10.1002/stc.2821
   Zhang H, 2017, INT J BIOL MACROMOL, V97, P201, DOI 10.1016/j.ijbiomac.2017.01.031
   Zheng BL, 2020, IEEE T CIRC SYST VID, V30, P3982, DOI 10.1109/TCSVT.2019.2931045
   Zhou WJ, 2021, IEEE T SYST MAN CY-S, V51, P3641, DOI 10.1109/TSMC.2019.2957386
NR 33
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 4
PY 2023
DI 10.1007/s11042-023-15186-3
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I1AI5
UT WOS:001000166200003
DA 2024-07-18
ER

PT J
AU Sridhar, B
AF Sridhar, B.
TI An effective sharing approach of selective video frames for secure
   multimedia transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Copyright protection; Crypto-watermarking; Digital rights management;
   Gate-fold sharing; Discrete wavelet transform (DWT); Singular value
   decomposition (SVD)
ID REAL-TIME; WATERMARKING; ROBUST; WAVELET; DOMAIN; IMAGE
AB Copyright marking of computerized data issues is more attractive in research society. This research work illustrates the non-blind detection technique on video. In this proposed approach a Crypto-watermarking technique has been addressed to enhance the protection of digital media content. In video randomly selected the two luminance video frames are undergone pixel rearrangement and form gate fold frames. Now, these two gatefold frames are shared by alternative pixels results and obtained the four different shares. Now the video frame shares are stack to form crypto in structure. Wavelet transform is enforced to each crypto share and the copyright information is concealed in the diagonal fashion of the medium level sub-band coefficients. Finally, an Inverse wavelet is enforced to recover the encrypted video frames and after that, the reverse processes are enabled to the crypto share and recover the two luminance frames. This method gives the PSNR value of 56.3611 dB and MSE value of 0.1521.The advantage of this technique is concealed digital information in crypto shares yields a degree of robustness and security is increased. So removal of a watermark in the video frame and claim ownership is completely avoided.
C1 [Sridhar, B.] MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
C3 MLR Institute of Technology
RP Sridhar, B (corresponding author), MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
EM sridharbece@gmail.com
RI Balakrishnan, Sridhar/AAA-4514-2021
OI Balakrishnan, Sridhar/0000-0002-3144-7468
CR Al-Taweel FAP., 2009, TENCON IEEE REGION 1, P1
   Busch C, 1999, IEEE COMPUT GRAPH, V19, P25, DOI 10.1109/38.736466
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deguillaume F, 2000, PROC SPIE, V3971, P346, DOI 10.1117/12.384989
   Diyanat A, 2013, ISECURE-ISC INT J IN, V5, P83
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Huang H.-Y., 2007, P MACH VIS APPL, P256
   Ibrahim M.M., 2014, SCI WORLD J, P1
   Jeebananda P, 2016, 1 INDIA INT C INFORM, P1
   Jie sang, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100052
   Kaczynski M, 2022, SENSORS-BASEL, V22
   Kanocz T, 2011, P IEEE, V1-4
   Kim KS, 2008, IEICE T INF SYST, VE91D, P1359, DOI 10.1093/ietisy/e91-d.5.1359
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Liu L, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P476, DOI 10.1109/ICINFA.2008.4608046
   Mostafa K. S. A., 2016, J. Inf. Secur., V7, P260, DOI [10.4236/jis.2016.74021, DOI 10.4236/JIS.2016.74021]
   Naved A., 2016, INT J ADV RES COMPUT, V6, P490
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Shenggang Liu, 2015, 2015 40th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), P1, DOI 10.1109/IRMMW-THz.2015.7327569
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Shukla Dolley, 2018, Radioelectronics and Communications Systems, V61, P1, DOI 10.3103/S0735272718010016
   Singh R, 2022, COMPLEX INTELL SYST, V8, P1047, DOI 10.1007/s40747-021-00569-6
   Sridhar B, 2023, MULTIMED TOOLS APPL, V82, P19657, DOI 10.1007/s11042-023-14426-w
   Sridhar B, 2019, PATTERN RECOGN IMAGE, V29, P194, DOI 10.1134/S105466181901022X
   Sridhar B., 2018, Pattern Recognition and Image Analysis, V28, P537, DOI 10.1134/S1054661818030203
   Sridhar B, 2017, INT J SMART SENS INT, V10, P387, DOI 10.21307/ijssis-2017-217
   Sridhar B, 2016, J COMMUN TECHNOL EL+, V61, P165, DOI 10.1134/S1064226916020042
   Sridhar B, 2015, LAT AM APPL RES, V45, P207
   Steghrarzadeh K, 2006, 2 INT C INF COMM TEC, P1841
   Tabassum T, 2012, INT CONF COMPUT INFO, P101, DOI 10.1109/ICCITechn.2012.6509780
   Nguyen T, 2015, PROC INT CONF ADV, P439, DOI 10.1109/ATC.2015.7388367
   Vafaei M., 2013, World Appl. Sci. J, V22, P1572
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Yuanyu Ding, 2010, 2010 Third International Symposium on Electronic Commerce and Security (ISECS 2010), P289, DOI 10.1109/ISECS.2010.70
NR 37
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-15843-7
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0SS7
UT WOS:000999967700004
DA 2024-07-18
ER

PT J
AU Kheder, MQ
   Mohammed, AA
AF Kheder, Mohammed Qader
   Mohammed, Aree Ali
TI Improved traffic sign recognition system (itsrs) for autonomous vehicle
   based on deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic Sign Recognition; ITSRS; Deep Learning; CNN; LeNet-5 Network;
   GTSRB; ROC
ID CLASSIFICATION
AB Due to the considerable number of deaths and vehicle accidents caused by a driver's inattention, as reported by WHO, automobile manufacturers are aiming to combine advanced driver assistance systems (ADAS) with artificial intelligence algorithms, particularly deep learning and computer vision techniques. One feature that assists drivers is traffic sign recognition, which is a technique that allows vehicles to detect and recognize road signs placed on the road. This can be achieved by the aid of computer vision and Convolutional Neural Networks (CNN). The main aim of this research is to propose and improve a CNN based-model that can be efficiently and accurately applied for embedded applications, this might be accomplished with the help of several preprocessing algorithms. An improved network model called LeNet-5 has been developed for the classification of traffic signs. Furthermore, the proposed model network is trained using both German Traffic Sign Recognition Benchmark (GTSRB) and extended GTSRB (EGTSRB) datasets. According to the test results, the improved LeNet-5 architecture obtained an accuracy of 99.12% on GTSRB and 99.78% on EGTSRB datasets respectively, which has a positive performance compared to other state-of-the-art papers in terms of accuracy.
C1 [Kheder, Mohammed Qader; Mohammed, Aree Ali] Univ Sulaimani, Coll Sci, Comp Sci Dept, Sulaimani, Iraq.
C3 University of Sulimanyah
RP Kheder, MQ (corresponding author), Univ Sulaimani, Coll Sci, Comp Sci Dept, Sulaimani, Iraq.
EM mohammed.kheder@univsul.edu.iq; aree.ali@univsul.edu.iq
CR Akshata V. S., 2019, J. Emerg. Technol. Innov. Res, V6, P186
   [Anonymous], 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P4244
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Cao JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19184021
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Duth PS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P718, DOI 10.1109/ICISC.2018.8398893
   Haque WA, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114481
   Bui HM, 2016, 2016 IEEE SIXTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P321, DOI 10.1109/CCE.2016.7562656
   Jose Ajay, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P507, DOI 10.1007/978-981-13-3600-3_48
   Kulkarni S., 2020, INT RES J ENG TECHNO, V7, P1459
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li TH, 2020, COMP M BIO BIO E-IV, V8, P109, DOI 10.1080/21681163.2019.1608307
   Li WL, 2019, ICVIP 2019: PROCEEDINGS OF 2019 3RD INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING, P13, DOI 10.1145/3376067.3376102
   Munadi K, 2020, IEEE ACCESS, V8, P217897, DOI 10.1109/ACCESS.2020.3041867
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Patil D., 2021, Int. J. Eng. Res. Technol, V9, P422
   Radu MD, 2020, INT C ELECT COMPUT, DOI 10.1109/ecai50035.2020.9223186
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Sadou II, 2022, EUROMICRO CONF PROC, P205, DOI 10.1109/DSD57027.2022.00036
   Serna CG, 2020, IEEE T INTELL TRANSP, V21, P4388, DOI 10.1109/TITS.2019.2941081
   Shah Bhoomi, 2022, Procedia Computer Science, P202, DOI 10.1016/j.procs.2022.12.023
   Singh K., 2022, Adv. J. Graduate Res, V11, P23, DOI [10.21467/ajgr.11.1.23-33, DOI 10.21467/AJGR.11.1.23-33]
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sultana F., 2020, Intelligent Computing: Image Processing Based Applications. Advances in Intelligent Systems and Computing (AISC 1157), P1, DOI 10.1007/978-981-15-4288-6_1
   Sun Y., 2021, J APPL MATH PHYS, V9, P3122, DOI [10.4236/jamp.2021.912204, DOI 10.4236/JAMP.2021.912204]
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Xie BQ, 2019, IEEE ACCESS, V7, P53330, DOI 10.1109/ACCESS.2019.2912311
   Xu H, 2020, MULTIMED TOOLS APPL, V79, P11551, DOI 10.1007/s11042-019-08239-z
   Xu TB, 2019, PATTERN RECOGN, V88, P272, DOI 10.1016/j.patcog.2018.10.029
   Zaibi A, 2021, J SENSORS, V2021, DOI 10.1155/2021/8870529
   Zhou SR, 2018, CMC-COMPUT MATER CON, V57, P11, DOI 10.32604/cmc.2018.02617
NR 32
TC 0
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15898-6
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000007
DA 2024-07-18
ER

PT J
AU Durdu, A
AF Durdu, Ali
TI Image transfer with secure communications application using a new
   reversible chaotic image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic; Image encryption; Reversible; p-c method; Chaotic systems;
   Synchronization
ID SEMI-TENSOR PRODUCT; ALGORITHM; SYNCHRONIZATION; SYSTEMS; MATRIX
AB In this study, encrypted image transmission was carried out with a secure communication application using reversible chaotic image encryption with the synchronization of two identical chaotic systems. Encryption and decryption of the image can be done with the same algorithm using the same chaotic signal. The image can be encrypted using the same chaotic signal on the sending side and decoded with the encryption algorithm and chaotic signal on the receiving side. Experimental results show that the proposed encryption algorithm can securely encrypt and transfer images in 24-bit RGB and 8-bit grayscale images. In the study, histogram, histogram variance, salt & pepper, speckle, NPCR and UACI, four classical types of attacks, NIST, key sensitive and crop visual and statistical attacks were made on encrypted images and the robustness of the encryption method was tested. In addition, PSNR, SSIM, UIQ, BER and NCC image quality criteria were used and the results of attacks on chaotic encrypted images were measured. As a result of visual and statistical attacks, it has been seen that the proposed chaotic encryption algorithm is resistant to attacks. The NPCR and UACI analysis results of the proposed method were compared with the results of similar studies in the literature. According to similar chaotic image coding studies in the literature, the NPCR and UACI values of the proposed method gave better results than most. As a result of the tests, with the secure communication application of the proposed method, image encryption and decryption can be performed by using a common chaotic signal on the sender and receiver sides.
C1 [Durdu, Ali] Social Sci Univ Ankara, Fac Polit Sci, Dept Management Informat Syst, Ankara, Turkiye.
C3 Ankara University; Ankara Sosyal Bilimler Universitesi
RP Durdu, A (corresponding author), Social Sci Univ Ankara, Fac Polit Sci, Dept Management Informat Syst, Ankara, Turkiye.
EM ali.durdu@asbu.edu.tr
CR [Anonymous], 2010, 2010 6 INT C WIRELES, DOI DOI 10.1109/WICOM.2010.5601297
   Babu NR, 2021, MULTIMED TOOLS APPL, V80, P18043, DOI 10.1007/s11042-020-10288-8
   Cheng C, 2012, P 2012 4 INT C COMP, DOI [10.1109/CICSyN.2012.46, DOI 10.1109/CICSYN.2012.46]
   drive.google, MATLAB CODE
   Durdu A, 2015, INF TECHNOL CONTROL, V44, P271, DOI 10.5755/j01.itc.44.3.7720
   Findik O., 2010, ADV INFORM TECHNOLOG, DOI [10.1007/978-3-642-16699-0_4, DOI 10.1007/978-3-642-16699-0_4]
   Hamadi IA, 2022, OPT QUANT ELECTRON, V54, DOI 10.1007/s11082-021-03406-9
   Hasimoto-Beltrán R, 2007, REV MEX FIS, V53, P58
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang LL, 2004, PHYS LETT A, V320, P271, DOI 10.1016/j.physleta.2003.11.027
   Jamil T., 1999, IEEE Potentials, V18, P10, DOI 10.1109/45.747237
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P28025, DOI 10.1007/s11042-019-07893-7
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li CH, 2017, AER ADV ENG RES, V86, P261
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li WS, 2015, INT CONF INSTR MEAS, P262, DOI 10.1109/IMCCC.2015.62
   Liao TL, 1999, J FRANKLIN I, V336, P925, DOI 10.1016/S0016-0032(99)00010-1
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Park JH, 2005, CHAOS SOLITON FRACT, V25, P579, DOI 10.1016/j.chaos.2004.11.038
   PECORA LM, 1990, PHYS REV LETT, V64, P821, DOI 10.1103/PhysRevLett.64.821
   PECORA LM, 1991, PHYS REV A, V44, P2374, DOI 10.1103/PhysRevA.44.2374
   Pehlivan I, 2007, INFORM SECURITY CRYP
   Proakis J., 2007, DIGITAL COMMUNICATIO
   Qobbi Y, 2022, SOFT COMPUT, V26, P5823, DOI 10.1007/s00500-021-06567-7
   Sun FY, 2007, CHINESE PHYS, V16, P3616, DOI 10.1088/1009-1963/16/12/011
   Uçar A, 2006, CHAOS SOLITON FRACT, V27, P1292, DOI 10.1016/j.chaos.2005.04.104
   Wang FQ, 2007, PHYSICA D, V225, P55, DOI 10.1016/j.physd.2006.09.038
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiao HP, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2707
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
   Yassen MT., 2003, CHAOS SOLITON FRACT, V15, P27183
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 53
TC 6
Z9 6
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15707-0
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100007
DA 2024-07-18
ER

PT J
AU Chanchal, AK
   Lal, S
   Barnwal, D
   Sinha, P
   Arvavasu, S
   Kini, J
AF Chanchal, Amit Kumar
   Lal, Shyam
   Barnwal, Dipanshu
   Sinha, Prince
   Arvavasu, Shrikant
   Kini, Jyoti
TI Evolution of LiverNet 2.x: Architectures for automated liver cancer
   grade classification from H&E stained liver histopathological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Atrous convolutions; Convolutional neural networks; Deep learning; Dense
   connections; Histopathology images; Medical image classification
ID DEEP LEARNING ARCHITECTURE; SEGMENTATION
AB Recently, the automation of disease identification has been quite popular in the field of medical diagnosis. The rise of Convolutional Neural Networks (CNNs) for training and generalizing medical image data has proven to be quite efficient in detecting and identifying the types and sub-types of various diseases. Since the classification of large datasets of Hematoxylin & Eosin (H&E) stained histopathology images by experts can be expensive and time-consuming, automated processes using deep learning have been encouraged for the past decade. This paper introduces LiverNet 2.x model by modifying the previously encountered LiverNet architecture. The proposed model uses two different improvements of the Atrous Spatial Pyramid Pooling (ASPP) block to extract the clinically defined features of hepatocellular carcinoma (HCC) from liver histopathology images. LiverNet 2.0 uses a modified form of ASPP block known as DenseASPP, where all the atrous convolution outputs are densely connected. Whereas LiverNet 2.1 uses fewer concatenations while maintaining a large receptive field by stacking the dilated convolutional blocks in a tree-like fashion. This paper also discusses the trade-off between LiverNet 2.0 and LiverNet 2.1 in terms of accuracy and computational complexity. All comparison model and the proposed model is trained and tested on the patches of two different histopathological datasets. The experimental results show that the proposed model performs better compared to reference models. For the KMC Liver dataset, LiverNet 2.0 and LiverNet 2.1 achieved an accuracy of 97.50% and 97.14% respectively. Accuracy of 94.37% and 97.14% for the TCGA Liver dataset are achieved.
C1 [Chanchal, Amit Kumar; Lal, Shyam; Barnwal, Dipanshu; Sinha, Prince; Arvavasu, Shrikant] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.
   [Kini, Jyoti] Kasturba Med Coll & Hosp, Dept Pathol, Mangalore, India.
   [Kini, Jyoti] Manipal Acad Higher Educ, Dept Pathol, Manipal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Manipal Academy of Higher Education (MAHE);
   Kasturba Medical College, Mangalore; Manipal Academy of Higher Education
   (MAHE)
RP Lal, S (corresponding author), Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.
EM amit.chanchal01@gmail.com; shyam.mtec@gmail.com;
   dipanshu27dps@gmail.com; princesinha24august@gmail.com;
   ashrikant39@gmail.com; kinijyoti@gmail.com
OI Chanchal, Amit Kumar/0000-0002-2224-1863; Lal, Dr.
   Shyam/0000-0002-4355-6354
CR Aatresh AA, 2021, INT J COMPUT ASS RAD, V16, P1549, DOI 10.1007/s11548-021-02410-4
   Abbasniya MR, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108382
   Afza F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030799
   Alhindi TJ, 2018, IEEE IJCNN
   Arooj S, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.924432
   Cai SF, 2020, Arxiv, DOI arXiv:1904.03392
   Calderaro J, 2019, J HEPATOL, V71, P616, DOI 10.1016/j.jhep.2019.06.001
   Chanchal AK, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107177
   Chen C, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01919-1
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen MY, 2020, NPJ PRECIS ONCOL, V4, DOI 10.1038/s41698-020-0120-3
   Chiang CH, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253205
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cremers, 2017, Regularization for Deep Learning: A Taxonomy
   Hameed Z, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19278-2
   Hao Y, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0267955
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P18015, DOI 10.1007/s00521-022-07445-5
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kim T, 2021, QUANT IMAG MED SURG, V11, P1763, DOI 10.21037/qims-20-745
   Kingma Diederik P., 2015, P 3 INT C LEARN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lal S, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104075
   Liu M, 2022, IEEE J BIOMED HEALTH, V26, P5025, DOI 10.1109/JBHI.2022.3187765
   Lu LQ, 2020, PEERJ, V8, DOI 10.7717/peerj.8668
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Nguyen TBT, 2022, LECT NOTES I COMPUTE, V444
   Othman E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145429
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Rehman MU, 2022, IEEE T NETW SCI ENG, V9, P4322, DOI 10.1109/TNSE.2022.3199235
   Srinidhi CL, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102256
   Sun CL, 2020, IEEE J BIOMED HEALTH, V24, P1643, DOI 10.1109/JBHI.2019.2949837
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabari M, 2013, IEEE POW ENER SOC GE
   Togaçar M, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123592
   Travis WD, 2016, EUR RESPIR J, V47, P720, DOI 10.1183/13993003.00035-2016
   Vu TH, 2015, I S BIOMED IMAGING, P990, DOI 10.1109/ISBI.2015.7164037
   Wei BZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P348, DOI 10.1109/ICCCBDA.2017.7951937
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu XL, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/5334095
   Yang JD, 2019, NAT REV GASTRO HEPAT, V16, P589, DOI 10.1038/s41575-019-0186-y
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
NR 45
TC 3
Z9 3
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15176-5
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700004
DA 2024-07-18
ER

PT J
AU Hayit, T
   Erbay, H
   Varçin, F
   Hayit, F
   Akci, N
AF Hayit, Tolga
   Erbay, Hasan
   Varcin, Fatih
   Hayit, Fatma
   Akci, Nilufer
TI The classification of wheat yellow rust disease based on a combination
   of textural and deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Yellow rust; Textural features; Deep features; DenseNet; SVM; KNN
ID COLOR
AB Yellow rust is a devastating disease that causes significant losses in wheat production worldwide and significantly affects wheat quality. It can be controlled by cultivating resistant cultivars, applying fungicides, and appropriate agricultural practices. The degree of precautions depends on the extent of the disease. Therefore, it is critical to detect the disease as early as possible. The disease causes deformations in the wheat leaf texture that reveals the severity of the disease. The gray-level co-occurrence matrix(GLCM) is a conventional texture feature descriptor extracted from gray-level images. However, numerous studies in the literature attempt to incorporate texture color with GLCM features to reveal hidden patterns that exist in color channels. On the other hand, recent advances in image analysis have led to the extraction of data-representative features so-called deep features. In particular, convolutional neural networks (CNNs) have the remarkable capability of recognizing patterns and show promising results for image classification when fed with image texture. Herein, the feasibility of using a combination of textural features and deep features to determine the severity of yellow rust disease in wheat was investigated. Textural features include both gray-level and color-level information. Also, pre-trained DenseNet was employed for deep features. The dataset, so-called Yellow-Rust-19, composed of wheat leaf images, was employed. Different classification models were developed using different color spaces such as RGB, HSV, and L*a*b, and two classification methods such as SVM and KNN. The combined model named CNN-CGLCM_HSV, where HSV and SVM were employed, with an accuracy of 92.4% outperformed the other models.
C1 [Hayit, Tolga] Yozgat Bozok Univ, Fac Engn & Architecture, Dept Comp Engn, TR-66900 Yozgat, Turkiye.
   [Erbay, Hasan] Univ Turkish Aeronaut Assoc, Engn Fac, Comp Engn Dept, TR-06790 Ankara, Turkiye.
   [Erbay, Hasan] Ostim Tech Univ, Engn Fac, Comp Engn Dept, TR-06374 Ankara, Turkiye.
   [Varcin, Fatih] Sakarya Univ Appl Sci, Fac Technol, Dept Comp Engn, TR-54187 Sakarya, Turkiye.
   [Hayit, Fatma] Yozgat Bozok Univ, Tourism Fac, Dept Gastron & Culinary Arts, TR-66900 Yozgat, Turkiye.
   [Akci, Nilufer] Republ Turkiye Minist Agr & Forestry, Directorate Plant Protect Cent Res Inst, TR-06172 Ankara, Turkiye.
C3 Bozok University; Turkish Aeronautical Association; Turk Hava Kurumu
   University; Ostim Technical University; Sakarya University of Applied
   Science; Bozok University; Ministry of Food, Agriculture & Livestock -
   Turkey
RP Hayit, F (corresponding author), Yozgat Bozok Univ, Tourism Fac, Dept Gastron & Culinary Arts, TR-66900 Yozgat, Turkiye.
EM tolga.hayit@bozok.edu.tr; hasanerbay@yahoo.com; fatihvarcin@subu.edu.tr;
   fatma.hayit@bozok.edu.tr; nilufer.akci@tarimorman.gov.tr
RI HAYIT, FATMA/JFA-4345-2023; Varçın, Fatih/ABE-7006-2020
OI Varçın, Fatih/0000-0002-5100-3012
FU Scientific and Technological Research Council of Turkiye (TUB ?ITAK)
   [120O960]
FX This study was supported with project 120O960 by The Scientific and
   Technological Research Council of Turkiye (TUB ?ITAK). In addition, we
   would like to thank the Republic of Turkiye Ministryof Agriculture and
   Forestry Directorate of Field Crops Central Research Institute for
   letting us use theirfacilities.
CR Abayomi-Alli OO, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12746
   Aksoy S., 2000, Texture Analysis in Machine Vision, Series in Machine Perception and Artificial Intelligence, V40, P129, DOI [10.1142/97898127924950010, DOI 10.1142/97898127924950010]
   Almadhor A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113830
   [Anonymous], 2010, Int. J. Comput. Appl.
   Benco M, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58692
   Chakraborty S., 2021, 2021 2 INT C ROB EL, P147, DOI [10.1109/ICREST51555.2021.9331132, DOI 10.1109/ICREST51555.2021.9331132]
   Chen XM, 2020, FOOD SECUR, V12, P239, DOI 10.1007/s12571-020-01016-z
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devadas R, 2009, PRECIS AGRIC, V10, P459, DOI 10.1007/s11119-008-9100-2
   Dubey N., 2023, Smart Trends Comput Commun, P63
   Dusunceli F., 1996, The European and Mediterranean Cereal Rusts Powdery Mildew Conference
   Fekriershad S, 2017, SENSOR REV, V37, P33, DOI 10.1108/SR-07-2016-0120
   Gui WH, 2013, MINER ENG, V46-47, P60, DOI 10.1016/j.mineng.2013.03.024
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayit T, 2021, J PLANT PATHOL, V103, P923, DOI 10.1007/s42161-021-00886-2
   Hossain K, 2010, AIP CONF PROC, V1298, P583, DOI 10.1063/1.3516370
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Johnston C, 1964, 7 REVISION INT REGIS
   Khaldi B, 2019, IET IMAGE PROCESS, V13, P1401, DOI 10.1049/iet-ipr.2018.6440
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Lu JZ, 2018, PRECIS AGRIC, V19, P379, DOI 10.1007/s11119-017-9524-7
   Luz JS, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107819
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Metre V, 2013, ARXIV
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Nandhini S, 2022, NEURAL COMPUT APPL, V34, P5513, DOI 10.1007/s00521-021-06714-z
   Nanni L, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120143
   Naz J, 2023, NEURAL PROCESS LETT, V55, P115, DOI 10.1007/s11063-021-10481-2
   Nikoo H, 2011, MACHINE VISION IMAGE, P1
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Ning X, 2023, IEEE T COGN DEV SYST, V15, P774, DOI 10.1109/TCDS.2022.3182650
   Pardey PG, 2013, SCIENCE, V340, P147, DOI 10.1126/science.122970
   PETERSON RF, 1948, CAN J RES C, V26, P496, DOI 10.1139/cjr48c-033
   Pietikainen MK, 2000, TEXTURE ANAL MACHINE, V40
   Roelfs A. P., 1992, RUST DIS WHEAT CONCE
   Selvarajah S., 2011, INT J LATEST TRENDS, V2, P108
   Shearer S.A., 1986, Plant identification using color co-occurrence matrices derived from digitized images
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Srinidhi V. V., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1119, DOI 10.1109/ICCMC51019.2021.9418268
   Tou JY, 2009, S PROGR INF COMM TEC, V3, P56
   Vapnik V., 1999, NATURE STAT LEARNING
   Varçin F, 2021, J DIGIT IMAGING, V34, P85, DOI 10.1007/s10278-020-00402-5
   Vardhan MH., 2014, INT J ADV RES ELECT, V3, P75
   Verma R, 2021, INT C ART INT SPEECH, P500
   Wang C., 2022, PATTERN RECOGN, V108498, P124
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wang SH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3341095
   Wei LY, 2019, NEUROCOMPUTING, V324, P3, DOI 10.1016/j.neucom.2018.04.082
   Wellings CR, 2011, EUPHYTICA, V179, P129, DOI 10.1007/s10681-011-0360-y
   Yurttakal AH, 2018, IIOAB J, V9, P23
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
   Zhang W, 2021, ARXIV
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
NR 58
TC 7
Z9 7
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47405
EP 47423
DI 10.1007/s11042-023-15199-y
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986851800002
PM 37362723
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lin, YX
   Ling, BWK
   Li, CJ
   Liao, GZ
AF Lin, Yuxin
   Ling, Bingo Wing-Kuen
   Li, Caijun
   Liao, Guozhao
TI Multivariate two dimensional singular spectrum analysis based fusion
   method for four view image based object classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multivariate two dimensional singular spectrum analysis; Correlation
   coefficient based component selection method; Multi-view images; Object
   classification; Histogram of oriented gradient; Support vector machine
ID STRATEGY; OPTIMIZATION; RECOGNITION; ALGORITHM
AB A common method to perform the object classification with different images being taken at different views is to extract the features from each image without performing the fusion. On the other hand, this paper proposes a multivariate two dimensional singular spectrum analysis (M2DSSA) based approach to fuse the features in different images together to perform the object classification. First, a four channel two dimensional signal is formed using four images taken at four different views. Second, the M2DSSA is applied to the four channel two dimensional signal. Next, the histogram of the oriented gradient (Hog) is computed on each channel of each M2DSSA component. Then, the selection of the M2DSSA components is performed based on the correlation coefficients among these Hogs and the fusion of these images is performed via the M2DSSA. Next, the Hog of each reconstructed image is recomputed and these Hogs are employed as the features for the support vector machine to perform the object classification. Our proposed method yields the classification accuracies at 92.5925% and 97.8723% for the images in the first dataset and the second dataset, respectively. Since the information of the objects in different images is fused together, the computer numerical simulation results show that the classification accuracies of our proposed method are higher than those of the baseline method without performing the fusion and those of the other fusion methods.
C1 [Lin, Yuxin; Ling, Bingo Wing-Kuen; Li, Caijun; Liao, Guozhao] Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Ling, BWK (corresponding author), Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
EM yongquanling@gdut.edu.cn
OI Liao, Guo-Zhao/0009-0001-4594-4676
FU National Nature Science Foundation of China [U1701266, 61671163,
   62071128]; Team Project of the Education Ministry of the Guangdong
   Province [2017KCXTD011]; Guangdong Higher Education Engineering
   Technology Research Center for Big Data on Manufacturing Knowledge
   Patent [501130144]; Hong Kong Innovation and Technology Commission,
   Enterprise Support Scheme [S/E/070/17]
FX This paper was supported partly by the National Nature Science
   Foundation of China with the grant numbers U1701266, 61671163 and
   62071128, the Team Project of the Education Ministry of the Guangdong
   Province with the grant number 2017KCXTD011, the Guangdong Higher
   Education Engineering Technology Research Center for Big Data on
   Manufacturing Knowledge Patent with the grant number 501130144, and Hong
   Kong Innovation and Technology Commission, Enterprise Support Scheme
   with the grant number S/E/070/17.Availability of data and materialsThe
   datasets generated and analyzed during the current study are available
   in the public domain.
CR Atrish A, 2017, P INT C VIDEO IMAGE
   Cheng MM, 2019, IEEE T IMAGE PROCESS, V28, P2399, DOI 10.1109/TIP.2018.2877937
   Christoudias CM, 2008, PROC CVPR IEEE, P2126
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Golyandina N, 2018, USE R, P1, DOI 10.1007/978-3-662-57380-8
   Golyandina N, 2015, J STAT SOFTW, V67, P1
   Golyandina N, 2010, STAT INTERFACE, V3, P259
   Hassani H, 2013, INT J ENERGY STAT, V1, P55, DOI 10.1142/S2335680413500051
   iplab, MULT DAT SET IS DOWN
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Kannan S, 2020, SIGNAL IMAGE VIDEO P, V14, P877, DOI 10.1007/s11760-019-01619-w
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   KORN MR, 1987, PATTERN RECOGN, V20, P91, DOI 10.1016/0031-3203(87)90020-3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2019, ADV INTELL SYST, V748, P453, DOI 10.1007/978-981-13-0923-6_39
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Lin YX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030405
   Lin YX, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102131
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Medvedev AV, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3533266
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Sharma S, 2017, C INF COMM TECHN
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Shlemov A, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/689745
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Thomas A, 2006, IEEE COMP SOC C COMP
   Tomiyama K, 2004, P SOC PHOTO-OPT INS, V5599, P153, DOI 10.1117/12.571117
   Vuksanovic B, 2015, 9 INT S IM SIGN PROC
   Wang H, 2019, SIGNAL IMAGE VIDEO P, V13, P985, DOI 10.1007/s11760-019-01436-1
   Xu YY, 2015, MATH PROGRAM COMPUT, V7, P39, DOI 10.1007/s12532-014-0074-y
   Yang ZX, 2018, COGN COMPUT, V10, P908, DOI 10.1007/s12559-018-9598-1
   Zhang JW, 2014, J SYST SCI COMPLEX, V27, P56, DOI 10.1007/s11424-014-3314-3
NR 43
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46403
EP 46421
DI 10.1007/s11042-023-15712-3
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984795600002
DA 2024-07-18
ER

PT J
AU Zhang, JM
   Huang, HT
   Jin, XK
   Kuang, LD
   Zhang, J
AF Zhang, Jianming
   Huang, Haitao
   Jin, Xiaokang
   Kuang, Li-Dan
   Zhang, Jin
TI Siamese visual tracking based on criss-cross attention and improved head
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual tracking; Siamese network; Deep learning; Attention mechanism;
   Anchor-free; Center-ness
ID OBJECT; ROBUST
AB The efficient Siamese anchor-free tracker has fewer parameters, but it produces a large number of low-quality bounding boxes which are located far away from the center of the object. Moreover, a plenty of background information or distractors also interfere with the tracking process, resulting in the inaccurate results of classification and regression. As such, we propose a novel Siamese anchor-free network based on criss-cross attention and an improved head network. We apply ResNet-50 to extract the features of the template image and search region, then feed the feature maps into a recurrent criss-cross attention module to make it more discriminative. The enhanced feature maps are inputted into our improved head network, which include the center-ness branch based on the original classification and regression branches to filter out low-quality bounding boxes. Our proposed tracker reduces the impact of background information or distractors and can obtain high-quality bounding boxes, generating more accurate and robust tracking results. Extensive experiments and comparisons with state-of-the-art trackers are conducted on many challenging benchmarks such as VOT2016, VOT2018, GOT-10k, UAV123 and OTB2015. Our tracker achieves excellent performance with a considerable real-time speed.
C1 [Zhang, Jianming; Huang, Haitao] Changsha Univ Sci & Technol, Key Lab Safety Control Bridge Engn, Minist Educ, Changsha 410114, Peoples R China.
   [Zhang, Jianming; Huang, Haitao; Kuang, Li-Dan; Zhang, Jin] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
   [Jin, Xiaokang] Jinhua Adv Res Inst, Jinhua 321013, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology
RP Zhang, JM (corresponding author), Changsha Univ Sci & Technol, Key Lab Safety Control Bridge Engn, Minist Educ, Changsha 410114, Peoples R China.; Zhang, JM (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
EM jmzhang@csust.edu.cn; hthuang@stu.csust.edu.cn; jxk726@163.com;
   kuangld@csust.edu.cn; jzhang@csust.edu.cn
RI Zhang, Jianming/AAD-1000-2019
OI Zhang, Jianming/0000-0002-4278-0805; Jin, Xiaokang/0000-0002-9563-8888
FU Open Fund of Key Laboratory of Safety Control of Bridge Engineering,
   Ministry of Education (Changsha University of Science and Technology)
   [21~KB06]; Science Fund for Creative Research Groups of Hunan Province
   [2020JJ1006]; National Natural Science Foundation of China [61972056]
FX This work was supported in part by the Open Fund of Key Laboratory of
   Safety Control of Bridge Engineering, Ministry of Education (Changsha
   University of Science and Technology) under Grant 21~KB06, in part by
   the Science Fund for Creative Research Groups of Hunan Province under
   Grant 2020JJ1006, in part by the National Natural Science Foundation of
   China under Grant 61972056.
CR Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kristan M, 2016, The Visual Object Tracking VOT2016 challenge results, P777
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen H, 2022, J REAL-TIME IMAGE PR, V19, P463, DOI 10.1007/s11554-021-01190-z
   Sosnovik I, 2021, IEEE WINT CONF APPL, P2764, DOI 10.1109/WACV48630.2021.00281
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang F, 2022, PROC CVPR IEEE, P8731, DOI 10.1109/CVPR52688.2022.00854
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xing D., 2022, P IEEE CVF WINT C AP, P2139
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yu F, 2022, CHINESE PHYS B, V31, DOI 10.1088/1674-1056/ac3cb2
   Zhang JM, 2022, APPL SOFT COMPUT, V118, DOI 10.1016/j.asoc.2022.108485
   Zhang JM, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107730
   Zhang JM, 2022, NEURAL COMPUT APPL, V34, P6359, DOI 10.1007/s00521-021-06771-4
   Zhang JM, 2021, J AMB INTEL HUM COMP, V12, P8427, DOI 10.1007/s12652-020-02572-0
   Zhang JM, 2022, APPL INTELL, V52, P6129, DOI 10.1007/s10489-021-02694-8
   Zhang JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041129
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhang ZY, 2020, J REAL-TIME IMAGE PR, V17, P1647, DOI 10.1007/s11554-019-00922-6
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 56
TC 15
Z9 15
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15429-3
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F8FT6
UT WOS:000984658600004
DA 2024-07-18
ER

PT J
AU Zhao, XY
   Gao, G
   He, ZX
   Lv, YF
AF Zhao, Xinyue
   Gao, Gan
   He, Zaixing
   Lv, Yongfeng
TI Class specific nullspace marginal discriminant analysis with
   overfitting-prevention kernel estimation for hand trajectory
   recognitions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminant analysis; Dimensionality reduction; Feature extraction;
   Hand trajectory recognition
ID FEATURES
AB Hand trajectories are widely used for gesture recognition, action analysis, and sign language translation. Effective hand trajectory feature extraction facilitates accurate and fast identification. In this paper, we propose class specific nullspace marginal discriminant analysis (CSNMDA) with overfitting-prevention kernel estimation for hand trajectory feature extraction, which enhances the similarity of interested class (positive samples) and differentiating arbitrary samples not belonging to this class (negative samples). To address the intrinsic overfitting problems of discriminant analysis, we formulate a kernel space estimation method, which improves the model generalizability and accelerate the training speed. Besides, maximizing the distances between all negative samples and positive samples without distinction leads to limited discriminant power, especially for samples at the margin. Therefore, marginal discriminant analysis (MDA) is conducted to expand the margin of positive and negative class, achieving superior differentiation. According to the experiment on two public available hand trajectory databases, our method obtains higher accuracy compared with Class Specific Kernel Discriminant Analysis (CSKDA) and the Heterogeneous Orthogonal Class Specific Discriminant Analysis (HNCSDA).
C1 [Zhao, Xinyue; Gao, Gan; He, Zaixing] Zhejiang Univ, Sch Mech Engn, Hangzhou 310027, Peoples R China.
   [Zhao, Xinyue; He, Zaixing] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
   [Lv, Yongfeng] Zhejiang Inst Mech & Elect Engn, Hangzhou 310053, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang Institute of
   Mechanical & Electrical Engineering
RP He, ZX (corresponding author), Zhejiang Univ, Sch Mech Engn, Hangzhou 310027, Peoples R China.; He, ZX (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
EM zaixinghe@zju.edu.cn
RI Chen, Jin/KBQ-0163-2024; Gao, Gan/KPB-5299-2024
OI Chen, Jin/0009-0005-5844-635X; Gao, Gan/0000-0002-8100-7735
FU Zhejiang Provincial Natural Science Foundation of China [LY21E050021];
   National Natural Science Foundation of China [51775498, 51775497];
   Zhejiang Province Public Welfare Technology Application Research Project
   [LGG19E050019]
FX AcknowledgmentsThis research was supported by Zhejiang Provincial
   Natural Science Foundation of China(LY21E050021), the National Natural
   Science Foundation of China (51775498, 51775497) and Zhejiang Province
   Public Welfare Technology Application Research Project (LGG19E050019).
CR Alexandros I, 2018, ARXIV
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Azar SG, 2020, COMPUT SPEECH LANG, V61, DOI 10.1016/j.csl.2019.101053
   Beh J, 2014, PATTERN RECOGN, V47, P1586, DOI 10.1016/j.patcog.2013.11.010
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cao GQ, 2018, IET BIOMETRICS, V7, P63, DOI 10.1049/iet-bmt.2017.0081
   Caputo FM, 2018, COMPUT GRAPH-UK, V73, P17, DOI 10.1016/j.cag.2018.02.009
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Dong HS, 2018, PATTERN RECOGN LETT, V107, P66, DOI 10.1016/j.patrec.2017.10.032
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goudelis G, 2007, IEEE T INF FOREN SEC, V2, P570, DOI 10.1109/TIFS.2007.902915
   He ZX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107664
   Iosifidis A, 2015, CLASS SPECIFIC NONLI, P17
   Iosifidis A, 2017, IEEE T CYBERNETICS, V47, P4485, DOI 10.1109/TCYB.2016.2612479
   Iosifidis A, 2016, IEEE T INF FOREN SEC, V11, P2453, DOI 10.1109/TIFS.2016.2582562
   Iosifidis A, 2015, IEEE T HUM-MACH SYST, V45, P315, DOI 10.1109/THMS.2014.2379274
   Jia ZD, 2020, COMPUT CHEM ENG, V141, DOI 10.1016/j.compchemeng.2020.107023
   Kwak N, 2013, IEEE T NEUR NET LEAR, V24, P2113, DOI 10.1109/TNNLS.2013.2272292
   Li K, 2022, MACH LEARN, V111, P2037, DOI 10.1007/s10994-022-06140-9
   Liu FL, 2019, ARTIF INTELL REV, V52, P563, DOI 10.1007/s10462-019-09703-w
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Park CH, 2005, SIAM J MATRIX ANAL A, V27, P87, DOI 10.1137/S0895479804442334
   Raitoharju J, 2019, ARXIV
   Singh S, 2017, PATTERN RECOGN, V62, P45, DOI 10.1016/j.patcog.2016.07.031
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Wang C, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108589
   Xiao R, 2008, P 19 INT C PATT REC, P1
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
NR 33
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46293
EP 46311
DI 10.1007/s11042-023-15709-y
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984658600002
DA 2024-07-18
ER

PT J
AU Srinivas, LNB
   Bharathy, AMV
   Ramakuri, SK
   Sethy, A
   Kumar, R
AF Srinivas, L. N. B.
   Bharathy, A. M. Viswa
   Ramakuri, Sravanth Kumar
   Sethy, Abhisek
   Kumar, Ravi
TI An optimized machine learning framework for crop disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crop Disease Detection; Random Forest; Feature Extraction; Krill Herd
   Optimization; Machine Learning; Classify Crop Disease
ID FARMERS
AB The management of crops from the early to mature stage contains nutrient deficiency, monitoring plant disease, controlling irrigation, and controlling the use of pesticides and fertilizers. Moreover, lack of immunity and climate changes cause the crops and minimize the growth of agriculture due to crop disease. The identification and detection of crop diseases is the most challenging task due to less detection accuracy, overfitting, and error rate. So this research work designed a novel Krill Herd based Random Forest (KHbRF) for the accurate detection of crop disease, enhancing the performance of detection accuracy by using an optimized fitness function. The krill herd fitness function is updated to the classification layer for effective crop disease detection. Furthermore, development involves preprocessing, segmentation, feature extraction, and classification. The developed framework is implemented in the python tool, and the plant villa image dataset is tested and trained in the system. After that preprocessing removes errors and feature extraction extracts the texture features from the crop. At last, the classification layer detects the crop disease present in the dataset using the fitness of the krill herd. Additionally, attained results of the developed framework are compared with other state-of-the-art techniques in terms of detection accuracy, sensitivity, F-measure, and error.
C1 [Srinivas, L. N. B.] SRM Inst Sci & Technol, Sch Comp, Kattankulathur, Tamilnadu, India.
   [Bharathy, A. M. Viswa] Anna Univ, Dept CSE, Chennai, Tamilnadu, India.
   [Ramakuri, Sravanth Kumar] VNRVJIET, Dept ECE, Hyderabad, Telangana, India.
   [Sethy, Abhisek] Silicon Inst Technol, Dept CSE, Bhubaneswar 751024, Odisha, India.
   [Kumar, Ravi] Jaypee Univ Engn & Technol, Dept ECE, Guna, India.
C3 SRM Institute of Science & Technology Chennai; Anna University; Anna
   University Chennai; Vallurupalli Nageswara Rao Vignana Jyothi Institute
   of Engineering &Technology (VNR VJIET); Silicon Institute of Technology
RP Srinivas, LNB (corresponding author), SRM Inst Sci & Technol, Sch Comp, Kattankulathur, Tamilnadu, India.
EM balamuruganks.vital@gmail.com
RI KUMAR, RAVI/J-5961-2013; Ramakuri, sravanth Kumar/R-1123-2017
OI KUMAR, RAVI/0000-0001-9922-9064; Ramakuri, sravanth
   Kumar/0000-0002-8001-874X
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Alarcon P, 2021, FRONT SUSTAIN FOOD S, V5, DOI 10.3389/fsufs.2021.642635
   Ang KL, 2021, BIG DATA MACHINE LEA
   Antar M, 2021, RENEW SUST ENERG REV, V139, DOI 10.1016/j.rser.2020.110691
   Arif I, 2020, TRENDS BIOTECHNOL, V38, P1385, DOI 10.1016/j.tibtech.2020.04.015
   Ashapure A, 2020, ISPRS J PHOTOGRAMM, V169, P180, DOI 10.1016/j.isprsjprs.2020.09.015
   Balasundram SK, 2020, SUST PLANT CROP PRO, V13, P259, DOI 10.1007/978-3-030-35955-3_13
   Ceballos F, 2020, WORLD DEV, V136, DOI 10.1016/j.worlddev.2020.105069
   Chamuah A, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1901-6
   Chao XF, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071065
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   de Bang TC, 2021, NEW PHYTOL, V229, P2446, DOI 10.1111/nph.17074
   de la Rosa Guadalupe, 2021, Nanotechnology for Environmental Engineering, V6, DOI 10.1007/s41204-020-00100-1
   Flood J, 2010, FOOD SECUR, V2, P215, DOI 10.1007/s12571-010-0072-5
   Gabriel D, 2020, GENUS CITRUS, P371, DOI 10.1016/B978-0-12-812163-4.00018-8
   Harakannanavar S. S., 2022, Global Trans. Proc, V3, P305, DOI [10.1016/j.gltp.2022.03.016, DOI 10.1016/J.GLTP.2022.03.016]
   Holmelin NB, 2021, J RURAL STUD, V83, P71, DOI 10.1016/j.jrurstud.2021.02.009
   Hu WJ, 2020, IEEE ACCESS, V8, P115287, DOI 10.1109/ACCESS.2020.3001237
   Khan S, 2020, J PHYS C SERIES, V1432
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Li Y, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103852
   Selvaraj MG, 2020, ISPRS J PHOTOGRAMM, V169, P110, DOI 10.1016/j.isprsjprs.2020.08.025
   Shahzad A, 2021, ENVIRON SCI POLLUT R, V28, P14211, DOI 10.1007/s11356-021-12649-8
   Snelder DJ, 2008, CROP PROT, V27, P747, DOI 10.1016/j.cropro.2007.10.011
   Srivastava S., 2020, SN Computer Science, DOI [DOI 10.1007/S42979-020-0094-9, 10.1007/s42979-020-0094-9]
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Talari G., 2021, TRENDS FOOD SCI TECH
   Tiwari P., 2020, Agriculturally Important Fungi for Sustainable Agriculture, P171
   Zin NA, 2020, ANN AGR SCI-CAIRO, V65, P168, DOI 10.1016/j.aoas.2020.09.003
NR 30
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 8
PY 2023
DI 10.1007/s11042-023-15446-2
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7FF6
UT WOS:000983956900003
DA 2024-07-18
ER

PT J
AU Echtioui, A
   Zouch, W
   Ghorbel, M
   Mhiri, C
AF Echtioui, Amira
   Zouch, Wassim
   Ghorbel, Mohamed
   Mhiri, Chokri
TI Convolutional neural network with support vector machine for motor
   imagery EEG signal classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MI; CNN; LSTM; SVM
ID RECOGNITION
AB Electroencephalography (EEG) motor imagery (MI) signals has recently attracted a great deal of attention as these signals encrypt a person's desire of executing a command. MI signals are used to assist disabled people and even for autonomous driving through some control devices like wheelchairs just by thinking about it. Therefore, an accurate MI tasks classification from EEG signals is cricial to get a reliable Brain Computer Interface (BCI) system. In this paper, we proposed a new method of classifying MI tasks based on Convolutional Neural Network (CNN) methods. We applied a simple preprocessing to the data followed by a feature extraction step using Common Spatial Pattern (CSP) to extract spatial features and Wavelet Packet Decomposition (WPD) to extract frequency-time features. We then tested our four proposed models: CNN, CNN+LSTM, CNN-SVM and CNN+LSTM-SVM using BCI Competition IV 2a dataset. The obtained experimental results show that the proposed CNN-SVM gives the best results. Our results are really promising achieving interesting accuracy, precision, recall, and F1 score of 64.33%, 65.05%, 66.11%, et 64.11%, respectively.
C1 [Echtioui, Amira; Ghorbel, Mohamed] Sfax Univ, ATMS Lab, Adv Technol Med & Signals, ENIS, Sfax, Tunisia.
   [Zouch, Wassim] King Abdulaziz Univ KAU, Jeddah, Saudi Arabia.
   [Mhiri, Chokri] Habib Bourguiba Univ Hosp, Dept Neurol, Sfax, Tunisia.
   [Mhiri, Chokri] Sfax Univ, Fac Med, Neurosci Lab LR 12 SP 19, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); King
   Abdulaziz University; Universite de Sfax; Hopital Habib Bourguiba;
   Universite de Sfax
RP Echtioui, A (corresponding author), Sfax Univ, ATMS Lab, Adv Technol Med & Signals, ENIS, Sfax, Tunisia.
EM echtiouiamira@yahoo.fr
RI ZOUCH, Wassim/I-7791-2013
OI Echtioui, Amira/0000-0003-2041-1301
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Arshad J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110813
   Bashivan P., 2015, ARXIV
   Bengio Y, 2015, CORRABS150204390
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Grosse-Wentrup M, 2009, IEEE T BIO-MED ENG, V56, P1209, DOI 10.1109/TBME.2008.2009768
   Hou Y, 2022, FRONT BIOENG BIOTECH
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Kumar Shiu, 2016, 2016 3rd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE), P34, DOI 10.1109/APWC-on-CSE.2016.017
   Majidov I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071736
   Parra LC, 2005, NEUROIMAGE, V28, P326, DOI 10.1016/j.neuroimage.2005.05.032
   Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946
   Sakhavi S, 2017, I IEEE EMBS C NEUR E, P588, DOI 10.1109/NER.2017.8008420
   Sakhavi S, 2015, EUR SIGNAL PR CONF, P2736, DOI 10.1109/EUSIPCO.2015.7362882
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Nguyen T, 2018, IEEE ACCESS, V6, P27873, DOI 10.1109/ACCESS.2018.2841051
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Ward R, 2019, PR MACH LEARN RES, V97
   Yu ZY, 2022, INT J NEURAL SYST, V32, DOI 10.1142/S0129065722500320
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zheng W., 2009, P ADV NEUR INF PROC, P2268
   Zhu XY, 2019, BIOMED SIGNAL PROCES, V49, P396, DOI 10.1016/j.bspc.2018.12.027
NR 25
TC 0
Z9 0
U1 8
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45891
EP 45911
DI 10.1007/s11042-023-15468-w
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900006
DA 2024-07-18
ER

PT J
AU Rashid, M
   Singh, H
   Goyal, V
AF Rashid, Mamoon
   Singh, Harjeet
   Goyal, Vishal
TI FFTPSOGA: Fast Fourier Transform with particle swarm optimization and
   genetic algorithm approach for pattern identification of brain responses
   in multi subject fMRI data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Feature extraction; fMRI; Brain images; Fourier
   transform; Pattern identification; Neural activity; Voxel; Regions of
   interest
ID FEATURE-SELECTION; MUTUAL INFORMATION; FEATURE-EXTRACTION; RECOGNITION;
   MODEL
AB Functional Magnetic Resonance Imaging (fMRI) is the popular technique where it is possible to capture neural activity in brain regions when subjected to different stimuli. However, due to fMRI datasets' high dimensional and sparse nature, the best features' selection plays an essential role in providing the best classification accuracy in fMRI models. This paper selects the stable feature set from the fMRI dataset using hybrid Fast Fourier Transform with Particle Swarm Optimization and Genetic Algorithm (FFTPSOGA). Fast Fourier Transform (FFT) is used on the extracted features by PSO-GA to convert the magnitude of features into phase values for better performance. Next, the machine learning algorithms of GaussianNB, Support Vector Machine (SVM), and XGboost has been trained based on these extracted features of six subjects of the dataset. The experimental analysis reveals that the proposed algorithm resulted in optimum features that helped extract informative Regions of Interest (ROI) with better classification accuracy. Our implemented algorithm FFTPSOGA extracted the best voxels in six subjects of the dataset by selecting minimum ROIs with a model classification accuracy of 0.98, 0.95, 0.95, 0.95, 0.97, and 0.96 for the SVM classifier. Comparison of the proposed scheme with state-of-the-art techniques show that our algorithm resulted in best voxels and outperformed work in [1, 9, 25] by achieving higher accuracy of 98% and low computational costs with only 127 number of features. Due to its better performance, we believe that it can be used for the pattern identification of brain responses in multi-subject fMRI data.
C1 [Rashid, Mamoon] Punjabi Univ, Dept Comp Sci & Engn, Patiala, India.
   [Singh, Harjeet] Mata Gujri Coll, Dept Comp Sci, Sahib, Fatehgarh, India.
   [Goyal, Vishal] Punjabi Univ, Dept Comp Sci, Patiala, India.
C3 Punjabi University; Punjabi University
RP Rashid, M (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala, India.
EM mamoon873@gmail.com
RI Rashid, Mamoon/AAB-7135-2020
OI Rashid, Mamoon/0000-0002-8302-4571
CR Albalawi F, 2020, IEEE ACCESS, V8, P121451, DOI 10.1109/ACCESS.2020.3006521
   Anter AM, 2019, INFORM SCIENCES, V503, P670, DOI 10.1016/j.ins.2019.07.026
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chen JYE, 2015, NEUROPSYCHOL REV, V25, P289, DOI 10.1007/s11065-015-9294-9
   Cohen JD, 2017, NAT NEUROSCI, V20, P304, DOI 10.1038/nn.4499
   Eklund A, 2012, COMPUT METH PROG BIO, V105, P145, DOI 10.1016/j.cmpb.2011.07.007
   Erhardt EB, 2011, HUM BRAIN MAPP, V32, P2075, DOI 10.1002/hbm.21170
   Fan Miaolin, 2016, Brain Inform, V3, P193, DOI 10.1007/s40708-016-0048-0
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Ghamisi P, 2015, IEEE GEOSCI REMOTE S, V12, P309, DOI 10.1109/LGRS.2014.2337320
   Jin B, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S9-S15
   Kassraian-Fard P, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00177
   Kauttonen J, 2015, NEUROIMAGE, V110, P136, DOI 10.1016/j.neuroimage.2015.01.063
   Korhonen O, 2017, NETW NEUROSCI, V1, P254, DOI [10.1162/NETN_a_00013, 10.1162/netn_a_00013]
   Lahiri R, 2017, BIOMED SIGNAL PROCES, V36, P113, DOI 10.1016/j.bspc.2017.03.022
   Liu JD, 2020, IEEE J BIOMED HEALTH, V24, P2028, DOI 10.1109/JBHI.2019.2946676
   Ma Xinpei, 2016, Brain Inform, V3, P181, DOI 10.1007/s40708-016-0049-z
   Metawa N, 2017, EXPERT SYST APPL, V80, P75, DOI 10.1016/j.eswa.2017.03.021
   Michel V, 2008, I S BIOMED IMAGING, P592, DOI 10.1109/ISBI.2008.4541065
   Mirzaei S, 2019, J NEUROSCI METH, V318, P47, DOI 10.1016/j.jneumeth.2019.02.014
   Ota K, 2015, J NEUROSCI METH, V256, P168, DOI 10.1016/j.jneumeth.2015.08.020
   Paul S, 2015, PATTERN RECOGN LETT, V65, P51, DOI 10.1016/j.patrec.2015.07.007
   Poldrack RA, 2012, NEUROIMAGE, V62, P1216, DOI 10.1016/j.neuroimage.2011.08.007
   Ramakrishna JS, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1092, DOI 10.1109/ICACCI.2017.8125987
   Rashid M, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12644
   Satoru, 2016, 2016 IEEE S SER COMP, P1, DOI DOI 10.1109/SSCI.2016.7850135
   Sengupta S, 2019, MACH LEARN KNOW EXTR, V1, P157, DOI 10.3390/make1010010
   Serra A, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1248
   Shahamat H., 2015, J AI DATA MIN, V3, P30, DOI DOI 10.5829/ID0SI.JAIDM.2015.03.01.04
   Shi YH, 2018, IEEE T NEUR SYS REH, V26, P1690, DOI 10.1109/TNSRE.2018.2857501
   Sidhu G, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2936348
   Smith SM, 2014, NEUROIMAGE, V101, P738, DOI 10.1016/j.neuroimage.2014.07.051
   Song YY, 2019, APPL INTELL, V49, P1880, DOI 10.1007/s10489-018-1370-4
   Sumanaweera T., 2005, GPU GEMS 2, P765
   Tian DP, 2018, SWARM EVOL COMPUT, V41, P49, DOI 10.1016/j.swevo.2018.01.011
   Tom Mitchell WW, STARPLUS FMRI DATA
   Wang YB, 2016, J X-RAY SCI TECHNOL, V24, P467, DOI 10.3233/XST-160565
   Xu WY, 2020, J NEUROSCI METH, V335, DOI 10.1016/j.jneumeth.2019.108567
   Yang ZS, 2020, NEUROIMAGE, V223, DOI 10.1016/j.neuroimage.2020.117340
   Young KS, 2018, NEUROSCI BIOBEHAV R, V84, P424, DOI 10.1016/j.neubiorev.2017.08.003
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
NR 42
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45433
EP 45452
DI 10.1007/s11042-023-15471-1
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000982739000001
DA 2024-07-18
ER

PT J
AU Sabbane, F
   Tairi, H
AF Sabbane, Fadoua
   Tairi, Hamid
TI Watermarking approach based on Hermite transform and a sliding window
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical data security; Watermarking; Robustness; Hermite transform;
   Sliding windows; Texture extraction
ID MEDICAL IMAGES; ALGEBRA; SECURE
AB Nowadays, the distribution of huge amounts of medical images through open networks in telemedicine applications has become increasingly faster and easier. Therefore, a number of considerations are introduced related to the risks of the illegal use of these images, as total diagnosis depends on them. Indeed, the patient's data management, storage, and transmission require a technique for boosting security, integrity and privacy measures in telehealthcare services. In fact, in our previous works, we used polynomial decompositions such as Chebychev orthogonal polynomial transform in medical image watermarking. We then customise our tools for finding the best candidate area for embedding the watermark, always seeking to provide the best solution to this issue. In this research, a variation to medical image watermarking approach based on Hermite transform (HT) is suggested for reliable management of medical data. In this approach, the HT is employed as a preprocessing step so as to extract the texture component of the host medical image. Afterward, a sliding window technique is done to select the most suitable regions for watermark embedding. Lastly, the Arnold transform is utilized for encrypting the watermark to strengthen the security of our scheme. Experiments were conducted on various modalities of medical images. Results indicate that the proposed scheme is robust when subjected to various attacks while preserving a high level of security and invisibility factors. Also, our method preserves the quality of medical images with a good embedding capacity. The obtained results support the use of Hermite Polynomials for the implementation of watermarking in the medical imaging context.
C1 [Sabbane, Fadoua; Tairi, Hamid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LISAC Lab, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Sabbane, F (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LISAC Lab, Fes, Morocco.
EM sabbane.fadoua@gmail.com; htairi@yahoo.fr
CR Abdulfetah Ahmed A., 2010, Information Technology Journal, V9, P460, DOI 10.3923/itj.2010.460.466
   Al-Haj AM, 2010, ADV TECHNIQUES MULTI
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Barba-J L., 2020, Journal of Physics: Conference Series, V1547, DOI 10.1088/1742-6596/1547/1/012017
   Bastani A, 2020, RADIOENGINEERING, V29, P636, DOI 10.13164/re.2020.0636
   Berghel H, 1996, COMPUTER, V29, P101, DOI 10.1109/2.511977
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   EDEN M, 1986, SIGNAL PROCESS, V10, P385, DOI 10.1016/0165-1684(86)90046-0
   Ernawan F, 2023, MULTIMED TOOLS APPL, V82, P27123, DOI 10.1007/s11042-023-14447-5
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Gomez-Coronel SL, 2020, 16 INT S MED INF PRO, P34
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Hu RW, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107833
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Martens J-B, 2003, IMAGE TECHNOLOGY DES
   MARTENS JB, 1990, IEEE T ACOUST SPEECH, V38, P1607, DOI 10.1109/29.60076
   Martens JB, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/26145
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Panah AS, 2016, IEEE ACCESS, V4, P2670, DOI 10.1109/ACCESS.2016.2570812
   Patil N, 2019, DEV REVERSIBLE VIDEO, V8, P5
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Ramly S, 2011, COMM COM INF SC, V194, P372
   Rani N., 2012, GLOB J COMPUT SCI, V12, P1
   Rivero-Moreno CJ, 2004, INT C PATT RECOG, P684, DOI 10.1109/ICPR.2004.1334266
   Sabbane F, 2019, P NEW CHALL DAT SCI, P1
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Sharma S, 2023, MULTIMED TOOLS APPL, V82, P2207, DOI 10.1007/s11042-022-13207-1
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh KU, 2022, MULTIMED TOOLS APPL, V81, P39577, DOI 10.1007/s11042-022-12192-9
   Singh MK, 2021, IET IMAGE PROCESS, V15, P666, DOI 10.1049/ipr2.12052
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   van Dijk A. M., 1996, Proceedings. International Conference on Image Processing (Cat. No.96CH35919), P205, DOI 10.1109/ICIP.1996.559469
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Xiao B, 2020, INFORM SCIENCES, V516, P545, DOI 10.1016/j.ins.2019.12.044
   Xie HW, 2023, MULTIMED TOOLS APPL, V82, P27593, DOI 10.1007/s11042-023-14546-3
   Young RA, 1985, GAUSSIAN DERIVATIVE
NR 50
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47635
EP 47667
DI 10.1007/s11042-023-15324-x
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000008
PM 37362669
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chen, R
   Zhang, F
   Teng, L
   Wang, XY
AF Chen, Rong
   Zhang, Fan
   Teng, Lin
   Wang, Xingyuan
TI Medical image characteristic region recognition encryption algorithm
   based on intra and inter blocks scrambling and LSCC chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image characteristic region recognition; Intra and inter blocks
   scrambling; LSCC chaotic system
ID SEMI-TENSOR PRODUCT; MATRIX; SYSTEM
AB In recent years, telemedicine has received widespread attention. It is very necessary to encrypt medical images, especially the feature areas of images. Based on the chaotic model of Logistic mapping and Sine mapping, a new chaotic system of cross-combination mapping (LSCC) is proposed. A large number of tests show that LSCC chaotic system has good cryptographic characteristics. Based on LSCC mapping, a medical image feature region recognition encryption algorithm is proposed. Firstly, the binary method is used to recognize and extract the feature area of the image. Then, in the scrambling stage, we use our newly proposed intra-block scrambling method and inter-block scrambling method to scramble the feature area and the entire image. The chaotic sequence generated by the LSCC map is applied to each pixel value after nonlinear operation to achieve diffusion effect. After analyzing the performance test results, our cryptographic system has high security and can achieve the purpose of encrypting medical images and protecting image privacy information.
C1 [Chen, Rong; Zhang, Fan; Teng, Lin; Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Zhang, F; Teng, L (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM fanzhang963@163.com; tenglin@dlmu.edu.cn
OI Teng, Lin/0000-0002-3758-4439; Zhang, Fan/0000-0002-1337-578X
FU National Natural Science Foundation of China [61701070, 61672124]; Key
   R&D Projects of Liaoning Province [2019020105-JH2/103]; Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project [XLYC1802013]; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining Security [MIMS20-M-02]
FX The work is funded by the National Natural Science Foundation of China
   (Nos: 61701070, 61672124), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Liaoning Province Science and Technology Innovation
   Leading Talents Program Project (No: XLYC1802013), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Abdallah EE, 2006, INT C PATT RECOG, P673
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   García-Guerrero EE, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109646
   De la Fraga LG, 2021, NONLINEAR DYNAM, V104, P4569, DOI 10.1007/s11071-021-06491-3
   Hanif M, 2020, IEEE ACCESS, V8, P146408, DOI 10.1109/ACCESS.2020.3015085
   Hazer A, 2021, J OPTICS-UK, V23, DOI 10.1088/2040-8986/ac2463
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Hu GZ, 2021, NONLINEAR DYNAM, V103, P2819, DOI 10.1007/s11071-021-06228-2
   Ibrahim S, 2020, IEEE ACCESS, V8, P160433, DOI 10.1109/ACCESS.2020.3020746
   Kang SW, 2022, MULTIMED TOOLS APPL, V81, P1209, DOI 10.1007/s11042-021-11424-8
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Liu S, 2021, TECHNOL HEALTH CARE, V29, pS185, DOI 10.3233/THC-218019
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Nie Z, 2019, OPT APPL, V49, P545, DOI 10.37190/oa190402
   Ponnaboyina R, 2022, SOFT COMPUT, V26, P6255, DOI 10.1007/s00500-022-07164-y
   Qobbi Y, 2022, SOFT COMPUT, V26, P5823, DOI 10.1007/s00500-021-06567-7
   Qumsieh R, 2019, MULTIMED TOOLS APPL, V78, P33527, DOI 10.1007/s11042-019-08112-z
   Raj V, 2021, J INTELL FUZZY SYST, V40, P10385, DOI 10.3233/JIFS-200203
   Sarosh P, 2022, MULTIMED TOOLS APPL, V81, P7253, DOI 10.1007/s11042-021-11812-0
   Singh S, 2022, IEEE INTERNET THINGS, V9, P7481, DOI 10.1109/JIOT.2021.3108875
   Sivaraman R, 2020, MULTIMED TOOLS APPL, V79, P13841, DOI 10.1007/s11042-019-08592-z
   Song W, 2022, NEURAL COMPUT APPL, V34, P5743, DOI 10.1007/s00521-021-06725-w
   Soualmi A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6480
   Trujillo-Toledo DA, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111506
   Vagish KD, 2020, MULTIMED TOOLS APPL, V79, P23849, DOI 10.1007/s11042-020-09043-w
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110962
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wen WY, 2023, MULTIMEDIA SYST, V29, P1073, DOI 10.1007/s00530-022-01037-y
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xian YS, 2022, INT J COAL PREP UTIL, V42, P3249, DOI 10.1080/19392699.2021.1949712
   Yahi A, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168290
   Zhang M, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23081096
   Zhou S, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110225
   Zhou S, 2019, CHAOS, V29, DOI 10.1063/1.5087512
NR 49
TC 1
Z9 1
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45839
EP 45867
DI 10.1007/s11042-023-15458-y
EA APR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000979936300009
DA 2024-07-18
ER

PT J
AU Ahangi, A
   Möckel, R
AF Ahangi, Amir
   Mockel, Rico
TI Switching network for mixing experts with application to traffic sign
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic sign; Ensemble learning; Mixture of experts; Deep learning
ID DEEP NEURAL-NETWORK; ENSEMBLE; MIXTURE
AB The correct and robust recognition of traffic signs is indispensable to self-driving vehicles and driver-assistant systems. In this work, we propose and evaluate two network architectures for multi-expert decision systems that we test on a challenging Traffic Sign Recognition Benchmark dataset. The decision systems implement individual experts in the form of deep convolutional neural networks (CNNs). A gating network CNN acts as final decision unit and learns which individual expert CNNs are likely to contribute to an overall meaningful classification of a traffic sign. The gating network then selects the outputs of those individual expert CNNs to be fused to form the final decision. In this work we study the advantages and challenges of the proposed multi-expert architectures that in comparison to other network architectures allow for parallel training of individual experts with reduced datasets. Under the challenging conditions introduced by the benchmark dataset, the demonstrated multi-expert decision systems achieve a recognition performance that is superior to those of humans: with an accuracy of 99.10%, when training experts with the complete dataset and 98.94%, when individual experts are only trained with 36% of the training samples. Overall, our approach ranked fourth on the list of the applied approaches proposed for the German traffic sign Recognition Benchmark (GTSRB) dataset.
C1 [Ahangi, Amir; Mockel, Rico] Maastricht Univ, Dept Adv Comp Sci DACS, Maastricht, Netherlands.
C3 Maastricht University
RP Ahangi, A (corresponding author), Maastricht Univ, Dept Adv Comp Sci DACS, Maastricht, Netherlands.
EM amir.ahangi@maastrichtuniversity.nl; rico.mockel@maastrichtuniversity.nl
OI Mockel, Rico/0000-0001-5497-3754
FU Dutch National Science Foundation NWO [439.16.108]
FX We thank the Dutch National Science Foundation NWO for financial support
   through the project SWARMPORT (NWO project number 439.16.108).
CR Ahangi A, 2019, MULTIMED TOOLS APPL, V78, P20217, DOI 10.1007/s11042-019-7391-0
   Ahangi A, 2013, NEURAL COMPUT APPL, V23, P1319, DOI 10.1007/s00521-012-1074-3
   Arcos-García A, 2018, NEURAL NETWORKS, V99, P158, DOI 10.1016/j.neunet.2018.01.005
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Ciresan DC, 2011, PROC INT CONF DOC, P1135, DOI 10.1109/ICDAR.2011.229
   Combining pattern classifiers, 2014, Methods and algorithms, V2nd
   Deng L., 2014, 15 ANN C INT SPEECH, V2014, P1915, DOI [10.21437/Interspeech.2014-433, DOI 10.21437/INTERSPEECH.2014-433]
   Gecer B, 2017, IMAGE VISION COMPUT, V57, P165, DOI 10.1016/j.imavis.2016.10.006
   Gopalakrishnan S, 2012, J Family Med Prim Care, V1, P144, DOI 10.4103/2249-4863.104987
   Haloi M, 2016, Arxiv, DOI arXiv:1511.02992
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Maji D., 2016, ENSEMBLE DEEP CONVOL
   Masoudnia S, 2014, ARTIF INTELL REV, V42, P275, DOI 10.1007/s10462-012-9338-y
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Prieto A, 2016, NEUROCOMPUTING, V214, P242, DOI 10.1016/j.neucom.2016.06.014
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Shopa P, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Sun ZL, 2014, NEUROCOMPUTING, V128, P153, DOI 10.1016/j.neucom.2012.11.057
   Wang HZ, 2017, APPL ENERG, V188, P56, DOI 10.1016/j.apenergy.2016.11.111
   Zaklouta F, 2014, ROBOT AUTON SYST, V62, P16, DOI 10.1016/j.robot.2012.07.019
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P967, DOI 10.1109/TASLP.2016.2536478
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
NR 36
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43841
EP 43864
DI 10.1007/s11042-023-14959-0
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001066758900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, Y
   Zhou, LL
AF Huang, Yi
   Zhou, Lili
TI A hyper-chaos-based image encryption scheme with double parity alternate
   scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Parity alternate scrambling; Hyper-chaotic system;
   Bit-plane parity scrambling
ID SYSTEM
AB Due to the complex dynamic characteristics, randomness, larger key space and better sensitivity of hyper-chaotic system, it is very suitable for the application in image encryption. This paper mainly proposes a double parity alternate-based image encryption scheme with a four-dimensional hyper-chaotic system. The key stream, produced by the hyper-chaotic system, is closely relevant to the plain-text image. First of all, parity alternate scrambling is used to change the image pixel position, and then bit-plane parity alternate scrambling is used, which can not only change the position but also change the pixel value. Finally, the key stream generated by the hyper-chaotic system is used to diffuse the image to make the encryption system more secure. Additionally, the use of the double parity alternate scrambling and diffusion can make the pixel value distribution of the image be more uniform, and the given scheme is not only simple and easy to implement but also can resist some attacks effectively, such as differential attacks, statistical attacks, and etc. Theoretical analysis and numerical simulation show that the given scheme has good safety performance and good reliability for image encryption.
C1 [Huang, Yi; Zhou, Lili] Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Peoples R China.
C3 Xiangtan University
RP Zhou, LL (corresponding author), Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Peoples R China.
EM joe_lily@126.com
RI Zhou, Lili/J-5687-2016
OI Zhou, Lili/0000-0002-8602-2141
FU National Natural Science Foundation of China [11747141]; Natural Science
   Foundation of Hunan Province [2018JJ3512]; Scientific Research
   Foundation of Hunan Provincial Education Department [21B0178]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (No.11747141), in part by the Natural
   Science Foundation of Hunan Province (No.2018JJ3512), and in part by the
   Scientific Research Foundation of Hunan Provincial Education Department
   under Grant 21B0178.
CR Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Kaur S, 2022, INT J INTERACT MULTI, V7, P48, DOI 10.9781/ijimai.2022.01.004
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li XH, 2022, SOFT COMPUT, V26, P511, DOI 10.1007/s00500-021-06500-y
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Liu S, 2022, IEEE MULTIMEDIA, V29, P74, DOI 10.1109/MMUL.2021.3114589
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   Luo YL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105836
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Srivastava V, 2021, INT J INTERACT MULTI, V6, P18, DOI 10.9781/ijimai.2020.11.003
   Tsohou A, 2015, COMPUT SECUR, V52, P128, DOI 10.1016/j.cose.2015.04.006
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2016, OPT LASER ENG, V86, P248, DOI 10.1016/j.optlaseng.2016.06.008
   Wang XY, 2023, SOFT COMPUT, V27, P1223, DOI 10.1007/s00500-022-07706-4
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2016, MULTIMED TOOLS APPL, V75, P11433, DOI 10.1007/s11042-015-2861-5
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Zhang Y, 2017, OPT COMMUN, V392, P223, DOI 10.1016/j.optcom.2017.01.061
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhou LL, 2020, IEEE SYST J, V14, P2508, DOI 10.1109/JSYST.2019.2927495
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
NR 37
TC 4
Z9 4
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41879
EP 41893
DI 10.1007/s11042-023-15012-w
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000973357400004
DA 2024-07-18
ER

PT J
AU Khan, SD
   Alarabi, L
   Basalamah, S
AF Khan, Sultan Daud
   Alarabi, Louai
   Basalamah, Saleh
TI Segmentation of farmlands in aerial images by deep learning framework
   with feature fusion and context aggregation modules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart farming; Agriculture; Semantic segmentation; Deep learning; Aerial
   images
ID SEMANTIC SEGMENTATION; AGRICULTURE
AB Automated segmentation of farmland patterns in high resolution aerial images is very crucial for smart farming. Recently, deep learning techniques have achieved tremendous success in various semantic segmentation tasks, however, little efforts have been made in farmland semantic segmentation in high resolution aerial images. Farmland semantic segmentation in aerial images is a challenging task due to large variation in scales and shapes of agriculture patterns. Furthermore, different agriculture patterns share similar visual features that usually result in mis-classifications of pixels. To efficiently tackle these problems, we propose a deep learning framework that captures scene context and aggregate multi-scale information from different convolutional blocks. Generally, the framework consists of two main modules:(1) feature fusion module and (2) global contextual module. Feature fusion module combines the feature maps of different convolutional blocks to capture wide variation in object scales, while global contextual module aggregate rich contextual information from different regions of the image by employing pyramid pooling module. We gauge the performance of proposed framework on challenging benchmarks dataset, Agriculture-vision and also compare our results with various state-of-the-art methods. From experiment results, we demonstrate that the proposed framework achieves best performance in identifying various complex agriculture patterns and supersedes state-of-the-art methods.
C1 [Khan, Sultan Daud] Natl Univ Technol, Dept Comp Sci, Islamabad, Pakistan.
   [Alarabi, Louai] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Basalamah, Saleh] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Khan, SD (corresponding author), Natl Univ Technol, Dept Comp Sci, Islamabad, Pakistan.
EM sultandaud@nutech.edu.pk; lmarabi@uqu.edu.sa; smbasalamah@uqu.edu.sa
OI khan, sultan/0000-0002-7406-8441
FU National University of Technology, Islamabad, Pakistan; Umm Al-Qura
   University, Makkah, Saudi Arabia
FX This work is jointly supported by National University of Technology,
   Islamabad, Pakistan and Umm Al-Qura University, Makkah, Saudi Arabia
CR Al-amri Salem Saleh., 2010, Journal of Computing, V2, P83
   Arbeláez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhatnagar V, 2020, STUD BIG DATA, V67, P1, DOI 10.1007/978-981-15-0663-5_1
   Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI [10.1109/ICIP.2019.8803050, 10.1109/icip.2019.8803050]
   Cao GM, 2018, PROC SPIE, V10615, DOI 10.1117/12.2304811
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chen BY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040731
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng D, 2019, PROC CVPR IEEE, P7423, DOI 10.1109/CVPR.2019.00761
   Chiu MT, 2020, PROC CVPR IEEE, P2825, DOI 10.1109/CVPR42600.2020.00290
   Csurka G, 2008, BMVC, P1
   Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8
   Cui ZP, 2017, IEEE IMAGE PROC, P3100, DOI 10.1109/ICIP.2017.8296853
   Dankhara F, 2019, PROCEDIA COMPUT SCI, V160, P696, DOI 10.1016/j.procs.2019.11.025
   Demir I, 2018, IEEE COMPUT SOC CONF, P172, DOI 10.1109/CVPRW.2018.00031
   Ding L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3079925
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao X, 2020, J PHYS C SERIES, V1651
   Goap A, 2018, COMPUT ELECTRON AGR, V155, P41, DOI 10.1016/j.compag.2018.09.040
   Gonçalves P, 2021, ANIMALS-BASEL, V11, DOI 10.3390/ani11092625
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Gupta R, 2021, INT C PATT RECOG, P4405, DOI 10.1109/ICPR48806.2021.9412295
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He NJ, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2791-7
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Jung H, 2017, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2017.129
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kanna SKR, 2021, ARTIF INTELL, P229, DOI DOI 10.1002/9781119760429.CH13
   Khan SD, 2021, INFORMATION, V12, DOI 10.3390/info12060230
   Khan SD, 2021, INT J COMPUT INT SYS, V14, P1217, DOI 10.2991/ijcis.d.210326.001
   Kuo TS, 2018, IEEE COMPUT SOC CONF, P247, DOI 10.1109/CVPRW.2018.00046
   Lee K., 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, P7068
   Lempitsky V, 2011, ADV NEURAL INFORM PR, P1485
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu QH, 2020, IEEE COMPUT SOC CONF, P199, DOI 10.1109/CVPRW50498.2020.00030
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2013, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2013.270
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Mohammadimanesh F, 2019, ISPRS J PHOTOGRAMM, V151, P223, DOI 10.1016/j.isprsjprs.2019.03.015
   Nekrasov V, 2018, ARXIV
   Nobrega L, 2017, INT C INFORM COMMUNI, P131
   Pan TS, 2021, SIGNAL IMAGE VIDEO P, V15, P941, DOI 10.1007/s11760-020-01818-w
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Pascual G, 2018, IEEE COMPUT SOC CONF, P276, DOI 10.1109/CVPRW.2018.00052
   Patil K. A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P543, DOI 10.1109/ICGTSPICC.2016.7955360
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091432
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, P257, DOI 10.1109/CVPRW.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saraf SB, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P815, DOI 10.1109/RTEICT.2017.8256711
   Schroff F, 2008, P BRIT MACH VIS C, P1
   Seferbekov S, 2018, IEEE COMPUT SOC CONF, P272, DOI 10.1109/CVPRW.2018.00051
   Shang RH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050872
   Sheng H, 2020, IEEE COMPUT SOC CONF, P267, DOI 10.1109/CVPRW50498.2020.00038
   Sreekantha DK, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P134, DOI 10.1109/ISCO.2017.7855968
   Sun W, 2020, PROC SPIE, V11528, DOI 10.1117/12.2573244
   Sushanth G, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Thenkabail PS, 2010, REMOTE SENS-BASEL, V2, P2305, DOI 10.3390/rs2092305
   Tian C, 2018, IEEE COMPUT SOC CONF, P262, DOI 10.1109/CVPRW.2018.00049
   Tian Hong-kun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Vezhnevets A, 2011, IEEE I CONF COMP VIS, P643, DOI 10.1109/ICCV.2011.6126299
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Xia KJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1116-1
   Xia W, 2013, IEEE I CONF COMP VIS, P2176, DOI 10.1109/ICCV.2013.271
   Xu L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020108
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yang SW, 2020, IEEE COMPUT SOC CONF, P206, DOI 10.1109/CVPRW50498.2020.00031
   Yang X, 2021, IEEE-CAA J AUTOMATIC, V8, P273, DOI 10.1109/JAS.2020.1003536
   Yu Y, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.06.001
   Zha K, 2018, IEEE COMPUT SOC CONF, P242, DOI 10.1109/CVPRW.2018.00045
   Zhang SY, 2019, 2019 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS 2019), DOI [10.1109/LGRS.2018.2888887, 10.1109/ieee-iws.2019.8803909]
   Zhang XX, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23040435
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou B., 2014, CORR, V1412, P6856
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 87
TC 2
Z9 2
U1 7
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42353
EP 42372
DI 10.1007/s11042-023-14962-5
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200003
DA 2024-07-18
ER

PT J
AU Oliva, D
   Ortega-Sanchez, N
   Navarro, MA
   Ramos-Michel, A
   El-Abd, M
   Mousavirad, SJ
   Nadimi-Shahraki, MH
AF Oliva, Diego
   Ortega-Sanchez, Noe
   Navarro, Mario A.
   Ramos-Michel, Alfonso
   El-Abd, Mohammed
   Mousavirad, Seyed Jalaleddin
   Nadimi-Shahraki, Mohammad H.
TI Segmentation of thermographies from electronic systems by using the
   global-best brain storm optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Minimum cross-entropy; Global-best brain storm
   optimization; Thermographies
ID RECOMMENDATION SYSTEM; ENTROPY; IMAGES
AB Segmentation is an important and basic task in image processing. Although no unique method is applicable to all types of images (as thermographies), multilevel thresholding is one of the most widely used techniques for this purpose. Multilevel thresholding segmentation has a major drawback that is to properly find the best configuration of thresholds. For that reason some metaheuristic algorithms are used to optimize the searching for the best thresholds. This paper proposes a combination of the minimum cross-entropy method and the Global-best brain storm optimization algorithm (GBSO), which improves the standard BSO to find the optimal solutions in complex search spaces. The GBSO uses a population of agents based on a global best and a re-initialization scheme that is triggered by the current state of its population. Here, the GBSO is used to find the best configuration of thresholds by optimizing the minimum cross entropy that is commonly using in image segmentation. Once the best thresholds are obtained they are applied over the images to extract only the regions of interest. For example, in the case of thermographies the parts with higher temperatures. To verify the performance of the proposed method it is firstly applied to classical reference images and after that over thermal images from electronic devices. The idea is to provide an alternative to segment thermographies that permits separating regions with higher temperatures. This could be used as a preprocessing step in a complex image processing system. The experimental result in terms of segmentation of electronic devices in thermographies provides evidence of the good performance of the GBSO. Different comparison with recent methods from the state-of-the-art were conducted where the GBSO obtains 1st place with the best values for the MCET. To validate the quality of segmentation they were used metrics as the peak signal-to-noise ratio (PSNR) where the GBSO is in the 4th rank of comparison, the structural similarity index (SSIM) and the feature similarity index (FSIM). For the FSIM and SSIM the GBSO in the 4th and 3rd rank, respectively.
C1 [Oliva, Diego; Ortega-Sanchez, Noe; Navarro, Mario A.; Ramos-Michel, Alfonso] Univ Guadalajara, Div Tecnol Integrac Ciber Humana, CUCEI, Guadalajara, Jal, Mexico.
   [El-Abd, Mohammed] Amer Univ Kuwait, Coll Engn & Appl Sci, Salmiya, Kuwait.
   [Mousavirad, Seyed Jalaleddin] Univ Beira Interior, Covilha, Portugal.
   [Nadimi-Shahraki, Mohammad H.] Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Najafabad, Iran.
   [Nadimi-Shahraki, Mohammad H.] Islamic Azad Univ, Big Data Res Ctr, Najafabad Branch, Najafabad, Iran.
C3 Universidad de Guadalajara; American University of Kuwait; Universidade
   da Beira Interior; Islamic Azad University; Islamic Azad University
RP Ramos-Michel, A (corresponding author), Univ Guadalajara, Div Tecnol Integrac Ciber Humana, CUCEI, Guadalajara, Jal, Mexico.
EM diego.oliva@cucei.udg.mx; noe.ortega@academicos.udg.mx;
   marioa.navarro@alumno.udg.mx; alfonso.rmichel@academicos.udg.mx;
   melabd@auk.edu.kw; jalalmoosavirad@gmail.com; nadimi@ieee.org
RI Nadimi-Shahraki, Mohammad H./Q-8701-2017; Mousavirad, Seyed
   Jalaleddin/O-3254-2019; NAVARRO VELAZQUEZ, MARIO ALBERTO/KFQ-4380-2024;
   Oliva, Diego/A-3271-2016; Ramos Michel, Afonso/HDO-7177-2022; El-Abd,
   Mohammed/I-7184-2019
OI Nadimi-Shahraki, Mohammad H./0000-0002-0135-1115; Mousavirad, Seyed
   Jalaleddin/0000-0001-8661-7578; NAVARRO VELAZQUEZ, MARIO
   ALBERTO/0000-0001-8231-7041; Oliva, Diego/0000-0001-8781-7993; Ramos
   Michel, Afonso/0000-0003-2419-9512; El-Abd, Mohammed/0000-0003-0938-8542
CR Abd Elaziz M, 2021, MULTIMED TOOLS APPL, V80, P12435, DOI 10.1007/s11042-020-10313-w
   Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P305, DOI 10.1016/j.eswa.2019.01.075
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Ahmadianfar I, 2020, INFORM SCIENCES, V540, P131, DOI 10.1016/j.ins.2020.06.037
   Al-amri S., 2010, International Journal on Computer Science and Engineering, V2, P804
   Angelina S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P970, DOI 10.1109/ICCEET.2012.6203833
   Aranguren I, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102259
   Ayaz H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146422
   Balaras CA, 2002, ENERG BUILDINGS, V34, P171, DOI 10.1016/S0378-7788(01)00105-0
   Bayzidi H, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8548639
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Dan Yi, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P101, DOI 10.1007/978-981-16-3013-2_9
   Dehariya VK, 2010, 2010 INT C COMP INT, P386
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   El-Abd M, 2017, SWARM EVOL COMPUT, V37, P27, DOI 10.1016/j.swevo.2017.05.001
   El-Abd M, 2016, IEEE C EVOL COMPUTAT, P2682, DOI 10.1109/CEC.2016.7744125
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Gong YJ, 2018, IEEE T IMAGE PROCESS, V27, P1390, DOI 10.1109/TIP.2017.2778569
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hernández G, 2020, IEEE LAT AM T, V18, P1371, DOI 10.1109/TLA.2020.9111672
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Huang KW, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P82, DOI 10.1109/ICASI.2018.8394392
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Khokher MR, 2013, IET IMAGE PROCESS, V7, P201, DOI 10.1049/iet-ipr.2012.0082
   KULLBACK S, 1968, ANN MATH STAT, V39, P1236, DOI 10.1214/aoms/1177698249
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y, 2022, LECT NOTES COMPUT SC, V13340, P386, DOI 10.1007/978-3-031-06791-4_31
   Lindeberg T, 1997, COMPUT VIS IMAGE UND, V67, P88, DOI 10.1006/cviu.1996.0510
   Liu HC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20175013
   Liu Wenyi, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1588), P350, DOI 10.1007/978-3-031-06764-8_28
   Mahdy LN, 2020, INT J IMAG SYST TECH, V30, P1256, DOI 10.1002/ima.22432
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   McGlen RJ, 2004, APPL THERM ENG, V24, P1143, DOI 10.1016/j.applthermaleng.2003.12.029
   Merzban MH, 2019, EXPERT SYST APPL, V116, P299, DOI 10.1016/j.eswa.2018.09.008
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Oliva D., 2019, METAHEURISTIC ALGORI, V825
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NR, 1996, PATTERN RECOGN, V29, P575, DOI 10.1016/0031-3203(95)00111-5
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pare S, 2020, IJST-T ELECTR ENG, V44, P1, DOI 10.1007/s40998-019-00251-1
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   Sathya SS, 2018, BIOINSPIRED COMPUTIN, V31
   Senthilkumaran N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P844, DOI 10.1109/ARTCom.2009.219
   Shi YH, 2015, ADV COMPU INTELL ROB, P1, DOI 10.4018/978-1-4666-6328-2.ch001
   Singh S, 2022, ADV MATER PROCESS TE, V8, P3074, DOI 10.1080/2374068X.2021.1945300
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Stoynova A, 2018, 2018 41 INT SPRING S, P1
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   Tuba E, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P240, DOI 10.1109/EMES.2017.7980424
   Turner TA, 2001, VET CLIN N AM-EQUINE, V17, P95, DOI 10.1016/S0749-0739(17)30077-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xie J, 2021, CONSTR BUILD MATER, V282, DOI 10.1016/j.conbuildmat.2021.122642
   Xiliang Xiao, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P75, DOI 10.1007/978-981-16-3013-2_7
   Xu L, 2019, IEEE ACCESS, V7, P19502, DOI 10.1109/ACCESS.2019.2896673
   Yambal M., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P2927
   YANG XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI [DOI 10.1504/IJBIC.2010.032124, 10.1504/IJBIC.2010.032124]
   Yangxiu Fang, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P61, DOI 10.1007/978-981-16-3013-2_6
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zemkoho, 2011, OPTIMIZATION PROBLEM
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y.-J., 2006, Advances in Image and Video Segmentation, P1, DOI DOI 10.4018/978-1-59140-753-9.CH001
   Zhao XL, 2016, APPL SOFT COMPUT, V48, P151, DOI 10.1016/j.asoc.2016.07.016
   Zhou Y, 2021, IEEE T ARTIF INTELL
   Zhou Y, 2022, IEEE T NEUR NET LEAR, V33, P4635, DOI 10.1109/TNNLS.2021.3059529
   Zhu YH, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1605-z
NR 83
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44911
EP 44941
DI 10.1007/s11042-023-15059-9
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000968176200006
DA 2024-07-18
ER

PT J
AU Kihal, M
   Hamza, L
AF Kihal, Marouane
   Hamza, Lamia
TI Robust multimedia spam filtering based on visual, textual, and audio
   deep features and random forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spam filtering; Multimedia spam; Multimodal features; Convolutional
   neural networks; Random forest
ID CLASSIFICATION
AB Nowadays, there is a growing demand among Internet and social media users for improved protection against spam. Despite numerous studies focused on spam detection, no contribution has addressed filtering text, image, audio, and video modalities of multimedia content simultaneously. In view of this situation, we present in this paper a new deep multimodal decision-level fusion system that could effectively detect multimedia spam. Our proposed system employs Convolutional Neural Networks (CNN) for feature extraction and selection. The retrieved features are organized into three independent vectors, namely visual, textual, and audio (VTA) vectors, to attain a strong content representation. Each vector is then individually fed into a Random Forest (RF) model for further analysis and classification. Thus, we have called our model VTA-CNN-RF. We show that our model overcomes seven Machine Learning (ML) algorithms in each of the three types of VTA information. Additionally, our study involved experiments demonstrating the fusion's advantages on the system's overall performance. Our results indicate a precision rate of 99.08% on a publicly available hybrid dataset that includes text and image content and 98.20% on a composite multimedia dataset. The proposed VTA-CNN-RF model provides superior spam identification compared to previous methods.
C1 [Kihal, Marouane; Hamza, Lamia] Univ Bejaia, Fac Exact Sci, Lab Med Informat LIMED, Bejaia 06000, Algeria.
C3 Universite de Bejaia
RP Hamza, L (corresponding author), Univ Bejaia, Fac Exact Sci, Lab Med Informat LIMED, Bejaia 06000, Algeria.
EM lamia.hamza@univ-bejaia.dz; marouane.kihal@univ-bejaia.dz
OI Kihal, Marouane/0000-0002-6675-7087; Hamza, Lamia/0000-0002-5436-3099
CR Abid MA, 2022, MULTIMED TOOLS APPL, V81, P39853, DOI 10.1007/s11042-022-12991-0
   Adewole KS, 2020, J SUPERCOMPUT, V76, P4802, DOI 10.1007/s11227-018-2641-x
   Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Almeida TA, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P259
   Amir A, 2018, MULTIMED TOOLS APPL, V77, P13249, DOI 10.1007/s11042-017-4944-y
   Abkenar SB, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6381
   Bird S., 2009, NATURAL LANGUAGE PRO
   Chandrasekaran G, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1415
   Cherifi F, 2021, MULTIMED TOOLS APPL, V80, P14807, DOI 10.1007/s11042-021-10524-9
   Dredze M., 2007, P 4 C EM ANT, P1
   Fan AW, 2018, PERS UBIQUIT COMPUT, V22, P1029, DOI 10.1007/s00779-018-1168-8
   Fatichah C, 2019, LECT NOTE NETW SYST, V67, P295, DOI 10.1007/978-981-13-6031-2_19
   Freeman DavidMandell., 2013, P 2013 ACM WORKSHOP, P3
   Gao Y, 2008, INT CONF ACOUST SPEE, P1765
   Ghatasheh N, 2022, IEEE ACCESS, V10, P84365, DOI 10.1109/ACCESS.2022.3196905
   Goyal S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P522, DOI 10.1109/PDGC.2016.7913250
   Gunawan D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNETSAT), P1, DOI 10.1109/COMNETSAT.2018.8684085
   Hnini G, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112411968
   Jain Gauri, 2019, International Journal of Information Technology, V11, P239, DOI 10.1007/s41870-018-0157-5
   Jogin M, 2018, FEATURE EXTRACTION U
   Kanodia S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P60, DOI 10.1109/ICACCI.2018.8554405
   Khormali A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062953
   Klimt B, 2004, LECT NOTES COMPUT SC, V3201, P217
   Krithiga R, 2021, INT J PERVASIVE COMP, V17, P462, DOI 10.1108/IJPCC-09-2020-0130
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Q, 2020, NEUROCOMPUTING, V414, P143, DOI 10.1016/j.neucom.2020.07.049
   Li QS, 2022, IEEE T CIRC SYST VID, V32, P2496, DOI 10.1109/TCSVT.2021.3069254
   Liu XX, 2021, IEEE ACCESS, V9, P80253, DOI 10.1109/ACCESS.2021.3081479
   Makkar A, 2021, FUTURE GENER COMP SY, V125, P41, DOI 10.1016/j.future.2021.06.026
   Meel P, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P7, DOI 10.1109/Confluence51648.2021.9377172
   Othman N. F., 2019, INDONESIAN J ELECT E, V14, P1508, DOI DOI 10.11591/IJEECS.V14.I3.PP1508-1517
   Porter M., 2005, PORTER STEMMING ALGO
   Rodr iguez-Ortega Y., 2020, P INT C APPL INFORMA, P3
   Rosita J, 2022, INT J INTELL NETW, DOI [10.1016/j.ijin.2022.01.001, DOI 10.1016/J.IJIN.2022.01.001]
   Saidani N, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101716
   Sewagnon G, 2019, THESIS O AWOLOWO U
   Sharmin T, 2020, INF SECUR J, V29, P103, DOI 10.1080/19393555.2020.1722867
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabi MK, 2018, ARAB J SCI ENG, V43, P949, DOI 10.1007/s13369-017-2855-x
   Statista, 2021, AV DAIL SPAM VOL WOR
   Steinmetz R., 1993, MULTIMEDIA TECHNOLOG, DOI [10.1007/978-3-642-97502-8, DOI 10.1007/978-3-642-97502-8]
   Tuli P, 2022, MULTIMED TOOLS APPL, V81, P32323, DOI 10.1007/s11042-022-12841-z
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang ZY, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2021.108512
   Yang H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061152
NR 45
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40819
EP 40837
DI 10.1007/s11042-023-15170-x
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000962689300003
DA 2024-07-18
ER

PT J
AU Rewal, P
   Mishra, D
   Mishra, A
   Rana, S
AF Rewal, Purva
   Mishra, Dheerendra
   Mishra, Ankita
   Rana, Saurab
TI Enhancing security of biometrics based authentication framework for DRM
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; DRM systems; Authentication; Security
ID RIGHTS MANAGEMENT-SYSTEM; SCHEME
AB Due to current advancements in digital and Internet technologies, digital content theft has grown to a significant degree. Digital rights management (DRM) systems were established to regulate access to digital content. For DRM systems, protocols are being developed to ensure secure and authorized communication. Existing efficient authenticated key agreement (AKA) protocols for DRM systems achieve efficiency in computation and communication, but have some serious security flaws or do not support anonymity. In this paper, we focus on the idea of an efficient and secure AKA protocol for DRM Systems. We design an AKA protocol with lower communication costs and anonymity. The proposed scheme security is proved under the random oracle model. Moreover, we evaluate the performance of our design. Finally, a comparative analysis is followed to show the enhancement in communication efficiency without any significant increase in computation efficiency. The analysis indicates that the proposed scheme presents an anonymous authenticated and secure session establishment platform for DRM with low communication overhead.
C1 [Rewal, Purva; Mishra, Dheerendra] Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal 462003, India.
   [Mishra, Ankita] Govt Motilal Vigyan Mahavidyalaya, Dept Math, Bhopal 462008, India.
   [Mishra, Ankita; Rana, Saurab] Bennett Univ, Dept Math SCSET, Greater Noida 201310, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Rana, S (corresponding author), Bennett Univ, Dept Math SCSET, Greater Noida 201310, India.
EM saurabhranapsm@gmail.com
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397; Rana,
   Saurabh/0000-0003-1583-4510
CR Armando A., 2006, ERCIM News, V64
   Chang CC, 2013, SECUR COMMUN NETW, V6, P972, DOI 10.1002/sec.647
   Chang CC, 2010, EXPERT SYST APPL, V37, P6176, DOI 10.1016/j.eswa.2010.02.110
   Chen CL, 2008, EXPERT SYST APPL, V35, P878, DOI 10.1016/j.eswa.2007.07.029
   Das AK, 2015, SECUR COMMUN NETW, V8, P3383, DOI 10.1002/sec.1266
   Fan Q, 2022, J INTERNET TECHNOL, V23, P267, DOI 10.53106/160792642022032302007
   Glouche Y., 2008, SPAN: a security protocol animator for AVISPA. Version 1.5 user manual
   Hussain S., 2022, Wireless Communications and Mobile Computing, P1
   Jongho Moon, 2017, International Journal of Network Security, V19, P1053, DOI 10.6633/IJNS.201711.19(6).22
   Jung J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169414
   Khan M. A., 2021, 2021 International Congress of Advanced Technology and Engineering (ICOTEN), P1, DOI [10.1109/ICOTEN52080.2021.9493510, DOI 10.1109/ICEPT51706.2021.9435425, DOI 10.1109/ICOTEN52080.2021.9493510]
   Kim H, 2010, J SYST SOFTWARE, V83, P2431, DOI 10.1016/j.jss.2010.04.064
   Lee CC, 2018, INF TECHNOL CONTROL, V47, P262, DOI 10.5755/j01.itc.47.2.18506
   Lee CC, 2018, J INF SECUR APPL, V39, P19, DOI 10.1016/j.jisa.2018.02.001
   Maitra T, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3242
   Mishra D, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102928
   Pan HT., 2020, International Journal of Network Security, V22, P358
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P20319, DOI 10.1007/s11042-020-08683-2
   Ranade SK, 2021, MULTIMED TOOLS APPL, V80, P10797, DOI 10.1007/s11042-020-10244-6
   Yu S, 2020, PEER PEER NETW APPL, V13, P1340, DOI 10.1007/s12083-019-00836-x
NR 20
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40857
EP 40871
DI 10.1007/s11042-023-14891-3
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000962689300001
DA 2024-07-18
ER

PT J
AU Xiao, QJ
   Du, SQ
   Liu, BK
   Yu, Y
   Song, JM
AF Xiao, Qingjiang
   Du, Shiqiang
   Liu, Baokai
   Yu, Yao
   Song, Jinmei
TI Multi-view spectral clustering based on adaptive neighbor learning and
   low-rank tensor decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view clustering; Low-rank tensor; Adaptive neighbor learning;
   Tensor SVD
ID FACTORIZATION; MATRIX
AB Aiming at the problem that traditional multi-view clustering algorithms only focus on shared information in multi-views and ignore the unique information and high-order correlations of each view, in this paper, a multi-view spectral clustering algorithm based on adaptive neighbor learning and low-rank tensor decomposition (ANLTSC) is proposed. Specifically, in the ANLTSC model, we adopt the adaptive neighbor graph construction method to learn the similarity graph of each view and calculate the transition probability matrix corresponding to each view, so as to reveal the class properties between samples more accurately. Then, transition probability matrices are stacked into a tensor for mining high-order correlations between multi-view data. The noise between different views is effectively filtered through tensor decomposition, and an intrinsically low-rank tensor is obtained for final clustering. Finally, experiments are carried out on seven benchmark datasets, the results show that the proposed ANLTSC algorithm achieves the best clustering results on most multi-view datasets.
C1 [Xiao, Qingjiang; Du, Shiqiang; Liu, Baokai; Song, Jinmei] Northwest Minzu Univ, Chinese Natl Informat Technol Res Inst, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730030, Gansu, Peoples R China.
   [Du, Shiqiang; Yu, Yao] Northwest Minzu Univ, Coll Math & Comp Sci, Lanzhou 730030, Gansu, Peoples R China.
C3 Northwest Minzu University; Northwest Minzu University
RP Du, SQ (corresponding author), Northwest Minzu Univ, Chinese Natl Informat Technol Res Inst, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730030, Gansu, Peoples R China.; Du, SQ (corresponding author), Northwest Minzu Univ, Coll Math & Comp Sci, Lanzhou 730030, Gansu, Peoples R China.
EM shiqiangdu@hotmail.com
OI Du, Shiqiang/0000-0003-0865-401X
FU National Natural Science Foundation of China [61866033]; Gansu
   Provincial Department of Education University Teachers Innovation Fund
   Project [2023B-056]; Introduction of Talent Research Project of
   Northwest Minzu University [xbmuyjrc201904]; Fundamental Research Funds
   for the Central Universities of Northwest Minzu University [31920220019,
   31920220130]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61866033), the Gansu Provincial Department of
   Education University Teachers Innovation Fund Project (No.2023B-056),
   the Introduction of Talent Research Project of Northwest Minzu
   University (No. xbmuyjrc201904), and the Fundamental Research Funds for
   the Central Universities of Northwest Minzu University (No.31920220019,
   31920220130).
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chen YY, 2022, IEEE T NEUR NET LEAR, V33, P4712, DOI 10.1109/TNNLS.2021.3059874
   Du SQ, 2017, NEUROCOMPUTING, V241, P115, DOI 10.1016/j.neucom.2017.02.034
   Gao Q, 2021, ARXIV
   Gao QX, 2021, IEEE T PATTERN ANAL, V43, P2133, DOI 10.1109/TPAMI.2020.3017672
   HAO W, 2022, INT J GEOTECH ENG, V252, P9342, DOI DOI 10.1016/J.KNOSYS.2022.109342
   Hu WR, 2017, IEEE T NEUR NET LEAR, V28, P2961, DOI 10.1109/TNNLS.2016.2611525
   Hu ZX, 2020, NEUROCOMPUTING, V384, P1, DOI 10.1016/j.neucom.2019.12.004
   Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005
   Huang SD, 2020, NEUROCOMPUTING, V382, P196, DOI 10.1016/j.neucom.2019.11.070
   Huang YX, 2022, NEURAL PROCESS LETT, V54, P265, DOI 10.1007/s11063-021-10634-3
   Kang Z, 2020, IEEE T CYBERNETICS, V50, P1833, DOI 10.1109/TCYB.2018.2887094
   Ke G, 2022, APPL INTELL, P1
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Li XL, 2022, IEEE T PATTERN ANAL, V44, P330, DOI 10.1109/TPAMI.2020.3011148
   Li ZL, 2022, IEEE T MULTIMEDIA, V24, P2461, DOI 10.1109/TMM.2021.3081930
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu HF, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3182384
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu JY, 2022, IEEE T NEUR NET LEAR, V33, P5177, DOI 10.1109/TNNLS.2021.3069424
   Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567
   Lu GF, 2020, NEURAL NETWORKS, V125, P214, DOI 10.1016/j.neunet.2020.02.014
   Najafi M, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3187
   Narayana GS, 2021, MULTIMED TOOLS APPL, V80, P4769, DOI 10.1007/s11042-020-09718-4
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nie F., 2016, IJCAI, P1881
   Nie FP, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2022, DOI 10.1145/3219819.3220049
   Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Ren PZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2644
   Shu ZQ, 2021, MULTIMED TOOLS APPL, V80, P1707, DOI 10.1007/s11042-020-09766-w
   Sun MJ, 2022, IEEE T MULTIMEDIA, V24, P2567, DOI 10.1109/TMM.2021.3086727
   Tong T, 2019, MULTIMED TOOLS APPL, V78, P33247, DOI 10.1007/s11042-018-6643-8
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wang H, 2019, KNOWL-BASED SYST, V163, P1009, DOI 10.1016/j.knosys.2018.10.022
   Wang SQ, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106745
   Wang SW, 2022, IEEE T IMAGE PROCESS, V31, P556, DOI 10.1109/TIP.2021.3131941
   Weng WL, 2020, NEUROCOMPUTING, V378, P375, DOI 10.1016/j.neucom.2019.10.014
   Winn J, 2005, IEEE I CONF COMP VIS, P756
   Wu JL, 2020, AAAI CONF ARTIF INTE, V34, P6388
   Wu JL, 2019, IEEE T IMAGE PROCESS, V28, P5910, DOI 10.1109/TIP.2019.2916740
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xia W, 2022, NEURAL NETWORKS, V145, P1, DOI 10.1016/j.neunet.2021.10.006
   Xia W, 2022, IEEE T CYBERNETICS, V52, P8962, DOI 10.1109/TCYB.2021.3052352
   Xiao Q, 2022, J INTELL FUZZY SYST, P1
   Xiao QJ, 2021, CHIN CONT DECIS CONF, P2258, DOI 10.1109/CCDC52312.2021.9602065
   Xiao QJ, 2021, IEEE ACCESS, V9, P118851, DOI 10.1109/ACCESS.2021.3107673
   Xiao XB, 2020, NEURAL PROCESS LETT, V52, P1317, DOI 10.1007/s11063-020-10306-8
   Xie Y, 2020, IEEE T CYBERNETICS, V50, P572, DOI 10.1109/TCYB.2018.2869789
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Xu HL, 2020, NEURAL NETWORKS, V132, P245, DOI 10.1016/j.neunet.2020.08.019
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhao YJ, 2022, NEUROCOMPUTING, V468, P257, DOI 10.1016/j.neucom.2021.09.052
   Zheng QH, 2020, NEUROCOMPUTING, V379, P89, DOI 10.1016/j.neucom.2019.10.074
   Zhou JK, 2019, MULTIMED TOOLS APPL, V78, P33415, DOI 10.1007/s11042-019-08009-x
NR 64
TC 0
Z9 0
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41159
EP 41186
DI 10.1007/s11042-023-15018-4
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961747500010
DA 2024-07-18
ER

PT J
AU Bourouis, S
   Bouguila, N
AF Bourouis, Sami
   Bouguila, Nizar
TI Expectation propagation learning of finite and infinite Gamma mixture
   models and its applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video recognition; Expectation propagation; Gamma mixture model; Facial
   expression; Action recognition; Hand-gesture recognition
ID FACIAL EXPRESSION RECOGNITION; PATTERN-RECOGNITION; EXTRACTION
AB In this paper, we propose an efficient learning framework for both finite and infinite Gamma mixture models. Unlike existing learning methods such as maximum-likelihood method, we propose here to tackle the problem of learning Gamma mixtures within a coherent and unified framework based on an expectation-propagation inference method. In addition, we introduce an effective Bayesian technique in order to generalize the finite Gamma (EP-GaMM) to the infinite mixture (EP-inGaMM). The developed framework offers accurate approximations to the full posterior and takes into account the prior knowledge in the statistical model. In particular, the model's parameters are estimated accurately and the optimal number of components is determined automatically. The choice of Gamma mixture is motivated by its flexibility and its modeling capabilities in solving many real-life applications. We highlight the importance of the proposed framework by solving main common spatio-temporal objects recognition challenges which might be used especially in interactive systems or robotics. The effectiveness of our approach is demonstrated through several real challenging applications. Our experiments shows comparable to superior results to other methods from the state-of-the-art. Results show that the average recognition accuracy of the proposed framework can achieve 78% which is better than many other related methods.
C1 [Bourouis, Sami] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Taif, Saudi Arabia.
   [Bouguila, Nizar] Concordia Univ, Concordia Inst Informat Syst Engn CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Taif University; Concordia University - Canada
RP Bourouis, S (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Taif, Saudi Arabia.
EM s.bourouis@tu.edu.sa; nizar.bouguila@concordia.ca
RI Bourouis, Sami/N-4995-2019
OI Bourouis, Sami/0000-0002-6638-7039
CR Alharithi F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072450
   Almulihi A, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13152991
   Andrews JL, 2011, COMPUT STAT DATA AN, V55, P520, DOI 10.1016/j.csda.2010.05.019
   [Anonymous], 2007, 2007 IEEE COMP SOC C, DOI DOI 10.1109/IMTC.2007.379340
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bourouis S, 2023, CYBERNET SYST, V54, P474, DOI 10.1080/01969722.2022.2062850
   Bourouis S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135798
   Bourouis S, 2021, IEEE ACCESS, V9, P71170, DOI 10.1109/ACCESS.2021.3078670
   Bourouis S, 2021, INT J IMAG SYST TECH, V31, P1989, DOI 10.1002/ima.22577
   Bourouis S, 2021, IEEE ACCESS, V9, P13727, DOI 10.1109/ACCESS.2021.3051758
   Channoufi I, 2018, LECT NOTES COMPUT SC, V10884, P36, DOI 10.1007/978-3-319-94211-7_5
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Fan WT, 2015, ENG APPL ARTIF INTEL, V43, P1, DOI 10.1016/j.engappai.2015.03.016
   Fan WT, 2014, NEURAL PROCESS LETT, V39, P115, DOI 10.1007/s11063-013-9293-x
   Fang H, 2014, PATTERN RECOGN, V47, P1271, DOI 10.1016/j.patcog.2013.09.023
   Ferguson T. S., 1983, Recent Advances in Statistics, P287
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li JJ, 2020, ADV INTELL SYST COMP, V895, P756, DOI 10.1007/978-3-030-16946-6_62
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Liu X, 2008, PATTERN RECOGN, V41, P484, DOI 10.1016/j.patcog.2007.06.004
   Liu XF, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108105
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ma ZY, 2010, INT CONF ACOUST SPEE, P2082, DOI 10.1109/ICASSP.2010.5495085
   Mahmoudi MA, 2020, PATTERN RECOGN LETT, V138, P644, DOI 10.1016/j.patrec.2020.09.001
   Marcolin F, 2021, NEUROCOMPUTING, V443, P302, DOI 10.1016/j.neucom.2021.02.074
   Maybeck P. S., 1982, STOCHASTIC MODELS ES
   Mclachlan G., 2004, Finite Mixture Models
   McNicholas PD, 2016, J CLASSIF, V33, P331, DOI 10.1007/s00357-016-9211-9
   Minka T., 2001, UNCERTAINTY ARTIFICI, P362
   Najar F, 2020, SOFT COMPUT, V24, P10611, DOI 10.1007/s00500-019-04567-2
   Najar F, 2019, MULTIMED TOOLS APPL, V78, P18669, DOI 10.1007/s11042-018-7116-9
   Najar F, 2018, LECT NOTES COMPUT SC, V10882, P408, DOI 10.1007/978-3-319-93000-8_46
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Peng XL, 2016, IEEE COMPUT SOC CONF, P1544, DOI 10.1109/CVPRW.2016.192
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sallay H, 2021, COMPUTERS, V10, DOI 10.3390/computers10010006
   Sariyanidi E, 2017, IEEE T IMAGE PROCESS, V26, P1965, DOI 10.1109/TIP.2017.2662237
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   SETHURAMAN J, 1994, STAT SINICA, V4, P639
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Song ZY, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102829
   Teh Y. W., 2010, ENCY MACHINE LEARNIN, P280, DOI [DOI 10.1007/978-0-387-30164-8_219, 10.1007/978-0-387-30164-8_219]
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Wu HP, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041428
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang ZL, 2020, NEUROCOMPUTING, V409, P341, DOI 10.1016/j.neucom.2020.05.081
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3017608
   Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800
   Zhou H, 2019, J VIS COMMUN IMAGE R, P65
   Zhu RF, 2019, NEURAL NETWORKS, V111, P35, DOI 10.1016/j.neunet.2018.12.008
NR 59
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33267
EP 33284
DI 10.1007/s11042-023-14666-w
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000983548500007
DA 2024-07-18
ER

PT J
AU Yang, Y
   Gao, CR
   Ming, ZQ
   Guo, JX
   Leopold, E
   Cheng, JL
   Zuo, J
   Zhu, M
AF Yang, Yong
   Gao, Chengrui
   Ming, Zhangqiang
   Guo, Jixiang
   Leopold, Edou
   Cheng, Junlong
   Zuo, Jie
   Zhu, Min
TI LatLRR-CNN: an infrared and visible image fusion method combining latent
   low-rank representation and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Latent low-rank representation; Convolutional neural
   network; Infrared image; Visible image
ID MULTISCALE TRANSFORM; PERFORMANCE; NETWORK; COLOR; LIGHT; VIDEO
AB While infrared images have prominent targets and stable imaging, it can hardly maintain such detailed information or quality as texture or resolution. In contrast, although visible images have rich texture information and high resolution, the imaging is easily disturbed by the circumstance. Therefore, it is desirable to make up for shortcomings and integrate the advantages of the two images into one. In this paper, we propose an infrared and visible image fusion method that combines latent low-rank representation(LatLRR) and convolutional neural network(CNN), termed as LatLRR-CNN. This method can prevent loss of information, lack of imaging quality, and designing complex fusion rules or networks. Firstly, LatLRR is used to decompose infrared or visible images into low-rank parts and salient parts. Secondly, these two parts are fused separately using CNN. Finally, the fused low-rank part and the fused salient part are merged to obtain the fused image. Experiments on publicly accessible datasets reveal that our method outperforms state-of-the-art methods in terms of objective metrics and visual effects. Specifically, the average of our method on the Nato sequence, EN reaches 7.59, MI reaches 2.89, SD reaches 57.77, and VIf reaches 0.51.
C1 [Yang, Yong; Gao, Chengrui; Ming, Zhangqiang; Guo, Jixiang; Leopold, Edou; Cheng, Junlong; Zuo, Jie; Zhu, Min] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Zhu, M (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM yangyong9809@163.com; cr@stu.scu.edu.cn; mingzhangqiang@stu.scu.edu.cn;
   guojixiang@scu.edu.cn; ledou24@yahoo.fr; cjl951015@stu.scu.edu.cn;
   zuojie@scu.edu.cn; zhumin@scu.edu.cn
RI Cheng, Junlong/ABP-8353-2022; 0, 0/KEE-7704-2024; GAO,
   CHENGRUI/JQJ-6841-2023
OI Cheng, Junlong/0000-0002-6849-9093; 
FU National Key Research and Development Project of China [JG2018190]
FX Project supported by the National Key Research and Development Project
   of China (JG2018190).
CR Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Fu Y, 2021, INT C PATT RECOG, P10675, DOI 10.1109/ICPR48806.2021.9412293
   Gao ZS, 2022, SIGNAL IMAGE VIDEO P, V16, P219, DOI 10.1007/s11760-021-01963-w
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Kong WW, 2014, INFRARED PHYS TECHN, V67, P161, DOI 10.1016/j.infrared.2014.07.019
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Kumar P, 2006, LECT NOTES COMPUT SC, V4338, P528
   Li GF, 2021, INFORM FUSION, V71, P109, DOI 10.1016/j.inffus.2021.02.008
   Li H., 2018, ARXIV
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P4733, DOI 10.1109/TIP.2020.2975984
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rajkumar S, 2014, ADV INTELL SYST, V248, P93, DOI 10.1007/978-3-319-03107-1_11
   Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Simone G., 2002, Information Fusion, V3, P3, DOI 10.1016/S1566-2535(01)00056-2
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Wang JS, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3156205
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3954
   Yang Y, 2021, IEEE T CIRC SYST VID, V31, P4771, DOI 10.1109/TCSVT.2021.3054584
   Yang ZG, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020294
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang LM, 2022, MULTIMED TOOLS APPL, V81, P9277, DOI 10.1007/s11042-021-11549-w
   Zhang XY, 2017, J OPT SOC AM A, V34, P1400, DOI 10.1364/JOSAA.34.001400
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   Zhao F, 2021, INFORM FUSION, V76, P189, DOI 10.1016/j.inffus.2021.06.002
   Zhao JF, 2017, INFRARED PHYS TECHN, V81, P201, DOI 10.1016/j.infrared.2017.01.012
   Zhao JF, 2014, INFRARED PHYS TECHN, V62, P86, DOI 10.1016/j.infrared.2013.11.008
   Zhao Z., 2020, ARXIV
NR 48
TC 3
Z9 3
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36303
EP 36323
DI 10.1007/s11042-023-14967-0
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200010
DA 2024-07-18
ER

PT J
AU Relan, D
   Mokan, M
   Relan, R
AF Relan, Devanjali
   Mokan, Monika
   Relan, Rishi
TI An automatic AVR biomarker assessment system in retinal imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arterioles-Venule classification; Vessel width; Arteriolar-to-venular
   diameter ratio (AVR); Blood vessels; Retinal imaging; Wavelet transform;
   Canny edge detector
ID MICROVASCULAR ABNORMALITIES; ATHEROSCLEROSIS RISK; VESSEL DIAMETERS;
   VASCULAR CALIBER; STROKE; SEGMENTATION; PHOTOGRAPHY; NETWORK; SUPPORT;
   DISEASE
AB Retinal Imaging, a non-invasive way to scan the back of the eye, provides a mean to extract different possible biomarkers, such as Artery and Vein Ratio (AVR). AVR is a well-known biomarker for various diseases, such as diabetes, glaucoma, hypertension, etc. The main objective of this paper to propose a fully automatic method to measure the AVR. The research hypothesis is that the system generated AVR is not significantly different from the ground truth. We have tested the system performance on publicly available INSPIRE-AVR (Iowa Normative Set for Processing Images of the REtina) dataset which contains 40 high-resolution colour fundus camera images and an AVR reference standard. The prerequisite for AVR measurement is the classification of retinal vessels (into arteries and veins) and the estimation of the vessel width. The images were classified into arteries and veins using Locally Consistent Gaussian Mixture Model (LCGMM) unsupervised classifier. The vessel width was estimated using the proposed Wavelet transform method from pre-processed images. Images pre-processing was performed using homomorphic filtering. Obtained results are compared with the vessel width calculated using the most common canny edge detector method. The calculated AVR was evaluated using two methods namely- Knudtson and Goatman, by utilizing the calculated vessel's widths. The system-generated AVR results were compared with the ground truth (manually annotated by observer 1 (Ob1)), and statistical analysis was performed using a Student's t-test. Furthermore, the validation of system-generated AVR values with respect to (w.r.t) the ground truth was done by utilizing a Bland-Altman (BA) plot. Student's t-test shows no significant difference in the AVR measured using Knudtson blue(p-value is 0.805 > 0.05) and Goatman (p-value is 0.652 > 0.05) methods w.r.t Observer 1 (Ob1) when vessel width was measured using Wavelet transform. However, there was a significant difference between the AVRs by Ob1 and the system (with Knudtson: p-value is 0.01 < 0.05 and with Goatman: p-value is 0.02 < 0.05) when the vessel width was measured using the Canny edge detector. Bland Altman's analysis shows that both the Ob1 and the system (with width calculated using Wavelet method and the AVR calculated using Knudtson and Goatman formula) have no substantial bias in AVR estimation. Furthermore, the observed bias between the AVR measurements was very low at 0.003. Further, from BA plot it has been seen that the limits of agreement for the system where width was obtained using canny was much wider as compared to the system when the wavelet transform was used to calculate the width. Further, our system generated average accuracy of 99.7% and 99.5% using Kundson and Goatman formula w.r.t Ob1. and outperform the existing method.
C1 [Relan, Devanjali; Mokan, Monika] BML Munjal Univ, Kapriwas, India.
   [Relan, Rishi] Siemens Ltd, Mumbai, India.
   [Relan, Rishi] Tech Univ Denmark, Kongens Lyngby, Denmark.
C3 BML Munjal University; Siemens AG; Technical University of Denmark
RP Relan, D (corresponding author), BML Munjal Univ, Kapriwas, India.
EM devanjali.relan@bmu.edu.in
CR Abbas Q, 2020, MULTIMED TOOLS APPL, V79, P31595, DOI 10.1007/s11042-020-09630-x
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Badawi SA, 2022, J DIGIT IMAGING, V35, P281, DOI 10.1007/s10278-021-00545-z
   Baker ML, 2008, STROKE, V39, P1371, DOI 10.1161/STROKEAHA.107.496091
   Bankhead P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032435
   Bhuiyan A, 2008, BIOSIGNALS 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, VOL 1, P178
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Cheung N, 2007, GRAEF ARCH CLIN EXP, V245, P1245, DOI 10.1007/s00417-006-0486-0
   Chin KS, 2011, THESIS U DUNDEE UK
   Cooper LS, 2006, STROKE, V37, P82, DOI 10.1161/01.STR.0000195134.04355.e5
   Dashtbozorg B, 2013, COMP MED SY, P512, DOI 10.1109/CBMS.2013.6627854
   de Jong FJ, 2011, NEUROLOGY, V76, P816, DOI 10.1212/WNL.0b013e31820e7baa
   Dervenis N, 2019, INVEST OPHTH VIS SCI, V60, P2208, DOI 10.1167/iovs.18-26276
   Doubal FN, 2009, NEUROLOGY, V72, P1773, DOI 10.1212/WNL.0b013e3181a60a71
   Doubal FN, 2009, J NEUROL NEUROSUR PS, V80, P158, DOI 10.1136/jnnp.2008.153460
   French C, 2022, OPHTHAL PHYSL OPT, V42, P666, DOI 10.1111/opo.12967
   Frost S, 2013, TRANSL PSYCHIAT, V3, DOI 10.1038/tp.2012.150
   Goatman KA, 2006, AUTOMATED MEASUREMEN
   Guedri H, 2017, BIOMEDICINES, V5, DOI 10.3390/biomedicines5020012
   Heitmar Rebekka, 2015, J Optom, V8, P252, DOI 10.1016/j.optom.2014.07.002
   Hemminki V., 2007, GRAEF ARCH CLIN EXP, V17, P245
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Huang F, 2017, LECT NOTES COMPUT SC, V10554, P227, DOI 10.1007/978-3-319-67561-9_26
   Hubbard LD, 1999, OPHTHALMOLOGY, V106, P2269, DOI 10.1016/S0161-6420(99)90525-0
   Ikram MK, 2006, HYPERTENSION, V47, P189, DOI 10.1161/01.HYP.0000199104.61945.33
   Inspire-avr, INSP AVR IOW NORM SE
   Kharghanian A., 2012, Int. J. Mach. Learn. Comput., V2, P593, DOI DOI 10.7763/IJMLC.2012.V2.196
   Knudtson MD, 2003, CURR EYE RES, V27, P143, DOI 10.1076/ceyr.27.3.143.16049
   Kumar DK, 2012, INT SCHOLARLY RES NO, V2012
   Kumar K, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P261, DOI 10.1109/ICCWAMTIP.2014.7073404
   Lee YW, 2000, OPT ENG, V39, P2405, DOI 10.1117/1.1287992
   Leung H, 2003, INVEST OPHTH VIS SCI, V44, P2900, DOI 10.1167/iovs.02-1114
   Li HQ, 2005, IEEE T BIO-MED ENG, V52, P1352, DOI 10.1109/TBME.2005.847402
   Liew G, 2006, AM J OPHTHALMOL, V141, P597, DOI 10.1016/j.ajo.2005.11.016
   Liew G, 2008, CIRC-CARDIOVASC IMAG, V1, P156, DOI 10.1161/CIRCIMAGING.108.784876
   Liu JL, 2010, AAAI CONF ARTIF INTE, P512
   Longstreth WT, 2007, AM J EPIDEMIOL, V165, P78, DOI 10.1093/aje/kwj350
   Maderuelo-Fernandez JA, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2020.104090
   Menon S, 2022, J STROKE MED
   Mitchell P, 2005, NEUROLOGY, V65, P1005, DOI 10.1212/01.wnl.0000179177.15900.ca
   Mittal K, 2020, MULTIMED TOOLS APPL, V79, P22389, DOI 10.1007/s11042-020-09041-y
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Niemeijer M, 2011, IEEE T MED IMAGING, V30, P1941, DOI 10.1109/TMI.2011.2159619
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   PARR JC, 1974, AM J OPHTHALMOL, V77, P478, DOI 10.1016/0002-9394(74)90458-9
   Pitas I., 1990, HOMOMORPHIC FILTERS, P217, DOI DOI 10.1007/978-1-4757-6017-0_7
   PONOMAREV VI, 1995, P SOC PHOTO-OPT INS, V2564, P153, DOI 10.1117/12.217396
   Relan D, 2021, COMPUT METH PROG BIO, V199, DOI 10.1016/j.cmpb.2020.105894
   Relan D, 2013, IEEE ENG MED BIO, P7396, DOI 10.1109/EMBC.2013.6611267
   Relan D, 2019, MULTIMED TOOLS APPL, V78, P12783, DOI 10.1007/s11042-018-6474-7
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Sharma N, 2020, PROCEEDINGS
   Sun C, 2009, SURV OPHTHALMOL, V54, P74, DOI 10.1016/j.survophthal.2008.10.003
   Tong YH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144437
   Trucco E, 2015, BIOMEDICAL IMAGE UND, P91, DOI DOI 10.1002/9781118715321.CH3
   Wong TY, 2006, INVEST OPHTH VIS SCI, V47, P2341, DOI 10.1167/iovs.05-1539
   Wong TY, 2004, OPHTHALMOLOGY, V111, P1183, DOI 10.1016/j.ophtha.2003.09.039
   Wong TY, 2004, LANCET NEUROL, V3, P179, DOI 10.1016/S1474-4422(04)00682-9
   Wong TY, 2002, JAMA-J AM MED ASSOC, V287, P1153, DOI 10.1001/jama.287.9.1153
   Wong TY, 2001, LANCET, V358, P1134, DOI 10.1016/S0140-6736(01)06253-5
   Xu BW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40641-3
   Xu X, 2012, AUTOMATED DELINEATIO
   Xu XY, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049668
   Yin XX, 2020, J INNOV OPT HEAL SCI, V13, DOI 10.1142/S1793545819500214
   Yip W, 2016, TRANSL VIS SCI TECHN, V5, DOI 10.1167/tvst.5.5.11
   Zhao N, 2011, COMM COM INF SC, V176, P20
   Zhu TP, 2014, MICROVASC RES, V95, P7, DOI 10.1016/j.mvr.2014.06.007
NR 71
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36553
EP 36575
DI 10.1007/s11042-023-14865-5
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950429600009
DA 2024-07-18
ER

PT J
AU García-Ordás, MT
   Bayón-Gutiérrez, M
   Benavides, C
   Aveleira-Mata, J
   Benítez-Andrades, JA
AF Teresa Garcia-Ordas, Maria
   Bayon-Gutierrez, Martin
   Benavides, Carmen
   Aveleira-Mata, Jose
   Alberto Benitez-Andrades, Jose
TI Heart disease risk prediction using deep learning techniques with
   feature augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Sparse autoencoder; Convolutional neural network; Heart
   disease
ID ENSEMBLE APPROACH; CLASSIFICATION; MODEL
AB Cardiovascular diseases state as one of the greatest risks of death for the general population. Late detection in heart diseases highly conditions the chances of survival for patients. Age, sex, cholesterol level, sugar level, heart rate, among other factors, are known to have an influence on life-threatening heart problems, but, due to the high amount of variables, it is often difficult for an expert to evaluate each patient taking this information into account. In this manuscript, the authors propose using deep learning methods, combined with feature augmentation techniques for evaluating whether patients are at risk of suffering cardiovascular disease. The results of the proposed methods outperform other state of the art methods by 4.4%, leading to a precision of a 90%, which presents a significant improvement, even more so when it comes to an affliction that affects a large population.
C1 [Teresa Garcia-Ordas, Maria; Bayon-Gutierrez, Martin; Aveleira-Mata, Jose] Univ Leon, Escuela Ingn Ind & Informat, SECOMUCI Res Grp, Campus Vegazana s-n, Leon 24071, Leon, Spain.
   [Benavides, Carmen; Alberto Benitez-Andrades, Jose] Univ Leon, Dept Elect Syst & Automat Engn, SALBIS Res Grp, Campus Vegazana s-n, Leon 24071, Leon, Spain.
C3 Universidad de Leon; Universidad de Leon
RP Benítez-Andrades, JA (corresponding author), Univ Leon, Dept Elect Syst & Automat Engn, SALBIS Res Grp, Campus Vegazana s-n, Leon 24071, Leon, Spain.
EM mgaro@unileon.es; martin.bayon@unileon.es; carmen.benavides@unileon.es;
   jose.aveleira@unileon.es; jbena@unileon.es
RI Bayón, Martín/ABQ-3194-2022; Benítez Andrades, José Alberto/M-1195-2017
OI Bayón, Martín/0000-0003-1849-796X; Benítez Andrades, José
   Alberto/0000-0002-4450-349X
FU Springer Nature; Junta de Castilla y Leon [LE078G18]; Universidad de
   Leon under the "Programa Propio de Investigacion de la Universidad de
   Leon 2021" grant
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research was funded by the Junta de Castilla y
   Leon grant number LE078G18. This work is partially supported by
   Universidad de Leon under the "Programa Propio de Investigacion de la
   Universidad de Leon 2021" grant.
CR Adler ED, 2020, EUR J HEART FAIL, V22, P139, DOI 10.1002/ejhf.1628
   Akbilgic O, 2021, J AM COLL CARDIOL, V77, P3045
   Ali MM, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104672
   [Anonymous], 2008, PROC 25 INT C MACH L
   Araujo M, 2021, 2021 5 INT C ELECT E
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dalal S, 2023, INT J MODEL SIMUL SC, V14, DOI 10.1142/S1793962323410234
   Diwakar M, 2021, MATER TODAY-PROC, V37, P3213, DOI 10.1016/j.matpr.2020.09.078
   Edeh MO, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.892371
   Faiayaz Waris S, 2021, Mater Today: Proc., DOI DOI 10.1016/J.MATPR.2021.01.570
   Feeny AK, 2019, CIRC-ARRHYTHMIA ELEC, V12, DOI 10.1161/CIRCEP.119.007316
   Ghosh A, 2022, IEEE T NEUR NET LEAR, DOI DOI 10.17577/IJERTV11IS060029
   Ghouali S, 2022, IEEE OPEN J ENG MED, V3, P124, DOI 10.1109/OJEMB.2022.3192780
   Go AS, 2014, CIRCULATION, V129, pE28, DOI 10.1161/01.cir.0000441139.02102.80
   Jan M, 2018, RES REP CLIN CARDIOL, V9, P33, DOI 10.2147/RRCC.S172035
   kaggle, Fedesoriano Heart failure prediction dataset kaggle
   Khajehali Naghmeh, 2023, Pers Ubiquitous Comput, V27, P203, DOI 10.1007/s00779-021-01540-5
   Kim Young Joong, 2022, Personal and Ubiquitous Computing, V26, P259, DOI 10.1007/s00779-019-01248-7
   Kondababu A, 2021, Mater Today: Proc., DOI DOI 10.1016/J.MATPR.2021.01.475
   Krishnaiah V., 2016, HEART DIS PREDICTION
   Liu JM, 2022, PROCESSES, V10, DOI 10.3390/pr10040749
   Maini Ekta, 2021, Med J Armed Forces India, V77, P302, DOI 10.1016/j.mjafi.2020.10.013
   Muzammal M, 2020, INFORM FUSION, V53, P155, DOI 10.1016/j.inffus.2019.06.021
   Negassa A, 2021, AM J CARDIOL, V153, P86, DOI 10.1016/j.amjcard.2021.05.044
   Olsen CR, 2020, AM HEART J, V229, P1, DOI 10.1016/j.ahj.2020.07.009
   Panahiazar M, 2015, STUD HEALTH TECHNOL, V216, P40, DOI 10.3233/978-1-61499-564-7-40
   Pires IM., 2020, Procedia Comput Sci, V177, P432, DOI [DOI 10.1016/J.PROCS.2020.10.058, 10.1016/J.PROCS.2020.10.058]
   Samuel OW, 2020, FUTURE GENER COMP SY, V110, P781, DOI 10.1016/j.future.2019.10.034
   Soni J., 2011, Int J Comput Appl, V17, P43, DOI DOI 10.5120/2237-2860
   Yang H, 2015, J BIOMED INFORM, V58, pS171, DOI 10.1016/j.jbi.2015.09.006
NR 30
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31759
EP 31773
DI 10.1007/s11042-023-14817-z
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000949737500006
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Davix, XA
   Judson, D
   Sinha, GR
AF Davix, X. Ascar
   Judson, D.
   Sinha, G. R.
TI License plate localization using kernel search multiwavelet
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate recognition (LPR); Bilateral filtering; Kernel search
   multiwavelet decomposition (KsMWD); Inception Resnet V2 classification
ID INVARIANT TEXTURE CLASSIFICATION; ALGORITHM
AB According to global survey reports, license plate recognition (LPR) provides rich information in approximating the traffic conditions of urban arterials is an emerging data source. Several researchers studied and investigated about segmenting, extracting and classifying the license plate and their approaches do not provide accurate extraction in the different weather condition (night, day, rainy, cloudy etc.). In this research work, a novel feature extraction technique called as Kernel Search Multiwavelet Decomposition (KsMWD) is proposed for license plate detection. By computing the dissimilarity search patterns, the binary and original value of the pixels are multiplied and converted with reference to the referenced pixel and its surrounding neighbours. The proposed segmentation produces an accuracy of 98.97% which is higher than any other existing algorithm. Depending upon the directions, the first-order derivatives are calculated for the projected information from the actual wave crested values. The efficiency of developed classification algorithm is found as 98.37% by effective combination with the horizontal edge density extraction. Finally, the proposed Inception Resnet V2 classification gives better accuracy than other segmentation method. Simulation results are included and performance analyses are tabulated for different weather conditions.
C1 [Davix, X. Ascar] RVR & JC Coll Engn, Dept Elect & Commun Engn, Guntur 522019, Andhra Pradesh, India.
   [Judson, D.] St Xaviers Catholic Coll Engn, Dept Elect & Commun Engn, Nagercoil 629003, Tamil Nadu, India.
   [Sinha, G. R.] Int Inst Informat Technol Bangalore IIITB, Bangalore 560100, Karnataka, India.
C3 RVR & JC College of Engineering; International Institute of Information
   Technology Bangalore (IIIT Bangalore)
RP Davix, XA (corresponding author), RVR & JC Coll Engn, Dept Elect & Commun Engn, Guntur 522019, Andhra Pradesh, India.
EM davixascar@gmail.com; judson_d2001@yahoo.co.in; gr.sinha@iiitb.ac.in
RI Sinha, G R/T-2042-2019; X, Ascar Davix/ITT-3462-2023; D,
   judson/X-7783-2019
OI Sinha, G R/0000-0003-2384-4591; X, Ascar Davix/0000-0002-6795-7865; D,
   judson/0000-0002-1658-0762
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Abulgasem NA, INDIAN J COMPUT VIS, V1, P15
   Akoum A. H., 2010, 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA), P1399, DOI 10.1109/BICTA.2010.5645286
   Al-Shemarry MS, 2018, EXPERT SYST APPL, V92, P216, DOI 10.1016/j.eswa.2017.09.036
   Ascar Davix X, 2019, P 2019 IEEE INT C RE, P1, DOI [10.1109/ICRAECC43874.2019.8994964, DOI 10.1109/ICRAECC43874.2019.8994964]
   Atikuzzaman Md, 2019, 2019 INT C SUST TECH, P1, DOI DOI 10.1109/STI47673.2019.9068049
   Bachchan AK, 2017, LECT NOTES COMPUT SC, V10362, P22, DOI 10.1007/978-3-319-63312-1_3
   Choubey S., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P26, DOI 10.1109/ICECTECH.2011.5941950
   Choubey S, 2013, I MANAGERS J EMBED S, V2, P6
   Choubey S, 2011, COMM COM INF SC, V147, P422
   Davix X. Ascar, 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P82, DOI 10.1109/ICCS1.2017.8325967
   Davix X. A., 2017, J COMPUTATION THEORE, V14, P5539, DOI DOI 10.1166/JCTN.2017.6982
   Davix XA, 2021, ADV APPL MATH SCI, V20, P2479
   Davix XA, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2020.164689
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Gnanaprakash V., 2021, IOP Conference Series: Materials Science and Engineering, V1084, DOI 10.1088/1757-899X/1084/1/012027
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hontani H., 2001, IVEC2001. Proceedings of the IEEE International Vehicle Electronics Conference 2001. IVEC 2001 (Cat. No.01EX522), P67, DOI 10.1109/IVEC.2001.961728
   Jamtsho Y, 2020, ICT EXPRESS, V6, P121
   Jia WJ, 2007, J NETW COMPUT APPL, V30, P1324, DOI 10.1016/j.jnca.2006.09.010
   Khan NY, 2007, THIRD INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES 2007, PROCEEDINGS, P232
   Kim KK, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P614, DOI 10.1109/NNSP.2000.890140
   Kyaw NN, 2018, IEEE GLOB CONF CONSU, P771, DOI 10.1109/GCCE.2018.8574751
   Lategahn H, 2010, IEEE T IMAGE PROCESS, V19, P1548, DOI 10.1109/TIP.2010.2042100
   Li Q, 2018, J COMPUT METHODS SCI, V18, P1021, DOI 10.3233/JCM-180849
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lixia Liu, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P157, DOI 10.1109/CGIV.2010.32
   Mousa A, 2012, INT J SIGNAL PROCESS, V5, P1
   Naito T., 2000, Systems and Computers in Japan, V31, P82, DOI 10.1002/1520-684X(200010)31:11<82::AID-SCJ9>3.0.CO;2-X
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rafique Muhammad Aasim, 2018, Soft Computing, V22, P6429, DOI 10.1007/s00500-017-2696-2
   Rahmat Basuki, 2018, IAENG International Journal of Computer Science, V45, P458
   Raza MA, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062165
   Roy S., 2013, INT J INNOVATIVE TEC, V2, P241
   Salgado L., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P71, DOI 10.1109/CCST.1999.797895
   Sarfraz M, 2003, 2003 INTERNATIONAL CONFERENCE ON GEOMETRIC MODELING AND GRAPHICS, PROCEEDINGS, P36, DOI 10.1109/GMAG.2003.1219663
   Siddhartha C, 2011, INT J MACHINE LEARNI, VComput1, P394, DOI [10.7763/IJMLC.2011.V1.58, DOI 10.7763/IJMLC.2011.V1.58]
   Siddique NA, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P688, DOI 10.1109/ICIEV.2012.6317529
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang CM, 2015, 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), P1708, DOI 10.1109/FSKD.2015.7382203
   Yousif BB, 2020, IEEE ACCESS, V8, P49285, DOI 10.1109/ACCESS.2020.2979185
   Yuan YL, 2017, IEEE T IMAGE PROCESS, V26, P1102, DOI 10.1109/TIP.2016.2631901
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang X, 2010, P 2010 IEEE INT C IN, P2456, DOI [10.1109/ICINFA.2010.5512276, DOI 10.1109/ICINFA.2010.5512276]
NR 45
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28957
EP 28976
DI 10.1007/s11042-023-14570-3
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000945313000004
DA 2024-07-18
ER

PT J
AU Guha, I
   Saha, P
AF Guha, Indranil
   Saha, Punam
TI A model-independent method for local blur estimation and its application
   to edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scale; Blur-scale; Intensity gradient; Maximum likelihood function;
   Mahalanobis distance; False-maximal suppression; Edge detection
ID IMAGE; ALGORITHMS; FEATURES
AB Knowledge is hidden in images in form of objects, structures, patterns and their relationships, which are acquired through devices associated with various artifacts including blurring and noise. This paper presents a model-independent method for local blur-scale estimation based on a novel hypothesis that gradients inside a blur-scale region follow a Gaussian distribution with non-zero mean. New statistical test criteria involving maximal likelihood functions are presented to test the hypothesis and applied for blur-scale estimation. Also, the applications of blur-scale for scale-based gradient and edge computation are presented. In the context of scale-based edge computation, new methods are introduced to suppress false gradient maxima avoiding double edging artifacts. New methods are examined on computer-generated as well as real-life images with varying blur and noise. Experimental results show that computed blur-scale using the new algorithm is accurate (r = 0.95) and scale-based gradients are visually satisfactory at both sharp as well as blurred edge locations. Performance of the new edge detection algorithm is quantitatively examined and compared with two popular methods, and the results show that, at various contrast-to-noise ratio, the new method is superior to the others in terms of overall accuracy (92 to 96%), true edge detection (96 to 98%), and false edge reduction (93 to 100%).
C1 [Guha, Indranil; Saha, Punam] Univ Iowa, Dept ECE, Iowa City, IA 52242 USA.
C3 University of Iowa
RP Guha, I (corresponding author), Univ Iowa, Dept ECE, Iowa City, IA 52242 USA.
EM indranil-guha@uiowa.edu; punam-saha@uiowa.edu
OI GUHA, INDRANIL/0000-0002-6691-7204; Saha, Punam/0000-0003-1576-118X
FU NIH [R01-HL142042]
FX AcknowledgementsThis work was supported by the NIH grants R01-HL142042.
CR Abramoff M. D., 2004, BIOPHOTONICS INT, V11, P36, DOI DOI 10.1201/9781420005615.AX4
   Bahrami K, 2016, IEEE T MULTIMEDIA, V18, P1568, DOI 10.1109/TMM.2016.2573139
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Guha I, 2018, LECT NOTES COMPUT SC, V11241, P598, DOI 10.1007/978-3-030-03801-4_52
   JEONG H, 1992, IEEE T PATTERN ANAL, V14, P579, DOI 10.1109/34.134062
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Li LD, 2020, IEEE T CIRC SYST VID, V30, P3859, DOI 10.1109/TCSVT.2019.2947450
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Magnier B, 2018, MULTIMED TOOLS APPL, V77, P9489, DOI 10.1007/s11042-017-5127-6
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Meijering EHW, 2001, MED IMAGE ANAL, V5, P111, DOI 10.1016/S1361-8415(00)00040-2
   Netzer C., ELDER ZUCKER IMAGE C
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Prautzsch H., 2002, Bezier and B-Spline Techniques
   Saha PK, 2003, P SOC PHOTO-OPT INS, V5032, P314, DOI 10.1117/12.481433
   Saha PK, 2000, INT J IMAG SYST TECH, V11, P81, DOI 10.1002/(SICI)1098-1098(2000)11:1<81::AID-IMA9>3.0.CO;2-1
   Saha PK, 2018, IEEE T VIS COMPUT GR, V24, P2298, DOI 10.1109/TVCG.2017.2738023
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sonka M., 2014, Image processing, analysis, and machine vision
   Strand R, 2013, COMPUT VIS IMAGE UND, V117, P429, DOI 10.1016/j.cviu.2012.10.011
   Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162
   Wang Z, 2004, ADV NEUR IN, V16, P1435
   Xu ZY, 2011, COMPUT MED IMAG GRAP, V35, P64, DOI 10.1016/j.compmedimag.2010.09.007
   Zhang X, 2018, MEDICAL IMAGING 2018, V10578, P1
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25779
EP 25793
DI 10.1007/s11042-023-14779-2
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943638900011
DA 2024-07-18
ER

PT J
AU Mohiuddin, SK
   Malakar, S
   Kumar, M
   Sarkar, R
AF Mohiuddin, Sk
   Malakar, Samir
   Kumar, Munish
   Sarkar, Ram
TI A comprehensive survey on state-of-the-art video forgery detection
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery detection; Passive approach; Active approach; Copy-move
   video forgery; Deepfake; Surveillance video; Survey
ID DETECTION ALGORITHM; FRAME DELETION; TAMPERING DETECTION; DOUBLE
   COMPRESSION; UPSCALE-CROP; LOCALIZATION; CLASSIFICATION
AB Video plays a key role in carrying authenticity, especially in the surveillance system, medical field, court evidence, journalism, and social media among others. However, nowadays the trust in videos is decreasing day by day due to the forgery of the videos made by easily accessible video editing tools. Hence, a thrust for finding a robust solution to the problem of video forgery detection arises. As a result, researchers around the world are indulging themselves to come up with various methods for the said problem. In this article, we have comprehensively discussed many such initiatives made by researchers across the globe, keeping the focus on recent trends. In addition to this, we have also covered a wide range of forgery detection techniques that follow either an active or a passive approach, while the state-of-the-art surveys made so far on this research topic include only a few specific cases. In this article, we have described some recent technologies that are used in video forging, made a summary of the performances (provided categorically) of all the techniques discussed here, and briefed the available datasets. Finally, we have concluded this survey by clearly mentioning some future directions of the video forgery detection research based on a thorough review of existing techniques.
C1 [Mohiuddin, Sk; Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata 700026, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, India.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 Jadavpur University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, India.
EM myselfmohiuddin@gmail.com; malakarsamir@gmail.com; munishcse@gmail.com;
   ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Kumar, Munish/P-7756-2018
OI Sarkar, Ram/0000-0001-8813-4086; Kumar, Munish/0000-0003-0115-1620
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   Aghamaleki JA, 2017, MULTIMED TOOLS APPL, V76, P20691, DOI 10.1007/s11042-016-4004-z
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Al-Sanjary OI, 2018, 2018 IEEE CONFERENCE ON SYSTEMS, PROCESS AND CONTROL (ICSPC), P33, DOI 10.1109/SPC.2018.8704160
   Al-Sanjary OI, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P388, DOI 10.1109/ISCAIE.2018.8405504
   Ankerst M., 1999, SIGMOD Record, V28, P49, DOI 10.1145/304181.304187
   [Anonymous], 2022, RECOGNITION HUMAN AC
   [Anonymous], 2022, TREC VIDEO RETRIEVAL
   [Anonymous], 2022, REWIND DATABASE
   [Anonymous], 2022, LASIESTA DATASET
   [Anonymous], 2022, CHANGE DETECTION VID
   [Anonymous], 2022, NTHU FORENSICS PROJE
   [Anonymous], 2022, VIDEO TRACE LIB
   [Anonymous], 2017, NIMBLE CHALLENGE
   [Anonymous], 2022, VIDEO INPAINTING CAM
   [Anonymous], 2022, VIDEO MOTION INTERPO
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   [Anonymous], 2022, YUV DATASET
   Antony Neema, 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1085, DOI 10.1109/ICOEI.2018.8553953
   Aparicio-Díaz E, 2019, J INTELL FUZZY SYST, V36, P5023, DOI 10.3233/JIFS-179048
   Ardizzone E, 2015, LECT NOTES COMPUT SC, V9280, P665, DOI 10.1007/978-3-319-23234-8_61
   Bagiwa MA, 2016, DIGIT INVEST, V19, P29, DOI 10.1016/j.diin.2016.09.001
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bakas J, 2018, LECT NOTES COMPUT SC, V11281, P304, DOI 10.1007/978-3-030-05171-6_16
   Banerjee D, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115756
   Barburiceanu S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052332
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barua S, 2017, ADV INTELL SYST, V515, P343, DOI 10.1007/978-981-10-3153-3_34
   Benford F., 1938, P AM PHILOS SOC, V78, P551, DOI DOI 10.2307/984802
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bidokhti A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P13, DOI 10.1109/AISP.2015.7123529
   Bonettini N, 2021, INT C PATT RECOG, P5012, DOI 10.1109/ICPR48806.2021.9412711
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chatterjee G., 2017, AUSTR U POW ENG C AU, P1
   Chen CH, 2008, INT C PATT RECOG, P1814
   Chen H, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P37, DOI 10.1109/IITA.2008.451
   Chen M, 2007, PROC SPIE, V6505, DOI 10.1117/12.696519
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Chittapur G., 2019, INT J SCI TECHNOL RE, V8, P3240
   Corripio JR, 2013, P 5 INT C IM CRIM DE, P1, DOI [10.1049/ic.2013.0267, DOI 10.1049/IC.2013.0267]
   Costanzo A, 2016, EUR SIGNAL PR CONF, P2245, DOI 10.1109/EUSIPCO.2016.7760648
   D'Amiano L, 2015, IEEE INT CONF MULTI
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   Das Susovan, 2023, Proceedings of International Conference on Frontiers in Computing and Systems: COMSYS 2021. Lecture Notes in Networks and Systems (404), P323, DOI 10.1007/978-981-19-0105-8_31
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Dey C, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03155-3
   Dey S, 2022, APPL SOFT COMPUT, V114, DOI 10.1016/j.asoc.2021.108094
   Dirik AE, 2008, IEEE T INF FOREN SEC, V3, P539, DOI 10.1109/TIFS.2008.926987
   Dolhansky B., 2020, arXiv
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elrowayati AA, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P174, DOI 10.1109/ICCSCE.2017.8284400
   Fadl S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116066
   Fadl S, 2020, MULTIMED TOOLS APPL, V79, P17619, DOI 10.1007/s11042-019-08603-z
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Fayyaz MA, 2020, MULTIMED TOOLS APPL, V79, P5767, DOI 10.1007/s11042-019-08236-2
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Ganguly S, 2022, EXPERT SYST APPL, V210, DOI 10.1016/j.eswa.2022.118423
   Ganguly S, 2022, PATTERN ANAL APPL, V25, P981, DOI 10.1007/s10044-022-01083-2
   GRIP, 2022, US
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Gupta Ankita, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P659, DOI 10.1109/ABLAZE.2015.7154945
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Hong JH, 2019, DIGIT INVEST, V30, P23, DOI 10.1016/j.diin.2019.06.002
   Hongmei Liu, 2014, Information Security Practice and Experience. 10th International Conference, ISPEC 2014. Proceedings: LNCS 8434, P262, DOI 10.1007/978-3-319-06320-1_20
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Huang CC, 2020, INT J DIGIT CRIME FO, V12, P14, DOI 10.4018/IJDCF.2020010102
   Huang CC, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P20, DOI 10.1109/SIPROCESS.2017.8124498
   Huang M, 2015, P INT WORKSH DIG WAT, P61
   Hyun D-K, 2012, ERA INTERACTIVE MEDI, P25, DOI DOI 10.1007/978-1-4614-3501-3_3
   Hyun DK, 2013, SENSORS-BASEL, V13, P12605, DOI 10.3390/s130912605
   Iglewicz B., 1993, Volume 16: How to Detect and Handle Outliers, DOI DOI 10.2307/1269377
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   IVY LAB, 2022, US
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Jiang X., 2019, IEEE ACCESS, V7, P95352
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Joshi Vaishali, 2020, International Journal of Information Technology, V12, P273, DOI 10.1007/s41870-018-0268-z
   Kancherla K, 2012, LECT NOTES ARTIF INT, V7198, P308, DOI 10.1007/978-3-642-28493-9_33
   Kang XG, 2016, MULTIMED TOOLS APPL, V75, P13833, DOI 10.1007/s11042-015-2762-7
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1763, DOI 10.1007/s11277-020-07126-3
   Kaur R, 2016, INT J ADV RES COMPUT, V5, P112, DOI [10.17148/IJARCCE.2016.51221, DOI 10.17148/IJARCCE.2016.51221]
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   Kerekes RA, 2006, IEEE T IMAGE PROCESS, V15, P1794, DOI 10.1109/TIP.2006.873468
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Kingra S, 2017, INT J ELECTR COMPUT, V7, P831, DOI DOI 10.11591/IJECE.V7I2.PP831-841
   KINGRA S, 2016, INDIAN J SCI TECHNOL, V9, pN1094, DOI DOI 10.17485/ijst/2016/v9i44/105142
   Kirchner M, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035103
   Kohli A, 2020, IET IMAGE PROCESS, V14, P947, DOI 10.1049/iet-ipr.2019.0397
   Kono Kazuhiro, 2020, Proceedings of the Tenth International Conference on Soft Computing and Pattern Recognition (SoCPaR 2018). Advances in Intelligent Systems and Computing (AISC 942), P381, DOI 10.1007/978-3-030-17065-3_38
   Korshunov P., 2018, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar V, 2022, MULTIMED TOOLS APPL, V81, P42223, DOI 10.1007/s11042-021-11448-0
   Kumar V, 2022, MULTIMED TOOLS APPL, V81, P43979, DOI 10.1007/s11042-022-13284-2
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li Q, 2019, IET INFORM SECUR, V13, P1, DOI 10.1049/iet-ifs.2017.0555
   Li Y., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li ZH, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171201020
   Liang XY, 2018, IEEE ACCESS, V6, P53243, DOI 10.1109/ACCESS.2018.2869627
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P7405, DOI 10.1007/s11042-017-4652-7
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma R., 2010, P ACM INT C IMAGE VI, P228
   Mandelli S, 2018, EUR SIGNAL PR CONF, P1362, DOI 10.23919/EUSIPCO.2018.8553511
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   media, 2022, DERFS COLLECTION
   Mizher MA, 2017, INT J ELECTRON SECUR, V9, P191, DOI 10.1504/IJESDF.2017.10005634
   Mohiuddin S, 2021, P 3 INT C COMPUTATIO, P29
   Mohiuddin S. K., 2022, Mathematics and its Applications in New Computer Systems: MANCS-2021. Lecture Notes in Networks and Systems (424), P197, DOI 10.1007/978-3-030-97020-8_18
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Panchal HD, 2020, MULTIMED TOOLS APPL, V79, P24553, DOI 10.1007/s11042-020-09205-w
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Park JY, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P18, DOI 10.1109/ICCE.2002.1013909
   Paul A, 2022, NEURAL COMPUT APPL, V34, P10409, DOI 10.1007/s00521-021-06629-9
   Pramanik R, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18463-7
   Qadir G., 2012, IET C IMAGE PROCESSI
   López RR, 2020, IEEE ACCESS, V8, P36363, DOI 10.1109/ACCESS.2020.2971785
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Roy S, 2021, J AMB INTEL HUM COMP, V12, P10837, DOI 10.1007/s12652-020-02886-z
   Roy S, 2020, MULTIMED TOOLS APPL, V79, P31353, DOI 10.1007/s11042-020-09570-6
   Saddique M, 2020, IEEE ACCESS, V8, P56782, DOI 10.1109/ACCESS.2020.2980951
   Saddique M, 2019, ADV ELECTR COMPUT EN, V19, P97, DOI 10.4316/AECE.2019.03012
   Sah AK, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P64, DOI 10.1109/CALCON.2017.8280697
   Sarkar S, 2019, P 2 INT C COMPUTATIO, P27
   Sawant Rohini., 2018, Journal of Computer Engineering (IOSR-JCE), V20, P1
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Shaw S.S., 2021, P INT C MACH INT DAT, P345
   Shaw SS, 2021, COMPLEX INTELL SYST, V7, P2069, DOI 10.1007/s40747-021-00314-z
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh GM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124845
   Singh G, 2022, MULTIMED TOOLS APPL, V81, P1419, DOI 10.1007/s11042-021-11380-3
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Su LC, 2019, IEEE ACCESS, V7, P109719, DOI 10.1109/ACCESS.2019.2933871
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang W, 2013, IEEE INT CON DIS, P244, DOI 10.1109/ICDCSW.2013.69
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Xiaozhong P, 2012, ADV MATER RES-SWITZ, P692
   Xu JY, 2012, PHYSCS PROC, V33, P1316, DOI 10.1016/j.phpro.2012.05.217
   Xu JY, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413540013
   Xu QY, 2017, LECT NOTES COMPUT SC, V10431, P3, DOI 10.1007/978-3-319-64185-0_1
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Yin P, 2001, P SOC PHOTO-OPT INS, V4518, P239, DOI 10.1117/12.448208
   YouTube, 2022, US
   Yu LF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0468-x
   Yu Y, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107269
   Yuan Z, 2021, FUZZY SET SYST, V421, P1, DOI 10.1016/j.fss.2020.10.017
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang ZZ, 2015, SECUR COMMUN NETW, V8, P311, DOI 10.1002/sec.981
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zheng L, 2015, LECT NOTES COMPUT SC, V9023, P18, DOI 10.1007/978-3-319-19321-2_2
NR 168
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33499
EP 33539
DI 10.1007/s11042-023-14870-8
EA MAR 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943159500002
DA 2024-07-18
ER

PT J
AU Sabha, A
   Selwal, A
AF Sabha, Ambreen
   Selwal, Arvind
TI Data-driven enabled approaches for criteria-based video summarization: a
   comprehensive survey, taxonomy, and future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Object detection; Event detection; Machine
   learning; Deep neural networks
ID HUMAN ACTION RECOGNITION; EVENT DETECTION; AUDIO
AB The exponential growth in the usage of computing technologies in various applications has led to the creation of huge amount of multimedia information such as, video, audio, and text. The enormous amount of video data generated over the past years necessitates the use of video summarization techniques that has become an emerging field of research. These techniques may facilitate quick browsing, indexing and faster sharing of content among various sources. Video summarization has been popular method to generate a short summary of a longer sized video and these approaches may be broadly classified into handcrafted (using features descriptors) or deep learning (DL) based algorithms. In this paper, we expound a comprehensive review of state-of-the-art (SOTA) techniques for video summarization from traditional to modern data-driven approaches. In addition, we proposed a taxonomy for the classification of video summarization methods based on a plenty of criteria. We also present an analysis of evaluation protocols for these approaches using benchmark datasets and performance metrices. We identify and list various research challenges specifically for each sub-category of video summarization. It may be clearly inferred that modern deep learning-based approaches outperformed traditional methods in terms of accuracy with an additional training overhead. Furthermore, most of the handcrafted-based approaches offer limited performance in dynamic video scenario and there exist several inconsistencies such as scaling or rotational variations under different illumination conditions. Besides, our analysis investigates that multi-criteria-based video summarization is an area that requisite further exploration by the research community. This survey may serve as a reference article to the new researchers for carrying out investigations in this active field of computer vision.
C1 [Sabha, Ambreen; Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, Jammu & Kashmir, India.
C3 Central University of Jammu
RP Sabha, A (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, Jammu & Kashmir, India.
EM ambreensabha45@gmail.com
RI Selwal, Arvind/HTR-1625-2023
OI Selwal, Arvind/0000-0002-1075-6966; Sabha, Ambreen/0000-0002-6336-7171
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Agyeman R, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P270, DOI 10.1109/MIPR.2019.00055
   Ahmad Z, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER COMMUNICATIONS (ITCC 2019), P1, DOI 10.1145/3355402.3355419
   Ali H, 2020, ARTIF INTELL REV, V53, P2635, DOI 10.1007/s10462-019-09743-2
   Ali JJ., 2020, TELKOMNIKA TELECOMMU, V18, P2447, DOI 10.12928/TELKOMNIKA.V18I5.16634
   [Anonymous], 2011, P 19 ACM INT C MULT
   Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   B. World, 2019, WORLD POP AG 2019, DOI [10.1007/978-94-007-5204-7_6, DOI 10.1007/978-94-007-5204-7_6]
   Baillie M, 2003, LECT NOTES COMPUT SC, V2728, P300
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Benjak J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136386
   Bir B, 2020, WILDF FOR FIR WORLD
   Bojukyan E, 2022, 52 VIDEO MARKETING S
   Calic J, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P28, DOI 10.1109/ITCC.2002.1000355
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen T, 2012, COMPUT GRAPH-UK, V36, P241, DOI 10.1016/j.cag.2012.02.010
   Choros K, 2014, LECT NOTES COMPUT SC, V8397, P591, DOI 10.1007/978-3-319-05476-6_60
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dilawari A, 2019, IEEE ACCESS, V7, P29253, DOI 10.1109/ACCESS.2019.2902507
   Donchev D, 2022, 40 MIND BLOWING YOUT
   Dov D, 2015, IEEE-ACM T AUDIO SPE, V23, P732, DOI 10.1109/TASLP.2015.2405481
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Evangelopoulos G, 2009, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.2009.4960393
   Fei Mengjuan, 2023, Journal of Ambient Intelligence and Humanized Computing, V14, P14931, DOI 10.1007/s12652-018-0797-0
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   G. of India, 2020, ACC DEATHS SUIC IND
   Ghafoor HA, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7586417
   Ghatak S, 2020, MULTIMED TOOLS APPL, V79, P4429, DOI 10.1007/s11042-019-7389-7
   Gong FM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/1939171
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Guan GL, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2632267
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Han YM, 2018, PATTERN RECOGN LETT, V107, P83, DOI 10.1016/j.patrec.2017.08.015
   He LJ, 2021, APPL INTELL, V51, P2128, DOI 10.1007/s10489-020-01933-8
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Herranz L, 2010, IEEE T CIRC SYST VID, V20, P1265, DOI 10.1109/TCSVT.2010.2057020
   Huang C, 2020, IEEE T CIRC SYST VID, V30, P577, DOI 10.1109/TCSVT.2019.2890899
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Hussein F, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3063532
   Iosifidis A., 2010, 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2010), P84, DOI 10.1109/AIM.2010.5695742
   Ishikawa S., 2008, Proceedings of the British Machine Vision Conference (BMVC'08), P1
   Itazuri T, 2017, IEEE COMPUT SOC CONF, P179, DOI 10.1109/CVPRW.2017.28
   Jegham I, 2019, LECT NOTES COMPUT SC, V11678, P518, DOI 10.1007/978-3-030-29888-3_42
   Jegham I, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200901
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Kakadiya Rutvik, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P201, DOI 10.1109/ICECA.2019.8822186
   Kalaivani P, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON RECENT TRENDS AND CHALLENGES IN COMPUTATIONAL MODELS (ICRTCCM), P61, DOI 10.1109/ICRTCCM.2017.84
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kim G, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P564, DOI [10.1109/ICAIIC.2019.8669083, 10.1109/icaiic.2019.8669083]
   Kini MM, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960003
   Koidan K, 2018, NEW DATASETS ACTION
   Koutras P., 2018, 2018 IEEE 13th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP), P1, DOI [10.1109/IVMSPW.2018.8448977, DOI 10.1109/IVMSPW.2018.8448977]
   Kumar KPS, 2019, CLUSTER COMPUT, V22, P10577, DOI 10.1007/s10586-017-1131-x
   Kushwaha A, 2017, J MATH CRYPTOL, V2, P90
   Li A, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107355
   Li Y, 2019, PATTERN ANAL APPL, V22, P601, DOI 10.1007/s10044-017-0660-5
   Liu AA, 2015, NEUROCOMPUTING, V151, P544, DOI 10.1016/j.neucom.2014.04.090
   Liu H., 2011, VIS ANAL HUM, DOI [10.1007/978-0-85729-997-0, DOI 10.1007/978-0-85729-997-0]
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Luna E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124290
   Ma Y, 2002, USER ATTENTION MODEL, P1
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Marvaniya S, 2016, IEEE IMAGE PROC, P176, DOI 10.1109/ICIP.2016.7532342
   McCue T, 2018, VIDEO MARKETING TREN
   MEI T, 2013, ACM T MULTIM COMPUT, V9, P3
   Milotta FLM, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102664
   Mlik N, 2012, OBJECT BASED EVENT D
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muszynski M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3175497
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Oskouie P, 2014, ARTIF INTELL REV, V42, P173, DOI 10.1007/s10462-012-9332-4
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Parihar AS, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102991
   Park H, 2020, IEEE ACCESS, V8, P80010, DOI 10.1109/ACCESS.2020.2990618
   Park H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235114
   Plummer BA, 2017, PROC CVPR IEEE, P1052, DOI 10.1109/CVPR.2017.118
   Rouast PV, 2020, IEEE J BIOMED HEALTH, V24, P1727, DOI 10.1109/JBHI.2019.2942845
   Rouvier M, 2015, IEEE-ACM T AUDIO SPE, V23, P1031, DOI 10.1109/TASLP.2014.2387411
   Sabha A, 2021, P 2021 IEEE INT C IN, P1, DOI [10.1109/ICSES52305.2021.9633804, DOI 10.1109/ICSES52305.2021.9633804]
   Sahu A, 2020, PATTERN RECOGN LETT, V133, P256, DOI 10.1016/j.patrec.2020.02.029
   Sarika, 2022, 135 VIDEO MARKETING
   Savage C, 2016, DOES LENGTH MATTER I
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shammi S, 2019, P 2018 INT C COMMUNI, P36, DOI [10.1109/IC3IoT.2018.8668135, DOI 10.1109/IC3IOT.2018.8668135]
   Shang XD, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1756, DOI 10.1145/3474085.3475321
   Sharma D, 2022, MULTIMED TOOLS APPL, V81, P22129, DOI 10.1007/s11042-021-11254-8
   Sharma D, 2022, VISUAL COMPUT, V38, P2999, DOI 10.1007/s00371-021-02173-8
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   Sood M, 2020, HINDUSTAN TIMES
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Sridevi M, 2020, PROCEDIA COMPUT SCI, V167, P1839, DOI 10.1016/j.procs.2020.03.203
   Srivastava AK, 2018, SMART INNOVATIVE TRE, V828, DOI [10.1007/978-981-10-8660-1_69, DOI 10.1007/978-981-10-8660-1_69]
   Staff R, 2020, VIDEO MARKETING STAT
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun S, 2018, MULTIMED TOOLS APPL, V77, P9093, DOI 10.1007/s11042-017-4807-6
   Suresh A.J., 2020, MATER TODAY-PROC, DOI [10.1016/j.matpr.2020.09.609, DOI 10.1016/J.MATPR.2020.09.609]
   Tabish M, 2024, MULTIMED TOOLS APPL, V83, P15101, DOI 10.1007/s11042-021-10519-6
   Tang KY, 2018, IEEE INT CONF BIG DA, P4619, DOI 10.1109/BigData.2018.8621906
   Terms I, 2015, INT C IMAGE PROCESS, P1
   Tian ZQ, 2014, MULTIMED TOOLS APPL, V72, P1773, DOI 10.1007/s11042-013-1488-7
   Tribune T, 2022, RASH DRIVING BLAME 9
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma Kamal Kant, 2022, International Journal of Information Technology, V14, P397, DOI 10.1007/s41870-019-00364-0
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vivekraj VK, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347712
   Wang F, 2012, IEEE T MULTIMEDIA, V14, P76, DOI 10.1109/TMM.2011.2165531
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang T, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/837275
   World Health Organization, 2018, Global status report on alcohol and health 2018
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xu JF, 2021, MULTIMED TOOLS APPL, V80, P6121, DOI 10.1007/s11042-020-09888-1
   Xu LJ, 2019, IEEE ACCESS, V7, P163806, DOI 10.1109/ACCESS.2019.2952432
   Yasmin G, 2023, NEURAL COMPUT APPL, V35, P4881, DOI 10.1007/s00521-021-06132-1
   Ying Zhang, 2014, ACM Transactions on Multimedia Computing, Communications and Applications, V11, DOI 10.1145/2659520
   Yoon DH, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107396
   Zhang B, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2750780
   Zhang YJ, 2020, PATTERN RECOGN LETT, V130, P376, DOI 10.1016/j.patrec.2018.07.030
   Zhang ZM, 2021, PERS UBIQUIT COMPUT, V25, P1027, DOI 10.1007/s00779-019-01281-6
   Zhao B, 2022, NEUROCOMPUTING, V468, P360, DOI 10.1016/j.neucom.2021.10.039
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu WC, 2021, IEEE T IMAGE PROCESS, V30, P948, DOI 10.1109/TIP.2020.3039886
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
   Zutshi A, 2021, TRACS TRANSFORMER VI
NR 135
TC 5
Z9 5
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32635
EP 32709
DI 10.1007/s11042-023-14925-w
EA MAR 2023
PG 75
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941913300005
DA 2024-07-18
ER

PT J
AU Xiao, YQ
   Wu, YJ
   Yang, F
AF Xiao, Yuqi
   Wu, Yongjun
   Yang, Fan
TI A scale adaptive generative target tracking method based on modified
   particle filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Generative tracker; Particle filter algorithm; Scale
   adaptive tracking frame
ID SWARM OPTIMIZATION; ALGORITHM; CROSSOVER
AB This paper proposes an advanced particle filter (PF) algorithm based on the quantum particle swarm optimization method (QPSO) and adaptive genetic algorithm (QAPF). After resampling of the PF, the position updating equation of the QPSO is applied to improve the particle distribution. Then replace the individuals with lower fitness with those with higher fitness. The genetic operation from the adaptive genetic algorithm (AGA) is then applied to increase the accuracy and sample diversity. An frame size adaptive adjustment model is proposed to reduce the number of useless features and improve the accuracy of target positioning. Multiple simulations of the nonlinear target tracking model are carried out, and the results demonstrate that the numerical stability, efficiency and accuracy of our QAPF algorithm are significantly better than those of other similar algorithms. QAPF is also compared with similar tracking algorithms via a set of tracking experiments. Our experiments on the OTB-100 dataset prove that the QAPF algorithm is much better than the PF, PF improved by particle swarm optimization (PSO-PF) and PF advanced by genetic algorithm (GAPF) tracking algorithms and other typical generative trackers in terms of the tracking precision, success rate, efficiency and robustness.
C1 [Xiao, Yuqi] West Anhui Univ, Sch Mech & Vehicle Engn, Luan City 237012, Anhui, Peoples R China.
   [Wu, Yongjun] Chongqing Jiaotong Univ, Sch Traff & Transportat, Chongqing 400074, Peoples R China.
   [Yang, Fan] Agr Bank China, Zhuzhou Branch, Zhuzhou 412000, Hunan, Peoples R China.
C3 West Anhui University; Chongqing Jiaotong University; Agricultural Bank
   of China
RP Xiao, YQ (corresponding author), West Anhui Univ, Sch Mech & Vehicle Engn, Luan City 237012, Anhui, Peoples R China.
EM csuxyq@163.com
RI Yang, Fan/L-6871-2019; Xiao, Yuqi/AFE-4884-2022
OI Yang, Fan/0000-0003-4801-763X; Wu, Yongjun/0000-0001-9073-6633
CR Al Mallah R, 2017, IEEE T INTELL TRANSP, V18, P2435, DOI 10.1109/TITS.2016.2641903
   An X, 2014, IET COMPUT VIS, V8, P235, DOI 10.1049/iet-cvi.2013.0004
   Bhat PG., 2021, IEEE SENS J, VPP
   Bhat PG, 2021, IEEE SENS J, V21, P10112, DOI 10.1109/JSEN.2021.3054815
   Bi J, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/6/068901
   Cheng WC, 2012, SENSORS-BASEL, V12, P17168, DOI 10.3390/s121217168
   Dai CH, 2006, PROCEEDINGS OF 2006 IEEE INFORMATION THEORY WORKSHOP, P710
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Hermes C, 2009, IEEE INT VEH SYM, P652, DOI 10.1109/IVS.2009.5164354
   Ji XF, 2021, IEEE T EVOLUT COMPUT, V25, P794, DOI 10.1109/TEVC.2021.3064835
   Kang L, 2009, J COMPUT AID MOL DES, V23, P1, DOI 10.1007/s10822-008-9232-5
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Lei F, 2015, 2015 4 INT C MECHATR
   Li TC, 2014, EXPERT SYST APPL, V41, P3944, DOI 10.1016/j.eswa.2013.12.031
   Li XH, 2010, OPT ENG, V49, DOI 10.1117/1.3327281
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin SFD, 2015, IET IMAGE PROCESS, V9, P959, DOI 10.1049/iet-ipr.2014.0666
   Liu TY, 2016, KNOWL-BASED SYST, V101, P90, DOI 10.1016/j.knosys.2016.03.009
   Mergos PE, 2023, EVOL INTELL, V16, P873, DOI 10.1007/s12065-022-00700-7
   Mozhdehi R., 2021, Advances In Computer Vision And Computational Biology, P27
   Mozhdehi RJ, 2021, ARXIV
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Ql A., 2021, PATTERN RECOGN, V112, P107766
   Rymut B, 2013, LECT NOTES COMPUT SC, V8192, P426, DOI 10.1007/978-3-319-02895-8_38
   Shmaliy YS, 2012, IEEE T SIGNAL PROCES, V60, P5519, DOI 10.1109/TSP.2012.2205569
   Sun J, 2012, INFORM SCIENCES, V193, P81, DOI 10.1016/j.ins.2012.01.005
   Tang DY, 2014, INFORM SCIENCES, V289, P162, DOI 10.1016/j.ins.2014.08.030
   Tanzmeister G, 2017, IEEE T INTELL TRANSP, V18, P1454, DOI 10.1109/TITS.2016.2608919
   Wang XY, 2010, OPT ENG, V49, DOI 10.1117/1.3281669
   Wang ZL, 2012, APPL OPTICS, V51, P5051, DOI 10.1364/AO.51.005051
   Xiao YQ, 2019, APPL INTELL, V49, P3864, DOI 10.1007/s10489-019-01480-x
   Xue Y, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106031
   Yalcinoz T, 2005, ENG INTELL SYST ELEC, V13, P45
   Yang JY, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/497639
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zhang T, 2013, KNOWL-BASED SYST, V53, P13, DOI 10.1016/j.knosys.2013.07.015
   Zhang XY, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/54047
   Zhao B, 2015, INT C AUTOMATION MEC
   Zhou ZP, 2016, MULTIMED TOOLS APPL, V75, P3145, DOI 10.1007/s11042-014-2427-y
NR 41
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31329
EP 31349
DI 10.1007/s11042-023-14901-4
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000941913300002
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Akintoye, KA
   Asadianfam, S
   Rahim, MS
AF Kolivand, Hoshang
   Akintoye, Kayode Akinlekan
   Asadianfam, Shiva
   Rahim, Mohd Shafry
TI Improved methods for finger vein identification using composite
   Median-Wiener filter and hierarchical centroid features extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric system; Finger vein identification; Composite Median-Wiener;
   Feature extraction; Hierarchical Centroid Feature Method
ID GAUSSIAN-IMPULSE NOISE; IMAGE RETRIEVAL; RESTORATION; ENHANCEMENT;
   FUSION
AB Finger vein patterns contain highly discriminative characteristics, which are difficult to be forged due to residing underneath the skin. Several pieces of research have been carried out in this field but there is still an unresolved issue when data capturing and processing is of low quality. Low-quality data have caused errors in the feature extraction process and reduced identification performance rate in finger vein identification. The objective of this paper is to address this issue by presenting two methods, a new image enhancement, and a feature extraction method. The image enhancement, Composite Median-Wiener (CMW) filter, improves image quality and preserves the edges. Moreover, the feature extraction method, Hierarchical Centroid Feature Method (HCM), is fused with the statistical pixel-based distribution feature method at the feature-level fusion to improve the performance of finger vein identification. These methods were evaluated on public SDUMLA-HMT and FV-USM finger vein databases. Each database was divided into training and testing sets. The average result of the experiments conducted was taken to ensure the accuracy of the measurements. The k-Nearest Neighbor classifier with city block distance to match the features was implemented. Both these methods produced accuracy as high as 97.64% for identification rate and 1.11% of equal error rate (EER) for measures verification rate. These showed that the accuracy of the proposed finger vein identification method is higher than the existing methods. The results have proven that the CMW filter and HCM have significantly improved the accuracy of finger vein identification.
C1 [Kolivand, Hoshang; Asadianfam, Shiva] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, England.
   [Akintoye, Kayode Akinlekan; Rahim, Mohd Shafry] Univ Teknol Malaysia, Inst Human Centred Engn, MAGICX Media & Games Innovat Ctr Excellence, Johor Baharu 81310, Johor, Malaysia.
   [Asadianfam, Shiva] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
   [Asadianfam, Shiva] Islamic Azad Univ, Qom Branch, Dept Comp Engn, Qom, Iran.
C3 University of Liverpool; Liverpool John Moores University; Universiti
   Teknologi Malaysia; Islamic Azad University
RP Asadianfam, S (corresponding author), Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, England.; Asadianfam, S (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.; Asadianfam, S (corresponding author), Islamic Azad Univ, Qom Branch, Dept Comp Engn, Qom, Iran.
EM h.kolivand@ljmu.ac.uk; A.akin@live.utm.my; sh_asadianfam@yahoo.com;
   Shafry@utm.my
RI Kolivand, Hoshang/F-4736-2011; asadianfam, shiva/ABF-1231-2021;
   Kolivand, Hoshang/B-2501-2016
OI asadianfam, shiva/0000-0002-0062-7079; Kolivand,
   Hoshang/0000-0001-5460-5679
CR Ahamed JN., 2009, AM J SCI RES, V3, P5
   Ahmad SMS, 2012, INT J INNOV COMPUT I, V8, P7983
   Akintoye KA, 2017, INT J COMPUT APPL, V157
   Amara N. E. B., 2003, International Journal on Document Analysis and Recognition, V5, P195, DOI 10.1007/s10032-002-0092-6
   [Anonymous], 2012, INF SCI IND APPL
   [Anonymous], 2013, AUTOMATED BIOMETRICS
   [Anonymous], 2006, Handbook of Multibiometrics
   Arora S, 2017, 2017 4 INT C SIGNAL, V7
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   Beniwal P, 2013, INT J MED RES HEALTH, V1
   Chen TP, 2004, IEEE IMAGE PROC, P1253
   Chetna S., 2016, INT CONF ADVAN COMPU, V4, P35
   Cui Jian-jiang, 2009, Journal of Northeastern University (Natural Science), V30, P1099
   Datta S, 2019, IRBM, V40, P174, DOI 10.1016/j.irbm.2019.04.001
   Ezhilmaran D, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P271, DOI 10.1109/I-SMAC.2017.8058353
   Ezhilmaran D., 2015, INT J PHARMTECH RES, V8, P222
   Filipovic M, 2014, EUR SIGNAL PR CONF, P1637
   Fotopoulou F, 2013, PATTERN ANAL APPL, V16, P381, DOI 10.1007/s10044-011-0254-6
   Gupta A., 2014, INT J CURR ENG TECHN, V4, P3904
   Gupta P, 2015, DIGIT SIGNAL PROCESS, V38, P43, DOI 10.1016/j.dsp.2014.12.003
   Jain A. K., 2010, Second Gener Biom, V12, P2
   Jain AK, 2015, PHILOS T R SOC B, V370, DOI 10.1098/rstb.2014.0254
   Kang BJ, 2009, OPT ENG, V48, DOI 10.1117/1.3212651
   Kellman PJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094617
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Lin L, 2018, J INF PROCESS SYST, V14, P539, DOI 10.3745/JIPS.02.0083
   Liu T, 2013, IMAGING SCI J, V61, P491, DOI 10.1179/1743131X12Y.0000000013
   [路文 LU Wen], 2008, [电子学报, Acta Electronica Sinica], V36, P303
   Maragos P, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P135, DOI 10.1016/B978-012119792-6/50072-3
   Market B, 2008, IND REP 2009 2014
   Mukahar N, 2017, J PHYS CONF SER, V890, DOI 10.1088/1742-6596/890/1/012069
   Podgantwar UD., 2013, INT J ENG RES TECHNO, V2, P3294
   Proença H, 2011, IEEE T INF FOREN SEC, V6, P82, DOI 10.1109/TIFS.2010.2086446
   Qin HF, 2018, MULTIMED TOOLS APPL, V77, P2505, DOI 10.1007/s11042-016-4317-y
   Ramachandran V., 1966, IETE J ED, V7, P139, DOI [10.1080/09747338.1966.11467878, DOI 10.1080/09747338.1966.11467878]
   Rhodes K., 2003, Information security: Challenges in using biometrics
   Rodriguez P., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), P1077, DOI 10.1109/ICASSP.2012.6288073
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Shangqing Wei, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P1693, DOI 10.1109/TMEE.2011.6199537
   Shareef RAQ., 2015, INT J COMPUTER SCI M, V4, P1
   SHARMA S, 2014, INT J ADV SCI TECHNO, V2, P32
   Shazia Bakhtiar Affendi, 2016, INDIAN J SCI TECHNOL, V9, DOI [10.17485/ijst/2016/v9i48/109315, DOI 10.17485/ijst/2016/v9i48/109315]
   Shi YH, 2012, INT CONF SIGN PROCES, P1605, DOI 10.1109/ICoSP.2012.6491887
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   Shrikhande SP, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1646, DOI 10.1109/ICACCI.2015.7275849
   Shrikhande SP., 2016, INT J COMPUT APPL, V149, P28
   Sim KS, 2016, SCANNING, V38, P148, DOI 10.1002/sca.21250
   Smith M., 2018, Biometrics crime and security, DOI [10.4324/9781315182056, DOI 10.4324/9781315182056]
   Subramaniam B, 2018, MULTIPLE FEATURES CL, DOI [10.4066/biomedicalresearch.29-16-2318, DOI 10.4066/BIOMEDICALRESEARCH.29-16-2318]
   Syazana-Itqan K., 2016, Indian J. Sci. Technol, V9, P1
   Wang MW, 2017, MULTIMED TOOLS APPL, V76, P14937, DOI 10.1007/s11042-016-4285-2
   Wei Pi, 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P424, DOI 10.1109/ICEIE.2010.5559667
   Xueyan L., 2008, The fourth biometric-vein recognition
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yang GP, 2013, SENSORS-BASEL, V13, P12093, DOI 10.3390/s130912093
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2011, COMPUT HUM BEHAV, V27, P1565, DOI 10.1016/j.chb.2010.10.029
   Yang W, 2011, HAND BAS BIOM ICHB 2, P1
   Yousefi F, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P564
   Yuan T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086528
NR 61
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 31913
EP 31944
DI 10.1007/s11042-023-14469-z
EA MAR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941926100014
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Ed-daoudy, A
   Maalmi, K
   El Ouaazizi, A
AF Ed-daoudy, Abderrahmane
   Maalmi, Khalil
   El Ouaazizi, Aziza
TI A scalable and real-time system for disease prediction using big data
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; Streaming processing; Machine learning; MLlib; Apache Spark;
   Tweet processing
ID LOGISTIC-REGRESSION; ARCHITECTURE; ANALYTICS; INTERNET; TWITTER; THINGS
AB The growing chronic diseases patients and the centralization of medical resources cause significant economic impact resulting in hospital visits, hospital readmission, and other healthcare costs. This paper proposes a scalable and real-time system for disease prediction from medical data streams. This is carried out by integrating Twitter, Apache Kafka, Apache Spark and Apache Cassandra. Thus, Twitter users tweet attributes related to health, Kafka streaming receives all desired tweets attributes and ingest them to Spark streaming. Here, a machine learning algorithm is applied to predict health status and send back a response message through Kafka. The heart disease dataset, obtained from the UCI repository, was used for experiments. In order to enhance prediction accuracy, Relief algorithm is used for features selection. We compared sex types of relevant machine learning algorithms implemented by Spark MLlib such as Random Forest (RF), Naive Bayes, Support Vector Machine, Multilayer Perceptron, Decision Tree and Logistic Regression with the full features as well as selected features. The highest classification accuracy of 92.05% was reported using RF with selected features. The scalability of RF using Spark MLlib and WEKA framework for both training and application stages was measured. The results show significantly better performances of Spark in terms of scalability and computing times.
C1 [Ed-daoudy, Abderrahmane; Maalmi, Khalil; El Ouaazizi, Aziza] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci ENSA, Artificial Intelligence Data Sci & Emerging Syst L, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Ed-daoudy, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci ENSA, Artificial Intelligence Data Sci & Emerging Syst L, Fes, Morocco.
EM a.eddaoudy@gmail.com; khalil.maalmi@usmba.ac.ma;
   aziza.elouaazizi@usmba.ac.ma
CR Abbasi A, 2014, IEEE INTELL SYST, V29, P60, DOI 10.1109/MIS.2014.29
   Acharjya DP, 2016, INT J ADV COMPUT SC, V7, P511
   Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Al Rasyid MUH, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P409, DOI 10.1109/ELECSYM.2016.7861041
   Ali SM, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P656, DOI 10.1109/IC3I.2016.7918044
   [Anonymous], 2017, AP SPARK DOC OFF WEB
   [Anonymous], 2017, AP ZEPP OFF WEBP AP
   [Anonymous], 2015, INDIAN J SCI TECHNOL
   [Anonymous], 2017, AP SPARK OFF WEBP AP
   [Anonymous], 2020, HEART DIS UCI
   [Anonymous], 2017, AP KAFK OFF WEBP AP
   [Anonymous], 2017, AP CASS OFF WEBP AP
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Basheer S, 2021, SOFT COMPUT, V25, P12145, DOI 10.1007/s00500-021-05865-4
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Chen HC, 2012, MIS QUART, V36, P1165
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Condie T, 2013, PROC INT CONF DATA, P1242, DOI 10.1109/ICDE.2013.6544913
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Ed-daoudy A, 2020, HEALTH TECHNOL-GER, V10, P1145, DOI 10.1007/s12553-020-00460-3
   Ed-daoudy A, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0271-7
   Ed-daoudy A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723839
   Ed-daoudy A, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT)
   Fayyad U, 1996, AI MAG, V17, P37
   Gao DH, 2014, IEEE-ACM T AUDIO SPE, V22, P293, DOI 10.1109/TASL.2013.2282191
   Han SH, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120293
   Hassan M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P364, DOI 10.1109/IRI.2018.00061
   Hazarika AV, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P671, DOI 10.1109/I-SMAC.2017.8058263
   Heydari ST, 2012, J MED SYST, V36, P2449, DOI 10.1007/s10916-011-9711-4
   Ismail A, 2019, Security in Smart Cities: Models, Applications, and Challenges, P27, DOI [10.1007/978-3-030-01560-2_2, DOI 10.1007/978-3-030-01560-2_2]
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kolajo T, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0210-7
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Lakshman Avinash, 2010, Operating Systems Review, V44, P35, DOI 10.1145/1773912.1773922
   Lee K, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1474
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722
   Meng XR, 2016, J MACH LEARN RES, V17
   Mostafaeipour A, 2021, J SUPERCOMPUT, V77, P1273, DOI 10.1007/s11227-020-03328-5
   Nasiri H, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0215-2
   Pourahmad S, 2011, COMPUT MATH APPL, V62, P3353, DOI 10.1016/j.camwa.2011.08.050
   Rallapalli S, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND ENGINEERING (ICACCE 2016), P281, DOI 10.1109/ICACCE.2016.8073762
   Rathore MM, 2017, ACM T INTERNET TECHN, V18, DOI 10.1145/3108936
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Sampath P, 2017, INT J BIOMED ENG TEC, V23, P137, DOI 10.1504/IJBET.2017.10003493
   Sreejith S, 2016, ADV INTELL SYST, V425, P485, DOI 10.1007/978-3-319-28658-7_41
   Ta VD, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2016), P37, DOI 10.1109/ICCCBDA.2016.7529531
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Trigo JD, 2013, COMPUT CARDIOL CONF, V40, P33
   Veiga J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P424, DOI 10.1109/BigData.2016.7840633
   Venkatesh R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1398-y
   Wachowicz M, 2016, COMPUT ENVIRON URBAN, V59, P256, DOI 10.1016/j.compenvurbsys.2015.12.001
   Weka, 2017, WEK OFF WEBP WEK
   Yan K, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P157, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.34
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zaldumbide J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, P9, DOI 10.1109/DSDIS.2015.27
   Zhao TZ, 2014, LECT NOTES COMPUT SC, V8423, P95
NR 58
TC 4
Z9 4
U1 7
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30405
EP 30434
DI 10.1007/s11042-023-14562-3
EA FEB 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936302600001
DA 2024-07-18
ER

PT J
AU Wang, JJ
   He, ML
   Xu, WJ
   Jing, F
AF Wang, Jujie
   He, Maolin
   Xu, Wenjie
   Jing, Feng
TI A deep learning-based nonlinear ensemble approach with biphasic feature
   selection for multivariate exchange rate forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exchange rate forecasting; Biphasic feature selection; Deep learning;
   Nonlinear ensemble framework
ID NEURAL-NETWORKS; MODELS; PERFORMANCE; VOLATILITY; REGRESSION
AB Exchange rate prediction is a challenging task for investors and policymakers due to its nonstationary and nonlinear characteristics. This study develops a novel deep learning-based nonlinear ensemble approach with biphasic feature selection for multivariate exchange rate forecasting. The novel hybrid model has three modules, the preprocessing of target series, feature engineering, and forecasting module. The first module aims to extract more regular signals and reduce the dimension of the target series for better feeding into the forecasting module. The second part is the selection and reconstruction of twelve external variables, which outputs three sequences that contain the most important information. The forecasting part consists of Bi-directional long short-term memory and attention mechanism, which has better performance than the basic artificial intelligence algorithms. Three evaluation indicators are adopted to assess the hybrid model's performance. The results show that the new model performs better than other compared models.
C1 [Wang, Jujie; He, Maolin; Xu, Wenjie; Jing, Feng] Nanjing Univ Informat Sci & Technol, Sch Management Sci & Engn, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Wang, JJ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Management Sci & Engn, Nanjing 210044, Peoples R China.
EM jujiewang@126.com
RI Xu, Wenjie/GYJ-6557-2022
OI Xu, Wenjie/0000-0002-7778-0450
FU National Natural Science Foundation of China [71971122, 71501101]
FX AcknowledgmentsThis research was supported by the National Natural
   Science Foundation of China (Grant No. 71971122 and 71501101).
CR Abhyankar A, 2005, J INT ECON, V66, P325, DOI 10.1016/j.jinteco.2004.09.003
   Baffour AA, 2019, NEUROCOMPUTING, V365, P285, DOI 10.1016/j.neucom.2019.07.088
   Bai Y, 2019, WATER RESOUR MANAG, P15
   Barunik J, 2016, EUR J OPER RES, V251, P329, DOI 10.1016/j.ejor.2015.12.010
   Cai Z., 2012, STUD NONLINEAR DYN E, V16, P1878, DOI DOI 10.1515/1558-3708
   Chortareas G, 2011, INT J FORECASTING, V27, P1089, DOI 10.1016/j.ijforecast.2010.07.003
   Dunis CL, 2002, J FORECASTING, V21, P317, DOI 10.1002/for.833
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Galeshchuk S, 2016, NEUROCOMPUTING, V172, P446, DOI 10.1016/j.neucom.2015.03.100
   He KJ, 2018, PHYSICA A, V510, P15, DOI 10.1016/j.physa.2018.05.135
   Huang ML, 2014, SCI WORLD J, DOI 10.1155/2014/795624
   Huang YS, 2019, J CLEAN PROD, V209, P415, DOI 10.1016/j.jclepro.2018.10.128
   Kwok, 1998, GLOB FINANC J, V9, P5, DOI DOI 10.1016/S1044-0283(98)90012-6
   Li J, 2021, IEEE T IND INFORM, V17, P2443, DOI 10.1109/TII.2020.3000184
   Li YZ, 2021, ENERG ECON, V95, DOI 10.1016/j.eneco.2021.105140
   Liu H, 2019, RENEW ENERG, P13
   Medeiros MC, 2001, IEEE T NEURAL NETWOR, V12, P755, DOI 10.1109/72.935089
   MEESE RA, 1983, J INT ECON, V14, P3, DOI 10.1016/0022-1996(83)90017-X
   Peng T, 2021, ENERGY, V221, DOI 10.1016/j.energy.2021.119887
   Qiao WB, 2020, ENERGY, V193, P511, DOI 10.1016/j.energy.2019.116704
   Raji CG, 2017, IEEE T SYST MAN CY-S, V47, P2318, DOI 10.1109/TSMC.2017.2661996
   Rapach DE, 2006, INT J FORECASTING, V22, P341, DOI 10.1016/j.ijforecast.2005.09.006
   Rodrigues PC, 2020, COMMUN STAT-SIMUL C, V49, P591, DOI 10.1080/03610918.2019.1664578
   Santos DSD, 2019, KNOWL-BASED SYST, V175, P72, DOI 10.1016/j.knosys.2019.03.011
   Sermpinis G, 2015, EUR J OPER RES, V247, P831, DOI 10.1016/j.ejor.2015.06.052
   Sermpinis G, 2012, DECIS SUPPORT SYST, V54, P316, DOI 10.1016/j.dss.2012.05.039
   Shen FR, 2015, NEUROCOMPUTING, V167, P243, DOI 10.1016/j.neucom.2015.04.071
   Sun SL, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101160
   Sun SL, 2020, IEEE T SYST MAN CY-S, V50, P2284, DOI 10.1109/TSMC.2018.2799869
   Tyree EW, 1995, P 3 INT C ART INT AP, P11
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang JJ, 2022, ENVIRON SCI POLLUT R, V29, P85988, DOI 10.1007/s11356-021-16089-2
   WEST KD, 1995, J ECONOMETRICS, V69, P367, DOI 10.1016/0304-4076(94)01654-I
   Xue YT, 2018, APPL INTELL, V48, P3306, DOI 10.1007/s10489-018-1140-3
   Yang HF, 2019, ARTIF INTELL, V277, DOI 10.1016/j.artint.2019.103176
   Yang HL, 2017, COMPUT ECON, V49, P99, DOI 10.1007/s10614-015-9549-9
   Yang SM, 2020, SCI TOTAL ENVIRON, V716, DOI 10.1016/j.scitotenv.2020.137117
   Yu L, 2008, NEUROCOMPUTING, V71, P3295, DOI 10.1016/j.neucom.2008.04.029
   Yunjie Wei, 2019, Journal of Management Science and Engineering, V4, P45, DOI 10.1016/j.jmse.2019.02.001
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
   Zhang Q, 2020, J ELECTR ENG TECHNOL, V15, P635, DOI 10.1007/s42835-020-00358-0
   Zhou FT, 2022, APPL ENERG, V311, DOI 10.1016/j.apenergy.2022.118601
   Zhu JM, 2019, INT J MACH LEARN CYB, V10, P3349, DOI 10.1007/s13042-019-00922-9
NR 43
TC 0
Z9 0
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22961
EP 22979
DI 10.1007/s11042-023-14497-9
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936501100008
DA 2024-07-18
ER

PT J
AU Rao, BC
   Raju, K
   Babu, GR
   Pittala, CS
AF Rao, B. Chinna
   Raju, K.
   Babu, G. Ramesh
   Pittala, Chandra Sekhar
TI An improved GABOR wavelet transform and rough k-means clustering
   algorithm for MRI BRAIN tumor image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Oppositional fruit fly algorithm; Image segmentation; Rough K-means;
   Gabor wavelet transform; Feature extraction; Preprocessing
ID TEXTURE
AB Our Proposed research is about tumor identification in the human brain. Here, MRI images are considered as the key factor in this research. There are five stages included in this proposed research and the very first stage is pre-processing followed by feature extraction, feature selection, classification, and finally segmentation. The input images are changed into transforming domain, then it happens with the assistance of Improved Gabor Wavelet Transform (IGWT). By Oppositional fruit fly algorithm (OFFA), the features called GLCM reside features are extracted and predominant features are also got chosen. To confirm whether the images look normal or abnormal, the chosen features are handed over to the SVM (Support Vector Machine) classifier. Once the classification process gets completed, the abnormally looking images are then picked out and the images are sent to the next process called segmentation. We used a rough k-means algorithm for the successful segmentation process. In comparison with other existing researches, our work seems structured and efficient. And Based on some evaluation metrics we estimated our efficiency and performance.
C1 [Rao, B. Chinna; Babu, G. Ramesh] Raghu Engn Coll, Dept ECE, Visakhapatnam, Andhra Pradesh, India.
   [Raju, K.] Narasaraopeta Engn Coll Autonomous, Dept ECE, Narasaraopeta, Andhra Pradesh, India.
   [Pittala, Chandra Sekhar] MLR Inst Technol, Dept ECE, Hyderabad, India.
C3 MLR Institute of Technology
RP Rao, BC (corresponding author), Raghu Engn Coll, Dept ECE, Visakhapatnam, Andhra Pradesh, India.
EM chinnaraob84@gmail.com
CR Adjei P.E., 2018, International Journal of Computer Applications, V181, P1
   Al-Dmour H, 2018, NEUROCOMPUTING, V275, P546, DOI 10.1016/j.neucom.2017.08.051
   Angulakshmi M, 2018, Journal of King Saud University-Computer and Information Sciences
   Chanchlani A, 2017, IMP J INTERDISCIP RE, V3
   Chanu MM, 2021, J AMB INTEL HUM COMP, V12, P6911, DOI 10.1007/s12652-020-02336-w
   Chen JY, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102615
   Chinnam SKR, 2019, TRAIT SIGNAL, V36, P185, DOI 10.18280/ts.360209
   ChinnaRao B., 2018, INT J ADV ROBOT SYST, V10, P1645
   ChinnaRao B., 2019, INT J ADV TRENDS COM, V8, P2299, DOI [10.30534/ijatcse/2019/68852019, DOI 10.30534/IJATCSE/2019/68852019]
   ChinnaRao B., 2020, J COMPUTATI THEOR NA, V17, P1770, DOI [10.1166/jctn.2020.8440, DOI 10.1166/JCTN.2020.8440]
   ChinnaRao B, 2019, INT J ENVIRON SCI TE, V8
   ChinnaRao B, 2019, INT J INNOV TECHNOL, V8
   Gokulalakshmi A, 2020, SOFT COMPUT, V24, P18599, DOI 10.1007/s00500-020-05096-z
   Hu A, 2021, INT J IMAG SYST TECH, V31, P657, DOI 10.1002/ima.22495
   Iqbal MJ, 2022, MULTIMED TOOLS APPL, V81, P38409, DOI 10.1007/s11042-022-13166-7
   Jiang XY, 2020, IEEE T IMAGE PROCESS, V29, P736, DOI 10.1109/TIP.2019.2934572
   Khairandish MO, 2022, IRBM, V43, P290, DOI 10.1016/j.irbm.2021.06.003
   Khalili N, 2019, MAGN RESON IMAGING, V64, P77, DOI 10.1016/j.mri.2019.05.020
   Krishnakumar S, 2021, J AMB INTEL HUM COMP, V12, P6751, DOI 10.1007/s12652-020-02300-8
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Li CR, 2019, EXPERT SYST APPL, V137, P453, DOI 10.1016/j.eswa.2019.05.034
   Miao JQ, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106200
   Nair LR, 2021, J AMB INTEL HUM COMP, V12, P5917, DOI 10.1007/s12652-020-02139-z
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Shingade S., 2017, TECHNIQUES, V4, P16
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Tarhini GM., 2020, INT J SIGNAL PROCESS, V8, P19, DOI [10.18178/ijsps.8.1.19-25, DOI 10.18178/IJSPS.8.1.19-25]
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
NR 28
TC 0
Z9 0
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28143
EP 28164
DI 10.1007/s11042-023-14485-z
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934222700003
DA 2024-07-18
ER

PT J
AU Zakaria, ZA
   Ebadi, H
   Ahmadi, FF
AF Alizadeh Zakaria, Zahra
   Ebadi, Hamid
   Farnood Ahmadi, Farshid
TI Investigation of the application of geospatial artificial intelligence
   for integration of earthquake precursors extracted from remotely sensed
   SAR and thermal images for earthquake prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Earthquake prediction; Earthquake precursors;
   Remote sensing; InSAR; Thermal sensors
ID CRUSTAL DEFORMATION; IONOSPHERIC ANOMALIES; RADAR INTERFEROMETRY;
   VELOCITY; JAPAN; TIME
AB The main factors contributing to the occurrence of an earthquake are under the crust. Also; due to the lack of access to direct measurements of these factors and the parameters involved in the occurrence of an earthquake, the main goal of researchers is to study the earthquake occurrence through its precursors. Currently, monitoring and identifying some of these precursors are made possible by geomatics technologies. It is an undeniable fact that the behavioral variations of the precursors don't follow a common pattern in all earthquakes. Also, the variations of the precursors show peculiar behaviors in each region. So, it seems infeasible to provide an accurate prediction based on the analysis of the behavioral variations of a single precursor. Unlike previous studies, this study doesn't have a single-parametrical orientation toward an earthquake prediction process. Accordingly, this study aims to extract the trend of variations in crustal deformation anomalies and thermal anomalies before the earthquake to analyze them through an integrated process based on data mining methods. As a result, the tests of earthquake predictions for 17 cases have shown that the proposed method can make a reliable prediction of the probable time and magnitude range of oblique-thrust earthquakes with a magnitude greater than 5.5. Moreover, the proposed method has been able to accurately estimate the occurrence of the 26th November 2019 Albania earthquake (Mw = 6.4) as well as 21th September 2019 Albania earthquake (Mw = 5.6) before they happen.
C1 [Alizadeh Zakaria, Zahra; Ebadi, Hamid] KN Toosi Univ Technol, Departmant Geodesy & Geomat Engn, Tehran, Iran.
   [Farnood Ahmadi, Farshid] Univ Tabriz, Dept Geomat Engn, 29 Bahman Blvd, Tabriz, Iran.
C3 K. N. Toosi University of Technology; University of Tabriz
RP Ahmadi, FF (corresponding author), Univ Tabriz, Dept Geomat Engn, 29 Bahman Blvd, Tabriz, Iran.
EM farnood@tabrizu.ac.ir
CR Zakaria ZA, 2020, ACTA GEOPHYS, V68, P51, DOI 10.1007/s11600-019-00390-3
   Alvan HV, 2011, NAT POSTGR C NPC PUB, P1
   Asim KM, 2017, NAT HAZARDS, V85, P471, DOI 10.1007/s11069-016-2579-3
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P5375, DOI 10.1016/j.jksuci.2021.05.006
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Blewitt G., 2007, Treatise on Geophysics, Volume 3: Geodesy, V3, P351, DOI DOI 10.1016/B978-044452748-6.00058-4
   Bondur VG, 2021, IZV ATMOS OCEAN PHY+, V57, P991, DOI 10.1134/S0001433821090425
   Calais E, 2003, J GEOPHYS RES-SOL EA, V108, DOI 10.1029/2002JB002373
   Dautermann T, 2007, J GEOPHYS RES-SOL EA, V112, DOI 10.1029/2006JB004447
   DAVIES K, 1965, J GEOPHYS RES, V70, P2251, DOI 10.1029/JZ070i009p02251
   De Weerdt J., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P148, DOI 10.1109/CIDM.2011.5949428
   Dumka RK, 2022, J GEOD GEODYN, V13, P254, DOI 10.1016/j.geog.2021.05.004
   Fadilah M, 2021, IOP C SERIES EARTH E
   Grant RA, 2015, PHYS CHEM EARTH, V85-86, P69, DOI 10.1016/j.pce.2015.02.012
   Gu G, 2013, INT CONF WIRE COMMUN, V4, P9
   Guo GM, 2008, INT J REMOTE SENS, V29, P1921, DOI 10.1080/01431160701373762
   HAGER BH, 1991, ANNU REV EARTH PL SC, V19, P351, DOI 10.1146/annurev.ea.19.050191.002031
   Han P, 2011, NAT HAZARD EARTH SYS, V11, P965, DOI 10.5194/nhess-11-965-2011
   Han SC, 2006, SCIENCE, V313, P658, DOI 10.1126/science.1128661
   Hayakawa Masashi, 2013, Animals, V3, P19, DOI 10.3390/ani3010019
   Ida Y, 2022, PURE APPL GEOPHYS, V179, P1, DOI 10.1007/s00024-021-02916-7
   Ingebritsen SE, 2014, NAT GEOSCI, V7, P697, DOI 10.1038/ngeo2261
   Jade S, 2004, CURR SCI INDIA, V86, P1443
   Kraemer H.C., 2014, Wiley StatsRef: Statistics reference online, P1
   Li Q, 2021, REMOTE SENS ENVIRON, V262, DOI 10.1016/j.rse.2021.112508
   Lippiello E, 2012, SCI REP-UK, V2, DOI 10.1038/srep00846
   Liu J, 2022, J GEOD GEODYN, V13, P415, DOI 10.1016/j.geog.2022.02.004
   Lucente FP, 2010, GEOLOGY, V38, P1015, DOI 10.1130/G31463.1
   Massonnet D, 1998, REV GEOPHYS, V36, P441, DOI 10.1029/97RG03139
   Mohamed EK, 2022, ARAB J SCI ENG, V47, P7387, DOI 10.1007/s13369-021-06524-4
   Molchanov O, 2006, NAT HAZARD EARTH SYS, V6, P745, DOI 10.5194/nhess-6-745-2006
   Moreno M, 2010, NATURE, V467, P198, DOI 10.1038/nature09349
   Moro M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12058-3
   Ogata Y, 2012, GEOPHYS J INT, V191, P1237, DOI 10.1111/j.1365-246X.2012.05645.x
   Park SM, 2021, ADV SPACE RES, V68, P4137, DOI 10.1016/j.asr.2021.07.026
   PEACOCK S, 1988, J GEOPHYS RES-SOLID, V93, P3339, DOI 10.1029/JB093iB04p03339
   Pulinets S., 2004, Ionospheric Precursors of Earthquakes
   Pulinets SA, 2006, PHYS CHEM EARTH, V31, P143, DOI 10.1016/j.pce.2006.02.042
   Pulinets S, 2014, ADV SPACE RES, V53, P709, DOI 10.1016/j.asr.2013.12.035
   RIKITAKE T, 1975, B SEISMOL SOC AM, V65, P1133
   Saraf AK, 2009, INT J APPL EARTH OBS, V11, P373, DOI 10.1016/j.jag.2009.07.003
   THOMAS D, 1988, PURE APPL GEOPHYS, V126, P241, DOI 10.1007/BF00878998
   Thomas JN, 2015, NAT HAZARD EARTH SYS, V15, P1061, DOI 10.5194/nhess-15-1061-2015
   Tomás R, 2014, ENVIRON EARTH SCI, V71, P163, DOI 10.1007/s12665-013-2422-z
   Tronin AA, 2002, J GEODYN, V33, P519, DOI 10.1016/S0264-3707(02)00013-3
   Wang T, 2013, GEOPHYS RES LETT, V40, P2631, DOI 10.1002/grl.50554
   Ward SN, 2004, B SEISMOL SOC AM, V94, P2079, DOI 10.1785/0120040049
   Wen Y, EARTH PLANET PHYS, V6, P1
   Xiong P, 2021, SCI TOTAL ENVIRON, V771, DOI 10.1016/j.scitotenv.2021.145256
   Xu M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163075
   Yao YB, 2012, CHINESE SCI BULL, V57, P500, DOI 10.1007/s11434-011-4851-y
   Yue H, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL048700
NR 52
TC 4
Z9 4
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22853
EP 22870
DI 10.1007/s11042-023-14611-x
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000937945000011
DA 2024-07-18
ER

PT J
AU Vedantham, R
   Reddy, ES
AF Vedantham, Ramachandran
   Reddy, Edara Sreenivasa
TI Facial emotion recognition on video using deep attention based
   bidirectional LSTM with equilibrium optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Optimization algorithm; Deep network; Optical flow;
   Feature extraction; And selection
ID MOTION
AB Facial emotion recognition (FER) from videos is now considered a significant role in HCI (Human-Computer Interaction). The dynamic variations shown by various facial movements need to be realized quickly without degrading the recognition performance. Therefore, the procedure of classifying the facial emotions from videos is now demanded as a challenging and interesting issue. This work proposes a practical methodology for identifying emotions through facial expressions from videos. At first, the Lucas-Kanade (LK) based optical flow scheme is used for motion detection from the input videos. After finding the set of LK frames, the pre-processing scheme is applied. In this process, the Viola-Jones algorithm is utilized for face detection, and then the gray scale conversion is involved. Moreover, the FAST corner detection approach is used to detect the facial landmark points over the gray scale frame. The Neighborhood Difference Features (NDF) are extracted in feature extraction (FE). The optimal set of features is selected from the mined features using the Modified Plant Genetics-Inspired Evolutionary Optimization (MPGEO) algorithm in the feature selection (FS). Finally, the chosen features are fed into the Deep Attention-based Bidirectional LSTM with Equilibrium Optimizer (DABLEO) classifier for the emotion classification. The proposed scheme is performed in the Python software using four standard datasets like FAMED, CK+, AFEW, and MMI, and it delivers the classification accuracy of 96.5%, 99.2%, 90%, and 92% individually. As related to other schemes, the proposed scheme is better for all performances of emotion recognition.
C1 [Vedantham, Ramachandran] Vasireddy Venkatadri Inst Technol, CSE Dept, Nambur, Andhra Pradesh, India.
   [Reddy, Edara Sreenivasa] Acharya Nagarjuna Univ, ANU Coll Engn & Technol, Nambur, Andhra Pradesh, India.
C3 Acharya Nagarjuna University
RP Vedantham, R (corresponding author), Vasireddy Venkatadri Inst Technol, CSE Dept, Nambur, Andhra Pradesh, India.
EM vrc.bhatt@vvit.net
RI Ramachandran, Vedantham/E-7627-2016
OI Ramachandran, Vedantham/0000-0002-3857-8145
CR Abdulsalam Wisal Hashim, 2019, International Journal of Machine Learning and Computing, V9, P14, DOI 10.18178/ijmlc.2019.9.1.759
   Al-Tuwaijari Jamal M., 2020, 2020 6th International Engineering Conference, Sustainable Technology and Development (IEC). Proceedings, P211, DOI 10.1109/IEC49899.2020.9122927
   Alreshidi A, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7010006
   [Anonymous], 2020, FRONTIER APPL NATURE
   Basbrain Arwa, 2020, Intelligent Data Engineering and Automated Learning - IDEAL 2020. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12489), P197, DOI 10.1007/978-3-030-62362-3_18
   Ben Abdallah Taoufik, 2020, Advanced Concepts for Intelligent Vision Systems. 20th International Conference, ACIVS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12002), P504, DOI 10.1007/978-3-030-40605-9_43
   Demochkina Polina, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12665), P266, DOI 10.1007/978-3-030-68821-9_25
   Dey T, 2015, INT C COMP AC TECHN, P1
   Dhall A, 2011, TRCS1121 AUSTR NAT U
   Du ZY, 2021, IEEE T AFFECT COMPUT, V12, P565, DOI 10.1109/TAFFC.2019.2940224
   Fan YR, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P584, DOI 10.1145/3242969.3264978
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Gautam K. S., 2021, International Journal of Computers and Applications, V43, P858, DOI 10.1080/1206212X.2019.1642438
   Gupta R., 2021, Mater. Today: Proc., DOI 10.1016/j.matpr.2020.11.795
   Haddad Jad, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P298, DOI 10.1007/978-3-030-64559-5_23
   Hajarolasvadi N, 2021, SIGNAL IMAGE VIDEO P, V15, P1049, DOI 10.1007/s11760-020-01830-0
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Huang J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6837, DOI 10.1109/ICASSP.2018.8461963
   Knyazev B, 2018, IEEE INT CONF AUTOMA, P692, DOI 10.1109/FG.2018.00109
   Li Lou, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022073
   Li Y, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Liu XF, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013022
   Longmore CA, 2013, NEUROPSYCHOLOGIA, V51, P864, DOI 10.1016/j.neuropsychologia.2013.01.022
   Lu C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P646, DOI 10.1145/3242969.3264992
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Meng DB, 2019, IEEE IMAGE PROC, P3866, DOI [10.1109/ICIP.2019.8803603, 10.1109/icip.2019.8803603]
   Mo SS, 2018, NEUROCOMPUTING, V291, P11, DOI 10.1016/j.neucom.2018.02.052
   Pan XZ, 2020, IETE TECH REV, V37, P402, DOI 10.1080/02564602.2019.1645620
   Pan XZ, 2019, IEEE ACCESS, V7, P48807, DOI 10.1109/ACCESS.2019.2907271
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Priya RV, 2019, MULTIMED TOOLS APPL, V78, P17847, DOI 10.1007/s11042-018-6954-9
   Ngoc QT, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050764
   Rajan S, 2020, IET IMAGE PROCESS, V14, P1373, DOI 10.1049/iet-ipr.2019.1188
   Rocktaschel T., 2015, ARXIV
   Samadiani N, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5764
   Sepas-Moghaddam A, 2020, INT CONF ACOUST SPEE, P3367, DOI [10.1109/icassp40776.2020.9053919, 10.1109/ICASSP40776.2020.9053919]
   Smith KE, 2020, PSYCHONEUROENDOCRINO, V122, DOI 10.1016/j.psyneuen.2020.104873
   Sreenivas V, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00326-5
   Sun M., 2018, 2018 43rd International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2018.8510354
   Vedantham R, 2020, MULTIMED TOOLS APPL, V79, P21487, DOI 10.1007/s11042-020-08901-x
   Xing BX, 2019, IEEE ACCESS, V7, P59844, DOI 10.1109/ACCESS.2019.2914872
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
NR 43
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28681
EP 28711
DI 10.1007/s11042-023-14491-1
EA FEB 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000937945000001
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Dogan, S
   Kaya, MC
   Subasi, A
AF Tuncer, Turker
   Dogan, Sengul
   Kaya, M. Cagri
   Subasi, Abdulhamit
TI Automated and accurate focal EEG signal detection method based on the
   cube pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cube pattern; TQWT; NCA; Multi-scale principal component analysis; EEG
   classification
ID CLASSIFICATION; FEATURES
AB Electroencephalography (EEG) signals are named letters of the brain, and their translation is a complex issue. This work recommends a new hand-crafted feature-based EEG signal classification model, including a new local histogram-based feature generation function, the cube pattern. The recommended model comprises preprocessing/signal denoising, feature extraction using the presented cube pattern, neighborhood component analysis-based feature selection, and classification by employing 25 classifiers. Multi-scale principal component analysis (MSPCA) is applied to the raw EEG signals in the denoising phase. Afterward, the denoised EEG signals are forwarded to the feature extraction method. Next, tunable q-factor wavelet transform (TQWT) is employed to denoise signals for decomposition, and levels/sub-bands are generated. The selected features are classified from 25 classifiers by using the MATLAB Classification Learning tool. The presented model is applied to a commonly used EEG signal dataset. Variable performance evaluation metrics are used to test the performance of each classifier. Per the calculated results, the presented model reached over 99% accuracy using 24 of the 25 classifiers, and a comprehensive benchmark is obtained. The calculated results and obtained findings denote the high performance of the presented cube pattern and the neighborhood component analysis-based model.
C1 [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
   [Kaya, M. Cagri] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkiye.
   [Kaya, M. Cagri] Ardahan Univ, Dept Comp Engn, Ardahan, Turkiye.
   [Subasi, Abdulhamit] Univ Turku, Inst Biomed, Fac Med, FI-20014 Turku, Finland.
   [Subasi, Abdulhamit] Effat Univ, Coll Engn, Dept Comp Sci, Jeddah 21478, Saudi Arabia.
C3 Firat University; Middle East Technical University; Ardahan University;
   University of Turku; Effat University
RP Dogan, S (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM turkertuncer@firat.edu.tr; sdogan@firat.edu.tr; mckaya@ceng.metu.edu.tr;
   abdulhamit.subasi@utu.fi
RI Kaya, Muhammed Çağrı/G-6452-2018; DOGAN, Sengul/W-4854-2018; TUNCER,
   Türker/ABG-1146-2020; Subasi, Abdulhamit/E-7533-2017
OI DOGAN, Sengul/0000-0001-9677-5684; Subasi,
   Abdulhamit/0000-0001-7630-4084
CR Al-Hadeethi H, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113676
   Andrzejak RG, 2012, PHYS REV E, V86, DOI 10.1103/PhysRevE.86.046206
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Arunkumar N, 2018, J COMPUT SCI-NETH, V27, P440, DOI 10.1016/j.jocs.2018.02.002
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Bakhshali MA, 2019, MEASUREMENT, V140, P354, DOI 10.1016/j.measurement.2019.04.023
   Bhati D, 2017, DIGIT SIGNAL PROCESS, V62, P259, DOI 10.1016/j.dsp.2016.12.004
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Dai YX, 2015, MEASUREMENT, V74, P11, DOI 10.1016/j.measurement.2015.07.008
   Daoud H, 2020, IEEE T BIOMED CIRC S, V14, P209, DOI 10.1109/TBCAS.2019.2957087
   Deivasigamani S, 2016, INT J IMAG SYST TECH, V26, P277, DOI 10.1002/ima.22199
   Fasil OK, 2019, NEUROSCI LETT, V694, P1, DOI 10.1016/j.neulet.2018.10.062
   Fraiwan L, 2020, IEEE ACCESS, V8, P77255, DOI 10.1109/ACCESS.2020.2989442
   Gandhi T, 2011, NEUROCOMPUTING, V74, P3051, DOI 10.1016/j.neucom.2011.04.029
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Gupta V, 2017, PATTERN RECOGN LETT, V94, P180, DOI 10.1016/j.patrec.2017.03.017
   Jukic S, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091481
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   Kim KS, 2011, CURR APPL PHYS, V11, P740, DOI 10.1016/j.cap.2010.11.051
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M. Ravi, 2019, Cluster Computing, V22, P13521, DOI [10.1007/978-981-10-8354-9_1, 10.1007/s10586-018-1995-4]
   Lin HJ, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107706
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Parija S, 2020, IET SIGNAL PROCESS, V14, P162, DOI 10.1049/iet-spr.2019.0277
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sairamya NJ, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102096
   San-Segundo R, 2019, COMPUT BIOL MED, V109, P148, DOI 10.1016/j.compbiomed.2019.04.031
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Sharma R, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101856
   Sharma R, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419400104
   Sharma R, 2017, J COMPUT SCI-NETH, V20, P52, DOI 10.1016/j.jocs.2017.03.022
   Singh P, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400024
   Srinath R, 2021, INT J IMAG SYST TECH, V31, P729, DOI 10.1002/ima.22486
   Subasi A, 2019, MEASUREMENT, V146, P846, DOI 10.1016/j.measurement.2019.07.026
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Yang WY, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107363
   Zhou MN, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00095
NR 39
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19675
EP 19691
DI 10.1007/s11042-023-14430-0
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F2YY1
UT WOS:000922388600002
DA 2024-07-18
ER

PT J
AU Liu, HX
   Wagner, C
AF Liu, Hugh Xuechen
   Wagner, Christian
TI Proxies to the monthly active user number of Geo AR Mobile games -
   online search volume as a proposal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game metrics; Geo AR mobile games; Online search volume; Proxy; Google
   trends; Correlation
ID SOCIAL MEDIA; ENGAGEMENT; BEHAVIOR; GUIDE
AB Mobile game metrics have received attention since the emergence of big data technology and data-based decision-making. Among different metrics, the monthly active user number is usually significant because it shows the level of players' engagement and the profit of this game as a business. Therefore, the monthly active user number is valuable for researchers, analysts, and decision-makers interested in the mobile game industry. However, the actual monthly active user number data typically have the accuracy, accessibility, granularity, and cost problems. Therefore, a proxy to the monthly active user number would be helpful to facilitate the decision-making process. This paper proposes to capture user activity through the searches on the Internet from an information-seeking perspective. And the online search volume, wiki page view, social media posts and views are proposed as potential proxies. This paper proposes that the online search volume is an acceptable proxy for the monthly active user number in the context of Geo Augmented Reality (AR) mobile games through data analysis.
C1 [Liu, Hugh Xuechen; Wagner, Christian] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Liu, HX (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM hugh.liu@my.cityu.edu.hk; c.wagner@cityu.edu.hk
RI Wagner, Christian/H-6310-2012
OI Wagner, Christian/0000-0003-0907-8552; LIU, Hugh
   Xuechen/0000-0002-9200-0053
FU project "Opportunities in Contemporary Digital Game Design, Start-up
   Grant for New Faculty, City University of Hong Kong
FX The preparation of this manuscript was funded by the project
   "Opportunities in Contemporary Digital Game Design," Start-up Grant for
   New Faculty, City University of Hong Kong.
CR Al-Haija QA, 2019, FORECASTING NUMBER M
   Anderson EF, 2010, VIRTUAL REAL-LONDON, V14, P255, DOI 10.1007/s10055-010-0177-3
   [Anonymous], INGRESS AMA ARCH
   [Anonymous], PAGEVIEWS ANAL
   Asraf Syed Muhammad Hazry, 2020, Journal of Physics: Conference Series, V1529, DOI 10.1088/1742-6596/1529/2/022098
   Bowman S., 2003, We Media: How audiences are shaping the future of news and information
   Byrd M., IS HARRY POTTER WIZA
   Canty A, 2002, R NEWS, V2, P2, DOI DOI 10.1159/000323281
   Carpenter J, 2000, STAT MED, V19, P1141, DOI 10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F
   Cheng Z, 2016, J INF TECHNOL-UK, V31, P257, DOI 10.1057/s41265-016-0005-7
   Clawson T, AUGMENTED REALITY DO
   Czyz SH, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01178
   Davidson R., 2000, Econometric Reviews, V19, P55, DOI [10.1080/07474930008800459, DOI 10.1080/07474930008800459]
   Davies D, MEET 7 MOST POPULAR
   Digital_Stat, HOT GAM AM POK GO ST
   Dolan R, 2016, J STRATEG MARK, V24, P261, DOI 10.1080/0965254X.2015.1095222
   Donkin C, NIANTIC SCRAPS HYPED
   El Afi F, 2021, MANAG MARK, V16, P370, DOI 10.2478/mmcks-2021-0022
   El-Nasr M., 2013, Game Analytics-Maximizing the Value of Player Data
   Fields T.V., 2013, Game Analytics: Maximizing the Value of Player Data, P53
   Foxx C, POKEMON GO PLAYERS T
   France-Presse A, POK GO PLAYERS DESTR
   Goel S, 2010, P NATL ACAD SCI USA, V107, P17486, DOI 10.1073/pnas.1005962107
   Google/Ipsos, CONS INS
   Grguric Mihovil, 13 KEY MOBILE GAME M
   Grohn J., 2017, Exploring co-creation experience and value in the video game industry: how gamers create value through a rule changing online game that has no rules"
   Gupta GCA, 2016, CTR AIR POWER STUDIE, V7
   Guzsvinecz T, 2023, MULTIMED TOOLS APPL, V82, P4641, DOI 10.1007/s11042-022-12308-1
   Hamari J, 2019, INT J HUM-COMPUT INT, V35, P804, DOI 10.1080/10447318.2018.1497115
   Harborth D, 2021, COMPUT HUM BEHAV, V122, DOI 10.1016/j.chb.2021.106833
   Hazra A, 2017, J THORAC DIS, V9, P4125, DOI 10.21037/jtd.2017.09.14
   Howe KB, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i6270
   ironSource, MOB GAM BUS MOD
   Jiang XJ, 2021, FRONT PHYS-LAUSANNE, V9, DOI 10.3389/fphy.2021.631665
   Karnes K., CUSTOMER LIFETIME VA
   Kawa L, THESE CHARTS SHOW PO
   Korgaonkar PK, 1999, J ADVERTISING RES, V39, P53
   Ku GCM, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9070794
   Laato S, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4020029
   Landi M, 2017, POKEMON GO APP NAMED
   Lemon J, POKEMON GO PLAYERS I
   Levine R., 2009, CLUETRAIN MANIFESTO
   Lien CH, 2014, COMPUT HUM BEHAV, V41, P104, DOI 10.1016/j.chb.2014.08.013
   Liikkanen LA, 2015, COMPUT HUM BEHAV, V50, P108, DOI 10.1016/j.chb.2015.01.067
   Liu HX, 2022, LECT NOTES COMPUT SC, V13517, P604, DOI 10.1007/978-3-031-22131-6_45
   Ljepava N, 2013, COMPUT HUM BEHAV, V29, P1602, DOI 10.1016/j.chb.2013.01.026
   M IQBAL, 2021, POK GO REV US
   Majgaard G, 2017, PROC EUR CONF GAME, P402
   Mukaka MM, 2012, MALAWI MED J, V24, P69
   NEXT GAMES, 2019, NEXT GAM CORP HALF Y
   NEXT GAMES, FIN STAT B 2020
   Nick W, POKEMON GO BRINGS AU
   Nóbrega R, 2017, 2017 24 ENCONTRO PORTUGUES DE COMPUTACAO GRAFICA E INTERACAO (EPCGI)
   Penttinen V, 2022, J INTERACT MARK, V57, P561, DOI 10.1177/10949968221102825
   Provost F, 2013, BIG DATA, V1, P51, DOI 10.1089/big.2013.1508
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Richardson D, 2016, INT J GAME-BASED LEA, V6, P34, DOI 10.4018/IJGBL.2016070103
   Seif El-Nasr M., 2021, GAME DATA SCI, DOI [10.1093/oso/9780192897879.001.0001, DOI 10.1093/OSO/9780192897879.001.0001]
   SensorTower, APP INT METH
   Shao GS, 2009, INTERNET RES, V19, P7, DOI 10.1108/10662240910927795
   Southern M, GOOGLES SHARE SEARCH
   Su YH, 2021, SERV ORIENTED COMPUT, V15, P141, DOI 10.1007/s11761-020-00303-z
   Tremblay MC, 2021, MIS QUART, V45, P455, DOI 10.25300/MISQ/2021/15434.1.1
   Udonis, 13 KEY MOB GAM METR
   VANEWIJK PH, 1993, ECOTOX ENVIRON SAFE, V25, P25, DOI 10.1006/eesa.1993.1003
   Vogel M, POKEMON GO HAD MOST
   Wagner A, ARE YOU MAXIMIZING U
   Wang AI, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100411
   Watts S, MINECRAFT EARTH SHUT
   Whiting A, 2013, QUAL MARK RES, V16, P362, DOI 10.1108/QMR-06-2013-0041
   Wu JH, 2010, COMPUT HUM BEHAV, V26, P1862, DOI 10.1016/j.chb.2010.07.033
   Ye L., PRACTICAL GUIDE BOOT
NR 72
TC 3
Z9 3
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25403
EP 25425
DI 10.1007/s11042-023-14366-5
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000926801100005
PM 36685014
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Paul, S
   Pal, AK
AF Paul, Srilekha
   Pal, Arup Kumar
TI A fast copy-move image forgery detection approach on a reduced search
   space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Copy-move forgery detection; Discrete cosine
   transform; Gaussian image pyramid
ID DIGITAL IMAGES; SECURITY; FEATURES; WAVELET; SYSTEM; TOPSIS; DCT; AHP
AB This paper proposes an overlapping block-based passive forensic scheme for copy-move forgery detection in digital images that works on a reduced search space. It uses a Gaussian image pyramid to generate and analyze input images at different resolutions. The conventional overlapping block-based procedures produce satisfactory results but are highly compute-intensive for large and medium-sized images. An increase in image size leads to a rapid rise in the number of overlapping blocks in the image, making processes like feature extraction, matching, and shift-vector calculations very expensive. The proposed approach initially performs relative forgery detection through block-wise processing of lower resolution components of the original image. In this process, discrete cosine transform is used to extract significant coefficients from each block and further analyzed to identify forgeries relatively in the selected lower resolution components. This process aids in selecting a smaller search space for potentially forged areas in the original image. Finally, the actual forgery detection is performed on this reduced search space, decreasing the computational overhead while maintaining accuracy in the results. The proposed procedure also shows robustness against various attacks and post-processing operations.
C1 [Paul, Srilekha; Pal, Arup Kumar] Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Pal, AK (corresponding author), Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM srilekhapaul7@gmail.com; arupkrpal@gmail.com
OI Paul, Srilekha/0000-0003-2882-7395
FU Department of Science & Technology (DST), New Delhi;  [SR/FST/ET-I/
   2017/75]
FX AcknowledgementsThe authors sincerely thank the Department of Science &
   Technology (DST), New Delhi, for supporting this work under FIST project
   grant (No. SR/FST/ET-I/ 2017/75).
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bovik Alan C, 2010, Handbook of image and video processing
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dixit A, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115282
   Florindo JB, 2018, INFORM SCIENCES, V459, P36, DOI 10.1016/j.ins.2018.05.037
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Kaur J, 2020, RISK MANAG HEALTHC P, V13, P355, DOI 10.2147/RMHP.S233706
   Kumar R, 2020, IEEE ACCESS, V8, P48870, DOI 10.1109/ACCESS.2020.2978038
   Kumar R, 2020, IEEE ACCESS, V8, P50944, DOI 10.1109/ACCESS.2020.2970245
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Parveen A., 2019, Iran Journal of Computer Science, V2, P89, DOI DOI 10.1007/S42044-019-00029-Y
   Paul S, 2021, CLOUD SECURITY, P114, DOI [10.1201/9780367821555-9/active-forgery-detection-grayscale-images-using-crc-8-based- fragile-watermarking-srilekha-paul-arup-kumar-pal, DOI 10.1201/9780367821555-9/ACTIVE-FORGERY-DETECTION-GRAYSCALE-IMAGES-USING-CRC-8-BASED-FRAGILE-WATERMARKING-SRILEKHA-PAUL-ARUP-KUMAR-PAL]
   Prasad S, 2022, WIRELESS PERS COMMUN, V125, P2581, DOI 10.1007/s11277-022-09675-1
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P152, DOI 10.1016/j.cag.2017.08.014
   Sencar, 2014, DIGITAL IMAGE FORENS
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Shivakumar B., 2011, International Journal of Computer Applications, V27, P9, DOI DOI 10.5120/3283-4472
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Sunil K., 2014, Ict and critical infrastructure: Proceedings of the 48th annual convention of computer society of india-vol, Vii, P577, DOI DOI 10.1007/978-3-319-03095-1_62
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Walia S, 2019, AUST J FORENSIC SCI, V51, P488, DOI 10.1080/00450618.2018.1424241
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yadav AR, 2015, OPTIK, V126, P5570, DOI 10.1016/j.ijleo.2015.09.030
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 40
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25917
EP 25944
DI 10.1007/s11042-022-14224-w
EA JAN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000907916500002
DA 2024-07-18
ER

PT J
AU Palos-Sanchez, PR
   Baena-Luna, P
   Silva-O'Connor, D
AF Palos-Sanchez, Pedro R. R.
   Baena-Luna, Pedro
   Silva-O'Connor, Daniel
TI Exploring employees' beliefs regarding the potential benefits of virtual
   worlds for group cohesion: gather town
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telework; Team cohesion; Virtual worlds; Gather town; Focus group
ID PERFORMANCE; GRATIFICATIONS; GAMES
AB As a consequence of advances in Information and Communication Technologies, teleworking is becoming more and more common in organizations. These new ways of working create new challenges for companies such as team cohesion despite working in different locations. This article aims to analyze the effect of the use of so-called "virtual worlds " on the group cohesion of employees in organizations. The focus group methodology has made it possible to gather the beliefs and opinions of company employees about the use of these resources and tools. The results obtained show the positive effect of the use of virtual worlds on the cohesion of the teleworking team.
C1 [Palos-Sanchez, Pedro R. R.; Baena-Luna, Pedro] Univ Seville, Ramon & Cajal Av, 1, Seville 41018, Spain.
   [Silva-O'Connor, Daniel] Open Univ Catalunya, 156, Rambla Poblenou, Barcelona 08018, Spain.
C3 University of Sevilla; UOC Universitat Oberta de Catalunya
RP Baena-Luna, P (corresponding author), Univ Seville, Ramon & Cajal Av, 1, Seville 41018, Spain.
EM ppalos@us.es; pbaenaluna@us.es; dsilvao@uoc.edu
RI Palos-Sanchez, Pedro R./A-8952-2017; Baena-Luna, Pedro/S-9594-2017
OI Palos-Sanchez, Pedro R./0000-0001-9966-0698; Baena-Luna,
   Pedro/0000-0002-8509-0222
FU Universidad de Sevilla/CBUA
FX Funding for open access publishing: Universidad de Sevilla/CBUA
CR Abarca VMG, 2020, IEEE ACCESS, V8, P168923, DOI 10.1109/ACCESS.2020.3023546
   Hadi SA, 2021, ANXIETY STRESS COPIN, V34, P530, DOI 10.1080/10615806.2021.1903447
   Altebarmakian M, 2019, INT J COMP-SUPP COLL, V14, P443, DOI 10.1007/s11412-019-09309-y
   [Anonymous], 2021, LEY 102021 9 JULIO T, V164
   Aten K, 2020, OXFORD RES ENCY BUSI, P1, DOI [10.1093/acrefore/9780190224851.013.170, DOI 10.1093/ACREFORE/9780190224851.013.170]
   Bakker A. B., 2007, J MANAGERIAL PSYCHOL, V22, P309, DOI [10.1108/02683940710733115, DOI 10.1108/02683940710733115]
   Blackwood RA, 2015, ACCOUNT RES, V22, P236, DOI 10.1080/08989621.2014.956866
   Bozanta A, 2016, COMPUT HUM BEHAV, V59, P380, DOI 10.1016/j.chb.2016.02.042
   Carron AV, 2012, SMALL GR RES, V43, P726, DOI 10.1177/1046496412468072
   Castaño N, 2013, GROUP DYN-THEOR RES, V17, P207, DOI 10.1037/a0034142
   Choi EK, 2016, J HOSP MARKET MANAG, V25, P771, DOI 10.1080/19368623.2016.1100102
   Cifre E., 2012, Persona, P71
   E.U, 2020, TEL EU COVID 19 WE W, V2009
   Festinger Leon, 1950, The Milbank Memorial Fund quarterly, DOI DOI 10.2307/3348388
   Forsyth DR, 2021, GROUP DYN-THEOR RES, V25, P213, DOI 10.1037/gdn0000163
   Galyon CE, 2016, SOC PSYCHOL EDUC, V19, P61, DOI 10.1007/s11218-015-9321-y
   Garro-Abarca V, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.624637
   Günther N, 2022, GER J HUM RESOUR MAN, V36, P353, DOI 10.1177/23970022221083694
   Ho KKW, 2018, INTERNET RES, V28, P587, DOI 10.1108/IntR-04-2017-0175
   INE, 2021, EMPR CON 10 MAS EMPL
   KATZ E, 1973, PUBLIC OPIN QUART, V37, P508
   Krueger R., 1998, Developing Questions for Focus Groups, DOI DOI 10.4135/9781483328126
   Krueger R., 2014, FOCUS GROUPS PRACTIC
   Kuckartz U., 2014, Qualitative text analysis: A guide to methods, practice using software, P65, DOI [10.4135/9781446288719.n4, DOI 10.4135/9781446288719]
   Latulipe C, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P411, DOI 10.1145/3478431.3499383
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y, 2022, INT C ART INT SEC, P386
   Litosseliti L., 2003, USING FOCUS GROUPS R
   Liu Wenyi, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1588), P350, DOI 10.1007/978-3-031-06764-8_28
   Lugo, 2022, IIE ANN C P, P1
   McClure C. D., 2021, Compass: Journal of Learning and Teaching, V14, DOI [10.21100/compass.v14i2.1232, DOI 10.21100/COMPASS.V14I2.1232]
   Messenger JC, 2019, ILO FUTUR WORK SER, P1, DOI 10.4337/9781789903751
   Miglioretti M, 2021, J WORK ORGAN PSYCHOL, V37, P11
   Mouratidis K, 2021, SUSTAIN CITIES SOC, V74, DOI 10.1016/j.scs.2021.103182
   Najjar N, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P112, DOI 10.1145/3478431.3499396
   Palos-Sanchez P, 2021, EUR RES MANAG BUS EC, V27, DOI 10.1016/j.iedeen.2021.100149
   Paul R, 2016, IEEE T PROF COMMUN, V59, P186, DOI 10.1109/TPC.2016.2583319
   Pyöriä P, 2011, MANAG RES REV, V34, P386, DOI 10.1108/01409171111117843
   Rakovac bekes E., 2022, 2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)., P579, DOI 10.23919/MIPRO55190.2022.9803319
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Riasudeen S, 2019, PSYCHOL STUD, V64, P401, DOI 10.1007/s12646-019-00501-6
   Rodriguez S, 2021, FACEBOOK TAKES STEP
   Salanova M, 2007, REV 28 ABRIL REV DIG, V1, P1
   Salas E, 2015, HUM FACTORS, V57, P365, DOI 10.1177/0018720815578267
   Sriworapong S, 2022, COMM COM INF SC, V1626, P140, DOI 10.1007/978-3-031-14832-3_10
   Standl B, 2021, INT J ENG PEDAGOG, V11, P87, DOI 10.3991/ijep.v11i5.22413
   Tajfel H., 1981, Human Groups and Social Categories
   Tzafrir SS., 2005, J. High Technol. Manage. Res, V16, P193, DOI DOI 10.1016/J.HITECH.2005.10.008
   Vargas O, 2019, TELEWORK ITS EFFECTS
   Yang M, 2021, ACS APPL MATER INTER, V13, P38647, DOI 10.1021/acsami.1c05751
   Yi D, 2021, INNOVATION MED HEALT, V242, DOI [10.1007/978-981-16-3013-2_9, DOI 10.1007/978-981-16-3013-2_9]
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhao X, 2024, RELC J, V55, P240, DOI 10.1177/00336882221097216
NR 53
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24943
EP 24965
DI 10.1007/s11042-022-14308-7
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000903319100002
PM 36588766
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Hidayat, T
   Zakaria, MH
   Pee, ANC
AF Hidayat, Tonny
   Zakaria, Mohd Hafiz
   Pee, Ahmad Naim Che
TI Increasing the Huffman generation code algorithm to equalize compression
   ratio and time in lossless 16-bit data archiving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Huffman; Compression; Binary; Lossless
ID MEMORY-EFFICIENT; ARCHITECTURE; LENGTH
AB Compression is a process that is always carried out in terms of digitizing data, which is considered very important, especially in the development and growth of the Big Data era. Lossless compression is the process of reducing the size of the data but with the condition that it can be returned to its original source during the decompression process. One of the purposes of doing Lossless compression is to archive a file, usually the file is RAW and has a large file size with a minimum 16-Bit file system (65,536 possible differences in values). Huffman's algorithm is currently still very effective in compressing 8-bit data, which can be grouped into Static, Dynamic, and Adaptive extensions, but its performance cannot be determined if it is performed on data with complex variables and probabilities such as WAV format audio data. Based on a literature review, the compression performance measurement for file archiving uses the Compression Ratio (CR) and Compression Time (CT) indicators. This research resulted in a new scheme which we named 4-ary/MQ, the architectural basis of which is based on entropy coding rooted in the static, dynamic and adaptive variants of the Huffman scheme. For the variable code length characteristics, it follows the Quad Tree dynamic branching (FGK rule), the node symbol setting adopts an adaptive method, namely adding a maximum of 2 variables with a value of '0' to maintain the root of the branch after the root always has 4 branches. Based on descriptive analysis of compression results, deviation, average, ANOVA and DMRT, 4-ary/MQ produces optimal CR with fast CT when compared to various variants of the Huffman algorithm and other lossless compression applications such as (PKZIP, WinZip, 7-Zip, and Monkeys Audio). From the results of trial analysis based on manual mathematical and statistical calculations, it is certain that 4-ary/MQ provides high compression results with a very fast process, so it has many benefits if it is used to compress data on local storage media, hosting/cloud and bandwidth.
C1 [Hidayat, Tonny] Univ AMIKOM Yogyakarta, Fac Comp Sci, Yogyakarta, Indonesia.
   [Zakaria, Mohd Hafiz; Pee, Ahmad Naim Che] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Melaka, Malaysia.
C3 Universiti Teknologi Malaysia; University Teknikal Malaysia Melaka
RP Hidayat, T (corresponding author), Univ AMIKOM Yogyakarta, Fac Comp Sci, Yogyakarta, Indonesia.
EM tonny@amikom.ac.id; hafiz@utem.edu.my; naim@utem.edu.my
RI hidayat, tonny/HLH-3555-2023; hidayat, tonny/W-3697-2018
OI hidayat, tonny/0000-0003-3406-0880; hidayat, tonny/0000-0003-3406-0880
CR Al-Bahadili H, 2010, INT J AUTOM COMPUT, V7, P123, DOI 10.1007/s11633-010-0123-6
   Alakuijala J, 2016, COMP BROTLI DEFLATE
   Alakuijala J, 2013, DATA COMPRESSION USI
   Alakuijala J, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3231935
   Ali Ahmed S., 2011, Journal of Software, V6, P298, DOI 10.4304/jsw.6.2.298-305
   Arshad R, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P361, DOI 10.1109/INTECH.2016.7845058
   Baer MB, 2006, IEEE T INFORM THEORY, V52, P344, DOI 10.1109/TIT.2005.860469
   Benjamin A, 2010, MUSIC COMPRESSION AL
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Bosch J. J., 2012, ISMIR, P559, DOI DOI 10.5281/ZENODO.1416075
   Bosch JJ, 2016, J NEW MUSIC RES, V45, P101, DOI 10.1080/09298215.2016.1182191
   Breaban MC, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P88, DOI 10.1109/DAAS.2018.8396077
   Bryukhanov YA, 2017, 2017 IEEE E W DESIGN, P1
   Calim Aysegul Senol, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P21, DOI 10.1109/UBMK52708.2021.9558902
   Chambliss D, 2008, IBM J RES DEV, V52, P427, DOI 10.1147/rd.524.0427
   Chen HC, 1999, INFORM PROCESS LETT, V69, P119, DOI 10.1016/S0020-0190(99)00002-2
   Chowdhury RA, 2002, INFORM PROCESS LETT, V81, P305, DOI 10.1016/S0020-0190(01)00243-5
   Chung KL, 1997, INFORM PROCESS LETT, V61, P97, DOI 10.1016/S0020-0190(96)00204-9
   Djusdek DF, 2016, INT CONF INFORM COMM, P101, DOI 10.1109/ICTS.2016.7910281
   Elakkiya S., 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V103, P1003, DOI 10.1007/s40031-021-00686-3
   Faller N, 1973, 7 AS C CIRC SYST COM, P593
   FENWICK PM, 1995, IEEE T COMMUN, V43, P163, DOI 10.1109/26.380027
   Fonseca E, 2019, INT CONF ACOUST SPEE, P21, DOI 10.1109/ICASSP.2019.8683158
   Fruchtman A, 2020, IEEE DATA COMPR CONF, P368, DOI 10.1109/DCC47342.2020.00059
   GALLAGER RG, 1978, IEEE T INFORM THEORY, V24, P668, DOI 10.1109/TIT.1978.1055959
   Guido RC, 2016, KNOWL-BASED SYST, V105, P248, DOI 10.1016/j.knosys.2016.05.011
   Gupta A., 2017, 2017 Second International Conference on Electrical, Computer and Communication Technologies (ICECCT), IEEE, P1, DOI [DOI 10.1109/ICECCT.2017.8117850, DOI 10.1007/978-81-322-3706-8_1]
   Habib A, 2018, J COMPUT SCI-NETH, V14, P1599, DOI DOI 10.3844/JCSSP.2018.1599.1610
   Habib A, 2013, J COMPUT, V8, P1175, DOI 10.4304/jcp.8.5.1175-1183
   Habib Ahsan, 2017, APPL INF, V4, P5, DOI DOI 10.1186/S40535-016-0032-Z
   HASHEMIAN R, 1995, IEEE T COMMUN, V43, P2576, DOI 10.1109/26.469442
   Hermassi H, 2010, COMMUN NONLINEAR SCI, V15, P2987, DOI 10.1016/j.cnsns.2009.11.022
   Hidayat Tonny, 2020, 2020 3rd International Conference on Information and Communications Technology (ICOIACT), P170, DOI 10.1109/ICOIACT50329.2020.9332044
   Hidayat Tonny, 2018, Journal of Theoretical and Applied Information Technology, V96, P3467
   Hidayat T, 2019, INT J ADV TRENDS COM, V8, P317, DOI [10.30534/ijatcse/2019/5381.52019, DOI 10.30534/IJATCSE/2019/5381.52019]
   Hidayat T, 2019, INT J SIMUL SYST SCI, V19
   Hidayat T, 2019, INT J SIMUL SYST SCI, V19, P1, DOI [10.5013/IJSSST.a.19.05.31, DOI 10.5013/IJSSST.A.19.05.31]
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Islam M., 2019, 2019 INT C INN INT, P1, DOI [DOI 10.1109/3ict.2019.8910317, DOI 10.1109/icccnt45670.2019.8944528, 10.1109/ICISCT47635.2019.9012031]
   Jayasankar U, 2021, J KING SAUD UNIV-COM, V33, P119, DOI 10.1016/j.jksuci.2018.05.006
   JOHNSON Jr P.D., 2003, Introduction to Information Theory and Data Compression, V2nd
   KATONA GOH, 1976, IEEE T INFORM THEORY, V22, P337, DOI 10.1109/TIT.1976.1055554
   Kaur, 2015, INT J ADV TECHNOL EN, V4, P1273
   Kavousianos X, 2008, IEEE T COMPUT AID D, V27, P1333, DOI 10.1109/TCAD.2008.923100
   KNUTH DE, 1985, J ALGORITHM, V6, P163, DOI 10.1016/0196-6774(85)90036-7
   Kodituwakku S., 2010, Indian Journal of Computer Science and Engineering, V1, P416
   Li QH, 2019, IEEE IC COMP COM NET, DOI 10.1109/icccn.2019.8846922
   Li SY, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P458, DOI 10.1109/SPAWDA.2015.7364530
   Lin YK, 2012, J SYST SOFTWARE, V85, P974, DOI 10.1016/j.jss.2011.11.1019
   Liudong Zuo, 2020, 2020 International Conference on Computing, Networking and Communications (ICNC), P74, DOI 10.1109/ICNC47757.2020.9049789
   McAnlis C., 2016, Understanding Compression: Data Compression for Modern Developers
   Mentzer F, 2020, PROC CVPR IEEE, P6637, DOI 10.1109/CVPR42600.2020.00667
   Metwally A, 2005, LECT NOTES COMPUT SC, V3363, P398, DOI 10.1007/978-3-540-30570-5_27
   Mustafa, 2017, JURNAL KURIKULUM PEN, V2, P1
   Nam LH, 2021, BUILDING BIG DATA OR, P172
   Nobre ICM, 2019, INT CONF ACOUST SPEE, P5376, DOI 10.1109/ICASSP.2019.8682784
   Oommen BJ, 2004, NEW FAMILY WEAK ESTI, P644, DOI [10.1007/978-3-540-27868-9_70, DOI 10.1007/978-3-540-27868-9_70]
   PAAKKONEN J, 2019, IEEE WORKSHOP SIGNAL, P1
   Pal RS, 2021, 2021 INNOVATIONS IN ENERGY MANAGEMENT AND RENEWABLE RESOURCES(IEMRE 2021), DOI 10.1109/IEMRE52042.2021.9386880
   Ramya K. A., 2016, INT J COMPUT SCI ENG, V4, P1277
   Salomon D., 2010, Handbook of Data Compression, V5th
   Sayood K, 2017, Introduction to data compression
   SCHACK R, 1994, IEEE T INFORM THEORY, V40, P1246, DOI 10.1109/18.335944
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shao ZY, 2022, IEEE T CIRCUITS-II, V69, P209, DOI 10.1109/TCSII.2021.3091611
   Sharma M, 2010, INT J COMPUT SCI NET, V10, P133
   Singh R, 2013, INT J ADVANC RES COM, V3, P2277
   Snyder D, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1510.08484
   Suri PR, 2011, INT J COMPUTER SCI I, V8, P483
   Szpankowski W, 2011, IEEE T INFORM THEORY, V57, P4017, DOI 10.1109/TIT.2011.2145590
   Trum Caroline, 2020, Natural Gas & Electricity, V36, P9, DOI 10.1002/gas.22157
   VITTER JS, 1989, ACM T MATH SOFTWARE, V15, P158, DOI 10.1145/63522.214390
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 75
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24031
EP 24068
DI 10.1007/s11042-022-14130-1
EA DEC 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000912823400001
DA 2024-07-18
ER

PT J
AU Jaiswal, A
   Kumar, R
AF Jaiswal, Arvind
   Kumar, Rajeev
TI Breast cancer diagnosis using Stochastic Self-Organizing Map and Enlarge
   C4.5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Prediction; Dimensionality reduction; Stochastic
   Self-organizing Map and Enlarge C4; 5 algorithm
ID CLASSIFICATION; SEGMENTATION
AB Timely and accurate Breast Cancer (BC) prediction allows healthcare providers and doctors to take suitable decisions to treat the patients. Thus, this study employed a strategy based on Deep Learning (DL) to diagnose BC. The study intends to cluster the BC data by the proposed Stochastic Self-Organizing Map (SOM) as it has the ability to process complex data. On the other hand, Enlarge C4.5 (E-C4.5) algorithm is introduced to predict the BC cases based on the clustered outcomes. The BC dataset is loaded and pre-processing is performed where dimensionality reduction is executed to select only the relevant features for clustering. This process eases the clustering. Then, clustering is undertaken by the proposed Stochastic Self-Organizing Map. Here, all the identical data are grouped as clusters which make it easy for prediction. Followed by this, Breast Cancer is predicted by the proposed Enlarge-C4.5 algorithm. After this, the predicted results are analysed by comparative analysis through the four standard performance metrics. This analysis is significant as it shows the degree to which the introduced techniques are effective than the existing techniques. The histogram, correlation map, confusion matrix and clustering results are also discussed clearly. The analytical outcomes explore that the proposed methods are effective than the conventional methods as the proposed method shows a high accuracy rate, precision rate, recall rate and F1-score rate. The misinterpretation rate is also found to be minimum on implementing the proposed method, which is confirmed through the confusion matrix. The proposed method also determines the malignant and benign counts.
C1 [Jaiswal, Arvind] Acropolis Inst Technol & Res, Indore, Madhya Pradesh, India.
   [Kumar, Rajeev] GL Bajaj Inst Technol & Management, Greater Noida, Uttar Pradesh, India.
RP Kumar, R (corresponding author), GL Bajaj Inst Technol & Management, Greater Noida, Uttar Pradesh, India.
EM arvindjsir@gmail.com; rajeev2009mca@gmail.com
RI Kumar, Rajeev/AAJ-4134-2021; Kumar, Rajeev/N-8237-2016
OI Kumar, Rajeev/0000-0002-4141-1282; Kumar, Rajeev/0000-0002-4141-1282;
   Jaiswal, Dr. Arvind/0009-0005-4416-2997
CR Aavula Ravi, 2021, ICCCE 2020. Proceedings of the 3rd International Conference on Communications and Cyber Physical Engineering. Lecture Notes in Electrical Engineering (LNEE 698), P1517, DOI 10.1007/978-981-15-7961-5_137
   Abdulkareem SA., 2021, INT J SCI BASIC APPL, V55, P67
   Arefan D, 2020, MED PHYS, V47, P110, DOI 10.1002/mp.13886
   Baloni P, 2021, METABOLITES, V11, DOI 10.3390/metabo11010020
   Begum A, 2021, INT J COMPUT SCI ENG, V9, P70, DOI [10.26438/ijcse/v9i6.7076, DOI 10.26438/IJCSE/V9I6.7076]
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Ghiasi MM, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104089
   Ghosh SK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114329
   Gupta Puja, 2020, Procedia Computer Science, V171, P593, DOI 10.1016/j.procs.2020.04.064
   Hakkoum H, 2021, COMP M BIO BIO E-IV, V9, P587, DOI 10.1080/21681163.2021.1901784
   Herent P, 2019, DIAGN INTERV IMAG, V100, P219, DOI 10.1016/j.diii.2019.02.008
   Jaiswal A., 2020, J ALL RES ED SCI MET, V8, P146
   Juanying Xie, 2020, Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices. 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12144), P457, DOI 10.1007/978-3-030-55789-8_40
   Kadam VJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1397-z
   Karthik S., 2018, Knowledge Computing and Its Applications: Knowledge Manipulation and Processing Techniques, P227, DOI [10.1007/978-981-10-6680-1_12, DOI 10.1007/978-981-10-6680-1_12]
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Kumar V, 2020, LECT NOTE DATA ENG, V37, P435, DOI 10.1007/978-981-15-0978-0_43
   Kumari Madhu, 2018, Procedia Computer Science, V132, P371, DOI 10.1016/j.procs.2018.05.197
   Meenalochini G, 2021, MATER TODAY-PROC, V37, P2738, DOI 10.1016/j.matpr.2020.08.543
   Men K, 2018, PHYS MEDICA, V50, P13, DOI 10.1016/j.ejmp.2018.05.006
   Nawaz M, 2018, INT J ADV COMPUT SC, V9, P316
   Ravi V, 2023, IEEE T ENG MANAGE, V70, P249, DOI 10.1109/TEM.2021.3059664
   Saha M, 2018, IEEE T IMAGE PROCESS, V27, P2189, DOI 10.1109/TIP.2018.2795742
   Shaikh K, 2020, ARTIF INTELL
   Shukla N, 2018, COMPUT METH PROG BIO, V155, P199, DOI 10.1016/j.cmpb.2017.12.011
   Singh A, 2021, WORLD J ENG RES TECH, V7, P149
   Sun DD, 2019, IEEE ACM T COMPUT BI, V16, P841, DOI 10.1109/TCBB.2018.2806438
   Wolberg WH, MANG OL BREAST CANC
   Wu JD, 2021, J PERS MED, V11, DOI 10.3390/jpm11020061
   Zhang DJ, 2018, IEEE ACCESS, V6, P28936, DOI 10.1109/ACCESS.2018.2837654
   Zhang XH, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103985
   Zhang YD, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102439
NR 33
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18059
EP 18076
DI 10.1007/s11042-022-14265-1
EA DEC 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000893056800005
DA 2024-07-18
ER

PT J
AU Salemi, H
   Rostami, H
   Talatian-Azad, S
   Khosravi, MR
AF Salemi, Hossein
   Rostami, Habib
   Talatian-Azad, Saeed
   Khosravi, Mohammad Reza
TI LEAESN: Predicting DDoS attack in healthcare systems based on Lyapunov
   Exponent Analysis and Echo State Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia-based E-health; Chaos theory; DDoS attack; Echo State
   Network; Lyapunov exponent; Prediction
ID PRACTICAL METHOD; CHAOS; MECHANISMS
AB The availability of the system is one of the main requirements of a multimedia-based e-health application that carries critical patient health information in the network environment. On the other hand, the Distributed Denial of Service (DDoS) attack is one of the most common attacks on the availability of computer networks which can be devastating for a healthcare system. Therefore, a countermeasure to this attack has to be performed in the early steps of the attack to protect the systems against its damages. Detection methods cannot support this and are only able to detect the attack after it happened. Thus, it is necessary to predict DDoS attacks according to the evidence which the attack makes in the network in the early steps of the attack. Therefore, Prediction approaches can reduce the cost of the attacks compared to detection approaches. In this paper, we propose a new method for prediction of DDoS attack based on Lyapunov Exponent Analysis and Echo State Network (LEAESN). In this method, the future traffic of the network is predicted using the Exponential Smoothing technique, then the time series of the prediction error is calculated based on the difference of this prediction and the observed traffic of the network. As shown in this paper, this time series is chaotic in the presence of attack traffics. To predict the DDoS attack, this time series is predicted using a Recurrent Neural Echo State Network (SCESN), and the attack is detected using Lyapunov exponent analysis on the predicted time series. For the evaluation of LEAESN, we test the method on the Darpa98 dataset which consists of a standard dataset for evaluation of intrusion detection systems. LEAESN has an appropriate ability to predict the DDoS attack.
C1 [Salemi, Hossein; Rostami, Habib; Talatian-Azad, Saeed; Khosravi, Mohammad Reza] Persian Gulf Univ, Fac Intelligent Syst & Data Sci, Comp Engn Dept, Bushehr 75168, Iran.
C3 Persian Gulf University
RP Rostami, H (corresponding author), Persian Gulf Univ, Fac Intelligent Syst & Data Sci, Comp Engn Dept, Bushehr 75168, Iran.
EM salemi@pgu.ac.ir; habib@pgu.ac.ir; s.talatian@pgu.ac.ir;
   mohammadkhosravi@acm.org
RI Khosravi, Mohamadreza (Mohammad Reza)/KOD-0343-2024; Rostami, habib
   Rostami/G-5904-2018
OI Rostami, habib Rostami/0000-0002-5396-6517; Talatian Azad,
   Saeed/0000-0003-1027-4438
CR Abbas H, 2016, ANN TELECOMMUN, V71, P477, DOI 10.1007/s12243-016-0495-x
   Akrami A, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01672-x
   Alarqan MA, 2020, COMM COM INF SC, V1132, P138, DOI 10.1007/978-981-15-2693-0_10
   [Anonymous], 2011, P INT C NETW EL ENG
   [Anonymous], 2018, 2018 Internet security threat report
   [Anonymous], 1998, DARPA98
   Bhattacharyya DK, 2016, DDOS ATTACKS: EVOLUTION, DETECTION, PREVENTION, REACTION, AND TOLERANCE, P1, DOI 10.1201/b20614
   Boeing G, 2016, SYSTEMS-BASEL, V4, DOI 10.3390/systems4040037
   Bradley E, 2015, CHAOS, V25, DOI 10.1063/1.4917289
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8
   Chen YH, 2013, IEEE COMMUN LETT, V17, P1052, DOI 10.1109/LCOMM.2013.031913.130066
   Chonka A, 2009, IEEE COMMUN LETT, V13, P717, DOI 10.1109/LCOMM.2009.090615
   Cisco, 2018, CISC 2018 ANN CYB RE
   FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845
   Hilborn R. C., 2000, CHAOS NONLINEAR DYNA
   Huffaker R., 2010, Proceedings in Food System Dynamics, P1, DOI DOI 10.18461/PFSD.2010.10017
   Jaeger H., 2001, ECHO STATE APPROACH, P34
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim HS, 1999, PHYSICA D, V127, P48, DOI 10.1016/S0167-2789(98)00240-1
   Kolias C, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.201
   Lakhina A, 2004, ACM SIGCOMM COMP COM, V34, P219, DOI 10.1145/1030194.1015492
   Lorenz E. N., 1972, AAAS SECT ENV SCI NE
   Ma XL, 2014, IEEE COMMUN LETT, V18, P114, DOI 10.1109/LCOMM.2013.112613.132275
   Najibi E, 2015, APPL INTELL, V43, P460, DOI 10.1007/s10489-015-0652-3
   Nezhad SMT, 2016, IEEE COMMUN LETT, V20, P700, DOI 10.1109/LCOMM.2016.2517622
   Peddi VB, 2017, FUTURE GENER COMP SY, V66, P71, DOI 10.1016/j.future.2016.03.019
   Procopiou A, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/8469410
   PYRAGAS K, 1993, PHYS LETT A, V181, P203, DOI 10.1016/0375-9601(93)90640-L
   Rickles D, 2007, J EPIDEMIOL COMMUN H, V61, P933, DOI 10.1136/jech.2006.054254
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P
   Saied A, 2016, NEUROCOMPUTING, V172, P385, DOI 10.1016/j.neucom.2015.04.101
   Somasundaram R, 2021, WIREL NETW, V27, P5503, DOI 10.1007/s11276-020-02340-0
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Velliangiri S, 2021, J EXP THEOR ARTIF IN, V33, P405, DOI 10.1080/0952813X.2020.1744196
   Verisign, 2018, VER DISTR DEN SERV T
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu XY, 2013, IEEE COMMUN LETT, V17, P2396, DOI 10.1109/LCOMM.2013.102913.130932
   Zargar ST, 2013, IEEE COMMUN SURV TUT, V15, P2046, DOI 10.1109/SURV.2013.031413.00127
NR 38
TC 10
Z9 10
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41455
EP 41476
DI 10.1007/s11042-020-10179-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M1XN8
UT WOS:001028181700001
DA 2024-07-18
ER

PT J
AU Khurana, P
   Sharma, K
   Khatter, K
AF Khurana, Parul
   Sharma, Kiran
   Khatter, Kiran
TI Proof of bibliometric indicators: a blockchain based consensus protocol
   for publications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed ledger technology; Bibliometrics; Consensus; Proof of
   bibliometric indicators; Blockchain
ID GOOGLE SCHOLAR; WEB; SCOPUS; SCIENCE; CITATIONS; ALGORITHM
AB To analyze the research impact of the researcher, different bibliographic databases like Scopus, Web of Science, Google Scholar, etc. are accessed for evaluating the trend of publications and citations from time to time. However, the choice of the bibliographic database is always debatable. Hence, to provide an optimal solution for a given problem, this study proposes a distributed ledger-based consensus mechanism for the presentation of authors' informetrics. The proposed consensus mechanism named "proof of bibliometric indicators" is a consent-based system that is introduced as a base to form trustworthiness among authors and various stakeholders, thus exhibiting a development of the decentralized application. In the end, the proposed system is also implemented with the capabilities of an Ethereum-based decentralized application designed by Truffle and Ganache.
C1 [Khurana, Parul] Lovely Profess Univ, Sch Comp Applicat, Jalandhar Delhi GT Rd, Phagwara 144411, Punjab, India.
   [Sharma, Kiran; Khatter, Kiran] BML Munjal Univ, Sch Engn & Technol, Gurugram 122413, Haryana, India.
C3 Lovely Professional University; BML Munjal University
RP Sharma, K; Khatter, K (corresponding author), BML Munjal Univ, Sch Engn & Technol, Gurugram 122413, Haryana, India.
EM parul.khurana@lpu.co.in; kiran.sharma@bmu.edu.in;
   kiran.khatter@bmu.edu.in
RI /AIA-2445-2022; Khatter, Kiran/S-3936-2019
OI Khatter, Kiran/0000-0002-1000-6102; Sharma, Kiran/0000-0002-3797-7363;
   /0000-0002-1690-7972
CR Aamir M, 2020, WIRELESS PERS COMMUN, V113, P1397, DOI 10.1007/s11277-020-07226-0
   Adriaanse LS, 2013, ELECTRON LIBR, V31, P727, DOI 10.1108/EL-12-2011-0174
   Amoretti M, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P146, DOI 10.1109/QRS-C.2018.00038
   Archambault É, 2009, J AM SOC INF SCI TEC, V60, P1320, DOI 10.1002/asi.21062
   Arndt Timothy, 2020, International Journal of Information and Education Technology, V10, P7, DOI 10.18178/ijiet.2020.10.2.1344
   Asif R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010028
   Ayaz S, 2018, SCIENTOMETRICS, V114, P993, DOI 10.1007/s11192-017-2618-1
   Baldominos A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080723
   Biswas S, 2020, IEEE INTERNET THINGS, V7, P2343, DOI 10.1109/JIOT.2019.2958077
   Bravo-Marquez F, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON DECENTRALIZED APPLICATIONS AND INFRASTRUCTURES (DAPPCON), P119, DOI 10.1109/DAPPCON.2019.00023
   Brown, 2016, RICHARD GENDAL BROWN, P18
   Chatzopoulos D, 2021, ARXIV
   Cheng JR, 2021, MULTIMED TOOLS APPL, V80, P30623, DOI 10.1007/s11042-020-09368-6
   Chenli C, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (ICBC), P19, DOI [10.1109/BLOC.2019.8751419, 10.1109/bloc.2019.8751419]
   Costa FZD, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2020), P170, DOI 10.1109/Blockchain50366.2020.00028
   Costas R, 2007, J INFORMETR, V1, P193, DOI 10.1016/j.joi.2007.02.001
   Ehmke C, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P48, DOI 10.1145/3194113.3194122
   Feng JY, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL ACM WORKSHOP ON SECURITY AND PRIVACY FOR THE INTERNET-OF-THINGS (IOT S&P'19), P32, DOI 10.1145/3338507.3358613
   Fu X, 2021, IEEE T SYST MAN CY-S, V51, P2415, DOI 10.1109/TSMC.2019.2913007
   Gai FY, 2018, LECT NOTES COMPUT SC, V10828, P666, DOI 10.1007/978-3-319-91458-9_41
   Ghazali R, 2021, MULTIMED TOOLS APPL, P1
   Guo H, 2020, IEEE ACCESS, V8, P182776, DOI 10.1109/ACCESS.2020.3029512
   Han X, 2019, IEEE T COMPUT SOC SY, V6, P922, DOI 10.1109/TCSS.2019.2938841
   Harzing AW, 2019, SCIENTOMETRICS, V120, P341, DOI 10.1007/s11192-019-03114-y
   Hasan HR, 2018, LECT NOTES COMPUT SC, V10974, P139, DOI 10.1007/978-3-319-94478-4_10
   Khatter K, 2022, INT J SYST ASSUR ENG, V13, P1219, DOI 10.1007/s13198-021-01418-y
   Khurana P, 2022, J SCIENTOMETR RES, V11, P146, DOI 10.5530/jscires.11.2.16
   Khurana P, 2022, SCIENTOMETRICS, V127, P4483, DOI 10.1007/s11192-022-04464-w
   Kim S, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P841, DOI 10.1145/3196494.3201592
   Kinkelin H, 2020, P NOMS 2020 2020 IEE, P1
   Kulkarni AV, 2009, JAMA-J AM MED ASSOC, V302, P1092, DOI 10.1001/jama.2009.1307
   Kumar AV, 2021, RETHINK GLOB, P23
   Li KJ, 2017, 2017 19TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS (HPCC) / 2017 15TH IEEE INTERNATIONAL CONFERENCE ON SMART CITY (SMARTCITY) / 2017 3RD IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (DSS), P466, DOI 10.1109/HPCC-SmartCity-DSS.2017.61
   Liu CG, 2021, IEEE T SYST MAN CY-S, V51, P2894, DOI 10.1109/TSMC.2019.2917547
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Lu XH, 2021, MULTIMED TOOLS APPL, V80, P31887, DOI 10.1007/s11042-021-11183-6
   Lundbæk LN, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.180422
   Makhdoom I, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (IEEE ICBC), DOI 10.1109/icbc48266.2020.9169406
   Martin-Martin A, 2019, Impact of Social Sciences Blog
   Martín-Martín A, 2021, SCIENTOMETRICS, V126, P871, DOI 10.1007/s11192-020-03690-4
   Martín-Martín A, 2018, J INFORMETR, V12, P1160, DOI 10.1016/j.joi.2018.09.002
   Maslove David M, 2018, JMIR Med Inform, V6, pe11949, DOI 10.2196/11949
   Maull R, 2017, STRATEG CHANG, V26, P481, DOI 10.1002/jsc.2148
   Milutinovic M, 2016, SYSTEX 2016: 1ST WORKSHOP ON SYSTEM SOFTWARE FOR TRUSTED EXECUTION, DOI 10.1145/3007788.3007790
   Mishra RA, 2020, CONSUM COMM NETWORK, DOI 10.1109/ccnc46108.2020.9045196
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nascimento J, 2022, IEEE INT WORKS INFOR, DOI 10.1109/WIFS55849.2022.9975429
   Naughton J, 2016, GUARDIAN, V24
   Perdana A, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2020.103316
   Popper N, 2015, NEW YORK TIMES, V15
   Pournaras E, 2020, J PARALLEL DISTR COM, V145, P160, DOI 10.1016/j.jpdc.2020.06.015
   Pringle J, 2008, LEARN PUBL, V21, P85, DOI 10.1087/095315108X288901
   Puntinx, 2017, VIITATTU, V1, P2017
   Qu XD, 2021, IEEE T PARALL DISTR, V32, P2074, DOI 10.1109/TPDS.2021.3056773
   Raj A, 2021, MULTIMED TOOLS APPL, V80, P18901, DOI 10.1007/s11042-021-10715-4
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Ren Y, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/3186112
   Sankar LS, 2017, INT CONF ADVAN COMPU
   Shafay M, 2023, CLUSTER COMPUT, V26, P197, DOI 10.1007/s10586-022-03582-7
   Shibata N, 2019, IEEE ACCESS, V7, P172994, DOI 10.1109/ACCESS.2019.2956698
   Shoker A, 2017, 2017 IEEE 16TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P393
   Singh A, 2022, J SYST ARCHITECT, V127, DOI 10.1016/j.sysarc.2022.102503
   Song HY, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102507
   Steward K, 2017, Overview report The British Standards Institution (BSI)
   Talukder AK, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P257, DOI 10.1109/SmartWorld.2018.00079
   Ullah N, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041801
   Umate R., 2020, DERMATOLOGY, V41, P1
   Visser M, 2021, QUANT SCI STUD, V2, P20, DOI [10.1162/qes_a_00112, 10.1162/qss_a_00112]
   Wang EK, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101871
   Xiong HL, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14020047
   Yang J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071370
   Yu B, 2019, COMPUT SECUR, V87, DOI 10.1016/j.cose.2019.101580
   Yuen HY, 2019, BSCI '19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON BLOCKCHAIN AND SECURE CRITICAL INFRASTRUCTURE, P19, DOI 10.1145/3327960.3332386
NR 73
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18501
EP 18516
DI 10.1007/s11042-022-14161-8
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000885231500009
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   Almomani, I
   Ara, A
   Alkhayer, A
AF El-Shafai, Walid
   Almomani, Iman
   Ara, Anees
   Alkhayer, Aala
TI An optical-based encryption and authentication algorithm for color and
   grayscale medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical processing; Security algorithms; DWT; DRPE; LSB; Compressive
   sensing; Hashing; Steganography; Encryption; SHA-256
ID SECURE; EFFICIENT; STEGANOGRAPHY; PLANE; MODEL
AB The continuous digitization of healthcare services makes them more targeted by security attackers that attempt to steal the patients' confidential records and hijack their healthcare rights. Consequently, many existing approaches were proposed to protect healthcare data and services. However, these current solutions lack efficiency, as indicated by the high number of security breaches in healthcare systems. Therefore, this research was motivated to introduce a more efficient algorithm that achieves several essential security requirements such as authentication, confidentiality, and integrity while preserving high resistance against a comprehensive set of different security threats. This proposed algorithm is a hybrid optical-based that utilizes effective hashing, steganography, and encryption techniques for the secure transmission of color or grayscale medical images, even over insecure channels. The input medical image is initially decomposed into three color components (red, green, and blue). Then, each one of these color components is forwarded to multiple sequential security stages. At the first security stage, the Discrete Wavelet Transform (DWT)-based compressive sensing technique is employed to compress the color components of the plaintext medical image to obtain the compressed image components. After that, the sigmoid function-based quantization process is applied to the compressed image components to generate the digital quantized image components. The digital pixels of these components will then be encrypted using Rubik's cube-based encryption algorithm to obtain the final ciphertext medical image. In parallel, to ensure the authentication and integrity of the transmitted medical image, the image phase component is extracted using the optical Double Random Phase Encoding (DRPE) technique. Then, it is quantized before concatenation with a secret key and forwarded to the SHA-256 hashing algorithm to generate the HMAC digest (Hash-based Message Authentication Code value). The HMAC digest is then embedded using Least Significant Bit (LSB)-based steganography within the final encrypted color medical image to increase its secrecy. The proposed algorithm was extensively evaluated using different quality and security assessment metrics to validate its robustness and efficiency against various channel noise and attacks. The obtained outcomes prove the higher performance of the proposed algorithm for secure medical image communication than other recent and related security algorithms in terms of all tested computational and security parameters. In addition, the obtained results confirm that the optical-based security techniques have superior efficiency & robustness and low complexity compared to the related traditional digital-based security techniques.
C1 [El-Shafai, Walid; Almomani, Iman; Ara, Anees; Alkhayer, Aala] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Almomani, Iman] Univ Jordan, King Abdullah 2 Sch Informat Technol, Comp Sci Dept, Amman 11942, Jordan.
C3 Prince Sultan University; Egyptian Knowledge Bank (EKB); Menofia
   University; University of Jordan
RP El-Shafai, W (corresponding author), Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.; El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM welshafai@psu.edu.sa; imomani@psu.edu.sa; aara@psu.edu.sa;
   akhayer@psu.edu.sa
RI El-Shafai, Walid/AAG-4796-2021; Almomani, Iman/ABH-5908-2020; Ara,
   Anees/T-7583-2018
OI El-Shafai, Walid/0000-0001-7509-2120; Almomani,
   Iman/0000-0003-4639-516X; 
FU Prince Sultan University; Security Engineering Lab (SEL)
FX The authors would like to acknowledge the support of Prince Sultan
   University, especially the Security Engineering Lab (SEL). Moreover,
   this research was done during the author Iman Almomani's sabbatical year
   2021/2022 from The University of Jordan, Amman, Jordan.
CR Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Abd-El-Atty B, 2021, OPT LASER ENG, V138, DOI 10.1016/j.optlaseng.2020.106403
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Alarifi A, 2020, IEEE ACCESS, V8, P128548, DOI 10.1109/ACCESS.2020.3008644
   Alder, 2021, HEALTHCARE DATA BREA
   Almomani I, 2022, 2022 2ND INTERNATIONAL CONFERENCE OF SMART SYSTEMS AND EMERGING TECHNOLOGIES (SMARTTECH 2022), P214, DOI 10.1109/SMARTTECH54121.2022.00054
   Almomani I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062281
   Almomani I, 2022, CMC-COMPUT MATER CON, V70, P1209, DOI 10.32604/cmc.2022.018631
   Alqahtani F, 2022, CMC-COMPUT MATER CON, V70, P3133, DOI 10.32604/cmc.2022.020454
   Archana, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106399
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Borda M, 2011, FUNDAMENTALS IN INFORMATION THEORY AND CODING, P1, DOI 10.1007/978-3-642-20347-3
   Chen MM, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106026
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   El-Shafai W, 2022, J INF SECUR APPL, V64, DOI 10.1016/j.jisa.2021.103039
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P895, DOI 10.32604/cmc.2022.018545
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   El-Shafai W, 2021, IEEE ACCESS, V9, P35004, DOI 10.1109/ACCESS.2021.3062403
   Fan HJ, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.1321
   Faragallah OS, 2022, J AMB INTEL HUM COMP, V13, P1215, DOI 10.1007/s12652-020-02832-z
   Faragallah OS, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106333
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Faragallah OS, 2019, IEEE ACCESS, V7, P4184, DOI 10.1109/ACCESS.2018.2879857
   George SN, 2014, J OPT-INDIA, V43, P1, DOI 10.1007/s12596-013-0147-8
   Godinho TM, 2017, J BIOMED INFORM, V71, P190, DOI 10.1016/j.jbi.2017.06.009
   Gopinathan U., 2005, 2005 IEEE LEOS Annual Meeting, P951, DOI 10.1109/LEOS.2005.1548326
   Gueron S., 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P354, DOI 10.1109/ITNG.2011.69
   Hafsa A, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/6610655
   Hazer A, 2021, J OPTICS-UK, V23, DOI 10.1088/2040-8986/ac2463
   Helmy M, 2022, MULTIDIM SYST SIGN P, V33, P181, DOI 10.1007/s11045-021-00796-7
   Jeevitha S, 2021, J AMB INTEL HUM COMP, V12, P3373, DOI 10.1007/s12652-020-02399-9
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Kang SW, 2022, MULTIMED TOOLS APPL, V81, P1209, DOI 10.1007/s11042-021-11424-8
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Maurya AK, 2021, J SYST ARCHITECT, V120, DOI 10.1016/j.sysarc.2021.102296
   Moon I, 2016, APPL OPTICS, V55, P4328, DOI 10.1364/AO.55.004328
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605
   Selvaraj C, 2022, MOL DIVERS, V26, P1893, DOI 10.1007/s11030-021-10326-z
   Shen YX, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106911
   Stone C. J., 1984, PROC BERKELEY C HONO, V2, P513
   Taylor J. R., 1997, An Introduction to Error Analysis, V2nd, DOI DOI 10.1088/0957-0233/9/6/022
   Thanki R, 2020, INTELLIGENT DATA SEC, P185
   Umbaugh S. E., 2010, Digital Image Processing and Analysis: Human and Computer Vision Applications with CVIPtools, DOI [10.1201/9781439802069, DOI 10.1201/9781439802069]
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 58
TC 6
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23735
EP 23770
DI 10.1007/s11042-022-14093-3
EA NOV 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884646200008
DA 2024-07-18
ER

PT J
AU Xu, WN
   Fu, YL
AF Xu, Wanni
   Fu, Youlei
TI Deep learning algorithm in ancient relics image colour restoration
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algorithm optimization; Deep learning; Ancient relics; Colour image
   segmentation; Image restoration
ID NETWORK; BRAIN
AB In order to restore the original colours of ancient relics more accurately and to reduce the burden of manual restoration, we developed a novel colour-restoration technique based on the DenseNet algorithm, which was used in a case study involving restoration of Dunhuang mural images and is based on deep learning. In recent years, deep learning-based methods have been an important direction for research into virtual restoration of image colours. Typical, damaged murals were generated from 60 mural datasets as input for the system, and these were enhanced by DenseNet, based on the interactive, digital mural-restoration system. We compared execution time, peak signal-to-noise ratio and structural similarities to evaluate DenseNet, SegNet, Deeplab and ResNet algorithms. In terms of time efficiency, the DenseNet algorithm was 44.62% faster than the SegNet algorithm. Regarding structural similarity (SSIM) values for the four models, DenseNet was the lowest: 1.289% lower than SegNet, 2.442% lower than Deeplab v3 and 1.288% lower than ResNet. In terms of the overall comparison, the repair effect for DenseNet was the best. Our method is highly reliable for mural restoration and not only saves time but also produces better virtual restoration results than other methods.
C1 [Xu, Wanni] Fuzhou Univ, Xiamen Acad Arts & Design, Xiamen 361021, Peoples R China.
   [Xu, Wanni; Fu, Youlei] Nanchang Inst Technol, Acad Arts & Design, Nanchang 330044, Jiangxi, Peoples R China.
   [Xu, Wanni] Jiangxi Tellhow Animat Coll, Sch Creat Arts, Nanchang 330200, Jiangxi, Peoples R China.
   [Fu, Youlei] Quanzhou Normal Univ, Fine Art & Design Coll, Quanzhou 362000, Peoples R China.
C3 Fuzhou University; Nanchang Institute Technology; Quanzhou Normal
   University
RP Xu, WN (corresponding author), Fuzhou Univ, Xiamen Acad Arts & Design, Xiamen 361021, Peoples R China.; Xu, WN (corresponding author), Nanchang Inst Technol, Acad Arts & Design, Nanchang 330044, Jiangxi, Peoples R China.; Xu, WN (corresponding author), Jiangxi Tellhow Animat Coll, Sch Creat Arts, Nanchang 330200, Jiangxi, Peoples R China.
EM 80760017t@ntnu.edu.tw; 80868006t@ntnu.edu.tw
OI Fu, You-Lei/0000-0001-8756-0358
FU Fujian Provincial Key Laboratory of DataIntensive Computing; Fujian
   Provincial Big Data Research Institute of Intelligent Manufacturing;
   Fujian University Laboratory of Intelligent Computing and Information
   Processing
FX The authors acknowledge the support by Fujian Provincial Key Laboratory
   of DataIntensive Computing, Fujian University Laboratory of Intelligent
   Computing and Information Processing, and Fujian Provincial Big Data
   Research Institute of Intelligent Manufacturing.
CR Ancora D, 2021, IEEE T IMAGE PROCESS, V30, P1332, DOI 10.1109/TIP.2020.3043387
   Azad Reza, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P251, DOI 10.1007/978-3-030-66415-2_16
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BELFKIH S, 2002, C COLOUR GRAPHICS IM, V2002, P416
   BESCOS J, 1988, APPL OPTICS, V27, P419, DOI 10.1364/AO.27.000419
   Bhargavi K., 2014, INT J INNOV RES DEV, V3, P234
   Cadík M, 2008, COMPUT GRAPH FORUM, V27, P1745
   Caraffa L, 2013, IEEE INT VEH SYM, P994, DOI 10.1109/IVS.2013.6629596
   Chen Zhen, 2013, Journal of Multimedia, V8, P432, DOI 10.4304/jmm.8.4.432-438
   Daschiel H, 2005, IEEE T GEOSCI REMOTE, V43, P188, DOI 10.1109/TGRS.2004.838374
   Deng X, 2021, IEEE T PATTERN ANAL, V43, P3333, DOI 10.1109/TPAMI.2020.2984244
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Ewees AA, 2020, IEEE ACCESS, V8, P26304, DOI 10.1109/ACCESS.2020.2971249
   Fathima E., 2018, INT J PURE APPL MATH, V119, P12415
   Gevrekci M, 2007, INT CONF ACOUST SPEE, P753
   Gibson KB, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-37
   Gottapu RD, 2018, PROCEDIA COMPUT SCI, V140, P179, DOI 10.1016/j.procs.2018.10.327
   Gu ED, 2001, P SOC PHOTO-OPT INS, V4552, P292
   Haseyama M, 1999, INT CONF ACOUST SPEE, P3445, DOI 10.1109/ICASSP.1999.757583
   Hastings E, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P154, DOI 10.1109/CIG.2007.368092
   Hoekstra D, 2010, INT J INTANG HERIT, V5, P61, DOI 10.35638/ijih.2010..5.004
   Huang LQ, 2020, NEUROCOMPUTING, V396, P324, DOI 10.1016/j.neucom.2018.12.083
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jiang B, 2015, J REAL-TIME IMAGE PR, V10, P239, DOI 10.1007/s11554-014-0399-9
   Jiang J., 2013, ELECT DES ENG, V2, P177
   Jin Z, 2020, IEEE T MULTIMEDIA, V22, P1055, DOI 10.1109/TMM.2019.2938340
   Kallel F, 2017, IEEE T NANOBIOSCI, V16, P666, DOI 10.1109/TNB.2017.2771350
   Kamran SA, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ADVANCED INTELLIGENT INFORMATICS (SAIN), P123, DOI 10.1109/SAIN.2018.8673354
   Kekre H. B., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P82, DOI 10.1109/ICETET.2008.107
   Li CL, 2020, IEEE ACCESS, V8, P169887, DOI 10.1109/ACCESS.2020.3023485
   Li QQ, 2018, GEOMATICS INFORM SCI, V237
   Lin KY., 2015, CHINESE J IMAGE GRAP, V01, P1
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   McAuliffe MJ, 2001, COMP MED SY, P381
   Naik K, 2015, ADV INTELL SYST, V332, P97, DOI 10.1007/978-81-322-2196-8_12
   Pavicevic A., 2010, BULGARIAN ETHNOLOGY, V1-2, P51
   Schutzius TM, 2012, NANOSCALE, V4, P5378, DOI 10.1039/c2nr30979c
   Shen C, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.576791
   Song G, 2021, CHINA GEOL, V4, P527, DOI 10.31035/cg2021062
   Steffens CR, 2020, J INTELL ROBOT SYST, V99, P609, DOI 10.1007/s10846-019-01124-9
   Suhr JK, 2011, IEEE T CIRC SYST VID, V21, P365, DOI 10.1109/TCSVT.2010.2087810
   Tang ZH, 2021, RENEW ENERG, V173, P1005, DOI 10.1016/j.renene.2021.04.041
   Tian B., 2018, J SHANDONG I COMMERC, V2, P25
   Wu Z., 2020, IEEE T MED IMAGING, V28, P136
   Yadav V, 2014, CHEM MATER, V26, P4647, DOI 10.1021/cm5022323
   Yan XQ, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115973
   Yan XQ, 2021, NEUROCOMPUTING, V448, P106, DOI 10.1016/j.neucom.2021.03.090
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yin WY, 2020, LANZHOU U TECHNOLOGY, P1
   Youjun Yue, 2020, 2020 IEEE International Conference on Mechatronics and Automation (ICMA), P1986, DOI 10.1109/ICMA49215.2020.9233609
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang GL, 2021, DESIGN STUD, V72, DOI 10.1016/j.destud.2021.100990
   Zhang S., 2012, J XIAN JIAOTONG U, V78, P45
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhao Hong-yu, 2014, Journal of Beijing University of Technology, V40, P404
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
NR 60
TC 3
Z9 3
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23119
EP 23150
DI 10.1007/s11042-022-14108-z
EA NOV 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000880546200002
DA 2024-07-18
ER

PT J
AU Bhatt, A
   Choubey, SB
   Choubey, A
   Pachori, K
   Thakur, V
AF Bhatt, Abhishek
   Choubey, Shruti Bhargava
   Choubey, Abhishek
   Pachori, Khushboo
   Thakur, Vandana
TI Computer vision-based predictive analysis of chronic cardiovascular
   disease using heartbeat features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heartbeats classification; Estimation; Data mining; Decision tree;
   Random forest; Electrocardiogram (ECG); Naive Bayes; K-NN; Artificial
   intelligence
ID CLASSIFICATION; NETWORKS
AB Heart disease has become one of the world's most dangerous and serious diseases due to the difficulty in identifying it. Machine learning may assist the medical field by providing accurate and timely illness diagnoses. The main objective is to develop an expert system that can identify heart illness early and assist cardiologists in making more accurate diagnoses. This paper examines many aspects of heart illness and develops a model using supervised learning techniques like Logistic Regression, Naive Bayes, decision trees, K-nearest neighbor (KNN), random forest, Support Vector Machine (SVM), and the XG Boost methods. It utilizes a dataset of the Cleveland catalog of heart patients at UCI. There are around 303 occurrences plus 76 characteristics within the collection. Only 14 out 76 characteristics are tested, despite their importance in proving the effectiveness of alternative algorithms. The accuracy of different classifiers are,in Naive Bayes 83.51%, SVM 84.79%, Decision Tree 77.5%, Random Forest 87.94%, and KNN 80.21%, Logical Regression 85.0% is obtained. Gradient Boost has the highest accuracy rate of 95.62%, Sensitivity of 92.3%, Precision 83.7%, and specificity of 93.8 Percent in the case of same data set we have applied for other classifier.
C1 [Bhatt, Abhishek] Symbiosis Skill & Profess Univ, Sch Data Sci, Pune, Maharashtra, India.
   [Choubey, Shruti Bhargava; Choubey, Abhishek] Sreenidhi Inst Sci & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Pachori, Khushboo] Oriental Inst Sci & Technol, Bhopal, India.
   [Thakur, Vandana] Technocrats Inst Technol, Bhopal, India.
C3 Sreenidhi Institute of Science & Technology
RP Bhatt, A (corresponding author), Symbiosis Skill & Profess Univ, Sch Data Sci, Pune, Maharashtra, India.
EM abhishek.bhat@sspu.ac.in
RI bhatt, abhishek/G-5819-2015; thakur, vandana/HQE-3101-2023; Bhargava,
   shruti/JXY-2303-2024
OI bhatt, abhishek/0000-0001-7743-6070; T. Bhatt,
   Vandana/0000-0002-8193-5320
CR Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   Al-Razzuqi RAM, 2011, INT J DIABETES DEV C, V31, P22, DOI 10.1007/s13410-010-0001-3
   Alarsan FI, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0244-x
   Azar AT, 2013, NEURAL COMPUT APPL, V23, P1019, DOI 10.1007/s00521-012-1026-y
   Bahrami B., 2015, Journal of Multidisciplinary Engineering Science and Technology, V2, P3159
   Bahrammirzaee A, 2010, NEURAL COMPUT APPL, V19, P1165, DOI 10.1007/s00521-010-0362-z
   Bansal A, 2015, INT J DIABETES DEV C, V35, P432, DOI 10.1007/s13410-015-0296-1
   Blake, 2007, J ENV HLTH, V70
   Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262
   Chaurasia V., 2014, International Journal of Advanced Computer Science and Information Technology, V2, P56
   Dangare ChaitraliS., 2012, INT J COMPUTER APPL, V47, P44, DOI [DOI 10.5120/7228-0076, 10.5120/7228-0076]
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Deepika K, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P381, DOI 10.1109/ICATCCT.2016.7912028
   Dinesh K.G., 2018, 2018 INT C CURRENT T, P1, DOI [10.1109/ICCTCT.2018.8550857, DOI 10.1109/ICCTCT.2018.8550857]
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V29, P685, DOI 10.1007/s00521-016-2604-1
   Farran B, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2012-002457
   Fuhad KMF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10050329
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Heydari M, 2016, INT J DIABETES DEV C, V36, P167, DOI 10.1007/s13410-015-0374-4
   Hoptroff R.G., 1993, Neural Computing Applications, V1, P59, DOI [DOI 10.1007/BF01411375, 10.1007/BF01411375]
   Jindal Harshit, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012072
   Kalaiselvi C., 2015, INT J COMPUT ALGORIT, V4, P54, DOI DOI 10.20894/IJCOA.101.004.002.001
   Kanmani S, 2007, INFORM SOFTWARE TECH, V49, P483, DOI 10.1016/j.infsof.2006.07.005
   Khan SI, 2022, CONCURRENT ENG-RES A, V30, P103, DOI 10.1177/1063293X211026620
   Kidwell DA, BOOK TRACKING LOGIN, P1
   King, 1992, STAT PROJ DAT SET, P1
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Mariot A, 1964, FRIULI MEDICAL, V19
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Patel J., 2021, P 2 INT C COMP COMM, P653, DOI [10.1007/978-981-16-0733-2_46, DOI 10.1007/978-981-16-0733-2_46]
   Policy P, 2019, WE USE COOKIES PERSO, P1
   Purushottam, 2016, PROCEDIA COMPUT SCI, V85, P962, DOI 10.1016/j.procs.2016.05.288
   Ranawana R, 2005, NEURAL COMPUT APPL, V14, P122, DOI 10.1007/s00521-004-0447-7
   Rehman MZU, 2022, CMC-COMPUT MATER CON, V70, P1401, DOI 10.32604/cmc.2022.019046
   Shah D., 2020, SN Comput Sci, V1, P345, DOI DOI 10.1007/S42979-020-00365-Y
   Sharma Vijeta, 2020, 2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN), P177, DOI 10.1109/ICACCCN51052.2020.9362842
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Wu Y., 1999, STAT LEARN THEORY TE, V41, P377, DOI DOI 10.2307/1271368
   Yasdi R, 2000, NEURAL COMPUT APPL, V9, P245, DOI 10.1007/s005210070002
NR 41
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15043
EP 15060
DI 10.1007/s11042-022-14020-6
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000876660900003
DA 2024-07-18
ER

PT J
AU Mehta, S
AF Mehta, Shikha
TI Enhanced SFLA with spectral clustering based co-evolution for 24
   constrained industrial optimization problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-evolution algorithms; Multi population methods; SFLA; Spectral
   clustering; Constrained optimization algorithms; Constrained industrial
   optimization algorithms
ID FROG-LEAPING ALGORITHM; METAHEURISTIC ALGORITHM; DIFFERENTIAL EVOLUTION;
   HANDLING METHOD
AB Solving real world problems with large numbers of constraints and complex optimization functions is a challenging issue. For such problems, meta-heuristic algorithms are able to provide near optimal solutions. Shuffled Frog Leaping Algorithm(SFLA) is a population based meta-heuristic algorithm which employs the concept of population division for evolving the solutions over generations. To enhance the efficacy of SFLA for solving constrained optimization, this work presents Spectral Clustering based co-evolution technique. Spectral Clustering is a graph based clustering algorithm which is used to create memeplexes or partitioning of the population in SFLA. Proposed technique is able to improve the balance between the exploration and exploitation phase of SFLA. The performance of the proposed algorithm (SCSFLA) is evaluated over 24 real world constrained optimization problems. Success rate ratio ranking reveals that proposed Spectral clustering based SFLA (SCSFLA) technique outperforms existing Seed and distance based SFLA (SEEDSFLA), Random SFLA (RSFLA), conventional SFLA and Dynamic sub-swarm number strategy (DSFLA). SCSFLA also performs better than the well-known constrained optimization algorithms IUDE, MAgES, iLSHADE44 for 22 functions out of 24.
C1 [Mehta, Shikha] Jaypee Inst Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Mehta, S (corresponding author), Jaypee Inst Informat Technol, Noida, India.
EM shikha.mehta@jiit.ac.in
RI mehta, shikha/AAE-3586-2021
OI mehta, shikha/0000-0002-2601-6284
CR AGGARWAL A, 1990, COMPUT CHEM ENG, V14, P631, DOI 10.1016/0098-1354(90)87033-L
   Andrei N., 2013, NONLINEAR OPTIMIZATI
   Angira R, 2006, CHEM ENG SCI, V61, P4707, DOI 10.1016/j.ces.2006.03.004
   Babu BV, 2008, STUD FUZZ SOFT COMP, V226, P1, DOI 10.1007/978-3-540-77465-5_1
   Banati Hera, 2013, International Journal of Advanced Intelligence Paradigms, V5, P31
   Brazdil PB, 2000, LECT NOTES ARTIF INT, V1810, P63
   Cai JC, 2021, INT J PROD RES, V59, P5404, DOI 10.1080/00207543.2020.1780333
   Cai JC, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103540
   Chaudhary R, 2020, SWARM EVOL COMPUT, V55, DOI 10.1016/j.swevo.2020.100672
   Costa L, 2001, COMPUT CHEM ENG, V25, P257, DOI 10.1016/S0098-1354(00)00653-0
   Daoden, 2016, MODIFIED SHUFFLED FR
   Deb K, 2000, COMPUT METHOD APPL M, V186, P311, DOI 10.1016/S0045-7825(99)00389-8
   Del Ser J, 2019, SWARM EVOL COMPUT, V48, P220, DOI 10.1016/j.swevo.2019.04.008
   Ding WP, 2013, KNOWL-BASED SYST, V50, P1, DOI 10.1016/j.knosys.2013.03.008
   DUAN QY, 1993, J OPTIMIZ THEORY APP, V76, P501, DOI 10.1007/BF00939380
   Duan XH, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7896926
   Eusuff M, 2006, ENG OPTIMIZ, V38, P129, DOI 10.1080/03052150500384759
   Fan Z, 2018, IEEE C EVOL COMPUTAT, P431, DOI 10.1109/CEC.2018.8477943
   Fay, 1967, ANGEW CHEMIE INT 6 1, V18, P163
   Ferreira MP, 2018, EXPERT SYST APPL, V110, P106, DOI 10.1016/j.eswa.2018.05.027
   Floudas C.A., 1995, Nonlinear and Mixed Integer optimization: Fundamentals and Applications
   FLOUDAS CA, 1990, LECT NOTES COMPUT SC, V455, P1
   Floudas CA., 1990, ORSA J COMPUTING, V2, P225
   Guo YX, 2020, ADV WATER RESOUR, V138, DOI 10.1016/j.advwatres.2020.103531
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   He XY, 2018, APPL SOFT COMPUT, V64, P227, DOI 10.1016/j.asoc.2017.11.050
   Hellwig M, 2018, IEEE C EVOL COMPUTAT, P749, DOI 10.1109/CEC.2018.8477950
   Jaballah S, 2014, INT C INTELL COMP CO, P23, DOI 10.1109/ICCP.2014.6936975
   Jaddi NS, 2015, INFORM SCIENCES, V294, P628, DOI 10.1016/j.ins.2014.08.050
   Jadidoleslam M, 2015, INT J ELEC POWER, V64, P743, DOI 10.1016/j.ijepes.2014.07.073
   Karpagam M, 2020, SOFT COMPUT, V24, P637, DOI 10.1007/s00500-019-04484-4
   Kashtiban, 2009, VARIOUS STRATEGIES P, DOI [10.1109/CSICC.2009.5349641, DOI 10.1109/CSICC.2009.5349641]
   Kaur P, 2017, J PARALLEL DISTR COM, V101, P41, DOI 10.1016/j.jpdc.2016.11.003
   Kordestani JK, 2019, SWARM EVOL COMPUT, V44, P788, DOI 10.1016/j.swevo.2018.09.002
   Kumar A, 2020, SWARM EVOL COMPUT, V56, DOI 10.1016/j.swevo.2020.100693
   Lassig J, 2010, BENEFIT MIGRATION PA, DOI [10.1145/1830483.1830687, DOI 10.1145/1830483.1830687]
   Lei DM, 2020, ENG OPTIMIZ, V52, P1461, DOI 10.1080/0305215X.2019.1674295
   Li CH, 2012, IEEE T EVOLUT COMPUT, V16, P556, DOI 10.1109/TEVC.2011.2169966
   Li XD, 2004, LECT NOTES COMPUT SC, V3102, P105
   Ma HP, 2019, SWARM EVOL COMPUT, V44, P365, DOI 10.1016/j.swevo.2018.04.011
   Ma XY, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1260196
   Mehta S, 2014, SWARM EVOL COMPUT, V17, P25, DOI 10.1016/j.swevo.2014.02.003
   Niknam T, 2011, ENERGY, V36, P6420, DOI 10.1016/j.energy.2011.09.027
   Pant Millie, 2009, International Journal of Recent Trends in Engineering, V1, P21
   Parrott D, 2006, IEEE T EVOLUT COMPUT, V10, P440, DOI 10.1109/TEVC.2005.859468
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Rao S.S., 2009, ENG OPTIMIZATION THE, DOI DOI 10.1002/9780470549124
   RYOO HS, 1995, COMPUT CHEM ENG, V19, P551, DOI 10.1016/0098-1354(94)00097-8
   Sauer R.N., 1964, Hydrocarb. Process., V84, P2
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siddall J.N., 1982, Optimal Engineering Design: Principles and Applications
   Skolicki Z, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1295
   Tang JX, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.004
   Trivedi A, 2018, P 2018 IEEE C EV COM, P1
   Wang, 2013, QUANTUM BINARY SHUFF, DOI [10.1109/IMCCC.2013.366, DOI 10.1109/IMCCC.2013.366]
   Xia XW, 2018, APPL SOFT COMPUT, V67, P126, DOI 10.1016/j.asoc.2018.02.042
   Yan Z, 2014, NEURAL NETWORKS, V55, P20, DOI 10.1016/j.neunet.2014.03.006
   Yang XS, 2014, EVOL INTELL, V7, P17, DOI 10.1007/s12065-013-0102-2
   Zhang JH, 2018, APPL MATH MODEL, V63, P464, DOI 10.1016/j.apm.2018.06.036
NR 60
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17853
EP 17878
DI 10.1007/s11042-022-13790-3
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000871167100002
DA 2024-07-18
ER

PT J
AU Muthukumar, P
   Khan, N
AF Muthukumar, P.
   Khan, Nasreen
TI The large key space image encryption algorithm based on modulus
   synchronization between real and complex fractional-order dynamical
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex fractional-order systems; Hyper-chaos; Modulus synchronization;
   Digital image encryption; Coronavirus image
ID CHAOS
AB This paper constructs and analyzes the dynamical properties of a new fractional-order real hyper-chaotic system and its corresponding complex variable system. A thorough analysis was done by employing stability of equilibrium points, phase plots, Lyapunov spectrum, and bifurcation analysis for the consequences of varying fractional-order derivative and parameter values on the system. For the first time, a modulus synchronization scheme is proposed to synchronize real and complex fractional-order dynamical systems. Based on Lyapunov stability theory, non-linear controllers are designed to achieve the proposed modulus synchronization scheme. A new modulus synchronization encryption algorithm with a large key space size for digital images is introduced for the application. The experimental results and analysis validate the desired algorithm. Also, we compare our result of the new encryption algorithm with the previously published literature and verify the efficacy of the considered scheme. Numerical simulations are given to validate the theoretical analysis
C1 [Muthukumar, P.] Gobi Arts & Sci Coll, PG & Res Dept Math, Gobichettipalayam 638453, Tamil Nadu, India.
   [Khan, Nasreen] Jamia Millia Islamia, Dept Math, New Delhi, India.
C3 Jamia Millia Islamia
RP Khan, N (corresponding author), Jamia Millia Islamia, Dept Math, New Delhi, India.
EM muthukumardg1@gmail.com; nasreen899@gmail.com
RI KHAN, NASREEN/GXE-9649-2022; Muthukumar, P./J-2764-2014
OI KHAN, NASREEN/0000-0001-8448-7511; Muthukumar, P./0000-0001-7152-2947
FU UGC,India [19/06/2016(i)EU-V]
FX Nasreen (19/06/2016(i)EU-V) thankful to UGC,India for providing
   financial support as S.R.F.
CR Aguila-Camacho N, 2014, COMMUN NONLINEAR SCI, V19, P2951, DOI 10.1016/j.cnsns.2014.01.022
   [Anonymous], 2000, INTRO FRACTIONAL CAL
   BAGLEY RL, 1991, J GUID CONTROL DYNAM, V14, P304, DOI 10.2514/3.20641
   Balasubramaniam P, 2015, NONLINEAR DYNAM, V80, P249, DOI 10.1007/s11071-014-1865-4
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chen LP, 2012, PHYS LETT A, V376, P2381, DOI 10.1016/j.physleta.2012.05.060
   CHUA LO, 1986, IEEE T CIRCUITS SYST, V33, P1072, DOI 10.1109/TCS.1986.1085869
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gholamin P, 2019, PRAMANA-J PHYS, V92, DOI 10.1007/s12043-019-1738-y
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   HE JB, 2013, J ZHANGZHOU NORMAL U, V2
   Huang YY, 2020, IEEE ACCESS, V8, P135308, DOI 10.1109/ACCESS.2020.3011524
   Kayalvizhi S, 2020, MULTIMED TOOLS APPL, V79, P3957, DOI 10.1007/s11042-019-7642-0
   Khan A., 2021, International Journal of Applied and Computational Mathematics, V7, P1
   Khan A, 2021, MATH METHODS APPL SC
   Khan A., 2019, Int J Dyn Control, V7, P1419, DOI [10.1007/s40435-019-00585-y, DOI 10.1007/S40435-019-00585-Y]
   Kumar M, 2020, SOFT COMPUT, V24, P13197, DOI 10.1007/s00500-020-04733-x
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Li PY, 2019, IEEE ACCESS, V7, P109577, DOI 10.1109/ACCESS.2019.2934120
   Li TY, 2017, COMPLEXITY, DOI 10.1155/2017/9010251
   Li ZH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050481
   Lien C.-H, 2019, Journal of Physics: Conference Series, V1179, DOI 10.1088/1742-6596/1179/1/012085
   Luo C, 2013, INT J MOD PHYS C, V24, DOI 10.1142/S0129183113500253
   Luo C, 2013, NONLINEAR DYNAM, V71, P241, DOI 10.1007/s11071-012-0656-z
   Mohadeszadeh M, 2019, PRAMANA-J PHYS, V92, DOI 10.1007/s12043-018-1687-x
   Muthukumar P, 2018, ISA T, V82, P51, DOI 10.1016/j.isatra.2017.07.007
   Muthukumar P, 2014, CHAOS, V24, DOI 10.1063/1.4886355
   Muthukumar P, 2014, NONLINEAR DYNAM, V77, P1547, DOI 10.1007/s11071-014-1398-x
   Muthukumaran P, 2021, INT J ENVIRON SCI TE, V18, P2491, DOI 10.1007/s13762-020-03048-6
   Niu YJ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6795964
   Podlubny I, 1998, FRACTIONAL DIFFERENT
   Saichev AI, 1997, CHAOS, V7, P753, DOI 10.1063/1.166272
   Tavazoei MS, 2007, PHYS LETT A, V367, P102, DOI 10.1016/j.physleta.2007.05.081
   Yadav VK, 2019, CHINESE J PHYS, V57, P282, DOI 10.1016/j.cjph.2018.12.001
   Yadav VK, 2016, OPTIK, V127, P10527, DOI 10.1016/j.ijleo.2016.08.026
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 44
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17801
EP 17825
DI 10.1007/s11042-022-14074-6
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000869613000001
PM 36276603
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gan, MG
   Zhang, Y
AF Gan, Ming-Gang
   Zhang, Yan
TI Improving accuracy of temporal action detection by deep hybrid
   convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boundary regression; Proposal classification; Temporal action detection;
   Temporal action location; Video analysis
ID ACTION RECOGNITION; VIDEO; CORPUS
AB Temporal action detection, a fundamental yet challenging task in understanding human actions, is usually divided into two stages: temporal action proposal generation and proposal classification. Classifying action proposals is always considered an action recognition task and receives little attention. However, compared with action classification, classifying action proposals has more large intra-class variations and subtle inter-class differences, making it more difficult to classify accurately. In this paper, we propose a novel end-to-end framework called Deep Hybrid Convolutional Network (DHCNet) to classify action proposals and achieve high-performance temporal action detection. DHCNet improves temporal action detection performance from three aspects. First, DHCNet utilizes Subnet I to effectively model the temporal structure of proposals and generate discriminative proposal features. Second, the Subnet II of DHCNet exploits Graph Convolution (GConv) to acquire information from other proposals and obtains much semantic information to enhance the proposal feature. Third, DHCNet adopts a coarse-to-fine cascaded classification, where the influence of large intra-class variations and subtle inter-class differences are reduced significantly at different granularities. Besides, we design an iterative boundary regression method based on closed-loop feedback to refine the temporal boundaries of proposals. Extensive experiments demonstrate the effectiveness of our approach. Furthermore, DHCNet achieves the state-of-the-art performance on the THUMOS'14 dataset(59.9% on mAP@0.5).
C1 [Gan, Ming-Gang; Zhang, Yan] Beijing Inst Technol, Sch Automat, State Key Lab Intelligent Control & Decis Complex, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Zhang, Y (corresponding author), Beijing Inst Technol, Sch Automat, State Key Lab Intelligent Control & Decis Complex, Beijing 100081, Peoples R China.
EM aganbit@126.com; zhangyanfxtx_2016@163.com
RI jin, li/IWU-4648-2023; Zhang, Zhentao/JQV-7389-2023; zhang,
   jt/JVE-1333-2024
OI Zhang, Yan/0000-0002-9125-3630
FU National Key R&D Program of China [2020YFB1708500]
FX This work is supposed by the National Key R&D Program of China under
   Grant 2020YFB1708500.
CR Aghaahmadi M, 2013, MULTIMED TOOLS APPL, V65, P521, DOI 10.1007/s11042-012-1128-7
   Alwassel H, 2021, IEEE INT CONF COMP V, P3166, DOI 10.1109/ICCVW54120.2021.00356
   [Anonymous], 2018, EUR C COMP VIS
   [Anonymous], 2016, CUHK & ETHZ & SIAT submission to ActivityNet challenge 2016
   Bagchi A, 2021, ARXIV
   Bartlett PL, 2008, J MACH LEARN RES, V9, P1823
   Bastanfard, 2009, PACIFCRIM C MULTIMED
   Bastanfard A, 2009, IEEE SYS MAN CYBERN, P169, DOI 10.1109/ICSMC.2009.5346591
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V5916, P284, DOI 10.1007/978-3-642-11301-7_30
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen HF, 2017, CHINA COMMUN, V14, P163, DOI 10.1109/CC.2017.7868164
   Chen PH, 2020, IEEE T MULTIMEDIA, V22, P2723, DOI 10.1109/TMM.2019.2959977
   Cheng G., 2015, Advances in human action recognition: A survey
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Esfandiari N., 2020, PROC 12 INT S COMMUN, P1
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao J., 2017, arXiv
   Gao JL, 2020, AAAI CONF ARTIF INTE, V34, P10810
   Gao LL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107477
   Gao ZN, 2019, AAAI CONF ARTIF INTE, P8328
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Huang G, 2021, ARXIV
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Li X., 2019, ARXIV
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin CM, 2021, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR46437.2021.00333
   Lin CRN, 2020, AAAI CONF ARTIF INTE, V34, P11499
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu X., 2021, ARXIV
   Liu XL, 2021, PROC CVPR IEEE, P12591, DOI 10.1109/CVPR46437.2021.01241
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Nawhal M, 2021, ARXIV
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Park E, 2016, IEEE WINT CONF APPL
   Peng L, 2021, MULTIMEDIA SYST, V27, P363, DOI 10.1007/s00530-020-00697-y
   Piergiovanni AJ, 2018, IEEE COMPUT SOC CONF, P1821, DOI 10.1109/CVPRW.2018.00226
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2021, P 2021 INT C MULTIME
   Simonyan K, 2014, ADV NEUR IN, V27
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Soomro K, 2017, IEEE I CONF COMP VIS, P696, DOI 10.1109/ICCV.2017.82
   Su B, 2017, IEEE T IMAGE PROCESS, V26, P5784, DOI 10.1109/TIP.2017.2745212
   Su R, 2021, IEEE T IMAGE PROCESS, V30, P2103, DOI 10.1109/TIP.2020.3044218
   Tang Y.P., 2019, ARXIV
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaudaux-Ruth G, 2021, IEEE WINT CONF APPL, P1268, DOI 10.1109/WACV48630.2021.00131
   Wang BL, 2021, IEEE SIGNAL PROC LET, V28, P503, DOI 10.1109/LSP.2021.3061289
   Wang Chen, 2021, arXiv
   Wang H, 2014, IEEE T MULTIMEDIA, V16, P1282, DOI 10.1109/TMM.2014.2312251
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang Z, 2020, AAAI20
   Wu J., 2021, ARXIV
   Xu M, 2021, ARXIV
   Xu M, 2019, ARXIV
   Yilmaz AA, 2020, IEEE ACCESS, V8, P100631, DOI 10.1109/ACCESS.2020.2997962
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhang W, 2021, NEUROCOMPUTING, V444, P16, DOI 10.1016/j.neucom.2021.02.085
   Zhao C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13638, DOI 10.1109/ICCV48922.2021.01340
   Zhao H, 2019, IEEE I CONF COMP VIS, P8667, DOI 10.1109/ICCV.2019.00876
   Zhao P, 2020, PREPRINT
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 73
TC 0
Z9 0
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16127
EP 16149
DI 10.1007/s11042-022-13962-1
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000869338900002
DA 2024-07-18
ER

PT J
AU Chen, TF
   Huang, YB
   Pu, XR
   Yan, SH
   Zhang, QY
AF Chen, Teng-fei
   Huang, Yi-bo
   Pu, Xiang-rong
   Yan, Shao-hui
   Zhang, Qiu-yu
TI Encrypted speech Biohashing authentication algorithm based on 4D
   hyperchaotic Bao system and feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech authentication; Biohashing; 4D hyperchaotic Bao system;
   2D-LICM; Feature fusion; Security
ID RETRIEVAL ALGORITHM; AUDIO; TRANSFORM; SECURITY; SCHEME; HASH
AB Most of the existing Biohashing authentication algorithms extract perception feature from the original domain and store the generated hashing sequence in the cloud, which can easily cause the hashing sequence to be leaked. At the same time, the algorithm's robustness and matching accuracy under background noise are too low, leading to serious deviation in the authentication process. Therefore, this paper proposed an encrypted speech Biohashing authentication algorithm based on 4D hyperchaotic Bao system and feature fusion. Firstly, the algorithm encrypts the original speech by setting the key to the 4D hyperchaotic Bao system and transforms it into encrypted speech. Secondly, the preprocessed encrypted speech is processed by discrete wavelet transform (DWT) and spectral entropy to obtain the feature fusion matrix of the speech, and the pseudo-random matrix is generated by using two-dimensional Logistic ICMIC cascade mapping (2D-LICM). Then the feature fusion matrix and pseudo-random matrix are projected and mapped to construct the biometric template. Finally, the threshold is selected for binarization, and the Biohashing sequence is generated and uploaded to the cloud. In this way, a one-to-one correspondence is established between the encrypted speech and the hashing sequence. The experimental results show that the algorithm can directly extract the authentication digest from the encrypted speech. During the authentication process, the download and decryption of the speech data is not required, which improves the security of the hashing sequence storage. The encrypted speech can reduce the amplitude of signal change, has strong discrimination and robustness, and can resist complex background noise and has good real-time performance.
C1 [Chen, Teng-fei; Huang, Yi-bo; Pu, Xiang-rong; Yan, Shao-hui] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM ctf122508@163.com; huang_yibo@nwnu.edu.cn; 1755021062@qq.com;
   ysh022402@nwnu.edu.cn; zhangqylz@163.com
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Youth Science
   and Technology Fund of Gansu Province of China [21JR7RA120]
FX This work is supported by the National Natural Science Foundation of
   China (No.61862041), Youth Science and Technology Fund of Gansu Province
   of China(No.21JR7RA120).
CR Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Bao BC, 2009, J SYST ENG ELECTRON, V20, P1179
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen N, 2013, ELECTRON LETT, V49, P7, DOI 10.1049/el.2012.3812
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Chen YZ, 2019, SIGNAL PROCESS, V154, P314, DOI 10.1016/j.sigpro.2018.09.013
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Ge SM, 2019, IEEE T IMAGE PROCESS, V28, P2051, DOI 10.1109/TIP.2018.2883743
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Huang YB, 2020, MULTIMED TOOLS APPL, V79, P24889, DOI 10.1007/s11042-020-09211-y
   Huang YB, 2020, IEEE ACCESS, V8, P34140, DOI 10.1109/ACCESS.2020.2974029
   Kang Q, 2016, NEUROCOMPUTING, V181, P132, DOI 10.1016/j.neucom.2015.06.098
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Leonov GA, 2018, UKR MATH J+, V70, P42, DOI 10.1007/s11253-018-1487-y
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Liao QH, 2019, J PHYS CHEM B, V123, P3576, DOI 10.1021/acs.jpcb.8b12363
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mendelson A, 2019, COMPUTER, V52, P65, DOI 10.1109/MC.2019.2943137
   Peng LN, 2020, IEEE T VEH TECHNOL, V69, P1091, DOI 10.1109/TVT.2019.2950670
   Prathosh AP, 2013, IEEE T AUDIO SPEECH, V21, P2471, DOI 10.1109/TASL.2013.2273717
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Shukla MK, 2018, ASIAN J CONTROL, V20, P707, DOI 10.1002/asjc.1593
   Siniscalchi SM, 2014, NEUROCOMPUTING, V140, P326, DOI 10.1016/j.neucom.2014.03.005
   Ullah S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030662
   [王琳 Wang Lin], 2010, [计算机仿真, Computer Simulation], V27, P373
   Wang ZZ, 2016, NEUROCOMPUTING, V173, P1203, DOI 10.1016/j.neucom.2015.08.078
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang QY, 2019, TURK J ELECTR ENG CO, V27, P1719, DOI 10.3906/elk-1808-161
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang QY., 2019, INT J NETW SECUR, V21, P259
   Zhang YB., 2019, RADIOENGINEERING, V49, P899
   Zhao SP, 2019, INFORM SCIENCES, V489, P167, DOI 10.1016/j.ins.2019.03.027
   Zheng Y, 2018, 2018 IEEE INT C CONS
   Zhou L, 2019, IEEE MULTIMEDIA, V26, P8, DOI 10.1109/MMUL.2018.2875256
   Zhou ZY, 2013, 2013 IEEE DIGITAL SI
NR 44
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16767
EP 16792
DI 10.1007/s11042-022-13933-6
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000864966700003
DA 2024-07-18
ER

PT J
AU Kim, H
   Pang, ZQ
   Zhao, LL
   Su, XH
   Lee, JS
AF Kim, Hyeongbok
   Pang, Zhiqi
   Zhao, Lingling
   Su, Xiaohong
   Lee, Jin Suk
TI Semantic-aware deidentification generative adversarial networks for
   identity anonymization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Generative adversarial networks; Image generation;
   Identity anonymization
ID FACE; PRIVACY
AB Privacy protection in the computer vision field has attracted increasing attention. Generative adversarial network-based methods have been explored for identity anonymization, but they do not take into consideration semantic information of images, which may result in unrealistic or flawed facial results. In this paper, we propose a Semantic-aware De-identification Generative Adversarial Network (SDGAN) model for identity anonymization. To retain the facial expression effectively, we extract the facial semantic image using the edge-aware graph representation network to constraint the position, shape and relationship of generated facial key features. Then the semantic image is injected into the generator together with the randomly selected identity information for de-Identification. To ensure the generation quality and realistic-looking results, we adopt the SPADE architecture to improve the generation ability of conditional GAN. Meanwhile, we design a hybrid identity discriminator composed of an image quality analysis module, a VGG-based perceptual loss function, and a contrastive identity loss to enhance both the generation quality and ID anonymization. A comparison with the state-of-the-art baselines demonstrates that our model achieves significantly improved de-identification (De-ID) performance and provides more reliable and realistic-looking generated faces. Our code and data are available on https://github.com/ kimhyeongbok/SDGAN
C1 [Kim, Hyeongbok; Pang, Zhiqi; Zhao, Lingling; Su, Xiaohong] Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China.
   [Lee, Jin Suk] Testworks Inc, Seoul, South Korea.
C3 Harbin Institute of Technology
RP Su, XH (corresponding author), Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China.
EM sxh@hit.edu.cn; jslee@testworks.co.kr
RI ZHAO, lingling/AAM-3755-2020
OI ZHAO, lingling/0000-0003-0315-4569; Kim, Hyeongbok/0000-0003-2264-9962
CR Boyle Michael., 2000, Proc. ACM CSCW 2000, P1
   Breve B, 2020, ITASEC, P71
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Desiato D, 2018, SEBD
   Gafni O, 2019, IEEE I CONF COMP VIS, P9377, DOI 10.1109/ICCV.2019.00947
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R., 2006, 2006 C COMPUTER VISI, P161
   Guo JF, 2021, APPL INTELL, V51, P5953, DOI 10.1007/s10489-020-02121-4
   Guo K, 2022, MULTIMED TOOLS APPL, V81, P5889, DOI 10.1007/s11042-021-11822-y
   Gusi Te, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P258, DOI 10.1007/978-3-030-58610-2_16
   Hensel M, 2017, ADV NEUR IN, V30
   Huan GB, 2008, WORKSHOP FACESREAL L
   Hukkelås H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Liu X., 2020, P IEEE CVF C COMP VI, P8057
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Ma T., 2021, arXiv
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Maximov M, 2020, PROC CVPR IEEE, P5446, DOI 10.1109/CVPR42600.2020.00549
   Meden B., 2017, 2017 INT C WORKSHOP, P1, DOI 10.1109/IWOBI.2017.7985521
   Meden B, 2017, IET SIGNAL PROCESS, V11, P1046, DOI 10.1049/iet-spr.2017.0049
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Neustaedter C., 2006, ACM Transactions on Computer-Human Interaction, V13, P1, DOI 10.1145/1143518.1143519
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Pang Z, 2021, IEEE T CIRCUITS SYST, P1
   PANG Z, 2021, APPL INTELL, P1
   Panis G, 2015, LECT NOTES COMPUT SC, V8926, P737, DOI 10.1007/978-3-319-16181-5_56
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Ren ZZ, 2018, LECT NOTES COMPUT SC, V11205, P639, DOI 10.1007/978-3-030-01246-5_38
   Ryoo MS, 2018, AAAI CONF ARTIF INTE, P7315
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan S, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1589
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sun QR, 2018, PROC CVPR IEEE, P5050, DOI 10.1109/CVPR.2018.00530
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Targ S., 2016, ARXIV
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu YF, 2019, J COMPUT SCI TECH-CH, V34, P47, DOI 10.1007/s11390-019-1898-8
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xiuye Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P727, DOI 10.1007/978-3-030-58592-1_43
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
NR 49
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15535
EP 15551
DI 10.1007/s11042-022-13917-6
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864966800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, Q
   Jiang, B
   Bo, XC
   Yang, C
   Wu, X
AF Li, Qiao
   Jiang, Bin
   Bo, Xiaochen
   Yang, Chao
   Wu, Xu
TI Effective low-light image enhancement with multiscale and context
   learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image enhancement; Transformer; CNN
ID CONTRAST ENHANCEMENT; QUALITY ASSESSMENT
AB Convolutional Neural Network (CNN) has been widely used in low-light image enhancement task, and has achieved good enhancement results. However, the enhancement results not only are limited by the convolution kernel, but also are affected by the different shapes and sizes of low-light regions. CNN can only capture local dependencies. It is difficult to obtain long-distance dependencies and multiscale features from images, resulting in over/under enhancement. To alleviate these problems, we propose a Multiscale and Context Learning Network (MCLNet) for adaptive low-light enhancement by multiscale feature extraction and global relationships learning. Concretely, in order to obtain discriminative representation in diverse low-light regions, we design an Attentive Residual Multiscale Block (ARMB) to captures valuable multiscale features through spatial attention mechanisms at different scales. Further, we propose a Bottleblock of Scale Aggregation Module (BSAM) to learn hierarchical discriminative features based on th ARBM. Finally, to further adaptive enhancement from globel view, we present a Context Encoding Module (CEM) to model long-distance dependencies by Transformer. Experimental results show that our proposed MCLNet achieves superior performance of low-light images enhancement than some state-of-the-art methods.
C1 [Li, Qiao; Jiang, Bin; Yang, Chao] Hunan Univ, Changsha, Peoples R China.
   [Bo, Xiaochen] Beijing Inst Radiat Med, Beijing, Peoples R China.
   [Wu, Xu] Shenzhen Univ, Shenzhen, Peoples R China.
C3 Hunan University; Academy of Military Medical Sciences - China; Shenzhen
   University
RP Jiang, B (corresponding author), Hunan Univ, Changsha, Peoples R China.
EM hliqiao@hnu.edu.cn; jiangbin@hnu.edu.cn; boxiaoc@163.com;
   yangchaoedu@hnu.edu.cn; csxuwu@163.com
RI Wu, Xu/KLD-7259-2024
OI Jiang, Bin/0000-0002-5840-9664
FU National Natural Science Foundation of China [62072169, 62172156];
   Natural Science Foundation; Natural Key R&D Program of China
   [2020YFB1713003]; Scientific Research Project of Hunan Provincial
   Education Department [19A286]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant 62072169 and 62172156, and Natural
   Science Foundation, and Natural Key R&D Program of China under Grant
   No.2020YFB1713003,and Scientific Research Project of Hunan Provincial
   Education Department No.19A286.
CR Cai Z, 2021, ROBUST IMAGE DENOISI
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chongyi L, 2021, ARXIV
   Dong X, 2011, IEEE INT CON MULTI
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fu Q., 2020, ARXIV
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Ghosh S, 2019, IEEE IMAGE PROC, P205, DOI [10.1109/ICIP.2019.8802986, 10.1109/icip.2019.8802986]
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jiang Y., 2021, ARXIV
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   LAND EH, 1964, AM SCI, V52, P247
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Liu CW, 2019, J MOD OPTIC, V66, P1590, DOI 10.1080/09500340.2019.1649482
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F, BRIT MACHINE VISION, P220
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mun J, 2019, J VIS COMMUN IMAGE R, V58, P688, DOI 10.1016/j.jvcir.2018.12.037
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Shen L., 2017, ARXIV
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan SF, 2019, IEEE ACCESS, V7, P70842, DOI 10.1109/ACCESS.2019.2918557
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2019, IEEE INT CONF MULTI, P276, DOI 10.1109/ICMEW.2019.00054
   Wang W., 2021, ARXIV
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, ARXIV
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Yang C., 2021, ARXIV
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zhang C, 2020, IEEE T POWER ELECTR, V35, P9770, DOI 10.1109/TPEL.2020.2970390
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
   Zhang Y.-F., 2021, arXiv
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhuang LY, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3837275
NR 53
TC 0
Z9 0
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15271
EP 15286
DI 10.1007/s11042-022-13830-y
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864205500002
DA 2024-07-18
ER

PT J
AU Yang, SM
   Li, QX
   Wei, WH
   Zhang, YH
AF Yang, Simin
   Li, Qingxia
   Wei, Wenhong
   Zhang, Yuhui
TI A multi-objective evolutionary algorithm based on mixed encoding for
   community detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex network; Multi-objective evolutionary; Mixed encoding;
   Community; Detection
ID GENETIC ALGORITHM; NETWORKS; SEGMENTATION
AB Community structure is one of the most significant features in complex networks and community detection is a crucial method to analyze community structure. Existing representations in community detection have the characteristics of inflexibility and easily generate invalid solutions. To address the drawbacks, this paper proposed a multi-objective evolutionary algorithm based on mixed encoding (MOGAME). The algorithm combines the locus-based representation and labels-based representation, which can avoid generating invalid solution and improve the performance. Extensive experiments on both synthetic and real-word networks show that the proposed algorithm performs better than the existing algorithms with respect to accuracy and stability.
C1 [Yang, Simin; Wei, Wenhong; Zhang, Yuhui] Dongguan Univ Technol, Sch Comp Sci & Technol, Dongguan 523808, Peoples R China.
   [Li, Qingxia] Dongguan City Coll, Sch Comp & Informat, Dongguan 523419, Peoples R China.
C3 Dongguan University of Technology
RP Wei, WH (corresponding author), Dongguan Univ Technol, Sch Comp Sci & Technol, Dongguan 523808, Peoples R China.
EM weiwh@dgut.edu.cn
FU Ministry of Science and Technology of China [2018AAA0101301]; Key
   Projects of Artificial Intelligence of High School in Guangdong Province
   [2019KZDZX1011]; Innovation Project of High School in Guangdong Province
   [2018KTSCX314]; Dongguan Social Development Science and Technology
   Project [20211800904722]; Dongguan Science and Technology Special
   Commissioner Project [20201800500442]
FX This work was supported by the Key Project of Science and Technology
   Innovation 2030 supported by the Ministry of Science and Technology of
   China (Grant No. 2018AAA0101301), the Key Projects of Artificial
   Intelligence of High School in Guangdong Province (No. 2019KZDZX1011),
   Innovation Project of High School in Guangdong Province (No.
   2018KTSCX314), Dongguan Social Development Science and Technology
   Project (No. 20211800904722) and Dongguan Science and Technology Special
   Commissioner Project (No. 20201800500442).
CR [Anonymous], 2007, arXiv
   [Anonymous], Physical Review E, DOI DOI 10.1103/PHYSREVE.80.056117
   Bello-Orgaz G, 2018, INFORM SCIENCES, V462, P290, DOI 10.1016/j.ins.2018.06.015
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Browet A, 2011, LECT NOTES COMPUT SC, V6636, P358, DOI 10.1007/978-3-642-21073-0_32
   Cai Q, 2015, INFORM SCIENCES, V316, P503, DOI 10.1016/j.ins.2014.09.041
   Chen KQ, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122259
   Cheng F, 2018, APPL SOFT COMPUT, V69, P357, DOI 10.1016/j.asoc.2018.04.037
   Dong M-G., 2020, COMPUT SCI, V47, P461
   Gao WF, 2021, INFORM SCIENCES, V578, P129, DOI 10.1016/j.ins.2021.07.051
   Gong MG, 2012, PHYSICA A, V391, P4050, DOI 10.1016/j.physa.2012.03.021
   Gong MG, 2014, IEEE T EVOLUT COMPUT, V18, P82, DOI 10.1109/TEVC.2013.2260862
   Gong MG, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.056101
   Imtiaz ZB, 2021, FUTURE GENER COMP SY, V115, P659, DOI 10.1016/j.future.2020.10.004
   Javed MA, 2018, J NETW COMPUT APPL, V108, P87, DOI 10.1016/j.jnca.2018.02.011
   Ji P, 2020, J AMB INTEL HUM COMP, V11, P173, DOI 10.1007/s12652-019-01241-1
   Kumar A, 2020, IEEE T COMPUT SOC SY, V7, P802, DOI 10.1109/TCSS.2020.2989295
   Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110
   Li JW, 2013, SOFT COMPUT, V17, P925, DOI 10.1007/s00500-012-0942-1
   Lin Z, 2014, PHYSICA A, V416, P386, DOI 10.1016/j.physa.2014.09.023
   Linares OAC, 2017, IET IMAGE PROCESS, V11, P1219, DOI 10.1049/iet-ipr.2016.0072
   Liu WQ, 2021, IEEE T EMERG TOP COM, V9, P1609, DOI 10.1109/TETC.2019.2929100
   Luo, 2011, J NATL U DEF TECHNOL, V133, P89
   Mester A, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9182294
   Moayedikia A, 2018, APPL SOFT COMPUT, V67, P434, DOI 10.1016/j.asoc.2018.03.014
   Mourchid Y, 2017, STUD COMPUT INTELL, V693, P821, DOI 10.1007/978-3-319-50901-3_65
   Mourchidl Y, 2015, INT CONF INTELL SYST, P648, DOI 10.1109/ISDA.2015.7489194
   Newman M., 2004, PHYS REV E, V69, P0661331
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Pérez-Peló S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010023
   Pizzuti C, 2008, LECT NOTES COMPUT SC, V5199, P1081, DOI 10.1007/978-3-540-87700-4_107
   Pizzuti C, 2018, IEEE T EVOLUT COMPUT, V22, P464, DOI 10.1109/TEVC.2017.2737600
   Pizzuti C, 2012, IEEE T EVOLUT COMPUT, V16, P418, DOI 10.1109/TEVC.2011.2161090
   Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101
   Sathyakala M, 2021, J AMB INTEL HUM COMP, V12, P6761, DOI 10.1007/s12652-020-02301-7
   Shang JL, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010049
   Su YS, 2021, INFORM SCIENCES, V576, P374, DOI 10.1016/j.ins.2021.06.089
   Sun X-L., 2021, CHIN J NETW INF SECU, V32, P56
   Teng XY, 2021, IEEE T CYBERNETICS, V51, P138, DOI 10.1109/TCYB.2019.2931983
   Wu P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126845
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yin Xinhong, 2022, ICMLC 2022: 2022 14th International Conference on Machine Learning and Computing (ICMLC), P347, DOI 10.1145/3529836.3529949
   Zhang L, 2017, IEEE T CYBERNETICS, V47, P2703, DOI 10.1109/TCYB.2017.2711038
   Zhang XY, 2017, IEEE T COMPUT SOC SY, V4, P218, DOI 10.1109/TCSS.2017.2749282
   Zhou YL, 2016, SOFT COMPUT, V20, P3273, DOI 10.1007/s00500-015-1706-5
NR 48
TC 3
Z9 3
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14107
EP 14122
DI 10.1007/s11042-022-13846-4
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219700008
DA 2024-07-18
ER

PT J
AU Sha, J
   Zeng, GL
   Xu, ZF
   Yang, Y
AF Sha, Jing
   Zeng, Gong-Li
   Xu, Zhi-Feng
   Yang, Yang
TI A light-weight and accurate pig detection method based on complex scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Embedded platform; YOLOv3-tiny; Pig
   detection
AB With the wide application and rapid development of digital media technology, the interaction between people and computers has become an important part of people's daily life. Pig detection using computer vision is an important technology for realizing fine pig management, real-time monitoring of pig growth and prediction of pig production. In the actual breeding environment, the accurate detection of pigs is difficult, and factors such as target occlusion and small targets seriously affect the accuracy of pig detection. We take a group of healthy pigs in a real breeding environment as the research object and propose a lightweight pig detection method based on YOLOv3-tiny. The method first uses Removal Net to replace YOLOv3-tiny's backbone network, which improves the accuracy and speed of the detection method. Moreover, a new prediction branch is added to the prediction network to improve the detection accuracy for small objects. Then the soft non-maximum suppression(Soft-NMS) algorithm replaces the NMS algorithm in YOLOv3-tiny, which improves the detection ability for occluded objects. Finally, the feasibility and superiority of this method are proved by several groups of comparative tests. The experimental results indicate that our proposed pig-based detection method based on computer vision can provide an effective reference for refined management and real-time monitoring of pigs.
C1 [Sha, Jing; Zeng, Gong-Li; Xu, Zhi-Feng; Yang, Yang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Sha, J; Zeng, GL (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM xo5547@163.com; zenggongli@qq.com
FU Shandong Natural found [ZR2020MF033]
FX This work is supported by Shandong Natural found (No. ZR2020MF033). We
   gratefully acknowledge the invaluable cooperation in preparing this
   paper.
CR Andrew W, 2017, IEEE INT CONF COMP V, P2850, DOI 10.1109/ICCVW.2017.336
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Congguo Ma, 2012, Proceedings of the 2012 Fifth International Conference on Information and Computing Science (ICIC), P103, DOI 10.1109/ICIC.2012.61
   Han SQ, 2017, IOP C SER EARTH ENV, V69, DOI 10.1088/1755-1315/69/1/012096
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Psota ET, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040852
   Redmon J, 2022, ARXIV
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sa J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020266
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082878
   Shafiee MJ, 2017, FAST YOLO FAST YOU O, P1709
   Shi R, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105214
   Sun SW, 2019, PROC SPIE, V11321, DOI 10.1117/12.2538904
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang JZ, 2018, LECT NOTES COMPUT SC, V10996, P620, DOI 10.1007/978-3-319-97909-0_66
   Wang ZQ, 2017, CHIN CONTR CONF, P11104, DOI 10.23919/ChiCC.2017.8029130
   Xiao D, 2019, IEEE ACCESS, V7, P123757, DOI 10.1109/ACCESS.2019.2928603
   Zhang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051188
   Zhen Yang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1673, DOI 10.1109/ICCT46805.2019.8947158
NR 29
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13649
EP 13665
DI 10.1007/s11042-022-13771-6
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190800006
DA 2024-07-18
ER

PT J
AU Nazari, F
   Tabibian, S
   Homayounvala, E
AF Nazari, Fateme
   Tabibian, Shima
   Homayounvala, Elaheh
TI Multimodal user interaction with in-car equipment in real conditions
   based on touch and speech modes in the Persian language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-vehicle equipment; Multimodal user interface; Voice command
   detection; Hidden Markov model; Accessibility
ID RECOGNITION; SYSTEM
AB Nowadays, communication with in-car equipment is performed via a large number of buttons or a touch screen. This increases the need for driver's visual attention and leads to reduce the concentration of drivers while driving. Speech-based interaction has been introduced in recent years as a way to reduce driver distractions. This input mode faces several technical challenges such as the need to memorize voice commands and the difficulties of canceling them. This paper focuses on presenting a multimodal user interface design based on touch and speech modes, for controlling five in-car devices (radio, CD player or music player, fan, heater, and driver-side window). The research is designed to collect a dataset of in-car voice commands in the Persian language in real conditions (in a real car and in the presence of background noises) to firstly create a dataset of Persian voice commands (due to lack of research in this area in Persian speaking countries) and secondly intending to solve the mentioned challenges. To evaluate the proposed user interface, 15 participants performed ten different tasks based on the speech and touch modes, with and without driving simulation. The evaluation results indicated that the speech input mode with and without driving simulation has had in average smaller number of clicks for performing tasks (0.2 and 0.6), smaller task completion time (7.37 and 3.3 seconds), smaller time intervals between clicks (8.2 and 5 seconds) and smaller driver's distraction rate (25.08%) in comparison to the touch input mode, respectively. Moreover, using two different input modes in designing the in-vehicle user interface leads to increased accessibility.
C1 [Nazari, Fateme; Tabibian, Shima] Shahid Beheshti Univ, Cyberspace Res Inst, Shahid Shahri Sq,Daneshjou Blvd,Shahid Chamran Hi, Tehran 1983969411, Iran.
   [Homayounvala, Elaheh] London Metropolitan Univ, Sch Comp & Digital Media, London, England.
C3 Shahid Beheshti University; London Metropolitan University
RP Tabibian, S (corresponding author), Shahid Beheshti Univ, Cyberspace Res Inst, Shahid Shahri Sq,Daneshjou Blvd,Shahid Chamran Hi, Tehran 1983969411, Iran.
EM fat.nazari@mail.sbu.ac.ir; sh_tabibian@sbu.ac.ir;
   e.homayounvala@londonmet.ac.uk
RI Homayounvala, Elaheh/HLQ-1180-2023
OI Homayounvala, Elaheh/0000-0003-0992-0287
CR Aftab AR, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P487, DOI 10.1145/3340555.3356093
   [Anonymous], 1999, AM C P 400 STANDARD
   [Anonymous], 2012, CONNECTIONIST SPEECH
   [Anonymous], 2018, ISO 9241-11
   Azargoshasb S, 2018, RSI INT CONF ROBOT M, P326, DOI 10.1109/ICRoM.2018.8657523
   Bellegarda J. R., 2014, Natural Interaction with Robots, Knowbots and Smartphones, P3
   Braun M, 2019, J MULTIMODAL USER IN, V13, P71, DOI 10.1007/s12193-019-00301-2
   Buchhop K, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P21, DOI 10.1145/3122986.3123001
   Burnett G, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P164, DOI 10.1145/3122986.3122990
   Castronovo S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P510
   Diaconu C, 2016, US Patent, Patent No. [9,251,214, 9251214]
   Endsley M.R., 2004, DESIGNING SITUATION, DOI DOI 10.1201/B11371
   Fischer P, 2008, IEEE SYS MAN CYBERN, P1511
   Hidden Markov Model Toolkit (HTK), 2015, SPEECH VIS ROB GROUP
   Hossan M. A., 2010, 2010 4 INT C SIGN PR, P1, DOI DOI 10.1109/ICSPCS.2010.5709752
   Kalkhoran LS, 2020, 6 IRANIAN C SIGNAL P, P1
   Khare A, 2009, MULTIMODAL INTERFACE, P1
   Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3
   Korayem MH, 2021, ROBOTICA, V39, P1779, DOI 10.1017/S0263574720001496
   Kujala T, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P1, DOI 10.1145/3122986.3122987
   Kujala T, 2013, PERS UBIQUIT COMPUT, V17, P815, DOI 10.1007/s00779-012-0517-2
   Marcus A., 1995, Human-Computer interaction, P425, DOI DOI 10.1016/B978-0-08-051574-8.50044-3
   McCallum M. C., 2004, International Journal of Speech Technology, V7, P25, DOI 10.1023/B:IJST.0000004804.85334.35
   Miller R., 2004, LECT NOTES
   Naseri MM, 2020, 6 IRANIAN C SIGNAL P, P1
   NIELSEN J, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P152, DOI 10.1145/191666.191729
   Pfleging B., 2012, Proceedings of the 4th International Conference on Automotive User Interfaces and, P155, DOI [10.1145/2390256.2390282, DOI 10.1145/2390256.2390282]
   Roider F, 2019, J MULTIMODAL USER IN, V13, P89, DOI 10.1007/s12193-019-00297-9
   Sameti H, 2008, COMM COM INF SC, V6, P485
   Tabibian S, 2018, 4 C SIGN PROC INT SY, P1
   Tabibian S, 2017, INT J SPEECH TECHNOL, V20, P1049, DOI 10.1007/s10772-017-9467-4
   Tsimhoni O., 2001, Proceedings of the Human Factors and Ergonomics Society 45th Annual Meeting, V45, P1586, DOI DOI 10.1177/154193120104502305
   Veisi H, 2020, INT J SPEECH TECHNOL, V23, P893, DOI 10.1007/s10772-020-09768-x
   Wickens C., 2004, INTRO HUMAN FACTORS, V2nd
   Yang S, 2014, INT C HUMAN COMPUTER, P484
   Zhao D, 2019, LECT NOTES COMPUT SC, V11903, P384, DOI 10.1007/978-3-030-34113-8_32
NR 36
TC 0
Z9 0
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12995
EP 13023
DI 10.1007/s11042-022-13784-1
EA SEP 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000858369900004
DA 2024-07-18
ER

PT J
AU Reddy, ASK
   Rao, KNB
   Soora, NR
   Shailaja, K
   Kumar, NCS
   Sridharan, A
   Uthayakumar, J
AF Reddy, A. Siva Krishna
   Rao, K. N. Brahmaji
   Soora, Narasimha Reddy
   Shailaja, Kotte
   Kumar, N. C. Santosh
   Sridharan, Abel
   Uthayakumar, J.
TI Multi-modal fusion of deep transfer learning based COVID-19 diagnosis
   and classification using chest x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Chest X-rays; Deep learning; Fusion model; Radiological images
ID CORONAVIRUS; WUHAN
AB COVID-19 pandemic has a significant impact on the global health and daily lives of people living over the globe. Several initial tests are based on the detecting of the genetic material of the coronavirus, and they have a minimum detection rate with a time-consuming process. To overcome this issue, radiological images are recommended where chest X-rays (CXRs) are employed in the diagnostic process. This article introduces a new Multi-modal fusion of deep transfer learning (MMF-DTL) technique to classify COVID-19. The proposed MMF-DTL model involves three main processes, namely pre-processing, feature extraction, and classification. The MMF-DTL model uses three DL models namely VGG16, Inception v3, and ResNet 50 for feature extraction. Since a single modality would not be adequate to attain an effective detection rate, the integration of three approaches by the use of decision-based multimodal fusion increases the detection rate. So, a fusion of three DL models takes place to further improve the detection rate. Finally, a softmax classifier is employed for test images to a set of six different. A wide range of experimental result analyses is carried out on the Chest-X-Ray dataset. The proposed fusion model is found to be an effective tool for COVID-19 diagnosis using radiological images with the average sens(y) of 92.96%, spec(y) of 98.54%, prec(n) of 93.60%, accu(y) of 98.80%, F-score of 93.26% and kappa of 91.86%.
C1 [Reddy, A. Siva Krishna] SR Univ, Sch CS & AI, Dept CS & AI, Warangal, Telangana, India.
   [Rao, K. N. Brahmaji] Raghu Inst Technol, Vishakhapatnam, Andhra Pradesh, India.
   [Soora, Narasimha Reddy] Kakatiya Inst Technol & Sci, Warangal 15, Telangana, India.
   [Shailaja, Kotte] Kakatiya Inst Technol & Sci, Dept EIE, Warangal 15, Telangana, India.
   [Kumar, N. C. Santosh] Kakatiya Inst Technol & Sci, Dept Comp Sci & Engn, Warangal 15, Telangana, India.
   [Sridharan, Abel] Univ Madras, Dept Comp Sci, Madras, Tamil Nadu, India.
   [Uthayakumar, J.] Genesys Acad Comp Sci, Pondicherry, India.
C3 Kakatiya University; Kakatiya University; Kakatiya University;
   University of Madras
RP Uthayakumar, J (corresponding author), Genesys Acad Comp Sci, Pondicherry, India.
EM reddyandluru@gmail.com; brahmaji77@gmail.com; snreddy75@gmail.com;
   shailaja.wgl@gmail.com; santosh.naliganti@gmail.com;
   abel.sridharan@gmail.com; uthayresearchscholar@gmail.com
RI Soora, Narasimha Reddy/AAF-6622-2019; kotte, Shailaja/JJE-4657-2023
OI Soora, Narasimha Reddy/0000-0002-2268-0022; KOLIPAKA, NAGA BRAHMAJI
   RAO/0000-0003-0792-2086
CR Al-Turjman F., 2020, AI POWERED IOT COVID
   Al-Turjman F, 2019, IEEE ACCESS, V7, P115749, DOI 10.1109/ACCESS.2019.2931637
   [Anonymous], IDENTIFICATION PLANT
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ayyar MP, 2021, IEEE INT CONF COMP V, P519, DOI 10.1109/ICCVW54120.2021.00064
   Basu N., 2016, EUROPEAN J BIOMED, V3, P493
   Chu DKW, 2020, CLIN CHEM, V66, P549, DOI 10.1093/clinchem/hvaa029
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jang H., 2017, PLoS One, V12, P1, DOI 10.1371/journal.pone.0119873
   Kamal KC, 2021, SIGNAL IMAGE VIDEO P, V15, P959, DOI 10.1007/s11760-020-01820-2
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Liu R, 2020, CLIN CHIM ACTA, V505, P172, DOI 10.1016/j.cca.2020.03.009
   Nguyen D, 2021, Arxiv, DOI arXiv:2102.09616
   Ozturk S., 2020, MEDRXIV, DOI [10.1101/2020.04.03.20048868, DOI 10.1101/2020.04.03.20048868]
   Rahman MA, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102372
   Rasheed J, 2021, INTERDISCIP SCI, V13, P103, DOI 10.1007/s12539-020-00403-6
   Salman S, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109689
   Shankar K, 2021, COMPLEX INTELL SYST, V7, P1277, DOI 10.1007/s40747-020-00216-6
   Simonyan K., 2014, CORR
   Wang DW, 2020, JAMA-J AM MED ASSOC, V323, P1061, DOI 10.1001/jama.2020.1585
   WHO-Coronavirus disease, 2019, WWW WHO INT EM DIS N
   Xie MX, 2020, INT J INFECT DIS, V94, P119, DOI 10.1016/j.ijid.2020.03.071
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
NR 25
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12653
EP 12677
DI 10.1007/s11042-022-13739-6
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854429700011
PM 36157355
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Singh, V
   Tiwary, US
AF Singh, Varsha
   Tiwary, Uma Shanker
TI Visual content generation from textual description using improved
   adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-image generation; Generative Adversarial Networks (GANs);
   Fine-grained images; Multi-model problem
AB This paper presents an improved adversarial network for visual content generation from textual description. Synthesizing high-quality images from the textual description is the most challenging problem in Computer vision. Existing methods first generate the initial image sketch and then refine that to fine-grained details at different portions of that image. Mostly available text to image generation methods and approaches nearly reflect the meaning of a given text description. But have not successfully generated details and different parts of the objects. As these methods depend on (1) the initial generated image. If the initial image is not generated correctly, the process fails to generate the fine-grained image with details. (2) According to the image's content, each word has a different level of importance; however, similar text representation is used even for different image contents. Here, an improved Adversarial Network based on hyper-parameter optimization to generate fine-grained images is proposed. Inception Score (IS), t-Distributed Stochastic Neighbor Embedding (TSNE) and R-precision as a metric is used to evaluate and refine the initial image automatically. An attention mechanism is used to pay attention to more valuable words of text description to generate more refined sub-parts of the image. For which an attentional module is used to calculate the matching loss of image-text for generator training. The proposed model has been evaluated on the Caltech-UCSD Birds 200 dataset. Results using Inception score, R-precision, and TSNE matrix shows the model performs favourably against state of the art approaches ATT-GAN (2018) and DM-GAN (2019) improving by 25.72% and 19.37% respectively in terms of Inception score.
C1 [Singh, Varsha; Tiwary, Uma Shanker] Indian Inst Informat Technol, Dept Informat Technol, Allahabad 211006, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Singh, V (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad 211006, Uttar Pradesh, India.
EM rsi2018002@iiita.ac.in; ust@iiita.ac.in
RI Singh, Varsha/JJC-3364-2023
OI Singh, Varsha/0000-0003-4777-1278
CR Abbood SH, 2022, INT J ONLINE BIOMED, V18, P151, DOI 10.3991/ijoe.v18i03.28005
   Aggarwal A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6157
   Aggarwal A, 2021, MULTIMED TOOLS APPL, V80, P1289, DOI 10.1007/s11042-020-09520-2
   Agnese J, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1345
   Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374
   Banerjee S., 2020, arXiv
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Cheng J., 2020, IEEE C COMP VIS PATT, P10911
   Dash A., 2017, arXiv
   Ding M., 2021, ARXIV
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Dong H, 2017, IEEE I CONF COMP VIS, pCP1, DOI 10.1109/ICCV.2017.608
   Fu A, 2017, TEXT TO IMAGE GENERA
   Gao LL, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107384
   Garg K, 2022, LECT NOTES COMPUT SC, V13184, P16, DOI 10.1007/978-3-030-98404-5_2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou Y., 2020, arXiv
   Hensel M, 2017, ADV NEUR IN, V30
   Hinz T., 2019, ARXIV
   Hong S, 2018, PROC CVPR IEEE, P7986, DOI 10.1109/CVPR.2018.00833
   Huang H., 2018, arXiv
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kumar M, 2022, ARTIF INTELL REV, V55, P2997, DOI 10.1007/s10462-021-10070-8
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   Li BW, 2019, ADV NEUR IN, V32
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Mansimov E, 2015, ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mishra Priyanka, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P139, DOI 10.1109/ICETCE48199.2020.9091779
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Peng DL, 2021, NEURAL NETWORKS, V138, P57, DOI 10.1016/j.neunet.2021.01.023
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Ramesh A., 2021, arXiv
   Reed S, 2016, ADV NEUR IN, V29
   Reed S, 2016, PR MACH LEARN RES, V48
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Sah S, 2018, IEEE IMAGE PROC, P3783, DOI 10.1109/ICIP.2018.8451656
   Salimans T, 2016, ADV NEUR IN, V29
   Sun QL, 2002, MED ENG PHYS, V24, P595, DOI 10.1016/S1350-4533(02)00045-0
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao M, 2020, ARXIV
   Valle R., 2019, HANDS ON GENERATIVE
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Ye H., 2021, ARXIV
   Yuan MK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1407, DOI 10.1145/3240508.3240559
   Zakraoui J, 2021, MULTIMED TOOLS APPL, V80, P27423, DOI 10.1007/s11042-021-11038-0
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang H, 2021, PROC CVPR IEEE, P833, DOI 10.1109/CVPR46437.2021.00089
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang Y., 2022, VISUAL COMPUT, P1
   Zhou P., 2021, ARXIV
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 58
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10943
EP 10960
DI 10.1007/s11042-022-13720-3
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854695000005
DA 2024-07-18
ER

PT J
AU Lee, S
   Kye, H
AF Lee, Sehee
   Kye, Heewon
TI Efficient MIP volume rendering via fast SIMD interpolation and memory
   access reordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum intensity projection; Shear-warp volume rendering; Single
   instruction multiple data; Real-time rendering; Efficient memory access
ID INTENSITY PROJECTION ALGORITHM; AVX
AB This study describes an acceleration method that can perform efficient maximum intensity projection (MIP) visualization, which is essential for medical imaging systems. The proposed method is based on shear-warp volume rendering and produces rendering images using trilinear interpolation in real time without a GPU. This study includes two acceleration methods. First, we propose a high-speed interpolation method using AVX2, which is a single instruction, multiple data system of modern CPUs. Trilinear interpolation can be performed rapidly using the AVX2 instructions by taking advantage of the fact that each interpolation weight is the same while using the shear-warp volume rendering. Second, we propose a method for efficiently accessing the memory, focusing on the fact that changing the order of the comparison operations does not affect the image quality in MIP. We propose a new method for changing the repetition and memory access orders so that large volume data can be read sequentially, and image data can be accessed repeatedly. Moreover, we investigate the effectiveness of aligned memory access. The experiment demonstrates significant improvements compared to existing methods. As a result, volume data composed of more than 500 images used in clinical practice can be rendered in real time using trilinear interpolation. In this study, high-quality MIP volume rendering is possible in real-time with only CPU. Since this study does not go through a complicated pre-processing process, it can be easily applied to existing medical imaging systems.
C1 [Lee, Sehee] Hansung Univ, Dept Informat Syst Engn, 116 Samseongyo Ro,16 Gil, Seoul 02876, South Korea.
   [Kye, Heewon] Hansung Univ, Div Comp Engn, 116 Samseongyo Ro,16 Gil, Seoul 02876, South Korea.
C3 Hansung University; Hansung University
RP Kye, H (corresponding author), Hansung Univ, Div Comp Engn, 116 Samseongyo Ro,16 Gil, Seoul 02876, South Korea.
EM kuei@hansung.ac.kr
OI KYE, HEEWON/0000-0001-7951-3228
FU Hansung University
FX This research was financially supported by Hansung University.
CR Agulleiro JI, 2015, J STRUCT BIOL, V189, P147, DOI 10.1016/j.jsb.2014.11.009
   Amiri H, 2020, J PARALLEL DISTR COM, V135, P83, DOI 10.1016/j.jpdc.2019.09.012
   [Anonymous], 2014, ARCS 2014 2014WORKSH
   Belina S, 2009, COLLEGIUM ANTROPOL, V33, P43
   Chen KH., 2012, SAE Int., V1, P1, DOI DOI 10.4271/2012-01-0645
   Dachille F., 1998, SIGGRAPHEUROGRAPHICS, P69
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   Fang LF, 2002, MAGNET RESON MED, V47, P696, DOI 10.1002/mrm.10114
   Knoll A, 2011, IEEE PAC VIS SYMP, P3, DOI 10.1109/PACIFICVIS.2011.5742355
   Kye H, 2018, MULTIMED TOOLS APPL, V77, P15971, DOI 10.1007/s11042-017-5171-2
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Meissner M, 2001, IEEE 2001 SYMPOSIUM ON PARALLEL AND LARGE-DATA VISUALIZATION AND GRAPHICS, PROCEEDINGS, P107, DOI 10.1109/PVGS.2001.964411
   Mroz L., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P135
   Mroz L, 2000, COMPUT GRAPH FORUM, V19, pC341, DOI 10.1111/1467-8659.00426
   REZK-SALAMA C., 2000, EGSIGGRAPH WORKSHOP, P109, DOI DOI 10.1145/346876.348238
   Sabella P., 1988, Computer Graphics, V22, P51, DOI 10.1145/378456.378476
   SCHREINER S, 1993, IEEE T MED IMAGING, V12, P50, DOI 10.1109/42.222666
   Schulze J.P., 2003, VG 03, P109
   Shahbahrami A., 2006, P 17 ANN WORKSH CIRC, P334
   Sweeney Jon., 2002, PROC S DATA VISUALIS, P95
   Treibig J, 2013, INT J HIGH PERFORM C, V27, P162, DOI 10.1177/1094342012442424
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Zekri Ahmed Sherif, 2014, International Journal of Computer Science & Information Technology, V6, P67, DOI 10.5121/ijcsit.2014.6305
   Zhao K, 2014, COMM COM INF SC, V474, P228
NR 25
TC 0
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10515
EP 10534
DI 10.1007/s11042-022-13732-z
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000850023000006
DA 2024-07-18
ER

PT J
AU De, S
   Bhaumik, J
   Giri, D
   Das, AK
AF De, Supriyo
   Bhaumik, Jaydeb
   Giri, Debasis
   Das, Ashok Kumar
TI A new robust and fragile scheme based on chaotic maps and dwt for
   medical image security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-dimensional chaos; Discrete wavelet transform (DWT); Blind
   watermarking; Image authentication; Tamper detection
ID WATERMARKING; ENCRYPTION
AB Medical image security includes copyright protection, authentication, data integrity and confidentiality simultaneously. In this article, a new robust and fragile medical image security scheme has been introduced. The Beddington, Free and Lawton (BFL) map and the Henon map based image encryption scheme is brought out for confidentiality. Further, a Discrete Wavelet Transform (DWT)-based image watermarking scheme is developed for copyright protection, authentication and data integrity. The proposed scheme is essentially robust and retrievable in terms of the watermark; however, it is highly sensitive and irretrievable with reference to the host image. The scheme separates the host image in Region of Interest (ROI) and Region of Non-Interest (RONI) parts, and it embeds the encoded message inside the RONI part. In addituon, the proposed scheme does not need any side information for message extraction. The performance of the scheme has been successfully tested and verified by several well known parameters. Moreover, the extensive experimental results exhibit the strength and effectiveness of the proposed technique with respect to the other state-of-the-art existing techniques.
C1 [De, Supriyo] Techno Engn Coll Banipur, Habra 743233, W Bengal, India.
   [Bhaumik, Jaydeb] Jadavpur Univ, Kolkata 700032, W Bengal, India.
   [Giri, Debasis] Maulana Abul Kalam Azad Univ Technol, Nadia 741249, W Bengal, India.
   [Das, Ashok Kumar] Int Inst Informat Technol, Secur Theory & Algorithm Res, Hyderabad 500032, India.
C3 Jadavpur University; Maulana Abul Kalam Azad University of Technology;
   International Institute of Information Technology Hyderabad
RP Das, AK (corresponding author), Int Inst Informat Technol, Secur Theory & Algorithm Res, Hyderabad 500032, India.
EM supriyo.tech@gmail.com; bhaumik.jaydeb@gmail.com;
   debasis_giri@hotmail.com; iitkgp.akdas@gmail.com
RI De, Supriyo/HRB-3694-2023; Giri, Debasis/ABF-6428-2022; Das, Ashok
   Kumar/U-2790-2019
OI Giri, Debasis/0000-0003-3033-3036; Das, Ashok Kumar/0000-0002-5196-9589
CR Abd-Eldayem MM, 2013, EGYPT INFORM J, V14, P1, DOI 10.1016/j.eij.2012.11.002
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   BEDDINGTON JR, 1975, NATURE, V255, P58, DOI 10.1038/255058a0
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   2017, HDR DATASET COMPUTAT
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kester QA, 2015, 2015 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS (ICCSA), P8, DOI 10.1109/ICCSA.2015.8
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Nottingham Trent University UK, UCID IMAGE DATABASE
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Showkat S, 2021, MULTIMED TOOLS APPL, V80, P2009, DOI 10.1007/s11042-020-09732-6
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Stinson D., 2002, CRYPTOGRAPHY THEORY, V2nd
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   The National Library of Medicine U.S., DATASET VISIBLE HUMA
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   University of California San Diego, STARE IMAGE DATABASE
   University of Southern California, USC SIPI IMAGE DATAB
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
NR 31
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11753
EP 11792
DI 10.1007/s11042-022-13585-6
EA SEP 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000849154000002
DA 2024-07-18
ER

PT J
AU Arsan, T
   Bulut, EE
   Eren, B
   Uzgor, A
   Yolcu, S
AF Arsan, Taner
   Bulut, Enes Emre
   Eren, Berk
   Uzgor, Ahmet
   Yolcu, Selcuk
TI A novel IPTV framework for automatic TV commercials detection, labeling,
   recognition and replacement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commercial detection and recognition; IPTV; Live broadcasting; Video
   streaming; Commercial replacing
ID SEGMENTATION
AB Advertisements are one of the most important way for companies to access their customers. In this context, televison commercials are gaining significant importance in many sectors daily, and it is crucial for companies to promote their products in the best way. This creates a big rivalry between companies. From this point of view, we have created an IPTV Framework that can automatically detect commercials of rival companies and replace them with desired commercials for companies to help them highlight their products to their customers. We have benefited from monochrome frames to detect the Livestream commercial block and proposed a fingerprint algorithm to create an automatic commercial database. We can easily recognize the commercials, and we can mask the commercials of rival companies with these techniques. We have tested our algorithm in real-time by streaming a recorded broadcast from a server of a specific TV channel. Experimental results show that our algorithm provides high accuracy in real-time commercial recognition.
C1 [Arsan, Taner] Kadir Has Univ, Comp Engn Dept, TR-34083 Istanbul, Turkey.
   [Bulut, Enes Emre; Eren, Berk; Uzgor, Ahmet; Yolcu, Selcuk] Turcom Technol, TR-34485 Istanbul, Turkey.
C3 Kadir Has University
RP Arsan, T (corresponding author), Kadir Has Univ, Comp Engn Dept, TR-34083 Istanbul, Turkey.
EM arsan@khas.edu.tr
RI Arsan, Taner/AAB-2736-2019
OI Arsan, Taner/0000-0002-4453-3218
FU Scientific and Technological Research Council of Turkey (TuBTAK)
   [7160967]
FX This project was financially supported by the Scientific and
   Technological Research Council of Turkey (TuBTAK). The Project Grant
   Number is 7160967.
CR [Anonymous], 2017, CONSUMERS VIEW ADVER
   [Anonymous], DEFINITION ADVERTISI
   [Anonymous], 2018, US ONLINE TRADITIONA
   Berrani SA, 2008, SIGNAL PROCESS-IMAGE, V23, P525, DOI 10.1016/j.image.2008.04.018
   Bo Zhang, 2012, Proceedings of the 2012 International Symposium on Instrumentation & Measurement, Sensor Network and Automation (IMSNA), P322, DOI 10.1109/MSNA.2012.6324578
   Bo Zhang, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P2010, DOI 10.1109/FSKD.2012.6234003
   Covell M, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P461, DOI 10.1109/MMSP.2006.285351
   Fati SM, 2019, MULTIMED TOOLS APPL, V78, P16817, DOI 10.1007/s11042-018-7057-3
   Gomes A, 2017, P SAS S, V2018, P1, DOI 10.1109/ICSPCS.2017.8270456
   Hauptmann AG, 1998, P IEEE INT FORUM RES, P168, DOI 10.1109/ADL.1998.670392
   Hua XS, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P149
   Hyun Soo Kim, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370495
   IMARC (International Market Analysis Research and Consulting), 2019, Silicones and Siloxanes Market: Global Industry Trends, Share, Size, Growth, Opportunity and Forecast 2020-2025
   Jiang D, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101735
   Kannan Ramasamy, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370394
   Kitanovski V., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P140, DOI 10.1109/EUVIP.2010.5699100
   Li MY, 2017, PROCEEDINGS OF 2017 VI INTERNATIONAL CONFERENCE ON NETWORK, COMMUNICATION AND COMPUTING (ICNCC 2017), P48, DOI 10.1145/3171592.3171619
   Li Y., 2008, Conferences in Research and Practice in Information Technology Series, V75, P57
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Putpuek Narongsak, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3288, DOI 10.1109/ICPR.2010.804
   Sadlier DA, 2002, PATTERN RECOGN, V35, P2719, DOI 10.1016/S0031-3203(01)00251-5
   Sarikh S., 2017, 2017 25 SIGNAL PROCE, P1, DOI DOI 10.1109/SIU.2017.7960392
   Schöffmann K, 2009, LECT NOTES COMPUT SC, V5371, P119, DOI 10.1007/978-3-540-92892-8_13
   Senarath R., 2017, 2017 IEEE NTERNATION, P1, DOI [10.1109/ICIINFS.2017.8300389, DOI 10.1109/ICIINFS.2017.8300389]
   Shivadas A, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P465, DOI 10.1109/CRV.2007.53
   Tapu R, 2020, IEEE ACCESS, V8, P99582, DOI 10.1109/ACCESS.2020.2997949
   Tvheadend, US
   Wen XD, 1999, MULTIMEDIA SYST, V7, P350, DOI 10.1007/s005300050137
   Wu XM, 2013, IEEE T CIRC SYST VID, V23, P1054, DOI 10.1109/TCSVT.2013.2248991
NR 29
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8561
EP 8579
DI 10.1007/s11042-021-11563-y
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000847985800003
DA 2024-07-18
ER

PT J
AU Zhang, MX
   Zhu, YH
   Zhang, WJ
   Zhu, YW
   Feng, TY
AF Zhang, Meixian
   Zhu, Yonghua
   Zhang, Wenjun
   Zhu, Yunwen
   Feng, Tianyu
TI Modularized composite attention network for continuous music emotion
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music emotion recognition; Filter bank output; Handcrafted features;
   Valence; Arousal
ID FEATURES
AB Music Emotion Recognition (MER) has attracted much interest in the past decades. Many deep learning methods have been applied to this field recently. However, the previous methods for MER mostly utilized simple convolutional layers to extract features from the original audio signals, in which representative emotion-related features cannot be extracted. In this paper, we propose a novel method named Modularized Composite Attention Network (MCAN) for continuous MER. A sample reconstruction technique is proposed to enhance the stability of the network. Specifically, a feature augmentation module is constructed to extract salient features and we design a weighted attention module to control the focus of the whole network. Furthermore, a style embedding module is introduced to enhance the detail processing capability of the network. We conduct experiments on two datasets, that is, the benchmark dataset DEAM and the newly proposed dataset PMEmo. The superior results prove the effectiveness of our proposed MCAN. Especially qualitative analyses are given to for explaining the performance of our model.
C1 [Zhang, Meixian; Zhu, Yonghua; Zhang, Wenjun; Zhu, Yunwen; Feng, Tianyu] Shanghai Univ, Shanghai Film Acad, Shanghai, Peoples R China.
   [Zhang, Wenjun] Shanghai Jianqiao Univ, Coll Informat Technol, Shanghai, Peoples R China.
C3 Shanghai University
RP Zhu, YH (corresponding author), Shanghai Univ, Shanghai Film Acad, Shanghai, Peoples R China.
EM little_xx@shu.edu.cn; zyh@shu.edu.cn; 18096@gench.edu.cn;
   eilleen31@shu.edu.cn; fengtianyu@shu.edu.cn
RI Zhu, Yonghua/HSI-1360-2023; Feng, Tian-Yu/AAX-3892-2020
OI Zhang, Meixian/0000-0002-6696-2814
CR Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Amiriparian S., 2019, CEUR WORKSHOP PROC
   [Anonymous], 2003, Proceedings of the International Symposium on Music Information Retrieval
   [Anonymous], 2016, IJCAI
   [Anonymous], 2001, P COST G6 C DIG AUD
   [Anonymous], 2011, Music Emotion Recognition
   [Anonymous], 2018, P ISMIR 2018 19 INT
   Bharti Deepak, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P491, DOI 10.1109/ICOSEC49089.2020.9215376
   Bogdanov D., 2013, P 14 INT SOC MUS INF, P493, DOI DOI 10.1145/2502081.2502229
   Bogdanov D., 2019, P MEDIAEVAL 2019 WOR
   Cabrera D., 1999, Australian Acoustical Society Conference, V24, P47
   Chen S., 2015, AVEC 2015-Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015, P49, DOI DOI 10.1145/2808196.2811638
   CHEUK KW, 2020, IEEE IJCNN
   Dieleman S., 2011, 12th International Society for Music Information Retrieval Conference (ISMIR-2011), P669
   Dingle GA, 2015, ART PSYCHOTHER, V45, P18, DOI 10.1016/j.aip.2015.05.005
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Florence S., 2020, IOP C SERIES MAT SCI, V912
   Grekow, 2018, CONTENT BASED MUSIC, DOI 10.1007/978-3-319-70609-2
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P8213, DOI 10.1007/s11042-020-10030-4
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang J, 2018, PROCEEDINGS OF THE 2018 AUDIO/VISUAL EMOTION CHALLENGE AND WORKSHOP (AVEC'18), P57, DOI 10.1145/3266302.3266304
   Hung HT, 2019, P MEDIAEVAL 2019 WOR
   Jun S., 2009, P 5 INT C VIS INF EN, P673, DOI DOI 10.1049/CP:20080398
   Lartillot O., 2007, INT C MUSIC INFORM R
   Li XX, 2016, INT CONF ACOUST SPEE, P544, DOI 10.1109/ICASSP.2016.7471734
   Li YS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060593
   Licai Sun, 2020, MuSe'20: Proceedings of the 1st International Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop, P27, DOI 10.1145/3423327.3423672
   MacDorman KF, 2007, J NEW MUSIC RES, V36, P281, DOI 10.1080/09298210801927846
   Malik M., 2017, Proc. Sound Music Comput. Conf, P208
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mayerl M, 2019, P MEDIAEVAL 2019 WOR
   Orjesek R, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P213, DOI 10.1109/radioelek.2019.8733572
   Patra Braja Gopal, 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P62, DOI 10.1007/978-3-319-03844-5_7
   Sangnark S, 2019, J PHYS CONF SER, V1195, DOI 10.1088/1742-6596/1195/1/012009
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Schmidt E.M., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference (ISMIR), P465
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soleymani M., 2013, P 2 ACM INT WORKSH C, P1, DOI DOI 10.1145/2506364.2506365
   Sukhavasi M, 2019, P MEDIAEVAL 2019 WOR
   Sun X., 2020, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), P1, DOI 10.1145/3340463
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Tzanetakis G., 2000, Organised Sound, V4, P169, DOI DOI 10.1017/S1355771800003071
   Wang J.-C., 2012, P 20 ACM INT C MULTI, P89, DOI DOI 10.1145/2393347.2396494
   Wang YN, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P595, DOI 10.1145/3340555.3355720
   Wu B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P117, DOI 10.1145/2647868.2654904
   Yang J, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.760060
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Yang Y.-H., 2006, P 14 ANN ACM INT C M, P81, DOI DOI 10.1145/1180639.1180665
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yuanzhong Wang, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P262
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang KJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P135, DOI 10.1145/3206025.3206037
   Zhao J., 2019, P INT AUD VIS EM CHA, P37
   Zhao SC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2945, DOI 10.1145/3394171.3413776
NR 55
TC 0
Z9 0
U1 6
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7319
EP 7341
DI 10.1007/s11042-022-13577-6
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842724400002
DA 2024-07-18
ER

PT J
AU Brahma, SR
   Singh, S
   Gupta, DK
   Malik, A
AF Brahma, Sanjiu Raja
   Singh, Samayveer
   Gupta, Deepak Kumar
   Malik, Aruna
TI A reversible data hiding technique using lower magnitude error channel
   pair selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grayscale invariance; Colour image; Adjusted variance; Double embedding;
   Channel pair
ID COLOR IMAGE; WATERMARKING
AB There are many data hiding algorithms in which the quality of images is degraded during data concealing and extracting. Thus, now a day such methods are required that can recover the image as well as data during extraction called reversible data hiding methods. The existing reversible data hiding methods provide good quality with the low capacity or poor quality with the high capacity because of the quality and capacity are entirely related to each other. Thus there is a dire need to develop a method which can provide good quality as well as capacity. In this paper, a reversible data hiding (RDH) technique for colour image based on prediction error expansion (PEE) with efficient pixel selection is presented. In traditional methods, the local variance of the grayscale image is used as the pixel selection parameter as it is proportional to the prediction error (PE). Considering that different colour channels contribute by different amount in the formation of grey image, we propose a pixel selection technique where the local variance of the colour channels is also used along with that of grayscale image to improve the quality of the selected pixels as embedding in pixels with lower magnitude PEs will yield lower distortion. Also to improve the embedding capacity of the RDH technique, double embedding in one of the colour channel has been proposed which will again be achieved by pixel selection among the selected pixels.
C1 [Brahma, Sanjiu Raja; Singh, Samayveer; Gupta, Deepak Kumar; Malik, Aruna] Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Singh, S (corresponding author), Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM samayveersingh@gmail.com
RI Singh, Samayveer/X-8119-2019
OI Singh, Samayveer/0000-0002-4199-721X
CR Amanatiadis A, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/10/104015
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Danahy E, 2007, IMAGE PROCESSING ALG, V6497, P305
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Gao ZP, 2019, ARXIV
   Gedam MG, 2016, NCRTCSIT IOSR J COMP, V5, P43
   Govind PVS, 2015, PROCEDIA COMPUT SCI, V46, P491, DOI 10.1016/j.procs.2015.02.073
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Huang HC., 2017, J INFORM HIDING MULT, V8, P435
   Huang HC, 2016, JOINT INT CONF SOFT, P706, DOI [10.1109/SCIS-ISIS.2016.0152, 10.1109/SCIS&ISIS.2016.185]
   Jung KH, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P355, DOI 10.1109/ICHIT.2008.279
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kore SN, 2015, IJIRCCE, V3, P7027
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Ronanki VG., 2015, IJCSIT, V6, P4299
   Roy A, 2020, IEEE T CIRC SYST VID, V30, P2377, DOI 10.1109/TCSVT.2019.2911042
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Saravanan C, 2010, INT C COMPUT ENG APP, P196, DOI 10.1109/ICCEA.2010.192
   Singh Ajay Kumar, 2015, International Journal of Advanced Computer Science, V5, P426
   Tang ZJ, 2020, IEEE ACCESS, V8, P6915, DOI 10.1109/ACCESS.2020.2964264
   Wu H., 2016, ARXIV
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang QY., 2018, J INF HIDING MULTIME, V9, P61
   Zhou SY, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107562
NR 28
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8467
EP 8488
DI 10.1007/s11042-022-13554-z
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000836525000010
DA 2024-07-18
ER

PT J
AU Patel, N
   Kumar, V
AF Patel, Neeraj
   Kumar, Vinod
TI An efficient key distribution Scheme for WSN with Mutual Healing
   Capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key distribution; Wireless sensor networks; Mutual healing; Chinese
   remainder theorem; Secure communication
ID AUTHENTICATION
AB The need for secure communication in Wireless Sensor Networks (WSNs) is increasing as more and more complex sensors are being developed and deployed for a variety of purposes. Secure communication in WSN can be made possible by using secret group key. However, securely distributing group key among sensor nodes is a difficult task and requires very complex mathematical calculations. The schemes presented so far are either vulnerable to various security attacks or have high computational and storage complexity. This paper presents a new Group Key Distribution scheme with Mutual Healing (GKDMH) which is based on Chinese Remainder theorem. The proposed scheme has better performance than existing schemes in terms of computational and storage complexity, and provides mutual healing in case of missed transmissions.
C1 [Patel, Neeraj; Kumar, Vinod] Univ Allahabad, Dept Elect & Commun, Prayagraj, UP, India.
C3 University of Allahabad
RP Patel, N (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, UP, India.
EM neeraj2020mtech@gmail.com
RI Kumar, Vinod/AAE-4887-2020; Kumar, Vinod/JDD-5866-2023
OI Kumar, Vinod/0000-0002-8924-4612; 
CR Agrawal S., 2016, P IEEE INT C ADV NET, P1, DOI DOI 10.1109/ANTS.2016.7947799
   Agrawal S, 2017, COMPUT COMMUN, V112, P131, DOI 10.1016/j.comcom.2017.08.014
   Bhaskar PK, 2015, LECT NOTES COMPUT SC, V8956, P311, DOI 10.1007/978-3-319-14977-6_30
   Blundo C, 2004, DESIGN CODE CRYPTOGR, V32, P15, DOI 10.1023/B:DESI.0000029210.20690.3f
   Chen CL, 2015, J SENSORS, V2015, DOI 10.1155/2015/534657
   Du XJ, 2005, IEEE T BROADCAST, V51, P264, DOI 10.1109/TBC.2005.847600
   Gu J, 2010, IEEE ICC
   Han S, 2010, 2010 IEEE INT C COMM, P1, DOI [10.1109/ICC.2010.5501988, DOI 10.1109/ICC.2010.5501988]
   Han S, 2009, IEEE T WIREL COMMUN, V8, P1876, DOI 10.1109/TWC.2009.080046
   Hong D, 2005, IEEE COMMUN LETT, V9, P759, DOI [10.1109/LCOMM.2005.1496607, 10.1109/LCOMM.2005.08015]
   Lauter K, 2004, IEEE WIREL COMMUN, V11, P62, DOI 10.1109/MWC.2004.1269719
   Liu D., 2003, PROC 10 ACM C COMPUT, P231, DOI DOI 10.1145/948109.948141
   Liu YJ, 2014, INT J COMMUN SYST, V27, P3502, DOI 10.1002/dac.2569
   Louw J, 2016, IEEE INTL CONF IND I, P1166, DOI 10.1109/INDIN.2016.7819342
   Lv XX, 2013, IET INFORM SECUR, V7, P61, DOI 10.1049/iet-ifs.2010.0314
   Rams T, 2013, 2013 CONFERENCE ON NETWORKED SYSTEMS (NETSYS), P59, DOI 10.1109/NetSys.2013.19
   Rams T, 2013, IEEE COMMUN SURV TUT, V15, P820, DOI 10.1109/SURV.2012.081712.00144
   Shim KA, 2013, AD HOC NETW, V11, P182, DOI 10.1016/j.adhoc.2012.04.015
   Staddon J, 2002, P IEEE S SECUR PRIV, P241, DOI 10.1109/SECPRI.2002.1004375
   Steiner M, 2000, IEEE T PARALL DISTR, V11, P769, DOI 10.1109/71.877936
   Tanwar S, 2019, J DISCRET MATH SCI C, V22, P953, DOI 10.1080/09720529.2019.1632024
   Tanwar S, 2017, INT J INF SECUR PRIV, V11, P1, DOI 10.4018/IJISP.2017070101
   Tian BM, 2011, J NETW COMPUT APPL, V34, P80, DOI 10.1016/j.jnca.2010.09.002
   Vijayakumar P, 2014, IET INFORM SECUR, V8, P179, DOI 10.1049/iet-ifs.2012.0352
   Xinliang Zheng, 2007, Proceedings of the 45th ACM Southeast Conference. ACMSE 07, P266, DOI 10.1145/1233341.1233389
   Ye N, 2014, APPL MATH INFORM SCI, V8, P1617, DOI 10.12785/amis/080416
   Zhou J, 2009, J CHIN INST ENG, V32, P967, DOI 10.1080/02533839.2009.9671584
NR 27
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36735
EP 36749
DI 10.1007/s11042-022-13501-y
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000836366300007
DA 2024-07-18
ER

PT J
AU De Bock, J
   Verstockt, S
AF De Bock, Jelle
   Verstockt, Steven
TI Road cycling safety scoring based on geospatial analysis, computer
   vision and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Computer vision; Data analysis; Geospatial analysis;
   Sports data science
AB Road cycling is a cycling discipline in which riders ride on public roads. Traffic calming measures are made to make public roads safer for everyday usage for all its users. However, these measures are not always yielding a safer cycling racecourse. In this paper we present a methodology that inspects the safety of roads tailored to road bicycle racing. The automated approach uses computer vision and geospatial analysis to give an indicative racecourse safety score based on collected, calculated and processed multimodal data. The current version of our workflow uses OpenStreetMap (OSM), turn detection and stage type / bunch sprint classification for the geospatial analysis and uses road segmentation and an extensible object detector that is currently trained to detect road cracks and imperfections for visual analysis. These features are used to create a mechanism that penalizes dangerous elements on the route based on the remaining distance and the generated penalties with its relative importance factors. This results in a comprehensive safety score along with a detailed breakdown of the most concerning passages on the course which can be used by race organizers and officials to help them in the iterative process to create an engaging, yet safe course for the riders.
C1 [De Bock, Jelle; Verstockt, Steven] Univ Ghent, IDLab, Technol Pk Zwijnaarde 122, B-9052 Ghent, Belgium.
C3 Ghent University
RP De Bock, J (corresponding author), Univ Ghent, IDLab, Technol Pk Zwijnaarde 122, B-9052 Ghent, Belgium.
EM jelle.debock@ugent.be; steven.verstockt@ugent.be
RI De Bock, Jelle/GQQ-2185-2022
OI De Bock, Jelle/0000-0002-1676-9813; Verstockt,
   Steven/0000-0003-1094-2184
FU IMEC; Ghent University; Union Cycliste Internationale (UCI)
FX This research is funded by the IMEC, Ghent University and Union Cycliste
   Internationale (UCI).
CR Arya D, 2020, Arxiv, DOI arXiv:2008.13101
   Chen C, 2017, ACCIDENT ANAL PREV, V108, P234, DOI 10.1016/j.aap.2017.09.001
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   de Geus B, 2012, ACCIDENT ANAL PREV, V45, P683, DOI 10.1016/j.aap.2011.09.045
   Deac C, 2019, MATEC WEB CONF, V290, DOI 10.1051/matecconf/201929006004
   Economic Commission for Europe, 2019, STAT ROAD TRAFFIC AC
   Elvik R, 2017, ACCIDENT ANAL PREV, V99, P364, DOI 10.1016/j.aap.2016.12.018
   Gitelman V, 2001, P INT C TRAFF SAF 3
   Ibrahim M. R., 2021, PREPRINT, DOI 10.48550/ARXIV.2102.00565
   Ihs A., 2005, 6th International Conference on Managing Pavements 19-24 October 2004 Brisbane Convention Exhibition Centre, Queensland Australia, P11
   Jateikiene L, 2016, TRANSP RES PROC, V14, P4228, DOI 10.1016/j.trpro.2016.05.394
   Jocher G., 2020, YOLOV5 CODE REPOSITO
   Kirmse A, 2017, PROG PHYS GEOG, V41, P788, DOI 10.1177/0309133317738163
   Kurath S., 2017, GI Forum, V2, P173
   Montgomery D C., 2021, Introduction to linear regression analysis
   Murgano E, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124183
   Rateke T., 2019, REV INFORM TEORICA A
   Rateke T, 2021, AUTON ROBOT, V45, P299, DOI 10.1007/s10514-020-09964-3
   Segvic S., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P66, DOI 10.1109/ITSC.2010.5624979
   Union Cycliste Internationale, 2018, CALCULATION TIME GAP
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
NR 22
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8359
EP 8380
DI 10.1007/s11042-022-13552-1
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000832844000008
DA 2024-07-18
ER

PT J
AU Juneja, K
AF Juneja, Kapil
TI Design of a multi-stage hybrid model for face recognition in varied
   illumination conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination invariant; Face recognition; Fuzzy; Weber; SURF
ID SINGULAR-VALUE DECOMPOSITION; FEATURE-EXTRACTION; IMAGE-ENHANCEMENT;
   CONTRAST; NORMALIZATION; PROJECTION; QUALITY
AB Varied Illumination and unequal contrast are the critical challenges in the face recognition system. This paper presents a multi-stage hybrid model to handle extreme illumination, unequal contract, and varied pose challenges. These challenges are handled within pre-processing and feature generation stages. In the pre-processing stage, the content and structural feature-based feature exposing and region selection method is defined. In the second stage, the hybrid feature generation- adaptive weber and speeded up robust features(AWSURF) model is applied on rectified and normalized face images. In this stage, a weber filter is applied for generating the exposing the structural contents. The Speeded up Robust Features (SURF) method is applied to the weber face for extracting the illumination and pose robust features. The proposed model has experimented on Yale, Extended-Yale and CMU-PIE datasets. The proposed model is experimented and validated against EigneFace, Local Binary Pattern(LBP), Gabor,EigenFace+Gabor, Gabor+LBP,Weber, SURF,Weber+SURF feature processors. The experimental analysis is done against accuracy and error measures. The proposed model achieved the 92.88%, 91.77% and 99.09% accuracy against Yale, Extended-Yale and CMU-PIE datasets and outperformed the experimented handcraft approaches. The analysis results confirm that the proposed model achieved a higher average accuracy rate against state-of-art deep learning and handcraft approaches.
C1 [Juneja, Kapil] Bennett Univ, Dept Comp Sci Engn, Greater Noida, Uttar Pradesh, India.
RP Juneja, K (corresponding author), Bennett Univ, Dept Comp Sci Engn, Greater Noida, Uttar Pradesh, India.
EM kapil.juneja81@gmail.com
CR Alotaibi S, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P585, DOI 10.1109/IntelliSys.2017.8324354
   Alrjebi MM, 2018, MULTIMED TOOLS APPL, V77, P25659, DOI 10.1007/s11042-018-5812-0
   [Anonymous], 2012, P 29 INT C MACH LEAR
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen GY, 2019, J ELECTR ENG-SLOVAK, V70, P113, DOI 10.2478/jee-2019-0017
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen XY, 2017, MULTIMED TOOLS APPL, V76, P22043, DOI 10.1007/s11042-017-4782-y
   Cherifi CF, 2019, ARAB J SCI ENG, V44, P7203, DOI 10.1007/s13369-019-03916-5
   Dalal S, 2020, ARAB J SCI ENG, V45, P9977, DOI 10.1007/s13369-020-04566-8
   Dandpat SK, 2018, 2018 3RD INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
   Faraji MR, 2018, NEUROCOMPUTING, V308, P87, DOI 10.1016/j.neucom.2018.04.062
   Gangonda SS, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hu CH, 2019, MULTIMED TOOLS APPL, V78, P27425, DOI 10.1007/s11042-019-07830-8
   Hu CH, 2019, IEEE T IMAGE PROCESS, V28, P2624, DOI 10.1109/TIP.2018.2887346
   Hu CH, 2017, PATTERN RECOGN, V64, P60, DOI 10.1016/j.patcog.2016.10.029
   Jiménez-Sánchez AR, 2009, IEEE T IMAGE PROCESS, V18, P613, DOI 10.1109/TIP.2008.2010152
   Juneja Kapil, 2019, Applications of Computing, Automation and Wireless Systems in Electrical Engineering. Proceedings of MARC 2018. Lecture Notes in Electrical Engineering (LNEE 553), P945, DOI 10.1007/978-981-13-6772-4_82
   Juneja Kapil, 2018, International Journal of Image, Graphics and Signal Processing, V10, P1, DOI 10.5815/ijigsp.2018.03.01
   Juneja K, 2021, WIRELESS PERS COMMUN, V118, P3075, DOI 10.1007/s11277-021-08170-3
   Juneja K, 2020, J KING SAUD UNIV-COM, V32, P618, DOI 10.1016/j.jksuci.2017.10.006
   Juneja K, 2017, COMM COM INF SC, V750, P181, DOI 10.1007/978-981-10-6544-6_18
   Juneja K, 2017, COMM COM INF SC, V750, P216, DOI 10.1007/978-981-10-6544-6_21
   Juneja K, 2016, ADV INTELL SYST, V452, P161, DOI 10.1007/978-981-10-1023-1_16
   Juneja K, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P218, DOI 10.1109/ICATCCT.2015.7456885
   Junjea K, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P320, DOI 10.1109/ICIIP.2015.7414788
   Kasperek J., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P430
   Kathuria D, 2018, C INFORM COMMUNICATI, P1
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li CR, 2019, EXPERT SYST APPL, V137, P453, DOI 10.1016/j.eswa.2019.05.034
   Li L, 2018, NEURAL PROCESS LETT, V47, P1197, DOI 10.1007/s11063-017-9693-4
   Li L, 2016, AEU-INT J ELECTRON C, V70, P920, DOI 10.1016/j.aeue.2016.04.007
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liang JZ, 2016, SIGNAL IMAGE VIDEO P, V10, P1441, DOI 10.1007/s11760-016-0950-1
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu T, 2018, MULTIMED TOOLS APPL, V77, P11219, DOI 10.1007/s11042-017-5475-2
   Machidon AL, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P80, DOI [10.1109/tsp.2019.8768864, 10.1109/TSP.2019.8768864]
   Meena H, 2017, INT CONF CLIM CHG, P1, DOI 10.17501/iccc.2017.1101
   Mukhopadhyay S, 2000, SIGNAL PROCESS, V80, P685, DOI 10.1016/S0165-1684(99)00161-9
   Mustapha A, 2017, MULTIMED TOOLS APPL, V76, P21961, DOI 10.1007/s11042-017-4665-2
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Park S, 2018, IEEE ACCESS, V6, P22084, DOI 10.1109/ACCESS.2018.2812809
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Qahwaji R, 2020, DEEP LEARNING COMPUT, P38
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Sellahewa H, 2010, IEEE T INSTRUM MEAS, V59, P805, DOI 10.1109/TIM.2009.2037989
   Serajeh R, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P902, DOI 10.1109/KBEI.2017.8324926
   Silwal R, 2020, MULTIMED TOOLS APPL, V79, P31027, DOI 10.1007/s11042-020-09559-1
   Süsstrunk S, 2004, PROC SPIE, V5304, P118, DOI 10.1117/12.537804
   Terol-Villalobos IR, 2004, OPT ENG, V43, P1577, DOI 10.1117/1.1757456
   Terol-Villalobos IR, 2001, ADV IMAG ELECT PHYS, V118, P207, DOI 10.1016/S1076-5670(01)80106-3
   Vishwakarma Virendra P., 2018, 2018 2nd IEEE International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES), P982, DOI 10.1109/ICPEICES.2018.8897464
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Wang JW, 2018, INFORM SCIENCES, V435, P69, DOI 10.1016/j.ins.2017.12.057
   Wang Y, 2010, PATTERN RECOGN, V43, P3580, DOI 10.1016/j.patcog.2010.05.021
   Yadav J, 2019, ARAB J SCI ENG, V44, P9067, DOI 10.1007/s13369-019-03729-6
   Yang C, 2019, COMPUTING, V101, P605, DOI 10.1007/s00607-019-00706-7
   Yu JB, 2020, NEURAL COMPUT APPL, V32, P6009, DOI 10.1007/s00521-019-04085-0
   Zhang Y, 2019, SIGNAL IMAGE VIDEO P, V13, P657, DOI 10.1007/s11760-018-1394-6
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P28355, DOI 10.1007/s11042-018-6044-z
   Zhao ZH, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), P218, DOI 10.1109/ICISCAE.2018.8666899
   Zhi RC, 2008, NEUROCOMPUTING, V71, P3607, DOI 10.1016/j.neucom.2008.04.047
NR 69
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5627
EP 5662
DI 10.1007/s11042-022-13586-5
EA JUL 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000832844000009
DA 2024-07-18
ER

PT J
AU Kathavate, PN
   Amudhavel, J
AF Kathavate, Pravin Narayan
   Amudhavel, J.
TI Optimized convolutional neural network for soft tissue sarcoma diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft tissue sarcoma; Local vector pattern; Convolutional neural network;
   Bat algorithm; SA-BA model
ID GENETIC ALGORITHM; CLASSIFICATION; IMAGES; FUSION; TUMORS; MRI
AB Indistinct soft tissue sarcomas are a form of tumor that can be difficult to diagnose in a tremendous population. For earlier prediction of distant metastasis, some traditional classifications are suffered by technological issues, lack of enhancement methods, reliability, and so on. To provide a better classification, this paper introduces a new deep learning-based soft tissue sarcoma classification framework. Initially, spatial features and LVP features are extracted.The main aim of this phase is to generate LVP using each pixel vector and provides the benefits of inherent structures in edge patches. The subsequent classification phase is utilized an optimized Convolutional Neural Network (CNN). Moreover, the weight and filter size of CNN will be optimally tuned by the new Self Adaptive Bat Algorithm (SA-BA). Finally, SA-BA method is compared over some existing classifiers in terms of various measures.
C1 [Kathavate, Pravin Narayan; Amudhavel, J.] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kathavate, PN (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
EM pravin.kathavate@gmail.com; info.amudhavel@gmail.com
RI Jayavel, Amudhavel/H-3212-2011
OI Jayavel, Amudhavel/0000-0001-6227-0733
CR Abed-alguni B, 2020, J INTELL SYST, V29, P1043, DOI 10.1515/jisys-2018-0331
   Al-Husseinawi E, 2019, PATHOLOGY, V51, P610, DOI 10.1016/j.pathol.2019.05.003
   Banerjee I, 2018, COMPUT MED IMAG GRAP, V65, P167, DOI 10.1016/j.compmedimag.2017.05.002
   Baskaran K, 2018, MATER TODAY-PROC, V5, P1879, DOI 10.1016/j.matpr.2017.11.289
   Blackledge MD, 2019, FRONT ONCOL, V9, DOI 10.3389/fonc.2019.00941
   Callegaro D, 2019, ECLINICALMEDICINE, V17, DOI 10.1016/j.eclinm.2019.11.008
   Clark MA, 2005, NEW ENGL J MED, V353, P701, DOI 10.1056/NEJMra041866
   Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9
   Dadras M, 2020, J PLASTIC RECONSTRUC
   Dadras M, 2020, SURG ONCOL, V33, P126, DOI 10.1016/j.suronc.2020.02.016
   De Sanctis R, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/2786163
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Farhidzadeh H, 2015, IEEE SYS MAN CYBERN, P2798, DOI 10.1109/SMC.2015.488
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Gomez-Brouchet A, 2019, ORTHOP TRAUMATOL-SUR, V105, P773, DOI 10.1016/j.otsr.2018.12.015
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Han AKW, 2020, TAIWAN J OBSTET GYNE, V59, P275, DOI 10.1016/j.tjog.2020.01.017
   Hermessi H, 2019, EXPERT SYST APPL, V120, P116, DOI 10.1016/j.eswa.2018.11.025
   Honoré C, 2015, J VISC SURG, V152, P223, DOI 10.1016/j.jviscsurg.2015.05.001
   Jiang Q, 2017, IEEE ACCESS, V5, P20286, DOI 10.1109/ACCESS.2017.2758644
   Juntu J, 2010, J MAGN RESON IMAGING, V31, P680, DOI 10.1002/jmri.22095
   Kulluk S, 2012, ENG APPL ARTIF INTEL, V25, P11, DOI 10.1016/j.engappai.2011.07.006
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Liu Q, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103505
   Meyer HJ, 2019, SURG ONCOL, V30, P92, DOI 10.1016/j.suronc.2019.06.006
   Nawaz MS, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107200
   Pasquali S, 2018, EUR J CANCER, V93, P28, DOI 10.1016/j.ejca.2018.01.071
   Peeken JC, 2019, EBIOMEDICINE, V48, P332, DOI 10.1016/j.ebiom.2019.08.059
   Peeken JC, 2019, RADIOTHER ONCOL, V135, P187, DOI 10.1016/j.radonc.2019.01.004
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Ramya HR, 2016, 2016 INT C CIRC CONT, P1, DOI DOI 10.1109/CIMCA.2016.8053286
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Weigl H, 2020, SURG ONCOL, V34, P109, DOI 10.1016/j.suronc.2020.04.001
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Yeh JY, 2008, EXPERT SYST APPL, V34, P1285, DOI 10.1016/j.eswa.2006.12.012
   Zhang Y, 2019, ACAD RADIOL, V26, P1262, DOI 10.1016/j.acra.2018.09.025
NR 39
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4497
EP 4515
DI 10.1007/s11042-022-13429-3
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832844000013
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, S
   Kumar, J
   Prasad, KMVV
AF Kumar, Sandeep
   Singh, Sukhwinder
   Kumar, Jagdish
   Prasad, K. M. V. V.
TI Age and gender classification using Seg-Net based architecture and
   machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age classification; SVM; Gabor features; Gender recognition; ADMM
ID COMPONENT ANALYSIS; NEURAL-NETWORKS; RECOGNITION; IMAGES; FEATURES;
   TEXTURE; POSE
AB A facial recognition framework is a natural face-recognizing process from a computerized image or videos. Nowadays, for real-time applications, i.e., human-computer interaction, visual supervision, commercial applications, etc., Human Facial features are utilized for gender classification (GC) and age classification. This paper focuses on gender and age classification methodology from various face images-the proposed work based on Seg-Net-based architecture with machine learning algorithm gives excellent results. The overall accuracy increased through the advanced Seg-Net architecture and Support Vector Machine for age and gender recognition. Our proposed method achieved better results in Age classification on various datasets, i.e., Adience, IOG, and FG-Net datasets, accuracy 74.5%, 75.7%, and 92.48%, and in GC also achieved better results as compared to existing technology on the various datasets, i.e., Adience, IOG, FEI, and own datasets respectively accuracy 88.3%, 95.1%, 94.1%, and 91.8%.
C1 [Kumar, Sandeep; Singh, Sukhwinder] Punjab Engn Coll, ECE Dept, Chandigarh 160012, India.
   [Kumar, Jagdish] Punjab Engn Coll, EE Dept, Chandigarh 160012, India.
   [Prasad, K. M. V. V.] Symbiosis Int Deemed Univ, Symbiosis Inst Technol, E&TC Dept, Pune 412115, Maharashtra, India.
C3 Punjab Engineering College (Deemed University); Punjab Engineering
   College (Deemed University); Symbiosis International University;
   Symbiosis Institute of Technology (SIT)
RP Kumar, S (corresponding author), Punjab Engn Coll, ECE Dept, Chandigarh 160012, India.
EM er.sandeepsahratia@gmail.com; sukhwindersingh@pec.ac.in;
   jagdishkumar@pec.ac.in; mvvprasad.kantipudi@gmail.com
RI Kumar, Sandeep/ADM-4627-2022; Singh, Sukhwinder/JGL-7957-2023;
   KANTIPUDI, MVV PRASAD/P-3791-2019
OI Kumar, Sandeep/0000-0002-4752-7884; KANTIPUDI, MVV
   PRASAD/0000-0002-0605-4654
CR Ali ASO, 2015, IET BIOMETRICS, V4, P98, DOI 10.1049/iet-bmt.2014.0018
   Alnajar F, 2012, IMAGE VISION COMPUT, V30, P946, DOI 10.1016/j.imavis.2012.07.009
   AltunH, 2021 INNOVATIONS INT, P1
   [Anonymous], FG NET AG DAT
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], FACE DATABASES WEBSI
   Bekhouche SE, 2015, 3RD INTERNATIONAL CONFERENCE ON CONTROL, ENGINEERING & INFORMATION TECHNOLOGY (CEIT 2015)
   Benkaddour Mohammed Kamel, 2021, 2020 2nd International Workshop on Human-Centric Smart Environments for Health and Well-being (IHSH), P215, DOI 10.1109/IHSH51661.2021.9378708
   Bouchaffra D, 2015, IEEE T NEUR NET LEAR, V26, P1375, DOI 10.1109/TNNLS.2014.2341634
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cascone L, 2020, PATTERN RECOGN LETT, V140, P238, DOI 10.1016/j.patrec.2020.10.009
   Castrillon-Santana M, 2015, ARXIV
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Cerit B, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P853, DOI 10.1109/SIU.2016.7495874
   Chennu Jaya Venkata Phani Sekhar, 2016, 2016 IEEE 6th International Conference on Power Systems (ICPS), DOI 10.1109/ICPES.2016.7584074
   Cosgun S, 2015, 2015 IEEE
   Cottrell GarrisonW., 1990, ADV NEURAL INFORM PR, P564
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Edelman Betty, 1998, Journal of Biological Systems, V6, P241, DOI 10.1142/S0218339098000170
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fazl-Ersi E, 2014, IEEE IMAGE PROC, P5891, DOI 10.1109/ICIP.2014.7026190
   Fukai Hironobu, 2007, SICE '07. 46th SICE Annual Conference, P2808
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Garain A, 2021, IEEE ACCESS, V9, P85672, DOI 10.1109/ACCESS.2021.3085971
   Gawande MP., 2014, IOSR J ELECT COMM EN, V9, P01, DOI [10.9790/2834-09160105, DOI 10.9790/2834-09160105]
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Günay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Hayashi J, 2002, INT C PATT RECOG, P405, DOI 10.1109/ICPR.2002.1044736
   Hechmi K, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P687, DOI 10.1109/ASRU51503.2021.9688085
   Hosseini S, 2018, PROC INT WORKSH ADV
   Hu M, 2014, INT CONF CLOUD COMPU, P103, DOI 10.1109/CCIS.2014.7175711
   Iga R, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P756
   Jagtap J, 2017, 2017 INT C SIGNAL IN, P1
   Jun-Da Txia, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P885, DOI 10.1109/IIH-MSP.2009.142
   KaleA Altun O, 2021, P 2021 INN INT SYST, P1, DOI [10.1007/s11277-018-5913-0, DOI 10.1007/S11277-018-5913-0]
   Kecman V., 2001, LEARNING SOFT COMPUT
   Khan A, 2005, INT J KNOWL-BASED IN, V9, P1
   Kit FSD, COGNITEC SYSTEMS
   KO JB, 2014, 2014 INT C EL INF CO, P1
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Levi G., 2015, CVPRW, P34
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu X, 2017, DEEP CONVOLUTIONAL N
   Ma D., 2016, INT J COMPUT VISION, V126, P1
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Mery D, 2015, LECT NOTES COMPUT SC, V8926, P778, DOI 10.1007/978-3-319-16181-5_59
   Nayak JS, 2022, J KING SAUD UNIV-COM, V34, P5183, DOI 10.1016/j.jksuci.2021.01.005
   Ozbulak G., 2016, 2016 INT C BIOMETRIC, P1, DOI DOI 10.1109/BIOSIG.2016.7736925
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Peng, ADAPTIVE MEDIAN FILT
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reddy PCS., 2020, MATER TODAY-PROC, V2, P1
   Ricanek Karl  Jr., 2013, Age Factors in Biometric Processing, P93, DOI 10.1049/PBSP010E_ch5
   Sakarkaya M., 2012, Proceedings of the 2012 IEEE 16th International Conference on Intelligent Engineering Systems (INES), P97, DOI 10.1109/INES.2012.6249810
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Srikrishnaswetha Kone, 2019, Innovations in Electronics and Communication Engineering. Proceedings of the 7th ICIECE 2018. Lecture Notes in Networks and Systems (LNNS 65), P87, DOI 10.1007/978-981-13-3765-9_10
   Srikrishnaswetha Kone, 2020, Innovations in Electronics and Communication Engineering. Proceedings of the 8th ICIECE 2019. Lecture Notes in Networks and Systems (LNNS 107), P311, DOI 10.1007/978-981-15-3172-9_31
   Srikrishnaswetha K., 2018, IN 2018 4 INT C COMP, P1
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Takimoto Hironori, 2006, 2006 SICE-ICASE International Joint Conference, P3883, DOI 10.1109/SICE.2006.314846
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Thepade SD, 2021, 2021 INT C COMMUNICA, P1
   Tian Y., 2017, PR MACH LEARN RES
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Wang CX, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 1, PROCEEDINGS, P312, DOI 10.1109/ISCSCT.2008.204
   Wu SF, 2019, J VIS COMMUN IMAGE R, V60, P116, DOI 10.1016/j.jvcir.2019.01.013
   Xiao B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P451
   Xu C, 2021, IEEE WINT CONF APPL, P3459, DOI 10.1109/WACV48630.2021.00350
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Zabala-Blanco D., 2021, P IEEE 2021 40 INT C, P1
   Zhang D, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P62
   Zhou SK, 2010, US, Patent No. 7804999
NR 85
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42285
EP 42308
DI 10.1007/s11042-021-11499-3
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000830266500005
DA 2024-07-18
ER

PT J
AU Zheng, JM
   Zeng, QX
AF Zheng, Jiming
   Zeng, Qingxia
TI The unified image encryption algorithm based on composite chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos map; Unity encryption; SHA256; Permutation operation; Diffusion
   operation
AB This paper proposes a fast and unified encryption and decryption algorithm based on a composite chaotic system. By combining Logistic map and Sine map, the New-Logistic-Sine map (NLS map) is obtained. NLS map generated the diffusion key matrix needed in the algorithm process, which can enhance the anti-attack ability of the encryption algorithm. Different from most image cryptography systems, the algorithm adopted in this paper has the same encryption process and decryption process, which can save half of the resources in real applications. Firstly, the Secure Hash Algorithm 256 (SHA256) value of the original image was obtained, and the initial values and control parameters of NLS map and Logistic map were calculated; Secondly, the diffusion key matrix is obtained by iterative the NLS map, and is used to perform the first diffusion of the original image; Thirdly, the permutation key sequence is obtained by iterative the Logistic map, and using the sequence to perform the permutation operation on the image after the first diffusion; Finally, the same diffusion key matrix as the first diffusion operation is used to carry out the second diffusion operation on the displaced image to obtain the final encrypted image. The simulation experiment and security analysis show that the proposed image cryptosystem possessed identical encryption process and decryption process, and the algorithm speed is improved ensure the security of the algorithm.
C1 [Zheng, Jiming; Zeng, Qingxia] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Zheng, Jiming] Chongqing Univ Posts & Telecommun, Key Lab Intelligent Anal & Decis Complex Syst, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Zheng, JM (corresponding author), Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.; Zheng, JM (corresponding author), Chongqing Univ Posts & Telecommun, Key Lab Intelligent Anal & Decis Complex Syst, Chongqing 400065, Peoples R China.
EM Zhengjm@cqupt.edu.cn
OI Zheng, Jiming/0000-0002-6237-0168
FU National Natural Science Foundation of China [61901074]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61901074).
CR Alawida M, 2019, SIGNAL PROCESS, V164, P249, DOI 10.1016/j.sigpro.2019.06.013
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Dagadu JC, 2019, MULTIMED TOOLS APPL, V78, P24979, DOI 10.1007/s11042-019-7693-2
   Dai Y, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P210, DOI 10.1109/ICInfA.2012.6246810
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   Kohli R, 2013, INT J ADV RES COMPUT, V3
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Taneja N, 2013, MULTIMED TOOLS APPL, V67, P593, DOI 10.1007/s11042-012-1037-9
   Taneja N, 2012, MULTIMED TOOLS APPL, V61, P281, DOI 10.1007/s11042-011-0837-7
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zheng JM, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/5982743
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou SG, 2016, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA AND SMART CITY (ICITBS), P462, DOI 10.1109/ICITBS.2015.119
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 32
TC 6
Z9 6
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22231
EP 22250
DI 10.1007/s11042-022-13461-3
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000828935900002
DA 2024-07-18
ER

PT J
AU Jagtap, N
   Thepade, SD
AF Jagtap, Nalini
   Thepade, Sudeep D.
TI Reliable and robust low rank representation based noisy images
   multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; High-level coefficients; Low-level
   coefficients; Hybrid thresholding; Image denoising; Low-rank
   representation; Multifocal fusion
ID TRANSFORM; NETWORKS
AB The noisy images fusion is still a challenging multi-focus image fusion (MIF) problem as the noise is inevitable for an input image. But most of the recent works do not bother about noisy images fusion and become challenging for color images. The fusion of noisy images pairs using existing MIF techniques compromises the robustness and reliability. We propose a novel framework to achieve the robust and reliable noisy images MIF called noisy image MIF (NIMIF). The NIMIF consists of the hybrid denoising technique, low-rank representation (LRR), and discrete wavelet transform (DWT). We propose two different NIMIF systems for greyscale MIF and color MIF. In color NIMIF, the input RGB color images have first converted into YCbCr color space due to their robustness. Then the Y color space image or greyscale image (in greyscale NIMIF) is decomposed using the DWT into high and low-level coefficients of each input image. We fuse the low-frequency coefficients using the spatial frequency (SF) technique. Before fusing the high-frequency coefficients, we apply the hybrid thresholding to suppress the noisy data from the input source images. The outcome of hybrid thresholding denoising fed to LRR to produce the fusion of high-frequency coefficients. Finally, NIMIF applies the inverse DWT to produce the MIF outcome. We present the comparative analysis of greyscale and color NIMIF using objective and visual results compare to state-of-art techniques. The simulation results prove that the integrated hybrid thresholding and LRR fusion technique form the reliable MIF solution for noisy greyscale and color image pairs.
C1 [Jagtap, Nalini; Thepade, Sudeep D.] Pimpri Chinchwad Coll Engn, Pune, Maharashtra, India.
RP Thepade, SD (corresponding author), Pimpri Chinchwad Coll Engn, Pune, Maharashtra, India.
EM sudeepthepade@gmail.com
RI THEPADE, SUDEEP/P-9054-2015
OI THEPADE, SUDEEP/0000-0001-7809-4148
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Adu JH, 2016, J VIS COMMUN IMAGE R, V40, P218, DOI 10.1016/j.jvcir.2016.06.026
   Alhayani B, 2021, WIRELESS PERS COMMUN, V120, P665, DOI 10.1007/s11277-021-08484-2
   Amin-Naji M, 2020, J AMB INTEL HUM COMP, V11, P1749, DOI 10.1007/s12652-019-01199-0
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Aravind BN, 2015, 2015 INTERNATIONAL CONFERENCE ON TRENDS IN AUTOMATION, COMMUNICATIONS AND COMPUTING TECHNOLOGY (I-TACT-15)
   Bai XZ, 2016, IEEE ACCESS, V4, P4749, DOI 10.1109/ACCESS.2016.2604480
   Bavirisetti DP, 2018, AIN SHAMS ENG J, V9, P1103, DOI 10.1016/j.asej.2016.06.011
   Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Deshmukh V, 2018, SMART INNOV SYST TEC, V83, P233, DOI 10.1007/978-3-319-63673-3_28
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Du CB, 2018, OPTOELECTRON LETT, V14, P71, DOI 10.1007/s11801-018-7207-x
   Du CB, 2018, OPTIK, V157, P1003, DOI 10.1016/j.ijleo.2017.11.162
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Gayathri N, 2016, INT CONF COMMUN SYST, P173, DOI 10.1109/CSN.2016.7824009
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   GUPTA V, 2013, 2013 10 INT C WIRELE
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jiang Q, 2018, IEEE SENS J, V18, P2494, DOI 10.1109/JSEN.2018.2791642
   Jin X, 2016, J SENSORS, V2016, DOI 10.1155/2016/8359602
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kekre HB, 2010, P INT C WORKSHOP EME, DOI [10.1145/1741906.1742014, DOI 10.1145/1741906.1742014]
   Li CS, 2018, APPL OPTICS, V57, P4514, DOI 10.1364/AO.57.004514
   Li H, 2018, MULTIFOCUS NOISY IMA
   Li HF, 2016, INFORM SCIENCES, V349, P25, DOI 10.1016/j.ins.2016.02.030
   Li H, 2017, LECT NOTES COMPUT SC, V10666, P675, DOI 10.1007/978-3-319-71607-7_59
   Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048
   Liu SQ, 2019, IEEE ACCESS, V7, P152043, DOI 10.1109/ACCESS.2019.2947378
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Mahajan HB., 2018, INT J ADV SCI TECHNO, V2018, P37
   Mahajan HB., 2019, J ADV RES DYNAMICAL, V11, P1276, DOI [10.5373/JARDCS/V11I9/20193162, DOI 10.5373/JARDCS/V11I9/20193162]
   Mahajan HB, 2021, WIRELESS PERS COMMUN, V121, P3125, DOI 10.1007/s11277-021-08866-6
   Mahajan HB, 2021, J AMB INTEL HUM COMP, V12, P7777, DOI 10.1007/s12652-020-02502-0
   Naik AJ, 2021, MULTIMED TOOLS APPL, V80, P18365, DOI 10.1007/s11042-021-10682-w
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pan T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143901
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Rahman MA, 2017, DIGIT SIGNAL PROCESS, V60, P1, DOI 10.1016/j.dsp.2016.08.004
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P9387, DOI 10.1007/s11042-019-7725-y
   Wald L, 1999, IEEE T GEOSCI REMOTE, V37, P1190, DOI 10.1109/36.763269
   Wang JJ, 2015, OPTIK, V126, P2508, DOI 10.1016/j.ijleo.2015.06.019
   Wirat R, 2010, LECT NOTES ENG COMPU, V2181
   Xu ZY, 2021, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.615435
   Yahya AA, 2019, MULTIMED TOOLS APPL, V78, P15545, DOI 10.1007/s11042-018-6955-8
   Yang DS, 2018, J SYST ENG ELECTRON, V29, P415, DOI 10.21629/JSEE.2018.02.21
   Yang Y, 2017, IEEE ACCESS, V5, P14898, DOI 10.1109/ACCESS.2017.2698217
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Zafar R, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070060
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang S, 2020, IEEE ACCESS, V8, P35638, DOI 10.1109/ACCESS.2020.2973269
   Zhang XL, 2014, SIGNAL PROCESS, V102, P64, DOI 10.1016/j.sigpro.2014.02.024
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 65
TC 1
Z9 1
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8235
EP 8259
DI 10.1007/s11042-021-11576-7
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900008
DA 2024-07-18
ER

PT J
AU Jha, GK
   Gaur, M
   Ranjan, P
   Thakur, HK
AF Jha, Govind Kumar
   Gaur, Manish
   Ranjan, Preetish
   Thakur, Hardeo Kumar
TI A trustworthy model of recommender system using hyper-tuned restricted
   boltzmann machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Recommendation system; Reconstruction; Trust;
   Collaborative filtering; Hyper-tuned RBM; SAE
AB The rapid and ubiquitous digital revolution has led to acceleration towards a digitally connected world where accepting recommendations digitally has become a part of our e-commerce related lifestyle. Most of these recommendations are based on rating values, wherein some values are fraudulent. This is a vulnerability in the security of the system and thus hampers its credibility and trust. It is necessary to identify the fraudulent ratings in real-time and build a trustworthy black-box recommender system. This paper proposes hyper-tuned Restricted Boltzmann Machines to regenerate tabular data models using contrastive divergence learning procedures to enhance accuracy, transparency, and recommendations' ability. Most of the existing recommender systems cannot handle the large dataset and deteriorate their performance. Experiments over the Movies Lens,Film Trust and Netflix rating dataset demonstrate that the tuned RBMs performed well compared with SVD, SVD ++, trust SVD, and Stack Auto Encoder(SAE) models with a moderate increase in computational complexity. We build a trustworthy recommender system based on hyper-tuned RBM, a deep learning-based system widely used by E-commerce companies to recommend products. Netflix recommends television shows and movies depending upon the number of customers who have seen a similar genre. Similarly, Amazon recommends an item to a customer based on whether other consumers would be interested in purchasing the product. Through rigorous evaluations, we have shown that our proposed scheme outperforms the existing recommender systems.
C1 [Jha, Govind Kumar] Bhagalpur Coll Engn, Bhagalpur, Bihar, India.
   [Gaur, Manish] Dr APJ Abdul Kalam Tech Univ Lucknow, Inst Engn & Technol, Lucknow, Uttar Pradesh, India.
   [Ranjan, Preetish] Amity Univ, Patna, Bihar, India.
   [Thakur, Hardeo Kumar] Manav Rachna Univ, Faridabad, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Jha, GK (corresponding author), Bhagalpur Coll Engn, Bhagalpur, Bihar, India.
EM gvnd.jha@gmail.com; manish.gaur@ietlucknow.ac.in; pranjan@ptn.amity.edu;
   hkthakur@mru.edu.in
RI THAKUR, HARDEO KUMAR/Q-3224-2019
OI THAKUR, HARDEO KUMAR/0000-0002-2954-1308; Gaur,
   Manish/0000-0002-4161-2789; JHA, GOVIND KUMAR/0000-0003-2258-1865
CR AALEN OO, 1978, SCAND J STAT, V5, P141
   Abdollahi B, 2016, ARXIV PREPRINT ARXIV
   Amatriain Xavier, 2015, Handbook, P385, DOI [10.1007/978-1-4899-7637-611, DOI 10.1007/978-1-4899-7637-6_11]
   Ferreira D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165510
   Fu MS, 2019, IEEE T CYBERNETICS, V49, P1084, DOI 10.1109/TCYB.2018.2795041
   Ghasemzadeh P, 2020, IEEE INT CONF COMM, P1, DOI [10.1109/ICCWorkshops49005.2020.9145320, DOI 10.1109/ICCWORKSHOPS49005.2020.9145320]
   Guo GB, 2015, AAAI CONF ARTIF INTE, P123
   He F, 2018, 2018 3 INT C AUTOMAT, P238, DOI DOI 10.2991/AMCCE-18.2018.42
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Huang ZH, 2019, IEEE ACCESS, V7, P137900, DOI 10.1109/ACCESS.2019.2929789
   Igel C, 2012, Lecture Notes in Computer Science, P14, DOI DOI 10.1007/978-3-642
   Neto C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21121163
   Neve J, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P219, DOI 10.1145/3298689.3347026
   Ranjan P, 2014, 2014 INTERNATIONAL CONFERENCE ON ENGINEERING AND TELECOMMUNICATION (EN&T 2014), P97, DOI 10.1109/EnT.2014.11
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Sun M., 2018, Big Data and Cognitive Computing, V2, P7
   Wang JY, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P53, DOI 10.1145/3192975.3193018
   Wu H, 2018, KNOWL-BASED SYST, V145, P46, DOI 10.1016/j.knosys.2018.01.003
   Yang F, 2018, IEEE INT CONF BIG DA, P4109, DOI 10.1109/BigData.2018.8622127
   Zhang LC, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1236, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.224
   Zheng Y, 2016, PR MACH LEARN RES, V48
NR 21
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8261
EP 8285
DI 10.1007/s11042-021-11575-8
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900009
DA 2024-07-18
ER

PT J
AU Kuang, L
   Wang, YT
   Hang, T
   Chen, BJ
   Zhao, GY
AF Kuang, Liang
   Wang, Yiting
   Hang, Tian
   Chen, Beijing
   Zhao, Guoying
TI A dual-branch neural network for DeepFake video detection by detecting
   spatial and temporal inconsistencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DeepFake video detection; Optical flow; Convolution neural network; Long
   short-term memory network
AB It has become a research hotspot to detect whether a video is natural or DeepFake. However, almost all the existing works focus on detecting the inconsistency in either spatial or temporal. In this paper, a dual-branch (spatial branch and temporal branch) neural network is proposed to detect the inconsistency in both spatial and temporal for DeepFake video detection. The spatial branch aims at detecting spatial inconsistency by the effective EfficientNet model. The temporal branch focuses on temporal inconsistency detection by a new network model. The new temporal model considers optical flow as input, uses the EfficientNet to extract optical flow features, utilize the Bidirectional Long-Short Term Memory (Bi-LSTM) network to capture the temporal inconsistency of optical flow. Moreover, the optical flow frames are stacked before inputting into the EfficientNet. Finally, the softmax scores of two branches are combined with a binary-class linear SVM classifier. Experimental results on the compressed FaceForensics++ dataset and Celeb-DF dataset show that: (a) the proposed dual-branch network model performs better than some recent spatial and temporal models for the Celeb-DF dataset and all the four manipulation methods in FaceForensics++ dataset since these two branches can complement each other; (b) the use of optical flow inputs, Bi-LSTM and dual-branches can greatly improve the detection performance by the ablation experiments.
C1 [Kuang, Liang; Hang, Tian; Chen, Beijing] Nanjing Univ Informat Sci & Technol, Sch Comp, Nanjing 210044, Peoples R China.
   [Kuang, Liang] Jiangsu Vocat Coll Informat Technol, Sch IoT Engn, Wuxi 214153, Jiangsu, Peoples R China.
   [Wang, Yiting] Univ Warwick, Warwick Mfg Grp, Coventry CV4 7AL, W Midlands, England.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Zhao, Guoying] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland.
C3 Nanjing University of Information Science & Technology; Jiangsu
   Vocational College of Information Technology; University of Warwick;
   Nanjing University of Information Science & Technology; University of
   Oulu
RP Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp, Nanjing 210044, Peoples R China.; Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
EM nbutimage@126.com
RI WANG, YITING/IVV-3708-2023; wang, qi/ITT-9652-2023
OI WANG, YITING/0000-0003-2008-4435; 
FU National Natural Science Foundation of China [62072251]; Natural Science
   Research Project of Jiangsu Universities [20KJB520021]; Higher
   Vocational Education Teaching Fusion Production Integration Platform
   Construction Projects of Jiangsu Province [2019(26)]; PAPD fund
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62072251, Natural Science Research Project of Jiangsu
   Universities under Grant 20KJB520021, Higher Vocational Education
   Teaching Fusion Production Integration Platform Construction Projects of
   Jiangsu Province under Grant No. 2019(26), the PAPD fund.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P IEEE C COMP VIS PA, P38, DOI DOI 10.1109/ICCV.2015.425
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Chen B, 2020, IEEE T MULTIMEDIA
   Chen BJ, 2021, INFORM SCIENCES, V572, P16, DOI 10.1016/j.ins.2021.05.006
   Chen PK, 2022, PROD PLAN CONTROL, V33, P450, DOI 10.1080/09537287.2020.1829146
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   DeepFake Detection Challenge (DFDC), US
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Ganiyusufoglu I., 2020, ARXIV201011844
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li Y., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Lima OD., 2020, DEEPFAKE DETECTION U
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen T. T., 2019, CoRR
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Xiaodan Li, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P1864, DOI 10.1145/3394171.3414034
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zaremba W., 2014, CORR
   Zhang DY, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8830310
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 40
TC 4
Z9 4
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42591
EP 42606
DI 10.1007/s11042-021-11539-y
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Diwan, T
   Shukla, R
   Ghuse, E
   Tembhurne, JV
AF Diwan, Tausif
   Shukla, Rohan
   Ghuse, Ekta
   Tembhurne, Jitendra V.
TI Model hybridization & learning rate annealing for skin cancer detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Deep learning; Convolutional neural networks; Learning rate
   annealing; Hybrid architecture
ID CLASSIFICATION; DIAGNOSIS; IMAGES; SYSTEM
AB The increasing frequency of skin tumour across the globe and their timely diagnosis is one of the most promising research directions in the healthcare domain. The most important cause behind the skin cancer mortalities is delayed detection. Early detection followed by adequate treatment may enhance the chances of human survival to a great extent. However, extracting the features from the tumour images for the possible detection of skin cancer is not a trivial task. Numerous deep learning models are extensively employed for the efficient features' extraction for skin cancer detection but literature demonstrate further scope of improvements in various performance measures. In this paper, we propose a hybrid deep Convolutional Neural Network architecture inspired from pretrained architectures for the skin cancer detection by incorporating three major heuristics viz. usage of multiple smaller sized convolutional filters instead of using a single larger filter homogeneously and consistently across the entire model, utilization of skip or residual connections to mitigate the vanishing gradient problem in the deeper model, and learning rate annealing by introducing cyclic learning rate. Experimental results performed on HAM10000 dataset observed an improvement in various performance measures and faster model convergence to a significant extent in comparison with the state-of-the-arts.
C1 [Diwan, Tausif; Shukla, Rohan; Ghuse, Ekta; Tembhurne, Jitendra V.] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
RP Diwan, T (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM tausif.diwan@cse.iiitn.ac.in; ssrohan99@gmail.com;
   ekta1999ghuse@gmail.com; jitendra.tembhurne@cse.iiitn.ac.in
RI Tembhurne, Jitendra/AGI-1097-2022; Diwan, Tausif/AFN-9746-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456; 
CR Abbas Q, 2013, PATTERN RECOGN, V46, P86, DOI 10.1016/j.patcog.2012.07.027
   Allwein E. L., 2001, Journal of Machine Learning Research, V1, P113, DOI 10.1162/15324430152733133
   Almansour E, 2016, INT J COMPUT SCI NET, V16, P135
   Anas M., 2017, International Journal of Technical Research and Applications, V5, P62
   [Anonymous], 2017, An Intuitive Explanation of Convolutional Neural Networks
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Blum A, 2004, BRIT J DERMATOL, V151, P1029, DOI 10.1111/j.1365-2133.2004.06210.x
   Capdehourat G, 2011, PATTERN RECOGN LETT, V32, P2187, DOI 10.1016/j.patrec.2011.06.015
   Chaturvedi S.S., 2020, Advanced machine learning technologies and applications: proceedings of AMLTA 2020, P165, DOI [DOI 10.1007/978-981-15-3383-9_15, 10.1007/978-981-15-3383-9_15, DOI 10.1007/978-981-15-3383-915]
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fujisawa Y, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00191
   github, Convolutional Neural Networks for Visual Recognition
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Hasan M, 2019, ICCAI '19 - PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE, P254, DOI 10.1145/3330482.3330525
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Iwendi C, 2020, COMPUT COMMUN, V161, P160, DOI 10.1016/j.comcom.2020.07.032
   Iwendi C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092559
   Iwendi C, 2020, IEEE ACCESS, V8, P28462, DOI 10.1109/ACCESS.2020.2968537
   jeremyjordan, SETTING LEARNING RAT
   Kerr OA, 2010, CLIN EXP DERMATOL, V35, P380, DOI 10.1111/j.1365-2230.2009.03586.x
   Li N, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/7942501
   Ramlakhan K, 2011, PROC INT C TOOLS ART, P138, DOI 10.1109/ICTAI.2011.29
   Ratul M.A.R., 2020, bioRxiv, DOI DOI 10.1101/860700
   Rezvantalab A., 2018, Dermatologist Level Dermoscopy Skin Cancer Classification Using Different Deep Learning Convolutional Neural Networks Algorithms. arXiv Prepr arXiv
   Ruiz D, 2011, EXPERT SYST APPL, V38, P15217, DOI 10.1016/j.eswa.2011.05.079
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI 10.3322/caac.21590
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Vijayalakshmi M., 2019, Int J Trend Sci Res Dev, V3, P780
   Wang J.L., 2018, 2018 INT C COMPUTATI, P703, DOI 10.1109/CSCI46756.2018.00141
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 34
TC 8
Z9 8
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2369
EP 2392
DI 10.1007/s11042-022-12633-5
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814451000002
DA 2024-07-18
ER

PT J
AU Gulhane, VA
   Rode, SV
   Pande, CB
AF Gulhane, Viraj A.
   Rode, Sandeep, V
   Pande, Chaitanya B.
TI Correlation Analysis of Soil Nutrients and Prediction Model Through ISO
   Cluster Unsupervised Classification with Multispectral Data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soil nutrients; Remote sensing; Image index; ISO cluster; Classification
ID ORGANIC-CARBON; LAND; ASSIMILATION; SIMULATION; VEGETATION; RETRIEVAL;
   DUMP
AB The agricultural sector is the backbone of the Indian economy, where precision agriculture is playing a vital role in boosting productivity. The soil chemical parameters play an important role in precision agriculture. Analysis and prediction of micronutrient of the soil chemical parameters are highly insisted upon by farmers and agriculture researchers. The soil nutrients parameters can be analyzed from multispectral data through ISO cluster unsupervised classification. Understanding the nutrient level of soil is highly recommended for farming; early understanding may help to improve soil fertility and fully meet productivity requirements. This paper addresses the soil nutrients analysis by the regression method and its spectral indexed based on the prediction model by Iterative Self-Organizing (ISO) cluster unsupervised classification algorithm. Therefore, for this study, the Baggi, Ibrahimpur, Wai, Mogra, and Bori (for validation) villages were selected. These villages are located in the Amravati district and fall under Maharashtra provenance of India. From the study area, three soil nutrients parameters such as P, Fe, pH indices-based data were acquired from the spectral calculation of Sentinel-2 and Landsat-8 bands. The P, Fe and pH indices were calculated from the yellowness index (YI), ferrous oxide index, and carbonate level. The ISO cluster unsupervised mechanism has been used for prediction of soil chemical parameter indices out of 100 samples. The study regions recognition rate is 97% for P, 94.05% for Fe, and 69% for pH. During the validation process, four villages' results were used for the identification of soil nutrient parameters for Bori village. The results of the study area can be helpful for the development of the planning of soil fertility in the agriculture fields and effectively increase the crop yield production in the semi-arid region.
C1 [Gulhane, Viraj A.; Rode, Sandeep, V] Sipna Coll Engn & Technol, Dept Elect & Telecommun, Amravati, Maharashtra, India.
   [Pande, Chaitanya B.] MPKV, Ctr Climate Smart Agr & Water Management, Rahuri, Maharashtra, India.
RP Gulhane, VA (corresponding author), Sipna Coll Engn & Technol, Dept Elect & Telecommun, Amravati, Maharashtra, India.
EM virajgulhane22@gmail.com
RI Pande, Chaitanya Baliram/ISU-8862-2023; Rode, Sandeep V/AAA-8069-2021;
   Pande, Chaitanya Baliram/AAE-3162-2020
OI Pande, Chaitanya Baliram/0000-0003-1738-3565; Pande, Chaitanya
   Baliram/0000-0003-1738-3565
CR Bach H, 2003, IEEE T GEOSCI REMOTE, V41, P1629, DOI 10.1109/TGRS.2003.813270
   Barnes EM, 2003, PHOTOGRAMM ENG REM S, V69, P619, DOI 10.14358/PERS.69.6.619
   BENDOR E, 1995, SOIL SCI SOC AM J, V59, P364, DOI 10.2136/sssaj1995.03615995005900020014x
   Dong H, 2011, INT GEOSCI REMOTE SE, P3330, DOI 10.1109/IGARSS.2011.6049997
   Forkuor G, 2018, GISCI REMOTE SENS, V55, P331, DOI 10.1080/15481603.2017.1370169
   Hank TB, 2015, REMOTE SENS-BASEL, V7, P3934, DOI 10.3390/rs70403934
   Hongyan Chen, 2011, Proceedings of the 2011 International Conference on Remote Sensing, Environment and Transportation Engineering (RSETE 2011), P3072, DOI 10.1109/RSETE.2011.5964963
   Huang YH, 2018, RSC ADV, V8, P41499, DOI 10.1039/c8ra08002j
   Ines AVM, 2013, REMOTE SENS ENVIRON, V138, P149, DOI 10.1016/j.rse.2013.07.018
   Isenstein EM, 2014, J ENVIRON SCI-CHINA, V26, P1831, DOI 10.1016/j.jes.2014.06.019
   Kneubühler M, 2014, IEEE J-STARS, V7, P2600, DOI 10.1109/JSTARS.2014.2323574
   Kumar N, 2018, J INDIAN SOC REMOTE, V46, P705, DOI 10.1007/s12524-017-0738-y
   Liao Q., 2012, IEEE 2012 1 INT C AG, P1
   Lihua X., 2012, 2 INT C REMOTE SENSI
   Lu P, 2012, GLOB CONGRESS INTELL, P291, DOI 10.1109/GCIS.2012.13
   Moran MS, 1997, REMOTE SENS ENVIRON, V61, P319, DOI 10.1016/S0034-4257(97)00045-X
   Mulla DJ, 2013, BIOSYST ENG, V114, P358, DOI 10.1016/j.biosystemseng.2012.08.009
   Pande CB, 2018, APPL WATER SCI, V8, DOI 10.1007/s13201-018-0764-0
   Qiu L, 2013, INT CONF AGRO-GEOINF, P13, DOI 10.1109/Argo-Geoinformatics.2013.6621870
   Reddy DM, 2017, CONT RES INDIA, V7
   Tomar V, 2014, IEEE SENS J, V14, P3599, DOI 10.1109/JSEN.2014.2329185
   Ustin SL, 2006, INT GEOSCI REMOTE SE, P1996, DOI 10.1109/IGARSS.2006.517
   Wang XL, 2010, SCI TOTAL ENVIRON, V408, P3310, DOI 10.1016/j.scitotenv.2010.03.026
   Zhang XR, 2016, FRESEN ENVIRON BULL, V25, P4767
   Zheng HB, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL IV, PROCEEDINGS, P550, DOI 10.1109/AICI.2009.137
NR 25
TC 26
Z9 26
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2165
EP 2184
DI 10.1007/s11042-022-13276-2
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000813585100001
DA 2024-07-18
ER

PT J
AU Verma, VS
   Gupta, S
   Gupta, P
AF Verma, Vivek Singh
   Gupta, Sandesh
   Gupta, Phalguni
TI Image data protection in IoT applications using significant block
   selection based image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lifting wavelet transform; Block selection; Significant set of blocks;
   Image protection
ID SIGNIFICANT DIFFERENCE; LIFTING SCHEME; ROBUST; EXTRACTION;
   INTERPOLATION; CONSTRUCTION
AB Recent developments in IoT (Internet of Things) and its importance are significantly accepted in different applications of medical research, automobile sector, robotics, national security, and real-life usage. Securing the interface between IoT and the real-world is one of the challenging tasks for every researcher. This paper presents a watermarking scheme to protect the image database used in the presentation layer of IoT applications. The host image is decomposed using the Lifting wavelet transform (LWT) and fixed-size blocks of low-frequency components are obtained. Procedurally selected blocks of frequency components called a significant set of blocks (SSB) are used to quantize the watermark bits into it. Considering each block similar to the node of wireless networks an algorithm for block selection is proposed. Watermark extraction from an attacked watermarked image is performed using an adaptive thresholding approach. Key-based randomization at various levels provides the security feature to the proposed scheme. The LWT is used to make the algorithm more robust and computationally fast. However, randomly selected root based SSB generation leads the scheme more secure from an external intruder. The scheme performs significantly well under various signal processing operations; and outperforms in comparison with other existing schemes.
C1 [Verma, Vivek Singh] Govt Polytech Shahbad, Rampur 244901, India.
   [Gupta, Sandesh] CSJM Univ, Univ Inst Engn & Technol, Kanpur 208024, Uttar Pradesh, India.
   [Gupta, Phalguni] GLA Univ, Mathura 281406, India.
C3 GLA University
RP Gupta, S (corresponding author), CSJM Univ, Univ Inst Engn & Technol, Kanpur 208024, Uttar Pradesh, India.
EM viveksv10@gmail.com; sandesh@csjmu.ac.in; pg@gla.ac.in
RI Verma, Vivek Singh/HLH-7169-2023
OI Verma, Vivek Singh/0000-0002-1497-2754
CR Al-Shayea TK, 2019, IEEE ICC
   Ali S, 2018, IEEE GLOBE WORK
   Chen DY, 2000, IEEE T CONSUM ELECTR, V46, P404, DOI 10.1109/30.883385
   CLARK BN, 1990, DISCRETE MATH, V86, P165, DOI 10.1016/0012-365X(90)90358-O
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fu YG, 2013, OPTIK, V124, P517, DOI 10.1016/j.ijleo.2011.12.042
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Hurrah NN, 2019, AD HOC NETW, V95, DOI 10.1016/j.adhoc.2019.101989
   Kim DY, 2009, IEEE T PARALL DISTR, V20, P147, DOI 10.1109/TPDS.2008.74
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liang W, 2020, IEEE T IND INFORM, V16, P6543, DOI 10.1109/TII.2020.2966069
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Medileh S, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102240
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Petitcolas FAP, 1997, WEAKNESS EXISTING WA
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Sheikh JA, 2018, INT J SPEECH TECHNOL, V21, P715, DOI 10.1007/s10772-018-9541-6
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Verma VS, 2019, MULTIMED TOOLS APPL, V78, P23203, DOI 10.1007/s11042-019-7599-z
   Verma VS, 2017, J FRANKLIN I, V354, P6422, DOI 10.1016/j.jfranklin.2017.07.032
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Verma VS, 2015, SIGNAL IMAGE VIDEO P, V9, P1443, DOI 10.1007/s11760-013-0603-6
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wazirali R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141744
NR 34
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5073
EP 5090
DI 10.1007/s11042-022-12309-0
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000812603300006
DA 2024-07-18
ER

PT J
AU Luo, HB
   U, K
   Zhao, WK
AF Luo, Huibin
   U, KinTak
   Zhao, Weikang
TI Multi-focus image fusion through pixel-wise voting and morphology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image; Image fusion; Sliding window; Pixel-wise voting;
   Morphology
ID EXTRACTION; TRANSFORM; FRAMEWORK; ALGORITHM
AB Multi-focus image fusion (MFIf) aims to fuse two or more images into one image, so that the fused image contains more information. This paper proposes a new multi-focus image fusion based on pixel-wise voting and morphology. Firstly, we perform sliding window on the multi-focus image and calculate the gray-scale variance of each sliding window. Then, the voting matrix of each pixel is obtained by comparing the sliding window gray-scale variance. Next, a multi-focus decision map (IFM) is obtained through voting. At the same time, morphological operations can further denoise the IFM and achieve a better image fusion effect. Finally, we also use the weighting method for boundary optimization to get the better fused image. We conducted experiments on "books", "flower", "newspaper", "lytro" and "aymaz" datasets. Comparing with other 10 fusion algorithms, the experimental results demonstrate that our proposed multi-focus image fusion method can achieve a good fusion effect.
C1 [Luo, Huibin; U, KinTak; Zhao, Weikang] Macau Univ Sci & Technol, Fac Informat Technol, Taipa 999078, Macao, Peoples R China.
   [Luo, Huibin] Beijing Inst Technol, Zhuhai, Peoples R China.
C3 Macau University of Science & Technology; Beijing Institute of
   Technology
RP Luo, HB (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Taipa 999078, Macao, Peoples R China.; Luo, HB (corresponding author), Beijing Inst Technol, Zhuhai, Peoples R China.
EM zhbitluo@163.com; ktu@must.edu.mo
FU Macau University of Science and Technology Foundation [FRG21-020-FI]
FX Thanks to the editor and anonymous review, and to the person who
   provided the image datasets. This work was supported by Macau University
   of Science and Technology Foundation (No. FRG21-020-FI).
CR Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   [Anonymous], 2004, Mathematical techniques in multisensor data fusion
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bai XZ, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P534
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Chai Y, 2012, OPTIK, V123, P569, DOI 10.1016/j.ijleo.2011.02.034
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Hu JW, 2012, INFORM FUSION, V13, P196, DOI 10.1016/j.inffus.2011.01.002
   Li HF, 2013, MACH VISION APPL, V24, P1167, DOI 10.1007/s00138-013-0502-4
   Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   [刘羽 Liu Yu], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1435
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002
   Saeed K, 2020, IEEE ACCESS, V8, P123556, DOI 10.1109/ACCESS.2020.3006100
   Sahoo DK, 2016, 2016 INT C SIGN PROC
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Van Genderen J, 1994, IMAGE FUSION ISSUES
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang J, 2011, 2011 4 INT C INT COM, V2
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang X, 2021, AUTOPHAGY, V17, P1519, DOI 10.1080/15548627.2020.1840796
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
NR 38
TC 2
Z9 2
U1 3
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 899
EP 925
DI 10.1007/s11042-022-13218-y
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700002
DA 2024-07-18
ER

PT J
AU Wang, MJ
   Chen, YC
   Qi, BZ
AF Wang, Mingjia
   Chen, YuCui
   Qi, Baozhu
TI Residual UNet with spatial and channel attention for automatic magnetic
   resonance image segmentation of rectal cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rectal tumor segmentation; Residual convolution; Attention mechanism;
   UNet
ID NETWORKS
AB The precise segmentation of rectal tumors is a key step in the diagnosis and treatment of rectal cancer. This paper aims to study the automatic segmentation task of rectal tumors based on deep learning methods, and proposes a residual UNet network model that combines spatial attention and channel attention. The model uses residual convolution for feature extraction, and uses squeeze-and-excitation module and attention gating module to focus on more useful features. In this study, we established a rectal tumor dataset for model evaluation, and used a combination of two-class cross-entropy and DICE loss function in the training process. Comparative experiments show that the DICE similarity coefficient is 0.8476, the Hausdorff distance reaches 9.5622, the prediction accuracy of the model is 0.9938, and the evaluation indicators are better than the segmentation results of UNet and AttUNet, which can effectively segment the rectal tumor area, and the combined loss function can also improve the segmentation accuracy by about 15% to a certain extent.
C1 [Wang, Mingjia; Chen, YuCui; Qi, Baozhu] Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
C3 Qingdao University of Science & Technology
RP Wang, MJ (corresponding author), Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
EM mingjiawang@126.com
RI 齐, 宝柱/GWC-0072-2022
OI 齐, 宝柱/0009-0003-3227-7039
FU National Natural Science Foundation of China [61971253]; Shandong
   Provincial Natural Science Foundation, China [ZR2014FL026]
FX This work was supported by National Natural Science Foundation of China
   (Grant No.61971253); Shandong Provincial Natural Science Foundation,
   China (Grant No.ZR2014FL026).
CR [Anonymous], 2020, Journal of Computer Applications, V40, P2392
   Chen K, 2021, ARXIV210704191
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Ciresan D., 2012, NIPS, P2843
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36
   Ghosal P., 2019, P 2019 2 INT C ADV C, P1, DOI [DOI 10.1109/ICACCP.2019.8882973, 10.1109/ICACCP.2019.8882973]
   Guo YR, 2016, IEEE T MED IMAGING, V35, P1077, DOI 10.1109/TMI.2015.2508280
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Q, 2018, COMPUT BIOL MED, V95, P198, DOI 10.1016/j.compbiomed.2018.02.012
   Isensee Fabian, 2018, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Third International Workshop, BrainLes 2017. Held in Conjunction with MICCAI 2017. Revised Selected Papers: LNCS 10670, P287, DOI 10.1007/978-3-319-75238-9_25
   Isensee F., 2018, nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation, DOI DOI 10.1007/978-3-658-25326-4_7
   Jian JM, 2018, AUSTRALAS PHYS ENG S, V41, P393, DOI 10.1007/s13246-018-0636-9
   Koonsanit K, 2017, BIOMED ENG INT CONF
   Liu SQ, 2020, IEEE ACCESS, V8, P2906, DOI 10.1109/ACCESS.2019.2961125
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28787-y
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Park YJ, 2019, IEEE IMAGE PROC, P3437, DOI [10.1109/icip.2019.8803746, 10.1109/ICIP.2019.8803746]
   Pei Y, 2020, IEEE ACCESS, V8, P64131, DOI 10.1109/ACCESS.2020.2982543
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ran Z., 2019, BEIJING BIOMEDICAL E, V38, P7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2018, MED IMAGE ANAL, V45, P94, DOI 10.1016/j.media.2018.01.006
   Sun MY, 2020, IEEE ACCESS, V8, P15812, DOI 10.1109/ACCESS.2020.2967350
   Tapan U, 2014, DIAGN INTERV RADIOL, V20, P390, DOI 10.5152/dir.2014.13265
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang JZ, 2018, MED PHYS, V45, P2560, DOI 10.1002/mp.12918
   Wang MM, 2019, MED PHYS, V46, P2659, DOI 10.1002/mp.13541
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   [郑荣寿 Zheng Rongshou], 2019, [中华肿瘤杂志, Chinese Journal of Oncology], V41, P19
   Zhuang ZM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221535
   Zulfahmi R, 2019, 2019 INT C INFORMATI, P4954
NR 35
TC 2
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43821
EP 43835
DI 10.1007/s11042-022-13256-6
EA MAY 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805509400001
DA 2024-07-18
ER

PT J
AU Chatterjee, K
   Chaudhary, RRK
   Singh, A
AF Chatterjee, Kakali
   Chaudhary, Ravi Raushan Kumar
   Singh, Ashish
TI A lightweight block cipher technique for IoT based E-healthcare system
   security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things (IoT); Block cipher; Lightweight cryptography; LWARX;
   E-healthcare system; Encryption and decryption
ID KEY AGREEMENT SCHEME; USER AUTHENTICATION SCHEME; INTERNET; THINGS;
   CRYPTOGRAPHY
AB All the real and virtual IoT devices are connected to provide intelligent and decision-making services. Each IoT based application is designed for some specific purpose and function. For instance, the IoT based e-healthcare system is intended for providing healthcare services more smartly. All the healthcare data are stored/accessed remotely in an open environment with the help of the Internet and wireless media. Several cryptographic approaches were developed, protecting the system from misuse, modification, and node tempering of data. Such cryptographic approaches are inadequate due to the device's small size, low processing capacity, insufficient memory, and power resources. A Lightweight Cryptographic Algorithm (LCA) is needed to secure such a system. In this paper, a lightweight cryptographic algorithm for the security of the e-healthcare system is proposed. The proposed lightweight scheme is based on the Addition substitution and XOR (LWARX). Also, a secure authentication scheme based on the LWARX technique is proposed for secure communication in the healthcare system. The security analysis of the authentication scheme shows it will resist all types of network attacks. The performance analysis of the LWARX shows the enhanced results.
C1 [Chatterjee, Kakali; Chaudhary, Ravi Raushan Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
   [Singh, Ashish] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; Kalinga Institute of Industrial Technology (KIIT)
RP Chatterjee, K (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM kakali@nitp.ac.in; ravi.it17@nitp.ac.in; ashish.singhfcs@kiit.ac.in
OI chaudhary, Dr ravi raushan kumar/0000-0002-0910-5234
CR Abdulrazzaq, 2021, TURK J COMPUT MATH E, V12, P133
   Abie H., 2012, P 7 INT C BOD AR NET
   Ahmed E, 2016, IEEE WIREL COMMUN, V23, P10, DOI 10.1109/MWC.2016.7721736
   Almulhim M, 2019, INT J COMPUT SCI NET, V19, P107
   Almulhim M, 2018, INT CONF ADV COMMUN, P481, DOI 10.23919/ICACT.2018.8323802
   Banik S, 2015, LECT NOTES COMPUT SC, V9453, P411, DOI 10.1007/978-3-662-48800-3_17
   Bansod G, 2016, SECUR COMMUN NETW, V9, P5238, DOI 10.1002/sec.1692
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Beaulieu Ray., 2013, IACR Cryptology ePrint Archive, V2013, P404
   Binu PK, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P487, DOI 10.1109/ICACCI.2017.8125887
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Borghoff J, 2012, LECT NOTES COMPUT SC, V7658, P208, DOI 10.1007/978-3-642-34961-4_14
   Chaudhary R, 2018, IEEE COMMUN MAG, V56, P24, DOI 10.1109/MCOM.2018.1700787
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   Das AK, 2015, J KING SAUD UNIV-COM, V27, P193, DOI 10.1016/j.jksuci.2014.03.020
   Dhanda SS, 2020, WIRELESS PERS COMMUN, V112, P1947, DOI 10.1007/s11277-020-07134-3
   Dhillon Parwinder Kaur, 2018, Journal of Reliable Intelligent Environments, V4, P141, DOI 10.1007/s40860-018-0062-5
   Dhillon PK, 2017, J INF SECUR APPL, V34, P255, DOI 10.1016/j.jisa.2017.01.003
   Girija M, 2021, PEER PEER NETW APPL, V14, P2462, DOI 10.1007/s12083-020-00992-5
   Gong Z, 2011, INT WORKSHOP RADIO F, P118
   Guo Y, 2021, IEEE INTERNET THINGS, V8, P13014, DOI 10.1109/JIOT.2021.3064203
   Hamidi H, 2019, FUTURE GENER COMP SY, V91, P434, DOI 10.1016/j.future.2018.09.024
   Hatzivasilis G, 2018, J CRYPTOGR ENG, V8, P141, DOI 10.1007/s13389-017-0160-y
   He DB, 2015, IEEE INTERNET THINGS, V2, P72, DOI 10.1109/JIOT.2014.2360121
   Hong D, 2006, LECT NOTES COMPUT SC, V4249, P46, DOI 10.1007/11894063_4
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Hou JL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/183659
   Karako F, 2013, INT WORKSHOP LIGHTWE, P1627
   Kaul SD, 2016, WIRELESS PERS COMMUN, V89, P621, DOI 10.1007/s11277-016-3297-6
   Li L, 2018, MICROPROCESS MICROSY, V60, P138, DOI 10.1016/j.micpro.2018.04.009
   Li L, 2016, MICROPROCESS MICROSY, V45, P45, DOI 10.1016/j.micpro.2016.03.011
   Mohammed M.N., 2020, J PHYS C SER, V1450, DOI [DOI 10.1088/1742-6596/1450/1/012079, 10.1088/1742-6596/1450/1/012079/meta]
   Moosavi SR, 2018, PROCEDIA COMPUT SCI, V130, P432, DOI 10.1016/j.procs.2018.04.064
   Prakasam P, 2021, ICT EXPRESS, V7, P487, DOI 10.1016/j.icte.2021.03.007
   Ragab AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02782-6
   Rana M, 2021, COMPUT COMMUN, V165, P85, DOI 10.1016/j.comcom.2020.11.002
   Sadeghi S, 2017, MICROPROCESS MICROSY, V52, P34, DOI 10.1016/j.micpro.2017.05.007
   Shamshad S, 2022, DIGIT COMMUN NETW, V8, P150, DOI 10.1016/j.dcan.2021.07.002
   Sharma G, 2019, IJST-T ELECTR ENG, V43, P619, DOI 10.1007/s40998-018-0146-5
   Sliman L, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102897
   Suzaki T., 2011, ECRYPT WORKSH LIGHTW
   Taware S, 2021, J AMBIENT INTELL HUM, V19
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wu F, 2018, J AMB INTEL HUM COMP, V9, P919, DOI 10.1007/s12652-017-0485-5
   Wu WL, 2011, LECT NOTES COMPUT SC, V6715, P327, DOI 10.1007/978-3-642-21554-4_19
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
   Yachana, 2018, TELEMAT INFORM, V35, P790, DOI 10.1016/j.tele.2017.09.008
   Yeh KH, 2016, IEEE ACCESS, V4, P10288, DOI 10.1109/ACCESS.2016.2638038
   Zhang WT, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5459-7
NR 49
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43551
EP 43580
DI 10.1007/s11042-022-13106-5
EA MAY 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000801074700002
DA 2024-07-18
ER

PT J
AU Jin, X
   He, Z
   Xu, J
   Wang, YW
   Su, YT
AF Jin, Xiao
   He, Zhen
   Xu, Jing
   Wang, Yongwei
   Su, Yuting
TI Video splicing detection and localization based on multi-level deep
   feature fusion and reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object-based forgery detection in videos; Video forensics; Video
   splicing detection; Splicing forgery detection
ID IMAGE; FORGERY; FORENSICS; NETWORK
AB Splicing forgery refers to copying some regions of a video or an image to another video/image. Although image splicing detection has been studied for many years, video splicing detection has attracted relatively much less attention. In this paper, we proposed a novel framework for video splicing detection by modeling this forensic task as a video object segmentation problem. Based on the nature of this forgery operation, discontinuous noise distribution and object contours are adopted as traces to guide the localization results. The method consists of three modules: EXIF-consistency prediction, suspected region tracking, and semantic segmentation. To bridge the gap between sensor-level and semantic-level features, three modules in our framework are integrated for final tampered areas detection. Firstly, we use the EXIF-consistency prediction module to extract sensor-level traces from tampered areas. Then, we employ a deep reinforcement learning-based method for tracking suspected regions. Finally, a semantic segmentation module is adopted to localize the final results of the tampered regions. Compared with several state-of-the-art forensic approaches, our method demonstrates superiority in publicly available datasets. In terms of F1 score, our method achieves 0.623 in GRIP dataset.
C1 [Jin, Xiao; He, Zhen; Xu, Jing] Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.
   [Wang, Yongwei] Nanyang Technol Univ, Joint NTU WeBank Res Ctr Fintech, Singapore 639798, Singapore.
   [Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Nankai University; Nanyang Technological University; Tianjin University
RP Xu, J (corresponding author), Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China.
EM xujing@nankai.edu.cn
RI xu, jingcheng/HJZ-3124-2023; Jin, Xiao/IVV-4814-2023; xu,
   jing/GRR-8698-2022
FU National Natural Science Foundation of China [62002177]; Tianjin Natural
   Science Foundation, China [21JCYBJC00110, 19JCQNJC00300]; Fundamental
   Research Funds for the Central Universities of Nankai University
   [63201192, 63211116]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 62002177), Tianjin Natural Science Foundation, China (Grant
   No. 21JCYBJC00110 and 19JCQNJC00300), and Fundamental Research Funds for
   the Central Universities of Nankai University (Grant No. 63201192,
   63211116).
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   [Anonymous], 2014, INT C LEARN REPR
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bammey Q, 2020, P IEEE C COMPUTER VI
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chatfield K, 2014, ARXIV 14053531
   Chen RC, 2014, FORENSIC SCI INT, V236, P164, DOI 10.1016/j.forsciint.2013.12.022
   Cozzolino D, 2019, P IEEE C COMPUTER VI, P130, DOI DOI 10.1109/CVPRW47913.2019
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Huh M, 2018, P EUROPEAN C COMPUTE
   Islam A, 2020, P IEEE C COMPUTER VI
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Jiang JM, 2016, IEEE T CIRC SYST VID, V26, P506, DOI 10.1109/TCSVT.2015.2416557
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Khoreva A, 2017, P IEEE C COMPUTER VI
   Kniaz VV, 2019, ADV NEUR IN, V32, P215
   Lin X, 2019, MEASUREMENT, V139, P61, DOI 10.1016/j.measurement.2019.02.086
   Liu B, 2020, INFORM SCIENCES, V526, P133, DOI 10.1016/j.ins.2020.03.099
   Liu B, 2020, NEUROCOMPUTING, V387, P172, DOI 10.1016/j.neucom.2019.12.105
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Perazzi F, 2016, P IEEE C COMPUTER VI
   Poupart P, 2018, P ANN C NEUR INF PRO, V31, P5688
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Sun P, 2018, FORENSIC SCI INT, V289, P1, DOI 10.1016/j.forsciint.2018.04.049
   Vecchio G, 2020, IEEE T NEUR NET LEAR, V31, P5103, DOI 10.1109/TNNLS.2019.2963282
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang XF, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108347
   WARIF NBA, 2016, J NETW COMPUT APPL, V75, P259, DOI DOI 10.1016/J.JNCA.2016.09.008
   Wei Y, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3408299
   Wu Y, 2017, P ACM INT C MULTIMED
   Wu Y., 2019, P IEEE C COMPUTER VI
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xie S., 2015, P IEEE INT C COMPUTE
   Yang J, 2016, IEEE T IMAGE PROCESS, V25, P503, DOI 10.1109/TIP.2015.2500820
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Yun S, 2018, IEEE T NEUR NET LEAR, V29, P2239, DOI 10.1109/TNNLS.2018.2801826
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
   Zhou P., 2018, P IEEE C COMPUTER VI
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
   Zhuo T, 2020, IEEE T IMAGE PROCESS, V29, P237, DOI 10.1109/TIP.2019.2930152
NR 51
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40993
EP 41011
DI 10.1007/s11042-022-13001-z
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000796326600003
DA 2024-07-18
ER

PT J
AU Nagalingayya, M
   Mathpati, BS
AF Nagalingayya, M.
   Mathpati, Basavaraj S.
TI Energy-efficient cooperative routing scheme with recurrent neural
   network based decision making system for wireless multimedia sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WMSNs; Cooperative route; Reliability; Recurrent neural network; SA-GWA
   algorithm
AB "Wireless multimedia sensor networks (WMSNs)" are deployed in wider range of applications including video surveillance and area monitoring. However, due to the error-prone unreliable medium and application-based quality of service (QoS) requirements, routing in WMSNs becomes a serious issue. Thereby, this work intends to find the maximum energy cooperative route in WMSNs. Accordingly, Recurrent Neural Network (RNN) oriented decision making system is introduced for selecting the appropriate cooperative nodes with the knowledge of: (i) Tri-level energy utilization of nodes (ii) Reliability (iii) Delay to encounter the multimedia services in the network for transmitting the multimedia information. To make the precise decision on this, this paper intends to enhance the system model of RNN via optimizing the weights. For this optimization, a new Sea lion Adapted Grey Wolf Optimization (SA-GWA) is introduced, which is the hybridization of both Sea lion Optimization (SLnO) and Grey Wolf Optimizer (GWO). Finally, the superiority of the proposed model is validated over existing models in terms of reliability, residual energy and delay analysis.
C1 [Nagalingayya, M.; Mathpati, Basavaraj S.] Sharnbasva Univ Kalaburgi, Dept Comp Sci & Engn, Gulbarga 585105, Karnataka, India.
RP Nagalingayya, M (corresponding author), Sharnbasva Univ Kalaburgi, Dept Comp Sci & Engn, Gulbarga 585105, Karnataka, India.
EM nmmath86@gmail.com; drbasu2014@gmail.com
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, SOFT COMPUT, V21, P7191, DOI 10.1007/s00500-016-2262-3
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Ahmed AA, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3296
   Akila IS, 2016, COMPUT J, V59, P1551, DOI 10.1093/comjnl/bxw062
   Al-Turjman F, 2017, IEEE WIREL COMMUN, V24, P126, DOI 10.1109/WCM.2017.1700054
   Alanazi A, 2015, SENSORS-BASEL, V15, P22209, DOI 10.3390/s150922209
   Banerjee R, 2019, WIREL NETW, V25, P167, DOI 10.1007/s11276-017-1543-9
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Civelek M, 2017, IEEE SENS J, V17, P1116, DOI 10.1109/JSEN.2016.2638853
   Darabkh KA, 2018, COMPUT ELECTR ENG, V72, P702, DOI 10.1016/j.compeleceng.2017.11.017
   Hasan MZ, 2017, IEEE COMMUN SURV TUT, V19, P1424, DOI 10.1109/COMST.2017.2661201
   Jan MA, 2019, IEEE INTERNET THINGS, V6, P1576, DOI 10.1109/JIOT.2018.2848284
   Jiang DD, 2017, NEUROCOMPUTING, V220, P160, DOI 10.1016/j.neucom.2016.07.056
   Jung K, 2017, MULTIMED TOOLS APPL, V76, P18175, DOI 10.1007/s11042-016-4190-8
   Kao LJ, 2020, J MANUF SYST, V57, P109, DOI 10.1016/j.jmsy.2020.07.020
   Khernane N, 2018, COMPUT COMMUN, V124, P1, DOI 10.1016/j.comcom.2018.04.012
   Kim S, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102252
   Koyuncu M, 2019, IEEE SENS J, V19, P1839, DOI 10.1109/JSEN.2018.2885281
   Kucukkececi C, 2019, IEEE ACCESS, V7, P67818, DOI 10.1109/ACCESS.2019.2918765
   Lin TL, 2018, IEEE SENS J, V18, P9792, DOI 10.1109/JSEN.2018.2865916
   Malhotra J, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0939-2
   Mali G, 2016, IEEE T COMPUT, V65, P1978, DOI 10.1109/TC.2015.2456026
   Masadeh R, 2019, INT J ADV COMPUT SC, V10, P388
   Mekonnen T., 2017, IEEE ACCESS, V6, P2169
   Mekonnen T, 2017, IEEE ACCESS, V5, P15848, DOI 10.1109/ACCESS.2017.2737078
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Momani S., 2016, Applied Mathematics Information Sciences, V10, P225, DOI DOI 10.18576/AMIS/100122
   Mukhedkar, 2019, J NETW COMMUN SYST, V2, P1, DOI DOI 10.46253/JNACS.V2I3.A1
   Park CM, 2017, IEEE ACCESS, V5, P11054, DOI 10.1109/ACCESS.2017.2715407
   Rathod S., 2020, Journal of Networking and Communication Systems, V3, P101504
   Roy R. G., 2019, J COMPUT MECH POWER, P9, DOI DOI 10.46253/JCMPS.V2I1.A2
   Thomas M. J. S., 2018, MULTIMEDIA RES, P33, DOI DOI 10.46253/J.MR.V1I1.A5
   Vinusha S., 2018, J NETW COMMUN SYST, V1, P19
   Wang, 2020, J NETW COMMUN SYST, V3
   Wang DH, 2020, COMPUT NETW, V178, DOI 10.1016/j.comnet.2020.107313
   Yang X, 2018, ELECTRON LETT, V54, P323, DOI 10.1049/el.2017.2515
   Zhou LB, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1468-3
   Zhu HM, 2016, IEEE SENS J, V16, P4484, DOI 10.1109/JSEN.2016.2523601
NR 39
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39785
EP 39801
DI 10.1007/s11042-022-12938-5
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000790129700001
DA 2024-07-18
ER

PT J
AU Pavithra, LK
   Srinivasan, R
   Sharmila, TS
AF Pavithra, L. K.
   Srinivasan, R.
   Sharmila, T. Sree
TI Optimum anamorphic image generation using image rotation and relative
   entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anamorphic; Relative entropy; Shannon's entropy; Image rotation
AB Anamorphosis is related to the art that gives illusion (distortion) over the image or object when the viewer looks the original image or from the random viewpoint. This illusion effect is nullified when the image or object is viewed from the standard viewpoint. In digital imaging domain, anamorphic images (distortion) are generated by changing the pixel coordinates of the given image into new pixel coordinates, and this process typically increases the size of the original image matrix which results in gaps between the successive pixels. In anamorphic transform, the gaps between the successive pixel positions increases as we travel from viewing end to the tail end, and these gaps are filled by interpolating the successive pixels. The viewing angle, distance, height between the viewer and original image are responsible for the amount of distortion introduced in anamorphic images. The proposed work reveals that the rotation of the original image also plays an important role in creating distortion in anamorphic images. The proposed work uses the Kullback-Leibler distance (KLD) to measure the amount of distortion between the original and anamorphized images. A larger KLD implies that the original and anamorphic images are well separated i.e., a good anamorphism has achieved. It is found that the smaller viewing angle combined with the viewing distance and height achieves the larger KLD. The optimum anamorphic image generation is done at two levels: (i) Choosing an appropriate viewing angle, distance, and height, and (ii) Choosing the appropriate rotation of the image to be anamorphized. The former is optimized through KLD, and for the latter Shannon's entropy of the tail portion of the original image under different rotations is used. The proposed technique is tested on various images with different resolutions and is found to be working properly.
C1 [Pavithra, L. K.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
   [Srinivasan, R.; Sharmila, T. Sree] Sri Sivasubramaniya Nadar Coll Engn, Dept Informat Technol, Chennai 603110, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; SSN College of
   Engineering
RP Pavithra, LK (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM pavithrra.pavi@gmail.com
OI T, Sree Sharmila/0009-0009-1736-2669
CR Bouwers A, 1956, J SMPTE, V65
   Bromiley P. A., 2004, STAT INF SERIES, V2004-004, P9
   Chris SBS, 2019, PROCEDIA COMPUT SCI, V165, P774, DOI 10.1016/j.procs.2020.01.012
   Cover T., 1991, Wiley Series in Telecommunications, DOI [10.1002/0471200611, DOI 10.1002/0471200611]
   DeWeerd AJ, 2006, AM J PHYS, V74, P83, DOI 10.1119/1.2117148
   Di Lazzaro P, 2019, J MATH ARTS, V13, P353, DOI 10.1080/17513472.2018.1506627
   Di Paola F, 2015, NEXUS NETW J, V17, P253, DOI 10.1007/s00004-014-0225-5
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Hansford D, 2007, COMPUTING, V79, P211, DOI 10.1007/s00607-006-0199-6
   Hu L, 2010, ADV MULTIMEDIA INFOR, V6297
   Hunt JL, 2000, AM J PHYS, V68, P232, DOI 10.1119/1.19406
   Jain A., 1986, FUNDAMENTALS DIGITAL
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Malkasian Carter, 2017, The Oxford compendium of visual illusions, DOI [10.1093/acprof:oso/9780199794607.001.0001, DOI 10.1093/ACPROF:OSO/9780199794607.001.0001]
   Ravnik R, 2014, INTERACT COMPUT, V26, P46, DOI 10.1093/iwc/iwt027
   Sánchez-Reyes J, 2016, COMPUT AIDED GEOM D, V46, P30, DOI 10.1016/j.cagd.2016.06.002
   Singh OP, 2023, COMPLEX INTELL SYST, V9, P2759, DOI 10.1007/s40747-021-00309-w
   Stojakovic V, 2016, NEXUS NETW J, V18, P759, DOI 10.1007/s00004-016-0302-z
   Stork DG, 2009, LECT NOTES COMPUT SC, V5702, P9, DOI 10.1007/978-3-642-03767-2_2
   Topper D, 2000, LEONARDO, V33, P115, DOI 10.1162/002409400552379
   Yang Bo, 2014, Journal of Applied Sciences, V13, P2394, DOI 10.3923/jas.2013.2394.2398
NR 22
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38971
EP 39001
DI 10.1007/s11042-022-12982-1
EA APR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500005
DA 2024-07-18
ER

PT J
AU Bhaskar, S
   Thasleema, TM
AF Bhaskar, Shabina
   Thasleema, T. M.
TI LSTM model for visual speech recognition through facial expressions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio-visual emotion recognition; Audio-visual speech recognition;
   Hearing impaired; Convolutional neural network; Long short term memory
ID FEATURES
AB Hearing impaired persons are more expressive while speaking and expression is a salient feature in hearing impaired Visual Speech Recognition. Most Visual Speech Recognition systems focus only on the lip area for the recognition of speech or speaker. This work utilizes video data which includes information from both speech and facial expressions. As part of this study, we have developed a Malayalam audio-visual speech expression database of unimpaired people. The experiments were conducted on this newly developed Malayalam audio-visual speech database. The data has been collected from two people, 1 male, and 1 female. A combination of Convolutional Neural Network-Long Short Term Memory deep learning video processing model is applied for this system. The result demonstrate that, the classification accuracy is better for the features extracted using GoogleNet model compared to AlexNet and ResNet model. The system evaluation is carried out in both Speaker-dependent and speaker-independent domains. The recognition rate of the system for both speaker-dependent and speaker-independent experiments proves that facial expression analysis plays a crucial role in Visual Speech Recognition.
C1 [Bhaskar, Shabina; Thasleema, T. M.] Cent Univ Kerala, Kasaragod, Kerala, India.
C3 Central University of Kerala
RP Bhaskar, S (corresponding author), Cent Univ Kerala, Kasaragod, Kerala, India.
EM shabinabhaskar@hotmail.com; thasleema@cukerala.ac.in
FU Central University of Kerala
FX The authors express sincere thanks to Central University of Kerala for
   the research support. Also, We thank the Kevees Studio team for the
   support they have made for the database development. The authors
   acknowledge the participants who have participated in data collection.
CR [Anonymous], 2008, Advances in neural information processing systems
   Arunachalam R, 2019, MULTIMED TOOLS APPL, V78, P20787, DOI 10.1007/s11042-019-7329-6
   Avots E, 2019, MACH VISION APPL, V30, P975, DOI 10.1007/s00138-018-0960-9
   Bao W, 2014, INT CONF SIGN PROCES, P583, DOI 10.1109/ICOSP.2014.7015071
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen JZ, 2022, NEURAL COMPUT APPL, V34, P2233, DOI 10.1007/s00521-021-06526-1
   Chen XJ, 2020, SIGNAL IMAGE VIDEO P, V14, P981, DOI 10.1007/s11760-019-01630-1
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Dhanjal Amandeep Singh, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P205, DOI 10.1109/COMITCon.2019.8862454
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Elmadany NE, 2016, IEEE INT SYMP CIRC S, P590, DOI 10.1109/ISCAS.2016.7527309
   Fabelo H, 2019, IEEE ACCESS, V7, P39098, DOI 10.1109/ACCESS.2019.2904788
   Frank M.G., 2001, International Encyclopedia of the Social & Behavioral Sciences, P5230, DOI DOI 10.1016/B0-08-043076-7/01713-7
   Goehring T, 2017, HEARING RES, V344, P183, DOI 10.1016/j.heares.2016.11.012
   Goldschen A. J., 2002, PROC 28 ASILOMAR C S, P572
   Hao MF, 2020, IEEE ACCESS, V8, P204518, DOI 10.1109/ACCESS.2020.3036865
   Jan A, 2018, IEEE T COGN DEV SYST, V10, P668, DOI 10.1109/TCDS.2017.2721552
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Martinez B, 2020, INT CONF ACOUST SPEE, P6319, DOI [10.1109/ICASSP40776.2020.9053841, 10.1109/icassp40776.2020.9053841]
   Ngiam J, 2007, P ACM INT MULT C EXH, P57
   Noda K, 2014, INTERSPEECH, P1149
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Ogawa T, 2018, IEEE ACCESS, V6, P61401, DOI 10.1109/ACCESS.2018.2876710
   Petajan E. D., 1984, IEEE Global Telecommunications Conference, GLOBECOM '84 Conference Record. `Communications in the Information Age' (Cat. No. 84CH2064-4), P265
   Phutela D., 2015, IUP J SOFT SKILLS, V9, P43
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Puviarasan N, 2011, EXPERT SYST APPL, V38, P4477, DOI 10.1016/j.eswa.2010.09.119
   Rahdari F, 2019, IJST-T ELECTR ENG, V43, P171, DOI 10.1007/s40998-018-0142-9
   Roisman GI, 2007, J PERS SOC PSYCHOL, V92, P678, DOI 10.1037/0022-3514.92.4.678
   Shah M, 1997, CONTINUOUS AUTOMATIC, P321
   Shoumy NJ, 2020, J NETW COMPUT APPL, V149, DOI 10.1016/j.jnca.2019.102447
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Vakhshiteh F, 2019, CIRC SYST SIGNAL PR, V38, P2523, DOI 10.1007/s00034-018-0975-5
   Vidal Andrea, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P397, DOI 10.1145/3382507.3418872
   Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852
   Wang W., 2011, MACHINE AUDITION PRI
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   Wong SC, 2017, IEEE T IMAGE PROCESS, V26, P4669, DOI 10.1109/TIP.2017.2696744
   Yu KW, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON ENERGY SMART SYSTEMS (2019 IEEE ESS), P18, DOI 10.1109/ess.2019.8764179
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 47
TC 12
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5455
EP 5472
DI 10.1007/s11042-022-12796-1
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000784679300010
DA 2024-07-18
ER

PT J
AU Dai, C
   Pan, C
   He, W
AF Dai, Chao
   Pan, Chen
   He, Wei
TI Feature extraction and fusion network for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Saliency detection; Feature difference; Feature fusion;
   Feature enhancement
AB In the salient object detection (SOD) models based on convolutional neural network (CNN), the high-level semantic features and low-level features of the image are effectively fused and complementary, which can effectively improve the performance of SOD. However, there are usually great differences between high-level semantic features and low-level features, and low-level features are often rich in noise. How to make full use of different features and avoid noise interference is a hot issue for researchers. Different from the traditional methods, this paper proposes a novel feature extraction and fusion network (EFNet). By setting a middle-level feature extraction module as the medium for the fusion of high-level semantic features and low-level image features, this special module integrates the two by reducing the difference between low-level image features and deep semantic features; In addition, a feature enhancement module is applied to enhance the image features, and the proposed SOD method can obtain good performance. Experimental results on five benchmark datasets show that the proposed method outperforms 15 state-of-the-art methods on five important evaluation metrics. Code will be available at: https://github.com/dc3234/EFNet.
C1 [Dai, Chao; Pan, Chen; He, Wei] China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Pan, C (corresponding author), China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
EM s20030812003@cjlu.edu.cn; pc916@cjlu.edu.cn; s1903081203@cjlu.edu.cn
FU Natural Science Foundation of Zhejiang Province of China
FX This research project was supported by the Natural Science Foundation of
   Zhejiang Province of China (NO.LY19F030013).
CR [Anonymous], 2010, P INT C ADV NEUR INF
   Atrish A, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P103, DOI 10.1145/3177404.3177432
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Fang C., 2021, ARXIV210209133
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Kang D, 2020, IEEE ACCESS, V8, P104357, DOI 10.1109/ACCESS.2020.2999627
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar A, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2019, ADV INTELL SYST, V748, P453, DOI 10.1007/978-981-13-0923-6_39
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Lee H, 2018, IEEE WINT CONF APPL, P1170, DOI 10.1109/WACV.2018.00133
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liang YH, 2021, NEUROCOMPUTING, V422, P22, DOI 10.1016/j.neucom.2020.09.033
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239
   Liu Y, 2022, IEEE T CYBERNETICS, V52, P6131, DOI 10.1109/TCYB.2021.3051350
   Luo WJ, 2016, ADV NEUR IN, V29
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Noori M, 2020, ENG APPL ARTIF INTEL, V89, DOI 10.1016/j.engappai.2019.103419
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ravi V., 2021, ADV ARTIFICIAL INTEL, P227, DOI [10.1007/978-3-030-69951-2_9, DOI 10.1007/978-3-030-69951-2_9]
   Ravi V, 2022, MULTIMEDIA SYST, V28, P1401, DOI 10.1007/s00530-021-00826-1
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
NR 48
TC 3
Z9 3
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33955
EP 33969
DI 10.1007/s11042-022-12394-1
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300016
DA 2024-07-18
ER

PT J
AU Jiang, W
   Ye, L
   Yi, Z
   Peng, C
AF Jiang, Wang
   Ye, Lin
   Yi, Zhang
   Peng, Cheng
TI A new occluded face recognition framework with combination of both
   Deocclusion and feature filtering methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occluded face recognition; Face deocclusion; Generative adversarial
   network; Head pose estimation
ID ROBUST; REPRESENTATION; NETWORK
AB Face recognition plays the significant role in many human-computer interaction decvices and applications, whose access control systems are based on the verification of face biometrical features. Though great improvement in the recognition performances have been achieved, when under some specific conditions like faces with occlusions, the performance would suffer a severe drop. Occlusion is one of the most significant reasons for the performance degrade of the existing general face recognition systems. The biggest problem in occluded face recognition (OFR) lies in the lack of the occluded face data. To mitigate this problem, this paper has proposed one new OFR network DOMG-OFR (Dynamic Occlusion Mask Generator based Occluded Face Recognition), which keeps trying to generate the most informative occluded face training samples on feature level dynamically, in this way, the recognition model would always be fed with the most valuable training samples so as to save the labor in preparing the synthetic data while simultaneously improving the training efficiency. Besides, this paper also proposes one new module called Decision Module (DM) in an attempt to combine both the merits of the two mainstream methodologies in OFR which are face image reconstruction based methodologies and the face feature filtering based methodologies. Furthermore, to enable the existing face deocclusion methods that mostly target at near frontal faces to work well on faces under large poses, one head pose aware deocclusion pipeline based on the Condition Generative Adversarial Network (CGAN) is proposed. In the experimental parts, we have also investigated the effects of the occlusions upon face recognition performance, and the validity and the efficiency of our proposed Decision based OFR pipeline has been fully proved. Through comparing both the verification and the recognition performance upon both the real occluded face datasets and the synthetic occluded face datasets with other existing works, our proposed OFR architecture has demonstrated obvious advantages over other works.
C1 [Jiang, Wang; Ye, Lin; Yi, Zhang] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Peoples R China.
   [Peng, Cheng] Sichuan Univ, Coll Aeronaut & Astronaut, Chengdu, Peoples R China.
C3 Sichuan University; Sichuan University
RP Peng, C (corresponding author), Sichuan Univ, Coll Aeronaut & Astronaut, Chengdu, Peoples R China.
EM jiang.wang@stu.scu.edu.cn; linlanye@sina.cn; raven.zhang@foxmail.com;
   chengpeng_scu@163.com
RI feng, feng/KBR-1814-2024
CR Ahn C, 2019, IEEE I CONF COMP VIS, P6528, DOI 10.1109/ICCV.2019.00663
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Benavente R, 1998, 24 COMP VIS CTR
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Cheng LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1099, DOI 10.1145/2733373.2806291
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dong JR, 2020, 2020 IEEE MTT-S INTERNATIONAL CONFERENCE ON NUMERICAL ELECTROMAGNETIC AND MULTIPHYSICS MODELING AND OPTIMIZATION (NEMO 2020), DOI [10.1109/NEMO49486.2020.9343509, 10.1145/3446999.3447000]
   Dosi H, 2018, IN PRESS, V1024, P339
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jingru Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11659, DOI 10.1109/CVPR42600.2020.01168
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Li KJ, 2020, IEEE INT CONF AUTOMA, P45, DOI [10.1109/FG47880.2020.00022, 10.1109/CISCE50729.2020.00038]
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Low CY, 2019, IEEE T CIRC SYST VID, V29, P115, DOI 10.1109/TCSVT.2017.2761829
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Nash Simon, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Biosignals, P106
   Olszewska J.I., 2016, PATTERN RECOGN, P59
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shao CB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P666
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Song LS, 2019, AAAI CONF ARTIF INTE, P2506
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Trigueros DS, 2018, IMAGE VISION COMPUT, V79, P99, DOI 10.1016/j.imavis.2018.09.011
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wan WT, 2017, IEEE IMAGE PROC, P3795, DOI 10.1109/ICIP.2017.8296992
   Wang G., 2020, arXiv
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang J., 2017, ARXIV171107246
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Weng RL, 2016, IEEE T IMAGE PROCESS, V25, P1163, DOI 10.1109/TIP.2016.2515987
   Weng RL, 2013, IEEE I CONF COMP VIS, P601, DOI 10.1109/ICCV.2013.80
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340
   Yi Dong, 2014, ARXIV14117923
   Yin BJ, 2019, IEEE I CONF COMP VIS, P9347, DOI 10.1109/ICCV.2019.00944
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yuan XW, 2019, IEEE I CONF COMP VIS, P10061, DOI 10.1109/ICCV.2019.01016
   Zeng D, 2020, ARXIV200611366
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zhang ZS, 2020, IEEE WINT CONF APPL, P1350, DOI [10.1109/wacv45572.2020.9093445, 10.1109/WACV45572.2020.9093445]
   Zhao F, 2018, IEEE T IMAGE PROCESS, V27, P778, DOI 10.1109/TIP.2017.2771408
   Zhao Y, 2013, 2013 IEEE INT, P109
NR 55
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33867
EP 33896
DI 10.1007/s11042-022-12851-x
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300011
PM 35469149
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zou, LM
   Sun, JD
   Wan, WB
   Li, J
   Wu, QMJ
AF Zou, Liming
   Sun, Jiande
   Wan, Wenbo
   Li, Jing
   Wu, Q. M. Jonathan
TI A cover selection-based reversible data hiding method by learning
   cross-modal hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Different network conditions; Reversible data hiding (RDH); Cover
   selection; Information expansion model
ID PREDICTION-ERROR EXPANSION; WATERMARKING
AB With the rapid development of the Internet, various ways of transmitting data have emerged, such as cloud and social applications. However, these data transmission ways with different network conditions have different effects on data hiding. To solve the problem of data hiding in different network transmission conditions, a cover selection-based reversible data hiding (RDH) method by learning cross-modal hashing was proposed in this paper. In the proposed method, images and audio are selected to carry messages according to the transmission environment. A cross-modal hashing method was adopted and an information expansion model was established to build the connection between images, audio, and secret messages. When the cover is selected, the prediction error expansion (PEE)-based method for images and the histogram shifting (HS)-based method for audio is applied to embed messages. Experimental results show that our method can achieve high embedding efficiency, visual quality for images, and auditory quality for audio, respectively.
C1 [Zou, Liming; Sun, Jiande; Wan, Wenbo] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.
   [Li, Jing] Shandong Normal Univ, Sch Journalism & Commun, Jinan 250358, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 Shandong Normal University; Shandong Normal University; University of
   Windsor
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.; Li, J (corresponding author), Shandong Normal Univ, Sch Journalism & Commun, Jinan 250358, Peoples R China.
EM jiandesun@hotmail.com; lijingjdsun@hotmail.com
RI Zhang, Yuchen/GYI-8858-2022
FU Scientific Research Leader Studio of Jinan [2021GXRC081]; Joint Project
   for Smart Computing of Shandong Natural Science Foundation
   [ZR2020LZH015]; Taishan Scholar Project of Shandong, China
FX This work was supported in part by Scientific Research Leader Studio of
   Jinan (No. 2021GXRC081), in part by Joint Project for Smart Computing of
   Shandong Natural Science Foundation (ZR2020LZH015), and in part by
   Taishan Scholar Project of Shandong, China (No. ts20190924).
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang Q, 2021, IEEE T CIRC SYST VID, V31, P4850, DOI 10.1109/TCSVT.2021.3055612
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Faragallah OS, 2021, MULTIMED TOOLS APPL, V80, P26297, DOI 10.1007/s11042-021-10956-3
   He WG, 2021, IEEE T IMAGE PROCESS, V30, P5045, DOI 10.1109/TIP.2021.3078088
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Hou DD, 2018, IEEE T IMAGE PROCESS, V27, P5087, DOI 10.1109/TIP.2018.2851074
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hu R., 2021, IEEE T PATTERN ANAL, P1
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Ke Y, 2020, IEEE T CIRC SYST VID, V30, P2353, DOI 10.1109/TCSVT.2019.2963393
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Lee SH, 2018, MULTIMED TOOLS APPL, V77, P19499, DOI 10.1007/s11042-017-5379-1
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li S, 2020, REVERSIBLE DATA HIDI, V8
   Liu Y, 2013, 2013 IEEE 77 VEH TEC, P1
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2020, IEEE T CIRC SYST VID, V30, P2329, DOI 10.1109/TCSVT.2019.2921812
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P12569, DOI 10.1007/s11042-019-08335-0
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang XX, 2020, MULTIMED TOOLS APPL, V79, P28661, DOI 10.1007/s11042-020-09315-5
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2021, MULTIMED TOOLS APPL, V80, P29915, DOI 10.1007/s11042-021-11143-0
   Xiang Shijun, 2021, IEEE T CIRC SYST VID
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yao H, 2021, INFORM SCIENCES, V563, P130, DOI 10.1016/j.ins.2021.02.015
   Yao H, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0281-y
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
   Zheng WB, 2020, IEEE ACCESS, V8, P13105, DOI 10.1109/ACCESS.2020.2963891
   Zhou H, 2019, IEEE T MULTIMEDIA, V21, P1384, DOI 10.1109/TMM.2018.2882088
NR 44
TC 0
Z9 0
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2983
EP 3005
DI 10.1007/s11042-022-12936-7
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000784679300014
DA 2024-07-18
ER

PT J
AU Huang, WK
   Xue, YH
   Xu, ZF
   Peng, GL
   Wu, Y
AF Huang, Wenkai
   Xue, Yihao
   Xu, Zefeng
   Peng, Guanglong
   Wu, Yu
TI Polyphonic music generation generative adversarial network with Markov
   decision process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polyphonic music generation; Markov decision process (MDP); Monte Carlo
   tree search (MCTS); Deep learning; Wasserstein Generative Adversarial
   Network (WGAN)
AB In the process of polyphonic music creation, it is important to combine two or more independent melodies through technical treatment. However, due to the diversity of polyphonic music sequences and the limitations of neural networks, it is difficult to create chords or melodies beyond the training data. As the music sequence increases, the probability of the generator producing the same note will increase, which will destroy the coherence of the music. Therefore, this paper proposes a novel polyphonic music creation model, combining the ideas of the Markov decision process (MDP) and Monte Carlo tree search (MCTS) and improving the Wasserstein Generative Adversarial Network (WGAN) theory. Through the zero-sum game and conditional constraints between generator and discriminator, the model in this study is closer to the unconstrained creation of music, and the growth of music sequence will not affect music coherence. Experimental results show that the algorithm proposed here has a better effect on polyphonic music generation than the latest methods.
C1 [Huang, Wenkai] Guangzhou Univ, Ctr Res Leading Technol Special Equipment, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
   [Xue, Yihao; Xu, Zefeng; Peng, Guanglong] Guangzhou Univ, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
   [Wu, Yu] Guangzhou Univ, Lab Ctr, Guangzhou 510006, Peoples R China.
C3 Guangzhou University; Guangzhou University; Guangzhou University
RP Huang, WK (corresponding author), Guangzhou Univ, Ctr Res Leading Technol Special Equipment, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
EM 16796796@qq.com
RI Huang, Wenkai/ITU-1550-2023
OI Huang, Wenkai/0000-0003-3111-7511
FU Guangdong Provincial Key Platform and Major Scientific Research Projects
   [2018GXJK138]
FX This work was supported by the Guangdong Provincial Key Platform and
   Major Scientific Research Projects under Grant 2018GXJK138.
CR Agarwal S, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P455, DOI 10.1109/SSCI.2018.8628712
   Arjovsky M, 2017, 170107875 ARXIV
   Bi CK, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105741
   Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810
   Chen JN, 2020, IEEE T VEH TECHNOL, V69, P7146, DOI 10.1109/TVT.2020.2991584
   Conklin D, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091704
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dean RT, 2020, NEURAL COMPUT APPL, V32, P969, DOI 10.1007/s00521-018-3765-x
   Dong, 2018, 19 INT SOC MUS INF R
   Dong, 2017, 18 INT SOC MUS INF R, P23
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Goienetxea I, 2019, IEEE ACCESS, V7, P183365, DOI 10.1109/ACCESS.2019.2959696
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hadjeres G, 2020, NEURAL COMPUT APPL, V32, P995, DOI 10.1007/s00521-018-3868-4
   Herremans D, 2019, IEEE T AFFECT COMPUT, V10, P510, DOI 10.1109/TAFFC.2017.2737984
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Lewis D. D., 1996, SIGIR Forum, P298
   Li Juan, 2011, Computer Engineering and Applications, V47, P124, DOI 10.3778/j.issn.1002-8331.2011.26.035
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   Lovejoy WS, 1991, ANN OPER RES, V28, P47, DOI 10.1007/BF02055574
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Mangal Sanidhya, 2019, ARXIV190801080
   Mao HH, 2018, IEEE INT C SEMANT CO, P377, DOI 10.1109/ICSC.2018.00077
   Mo F., 2018, P IEEE INT C ROB BIO, P1483
   Opitz J, 2021, 191103347 ARXIV
   Parras J, 2019, EXPERT SYST APPL, V122, P376, DOI 10.1016/j.eswa.2019.01.023
   Polo A, 2019, J MULTIMODAL USER IN, V13, P231, DOI 10.1007/s12193-018-0280-4
   Sehnke F, 2010, NEURAL NETWORKS, V23, P551, DOI 10.1016/j.neunet.2009.12.004
   Sironi CF, 2020, IEEE T GAMES, V12, P132, DOI 10.1109/TG.2018.2884768
   Whorley RP, 2016, J NEW MUSIC RES, V45, P160, DOI 10.1080/09298215.2016.1173708
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang YZ, 2020, IEEE ACCESS, V8, P28021, DOI 10.1109/ACCESS.2019.2961239
NR 34
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29865
EP 29885
DI 10.1007/s11042-022-12925-w
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500024
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kumar, N
AF Singh, Vivek Kumar
   Kumar, Nitin
TI CoBRa: convex hull based random walks for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convex hull; Random walks; Initial saliency map; Thresholding; Saliency
   detection
ID IMAGE SEGMENTATION; ATTENTION; MODEL; FRAMEWORK
AB Salient object detection is a challenging research area, which aims to highlight significant region of the visual scene more accurately and quickly. In this research direction, we propose a novel saliency detection model called Convex Hull Based Random Walks (CoBRa) approach. In the proposed model, an image is segmented into superpixels and Convex Hull is constructed based on the segmented image to roughly partition the segmented image into two regions: CH-foreground and CH-background regions and the centroid of the CH-foreground region is calculated. Then, initial saliency is computed by using two priors viz. contrast and center priors. Here, the proposed model exploits CH-foreground region centroid obtained by Convex Hull to computed center prior which is more efficient than image center. Afterwards, two thresholds are empirically obtained and applied on initial saliency map to produce two binary segmented images. Based on these two binary images, the proposed model collects foreground and background seeds. These seeds are further refined with CH-foreground and CH-background regions to produce reliable and effective seeds. Finally, a random walk is constructed with the determined seeds to generate a pixel-wise saliency map. The superiority of the proposed model is validated via extensive experimental results performed on six publicly available datasets viz. MSRA10K, DUT-OMRON, ECSSD, PASCAL-S, SED2, and THUR15K. The performance of the proposed model was compared with eight state-of-the-art methods in terms of Precision, Recall, F-Measure, Receiver Operating Characteristics (ROC), and Area under the curve (AUC). The proposed method outperforms or comparable with compared methods in terms of all the performance measures.
C1 [Singh, Vivek Kumar; Kumar, Nitin] Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Singh, VK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
EM vivek.kumarsingh@nituk.ac.in; nitin@nituk.ac.in
FU Ministry of Human Resource Development Government of India, India
FX We acknowledge Ministry of Human Resource Development Government of
   India, India for supporting this research by providing fellowship to one
   of the author Mr. Vivek Kumar Singh.
CR Achanta R., 2010, SLIC Superpixels
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng C, 2020, IEEE T MULTIMEDIA, V22, P885, DOI 10.1109/TMM.2019.2934833
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frintrop S, 2005, LECT NOTES COMPUT SC, V3663, P117
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Guo F, 2020, IEEE T CIRC SYST VID, V30, P4887, DOI 10.1109/TCSVT.2019.2906226
   Guo F, 2018, IEEE T CYBERNETICS, V48, P3159, DOI 10.1109/TCYB.2017.2761361
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P202, DOI 10.1016/j.jvcir.2018.11.007
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Lee G, 2018, IEEE T PATTERN ANAL, V40, P1599, DOI 10.1109/TPAMI.2017.2737631
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin X, 2019, INFORM SCIENCES, V485, P521, DOI 10.1016/j.ins.2019.02.002
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Singh N, 2016, DIGIT SIGNAL PROCESS, V55, P22, DOI 10.1016/j.dsp.2016.05.003
   Wang L, 2018, IEEE IPCCC
   Wang LH, 2019, NEUROCOMPUTING, V329, P433, DOI 10.1016/j.neucom.2018.10.061
   Wang WG, 2020, IEEE T PATTERN ANAL, V42, P1913, DOI 10.1109/TPAMI.2019.2905607
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao Y, 2019, NEUROCOMPUTING, V351, P156, DOI 10.1016/j.neucom.2019.03.066
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 49
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30283
EP 30303
DI 10.1007/s11042-022-12470-6
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500003
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumar, K
   Mahajan, S
   Chakraborty, C
   Pandit, AK
AF Kumar, Rajender
   Kumar, Krishan
   Mahajan, Shubham
   Chakraborty, Chinmay
   Pandit, Amit Kant
TI Implementation of K-multi constraint shortest paths (K-MCSP) for video
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; K-multiple constrained shortest path; Block matching
   algorithms; Quad-tree
AB Motion Estimation (ME) is one of the vital components in video coding standards. Many motion estimation techniques are developed by researchers but out of these, motion estimation using block matching algorithm (BMA) is most broadly used for estimating the motion vectors in most efficient manner. Therefore, an efficient representation of motion vectors (MVs) and its transmission is the most crucial step of video coding standards to achieve better coding efficiency with minimum degradation in video quality. Since motion estimation consumed about 70%-90% of total computational power, hence reducing the redundancy and computational complexity is need of hour and one of most widely used area of research in the last few decades. In this paper, first a review of various block matching algorithms along with their limitations is done and then a modified block matching algorithm using quadtree decomposition is proposed for finding the optimal solution for rate distortion trade-off which is termed as rate distortion optimization (RDO) problem in video coding. Moreover, K-Multiple Constrained Shortest Path (K-MCSP) algorithm which uses non-linear function in place of linear function is used for finding the shortest paths & best feasible path instead of Multiple Constrained Shortest Path (MCSP). It is experimentally tested for the first six frames of three benchmarking test video namely News, Mother Daughter and Foreman. In all the cases, distribution of bits among DVF and DFD are calculated and it is found that they satisfy the given constraints. The experimental testing demonstrate that the proposed technique is able to decrease the computational complexity by 8-20% with minimum variation in PSNR for all K-MCSP paths to compromise between DVF and DFD which is not achievable in fixed block size matching algorithms (FSBMA).
C1 [Kumar, Rajender; Kumar, Krishan; Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra, J&K, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Dept Elect & Commun Engn, Mesra, Jharkhand, India.
C3 Shri Mata Vaishno Devi University; Birla Institute of Technology Mesra
RP Kumar, R (corresponding author), Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra, J&K, India.
EM rajender.mtech@gmail.com
RI MAHAJAN, SHUBHAM/AAY-6389-2020; Chakraborty, Chinmay/N-3608-2017
OI MAHAJAN, SHUBHAM/0000-0003-0385-3933; Chakraborty,
   Chinmay/0000-0002-4385-0975
CR Abdulla, 2010, 2 INT C ED TECHN COM
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Chakraborty C, J FUZZY SYSTEMS, V3, P77
   Chakraborty C, 2019, INT J E-HEALTH MED C, V10, P1, DOI 10.4018/IJEHMC.2019040101
   Chen SG, 1998, ICC 98 - 1998 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS VOLS 1-3, P874, DOI 10.1109/ICC.1998.685137
   Choi K, 2019, IEEE DATA COMPR CONF, P310, DOI 10.1109/DCC.2019.00039
   De Neve H, 1998, 1998 IEEE ATM WORKSHOP PROCEEDINGS, P324, DOI 10.1109/ATM.1998.675192
   Iwendi C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111331
   Jungwoo Lee, 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P480, DOI 10.1109/ICIP.1995.537676
   Kumar K, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02766-6
   Liu G, 2001, IEEE INFOCOM SER, P743, DOI 10.1109/INFCOM.2001.916263
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Mittal M, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3997
   Russell S., 1996, ARTIF INTELL, P70
   Schuster GM, 1998, IEEE T IMAGE PROCESS, V7, P1505, DOI 10.1109/83.725359
   Smieee CI, 2018, IEEE INT CONF INDUST, P1935, DOI 10.1109/ICIT.2018.8352482
   STROBACH P, 1990, IEEE T COMMUN, V38, P477, DOI 10.1109/26.52659
   SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030
NR 19
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35379
EP 35410
DI 10.1007/s11042-022-12180-z
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000777241700002
DA 2024-07-18
ER

PT J
AU Latha, D
   Geetha, A
AF Latha, D.
   Geetha, A.
TI Effective CBIR based on hybrid image features and multilevel approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; GLCM; RGB; HSV; LTP and LBP
ID RETRIEVAL; CLASSIFICATION; SCALE
AB Content based image retrieval (CBIR) process can retrieve images by matching its feature set values. The proposed novel CBIR methodology called Effective CBIR based on hybrid image features and multilevel approach (CBIR_LTP_GLCM) integrates the hybrid features such as color features and texture features, along with multilevel approach. The color features such as mean and standard deviation are adopted in the proposed method to represent the global color properties of an image. This method manipulates the color input-image by processing the Hue, Saturation and Value channels of the HSV color space. This novel work is enriched with the image feature derived from Local Ternary Pattern (LTP) in addition with GLCM. So, the proposed method CBIR_LTP_GLCM is potentially charged with meaningful modifications travelling with color image manipulation and extended image retrieval accuracy with the aid of multilevel approach. The proposed methodology is experimentally compared with the existing recent CBIR versions by using the standard database such as Corel-1 k, and a user contributed database named DB_VEG.
C1 [Latha, D.] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
   [Geetha, A.] Nesamony Mem Christian Coll, Dept Comp Applicat, Marthandam, India.
RP Latha, D (corresponding author), Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
EM dlathasatheesh@gmail.com
CR Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   [Anonymous], 2016, COREL DATABASE 2016
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Foley J.D., 1990, Computer graphics: Principles and practice
   Goldstein E.B., 2003, SENSATION PERCEPTION, V2nd
   González R, 2016, PROC IEEE-PES
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Husain SS, 2017, IEEE T PATTERN ANAL, V39, P1783, DOI 10.1109/TPAMI.2016.2613873
   Iakovidis DK, 2009, IEEE T INF TECHNOL B, V13, P442, DOI 10.1109/TITB.2008.923144
   Kong FH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2228, DOI 10.1109/ICMLC.2009.5212186
   Kumar T., 2018, 2018 IEEE 20 INT C E, P1
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Unay D, 2010, IEEE T INF TECHNOL B, V14, P897, DOI 10.1109/TITB.2009.2038152
   Yang JC, 2017, IEEE T IND INFORM, V13, P2350, DOI 10.1109/TII.2017.2657545
   Zhang J., 2007, 4 TH INT C FUZZ SYST
NR 24
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28559
EP 28582
DI 10.1007/s11042-022-12588-7
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200001
DA 2024-07-18
ER

PT J
AU Khaleghi, E
   Soltanizadeh, H
   Gholizade, M
   Azadi, F
   Zahraei, M
   Rahmanimanesh, M
AF Khaleghi, Esmaeel
   Soltanizadeh, Hadi
   Gholizade, Masoume
   Azadi, Farhad
   Zahraei, Mohammad
   Rahmanimanesh, Mohammad
TI Detection of gait disorders in people with a walking disability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movement detection; Gait disorder; Kinect sensor; Fuzzy system; 3D
   body's skeletal position
ID RECOGNITION; PARAMETERS
AB A person's gait is their walking pattern. Walking necessitates muscular coordination and balance for the body to move forward rhythmically. Gait disorder is an issue in human society that can limit a person's life activity as an injury. Proper and rapid diagnosis of this disorder can help the healing process. Therefore, several types of research have always been done to identify the disorder, based on which the physician can consider an appropriate treatment plan for the patients. In this study, a Kinect sensor that has the ability to identify 25 points of anatomical points of the body has been used to receive and record data, Using the Kinect sensor to monitor and control gait disorder is cheaper than other existing systems. Also, it offers a higher quality in recording activities and feedback, which can show the desired indicators more accurately about the patient's gait disorder. The proposed method is defined based on a Fuzzy inference system defined by a medical team consisting of Medical Doctor Orthopedic and medical doctors as experts in this system. We gather data from 90 participants as a data set and then divided it randomly into two groups, 45 participants for the Fuzzy inference system construction as training step and 45 participants for the Fuzzy inference system evaluation as a test step. The outputs of the Fuzzy system validation show that based on three-dimensional information, 7 extracted features and rules made in the Fuzzy inference system, the accuracy is 95.1% .
C1 [Khaleghi, Esmaeel] Semnan Univ, Biotechnol Dept, Semnan, Iran.
   [Soltanizadeh, Hadi; Rahmanimanesh, Mohammad] Semnan Univ, Fac Elect & Comp Engn Dept, Semnan, Iran.
   [Gholizade, Masoume] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
   [Azadi, Farhad] Univ Social Welf & Rehabil Sci, Dept Physiotherapy, Tehran, Iran.
   [Zahraei, Mohammad] MD Orthopaed, Semnan, Iran.
C3 Semnan University; Semnan University; Semnan University
RP Soltanizadeh, H (corresponding author), Semnan Univ, Fac Elect & Comp Engn Dept, Semnan, Iran.
EM eskhaleghi2879@gmail.com; h_soltanizadeh@semnan.ac.ir;
   masoume_gholizade@semnan.ac.ir; fa.azadi@uswr.ac.ir;
   mhdzahrayee@yahoo.com; rahmanimanesh@semnan.ac.ir
RI Gholizade, Masoume/JDW-7531-2023; Soltanizadeh, Hadi/AAH-1840-2019
OI Soltanizadeh, Hadi/0000-0002-2210-675X; Gholizade,
   Masoume/0000-0002-5221-8197
CR Ahmadi M, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0456-x
   Alabbasi H, 2015, E-HEALTH BIOENG CONF
   Alexander NB, 2005, CLEV CLIN J MED, V72, P586, DOI 10.3949/ccjm.72.7.586
   Baker JM, 2018, AM J MED, V131, P602, DOI 10.1016/j.amjmed.2017.11.051
   Bari ASMH, 2019, IEEE ACCESS, V7, P162708, DOI 10.1109/ACCESS.2019.2952065
   DesJardins AM, 2016, TECHNOL HEALTH CARE, V24, P843, DOI 10.3233/THC-161232
   Ebersbach G, 2000, MOVEMENT DISORD, V15, P1145, DOI 10.1002/1531-8257(200011)15:6<1145::AID-MDS1013>3.0.CO;2-C
   Eltoukhy M, 2017, GAIT POSTURE, V51, P77, DOI 10.1016/j.gaitpost.2016.10.001
   González I, 2016, J BIOMED INFORM, V62, P210, DOI 10.1016/j.jbi.2016.07.009
   Hazra S, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102512
   Huitzil I, 2019, INT J APPROX REASON, V113, P354, DOI 10.1016/j.ijar.2019.07.012
   Iwama Y, 2018, OSTEOARTHR CARTILAGE, V26, pS385, DOI 10.1016/j.joca.2018.02.753
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Li S, 2016, PEERJ, V4, DOI 10.7717/peerj.2364
   Liu HB, 2014, INFORM SCIENCES, V258, P220, DOI 10.1016/j.ins.2013.07.027
   Mahlknecht P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069627
   Marino FR, 2019, J AM HEART ASSOC, V8, DOI 10.1161/JAHA.119.013212
   Pfitscher M, 2019, INTELIGENCIA ARTIFIC, V22, P121, DOI 10.4114/intartf.vol22iss63pp121-134
   Pirker W, 2017, WIEN KLIN WOCHENSCHR, V129, P81, DOI 10.1007/s00508-016-1096-4
   Pua YH, 2020, KNEE SURG SPORT TR A, V28, P3207, DOI 10.1007/s00167-019-05822-7
   Schneider B, 2018, STUD COMPUT INTELL, V730, P355, DOI 10.1007/978-3-319-63754-9_16
   Sun B, 2018, IEEE SENS J, V18, P7305, DOI 10.1109/JSEN.2018.2839732
   Tupa O, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0092-7
   Wang NF, 2020, LECT NOTES ARTIF INT, V12595, P489, DOI 10.1007/978-3-030-66645-3_41
   Xu X, 2015, GAIT POSTURE, V42, P145, DOI 10.1016/j.gaitpost.2015.05.002
NR 25
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27969
EP 27989
DI 10.1007/s11042-021-11750-x
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100002
DA 2024-07-18
ER

PT J
AU Maldonado-Mendez, C
   Hernandez-Mendez, S
   Torres-Muñoz, D
   Hernandez-Mejia, C
AF Maldonado-Mendez, Carolina
   Hernandez-Mendez, Sergio
   Torres-Munoz, Delia
   Hernandez-Mejia, Carlos
TI Fall detection using features extracted from skeletal joints and SVM:
   Preliminary results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall recognition; Genetic algorithm; Kinect; Skeletal joints; Support
   vector machine; Visual information
ID SYSTEM
AB In this work we are interested in detecting fall from a non-fall event by means of visual information. A non-fall event can be an activity of daily living (ADL) such as when a person is sitting, walking, lying on the floor, picking up an object. We propose a fall detection system based on a set of visual features, which captures the following information: whether the person is in balance, is close to the ground, the dispersion of joint heights and their change in a time window. The feature set is computed from the joint data provided by the Kinect. The sequences performed by the odd subjects from the TST Fall detection v2 dataset are used to generate the classifier, which is a support vector machine (SVM). This database provides the position of the skeletal joints for actions such as ADL and 4 types of falls. Subsequently, the proposed system is validated with the sequences executed by the even subjects from the TST v2 fall detection dataset and the other two publicly available 3D action datasets. The obtained recognition accuracy is respectively 89.5%, 97.2% and 96%. The experimental results show that the captured features are useful to detect the fall in datasets that are first seen by the classifier.
C1 [Maldonado-Mendez, Carolina] Univ Xalapa, Escuela Ingn, Xalapa, Veracruz, Mexico.
   [Hernandez-Mendez, Sergio] Univ Veracruzana, Artificial Intelligence Res Inst, Xalapa, Veracruz, Mexico.
   [Torres-Munoz, Delia] Tecnol Super San Martin Texmelucan, Puebla, Mexico.
   [Hernandez-Mejia, Carlos] Inst Tecnol Super Misantla, Ciencias Ingn, Misantla, Ver, Mexico.
C3 Universidad Veracruzana
RP Maldonado-Mendez, C (corresponding author), Univ Xalapa, Escuela Ingn, Xalapa, Veracruz, Mexico.
EM ux99979989@ux.edu.mx; sergihernandez@uv.mx; deletsm@gmail.com;
   cmahernandez@gmail.com
RI Hernández Mejía, Carlos Manuel/JAX-9935-2023
OI Hernández Mejía, Carlos Manuel/0000-0003-2481-8723; Maldonado-Mendez,
   Carolina/0000-0002-9441-2633
CR Agahian S, 2019, VISUAL COMPUT, V35, P591, DOI 10.1007/s00371-018-1489-7
   [Anonymous], 2008, WHO global report on falls prevention in older age
   Baskoro AS, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P335, DOI 10.1109/ELECSYM.2016.7861027
   Cai W, 2020, INT CONF AWARE SCI, DOI 10.1109/ICAST51195.2020.9319493
   Cameron R, 2018, ADV INTELL SYST COMP, V650, P276, DOI 10.1007/978-3-319-66939-7_24
   Chatzaki C, 2017, COMM COM INF SC, V736, P100, DOI 10.1007/978-3-319-62704-5_7
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Dekker M.H. P., 2009, Zero-moment point method for stable biped walking
   Gasparrini S, 2016, ADV INTELL SYST, V399, P99, DOI 10.1007/978-3-319-25733-4_11
   Goldberg D., 2002, DESIGN INNOVATION LE, V7
   Gutiérrez J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030947
   Hadjadji B, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103375
   Hernandez-Mendez S., 2017, ELECTR COMMUN, P1
   Htoo CK, 2019, 17 INT C COMP APPL I
   Kepski M, 2018, IET COMPUT VIS, V12, P48, DOI 10.1049/iet-cvi.2017.0119
   Keskes O, 2021, IEEE ACCESS, V9, P28224, DOI 10.1109/ACCESS.2021.3058219
   Maldonado-Mendez  C., 2017, POW EL COMP ROPEC 20, P1
   Maldonado-Mendez C, 2019, 2019 IEEE INT C ENG, V1, P1
   Merrouche F, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P586, DOI 10.1109/SIPROCESS.2016.7888330
   Min WD, 2018, IET COMPUT VIS, V12, P1133, DOI 10.1049/iet-cvi.2018.5324
   Qin Y, 2020, VISUAL COMPUT, V36, P621, DOI 10.1007/s00371-019-01644-3
   REN L, 2019, IEEE ACCESS, V7
   Sardain P, 2004, IEEE T SYST MAN CY A, V34, P630, DOI 10.1109/TSMCA.2004.832811
   Seredin OS, 2019, INT ARCH PHOTOGRAMM, V42-2, P189, DOI 10.5194/isprs-archives-XLII-2-W12-189-2019
   Simon, 2012, PRINCE COMPUTER VISI
   Sucerquia A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010198
   Sun X, 2021, J SENSORS, V2021, DOI 10.1155/2021/6232968
   Valcourt L, 2016, IEEE LAT AM T, V14, P1011, DOI 10.1109/TLA.2016.7437252
   Wilmart R, 2014, COMPUTATION SAFETY Z
   Xu YF, 2019, CHIN CONTR CONF, P8488, DOI [10.23919/chicc.2019.8865732, 10.23919/ChiCC.2019.8865732]
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao LY, 2019, TEH VJESN, V26, P1363, DOI 10.17559/TV-20190411015902
   Yu XG, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P42, DOI 10.1109/HEALTH.2008.4600107
   Zhang J, 2017, FRONT INFORM TECH EL, V18, P1002, DOI 10.1631/FITEE.1601401
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
NR 38
TC 1
Z9 1
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27657
EP 27681
DI 10.1007/s11042-022-12405-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800014
DA 2024-07-18
ER

PT J
AU Rani, JSJ
   Augasta, MG
AF Rani, J. Stella Janci
   Augasta, M. Gethsiyal
TI Human re-identification by local maximal occurrence of color and
   scale-Invariant Channel integrated statistical pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human; person re-identification; Feature extraction; Metric learning;
   Handcrafted features; Deep features
ID PERSON REIDENTIFICATION; PEDESTRIAN RECOGNITION; CLASSIFICATION;
   FEATURES
AB Feature representation and metric learning are the two major components in human re-identification. An effective feature representation has to be robust to illumination and viewpoint changes. In this paper, for achieving robustness towards illumination changes and image noises, a new feature extraction method called CHannel integrated LOcal Maximal Occurrence (CHLOMO) is proposed by introducing a new operator namely Scale Invariant Channel Integrated Statistical Pattern (SICISP) with the improved Scale Invariant Local Ternary pattern (SILTP) which was constructed using gray texture only. In this proposed model, initially, SICISP is constructed from two kinds of patterns of each color channel which is well established for its invariant color texture description of illumination. Then, the statistical texture feature representation along with HSV colour representation is used to produce the CHannel Integrated LOcal Maximum Occurrence features in terms of the min-max fusion process. Finally, the Cross-view Quadratic Discriminant Analysis (XQDA) similarity metric algorithm has been used to learn the extracted features and to re-identify an individual. The performance of the proposed method is demonstrated in terms of better feature representation with enhanced accuracy of human re-identification by implementing it on the challenging small-scale & large-scale human re-identification datasets such as VIPeR, Market1501, and CUHK03.
C1 [Rani, J. Stella Janci] Manonmaniam Sundaranar Univ, Tirunelveli, Tamil Nadu, India.
   [Augasta, M. Gethsiyal] Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Rani, JSJ (corresponding author), Manonmaniam Sundaranar Univ, Tirunelveli, Tamil Nadu, India.
EM jstellajara17@gmail.com; augastaglady@gmail.com
RI J, STELLA JANCI RANI/HJH-0349-2022; M, Gethsiyal Augasta/AAS-2164-2020
OI J, STELLA JANCI RANI/0000-0002-9381-9482; M, Gethsiyal
   Augasta/0000-0002-1975-7623
CR Alipanahi B, 2008, INT C ART INT, P2
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2007, P IEEE INT WORKSH PE
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Chen JX, 2017, PROC CVPR IEEE, P5330, DOI 10.1109/CVPR.2017.566
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cong Y, 2015, IEEE T CIRC SYST VID, V25, P922, DOI 10.1109/TCSVT.2014.2355692
   Davis J. V., 2007, ICML, P209
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hastie T., 2009, ELEMENTS STAT LEARNI, V2, P1, DOI [DOI 10.1007/978-0-387-84858-7, https://doi.org/10.1007/978-0-387-84858-7]
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Johnson DM, 2016, IEEE T KNOWL DATA EN, V28, P1035, DOI 10.1109/TKDE.2015.2507130
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao S., 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, P1301, DOI DOI 10.1109/CVPR.2010.5539817
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu FY, 2019, IEEE I CONF COMP VIS, P6638, DOI 10.1109/ICCV.2019.00674
   Liu Y, 2012, INT CONF INTELL SYST, P884, DOI 10.1109/ISDA.2012.6416655
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Rani JSJ, 2020, TEST ENG MANAGEMENT
   Rassem TH, 2014, SCI WORLD J, DOI 10.1155/2014/373254
   Ren CX, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106995
   Shi H, 2015, ARXIV PREPRINT ARXIV
   Song MY, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P675, DOI 10.1109/CISP.2015.7407963
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wood R, 2012, P 5 INT C BIO INSP S
   Wu L, 2016, ARXIV160107255V2
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou K, 2021, INT J ADV MANUF TECH, V115, P1005, DOI 10.1007/s00170-021-07253-6
   2014, ADV COMPUT VIS PATT, P1
NR 56
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26035
EP 26059
DI 10.1007/s11042-022-12888-y
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100007
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Yan, LJ
AF Zhang, Yanhu
   Yan, Lijuan
TI A fast face recognition based on image gradient compensation for feature
   description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient; Image gradient; Image gradient compensation; Face recognition;
   Principal component analysis; Support vector machine
ID INDEPENDENT COMPONENT ANALYSIS; CLASSIFICATION; EIGENFACES; ALGORITHM;
   PATTERNS
AB To improve the efficiency of traditional face recognition techniques, this paper proposes a novel face recognition algorithm called Image Gradient Feature Compensation (IGFC). Based on the gradients along four directions in an image, a fusion algorithm and a compensation method are implemented to obtain features of the original image. In this study, gradient magnitude maps of a face image are calculated along four directions. Fusion gradients and differential fusion gradients are produced by fusing the four gradient magnitude maps of a face image in multiple ways, and they are used as compensation variables to compensate the appropriate coefficients on the original image and build IGFC feature maps of the original face image. Subsequently, IGFC feature maps are divided into several blocks to calculate the concatenated histogram over all blocks, which is in turn utilized as the feature descriptor for face recognition. Principal component analysis (PCA) is used to cut down the number of dimensions in high-dimensional features, which are recognized by the Support Vector Machine (SVM) classifier. Finally, the proposed IGFC method is superior to traditional methods as suggested by verification studies on YALE, ORL, CMU_PIE, and FERET face databases. When the LibSVM parameter was set to '-s 0 -t 2 -c 16 -g 0.0009765625', the algorithm achieved 100% recognition on Yale and ORL data sets, 92.16% on CMU_PIE data sets, and 74.3% on FERET data sets. The average time for simultaneous completion of the data sets examined was 1.93 s, and the algorithm demonstrated a 70.71% higher running efficiency than the CLBP algorithm. Therefore, the proposed algorithm is highly efficient in feature recognition with excellent computational efficiency.
C1 [Zhang, Yanhu; Yan, Lijuan] Guangdong Songshan Polytech, Sch Comp & Informat Engn, Shaoguan 512126, Guangdong, Peoples R China.
   [Zhang, Yanhu] Jose Rizal Univ, 1550 Mandaluyong, Manila, Philippines.
C3 Jose Rizal University
RP Yan, LJ (corresponding author), Guangdong Songshan Polytech, Sch Comp & Informat Engn, Shaoguan 512126, Guangdong, Peoples R China.
EM forzyh@163.com; juanjanny@qq.com
FU Characteristic Innovation Research Fund for Universities of Guangdong
   Province [2019GKTSCX041]; Science and Technology Program of Shaoguan
   [2018SN041]
FX This work was supported by Characteristic Innovation Research Fund for
   Universities of Guangdong Province(No.2019GKTSCX041) and Science and
   Technology Program of Shaoguan(No.2018SN041).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Bo F., 2019, COMPUT APPL SOFTW, V36, P209
   Cai Y, 2019, NEUROCOMPUTING, V363, P375, DOI 10.1016/j.neucom.2019.07.047
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZX, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421520054
   Chu YJ, 2019, VISUAL COMPUT, V35, P239, DOI 10.1007/s00371-017-1468-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Déniz O, 2003, PATTERN RECOGN LETT, V24, P2153, DOI 10.1016/S0167-8655(03)00081-3
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Fang SS, 2018, MULTIMED TOOLS APPL, V77, P2807, DOI 10.1007/s11042-017-4412-8
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Kim J, 2020, IEEE ACCESS, V8, P80948, DOI 10.1109/ACCESS.2020.2991255
   Bao LN, 2016, ADV INTELL SYST, V435, P287, DOI 10.1007/978-81-322-2757-1_29
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Bui L, 2011, LECT NOTES COMPUT SC, V6881, P436, DOI 10.1007/978-3-642-23851-2_45
   [李宽 Li Kuan], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P777
   Li Q., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   [宁欣 Ning Xin], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P2623
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Qu XJ, 2018, INT SYM COMPUT INTEL, P289, DOI 10.1109/ISCID.2018.00072
   Ramaiah NP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, INFORMATICS, COMMUNICATION AND ENERGY SYSTEMS (SPICES)
   Singh G, 2018, J INF TECHNOL RES, V11, P91, DOI 10.4018/JITR.2018010106
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Tang ZJ, 2018, APPL MATH COMPUT, V321, P721, DOI 10.1016/j.amc.2017.11.017
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan Yuan, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P640
   [王宪 Wang Xian], 2012, [光电工程, Opto-Electronic Engineering], V39, P109
   Yang Huixian, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P130
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang S., 2017, J COMPUT AIDED COMPU, V29, P1668
   Yang Zhao-xia, 2002, Acta Scientiarum Naturalium Universitatis Sunyatseni, V41, P6
   Zhang Bei, 2015, Computer Engineering and Design, V36, P778, DOI 10.16208/j.issn1000-7024.2015.03.043
   [张洁玉 Zhang Jieyu], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1327
NR 46
TC 7
Z9 8
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26015
EP 26034
DI 10.1007/s11042-022-12804-4
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100012
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, HS
   Cho, SI
AF Lee, Ho Sub
   Cho, Sung In
TI Spatial color histogram-based image segmentation using texture-aware
   region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Image processing; Image segmentation; Spatial-color
   histograms; Region merging
ID MEAN-SHIFT; SUPERPIXELS; ALGORITHM
AB We propose a new image segmentation method using spatial-color histograms that include the color and spatial information of a given image. Previous methods used a histogram with only the color information of the image or did not effectively suppress the texture components of the same object to form segmented regions, and they frequently led to the false merging of two different regions. Thus, these methods caused an over-segmentation result in the same object or an under-segmentation result in the regional boundary between two different objects. To resolve these problems, the proposed method performs a clustering that considers both color and spatial information of the image in the histogram domain and texture-aware region merging. Moreover, using a total variation-based regularizer that can remove the texture components in the same object and preserve the edge components between different objects, we improve the accuracy of region merging process that is applied to the result of the proposed histogram-based segmentation. Compared to the best results obtained using previous histogram-based methods, the proposed method achieved improvements of 0.02335 (2.910%), 0.0195 (3.977%), 0.05515 (2.431%), and 0.9639 (9.250%) in probability rand index, segmentation covering, variation of information, and boundary displacement error, which are the most widely used for segmentation evaluation metrics, respectively. Further, when compared to the state-of-the-art methods, which use the superpixel, iterative contraction and merging, and deep learning-based methods, the proposed method provides promising segmentation quality with fast operation speed.
C1 [Lee, Ho Sub] Daegu Univ, Dept Elect Engn, Gyeonsan 38453, South Korea.
   [Cho, Sung In] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
C3 Daegu University; Dongguk University
RP Cho, SI (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
EM hslee34@daegu.ac.kr; csi2267@dongguk.edu
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2020R1G1A1102163]
FX This research was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2020R1G1A1102163).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chen TW, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P324, DOI 10.1109/MMSP.2008.4665097
   Cheng CC, 2010, IEEE T CONSUM ELECTR, V56, P1739, DOI 10.1109/TCE.2010.5606320
   Cho H, 2014, IEEE T CONSUM ELECTR, V60, P719, DOI 10.1109/TCE.2014.7027348
   Cho SI, 2014, IET IMAGE PROCESS, V8, P761, DOI 10.1049/iet-ipr.2013.0602
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550
   Cour T, 2005, PROC CVPR IEEE, P1124
   DEREFELDT G, 1995, DISPLAYS, V16, P69, DOI 10.1016/0141-9382(95)91176-3
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Fu X, 2015, IEEE I CONF COMP VIS, P1618, DOI 10.1109/ICCV.2015.189
   Gass T, 2014, IEEE T IMAGE PROCESS, V23, P2931, DOI 10.1109/TIP.2014.2322447
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   He LF, 2009, PATTERN RECOGN, V42, P1977, DOI 10.1016/j.patcog.2008.10.013
   Heidrich Wolfgang, ERIK REINHARD
   Hill B, 1997, ACM T GRAPHIC, V16, P109, DOI 10.1145/248210.248212
   Jeong SG, 2013, IEEE T IMAGE PROCESS, V22, P4497, DOI 10.1109/TIP.2013.2274731
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Kang SJ, 2015, J DISP TECHNOL, V11, P399, DOI 10.1109/JDT.2015.2416171
   Kim S., 2011, Advances in Neural Information Processing Systems 24 (NIPS), P1530
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Malcolm J, 2007, IEEE IMAGE PROC, P2061
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI DOI 10.1145/1102351.1102424
   Mezaris V, 2004, INT J PATTERN RECOGN, V18, P701, DOI 10.1142/S0218001404003393
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi Zhao, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P258
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Syu JH, 2017, IEEE T IMAGE PROCESS, V26, P2246, DOI 10.1109/TIP.2017.2651395
   Tan KS, 2013, APPL SOFT COMPUT, V13, P2017, DOI 10.1016/j.asoc.2012.11.038
   Tan KS, 2013, APPL SOFT COMPUT, V13, P1832, DOI 10.1016/j.asoc.2012.12.022
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
NR 45
TC 2
Z9 2
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24573
EP 24600
DI 10.1007/s11042-022-11983-4
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200003
DA 2024-07-18
ER

PT J
AU Mohapatra, S
   Satpathy, S
   Mohanty, SN
AF Mohapatra, Subhasish
   Satpathy, Suneeta
   Mohanty, Sachi Nandan
TI A comparative knowledge base development for cancerous cell detection
   based on deep learning and fuzzy computer vision approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FCVT; AI; Cancer image analysis; Diagnosis
ID LOGIC
AB Cancer was once thought to be a chronic fatal disease, but now it is proven to be a myth. This is due to rapid advancements in artificial intelligence (AI) techniques used to detect cancer early by collecting symptoms or analysing cancer images. Various research projects are underway to automate early cancer detection and display a perfect diagnosis plan using AI. Since early accurate diagnosis and detection of cancer disease can increase the survival rate, the present research study aims to build a model equipped with both deep learning and FCVT techniques, so that a comparative analysis between both the techniques for cancer image analysis can be done for deriving the best approximate result before the final decision is taken by the healthcare professionals. The model proposed for analysis is also tested on a standard dataset of cancer cell images and showed 95% accuracy. Hence the present study is done with a hope to design the models so that it can act as an augmentation tool to the existing healthcare facility for cancer disease forecasting and assist clinical oncology domain.
C1 [Mohapatra, Subhasish] Adamas Univ, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
   [Satpathy, Suneeta] Sri Sri Univ, Fac Emerging Technol, Cuttack, Odisha, India.
   [Mohanty, Sachi Nandan] Vardhaman Coll Engn Autonomous, Dept Comp Sci & Engn, Hyderabad, India.
C3 Vardhaman College of Engineering
RP Mohapatra, S (corresponding author), Adamas Univ, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
EM mohapatra.subhasish@gmail.com; suneeta1912@gmail.com;
   sachinandan09@gmail.com
RI satpathy, suneeta/AAL-4332-2021; Mohapatra, Subhasish/AFA-3351-2022
OI Mohapatra, Subhasish/0000-0003-1319-8100; satpathy,
   suneeta/0000-0002-6943-171X; Nandan Mohanty,
   Dr.Sachi/0000-0002-4939-0797
CR Alshennawy A.A., 2009, Int. J. Comput. Inform. Eng., V3, P540
   [Anonymous], 2012, INTRO FUZZY LOGIC AP
   [Anonymous], 2012, INT J CURR RES
   Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Banerjee S, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080577
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   BORGLUND M, 1988, SCAND J CLIN LAB INV, V48, P27, DOI 10.3109/00365518809085390
   CHEN YH, 1995, OPT LASER ENG, V22, P181, DOI 10.1016/0143-8166(94)00045-C
   Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3
   Debelee TG, 2020, J IMAGING, V6, DOI 10.3390/jimaging6110121
   Dhanaseelan FR, 2021, INT J INF RETR RES, V11, P36, DOI 10.4018/IJIRR.2021010102
   Farooq M.S., 2018, Lahore Garrison University Research Journal of Computer Science and Information Technology, Vol, V2, P57
   Genovese G, 2014, NEW ENGL J MED, V371, P2477, DOI 10.1056/NEJMoa1409405
   Jaleel JA., 2013, INT J ENG INNOVATIVE, V3, P311
   Jindal N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103464
   Kadampur Mohammad Ali, 2020, Informatics in Medicine Unlocked, V18, P119, DOI 10.1016/j.imu.2019.100282
   Kumar SP, 2021, IOP C SER MAT SCI EN, V1022
   Mohapatra S., 2010, 2010 International Conference on Industrial Electronics, Control and Robotics (IECR), P215, DOI 10.1109/IECR.2010.5720171
   Mzurikwao D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76670-6
   Nikita BK, 2020, INT J SCI TECHNOL RE, V9
   Pham TD, 2019, IEEE-CAA J AUTOMATIC, V6, P1306, DOI 10.1109/JAS.2019.1911774
   Putzu L, 2013, PROCEEDINGS IWBBIO 2013: INTERNATIONAL WORK-CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, P99
   Scrobota I, 2017, IRAN J PUBLIC HEALTH, V46, P612
   Shemona JS, 2020, IET IMAGE PROCESS, V14, P1726, DOI 10.1049/iet-ipr.2019.1067
   Srivastava S, 2020, INT J SYST ASSUR ENG, V11, P350, DOI 10.1007/s13198-019-00863-0
   TAHANI H, 1990, IEEE T SYST MAN CYB, V20, P733, DOI 10.1109/21.57289
   van Ooijen H, 2018, AM J PATHOL, V188, P1956, DOI 10.1016/j.ajpath.2018.05.020
   Venet D, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002240
   Zareiforoush H, 2016, COMPUT ELECTRON AGR, V124, P14, DOI 10.1016/j.compag.2016.01.024
NR 29
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24799
EP 24814
DI 10.1007/s11042-022-12824-0
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200008
DA 2024-07-18
ER

PT J
AU AboElenein, NM
   Songhao, P
   Afifi, A
AF AboElenein, Nagwa M.
   Songhao, Piao
   Afifi, Ahmed
TI IRDNU-Net: Inception residual dense nested u-net for brain tumor
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; U-Net; Residual module; Inception; BraTS challenge;
   DenseNet
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Accurate segmentation of brain tumors is an essential stage in treatment planning. Fully convolutional neural networks, specifically the encoder-decoder architectures such as U-net, have proven successful in medical image segmentation. However, segmenting brain tumors with complex structure requires building a deeper and wider model which increases the computational complexity and may also cause the gradient vanishing problem. Therefore, in this work, we propose a novel encoder-decoder architecture, called Inception Residual Dense Nested U-Net (IRDNU-Net). In this model carefully designed Residual and Inception modules are used in place of standard U-Net convolutional layers to increase the width of the model without increasing the computational complexity. Additionally, in the proposed architecture, the encoder and decoder are connected via a sequence of Inception-Residual densely nested paths to extract more information and increase the depth of the network while reducing the number of network parameters. The proposed segmentation architecture was evaluated on two large brain tumor segmentation benchmark datasets; the BraTS'2019 and BraTS'2020. It achieved a mean Dice similarity coefficient of 0.888 for the whole tumor region, 0.876 for the core region, and 0.819 for the enhancement region. Experimental results illuminate that IRDNU-Net outperforms U-Net by 1.8%, 11.4%, and 11.7% in the whole tumor, core tumor, and enhancing tumor, respectively. Moreover, the IRDNU-Net enables a great improvement on the accuracy compared to comparative approaches, and its ability in the face of challenging problems, such as small tumor regions, with fewer parameters.
C1 [AboElenein, Nagwa M.; Songhao, Piao] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [AboElenein, Nagwa M.; Afifi, Ahmed] Menoufia Univ, Fac Comp & Informat, Menoufia 32511, Egypt.
   [Afifi, Ahmed] King Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 400, Al Hasa 31982, Saudi Arabia.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University; King Faisal University
RP Songhao, P (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM nagwa.saliml@hit.edu.cn; piaosh@hit.edu.cn; aafifi@kfu.edu.sa
OI /0000-0002-5485-3012
CR Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Ahmad P, 2019, International MICCAI Brainlesion Workshop, P158
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Cahall DE, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00044
   Chandra S, 2019, LECT NOTES COMPUT SC, V11384, P299, DOI 10.1007/978-3-030-11726-9_27
   Chen W, 2019, LECT NOTES COMPUT SC, V11384, P358, DOI 10.1007/978-3-030-11726-9_32
   Cheng XC, 2020, LECT NOTES COMPUT SC, V11992, P242, DOI 10.1007/978-3-030-46640-4_23
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He HL, 2021, FRONT MOL BIOSCI, V8, DOI 10.3389/fmolb.2021.614174
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Hu Y, 2018, LECT NOTES COMPUT SC, V10670, P423, DOI 10.1007/978-3-319-75238-9_36
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kermi A, 2019, LECT NOTES COMPUT SC, V11384, P37, DOI 10.1007/978-3-030-11726-9_4
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar Munish, 2020, ACM Digital Government: Research and Practice, V1, DOI 10.1145/3411760
   Li HC, 2019, COMPUT BIOL MED, V108, P150, DOI 10.1016/j.compbiomed.2019.03.014
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   Lou AG, 2021, PROC SPIE, V11596, DOI 10.1117/12.2582338
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Miranda-Filho A, 2017, NEURO-ONCOLOGY, V19, P270, DOI 10.1093/neuonc/now166
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhou CH, 2020, IEEE T IMAGE PROCESS, V29, P4516, DOI 10.1109/TIP.2020.2973510
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 40
TC 4
Z9 4
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24041
EP 24057
DI 10.1007/s11042-022-12586-9
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000018
DA 2024-07-18
ER

PT J
AU Bao, H
   Shu, P
   Wang, QJ
AF Bao, Hua
   Shu, Ping
   Wang, Qijun
TI Accurate visual representation learning for single object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Visual representation; Visual tracking
ID CORRELATION FILTERS
AB As a fundamental visual task, single object tracking has witnessed astonishing improvements. However, there still existing many factors should be to addressed for accurately tracking performance. Among them, visual representation is one of important influencers suffer from complex appearance changes. In this work, we propose a rich appearance representation learning strategy for tracking. First, by embedding the saliency feature extractor module, we try to improve the visual representation ability by fusing the saliency information learning from different convolution lays. With leveraging lightweight Convolutional Neural Network VGG-M as the features extractor backbone, we can attain robust appearance model by deep features with fruitful semantic information. Second, as for the classifier has significant complementary guidance for location prediction, we propose to generate diverse feature instances of the target by introducing the adversarial learning strategy. Given the generated diverse instances, many complex situations in the tracking process can be effectively simulated, especially the occlusion that conformed to the long tail distribution. Third, to optimize the bounding boxes refinement, we employ a precise pooling strategy for attaining feature maps with high resolution. Then, our approach can capture the subtle appearance changes effectively over a long time range. Finally, extensive experiments was conducted on several benchmark datasets, the results demonstrate that the proposed approach performs favorably against many state-of-the-art algorithms.
C1 [Bao, Hua; Shu, Ping] Anhui Univ, Sch Elect Engn & Automat, Hefei 230601, Peoples R China.
   [Bao, Hua; Shu, Ping; Wang, Qijun] Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
   [Wang, Qijun] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
C3 Anhui University; Anhui University
RP Wang, QJ (corresponding author), Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.; Wang, QJ (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
EM baohua@ahu.edu.cn; shuping@stu.ahu.edu.cn; wangqijun308@163.com
RI wang, qi/HTN-8786-2023; wang, qi/IAN-4150-2023; wang, qi/ITT-9652-2023
OI wang, qi/0000-0002-2794-6897; 
FU Provincial Natural Science Foundation of AnHui [1908085MF217]; Anhui
   Provincial Education Department Fund [KJ2019A0022]
FX This document is the results of the research project funded by
   Provincial Natural Science Foundation of AnHui(No. 1908085MF217), and
   the Anhui Provincial Education Department Fund (No. KJ2019A0022).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen BY, 2018, LECT NOTES COMPUT SC, V11211, P328, DOI 10.1007/978-3-030-01234-2_20
   Chen P, 2019, IEICE T INF SYST, VE102D, P2067, DOI 10.1587/transinf.2018EDL8239
   Chen X., 2020, P P IEEECVF C COMPUT, P10176
   Cheng X, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00535-1
   Chu LT, 2019, IEEE INT CONF INDUST, P893, DOI 10.1109/ICIT.2019.8755125
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Held D, 2018, P EUROPEAN C COMPUTE, P749
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu HW, 2019, IEEE T MULTIMEDIA, V21, P510, DOI 10.1109/TMM.2018.2859831
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Ma B, 2018, IEEE T NEUR NET LEAR, V29, P4769, DOI 10.1109/TNNLS.2017.2776124
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ning X, 2018, LECT NOTES COMPUT SC, V11306, P441, DOI 10.1007/978-3-030-04224-0_38
   Pu S., 2018, ADV NEURAL INFORM PR, V31, P1931, DOI DOI 10.1016/J.PATCOG.2018.10.005
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Sun YX, 2019, PROC CVPR IEEE, P5776, DOI 10.1109/CVPR.2019.00593
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang JX, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01750-4
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 67
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24059
EP 24079
DI 10.1007/s11042-021-11736-9
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000001
DA 2024-07-18
ER

PT J
AU Khan, AA
   Shaikh, AA
   Shaikh, ZA
   Laghari, AA
   Karim, S
AF Khan, Abdullah Ayub
   Shaikh, Aftab Ahmed
   Shaikh, Zaffar Ahmed
   Laghari, Asif Ali
   Karim, Shahid
TI IPM-Model: AI and metaheuristic-enabled face recognition using image
   partial matching for multimedia forensics investigation with genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial Intelligence (AI); Metaheuristic; Image Processing and
   Recognition; Partial image matching; Principal component analysis (PCA);
   Artificial neural networks (ANN); Digital Forensics Investigation
AB The rapid enhancement in the development of information technology has driven the development of human facial image recognition. Recently, facial recognition has been successfully applied in several distinct domains with the help of computing and information technology. This kind of application plays a significant role in the process of digital forensics investigation, recognizing the patterns of a human face based on the partial matching of images that would be in 24-bit color image format, including the spacing of the eyes, the bridging of the nose, the contour of the lips, ears, and chin. In this paper, we have proposed and implemented an image recognition model based on principal component analysis, genetic algorithms, and neural networks, in which PCA reduces the dimension of the benchmark dataset, while genetic algorithms and neural nets optimize the searching patterns of image matching and provide highly efficient output with a minimal amount of time. Through the experiment results on the human facial images dataset of the Georgia Institute of Technology, the overall match showed that the proposed model can achieve the recognition of human face images with an accuracy rate of 93.7%. Moreover, this model helps to examine, analyze, and detect individuals by partial matching with reidentification in the procedure of forensics investigation. The experimental result shows the robustness of the proposed model in terms of efficiency compared to other state-of-the-art methods.
C1 [Khan, Abdullah Ayub; Shaikh, Aftab Ahmed; Laghari, Asif Ali] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi 74000, Sindh, Pakistan.
   [Khan, Abdullah Ayub; Shaikh, Zaffar Ahmed] Benazir Bhutto Shaheed Univ, Fac Comp Sci & Informat Technol, Karachi 75660, Pakistan.
   [Karim, Shahid] Ilma Univ, Dept Comp Sci, Karachi, Sindh, Pakistan.
RP Laghari, AA (corresponding author), Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi 74000, Sindh, Pakistan.
EM asif.laghari@smiu.edu.pk
RI Laghari, Asif Ali/AAF-5893-2020; Khan, Abdullah Ayub/ABF-7133-2021;
   Karim, Shahid/AAO-1087-2020; Shaikh, Zaffar Ahmed/D-3954-2012
OI Laghari, Asif Ali/0000-0001-5831-5943; Khan, Abdullah
   Ayub/0000-0003-2838-7641; Karim, Shahid/0000-0001-9986-5052; Shaikh,
   Zaffar Ahmed/0000-0003-0323-2061
CR Abdullah NA, 2017, AIP CONF PROC, V1891, DOI [10.1063/1.5005335, 10.1063/.5005335]
   Alsmadi MK, 2017, FACE IMAGE RECOGNITI
   [Anonymous], 2014, 2014 INT C ELECT ENG
   Arnes A., 2017, Digital Forensics
   Bastanfard A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P50
   Bhatele K, 2020, HDB RES MULTIMEDIA C, P165
   Bowyer KW, 2016, HANDBOOKOF IRIS RECO
   Casey E, 2010, HANDBOOK OF DIGITAL FORENSICS AND INVESTIGATION, P1
   Chelali FZ, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P17, DOI 10.1109/SOCPAR.2014.7007975
   Darwin C., 2018, On the Origin of Species: Or; The Preservation of the Favoured Races in the Struggle for Life
   Gilani SZ, 2017, PATTERN RECOGN, V69, P238, DOI 10.1016/j.patcog.2017.04.013
   Greiff S, 2015, THINK REASONING, V21, P356, DOI 10.1080/13546783.2014.989263
   Gupta P, 2019, NEUROCOMPUTING, V335, P352, DOI 10.1016/j.neucom.2018.06.079
   Jones GM., 2017, International Journal of Computational Intelligence Research, V13, P1859
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Joshi JC., 2016, IUP Journal of Telecommunications, V8, P53
   Kasar MM, 2016, INT J SECUR APPL, V10, P81, DOI 10.14257/ijsia.2016.10.3.08
   Kent Karen, 2006, Technical Report
   Khan AA., 2022, NEUROSCIENCE INFORMA, V2, P100030, DOI 10.1016/j.neuri.2021.100030
   Khan AA, 2021, MF LEDGER BLOCKCHAIN
   Khan AA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10243083
   Khan AA, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12111525
   Khan AA, 2021, EAI ENDORSED TRANS S, V8, DOI 10.4108/eai.21-4-2021.169418
   Khan AA, 2022, IET IMAGE PROCESS, V16, P2854, DOI 10.1049/ipr2.12272
   Laghari AA, 2021, ARCH COMPUT METHOD E, V28, P3631, DOI 10.1007/s11831-020-09517-y
   Li LX, 2020, IEEE ACCESS, V8, P139110, DOI 10.1109/ACCESS.2020.3011028
   Li MJ, 2018, CLUSTER COMPUT, V21, P1117, DOI 10.1007/s10586-017-0806-7
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mehraj Haider, 2020, International Journal of Cloud Computing, V9, P131
   Mitchell RS., 2013, CARBONELL ARTIFICIAL
   Mousavi SMH, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-020-03999-y
   Narayanan NK, 2010, INT J COMPUT INT SYS, V3, P566, DOI 10.1080/18756891.2010.9727723
   Okada K, 2011, ELECTR COMMUN JPN, V94, P1, DOI 10.1002/ecj.10373
   Pal A., 2018, INT C MATH COMPUTING, P61, DOI DOI 10.1007/978-981-13-0023-37
   Roetzela W, 2019, DESIGN OPERATION HEA, V431
   Sabhanayagam T., 2018, International Journal of Applied Engineering Research, V13, P2276, DOI [10.1016/j.matpr.2021.07.005, DOI 10.1016/J.MATPR.2021.07.005]
   Sadler Matthew, 2019, Game Changer: AlphaZeros Groundbreaking Chess Strategies and the Promise of AI
   Shah NF, 2019, ADV INTELL SYST COMP, V707, P175, DOI 10.1007/978-981-10-8639-7_18
   Su Y, 2018, NEURAL PROCESS LETT, V47, P277, DOI 10.1007/s11063-017-9649-8
   Sukhija P, 2016, PROCEDIA COMPUT SCI, V85, P410, DOI 10.1016/j.procs.2016.05.183
   Zhang YS, 2020, IEEE T INF FOREN SEC, V15, P1683, DOI 10.1109/TIFS.2019.2947872
   Zhi H, 2019, J VIS COMMUN IMAGE R, V58, P495, DOI 10.1016/j.jvcir.2018.12.012
   Zhong DX, 2019, NEUROCOMPUTING, V328, P16, DOI 10.1016/j.neucom.2018.03.081
   Zhong YJ, 2020, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR42600.2020.00686
   Zhou ZL, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8040644
   Zhou ZL, 2020, IEEE TETCI, V4, P593, DOI 10.1109/TETCI.2019.2909936
NR 46
TC 24
Z9 27
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23533
EP 23549
DI 10.1007/s11042-022-12398-x
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800008
DA 2024-07-18
ER

PT J
AU Jia, LS
   Zhou, XZ
   Xue, CQ
AF Jia, Lesong
   Zhou, Xiaozhou
   Xue, Chengqi
TI Non-trajectory-based gesture recognition in human-computer interaction
   based on hand skeleton data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Skeleton data; HMM; HCI
ID INTERFACES; FEATURES
AB Currently, no efficient, accurate and flexible gesture recognition algorithm has been developed to recognize non-trajectory-based gesture recognition. Therefore, we aim to construct a gesture recognition algorithm to not only complete gesture recognition accurately and quickly but also adapt to individual differences. In this paper, we present a novel non-trajectory-based gesture recognition method (NT-GRM) based on hand skeleton information and a hidden Markov model (HMM). To recognize a static gesture, the direction information of each bone section of the hands was taken as the observation data to construct the HMM. In addition, multiple static gestures were detected in turn to identify a dynamic gesture. As determined by experimental verification, the NT-GRM can complete recognition in a system containing ten interactive gestures with a recognition accuracy of over 95% and a recognition speed of 21.73 ms. The training time required for each static gesture model is 2.56 s. And the NT-GRM can identify static and dynamic gestures accurately and quickly with small training samples in different functional modes. In conclusion, the NT-GRM can be applied to the development of gesture interaction systems to help developers realize practical functions such as gesture library construction, user gesture customization, and user gesture adaptation.
C1 [Jia, Lesong; Zhou, Xiaozhou; Xue, Chengqi] Southeast Univ, Sch Mech Engn, Nanjing 211189, Peoples R China.
C3 Southeast University - China
RP Zhou, XZ (corresponding author), Southeast Univ, Sch Mech Engn, Nanjing 211189, Peoples R China.
EM lesong@seu.edu.cn; zxz@seu.edu.cn; ipd_xcq@seu.edu.cn
OI ZHOU, XIAOZHOU/0000-0003-0370-2369
FU National Natural Science Foundation of China [71901061, 71871056];
   Science and Technology on Avionics Integration Laboratory and
   Aeronautical Science Fund [20185569008]; Fundamental Research Funds for
   the Central Universities [2242019k1G016]
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 71901061, No. 71871056), Science and Technology
   on Avionics Integration Laboratory and Aeronautical Science Fund (No.
   20185569008), Fundamental Research Funds for the Central Universities
   (No.2242019k1G016).
CR Al-Hammadi M, 2020, IEEE ACCESS, V8, P192527, DOI 10.1109/ACCESS.2020.3032140
   Ameur Safa, 2016, 2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), P514, DOI 10.1109/SETIT.2016.7939924
   Arjun AM, 2020, 2020 4 INT C COMP ME, P833, DOI [10.1109/ICCMC48092.2020.ICCMC-000154, DOI 10.1109/ICCMC48092.2020.ICCMC-000154]
   Bilmes JA, 1998, GENTLE TUTORIAL EM A, V4, P126
   Chen L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030672
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Chung WK, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P336
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P15537, DOI 10.1007/s11042-015-2505-9
   Elmezain M, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P1170
   Fok KY, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P411, DOI 10.1109/CyberC.2015.81
   Gieser Shawn N., 2015, Digital Human Modeling. Applications in Health, Safety, Ergonomics and Risk Management: Ergonomics and Health. 6th International Conference, DHM 2015, held as part of HCI International 2015. Proceedings: LNCS 9185, P144, DOI 10.1007/978-3-319-21070-4_15
   Hakonen M, 2015, BIOMED SIGNAL PROCES, V18, P334, DOI 10.1016/j.bspc.2015.02.009
   Jirak D, 2023, COGN COMPUT, V15, P1427, DOI 10.1007/s12559-020-09754-0
   Joshi A, 2017, IMAGE VISION COMPUT, V58, P86, DOI 10.1016/j.imavis.2016.06.001
   Khan F.R., 2016, Int. J. Adv. Sci. Eng. Inf. Technol, V6, P1089
   Kohlschein, 2013, CURRENT PROTOCOLS BI
   Lee AR, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105385
   Li Dong-jIe, 2014, Electric Machines and Control, V18, P87
   Liao T.L., 2020, J NETW INTELL, V5, P226
   Lien JM, 2016, ACM T GRAPHIC, V35, DOI [10.1145/2897824.2925953, 10.1145/9999997.9999999]
   Liu X, 2020, IEEE T IMAGE PROCESS, V29, P4583, DOI 10.1109/TIP.2020.2974061
   Louzir A, 2021, 2021 IEEE INT C CONS, P1, DOI [10.1109/ISCAS51556.2021.9401065, DOI 10.1109/ISCAS51556.2021.9401065]
   Lu L., 2015, J COMPUTER AIDED DES, V27, P2411
   Mantecón T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223320
   Mapari RB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P323, DOI 10.1109/ICRCICN.2015.7434258
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Nielsen M, 2003, LECT NOTES ARTIF INT, V2915, P409
   Parcheta Z, 2017, LECT NOTES COMPUT SC, V10255, P419, DOI 10.1007/978-3-319-58838-4_46
   Qin SX, 2014, J SIGNAL PROCESS SYS, V74, P47, DOI 10.1007/s11265-013-0778-7
   Rahim MA, 2020, MULTIMED TOOLS APPL, V79, P11813, DOI 10.1007/s11042-019-08448-6
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Saha S, 2017, IEEE IJCNN, P2776, DOI 10.1109/IJCNN.2017.7966198
   Schmidt T, 2014, BRAZ WORKSH COMP VIS
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Singh J. Bharath, 2021, IOP Conference Series: Materials Science and Engineering, V1012, DOI 10.1088/1757-899X/1012/1/012017
   Tornay S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6049
   Vamsikrishna KM, 2016, IEEE T BIO-MED ENG, V63, P991, DOI 10.1109/TBME.2015.2480881
   Werner C, 2020, ARCH GERONTOL GERIAT, V87, DOI 10.1016/j.archger.2019.103996
   Wu CF, 2016, COMPUTER SYSTEMS APP, P115, DOI [10.15888/j.cnki.csa.005266, DOI 10.15888/J.CNKI.CSA.005266]
   Wu HY, 2020, MULTIMED TOOLS APPL, V79, P263, DOI 10.1007/s11042-019-08075-1
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Wu YH, 2018, IEEE SENS J, V18, P8143, DOI 10.1109/JSEN.2018.2863044
   Wysoski SG, 2003, THESIS NAGOYA I TECH
   Yuan J., 2015, INT C IM PROC COMP V
   Zhang XH, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P401, DOI [10.1109/ISAI.2016.49, 10.1109/ISAI.2016.0091]
   Zhao ZF, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5004004
NR 51
TC 5
Z9 5
U1 7
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20509
EP 20539
DI 10.1007/s11042-022-12355-8
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600010
DA 2024-07-18
ER

PT J
AU Hu, YX
   Lu, WH
   Ma, MD
   Sun, QL
   Wei, JG
AF Hu, Yangxia
   Lu, Wenhuan
   Ma, Maode
   Sun, Qilong
   Wei, Jianguo
TI A semi fragile watermarking algorithm based on compressed sensing
   applied for audio tampering detection and recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Tamper detection and recovery; Compressed sensing;
   Discrete wavelet transform (DWT)
ID COPYRIGHT PROTECTION; SCHEME; RESTORATION; BLIND; AUTHENTICATION;
   SECURITY; ROBUST
AB Research on audio tampering detection and recovery plays an important role in the field of audio integrity, and authenticity certification. Generally, we use technology of fragile/semi fragile watermarking to detect and recover tampered audio. In this study, a new scheme for watermark embedding, tampering detection, and recovery is proposed. In the new scheme, we get the compressed version of original audio signal using compressed sensing technology and apply discrete wavelet transform (DWT) to each audio frame. In process of embedding, a new self-adaptive algorithm is proposed. Watermark is the quantized reference value of original framed audio signal and tampering location data, and is embedded in the region with low energy of high frequency coefficients and high energy of low frequency coefficients respectively after 2-level DWT. In process of detection, we locate tampered areas by comparing the value of generated random number and extracted watermark after XOR operation with the extracted location data. As for speech, we set a threshold to judge whether it is tampered or not. At last, we extract watermark in areas which are not damaged and get the recovered signal after decompression. Experiments and analysis show that signal after embedding has at least 5 dB higher average signal-to-noise ratio than others, and broken frames and groups can be detected exactly. When signal is destroyed by 20%, 98% of the corpus is intelligible after recovery, and even destroyed by 50%, 80% of the corpus recovered is also intelligible. Compared with other recovery algorithms, audio signal recovered by our proposal has a higher signal-to-noise ratio and a better robustness to some signal processing. When tampering rate is 50%, the average detection rate is over 93%, which indicates that our method is workable.
C1 [Hu, Yangxia; Lu, Wenhuan; Ma, Maode; Wei, Jianguo] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Sun, Qilong] Qinghai Nationalities Univ, Sch Comp Sci & Technol, Xining 810000, Peoples R China.
C3 Tianjin University; Qinghai Nationalities University
RP Wei, JG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM 15122299017@126.com
RI Ma, MMD/HLG-6791-2023; Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759
FU National Natural Science Foundation of China; Key Basic Research and
   Development of Ministry of Science and Technology [2018YFC0806802]
FX This research is supported by the National Natural Science Foundation of
   China (No.NSFC61876131), and the Key Basic Research and Development of
   Ministry of Science and Technology (No.2018YFC0806802).
CR Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Chen YF., 2016, COMP AIDED DES APPL, V56, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hu HT, 2019, IEEE ACCESS, V7, P180395, DOI 10.1109/ACCESS.2019.2958095
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Jing Wang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P206, DOI 10.1007/978-3-319-31960-5_17
   Kaur A, 2017, J INF SECUR APPL, V33, P1, DOI 10.1016/j.jisa.2016.12.003
   Khalil M, 2014, DIGIT SIGNAL PROCESS, V34, P116, DOI 10.1016/j.dsp.2014.07.009
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149
   Larbi SD, 2005, IEEE T SIGNAL PROCES, V53, P816, DOI 10.1109/TSP.2004.839899
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P12481, DOI 10.1007/s11042-016-3664-z
   Menendez-Ortiz A, 2019, J FRANKLIN I, V356, P6793, DOI 10.1016/j.jfranklin.2019.06.019
   Nair U., 2020, Iran J Comput Sci, V3, P217, DOI [10.1007/s42044-020-00059-x, DOI 10.1007/S42044-020-00059-X]
   Nishimura R, 2012, IEEE T AUDIO SPEECH, V20, P2461, DOI 10.1109/TASL.2012.2203810
   Patra B, 2012, I S INTELL SIG PROC
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Renza D, 2018, EXPERT SYST APPL, V91, P211, DOI 10.1016/j.eswa.2017.09.003
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Sarreshtedari S, 2015, IEEE-ACM T AUDIO SPE, V23, P1917, DOI 10.1109/TASLP.2015.2456431
   Shen JQ, 2017, THESIS HUAZHONG U SC, P25
   Tang X, 2015, THESIS BEIJING U POS, P32
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Wang N, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1763, DOI 10.1109/ICCT.2017.8359932
   Wang SB, 2019, SPEECH COMMUN, V112, P1, DOI 10.1016/j.specom.2019.06.004
   Yang Q, 2012, THESIS NANKAI U, P55
   Zhang Hong-bin, 2004, Acta Electronica Sinica, V32, P196
NR 37
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17729
EP 17746
DI 10.1007/s11042-022-12719-0
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900010
DA 2024-07-18
ER

EF