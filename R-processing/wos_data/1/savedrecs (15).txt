FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Ksibi, S
   Mejdoub, M
   Ben Amar, C
AF Ksibi, Salma
   Mejdoub, Mahmoud
   Ben Amar, Chokri
TI Deep salient-Gaussian Fisher vector encoding of the spatio-temporal
   trajectory structures for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep weighted encoding; Spatio-temporal
   trajectory structures; Deep spatio-temporal appearance descriptor; Deep
   CNN
ID DESCRIPTORS
AB In this paper, we propose a deep spatio-temporal appearance (DSTA) descriptor for person re-identification (re-ID). The proposed descriptor is based on the deep Fisher vector (FV) encoding of the trajectory spatio-temporal structures. These have the advantage of robustly handling the misalignment in the pedestrian tracklets. The deep encoding exploits the richness of the spatio-temporal structural information around the trajectories. This is achieved by hierarchically encoding the trajectory structures leveraging a larger tracklet neighborhood scale when moving from one layer to the next one. In order to eliminate the noisy background located around the pedestrian and model the uniqueness of its identity, the deep FV encoder is further enriched towards the deep Salient-Gaussian weighted FV (deepSGFV) encoder by integrating the pedestrian Gaussian and saliency templates in the encoding process, respectively. The proposed descriptor produces competitive accuracy with respect to state-of-the art methods and especially the deep CNN ones without necessitating either pre-training or data augmentation on four challenging pedestrian video datasets: PRID2011, i-LIDS-VID, Mars and LPW. The further combination of DSTA with deep CNN boosts the current state-of-the-art methods and demonstrates their complementarity.
C1 [Ksibi, Salma; Mejdoub, Mahmoud; Ben Amar, Chokri] Univ Sfax, ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ksibi, S (corresponding author), Univ Sfax, ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
EM salma.ksibi.2014@ieee.org; mah.mejdoub@gmail.com;
   chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; Ksibi, Salma/D-4400-2017
OI Ksibi, Salma/0000-0002-8946-1887
CR [Anonymous], 13 IEEE ACS INT C CO
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Bedagkar-Gala A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1721, DOI 10.1109/ICCVW.2011.6130457
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chinnasamy  Gokilavani, 2015, INT J APPL RES, P43
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Farquhar J.D. H., 2005, Improving "bag-of-keypoints" image categorisation: Generative models and pdf-kernels
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ksibi S, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P63, DOI 10.5220/0006625400630074
   Ksibi S, 2016, INT C PATT RECOG, P3097, DOI 10.1109/ICPR.2016.7900110
   Ksibi S, 2016, IEEE SYS MAN CYBERN, P4344, DOI 10.1109/SMC.2016.7844914
   Kuo CH, 2013, IEEE WORK APP COMP, P281, DOI 10.1109/WACV.2013.6475030
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Y, 2017, ARXIV17030722 CORR
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mejdoub M, 2017, INT J ADV COMPUT SC, V8, P399
   Messelodi S, 2015, IMAGE VISION COMPUT, V44, P44, DOI 10.1016/j.imavis.2015.09.008
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Sapienza M, 2014, INT J COMPUT VISION, V110, P30, DOI 10.1007/s11263-013-0662-8
   Song G, 2017, ARXIV17110876 CORR
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wali A, 2010, LECT NOTES COMPUT SC, V6475, P110, DOI 10.1007/978-3-642-17691-3_11
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu Y, 2014, P ACM INT C MULT, P937
   Yi D., 2014, DEEP METRIC LEARNING
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang W, 2017, ARXIV17020629 CORR
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L., 2015, ARXIV PREPRINT ARXIV, P1
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou Z, 2017, THE IEEE CONFERENCE
NR 49
TC 6
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1583
EP 1611
DI 10.1007/s11042-018-6200-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700017
DA 2024-07-18
ER

PT J
AU Xie, C
   Wang, N
   Zhou, WG
   Li, WP
   Li, HQ
AF Xie, Chao
   Wang, Ning
   Zhou, Wengang
   Li, Weiping
   Li, Houqiang
TI Multi-tracker fusion via adaptive outlier detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Pair-wise evaluation; Outlier detection; Tracker fusion
ID OPTIMIZATION
AB In visual tracking task, due to the ubiquitous challenging attributes such as illumination changes, occlusion and target deformation, there hardly exists a tracker that works satisfactorily under various circumstances. To cope with different challenging factors, in this paper, we propose a fusion framework to absorb the strength of different tracking algorithms for robust object tracking. Our approach focuses on the output fusion of different trackers, without knowing their specific details, which makes our framework quite general to incorporate any new tracker. The proposed framework consists of three main steps. First, it measures the pair-wise correlation between different tracker pairs based on their appearance and geometric consistency. Then, we introduce two effective strategies to identify the unreliable trackers by analyzing the computed pair-wise relationships. Through this outlier detection process, our fusion framework adaptively discards the potential failure trackers and weights the rest trackers differently. Finally, the fusion result is derived from weighted combination of the outputs from the reliable group of trackers. Extensive experimental results on the challenging OTB-2013 and OTB-2015 datasets demonstrate the effectiveness of the proposed fusion framework.
C1 [Xie, Chao; Wang, Ning; Zhou, Wengang; Li, Weiping; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhou, WG (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
EM chaoxie@ustc.edu.cn; wn6149@mail.ustc.edu.cn; zhwg@ustc.edu.cn;
   wpli@ustc.edu.cn; lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013
CR [Anonymous], 2012, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2014, ECCV
   [Anonymous], 2015, ICCV WORKSH
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2013, ECCV
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, ECCV
   [Anonymous], 2012, ECCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2015, ICML
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, CVPR
   Bertinetto L., 2016, CVPR
   Bertinetto Luca, 2016, ECCV
   Bolme D. S., 2010, CVPR
   Bomze IM, 2002, J GLOBAL OPTIM, V22, P17, DOI 10.1023/A:1013886408463
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan H., 2017, CVPR WORKSH
   Gao Y, 2014, IEEE T CIRC SYST VID, V24, P1122, DOI 10.1109/TCSVT.2014.2302366
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jia X., 2012, CVPR
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khalid O, 2017, IEEE T CIRC SYST VID, V27, P1527, DOI 10.1109/TCSVT.2016.2542699
   Li JT, 2017, IEEE T IMAGE PROCESS, V26, P2736, DOI 10.1109/TIP.2017.2686601
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li Yang, 2014, ECCV WORKSH
   Liu H., 2010, ICML
   Liu Siqi, 2016, P IEEE C COMP VIS PA
   Ma C., 2015, CVPR
   Shen M, 2018, MULTIMED TOOLS APPL, P1
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Wang HM, 2018, MYCOKEYS, P1, DOI 10.3897/mycokeys.39.27014
   Wang N. Y., 2014, ICML
   Wu Y., 2013, CVPR
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang L, 2018, MULTIMED TOOLS APPL, P1
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang Tianzhu, 2016, CVPR
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 63
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2227
EP 2250
DI 10.1007/s11042-018-6278-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700042
DA 2024-07-18
ER

PT J
AU N'guessan, SO
   Ling, N
AF N'guessan, Sylvia O.
   Ling, Nam
TI Saturation-aware human attention region of interest algorithm for
   efficient video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive perceptual quantization; Human attention; Human visual system;
   Just-noticeable distortion; Region-of-interest; Saturation; Streaming
   media; Video coding; Visual communication
ID MODEL; SENSITIVITY
AB We propose a saturation-aware human attention region-of-interest (SA-HAROI) video compression method that performs a perceptual adaptive quantization algorithm on video frames as a function of the distribution of their luminance, motion vector, and color saturation. Our work is an application of a psycho-visual study that demonstrated that human attention automatically enhanced perceived saturation. Consequently, the adaptive quantization phase of our compression algorithm is characterized by a luminance and saturation-aware just noticeable distortion (JND) function. After running multiple experiments on 18 videos with various resolutions ranging from QCIF to 4K, results showed that our method achieves higher compression than that of both the H.264/AVC JM and the HEVC HM while maintaining subjective quality. We observed that in comparison to both implementation of the standards (JM and HM), for an IPPP coding structure, the performance of our algorithm culminated with HD and 4K videos yielding a bit rate reduction averaging 15% and an encoding time reduction of about 20% in certain cases. Finally, after comparing our method to other similar techniques, we concluded that saturation is a significant parameter in the improvement of video compression.
C1 [N'guessan, Sylvia O.; Ling, Nam] Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
C3 Santa Clara University
RP N'guessan, SO (corresponding author), Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
EM snguessan@scu.edu; nling@scu.edu
CR Agrafiotis D, 2006, IEEE IMAGE PROC, P53, DOI 10.1109/ICIP.2006.313201
   Al-Rahayfeh A, 2013, 2013 NINTH ANNUAL CONFERENCE ON LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY (LISAT 2013)
   [Anonymous], 2014, High efficiency video coding
   [Anonymous], 2015, JM SOFTWARE
   [Anonymous], 2009, RECOMMENDATION BT 50
   Bjotegaard G., 2001, VCEGM33
   Blake R., 2006, Perception, Vfifth
   Blake R., 2003, Motion Processing in Human Visual Cortex
   Bojkovic Z, 2004, NEUREL 2004: SEVENTH SEMINAR ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING, PROCEEDINGS, P67
   Camgoz N., 2000, Effects of hue, saturation, and brightness on attention and preference
   Carrasco M, 2006, PROG BRAIN RES, V154, P33
   Chen ZZ, 2014, INT CONF DIGIT SIG, P827, DOI 10.1109/ICDSP.2014.6900782
   Chen ZZ, 2010, IEEE INT CON MULTI, P784, DOI 10.1109/ICME.2010.5582549
   Darrell T, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P26
   Dongheng L, 2005, COMP VIS PATT REC CV, P79
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Forte D, 2011, GREEN COMP C WORKSH
   Fuller S, 2006, VISION RES, V46, P4032, DOI 10.1016/j.visres.2006.07.014
   Gitman Y, 2014, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2014.7025220
   Gonzalez R, 2008, DIGITAL IMAGE PROCES, P35
   Grois D., 2010, Electrical and Electronics Engineers in Israel (IEEEI)
   Guoqing Xiang, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P54, DOI 10.1007/978-3-319-13168-9_6
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harezlak K, 2014, 18 ANN C KNOWL BAS I
   Hrarti M., 2011, 2011 3rd European Workshop on Visual Information Processing, P61, DOI 10.1109/EuVIP.2011.6045539
   HSL and HSV, 2016, HSL AND HSV
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 2000, MODELS BOTTOM UP EAN
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim JY, 2010, IEEE T CONSUM ELECTR, V56, P951, DOI 10.1109/TCE.2010.5506025
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Liu F, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING (GRC), P175, DOI 10.1109/GRC.2014.6982830
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Makar M, 2010, IEEE IMAGE PROC, P4437, DOI 10.1109/ICIP.2010.5653982
   Myers R.L., 2003, Display Interface: Fundamentals and Standards
   N'guessan S, SA HAROI EXPT RESULT
   N'guessan SO, 2012, HUMAN ATTENTION REGI
   N'guessan SO, 2014, COMPRESSION HD VIDEO
   Naccari M, 2013, IEEE INT CON MULTI
   Osberger W, 2001, PROC SPIE, V4299, P361, DOI 10.1117/12.429506
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Pudlewski S, 2013, IEEE T MULTIMEDIA, V15, P2072, DOI 10.1109/TMM.2013.2280245
   Rajeshwari J, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P728, DOI 10.1109/IC3I.2014.7019746
   ROBINSON DA, 1965, J PHYSIOL-LONDON, V180, P569, DOI 10.1113/jphysiol.1965.sp007718
   Shioiri S., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P5, DOI 10.1109/ICSMC.1999.825198
   Soyak E, 2011, IEEE T CIRC SYST VID, V21, P1378, DOI 10.1109/TCSVT.2011.2163448
   Stuart GW, 2014, VISION RES, V96, P25, DOI 10.1016/j.visres.2013.12.013
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Thibos LN, 1989, P SPIE, V1199
   Tobii, 2015, TOB IS WORLD LEAD EY
   Tsai CM, 2009, IEEE IMAGE PROC, P969, DOI 10.1109/ICIP.2009.5413796
   Tzvetanka I., 2003, Detecting Cartoons: A case study in automatic video-genre classification
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Willenbockel V, 2010, DOES COLOR CEONTRAST
   Wright RD., 2008, ORIENTING ATTENTION
   Wu GL, 2010, IEEE INT CON MULTI, P790, DOI 10.1109/ICME.2010.5582545
   Zheng H, 2015, P INT C ART REAL TEL, P345
   Zhu J, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING ICISCE 2015, P404, DOI 10.1109/ICISCE.2015.95
NR 59
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31067
EP 31093
DI 10.1007/s11042-018-6108-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600041
DA 2024-07-18
ER

PT J
AU Sharma, G
   Gupta, S
   Dhall, S
   Nagpal, CK
AF Sharma, Gaurav
   Gupta, Shailender
   Dhall, Sangeeta
   Nagpal, C. K.
TI Publicly verifiable watermarking scheme for intellectual property
   protection using quantum Chaos and bit plane complexity slicing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BPCS; Chaotic maps; Hash; Quantum chaotic maps; Zero knowledge
   verification protocol
ID IMAGE; AUTHENTICATION
AB Intellectual Property such as music, painting, videos and other similar works being broadcasted on web need to be protected against copyright infringement to ensure the rights of their legitimate owners. Moreover, their users must also be sure of the originality of these artefacts. Both these problems can be solved through proper authentication on behalf of the creator. For this purpose, various publicly verifiable watermarking schemes have been available in literature. Recent proposal, in this domain, is based on chaos theory and Secured Hashing Algorithms SHA-2. Due to tremendous growth in the availability of Intellectual Property on the web and associated breaches it becomes a mandatory requirement to update these authenticating schemes. This paper proposes the usage of some more secure, reliable and efficient components in watermarking schemes than being used at present. Proposed changes include the deployment of encryption scheme based on Quantum Logistic maps instead of current Chaos encryption based on peter de-jong map, in order to optimise randomness, correlation and time complexity. For better security and efficiency in hardware implementation SHA-3 is a better choice than SHA-2. Data embedding can be done in regions where imperceptibility is quite high. The proposed changes can result in the creation of more reliable and efficient system. To test the hypothesis, proposed mechanism has been implemented in MATLAB-16a and various performance metrics such as correlation coefficient, PSNR, UIQI, SSIM have been measured. The results show that proposed scheme outperforms its counterpart in terms of all the performance metrics.
C1 [Sharma, Gaurav; Gupta, Shailender; Dhall, Sangeeta; Nagpal, C. K.] YMCA Univ Sci & Technol, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Sharma, G (corresponding author), YMCA Univ Sci & Technol, Faridabad, Haryana, India.
EM sharma.grv69@gmail.com; shailender81@gmail.com;
   sangeeta_dhall@yahoo.co.in; nagpalckumar@rediffmail.com
RI dhall, sangeeta/AAG-2948-2020; Nagpal, Chander Kumar/AAG-3473-2021;
   Sharma, Gaurav/HTO-3197-2023; gupta, shailender/Y-8231-2019
OI Nagpal, Chander Kumar/0000-0003-1518-2882; gupta,
   shailender/0000-0003-1383-7152
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Adelsbach A., 2001, Proceedings of the 4th Inter. Workshop on Info. Hiding, V2137, P273, DOI [10.1007/3-540-45496-9_20, DOI 10.1007/3540-454969_20]
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   [Anonymous], LNCS
   [Anonymous], P SPIE MULTIMEDIA SY
   [Anonymous], 2013, Intellectual Property Laws Amendment Act 28 of
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Dworkin M.J, 2015, Federal Information Processing Standards, DOI [DOI 10.6028/NIST.FIPS.202, 10.6028/NIST.FIPS.202]
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lach J, 2001, IEEE T COMPUT AID D, V20, P1253, DOI 10.1109/43.952741
   Lach J., 1999, Proceedings 1999 Design Automation Conference (Cat. No. 99CH36361), P831, DOI 10.1109/DAC.1999.782152
   LeClair J, 2015, CIO MAGAZINE
   Lemley MA, 2005, TEX LAW REV, V83, P1031
   Mohanty SP, 2004, LECT NOTES COMPUT SC, V3356, P344
   Phan RCW, 2008, PATTERN RECOGN, V41, P3493, DOI 10.1016/j.patcog.2008.05.009
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Qu G, 2002, IEEE T COMPUT AID D, V21, P1363, DOI 10.1109/TCAD.2002.804205
   Saha D, 2012, IEEE T VLSI SYST, V20, P1749, DOI 10.1109/TVLSI.2011.2162347
   Schneier B, 1995, APPL CRYPTOGRAPHY PR
   Secure Hash Standard (SHS). (U.S. Department of Commerce Washington D.C.), 2015, FIPS1804, V180-4, DOI [10.6028/NIST.FIPS.180-4, DOI 10.6028/NIST.FIPS.180-4]
   Tehranipoor Mohammad, 2011, INTRO HARDWARE SECUR
   Wang X., 2012, RECENT ADV COMPUTER, P223
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang JL, 2017, IEEE T VLSI SYST, V25, P1520, DOI 10.1109/TVLSI.2016.2619682
   Zhang JL, 2012, RADIOENGINEERING, V21, P764
NR 29
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31737
EP 31762
DI 10.1007/s11042-018-6226-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000010
DA 2024-07-18
ER

PT J
AU Zhang, QB
   Lu, W
   Wang, RX
   Li, GQ
AF Zhang, Qingbo
   Lu, Wei
   Wang, Ruxin
   Li, Guoqiang
TI Digital image splicing detection based on Markov features in block DWT
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Image splicing detection; Discrete wavelet
   transform; Discrete cosine transform; JPEG compression
ID CLASSIFICATION; OPTIMIZATION; TRACKING; DCT
AB Image splicing is very common and fundamental in image tampering. Many splicing detection schemes based on Markov features in transform domain have been proposed. Based on previous studies, the traditional DWT based schemes perform not better than the DCT based schemes. In this paper, a block DWT based scheme is proposed to improve the detection performance of the DWT based scheme. Firstly, the block DWT is applied on the source image. Then, the Markov features are constructed in block DWT domain to characterize the dependency among wavelet coefficients across positions. After that, feature selection method SVM-RFE is used to reduce the dimensionality of features. Finally, Support Vector Machine is exploited to classify the authentic and spliced images. Experiment results show that the detection performance of the features extracted in DWT domain can be improved with block DWT based scheme. And then, in order to further clarify the phenomenon about the traditional DWT based schemes perform not better than the DCT based schemes, a detail comparison between the two kinds of schemes is proposed based on a set of experiments. The results show that the DWT based scheme is more applicable and powerful than the DCT based scheme, and the DCT based scheme is more suitable for handling these datasets which generated with the process of JPEG compression.
C1 [Zhang, Qingbo; Lu, Wei; Wang, Ruxin] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Li, Guoqiang] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Shanghai Jiao Tong University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM luwei3@mail.sysu.edu.cn
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Fundamental
   Research Funds for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], 2003, 2003 C COMPUTER VISI, DOI [DOI 10.1109/CVPRW.2003.10093, DOI 10.1109/CVPRW.2003.10093.27.T.-T]
   [Anonymous], TECH REP 203 2004 3
   [Anonymous], IEEE INTERNATIONAL C
   [Anonymous], 2003, INT C COMP VIS PATT
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Granty Regina Elwin J., 2010, Proceedings of the 2010 International Conference on Communication and Computational Intelligence (INCOCCI), P431
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Gyamfi KS, 2018, EXPERT SYST APPL, V91, P252, DOI 10.1016/j.eswa.2017.09.010
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu C. W., 2010, Technical Report
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Li J, 2000, IEEE T SIGNAL PROCES, V48, P517, DOI 10.1109/78.823977
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Lu W, 2011, ENG APPL ARTIF INTEL, V24, P666, DOI 10.1016/j.engappai.2011.01.002
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Sutthiwan P, 2010, IEEE INT CON MULTI, P1463, DOI 10.1109/ICME.2010.5583264
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Vyas C, 2014, IEEE INT C COMPUTATI, P1
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 47
TC 18
Z9 20
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31239
EP 31260
DI 10.1007/s11042-018-6230-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600049
DA 2024-07-18
ER

PT J
AU Zhao, K
   Deng, JJ
   Cheng, DQ
AF Zhao, Kai
   Deng, Jingjing
   Cheng, Deqiang
TI Real-time moving pedestrian detection using contour features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Elliptic Fourier descriptors; Normalized central
   moments; Support vector machine; Linear fit
AB Pedestrian detection is one of the most fundamental research in computer vision. However, many high performance detectors run slowly. In this paper, we propose a real-time moving pedestrian detector by using efficient contour features. Firstly, the moving targets are detected by background subtraction. By combining the elliptic Fourier descriptors and the normalized central moments, we propose the Elliptic Fourier and Moments Descriptors (EFMD) to describe the moving target contours. Secondly, the moving targets are classified by the trained Support Vector Machine (SVM). In addition, we introduce a novel overlap handling algorithm based on linear fitting and normalized central moments, which improves the detection performance by reducing both false positives and miss rate. The experimental results on PETS 2009 and CAVIAR datasets show that our approach achieves a miss rate of 14% (PETS 2009) and 13% (CAVIAR) at 10(-1) False Positives Per Image (FPPI) and an average runtime per frame of 30 ms (PETS 2009) and 25 ms (CAVIAR), which significantly outperforms several state-of-the-art detectors in both detection performance and runtime.
C1 [Zhao, Kai; Deng, Jingjing; Cheng, Deqiang] China Univ Min & Technol, Sch Informat & Control Engn, 1 Daxue Rd, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Cheng, DQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, 1 Daxue Rd, Xuzhou 221116, Jiangsu, Peoples R China.
EM dqcheng@cumt.edu.cn
RI Cheng, Deqiang/HDO-0132-2022
FU Fundamental Research Funds for the Central Universities [2014ZDPY32]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (No.2014ZDPY32).
CR [Anonymous], 2010, P BRIT MACH VIS C BM
   [Anonymous], 2009, BRIT MACH VIS C BMVC
   [Anonymous], P S GERM ASS PATT RE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2009, Scholarpedia
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31
   Liu YZ, 2009, PATTERN RECOGN LETT, V30, P148, DOI 10.1016/j.patrec.2008.03.007
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Paisitkriangkrai S, 2016, IEEE T PATTERN ANAL, V38, P1243, DOI 10.1109/TPAMI.2015.2474388
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shen JF, 2017, PATTERN RECOGN, V63, P127, DOI 10.1016/j.patcog.2016.09.010
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wu B., 2008, COMPUTER VISION PATT
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang SS, 2016, MULTIMED TOOLS APPL, V75, P6263, DOI 10.1007/s11042-015-2571-z
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 34
TC 11
Z9 12
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30891
EP 30910
DI 10.1007/s11042-018-6173-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600034
DA 2024-07-18
ER

PT J
AU Lei, C
   Zhu, XF
AF Lei, Cong
   Zhu, Xiaofeng
TI Unsupervised feature selection via local structure learning and sparse
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Subspace learning; Sparse feature selection;
   Hypergraph representation
ID ASSOCIATION RULES; JOINT REGRESSION; CLASSIFICATION; REPRESENTATION;
   OPTIMIZATION
AB Feature self-representation has become the backbone of unsupervised feature selection, since it is almost insensitive to noise data. However, feature selection methods based on feature self-representation have the following drawbacks: 1) The self-representation coefficient matrix is fixed and can not be fine-tuned according to the structure of data. 2) they do not consider the manifold structure of data, thus unable to further increase the performance of feature selection. To solve the above problems, this paper proposes an unsupervised feature selection algorithm that combines feature self-representation and manifold learning. Specifically, we first utilize feature self-representation to construct the model. After that, the self-representation coefficient matrix is dynamically adjusted to the optimal state based on the similarity matrix. Then, we use low-rank representation to explore the global manifold structure of the data. Finally, we combine sparse learning with feature selection. The experimental results on twelve datasets show that the proposed method outperforms all the competing methods.
C1 [Lei, Cong; Zhu, Xiaofeng] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Zhu, XF (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM seanzhuxf@gmail.com
RI Zhu, Xiaofeng/HII-5291-2022
OI Zhu, Xiaofeng/0000-0001-6840-0578
FU China Key Research Program [2016YFB1000905]; China 1000-Plan National
   Distinguished Professorship; Nation Natural Science Foundation of China
   [61573270, 61672177, 61363009]; Guangxi Natural Science Foundation
   [2015GXNSFCB139-011]; Guangxi High Institutions Program of Introducing
   100 High-Level Overseas Talents; Guangxi Collaborative Innovation Center
   of Multi-Source Information Integration and Intelligent Processing;
   Guangxi Bagui Teams for Innovation and Research; Research Fund of
   Guangxi Key Lab of MIMS [16-A-01-01, 16-A-01-02]; Innovation Project of
   Guangxi Graduate Education [XYCSZ2017064, XYCSZ2017067, YCSW2017065]
FX This work was supported in part by the China Key Research Program (Grant
   No: 2016YFB1000905), the China 1000-Plan National Distinguished
   Professorship, the Nation Natural Science Foundation of China (Grants
   No: 61573270, 61672177 and 61363009), the Guangxi Natural Science
   Foundation (Grant No: 2015GXNSFCB139-011), the Guangxi High Institutions
   Program of Introducing 100 High-Level Overseas Talents, the Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing, the Guangxi Bagui Teams for Innovation and
   Research, the Research Fund of Guangxi Key Lab of MIMS (16-A-01-01 and
   16-A-01-02), the Guangxi Bagui Teams for Innovation and Research, and
   Innovation Project of Guangxi Graduate Education under grant
   XYCSZ2017064, XYCSZ2017067 and YCSW2017065.
CR [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   Boyd S., 2013, CONVEX OPTIMIZATION
   Cai D., 2010, KDD, P333
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Cai X., 2013, 23 INT JOINT C ARTIF, P1240, DOI [10.5555/2540128.2540307, DOI 10.5555/2540128.2540307]
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Gao L, 2017, NEUROCOMPUTING, V253, P77, DOI 10.1016/j.neucom.2016.11.078
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Ling Charles X., 2004, P 21 INT C MACH LEAR, P69, DOI DOI 10.1109/TSMCB.2008.2007853
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Poortarigh M., 2017, NEUROCOMPUTING, DOI [10.1016/j.neucom.2017.11.034, DOI 10.1016/J.NEUCOM.2017.11.034]
   Qian BY, 2015, DATA MIN KNOWL DISC, V29, P1070, DOI 10.1007/s10618-014-0379-5
   Qian BY, 2014, IEEE T IMAGE PROCESS, V23, P5573, DOI 10.1109/TIP.2014.2365952
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Song JK, 2016, IMAGE VISION COMPUT, V55, P101, DOI 10.1016/j.imavis.2016.02.005
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song JK, 2016, IEEE T MULTIMEDIA, V18, P484, DOI 10.1109/TMM.2016.2515990
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Sun JY, 2014, IEEE IJCNN, P558, DOI 10.1109/IJCNN.2014.6889514
   Wang T, 2012, INFORM SYST, V37, P508, DOI 10.1016/j.is.2011.10.009
   Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wu XD, 2005, INFORM SYST, V30, P71, DOI 10.1016/j.is.2003.10.001
   Wu XD, 2004, ACM T INFORM SYST, V22, P381, DOI 10.1145/1010614.1010616
   Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353, DOI 10.1109/TKDE.2003.1185839
   XIA Y, 2015, PROC CVPR IEEE, P3332
   Xie Q, 2016, NEUROCOMPUTING, V195, P50, DOI 10.1016/j.neucom.2015.07.145
   Xie Q, 2016, IEEE T KNOWL DATA EN, V28, P1258, DOI 10.1109/TKDE.2016.2516541
   Xie Q, 2014, VLDB J, V23, P915, DOI 10.1007/s00778-014-0355-0
   Yan XW, 2009, EXPERT SYST APPL, V36, P3066, DOI 10.1016/j.eswa.2008.01.028
   Zhang Chengqi, 2003, Association rule mining: models and algorithms, V2307
   Zhang S, 1999, DATA PREPARATION DAT
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhang SC, 2003, INFORM SYST, V28, P691, DOI 10.1016/S0306-4379(02)00079-0
   Zhang SC, 2002, IEEE T SYST MAN CY A, V32, P515, DOI 10.1109/TSMCA.2002.804793
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhang SC, 2011, J SYST SOFTWARE, V84, P452, DOI 10.1016/j.jss.2010.11.887
   Zhang SC, 2011, APPL INTELL, V35, P123, DOI 10.1007/s10489-009-0207-6
   Zhang Shichao., 2003, IEEE Computational Intelligence Bulletin, V2, P5
   Zhao YC, 2006, IEEE T KNOWL DATA EN, V18, P231, DOI 10.1109/TKDE.2006.30
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2017, AAAI CONF ARTIF INTE, P2963
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, BRAIN IMAGING BEHAV, V10, P818, DOI 10.1007/s11682-015-9430-4
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2015, NEUROCOMPUTING, V169, P43, DOI 10.1016/j.neucom.2014.08.106
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P264, DOI 10.1007/978-3-319-46720-7_31
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 66
TC 58
Z9 62
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29605
EP 29622
DI 10.1007/s11042-017-5381-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800023
DA 2024-07-18
ER

PT J
AU Liu, YY
   Chen, JY
   Zhang, ML
   Rao, C
AF Liu, Yuanyuan
   Chen, Jingying
   Zhang, Mulan
   Rao, Chuan
TI Student engagement study based on multi-cue detection and recognition in
   an intelligent learning environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-cue behavior detection; Class engagement study; VFOA recognition;
   Smile detection; Intelligent learning environment
AB Student engagement has great impact on learning performance. It's necessary to investigate student engagement objectively from learning behavior. In this paper, we propose a student engagement study approach in an intelligent learning environment, which automatically detects and analyses multiple learning behavioral cues based on five modules, i.e., attendance management, teacher-student (T&S) communication, visual focus of attention (VFOA) recognition, smile detection and engagement analysis. Attendance management matches the student's identity and locates his/her profile using face recognition. T&S communication provides an additional channel of Question and Answer (Q&A) between a teacher and students for students' behavioral engagement analysis via their cell phones. VFOA recognition is used to recognize students' cognitive engagement through capturing students' attention based on the estimated head poses, visual environment cues and prior states in class. Smile detection achieves students' affective engagement through spontaneous smile expression classification. Finally, a tree-structural engagement model is proposed to decide student engagement based on multi-cues of one's behavioral, cognitive and affective engagement. We thoroughly evaluated each module for engagement study on some public available datasets and practical video sequences in class applications. The experimental results suggest that the proposed approach can automatically detect and analyze student class engagement objectively and effectively.
C1 [Liu, Yuanyuan] China Univ Geosci, Fac Informat Engn, Wuhan, Hubei, Peoples R China.
   [Chen, Jingying; Zhang, Mulan; Rao, Chuan] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
C3 China University of Geosciences; Central China Normal University
RP Chen, JY (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
EM liuyy@cug.edu.cn; chenjy@mail.ccnu.edu.cn
RI liu, yuanyuan/IQS-2755-2023
FU National Social Science Foundation of China [16BSH107]
FX This work was supported by the National Social Science Foundation of
   China (Grant no. 16BSH107).
CR Agarwal M, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P310, DOI 10.1109/ICSAP.2010.51
   An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   [Anonymous], 1998, Intel Technology Journal, DOI DOI 10.1109/ACV.1998.732882
   [Anonymous], 2004, INT C PATT REC WORKS
   [Anonymous], TR200396 MITS EL RES
   Ba SO, 2011, IEEE T PATTERN ANAL, V33, P101, DOI 10.1109/TPAMI.2010.69
   Boyle J.T., 2003, ALT J, V11, P43
   Breiman L., 2001, Mach. Learn., V45, P5
   Chen D, 2017, IEEE T PARALL DISTR, V28, P1091, DOI 10.1109/TPDS.2016.2613054
   Chen JY, 2016, COMPUTING, V98, P215, DOI 10.1007/s00607-014-0430-9
   Chen JY, 2014, IEEE T IND INFORM, V10, P323, DOI 10.1109/TII.2013.2271914
   Cohen M, 2012, IEEE T PATTERN ANAL, V34, P2327, DOI 10.1109/TPAMI.2012.49
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Gall J., 2013, Decision Forests for Computer Vision and Medical Image Analysis, P143
   Graesser A, 2007, FRONT ARTIF INTEL AP, V158, P569
   Guerra J, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P152, DOI 10.1145/2856767.2856784
   Gui J, 2016, IEEE T CYBERNETICS, V46, P1877, DOI 10.1109/TCYB.2015.2457234
   Guo P. J., 2014, P 1 ACM C LEARN SCAL, P41, DOI [10.1145/2556325.2566239, DOI 10.1145/2556325.2566239]
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Ito A, 2005, 2005 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P437, DOI 10.1109/CW.2005.82
   Kahou SE, 2015, LECT NOTES COMPUT SC, V8926, P135, DOI 10.1007/978-3-319-16181-5_10
   Koji Y, 2016, 12 INT C NAT COMP FU, P2098
   Liu Y, 2015, NEUROCOMPUTING, P42
   Liu Y, 2014, APPL MECH MATER, V464, P235, DOI 10.4028/www.scientific.net/AMM.464.235
   Liu YY, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P618, DOI 10.1109/FSKD.2016.7603245
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo CW, 2015, IEEE SIGNAL PROC LET, V22, P2324, DOI 10.1109/LSP.2015.2480758
   Mi JX, 2013, OPTIK, V124, P6786, DOI 10.1016/j.ijleo.2013.05.099
   Odobez J., 2007, IEEE INT C MULT EXP, P183
   Podder PK, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P108
   Rodgers T., 2008, International Journal of Cyber Society and Edcation, V1, P143
   Rodrigues C, 2015, ICEE INT C ENERG, P81
   Scornavacca E., 2007, Proceedings of the Conference on Mobile Learning Technologies and Applications, P47
   Senechal T., 2013, IEEE 10th Int. Conf. and Workshop Automat. Face and Gesture Recog, P1, DOI [DOI 10.1109/FG.2013.6553776, 10.1109/fg.2013.6553776]
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Siau K, 2006, IEEE T EDUC, V49, P398, DOI 10.1109/TE.2006.879802
   Ting CY, 2013, IEEE SYS MAN CYBERN, P2939, DOI 10.1109/SMC.2013.501
   Woolf B, 2009, INT J LEARN TECHNOL, V4, P129, DOI 10.1504/IJLT.2009.028804
   Yang C, 2005, PROC CVPR IEEE, P176
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhao X, 2014, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2014.7024999
NR 41
TC 7
Z9 8
U1 3
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28749
EP 28775
DI 10.1007/s11042-018-6017-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500040
DA 2024-07-18
ER

PT J
AU Luaces, D
   Viqueira, JRR
   Gamallo, P
   Mera, D
   Flores, JC
AF Luaces, David
   Viqueira, Jose R. R.
   Gamallo, Pablo
   Mera, David
   Flores, Julian C.
TI GeoHbbTV: A framework for the development and evaluation of geographic
   interactive TV contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive TV; HbbTV; Geographic visualization; Geographic annotation;
   Geographic tagging
ID USER EXPERIENCE; INFORMATION-RETRIEVAL; SOCIAL TV; TELEVISION; INTERNET;
   PROGRAMS; NEWS; HOME
AB Synchronizing TV contents with applications is a topic that has gained much interest during the last years. Reaching the viewers through various channels (TV, web, mobile devices, etc.) has shown to be a means for increasing the audience. Related to the above, the hybrid TV standard HbbTV (Hybrid Broadcast Broadband TV) synchronizes the broadcast of video and audio with applications that may be delivered through either the broadcast channel or a broadband network. Thus, HbbTV applications may be developed to provide contextual information for emitted TV shows and advertisements. This paper reports on the integration of the automatic generation of geographic focus of text content with interactive TV. In particular it describes a framework for the incorporation of geographic context to TV shows and its visualization through HbbTV. To achieve this, geographic named entities are first extracted from the available subtitles and next the spatial extension of those entities is used for the production of context maps. An evaluation strategy has been devised and used to test alternative prototype implementations for TV newscast in Spanish language. Finally, to go beyond the initial solution proposed, some challenges for future research are also discussed.
C1 [Luaces, David; Viqueira, Jose R. R.; Gamallo, Pablo; Mera, David; Flores, Julian C.] Univ Santiago de Compostela, Ctr Singular Invest Tecnol Informac CiTIUS, Rua Genaro de la Fuente Dominguez S-N, Santiago De Compostela 15782, Spain.
C3 Universidade de Santiago de Compostela
RP Viqueira, JRR (corresponding author), Univ Santiago de Compostela, Ctr Singular Invest Tecnol Informac CiTIUS, Rua Genaro de la Fuente Dominguez S-N, Santiago De Compostela 15782, Spain.
EM david.luaces@usc.es; jrr.viqueira@usc.es; pablo.gamallo@usc.es;
   david.mera@usc.es; julian.flores@usc.es
RI gamallo, pablo/A-6985-2009; Flores, Julian/L-5932-2014; Mera,
   David/I-2406-2015
OI gamallo, pablo/0000-0002-5819-2469; Flores, Julian/0000-0002-9607-1756;
   Viqueira, Jose R.R./0000-0002-1539-3746; Mera,
   David/0000-0002-0639-6574; Luaces Cachaza, David/0000-0002-6431-5242
FU Galician Government (Xunta de Galicia); FEDER funds of the EU under the
   Consolidation Program of Competitive Research Units [R2014/007,
   GPC2014/037, R2016/011]
FX This work has been partially funded by the Galician Government (Xunta de
   Galicia) and FEDER funds of the EU under the Consolidation Program of
   Competitive Research Units (R2014/007, GPC2014/037, R2016/011).
CR Abreu JF, 2015, 6 INT DIG TV C 4 IB
   Abreu J, 2015, PROCEDIA COMPUT SCI, V64, P1240, DOI 10.1016/j.procs.2015.08.508
   Adelfio Marco D., 2013, Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, P532, DOI DOI 10.1145/2525314.2525321
   Aguilar M, 2016, COMM COM INF SC, V605, P9, DOI 10.1007/978-3-319-38907-3_2
   Amitay E., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P273, DOI 10.1145/1008992.1009040
   ANGEL A, 2008, P 16 ACM SIGSPATIAL, P1
   [Anonymous], 2009, P 17 ACM SIGSPATIAL, DOI DOI 10.1145/1653771.1653781
   Anstead Edward., 2014, P ACM INT C INTERACT, P103, DOI [10.1145/2602299, DOI 10.1145/2602299]
   Athanasiadis E, 2010, J SYST SOFTWARE, V83, P1453, DOI 10.1016/j.jss.2010.02.040
   Bao Jie., 2013, Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, P184
   Buscaldi D., 2011, SIGSPATIAL Special, V3, P16
   Carreras X, 2002, COLING 02 P 6 C NAT
   Cesar P., 2011, 2011 IEEE Consumer Communications and Networking Conference (CCNC 2011), P347, DOI 10.1109/CCNC.2011.5766487
   Cesar P., 2008, Proceedings of the 16th ACM international conference on Multimedia (MM '08), P11, DOI DOI 10.1145/1459359.1459362
   Chorianopoulos K, 2008, MULTIMED TOOLS APPL, V36, P1, DOI 10.1007/s11042-006-0081-8
   Coelho J, 2017, INT J HUM-COMPUT ST, V98, P38, DOI 10.1016/j.ijhcs.2016.09.015
   Compton R., 2014, CORR
   Costa D, 2015, PROCEDIA COMPUT SCI, V67, P388, DOI 10.1016/j.procs.2015.09.283
   Cunningham H., 2014, Developing Language Processing Components with GATE Version 8, V8th
   D'Ignazio C, 2014, NEWSKDD WORKSH 201H
   Ding Junyan., 2000, VLDB 00 P 26 INT C V, P545
   Dowell J, 2015, PERS UBIQUIT COMPUT, V19, P1215, DOI 10.1007/s00779-015-0867-7
   Ducheneaut N, 2008, INT J HUM-COMPUT INT, V24, P136, DOI 10.1080/10447310701821426
   Epelde G, 2013, MULTIMED TOOLS APPL, V67, P497, DOI 10.1007/s11042-011-0949-0
   Finkel Jenny Rose, 2005, ACL, P363
   Gamallo P, 2011, LECT NOTES ARTIF INT, V7026, P610, DOI 10.1007/978-3-642-24769-9_44
   Garcia M, 2015, YET ANOTHER SUITE MU, P65, DOI [10.1007/978-3-319-27653-3_7, DOI 10.1007/978-3-319-27653-3_7]
   Gelernter J, 2013, GEOINFORMATICA, V17, P635, DOI 10.1007/s10707-012-0173-8
   Goldberg DW, 2009, INT J GEOGR INF SCI, V23, P93, DOI 10.1080/13658810802577262
   Goodchild MF, 2008, INT J GEOGR INF SCI, V22, P1039, DOI 10.1080/13658810701850497
   Guna J, 2017, MULTIMED TOOLS APPL, V76, P20377, DOI 10.1007/s11042-016-3243-3
   Guna J, 2017, MULTIMED TOOLS APPL, V76, P16125, DOI 10.1007/s11042-016-3898-9
   Jiang R, 2016, P 6 NAM ENT WORKSH, P21, DOI DOI 10.18653/V1/W16-2703
   Jones CB, 2008, INT J GEOGR INF SCI, V22, P219, DOI 10.1080/13658810701626343
   Kim J, 2017, J BUS RES, V76, P67, DOI 10.1016/j.jbusres.2017.03.001
   Kim Sun, 2012, J Biomed Semantics, V3 Suppl 3, pS6, DOI 10.1186/2041-1480-3-S3-S6
   Kiryakov A., 2004, Services and Agents on the World Wide Web, V2, P49, DOI [DOI 10.1016/J.WEBSEM.2004.07.005, 10.1016/j.websem.2004.07.005]
   Krämer NC, 2015, COMPUT HUM BEHAV, V51, P255, DOI 10.1016/j.chb.2015.05.005
   Lamprier S, 2008, J UNIVERS COMPUT SCI, V14, P178
   Li CL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P721, DOI 10.1145/2348283.2348380
   Li Z., 2011, P 19 ACM INT C MULTI, P133
   Lieberman M.D., 2007, P 15 ACM INT S ADV G, P1
   Lieberman MD, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P843
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Murray J.H., 2012, P 10 EUROPEAN C INTE, P223, DOI [10.1145/2325616, DOI 10.1145/2325616]
   Nandakumar A.Murray., 2014, P 2014 INT C INTERAC, P3
   Nitta N, 2005, MULTIMED TOOLS APPL, V25, P59, DOI 10.1023/B:MTAP.0000046382.62218.e1
   Padro L, 2012, C LANG RES EV LREC 1
   Pasley R.C., 2007, P 4 ACM WORKSHOP GEO, P77
   Purves RS, 2007, INT J GEOGR INF SCI, V21, P717, DOI 10.1080/13658810601169840
   Ritter A., 2011, P EMNLP, P1524
   Samet H, 2014, COMMUN ACM, V57, P64, DOI 10.1145/2629572
   Sang E.F.T.K., 2002, P CONLL 2002 TAIP TA, P1, DOI DOI 10.3115/1118853.1118877
   Schaap G, 2018, COMPUT HUM BEHAV, V84, P76, DOI 10.1016/j.chb.2018.02.006
   Silva P, 2015, P ACM INT C INT EXP, P167, DOI DOI 10.1145/2745197.2755519
   Strzebkowski R, 2014, P 2 INT WORKSH INT C
   Teitler Benjamin E., 2008, ACM GIS, DOI [10.1145/1463434.1463458, DOI 10.1145/1463434.1463458]
   Tsekleves E, 2011, ENTERTAIN COMPUT, V2, P151, DOI 10.1016/j.entcom.2011.02.002
   Van den Broeck W., 2017, P 2 INT WORKSH MULT, P25, DOI [https://doi.org/10.1145/3132361.3132362, DOI 10.1145/3132361.3132362]
   Vanattenhoven J, 2017, MULTIMED TOOLS APPL, V76, P5661, DOI 10.1007/s11042-016-3646-1
   Vasardani M, 2013, INT J GEOGR INF SCI, V27, P2509, DOI 10.1080/13658816.2013.785550
   Vidal JC, 2014, KNOWL-BASED SYST, V55, P29, DOI 10.1016/j.knosys.2013.10.007
   WANG C., 2005, Proceedings of WWW-05, the 14th International World Wide Web Conference, P1138
NR 63
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28023
EP 28048
DI 10.1007/s11042-018-6021-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500013
DA 2024-07-18
ER

PT J
AU Attari, AA
   Shirazi, AAB
AF Attari, Ali Akbar
   Shirazi, Ali Asghar Beheshti
TI Robust audio watermarking algorithm based on DWT using Fibonacci numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind audio watermarking; Fibonacci numbers; Discrete wavelet transform;
   Human auditory masking
ID SINGULAR-VALUE DECOMPOSITION; SCHEME; DOMAIN; BLIND; SYNCHRONIZATION;
   TRANSFORM; DCT
AB This paper presents a blind and robust audio watermarking algorithm developed based on Fibonacci numbers properties and the discrete wavelet transform (DWT) advantages. The method embeds watermark bits in the 6th level approximation subband of DWT at which there is less sensitivity of the human auditory system. The key idea is dividing the 6th level approximation coefficients into small frames and modifying their magnitude based on Fibonacci numbers and watermark bit values. The proposed watermarking method demonstrates a superior robustness against different common attacks (i.e., Gaussian noise addition, Low-pass filter, Resampling, Requantizing, MP3 compression, Amplitude scaling, Echo addition, Time shift, and Cropping). Compared to recently developed methods, the proposed algorithm is much more robust against the most common attacks with capacity as high as 686 bits per second. The results of PEAQ testing verify the quality of watermarked audio signal without significant perceptual distortion. The algorithm allows flexibility in audio watermark algorithm to achieve a balance between robustness and imperceptibility while the capacity is maintained constant by choosing various kinds of sequence.
C1 [Attari, Ali Akbar; Shirazi, Ali Asghar Beheshti] IUST, Sch Elect Engn, Tehran 16844, Iran.
C3 Iran University Science & Technology
RP Shirazi, AAB (corresponding author), IUST, Sch Elect Engn, Tehran 16844, Iran.
EM A_Attari@vu.iust.ac.ir; abeheshti@iust.ac.ir
RI Beheshti Shirazi, Ali Asghar/T-6012-2018
CR Akansu A.N., 2001, Multiresolution signal decomposition: transforms, subbands, and wavelets, V2nd
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Attari AA, 2017, P INT C GRAPH SIGN P, P69
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Can Yekta Said, 2014, Journal of Advances in Computer Networks, V2, P6, DOI 10.7763/JACN.2014.V2.71
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Dhar PK, 2014, INT J SPEECH TECHNOL, V17, P133, DOI 10.1007/s10772-013-9214-4
   Fallahpour M, 2015, IEEE-ACM T AUDIO SPE, V23, P1273, DOI 10.1109/TASLP.2015.2430818
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Fugal D.L., 2009, Conceptual Wavelets in Digital Signal Processing: An In-depth, Practical Approach for the Non-mathematician
   Hu HT, 2017, CLUSTER COMPUT, V20, P805, DOI 10.1007/s10586-017-0770-2
   Hu HT, 2016, CIRC SYST SIGNAL PR, V35, P553, DOI 10.1007/s00034-015-0074-9
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Hu HT, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-12
   Hu HT, 2012, SIGNAL PROCESS, V92, P1109, DOI 10.1016/j.sigpro.2011.11.001
   Jeyhoon M, 2017, MULTIMED TOOLS APPL, V76, P3343, DOI 10.1007/s11042-016-3934-9
   Kabal P., 2002, TSP Lab Technical Report.
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Lin Yiqing, 2015, AUDIO WATERMARK
   Liu SC, 2006, J INF SCI ENG, V22, P535
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   seok Jongwon, 2012, Journal of Information and Communication Convergence Engineering, V10, P175, DOI 10.6109/jicce.2012.10.2.175
   Tewari T. K., 2015, THESIS
   Wang HQ, 2008, APPL ACOUST, V69, P868, DOI 10.1016/j.apacoust.2007.06.001
   Wang J., 2011, THESIS
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Xiang Y., 2017, DIGITAL AUDIO WATERM
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
NR 29
TC 10
Z9 10
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25607
EP 25627
DI 10.1007/s11042-018-5809-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400044
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Sunar, MS
   Kakh, SY
   Al-Rousan, R
   Ismail, I
AF Kolivand, Hoshang
   Sunar, Mohd Shahrizal
   Kakh, Samira Y.
   Al-Rousan, Riyadh
   Ismail, Ismahafezi
TI Photorealistic rendering: a survey on evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evaluation; Validation; Benchmarks for rendering; Real-time rendering;
   Realistic rendering
ID ILLUMINATION ESTIMATION; 3D RECONSTRUCTION; TRACKING; GENERATION;
   PERCEPTION; BLUR
AB This article is a systematic collection of existing methods and techniques for evaluating rendering category in the field of computer graphics. The motive for doing this study was the difficulty of selecting appropriate methods for evaluating and validating specific results reported by many researchers. This difficulty lies in the availability of numerous methods and lack of robust discussion of them. To approach such problems, the features of well-known methods are critically reviewed to provide researchers with backgrounds on evaluating different styles in photo-realistic rendering part of computer graphics. There are many ways to evaluating a research. For this article, classification and systemization method is use. After reviewing the features of different methods, their future is also discussed. Finally, dome pointers are proposed as to the likely future issues in evaluating the research on realistic rendering. It is expected that this analysis helps researchers to overcome the difficulties of evaluation not only in research, but also in application.
C1 [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Sunar, Mohd Shahrizal; Al-Rousan, Riyadh] Ctr Univ Teknol, MaGIC X Media & Games Innovat Ctr Excellence, UTM IRDA Digital Media, Skudai Johor 81310, Malaysia.
   [Kakh, Samira Y.] EDENZ Coll, Auckland, New Zealand.
   [Ismail, Ismahafezi] Univ Sultan Zainal Abidin, Fac Informat & Comp, Kuala Terengganu, Malaysia.
C3 Liverpool John Moores University; University of Liverpool; Universiti
   Teknologi Malaysia; Universiti Sultan Zainal Abidin
RP Kolivand, H (corresponding author), Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
EM H.Kolivand@ljmu.ac.uk
RI Ismail, Ismahafezi/G-8521-2019; Sunar, Mohd Shahrizal/AFQ-7366-2022;
   Kolivand, Hoshang/F-4736-2011; Kolivand, Hoshang/B-2501-2016
OI Ismail, Ismahafezi/0000-0001-9080-7825; Sunar, Mohd
   Shahrizal/0000-0002-0244-1622; Kolivand, Hoshang/0000-0001-5460-5679
CR Ackroyd S., 1981, DATA COLLECTION CONT
   Aittala M, 2010, VISUAL COMPUT, V26, P669, DOI 10.1007/s00371-010-0501-7
   Alhajhamad H, 2015, INT C INT SOFTW METH, P541
   Ali HH, 2017, MULTIMED TOOLS APPL, V76, P2591, DOI 10.1007/s11042-016-3254-0
   Ando R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461982
   Annen T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360633
   Annen Thomas., 2007, Proc. Eurographics Symposium on Ren- dering, P51
   Annen Thomas., 2008, P GRAPHICS INTERFACE, P155
   [Anonymous], 1990, QUALITATIVE EVALUATI, DOI DOI 10.1002/NUR.4770140111
   [Anonymous], 2005, Qualitative research Wiley Online Library
   [Anonymous], 1978, P 5 ANN C COMPUTER G, P270
   Audet Samuel, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P47, DOI 10.1109/CVPR.2009.5204319
   Baran I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866200
   Barringer R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462015
   Billeter M., 2010, P C HIGH PERF GRAPH, P39
   Bojsen-Hansen M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461991
   Chinthammit W, 2014, BIOMED RES INT
   CROW FC, 1977, COMMUN ACM, V20, P799, DOI 10.1145/359863.359869
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   de Castro T. K., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P36, DOI 10.1109/SVR.2012.9
   De Rousiers C, 2011, S INT 3D GRAPH GAM, P7
   Debevec P., 1998, SIGGRAPH98, P189, DOI DOI 10.1145/280814.280864
   Dimitrov R, 2007, TECHNICAL REPORT
   DOBASHI Y., 2002, GRAPHICS HARDWARE, P99
   Eisemann Elmar, 2006, P 2006 S INTERACTIVE, P71, DOI DOI 10.1145/1111411.1111424
   Engelhardt T., 2010, Proceedings_of_the_2010_ ACM_SIGGRAPH_symposium_on_Interactive_3D_Graphics_and_Games, P119
   Fernando Randima., 2005, SIGGRAPH 05, P35
   FOURNIER A, 1993, GRAPH INTER, P254
   Glaister A, 2008, WINDOWS ADV RASTERIZ
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grosch T, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P125
   Grosch Thorsten., 2005, Eurographics (Short Presentations), P53
   Gruber L, 2012, INT SYM MIX AUGMENT, P119, DOI 10.1109/ISMAR.2012.6402548
   Haller M., 2003, Proceedings of the ACM symposium on Virtual reality software and technology, P56, DOI DOI 10.1145/1008653.1008665
   Hensley J, 2005, COMPUT GRAPH FORUM, V24, P547, DOI 10.1111/j.1467-8659.2005.00880.x
   Hewitt M, 2007, NIHR RDS E MIDLANDS
   Hosek L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185591
   Jansen J., 2010, Proceedings of the 2010 ACM SIGGRAPH symposium on Interactive 3D Graphics and Games," I3D '10, P165
   Jensen B, 2009, SIMPLIFYING REAL TIM
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   Jia N, 2013, P 19 ACM S VIRT REAL, P209
   Jiang D, 2013, MULTIMED TOOLS APPL, P1
   Jimenez J., 2011, SIGGRAPH Courses, V2, P4
   Kán P, 2012, INT SYM MIX AUGMENT, P99, DOI 10.1109/ISMAR.2012.6402546
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Kellert M., 2013, 2013 Conference on Lasers & Electro-Optics. Europe & International Quantum Electronics Conference (CLEO EUROPE/IQEC), DOI 10.1109/CLEOE-IQEC.2013.6800663
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Knecht M., 2010, 2010 IEEE International Symposium on Mixed and Augmented Reality, P99, DOI DOI 10.1109/ISMAR.2010.5643556
   Kolivand H, 2013, THESIS
   Kolivand H, 2014, MULTIMED TOOLS APPL, P1
   Kolivand H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166424
   Kolivand H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108334
   Kolivand H, 2014, MULTIMED TOOLS APPL, V73, P1225, DOI 10.1007/s11042-013-1630-6
   Kolivand H, 2014, MULTIMED TOOLS APPL, V72, P2143, DOI 10.1007/s11042-013-1494-9
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Lauritzen Andrew., 2008, P GRAPHICS INTERFACE, P139
   Lavoué G, 2016, IEEE COMPUT GRAPH, V36, P21, DOI 10.1109/MCG.2016.72
   Lensing P, 2012, INT SYM MIX AUGMENT, P109, DOI 10.1109/ISMAR.2012.6402547
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Li D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462008
   Lieberknecht S, 2009, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2009.5336487
   Liu YL, 2010, COMPUT ANIMAT VIRT W, V21, P321, DOI 10.1002/cav.357
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Lokovic T, 2000, COMP GRAPH, P385, DOI 10.1145/344779.344958
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Madsen CB, 2013, COMPUTER VISION IMAG, P33
   Magnenat-Thalmann, 1988, Proceedings of Graphics Interface '88, P26
   Malterud K, 2001, LANCET, V358, P483, DOI 10.1016/S0140-6736(01)05627-6
   Martin Tobias., 2004, P EUROGRAPHICS S REN, P153
   Maule M., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P50, DOI 10.1109/SIBGRAPI-T.2012.9
   Max N. L., 1986, Computer Graphics, V20, P117, DOI 10.1145/15886.15899
   Mehta SU, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461947
   Mehta SU, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366182
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Nan Liu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P488, DOI 10.1109/WCSE.2009.716
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nowrouzezahrai D., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P173, DOI 10.1109/ISMAR.2011.6092384
   Oliveira MM, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P89
   Pan MH, 2009, COMPUT GRAPH FORUM, V28, P1927, DOI 10.1111/j.1467-8659.2009.01571.x
   Park Y, 2012, IEEE T VIS COMPUT GR, V18, P1449, DOI 10.1109/TVCG.2011.158
   Park Y, 2009, INT SYM MIX AUGMENT, P163, DOI 10.1109/ISMAR.2009.5336480
   Patton M.Q., 1982, Practical evaluation
   PELLACINI F, 2010, ACM T GRAPHIC, V29
   PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I
   Pharr M., 2010, PHYS BASED RENDERING
   Popper K., 2005, The logic of scientific discovery
   Rademacher P, 2001, SPRING EUROGRAP, P235
   Reeves W, 1987, P SIGGRAPH 87, V21, P557
   Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112
   Salvi M, 2010, COMPUT GRAPH FORUM, V29, P1289, DOI 10.1111/j.1467-8659.2010.01724.x
   Shen L, 2011, COMPUT GRAPH FORUM, V30, P493, DOI 10.1111/j.1467-8659.2011.01875.x
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Sunar M, 2001, THESIS
   Takagi A, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P68, DOI 10.1109/ISAR.2000.880925
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Wang LL, 2014, COMPUT GRAPH FORUM, V33, P264, DOI 10.1111/cgf.12348
   William D., 2006, P 2006 S INT 3D GRAP, P161, DOI DOI 10.1145/1111411.1111440
   Wu CL, 2011, IEEE T VIS COMPUT GR, V17, P1082, DOI [10.1109/TVCG.2010.224, 10.1109/TPDS.2010.224]
   Wyman C, 2015, ACM SIGGRAPH 2015 TA, P69
   Wyman C, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P87, DOI 10.1109/RT.2008.4634627
   Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048
   Xie L, 2013, MULTIMED TOOLS APPL, P1
   Xing G, 2011, 12 INT C COMP AID DE, P43
   Xing GY, 2012, COMPUT GRAPH-UK, V36, P857, DOI 10.1016/j.cag.2012.07.005
   Zheng F, 2012, INT SYM MIX AUGMENT, P335, DOI 10.1109/ISMAR.2012.6402601
   Zhou G, 2016, NEUROCOMPUTING
   Zokai S, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P217, DOI 10.1109/ISMAR.2003.1240705
NR 110
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25983
EP 26008
DI 10.1007/s11042-018-5834-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400059
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Terzidou, T
   Tsiatsos, T
   Apostolidis, H
AF Terzidou, Theodouli
   Tsiatsos, Thrasyvoulos
   Apostolidis, Hippokratis
TI Architecture and interaction protocol for pedagogical-empathic agents in
   3D virtual learning environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedagogical agents; Empathic agents; 3D virtual learning environments;
   Agent architecture; Interaction protocol; Immersive learning
ID 2ND LIFE; STUDENTS
AB This paper proposes an interaction design architecture and an interaction protocol for the construction of pedagogical agents acting in distributed 3D learning environments. Agents designed based on the proposed architecture are able to interact verbally, non-verbally or both with the students, combining empathic and pedagogical behavioral parameters in order to support students during online educational activities. The representation of the agent results from both pedagogical and emotional factors and is related with the learning environment and its technology. The agent logic is based on three types of the learning environment's events: (a) emotional events, (b) pedagogical events and (c) events that are triggered by the environment itself. The proposed architecture is validated through the implementation of an autonomous pedagogical-empathic agent in the virtual environment of OpenSim. The agent observes students' anxiety during the learning process and reacts when their anxiety level is considered high.
C1 [Terzidou, Theodouli; Tsiatsos, Thrasyvoulos; Apostolidis, Hippokratis] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Tsiatsos, T (corresponding author), Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
EM lterz@csd.auth.gr; tsiatsos@csd.auth.gr; aposti@csd.auth.gr
RI Tsiatsos, Thrasyvoulos/W-5386-2019; Apostolidis,
   Hippokratis/HKE-3192-2023
OI Tsiatsos, Thrasyvoulos/0000-0002-4946-9585; 
CR Aguilar RA, 2006, ELECT ROBOT AUTO MEC, P149
   Aimeur E, 1996, COMPUT EDUC, V27, P115, DOI 10.1016/0360-1315(96)00018-8
   Andreas K, 2010, COMPUT EDUC, V55, P603, DOI 10.1016/j.compedu.2010.02.021
   [Anonymous], 2007, Developing Multi-Agent Systems with JADE
   Apostolidis H, 2014, RES E LEARNING ICT E, P227
   Arafa Y, 2000, EP28831 MAPPA ESPRIT
   CHAN TW, 1990, INTELLIGENT TUTORING, P7
   Chen GD, 2012, EDUC TECHNOL SOC, V15, P62
   Chopra AK, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2438653.2438655
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   Clark R.E., 2014, The Cambridge Handbook of Multimedia Learning, P151
   Cook DJ, 2009, J AMB INTEL SMART EN, V1, P51, DOI 10.3233/AIS-2009-0007
   Damasio A., 1994, DESCARTESS ERROR EMO
   De Lucia A, 2009, COMPUT EDUC, V52, P220, DOI 10.1016/j.compedu.2008.08.001
   DILLENBOURG P, 1992, LECT NOTES COMPUT SC, V608, P651
   Elliott C., 1999, Artificial intelligence today. Recent trends and developments, P195
   *FIPA, 2000, FIPA ACL MESS STRUCT
   FRANKLIN S., 1997, INT WORKSHOP AGENT T, V1193, P21
   Gill S., 2004, Journal of Bodywork and Movement Therapies, V8, P288, DOI [DOI 10.1016/J.JBMT.2003.11.002, 10.1016/j.jbmt.2003.11.002]
   Hmelo-Silver C.E., 2002, P CSCL 2002, P199
   Izard CE, 2009, ANNU REV PSYCHOL, V60, P1, DOI 10.1146/annurev.psych.60.110707.163539
   Jarmon L, 2009, COMPUT EDUC, V53, P169, DOI 10.1016/j.compedu.2009.01.010
   Johnson W.L., 2000, INT J ARTIFICIAL INT, V11, P47
   Keil D, 2006, LECT NOTES COMPUTER, V3830
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P569, DOI 10.1007/s11423-006-0637-3
   Kim Y, 2017, ETR&D-EDUC TECH RES, V65, P219, DOI 10.1007/s11423-016-9476-z
   Landowska A, 2013, C HUM SYST INTERACT, P540, DOI 10.1109/HSI.2013.6577878
   Larson H.A., 2010, J SCH COUNSELING, V8, pn19
   Linnenbrink E. A., 2007, Emotion in Education, P107, DOI DOI 10.1016/B978-012372545-5/50008-3
   Lopes CV, 2011, IEEE INTERNET COMPUT, V15, P22, DOI 10.1109/MIC.2011.77
   Luck M., 1997, Intelligent Agents III. Agent Theories, Architectures, and Languages. ECAI '96 Workshop (ATAL) Proceedings, P49, DOI 10.1007/BFb0013575
   Maes P., 1991, DESIGNING AUTONOMOUS
   Miller RL, 2002, ENC COLL LEARN COMP
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Odell J., 2003, The Journal of Object Technology, V2, P39, DOI DOI 10.5381/JOT.2003.2.1.C5
   Olafson KM, 2001, BRAIN COGNITION, V45, P15, DOI 10.1006/brcg.2000.1248
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Russell S., 2009, Artificial intelligence
   Soliman M., 2010, 2010 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), P827
   Soller A., 2004, P ITS WORKSH, P5
   Takatoa R, 2005, COMPUTER SCI INFORM, V2, P23
   Terzidou T, 2015, ENCY INFORM SCI TECH, P2572, DOI [10.4018/978-1-4666-5888-2.ch250, DOI 10.4018/978-1-4666-5888-2.CH250]
   Terzidou T, 2016, IEEE T LEARN TECHNOL, V9, P217, DOI 10.1109/TLT.2016.2521649
   Ur S., 1995, Journal of Artificial Intelligence in Education, V6, P405
   VandenBos G.R.E., 2015, APA dictionary of psychology, V2nd, DOI DOI 10.1037/14646-000
   Veletsianos G, 2008, BRIT J EDUC TECHNOL, V39, P969, DOI 10.1111/j.1467-8535.2007.00797.x
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Wooldridge M, 1999, MULTIAGENT SYSTEMS, P27
NR 49
TC 10
Z9 10
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27661
EP 27684
DI 10.1007/s11042-018-5942-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500063
DA 2024-07-18
ER

PT J
AU Zhang, HZ
   Luo, CB
   Wang, Q
   Kitchin, M
   Parmley, A
   Monge-Alvarez, J
   Casaseca-de-la-Higuera, P
AF Zhang, Huaizhong
   Luo, Chunbo
   Wang, Qi
   Kitchin, Matthew
   Parmley, Andrew
   Monge-Alvarez, Jesus
   Casaseca-de-la-Higuera, Pablo
TI A novel infrared video surveillance system using deep learning based
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; CNN; Object detection; ATD/R; Super-resolution
ID OBJECT DETECTION
AB This paper presents a new, practical infrared video based surveillance system, consisting of a resolution-enhanced, automatic target detection/recognition (ATD/R) system that is widely applicable in civilian and military applications. To deal with the issue of small numbers of pixel on target in the developed ATD/R system, as are encountered in long range imagery, a super-resolution method is employed to increase target signature resolution and optimise the baseline quality of inputs for object recognition. To tackle the challenge of detecting extremely low-resolution targets, we train a sophisticated and powerful convolutional neural network (CNN) based faster-RCNN using long wave infrared imagery datasets that were prepared and marked in-house. The system was tested under different weather conditions, using two datasets featuring target types comprising pedestrians and 6 different types of ground vehicles. The developed ATD/R system can detect extremely low-resolution targets with superior performance by effectively addressing the low small number of pixels on target, encountered in long range applications. A comparison with traditional methods confirms this superiority both qualitatively and quantitatively.
C1 [Zhang, Huaizhong] Univ West Scotland, Dept Comp Sci, Paisley PA1 2BE, Renfrew, Scotland.
   [Wang, Qi; Monge-Alvarez, Jesus; Casaseca-de-la-Higuera, Pablo] Univ West Scotland, Paisley PA1 2BE, Renfrew, Scotland.
   [Zhang, Huaizhong] Edge Hill Univ, Dept Comp Sci, Ormskirk L39 4QP, England.
   [Luo, Chunbo] Univ Exeter, Exeter EX4 4QJ, Devon, England.
   [Kitchin, Matthew; Parmley, Andrew] Thales UK, Glasgow G51 4BZ, Lanark, Scotland.
   [Casaseca-de-la-Higuera, Pablo] Univ Valladolid, Lab Procesado Imagen, E-47011 Valladolid, Spain.
C3 University of West Scotland; University of West Scotland; Edge Hill
   University; University of Exeter; Thales Group; Universidad de
   Valladolid
RP Zhang, HZ (corresponding author), Univ West Scotland, Dept Comp Sci, Paisley PA1 2BE, Renfrew, Scotland.; Zhang, HZ (corresponding author), Edge Hill Univ, Dept Comp Sci, Ormskirk L39 4QP, England.
EM zhangh@edgehill.ac.uk
RI Casaseca-de-la-Higuera, Pablo/L-4140-2017
OI Casaseca-de-la-Higuera, Pablo/0000-0003-1565-0842; Zhang,
   Huaizhong/0000-0001-7867-9453
FU Thales UK; Centre of Excellence for Sensor and Imaging System (CENSIS);
   Scottish Funding Council under the project "AALART. Thales-Challenge
   Low-pixel Automatic Target Detection and Recognition (ATD/ATR)"
   [CAF-0036]; Royal Society of Edinburgh; National Science Foundation of
   China
FX This work was funded by Thales UK, the Centre of Excellence for Sensor
   and Imaging System (CENSIS), and the Scottish Funding Council under the
   project "AALART. Thales-Challenge Low-pixel Automatic Target Detection
   and Recognition (ATD/ATR)", ref. CAF-0036. Thanks are also given to the
   Digital Health and Care Institute (DHI, project Smartcough-MacMasters),
   which partially supported Mr. Monge-Alvarez's contribution, and to the
   Royal Society of Edinburgh and National Science Foundation of China for
   the funding associated to the project "Flood Detection and Monitoring
   using Hyperspectral Remote Sensing from Unmanned Aerial Vehicles", which
   partially covered Dr. Casaseca-de-la-Higuera's, Dr. Luo's, and Prof.
   Wang's contribution. Dr. Casaseca-de-la-Higuera would also like to
   acknowledge the Royal Society of Edinburgh for the funding associated to
   project "HIVE".
CR Bagavathiappan S, 2013, INFRARED PHYS TECHN, V60, P35, DOI 10.1016/j.infrared.2013.03.006
   Craig R, 2012, SPIE
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fernandez R., 2016, THESIS
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manolakis D., 2003, Lincoln Laboratory Journal, V14, P79
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang L., 2015, CVPR
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2016, SPIE, P515
NR 28
TC 25
Z9 28
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26657
EP 26676
DI 10.1007/s11042-018-5883-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500020
OA Green Submitted, Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Khadhraoui, T
   Borgi, MA
   Benzarti, F
   Ben Amar, C
   Amiri, H
AF Khadhraoui, Taher
   Borgi, Mohamed Anouar
   Benzarti, Faouzi
   Ben Amar, Chokri
   Amiri, Hamid
TI Local generic representation for patch uLBP-based face recognition with
   single training sample per subject
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Uniform local binary patterns; Local generic
   representation; Single training sample per subject
ID SPARSE REPRESENTATION; BINARY PATTERNS; COLLABORATIVE REPRESENTATION;
   ROBUST; CLASSIFICATION; SELECTION; CORRENTROPY; SIGNAL
AB In this paper, we propose a novel paradigm of Patch uniform Local Binary Patterns (PuLBP) based Local Generic Representation (LGR) for face recognition. Indeed, we introduce a new block in which an uLBP is used to approximate both reference and variation subsets. Thus, we concentrate on the challenging problem of a single sample per person in a gallery set. Particularly, the main problem is whether only one training subject per class is available. One of the novelties of our technique is to generate virtual samples of each subject. The new sample generic image in a gallery set is adopted to produce the intra-personal variations of different individuals. We illustrate the experimental results of our new algorithm on different benchmark databases, including the AR face database, the Extended Yale B face database, the FRGC database and the FEI database.
C1 [Khadhraoui, Taher; Benzarti, Faouzi; Amiri, Hamid] Univ Tunis El Manar, Natl Engn Sch Tunis ENIT, SITI Lab, Tunis, Tunisia.
   [Borgi, Mohamed Anouar; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Khadhraoui, T (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis ENIT, SITI Lab, Tunis, Tunisia.
EM khadhra.th@gmail.com; anoir.borgi@ieee.org; benzartif@yahoo.fr;
   chokri.benamar@ieee.org; hamidlamiri@gmail.com
RI Benzarti, Faouzi/AAJ-8072-2020; Chokri, BEN AMAR/K-5237-2012; Benzarti,
   Faouzi/H-8065-2018
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program; NSF [DMS 1005799, DMS 1008900]
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program. D. L acknowledges partial support by
   NSF DMS 1005799 and DMS 1008900.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, ASIAN C COMPUTER VIS
   [Anonymous], 2016, MULTIMED TOOLS APPL
   Borg M., 2016, IEEE T SOFTWARE ENG, V99, P1
   Borgi Mohamed Anouar, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P514, DOI 10.1109/ICASSP.2014.6853649
   Borgi MA, 2015, MULTIMED TOOLS APPL, V74, P11281, DOI 10.1007/s11042-014-2228-3
   Borgi MA, 2015, EXPERT SYST APPL, V42, P269, DOI 10.1016/j.eswa.2014.07.044
   Cevikalp H, 2010, PATTERN RECOGN LETT, V31, P1285, DOI 10.1016/j.patrec.2010.03.009
   Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Fan ZZ, 2015, J VIS COMMUN IMAGE R, V28, P15, DOI 10.1016/j.jvcir.2015.01.001
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Khadhraoui T., 2014, 15 IEEEACIS INT C SO, P1, DOI [10.1109/SNPD.2014.6888679, DOI 10.1109/SNPD.2014.6888679]
   Khadhraoui T, 2014, 2014 IEEE/ACIS 13TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P211, DOI 10.1109/ICIS.2014.6912136
   Khorsandi R. S., 2015, SPARSE REPRESENTATIO
   Kumar P, 2016, INT J APPL ENG RES
   Kumar R, 2011, IEEE I CONF COMP VIS, P2375, DOI 10.1109/ICCV.2011.6126520
   Lee W, 2013, SENSORS-BASEL, V13, P12830, DOI 10.3390/s131012830
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Lu CY, 2013, IEEE I CONF COMP VIS, P1801, DOI 10.1109/ICCV.2013.226
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mäenpää T, 2002, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2002.1044840
   Maenpaa T, 2003, IMAGE ANAL, P267
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Martinez A., 1998, AR FACE DATABASE
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shahdi S. O., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P52, DOI 10.1109/ICSIPA.2011.6144064
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Vezzetti E, 2016, INT J BIOMETRICS, V8, P216
   Wang C, 2015, IMAGE VISION COMPUT, V38, P65, DOI 10.1016/j.imavis.2014.10.013
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu J, 2013, NEUROCOMPUTING, V99, P76, DOI 10.1016/j.neucom.2012.06.018
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 52
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24203
EP 24222
DI 10.1007/s11042-018-5679-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900049
DA 2024-07-18
ER

PT J
AU Qi, MP
   Chen, JH
AF Qi, Mingping
   Chen, Jianhua
TI New robust biometrics-based mutual authentication scheme with key
   agreement using elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Elliptic curve cryptography; Mobile environment;
   Biometrics; Smart card
ID PASSWORD AUTHENTICATION; SMART CARDS; PRIVACY
AB In this work, we demonstrate that Chaudhry et al.'s recent biometrics-based three factor authentication scheme is vulnerable to the denial of service attack, and it also fails to provide perfect forward secrecy because it only uses the lightweight symmetric key primitives to ensure security. To enhance the information security, this article presents a new robust biometrics-based mutual authentication scheme using elliptic curve cryptography for client-server architecture based applications in mobile environment. The proposed scheme supports session key agreement and flawless mutual authentication of participants, which is proved under the BAN logic. Moreover, the proposed scheme provides prefect security attributes and resists all known attacks, and it has perfect performance in communication cost. Thereby, the proposed scheme is more suitable for client-server architecture based applications.
C1 [Qi, Mingping; Chen, Jianhua] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Qi, MP (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
EM mpqr_math@163.com; chenjh_eoc@163.com
CR [Anonymous], MULTIMED TOOL APPL
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chaudhry SA, 2018, MULTIMED TOOLS APPL, V77, P5503, DOI 10.1007/s11042-017-4464-9
   Chaudhry SA, 2018, J SUPERCOMPUT, V74, P3504, DOI 10.1007/s11227-015-1601-y
   Chen BL, 2014, INT J COMMUN SYST, V27, P377, DOI 10.1002/dac.2368
   Cheng-Chi Lee, 2002, Operating Systems Review, V36, P23, DOI 10.1145/583800.583803
   Das AK, 2015, WIRELESS PERS COMMUN, V82, P1377, DOI 10.1007/s11277-015-2288-3
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   Jiang Q, 2015, INT J COMMUN SYST, V28, P383, DOI 10.1002/dac.2644
   Khan MK, 2009, IETE TECH REV, V26, P191, DOI 10.4103/0256-4602.50703
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kim TH, 2012, J SYST SOFTWARE, V85, P2899, DOI 10.1016/j.jss.2012.06.063
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Law L, 2003, DESIGN CODE CRYPTOGR, V28, P119, DOI 10.1023/A:1022595222606
   Li CT, 2013, IET INFORM SECUR, V7, P3, DOI 10.1049/iet-ifs.2012.0058
   Li XX, 2010, IEEE T IND ELECTRON, V57, P793, DOI 10.1109/TIE.2009.2028351
   Lin CL, 2003, COMPUT SECUR, V22, P68, DOI 10.1016/S0167-4048(03)00114-7
   Maitra T, 2016, SECUR COMMUN NETW, V9, P4166, DOI 10.1002/sec.1596
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2015, WIRELESS PERS COMMUN, V83, P1
   Nikooghadam M, 2017, MULTIMED TOOLS APPL, V76, P13401, DOI 10.1007/s11042-016-3704-8
   Peyravian M, 2006, COMPUT COMMUN, V29, P660, DOI 10.1016/j.comcom.2005.07.025
   Tsai JL, 2013, IEEE T IND INFORM, V9, P2004, DOI 10.1109/TII.2012.2230639
   Wang D, 2015, L N INST COMP SCI SO, V152, P141, DOI 10.1007/978-3-319-23829-6_11
   Wen FT, 2015, WIRELESS PERS COMMUN, V80, P1747, DOI 10.1007/s11277-014-2111-6
   Wu F, 2015, COMPUT ELECTR ENG, V45, P274, DOI 10.1016/j.compeleceng.2015.02.015
   Xie Q, 2017, COMPUT ELECTR ENG, V59, P218, DOI 10.1016/j.compeleceng.2016.11.038
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yan XP, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9972-1
   Yang GM, 2008, J COMPUT SYST SCI, V74, P1160, DOI 10.1016/j.jcss.2008.04.002
   Yeh HL, 2013, IET INFORM SECUR, V7, P247, DOI 10.1049/iet-ifs.2011.0348
   Zhang LP, 2017, WIREL NETW, V23, P1901, DOI 10.1007/s11276-016-1267-2
NR 32
TC 14
Z9 15
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23335
EP 23351
DI 10.1007/s11042-018-5683-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900012
DA 2024-07-18
ER

PT J
AU Ghouti, L
AF Ghouti, Lahouari
TI Robust perceptual color image hashing using randomized hypercomplex
   matrix factorizations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust color perceptual hashing; Singular value decomposition (SVD);
   Quaternion SVD (QSVD); Non-negative matrix factorization (NMF); Fast
   Johnson-Lindenstrauss transform (FJLT); Hash code detection
ID SINGULAR-VALUE DECOMPOSITION; BIDIAGONALIZATION; EXTRACTION; TRANSFORM;
   REAL
AB Compact representations of color image and video content allow efficient search, retrieval and storage of this content over the Internet and online repositories. However, most of these representations neither take into account the inherent correlation nor the perceptual redundancy of the color information. In this paper, we propose a perceptual hash representation for color images using robust image features. These features, most dominant singular vectors extracted using the quaternion singular value decomposition (QSVD) of pseudorandomly selected overlapping image blocks, are efficiently used for color image search and retrieval applications. Their robustness is guaranteed by the underlying singular vectors. The motivation behind our work is twofold: 1) the ability of the QSVD algorithm to provide the best low-rank approximation of color images in the Frobenius norm sense and 2) compact representations to handle the color components as a single entity. The QSVD algorithm leads to proper modeling of possible geometric attacks as an independent and identically-distributed (i.i.d) quaternionic random noise on the singular vectors. Such modeling simplifies the hash code detector design. Hash code robustness against geometric attacks is evaluated over a large set of test color images where the proposed scheme outperforms existing factorization-based hashing algorithms in terms of lower miss and false alarm probabilities by orders of magnitude. Finally, the improved robustness and performance does not come at the expense of increased computational complexity which is another salient feature of the proposed hashing scheme.
C1 [Ghouti, Lahouari] King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Ghouti, L (corresponding author), King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia.
EM lahouari@kfupm.edu.sa
OI Ghouti, Lahouari/0000-0002-6381-4250
FU King Fahd University of Petroleum and Minerals
FX The author would like to thank King Fahd University of Petroleum and
   Minerals for supporting this work and the anonymous reviewers are for
   their careful reading of the paper drafts, helpful and constructive
   comments that greatly contributed to improving the quality of the paper.
CR Ailon N, 2009, SIAM J COMPUT, V39, P302, DOI 10.1137/060673096
   Alam M, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P340, DOI 10.1109/SIPS.2003.1235693
   [Anonymous], THESIS
   [Anonymous], [No title captured]
   [Anonymous], P 4 INT C IM CRIM DE
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], PHOTONICS W 98 ELECT
   [Anonymous], [No title captured]
   Bhattacharjee S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P435, DOI 10.1109/ICIP.1998.723518
   Cannons J, 2004, IEEE T IMAGE PROCESS, V13, P1393, DOI 10.1109/TIP.2004.834660
   Cox I. J., 2002, Digital Watermarking
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Ghouti Lahouari, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3794, DOI 10.1109/ICASSP.2014.6854311
   Ghouti L, 2017, NEW PERCEPTUAL VIDEO, P1
   Ginzberg P, 2011, IEEE T SIGNAL PROCES, V59, P3025, DOI 10.1109/TSP.2011.2138701
   Golub G. H., 1965, SIAM J. Numer. Anal., V2, P205
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Gonde AB, 2013, DIGIT SIGNAL PROCESS, V23, P142, DOI 10.1016/j.dsp.2012.04.019
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gueziec AP, 1997, IEEE COMPUT SCI ENG, V4, P29, DOI 10.1109/99.641607
   Horn R., 1985, Matrix Analysis, DOI [10.1017/CBO9780511810817, 10.1017/CBO9781139020411]
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Khelifi F, 2010, IEEE SIGNAL PROC LET, V17, P43, DOI 10.1109/LSP.2009.2032451
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Laradji IH, 2013, IEEE IMAGE PROC, P4402, DOI 10.1109/ICIP.2013.6738907
   Le Bihan N, 2004, SIGNAL PROCESS, V84, P1177, DOI 10.1016/j.sigpro.2004.04.001
   Le Bihan N, 2007, APPL MATH COMPUT, V187, P1265, DOI 10.1016/j.amc.2006.09.055
   Loots MT, 2013, STATISTICS-ABINGDON, V47, P1224, DOI 10.1080/02331888.2012.695376
   Lv X, 2013, THESIS
   Mallik RK, 2011, IEEE T COMMUN, V59, P3353, DOI 10.1109/TCOMM.2011.101011.110046
   Mao Y, 2007, IEEE T INF FOREN SEC, V2, P462, DOI 10.1109/TIFS.2007.902260
   Menezes A., 1996, Cryptography
   Mihcak K, 2001, P ACM WORKSH SEC PRI, P13
   Miller ML, 2005, J VLSI SIG PROC SYST, V41, P285, DOI 10.1007/s11265-005-4152-2
   Monga V., 2006, Acoustics, Speech and Signal Processing, V2, May 2006, pII
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T INF FOREN SEC, V1, P68, DOI 10.1109/TIFS.2005.863502
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Naouai M, 2011, LECT NOTES COMPUT SC, V6669, P452
   Ou Y, 2010, IEICE T INF SYST, VE93D, P1020, DOI 10.1587/transinf.E93.D.1020
   PAIGE CC, 1974, SIAM J NUMER ANAL, V11, P197, DOI 10.1137/0711019
   Papoulis A., 1965, PROBABILITY RANDOM V
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Qi QF, 2008, IEEE INT C NETW SENS, P462
   Sangwine SJ, 2006, APPL MATH COMPUT, V182, P727, DOI 10.1016/j.amc.2006.04.032
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   SPRINGER MD, 1970, SIAM J APPL MATH, V18, P721, DOI 10.1137/0118065
   Su PC, 2009, IEEE T CIRC SYST VID, V19, P668, DOI 10.1109/TCSVT.2009.2017404
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang ZJ, 2013, AEU-INT J ELECTRON C, V67, P717, DOI 10.1016/j.aeue.2013.02.009
   Tang ZJ, 2012, APPL MATH INFORM SCI, V6, p643S
   Tang ZJ, 2011, FUND INFORM, V106, P75, DOI 10.3233/FI-2011-377
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Took CC, 2011, SIGNAL PROCESS, V91, P214, DOI 10.1016/j.sigpro.2010.06.024
   Vakhania NN, 2010, THEOR PROBAB APPL+, V54, P363, DOI 10.1137/S0040585X97984176
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Vía J, 2011, IEEE T SIGNAL PROCES, V59, P1356, DOI 10.1109/TSP.2010.2101067
   Vía J, 2010, IEEE T INFORM THEORY, V56, P3502, DOI 10.1109/TIT.2010.2048440
   [王海涛 Wang Haitao], 2005, [计算机工程, Computer Engineering], V31, P178
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolf L.A., 1936, Bull. Amer. Math. Soc, V42, P737, DOI DOI 10.1090/S0002-9904-1936-06417-7
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
   Xu Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043493
   Xudong Lv, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P725, DOI 10.1109/MMSP.2008.4665170
   Zhang FZ, 1997, LINEAR ALGEBRA APPL, V251, P21, DOI 10.1016/0024-3795(95)00543-9
   Zhenjun Tang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P237, DOI 10.1007/978-3-642-35236-2_24
NR 69
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19895
EP 19929
DI 10.1007/s11042-017-5355-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500046
DA 2024-07-18
ER

PT J
AU Qian, C
   Breckon, TP
   Xu, ZZ
AF Qian, Cheng
   Breckon, Toby P.
   Xu, Zezhong
TI Clustering in pursuit of temporal correlation for human motion
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humanmotion segmentation; Temporal correlation; Temporal clustering;
   Spectral clustering
ID SUBSPACE SEGMENTATION; ROBUST
AB Temporal correlation is an important property of the video sequence. However, most methods only accomplish the clustering of frames via the measurement of similarity between frame pair, and the temporal correlation among frames is rarely taken into account. In this paper, a method for clustering in pursuit of temporal correlation is proposed to address human motion segmentation problem. Aiming at the video sequence, a one-hot indicator vector is extracted from a frame as a frame-level feature. The description of the relationship between the features is formulated as a minimization problem with respect to a similarity graph. A temporal constraint in the form of a trace is imposed on the similarity graph to capture the temporal correlation. On the premise of the non-negative similarity graph, an optimal solution to the graph augments the relationship between the selected features and their adjacent features, while suppressing its relevance to the features that are far away from it in terms of the time span. Normalized cut is implemented on the graph so as to give clustering results. The experiments on human motion segmentation demonstrate the superior performance of the proposed method in tackling the motion data.
C1 [Qian, Cheng; Xu, Zezhong] Changzhou Inst Technol, 666 Liaohe Rd, Changzhou 213031, Jiangsu, Peoples R China.
   [Qian, Cheng] Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, 200 Xiaolingwei, Nanjing 210094, Jiangsu, Peoples R China.
   [Breckon, Toby P.] Univ Durham, Sch Engn & Comp Sci, Durham DH1 3LE, England.
C3 Changzhou Institute of Technology; Nanjing University of Science &
   Technology; Durham University
RP Qian, C (corresponding author), Changzhou Inst Technol, 666 Liaohe Rd, Changzhou 213031, Jiangsu, Peoples R China.; Qian, C (corresponding author), Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, 200 Xiaolingwei, Nanjing 210094, Jiangsu, Peoples R China.
EM qc_hz@163.com
RI Xu, Zezhong/AAJ-3849-2020; Breckon, Toby/ABD-1451-2020
OI Breckon, Toby/0000-0003-1666-7590
FU National Natural Science Foundation of China [61602063]; Project of
   Natural Science Research of Higher Education Institutions of Jiangsu
   Province [15KJB520003]; Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) [SHAQKFKT201505]; Qing Lan Project
FX This work has been partly supported by the National Natural Science
   Foundation of China (Grant No. 61602063), the Project of Natural Science
   Research of Higher Education Institutions of Jiangsu Province (Grant No.
   15KJB520003) and the Project supported by the Jiangsu Key Laboratory of
   Image and Video Understanding for Social Safety (Nanjing University of
   Science and Technology) (Grant No. SHAQKFKT201505). It is also sponsored
   by Qing Lan Project.
CR [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   Aoki T, 2013, IEEE SYS MAN CYBERN, P1181, DOI 10.1109/SMC.2013.205
   Avgerinakis K, 2016, COMPUT VIS IMAGE UND, V144, P46, DOI 10.1016/j.cviu.2015.10.013
   Bahadori MT, 2015, PR MACH LEARN RES, V37, P228
   Baptista RD, 2017, IEEE T NEUR SYS REH, V25, P628, DOI 10.1109/TNSRE.2016.2591783
   Beh J, 2014, PATTERN RECOGN, V47, P1586, DOI 10.1016/j.patcog.2013.11.010
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fod A., 2012, AUTON ROBOT, V12, P39
   Gao X., 2017, ACM T INTEL SYST TEC, V8, P1
   Gong D, 2012, LECT NOTES COMPUT SC, V7574, P229, DOI 10.1007/978-3-642-33712-3_17
   Gong D, 2014, IEEE T PATTERN ANAL, V36, P1414, DOI 10.1109/TPAMI.2013.244
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hu H, 2015, IEEE T PATTERN ANAL, V37, P1542, DOI 10.1109/TPAMI.2014.2377740
   Hwang KS, 2017, IEEE T IND INFORM, V13, P1099, DOI 10.1109/TII.2017.2647993
   Jung HJ, 2017, PATTERN RECOGN LETT, V85, P21, DOI 10.1016/j.patrec.2016.11.012
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Kruger B, 2017, IEEE T PATTERN ANAL, V19, P787
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Li M, 2016, MULTIMED TOOLS APPL, V75, P9205, DOI 10.1007/s11042-016-3480-5
   Li S, 2015, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2015.506
   Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1
   Lin JFS, 2016, IEEE T HUM-MACH SYST, V46, P325, DOI 10.1109/THMS.2015.2493536
   Lin JFS, 2014, IEEE ENG MED BIO, P9, DOI 10.1109/EMBC.2014.6943516
   Lin JFS, 2014, IEEE T NEUR SYS REH, V22, P168, DOI 10.1109/TNSRE.2013.2259640
   Liu G., 2010, P INT C MACH LEARN, P663
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lv N, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1117, DOI 10.1109/CISP.2013.6745223
   Tao DP, 2017, IEEE T CIRC SYST VID, V27, P62, DOI 10.1109/TCSVT.2016.2539778
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tierney S, 2014, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2014.134
   Vicente I, 2012, ADV ROBOTICS, V21, P1687
   Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 35
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19615
EP 19631
DI 10.1007/s11042-017-5408-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500033
DA 2024-07-18
ER

PT J
AU Gan, JJ
   Liu, JF
   Luo, XY
   Yang, CF
   Liu, FL
AF Gan, Junjun
   Liu, Jiufen
   Luo, Xiangyang
   Yang, Chunfang
   Liu, Fenlin
TI Reliable steganalysis of HUGO steganography based on partially known
   plaintext
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Syndrome-trellis codes(STCs); Parameter recognition;
   Ciphertext embedding
ID IMAGE
AB The image adaptive steganography represented by HUGO (Highly Undetectable steGO) has high anti-detection capabilities. The primary challenge for steganalyzers is how to reliably detect such steganography and extract the embedded message from stego. Although existing steganalysis algorithms based on parameter recognition of STCs (Syndrome-Trellis Codes) can reliably detect adaptive steganography when the embedded message is in plaintext, the steganalysis method is ineffective when the embedded message is in ciphertext. Therefore, a steganalysis algorithm based on partially known plaintext is proposed in this paper. The steganalysis algorithm targets situations wherein in order to facilitate the receiver's extraction and storage of the embedded message, the file format name and message length may be transported without encryption when HUGO steganography is used to transport the encrypted file. First, the structural characteristics of the parity-check matrix were utilized to simplify the STCs decoding equation. Second, we calculated the submatrix by solving nonhomogeneous linear equations instead of exhausting submatrix, thus, parameter recognition efficiency was significantly improved. Finally, we verified the correctness of the submatrix and extracted the embedded message from stego images. The experimental results show that parameter recognition of STCs can be achieved using an ordinary PC within a short time. Therefore, the embedded message can be extracted when the partly embedded message is known.
C1 [Gan, Junjun; Liu, Jiufen; Luo, Xiangyang; Yang, Chunfang; Liu, Fenlin] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
   [Gan, Junjun; Liu, Jiufen; Luo, Xiangyang; Yang, Chunfang; Liu, Fenlin] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Liu, Jiufen] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.; Luo, XY (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM junjun_gan@163.com; jiufenliu@163.com; luoxy_ieu@sina.com;
   chunfangyang@126.com; liufenlin@vip.sina.com
FU National Natural Science Foundation of China [61379151, 61401512,
   61572052, U1636219]; National Key R&D Program of China [2016YFB0801303,
   2016QY01W0105]; Key Technologies R&D Program of Henan Province
   [162102210032]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61379151, 61401512, 61572052, and U1636219), the
   National Key R&D Program of China (Grant No. 2016YFB0801303 and
   2016QY01W0105), and the Key Technologies R&D Program of Henan Province
   (Grant No. 162102210032).
CR [Anonymous], ACM WORKSH INF HID M
   [Anonymous], P SPIE EL IM MED WAT
   [Anonymous], 2012, LECT NOTES COMPUTER
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P85, DOI 10.1007/978-3-642-24178-9_7
   Fridrich J., 2013, TRONIC IMAGING MEDIA, V8665, P1
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
NR 21
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18007
EP 18027
DI 10.1007/s11042-017-5134-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900024
DA 2024-07-18
ER

PT J
AU Himeur, Y
   Sadi, KA
AF Himeur, Yassine
   Sadi, Karima Ait
TI Robust video copy detection based on ring decomposition based binarized
   statistical image features and invariant color descriptor (RBSIF-ICD)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video copy detection; Ring decomposition; RBSIF; ICD; Verification rate;
   Matching
ID SEGMENTATION; ROTATION
AB Content based video copy detection (CBVCD) is considered as an active research field due to the requirement of copyright protection, business intelligence, video retrieval, etc. In this paper, we propose a CBVCD scheme using Ring decomposition based Binarized Statistical Image Features (RBSIF) and Invariant Color Descriptor (ICD), namely RBSIF-ICD. This hybrid descriptor is based on the combination of texture features extracted using RBSIF and a color characteristics derived using ICD. Firstly, a pre-processing is applied on each video sequence to remove borders. Secondly, the RBSIF descriptor is applied to each video frame to obtain the texture features. Then, ICD is applied to the video frames to construct an invariant color description which is very robust to geometrical attacks. Finally, RBSIF and ICD are fused to develop the RBSIF-ICD that will be very robust against several attacks such as rotation, flipping, strong compression, ... etc. For the evaluation purpose, the TRECVID 2009 database is used to test the robustness of the proposed system. Experiments reveal that the proposed RBSIF-ICD system outperforms the state-of-the-art algorithms under all the attacks and manipulations considered in this framework.
C1 [Himeur, Yassine; Sadi, Karima Ait] CDTA, TELECOM Div, Algiers 16303, Algeria.
C3 Centre for the Development of Advanced Technologies (CDTA)
RP Himeur, Y (corresponding author), CDTA, TELECOM Div, Algiers 16303, Algeria.
EM yhimeur@cdta.dz; aitsaadi@cdta.dz
RI Himeur, Yassine/AAK-7814-2021
OI Himeur, Yassine/0000-0001-8904-5587
FU CDTA project - FNR (Fond National de la Recherche Scientique et de
   Developpement Technologique) of Algeria [FNR:BIOSMC/PCV/14-16]
FX This project is supported by the CDTA project funded by the FNR (Fond
   National de la Recherche Scientique et de Developpement Technologique)
   of Algeria (FNR:BIOSMC/PCV/14-16).
CR [Anonymous], 2013, P IEEE 6 INT C BIOME
   [Anonymous], 2016, INT J COMPUTING
   Boukhari A, 2016, J VIS COMMUN IMAGE R, V34, P50, DOI 10.1016/j.jvcir.2015.10.015
   Chiu CY, 2010, IEEE T CIRC SYST VID, V20, P1603, DOI 10.1109/TCSVT.2010.2087471
   Cirakman O, 2014, MULTIMED TOOLS APPL, V71, P1381, DOI 10.1007/s11042-012-1269-8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Domke J, 2006, P BRIT MACH VIS C ED
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Himeur Y, 2011, INT J COMPUT APPL, V53, P33
   Himeur Y, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P40
   Himeur Y, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P300, DOI 10.1109/SITIS.2015.71
   Himeur Y, 2015, IEEE INT SYMP SIGNAL, P495, DOI 10.1109/ISSPIT.2015.7394386
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Kim S, 2014, J VIS COMMUN IMAGE R, V25, P373, DOI 10.1016/j.jvcir.2013.12.003
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Law-To J, 2009, MULTIMEDIA SYST, V15, P337, DOI 10.1007/s00530-009-0164-2
   Liao KY, 2015, J INTELL INF SYST, V44, P133, DOI 10.1007/s10844-014-0332-5
   Liu H, 2013, IEEE T KNOWL DATA EN, V25, P1706, DOI 10.1109/TKDE.2012.92
   Liu Y., 2008, GIS 08, P1
   Liu Z, 2009, P TRECVID 2009 WORKS
   Maani R, 2013, PATTERN RECOGN, V46, P2103, DOI 10.1016/j.patcog.2013.01.014
   Barrios JM, 2013, MULTIMED TOOLS APPL, V62, P75, DOI 10.1007/s11042-011-0915-x
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Nan N, 2015, IEEE T CIRC SYST VID, V25, P1682, DOI 10.1109/TCSVT.2015.2395771
   Nie X, 2014, IET IMAGE PROCESS, V8, P751
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P109, DOI 10.1007/978-0-85729-748-8_7
   Poullot S, 2010, MULTIMED TOOLS APPL, V47, P279, DOI 10.1007/s11042-009-0323-7
   Ren J, 2012, P 2 ACM INT C MULT R, V14
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   Tasdemir K, 2014, SIGNAL IMAGE VIDEO P, V8, P1049, DOI 10.1007/s11760-014-0627-6
   Thomas RM, 2015, PROCEDIA COMPUT SCI, V46, P1668, DOI 10.1016/j.procs.2015.02.106
   Tian YH, 2013, IEEE MULTIMEDIA, V20, P72, DOI 10.1109/MMUL.2012.62
   Wei SK, 2015, MULTIMEDIA SYST, V21, P207, DOI 10.1007/s00530-014-0398-5
   Xu ZH, 2009, IEEE INT CON MULTI, P434, DOI 10.1109/ICME.2009.5202527
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhao WL, 2013, IEEE T IMAGE PROCESS, V22, P980, DOI 10.1109/TIP.2012.2226043
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
   2009, NATURAL IMAGE STAT, V39, P151
NR 41
TC 14
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17309
EP 17331
DI 10.1007/s11042-017-5307-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300060
DA 2024-07-18
ER

PT J
AU Kashef, S
   Nezamabadi-pour, H
   Rashedi, E
AF Kashef, Shima
   Nezamabadi-pour, Hossein
   Rashedi, Esmat
TI Adaptive enhancement and binarization techniques for degraded plate
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE license plate recognition (LPR); contrast enhancement; background
   removal; shadow removal; binarization
ID ALGORITHM; RECOGNITION
AB Vehicle License Plate Recognition (VLPR) is one of the most important aspects of applying computer techniques in Intelligent Transport Systems (ITS). They face difficulties like shadows effects, non-uniform illumination intensity, and dirty plates. To tackle these problems, this paper proposes a new VLPR system by producing a contrast enhancement method, a background removal method, and a binarization method. After binarization, an OCR method using artificial neural network (ANN) reads the plate characters. The performance of the proposed system is tested on 4 k Iranian vehicle license plate images. The proposed method causes the correct recognition rate of 91.2%. The results obtained in comparison to those of well-known methods show that the proposed system is robust for moving cars in outside environment and under different illumination conditions.
C1 [Kashef, Shima; Nezamabadi-pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
   [Rashedi, Esmat] Grad Univ Adv Technol, Dept Elect Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK); Graduate University of
   Advanced Technology
RP Kashef, S (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
EM shkashef.1988@yahoo.com; nezam@uk.ac.ir; e.rashedi@kgut.ac.ir
RI Rashedi, Esmat/AAZ-7069-2020; Nezamabadi-pour, Hossein/AAB-4009-2019
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348; Rashedi,
   Esmat/0000-0002-2539-5817
CR Alcalá-Fdez J, 2009, SOFT COMPUT, V13, P307, DOI 10.1007/s00500-008-0323-y
   [Anonymous], 1985, INTRO DIGITAL IMAGE
   Ayati SM, 2014, MAJL C EL ENG
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Bizhani MR, 2014, 12 IR C INT SYST ICI
   Chang YF, 2008, IEEE SYS MAN CYBERN, P667, DOI 10.1109/ICSMC.2008.4811354
   Chen B, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1386, DOI 10.1109/ICAL.2008.4636370
   Chen KN, 2012, DIGIT SIGNAL PROCESS, V22, P726, DOI 10.1016/j.dsp.2012.04.010
   ErdincKocer H., 2011, P COMPUT SCI, V3, P1033, DOI DOI 10.1016/J.PR0CS.2010.12.169
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gazcón NF, 2012, PATTERN RECOGN LETT, V33, P1066, DOI 10.1016/j.patrec.2012.02.004
   Huang YP, 2009, EXPERT SYST APPL, V36, P9260, DOI 10.1016/j.eswa.2008.12.006
   Hung CS, 2009, ICIEA: 2009 4TH IEEE CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS, VOLS 1-6, P236, DOI 10.1109/ICIEA.2009.5138203
   Massoud MA, 2013, ALEX ENG J, V52, P319, DOI 10.1016/j.aej.2013.02.005
   Meng-Ling Feng, 2004, IEICE Electronics Express, V1, DOI 10.1587/elex.1.501
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rashedi E, 2018, MULTIMED TOOLS APPL, V77, P2771, DOI 10.1007/s11042-017-4429-z
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831
   Sedighi A, 2011, EXPERT SYST APPL, V38, P13497, DOI 10.1016/j.eswa.2011.02.030
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Tan HC, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4034, DOI 10.1109/ICMLC.2008.4621108
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197
   Wang F, 2008, PATTERN RECOGN LETT, V29, P1007, DOI 10.1016/j.patrec.2008.01.026
   Wolf C, 2003, PATTERN ANAL APPL, V6, P309, DOI 10.1007/s10044-003-0197-7
   Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482
   Yaghoobi S., 2015, 2015 2 INT C PATTERN, P1
   YANG Y, 2011, PROCEDIA ENGINEER, V15
   Yi Wang, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P91, DOI 10.1109/ICWAPR.2012.6294761
   Zheng LH, 2013, J COMPUT SYST SCI, V79, P245, DOI 10.1016/j.jcss.2012.05.006
NR 30
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16579
EP 16595
DI 10.1007/s11042-017-5229-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300027
DA 2024-07-18
ER

PT J
AU Makula, P
   Kumar, A
   Mukherjee, S
AF Makula, Pooja
   Kumar, Akshay
   Mukherjee, Snehasis
TI Measuring level of cuteness of baby images: a supervised learning scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SURF; HOG; Multi layer perceptron; Perception; CNN
AB The attractiveness of a baby face image depends on the perception of the perceiver. However, several recent studies advocate the idea that human perceptual analysis can be approximated by statistical models. We believe that the cuteness of baby faces depends on the low level facial features extracted from different parts (e.g., mouth, eyes, nose) of the faces. In this paper, we introduce a new problem of classifying baby face images based on their cuteness level using supervised learning techniques. The proposed learning model finds the potential of a deep learning technique in measuring the level of cuteness of baby faces. Since no datasets are available to validate the proposed technique, we construct a dataset of images of baby faces, downloaded from the internet. The dataset consists of several challenges like different view-point, orientation, lighting condition, contrast and background. We annotate the data using some well-known statistical tools inherited from Reliability theory. The experiments are conducted with some well-known image features like Speeded Up Robust Feature (SURF), Histogram of Oriented Gradient (HOG), Convolutional Neural Network (CNN) on Gradient and CNN on Laplacian, and the results are presented and discussed.
C1 [Makula, Pooja; Kumar, Akshay; Mukherjee, Snehasis] IIIT SriCity, Sricity 517646, AP, India.
RP Mukherjee, S (corresponding author), IIIT SriCity, Sricity 517646, AP, India.
EM pooja.m13@iiits.in; akshay.k13@iiits.in; snehasis.mukherjee@iiits.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
CR [Anonymous], 2004, P ICML 04 P 21 INT C, DOI [10.1145/1015330.1015415, DOI 10.1145/1015330.1015415]
   [Anonymous], ADV MACHINE LEARNING
   [Anonymous], 2002, INTRO MEASUREMENT TH
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], FACIAL ANAL BEAUTY M
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Garg S, 2016, IEEE WINT CONF APPL
   Gunes H., 2011, P JOINT ACM WORKSH H, P19
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Schmid K, 2008, PATTERN RECOGN, V41, P2710, DOI 10.1016/j.patcog.2007.11.022
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P, 2006, INT C PATT RECOG, P311
NR 14
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16867
EP 16885
DI 10.1007/s11042-017-5257-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300039
DA 2024-07-18
ER

PT J
AU Yadav, GS
   Ojha, A
AF Yadav, Gyan Singh
   Ojha, Aparajita
TI Secure data hiding scheme using shape generation algorithm: a key based
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Secret key; Midpoint circle generation algorithm; Avalanche
   effect
ID PARALLEL FRAMEWORK; IMAGES; HEVC; STEGANOGRAPHY; QUALITY; INTERPOLATION;
   CRYPTOGRAPHY; PREDICTION; CAPACITY
AB Data hiding in images has evolved as one of the trusted methods of secure data communication and numerous approaches have been introduced over the years using gray scale images as the cover media. Most of the methods are based on data hiding in least significant bit planes of cover images. Many such methods purely depend on data substitution algorithms by defining a pattern in which data is embedded. One can gain access to the secret data in a few attempts, if the algorithm is known. Keeping this in view several approaches based on secret keys have also been proposed by researchers. This paper proposes an efficient data embedding scheme using a key and an embedding pattern generated through midpoint circle generation algorithm. The pattern can be applied to a carrier that is mapped onto a grid/image. The cryptosystem uses the concept of steganography and is computationally light and secure. The secret-key is generated in such a way that Avalanche effect is ensured except in very rare cases. The proposed data embedding method is shown to be robust and highly secure while maintaining good hiding capacity and imperceptibility. It is applicable for data hiding in a generic grid that could be of pixels or bits.
C1 [Yadav, Gyan Singh; Ojha, Aparajita] PPDM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Yadav, GS (corresponding author), PPDM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, Madhya Pradesh, India.
EM gyan.yadav@iiitdmj.ac.in; aojha@iiitdmj.ac.in
RI Yadav, Gyan Singh/T-3822-2019; Ojha, Aparajita/Q-3902-2016
OI Ojha, Aparajita/0000-0003-1567-8378; Yadav, Gyan/0000-0003-2543-6719
CR Cao H, 2010, IEEE T INF FOREN SEC, V5, P314, DOI 10.1109/TIFS.2010.2046234
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Das S, 2010, INT CONF ACOUST SPEE, P1782, DOI 10.1109/ICASSP.2010.5495425
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Gou HM, 2005, IEEE T SIGNAL PROCES, V53, P3988, DOI 10.1109/TSP.2005.855411
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Hearn Donald, 2004, Computer Graphics with Open GL
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Janakiraman S., 2014, J INFORM TECHNOLOGY, V6, P188
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Lee CF, 2010, J SYST SOFTWARE, V83, P832, DOI 10.1016/j.jss.2009.12.018
   Lee IS, 2009, PATTERN RECOGN, V42, P1604, DOI 10.1016/j.patcog.2009.01.014
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ohbuchi R, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P180, DOI 10.1109/CGI.1999.777952
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Revenkar PS, 2010, INT J SECUR APPL, V4, P49
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Stallings W., 2006, Cryptography and Network Security, V4th
   Suma Christal Mary S., 2013, Journal of Computer Science, V9, P1556, DOI 10.3844/jcssp.2013.1556.1565
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C, 2017, MATER CHEM FRONT, V1, P2174, DOI 10.1039/c7qm00201g
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
   Zhenfei Zhao, 2012, Information Technology Journal, V11, P209, DOI 10.3923/itj.2012.209.216
NR 41
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16319
EP 16345
DI 10.1007/s11042-017-5200-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300015
DA 2024-07-18
ER

PT J
AU Yang, SY
   Yang, S
   Yang, WH
   Liu, JY
AF Yang, Saboya
   Yang, Shuai
   Yang, Wenhan
   Liu, Jiaying
TI Automatic portrait oil painter: joint domain stylization for portrait
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stylization; Saliency aware; Dictionary learning; Texture
   synthesis
ID COLOR; SUPERRESOLUTION; STATISTICS
AB Everyone has the dream of being in the center of famous art paintings, admired by numerous future generations. However, the dream came true at a huge cost of the painter's commission in old days. In our paper, another practical choice is provided for everyone to achieve that dream - an automatic portrait oil painter transferring some artistic styles from one single reference painting. To address this issue, we propose a joint-domain image stylization approach, particularly for portrait oil paintings. From the view of artistic appreciation, we analyze an amount of oil painting art works and summarize three critical factors to depict the figure, i.e. color, structure and texture. Based on this point, we separate and represent an artistic work into these three domains. Then, considering their intrinsic properties and following an art creation route, we propose the corresponding approaches to jointly model and transfer the features in these domains. First, a swatch-based color adjustment is proposed to recolor the tone of the input image based on semantic regions corresponding to the references. Second, the main structures of the input image is maintained by sparse reconstruction. Third, a coarse-to-fine texture synthesis is used to enhance the detail oil painting patterns. Extensive experimental results demonstrate that the proposed method achieves desirable results compared with state-of-the-art methods in not only transferring the styles from references but also keeping consistent contents with the given portrait.
C1 [Yang, Saboya; Yang, Shuai; Yang, Wenhan; Liu, Jiaying] Peking Univ, Inst Comp Sci & Technol, Comp Sci, Beijing, Peoples R China.
C3 Peking University
RP Liu, JY (corresponding author), Peking Univ, Inst Comp Sci & Technol, Comp Sci, Beijing, Peoples R China.
EM liujiaying@pku.edu.cn
RI Li, Mengqi/AAG-6804-2021; Liu, JY/GYJ-0138-2022
OI Liu, Jiaying/0000-0002-0468-9576
FU National Natural Science Foundation of China [61472011]
FX This work was supported by the National Natural Science Foundation of
   China under Contract 61472011.
CR [Anonymous], 2016, IEEE C COMP VIS PATT
   Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Bhujle H, 2014, IEEE T IMAGE PROCESS, V23, P356, DOI 10.1109/TIP.2013.2290871
   Bousseau A, 1983, INT S NONPH AN REND, P141
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Dezeustre G, 2014, GLAZE APP
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FLANAGAN P, 1990, VISION RES, V30, P769, DOI 10.1016/0042-6989(90)90102-Q
   Frigo O, 2016, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2016.66
   Greenfield GR, 2003, WSCG'2003, VOL 11, NO 1, CONFERENCE PROCEEDINGS, P189
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang TW, 2009, IEEE I CONF COMP VIS, P199, DOI 10.1109/ICCV.2009.5459165
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   Kai-Han Lo, 2016, IEEE Multimedia, V23, P60, DOI 10.1109/MMUL.2016.36
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Liu XY, 2017, MULTIMED TOOLS APPL, V76, P12853, DOI 10.1007/s11042-016-3649-y
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Marr D., 1982, Visual perception
   Paget R., 1995, Conference Proceedings DICTA-95. Digital Image Computing: Techniques and Applications, P547
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Porter T., 1984, Computers & Graphics, V18, P253
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rosales R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P472
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Salisbury M, 1996, BRIT J SPORT MED, V48, P622
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Wang QY, 2017, MULTIMED TOOLS APPL, V76, P16767, DOI 10.1007/s11042-016-3951-8
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang T, 2013, BRIT MACH VIS C
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang L, 2012, IEEE MULTIMEDIA, V19, P29, DOI 10.1109/MMUL.2012.12
   Yang Y, 2017, MULTIMED TOOLS APPL, V76, P523, DOI 10.1007/s11042-015-3063-x
   Zhang W, 2013, IEEE T MULTIMEDIA, V15, P1594, DOI 10.1109/TMM.2013.2265675
   Zhao M., 2011, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Non-Photorealistic Animation and Rendering, P117
   Zhao M., 2010, PROC INT S NONPHOTOR, P99, DOI DOI 10.1145/1809939.1809951
   Zhao MT, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2422105.2422110
NR 53
TC 4
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
DI 10.1007/s11042-017-5190-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300006
DA 2024-07-18
ER

PT J
AU Behera, SK
   Dogra, DP
   Roy, PP
AF Behera, Santosh Kumar
   Dogra, Debi Prosad
   Roy, Partha Pratim
TI Analysis of 3D signatures recorded using leap motion sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signature recognition; Signature verification; 3D sequence analysis
ID HIDDEN MARKOV-MODELS; VERIFICATION; RECOGNITION; DTW
AB Signature recognition is identifying the signature's owner, whereas verification is the process to find whether a signature is genuine or forged. Though, both are important in the field of forensic sciences, however, verification is more important to banks and credit card companies. In this paper, we have proposed a methodology to analyze 3D signatures captured using Leap motion sensor. We have extended existing 2D features into 3D from raw signatures and applied well-known classifiers for recognition as well as verification. We have shown that the 3rd dimension, which essentially represents instantaneous pressure during writing, can improve the accuracy of the biometric systems. We have created a large dataset containing more than 2000 signatures registered by 100 volunteers using the Leap motion interface. This has been made available online for the research community. Our analysis shows that, the proposed 3D extension is better than its original 2D version. Recognition and verification accuracy have increased by 6.8% and 9.5%, respectively using k-NN. Similarly, accuracy has increased by 9.9% (recognition) and 6.5% (verification) when HMM is used as the classifier. Similar results have been recorded on benchmark datasets. A comparison with 2D tablet-stylus interface has been carried out which also supports our claims. We believe, Leap motion can be an alternative to the existing biometric setups.
C1 [Behera, Santosh Kumar; Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, India.
   [Roy, Partha Pratim] IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bhubaneswar; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Behera, SK (corresponding author), IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, India.
EM sb29@iitbbs.ac.in; dpdogra@iitbbs.ac.in; proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/AAW-2994-2020; Roy, Partha Pratim/AAV-9061-2020; Roy,
   Partha Pratim/GPF-4253-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR Alonso-Fernandez F, 2009, IEEE IMAGE PROC, P2725, DOI 10.1109/ICIP.2009.5414157
   Bailador G, 2011, PATTERN RECOGN, V44, P2468, DOI 10.1016/j.patcog.2011.04.010
   Bashir M., 2011, BIOSIG, P219
   Byeon W, 2014, INT C PATT RECOG, P1144, DOI 10.1109/ICPR.2014.206
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Dolfing JGA, 1998, INT C PATT RECOG, P1309, DOI 10.1109/ICPR.1998.711942
   Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5
   Elons AS, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P368, DOI 10.1109/ICCES.2014.7030987
   Fang B, 2003, PATTERN RECOGN, V36, P91, DOI 10.1016/S0031-3203(02)00061-4
   Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P981, DOI 10.1016/j.patcog.2006.06.007
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Guru DS, 2009, IEEE T PATTERN ANAL, V31, P1059, DOI 10.1109/TPAMI.2008.302
   Houmani N, 2014, ENCY BIOMETRICS
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Iwai Y., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P127, DOI 10.1109/RATFG.1999.799235
   Jaeger S., 2000, 7 INT WORKSHOP FRONT, P249
   Jain AK, 2002, PATTERN RECOGN, V35, P2963, DOI 10.1016/S0031-3203(01)00240-0
   Jambor S., 2014, PREPRINT, P1
   Justino E. J. R., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P105, DOI 10.1109/SIBGRA.2000.883902
   Kashi RS, 1997, PROC INT CONF DOC, P253, DOI 10.1109/ICDAR.1997.619851
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Lee LL, 1996, IEEE T PATTERN ANAL, V18, P643, DOI 10.1109/34.506415
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang R, 2016, 28 INT C TOOLS ART I
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Nakanishi I, 2006, IEICE T FUND ELECTR, VE89A, P178, DOI 10.1093/ietfec/e89-a.1.178
   Nguyen Vu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1300, DOI 10.1109/ICDAR.2009.123
   Pratim P, 2012, INT CONF FRONT HAND, P225, DOI 10.1109/ICFHR.2012.270
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rashid O, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P572, DOI 10.1109/ICICISYS.2009.5357615
   Sabourin R, 1997, IEEE T PATTERN ANAL, V19, P976, DOI 10.1109/34.615447
   Shanker AP, 2007, PATTERN RECOGN LETT, V28, P1407, DOI 10.1016/j.patrec.2007.02.016
   Shrivastava R, 2013, IEEE INT ADV COMPUT, P947
   Singh R., 2015, IEEE 2015 IEEE 7 INT, P1
   Vamsikrishna KM, 2016, IEEE T BIO-MED ENG, V63, P991, DOI 10.1109/TBME.2015.2480881
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zou MF, 2003, IEEE SYS MAN CYBERN, P256
NR 40
TC 16
Z9 16
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14029
EP 14054
DI 10.1007/s11042-017-5011-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900041
DA 2024-07-18
ER

PT J
AU Hameed, MA
   Aly, S
   Hassaballah, M
AF Hameed, Mohamed Abdel
   Aly, Saleh
   Hassaballah, M.
TI An efficient data hiding method based on adaptive directional pixel
   value differencing (ADPVD)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; Pixel-value differencing; Adaptive
   directional PVD; ADPVD
ID SIGNIFICANT-BIT SUBSTITUTION; STEGANOGRAPHIC METHOD; IMAGE
   STEGANOGRAPHY; MODULUS FUNCTION; HIGH-CAPACITY; INFORMATION; SECURITY
AB Steganography is an important secret information communication technology in which one may send messages without others having knowledge of their existence. This paper proposes a new adaptive steganography method for color images using adaptive directional pixel-value differencing (ADPVD). The proposed method increases the capacity of the hidden secret data and improves the security of the stego-color image as well. The hiding capacity of the original PVD method is investigated by considering three directional edges: horizontal, vertical and diagonal directions using color cover image. The cover image is partitioned into 2-pixel blocks in a non-overlapping fashion and scanned in raster-scan order in all three directions. The proposed method adaptively selects the appropriate embedding directions for each color channel according to the largest embedding capacity. The security is improved since different pixel directions are employed adaptively to embed different number of message bits in each color channel. The experimental results show that the proposed method provides both larger embedding capacity and better visual quality of the stego color image compared with other PVD-based algorithms.
C1 [Hameed, Mohamed Abdel] South Valley Univ, Dept Math, Fac Sci, Qena 83523, Egypt.
   [Aly, Saleh] Aswan Univ, Dept Elect Engn, Fac Engn, Aswan, Egypt.
   [Aly, Saleh] Majmaah Univ, Dept Informat Technol, Comp Sci & Informat Technol Coll, Al Majmaah, Saudi Arabia.
   [Hassaballah, M.] South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Luxor, Egypt.
C3 Egyptian Knowledge Bank (EKB); South Valley University Egypt; Egyptian
   Knowledge Bank (EKB); Aswan University; Majmaah University; Egyptian
   Knowledge Bank (EKB); South Valley University Egypt
RP Aly, S (corresponding author), Aswan Univ, Dept Elect Engn, Fac Engn, Aswan, Egypt.; Aly, S (corresponding author), Majmaah Univ, Dept Informat Technol, Comp Sci & Informat Technol Coll, Al Majmaah, Saudi Arabia.
EM m.abdelhamidali@gmail.com; saleh@aswu.edu.eg; m.hassaballah@svu.edu.eg
RI Abdel Hameed, Mohamed/HRC-4106-2023; Aly, Saleh/L-1378-2019;
   Hassaballah, Mahmoud/A-5197-2018
OI Abdel Hameed, Mohamed/0000-0002-2911-770X; Aly,
   Saleh/0000-0002-1772-4254; Hassaballah, Mahmoud/0000-0001-5655-8511
CR [Anonymous], 2014, AUST J BASIC APPL SC
   [Anonymous], INT J INFORM SCI TEC
   [Anonymous], 2013, INT J ADV INFORM TEC
   Borges PVK, 2008, IEEE T MULTIMEDIA, V10, P1479, DOI 10.1109/TMM.2008.2007294
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Gulati T, 2016, INT J ENG TRENDS TEC, V35, P610
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Neeta D, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P173
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Parah SA, 2017, MULTIDIM SYST SIGN P, V28, P549, DOI 10.1007/s11045-015-0358-z
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu NI, 2012, APPL SOFT COMPUT, V12, P942, DOI 10.1016/j.asoc.2011.09.002
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 33
TC 40
Z9 40
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14705
EP 14723
DI 10.1007/s11042-017-5056-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200010
DA 2024-07-18
ER

PT J
AU Usha, SGA
   Vasuki, S
AF Usha, S. Gandhimathi Alias
   Vasuki, S.
TI Improved segmentation and change detection of multi-spectral satellite
   imagery using graph cut based clustering and multiclass SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Satellite image analysis; Land cover classification; Change detection;
   Graph cut approach; SVM classification
ID UNSUPERVISED CHANGE DETECTION; LAND-USE CHANGES; COASTAL ZONE; COVER
   CHANGE; CLASSIFICATION; WAVELET; FEATURES; SPACE; MODEL; MAPS
AB The Satellite image analysis automatically looks over an image to attain valuable information such as land cover classification and change detection from it. Generally, many image segmentation algorithms exploit specific spatial information between the pixel and its neighbors together with the color information to lengthen the cluster quality. Recently, a variety of clustering processes have been suggested to grasp data that is not linearly separable. The main issue in clustering algorithm is its inconsistency. To address this issue, the innovative spatial-spectral method for image segmentation and change detection based on Graph cut based clustering is proposed. In this hybrid approach, the Multispectral satellite images are preprocessed using Difference Of Offset Gaussian (DOOG) filters and then segmented by graph cut based clustering. Multi-class problems are highly expensive to solve, there is a need of a massive optimization problem. The changes between the classified images can be obtained by using image differencing method. The performance of the proposed method has been evaluated with the temporal data sets of LANDSAT images. From the experimental results, it is observed that in the proposed work, the mean value of the changed area for a particular dataset achieves a 47.2% reduction compared to the conventional system.
C1 [Usha, S. Gandhimathi Alias; Vasuki, S.] Velammal Coll Engn & Technol, Elect & Commun Engn Dept, Madurai, Tamil Nadu, India.
RP Usha, SGA (corresponding author), Velammal Coll Engn & Technol, Elect & Commun Engn Dept, Madurai, Tamil Nadu, India.
EM ushadears@gmail.com
RI Usha, S Gandhimathi alias/CAH-9310-2022; ECE0909, Dr.
   Vasuki.S/ABG-3155-2021
OI ECE0909, Dr. Vasuki.S/0000-0003-0815-6424; S, Gandhimathi Alias
   Usha/0000-0003-1908-6249
CR Agrawal RK, 2015, APPL SOFT COMPUT, V28, P217, DOI 10.1016/j.asoc.2014.11.052
   [Anonymous], 2006, REMOTE SENSING DIGIT
   Berlanga-Robles CA, 2002, J COASTAL RES, V18, P514
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen XH, 2012, ISPRS J PHOTOGRAMM, V71, P86, DOI 10.1016/j.isprsjprs.2012.05.006
   Dams J, 2013, J HYDROL, V485, P84, DOI 10.1016/j.jhydrol.2012.09.045
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Ding H, 2007, PEDOSPHERE, V17, P712, DOI 10.1016/S1002-0160(07)60086-1
   Ehlers M, 2014, GLOBAL URBAN MONITOR, P325
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Glanz H, 2014, ISPRS J PHOTOGRAMM, V97, P219, DOI 10.1016/j.isprsjprs.2014.09.004
   Hadid A, 2004, PROC CVPR IEEE, P797
   Henits L, 2016, INT J REMOTE SENS, V37, P3439, DOI 10.1080/01431161.2015.1125558
   Jensen J.R., 2007, GEO SPATIAL TECHNOLO, P7
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kathirvel R, 2015, MIDDLE-EAST J SCI RE, V23, P2446, DOI DOI 10.5829/idosi.mejsr.2015.23.10.22695
   Lenney MP, 1996, REMOTE SENS ENVIRON, V56, P8, DOI 10.1016/0034-4257(95)00152-2
   Liu ML, 2005, INT GEOSCI REMOTE SE, P1534
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ngo LT, 2015, COMPUT GEOSCI-UK, V83, P1, DOI 10.1016/j.cageo.2015.06.011
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Mendoza JE, 2002, LANDSCAPE URBAN PLAN, V59, P147, DOI 10.1016/S0169-2046(02)00012-9
   Palmer AR, 1998, J ARID ENVIRON, V39, P143, DOI 10.1006/jare.1998.0399
   Petropoulos GP, 2011, INT J APPL EARTH OBS, V13, P70, DOI 10.1016/j.jag.2010.06.008
   Pratola C, 2013, IEEE T GEOSCI REMOTE, V51, P2055, DOI 10.1109/TGRS.2012.2236846
   Raja RAA, 2013, J INDIAN SOC REMOTE, V41, P35, DOI 10.1007/s12524-011-0199-7
   RAM B, 1993, INT J REMOTE SENS, V14, P3191, DOI 10.1080/01431169308904433
   Sadek S. A., 1993, Egyptian Journal of Soil Science, V33, P23
   Salas EAL, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010078
   Särkkä S, 2010, IEEE T AUTOMAT CONTR, V55, P1938, DOI 10.1109/TAC.2010.2050017
   Seto KC, 2005, INT J REMOTE SENS, V26, P563, DOI 10.1080/01431160512331299270
   Shalaby A, 2007, APPL GEOGR, V27, P28, DOI 10.1016/j.apgeog.2006.09.004
   Srivastava PK, 2012, ADV SPACE RES, V50, P1250, DOI 10.1016/j.asr.2012.06.032
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Venkateswaran K, 2015, J INDIAN SOC REMOTE, V43, P729, DOI 10.1007/s12524-015-0461-5
   Volpi M, 2012, IEEE GEOSCI REMOTE S, V9, P1026, DOI 10.1109/LGRS.2012.2189092
   Young RA, 2001, SPATIAL VISION, V14, P261, DOI 10.1163/156856801753253582
NR 41
TC 13
Z9 13
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15353
EP 15383
DI 10.1007/s11042-017-5120-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200041
DA 2024-07-18
ER

PT J
AU Liu, P
   Wang, R
   Ding, J
   Yin, XC
AF Liu, Ping
   Wang, Rui
   Ding, Jie
   Yin, Xinchun
TI Performance modeling and evaluating workflow of ITS: real-time
   positioning and route planning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent traffic system; Multimedia data; PEPA; Performance
   evaluation
ID INTERNET; THINGS
AB Intelligent Traffic Systems (ITS), as integrated systems including control technologies, communication technologies, vehicle sensing and vehicle electronic technologies, have provided valuable solutions to the increasingly serious traffic problems. In the process of construction and operation of ITS, big data, especially multimedia data is produced at a rapid speed, which has made traffic information more and more complicated, causing traffic management facing new challenges. Hence, in order to achieve efficient management of all types of transportation resources and make better use of ITS, it is necessary and significant to study the architecture and performance of ITS in depth. Through dividing the system into different functional modules and assigning these modules to components in Performance Evaluation Process Algebra (PEPA), we can adopt a new method to realize the modeling and evaluating the working process of real-time positioning and route planning in ITS. Meanwhile, the fluid flow approximation is employed to conduct a performance analysis through PEPA models, guaranteeing that the response time, the maximum utilization and the throughput of the system can be achieved and analyzed.
C1 [Liu, Ping; Wang, Rui; Ding, Jie] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Ding, Jie; Yin, Xinchun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
   [Yin, Xinchun] Yangzhou Univ, Guangling Coll, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University; Nanjing University; Yangzhou University
RP Ding, J (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.; Ding, J (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM jieding@yzu.edu.cn
FU National NSF of China [61472343]; Blue Project of Jiangsu Province,
   China
FX The authors acknowledge the financial support by the National NSF of
   China under Grant No. 61472343. J. Ding is also supported by Blue
   Project of Jiangsu Province, China.
CR Ashraf QM, 2016, IEEE ACCESS, V4, P1313, DOI 10.1109/ACCESS.2016.2545741
   Chen X, 2016, P INT COMP SOFTW APP, P616, DOI 10.1109/COMPSAC.2016.114
   Ding J, 2015, WIRELESS PERS COMMUN, V84, P231, DOI 10.1007/s11277-015-2605-x
   Ding J, 2012, COMPUT J, V55, P1383, DOI 10.1093/comjnl/bxs013
   Hillston J., 2005, Proceedings. Second International Conference on the Quantitative Evaluation of Systems, P33, DOI 10.1109/QEST.2005.12
   Hillston J., 1996, A Compositional Approach to Performance Modelling
   Jiau MK, 2015, IEEE T INTELL TRANSP, V16, P2711, DOI 10.1109/TITS.2015.2421557
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Mashal I, 2016, PHYSICA A, V451, P646, DOI 10.1016/j.physa.2016.01.051
   Palattella MR, 2016, IEEE J SEL AREA COMM, V34, P510, DOI 10.1109/JSAC.2016.2525418
   Singh Bhupendra, 2015, J. Transp. Lit., V9, P30
   Wen ZG, 2016, INT J ADV MANUF TECH, V84, P361, DOI 10.1007/s00170-015-8231-7
   Whaiduzzaman M, 2014, J NETW COMPUT APPL, V40, P325, DOI 10.1016/j.jnca.2013.08.004
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
NR 15
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10867
EP 10881
DI 10.1007/s11042-017-5364-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900029
DA 2024-07-18
ER

PT J
AU Lu, T
   Guan, YJ
   Zhang, YD
   Qu, SM
   Xiong, ZX
AF Lu, Tao
   Guan, Yingjie
   Zhang, Yanduo
   Qu, Shenming
   Xiong, Zixiang
TI Robust and efficient face recognition via low-rank supported extreme
   learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Robust feature; Low-rank matrix recovery; Extreme
   learning machine; Time complexity
ID ALGORITHM
AB Recently, face recognition algorithms have made great progress in various real-world applications, e.g., authentication and criminal investigation. Deep-learning offers an end-to-end paradigm for vision recognition tasks and achieves good performance. However, designing and training the complex network architecture are time-consuming and labor-intensive. Moreover, under complex scenarios, illumination change, noise or occlusion in images degrade the performance of recognition algorithms. In order to ameliorate these issues, we propose an efficient three-layered low-rank supported extreme learning machine (LSELM) algorithm for face recognition which improves the recognition performance under complex scenarios with high efficiency. In the first layer, a given probe sample is clustered into certain training subspace as pre-clustering. In the second layer, with this subspace, a low-rank subspace of probe sample as robust feature which is insensitive to disguise, noise, variant expression or illumination will be recovered by low-rank decomposition. Furthermore, these low-rank discriminative features are coded to support training a forward neural network termed LSELM. Experimental results indicate that the proposed approach is on par with some deep-learning based face recognition algorithms on recognition performance but with less time complexity over some popular face datasets e.g., AR, Extend Yale-B, CMU PIE and LFW datasets.
C1 [Lu, Tao; Guan, Yingjie; Zhang, Yanduo] Wuhan Inst Technol, Sch Engn & Comp Sci, Wuhan 430073, Hubei, Peoples R China.
   [Lu, Tao; Xiong, Zixiang] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.
   [Qu, Shenming] Henan Univ, Sch Software, Kaifeng 475001, Peoples R China.
C3 Wuhan Institute of Technology; Texas A&M University System; Texas A&M
   University College Station; Henan University
RP Lu, T (corresponding author), Wuhan Inst Technol, Sch Engn & Comp Sci, Wuhan 430073, Hubei, Peoples R China.; Lu, T; Xiong, ZX (corresponding author), Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.
EM lutxyl@gmail.com; zx@ece.tamu.edu
RI Kanghui, Zhao/AAF-1289-2019
OI Lu, Tao/0000-0001-8117-2012
FU China Scholarship Council; National Natural Science Foundation of China
   [61502354, 61501413, 61671332, 41501505]; Natural Science Foundation of
   Hubei Province of China [2012FFA099, 2012FFA134, 2013CF125, 2014CFA130,
   2015CFB451]; Hubei Chenguang Talented Youth Development Foundation;
   Scientific Research Foundation of Wuhan Institute of Technology
   [K201713]
FX This work is supported by the grant of China Scholarship Council, the
   National Natural Science Foundation of China (61502354, 61501413,
   61671332, 41501505), the Natural Science Foundation of Hubei Province of
   China (2012FFA099, 2012FFA134, 2013CF125, 2014CFA130, 2015CFB451), Hubei
   Chenguang Talented Youth Development Foundation, Scientific Research
   Foundation of Wuhan Institute of Technology(K201713). Thanks for the
   reviewers' valuable comments for the paper.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al-Ayyoub M, 2016, MULTIMED TOOLS APP, P1
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], 2015, DEEPID3 FACE RECOGNI
   [Anonymous], 2010, 100920105055 ARXIV
   [Anonymous], HDB RES MODERN CRYPT
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   [Anonymous], 2015, IEEE INT C COMP VIS
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Du HS, 2015, INT J AUTOM COMPUT, V12, P579, DOI 10.1007/s11633-015-0901-2
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Furrer R, 2010, J STAT SOFTW, V36, P1
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2004, ADV NEUR IN, V16, P153
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tirkaz Caglar, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P940, DOI 10.1109/SIU.2009.5136552
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Lingling, 2011, WSEAS Transactions on Circuits and Systems, V10, P393
   Zhang YH, 2016, CHINA COMMUN, V13, P16, DOI 10.1109/CC.2016.7559071
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3973, DOI 10.1007/s11042-015-3136-x
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 44
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11219
EP 11240
DI 10.1007/s11042-017-5475-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900047
DA 2024-07-18
ER

PT J
AU Shen, G
   Liu, F
   Fu, ZX
   Yu, B
AF Shen, Gang
   Liu, Feng
   Fu, Zhengxin
   Yu, Bin
TI Visual cryptograms of random grids via linear algebra
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image secret sharing; Visual cryptography; Random grid; Linear algebra;
   General access structure
ID GENERAL ACCESS STRUCTURES; COLOR IMAGES; SCHEMES; AUTHENTICATION;
   CONTRAST; STEGANOGRAPHY; ENCRYPTION; PIXELS
AB Two visual models of image secret sharing have been studied: visual cryptography schemes (VCS), introduced by Naor and Shamir, and visual cryptograms of random grids (VCRG), introduced by Kafri and Keren. VCRG has gained much attention in academia than before to avoid the pixel expansion of VCS. Although there is a strict relation between VCRG and VCS, VCRG can still be improved to achieve a better result. In this paper, based on new insight into linear algebraic technique to construct VCS, where we are able to construct VCS by solving a linear system of more equations at a time, we put forward a new construction of VCRG for general access structures. The effectiveness and advantage of the proposed construction are formally analyzed and experimentally demonstrated. With theoretical and practical interests, our construction exposes new possibilities to the researches of visual models of image secret sharing.
C1 [Shen, Gang; Fu, Zhengxin; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Liu, Feng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Liu, Feng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
C3 PLA Information Engineering University; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Shen, G (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM shengang_zisti@163.com
RI liu, feng/B-3050-2019; Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU National Natural Science Foundation of China [61602513, 61671448];
   Strategic Priority Research Program of the Chinese Academy of Sciences
   [XDA06010701]; National Key R&D Program of China [2016YFB0800100]
FX We would like to thank the anonymous reviewers for their important and
   helpful comments. This work was supported by the National Natural
   Science Foundation of China with No. 61602513 and No. 61671448, the
   Strategic Priority Research Program of the Chinese Academy of Sciences
   with No. XDA06010701, and the National Key R&D Program of China with No.
   2016YFB0800100.
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Adhikari A, 2014, DESIGN CODE CRYPTOGR, V73, P865, DOI 10.1007/s10623-013-9832-5
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   D'Arco P, 2014, J SYST SOFTWARE, V95, P89, DOI 10.1016/j.jss.2014.03.079
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hawkes LW, 2000, TR001001 FLOR STAT U, P1
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu F, 2015, CN Patent App, Patent No. [CN 201410542752, 201410542752]
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Peng Li, 2012, ICIC Express Letters, V6, P2033
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2015, THEOR COMPUT SCI, V565, P30, DOI 10.1016/j.tcs.2014.10.048
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Teng Guo, 2013, Information Security and Cryptology. 8th International Conference, Inscrypt 2012. Revised Selected Papers, P90, DOI 10.1007/978-3-642-38519-3_7
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Yamaguchi Yasushi, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P228, DOI 10.1007/978-3-642-32205-1_19
   Yan WQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P572
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2006, INTEGR COMPUT-AID E, V13, P189
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 40
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12871
EP 12899
DI 10.1007/s11042-017-4921-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100054
DA 2024-07-18
ER

PT J
AU Wang, SH
   Zhang, Y
   Li, YJ
   Jia, WJ
   Liu, FY
   Yang, MM
   Zhang, YD
AF Wang, Shui-Hua
   Zhang, Yin
   Li, Yu-Jie
   Jia, Wen-Juan
   Liu, Fang-Yuan
   Yang, Meng-Meng
   Zhang, Yu-Dong
TI Single slice based detection for Alzheimer's disease via wavelet entropy
   and multilayer perceptron trained by biogeography-based optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathological brain detection; Inter-class variance; Alzheimer's disease;
   Wavelet entropy; Multilayer perceptron; Biogeography-based optimization
ID COMPUTER-AIDED DIAGNOSIS; NEURAL-NETWORK; PREDICTION; TRANSFORM;
   ALGORITHM; CLASSIFICATION; MOMENT; IMAGES; MRI
AB Detection of Alzheimer's disease (AD) from magnetic resonance images can help neuroradiologists to make decision rapidly and avoid missing slight lesions in the brain. Currently, scholars have proposed several approaches to automatically detect AD. In this study, we aimed to develop a novel AD detection system with better performance than existing systems. 28 ADs and 98 HCs were selected from OASIS dataset. We used inter-class variance criterion to select single slice from the 3D volumetric data. Our classification system is based on three successful components: wavelet entropy, multilayer perceptron, and biogeography-base optimization. The statistical results of our method obtained an accuracy of 92.40 +/- 0.83%, a sensitivity of 92.14 +/- 4.39%, a specificity of 92.47 +/- 1.23%. After comparison, we observed that our pathological brain detection system is superior to latest 6 other approaches.
C1 [Wang, Shui-Hua; Jia, Wen-Juan; Liu, Fang-Yuan; Yang, Meng-Meng; Zhang, Yu-Dong] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Li, Yu-Jie] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Zhang, Yu-Dong] Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.
   [Zhang, Yu-Dong] Columbia Univ, MRI Unit, New York, NY 10032 USA.
   [Zhang, Yu-Dong] New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
C3 Nanjing Normal University; Zhongnan University of Economics & Law;
   Yangzhou University; Columbia University; Columbia University; New York
   State Psychiatry Institute
RP Zhang, YD (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Zhang, YD (corresponding author), Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.; Zhang, YD (corresponding author), Columbia Univ, MRI Unit, New York, NY 10032 USA.; Zhang, YD (corresponding author), New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
EM zhangyudong@njnu.edu.cn
RI Zhang, Yin/K-2414-2019; LIU, FANGYUAN/KPA-7326-2024; Li,
   YuJie/HGT-8657-2022; Yang, Mengmeng/AAV-5795-2021; Li,
   Yujie/AAH-3298-2019; Li, YuJie/JAC-4451-2023; Zhang, Yin/O-2149-2015;
   Wang, shuihua/G-7326-2016; Zhang, Yudong/I-7633-2013
OI Zhang, Yin/0000-0002-8103-8937; LIU, FANGYUAN/0000-0003-2251-9498; Yang,
   Mengmeng/0000-0002-8988-269X; Li, Yujie/0000-0002-0275-2797; Zhang,
   Yin/0000-0002-1772-0763; Wang, shuihua/0000-0003-4713-2791; Zhang,
   Yudong/0000-0002-4870-1493
FU NSFC [61602250, 61503188]; Natural Science Foundation of Jiangsu
   Province [BK20150983, BK20150982]; Open Fund of Key Laboratory of
   Statistical Information Technology and Data Mining, State Statistics
   Bureau [SDL201608]; Open Fund of Fujian Provincial Key Laboratory of
   Data Intensive Computing [BD201607]; NIH grants [P50 MH071616, P01
   AG03991, P50AG05681, R01 AG021910, R01 MH56584, U24 RR021382]
FX This paper was supported by NSFC (61602250, 61503188), Natural Science
   Foundation of Jiangsu Province (BK20150983, BK20150982), Open Fund of
   Key Laboratory of Statistical Information Technology and Data Mining,
   State Statistics Bureau, (SDL201608), and Open Fund of Fujian Provincial
   Key Laboratory of Data Intensive Computing (BD201607). The authors
   express their gratitude to the OASIS dataset supported by NIH grants
   (P50 MH071616, P01 AG03991, P50AG05681, R01 AG021910, R01 MH56584, and
   U24 RR021382).
CR Aggarwal N, 2015, INT J IMAG SYST TECH, V25, P179, DOI 10.1002/ima.22135
   [Anonymous], 2016, EXPERT SYST, DOI DOI 10.1111/exsy.12146
   Ardekani BA, 2013, CEREB CORTEX, V23, P2514, DOI 10.1093/cercor/bhs253
   Bakhshi AD, 2013, IET SIGNAL PROCESS, V7, P783, DOI 10.1049/iet-spr.2012.0128
   Behera NKS, 2015, 1 INT C COMP INT DAT, P272
   Bhuiyan MAA, 2016, INT J ADV COMPUT SC, V7, P25
   Bozorg Haddad O, 2016, J WATER RES PLAN MAN, V142, DOI 10.1061/(ASCE)WR.1943-5452.0000558
   Candra H, 2015, IEEE ENG MED BIO, P7250, DOI 10.1109/EMBC.2015.7320065
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   De Visschere P, 2015, CLIN IMAG, V39, P636, DOI 10.1016/j.clinimag.2015.02.008
   Dil EA, 2016, ULTRASON SONOCHEM, V33, P129, DOI 10.1016/j.ultsonch.2016.04.031
   Fang LT, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/513849
   Farswan P, 2016, ADV INTELL SYST, V382, P227, DOI 10.1007/978-3-662-47926-1_22
   Frantzidis CA, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00224
   Goh S, 2014, JAMA PSYCHIAT, V71, P665, DOI 10.1001/jamapsychiatry.2014.179
   Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786
   Gorji HT, 2015, NEUROSCIENCE, V305, P361, DOI 10.1016/j.neuroscience.2015.08.013
   Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065
   Heidari AA, 2015, INT ARCH PHOTOGRAMM, V41, P301, DOI 10.5194/isprsarchives-XL-1-W5-301-2015
   Ibáñez F, 2015, SMART MATER STRUCT, V24, DOI 10.1088/0964-1726/24/8/085036
   Ibrahim AO, 2015, 2015 International Conference on Computing, Control, Networking, Electronics and Embedded Systems Engineering (ICCNEEE), P422, DOI 10.1109/ICCNEEE.2015.7381405
   Ji TY, 2014, IEEE POW EN SOC GEN, P46
   Jiang WJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070979
   Krawczyk B, 2015, ARTIF INTELL MED, V65, P219, DOI 10.1016/j.artmed.2015.07.005
   Lee SG, 2014, STRUCT HEALTH MONIT, V13, P307, DOI 10.1177/1475921714522845
   Liu G., 2016, ENTROPY, V8, P11
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Lu HM, 2016, IEICE T INF SYST, VE99D, P219, DOI 10.1587/transinf.2014EDP7405
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   Magnander T, 2016, EJNMMI PHYS, V3, DOI 10.1186/s40658-016-0137-4
   Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mashhadban H, 2016, CONSTR BUILD MATER, V119, P277, DOI 10.1016/j.conbuildmat.2016.05.034
   Meng GL, 2015, MED SCI MONITOR, V21, P3600, DOI 10.12659/MSM.895334
   Mirjalili S, 2014, INFORM SCIENCES, V269, P188, DOI 10.1016/j.ins.2014.01.038
   Mondal U, 2016, T I MEAS CONTROL, V38, P14, DOI 10.1177/0142331214562657
   Park JS, 2016, HEALTH COMMUN, V31, P346, DOI 10.1080/10410236.2014.957375
   Peng IB, 2015, IEEE INT C CL COMP, P408, DOI 10.1109/CLUSTER.2015.63
   Peters S, 2013, NEURORADIOLOGY, V55, P853, DOI 10.1007/s00234-013-1185-2
   Plant C, 2010, NEUROIMAGE, V50, P162, DOI 10.1016/j.neuroimage.2009.11.046
   Pu X, 2015, 2015 INTERNATIONAL CONFERENCE ON MECHANICAL SCIENCE AND MECHANICAL DESIGN, MSMD 2015, P223
   Rajchl M, 2016, MED IMAGE ANAL, V27, P45, DOI 10.1016/j.media.2015.05.005
   Saghatforoush A, 2016, ENG COMPUT-GERMANY, V32, P255, DOI 10.1007/s00366-015-0415-0
   Savio A, 2013, EXPERT SYST APPL, V40, P1619, DOI 10.1016/j.eswa.2012.09.009
   Shamshirband S, 2016, J IRRIG DRAIN ENG, V142, DOI 10.1061/(ASCE)IR.1943-4774.0000949
   Shiyang L, 2007, FLUCT NOISE LETT, V7, pL135
   Sonawane JS, 2014, IEEE INT C INF COMM, P5
   Sterkenburg TF, 2016, PHILOS SCI, V83, P459, DOI 10.1086/687257
   Torrents-Barrena J, 2015, ELECTRON LETT, V51, P1566, DOI 10.1049/el.2015.1735
   Wang L, 2014, ALZ DIS ASSOC DIS, V28, P122, DOI 10.1097/WAD.0b013e318299d096
   Wang SH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00106
   Wang SH, 2016, PROG ELECTROMAGN RES, V156, P105
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P637, DOI 10.1177/0037549715623847
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Watamura N, 2016, J NEUROSCI RES, V94, P15, DOI 10.1002/jnr.23674
   Wilkins HM, 2016, CURR TOP MED CHEM, V16, P849, DOI 10.2174/1568026615666150827095102
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zainuddin Z, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P8, DOI 10.1109/ICNC.2015.7377957
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, J ELECTROMAGNET WAVE, V25, P1081, DOI 10.1163/156939311795762024
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/528069
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P873, DOI 10.1177/0037549716667834
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/546814
   Zhang YD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/840491
   Zhang YD, 2014, PROG ELECTROMAGN RES, V144, P171, DOI 10.2528/PIER13121310
   Zhang YD, 2013, SENSORS-BASEL, V13, P4029, DOI 10.3390/s130404029
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
   Zou YC, 2015, ENTROPY-SWITZ, V17, P7167, DOI 10.3390/e17107167
NR 79
TC 86
Z9 88
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10393
EP 10417
DI 10.1007/s11042-016-4222-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900002
DA 2024-07-18
ER

PT J
AU Xiao, S
   Li, W
   Jiang, HF
   Xu, Z
   Hu, ZH
AF Xiao, Shuo
   Li, Wei
   Jiang, Haifeng
   Xu, Zhiou
   Hu, Zihao
TI Trajectroy prediction for target tracking using acoustic and image
   hybrid wireless multimedia sensors networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Acoustic and image sensors; Target
   tracking; Trajectory prediction
ID MULTIOBJECTIVE OPTIMIZATION; SELECTION
AB Wireless multimedia sensor networks (WMSN), with self-organizing and high fault tolerant characteristics, have achieved great advantages in target tracking region. However, the capabilities of these tiny devices are limited by their battery power, storage capacity, computational ability and communication bandwidth. In this paper, hybrid wireless multimedia sensors networks composed of acoustic and image sensors are proposed for target tracking. When the target appears in the detection area, it may change the environment parameters nearby, so acoustic sensors are used to gather target signal firstly. Then, a target location method is executed based on the strength of the received acoustic signal. Furthermore, to achieve energy-efficient target tracking with high reliability and robust, image sensors are used as supplements to the acoustic sensors. This approach also reduces the power consumption communication burden of the whole networks. In order to decrease the number of active nodes, Gauss Markov mobility model is also adopted to predict the target trajectory and minimize the tracking region with considering of vehicular kinematics. Simulation results verify that, compared with other algorithms, our scheme can reduce the energy consumption and improve tracking accuracy.
C1 [Xiao, Shuo; Li, Wei; Jiang, Haifeng; Xu, Zhiou; Hu, Zihao] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Xu, Z (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM sxiao@cumt.edu.cn; wei_li@cumt.edu.cn; haifengjiang@cumt.edu.cn;
   xuzhioucumt@cumt.edu.cn; zihaohu@cumt.edu.cn
FU Fundamental Research Funds for the Central Universities [2015XKMS087]
FX The Fundamental Research Funds for the Central Universities
   (2015XKMS087).
CR [Anonymous], APPL BASED RATE CONT
   [Anonymous], PROC IEEE INT C COMP
   [Anonymous], IEEE COMMUN MAG
   [蔡劼 Cai Jie], 2015, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V55, P565
   Jara EC, 2014, IEEE T EVOLUT COMPUT, V18, P167, DOI 10.1109/TEVC.2013.2243455
   Galluccio L, 2015, IEEE CONF COMPUT, P19, DOI 10.1109/INFCOMW.2015.7179322
   GhasemiGol M, 2015, WIREL NETW, V21, P1425, DOI 10.1007/s11276-014-0858-z
   Gungor VC, 2009, IEEE T IND ELECTRON, V56, P4258, DOI 10.1109/TIE.2009.2015754
   Jinpeng Tian, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P32, DOI 10.1109/CSIE.2009.252
   Joshi S, 2009, IEEE T SIGNAL PROCES, V57, P451, DOI 10.1109/TSP.2008.2007095
   Kumari S, 2015, AD HOC NETW, V27, P159, DOI 10.1016/j.adhoc.2014.11.018
   Li M, 2009, ACM T SENSOR NETWORK, V5, DOI 10.1145/1498915.1498916
   Liu M., 2013, Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on, P1, DOI DOI 10.1109/FG.2013.6553734
   Liu SJ, 2015, IEEE T SIGNAL PROCES, V63, P2582, DOI 10.1109/TSP.2015.2413381
   Masazade E, 2012, IEEE T SIGNAL PROCES, V60, P5048, DOI 10.1109/TSP.2012.2204257
   Miettinen K, 2008, LECT NOTES COMPUT SC, V5252, P1, DOI 10.1007/978-3-540-88908-3_1
   Ngai ECH, 2016, SECUR COMMUN NETW, V9, P77, DOI 10.1002/sec.245
   Olfati-Saber R, 2007, IEEE DECIS CONTR P, P1814
   Sinopoli B, 2004, IEEE T AUTOMAT CONTR, V49, P1453, DOI 10.1109/TAC.2004.834121
   Wang CD, 2016, IEEE T PARALL DISTR, V27, P405, DOI 10.1109/TPDS.2015.2402156
   Wang GD, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511441
   Wang GD, 2014, FUTURE GENER COMP SY, V39, P67, DOI 10.1016/j.future.2013.12.016
   Wang GD, 2014, IET COMMUN, V8, P860, DOI 10.1049/iet-com.2013.0154
   Xiao S, 2017, WIRELESS PERS COMMUN, V95, P1891, DOI 10.1007/s11277-016-3705-y
   Zhu YM, 2007, IEEE INFOCOM SER, P2401, DOI 10.1109/INFCOM.2007.289
   Zuo L, 2007, INT CONF ACOUST SPEE, P1041
NR 26
TC 11
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12003
EP 12022
DI 10.1007/s11042-017-4846-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100018
DA 2024-07-18
ER

PT J
AU Liu, JY
   Yang, DD
   Zhou, HB
   Chen, SQ
AF Liu, Jingyi
   Yang, Dingding
   Zhou, Hongbo
   Chen, Shiqiang
TI A digital image encryption algorithm based on bit-planes and an improved
   logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image encryption; Logistic map; bit-plane; One-time pad
AB This paper presents a digital image encryption algorithm based on bit-planes and an improved logistic map. First, a chaotic sequence, which is generated by the improved logistic map, scrambles the pixels of the original image. Second, the scrambled image is split into a high 4-bit matrix and a low 4-bit matrix. The low 4-bit matrix is then introduced into the improved logistic model to generate a chaotic sequence that is highly correlated with the image as the key, and the key is used for position scrambling and the XOR operation of the high 4-bit matrix. Finally, the two matrices are combined into an 8-bit image matrix to obtain the ciphertext image. The algorithm has a significant one-time pad characteristic. MATLAB simulation experiments are conducted to analyze the security of image encryption in terms of the histogram, plaintext sensitivity, information entropy, and adjacent pixels correlation index. Experimental results show that the number of pixel changes ratio (NPCR) is greater than 90% and the information entropy of the ciphertext image reaches 7.99, demonstrating that the algorithm offers good encryption.
C1 [Liu, Jingyi; Yang, Dingding; Chen, Shiqiang] Hubei Univ Nationalities, Sch Sci, Enshi 445000, Hubei, Peoples R China.
   [Zhou, Hongbo] Guiyang Univ, Sch Math & Informat Sci, Guiyang 550005, Guizhou, Peoples R China.
   [Chen, Shiqiang] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
C3 Hubei Minzu University; Guiyang University; Sichuan University
RP Chen, SQ (corresponding author), Hubei Univ Nationalities, Sch Sci, Enshi 445000, Hubei, Peoples R China.; Chen, SQ (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
EM 369417266@qq.com; 2435507212@qq.com; 79807140@qq.com; chensq8808@126.com
RI Liu, Jia-Bao/C-7850-2015; li, jia/GVT-7587-2022; liu, jia/HKE-9796-2023;
   liu, jia/JAC-7852-2023
OI Liu, Jia-Bao/0000-0002-9620-7692; 
FU Project of the National Science & Technology Pillar Program of China
   [2015BAK27B03]; Science & Technology Cooperation Project of Guizhou
   [LH-2015-7294]
FX This work was supported by the Project of the National Science &
   Technology Pillar Program of China during the Twelfth Five-year Plan
   Period (2015BAK27B03) and the Science & Technology Cooperation Project
   of Guizhou (LH-2015-7294).
CR [Anonymous], 2017, BIOMED RES INT, DOI DOI 10.1128/MCB.00560-16
   [Anonymous], COMPUTER TECHNOLOGY
   [Anonymous], 2015, OPEN CYBERNETICS SYS
   [Anonymous], RES EXPLOR LAB
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   [柴秀丽 Chai Xiuli], 2016, [计算机科学, Computer Science], V43, P134
   Chen Shan-xue, 2015, Journal of Chinese Computer Systems, V36, P1607
   Deng Xiao-Heng, 2014, Journal on Communications, V35, P216, DOI 10.3969/j.issn.1000-436x.2014.03.025
   [郭毅 Guo Yi], 2015, [计算机应用研究, Application Research of Computers], V32, P1131
   Hao LJ, 2014, EUR PHYS J-SPEC TOP, V223, P1679, DOI 10.1140/epjst/e2014-02182-2
   Hu PF, 2018, FUTURE GENER COMP SY, V81, P582, DOI 10.1016/j.future.2017.03.030
   [黄志福 Huang Zhifu], 2017, [公路交通科技, Journal of Highway and Transportation Research and Development], V34, P8
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Liang W, 2018, COMPUT ELECTR ENG, V65, P310, DOI 10.1016/j.compeleceng.2017.05.001
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liu Lepeng, 2013, Journal of Computer Applications, V33, P1070, DOI 10.3724/SP.J.1087.2013.01070
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Lu Ping, 2011, Computer Engineering and Applications, V47, P191, DOI 10.3778/j.issn.1002-8331.2011.21.050
   Pan Tian-gong, 2013, Electric Machines and Control, V17, P97
   Samuel OW, 2018, COMPUT ELECTR ENG, V66, P557, DOI 10.1016/j.compeleceng.2017.02.002
   Samuel OW, 2018, COMPUT ELECTR ENG, V67, P646, DOI 10.1016/j.compeleceng.2017.04.003
   [石立万 Shi Liwan], 2017, [中国公路学报, China Journal of Highway and Transport], V30, P52
   [庹朝永 Tuo Chaoyong], 2013, [计算机科学, Computer Science], V40, P300
   [吴新华 Wu Xinhua], 2013, [微电子学与计算机, Microelectronics & Computer], V30, P69
   [谢国波 Xie Guobo], 2016, [微电子学与计算机, Microelectronics & Computer], V33, P80
   Xu Chao, 2014, Computer Engineering and Design, V35, P451
   Ye GD, 2016, MULTIMED TOOLS APPL, V75, P11433, DOI 10.1007/s11042-015-2861-5
   Yuan Ling, 2009, Journal of Computer Applications, V29, P2681, DOI 10.3724/SP.J.1087.2009.02681
   [张格森 Zhang Gesen], 2017, [微电子学与计算机, Microelectronics & Computer], V34, P13
   Zhang RJ, 2017, ARTIF INTELL MED, V83, P44, DOI 10.1016/j.artmed.2017.05.006
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
NR 31
TC 37
Z9 37
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10217
EP 10233
DI 10.1007/s11042-017-5406-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200054
DA 2024-07-18
ER

PT J
AU Prabhu, V
   Kuppusamy, PG
   Karthikeyan, A
   Varatharajan, R
AF Prabhu, V.
   Kuppusamy, P. G.
   Karthikeyan, A.
   Varatharajan, R.
TI Evaluation and analysis of data driven in expectation maximization
   segmentation through various initialization techniques in medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expectation maximization segmentation; K-means; Random initialization;
   Histogram initialization; Glioblastoma Multiframe; Fuzzy Cluster Means
ID EM ALGORITHM; BRAIN IMAGES; NETWORK
AB The operation of partitioning an image into a collection of connected sets of pixels is known as image segmentation. Expectation Maximization (EM) segmentation requires appropriate initialization of tissue class mean and variance, as it is get stuck on particular possible area of intensity of the probability nature. Decisive initialization is a necessary exploratory process for the forthcoming convergence of the algorithm to best regional maximum of possibility task. Indiscriminate initialization is not dossier directed, deep from optimal, outcomes are not reproducible, do not take advantage of deep rooted patterns in the data or may be loaded on outliers. This paper evaluates the performance of EM segmentation with random initialization, histogram guided initialization and initialization with k-means with respect to computational complexity and root mean squared error of tissue class mean and variance, updated by EM, with manually estimated tissue class mean and variance as ground truth, on paramount plane, T1 contrast and Magnetic resonance (MR) images of Glioblastoma Multiframe (GBM) Edema complex. The random initialization and histogram guided initialization was experimented for k-means, from the clustered output of which; initial tissue class mean and variance for EM are derived. RMS error remains the same for EM initialized and histogram guided K-means. EM initialized with K-means which has histogram guided initialization converges fast than the random initialization K-means, but the computational time is more for the former initialization than the latter. The experimental evaluation of EM initialization schemes and Fuzzy Cluster Means (FCM) were performed in MATLAB. The efficacy of Fuzzy Cluster Means clustering was analyzed qualitatively on tumour-edema complex. FCM could identify only 3 classes including background in the MR specimens. FCM consider edema and certain parts of WM as a single tissue class. Similarly, FCM clubs GM, CSF and necrotic focus into tissue class and produced empty clusters.
C1 [Prabhu, V.; Kuppusamy, P. G.; Karthikeyan, A.] Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College
RP Prabhu, V (corresponding author), Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM prabhu.cvj@gmail.com; kuppusamy.1975@gmail.com; a.karthik1982@gmail.com;
   varathu21@yahoo.com
RI A, Karthikeyan/AAB-9651-2019; v, prabhu/HNQ-9213-2023
OI A, Karthikeyan/0000-0001-6290-6770; v, prabhu/0000-0002-8083-0156
CR DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fatakdawala H, 2010, IEEE T BIO-MED ENG, V57, P1676, DOI 10.1109/TBME.2010.2041232
   Fwu JK, 1997, IEEE T IMAGE PROCESS, V6, P349, DOI 10.1109/83.551709
   Golani M, 2011, T EVOLUTIONARY A JUN
   Gonzalez R., 1992, DIGITAL IMAGE PROCES, P191
   Gooya A, 2012, IEEE T MED IMAGING, V31, P1941, DOI 10.1109/TMI.2012.2210558
   Greenspan H, 2006, IEEE T MED IMAGING, V25, P1233, DOI 10.1109/TMI.2006.880668
   Ilea DE, 2006, P 6 INT C VIS IM IM
   Karthikeyan A, 2018, CLUSTER COMPUT, V21, P177, DOI 10.1007/s10586-017-0979-0
   Karthikeyan A, 2017, COMPUT ELECTR ENG, V59, P39, DOI 10.1016/j.compeleceng.2017.03.006
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Liang ZR, 2009, IEEE T MED IMAGING, V28, P297, DOI 10.1109/TMI.2008.2004670
   Lomer JB, 2013, COMPUTING RES REPOSI
   Lu CF, 2008, IEEE ENG MED BIO, P5502, DOI 10.1109/IEMBS.2008.4650460
   Lynch M., 2007, Journal of Medical Engineering & Technology, V31, P332, DOI 10.1080/03091900600647643
   Melnykov V, 2012, COMPUT STAT DATA AN, V56, P1381, DOI 10.1016/j.csda.2011.11.002
   Mitra P, 2003, PATTERN RECOGN LETT, V24, P863, DOI 10.1016/S0167-8655(02)00198-8
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal SK, 2002, IEEE T GEOSCI REMOTE, V40, P2495, DOI 10.1109/TGRS.2002.803716
   Ray S., 1999, PROC 4 INT C ADV PAT, P137
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Srinivasan P, EM SEGMENTATION AUTO
   Tian GJ, 2011, IEEE T INF TECHNOL B, V15, P373, DOI 10.1109/TITB.2011.2106135
   Tomasi C, 1998, P 1998 IE INT C COMP
   Vlassis N, 2002, NEURAL PROCESS LETT, V15, P77, DOI 10.1023/A:1013844811137
   Wang S, 2009, INT J IMAG SYST TECH, V19, P111, DOI 10.1002/ima.20187
   Wu YT, 2009, IFMBE PROC, V23, P714
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 28
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10375
EP 10390
DI 10.1007/s11042-018-5792-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200063
DA 2024-07-18
ER

PT J
AU Vinay, K
   Kumar, SMD
   Raghavendra, S
   Venugopal, KR
AF Vinay, K.
   Kumar, S. M. Dilip
   Raghavendra, S.
   Venugopal, K. R.
TI Cost and fault-tolerant aware resource management for scientific
   workflows using hybrid instances on clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Scientific workflows; Scheduling; Spot; Blockspot;
   On-demand; Instances; Fault-tolerant
ID ENVIRONMENTS; ALLOCATION; TASKS; TIME
AB Cloud service providers are offering computing resources at a reasonable price as a pay-per-use model. Further, cloud service providers have also introduced different pricing models like spot, blockspot and spotfleet instances that are cost effective and user's have to go through the bidding to balance the reliability and monetary costs. Henceforth, Scientific Workflows (SWf) that are used to model applications of high throughput, computation and complex large-scale data analysis are significantly adopting these computing resources. Nevertheless, spot instances are terminated when the market spot price exceeds the users bid price. Moreover, failures are inevitable in such a large distributed systems and often pose a challenge to design a fault-tolerant scheduling algorithm for SWf. This paper presents an efficient, low-cost and fault-tolerant scheduling algorithm and a bidding strategy to minimize the volatility and cost of resource provisioning for SWf. The proposed algorithm uses spot and blockspot instances as hybrid instances in comparison with on-demand instance to reduce the execution cost and fault-tolerant while meeting the SWf deadline. The results obtained reveal the promising potential of the proposed scheduling algorithm and are demonstrated through empirical simulation study that is robust under short deadlines with minimal makespan and cost.
C1 [Vinay, K.; Kumar, S. M. Dilip; Raghavendra, S.; Venugopal, K. R.] Univ Visvesvaraya Coll Engn, Bengaluru 560001, KA, India.
RP Vinay, K (corresponding author), Univ Visvesvaraya Coll Engn, Bengaluru 560001, KA, India.
EM ec.vinay@gmail.com; dilipkumarsm@gmail.com; raghush86@gmail.com;
   venugopalkr@gmail.com
RI SUTAR, MIHIR KUMAR/G-2078-2018
OI S, Raghavendra/0000-0003-2733-3916
CR Almi'ani K, 2016, INT CON ADV INFO NET, P645, DOI 10.1109/AINA.2016.83
   [Anonymous], 2013, TECHNICAL REPORT
   Bala A, 2015, EXPERT SYST APPL, V42, P980, DOI 10.1016/j.eswa.2014.09.014
   Calheiros RN, 2014, IEEE T PARALL DISTR, V25, P1787, DOI 10.1109/TPDS.2013.238
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Chen JJ, 2007, ACM T AUTON ADAP SYS, V2, DOI 10.1145/1242060.1242063
   Chirkin AM, 2014, IERI PROC, V10, P216, DOI 10.1016/j.ieri.2014.09.080
   Darbha S., 1994, Proceedings of the 1994 International Conference on Parallel Processing, P52
   Dejun JA, 2010, LECT NOTES COMPUT SC, V6275, P197
   Hwang S, 2003, 12TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, PROCEEDINGS, P126
   Jangjaimon I, 2015, IEEE T COMPUT, V64, P396, DOI 10.1109/TC.2013.225
   Javadi B, 2012, J PARALLEL DISTR COM, V72, P1318, DOI 10.1016/j.jpdc.2012.06.012
   Jie Li, 2010, E-Science 2010. Proceedings 6th IEEE International Conference on E-Science (E-Science 2010), P246, DOI 10.1109/eScience.2010.47
   Juve G, 2013, FUTURE GENER COMP SY, V29, P682, DOI 10.1016/j.future.2012.08.015
   Li XJ, 2019, IEEE T SERV COMPUT, V12, P370, DOI 10.1109/TSC.2016.2625247
   Díaz JL, 2017, FUTURE GENER COMP SY, V71, P129, DOI 10.1016/j.future.2017.02.004
   Mehmi S, 2016, PROCEDIA COMPUT SCI, V94, P435, DOI 10.1016/j.procs.2016.08.067
   Plankensteiner T.F. K., 2009, Proc. of the 3rd CoreGRID workshop on grid middleware, P1
   Qu CH, 2016, J NETW COMPUT APPL, V65, P167, DOI 10.1016/j.jnca.2016.03.001
   Ribas M, 2015, J NETW COMPUT APPL, V57, P102, DOI 10.1016/j.jnca.2015.07.002
   Rodriguez MA, 2014, IEEE T CLOUD COMPUT, V2, P222, DOI 10.1109/TCC.2014.2314655
   Samak T., 2012, 2012 8th International Conference on Network and Service Management (CNSM 2012), P46
   Tang XY, 2014, CLUSTER COMPUT, V17, P1413, DOI 10.1007/s10586-014-0372-1
   Vinay K, 2016, ANNU IEEE IND CONF, P1
   Wan JX, 2016, IEEE T NETW SERV MAN, V13, P941, DOI 10.1109/TNSM.2016.2618394
   Zhu XM, 2016, IEEE T PARALL DISTR, V27, P3501, DOI 10.1109/TPDS.2016.2543731
NR 26
TC 9
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10171
EP 10193
DI 10.1007/s11042-017-5304-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200052
DA 2024-07-18
ER

PT J
AU Wei, X
   Lu, W
   Bao, P
   Xing, WW
AF Wei, Xiang
   Lu, Wei
   Bao, Peng
   Xing, Weiwei
TI MGA for feature weight learning in SVM -a novel optimization method in
   pedestrian detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Metropolis criterion; Feature weight; Pedestrian
   detection
ID LOCAL BINARY PATTERNS
AB Pedestrian detection is a challenging task in computer vision, which is often treated as classification problem of pattern recognition. However, dealing with the high dimensional features extracted from images, it turns out to be difficult to choose and combine the informative features for classification. In this paper, a novel optimization method-Metropolis based Genetic Algorithm (MGA) is proposed to solve this problem, and a novel pedestrian detector MGA-SVM is presented and implemented. In MGA, the metropolis criterion is adopted into GA for dynamical parents' selection, which makes the algorithm get a stronger ability to jump out of local minimum as well as achieve convergence. To test the effectiveness of the proposed MGA, we implement it for feature weight learning in SVM pedestrian detector, which is named as MGA-SVM. The experimental results demonstrate the MGA has a better optimization capacity than original GA, which leads to a more accurate pedestrian detection result by using MGA-SVM.
C1 [Wei, Xiang; Lu, Wei; Bao, Peng; Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Lu, W (corresponding author), Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
EM biujqs@163.com
RI bao, peng/C-5665-2008
OI Wei, Xiang/0000-0002-8967-6423
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016 IE 28 INT C TOO
   [Anonymous], 2016, COMPUT INTEL NEUROSC, DOI DOI 10.1007/S00521-016-2680-2
   [Anonymous], P 3 INT C DAT MIN ME
   [Anonymous], 2015, Advances in Artificial Neural Systems, DOI DOI 10.1155/2015/265637
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 1995, IEEE INT WORKSH AUT
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lu XQ, 2012, IEEE T SYST MAN CY B, V42, P939, DOI 10.1109/TSMCB.2012.2185490
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mittal S, 2012, INT SOC DESIGN CONF, P324, DOI 10.1109/ISOCC.2012.6407106
   Mu Y, 2008, 2008 C COMPUTER VISI, P1
   Nguyen MH, 2010, PATTERN RECOGN, V43, P584, DOI 10.1016/j.patcog.2009.09.003
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Qi B, 2014, APPL OPTICS, V53, P2839, DOI 10.1364/AO.53.002839
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Silberstein S, 2014, IEEE INT VEH SYM, P859
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tinghua Wang, 2010, Proceedings of the 2010 International Conference on Intelligent Computation Technology and Automation (ICICTA 2010), P518, DOI 10.1109/ICICTA.2010.108
   Vondrick C, 2013, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2013.8
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang JE, 2011, PROC CVPR IEEE, P1393, DOI 10.1109/CVPR.2011.5995678
   Zhang Q, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON ADVANCED FIBERS AND POLYMER MATERIALS, VOLS 1 AND 2, P497
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
NR 34
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9021
EP 9037
DI 10.1007/s11042-017-4792-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800055
DA 2024-07-18
ER

PT J
AU Amato, G
   Falchi, F
   Vadicamo, L
AF Amato, Giuseppe
   Falchi, Fabrizio
   Vadicamo, Lucia
TI Aggregating binary local descriptors for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary local feature; Fisher vector; VLAD; Bag of words; Convolutional
   neural network; Content-based image retrieval
ID FISHER VECTOR; QUANTIZATION; FEATURES
AB Content-Based Image Retrieval based on local features is computationally expensive because of the complexity of both extraction and matching of local feature. On one hand, the cost for extracting, representing, and comparing local visual descriptors has been dramatically reduced by recently proposed binary local features. On the other hand, aggregation techniques provide a meaningful summarization of all the extracted feature of an image into a single descriptor, allowing us to speed up and scale up the image search. Only a few works have recently mixed together these two research directions, defining aggregation methods for binary local features, in order to leverage on the advantage of both approaches.In this paper, we report an extensive comparison among state-of-the-art aggregation methods applied to binary features. Then, we mathematically formalize the application of Fisher Kernels to Bernoulli Mixture Models. Finally, we investigate the combination of the aggregated binary features with the emerging Convolutional Neural Network (CNN) features. Our results show that aggregation methods on binary features are effective and represent a worthwhile alternative to the direct matching. Moreover, the combination of the CNN with the Fisher Vector (FV) built upon binary features allowed us to obtain a relative improvement over the CNN results that is in line with that recently obtained using the combination of the CNN with the FV built upon SIFTs. The advantage of using the FV built upon binary features is that the extraction process of binary features is about two order of magnitude faster than SIFTs.
C1 [Amato, Giuseppe; Falchi, Fabrizio; Vadicamo, Lucia] CNR, Inst Informat Sci & Technol ISTI, Via Moruzzi 1, I-56124 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Vadicamo, L (corresponding author), CNR, Inst Informat Sci & Technol ISTI, Via Moruzzi 1, I-56124 Pisa, Italy.
EM giuseppe.amato@isti.cnr.it; fabrizio.falchi@isti.cnr.it;
   lucia.vadicamo@isti.cnr.it
RI Amato, Giuseppe/F-2227-2013; Falchi, Fabrizio/J-2920-2012; Vadicamo,
   Lucia/P-5138-2018
OI Amato, Giuseppe/0000-0003-0171-4315; Falchi,
   Fabrizio/0000-0001-6258-5313; Vadicamo, Lucia/0000-0001-7182-7038
FU Tuscany region under the FAR-FAS program [CUP CIPE D58C15000270008];
   European Commission [325122]
FX This work was partially founded by: EAGLE, Europeana network of Ancient
   Greek and Latin Epigraphy, co-founded by the European Commission,
   CIP-ICT-PSP.2012.2.1 - Europeana and creativity, Grant Agreement n.
   325122; and Smart News, Social sensing for breakingnews, co-founded by
   the Tuscany region under the FAR-FAS 2014 program, CUP CIPE
   D58C15000270008.
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Amato G, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2964911
   Amato G, 2016, LECT NOTES COMPUT SC, V9939, P93, DOI 10.1007/978-3-319-46759-7_7
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, NIPS
   [Anonymous], ARXIVABS13101531
   [Anonymous], PROCEEDINGS OF THE 1
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], RR8325
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], MIR 08
   [Anonymous], ABS150103719 CORR
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 1964, The Theory of Matrices in Numerical Analysis
   [Anonymous], INTRO L1 NORM BASED
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], INFORM SCI
   [Anonymous], 2015, IEEE COMPUT SOC CONF
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], ARXIVABS150802496
   [Anonymous], 1996, HIGH LEVEL VISION OB
   [Anonymous], 2006, ADV DATABASE SYSTEMS
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen D, 2011, CONF REC ASILOMAR C, P850, DOI 10.1109/ACSSC.2011.6190128
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gálvez-López D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Lee S, 2015, ELECTRON LETT, V51, P555, DOI 10.1049/el.2015.0080
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Miksik O, 2012, INT C PATT RECOG, P2681
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salton G, 1986, Introduction to Modern Information Retrieval
   Sánchez J, 2015, PATTERN RECOGN LETT, V59, P26, DOI 10.1016/j.patrec.2015.03.010
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Simonyan K., 2014, 14091556 ARXIV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tolias G, 2014, LECT NOTES COMPUT SC, V8694, P382, DOI 10.1007/978-3-319-10599-4_25
   Tolias G, 2011, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2011.6126427
   Uchida Y, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P23, DOI 10.1109/ACPR.2013.6
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Van Opdenbosch D, 2014, IEEE IMAGE PROC, P2804, DOI 10.1109/ICIP.2014.7025567
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Witten I.H., 1999, Managing Gigabytes: Compressing and Indexing Documents and Images
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu Zhang, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P630, DOI 10.1007/978-3-642-36973-5_53
   Zhou BL, 2014, ADV NEUR IN, V27
NR 80
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5385
EP 5415
DI 10.1007/s11042-017-4450-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, WH
   Han, DF
   Li, HY
   Wang, XZ
   Zhu, JL
AF Li, Wenhui
   Han, Daifeng
   Li, Huiying
   Wang, Xuezhi
   Zhu, Jinlong
TI Extraction of digital terrain model based on regular mesh generation in
   mountainous areas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light detecting and ranging (LiDAR); Regular mesh generation;
   Mountainous regions; Digital terrain model
ID AIRBORNE LIDAR DATA; MANY-CORE PROCESSORS; POINT CLOUDS; FILTERING
   ALGORITHM; PARALLEL FRAMEWORK; HEVC; DENSIFICATION; SEGMENTATION;
   HEIGHT; DTM
AB Airborne LiDAR technology is a popular technique to quickly acquire high-precision information of the ground and the objects above it. Moreover, filtering the data is one of the necessary core processing steps. In recent years, many algorithms have been derived from traditional filtering algorithms. However, when applied to LiDAR data obtained from mountainous regions, most algorithms generate numerous omissions and errors when attempting to retain steep terrain features and filter vegetation information. This paper aims to quickly and accurately extract the digital terrain model (DTM) in mountainous regions. To accomplish this goal, a filtering algorithm based on a regular mesh generation strategy is proposed. The proposed algorithm initially divides the huge amount of point cloud data into strips and selects the appropriate spacing to subdivide each strip into equidistant grid data. The grid data is used as the input to an iterative polynomial fitting process, after which the point cloud is classified based on a controlled threshold. The experimental results show that the proposed method can quickly and efficiently classify data of mountains with different characteristics while retaining terrain feature information better than other algorithms. The average accuracy of recognition is greater than 92%. In addition, this algorithm also applies to mountains with lush vegetation.
C1 [Li, Wenhui; Han, Daifeng; Li, Huiying; Wang, Xuezhi] Jilin Univ, Comp Sci & Technol Dept, Changchun 130012, Jilin, Peoples R China.
   [Li, Wenhui; Han, Daifeng; Li, Huiying] Jilin Univ, Symbol Computat & Knowledge Engineer, Minist Educ, Changchun, Jilin, Peoples R China.
   [Zhu, Jinlong] Changchun Normal Univ, Comp Sci & Technol Dept, Changhun 130032, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Changchun Normal University
RP Li, HY (corresponding author), Jilin Univ, Comp Sci & Technol Dept, Changchun 130012, Jilin, Peoples R China.; Li, HY (corresponding author), Jilin Univ, Symbol Computat & Knowledge Engineer, Minist Educ, Changchun, Jilin, Peoples R China.
EM lihuiying@jlu.edu.cn
RI Wang, Jin/GYA-2019-2022; Zeng, Yun/JFK-6190-2023; LI,
   Wenhui/JCD-9947-2023
FU Scientific and Technological Development Scheme of Jilin Province
   [20140520071JH]
FX This study was supported by Scientific and Technological Development
   Scheme of Jilin Province (Grant No. 20140520071JH).
CR [Anonymous], 2016, REMOTE SENS
   Axelsson P., 2000, The International Archives of the Photogrammetry and Remote Sensing, Amsterdam, The Netherlands, VXXXIII, P110, DOI DOI 10.1016/J.ISPRSJPRS.2005.10.005
   Bao YF, 2008, SCI CHINA SER E, V51, P176, DOI 10.1007/s11431-008-6018-x
   Chaib S, 2016, INT GEOSCI REMOTE SE, P2742, DOI 10.1109/IGARSS.2016.7729708
   Chen CF, 2013, ISPRS J PHOTOGRAMM, V82, P1, DOI 10.1016/j.isprsjprs.2013.05.001
   Chen Q., 2016, REMOTE SENS, V8, P1
   Chen Q, 2007, PHOTOGRAMM ENG REM S, V73, P175, DOI 10.14358/PERS.73.2.175
   Chen Q, 2009, INT J REMOTE SENS, V30, P1069, DOI 10.1080/01431160802158310
   Clark ML, 2004, REMOTE SENS ENVIRON, V91, P68, DOI 10.1016/j.rse.2004.02.008
   Cobby DM, 2001, ISPRS J PHOTOGRAMM, V56, P121, DOI 10.1016/S0924-2716(01)00039-9
   George Sithole, 2003, REPORT ISPRS COMP FI
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Jody I, 2011, GOLDEN SOFTWARE
   Kraus K, 1998, ISPRS J PHOTOGRAMM, V53, P193, DOI 10.1016/S0924-2716(98)00009-4
   Li Y, 2014, REMOTE SENS-BASEL, V6, P12885, DOI 10.3390/rs61212885
   Li Y, 2014, PHOTOGRAMM ENG REM S, V80, P133, DOI 10.14358/PERS.80.2.133-141
   Li Y, 2013, OPT LASER TECHNOL, V54, P288, DOI 10.1016/j.optlastec.2013.06.007
   Lin XG, 2014, REMOTE SENS-BASEL, V6, P1294, DOI 10.3390/rs6021294
   Lohmann P., 2000, International Archives of Photogrammetry and Remote Sensing, V33, P540
   Maguya AS, 2014, REMOTE SENS-BASEL, V6, P6524, DOI 10.3390/rs6076524
   Meng XL, 2010, REMOTE SENS-BASEL, V2, P833, DOI 10.3390/rs2030833
   Meng XL, 2009, ISPRS J PHOTOGRAMM, V64, P117, DOI 10.1016/j.isprsjprs.2008.09.001
   Mongus D, 2012, ISPRS J PHOTOGRAMM, V67, P1, DOI 10.1016/j.isprsjprs.2011.10.002
   Pfeifer N, 1996, INT ARCH PHOTOGRAMM, V31, P383
   Sithole G, 2004, ISPRS J PHOTOGRAMM, V59, P85, DOI 10.1016/j.isprsjprs.2004.05.004
   Sithole G., 2001, INT ARCHIVE PHOTOGRA, V34, P203
   Soininen A., 1999, US GUID
   Streutker DR, 2006, REMOTE SENS ENVIRON, V102, P135, DOI 10.1016/j.rse.2006.02.011
   Susaki J, 2012, REMOTE SENS-BASEL, V4, P1804, DOI 10.3390/rs4061804
   Vosselman George., 2000, IAPRS, V33, P935942, DOI [10.1016/S0924-2716(98)00009-4, 10 1016/S0924-2716(98)00009-4]
   Wang C K, 2010, DEM GEMERATION AIRBO, P38
   Wang W, 2016, COLLABORATIVE SPARSE, V23, P80
   Wang W, 2016, CVPR 2016 IE C COMP
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang JX, 2013, ISPRS J PHOTOGRAMM, V81, P44, DOI 10.1016/j.isprsjprs.2013.04.001
   Zhang KQ, 2003, IEEE T GEOSCI REMOTE, V41, P872, DOI 10.1109/TGRS.2003.810682
NR 39
TC 2
Z9 3
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6267
EP 6286
DI 10.1007/s11042-017-4535-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800053
DA 2024-07-18
ER

PT J
AU Shi, ZF
   Xu, ZH
   Pang, K
   Cao, QJ
   Luo, T
AF Shi, Zaifeng
   Xu, Zehao
   Pang, Ke
   Cao, Qingjie
   Luo, Tao
TI Dissimilar pixel counting based impulse detector for two-phase mixed
   noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed noise removal; Impulse detector; Outlier point; Detection
   capability; Trilateral filter
ID BILATERAL FILTER; MEDIAN FILTER; ALGORITHM; IMAGES
AB Mixed noise is a challenging noise model due to its statistical complexity. A new two-phase denoising method based on an impulse detector using dissimilar pixel counting is proposed in this paper. This method consists of two stages: detection and filtering. For the detection phase, average difference scheme is proposed to distinguish whether two neighboring pixels are similar or not, and then the number of dissimilar pixels is compared with a threshold to locate the outlier point in noisy image. An iterative framework is used for detection accuracy with the least numbers of iteration. For the filtering phase, an extended trilateral filter is used to remove the mixture of Gaussian and impulse noise, which are treated differently depending on the guidance matrix from the detection phase. Extensive experimental results demonstrate that the proposed method exhibits better noise detection capability and outperforms many existing two-phase mixed noise removal methods in both quantitative evaluation and visual quality.
C1 [Shi, Zaifeng; Xu, Zehao; Cao, Qingjie] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
   [Pang, Ke; Luo, Tao] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Cao, Qingjie] Tianjin Normal Univ, Sch Math Sci, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University; Tianjin Normal University
RP Shi, ZF (corresponding author), Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
EM shizaifeng@tju.edu.cn
RI shi, zaifeng/AAM-6769-2020; LUO, TAO/HTS-4830-2023
OI LUO, TAO/0000-0003-2162-363X; Shi, Zaifeng/0000-0002-3851-5697
CR Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   COYLE EJ, 1989, IEEE T ACOUST SPEECH, V37, P2037, DOI 10.1109/29.45552
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   Gunturk BK, 2011, IEEE T IMAGE PROCESS, V20, P2690, DOI 10.1109/TIP.2011.2126585
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   Javed SG, 2016, MULTIMED TOOLS APPL, V75, P5887, DOI 10.1007/s11042-015-2554-0
   Jiang JL, 2015, SIGNAL PROCESS, V116, P101, DOI 10.1016/j.sigpro.2015.04.011
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jourabloo A, 2012, SCI IRAN, V19, P1738, DOI 10.1016/j.scient.2012.07.016
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Liu L., 2016, IEEE T CYBERNETICS, P1
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   López-Rubio E, 2010, PATTERN RECOGN, V43, P1835, DOI 10.1016/j.patcog.2009.11.017
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   Roig B, 2016, IET IMAGE PROCESS, V10, P24, DOI 10.1049/iet-ipr.2014.0838
   Smolka B, 2015, J REAL-TIME IMAGE PR, V10, P1
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wong A, 2008, SIGNAL PROCESS, V88, P1615, DOI 10.1016/j.sigpro.2008.01.002
   Wu Y, 2014, SIGNAL PROCESS, V103, P45, DOI 10.1016/j.sigpro.2014.01.007
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P763, DOI 10.1109/LSP.2013.2263135
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
NR 35
TC 5
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6933
EP 6953
DI 10.1007/s11042-017-4613-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700023
DA 2024-07-18
ER

PT J
AU Wu, O
   Han, MQ
AF Wu, Ou
   Han, Mengqiao
TI Screenshot-based color compatibility assessment and transfer for Web
   pages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color compatibility assessment; Color theme extraction; Color transfer;
   Screenshot; Web mining; Image processing; Transfer learning
ID PREFERENCE; AESTHETICS; USABILITY
AB Colors play particularly important roles in both designing and accessing Web pages. A well-designed color scheme improves the visual aesthetic of Web pages and facilitates user interactions. As far as we know, existing studies on color compatibility assessment and enhancement focus on images, and the assessment and enhancement for Web colors are rare. In order to aid Web designers evaluate and choose colors, this paper investigates color compatibility assessment for Web pages and applies this assessment to Web color editing based on Web screenshots rather than source codes. This study consists of four parts. First, the roles of color design in Web pages are discussed and a screenshot-based approach is proposed for the analysis of Web page regions. Second, a new method for extracting the color theme of a Web page is proposed. Then, we construct an assessment model that attributes scores to the color compatibility of Web pages through transfer learning. Third, we examine Web color transfer and combine it with the learned compatibility assessment model to create a new application that recommends colors for Web design. Lastly, the evaluation results suggest that the constructed compatibility assessment model and the proposed color transfer technique are effective and are superior over conventional methods. User studies suggest that our color recommendation application can generate new Web page screenshots that have higher color compatibility scores in comparison with those of the original pages.
C1 [Wu, Ou] Tianjin Univ, Ctr Appl Math, Tianjin, Peoples R China.
   [Han, Mengqiao] Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China.
C3 Tianjin University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Wu, O (corresponding author), Tianjin Univ, Ctr Appl Math, Tianjin, Peoples R China.
EM ou.wu@tju.edu.cn; michellehan33@126.com
FU NSFC [61379098]
FX This work is supported by NSFC No. 61379098.
CR [Anonymous], 2006, F-Shaped Pattern For Reading Web Content
   Cao LJ, 2003, NEUROCOMPUTING, V55, P321, DOI 10.1016/S0925-2312(03)00433-8
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Coursaris CK, 2008, J USABILITY STUD, V3, P103
   Cyr D, 2010, INT J HUM-COMPUT ST, V68, P1, DOI 10.1016/j.ijhcs.2009.08.005
   Dong W., 2010, ACM SIGGRAPH ASIA 20
   Flatla D.R., 2013, P SIGCHI C HUM FACT, P2069, DOI DOI 10.1145/2470654.2481283
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Forero PA, 2012, IEEE T SIGNAL PROCES, V60, P4163, DOI 10.1109/TSP.2012.2196696
   Goethe Johann., 1810, Theory of Colors
   HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180
   Huang JY, 2007, Advances in Neural Information Processing Systems (NeurIPS), V19, P601
   Ivory MY, 2005, ACM T INFORM SYST, V23, P463, DOI 10.1145/1095872.1095876
   IVORY MY, 2001, P SIGCHI C HUM FACT, P53
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kondratova I, 2007, LECT NOTES COMPUT SC, V4560, P123
   Koufaris M, 2002, INFORM SYST RES, V13, P205, DOI 10.1287/isre.13.2.205.83
   Kumar R, 2012, ACM S US INT SOFTW T, P2197
   Kumar R, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2197
   Lafleur C, 2011, MENSCH COMPUTER 2011, P101
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276381, 10.1145/1239451.1239454]
   Lee S, 2010, COMPUT IND, V61, P329, DOI 10.1016/j.compind.2009.12.004
   Lin S., 2013, P ACM SIGCHI C HUM F, P3101
   Ling J, 2002, DISPLAYS, V23, P223, DOI 10.1016/S0141-9382(02)00041-0
   Liu W, 2010, IEEE T KNOWL DATA EN, V22, P447, DOI 10.1109/TKDE.2009.109
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Park SE, 2004, INTERACT COMPUT, V16, P351, DOI 10.1016/j.intcom.2003.07.001
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Reinecke Katharina, 2013, P SIGCHI C HUM FACT, P2049, DOI [10.1145/2470654.2481281, DOI 10.1145/2470654.2481281, 10]
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schloss KB, 2011, ATTEN PERCEPT PSYCHO, V73, P551, DOI 10.3758/s13414-010-0027-0
   Schmidt KE, 2009, ERGONOMICS, V52, P631, DOI 10.1080/00140130802558995
   Su Z, 2014, IEEE T MULTIMEDIA, V16, P988, DOI 10.1109/TMM.2014.2305914
   Tai YW, 2005, PROC CVPR IEEE, P747
   Thorlacius L, 2007, NORD REV, V28, P63, DOI 10.1515/nor-2017-0201
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Xiao Y, 2013, IEEE T MULTIMEDIA, V15, P549, DOI 10.1109/TMM.2012.2233725
   Xiaolan Zhu, 2000, SIGIR Forum, V34, P288
   Yang YG, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/157245
NR 42
TC 3
Z9 3
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6671
EP 6698
DI 10.1007/s11042-017-4582-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700012
DA 2024-07-18
ER

PT J
AU Atsali, G
   Panagiotakis, S
   Markakis, E
   Mastorakis, G
   Mavromoustakis, CX
   Pallis, E
   Malamos, A
AF Atsali, Georgia
   Panagiotakis, Spyros
   Markakis, Evangelos
   Mastorakis, George
   Mavromoustakis, Constandinos X.
   Pallis, Evangelos
   Malamos, Athanasios
TI A mixed reality 3D system for the integration of X3DoM graphics with
   real-time IoT data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; IoT; Web; Real-time; Monitoring; Control; Data
   visualization; 3D graphics; X3DoM
ID WEB; VISUALIZATION; ENVIRONMENTS; MANAGEMENT; ENERGY
AB A mixed reality system is a set of interlinked real-time sensors' and actuators' data presented within a virtual world with graphics and texts. This paper describes a methodology for the implementation of mixed reality systems that interconnect real-world IoT systems with 3D virtual worlds. In particular, this paper presents the steps for integrating X3DoM graphics with real-time data and discusses the associated technologies from a developer's point of view. Such a mixed reality 3D system, interconnecting real-time sensors and actuators from a real-world wastewater management system, with all the corresponding components and controls was developed. This mixed reality 3D world was created using open source web technologies that provide users, in this case the building tenants, with the ability to monitor and control the water consumption of their homes at anytime and from anywhere. It provides not only a comprehensive monitoring 3D model of the real building management system but also an easy to use controlling platform, where the commands are executed in the real building infrastructure.
C1 [Atsali, Georgia; Panagiotakis, Spyros; Markakis, Evangelos; Mastorakis, George; Pallis, Evangelos; Malamos, Athanasios] Technol Educ Inst Crete, Dept Informat Engn, Multimedia Networks & Commun Lab, GR-71004 Iraklion, Crete, Greece.
   [Mavromoustakis, Constandinos X.] Univ Nicosia, Dept Comp Sci, Nicosia, Cyprus.
C3 Hellenic Mediterranean University; University of Nicosia
RP Panagiotakis, S (corresponding author), Technol Educ Inst Crete, Dept Informat Engn, Multimedia Networks & Commun Lab, GR-71004 Iraklion, Crete, Greece.
EM gogoatsali@gmail.com; spanag@teicrete.gr; markakis@pasiphae.eu;
   mastorakis@gmail.com; mavromoustakis.c@unic.ac.cy; pallis@pasiphae.eu;
   amalamos@ie.teicrete.gr
RI Mavromoustakis, Constandinos/M-8305-2014; Mastorakis,
   George/L-9001-2019; Pallis, Evangelos/AAL-7087-2021
OI Mavromoustakis, Constandinos/0000-0003-0333-8034; Mastorakis,
   George/0000-0002-6733-5652; Pallis, Evangelos/0000-0003-2373-9775;
   Panagiotakis, Spyros/0000-0001-8091-6462; Malamos,
   Athanasios/0000-0001-5910-5702; Markakis, Evangelos/0000-0003-0959-598X
CR Agrusa R, 2009, 2 C HUM SYST INT CAT
   [Anonymous], 2016, 3DS MAX DES
   Atila U., 2013, PROGR NEW TRENDS 3D, P249
   Atsali G, 2016, INT S AMB INT EMB SY
   Back M, 2010, IEEE INT CON MULTI, P1160, DOI 10.1109/ICME.2010.5582532
   Behr J, 2009, 14 INT C 3D WEB TECH
   Cagalaban G. A., 2009, INT J SMART HOME, V3, P49
   Cheng T, 2013, AUTOMAT CONSTR, V34, P3, DOI 10.1016/j.autcon.2012.10.017
   Choras M, 2009, CRIT INF INFR SEC 4
   Díaz L, 2013, ENVIRON MODELL SOFTW, V48, P65, DOI 10.1016/j.envsoft.2013.06.002
   Duquennoy S, 2009, 6 IEEE INT C EMB SOF
   Dykes J., 2005, Exploring geovisualization
   Eicke TN, 2015, EXPERT SYST APPL, V42, P3585, DOI 10.1016/j.eswa.2014.11.059
   Espíndola DB, 2013, COMPUT IND, V64, P376, DOI 10.1016/j.compind.2013.01.002
   Evans A, 2014, COMPUT GRAPH-UK, V41, P43, DOI 10.1016/j.cag.2014.02.002
   Feldhorst S, 2010, 8 IEEE INT C IND INF
   Guinard D, 2011, ARCHITECTING THE INTERNET OF THINGS, P97
   Hamza-Lup FG, 2016, GRAPH MODELS, V88, P66, DOI 10.1016/j.gmod.2016.03.005
   Hilda J J, 2016, INDIAN J SCI TECHNOL, V9, P1
   Kalochristianakis M, 2016, INT C TEL MULT HER C
   Kim J-S, 2015, 20 INT C 3D WEB TECH
   Olbrich M, 2014, 19 INT C WEB3D TECHN
   Paradiso JA, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.47
   Robles T, 2014, 28 INT C ADV INF NET
   Robles T., 2015, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications, V6, P4, DOI 10.22667/JOWUA.2015.03.31.004
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Stangl M, 2016, PROC CIRP, V52, P222, DOI 10.1016/j.procir.2016.07.073
   Stein C, 2014, 19 INT C WEB3D TECHN
   Syberfeldt A, 2013, COMPUT IND ENG, V64, P987, DOI 10.1016/j.cie.2013.01.008
   Thürlimann CM, 2015, WATER PRACT TECHNOL, V10, P10, DOI 10.2166/wpt.2015.002
   Walker JD, 2014, ENVIRON MODELL SOFTW, V55, P49, DOI 10.1016/j.envsoft.2014.01.023
   Wong BP, 2016, ENVIRON MODELL SOFTW, V84, P505, DOI 10.1016/j.envsoft.2016.07.020
NR 32
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4731
EP 4752
DI 10.1007/s11042-017-4988-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500037
DA 2024-07-18
ER

PT J
AU Chaudhary, M
   Kumar, H
   Kaushal, S
   Sangaiah, AK
AF Chaudhary, Meghna
   Kumar, Harish
   Kaushal, Sakshi
   Sangaiah, Arun Kumar
TI The case analysis on sentiment based ranking of nodes in social media
   space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Sentiment analysis; Ranking; Cosine similarity; Cyber
   Space
AB Now-a-days, social network sites have become quite popular for communication in the society. People have entangled their day-to-day activities around social media platforms. Social Networks have allowed the users to share their opinions on different topics. In social media, sentiment analysis is an important character to determine opinions of users. Moreover, user's can be ranked to determine their relative influence. This paper proposes a methodology to rank the users involving sentiment related parameters such as likes, comments and corresponding likescount. Analysis of users' comments is carried-out. Weights are assigned to these parameters and scores are calculated for each user. Users are ranked on the basis of scores obtained and compared with existing technique. In order to verify the effectiveness of proposed methodology, data is extracted from a verified Facebook page 'Panjab University, Chandigarh'. Mean, standard deviation and variance are computed to capture the usefulness of ranks obtained by the proposed method. Results depict that the proposed methodology is better than existing technique since it incorporates several features indicating positive and negative behavior of users. This technique can be used to determine the highly trusted and the most distrusted users in a social media user's profile. Users with negative scores can be considered for outlier analysis. The proposed methodology can also be extended to work on other social media platforms.
C1 [Chaudhary, Meghna; Kumar, Harish; Kaushal, Sakshi] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Panjab University; Vellore Institute of Technology (VIT); VIT Vellore
RP Sangaiah, AK (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM arunkumarsangaiah@gmail.com
RI Chaudhary, Meghna/KBQ-4437-2024; Sangaiah, Arun Kumar/U-6785-2019;
   Kumar, Harish/G-7632-2015
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; Kumar,
   Harish/0000-0002-2800-9715; Chaudhary, Meghna/0000-0002-7722-653X
CR [Anonymous], 2006, Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST'06, DOI DOI 10.3115/1654641.1654642
   [Anonymous], 2015, 2015 IEEE INT C DATA
   Cai CY, 2016, IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS: CYBERSECURITY AND BIG DATA, P202, DOI 10.1109/ISI.2016.7745470
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Chen HC, 2010, IEEE INTELL SYST, V25, P74, DOI 10.1109/MIS.2010.75
   David D. S., 2016, P INT C COMM EL SYST, P1, DOI DOI 10.1109/CESYS.2016.7889823
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651
   Eirinaki M, 2012, J COMPUT SYST SCI, V78, P1175, DOI 10.1016/j.jcss.2011.10.007
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jain V, 2018, NEURAL COMPUT APPL, V29, P555, DOI 10.1007/s00521-016-2533-z
   Ortega FJ, 2012, COMPUT NETW, V56, P2884, DOI 10.1016/j.comnet.2012.05.002
   Kamps J., 2004, P 4 INT C LANGUAGE R, P1115
   Kian Ming, 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P97
   Kwon O, 2010, COMPUT HUM BEHAV, V26, P254, DOI 10.1016/j.chb.2009.04.011
   Li M, 2016, IEEE ACM INT C ADV S
   Liang B, 2014, EXPERT SYST APPL, V41, P7455, DOI 10.1016/j.eswa.2014.05.050
   Liu B, 2010, IEEE INTELL SYST, V25, P76
   Mohammadinejad A, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P346, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.59
   Moohong Min, 2011, 2011 International Conference on Computational Aspects of Social Networks (CASoN 2011), P233, DOI 10.1109/CASON.2011.6085950
   Ntalianis K, 2016, IEEE 7 INT C INT COM, P27
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Reilly CF, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 2, P237, DOI 10.1109/CSCI.2014.127
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Sangaiah AK, 2017, NEURAL COMPUT APPL, V28, P111, DOI 10.1007/s00521-015-2040-7
   Santana P, 2014, INTRODUCAO A GEOGRAFIA DA SAUDE: TERRITORIO, SAUDE E BEM-ESTAR, P1, DOI 10.14195/978-989-26-0727-6
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Snyder B., 2007, proceedings of the Joint Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies, P300
   Subbian K., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P661, DOI 10.1109/PASSAT/SocialCom.2011.167
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Xiao X, 2018, FUTURE GENER COMP SY, V86, P863, DOI 10.1016/j.future.2017.01.035
   Zhang K, 2011, INT C PAR DISTRIB SY, P188, DOI 10.1109/ICPADS.2011.37
   Zhao YM, 2013, INT SYM COMPUT INTEL, P410, DOI 10.1109/ISCID.2013.108
NR 33
TC 5
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4217
EP 4236
DI 10.1007/s11042-017-4700-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500009
DA 2024-07-18
ER

PT J
AU Li, YF
   Li, PA
   Lei, DZ
   Shi, YC
   Tan, LX
AF Li, Yufeng
   Li, Ping'an
   Lei, Daozhong
   Shi, Yingchun
   Tan, Lixin
TI Investigating image stitching for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stitching; Transfer learning; Action recognition
AB Action recognition is usually a central problem for many practical applications, such as video annotations, video surveillance and human computer interaction. Most action recognition approaches are based on localized spatio-temporal features that can vary significantly when the viewpoint changes. However, their performance rapidly drops when the viewpoints of the training and testing data are different. In this paper, we propose a transfer learning framework for view-invariant action recognition by the way of sharing image stitching feature among different views. Experimental results on multi-view action recognition IXMAS dataset demonstrate that our method produces remarkably good results and outperforms baseline methods.
C1 [Li, Yufeng; Li, Ping'an; Lei, Daozhong; Shi, Yingchun; Tan, Lixin] Hunan Coll Informat, Sch Elect Engn, Changsha, Hunan, Peoples R China.
RP Tan, LX (corresponding author), Hunan Coll Informat, Sch Elect Engn, Changsha, Hunan, Peoples R China.
EM lixintan821@gmail.com
FU Scientific Research Project of Hunan Provincial Education Department,
   China;  [16C1139]
FX This research is supported by the Scientific Research Project of Hunan
   Provincial Education Department, China. The research and application of
   UAV Aerial system based on image splicing using multiple cameras (Grant
   No. 16C1139).
CR [Anonymous], 2007, ICCV
   [Anonymous], 2008, NIPS
   [Anonymous], 2011, CVPR
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Farhadi Ali., 2008, ECCV
   Huang C.-H., 2012, ECCV
   Li B., 2012, CVPR
   Li R., 2012, CVPR
   Reddy K., 2009, ICCV
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu Xinxiao., 2012, ECCV
   Yan Y, 2014, IEEE T IMAGE PROCESS
   Yan Y, 2013, IEEE INT C BIOINFORM
   Yan Y, 2017, IEEE DECIS CONTR P
NR 18
TC 1
Z9 1
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3279
EP 3286
DI 10.1007/s11042-017-5072-4
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600020
DA 2024-07-18
ER

PT J
AU Wang, SH
   Du, SD
   Atangana, A
   Liu, AJ
   Lu, ZY
AF Wang, Shuihua
   Du, Sidan
   Atangana, Abdon
   Liu, Aijun
   Lu, Zeyuan
TI Application of stationary wavelet entropy in pathological brain
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Stationary wavelet entropy; Pathological
   brain detection; Wavelet entropy; Wavelet energy; Discrete wavelet
   transform
ID SUPPORT VECTOR MACHINE; ALZHEIMERS-DISEASE; TSALLIS ENTROPY; MRI;
   CLASSIFICATION; IMAGES; TRANSFORM; DIAGNOSIS; HYBRIDIZATION;
   SCHIZOPHRENIA
AB Labeling brain images as healthy or pathological cases is an important procedure for medical diagnosis. Therefore, we proposed a novel image feature, stationary wavelet entropy (SWE), to extract brain image features. Meanwhile, we replaced the feature extraction procedure in state-of-the-art approaches with the proposed SWE. We found the classification performance improved after replacing wavelet entropy (WE), wavelet energy (WN), and discrete wavelet transform (DWT) with the proposed SWE. This proposed SWE is superior to WE, WN, and DWT.
C1 [Wang, Shuihua; Du, Sidan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Jiangsu, Peoples R China.
   [Atangana, Abdon] Univ Free State, ZA-9300 Bloemfontein, South Africa.
   [Liu, Aijun] Arizona State Univ, WP Carey Sch Business, POB 873406, Tempe, AZ 85287 USA.
   [Lu, Zeyuan] Chinese Acad Sci, Hefei Inst Phys Sci, Ctr Med Phys & Technol, Hefei 230031, Peoples R China.
C3 Nanjing University; University of the Free State; Arizona State
   University; Arizona State University-Tempe; Chinese Academy of Sciences;
   Hefei Institutes of Physical Science, CAS
RP Du, SD (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Jiangsu, Peoples R China.
EM coff128@nju.edu.cn
RI aijun, liu/X-6413-2019; Atangana, Abdon/AAE-4779-2021; Du,
   Sidan/JVN-2413-2024; Wang, shuihua/G-7326-2016
OI Du, Sidan/0000-0002-7079-0066; Wang, shuihua/0000-0003-4713-2791
FU National Nature Science of China [61271231]
FX This paper was supported by the National Nature Science of China
   (No.61271231).
CR [Anonymous], MATH PROBL ENG
   Babic-Stojic B, 2016, J MAGN MAGN MATER, V403, P118, DOI 10.1016/j.jmmm.2015.11.075
   Ramírez-Pacheco JC, 2015, ENTROPY-SWITZ, V17, P7979, DOI 10.3390/e17127856
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Cherif LH, 2010, EXPERT SYST APPL, V37, P913, DOI 10.1016/j.eswa.2009.09.036
   Cierpiol S, 2015, ACTA NEUROL BELG, V115, P841, DOI 10.1007/s13760-015-0488-y
   D'Angelino RHR, 2013, BIOMED RES INT, V2013, P6
   Dickie DA, 2015, MAGN RESON IMAGING, V33, P1299, DOI 10.1016/j.mri.2015.07.014
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Ella A, 2015, MAGN RESON IMAGING, V33, P1329, DOI 10.1016/j.mri.2015.09.001
   Fan YH, 2015, METAB BRAIN DIS, V30, P1479, DOI 10.1007/s11011-015-9722-9
   Farzan A, 2015, BEHAV BRAIN RES, V290, P124, DOI 10.1016/j.bbr.2015.04.010
   Fathabadi H, 2015, APPL SOFT COMPUT, V36, P375, DOI 10.1016/j.asoc.2015.07.039
   Goh S, 2014, JAMA PSYCHIAT, V71, P665, DOI 10.1001/jamapsychiatry.2014.179
   Gomez-Pilar J, 2015, ENTROPY-SWITZ, V17, P5241, DOI 10.3390/e17085241
   Gorji HT, 2015, NEUROSCIENCE, V305, P361, DOI 10.1016/j.neuroscience.2015.08.013
   Gu P, 2016, ULTRASONICS, V65, P51, DOI 10.1016/j.ultras.2015.10.023
   Harikumar R, 2015, INT J IMAG SYST TECH, V25, P33, DOI 10.1002/ima.22118
   Hayes BC, 2016, J MATERN-FETAL NEO M, V29, P777, DOI 10.3109/14767058.2015.1018167
   Kayvanrad MH, 2014, MAGN RESON IMAGING, V32, P1353, DOI 10.1016/j.mri.2014.08.004
   Mehra I, 2015, OPT COMMUN, V354, P344, DOI 10.1016/j.optcom.2015.06.015
   Merah M, 2015, COMPUT METH PROG BIO, V121, P149, DOI 10.1016/j.cmpb.2015.06.003
   Munteanu CR, 2015, EXPERT SYST APPL, V42, P6205, DOI 10.1016/j.eswa.2015.03.011
   Nascimento MZ, 2015, 3 INT C MATH MOD PHY
   Nazir M, 2015, J INTELL FUZZY SYST, V28, P1127, DOI 10.3233/IFS-141396
   Nguyen N, 2015, J COMPUT BIOL, V22, P236, DOI 10.1089/cmb.2014.0221
   Nicolis O, 2015, ENTROPY-SWITZ, V17, P4155, DOI 10.3390/e17064155
   Nourani V, 2015, J HYDROL, V524, P255, DOI 10.1016/j.jhydrol.2015.02.048
   Padma A, 2014, ARAB J SCI ENG, V39, P767, DOI 10.1007/s13369-013-0649-3
   Prinz V, 2015, J CEREBR BLOOD F MET, V35, P1903, DOI 10.1038/jcbfm.2015.153
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Thorsen F, 2013, J CONTROL RELEASE, V172, P812, DOI 10.1016/j.jconrel.2013.10.019
   VanMeerten NJ, 2016, SCHIZOPHR RES, V170, P102, DOI 10.1016/j.schres.2015.11.007
   Wals K, 2015, GLIA, V63, pE397
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P601, DOI 10.1177/0037549715603481
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang SH, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/454076
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wibmer A, 2015, EUR RADIOL, V25, P2840, DOI 10.1007/s00330-015-3701-8
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/931256
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhang YD, 2015, PATTERN RECOGN LETT, V62, P14, DOI 10.1016/j.patrec.2015.04.016
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2015, IEEJ T ELECTR ELECTR, V10, P116, DOI 10.1002/tee.22059
   Zhou X., 2016, J SENSORS, V2016, P1
NR 60
TC 61
Z9 62
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3701
EP 3714
DI 10.1007/s11042-016-3401-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600044
DA 2024-07-18
ER

PT J
AU Yoo, G
   Seo, S
   Hong, S
   Kim, H
AF Yoo, Gilsang
   Seo, Sanghyun
   Hong, Sungdae
   Kim, Hyeoncheol
TI Emotion extraction based on multi bio-signal using back-propagation
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion extraction; Bio signal; Back propagation; Artificial neural
   network
ID RECOGNITION; RESPONSES
AB This study proposes a system that can recognize human emotional state from bio-signal. The technology is provided to improve the interaction between humans and computers to achieve an effective human-machine that is capable for intelligent interaction. The proposed method is able to recognize six emotional states, such as joy, happiness, fear, anger, despair, and sadness. These set of emotional states are widely used for emotion recognition purposes. The result shows that the proposed method can distinguish one emotion compared to all other possible emotional states. The method is composed of two steps: 1) multi-modal bio-signal evaluation and 2) emotion recognition using artificial neural network. In the first step, we present a method to analyze and fix human sensitivity using physiological signals, such as electroencephalogram, electrocardiogram, photoplethysmogram, respiration, and galvanic skin response. The experimental analysis shows that the proposed method has good accuracy performance and could be applied on many human-computer interaction devices for emotion detection.
C1 [Yoo, Gilsang; Kim, Hyeoncheol] Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul, South Korea.
   [Seo, Sanghyun] Sungkyul Univ, Dept MediaSoftware, 53 SungkyulDaehak Ro, Anyang Si, Kyeonggi Do, South Korea.
   [Hong, Sungdae] Seokyeong Univ, Dept Film & Digital Media, 16-1 Jungneung Dong Sungbuk Ku, Seoul, South Korea.
C3 Korea University; Sungkyul University; Seokyeong University
RP Yoo, G (corresponding author), Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul, South Korea.
EM phd.yoo@gmail.com; shseo75@gmail.com; sungdaehong@gmail.com;
   hkim64@gmai1.com
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Korea University Grant with Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2015R1D1A1A01057975]
FX This research was supported by a Korea University Grant with Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education
   (NRF-2015R1D1A1A01057975).
CR AlaouiIsmaili O, 1997, PHYSIOL BEHAV, V62, P713, DOI 10.1016/S0031-9384(97)90016-0
   [Anonymous], 2013, ACOUSTICS SPEECH SIG
   [Anonymous], INT C COMP VIS THEOR
   [Anonymous], ACM INT C MULT INT
   [Anonymous], IEEE INT C MULT EXP
   Ax AR, 1953, PSYCHOSOM MED, V15, P147
   Boiten F, 1996, PSYCHOPHYSIOLOGY, V33, P123, DOI 10.1111/j.1469-8986.1996.tb02116.x
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burkhardt F., 2005, Proc. Electronic Speech Signal Processing (ESSP), P123
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Drummond PD, 2001, PSYCHOPHYSIOLOGY, V38, P190, DOI 10.1111/1469-8986.3820190
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Haag A., 2004, AFFECTIVE DIALOGUE S
   HANSON R., 1991, BAYESIAN CLASSIFICAT
   Healey J. A., 2000, Wearable and Automotive Systems for Affect Recognition from Physiology
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Lang PJ, 2008, A8 U FLOR
   Larsen R. J., 1992, REV PERSONALITY SOCI, V13
   Nasoz F., 2004, Cognition, Technology & Work, V6, P4, DOI 10.1007/s10111-003-0143-x
   Palomba D, 2000, INT J PSYCHOPHYSIOL, V36, P45, DOI 10.1016/S0167-8760(99)00099-9
   Petta P, 2011, COGN TECHNOL, P1, DOI 10.1007/978-3-642-15184-2
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Razak AA, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P297
   Sinha R, 1996, COGNITION EMOTION, V10, P173, DOI 10.1080/026999396380321
   Stemmler G, 2004, REGULATION OF EMOTION, P33
   Stephens CL, 2010, BIOL PSYCHOL, V84, P463, DOI 10.1016/j.biopsycho.2010.03.014
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang FN, 2015, MULTIMED TOOLS APPL, V74, P9983, DOI 10.1007/s11042-014-2319-1
   Westerdijk W, 1999, P 9 ICANN, P934
   Yegnanarayana B., 2004, ARTIFICIAL NEURAL NE
NR 32
TC 19
Z9 19
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4925
EP 4937
DI 10.1007/s11042-016-4213-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500047
DA 2024-07-18
ER

PT J
AU Fernández, IB
   Leszczuk, M
AF Blanco Fernandez, Ignacio
   Leszczuk, Mikolaj
TI Monitoring of audio visual quality by key indicators Detection of
   selected audio and audiovisual artefacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MOAVI; VQEG; Mute; Clipping; Lip sync
AB Over 10 billion hours of video are watched online every month. Together with high definition television broadcasting and the rise in high quality video on demand, this makes quality assessment a key task in the global multimedia market. Automating quality checking is currently based on finding major audiovisual artefacts. The Monitoring Of Audio Visual quality by key Indicators (MOAVI) subgroup of the Video Quality Experts Group (VQEG) is an open collaborative project for developing No-Reference models for monitoring audiovisual service quality. The purpose of this paper is to report on the development of the audiovisual part of this project, which includes the detection of muting, clipping and lip synchronization (also known as lip sync) artefacts.
C1 [Blanco Fernandez, Ignacio] Polytech Sch Engn Gijon, Plaza Campus Univ 92A, Asturias 33394, Spain.
   [Leszczuk, Mikolaj] AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Leszczuk, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM gncblncfrnndz@gmail.com; leszczuk@agh.edu.pl
RI Leszczuk, Mikołaj I/C-4857-2011
OI Leszczuk, Mikołaj I/0000-0001-9123-1039
FU National Centre for Research and Development, Poland [EUREKA C
   2013/1-5/MITSU/2/2014]
FX Research work co-funded by the National Centre for Research and
   Development, Poland, conferred on the basis of the decision number
   EUREKA C 2013/1-5/MITSU/2/2014.
CR [Anonymous], SPORADIC SIGNAL LOSS
   [Anonymous], 2001, INT WORKSH STAT COMP
   Baran R, 2015, MULTIMED TOOLS APPL, V74, P4269, DOI 10.1007/s11042-013-1545-2
   Cerqueira E, 2009, LECT NOTES COMPUT SC, V5630, P242, DOI 10.1007/978-3-642-02472-6_26
   Cooper J, 2014, COOPER J, Patent No. 14/460,305
   Czyzewski A, 2013, P M ACOUS, V20, DOI 10.1121/1.4863268
   Czyzewski A, 2017, BUILDING KNOWLEDGE P, P3, DOI [10.1007/978-3-319-43982-2_1, DOI 10.1007/978-3-319-43982-2_1]
   Farneback G, 2001, VERY HIGH ACCURACY V
   Garella Juan Pablo, 2016, BROADBAND MULTIMEDIA, P1
   Gowacz A, 2010, ANN TELECOMMUN, V65, P3, DOI 10.1007/s12243-009-0146-6
   Han CC, 2009, 2009 3RD INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, VOLS 1-11, P586
   Kacprzak Stanislaw, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P135, DOI 10.1007/978-3-642-39593-2_12
   Kim J, 2005, METHOD APPARATUS TES
   Leszczuk M, 2016, MULTIMED TOOLS APPL, V75, P10745, DOI 10.1007/s11042-014-2229-2
   Leszczuk M, 2014, COMM COM INF SC, V429, P16
   Lu GJ, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P776, DOI 10.1109/ICOSP.2000.891627
   Moddemeijer R, 1999, CONVERGENCE ITERATIV
   Person A, 1995, US Patent, Patent No. [5,453,716, 5453716]
   Ramirez J., 2007, VOICE ACTIVITY DETEC
   Skoglund J, 2014, US Patent, Patent No. [App. 13/767,387, 13767387]
   Sohn J, 1998, INT CONF ACOUST SPEE, P365, DOI 10.1109/ICASSP.1998.674443
   Staelens N, 2012, MULTIMEDIA SYST, V18, P445, DOI 10.1007/s00530-012-0262-4
   Stanger L, 2007, US Patent, Patent No. [7,212,248, 7212248]
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   Vanderhoff W, 2013, US Patent, Patent No. [8,595,784, 8595784]
   Vavrek J, 2013, MEDIAEVAL
   Venkatesh R, 2002, NO REFERENCE METRICS
   Yamasaki H, 2012, Patent No. [13/357.862, 13357862]
   Zhang DW, 2011, IEEE INT SYMP SIGNAL, P253
NR 29
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2823
EP 2848
DI 10.1007/s11042-017-4454-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400057
OA hybrid
DA 2024-07-18
ER

PT J
AU Dai, P
   Wang, X
   Zhang, WH
AF Dai, Peng
   Wang, Xue
   Zhang, Weihang
TI Coarse-to-fine multiview 3d face reconstruction using multiple
   geometrical features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face reconstruction; Multi-view; Coarse-to-fine; Structure from
   motion; Facial feature points; Occluding contours
ID DEPTH ESTIMATION; SINGLE IMAGE; SHAPE; FRAMEWORK; MOTION; MODEL
AB 3D face reconstruction from multi-view video sequences has become a hotspot in computer vision for the last decades. Structure from Motion (SfM) methods, which have been widely used for multi-view 3D face reconstruction, have two main limitations. First, self-occlusion causes certain facial feature points (FFPs) to be invisible in the images, which will lead to missing data. The existing SfM methods could recover the missing data through iterative calculation, however, with high computational costs and long processing time. Second, the SfM methods cannot reconstruct the accurate 3D facial shapes of cheeks because there are no FFPs in this area. This paper proposes a novel "coarse-to-fine" multi-view 3D face reconstruction method by taking the advantage of the complementarity between FFPs and occluding contours, i.e., the boundary lines depicted between the facial region and the background. In this method, a block SfM algorithm is firstly proposed to reconstruct a "coarse" 3D facial shape by utilizing sparse FFPs. The block SfM algorithm does not estimate the true locations of the self-occluded FFPs iteratively. Thus, the computational cost is significantly reduced. Then, a kernel partial least squares (KPLS) algorithm is introduced to refine the "coarse" 3D facial shape. The KPLS method applies occluding contours to remedy the limitation of sparse FFPs correspondence-based SfM method. The proposed method is evaluated on the synthetic sequences generated from the BJUT-3D face database and the real-world multi-view video sequences obtained in a controlled indoor environment. The results show improvements in both accuracy and efficiency.
C1 [Dai, Peng; Wang, Xue; Zhang, Weihang] Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
EM daip13@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn
OI Wang, Xue/0000-0003-4842-3160
FU National Natural Science Foundation of China [61472216]; PhD Programs
   Foundation of Ministry of Education of China [20120002110067]
FX This paper is supported by National Natural Science Foundation of China
   under Grant #61472216, and by PhD Programs Foundation of Ministry of
   Education of China under Grant #20120002110067.
CR Aissaoui A, 2014, MULTIMED TOOLS APPL, V72, P2413, DOI 10.1007/s11042-013-1556-z
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Angelopoulou ME, 2014, MACH VISION APPL, V25, P1317, DOI 10.1007/s00138-014-0609-2
   [Anonymous], 2006, DEV NEW PRECRASH SAF
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bookstein Fred L, 1997, MORPHOMETRIC TOOLS L
   Castrillón M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004
   Chouvatut V, 2013, MULTIMED TOOLS APPL, V63, P569, DOI 10.1007/s11042-011-0925-8
   Chowdhury AKR, 2003, COMPUT VIS IMAGE UND, V91, P188, DOI 10.1016/S1077-3142(03)00079-1
   Da FP, 2011, MACH VISION APPL, V22, P879, DOI 10.1007/s00138-010-0278-8
   Dai W, 2010, INT CONF ACOUST SPEE, P3646, DOI 10.1109/ICASSP.2010.5495899
   Ding L, 2014, VISUAL COMPUT, V30, P189, DOI 10.1007/s00371-013-0795-3
   Emrith K, 2013, COMPUT IND, V64, P1390, DOI 10.1016/j.compind.2013.03.011
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gonzalez-Mora J, 2010, IMAGE VISION COMPUT, V28, P1117, DOI 10.1016/j.imavis.2010.01.005
   Hansen MF, 2010, COMPUT VIS IMAGE UND, V114, P942, DOI 10.1016/j.cviu.2010.03.001
   Herold C, 2014, COMPUT VIS IMAGE UND, V122, P182, DOI 10.1016/j.cviu.2014.01.006
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Koo HS, 2008, PATTERN RECOGN LETT, V29, P712, DOI 10.1016/j.patrec.2007.11.018
   Kurtek S, 2015, COMPUT GRAPH-UK, V51, P52, DOI 10.1016/j.cag.2015.05.027
   Lee SJ, 2011, PATTERN RECOGN, V44, P1470, DOI 10.1016/j.patcog.2010.11.012
   Levine MD, 2009, PATTERN RECOGN LETT, V30, P908, DOI 10.1016/j.patrec.2009.03.011
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Lin KC, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/604108
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Lin YP, 2010, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2010.5539793
   Maejima A, 2008, IEICE T INF SYST, VE91D, P1135, DOI 10.1093/ietisy/e91-d.4.1135
   Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004
   Medioni G, 2009, IEEE T SYST MAN CY A, V39, P12, DOI 10.1109/TSMCA.2008.2007979
   Peng WL, 2016, NEUROCOMPUTING, V179, P228, DOI 10.1016/j.neucom.2015.11.090
   RANNAR S, 1994, J CHEMOMETR, V8, P111, DOI 10.1002/cem.1180080204
   Sánchez-Escobedo D, 2016, COMPUT VIS IMAGE UND, V142, P111, DOI 10.1016/j.cviu.2015.08.012
   Sánchez-Escobedo D, 2013, PATTERN RECOGN LETT, V34, P389, DOI 10.1016/j.patrec.2012.09.007
   Schendel SA, 2013, J ORAL MAXIL SURG, V71, P1406, DOI 10.1016/j.joms.2013.02.010
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P2887, DOI 10.1109/TIP.2012.2183882
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   Stylianou G, 2009, INT J IMAGE GRAPH, V9, P217, DOI 10.1142/S0219467809003411
   Sun YJ, 2015, MULTIMED TOOLS APPL, V74, P3635, DOI 10.1007/s11042-013-1791-3
   Sun ZL, 2013, IEEE T IMAGE PROCESS, V22, P17, DOI 10.1109/TIP.2012.2204269
   Tech M, 2005, BJUT 3D LARG SCAL CH
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Vandereycken B, 2013, SIAM J OPTIMIZ, V23, P1214, DOI 10.1137/110845768
   Wang N., 2014, Facial Feature Point Detection: A Comprehensive Survey, DOI DOI 10.1016/J.NEUCOM.2017.05.013
   Zeng D, 2016, EXAMPLAR COHERENT 3D
NR 48
TC 4
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 939
EP 966
DI 10.1007/s11042-016-4325-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400040
DA 2024-07-18
ER

PT J
AU Erdélyi, A
   Winkler, T
   Rinner, B
AF Erdelyi, Adam
   Winkler, Thomas
   Rinner, Bernhard
TI Privacy protection vs. utility in visual data An objective evaluation
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual privacy; Video surveillance; Privacy evaluation framework;
   Privacy/utility trade-off
ID TRACKING
AB Ubiquitous and networked sensors impose a huge challenge for privacy protection which has become an emerging problem of modern society. Protecting the privacy of visual data is particularly important due to the omnipresence of cameras, and various protection mechanisms for captured images and videos have been proposed. This paper introduces an objective evaluation framework in order to assess such protection methods. Visual privacy protection is typically realised by obfuscating sensitive image regions which often results in some loss of utility. Our evaluation framework assesses the achieved privacy protection and utility by comparing the performance of standard computer vision tasks, such as object recognition, detection and tracking on protected and unprotected visual data. The proposed framework extends the traditional frame-by-frame evaluation approach by introducing two new approaches based on aggregated and fused frames. We demonstrate our framework on eight differently protected video-sets and measure the trade-off between the improved privacy protection due to obfuscating captured image data and the degraded utility of the visual data. Results provided by our objective evaluation method are compared with an available state-of-the-art subjective study of these eight protection techniques.
C1 [Erdelyi, Adam; Rinner, Bernhard] Alpen Adria Univ, Klagenfurt & Lakeside Labs, Inst Networked & Embedded Syst, Klagenfurt, Austria.
   [Winkler, Thomas] Ams AG, Tobelbader Str 30, A-8141 Premstaetten, Austria.
C3 University of Klagenfurt
RP Erdélyi, A (corresponding author), Alpen Adria Univ, Klagenfurt & Lakeside Labs, Inst Networked & Embedded Syst, Klagenfurt, Austria.
EM mail@adamerdelyi.hu; thomas.winkler@ams.com; bernhard.rinner@aau.at
OI Erdelyi, Adam/0000-0003-0653-3513
FU University of Klagenfurt; European Regional Development Fund (ERDF);
   Carinthian Economic Promotion Fund (KWF) [KWF-3520/23312/35521]
FX Open access funding provided by University of Klagenfurt. This work was
   performed as part of the TrustEYE: Trustworthy Sensing and Cooperation
   in Visual Sensor Networks project [57] and received funding from the
   European Regional Development Fund (ERDF) and the Carinthian Economic
   Promotion Fund (KWF) under grant KWF-3520/23312/35521.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Anderson S, 2014, THESIS
   Chaaraoui AA, 2014, SENSORS-BASEL, V14, P8895, DOI 10.3390/s140508895
   [Anonymous], 2013, INT J ADV ENG RES ST
   [Anonymous], EFFECTIVE SURVEILLAN
   [Anonymous], 2013, 18 INT C DIG SIGN PR
   [Anonymous], P EUR C COMPUT VIS
   [Anonymous], 2011, INT ENCY STAT SCI
   Aved AJ, 2012, MULTIMEDIA SYST, V18, P123, DOI 10.1007/s00530-011-0245-x
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Badii A., 2013, Signal Image Processing, V4, P13
   Badii A, 2014, P MED WORKSH
   Badii A, 2014, P MED WORKSH BARC SP
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Birnstill P, 2015, 2015 12 IEEE INT C A, P1
   Bonetto Margherita, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), DOI 10.1109/FG.2015.7285023
   Boyle M., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P1, DOI 10.1145/358916.358935
   Byoung-Jin Han, 2011, 2011 IEEE Conference on Open Systems, P86, DOI 10.1109/ICOS.2011.6079313
   Cavoukian A., 2013, Surveillance, then and now: Securing privacy in public spaces
   Cavoukian A., 2011, Privacy by design
   Cheung S.-C.S., 2009, PROTECTING PRIVACY V, P11
   Clarke R, 2014, COMPUT LAW SECUR REV, V30, P286, DOI 10.1016/j.clsr.2014.03.005
   Dufaux F, 2010, IEEE INT CON MULTI, P66, DOI 10.1109/ICME.2010.5583552
   Erdelyi A, 2014, P MED WORKSH
   Erdélyi A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P44, DOI 10.1109/AVSS.2014.6918642
   Fradi H, 2014, P MED WORKSH
   Grabner H., 2006, BMVC, P47
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Korff D., 2010, Comparative Study On Different Approaches To New Privacy Challenges
   Korshunov P, 2012, IEEE INT WORKSH MULT, P378, DOI 10.1109/MMSP.2012.6343472
   Korshunov P, 2014, P MED WORKSH
   Korshunov P, 2013, P SPIE, V8856
   Korshunov P, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P208, DOI 10.1109/AVSS.2013.6636641
   Ma Zhendong, 2014, Privacy Technologies and Policy. Second Annual Privacy Forum, APF 2014. Proceedings: LNCS 8450, P101, DOI 10.1007/978-3-319-06749-0_7
   Maniry D, 2014, P MED WORKSH
   Martin K, 2008, IEEE T CIRC SYST VID, V18, P1152, DOI 10.1109/TCSVT.2008.927110
   Martinez-Balleste A., 2012, 2012 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P914, DOI 10.1109/PerComW.2012.6197644
   Morando F, 2014, PRIVACY EVALUATION W
   Pantoja C, 2014, P MED WORKSH
   Paralic M, 2014, P MED WORKSH
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Reisslein M, 2014, COMPUTER, V47, P23, DOI 10.1109/MC.2014.134
   Rinner B, 2008, P IEEE, V96, P1565, DOI 10.1109/JPROC.2008.928742
   Saini M, 2011, P INT C MULT EXP, P1
   Saini M, 2014, MULTIMED TOOLS APPL, V68, P135, DOI 10.1007/s11042-012-1207-9
   SanMiguel JC, 2012, IEEE T IMAGE PROCESS, V21, P2812, DOI 10.1109/TIP.2011.2182520
   Sarwar O, 2016, P IEEE C ADV VID SIG, P1
   Schmiedeke S, 2014, P MED WORKSH
   Tansuriyavong S., 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, P1, DOI DOI 10.1145/971478.971519
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler T., 2014, ACM COMPUT SURV, V47, P42
   Winkler T, 2012, TRUSTEYE TRUSTWORTHY
   Zhang CY, 2012, LECT NOTES COMPUT SC, V7382, P625, DOI 10.1007/978-3-642-31522-0_95
NR 56
TC 17
Z9 18
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2285
EP 2312
DI 10.1007/s11042-016-4337-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400035
OA hybrid
DA 2024-07-18
ER

PT J
AU Zekri, AS
AF Zekri, Ahmed Sherif
TI Optimizing image spatial filtering on single CPU core
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source-code restructuring; Sobel gradient filter; Vectorization; OpenMP
   threading
AB Nowadays, computing becomes a service on cloud computing resources. Users reserve virtual machines to execute their applications with minimum number of processing cores to save money. Optimizing user applications on the level of single core of a physical machine is highly desirable to users to reduce cost, as well as to cloud providers to reduce power consumption. In this paper, we showed how to exploit all the processing resources available in a single CPU physical core to optimize the performance of the 2D spatial filtering operation, a basic kernel in important image and multimedia applications such as image enhancement, edge detection, image segmentation, and image analysis. We proposed a novel computational procedure to restructure the conventional image filtering operation. Then, we demonstrated the merits of combining hand-optimized source-code restructuring, auto-optimized compiler techniques including vectorization, and hand-optimized threading to squeeze the performance of a single CPU core. Our intensive performance evaluations, using Sobel filters, on a variety of image sizes using the Linux Perf tool on a single core of the quad-core Intel Core i7 processor showed that our source-code restructurings with compiler auto-vectorization, using Intel AVX vector instructions, is 1.3X better than the non-restructured auto-vectorized version of the CImg library for computing the image gradient. Moreover, using OpenMP library directives we studied different image partitioning strategies to better exploit the two hardware threads inside a CPU core which boosted performance to 2.6X. Compared with the conventional CImg implementation, we obtained an average enhancement of 5.0X for image sizes ranging from 0.5 MPixel to 8 MPixel. However, comparing our best-optimized code to the conventional non-optimized serial code, without threading, resulted in a significant enhancement of 23X. The overall results showed how significant performance in important image processing applications can be obtained by applying source-code restructurings before employing any automatic compiler optimizations to exploit ILP, DLP and TLP parallelism degrees inside a single core of a multi-core CPU.
C1 [Zekri, Ahmed Sherif] Beirut Arab Univ, Dept Math & Comp Sci, Fac Sci, POB 115020, Beirut 11072809, Lebanon.
   [Zekri, Ahmed Sherif] Alexandria Univ, Dept Math & Comp Sci, Fac Sci, Alexandria, Egypt.
C3 Beirut Arab University; Egyptian Knowledge Bank (EKB); Alexandria
   University
RP Zekri, AS (corresponding author), Beirut Arab Univ, Dept Math & Comp Sci, Fac Sci, POB 115020, Beirut 11072809, Lebanon.; Zekri, AS (corresponding author), Alexandria Univ, Dept Math & Comp Sci, Fac Sci, Alexandria, Egypt.
EM a.zekri@bau.edu.lb
RI Zekri, Ahmed/W-8623-2019; Zekri, Ahmed/Q-1335-2019
OI Zekri, Ahmed/0000-0001-8518-1581
CR [Anonymous], 2016, Intel 64 and IA-32 Architectures Software Developer's Manual
   BACON DF, 1994, ACM COMPUT SURV, V26, P345, DOI 10.1145/197405.197406
   BANERJEE U, 1993, P IEEE, V81, P211, DOI 10.1109/5.214548
   Bik AJC, 2002, INT J PARALLEL PROG, V30, P65, DOI 10.1023/A:1014230429447
   Chang FC, 2012, INFORM SCIENCES, V192, P39, DOI 10.1016/j.ins.2010.02.025
   Free Software Foundation Inc, 2016, OPT CONTR OPT GCC G
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Intel Corporation, 2007, INT SSE4 PROGR REF
   Kim CG, 2014, MULTIMED TOOLS APPL, V68, P237, DOI 10.1007/s11042-011-0906-y
   Kim D, 2010, IEEE SIGNAL PROC MAG, V27, P97, DOI 10.1109/MSP.2009.935384
   Mitra Gaurav, 2013, 2013 IEEE International Symposium on Parallel and Distributed Processing, Workshops and PhD Forum (IPDPSW), P1107, DOI 10.1109/IPDPSW.2013.207
   Patterson DA., 2014, COMPUTER ORG DESIGN
   Pingali VK, 2003, INT J PARALLEL PROG, V31, P305, DOI 10.1023/A:1024556711058
   Slingerland NT, 2005, MICROPROCESS MICROSY, V29, P225, DOI 10.1016/j.micpro.2004.10.002
   Sobel I., 1990, An Isotropic 3x3 Image Gradient Operator, P376, DOI [10.13140/RG.2.1.1912.4965, DOI 10.13140/RG.2.1.1912.4965]
   Torres G, 2016, HARDWARESECRETS
NR 16
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 251
EP 281
DI 10.1007/s11042-016-4266-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400012
DA 2024-07-18
ER

PT J
AU Al-Zaydi, ZQH
   Ndzi, DL
   Kamarudin, ML
   Zakaria, A
   Shakaff, AYM
AF Al-Zaydi, Zeyad Q. H.
   Ndzi, David L.
   Kamarudin, Munirah L.
   Zakaria, Ammar
   Shakaff, Ali Y. M.
TI A robust multimedia surveillance system for people counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting systems; Monitoring; CCTV cameras; Background
   segmentation
ID CROWD ESTIMATION; TRACKING
AB Closed circuit television cameras (CCTV) are widely used in monitoring. This paper presents an intelligent CCTV crowd counting system based on two algorithms that estimate the density of each pixel in each frame and use it as a basis for counting people. One algorithm uses scale-invariant feature transform (SIFT) features and clustering to represent pixels of frames (SIFT algorithm) and the other uses features from accelerated segment test (FAST) corner points with SIFT features (SIFT-FAST algorithm). Each algorithm is designed using a novel combination of pixel-wise, motion-region, grid map, background segmentation using Gaussian mixture model (GMM) and edge detection. A fusion technique is proposed and used to validate the accuracy by combining the result of the algorithms at frame level. The proposed system is more practical than the state of the art regression methods because it is trained with a small number of frames so it is relatively easy to deploy. In addition, it reduces the training error, set-up time, cost and open the door to develop more accurate people detection methods. The University of California (UCSD) and Mall datasets have been used to test the proposed algorithms. The mean deviation error, mean squared error and the mean absolute error of the proposed system are less than 0.1, 16.5 and 3.1, respectively, for the Mall dataset and less than 0.07, 5.5 and 1.9, respectively, for UCSD dataset.
C1 [Al-Zaydi, Zeyad Q. H.; Ndzi, David L.] Univ Portsmouth, Sch Engn, Portsmouth PO1 3DJ, Hants, England.
   [Al-Zaydi, Zeyad Q. H.] Univ Technol Baghdad, Comp Ctr, Baghdad, Iraq.
   [Kamarudin, Munirah L.] Univ Malaysia Perlis, Sch Comp & Commun Engn, Perlis, Malaysia.
   [Zakaria, Ammar; Shakaff, Ali Y. M.] Univ Malaysia Perlis, Sch Mechatron Engn, Perlis, Malaysia.
C3 University of Portsmouth; University of Technology- Iraq; Universiti
   Malaysia Perlis; Universiti Malaysia Perlis
RP Al-Zaydi, ZQH (corresponding author), Univ Portsmouth, Sch Engn, Portsmouth PO1 3DJ, Hants, England.; Al-Zaydi, ZQH (corresponding author), Univ Technol Baghdad, Comp Ctr, Baghdad, Iraq.
EM zeyad.al-zaydi@port.ac.uk; david.ndzi@port.ac.uk;
   latifahmunirah@unimap.edu.my; ammarzakaria@unimap.edu.my;
   aliyeon@unimap.edu.my
RI Habeeb, Zeyad Qasim/D-4470-2019; Kamarudin, Latifah Munirah/G-8267-2016;
   Zakaria, Ammar/D-2902-2015
OI Habeeb, Zeyad Qasim/0000-0001-6188-9956; Kamarudin, Latifah
   Munirah/0000-0002-2547-3934; Ndzi, David/0000-0002-1125-1978; Zakaria,
   Ammar/0000-0002-7108-215X
CR Al-Zaydi ZQH, 2016, J VIS COMMUN IMAGE R, V39, P218, DOI 10.1016/j.jvcir.2016.05.018
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], THESIS
   [Anonymous], CROWD PEDESTRIAN COU
   [Anonymous], 2004, Surveillance & Society, DOI 10.24908/ss.v2i2/3.3369
   [Anonymous], USE CCTV COUNT PEOPL
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], INT J COMPUT APPL
   [Anonymous], ADV CONCEPTS INTELL
   [Anonymous], SINGLE PIXEL APPROAC
   [Anonymous], AM J SOCIAL ISSUES H
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587569
   [Anonymous], 2010, BRIT MACHINE VISION
   [Anonymous], P IEEE INT C COMP VI
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Berndt D. J., 1994, USING DYNAMIC TIME W, V04
   Bottesch T., 2016, INT C MACHINE LEARNI, P2578
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Çelik H, 2006, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2006.312946
   Chan A.B., 2009, PERF EV TRACK SURV W, P101
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2014, INT C PATT RECOG, P4672, DOI 10.1109/ICPR.2014.799
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Cheriyadat A. M., 2008, P 6 IEEE COMP SOC WO, P1, DOI DOI 10.1109/CVPRW.2008.4562983
   Cho SY, 1999, NEURAL PROCESS LETT, V10, P111, DOI 10.1023/A:1018781301409
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   Chow TWS, 1999, ARTIF INTELL ENG, V13, P301, DOI 10.1016/S0954-1810(99)00016-3
   Conte D., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P225, DOI 10.1109/AVSS.2010.78
   Conte D., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1743, DOI 10.1109/ICPR.2010.431
   Conte D, 2013, MACH VISION APPL, V24, P1029, DOI 10.1007/s00138-013-0491-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fradi H, 2012, IEEE INT WORKS INFOR, P246, DOI 10.1109/WIFS.2012.6412657
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Hafeezallah A, 2017, MULTIMED TOOLS APPL, V76, P15777, DOI 10.1007/s11042-016-3869-1
   Harville M., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P67
   Hashimoto K, 1997, TRANSDUCERS 97 - 1997 INTERNATIONAL CONFERENCE ON SOLID-STATE SENSORS AND ACTUATORS, DIGEST OF TECHNICAL PAPERS, VOLS 1 AND 2, P1291, DOI 10.1109/SENSOR.1997.635472
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Hu XM, 2015, OPTIK, V126, P123, DOI 10.1016/j.ijleo.2014.08.132
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Jeong CY, 2013, IEEE IMAGE PROC, P4545, DOI 10.1109/ICIP.2013.6738936
   Jingwen Li, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P54, DOI 10.1109/AVSS.2011.6027294
   Kilambi P, 2008, COMPUT VIS IMAGE UND, V110, P43, DOI 10.1016/j.cviu.2007.02.003
   Kong D., 2005, BMVC, p63.1
   Kong D, 2006, INT C PATT RECOG, P1187
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li XH, 2006, T I MEAS CONTROL, V28, P299, DOI 10.1191/0142331206tim178oa
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Ma HD, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089107
   Ma R, 2004, IEEE C CYBERN INTELL, P1
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Merad Djamel, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P233, DOI 10.1109/AVSS.2010.77
   Rao AS, 2015, VISUAL COMPUT, V31, P1533, DOI 10.1007/s00371-014-1032-4
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Ryan D. A., 2013, THESIS
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Ryan D, 2014, PATTERN RECOGN LETT, V44, P98, DOI 10.1016/j.patrec.2013.10.002
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Shrivakshan G T., 2012, A Comparison of various Edge Detection Techniques used in Image Processing
   Sidla Oliver, 2006, 2006 IEEE INT C VID, P70, DOI [DOI 10.1109/AVSS.2006.91, 10.1109/AVSS.2006.91]
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Tang NC, 2015, IEEE T IMAGE PROCESS, V24, P80, DOI 10.1109/TIP.2014.2363445
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Tu JH, 2013, IEEE IMAGE PROC, P3340, DOI 10.1109/ICIP.2013.6738688
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Wang JQ, 2014, IEEE T CIRC SYST VID, V24, P1620, DOI 10.1109/TCSVT.2014.2308616
   Wang M., 2014, Access Dissertations 385
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing XL, 2015, IEEE SIGNAL PROC LET, V22, P2349, DOI 10.1109/LSP.2015.2481930
   Xu B, 2016, IEEE WINTER APPL COM, P1
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1037, DOI 10.1109/TITS.2011.2132759
   Zhang ZX, 2015, NEUROCOMPUTING, V166, P151, DOI 10.1016/j.neucom.2015.03.083
NR 80
TC 9
Z9 9
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23777
EP 23804
DI 10.1007/s11042-016-4156-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700031
DA 2024-07-18
ER

PT J
AU Heidari, M
   Samavi, S
   Soroushmehr, SMR
   Shirani, S
   Karimi, N
   Najarian, K
AF Heidari, M.
   Samavi, S.
   Soroushmehr, S. M. R.
   Shirani, S.
   Karimi, N.
   Najarian, K.
TI Framework for robust blind image watermarking based on classification of
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Robustness; General framework; Invisibility
ID GENETIC WATERMARKING; COEFFICIENTS
AB With the widespread internet usage, digital contents are easily distributed throughout the world. To eliminate concerns of producers and owners of digital contents, watermarking techniques are extensively being used. Robustness against intentional and unintentional attacks is a major quality of watermarking systems. Since different attacks tend to target different parts of the frequency spectrum, in this paper we propose a framework for blind watermarking which determines the type of attack that the image has gone through before extracting the watermark. Within this framework, we propose an attack classification method to identify the region of the frequency spectrum that is less damaged. The watermark which is redundantly spread throughout the spectrum can be extracted from the less damaged regions. Experimental results show functionality of the framework by producing better results in comparison with well-known blind watermarking techniques.
C1 [Heidari, M.] Sharif Univ Technol, Dept Elect Engn, Tehran 1136511155, Iran.
   [Heidari, M.; Samavi, S.; Karimi, N.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Samavi, S.; Najarian, K.] Univ Michigan, Dept Emergency Med, Ann Arbor, MI 48109 USA.
   [Soroushmehr, S. M. R.; Najarian, K.] Univ Michigan, Michigan Ctr Integrat Res Crit Care, Ann Arbor, MI 48109 USA.
   [Shirani, S.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
   [Najarian, K.] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
C3 Sharif University of Technology; Isfahan University of Technology;
   University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; McMaster University; University
   of Michigan System; University of Michigan
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.; Samavi, S (corresponding author), Univ Michigan, Dept Emergency Med, Ann Arbor, MI 48109 USA.
EM samavi@mcmaster.ca
RI Karimi, Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607; heidari, morteza/0000-0003-0922-787X
CR Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   [Anonymous], 2010, DISCRETE TIME SIGNAL
   [Anonymous], Usc-sipi image database, V3
   Azzari L, 2014, IEEE T IMAGE PROCESS, V23, P3459, DOI 10.1109/TIP.2014.2321504
   BURGETT S, 1994, NOVEL METHOD COPYRIG
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Chu SC, 2008, CIRC SYST SIGNAL PR, V27, P171, DOI 10.1007/s00034-008-9025-z
   Cox IJ, 1999, SIGNAL PROC SERIES, P461
   Craver S, 1998, IEEE J SEL AREA COMM, V16, P573, DOI 10.1109/49.668979
   Fan Y., 2016, J INFORM HIDING MULT, V7, P399
   Fazlali HR, 2016, MULTIMED TOOLS APPL, V1, P16
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Kang XG, 2008, IEEE T MULTIMEDIA, V10, P953, DOI 10.1109/TMM.2008.2001361
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Surekha B, 2011, INT J SECUR APPL, V5, P1
   Tabatabaei SAH, 2015, IEEE T MULTIMEDIA, V17, P945, DOI 10.1109/TMM.2015.2432672
   WANG S, 2015, J INFORM HIDING MULT, V6, P1264
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhen Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2757, DOI 10.1109/ICIP.2011.6116241
   Zhu XS, 2014, IEEE T MULTIMEDIA, V16, P1888, DOI 10.1109/TMM.2014.2340695
NR 26
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23459
EP 23479
DI 10.1007/s11042-016-4150-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700015
DA 2024-07-18
ER

PT J
AU Qian, HM
   Zhou, J
   Mao, YB
   Yuan, Y
AF Qian, Huimin
   Zhou, Jun
   Mao, Yaobin
   Yuan, Yue
TI Recognizing human actions from silhouettes described with weighted
   distance metric and kinematics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human actions recognition; Poisson equation; Spatial-temporal motion
   accumulative image; Depth contour image
ID ACTION RECOGNITION; SHAPE
AB A virtual particle random walking theory under variable velocities is presented in this paper. Under the proposed theory, the solutions of some two-dimensional Poisson equations, which are discretized by nine-point finite difference method and defined on the so-called spatial-temporal motion accumulative image stemming from human silhouettes, provide us the depth contour image for actions description. Although merely two-dimensional definition domain and concepts are related to the Poisson equations, both spatial and temporal evolution information of human actions are successfully included in the depth contour image owing to designating the travelling velocities of virtual particles according to the spatial-temporal motion accumulative image. In addition, it is worth noting that projecting three-dimensional human actions to the two-dimensional image descriptors contributes to much lower computation cost in the corresponding recognition algorithms, compared to those when using the three-dimensional spatial-temporal descriptors directly. In order to enhance the recognition accuracy, a hierarchical cascaded classifier is configured with cascading nearest neighbor classifiers, in each layer of which different kinds of shape and kinematic features of human actions are dealt with. Numerical experimental results on several public human action databases are illustrated to verify recognition performance improvements by means of the proposed algorithm.
C1 [Qian, Huimin; Zhou, Jun; Yuan, Yue] Hohai Univ, Coll Energy & Elect Engn, 8 Focheng West Rd, Nanjing 211100, Jiangsu, Peoples R China.
   [Mao, Yaobin] Nanjing Univ Sci & Technol, Sch Automat, 200 Xiaolingwei, Nanjing, Jiangsu, Peoples R China.
C3 Hohai University; Nanjing University of Science & Technology
RP Qian, HM (corresponding author), Hohai Univ, Coll Energy & Elect Engn, 8 Focheng West Rd, Nanjing 211100, Jiangsu, Peoples R China.
EM qhmin0316@163.com; zhouj@lzu.edu.cn; maoyaobin@163.com; yyuan@hhu.edu.cn
RI Zhou, Jun/W-2233-2019
OI Zhou, Jun/0000-0001-5822-8233; Qian, Huimin/0000-0002-5976-1213
FU Nature Science Foundation of Jiangsu Province, China [BK20140860];
   National Natural Science Foundation (NNSF) of China [61573001]
FX The authors would like to thank the Nature Science Foundation of Jiangsu
   Province, China, under Grant No. BK20140860, and the National Natural
   Science Foundation (NNSF) of China under Grant No. 61573001.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahad MAR, 2008, INT J INNOV COMPUT I, V4, P1943
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], 2013, INT J COMPUTER VISIO
   [Anonymous], APPL ITERATIVE METHO
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2005, P IEEE COMP SOC C CO
   [Anonymous], 2008 P BRIT MACH VIS
   Aubert G, 2014, J MATH IMAGING VIS, V48, P149, DOI 10.1007/s10851-012-0404-5
   Bala A, 2014, IEEE INT ADV COMPUT, P1033, DOI 10.1109/IAdCC.2014.6779467
   Barkley Rosser J., 1975, Computers & Mathematics with Applications, V1, P351
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chandrashekhar, 2006, P AS S INF DISPL, P484
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Guoxin Jin, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2006, DOI 10.1109/ICASSP.2014.6853950
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Li NJ, 2013, INT CONF ACOUST SPEE, P3407, DOI 10.1109/ICASSP.2013.6638290
   Ling ZG, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P231
   Montagna R, 2013, IEEE T IMAGE PROCESS, V22, P4072, DOI 10.1109/TIP.2013.2270108
   Qian HM, 2015, CHIN CONTR CONF, P3680, DOI 10.1109/ChiCC.2015.7260208
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Sadek S, 2012, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2012.6466972
   Savarese S, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P119
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sekma M, 2015, PATTERN RECOGN LETT, V65, P37, DOI 10.1016/j.patrec.2015.06.029
   Strikwerda J.C., 2004, SIAM
   Veeraraghavan A, 2004, PROC CVPR IEEE, P730
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Whytock T, 2014, J MATH IMAGING VIS, V50, P314, DOI 10.1007/s10851-014-0501-8
   Yogarajah P, 2011, INT SYMP IMAGE SIG, P662
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 39
TC 9
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21889
EP 21910
DI 10.1007/s11042-017-4610-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200004
DA 2024-07-18
ER

PT J
AU Jeong, HY
AF Jeong, Hwa-Young
TI A priority for WSN in ubiquitous environment: multimedia security
   requirements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Human-centric environment; Ubiquitous
   computing; Multimedia security attributes; Multimedia security
   requirements; Relative priority; Analytic hierarchy process
AB With the rapid expansion of the human-centric ubiquitous environment, wireless sensor networks (WSN) will continue to be part of our everyday life and increase the amount and the type of data generated and transmitted by the WSN. As sensors become more essential in our daily life, the data from the sensors will become more private and need to be handled more sensitively. Therefore, the security of not only the data transmission between sensor nodes, but also the software system handling the data from sensor nodes will become more important. In this study, I concentrated on the security characteristics of the overall application systems in WSNs and derived the security attributes from the security requirements and standards of the existing network-based software systems. In the software development process, security must be considered throughout the whole process and, according to the applications the priority of each security attribute can be changed. I demonstrated the relative priority change in a web-based system and a WSN application system with an Analytic Hierarchy Process. The evaluation results showed that the difference of the relative priority of the security attributes in each sample system results not from the difference between the existing network-based system and the WSN but the type of the application. Therefore, the Multimedia security requirements and standards of the existing network-based software development process can be applied to the WSN application system through proper selection and modification.
C1 [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
C3 Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
EM hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Alcaraz C, 2013, AD HOC NETW, V11, P1091, DOI 10.1016/j.adhoc.2012.12.001
   Brodkin J., 2008, INFOWORLD
   CARMAN DW, 2000, 00010 NAI LAB
   Castillo-Effen M., 2004, P 5 IEEE INT CAR C D
   Claycomb WR, 2011, J NETW COMPUT APPL, V34, P418, DOI 10.1016/j.jnca.2010.03.004
   Dlamini M.T., 2009, INTERNET PEOPLE THIN, P2009
   El Yamany HF, 2010, INFORM SOFTWARE TECH, V52, P220, DOI 10.1016/j.infsof.2009.10.005
   Eschenauer L., 2002, ACM CCS2002, DOI DOI 10.1145/586110.586117
   Fayed NS, 2012, EGYPT INFORM J, V13, P185, DOI 10.1016/j.eij.2012.09.001
   Gao T., 2005, P 27 IEEE EMBS ANN I
   Gutiérrez C, 2009, INFORM SOFTWARE TECH, V51, P1712, DOI 10.1016/j.infsof.2009.05.004
   Hill J.L., 2000, System Architecture for Wireless Sensor Network
   Hoglund Greg, 2004, Exploiting Software: How to Break Code
   Hussain R, 2014, J INF PROCESS SYST, V10, P103, DOI 10.3745/JIPS.2014.10.1.103
   ISO, 1989, 749821989 ISO, P7498
   Kohno E, 2012, J COMPUT SYST SCI, V78, P1703, DOI 10.1016/j.jcss.2011.10.018
   Lorincz K., 2004, IEEE PERVASIVE COMPU
   McGraw G, 2004, IEEE SECUR PRIV, V2, P80, DOI 10.1109/MSECP.2004.1281254
   National Instruments, 2012, WHAT IS WIR SENS NET
   Perrig A, 2002, WIREL NETW, V8, P521, DOI 10.1023/A:1016598314198
   Saaty T. L., 2008, INT J SERV SCI, V1, P83, DOI [10.1504/IJSSCI.2008.017590, DOI 10.1504/IJSSCI.2008.017590]
   Saaty T.L., 1996, DECISION MAKING DEPE
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   Sharma G, 2012, PROC TECH, V1, P978, DOI 10.1016/j.protcy.2012.10.119
   Simon G., 2004, P 2 INT C EMB NETW S, P1
   Sinha A, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-13
   Stankovic J.A., 2006, Wireless Sensor Networks
   W3C, 2004, ARCHITECTURE
   Walters JohnPaul., 2006, SECURITY DISTRIBUTED
   Wener-Allen G, 2006, IEEE INTERNET COMPUT
   Yick J., 2005, P IEEE 2 INT C BROAD
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
   Yoon M., 2013, J CONVERGENCE, V4, P15
NR 33
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20027
EP 20047
DI 10.1007/s11042-016-4216-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500041
DA 2024-07-18
ER

PT J
AU Lee, JY
   Jung, KD
   Moon, SJ
   Jeong, HY
AF Lee, Jong-Yong
   Jung, Kye-Dong
   Moon, Seok-Jae
   Jeong, Hwa-Young
TI Improvement on LEACH protocol of a wide-area wireless sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Routing protocol; Wide-area WSN layer; Multi-hop; Dual-hop; LEACH;
   DL-LEACH
AB This paper proposes to increase the efficiency energy of nodes which rapidly drops during the transmission of the LEACH (Low Energy Adaptive Clustering Hierarchy), using the method of the dual-hop layered in the sensor field. By introducing dual-hop method in the data transmission, the proposed single-hop method for short-range transmission and multi-hop transmission method between the cluster heads for remote transmission was introduce. By introducing a partial multi-hop method in the data transmission, a single-hop method for short range transmission method between the cluster heads for remote transmission was introduces. In the proposed DL-LEACH, the energy consumption of cluster head for remote transmission reduces and increases the energy efficiency of sensor node by reducing the transmission distance and simplifying the transmission routine for short-range transmission. As compared the general LEACH, it was adapted to a wider sensor field.
C1 [Lee, Jong-Yong; Jung, Kye-Dong; Moon, Seok-Jae] Kwangwoon Univ, Dept Culture, 20 Kwangwoon Ro, Seoul 01897, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 24 Kyungheedae Ro, Seoul 02447, South Korea.
C3 Kwangwoon University; Kyung Hee University
RP Moon, SJ (corresponding author), Kwangwoon Univ, Dept Culture, 20 Kwangwoon Ro, Seoul 01897, South Korea.
EM jyonglee@kw.ac.kr; gdchung@kw.ac.kr; msj8086@kw.ac.kr; hyjeong@khu.ac.kr
CR Al-Karaki JN, 2004, IEEE WIREL COMMUN, V11, P6, DOI 10.1109/MWC.2004.1368893
   [Anonymous], 2013, MECH CONFAB
   Cho S, 2014, INT J ADV SMART CONV, V3, P1
   Chuan-Chi Weng, 2011, 2011 IEEE/SICE International Symposium on System Integration (SII 2011), P1143, DOI 10.1109/SII.2011.6147610
   Heinzelman W.R., 2000, 33 HAWAII INT C SYST
   Heinzelman WB, 2000, THESIS, P57
   Katiyar V., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P1070, DOI 10.1109/ICETECT.2011.5760277
   Lee J.Y., 2014, INT J SMART HOME, V8, P9, DOI [10.14257/ijsh.2014.8.3.02, DOI 10.14257/IJSH.2014.8.3.02]
   Lin CHR, 1997, IEEE J SEL AREA COMM, V15, P1265, DOI 10.1109/49.622910
   Mahfuz S, 2014, INT J SCI TECHNOL RE, V3, P127
   Qian L, 2013, P 2 INT C SYST ENG M, P72
   Rajagopalan R., 2006, Data aggregation techniques in sensor networks: A survey
   Singh S.K., 2010, INT J WIRELESS MOBIL, V2, P49, DOI [10.5121/ijwmn.2010.2304, DOI 10.5121/IJWMN.2010.2304]
   Song YI, 2014, ADV APPL CONVERG ADV, V148
NR 14
TC 23
Z9 26
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19843
EP 19860
DI 10.1007/s11042-016-3732-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500031
DA 2024-07-18
ER

PT J
AU Luque, A
   Aguayo, F
   Lama, JR
AF Luque, A.
   Aguayo, F.
   Lama, J. R.
TI Distributed lightning monitoring: an affordable proposal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless Multimedia Sensor Networks; Light measurement; Light spectral
   correction; Light directional correction; Distributed systems
ID SENSOR; DEVICES
AB In theaters and the filmmaking industry, video streams, images, audio streams and scalar data are commonly used. In these fields, one of the most important magnitudes to be collected and controlled is the light intensity in different scene spots. So, it is extremely important to be able to deploy a network of light sensors which are usually integrated in a more general Wireless Multimedia Sensor Network (WMSN). If many light measurements have to be acquired, the simpler and cheaper the sensor, the more affordable the WMSN will be. In this paper we propose the use of a set of very cheap light sensors (photodiodes) and to spectrally and directionally correct their measurements using mathematical methods. A real testing of the proposed solution has been accomplished, obtaining quite accurate light measurements. Testing results are also presented throughout the paper.
C1 [Luque, A.; Aguayo, F.; Lama, J. R.] Univ Seville, Dept Ingn Diseno, Escuela Politecn Super, C Virgen Africa 7, Seville 41011, Spain.
C3 University of Sevilla
RP Luque, A (corresponding author), Univ Seville, Dept Ingn Diseno, Escuela Politecn Super, C Virgen Africa 7, Seville 41011, Spain.
EM amalialuque@us.es
RI Juan, Lama-Ruiz/H-9887-2015; Luque, Amalia/I-7330-2015
OI Juan, Lama-Ruiz/0000-0003-1382-5274; 
FU Telefonica Chair "Intelligence in Networks" of the University of Seville
   (Spain)
FX This work has been supported by the Telefonica Chair "Intelligence in
   Networks" of the University of Seville (Spain).
CR Adamo G, 2014, SPIE OPTO
   [Anonymous], 2004, USITC PUBL, V15
   [Anonymous], 235392005 ISO
   [Anonymous], 105261999CIES005E199
   [Anonymous], NATURE GT FECHNER HI
   Bai Shilei, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P661, DOI 10.1109/ICICTA.2011.450
   Box H., 2013, Set Lighting Technician's Handbook: Film Lighting Equipment, Practice, and Electrical Distribution
   Cadena R, 2012, AUTOMATED LIGHTING A
   Chiang CT, 2014, IEEE SENS J, V14, P2537, DOI 10.1109/JSEN.2013.2295617
   DiBernardo E, 2014, Methods and apparatus for position estimation using reflected light sources, Patent No. [8,780,342, 8780342]
   Dibley M, 2012, INT J INNOV COMPUT I, V8, P8415
   Figueiro MG, 2013, LIGHTING RES TECHNOL, V45, P421, DOI 10.1177/1477153512450453
   Higuera J., 2014, IET C FUT INT CIT, P1
   Howell DW, 2009, U. S. Patent No, Patent No. [7,571,063, 7571063]
   Hui Ren, 2011, 2011 Fourth International Joint Conference on Computational Sciences and Optimization (CSO), P777, DOI 10.1109/CSO.2011.221
   Im KM, 2015, INT J DISTRIB SENS N
   Iyengar S.Sitharama., 2012, DISTRIBUTED SENSOR N
   Jing C, 2010, COMP DES APPL ICCDA, V3, pV3
   Karthikeyan M., 2014, PRACT CHEMOINFORMATI, V100, P1, DOI [10.1007/978-81-322-1780-0_1, DOI 10.1007/978-81-322-1780-0_1]
   Maiellaro G, 2014, IEEE T CIRCUITS-I, V61, P1036, DOI 10.1109/TCSI.2013.2286031
   Malacara D., 2001, Handbook of Optical Engineering
   Markvart J, 2015, LEUKOS, V11, P155, DOI 10.1080/15502724.2015.1020948
   Mendalka M., 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P99
   Miki M, 2013, 2013 IEEE 8TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2013), P137, DOI 10.1109/SACI.2013.6608954
   Neamen D.A., 2007, MICROELECTRONICS CIR, V3rd
   OSRAM Opto Semiconductors, 2014, SFH 213 DAT
   Park H, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P370, DOI 10.1109/IPSN.2007.4379697
   Pedrotti F. L., 2013, Introduction to Optics, V3rd
   Rawat P, 2014, J SUPERCOMPUT, V68, P1, DOI 10.1007/s11227-013-1021-9
   Schell S, 2005, Sensing device and method for measuring position and orientation relative to multiple light sources, Patent No. [11/ 090,405, 11090405]
   Skalicky S.E., 2016, OCULAR VISUAL PHYSL, P299, DOI DOI 10.1007/978-981-287-846-5_21
   Tian L, 2013, 2013 6 INT S COMP IN
   Wang Y, 2015, IEEE INT C NETW SENS, P450, DOI 10.1109/ICNSC.2015.7116079
   Wei Jiang, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P3923, DOI 10.1109/CISP.2010.5647570
   Zhang XS, 2011, PROCEEDINGS OF 2011 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY AND APPLICATION, ICCTA2011, P968, DOI 10.1049/cp.2011.0816
NR 35
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19825
EP 19841
DI 10.1007/s11042-016-3607-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500030
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Yin, CY
   Ma, LY
   Feng, L
AF Yin, Chunyong
   Ma, Luyu
   Feng, Lu
TI Towards accurate intrusion detection based on improved clonal selection
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial immune; Clonal selection; Intrusion detection; Biological
   immune; Adaptive
ID DETECTION SYSTEM; REGRESSION
AB Artificial immune system constructs a dynamic and adaptive information defense system through a function similar to the biological immune system. In order to resist the external invasion of useless and harmful information and ensure the effectiveness and the harmlessness of received information. Due to the low accuracy and the high false positive rate of the existing clonal selection algorithms applied to intrusion detection, in this paper, we propose an improved clonal selection algorithm. The improved method detects the intrusion behavior by selecting the best individual overall and cloning them. Experimental results show that the improved algorithm achieves very good performance when applied to intrusion detection. And it is shown that the algorithm is better than BP neural network with its 99.5 % accuracy and 0.1 % false positive rate.
C1 [Yin, Chunyong; Ma, Luyu; Feng, Lu] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Yin, CY (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Jiangsu, Peoples R China.
EM ycycam@163.com
FU National Natural Science Foundation of China [61373134]; Priority
   Academic Program Development of Jiangsu Higer Education
   Institutions(PAPD); Jiangsu Key Laboratory of Meteorological Observation
   and Information Processing [KDXS1105]; Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology(CICAEET)
FX Foundation item: This work was funded by the National Natural Science
   Foundation of China (No. 61373134). It was also supported by the
   Priority Academic Program Development of Jiangsu Higer Education
   Institutions(PAPD), Jiangsu Key Laboratory of Meteorological Observation
   and Information Processing (No. KDXS1105) and Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment
   Technology(CICAEET).
CR Aickelin U, 2003, LECT NOTES COMPUT SC, V2787, P147
   Aickelin U., 2014, SEARCH METHODOLOGIES, P187
   [Anonymous], OVERVIEW ARTIFICIAL
   Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Kim J, 2002, IEEE C EVOL COMPUTAT, P1015, DOI 10.1109/CEC.2002.1004382
   Kim J, 2001, IEEE C EVOL COMPUTAT, P1244, DOI 10.1109/CEC.2001.934333
   Li YH, 2012, EXPERT SYST APPL, V39, P424, DOI 10.1016/j.eswa.2011.07.032
   Liao HJ, 2013, J NETW COMPUT APPL, V36, P16, DOI 10.1016/j.jnca.2012.09.004
   McClelland JL, 1986, EXPLORATIONS MICROST, V1
   McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, P262, DOI 10.1145/382912.382923
   Ou CM, 2012, NEUROCOMPUTING, V88, P78, DOI 10.1016/j.neucom.2011.07.031
   [卿斯汉 Qing Sihan], 2004, [通信学报, Journal of China Institute of Communications], V25, P19
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Ulutas BH, 2011, ARTIF INTELL REV, V36, P117, DOI 10.1007/s10462-011-9206-1
   Yin C, 2014, SCI WORLD J, V2014
   Yin C., 2013, INT J HYBRID INFORM, V6, P291
   Yuesheng Gu, 2012, Journal of Software, V7, P1641, DOI 10.4304/jsw.7.7.1641-1648
   Zhang B, 2013, J CHEM PHARM RES, V5, P256
   Zhang F, 2013, EFFECTIVE FEATURE SE
NR 21
TC 12
Z9 12
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19397
EP 19410
DI 10.1007/s11042-015-3117-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500004
DA 2024-07-18
ER

PT J
AU Jiang, RM
   Wang, YX
   Yan, XY
AF Jiang, Ruomei
   Wang, Yanxia
   Yan, Xingyu
TI Density clustering analysis of fuzzy neural network initialization for
   grinding capability prediction of power plant ball mill
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ball mil; Grinding capability; Fuzzy neural network; Density clustering
AB Ball mill of thermal power plant has high energy consumption and the grinding capability is usually used for representing the efficiency of ball mill. This paper proposes a density clustering analysis method of fuzzy neural network initialization for grinding capability prediction of power plant ball mill. The proposed method integrates the density clustering algorithm and the fuzzy neural network to predict grinding capability, where the density clustering algorithm is used to initialize the rules base of the fuzzy neural network. Furthermore, two parameters of the density clustering analysis can be determined by calculation formula, and the structure of the proposed model could be optimized by the training capability of neural network. The experiments are performed on two datasets obtained from the thermal power plant under the stable conditions. The experiments results verify that the proposed model has higher effectiveness. In addition, the proposed model has been put into practice and the field operation curve proves that the grinding capability could be predicted correctly.
C1 [Jiang, Ruomei] Xi An Jiao Tong Univ City Coll, Dept Comp Sci & Informat Management, Xian 710018, Peoples R China.
   [Wang, Yanxia; Yan, Xingyu] Xi An Jiao Tong Univ, Sch Elect Engn, State Key Lab Elect Insulat & Power Equipment, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Wang, YX (corresponding author), Xi An Jiao Tong Univ, Sch Elect Engn, State Key Lab Elect Insulat & Power Equipment, Xian 710049, Peoples R China.
EM hit2011@stu.xjtu.edu.cn
OI wang, yanxia/0000-0002-1318-9231
FU National High-tech Research and Development Projects (863)
   [2006AA04Z180]
FX This work is supported by National High-tech Research and Development
   Projects (863) 2006AA04Z180.
CR Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Chen MY, 2013, INFORM SCIENCES, V220, P180, DOI 10.1016/j.ins.2011.09.013
   Cheng Qi-ming, 2009, Proceedings of the CSEE, V29, P22
   Choi BI, 2009, INFORM SCIENCES, V179, P2102, DOI 10.1016/j.ins.2008.04.009
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Esfahanipour A, 2010, EXPERT SYST APPL, V37, P4742, DOI 10.1016/j.eswa.2009.11.020
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Lianfei Zhai, 2006, Journal of Control Theory and Applications, V4, P62, DOI 10.1007/s11768-006-5260-7
   Lixin Jia, 2000, International Journal of Computers, Systems and Signals, V1, P231
   Ma DY, 2013, ENG APPL ARTIF INTEL, V26, P937, DOI 10.1016/j.engappai.2012.03.017
   Melin P, 2014, INTELL AUTOM SOFT CO, V20, P403, DOI 10.1080/10798587.2014.893047
   Pang-Ning Tan., 2006, Introduction to Data Mining
   Quansheng D, 2008, P 2008 IEEE PAC AS W, P901
   Tan YM, 2013, J EXP THEOR ARTIF IN, V25, P105, DOI 10.1080/0952813X.2012.680072
   Tian-You Chai, 2005, Acta Automatica Sinica, V31, P123
   Tushir M, 2010, APPL SOFT COMPUT, V10, P381, DOI 10.1016/j.asoc.2009.08.020
   Verlinde H, 2006, IEEE T SYST MAN CY B, V36, P679, DOI 10.1109/TSMCB.2005.860134
   Wang JS, 2008, 2008 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-11, P1424, DOI 10.1109/CCDC.2008.4597553
   Xia C., 2009, Computational Intelligence and Software Engineering, 2009. CiSE 2009. International Conference on, IEEE, Wuhan, P1
   Yager R. R., 1994, Journal of Intelligent and Fuzzy Systems, V2, P209, DOI [10.3233/IFS-1994-2301, DOI 10.3233/IFS-1994-2301]
   Yan P, 2006, STUD FUZZ SOFT COMP, V201, P573
   Zhou H, 2005, INT J AUTOM COMPUT, V2, P43, DOI 10.1007/s11633-005-0043-z
NR 23
TC 2
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18137
EP 18151
DI 10.1007/s11042-016-4089-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800031
DA 2024-07-18
ER

PT J
AU Bansal, R
   Gupta, S
   Sharma, G
AF Bansal, Ritesh
   Gupta, Shailender
   Sharma, Gaurav
TI An innovative image encryption scheme based on chaotic map and Vigenere
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confusion; Diffusion; Differential attacks; Image encryption/decryption;
   Logarithmic map; Sine map; Statistical attacks; Vigenere scheme
ID CRYPTOGRAPHY; ALGORITHM; SEQUENCES
AB Confidentiality of images during data communication is a prime concern of many researchers, as a result, several mechanisms have been proposed for image encryption. An encryption for image is said to be effective if it has large key space, aperiodic nature and sensitive to the initial conditions. In addition, it is also desired that the mechanism must have a good combination of computational speed, security and time complexity. These features can be induced in the encryption schemes by incorporation of chaos during encryption/decryption process. In this paper, a novel image encryption scheme based on chaotic maps and Vigenere Scheme is proposed. This scheme has one round consisting of two steps: diffusion and confusion. The former step involves three stages: forward diffusion, matching process using Vigenere scheme and backward diffusion. In later part, position permutation using chaotic map is used to swap pixel positions. The proposed as well as other mechanisms in literature are implemented in Matlab-2015 and their efficacy are compared using several performance metrics. The simulation results show that our scheme is better in terms of time complexity while keeping Peak Signal to Noise Ratio (PSNR) values same and having almost ideal entropy, Number of Pixels Change Rate (NPCR) and Unified Average Changing Intensity (UACI).
C1 [Bansal, Ritesh] YMCA Univ Sci & Technol, Elect Instrumentat & Control Engn, Faridabad, India.
   [Gupta, Shailender] YMCA Univ Sci & Technol, Dept Elect Engn, Faridabad, India.
   [Sharma, Gaurav] YMCA Univ Sci & Technol, Elect Instrumentat & Control Engn, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA; J.C. Bose University
   of Science & Technology, YMCA; J.C. Bose University of Science &
   Technology, YMCA
RP Bansal, R (corresponding author), YMCA Univ Sci & Technol, Elect Instrumentat & Control Engn, Faridabad, India.
EM ritesh.bansal@hotmail.com
RI Sharma, Gaurav/HTO-3197-2023; gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR [Anonymous], 2013, INT J ADV COMPUTER S
   [Anonymous], 2016, INT J SIG PROCESS PA
   Bansal R, 2016, INDIACOM IE IN PRESS
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Gupta K, 2009, 2009 1ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS(CICSYN 2009), P342, DOI 10.1109/CICSYN.2009.33
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   He J, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 1, PROCEEDINGS, P365, DOI 10.1109/NSWCTC.2009.243
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Kocarev L, 2011, CHAOS BASED CRYPTOGR, V354, P375
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Moumen C, 2012, PR ELECTROMAGN RES S, P42
   Racuciu C, 2008, REV AIR FORCE ACAD
   Sam I.S., 2010, MULTIMED TOOLS APPL, V56, P315
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Xiao HP, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2707
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Younes M. A. Bani, 2008, INT J COMPUT SCI, V35, P407
   Zeghid M., 2007, INT J COMPUT SCI ENG, V1, P70
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   ZHAO G, 2010, 2010 2 INT C SIGN PR, V0002, P00002
NR 28
TC 30
Z9 30
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16529
EP 16562
DI 10.1007/s11042-016-3926-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100021
DA 2024-07-18
ER

PT J
AU Ji, DS
   Li, XY
   Yang, QJ
   Ma, T
   Chen, XY
AF Ji, Dongsheng
   Li, Xiyan
   Yang, Qingjun
   Ma, Tao
   Chen, Xiaoyun
TI Analysis and segmentation of MRI volume data based on KmGAC model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI; Image segmentation; GAC; K-means; Hough operator; Volume data
AB Here we analyze the difficulties of segmentation without tag line of left ventricle MR images, and propose an algorithm for automatic segmentation of MRI volume data (VD) target profiles. Herein, we propose Geometric active contour model based on K-means clustering (KmGAC) method. Initially, using Hough operator to automatically locate initial contour of VD, the algorithm uses clustering approach to complete data subsampling and initial center determination. Next, according to the clustering rules, the proposed algorithm finishes MRI VD segmentation. Finally, the algorithm uses a category optimization method to improve segmentation results. Experiments show that the algorithm provides good segmentation results.
C1 [Ji, Dongsheng; Yang, Qingjun; Ma, Tao; Chen, Xiaoyun] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
   [Ji, Dongsheng] Gansu Radio & TV Univ, Lanzhou 730000, Peoples R China.
   [Li, Xiyan] Zhengzhou Chenggong Univ Finance & Econ, Zhengzhou 451200, Peoples R China.
C3 Lanzhou University
RP Chen, XY (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
EM jids8012@163.com; chenxy@lzu.edu.cn
RI LAPC, IAP/AAI-6991-2020
OI LAPC, IAP/0000-0002-0025-3484
FU Science and Technology Plan of Gansu Province [1308RJZA266]; Gansu Radio
   & TV university youth fund project [QN201501]
FX This paper is supported by Science and Technology Plan of Gansu Province
   (No. 1308RJZA266) and Gansu Radio & TV university youth fund project
   (NO. QN201501).
CR AlDaoud MB, 1996, PATTERN RECOGN LETT, V17, P451, DOI 10.1016/0167-8655(95)00119-0
   American Heart Association, 1998, HEART STORK STAT UPD
   BACKER E, 1981, IEEE T PATTERN ANAL, V3, P66, DOI 10.1109/TPAMI.1981.4767051
   Canny J, IEEE T PATTER
   DAI Da-meng, 2012, IJACT INT J ADV COMP, V4, P233
   Frangi AF, 2001, IEEE T MED IMAGING, V20, P2, DOI 10.1109/42.906421
   GOLDBERG N, 1991, IMAGE VISION COMPUT, V9, P303, DOI 10.1016/0262-8856(91)90035-N
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Li Pei-Hua, 2000, Journal of Software, V11, P751
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Paragios N, 2002, INT J COMPUT VISION, V50, P345, DOI 10.1023/A:1020882509893
   Philip KP, 1991, THESIS
   Poh CL, 2005, COMPUT CARDIOL, V32, P17
   Singh C, 2008, PATTERN RECOGN, V41, P3528, DOI 10.1016/j.patcog.2008.06.002
   Turnbull D, 2005, IEEE T KNOWL DATA EN, V17, P580, DOI 10.1109/TKDE.2005.62
   Zeng XL, 1998, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.1998.698681
NR 18
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17075
EP 17093
DI 10.1007/s11042-016-3679-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500011
DA 2024-07-18
ER

PT J
AU Zhang, L
   Peng, Q
   Wu, X
AF Zhang, Lei
   Peng, Qiang
   Wu, Xiao
TI Perception-based adaptive quantization for transform-domain Wyner-Ziv
   video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wyner-Ziv video coding; Adaptive quantization; Perception
ID QUALITY ASSESSMENT; INFORMATION; SCHEME; NOISE
AB Distributed video coding (DVC) is desirable for encoding systems with tight power or computational constraints, for which the popular practical solution is transform-domain Wyner-Ziv video coding (TD-WZVC). To achieve the similar coding performance with H.264/AVC, quantization is a key factor in TD-WZVC. Practically, the quantization matrix is trained offline and remains fixed value during coding. Optimal rate-distortion (RD) performance cannot be achieved due to the varying quality of side information (SI) frame. In this paper, a novel model of perceptual distortion probability is developed to estimate the perceptual distortion of SI frame and to derive the target perceptual distortion. With the two perceptual distortion probabilities, three components (i.e. quality of SI frame, perceptual features and RD optimization) are integrated to determine the optimal quantization matrix adaptively, which improves the coding performance. Extensive experiments demonstrate that the proposed scheme can adaptively determine proper quantization matrix online and achieve similar visual quality with less bit-rate, as compared to other adaptive quantization schemes in TD-WZVC.
C1 [Zhang, Lei; Peng, Qiang; Wu, Xiao] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
C3 Southwest Jiaotong University
RP Zhang, L (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
EM zl.swjtu@gmail.com; qpeng@home.swjtu.edu.cn; wuxiao@home.swjtu.edu.cn
OI Wu, Xiao/0000-0002-8322-8558
FU NSFC [60972111, 61036008, 61071184, 61373121]; Research Funds for the
   Doctoral Program of Higher Education of China [20100184120009,
   20120184110001]; Program for Sichuan Provincial Science Fund for
   Distinguished Young Scholars [2012JQ0029, 13QNJJ0149]; Fundamental
   Research Funds for the Central Universities [SWJTU09CX032, SWJTU10CX08,
   SWJTU11ZT08]
FX This work described in this paper was supported by the NSFC (Grant No.
   60972111, 61036008, 61071184, 61373121), Research Funds for the Doctoral
   Program of Higher Education of China (No. 20100184120009,
   20120184110001), Program for Sichuan Provincial Science Fund for
   Distinguished Young Scholars (No. 2012JQ0029, 13QNJJ0149), and the
   Fundamental Research Funds for the Central Universities (Project no.
   SWJTU09CX032, SWJTU10CX08, SWJTU11ZT08).
CR [Anonymous], AS C SIGN SYST COMP
   Artigas X, 2007, PICT COD S PCS
   Ascenso J, 2006, IEEE INT C IM PROC I, P8
   Ascenso J, IEEE INT C IM PROC I, P3513
   BRITES C, 2007, IEEE INT C IM PROC I
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2011, IEEE T CIRC SYST VID, V21, P1278, DOI 10.1109/TCSVT.2011.2147210
   Chen JW, 2012, IEEE T CIRC SYST VID, V22, P1027, DOI 10.1109/TCSVT.2012.2189671
   Chen ZZ, 2011, IEEE INT SYMP CIRC S, P1231
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chien WJ, 2009, IET IMAGE PROCESS, V3, P340, DOI 10.1049/iet-ipr.2008.0207
   Gu Z, 2007, P 6 INT C INF COMM S, P1
   HoangVan X, 2012, IEEE T BROADCAST, V58, P209, DOI 10.1109/TBC.2012.2187611
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Lin C, 2008, IEEE SIGNAL PROCESS, V15, P873
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Liu ZX, 2004, IEEE DATA COMPR CONF, P322
   Ma L, 2011, SIGNAL PROCESS-IMAGE, V26, P162, DOI 10.1016/j.image.2011.02.002
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Rebollo-Monedero D, 2003, IEEE DATA COMPR CONF, P13
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sofke S, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/978581
   Sun YC, 2012, J VIS COMMUN IMAGE R, V23, P535, DOI 10.1016/j.jvcir.2012.01.015
   Tianwu Yang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P85, DOI 10.1109/ICME.2012.171
   VARODAYAN D, 2006, EURASIP SIGNAL PROCE, V86
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu B, 2006, IEEE INT C MULT EXP, P117
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xue Z, 2010, IEEE T BROADCAST, V56, P481, DOI 10.1109/TBC.2010.2058371
   Yang XK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P737
   Yongpeng Li, 2009, IEEE Signal Processing Letters, V16, P985, DOI 10.1109/LSP.2009.2028111
   Zamir R, 2002, IEEE T INFORM THEORY, V48, P1250, DOI 10.1109/TIT.2002.1003821
   Zhang YX, 2010, SIGNAL PROCESS, V90, P2480, DOI 10.1016/j.sigpro.2010.02.001
   Zhang YX, 2008, IEEE T MULTIMEDIA, V10, P1648, DOI 10.1109/TMM.2008.2007324
   Zhang YS, 2011, IEEE T CIRC SYST VID, V21, P1100, DOI 10.1109/TCSVT.2011.2133830
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
NR 40
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16699
EP 16725
DI 10.1007/s11042-016-3947-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100029
DA 2024-07-18
ER

PT J
AU Zhao, XR
   Wang, X
   Wang, HY
AF Zhao, Xuran
   Wang, Xun
   Wang, Huiyan
TI Multi-view dimensionality reduction via subspace structure agreement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view learning; Dimensionality reduction; Biometrics; Co-training
ID RECOGNITION; FACE
AB Many state-of-the-art biometric systems make use of high-dimensional features to represent data samples, which often contain substantial amount of intra-class variation. In this paper, we propose an unsupervised multi-view dimensionality reduction approach to extract discriminative low-dimensional features and apply it to multi-modal biometric retrieval problems. The proposed approach is based on a novel concept referred to as multi-view subspace structure agreement, which aims to learn a subspace projection for each view, such that the k-nearest-neighbour similarity graphs built in subspaces of different views are maximumly compatible. The proposed method is unsupervised in nature, but exhibits high discriminative power and is thus well suited to applications where class labels are generally unavailable such as retrieval and clustering. We evaluate the performance of the proposed algorithm under an audio-visual speaker retrieval experiment, as well as a multi-feature face retrieval experiment. Experimental results show that the retrieval performance of the proposed approach out-performs other competing methods with a significant margin.
C1 [Zhao, Xuran; Wang, Xun] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Huiyan] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Comp Sci & Technol, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University
RP Wang, X (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, 18 Xuezheng St, Hangzhou, Zhejiang, Peoples R China.
EM zxr@zjgsu.edu.cn; wx@zjgsu.edu.cn; cederic@zjgsu.edu.cn
OI Wang, Huiyan/0000-0002-7942-605X
FU National Key Technology Research and Development Program of the Ministry
   of Science and Technology of China [2014BAK14B01]; National Natural
   Science Foundation of China [61379075, 61472362]; Natural Science
   Foundation of Zhejiang Province [LY14F020001]; Beihang University VR
   technology and system national key lab open project [BUAA-VR-16KF-17]
FX This work is supported in part by the National Key Technology Research
   and Development Program of the Ministry of Science and Technology of
   China (No. 2014BAK14B01), National Natural Science Foundation of China
   (No. 61379075), Natural Science Foundation of Zhejiang Province (No.
   LY14F020001), Beihang University VR technology and system national key
   lab open project (No. BUAA-VR-16KF-17) and National Natural Science
   Foundation of China (No. 61472362).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Andrew G., 2013, ICML, P1247
   [Anonymous], TECH REP
   [Anonymous], ARXIV13045634
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Chan TM, 2006, LECT NOTES COMPUT SC, V3832, P756
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chen HT, 2005, PROC CVPR IEEE, P846
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Hadid A, 2009, LECT NOTES COMPUT SC, V5707, P9, DOI 10.1007/978-3-642-04391-8_2
   Hardoon DR, P 3 INT WORKSH CONT, P2003
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58
   Kumar A., 2011, P 28 INT C MACHINE L, P393
   Kumar P., 2011, Adv. Neural Inf. Process. Syst., P1413, DOI DOI 10.5555/2986459.2986617
   Liu Z, 2010, J NETW COMPUT APPL, V33, P275, DOI 10.1016/j.jnca.2009.12.006
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Ross ArunA., 2006, HDB MULTIBIOMETRICS, V6
   Sargm M, 2006, P 2006 IEEE INT C AC, V1, pI
   Sindhwani V., 2008, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, P976, DOI DOI 10.1145/1390156.1390279
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang WR, 2015, INT CONF ACOUST SPEE, P4590, DOI 10.1109/ICASSP.2015.7178840
   Wang WR, 2015, ANN ALLERTON CONF, P688, DOI 10.1109/ALLERTON.2015.7447071
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhao XR, 2013, IEEE INT WORKS INFOR, P7, DOI 10.1109/WIFS.2013.6707786
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
   Zhu X, ROBUST JOINT GRAPH S
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
NR 42
TC 9
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17437
EP 17460
DI 10.1007/s11042-016-3943-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500031
DA 2024-07-18
ER

PT J
AU An, FP
   Zhou, XW
AF An, Feng-Ping
   Zhou, Xian-Wei
TI BEMD-SIFT feature extraction algorithm for image processing application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; BEMD; Sift; Genetic algorithm; Surf
ID EMPIRICAL MODE DECOMPOSITION
AB Scale-invariant feature transform (SIFT) algorithm has been successfully applied to object recognition and to image feature extraction, which is a major application in the field of image processing. Nonetheless, the SIFT algorithm has not been solved effectively in practical applications that requires real-time performance, much calculation, and high storage capacity given the framework level and the iterative calculation process in the SIFT Gaussian blur operation. The extraction of image feature information is accelerated using the speeded-up robust features algorithm. However, this algorithm remains sensitive to complicated deformation. To address these problems, in this paper, we proposes a novel algorithmic framework based on bidimensional empirical mode decomposition (BEMD) and SIFT to extract self-adaptive features from images. First, the BEMD algorithm is used to decompose the self-adaptive features of the original image and to obtain multiple BIMF components. Second, the SIFT algorithm optimizes the extraction of parameters that reflect characteristic information on BIMF components. Related parameters are obtained through genetic algorithm optimization. Third, the method for extracting the characteristic information of the BIMF components involves synthesizing all of the accumulated characteristic information in the original image. Comparison results show that the method of calculating image feature extraction speed, accuracy, and reliability has a stronger effect than other methods.
C1 [An, Feng-Ping; Zhou, Xian-Wei] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP An, FP (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
EM b20130380@xs.ustb.edu.cn
RI zhou, xian/JYQ-9844-2024
OI AN, FENGPING/0000-0002-2220-2987
FU National Science Foundation Project of P. R. China [61501026, 61272506]
FX This work is supported by National Science Foundation Project of P. R.
   China (No. 61501026 and No. 61272506).
CR [Anonymous], FIELD PROGR TECHN 20
   [Anonymous], 2004, ADAPTIVE IMAGE COMPR
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Gallix A, 2012, EXPERT SYST APPL, V39, P13451, DOI 10.1016/j.eswa.2012.05.058
   He Z, 2013, SIGNAL PROCESS, V93, P124, DOI 10.1016/j.sigpro.2012.07.009
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Juan L., 2010, International Journal of Image Processing (IJIP), V3, P143
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lee K, 2012, EXPERT SYST APPL, V39, P12975, DOI 10.1016/j.eswa.2012.05.057
   Lin DC, 2012, MECH SYST SIGNAL PR, V31, P13, DOI 10.1016/j.ymssp.2012.02.012
   Linderhed A, 2002, P SOC PHOTO-OPT INS, V4738, P1, DOI 10.1117/12.458772
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowe DG, 2001, PROC CVPR IEEE, P682
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Nunes JC, 2009, ADV DATA SCI ADAPT, V1, P125, DOI 10.1142/S1793536909000059
   Riaz F, 2013, IEEE SIGNAL PROC LET, V20, P607, DOI 10.1109/LSP.2013.2259622
   Se S, 2005, IEEE T ROBOT, V21, P364, DOI 10.1109/TRO.2004.839228
   Vapnik V., 2013, The nature of statistical learning theory
   Wu XQ, 2014, IEEE T INF FOREN SEC, V9, P526, DOI 10.1109/TIFS.2014.2301274
NR 22
TC 8
Z9 8
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13153
EP 13172
DI 10.1007/s11042-016-3746-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900010
DA 2024-07-18
ER

PT J
AU Su, X
   Li, WH
   Hu, HG
AF Su, Xin
   Li, Weihai
   Hu, Honggang
TI Cryptanalysis of a chaos-based image encryption scheme combining DNA
   coding and entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chosen-plaintext cryptanalysis; Chaotic system; DNA
   encoding; Information entropy
ID ALGORITHM
AB An image encryption scheme based on chaos system combining with DNA coding and information entropy has been proposed recently, in which chaos system and DNA operation are used to perform substitution, and entropy driven chaos system is used to perform permutation. However, two vulnerabilities are found and presented in this paper, which make the encryption fail under chosen-plaintext attack. A complete chosen-plaintext attack algorithm is given to rebuild chaos systems' outputs and recover plain image, and its efficiency is demonstrated by analysis and experiments. Further, some improvements are proposed to make up these vulnerabilities and enhance the security.
C1 [Su, Xin; Li, Weihai; Hu, Honggang] Univ Sci & Technol China, Sch Informat Sci & Technol, CAS Key Lab Electromagnet Space Informat, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Li, WH (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, CAS Key Lab Electromagnet Space Informat, Hefei 230027, Peoples R China.
EM whli@ustc.edu.cn
CR Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Halvorsen K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044212
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Masuda N, 2006, IEEE T CIRCUITS-I, V53, P1341, DOI 10.1109/TCSI.2006.874182
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mousa H, 2011, INT ARAB J INF TECHN, V8, P147
   O'Driscoll C, 2009, CHEM IND-LONDON, V6, P10
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Shoshani S, 2012, ANGEW CHEM INT EDIT, V51, P2883, DOI 10.1002/anie.201107156
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Solak E, 2009, 2009 6TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS AND DEVICES, VOLS 1 AND 2, P317
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 15
TC 36
Z9 36
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14021
EP 14033
DI 10.1007/s11042-016-3800-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800016
DA 2024-07-18
ER

PT J
AU Du, SY
   Bi, B
   Xu, GL
   Zhu, JH
   Zhang, XT
AF Du, Shaoyi
   Bi, Bo
   Xu, Guanglin
   Zhu, Jihua
   Zhang, Xuetao
TI Robust non-rigid point set registration via building tree dynamically
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid registration; Dynamic tree; Large shape difference; Affine
   registration; Coherent point drift method
ID CLASSIFICATION; ALGORITHM
AB The non-rigid registration methods, such as coherent point drift (CPD) method can deal with similar point sets, but it is difficult for them to achieve the non-rigid registration of point sets with large deformations. To overcome the problem, a novel approach via building dynamic tree is proposed in this paper. First of all, the similarity between the model and subject point sets is evaluated by the affine iterative closest point (ICP) algorithm with bidirectional distance, and the models and their similar subjects are connected. Secondly, the non-rigid registration is conducted on every two similar point sets. The subjects with accurate registration results are added to the model sets and wrong pairs are cut off based on a bidirectional distance. These steps are repeated and a dynamic tree is built up. In this way, a large deformation between two images is decomposed into a series of small deformations and the elimination of the wrong pairs in the dynamic tree guarantees the registration results are precise and satisfactory. Experimental results on several image datasets demonstrate that our method improves the accuracy of the point set registration results with large shape difference compared with existing approaches.
C1 [Du, Shaoyi; Bi, Bo; Xu, Guanglin; Zhu, Jihua; Zhang, Xuetao] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM dushaoyi@gmail.com
OI Du, Shaoyi/0000-0002-7092-0596
FU National Natural Science Foundation of China [61573274]; Program of
   Introducing Talents of Discipline to University [B13043]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61573274, and the Program of Introducing Talents
   of Discipline to University under Grant No. B13043.
CR Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Du SY, 2015, NEUROCOMPUTING, V168, P681, DOI 10.1016/j.neucom.2015.05.056
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P2769, DOI 10.1109/TIP.2014.2319735
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   Jia HJ, 2012, NEUROIMAGE, V59, P422, DOI 10.1016/j.neuroimage.2011.07.036
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   Liu MX, 2016, IEEE T MED IMAGING, V35, P1463, DOI 10.1109/TMI.2016.2515021
   Liu MX, 2015, HUM BRAIN MAPP, V36, P1847, DOI 10.1002/hbm.22741
   Mokhtarian F., 1996, BRIT MACHINE VISION, P53
   Mokhtarian F, 1997, ENGINEERING, V8, P51
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nüchter A, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P419
   Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427
   Wolz R, 2010, NEUROIMAGE, V49, P1316, DOI 10.1016/j.neuroimage.2009.09.069
   Ying SH, 2014, NEUROIMAGE, V84, P626, DOI 10.1016/j.neuroimage.2013.09.023
   Ying SH, 2009, IEEE T AUTOM SCI ENG, V6, P559, DOI 10.1109/TASE.2009.2021337
   Zhang J, 2016, IEEE T MED IMAGING, V35, P2524, DOI 10.1109/TMI.2016.2582386
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 27
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12065
EP 12081
DI 10.1007/s11042-016-4018-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000051
DA 2024-07-18
ER

PT J
AU Popadic, I
   Todorovic, BM
   Reljin, I
AF Popadic, Ilija
   Todorovic, Branislav M.
   Reljin, Irini
TI Method for HDR-like imaging using industrial digital cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imaging; Industrial cameras; HDR; Image fusion
AB Dynamic range of the scene can be significantly wider than the dynamic range of an image because of limitations of A/D conversion. In such a situation, numerous details of the scene cannot be adequately shown on the image. Standard industrial digital cameras are equipped with an auto-exposure function that automatically sets both the aperture value and cameras exposure time. When measuring a scene with atypical distribution of light and dark elements, the indicated auto-exposure time may not be optimal. The aim of work was to improve, with minimal cost, the performance of standard industrial digital cameras. We propose a low complexity method for creating HDR-like image using three images captured with different exposure times. The proposed method consists of three algorithms: (1) algorithm for estimating whether the auto-exposure time is optimal, (2) algorithm which determines exposure times for two additional images (one with shorter and another with longer than auto-exposure time), and (3) algorithm for HDR-like imaging based on fusion of three previously obtained images. Method is implemented on FPGA inserted into standard industrial digital camera. Results show that the proposed approach produces high quality HDR-like scene-mapped 8-bit images with minimal computational cost. All improvements may be noticed through the performance evaluation.
C1 [Popadic, Ilija; Reljin, Irini] Univ Belgrade, Fac Elect Engn, Blvd Kralja Aleksandra 73, Belgrade 11000, Serbia.
   [Popadic, Ilija; Todorovic, Branislav M.] VLATACOM Inst, Blvd Milutina Milankovica 5, Belgrade 11070, Serbia.
   [Todorovic, Branislav M.] RT RK Inst Comp Based Syst, Narodnog Fronta 23A, Novi Sad 21000, Serbia.
C3 University of Belgrade
RP Popadic, I (corresponding author), Univ Belgrade, Fac Elect Engn, Blvd Kralja Aleksandra 73, Belgrade 11000, Serbia.; Popadic, I (corresponding author), VLATACOM Inst, Blvd Milutina Milankovica 5, Belgrade 11070, Serbia.
EM ilija.popadic@vlatacom.com
RI Todorovic, Branislav M./GRR-6403-2022
OI Todorovic, Branislav M./0000-0003-1932-8332; Popadic,
   Ilija/0000-0002-5006-7786
CR [Anonymous], 2010, PROC 18 ACM INT C MU
   [Anonymous], 7 INT WORKSH QUAL MU
   [Anonymous], PFS TOOLS PACKAGE
   [Anonymous], SCIENCE
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Bilcu Radu Ciprian, 2008, 2008 15th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2008), P1312, DOI 10.1109/ICECS.2008.4675101
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Darmont A., 2013, SPIE
   Goshtasby A., 2005, 2D 3D IMAGE REGISTRA
   Jung JI, 2013, IET IMAGE PROCESS, V7, P606, DOI 10.1049/iet-ipr.2012.0614
   Lapray PJ, 2014, J REALTIME IMAGE PRO, P1
   Martínez MA, 2015, APPL OPTICS, V54, pB241, DOI 10.1364/AO.54.00B241
   Nemoto H., 2015, 9 INT WORKSHOP VIDEO
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
NR 14
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12801
EP 12817
DI 10.1007/s11042-016-3692-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200028
DA 2024-07-18
ER

PT J
AU Hong, CQ
   Yu, J
   You, J
   Yu, ZW
   Chen, XH
AF Hong, Chaoqun
   Yu, Jun
   You Jane
   Yu, Zhiwen
   Chen, Xuhui
TI Three-dimensional image-based human pose recovery with hypergraph
   regularized autoencoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D human pose recovery; Autoencoders; Manifold learning; Hypergraph;
   Patch alignment framework
ID RECOGNITION
AB Three-Dimensional image-based human pose recovery tries to retrieves 3D poses with 2D image. Therefore, one of the key problem is how to represent 2D images. However, semantic gap exists for current feature extractors, which limits recovery performance. In this paper, we propose a novel feature extractor with deep neural network. It is based on denoising autoencoders and improves previous autoencoders by adopting locality preserved restriction. To impose this restriction, we introduce manifold regularization with hypergraph learning. Hypergraph Laplacian matrix is constructed with patch alignment framework. In this way, an automatic feature extractor for images is achieved. Experimental results on three datasets show that the recovery error can be reduced by 10 % to 20 %, which demonstrates the effectiveness of the proposed method.
C1 [Hong, Chaoqun; Chen, Xuhui] Xiamen Univ Technol, Sch Comp Sci & Informat Engn, Xiamen, Peoples R China.
   [Yu, Jun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Yu, Jun] Hangzhou Dianzi Univ, Key Lab Complex Syst Modeling & Simulat, Minist Educ, Hangzhou, Zhejiang, Peoples R China.
   [You Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
   [Yu, Zhiwen] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
C3 Xiamen University of Technology; Hangzhou Dianzi University; Hangzhou
   Dianzi University; Hong Kong Polytechnic University; South China
   University of Technology
RP Yu, J (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.; Yu, J (corresponding author), Hangzhou Dianzi Univ, Key Lab Complex Syst Modeling & Simulat, Minist Educ, Hangzhou, Zhejiang, Peoples R China.
EM yujun@hdu.edu.cn
FU National Natural Science Foundation of China [61202145, 61572199,
   61472110]; Natural Science Foundation of Fujian Province of China
   [2014J01256]; Zhejiang Provincial Natural Science Foundation of China
   [LR15F020002]; Guangdong Natural Science Funds for Distinguished Young
   Scholars [S2013050014677]; Science and Technology Planning Project of
   Guangdong Province [2015A050502011]; central university project
   [2014G0007]
FX This work is supported by the National Natural Science Foundation of
   China (61202145, 61572199, 61472110), the Natural Science Foundation of
   Fujian Province of China (2014J01256), the Zhejiang Provincial Natural
   Science Foundation of China (LR15F020002), the Guangdong Natural Science
   Funds for Distinguished Young Scholars (S2013050014677), the grant from
   Science and Technology Planning Project of Guangdong Province
   (2015A050502011), and the central university project (2014G0007).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2014, INT C MACH LEARN
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], MODERN MACHINE LEARN
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422
   Chen C, 2011, COMPUT VIS IMAGE UND, V115, P290, DOI 10.1016/j.cviu.2010.11.007
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan X, 2015, IEEE INT C COMP VIS
   Gong C, 2014, IEEE T CYBERNETICS, V44, P882, DOI 10.1109/TCYB.2013.2274516
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Howe NR, 2000, ADV NEUR IN, V12, P820
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Karasuyama Masayuki, 2013, Adv. Neural Inf. Process. Syst., V26, P1547
   Lee H, 2009, IEEE C MACH LEARN
   Liu L, 2013, ACM INT C MULT
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666
   Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Song ML, 2014, IEEE T IMAGE PROCESS, V23, P5108, DOI 10.1109/TIP.2014.2361204
   Song ML, 2013, IEEE T IMAGE PROCESS, V22, P3283, DOI 10.1109/TIP.2013.2261307
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P2887, DOI 10.1109/TIP.2012.2183882
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Yang M, 2006, INT C PATT RECOG, P958
   Yu J, 2015, NEUROCOMPUTING, V166, P301, DOI 10.1016/j.neucom.2015.04.005
   Yu J, 2014, PATTERN RECOGN, V47, P3512, DOI 10.1016/j.patcog.2014.05.002
   Yuan Y, 2015, IEEE T NEURAL NETWOR
   Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
NR 36
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10919
EP 10937
DI 10.1007/s11042-016-3312-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400034
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Dong, L
   Ku, WP
AF Pan, Zhibin
   Dong, Liang
   Ku, Weiping
TI All-layer search algorithm using mean inequality and improved
   checkerboard partial distortion search for fast motion estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Mean inequality elimination; Improved checkerboard
   partial distortion search; All-layer search
AB Block-matching motion estimation algorithm is used in many video compression coding systems because it could greatly reduce the temporal redundancy between the consequent video sequences. In this paper, an all-layer search algorithm using mean inequality and improved checkerboard partial distortion search scheme for fast block-matching motion estimation is proposed. A layer in the proposed method refers to a processed image which is derived from the reference frame or the adjacent lower layer. Firstly, the proposed algorithm constructs all layers from the reference frame or the adjacent lower layer by summing up all pixels over a sub-block. Then, a new mean inequality elimination method is introduced to reject a lot of unnecessary candidate search points on the top layers before calculating the real block matching distortion. Finally, the proposed algorithm utilizes an improved checkerboard partial distortion search scheme in the process of the real block distortion calculation on the following layers to further reduce the amount of computation. Experimental results show that the proposed algorithm can effectively reduce the computational complexity of motion estimation meanwhile guarantee the matching quality compared to other motion estimation algorithms. Compared to the full search algorithm, the proposed algorithm can reduce 97.30 % computational complexity with a negligible degradation of the peak signal to noise ratio (PSNR). Compared to the diamond search algorithm, directional gradient descent search algorithm, partial distortion search algorithm, transform-domain successive elimination algorithm and two-layer motion estimation algorithm, the proposed algorithm can also save 63.56 %, 52.73 %, 92.87 %, 85.77 % and 33.96 % computational complexity, respectively.
C1 [Pan, Zhibin; Dong, Liang; Ku, Weiping] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Dong, Liang/JZD-4605-2024; Dong, Liang/IAR-4638-2023; Pan,
   Zhibin/I-8212-2012
FU Major Programs of National Natural Science Foundation of China
   [41390454]; Specialized Research Fund for the Doctoral Program of Higher
   Education [20130201110071]; Open Project Program of the National
   Laboratory of Pattern Recognition [201407370]; Open Project Program of
   the State Key Lab of CADCG [A1115]
FX This work is supported by the Major Programs of National Natural Science
   Foundation of China (Grant No. 41390454), Specialized Research Fund for
   the Doctoral Program of Higher Education (Grant No. 20130201110071),
   Open Project Program of the National Laboratory of Pattern Recognition
   (Grant No. 201407370) and Open Project Program of the State Key Lab of
   CAD&CG (Grant No. A1115).
CR Ahmad I, 2006, IEEE T CIRC SYST VID, V16, P420, DOI 10.1109/TCSVT.2006.870022
   Al-Najdawi N, 2014, INFORM SCIENCES, V268, P425, DOI 10.1016/j.ins.2013.08.009
   Bao XN, 2012, IEEE T MULTIMEDIA, V14, P237, DOI 10.1109/TMM.2011.2171677
   BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Cheung CH, 2003, IEEE T CIRC SYST VID, V13, P100, DOI 10.1109/TCSVT.2002.808091
   Cheung CK, 2000, IEEE T CIRC SYST VID, V10, P417, DOI 10.1109/76.836286
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jing X, 2007, IEEE SIGNAL PROC LET, V14, P840, DOI 10.1109/LSP.2007.900035
   Kai-Kuang M, 2003, CIRC SYST 2003 ISCAS, V702, DOI [10.1109/ISCAS.2003.1206072, DOI 10.1109/ISCAS.2003.1206072]
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lin CC, 2009, IET IMAGE PROCESS, V3, P88, DOI 10.1049/iet-ipr.2008.0042
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Paramkusam AV, 2014, ELECTRON LETT, V50, P276, DOI 10.1049/el.2013.4032
   Park CS, 2013, ELECTRON LETT, V49, P880, DOI 10.1049/el.2013.1318
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335
   Tedmori S., 2012, IET Computer Vision, V6, P21, DOI 10.1049/iet-cvi.2010.0188
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang CC, 2010, IEEE T CIRC SYST VID, V20, P1150, DOI 10.1109/TCSVT.2010.2056953
   Yi XQ, 2007, IEEE T MULTIMEDIA, V9, P995, DOI 10.1109/TMM.2007.898930
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 25
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9543
EP 9563
DI 10.1007/s11042-016-3562-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300020
DA 2024-07-18
ER

PT J
AU Tran, QD
   Hwang, D
   Lee, OJ
   Jung, JE
AF Quang Dieu Tran
   Hwang, Dosam
   Lee, O-Joun
   Jung, Jai E.
TI Exploiting character networks for movie summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie summarization; Movie analysis; Social network analysis; Video
   summarization; Movie character analysis
ID VIDEO; FRAMEWORK
AB Movie summarization focuses on providing as much information as possible for shorter movie clips while still keeping the content of the original movie and presenting a faster way for the audience to understand the movie. In this paper, we propose a novel method to summarize a movie based on character network analysis and the appearance of protagonist and main characters in the movie. Experiments were carried out for 2 movies (Titanic (1997) and Frozen (2013)) to show that our method outperforms conventional approaches in terms of the movie summarization rate.
C1 [Quang Dieu Tran; Hwang, Dosam] Yeungnam Univ, Dept Comp Engn, Gyongsan 712749, South Korea.
   [Lee, O-Joun; Jung, Jai E.] Chung Ang Univ, Dept Comp Engn, Seoul 156756, South Korea.
C3 Yeungnam University; Chung Ang University
RP Jung, JE (corresponding author), Chung Ang Univ, Dept Comp Engn, Seoul 156756, South Korea.
EM j3ung@cau.ac.kr
RI Lee, O-Joun/A-3607-2015; Jung, Jason J./B-9622-2012
OI Lee, O-Joun/0000-0001-8921-5443; Jung, Jason J./0000-0003-0050-7445;
   Tran, Quang Dieu/0000-0001-5559-8415
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [NRF-2014R1A2A2A05007154]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP)
   (NRF-2014R1A2A2A05007154).
CR [Anonymous], 2010, P 18 ACM INT C MULTI
   [Anonymous], 2015, COMPUT VIS MEDIA, DOI DOI 10.1007/S41095-015-0015-3
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bordwell D, 2006, WAY HOLLYWOOD TELLS IT: STORY AND STYLE IN MODERN MOVIES, P1
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Cheng KY, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P789
   Del Fabro M, 2013, MULTIMEDIA SYST, V19, P427, DOI 10.1007/s00530-013-0306-4
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Hong M, 2016, CYBERNET SYST, V47, P88, DOI 10.1080/01969722.2016.1128771
   Jung JJ, 2015, MOBILE NETW APPL, V20, P533, DOI 10.1007/s11036-014-0555-2
   Jung JJ, 2013, MULTIMED TOOLS APPL, V65, P29, DOI 10.1007/s11042-012-1133-x
   Jung JJ, 2012, EXPERT SYST APPL, V39, P4049, DOI 10.1016/j.eswa.2011.09.096
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Monaco James., 1981, READ FILM ART TECHNO
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Park SB, 2012, MULTIMED TOOLS APPL, V59, P601, DOI 10.1007/s11042-011-0725-1
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Phillips MA, 1996, SCREENPLAY SYSTEMS
   Salamin H, 2009, IEEE T MULTIMEDIA, V11, P1373, DOI 10.1109/TMM.2009.2030740
   Sharff Stefan., 1982, The Elements of Cinema: Toward a Theory of Cinesthetic Impact
   Tran QD, 2015, J UNIVERS COMPUT SCI, V21, P796
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Zhai Y, 2006, IEEE T MULTIMEDIA, V8, P686, DOI 10.1109/TMM.2006.876299
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
NR 29
TC 24
Z9 24
U1 8
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10357
EP 10369
DI 10.1007/s11042-016-3633-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400003
DA 2024-07-18
ER

PT J
AU Rahimi, G
   Yousefi, S
AF Rahimi, GholamAli
   Yousefi, Saleh
TI A QoE-aware transmission mechanism for interactive IPTV over IEEE 802.16
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive IPTV; Scalable video Coding (SVC); QoE; IEEE 802.16;
   Scheduler
AB In this paper, we study Quality of Experience (QoE) in the transmission of interactive IPTV (IIPTV) over IEEE 802.16 networks where the video traffic is coded using Scalable Video Coding (SVC). The proposed mechanism includes two major algorithms. 1) A QoE-based layer selection namely QoE-LVT which decides on the appropriate SVC layers that should be transmitted from the server to each subscriber. For this purpose, the loss rate experienced by each subscriber is returned to the server via an uplink connection. Given this feedback and also some other information internally available, the server estimates the QoE of the user using Neural Network-based learning functions. Then the appreciate decision for excluding the layers which cause QoE deterioration is taken. 2) A priority-based scheduling in the IEEE 802.16 MAC layer which assigns priority to each SVC layer according to the impact of the layer on the user's QoE. We provide some cross-layer interaction to enable distinguishing among different SVC video layers (i.e., base layer and two enhancement layers) in IEEE 802.16 MAC. Results of extensive simulations using NS-3 simulator confirm that compared to previous works our proposed mechanism improves QoE of both fixed and mobile users.
C1 [Rahimi, GholamAli; Yousefi, Saleh] Urmia Univ, Comp Engn Dept, Fac Engn, Orumiyeh 5756151818, Iran.
C3 Urmia University
RP Yousefi, S (corresponding author), Urmia Univ, Comp Engn Dept, Fac Engn, Orumiyeh 5756151818, Iran.
EM s.yousefi@urmia.ac.ir
RI Yousefi, Saleh/AAM-2561-2020
CR [Anonymous], 2007, SG12 ITUT
   [Anonymous], IEEE INT C EL INF TE
   [Anonymous], IPTVID0028 ITUR FG
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 2002, BT50011 ITUR
   [Anonymous], IEEE T BROADCASTING
   Barakovic S, 2012, J COMPUT NETW COMMUN
   Chaari L, 2012, COMPREHENSIVE SURVEY
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Du HF, 2009, IEEE WIREL COMMUN, V16, P72, DOI 10.1109/MWC.2009.5281258
   Hillested O., 2007, P PACK VID NOV, P26
   Hsing-Lung Chen, 2008, Fourth International Conference on Wireless and Mobile Communications. ICWMC 2008, P241, DOI 10.1109/ICWMC.2008.35
   Huang SJ, 2010, FOOD IND, V1, P71
   *ITUT, 1994, E800 ITUT
   Joo H, 2012, CONSUM COMM NETWORK, P759, DOI 10.1109/CCNC.2012.6181160
   Joo H, 2010, J VIS COMMUN IMAGE R, V21, P89, DOI 10.1016/j.jvcir.2009.04.004
   Ksentini A, 2013, IEEE T BROADCAST, V59, P251, DOI 10.1109/TBC.2013.2254891
   Lee DB, 2010, J VIS COMMUN IMAGE R, V21, P245, DOI 10.1016/j.jvcir.2010.01.002
   Lee H, 2011, WIREL NETW, V17, P103, DOI 10.1007/s11276-010-0267-x
   Lera A, 2007, IEEE NETWORK, V21, P34, DOI 10.1109/MNET.2007.4305171
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   O'Driscoll, 2008, NEXT GENERATION IPTV
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Venkataraman M, 2011, IEEE NETWORK, V25, P4, DOI 10.1109/MNET.2011.5687947
   Wongthavarawat K, 2003, INT J COMMUN SYST, V16, P81, DOI 10.1002/dac.581
NR 25
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10255
EP 10277
DI 10.1007/s11042-016-3612-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300053
DA 2024-07-18
ER

PT J
AU Song, Y
   Yang, GB
   Xie, HT
   Zhang, DY
   Sun, XM
AF Song, Yun
   Yang, Gaobo
   Xie, Hongtao
   Zhang, Dengyong
   Sun Xingming
TI Residual domain dictionary learning for compressed sensing video
   recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Dictionary learning; Residue-domain; Inter-frame
   difference; Video recovery
AB For compressed sensing (CS) recovery, the reconstruction quality is highly dependent on the sparsity level of the representation for the signal. Motivated by the observation that the temporal residual image is much sparser than its original image, a temporal residual-domain dictionary learning method for CS video recovery is proposed in this paper. The adaptive basis is learned from inter-frame differences by Karhunen-Loeve transform (KLT) to represent the residuals. And a block-based motion estimation/motion compensation (ME/MC) residual reconstruction strategy is incorporated for the CS video recovery. Experimental results on common test sequences at various sampling rates illustrate that the proposed algorithm gains great improvements over existing approaches. For some video sequences, the proposed method outperforms the state-of-art method near 1 dB in terms of peak signal noise rate (PSNR) at some higher sampling rate.
C1 [Song, Yun; Yang, Gaobo; Zhang, Dengyong] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Song, Yun; Zhang, Dengyong] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Xie, Hongtao] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
   [Sun Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology; Chinese
   Academy of Sciences; Institute of Information Engineering, CAS; Nanjing
   University of Information Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI Sun, Xingming/AAD-1866-2019
FU Hunan Province Science and Technology Planning Project [2014FJ6047,
   2014GK3030]; Science Research Key Project of the Education Department of
   Hunan Province [13A107, 15A007]; Changsha Science and Technology
   Planning Project [K1403028-11]
FX This work was supported in part by the Hunan Province Science and
   Technology Planning Project (nos. 2014FJ6047 and 2014GK3030), the
   Science Research Key Project of the Education Department of Hunan
   Province (nos. 13A107 and 15A007), and the Changsha Science and
   Technology Planning Project (no. K1403028-11).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Eslahi N, 2015, ARXIV150807640
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Kwon S, 2014, IEEE T INFORM THEORY, V60, P2986, DOI 10.1109/TIT.2014.2310482
   Liu QG, 2013, IEEE T IMAGE PROCESS, V22, P4652, DOI 10.1109/TIP.2013.2277798
   Liu Y, 2013, IEEE T CIRC SYST VID, V23, P438, DOI 10.1109/TCSVT.2012.2207269
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Stankovic V, 2008, P EUR SIGN P C EUSIP
   WAKIN M. B., 2006, P PCS APR, P711
   Yue H, 2013, IEEE T IMAGE PROCESS, V23, P2423
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhao YB, 2013, IEEE T SIGNAL PROCES, V61, P5777, DOI 10.1109/TSP.2013.2281030
NR 21
TC 42
Z9 42
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10083
EP 10096
DI 10.1007/s11042-016-3599-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300044
DA 2024-07-18
ER

PT J
AU Ghahremani, S
   Ghanbari, M
AF Ghahremani, Shahram
   Ghanbari, Mohammad
TI Error resilient video transmission in ad hoc networks using layered and
   multiple description coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Layered coding; Flexible macroblock ordering; Ad hoc network; Error
   resilient video coding
ID SCALABLE VIDEO
AB The mesh structure of ad hoc networks, provides the possibility of establishing two disjoint paths from a sender to a receiver. Transmission of video over such networks due to their unpredictability and difficulty in securing reliable channels is challenging. Layered Coding (LC) and Multiple Description Coding (MDC) are two different techniques which can benefit from path diversity for robust video communication and also to adapt with preferences of users\network. This paper presents an approach to provide error resilient video transmission over a variety of network conditions and applications needs using combined LC and MDC schemes. In the proposed method two descriptions of each layer are generated in the FMO format of the H.264/AVC standard. Unlike the conventional approaches, in our work macroblocks of each layer are divided into two paths. Hence, in the bursty error conditions the error will be smoothly spread in all layers. For better protection and more network compatibility, the base layer is data partitioned and its important part (DP_A) is repeated in both paths. Simulation results show transmission of duplicated DP_A and the non-corresponding descriptions of two layers together on disjoint paths, can improve the error concealment of the decoder and consequently enhance video quality by up to 2 dB.
C1 [Ghahremani, Shahram; Ghanbari, Mohammad] Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 University of Tehran; University of Essex
RP Ghahremani, S (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
EM Sh.ghahremani@ut.ac.ir; ghan@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378
CR Ali I, 2013, IEEE WIREL COMMUN, V20, P105, DOI 10.1109/MWC.2013.6549289
   Chen Y, 2002, FLEXIBLE DATA PARTIT
   Ghandi MM, 2006, J VIS COMMUN IMAGE R, V17, P451, DOI 10.1016/j.jvcir.2005.05.005
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Huo YK, 2014, IEEE VEH TECHNOL MAG, V9, P104, DOI 10.1109/MVT.2014.2334411
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Joint Video Team of ISO/IEC MPEG and ITU-T, 2010, VCEG ADV VID COD GEN
   Ke CH, 2012, KSII T INTERNET INF, V6, P379, DOI 10.3837/tiis.2012.01.021
   Lee YC, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P35
   Liao WH, 2001, LECT NOTES COMPUT SC, V2094, P158
   Maani E, 2010, IEEE T CIRC SYST VID, V20, P407, DOI 10.1109/TCSVT.2009.2035846
   Mao SW, 2001, IEEE VTS VEH TECHNOL, P615, DOI 10.1109/VTC.2001.956843
   Nguyen VT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1067
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Qadri NN, 2010, IET COMMUN, V4, P1300, DOI 10.1049/iet-com.2009.0458
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Singla ER, 2014, INT J COMPUT SCI INF, V5
   Team JV, 2009, INT RWTHAACHEN DE
   Wang HS, 2003, PROC SPIE, V5022, P111, DOI 10.1117/12.476503
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
NR 20
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 9033
EP 9049
DI 10.1007/s11042-016-3471-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800063
DA 2024-07-18
ER

PT J
AU Ghimire, D
   Lee, J
   Li, ZN
   Jeong, S
AF Ghimire, Deepak
   Lee, Joonwhoan
   Li, Ze-Nian
   Jeong, Sunghwan
TI Recognition of facial expressions based on salient geometric features
   and support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial points; Geometric features; AdaBoost; Extreme learning machine;
   Support vectormachines; Facial expression recognitions
ID EXTREME LEARNING-MACHINE; LOCAL BINARY PATTERNS; FACE RECOGNITION
AB Facial expressions convey nonverbal cues which play an important role in interpersonal relations, and are widely used in behavior interpretation of emotions, cognitive science, and social interactions. In this paper we analyze different ways of representing geometric feature and present a fully automatic facial expression recognition (FER) system using salient geometric features. In geometric feature-based FER approach, the first important step is to initialize and track dense set of facial points as the expression evolves over time in consecutive frames. In the proposed system, facial points are initialized using elastic bunch graph matching (EBGM) algorithm and tracking is performed using Kanade-Lucas-Tomaci (KLT) tracker. We extract geometric features from point, line and triangle composed of tracking results of facial points. The most discriminative line and triangle features are extracted using feature selective multi-class AdaBoost with the help of extreme learning machine (ELM) classification. Finally the geometric features for FER are extracted from the boosted line, and triangles composed of facial points. The recognition accuracy using features from point, line and triangle are analyzed independently. The performance of the proposed FER system is evaluated on three different data sets: namely CK+, MMI and MUG facial expression data sets.
C1 [Ghimire, Deepak; Jeong, Sunghwan] Korea Elect Technol Inst, IT Applicat Res Ctr, Jeonju Si 561844, Jeollabuk Do, South Korea.
   [Lee, Joonwhoan] Chonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
   [Li, Ze-Nian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.
C3 Jeonbuk National University; Simon Fraser University
RP Lee, J (corresponding author), Chonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
EM deepak@keti.re.kr; chlee@jbnu.ac.kr; li@cs.sfu.ca; shjeong@keti.re.kr
RI Ghimire, Deepak/W-2826-2019
OI Ghimire, Deepak/0000-0001-8940-8739
CR Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Aifanti N, 2014, SIGNAL PROCESS-IMAGE, V29, P177, DOI 10.1016/j.image.2013.10.004
   [Anonymous], 2014, ADV HUMAN COMPUTER I
   Asthana Akshay., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Blome DS, 2003, THESIS
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Choi HL, 2006, 2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13, P4592
   Cid F, 2014, SENSORS-BASEL, V14, P7711, DOI 10.3390/s140507711
   Cruz AC, 2014, IEEE T AFFECT COMPUT, V5, P418, DOI 10.1109/TAFFC.2014.2316151
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Hsu C. W., 2010, Technical Report
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kotisa I, 2008, IMAGE VISION COMPUT, V26, P1033
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Liu WF, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P680, DOI 10.1109/CISP.2008.216
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6
   Schels Martin, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4251, DOI 10.1109/ICPR.2010.1033
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Soyel H, 2012, COMPUT ELECTR ENG, V38, P1299, DOI 10.1016/j.compeleceng.2011.10.016
   Sung J, 2009, IMAGE VISION COMPUT, V27, P1313, DOI 10.1016/j.imavis.2008.11.010
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Uhls YT, 2014, COMPUT HUM BEHAV, V39, P387, DOI 10.1016/j.chb.2014.05.036
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
   Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 50
TC 42
Z9 42
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7921
EP 7946
DI 10.1007/s11042-016-3428-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800015
DA 2024-07-18
ER

PT J
AU Guo, SR
   Tan, GH
   Pan, HW
   Chen, L
   Gao, CM
AF Guo, Songrui
   Tan, Guanghua
   Pan, Huawei
   Chen, Lin
   Gao, Chunming
TI Face alignment under occlusion based on local and global feature
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occlusion; Local regression; Global regression; Shape-indexed feature;
   Face alignment
AB Shape alignment or estimation under occlusion is one of the most challenging tasks in computer vision field. Most previous works treat occlusion as noises or part models, which usually lead to low accuracy or inefficiencies. This paper proposes an efficient and accurate regression-based algorithm for face alignment. In this framework, local and global regressions are iteratively used to train a series of random forests in a cascaded manner. In training and testing process, each step consists of two layers. In the first layer, a set of highly discriminative local features are extracted from local regions according to locality principle. The regression forests are trained for each facial landmark independently using those local features. Then the leaf node of the regression tree is encoded by histogram statistic method and the final shape is estimated by a linear regression matrix. In the second layer, our proposed global features are generated. Then we use those features to train a random fern to keep the global shape constraints. Experiments show that our method has a high speed, but same or slightly lower accuracy than state of the art methods under occlusion condition. In order to gain a higher accuracy we use multi-random shape for initialization, which may slightly reduce the calculation efficiency as a trade-off.
C1 [Guo, Songrui; Tan, Guanghua; Pan, Huawei; Chen, Lin; Gao, Chunming] Hunan Univ, Coll Informat Sci & Engn, Changsha 410000, Hunan, Peoples R China.
C3 Hunan University
RP Tan, GH (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410000, Hunan, Peoples R China.
EM guanghuatan@gmail.com
RI chen, lin/GQP-5101-2022
FU National Natural Science Foundations of China [11201136]; Science and
   Technology Planning Project of Hunan Province [2014WK3002]
FX This paper is supported by "National Natural Science Foundations of
   China (No. 11201136)" and "the Science and Technology Planning Project
   of Hunan Province (2014WK3002)".
CR [Anonymous], 2011, BMVC
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burgos-Artizzu X. P, 2013, P IEEE INT C COMP VI, P1
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Cootes T, 1995, P BR MACH VIS C, P266
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2007, P BRIT MACH VIS C, P1, DOI 10.5244/C.21.79
   Cui Y, 2015, SIGNAL PROCESS, V110, P46, DOI 10.1016/j.sigpro.2014.09.029
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
NR 22
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8677
EP 8694
DI 10.1007/s11042-016-3470-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800046
DA 2024-07-18
ER

PT J
AU Nouri, R
   Mansouri, A
AF Nouri, Roya
   Mansouri, Azadeh
TI Digital image steganalysis based on the reciprocal singular value curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; SVD; DCT; JPEG
ID QUALITY ASSESSMENT; FEATURES
AB Embedding secret messages in steganographic approaches is similar to adding some weak noises to the original media. One of the traditional ways for image steganalysis is computing a feature sets using noise residuals. From another perspective, the disturbance of natural image statistics can be explored to extract the feature vector for steganalysis. In fact, the alteration of natural scene statistics can be investigated to reveal the presence of secret messages embedded in images. Hence, the feature vectors can be constructed using such changes. In the proposed scheme, the alteration of singular value curve is used to construct the steganalysis feature vector. Two spatial and JPEG based feature vectors are extracted in the proposed statistical exploitation. The experimental results illustrate the acceptable performance of the proposed feature vectors for both universal and JPEG based steganalysis methods.
C1 [Nouri, Roya; Mansouri, Azadeh] Kharazmi Univ, Dept Elect & Comp Engn, Tehran, Iran.
C3 Kharazmi University
RP Mansouri, A (corresponding author), Kharazmi Univ, Dept Elect & Comp Engn, Tehran, Iran.
EM a_mansouri@khu.ac.ir; std_roya_nouri@khu.ac.ir
RI Mansouri, Azadeh/AAC-2576-2022
OI Mansouri, Azadeh/0000-0002-2556-6022
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Avcibas I, 2005, EURASIP J APPL SIG P, V2005, P2749, DOI 10.1155/ASP.2005.2749
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Gou HM, 2007, IEEE IMAGE PROC, P2893
   Gül G, 2007, IEEE SIGNAL PROC LET, V14, P205, DOI 10.1109/LSP.2006.884010
   Gul G, 2009, IEEE IMAGE PROC, P4249, DOI 10.1109/ICIP.2009.5413716
   Gul G, 2010, IEEE T INF FOREN SEC, V5, P349, DOI 10.1109/TIFS.2010.2041826
   Guo Q, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/905761
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Kharrazi M, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2400672
   Liu QZ, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899420
   Mahmoudi-Aznaveh A, 2009, OPT REV, V16, P30, DOI 10.1007/s10043-009-0007-6
   Mansouri A, 2009, OPT REV, V16, P49, DOI 10.1007/s10043-009-0010-y
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Nouri R, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P124, DOI 10.1109/IranianMVIP.2015.7397519
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qingxiao Guan, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2721, DOI 10.1109/ICIP.2011.6116231
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sang QB, 2014, SIGNAL PROCESS-IMAGE, V29, P1149, DOI 10.1016/j.image.2014.09.005
NR 27
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8745
EP 8756
DI 10.1007/s11042-016-3507-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800049
DA 2024-07-18
ER

PT J
AU Petkos, G
   Schinas, M
   Papadopoulos, S
   Kompatsiaris, Y
AF Petkos, Georgios
   Schinas, Manos
   Papadopoulos, Symeon
   Kompatsiaris, Yiannis
TI Graph-based multimodal clustering for social multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal clustering; Social multimedia; Social event detection;
   Multimedia
AB Real world datasets often consist of data expressed through multiple modalities. Clustering such datasets is in most cases a challenging task as the involved modalities are often heterogeneous. In this paper we propose a graph-based multimodal clustering approach. The proposed approach utilizes an example relevant clustering in order to learn a model of the "same cluster" relationship between a pair of items. This model is subsequently used in order to organize the items of the collection to be clustered in a graph, where the nodes represent the items and a link between a pair of nodes exists if the model predicted that the corresponding pair of items belong to the same cluster. Eventually, a graph clustering algorithm is applied on the graph in order to produce the final clustering. The proposed approach is applied on two problems that are typically treated using clustering techniques; in particular, it is applied on the problem of detecting social events and to the problem of discovering different landmark views in collections of social multimedia.
C1 [Petkos, Georgios; Schinas, Manos; Papadopoulos, Symeon; Kompatsiaris, Yiannis] CERTH ITI, Thessaloniki, Greece.
RP Petkos, G (corresponding author), CERTH ITI, Thessaloniki, Greece.
EM gpetkos@iti.gr; manosetro@iti.gr; papadop@iti.gr; ikom@iti.gr
RI Papadopoulos, Symeon/AET-0683-2022; Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Symeon/0000-0002-5441-7341
CR Aggarwal C, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2601412
   [Anonymous], 2015, P 13 INT WORKSHOP CO
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bekkerman Ron, 2007, CVPR
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brenner M, 2011, CEUR WORKSHOP P
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Dang-Nguyen D, 2014, P MED 2014 WORKSH BA
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Ginsca A, 2014, P MED 2014 WORKSH BA
   Goder A, 2008, SIAM PROC S, P109
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Ionescu B, 2014, P MED 2014 WORKSH BA
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Khalidov V, 2011, NEURAL COMPUT, V23, P517, DOI 10.1162/NECO_a_00074
   Liu Xiaofang, 2011, TECHNOLOGICAL DEV EN, V03, P18
   Nguyen NP, 2011, IEEE INFOCOM SER, P2282, DOI 10.1109/INFCOM.2011.5935045
   Papadopoulos S, 2012, MEDIAEVAL, P2012
   Papadopoulos S, 2011, CEUR WORKSHOP P
   Papadopoulos S, 2012, DATA MIN KNOWL DISC, V24, P515, DOI 10.1007/s10618-011-0224-z
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Petkos G, 2014, P MED 2014 WORKSH BA
   Petkos G., 2012, P 2 ACM INT C MULT R, P231, DOI 10. 1145/2324796.2324825.
   Petkos G, 2014, 20 ANN INT C MMM 201, P146
   Phuvipadawat S., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P120, DOI 10.1109/WI-IAT.2010.205
   Rendle S, 2008, LECT NOTES ARTIF INT, V5012, P308, DOI 10.1007/978-3-540-68125-0_28
   Reuter T., 2012, PROC ANN ACM INT C M, P22
   Reuter Timo., 2013, P MEDIAEVAL 2013 MUL, P1
   Samangooei S, 2013, P MED 2013 MULT BENC
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Spiliopoulou M, 2011, SOCIAL NETWORK DATA ANALYTICS, P149
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Xu XW, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P824, DOI 10.1145/1281192.1281280
   Ye ZQ, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046115
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Zaharieva M, 2014, P MED 2014 WORKSH BA
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
NR 42
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7897
EP 7919
DI 10.1007/s11042-016-3378-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800014
DA 2024-07-18
ER

PT J
AU Wang, QZ
   Kang, WJ
AF Wang, Qingzhu
   Kang, Wanjun
TI Adaptive tensor compressive sensing based on noise estimation:
   application in three-dimensional images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Low-rank tensor approximation; Tucker decomposition
ID PARALLEL FRAMEWORK; DECOMPOSITIONS; ACQUISITION
AB Tensor Compressive Sensing (CS) is an emerging approach for higher order data representation, such as medical imaging, video sequences and multi-sensor networks. In this paper, we propose an Adaptive Tensor CS (ATCS) scheme for Three-dimensional (3D) images, especially those which contain noise. First, we find the relationship between reconstruction performance, noise level and sampling rate. Second, we develop the ATCS method by implementing a noise estimation algorithm. Finally, we apply the method in the CS system for efficient representation of 3D video sequences. We also demonstrate experimentally that ATCS outperforms other state of the art algorithms.
C1 [Wang, Qingzhu; Kang, Wanjun] Northeast Dianli Univ, Sch Informat Engn, Jilin 132012, Peoples R China.
C3 Northeast Electric Power University
RP Wang, QZ (corresponding author), Northeast Dianli Univ, Sch Informat Engn, Jilin 132012, Peoples R China.
EM 150681573@qq.com
FU National Natural Science Foundation of China [61301257]
FX This work was supported by National Natural Science Foundation of China
   (61301257).
CR Aderohunmu FA, 2015, SENSORS-BASEL, V15, P10221, DOI 10.3390/s150510221
   Caiafa CF, 2015, IEEE T SIGNAL PROCES, V63, P780, DOI 10.1109/TSP.2014.2385040
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cichocki A., 2015, IEEE SIGNAL IN PRESS
   Colom M, 2014, J OPT SOC AM A, V31, P863, DOI 10.1364/JOSAA.31.000863
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Friedland S, 2014, IEEE T IMAGE PROCESS, V23, P4438, DOI 10.1109/TIP.2014.2348796
   Gastaldo P, 2014, SENSORS-BASEL, V14, P10952, DOI 10.3390/s140610952
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li XW, 2014, SENSORS-BASEL, V14, P23398, DOI 10.3390/s141223398
   Lu WZ, 2015, IEEE SIGNAL PROC LET, V22, P1074, DOI 10.1109/LSP.2014.2385813
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Sidiropoulos ND, 2012, IEEE SIGNAL PROC LET, V19, P757, DOI 10.1109/LSP.2012.2210872
   Vannieuwenhoven N, 2012, SIAM J SCI COMPUT, V34, pA1027, DOI 10.1137/110836067
   Vervliet N, 2014, IEEE SIGNAL PROC MAG, V31, P71, DOI 10.1109/MSP.2014.2329429
   Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577
   Wang XP, 2014, SENSORS-BASEL, V14, P3897, DOI 10.3390/s140303897
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang JB, 2015, IEEE T IMAGE PROCESS, V24, P106, DOI 10.1109/TIP.2014.2365720
   Yu YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098441
   Zanotta DC, 2015, IEEE T GEOSCI REMOTE, V53, P3707, DOI 10.1109/TGRS.2014.2381645
   Zhu W, 2015, MULTIDIM SYST SIGN P, V26, P113, DOI 10.1007/s11045-013-0239-2
NR 27
TC 0
Z9 0
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6175
EP 6188
DI 10.1007/s11042-016-3296-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400005
DA 2024-07-18
ER

PT J
AU Agrawal, AK
   Singh, YN
AF Agrawal, Amrit Kumar
   Singh, Yogendra Narain
TI An efficient approach for face recognition in uncontrolled environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Facial features detection and unconstrained
   environment
ID CLASSIFICATION; EIGENFACES
AB There is a great demand of automatic face recognition in the society. The methods of face recognition are performed satisfactorily in controlled environment. The challenging benchmarks demonstrate that these methods may not adequately work in unconstrained environment. In this paper, we develop a novel framework of face recognition system that outperforms in unconstrained environment. The framework works on features based method that extracts facial landmarks from images. After quality check the patch experts are generated and used to model the appearance of landmarks of interests. The effect of discriminatory features is further enhanced by assigning weights to them that are to be set to the ratio of the interclass variance to the intraclass variance. The result shows that the proposed framework achieves better recognition accuracy in comparison to other known methods on publically available challenging datasets.
C1 [Agrawal, Amrit Kumar] Apollo Inst Technol, Kanpur 209402, Uttar Pradesh, India.
   [Singh, Yogendra Narain] Dr APJ Abdul Kalam Tech Univ, Inst Engn & Technol, Lucknow 226021, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Agrawal, AK (corresponding author), Apollo Inst Technol, Kanpur 209402, Uttar Pradesh, India.
EM agrawal.amrit4@gmail.com
RI Singh, Yogendra Narain/AAG-7703-2019
CR [Anonymous], 2006, BMVC
   [Anonymous], FACE RECOGNITION DAT
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chevallier L., 2013, COMPUTER VISION IMAG, P103
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Markus N., 2014, CoRR
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shyam R, 2016, ADV INTELL SYST, V384, P383, DOI 10.1007/978-3-319-23036-8_33
   Shyam R, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/4645971
   Shyam R, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P779, DOI 10.1109/SPIN.2015.7095267
   Shyam R, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P749, DOI 10.1109/SPIN.2014.6777054
   Singh YN, 2015, NEUROCOMPUTING, V167, P322, DOI 10.1016/j.neucom.2015.04.063
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 18
TC 9
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3751
EP 3760
DI 10.1007/s11042-016-3976-z
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200028
DA 2024-07-18
ER

PT J
AU Oh, SJ
   Kim, YJ
   Doo, IC
AF Oh, Se Jong
   Kim, Young Jae
   Doo, Ill Chul
TI Study of profit model of web-dramas on portal sites using big data;
   Focused on the Web-dramas with the K-pop Singers as the Lead Casts:
   "EXO, Next Door" and "I Order You"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web-drama; Big data; Portal sites; Profit mode; EXO; PPL; T-Commerce;
   M-Commerce; D2C; EXO; Next Door; I Order You; K-pop; K-pop Singers
AB The age of direct-to-consumer when an audience directly becomes consumer has arrived due to the rapid popularizaton of smartphones. Web-dramas market, the representative part of the D2C age, has expanded mainly based on portal sites. Especially a web-drama, <Exo, Next Door>, has gone over about 16 million views, with high expectation of being exported overseas. This report shall analyze the factors in success of web-drama utilizing Big Data from both the domestic and international portal sites. The yearly viewing numbers of the shows watched on PC's and mobile devices will be extracted, along with the related keywords that were brought to attention together with the show. Finally, the profit model of the web-drama will be constructed; the main methods for profit model of web-drama are paid service, ad revenue, and corporate investment or partnership. This work will also suggest 'M-Commerce,' a product placement method which is an expansion of T-Commerce. M-commerce profit model in foreign exports henceforth has tremendous practical value as a business model that can bring in additional profitability. Such a concept can become a strong selling point to investors. The combination of webdramas of various subjects and M-Commerce can function as a stage for new competent actors, songwriters, and directors, while providing a novel profit model that can grow with the PPL products.
C1 [Oh, Se Jong] NHN Entertainment AD, 629 Sampyeong dong, Gyeonggi, South Korea.
   [Kim, Young Jae] Hanyang Univ, 55 Hanyangdaehak ro, Ansan, South Korea.
   [Doo, Ill Chul] Ind Univ Cooperat, Dongguk Univ, 30,Pildong ro 1-gil, Seoul, South Korea.
C3 Hanyang University; Dongguk University
RP Doo, IC (corresponding author), Ind Univ Cooperat, Dongguk Univ, 30,Pildong ro 1-gil, Seoul, South Korea.
EM mrdoo@dongguk.edu
FU National Project of India [xxx-xxxx]; Department of Science and
   Technology, Government of India
FX The National Project of India (No.: xxx-xxxx). Authors are grateful to
   the Department of Science and Technology, Government of India for
   financial support to carry out this work.
CR [Anonymous], 2011, BIG DATA NEXT FRONTI
   [Anonymous], 2015, YIYAN CHIN NETW DRAM
   [Anonymous], 2014, ANSWILL WEB DRAM EM, V78
   [Anonymous], 2014, STUDY WEBTOON IND MI
   Cha Y-r, 2013, KOREA CONTENTS ASS, V13, P170
   Hwang S-t, 2014, KOREAN J ANIMATION, V10, P236
   Kim D-h, 2005, THE CHOSUN ILBO 0815
   Kim Y-b, 2009, J CULTURAL POLICY, V21, P218
   Kim YJ, 2014, KOREA SOC DIGITAL IN, V10, P228
   Kyoung SB, 2014, J KOREAN I COMMUN IN, V31, P12
   Laney D, 2001, 3D DATA MANAGEMENT C
   Lee D, 2008, NW MEDIA
   Lee M-h, 2011, KOREA REGIONAL COMMU, V11, P181
   Lee Y-j, 2013, KOREAN ASS BROADCAST
   Linda B, 2012, GETELASTIC
   Noh J-u, 2015, CHOSUN BIZ      0526
   Oh SJ, 2015, KOREA SOC DIGITAL IN, V11, P161
   Oh SJ, 2015, INFORM INT INTERDISC, V18, P1555
   Oh SJ, 2014, REV KOREAN CULTURAL, V48, P700
NR 19
TC 2
Z9 2
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6097
EP 6110
DI 10.1007/s11042-016-3556-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500067
DA 2024-07-18
ER

PT J
AU Yang, WK
   Sun, CY
   Zheng, WM
   Ricanek, K
AF Yang, Wankou
   Sun, Changyin
   Zheng, Wenming
   Ricanek, Karl
TI Gender classification using 3D statistical models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Procrustes transformation; Point alignment; 3D gender classification
ID FACE-RECOGNITION; SEX
AB In this paper, an effective gender classification based on 3D face model is proposed based on 3D principal components analysis (3D Eigenmodels) and 3D independent components analysis (3D ICmodels). In our work, the 3D face model is represented by 3D landmarks. The proposed gender classification method consists of three steps: 1) Align the 3D models to get 3D aligned shapes; 2) Perform 3D PCA/ICA transformation on the aligned 3D shapes; 3) Do gender classification on the 3D Eigenmodels/ICmodels features using SVM. The experimental results on BU_3DFE database demonstrate that the proposed method can achieve good performance.
C1 [Yang, Wankou; Sun, Changyin] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Yang, Wankou; Sun, Changyin] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Yang, Wankou; Zheng, Wenming] Southeast Univ, Minist Educ, Key Lab Child Dev & Learning Sci, Nanjing 210096, Peoples R China.
   [Ricanek, Karl] UNC Wilmington, Dept Comp Sci, Face Aging Grp, Wilmington, NC USA.
C3 Southeast University - China; Southeast University - China; Southeast
   University - China; University of North Carolina; University of North
   Carolina Wilmington
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM wankou.yang@yahoo.com
RI SUN, CHANG/GXM-3680-2022; sun, chang/ITV-6759-2023
FU NSF of China [61375001, 31200747]; Natural Science Foundation of Jiangsu
   Province [BK20140638, BK20150470, BK2012437]; Fundamental Research Funds
   for the Central Universities [2242015 K40037]; Open Project Program of
   Key Laboratory of Child Development and Learning Science of Ministry of
   Education, Southeast University [CDLS-2014-04]
FX This project is partly supported by NSF of China (61375001, 31200747),
   the Natural Science Foundation of Jiangsu Province (No.BK20140638,
   BK20150470, BK2012437), the Fundamental Research Funds for the Central
   Universities (2242015 K40037), and the Open Project Program of Key
   Laboratory of Child Development and Learning Science of Ministry of
   Education, Southeast University (No. CDLS-2014-04).
CR Albert AM, 2007, FORENSIC SCI INT, V172, P1, DOI 10.1016/j.forsciint.2007.03.015
   [Anonymous], IEEE T CIRCUITS SYST
   Ballihi L, 2012, INT S COMM CONTR SIG, P1, DOI DOI 10.1109/ISCCSP.2012.6217828
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BRUCE V, 1993, PERCEPTION, V22, P131, DOI 10.1068/p220131
   Cao Y, 2013, NEUROCOMPUTING, V120, P560, DOI 10.1016/j.neucom.2013.04.014
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen C, 2010, FACE AGE ESTIMATION
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cottrell G.W., 1991, Advances in Neural Information Processing Systems, V3, P564
   Duda R., 1973, Pattern Classification and Scene Analysis
   Ezghari S, 2015, GENDER CLASSIFICATIO
   Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Goodall C, 1997, CVPR
   Guo G.D., 2009, IEEE INT WORKSH HUM
   Gutta S., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P4084, DOI 10.1109/IJCNN.1999.830815
   Han X, 2009, INT C CYBERWORLDS
   Hu Y, 2010, INT CONF COMPUT AUTO, P369, DOI 10.1109/ICCAE.2010.5451407
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Jalil S. Z. A., 2011, 2011 UkSim 13th International Conference on Computer Modelling and Simulation (UKSim 2011), P59, DOI 10.1109/UKSIM.2011.21
   Khan S. A., 2011, 2011 Proceedings of the IEEE 14th International Multitopic Conference (INMIC 2011), P25, DOI 10.1109/INMIC.2011.6151483
   Kim J, 2004, IEEE T PATTERN ANAL, V26, P131
   Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Mozaffari Saeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1192, DOI 10.1109/ICPR.2010.297
   O'Toole AJ, 1995, PERCEPTION FACE GEND
   OToole AJ, 1997, PERCEPTION, V26, P75, DOI 10.1068/p260075
   Ricanek K., 2009, BTAS, P1
   Vapnik V, The Nature of Statistical Learning Theory
   Wang Y, 2010, BTAS
   Wild HA, 2000, J EXP CHILD PSYCHOL, V77, P269, DOI 10.1006/jecp.1999.2554
   Wu J., 2007, INT C IM AN REC, P499
   Yang J, 2007, IEEE T SYST MAN CY B, V37, P1015, DOI [10.1109/TSMCB.2007.891541, 10.1109/TSMCB.2006.891541]
   Yang MH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P471, DOI 10.1109/ICIP.2000.899454
   Yang ZG, 2006, INT C PATT RECOG, P1099
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang B, NEUROCOMPUTING, V170, P221
   Zhang BC, 2016, INT J COMPUT VISION, V118, P364, DOI 10.1007/s11263-016-0880-y
   [赵海英 Zhao Haiying], 2012, [自动化学报, Acta Automatica Sinica], V38, P1544
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 44
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4491
EP 4503
DI 10.1007/s11042-016-3446-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200063
DA 2024-07-18
ER

PT J
AU Zhuang, KC
   Shen, HB
   Zhang, H
AF Zhuang, Kechen
   Shen, Haibo
   Zhang, Hong
TI User spread influence measurement in microblog
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spread influence; Information spreader; Ranking; Microblog
AB With the popular of online social network, the studies of information diffusion on social media also become very attractive direction. Knowing the influence of users and being able to predict it can be very helpful in enhancing or controlling the information diffusion process, where the identification of influential spreaders in online social network is very critical. In this paper, a novel method called SIRank is proposed to measure the spread influence of users in microblog, considering the user interaction features, retweet intervals, location of users in information cascades and other relevant features. By quantifying cascade structure influence and user interaction influence on information diffusion, the proposed methods uses random walk on microblog network, successfully ranked the users' spread influence. Experiments were conducted on an anonymous real microblog dataset, the results shown that our method can efficiently measure the users' spread influence, and perform better in both coverage and prediction comparison than other ranking methods.
C1 [Zhuang, Kechen; Shen, Haibo; Zhang, Hong] Nanjing Univ Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Zhuang, KC (corresponding author), Nanjing Univ Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
EM xjzkcgf@126.com
FU National Nature Science Foundation of China [61300053]
FX The work was sponsored by the National Nature Science Foundation of
   China under grant number 61300053.
CR [Anonymous], 1999, WWW 1999
   [Anonymous], 2011, P INT AAAI C WEB SOC
   [Anonymous], 2013, P 7 WORKSH SOC NETW
   Cha  M., 2010, ICWSM, P10
   Gayo-Avello D, 2013, INFORM PROCESS MANAG, V49, P1250, DOI 10.1016/j.ipm.2013.06.003
   Hajian B., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P497, DOI 10.1109/PASSAT/SocialCom.2011.118
   Herzig J., 2014, Proc. 25th ACM Conf. Hypertext Soc. media
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Kong SB, 2011, LECT NOTES ARTIF INT, V7120, P138
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   Majer T, 2012, LECT NOTES COMPUT SC, V7147, P518
   Pei-Ying Huang, 2013, Information Retrieval Technology. 9th Asia Information Retrieval Societies Conference, AIRS 2013. Proceedings: LNCS 8281, P368, DOI 10.1007/978-3-642-45068-6_32
   Tunkelang Daniel., 2009, A twitter analog to PageRank
   Xia Y., 2014, MULTIMED TOOLS APPL, P1
   Xin Jin, 2013, Journal of Networks, V8, P1543, DOI 10.4304/jnw.8.7.1543-1550
   Zhang ZY, 2013, SOC NETW ANAL MIN, V3, P969, DOI 10.1007/s13278-012-0078-4
NR 16
TC 11
Z9 12
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3169
EP 3185
DI 10.1007/s11042-016-3818-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200002
DA 2024-07-18
ER

PT J
AU Fazlali, HR
   Samavi, S
   Karimi, N
   Shirani, S
AF Fazlali, H. R.
   Samavi, S.
   Karimi, N.
   Shirani, S.
TI Adaptive blind image watermarking using edge pixel concentration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Robustness; Imperceptibility; Adaptive blind
   watermarking; Contourlet; DCT
ID COPYRIGHT PROTECTION; SCHEME
AB In recent years many methods for image watermarking have been proposed to overcome the growing concern of copyright protection. The goal of all these methods is to satisfy the tradeoff between two important characteristics of robustness and imperceptibility. In this paper an adaptive blind watermarking method in the Contourlet transform domain is proposed. In this method we apply a two-level Contourlet transform on the original image. The first level approximate image is partitioned into blocks. Using a novel edge detection algorithm, important edges of each block of the approximate image are detected and the entropy of each block is also computed. Then by concatenating some portions of the second level subbands we form blocks. These formed blocks are transformed into DCT domain. Watermark is embedded by modification of the DCT coefficients. The severity of the embedding is controlled depending on the complexity of the corresponding block in the approximate image. For higher robustness against attacks, we embedded the watermark redundantly and used voting mechanism in extraction stage. Experimental results reveal that our method has high robustness and acceptable imperceptibility.
C1 [Fazlali, H. R.; Karimi, N.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, S.; Shirani, S.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM samavi@mcmaster.ca
RI Karimi, Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Azizi S, 2013, IEEE INT CONF MULTI
   Cox I.J., 2002, DIGITAL WATERMARKING, V53
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Ghannam S, 2009, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2009.5414260
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hernández-Vela A, 2012, IEEE T INF TECHNOL B, V16, P1332, DOI 10.1109/TITB.2012.2220781
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Kaviani Hoda Rezaee, 2012, IEEE International Conference on Communications (ICC 2012), P6739, DOI 10.1109/ICC.2012.6364908
   Kaviani HR, 2011, MACHINE VISION IMAGE, P1, DOI DOI 10.1109/IRANIANMVIP.2011.6121618
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Meerwald P., 2001, INT SOC OPTICS PHOTO, VIII, P505
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Taherinia AH, 2009, INT J ELECTRON SECUR, V2, P280, DOI 10.1504/IJESDF.2009.027523
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 25
TC 25
Z9 27
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3105
EP 3120
DI 10.1007/s11042-015-3200-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000068
DA 2024-07-18
ER

PT J
AU Pan, SM
   Wen, RH
   Zhou, ZH
   Zhou, NR
AF Pan, Shu Min
   Wen, Ru Hong
   Zhou, Zhi Hong
   Zhou, Nan Run
TI Optical multi-image encryption scheme based on discrete cosine transform
   and nonlinear fractional Mellin transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-image encryption; Fractional Mellin transform; Discrete cosine
   transform
ID MULTIPLE-IMAGE ENCRYPTION; RANDOM-PHASE ENCRYPTION; FOURIER-TRANSFORM;
   ENCODING TECHNIQUE; ALGORITHM; DOMAIN; OPERATION; HOLOGRAPHY; MAPS
AB A new multi-image encryption scheme with an optical implementation based on the nonlinear fractional Mellin transform is proposed, which could avoid the vulnerability of the linear encryption systems and encrypt multiple images simultaneously. In the proposed scheme, the original images are transformed into spectra by the discrete cosine transform, then the spectra are incised and spliced into a composite spectrum, and finally the composite spectrum is performed by the nonlinear fractional Mellin transform to obtain the final encrypted image. After the processing of the fractional Mellin transform, amplitude encoding and phase encoding are adopted. The orders of the fractional Mellin transform are the main keys of this multi-image encryption scheme. Simulation results demonstrate the validity and the security of the proposed scheme.
C1 [Pan, Shu Min; Zhou, Nan Run] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Wen, Ru Hong] Yichun Univ, Coll Phys Sci & Technol, Yichun 336000, Peoples R China.
   [Zhou, Zhi Hong; Zhou, Nan Run] Shanghai Jiao Tong Univ, Shanghai Key Lab Integrate Adm Technol Informat S, Shanghai 200240, Peoples R China.
C3 Nanchang University; Yichun University; Shanghai Jiao Tong University
RP Zhou, NR (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.; Zhou, NR (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Integrate Adm Technol Informat S, Shanghai 200240, Peoples R China.
EM nrzhou@ncu.edu.cn
RI Zhou, Nanrun/HGC-4650-2022
FU National Natural Science Foundation of China [61262084, 61462061];
   Foundation for Young Scientists of Jiangxi Province (Jinggang Star)
   [20122BCB23002]; Natural Science Foundation of Jiangxi Province
   [20132BAB201019]; Opening Project of Shanghai Key Laboratory of
   Integrate Administration Technologies for Information Security
   [AGK2014004]; Innovation Project of Jiangxi Graduate Education
   [YC2015-S036, YC2014-S070]
FX This work was supported by the National Natural Science Foundation of
   China (grant nos. 61262084 and 61462061); the Foundation for Young
   Scientists of Jiangxi Province (Jinggang Star) (grant no.
   20122BCB23002), the Natural Science Foundation of Jiangxi Province
   (grant no. 20132BAB201019), the Opening Project of Shanghai Key
   Laboratory of Integrate Administration Technologies for Information
   Security (grant no. AGK2014004), and the Innovation Project of Jiangxi
   Graduate Education (grant nos. YC2015-S036 and YC2014-S070).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen W, 2012, J OPTICS-UK, V14, DOI 10.1088/2040-8978/14/7/075402
   Dai CQ, 2014, LASER PHYS LETT, V11, DOI 10.1088/1612-2011/11/7/075603
   Deepan B, 2014, APPL OPTICS, V53, P4539, DOI 10.1364/AO.53.004539
   Di H, 2012, APPL OPTICS, V51, P1000, DOI 10.1364/AO.51.001000
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Guo CL, 2014, OPT COMMUN, V321, P61, DOI 10.1016/j.optcom.2014.01.061
   Ji XY, 2015, COMMUN NONLINEAR SCI, V22, P321, DOI 10.1016/j.cnsns.2014.09.011
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Lee IH, 2014, J OPT SOC KOREA, V18, P401, DOI 10.3807/JOSK.2014.18.4.401
   Liu YF, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/795101
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Liu ZJ, 2012, OPT LASER ENG, V50, P1352, DOI 10.1016/j.optlaseng.2012.05.021
   Liu ZJ, 2012, OPTIK, V123, P428, DOI 10.1016/j.ijleo.2011.04.022
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   Ran QW, 2014, OPT LASER ENG, V62, P80, DOI 10.1016/j.optlaseng.2014.05.008
   Sazbon D, 2002, PATTERN RECOGN, V35, P2993, DOI 10.1016/S0031-3203(02)00018-3
   Sazbon D, 2000, INT C PATT RECOG, P132, DOI 10.1109/ICPR.2000.902881
   Shi XY, 2013, OPT COMMUN, V297, P32, DOI 10.1016/j.optcom.2013.01.072
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Wang Q, 2014, OPT COMMUN, V320, P12, DOI 10.1016/j.optcom.2014.01.041
   Wang Q, 2012, OPT COMMUN, V285, P4317, DOI 10.1016/j.optcom.2012.07.033
   Wang XG, 2012, OPT COMMUN, V285, P4280, DOI 10.1016/j.optcom.2012.06.061
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou NR, 2011, OPT COMMUN, V284, P5588, DOI 10.1016/j.optcom.2011.08.034
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 31
TC 40
Z9 41
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2933
EP 2953
DI 10.1007/s11042-015-3209-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000059
DA 2024-07-18
ER

PT J
AU Safaaldin, S
   Erçelebi, E
AF Safaaldin, Shaima
   Ercelebi, Ergun
TI A new teleconference system with a fast technique in HEVC coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; H.265; video/IP; Compression ratio; Reliable system
ID DECISION
AB Tele-Communications play an important role nowadays. Globalization has led the requirement for traversed communication. Therefore a multimedia system takes an influential act in the comprehensive communication between the regions. Teleconferencing became an indispensable element in any business system. A teleconference offers the collaborators the ability to participate in a group consultation by managing a virtual convention while residing in geographically scattered areas. It also increases productivity, minimizes travel expenses and saves travel time. This paper presents a new Reliable Teleconference system that utilizes an improved HEVC (H.265) coding technology as an adequate approach to enhance the real-time video/IP technology system with improving the video quality and enhancing the compression efficiency corresponding with the previous codec (H.264).
C1 [Safaaldin, Shaima; Ercelebi, Ergun] Al Nahrain Univ, Baghdad, Iraq.
   [Safaaldin, Shaima; Ercelebi, Ergun] Gaziantep Univ, Elect Elect Dept, Gaziantep, Turkey.
C3 Al-Nahrain University; Gaziantep University
RP Safaaldin, S (corresponding author), Al Nahrain Univ, Baghdad, Iraq.; Safaaldin, S (corresponding author), Gaziantep Univ, Elect Elect Dept, Gaziantep, Turkey.
EM eng_shaima1183@yahoo.com; ergun.ercelebi@gmail.com
RI Baha aldin, Shaima safa aldin/V-3616-2019; ERCELEBI, ERGUN/AAG-4831-2019
OI Baha aldin, Shaima safa aldin/0000-0003-0911-6934; ERCELEBI,
   ERGUN/0000-0002-4289-7026
CR BenHajyoussef A., 2014, INT J EMERGING TREND, V3, P223
   Chakareski J, 2008, IEEE T MULTIMEDIA, V10, P858, DOI 10.1109/TMM.2008.921846
   Chiang CK, 2011, IEEE T CIRC SYST VID, V21, P1304, DOI 10.1109/TCSVT.2011.2147250
   Choe S, 2013, IEEE T CIRCUITS SYST, V2, P1
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Frank B., 2012, IEEE T CIRCUITS SYST, V22, P13
   Jen R, 2012, IEEE T CIRCUITS SYST, V22, P10
   Jens R, 2012, IEEE T CIRCUITS SYST, V22
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Ma SW, 2014, IEEE T MULTIMEDIA, V16, P266, DOI 10.1109/TMM.2013.2284751
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shi W, 2015, J SIGNAL PROCES, V19, P67
   Teck K, 2006, P 3 INT C INF TECHN
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yang J, 2006, IMPL MULT VID C SOFT
   Ye Y, 2014, IEEE MULTIMEDIA, V21, P58, DOI 10.1109/MMUL.2014.47
   Yi-Fei X, 2013, INT J FUTURE COMPUT, V1, P4
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2013, ENTROPY-SWITZ, V15, P2277, DOI 10.3390/e15062277
NR 20
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1775
EP 1800
DI 10.1007/s11042-015-3131-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000008
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, SK
AF Singh, Durgesh
   Singh, Sanjay K.
TI DCT based efficient fragile watermarking scheme for image authentication
   and restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-embedding; Fragile watermarking; Image authentication; Image
   restoration
AB Due to rapid development of Internet and computer technology, image authentication and restoration are very essential, especially when it is utilized in forensic science, medical imaging and evidence of court. A quantization and Discrete Cosine Transform(DCT) based self-embedding fragile watermarking scheme with effective image authentication and restoration quality is proposed in this paper. In this scheme, the cover image is divided in size of 2x2 non-overlapping blocks. For each block twelve bits watermark are generated from the five most significant bits (MSBs) of each pixel and are embedded into the three least significant bits (LSBs) of the pixels corresponding to the mapped block. The proposed scheme uses two levels encoding for content restoration bits generation. The restoration is achievable with high PSNR and NCC up to 50 % tampering rate. The experimental results demonstrate that the proposed scheme not only outperforms high quality restoration effectively, but also removes the blocking artifacts and improves the accuracy of tamper localization due to use of very small size blocks.
C1 [Singh, Durgesh; Singh, Sanjay K.] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, D (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM durgeshcse@gmail.com; sks.cse@iitbhu.ac.in
RI Singh, Sanjay Prithviraj/IQV-1492-2023; Singh, Durgesh/AAZ-2801-2020;
   Singh, Sanjay Kumar/AAC-2031-2022; kumar, Sanjay/ITT-3680-2023
OI Singh, Sanjay Prithviraj/0000-0001-5043-8762; Singh,
   Durgesh/0000-0002-6078-1502; Singh, Sanjay Kumar/0000-0002-9061-6313; 
CR Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Cheng CJ, 2014, J DISP TECHNOL, V10, P263, DOI 10.1109/JDT.2013.2295619
   Cox IJ., 2007, DIGITAL WATERMARKING
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   He HJ, 2007, 2007 SECOND INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P216, DOI 10.1109/BICTA.2007.4806454
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Li XQ, 2012, INT CONF SIGN PROCES, P1697, DOI 10.1109/ICoSP.2012.6491907
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Riaz S, 2008, 2008 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES, PROCEEDINGS, P211, DOI 10.1109/ICET.2008.4777502
   Singh D., 2013, INTELLIGENT INTERACT, V10, P111, DOI DOI 10.1007/978-3-642-37463-0_10
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Song C, 2009, P POSTGR NETW S
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XL, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/249485
NR 24
TC 86
Z9 86
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 953
EP 977
DI 10.1007/s11042-015-3010-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000041
DA 2024-07-18
ER

PT J
AU Tao, SQ
   Wang, ST
   Chen, AH
AF Tao, Songqiao
   Wang, Shuting
   Chen, Anhui
TI 3D CAD solid model retrieval based on region segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region segmentation; Model retrieval; Face adjacency graph
ID MECHANICAL COMPONENTS; SIMILARITY ASSESSMENT; FEATURE RECOGNITION;
   FEATURES; DESIGN
AB 3D shape retrieval may find the existing models as reference for design reuse. 3D segmentation decomposes models into new elements with large granularity and salient shapes to replace the faces in a solid model. In this way, it may reduce the complexity of a CAD model and make a local salient shape more prominent. Therefore, a retrieval method for 3D CAD solid models based on region segmentation is proposed in this paper. To deal with the problems of poor efficiency and uncertain results, a three-step segmentation method for CAD solid models is introduced. First, face adjacency graph (FAG) descriptions for query models and data models are created from their B-rep models. Second, the FAGs are segmented into a set of convex, concave and planar regions, and the relations among the regions are represented with a region graph. Finally, the sub-graphs are combined recursively to form optimal region sub-graphs with respect to an objective function through an optimal procedure. To avoid using complex graph matching or sub-graph matching for model shape comparison, region property codes are introduced to represent face regions in a CAD model. The similarity between the two compared models is evaluated by comparing their region property codes. The experiments show that the proposed method supports 3D CAD solid model retrieval.
C1 [Tao, Songqiao; Chen, Anhui] Wuhan Tech Coll Commun, Wuhan 430065, Peoples R China.
   [Wang, Shuting] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, ST (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
EM wangst@mail.hust.edu.cn
RI Wang, Shuting/HQY-9992-2023; Tao, Songqiao/GSD-8971-2022
OI Wang, Shuting/0000-0002-2038-9979; 
FU National Natural Science Foundation of China [51275182]; Provincial Key
   Technologies R & D Program of Qinghai [2011-G-A5A]
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 51275182) and the Provincial Key Technologies R
   & D Program of Qinghai (Grants: 2011-G-A5A).
CR [Anonymous], ACM T GRAPHICS
   [Anonymous], 2007, Computer-Aided Design Applications, DOI DOI 10.1080/16864360.2007.10738515
   Bai J, 2010, COMPUT AIDED DESIGN, V42, P1069, DOI 10.1016/j.cad.2010.07.002
   Bespalov D, 2006, COMPUT AIDED DESIGN, V38, P1020, DOI 10.1016/j.cad.2006.07.005
   Biasotti S, 2008, PATTERN RECOGN, V41, P2855, DOI 10.1016/j.patcog.2008.02.003
   Biasotti S, 2006, COMPUT AIDED DESIGN, V38, P1002, DOI 10.1016/j.cad.2006.07.003
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Buchele SF, 2004, COMPUT AIDED DESIGN, V36, P1063, DOI 10.1016/j.cad.2004.01.006
   Cardone A., 2003, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V3, P109, DOI 10.1115/1.1577356
   Cardone A, 2006, COMPUT AIDED DESIGN, V38, P954, DOI 10.1016/j.cad.2006.08.001
   Chu CH, 2006, ROBOT CIM-INT MANUF, V22, P332, DOI 10.1016/j.rcim.2005.07.005
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6
   Fu MW, 2003, COMPUT AIDED DESIGN, V35, P979, DOI 10.1016/S0010-4485(02)00160-4
   GADH R, 1992, COMPUT AIDED DESIGN, V24, P583, DOI 10.1016/0010-4485(92)90070-Q
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gao S, 1998, COMPUT AIDED DESIGN, V30, P727, DOI 10.1016/S0010-4485(98)00033-5
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Jing W, 2014, J COMPUT INF SYST, V10, P4511
   Kazhdan M., 2003, P EUR S GEOM PROC
   Li M, 2009, J MECH DESIGN, V131, DOI 10.1115/1.4000253
   Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9
   Lu Y, 2001, COMPUT AIDED DESIGN, V33, P221, DOI 10.1016/S0010-4485(00)00122-6
   Ma LJ, 2010, COMPUT GRAPH-UK, V34, P545, DOI 10.1016/j.cag.2010.06.002
   Ma LJ, 2009, COMPUT AIDED DESIGN, V41, P952, DOI 10.1016/j.cad.2009.05.007
   Misher F, 2010, ACM T GRAPHIC, V29
   Misic M., 2014, 3D MESH SEGMENTATION
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Saber E, 2005, PATTERN RECOGN, V38, P1560, DOI 10.1016/j.patcog.2005.03.027
   Sakurai H, 1996, COMPUT AIDED DESIGN, V28, P519, DOI 10.1016/0010-4485(95)00067-4
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Shah J., 1994, Manufacturing Research and Technology, V20, P129, DOI 10.1016/B978-0-444-81600-9.50012-2
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Southi R., 1997, Proceedings. Fourth Symposium on Solid Modeling and Applications, P285
   Tao SQ, 2012, PATTERN RECOGN, V45, P1721, DOI 10.1016/j.patcog.2011.09.017
   Woo Y, 2002, COMPUT AIDED DESIGN, V34, P195, DOI 10.1016/S0010-4485(01)00080-X
   Zhang J, 2013, COMPUT AIDED DESIGN, V45, P1138, DOI 10.1016/j.cad.2013.04.003
NR 38
TC 15
Z9 15
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 103
EP 121
DI 10.1007/s11042-015-3033-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000006
DA 2024-07-18
ER

PT J
AU Zhou, ZP
   Zhou, MZ
   Li, J
AF Zhou, Zhiping
   Zhou, Mingzhu
   Li, Jing
TI Object tracking method based on hybrid particle filter and sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle filter; Sparse representation; Object tracking; Local spatial
   information; Local binary patterns
AB In order to solve the problem of complex environmental impact like illumination variation, appearance change and partial occlusion during the object tracking in the sequence images, a hybrid particle filter tracking method based on the global and local information was proposed. The Local Binary Patterns (LBP) textual feature was imported into the particle filter algorithm which uses local information of the target via sparse coding on local patches and combines the global information to determine the tracking object. In the procedure, the robustness of the tracking algorithm was improved since the template is updated on the time. Experimental results show that the proposed tracking algorithm exhibited good result in the presence of complex background and partial occlusion.
C1 [Zhou, Zhiping; Zhou, Mingzhu; Li, Jing] Jiangnan Univ, Dept Informat Technol, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Zhou, MZ (corresponding author), Jiangnan Univ, Dept Informat Technol, Wuxi 214122, Peoples R China.
EM zzping@jiangnan.edu.cn; 6141913003@vip.jiangnan.edu.cn;
   6121905018@vip.jiangnan.edu.cn
CR Baum M, 2014, IEEE T AERO ELEC SYS, V50, P149, DOI 10.1109/TAES.2013.120107
   Bousetouane F, 2013, VISUAL COMPUT, V29, P155, DOI 10.1007/s00371-012-0677-0
   Chen F, 2011, IMAGE VISION COMPUT, V29, P787, DOI 10.1016/j.imavis.2011.08.006
   Ho MC, 2012, PATTERN RECOGN LETT, V33, P500, DOI 10.1016/j.patrec.2011.11.019
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiayan L., 2010, INF ENG COMP SCI ICI, P1
   Karavasilis V, 2010, LECT NOTES ARTIF INT, V6040, P153, DOI 10.1007/978-3-642-12842-4_19
   Kim DY, 2014, INFORM SCIENCES, V278, P641, DOI 10.1016/j.ins.2014.03.080
   Kumar A, 2006, PATTERN RECOGN, P1279
   Lu XQ, 2013, PATTERN RECOGN, V46, P1762, DOI 10.1016/j.patcog.2012.11.016
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ristic B., 2004, ARTECH HOUSE RADAR, P1
   Rui T, 2013, NEUROCOMPUTING, V119, P125, DOI 10.1016/j.neucom.2012.03.036
   Su, 2013, INT J APPL MATH INF, V7, P193
   Su YY, 2014, PATTERN RECOGN, V47, P1826, DOI 10.1016/j.patcog.2013.11.028
   Tsagkatakis G, 2011, IEEE T CIRC SYST VID, V21, P1810, DOI 10.1109/TCSVT.2011.2133970
   Vijay AA, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1065, DOI 10.1109/ICCICCT.2014.6993118
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Xie CJ, 2014, J VIS COMMUN IMAGE R, V25, P423, DOI 10.1016/j.jvcir.2013.12.012
   [杨大为 Yang Dawei], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P680
   Yang Y, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55951
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhu JD, 2010, IEEE T CIRC SYST VID, V20, P223, DOI 10.1109/TCSVT.2009.2031395
NR 23
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2979
EP 2993
DI 10.1007/s11042-015-3211-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000061
DA 2024-07-18
ER

PT J
AU Ge, DY
   Yao, XF
   Lian, ZT
AF Ge, Dong-yuan
   Yao, Xi-fan
   Lian, Zhao-tong
TI Binocular vision calibration and 3D re-construction with an orthogonal
   learning neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binocular vision; System calibration; Eigen-value; Eigen-vector;
   Orthogonal learning; State transition matrix
ID CAMERA CALIBRATION; RECOGNITION; ALGORITHM; IMAGE
AB A new approach for binocular vision system calibration and 3D re-construction is proposed. While the system is calibrated, the sum of square distances between the vector coordinates recombined with the coordinates of feature points in the world frame and those in image frame to the fitted hyperplane is taken as an objective function. An orthogonal learning neural network is designed, where a self-adaptive minor component extracting method is adopted. When the network comes to equilibrium, the projective matrixes for the two cameras are obtained from the eigen-vectors of the autocorrelation matrix corresponding to the minimum eigen values, so the calibration of the binocular vision system is achieved. As for 3D re-construction, an autocorrelation matrix is obtained from feature point coordinates in image planes and calibration data, and an orthogonal learning network is designed. After the network is trained, the autocorrelation matrix's eigen-vector corresponding to the minimum eigen-values is obtained, from which the 3D coordinates are obtained also. The proposed approach is a novel application of minor component analysis and orthogonal learning network in binocular vision system and 3D re-construction.
C1 [Ge, Dong-yuan] Xiamen Univ, Tan Kah Kee Coll, Dept Mech & Elect Engn, Zhangzhou 363105, Fujian Province, Peoples R China.
   [Ge, Dong-yuan; Lian, Zhao-tong] Univ Macau, Fac Business Adm, Taipa, Macau, Peoples R China.
   [Yao, Xi-fan] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 Xiamen University; University of Macau; South China University of
   Technology
RP Ge, DY (corresponding author), Xiamen Univ, Tan Kah Kee Coll, Dept Mech & Elect Engn, Zhangzhou 363105, Fujian Province, Peoples R China.; Ge, DY (corresponding author), Univ Macau, Fac Business Adm, Taipa, Macau, Peoples R China.
EM gordon399@163.com; mexfyao@scut.edu.cn; lianzt@umac.mo
RI Yao, Xifan/ABB-1074-2021; Ge, Dong-yuan/AFQ-8688-2022
OI Yao, Xifan/0000-0002-2712-0411; Ge, dongyuan/0000-0002-9888-2202
FU National Natural Science Foundation of China [51175187]; Hunan
   Provincial Natural Science Foundation of China [09JJ6092]; Science &
   Technology Foundation of Guangdong Province [2013B021300023,
   2013B090600112]
FX Foundation item: The work described in this paper is partially supported
   by the National Natural Science Foundation of China (51175187), the
   Hunan Provincial Natural Science Foundation of China (09JJ6092), and the
   Science & Technology Foundation of Guangdong Province under grant Nos.
   2013B021300023 and 2013B090600112. The authors also gratefully
   acknowledge the suggestions of the reviewers, which helped to improve
   the presentation.
CR Bozic B, 2014, TEH VJESN, V21, P451
   Brandusa PA, 2011, INT J INNOV COMPUT I, V7, P745
   Chatterjee C, 1997, COMPUT VIS IMAGE UND, V67, P58, DOI 10.1006/cviu.1997.0516
   Chen SY, 2013, IEEE T IND INFORM, V9, P1680, DOI 10.1109/TII.2012.2221471
   [葛动元 Ge Dongyuan], 2010, [光电子·激光, Journal of Optoelectronics·Laser], V21, P1720
   Guillemaut JY, 2005, IEEE T PATTERN ANAL, V27, P265, DOI 10.1109/TPAMI.2005.41
   Kang JH, 2015, MULTIMED TOOLS APPL, V74, P259, DOI 10.1007/s11042-013-1758-4
   Khan MAU, 2012, INT J COMPUT COMMUN, V7, P302
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P1819, DOI 10.3233/IFS-141468
   Kung SY, 1990, P IEEE INT C AC SPEE, V2, P861
   Ma S.D., 1996, IEEE T ROBOT AUTOMAT, V12, P114, DOI DOI 10.1109/70.481755
   Miyagawa I, 2010, IEEE T IMAGE PROCESS, V19, P1528, DOI 10.1109/TIP.2010.2042118
   PALMIERI F, 1993, IEEE T NEURAL NETWOR, V4, P748, DOI 10.1109/72.248453
   Perez U, 2009, INT J ADV ROBOT SYST, V6, P35
   Rahman T, 2012, IEEE T IMAGE PROCESS, V21, P626, DOI 10.1109/TIP.2011.2164421
   Wang B, 2011, P I MECH ENG B-J ENG, V225, P901, DOI 10.1177/2041297510393513
   Yin F, 2015, IET COMPUT VIS, V9, P354, DOI 10.1049/iet-cvi.2013.0301
   Yuan YM, 2011, ACTA OPT SINICA, V31
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao ZX, 2012, MEAS SCI REV, V12, P104, DOI 10.2478/v10048-012-0013-x
   Zheng Y, 2014, IEEE T INTELL TRANSP, V15, P831, DOI 10.1109/TITS.2013.2288353
   Zhou JM, 2011, SENSOR LETT, V9, P1031, DOI 10.1166/sl.2011.1379
NR 22
TC 12
Z9 13
U1 3
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15635
EP 15650
DI 10.1007/s11042-015-2845-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700032
DA 2024-07-18
ER

PT J
AU Geng, N
   Ma, FF
   Yang, HJ
   Li, BY
   Zhang, ZY
AF Geng, Nan
   Ma, Fufeng
   Yang, Huijun
   Li, Boyang
   Zhang, Zhiyi
TI Neighboring constraint-based pairwise point cloud registration algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud registrations; Weighted sampling; Geometrical feature;
   Features similar degree; Iterative closest point (ICP)
ID ICP
AB Three-dimensional point cloud registration is important in reverse engineering. In this paper, we propose a registration method for large-scale 3D point clouds, which is based on neighborhood constraints of geometrical features. The method consists of initial and exact registration steps.In the process of initial registration, we define a new functon that measures feature similarity by calculating the distance function, and in the process of exact registration, we introduce the angle information that improve the accuracy of iterative closest point algorithm. Compared with the traditional feature-based and iterative closest point algorithms, our method significantly reduced the registration time by 11.9 % and has only 1 % of the registration error of the traditional feature-based algorithm. The proposed algorithm can be used to create efficient 3D models for virtual plant reconstruction and computer-aided design, and the registration results can provide a reference for virtual plant reconstruction and growth.
C1 [Geng, Nan; Ma, Fufeng; Yang, Huijun; Li, Boyang; Zhang, Zhiyi] Northwest A&F Univ YangLing, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China
RP Zhang, ZY (corresponding author), Northwest A&F Univ YangLing, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM zhangzhiyi@nwafu.edu.cn
RI Li, Fan/JRY-4017-2023; Li, Nan/IXD-8260-2023; zhang, ZY/HJH-6535-2023
OI yang, Huijun/0000-0002-4226-2493
FU National High Technology Research and Development Program of China (863
   Program) [2013AA102304]; Science and Technology Innovation Project
   [QN2013056, 2014YB067]
FX This work was partially supported by the National High Technology
   Research and Development Program of China (863 Program) (No.
   2013AA102304), Science and Technology Innovation Project (QN2013056),
   and Science and Technology Innovation Project (2014YB067).
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Cheng L, 2013, REMOTE SENS-BASEL, V5, P6260, DOI 10.3390/rs5126260
   Cheng Z.Q., 2008, VGPBG SIGGRAPH, P9
   [戴静兰 DAI Jinglan], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P517
   Daniels J, 2008, VISUAL COMPUT, V24, P449, DOI 10.1007/s00371-008-0223-2
   Diez Y, 2012, PATTERN RECOGN LETT, V33, P2127, DOI 10.1016/j.patrec.2012.07.006
   dos Santos DR, 2013, PHOTOGRAMM REC, V28, P276, DOI 10.1111/phor.12027
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Du SY, 2008, IEEE SIGNAL PROC LET, V15, P689, DOI 10.1109/LSP.2008.2001823
   Guan Y, 2008, J TONGJI U NATURAL S, V7
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Huang T, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.2.021114
   Hui-jun Yang, 2012, ICIC Express Letters, Part B: Applications, V3, P733
   Jiajing Dai, 2011, 2011 International Conference on Multimedia Technology, P6187
   Jiang J, 2009, NEUROCOMPUTING, V72, P3839, DOI 10.1016/j.neucom.2009.05.013
   Liao YJ, 2014, COMM COM INF SC, V474, P216
   Luo Xianbo, 2004, Journal of Tsinghua University (Science and Technology), V44, P1104
   Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0
   Oztireli AC, 2008, VISUAL COMPUT, V24, P679, DOI 10.1007/s00371-008-0248-6
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Weinmann M., 2011, Int Arch Photogramm Remote Sens Spat Inf Sci, V38, P1
   Wu Min, 2003, Journal of Nanjing University of Aeronautics & Astronautics, V35, P552
   Xie ZX, 2010, IMAGE VISION COMPUT, V28, P563, DOI 10.1016/j.imavis.2009.09.006
   [辛伟 Xin Wei], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P886
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Zhang Xue-chang, 2005, Computer Integrated Manufacturing Systems, V11, P727
   Zhang ZY, 2012, APPL OPTICS, V51, P1638, DOI 10.1364/AO.51.001638
   Zhu J, 2012, IET COMPUT VIS, V6, P252, DOI 10.1049/iet-cvi.2011.0178
   Zhu Yanjuan, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P475
NR 30
TC 10
Z9 17
U1 1
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16763
EP 16780
DI 10.1007/s11042-015-2941-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600003
DA 2024-07-18
ER

PT J
AU Kushwaha, AKS
   Srivastava, R
AF Kushwaha, Alok Kumar Singh
   Srivastava, Rajeev
TI Automatic moving object segmentation methods under varying illumination
   conditions for video data: comparative study, and an improved method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object segmentation; Comparative study; Performance analysis;
   Wavelet domain
ID BACKGROUND SUBTRACTION; TRACKING; MOTION; ALGORITHMS
AB In recent past, many moving object segmentation methods under varying lighting changes have been proposed in literature and each of them has their own benefits and limitations. The various methods available in literature for moving object segmentation may be broadly classified into four categories i.e., moving object segmentation methods based on (i) motion information (ii) motion and spatial information (iii) learning (iv) and change detection. The objective of this paper is two-fold i.e., firstly, this paper presents a comprehensive comparative study of various classical as well as state-of-the art methods for moving object segmentation under varying illumination conditions under each of the above mentioned four categories and secondly this paper presents an improved approximation filter based method in complex wavelet domain and its comparison with other methods under four categories mentioned as above. The proposed approach consist of seven steps applied on given video frames which include: wavelet decomposition of frames using Daubechies complex wavelet transform; use of improved approximate median filter on detail co-efficient (LH, HL, HH); use of background modeling on approximate co-efficient (LL sub-band); soft thresholding for noise removal; strong edge detection; inverse wavelet transformation for reconstruction; and finally using closing morphology operator. The qualitative and quantitative comparative study of the various methods under four categories as well as the proposed method is presented for six different datasets. The merits, demerits, and efficacy of each of the methods under consideration have been examined. The extensive experimental comparative analysis on six different challenging benchmark data sets demonstrate that proposed method is performing better to other state-of-the-art moving object segmentation methods and is well capable of dealing with various limitations of existing methods.
C1 [Kushwaha, Alok Kumar Singh; Srivastava, Rajeev] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Kushwaha, AKS (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM alok.rs.cse12@iitbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; KUSHWAHA, ALOK KUMAR
   SINGH/0000-0003-2928-998X
CR [Anonymous], INT WORKSH PATT REC
   [Anonymous], 2011, International Journal of Engineering Science and Technology
   [Anonymous], DAUB 10 LECT WAV
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Baradarani A., 2010, PATTERN RECOGN, P151
   Barak A, 2008, PSYCHOLOGICAL ASPECTS OF CYBERSPACE: THEORY, RESEARCH, APPLICATIONS, P1
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Butler D, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P349
   Cavallaro A., 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P141, DOI 10.1109/ISCAS.2001.921026
   Cheng F, 2010, ACM S APPL COMP LAUS
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861
   Di Stefano L, 2007, ACCV WORKSH MULT MUL
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Ellis Liam, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P52, DOI 10.1007/978-3-642-37444-9_5
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang JC, 2004, ELECTRON LETT, V40, P798, DOI 10.1049/el:20040534
   Huang JC, 2003, ELECTRON LETT, V39, P1380, DOI 10.1049/el:20030909
   Ivanov Y, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P49
   Jalal AS, 2012, MULTIMEDIA TOOLS APP
   Karmann K.-P., 1990, SIGNAL PROCESSING
   Kato J, 2002, IEEE T PATTERN ANAL, V24, P1291, DOI 10.1109/TPAMI.2002.1033221
   Khare A, 2010, IMAGING SCI J, V58, P340, DOI 10.1179/136821910X12750339175826
   Khare M, 2014, IET IMAGE PROCESS, V8, P334, DOI 10.1049/iet-ipr.2012.0428
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim M, 2001, IMAGE VISION COMPUT, V19, P245, DOI 10.1016/S0262-8856(00)00074-3
   Kushwaha AKS, 2014, IMAGING SCI J, V62, P285, DOI 10.1179/1743131X13Y.0000000056
   Kushwaha AKS, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P326, DOI 10.1109/ICIEV.2012.6317384
   Liu HH, 2006, IEEE INT SYMP CIRC S, P5027
   Liu MY, 2005, P SOC PHOTO-OPT INS, V5960, P160, DOI 10.1117/12.631537
   Luque R. M., 2008, 2008 8th International Conference on Hybrid Intelligent Systems (HIS), P613, DOI 10.1109/HIS.2008.130
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mahmoodi S, 2009, IEEE SIGNAL PROC LET, V16, P857, DOI 10.1109/LSP.2009.2025924
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Mei X, 2005, J ELECT, V22, P498
   Meier T, 1998, IEEE T CIRC SYST VID, V8, P525, DOI 10.1109/76.718500
   Meier T., 1988, THESIS
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Remagnino P., 1997, PROC BRIT MACHINE VI, P380
   Reza H., 2009, P INT C IT CEL S CHA, P251
   Shih MY, 2007, IEEE IC COMP COM NET, P1178
   Snidaro L, 2003, PATTERN RECOGN LETT, V24, P1533, DOI 10.1016/S0167-8655(02)00392-6
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Sridhar S., 2008, DIGITAL IMAGE PROCES
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wang H, 2005, IEEE INT WORKSH VIS
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xiaoyan Z., 2007, P IEEE INT S INT SIG, P272
   Yang Gao-Bo, 2004, Journal of Shanghai University, V8, P70, DOI 10.1007/s11741-004-0015-5
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 60
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16209
EP 16264
DI 10.1007/s11042-015-2927-4
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700061
DA 2024-07-18
ER

PT J
AU Nigam, S
   Khare, A
AF Nigam, Swati
   Khare, Ashish
TI Integration of moment invariants and uniform local binary patterns for
   human activity recognition in video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Uniform LBP; Moment invariants; SVM
ID SURVEILLANCE; SYSTEM; SCALE
AB In this study, we present a method for human activity recognition in video sequences. Human activities are often described by a holistic feature vector comprising of a set of local motion descriptors. Here, we use a novel local shape feature descriptor for human activity recognition which is an integration of moment invariants and uniform local binary patterns (MI_ULBP). This feature descriptor is passed to a binary support vector machine pattern classifier for classification of human activities. Activity recognition is achieved through probabilistic search of image feature database representing previously seen activities. Experiments are performed over four benchmark video datasets Weizmann, KTH, CASIA and Collective human activity. Visual results and quantitative comparisons with existing methods show that the proposed method gives better recognition of human activities in video sequences with varying backgrounds and viewpoints.
C1 [Nigam, Swati; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad 211002, Uttar Pradesh, India.
C3 University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad 211002, Uttar Pradesh, India.
EM swatinigam.au@gmail.com; ashishkhare@hotmail.com
RI Prakash, Om/AAL-4460-2021; Khare, Ashish/D-4566-2012; Nigam,
   Swati/GXG-0462-2022
OI Prakash, Om/0000-0001-6395-9989; Nigam, Swati/0000-0002-2629-8461
FU Council of Scientific and Industrial Research, Human Resource
   Development Group, India [09/001/(0362)/2012/EMR-I]
FX This work was supported by the Council of Scientific and Industrial
   Research, Human Resource Development Group, India via grant number
   09/001/(0362)/2012/EMR-I.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2014, ADV COMPUT SCI APPL
   [Anonymous], VIS COMPUT
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], SYSTEM VIDEO SURVEIL
   [Anonymous], 2013 INT C INF EL VI
   Baumann A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/824726
   Binh NT, 2014, P INT C CONT AW SYST, P209
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Cao H, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P331
   Chan M, 2008, COMPUT METH PROG BIO, V91, P55, DOI 10.1016/j.cmpb.2008.02.001
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Cheng ZW, 2014, NEUROCOMPUTING, V136, P124, DOI 10.1016/j.neucom.2014.01.019
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fletcher T., 2008, Support Vector Machines Explained
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Garibotto G, 2013, LECT NOTES COMPUT SC, V8157, P721, DOI 10.1007/978-3-642-41184-7_73
   Gonzàlez J, 2012, COMPUT VIS IMAGE UND, V116, P305, DOI 10.1016/j.cviu.2012.01.001
   Hosny KM, 2010, PATTERN RECOGN LETT, V31, P533, DOI 10.1016/j.patrec.2009.12.008
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Ko Byoung Chul, 2013, OPT ENG, V52
   Lahdenoja O, 2013, INT SCHOLARLY RES NO
   Lane ND, 2014, MOBILE NETW APPL, V19, P345, DOI 10.1007/s11036-013-0484-5
   Liu Yanan, 2014, Journal of Multimedia, V9, P92, DOI 10.4304/jmm.9.1.92-98
   Loy C. C., 2010, THESIS
   Maenpaa T., 2004, The local binary pattern approach to texture analysis: Extensions and applications
   Maenpaa T., 2005, Handbook of Pattern Recognition and Computer Vision, V3rd, P197
   Mattivi R, 2011, STUD COMPUT INTELL, V332, P69
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Nigam S, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P244
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Olaru A, 2013, MOBILE NETW APPL, V18, P429, DOI 10.1007/s11036-012-0408-9
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Pehlivan S, 2014, IMAGE VISIO IN PRESS
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Sacchi C, 2000, IEEE T VEH TECHNOL, V49, P2013, DOI 10.1109/25.892603
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shen JF, 2013, NEURAL COMPUT APPL, V23, P1937, DOI 10.1007/s00521-012-1153-5
   Skibbe H, 2012, IEEE T PATTERN ANAL, V34, P1563, DOI 10.1109/TPAMI.2011.263
   Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang YL., 2007, Sci. STKE, V2007, P1
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461
   Zhao YJ, 2012, IEEE SIGNAL PROC LET, V19, P692, DOI 10.1109/LSP.2012.2210040
NR 57
TC 26
Z9 27
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17303
EP 17332
DI 10.1007/s11042-015-3000-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600026
DA 2024-07-18
ER

PT J
AU Shin, D
   Lee, G
   Shin, D
   Shin, D
AF Shin, Dongmin
   Lee, Gwanghyung
   Shin, Dongil
   Shin, Dongkyoo
TI System architecture using human interaction markup language for context
   awareness in home network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural user interface; Human computer interaction; Middleware; Home
   network
ID ISSUES
AB As pervasive computing is developed, a user's context information will be used in a system to provide the user with intelligent services. Context is defined as information that characterizes the situation of an entity under a certain system environment. In this paper, we classify the context in a system into three types: user context, device context, and proximity context, which is the context information between a user and device. We designed HIML (Human Interaction Markup Language) to express the proposed contexts, and the middleware performed on various platforms, including a NUI/NUX (Natural User Interface/Natural User eXperience) platform, and interacted between appliances and sensors using HIML. We demonstrated its functions through experiments.
C1 [Shin, Dongmin; Lee, Gwanghyung; Shin, Dongil; Shin, Dongkyoo] Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
C3 Sejong University
RP Shin, D (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM gentletiger@gce.sejong.ac.kr; khlkhlll@gce.sejong.ac.kr;
   dshin@sejong.ac.kr; shindk@sejong.ac.kr
RI Shin, Dongil/AAB-3750-2021
OI Shin, Dongmin/0009-0002-6167-4327
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [NIPA-2013-H0301-13-4007]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2013-H0301-13-4007) supervised by the NIPA
   (National IT Industry Promotion Agency).
CR [Anonymous], J CONVERGENCE
   [Anonymous], J CONVERG
   Augusto JC, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-12
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   DEY AK, 1999, GITGVU9922 COLL COMP
   Dubey T, 2013, J INF PROCESS SYST, V9, P477, DOI 10.3745/JIPS.2013.9.3.477
   Hong JI, 2001, HUM-COMPUT INTERACT, V16, P287, DOI 10.1207/S15327051HCI16234_11
   Korpipää P, 2003, IEEE PERVAS COMPUT, V2, P42, DOI 10.1109/MPRV.2003.1228526
   Lee G, 2013, P FTRA 2013 INT S UB, P160
   Lee HR, 2013, J INF PROCESS SYST, V9, P237, DOI 10.3745/JIPS.2013.9.2.237
   Luo Y, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-2
   McNaull J, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/2192-1962-4-1
   Peng K, 2013, J INF PROCESS SYST, V9, P247, DOI 10.3745/JIPS.2013.9.2.247
   Rose B, 2001, IEEE COMMUN MAG, V39, P78, DOI 10.1109/35.968816
   Shafer SAN, 2001, HUM-COMPUT INTERACT, V16, P363, DOI 10.1207/S15327051HCI16234_16
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   Yoon M., 2013, J CONVERGENCE, V4, P15
NR 17
TC 1
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15199
EP 15209
DI 10.1007/s11042-014-2286-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700005
DA 2024-07-18
ER

PT J
AU Uh, Y
   Byun, H
AF Uh, Youngjung
   Byun, Hyeran
TI Multi-view 3D reconstruction by random-search and propagation with
   view-dependent patch maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview stereo; 3D reconstruction; Randomization and propagation
ID STEREO
AB This paper proposes an efficient multi-view 3D reconstruction method based on randomization and propagation scheme. Our method progressively refines a 3D model of a given scene by randomly perturbing the initial guess of 3D points and propagating photo-consistent ones to their neighbors. While finding local optima is an ordinary method for better photo-consistency, our randomization and propagation takes lucky matchings to spread better points replacing old ones for reducing the computational complexity. Experiments show favorable efficiency of the proposed method accompanied by competitive accuracy with the state-of-the-art methods.
C1 [Uh, Youngjung; Byun, Hyeran] Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
C3 Yonsei University
RP Byun, H (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM youngjun.uh@yonsei.ac.kr; hrbyun@yonsei.ac.kr
RI Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Uh, Youngjung/0000-0001-8173-3334
FU Institute for Information & communications Technology Promotion(IITP)
   grant - Korea government(MSIP) (Basic Software Research in Human-level
   Lifelong Machine Learning (Machine Learning Center)) [B0101-16-0307]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIP)
   (No. B0101-16-0307, Basic Software Research in Human-level Lifelong
   Machine Learning (Machine Learning Center))
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2010, INT J VIRTUAL REALIT
   [Anonymous], P IEEE C COMP VIS PA
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Besse F, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.132
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Bradley D., 2008, CVPR, P1
   Campbell Neill DF, 2008, EUR C COMP VIS, P766
   Chang JY, 2011, COMPUT VIS IMAGE UND, V115, P620, DOI 10.1016/j.cviu.2010.11.017
   Cui P, 2015, COMM COM INF SC, V546, P124, DOI 10.1007/978-3-662-48558-3_13
   Deng Y, 2012, IEEE J-STSP, V6, P566, DOI 10.1109/JSTSP.2012.2195472
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Goesele M., 2006, COMP VIS PATT REC 20, P2402, DOI DOI 10.1109/CVPR.2006.199
   Goesele M., 2007, P INT C COMP VIS ICC
   Heise P, 2013, P INT C COMP VIS ICC
   Hiep VH, 2009, PROC CVPR IEEE, P1430, DOI 10.1109/CVPRW.2009.5206617
   Jancosek Michal, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1526, DOI 10.1109/ICCVW.2009.5457432
   Jancosek M, 2009, COMP VISIONWINTERWOR
   Jancosek Michal, 2014, INT SCHOLARLY RES NO, V2014
   Kazhdan M, 2006, P SYMPD GEOM PROC
   Kolev K, 2010, LECT NOTES COMPUT SC, V6313, P538
   Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004
   MERRELL P, 2007, P INT C COMP VIS ICC
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pons JP, 2005, PROC CVPR IEEE, P822
   Rong G., 2006, P 2006 S INTERACTIVE, P109, DOI DOI 10.1145/1111411.1111431
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schning J, 2015, COMPUTER ANAL IMAGES
   Schroers C, 2012, ANISOTROPIC RANGE IM
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Strecha C, 2004, PROC CVPR IEEE, P552
   Strecha C., 2006, IEEE Conference on Computer Vision and Pattern Recognition, V2, P2394
   Stühmer J, 2010, LECT NOTES COMPUT SC, V6376, P11
   Tanskanen P, 2013, P INT C COMP VIS ICC
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   TYLECEK R, 2009, COMP VIS WINT WORKSH
   Uh Y, 2014, 3D VIS 3DV 2014 2 IN, V1
   Wu Changchang, 2013, P INT C 3D VIS
   Zaharescu A, 2008, WORKSH MULT MULT SEN
   Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166
NR 46
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16597
EP 16614
DI 10.1007/s11042-016-3621-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700076
DA 2024-07-18
ER

PT J
AU Chen, C
   Ji, W
   Rho, S
   Chen, BW
   Chen, YQ
AF Chen, Chao
   Ji, Wen
   Rho, Seungmin
   Chen, Bo-Wei
   Chen, Yiqiang
TI Evaluate mobile video quality in hybrid spatial and temporal domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Scalable video; Signal processing
ID CODING EXTENSION; IMAGES
AB Mobile video quality assessment plays an essential role in multimedia systems and services. In the case of scalable video coding, which enables dynamic adaptation based on terminal capabilities and heterogeneous network, variable resolution is one of the most prominent types of video distortions. In this paper, we propose a new hybrid spatial and temporal distortion metric for evaluating video streaming quality with variable spatio-temporal resolution. The key idea is to project video sequence into feature domain and calculate the distortion of content information from the projected principal component matrix and its eigenvectors. This metric can measures the degree of content information degradation especially in spatio-temporal resolution scalable video. The performance of the proposed metric is evaluated and compared to some state-of-the-art quality evaluation metrics in the literature. Our results show that the proposed metric achieves good correlations with the subjective evaluations of the EPFL scale video database.
C1 [Chen, Chao; Ji, Wen; Chen, Yiqiang] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
   [Chen, Bo-Wei] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Sungkyul University; Princeton University
RP Ji, W (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
EM jiwen@ict.ac.cn; smrho@sungkyul.ac.kr; dennisbwc@gmail.com;
   yqchen@ict.ac.cn
RI Chen, Bowei/AAB-7002-2021; Rho, Seungmin/HTP-6683-2023
OI Chen, Bowei/0000-0002-4045-3253; 
FU National Natural Science Foundation of China [61572466]
FX This work is supported by the National Natural Science Foundation of
   China (61572466).
CR [Anonymous], 2010, PERC VID QUAL MEAS T
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], JVTQ083
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Chan CW, 2008, IEEE T MULTIMEDIA, V10, P1671, DOI 10.1109/TMM.2008.2007285
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Ji W, 2011, MULT EXP ICME 2011 I, P1
   Ji W, 2010, C ACM MULT 2010 OCT, V2010, P1223
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Li Z, 2005, IEEE T IMAGE PROCESS, V14, P1550, DOI 10.1109/TIP.2005.854477
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sohn H, 2010, IEEE T BROADCAST, V56, P269, DOI 10.1109/TBC.2010.2050628
   Sun S, JVTR006
   Vranjes D, 2013, ELMAR, P287
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Wang Y, 2005, IEEE T CIRC SYST VID, V15, P1270, DOI 10.1109/TCSVT.2005.854224
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2003, IEEE AS C SIGN SYST, P9
   Wulf S, 2013, SIG P ALGO ARCH ARR, P26
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
NR 25
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14507
EP 14524
DI 10.1007/s11042-015-2992-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500030
DA 2024-07-18
ER

PT J
AU Chu, HC
   Yin, MH
   Hsu, CH
   Park, JH
AF Chu, Hai-Cheng
   Yin, Ming-Hao
   Hsu, Ching-Hsien
   Park, Jong Hyuk
TI The disclosure of evaporating digital trails respecting the combinations
   of Gmail and IE for pervasive multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evaporating digital trails; Incident response team; Instant message; Web
   browser forensics; Cloud computing; Next generation cyberspace security
ID FORENSICS; MEMORY
AB Unquestionably, the proliferation of mobile devices has dominated the main streams in contemporary ubiquitous wireless networks. Unfortunately, the misappropriating of those state-of-the-art gadgets has resulted in unprecedented information security issues in next generation cyberspace security arena. This paper illustrates the essence of generic procedures to provide the probative digital evidences for a typical Gmail Chat session in connection with the IE browser under different scenarios. When the computer-related information security issues arise with regard to the company, the corporate information incident response team should be able to disclose and preserve the evaporating digital trails following the right procedures to avoid the volatile characteristics in their natures. Furthermore, the design of the experiments of the paper identifies four cases to demonstrate the feasibility, availability, reliability, and traceability among them, which are essential for the corporate information security staffs to seriously consider when mushrooming cyber crimes are unknowingly and hastily burgeoning in an unparalleled manner. The organizations might have to scrutinize the negligible digital trails with cognitive expertise instead of entirely relying on law enforcement agencies from the public sectors due to the time constraints as well as publicity concerns or the minor computing resource policy violation unwarily occurred by the employees accordingly.
C1 [Chu, Hai-Cheng] Natl Taichung Univ Educ, Dept Int Business, 140 Min Shen Rd, Taichung 40306, Taiwan.
   [Yin, Ming-Hao] Northeast Normal Univ, Sch Comp Sci & Informat Technol, Changchun 130024, Jilin Province, Peoples R China.
   [Hsu, Ching-Hsien] ChungHua Univ, Dept Comp Sci & Informat Engn, Hsinchu 30012, Taiwan.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, 172 Gongneung Dong 2, Seoul 139743, South Korea.
C3 National Taichung University of Education; Northeast Normal University -
   China; Chung Hua University; Seoul National University of Science &
   Technology
RP Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, 172 Gongneung Dong 2, Seoul 139743, South Korea.
EM hcchu@mail.ntcu.edu.tw; ymh@nenu.edu.cn; chh@chu.edu.tw;
   parkjonghyuk1@hotmail.com
RI Yin, Minghao/E-9611-2015; Hsu, Ching-Hsien/AAE-6917-2020
OI Yin, Minghao/0000-0002-6226-2394; 
FU National Taichung University of Education, Taiwan [NTCU-F102104]; MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the ITRC
   (Information Technology Research Center) support program
   [NIPA-2014-H0301-14-4007]
FX The authors would like to acknowledge the funding support of National
   Taichung University of Education, Taiwan, of the research grant of
   Project NTCU-F102104. This research was also supported by the MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the ITRC
   (Information Technology Research Center) support program
   (NIPA-2014-H0301-14-4007) supervised by the NIPA (National IT Industry
   Promotion Agency).
CR Cassidy RF, 2008, INT FED INFO PROC, V253, P223
   Chang-Lung Tsai, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P645
   Chu HC, 2011, IEEE J SEL AREA COMM, V29, P1368, DOI 10.1109/JSAC.2011.110804
   Chung H, 2012, DIGIT INVEST, V9, P81, DOI 10.1016/j.diin.2012.05.015
   Dezfouli F.N., 2012, Proc. 2012 Int. Conf. Cyber Secur. Cyber Warf. Digit. Forensic, P186, DOI DOI 10.1109/CYBERSEC.2012.6246108
   Kim Y., 2012, Journal of Computational Science Education, V3, P47, DOI DOI 10.22369/ISSN.2153-4136/3/1/6
   Lee J, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1377
   Oh J, 2011, DIGIT INVEST, V8, pS62, DOI 10.1016/j.diin.2011.05.008
   Ruan K., 2011, IFIP INT C DIGITAL F, P35, DOI [DOI 10.1007/978-3-642-24212-0_3, 10.1007/978-3-642-24212-03]
   Ruan K, 2012, IFIP ADV INF COMM TE, V383, P201
   Sharma MJ, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-16
   Simon M, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P283, DOI 10.1109/ARES.2010.73
   Sorensen LT, 2009, WIRELESS PERS COMMUN, V51, P811, DOI 10.1007/s11277-009-9770-8
   Subashini S, 2011, J NETW COMPUT APPL, V34, P1, DOI 10.1016/j.jnca.2010.07.006
   Sylve J, 2012, DIGIT INVEST, V8, P175, DOI 10.1016/j.diin.2011.10.003
   Taylor Mark, 2011, Network Security, V2011, P4, DOI 10.1016/S1353-4858(11)70024-1
   Thing VLL, 2010, DIGIT INVEST, V7, pS74, DOI 10.1016/j.diin.2010.05.010
   Wu B, 2013, RECOVERY APPROACH SQ, V7804, P295
   Yen YS, 2011, DIGIT INVEST, V8, P56, DOI 10.1016/j.diin.2011.03.003
   Yoo DS, 2010, J INF PROCESS SYST, V6, P501, DOI 10.3745/JIPS.2010.6.4.501
NR 20
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14039
EP 14055
DI 10.1007/s11042-014-2194-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500003
DA 2024-07-18
ER

PT J
AU Kang, S
   Hwang, J
   Kim, J
   Heo, N
AF Kang, Sanggil
   Hwang, Jaemin
   Kim, Jeonghyuk
   Heo, Nojeong
TI Design of database for evaluating 3D audio core algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D audio evaluation database; 3D core algorithm; XML; DBMS
ID SOURCE SEPARATION
AB In this paper, we develop 3D audio evaluation database (DB) for verifying performance of new developed 3D audio core algorithms such as sound source localization, artificial reverberation, source separation, and crosstalk cancellation. Our system is designed to evaluate the 3D audio core algorithms automatically. Conventional evaluation DBs have to be executed manually for evaluating audio systems because the audio sources are not indexed in general. To solve this problem, we propose the architecture of 3D audio core algorithm evaluation database using database management system (DBMS). In the experimental section, we show feasibility of our system using real 3D sound sources for sound source separation algorithm.
C1 [Kang, Sanggil; Hwang, Jaemin; Kim, Jeonghyuk] Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
   [Heo, Nojeong] Dongyang Univ, Dept Informat & Commun Engn, Yeongju, South Korea.
C3 Inha University
RP Kang, S (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
EM sgkang@inha.ac.kr
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [NIPA-2013-H0301-13-4005]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2013-H0301-13-4005) supervised by the NIPA
   (National IT Industry Promotion Agency)
CR [Anonymous], 2001, IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, DOI [DOI 10.1109/ASPAA.2001.969552, 10.1109/ASPAA.2001.969552]
   [Anonymous], J CONVERG
   Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307
   Cupala S, 2007, US Patent, Patent No. [20070061706 A1, 20070061706]
   Folstad A, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-18
   Gardner Bill, 1994, HRFT Measurements of a KEMAR Dummyhead Microphone
   Goto M., 2003, P 4 INT C MUS INF RE, P229
   GRIBONVAL R, 2003, 4 INT S IND COMP AN
   Gupta Navarun., 2010, INT CONF ACOUST SPEE, DOI DOI 10.1109/ICASSP.2010.5496084
   Huang Y-P, 2012, J CONVERG, V3, P1
   Jeub M, 2009, I COMMUN SYST DATA P, DOI [10.1109/ICDSP.2009.5201259, DOI 10.1109/ICDSP.2009.5201259]
   Jot J.-M., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P221, DOI 10.1109/ICASSP.1992.226080
   Kulkarni A, 1998, NATURE, V396, P747, DOI 10.1038/25526
   Lee Siijeong, 2005, I ELECT INF ENG, V42, P159
   Macnamara J, 2010, MEDIA INT AUST, P20, DOI 10.1177/1329878X1013700104
   Nakamura Satoshi, 2000, LREC
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Silla Jr CN, 2002, LATIN MUSIC DATABASE
   Stewart R, 2010, P IEEE INT C AC SPEE
   Vincent E, 2007, LECT NOTES COMPUT SC, V4666, P552
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wen J. Y. C., 2006, INT WORKSH AC ECH NO
   Zhu C, 2013, J INF PROCESS SYST, V9, P511, DOI 10.3745/JIPS.2013.9.4.511
NR 24
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14181
EP 14196
DI 10.1007/s11042-015-2679-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500011
DA 2024-07-18
ER

PT J
AU Kim, S
   Kim, SK
AF Kim, SeongKi
   Kim, Seok-Kyoo
TI Comparison of OpenCL and RenderScript for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPGPU; OpenCL; RenderScript; Mobile device; Parallel processing
AB With the recent advances in the programmability and performance of mobile Graphics Processing Units (GPUs), General-Purpose Graphics Processing Unit (GPGPU) technologies have become available even in mobile devices such as smartphones and tablets. Among the available GPGPU technologies for mobile devices, Open Computing Language (OpenCL) and RenderScript are used to accelerate applications in various fields such as computer graphics, image processing/recognition, and computer vision. For example, these technologies are used for detecting collisions and edges, processing data from a camera, recognizing an object in an image, processing the images stored on a device, and accelerating the drawing of an image when live wallpaper is used in Android-based devices. These technologies increase the processing speed as well as reduce the power consumption of mobile devices. In addition to these general applications, they have great potential for use in the optimizing algorithms of scientific fields. This paper describes GPGPU technologies for mobile devices, compares their similarities and differences, and compares their performance for further research purposes. To the best of our knowledge, this paper is the first work that compares and analyzes available GPGPU technologies for mobile devices.
C1 [Kim, SeongKi] Ewha Womans Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Kim, Seok-Kyoo] Sangmyung Univ, Dept Game Design & Dev, Seoul, South Korea.
C3 Ewha Womans University; Sangmyung University
RP Kim, S (corresponding author), Ewha Womans Univ, Dept Comp Sci & Engn, Seoul, South Korea.; Kim, SK (corresponding author), Sangmyung Univ, Dept Game Design & Dev, Seoul, South Korea.
EM skkim9226@gmail.com; skkim@smu.ac.kr
RI Kim, SeongKi/K-2774-2019
OI Kim, SeongKi/0000-0002-2664-3632; Kim, Seok-Kyoo/0000-0003-4725-0288
FU NRF in Korea [2015R1C1A1A01051839]
FX This work was supported by NRF in Korea (2015R1C1A1A01051839). Seok-Kyoo
   Kim is the corresponding author.
CR [Anonymous], 1999, 98991999 ISOIEC
   [Anonymous], J CONVERGENCE
   Bray T, 2011, INTRO RENDERSCRIPT
   Chang SM, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-14
   Ehringer D., 2010, TECHN REPORT, V4, P72
   Ghimire D, 2013, J INF PROCESS SYST, V9, P141, DOI 10.3745/JIPS.2013.9.1.141
   Hines S, 2011, LLVM DEV M
   Hsueh HY, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-7
   Manh HT, 2013, J INF PROCESS SYST, V9, P592, DOI 10.3745/JIPS.2013.9.4.592
   Kemp R, 2013, P 1 EUR WORKSH MOB E, P305
   Liu S L, 2011, MCHNR DGN MFR, V6, P1
   Malkawi M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-3
   Munshi A., 2009, OPENCL SPECIFICATION
   Munshi A, 2010, OPENGLES COMMON PROF
   Udayan JD, 2013, J CONVERG, V4, P6
   Verma OP, 2013, J INF PROCESS SYST, V9, P575, DOI 10.3745/JIPS.2013.9.4.575
   Wang GH, 2013, INT CONF ACOUST SPEE, P2629, DOI 10.1109/ICASSP.2013.6638132
   Yang CY, 2012, IEEE SYM EMBED SYST, P67, DOI 10.1109/ESTIMedia.2012.6507031
   Yang X., 2013, J CONVERG, V4, P11
   Zhang XY, 2014, IEEE T VIS COMPUT GR, V20, P447, DOI 10.1109/TVCG.2013.239
NR 20
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14161
EP 14179
DI 10.1007/s11042-016-3244-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500010
DA 2024-07-18
ER

PT J
AU Shahzad, A
   Lee, M
   Lee, C
   Xiong, NX
   Kim, S
   Lee, YK
   Kim, K
   Woo, SM
   Jeong, G
AF Shahzad, Aamir
   Lee, Malrey
   Lee, Changhoon
   Xiong, Naixue
   Kim, Suntae
   Lee, Young-Keun
   Kim, Kangmin
   Woo, Seon-mi
   Jeong, Gisung
TI The protocol design and New approach for SCADA security enhancement
   during sensors broadcasting system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervisory control and data acquisition; SCADA Broadcasting system;
   Distributed network protocol; Cryptography dynamic buffer; Cryptography
   mechanisms
ID ENCRYPTION SCHEMES; ATTACKS
AB Several security mechanisms have been investigated and deployed that provide protection for real time platforms. Each security mechanism is contributed to enhance the SCADA system security, but at the same time, the mechanism is limited and depended on the other protocols for the purposes of message security, and its delivery. Few researches are conducted on security for SCADA broadcasting system, but these are limited to end-to-end designs and developments. The security developments for multicasting and broadcasting systems are much complicated, time consumed and/or overloaded with the cryptography mechanisms. After conducting the detail survey, a simulation environment for SCADA water pumping system is designed in-which number of nodes is configured and well known cryptography algorithms are selected, and deployed as an inclusive development for SCADA/DNP3 broadcasting system. The inclusive security development is considered with the best performance, and with predominant weakness in mind, which are present in SCADA/DNP3 broadcasting system. However, overall communication is initiated, monitored and controlled at main controller side with the user defined human machine interface (HMI).
C1 [Shahzad, Aamir; Lee, Malrey] Chon Buk Natl Univ, Sch Elect & Informat Engn, Ctr Adv Image & Informat Technol, M561-756,664-14,1Ga, Jeonju, Chon Buk, South Korea.
   [Lee, Changhoon] Seoul Natl Univ Sci & Technol SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
   [Xiong, Naixue] Colorado Tech Univ, Sch Comp Sci, Colorado Springs, CO USA.
   [Kim, Suntae] Chon Buk Natl Univ, Dept Software Engn, M561-756,664-14,1Ga, Jeonju, Chon Buk, South Korea.
   [Lee, Young-Keun] Chonbuk Natl Univ Hosp, Dept Orthoped Surg, M561-756, Jeonju, South Korea.
   [Kim, Kangmin] Chonbuk Natl Univ, Div Biotechnol, Coll Environm & Bioresource Sci, M570-752, Iksan 570752, South Korea.
   [Woo, Seon-mi] JINI Co Ltd, M561-756,B-102 Technobill,109 Banryong Load, Jeonju Si, Jeollabuk Do, South Korea.
   [Jeong, Gisung] WonKwang Univ, Dept Fire Serv Adm, M561-756, Iksan, South Korea.
C3 Jeonbuk National University; Seoul National University of Science &
   Technology; Colorado Technical University; Jeonbuk National University;
   Jeonbuk National University; Jeonbuk National University Hospital;
   Jeonbuk National University; Wonkwang University
RP Lee, M (corresponding author), Chon Buk Natl Univ, Sch Elect & Informat Engn, Ctr Adv Image & Informat Technol, M561-756,664-14,1Ga, Jeonju, Chon Buk, South Korea.; Kim, K (corresponding author), Chonbuk Natl Univ, Div Biotechnol, Coll Environm & Bioresource Sci, M570-752, Iksan 570752, South Korea.
EM mail2aamirshahzad@gmail.com; mrlee@jbnu.ac.kr; xiongnaixue@gmail.com;
   stkim@jbnu.ac.kr; trueyklee@naver.com; activase@jbnu.ac.kr;
   smwoo@jbnu.ac.kr; jgskor@wku.ac.kr
RI xiong, naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635; Lee, Changhoon/0000-0003-4292-5792
FU next generation information computing development program through the
   national research foundation of Korea; ministry of science, ICT & Future
   Planning [2012M3C4A7033348]
FX This research was supported by next generation information computing
   development program through the national research foundation of Korea,
   and funded by the ministry of science, ICT & Future Planning
   (2012M3C4A7033348).
CR [Anonymous], 1999, LNCS, DOI DOI 10.1007/3-540-48405-1_34
   Arango IM, 2014, PROCEDIA ENGINEER, V89, P488, DOI 10.1016/j.proeng.2014.11.241
   Benrhouma O, 2015, MULTIMED TOOLS APPL, V74, P3617, DOI 10.1007/s11042-013-1790-4
   Bhattacherjee S, 2013, DESIGN CODE CRYPTOGR, V66, P335, DOI 10.1007/s10623-012-9702-6
   Chen HC, 2013, SECUR COMMUN NETW, V6, P100, DOI 10.1002/sec.536
   Cho EJ, 2013, SENSORS-BASEL, V13, P15863, DOI 10.3390/s131215863
   Clarke D. Reynders, 2004, PRACTICAL MODERN SCA
   Coates GM, 2008, IEEE T POWER SYST, V23, P831, DOI 10.1109/TPWRS.2008.926456
   Coates GM, 2010, IEEE T POWER DELIVER, V25, P158, DOI 10.1109/TPWRD.2009.2034830
   Davis C.M., 2006, NORTH AMER POW SYMP, P483, DOI DOI 10.1109/NAPS.2006.359615
   El Mrabet N, 2015, CRYPTOGR COMMUN, V7, P185, DOI 10.1007/s12095-014-0114-5
   Gentry C, 2009, LECT NOTES COMPUT SC, V5479, P171, DOI 10.1007/978-3-642-01001-9_10
   Ghazizadeh E, 2014, SCI WORLD J, DOI 10.1155/2014/260187
   Gu CS, 2014, SECUR COMMUN NETW, V7, P2432, DOI 10.1002/sec.954
   Herbert F, 2008, POW EN SOC GEN M CON, DOI [10.1109/PES.2008.4596335, DOI 10.1109/PES.2008.4596335]
   Hong S, 2010, ASIA-PAC POWER ENERG
   Jang U, 2014, SYMMETRY-BASEL, V6, P1011, DOI 10.3390/sym6041011
   Kang D-J., 2009, Transm. Distrib. Conf. Expos.: Asia Pac, V2009, P1, DOI [10.1109/TD-ASIA.2009.5357008, DOI 10.1109/TD-ASIA.2009.5357008]
   Kang H. M. Kim., 2007, FGCN 07 P FUT GEN CO, V02, DOI [10.1109/FGCN.2007.36, DOI 10.1109/FGCN.2007.36]
   Khalil IM, 2014, COMPUTERS, V3, P1, DOI 10.3390/computers3010001
   Kim I, 2013, SENSORS-BASEL, V13, P3998, DOI 10.3390/s130403998
   Kim J, 2015, IEEE T INF FOREN SEC, V10, P679, DOI 10.1109/TIFS.2014.2388156
   Kiuchi M., 2009, ICCAS SICE
   Krajewski J, 2014, SCHNEIDER ELECT, V2014, P1
   Lee CM, 2015, MULTIMED TOOLS APPL, V74, P1689, DOI 10.1007/s11042-014-2014-2
   Moon D, 2014, SYMMETRY-BASEL, V6, P997, DOI 10.3390/sym6040997
   Musa S., 2013, P 7 INT C UB INF MAN, P1
   Nikolic I, 2015, CRYPTOGR COMMUN, V7, P331, DOI 10.1007/s12095-014-0118-1
   Obaidat MS, 2014, SECUR COMMUN NETW, V7, P376, DOI 10.1002/sec.731
   Patel SC, 2009, COMMUN ACM, V52, DOI 10.1145/1538788.1538820
   Premnath AP, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P341, DOI 10.1109/ITNG.2014.38
   Risley J. Roberts, 2003, ELECT SECURITY REAL
   Robles RJ, 2011, COMM COM INF SC, V223, P19
   Robles RJ, 2012, INFORMATION-TOKYO, V15, P1241
   Robles RJ, 2010, COMM COM INF SC, V74, P56
   Saxena A, 2011, COMM COM INF SC, V142, P56
   Saxena O. Pal, 2011, INT J DISTRIBUTED PA, V2
   Shahzad A, 2014, J APPL SCI, DOI [10.3923/jas.2014.2487.24, DOI 10.3923/JAS.2014.2487.24]
   Sommestad T, 2010, IEEE POW ENER SOC GE
   Stouffer J. F. K. K. Keith, 2006, GUIDE SUPERVISORY CO
   Wang Chunlei, 2010, 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P342, DOI 10.1109/ICMTMA.2010.603
   Yoo H, 2015, MULTIMED TOOLS APPL, V74, P303, DOI 10.1007/s11042-014-1870-0
   Yun Jeong-Han, 2013, INT J CONTROL AUTOMA, V6
   Zhang YP, 2012, SECUR COMMUN NETW, V5, P422, DOI 10.1002/sec.331
   Zhu WT, 2013, J NETW COMPUT APPL, V36, P178, DOI 10.1016/j.jnca.2012.09.007
NR 45
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14641
EP 14668
DI 10.1007/s11042-015-3050-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500038
DA 2024-07-18
ER

PT J
AU Howell, MJ
   Herrera, NS
   Moore, AG
   McMahan, RP
AF Howell, Michael J.
   Herrera, Nicolas S.
   Moore, Alec G.
   McMahan, Ryan P.
TI A reproducible olfactory display for exploring olfaction in immersive
   media experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Olfaction; Olfactory display; Immersive media; Presence; Training
ID VIRTUAL-REALITY; MEMORY; ENVIRONMENT; SIMULATION; CUES
AB Olfaction, the sense of smell, is an important perceptual function. It has been shown to enhance the quality of life and to facilitate memory recall. However, despite its importance and potential benefits, olfaction is often neglected when creating immersive media experiences (IMEs). The probable reason is that olfactory displays are not readily available. We have developed a reproducible olfactory display that is simple and affordable to make olfactory displays more available. More importantly, we have conducted three exploratory studies on the effects of olfaction. The results of these studies indicate that olfaction is a nuanced sense that can have both positive and negative effects on user experiences. Hence, further research is needed to better understand and design for olfaction in IMEs.
C1 [Howell, Michael J.; Herrera, Nicolas S.; Moore, Alec G.; McMahan, Ryan P.] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Dallas
RP McMahan, RP (corresponding author), Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
EM rymcmaha@utdallas.edu
OI McMahan, Ryan/0000-0001-9357-9696
CR Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   Bink M, 2013, INT IND TRAIN SIM ED
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   CANN A, 1989, AM J PSYCHOL, V102, P91, DOI 10.2307/1423118
   D'Cruz M., 1999, Structured evaluation of training in virtual environments
   Danthiir V, 2001, INTELLIGENCE, V29, P337, DOI 10.1016/S0160-2896(01)00061-7
   Dinh HQ, 1999, IEEE VIRT REAL VR
   Ekstrom R.B., 1976, KIT FACTORREFERENCED
   Gallace Alberto, 2012, Multiple sensorial media advances and applications, P1, DOI DOI 10.4018/978-1-60960-821-7.CH001
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071398
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379794
   Ghinea G, 2010, IEEE T SYST MAN CY A, V40, P657, DOI 10.1109/TSMCA.2010.2041224
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Hamblin C.J., 2005, Transfer of training from virtual reality environments
   Hays R. T., 1992, MIL PSYCHOL, V4, P63, DOI DOI 10.1207/S15327876MP0402_1
   Herrera NS, 2014, ACM INT WORKSH IMM M
   Herz RS, 1996, PSYCHON B REV, V3, P300, DOI 10.3758/BF03210754
   Herz RS, 1997, MEM COGNITION, V25, P375, DOI 10.3758/BF03211293
   Johnson J, 2010, DESIGNING WITH THE MIND IN MIND: SIMPLE GUIDE TO UNDERSTANDING USER INTERFACE DESIGN RULES, P1, DOI 10.1016/B978-0-12-375030-3.00001-6
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Kadowaki A, 2010, IEEE INT S APPL INT
   Khan K, 2011, MED TEACH, V33, P1, DOI 10.3109/0142159X.2010.519412
   Lai C, 2015, 37 INT S APPL COMP O
   Lee A.T., 2005, Flight simulation: virtual environments in aviation
   Lucas J, 2008, 1 INT FUT MIN C
   Matsukura H, 2013, IEEE T VIS COMPUT GR, V19, P606, DOI 10.1109/TVCG.2013.40
   McMahan R., 2010, Extracting the Science: A Century of Mining Research, P520
   McMahan RP, 2008, AUSTRALAS I MIN MET, P167
   Miwa T, 2001, ARCH OTOLARYNGOL, V127, P497, DOI 10.1001/archotol.127.5.497
   Murray N, 2013, IEEE INT CON MULTI
   Murray N, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2540994
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   Nordin S, 2003, ACTA OTO-LARYNGOL, V123, P536, DOI 10.1080/00016480310001411
   Pointer SC, 1998, CHEM SENSES, V23, P359, DOI 10.1093/chemse/23.3.359
   Raij AB, 2007, IEEE T VIS COMPUT GR, V13, P443, DOI [10.1109/TVCG.2007.1036, 10.1109/TVCG.2007.1030]
   Richard E., 2006, Virtual Reality, V10, P207, DOI DOI 10.1007/S10055-006-0040-8
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Santos DV, 2004, ARCH OTOLARYNGOL, V130, P317, DOI 10.1001/archotol.130.3.317
   SCHAB FR, 1990, J EXP PSYCHOL LEARN, V16, P648, DOI 10.1037/0278-7393.16.4.648
   Schell J, 2001, IEEE COMPUT GRAPH, V21, P11, DOI 10.1109/38.933519
   Seah SA, 2014, ACM C HUM FACT COMP
   Shumin Zhai, 1998, Computer Graphics, V32, P50, DOI 10.1145/307710.307728
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   SMITH DG, 1992, PERCEPT MOTOR SKILL, V74, P339, DOI 10.2466/PMS.74.2.339-343
   Spangenberg ER, 1996, J MARKETING, V60, P67, DOI 10.2307/1251931
   SurveyOnics, 2011, ADV EFF SURV
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   TULVING E, 1985, CAN PSYCHOL, V26, P1, DOI 10.1037/h0080017
   Tulving E., 1985, OXFORD PSYCHOL SERIE, VNew
   van Wyk E, 2009, AGR
   Velasco C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01352
   Washburn DA, 2004, COMPUT SCI ENG, V6, P80, DOI 10.1109/MCSE.2004.66
   Yamada T, 2006, IEEE VIRT REAL VR
   Yanagida Y., 2013, Human Olfactory Displays and Interfaces, P60
   Yanagida Y, 2012, IEEE SENS
   Yanagida Y, 2004, IEEE VIRT REAL VR
NR 57
TC 16
Z9 19
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12311
EP 12330
DI 10.1007/s11042-015-2971-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700003
DA 2024-07-18
ER

PT J
AU Yoo, HS
   Kim, SW
AF Yoo, Hwan-Soo
   Kim, Seong-Whan
TI ESOTAG: E-book evolution using collaborative social tagging by readers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social tag; Collaborative filtering; E-book; Smart devices; External DSL
AB Rapid development of smart devices has lead people to be able to read books through their devices anytime and anywhere. Even though its popularity, e-books have ingrained disadvantages such as: (1) It does not have an expandable scheme that allows readers to add multimedia contents or their emotional expressions to books. (2) It is not easy to add multimedia resources as an author. (3) Due to the variety of resolutions on devices, the current ebook format tends to be uncomfortable for readers. The user constantly has to zoom in by pinching the screen when reading on a small device. (4) It is not easy to navigate contents within an e-book because of the absence of an e-book linking feature. To tackle the above mentioned problems, we design and use an external domain-specific language (DSL) within our research. We propose a collaborative social tagging framework for e-books. The goals of this paper are (1) to define a model of an evolvable social resources taggable book (modeling of collaborative e-book), (2) to make readers read rich content e-book easily regardless of their type of devices as well as screen size. (Responsiveness), and (3) to provide e-book resources with the Representational State Transfer (RESTful) address style by which other systems can identify the self-descriptive resources of an e-books (interoperability). The experimental results show that e-book featured social tagging makes readers more interested in reading e-books rather than plain e-books. Further work includes user experience (UX) improvement, and a visual DSL approach with which the authors could write books easier.
C1 [Yoo, Hwan-Soo; Kim, Seong-Whan] Univ Seoul, Sch Comp Sci, 13 Siripdae Gil, Seoul 130743, South Korea.
C3 University of Seoul
RP Kim, SW (corresponding author), Univ Seoul, Sch Comp Sci, 13 Siripdae Gil, Seoul 130743, South Korea.
EM rayryu7@uos.ac.kr; swkim7@uos.ac.kr
RI Yoo, Hwan Soo/N-4449-2018
OI Yoo, Hwan Soo/0000-0002-7799-0685
CR Cook JE, 2013, LIBR LEAD PIPE
   CordonGarcia JA, 2013, CHAND PUBL SOC MEDIA, P1, DOI 10.1533/9781780633923
   Daylamani Zad D, 2010, ANGELIDES RIOS C HDB, P263
   Ghosh D., 2011, DSLS IN ACTION
   Kasdorf B, 2011, INFORM STANDARDS Q, P4
   Kit Eaton, 2014, NY TIMES
   Kiu CC, 2011, EXPERT SYST APPL, V38, P6049, DOI 10.1016/j.eswa.2010.11.014
   Kramer D., 2010, Proc. IEEE International Conference on Networked Embedded Systems for Enterprise Applications, P1, DOI [10.1109/NESEA.2010.5678062, DOI 10.1109/NESEA.2010.5678062]
   Langlois B., 2007, OOPSLA 7 WORKSH DOM
   Mathes A., 2004, Computer M ediated Communication, V47, P1
   Ovadia S, 2014, BEHAV SOCIAL SCI LIB, V33, P120, DOI DOI 10.1080/01639269.2014.904696
   Peleteiro A, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P221, DOI 10.1109/ICCE.2011.5722551
   Ribiere V, 2012, INT P EC DEV RES, V35
   Tilkov S, 2010, IEEE INTERNET COMPUT, V14, P80, DOI 10.1109/MIC.2010.145
   Timeline - Art Museum, APP STOR
   Venugopal R, 2014, METHOD SYSTEM INSERT
   Vincent LC, Patent filed as US, Patent No. [13/644,731, 13644731]
   Webber J., 2010, REST in Practice
   Yoshida T, 2012, IMPROVING ITEM RECOM
NR 19
TC 2
Z9 2
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12795
EP 12813
DI 10.1007/s11042-016-3404-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700029
DA 2024-07-18
ER

PT J
AU Belalia, A
   Belloulata, K
   Kpalma, K
AF Belalia, Amina
   Belloulata, Kamel
   Kpalma, Kidiyo
TI Region-based image retrieval in the compressed domain using
   shape-adaptive DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval (CBIR); DCT; Segmentation; Region-based
   image retrieval (RBIR); Semantic image retrieval; SA-DCT
ID DISCRETE COSINE TRANSFORM; EXTRACTION; COLOR; SEGMENTATION; RECOGNITION;
   TEXTURE; DESCRIPTOR; FEATURES
AB Content-based image retrieval (CBIR) has drawn substantial research and many traditional CBIR systems search digital images in a large database based on features, such as color, texture and shape of a given query image. A majority of images are stored in compressed format and most of compression technologies adopt different kinds of transforms to achieve compression. Therefore, features can be extracted directly from images in compressed format by using, for example, discrete cosine transform (DCT) for JPEG compressed images. Region-based image retrieval (RBIR) is an image retrieval approach which focuses on contents from regions of images, instead of the content from the entire image in early CBIR. Although RBIR approaches attempt to solve the semantic gap problem existed in global low-level features in CBIR by using local low-level features based on regions of images. This paper proposes a new RBIR approach using Shape adaptive discrete cosine transform (SA-DCT). At a bottom level, local features are constructed from the coefficients of quantized block transforms (low-level features) for each region. Quantization acts for the concentration of block-wise information in a more condense way, which is highly desirable for the retrieval tasks. At an intermediate level, histograms of local image features are used as descriptors of statistical information. Finally, at the top level, the combination of histograms from different image regions (objects) is defined as a way to incorporate high-level semantic information. In this retrieval system, an image has a prior segmentation alpha plane, which is defined exactly as in MPEG-4. Therefore, an image is represented by segmented regions, each of which is associated with a feature vector derived from DCT and SA-DCT coefficients. Users can select any region as the main theme of the query image. The similarity between a query image and any database image is ranked according to a same similarity measure computed from the selected regions between two images. For those images without distinctive objects and scenes, users can still select the whole image as the query condition. The experimental results show that the proposed approach is able to identify main objects and reduce the influence of background in the image, and thus improve the performance of image retrieval in comparison with a conventional CBIR based on DCT.
C1 [Belalia, Amina; Belloulata, Kamel] Univ Djillali Liabes Sidi Bel Abbes, Dept Elect, Fac Engn, BP 89, Sidibel Abbes, Algeria.
   [Kpalma, Kidiyo] IETR, UEB INSA, UMR 6164, F-35708 Rennes, France.
C3 University Djillali Liabes Sidi Bel Abbes; Centre National de la
   Recherche Scientifique (CNRS); CNRS - Institute for Engineering &
   Systems Sciences (INSIS); Universite de Rennes
RP Belloulata, K (corresponding author), Univ Djillali Liabes Sidi Bel Abbes, Dept Elect, Fac Engn, BP 89, Sidibel Abbes, Algeria.
EM kamel.belloulata@USherbrooke.ca
RI , Belloulata/V-9150-2019
OI , Belloulata/0000-0002-6044-4389
FU Partenariat Hubert Curien PHC-TASSILI [N 12MDU864]
FX This work is currently supported by the Partenariat Hubert Curien
   PHC-TASSILI under grant N 12MDU864. The authors thank for their
   financial supports. We would like to thank the editor and anonymous
   reviewers for insightful comments and helpful suggestions to improve the
   quality of the paper.
CR Agarwal M, 2012, INT J MULTIMED INF R, V1, P129, DOI 10.1007/s13735-012-0005-5
   Bai C, 2015, MULTIMED TOOLS APPL, V74, P1469, DOI 10.1007/s11042-014-2053-8
   Bai C, 2012, EUR SIGNAL PR CONF, P170
   Belloulata K, 2002, IEEE T IMAGE PROCESS, V11, P351, DOI 10.1109/TIP.2002.999669
   Belloulata K, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P470, DOI 10.1109/ChinaSIP.2014.6889287
   Belloulata K, 2014, AEU-INT J ELECTRON C, V68, P687, DOI 10.1016/j.aeue.2014.02.011
   Bolle RM, 2000, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2000.906204
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang CC, 2004, IMAGE VISION COMPUT, V22, P471, DOI 10.1016/j.imavis.2003.11.008
   CHEN HH, 1994, IEEE IMAGE PROC, P85, DOI 10.1109/ICIP.1994.413280
   Cheng KO, 2010, PATTERN RECOGN, V43, P3314, DOI 10.1016/j.patcog.2010.05.012
   Climer S, 2002, PATTERN RECOGN, V35, P2479, DOI 10.1016/S0031-3203(01)00182-0
   Cong Bai, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P714
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Du YP, 2001, IEEE IMAGE PROC, P22, DOI 10.1109/ICIP.2001.958943
   Edmundson D, 2012, IEEE IMAGE PROC, P2421, DOI 10.1109/ICIP.2012.6467386
   Edmundson D, 2012, INT C PATT RECOG, P3188
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   Feng GC, 2003, PATTERN RECOGN, V36, P977, DOI 10.1016/S0031-3203(02)00114-0
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Gilge M., 1989, Signal Processing: Image Communication, V1, P153, DOI 10.1016/0923-5965(89)90007-6
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Hsu HC, 2008, IEEE T CIRC SYST VID, V18, P375, DOI 10.1109/TCSVT.2008.918275
   Information Technology, 2004, JTC1SC29WG11 ISOIEC
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Kauff P, 1998, IEEE T CIRC SYST VID, V8, P237, DOI 10.1109/76.678616
   Liu Y, 2004, P IEEE INT C MULT EX, P1891
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu Y, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P264
   Liu Y, 2009, J VIS COMMUN IMAGE R, V20, P157, DOI 10.1016/j.jvcir.2008.11.006
   Manipoonchelvi P, 2014, SIGNAL IMAGE VIDEO P, V6, P1
   Murala S, 2014, J VIS COMMUN IMAGE R, V25, P1324, DOI 10.1016/j.jvcir.2014.05.008
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shneier M, 1996, IEEE T PATTERN ANAL, V18, P849, DOI 10.1109/34.531805
   Shokoufandeh A, 2012, IET COMPUT VIS, V6, P500, DOI 10.1049/iet-cvi.2012.0030
   SIKORA T, 1995, SIGNAL PROCESS-IMAGE, V7, P381, DOI 10.1016/0923-5965(95)00009-9
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P59, DOI 10.1109/76.350781
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stasinski R, 1999, IEEE T CIRC SYST VID, V9, P16, DOI 10.1109/76.744272
   Sun YQ, 2005, MULTIMEDIA SYST, V10, P559, DOI 10.1007/s00530-005-0182-7
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Yang XH, 2014, IET COMPUT VIS, V8, P141, DOI 10.1049/iet-cvi.2012.0157
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
   Zhong D, 2005, PATTERN RECOGN LETT, V26, P2272, DOI 10.1016/j.patrec.2005.04.012
   Zhong D, 2007, PATTERN RECOGN LETT, V28, P2003, DOI 10.1016/j.patrec.2007.05.019
   Zhong D, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/631297
   Zou W, 2013, ELECTRON LETT, V49, P1140, DOI 10.1049/el.2013.2100
   Zou WB, 2012, INT C PATT RECOG, P922
   Zou WB, 2012, IEEE IMAGE PROC, P2577, DOI 10.1109/ICIP.2012.6467425
NR 58
TC 13
Z9 13
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10175
EP 10199
DI 10.1007/s11042-015-3026-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800004
DA 2024-07-18
ER

PT J
AU Ye, GD
   Huang, XL
AF Ye, Guodong
   Huang, Xiaoling
TI A novel block chaotic encryption scheme for remote sensing image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Block cipher; Lorenz chaotic system; Remote sensing
   image
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; PLAINTEXT ATTACKS;
   STREAM CIPHERS; LOGISTIC MAP; ALGORITHM; MECHANISM
AB An image encryption scheme is proposed using block cipher for remote sensing image in this paper. Remote sensing image means the detection of earth surface including mainly the land, ocean, and atmosphere from satellite. Due to the huge data in normal remote sensing image with security communication requirement, block encryption is adopted for fast implementation, which can effectively resist chosen and known plaintext attacks. Actually, it is a integer factorization problem in mathematics science. The factorization method is not secret but can be open. Some control parameters are produced from the plain-image of which shows that the new scheme can resist well the known-plaintext and chosen-plaintext attacks. Here, The Lorenz system in three-dimension is used for big key space. Classical encryption architecture, i.e., permutation and diffusion, is adopted for high security. All experimental results and security analyses show the efficiency of the proposed method. Therefore, it is suitable for secure communication of big remote sensing image.
C1 [Ye, Guodong; Huang, Xiaoling] Guangdong Ocean Univ, Coll Sci, Zhanjiang 524088, Guangdong, Peoples R China.
C3 Guangdong Ocean University
RP Ye, GD (corresponding author), Guangdong Ocean Univ, Coll Sci, Zhanjiang 524088, Guangdong, Peoples R China.
EM guodongye@hotmail.com
RI Ye, Guodong/B-3322-2017
FU National Natural Science Foundation of China [11301091]; Project of
   Enhancing School With Innovation of Guangdong Ocean University of China
   [Q14217]; Science & Technology Planning Project of Zhanjiang City of
   China [2015B01051, 2015B01098]
FX The authors would like to thank the editors and two anonymous reviewers
   for their positive comments and valuable suggestions. The work described
   in this paper was fully supported by the National Natural Science
   Foundation of China (No.11301091), the Project of Enhancing School With
   Innovation of Guangdong Ocean University of China (No.Q14217), and the
   Science & Technology Planning Project of Zhanjiang City of China
   (No.2015B01051, No.2015B01098).
CR Arroyo D, 2011, COMMUN NONLINEAR SCI, V16, P805, DOI 10.1016/j.cnsns.2010.04.031
   Behnia S, 2008, INT J BIFURCAT CHAOS, V18, P251, DOI 10.1142/S0218127408020288
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Kurian AP, 2008, SIGNAL PROCESS, V88, P2442, DOI 10.1016/j.sigpro.2008.04.003
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li S. J., 2001, LECT NOTES COMPUTER, V2247, P316
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mandal MK, 2014, SECUR COMMUN NETW, V7, P2145, DOI 10.1002/sec.927
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Palmer SCJ, 2015, REMOTE SENS ENVIRON, V157, P1, DOI 10.1016/j.rse.2014.09.021
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ruddick K, 2014, REMOTE SENS ENVIRON, V146, P63, DOI 10.1016/j.rse.2013.07.039
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
NR 28
TC 15
Z9 15
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11433
EP 11446
DI 10.1007/s11042-015-2861-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900028
DA 2024-07-18
ER

PT J
AU Xia, YJ
   Ren, XL
   Peng, ZC
   Zhang, JL
   She, L
AF Xia, Yingjie
   Ren, Xiaolong
   Peng, Zhengchao
   Zhang, Jianlin
   She, Li
TI Effectively identifying the influential spreaders in large-scale social
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Important nodes; Node centrality; Node ranking; Large-scale networks
AB With great theoretical and practical significance, the studies of information spreading on social media become one of the most exciting domains in many branches of sciences. How to control the spreading process is of particular interests, where the identification of the most influential nodes in larger-scale social networks is a crucial issue. Degree centrality is one of the simplest method which supposes that the node with more neighbours may be more influential. K-shell decomposition method partitions the networks into several shells based on the assumption that nodes in the same shell have similar influence and nodes in higher-level shells (e.g., central) are probably to infect more nodes. Degree centrality and k-shell decomposition are local methods which are efficient but less relevant. Global methods such as closeness and betweenness centralities are more exact but time-consuming. For effectively identifying the more influential spreaders in large-scale social networks, in this paper we proposed an algorithm framework to solve this dilemma by combining the local and global methods. All the nodes are graded by the local methods and then the periphery of the network is removed according to their central values. At last, the global methods are employed to find out which node is more influential. The experimental results show that our framework can be efficient and even more accurate than the global methods
C1 [Xia, Yingjie] Hangzhou Normal Univ, Intelligent Transportat & Informat Secur Lab, Hangzhou, Zhejiang, Peoples R China.
   [Ren, Xiaolong; Zhang, Jianlin; She, Li] Hangzhou Normal Univ, Alibaba Business Coll, Alibaba Res Ctr Complex Sci, Hangzhou, Zhejiang, Peoples R China.
   [Peng, Zhengchao] Univ Elect Sci & Technol China, Web Sci Ctr, Chengdu, Sichuan, Peoples R China.
C3 Hangzhou Normal University; Hangzhou Normal University; University of
   Electronic Science & Technology of China
RP Xia, YJ (corresponding author), Hangzhou Normal Univ, Intelligent Transportat & Informat Secur Lab, Hangzhou, Zhejiang, Peoples R China.
EM xiayingjie@zju.edu.cn; zhangjohn@vip.sina.com
RI Ren, Xiao-Long/ABB-2250-2021
OI Ren, Xiao-Long/0000-0003-2323-163X
FU National Natural Science Foundation of China [61472113, 61304188,
   11205042]; Zhejiang Provincial Natural Science Foundation of China
   [LZ13F020004, LR14F020003, Y6110317]; CCF-Tencent Open Research Fund
FX This paper draws on work supported in part by the following funds:
   National Natural Science Foundation of China under grant number
   61472113, 61304188 and 11205042, Zhejiang Provincial Natural Science
   Foundation of China under grant number LZ13F020004, LR14F020003 and
   Y6110317, and CCF-Tencent Open Research Fund.
CR Albert R, 2000, NATURE, V406, P378, DOI 10.1038/35019019
   [Anonymous], NETWORK SCI
   [Anonymous], NETWORKS INTRO
   [Anonymous], CHIN SCI B
   [Anonymous], FEATURE SELECTION FA
   [Anonymous], LINK MINING MODELS A
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], ARXIV12022684
   [Anonymous], COMPLEX SYSTEMS COMP
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101
   Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009
   Chen DB, 2012, PHYSICA A, V391, P1777, DOI 10.1016/j.physa.2011.09.017
   Frasco GF, 2014, PHYS REV X, V4, DOI 10.1103/PhysRevX.4.011008
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Garas A, 2012, NEW J PHYS, V14, DOI 10.1088/1367-2630/14/8/083030
   Gjoka M, 2010, IEEE INFOCOM SER, DOI 10.1109/infcom.2010.5462078
   Guimerà R, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.065103
   Guimerà R, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.248701
   Kitsak M, 2010, NAT PHYS, V6, P888, DOI [10.1038/NPHYS1746, 10.1038/nphys1746]
   Leskovec J., 2012, NIPS, V25, P539, DOI DOI 10.5555/2999134.2999195
   Lü LY, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021202
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Sparrowe RT, 2001, ACAD MANAGE J, V44, P316, DOI 10.5465/3069458
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Xia YJ, 2014, INT J MOD PHYS C, V25, DOI 10.1142/S0129183114400166
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhou YZ, 2014, PHYSICA A, V399, P16, DOI 10.1016/j.physa.2013.12.036
NR 33
TC 16
Z9 16
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8829
EP 8841
DI 10.1007/s11042-014-2256-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500001
DA 2024-07-18
ER

PT J
AU Amiri, T
   Moghaddam, ME
AF Amiri, Tayebe
   Moghaddam, Mohsen Ebrahimi
TI A new visual cryptography based watermarking scheme using DWT and SIFT
   for multiple cover images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Multiple cover image; SIFT; SVD
ID COPYRIGHT PROTECTION SCHEME
AB In this paper, a new Visual Cryptography based watermarking scheme for multiple cover images is proposed. The proposed scheme conceals watermark without altering the original cover images. First, it extracts the feature shares by applying the discrete wavelet transform (DWT), Singular value decomposition (SVD), and scale invariant feature transform (SIFT) on the cover images. The extracted feature shares are then used together with the private key and watermark to construct a secret share. The secret share should be registered with a trust authority. When a dispute over cover images happens, watermark can be extracted by using private key, feature shares, and secret share. The experimental results showed the method robustness versus various attacks, especially rotation and scaling.
C1 [Amiri, Tayebe; Moghaddam, Mohsen Ebrahimi] Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
C3 Shahid Beheshti University
RP Moghaddam, ME (corresponding author), Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
EM m_moghadam@sbu.ac.ir
CR Chang CC, 2002, PATTERN RECOGN LETT, V23, P931, DOI 10.1016/S0167-8655(02)00023-5
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen TH, 2009, COMPUT STAND INTER, V31, P1, DOI 10.1016/j.csi.2007.09.001
   Hsieh S. L., 2004, P INT COMP S, P661
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Lee JS, 2014, COMPUTER SCI INFORM, P225
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lin YT, 2011, IET IMAGE PROCESS, V5, P328, DOI 10.1049/iet-ipr.2009.0264
   Liu F, 2011, IET INFORM SECUR, V5, P121, DOI 10.1049/iet-ifs.2009.0183
   Liu F, 2009, COMPUT J, P107
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Pitas I, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P215, DOI 10.1109/ICIP.1996.560422
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang CC, 2000, IEICE T FUND ELECTR, VE83A, P1589
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
NR 26
TC 18
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8527
EP 8543
DI 10.1007/s11042-015-2770-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300018
DA 2024-07-18
ER

PT J
AU Li, YT
   Zhou, G
   Graham, D
   Holtzhauer, A
AF Li, Yantao
   Zhou, Gang
   Graham, Daniel
   Holtzhauer, Andrew
TI Towards an EEG-based brain-computer interface for online robot control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; BCI system; k-means clustering algorithm; Principal component
   analysis
ID BODY AREA NETWORKS; BCI; COMMUNICATION; PERFORMANCE
AB According to New York Times, 5.6 million people in the United States are paralyzed to some degree. Motivated by requirements of these paralyzed patients in controlling assisted-devices that support their mobility, we present a novel EEG-based BCI system, which is composed of an Emotive EPOC neuroheadset, a laptop and a Lego Mindstorms NXT robot in this paper. We provide online learning algorithms that consist of k-means clustering and principal component analysis to classify the signals from the headset into corresponding action commands. Moreover, we also discuss how to integrate the Emotiv EPOC headset into the system, and how to integrate the LEGO robot. Finally, we evaluate the proposed online learning algorithms of our BCI system in terms of precision, recall, and the F-measure, and our results show that the algorithms can accurately classify the subjects' thoughts into corresponding action commands.
C1 [Li, Yantao] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Zhou, Gang; Graham, Daniel] Coll William & Mary, Dept Comp Sci, Williamsburg, VA 23187 USA.
   [Holtzhauer, Andrew] Mitre Corp, Mclean, VA USA.
C3 Southwest University - China; William & Mary; MITRE Corporation
RP Li, YT (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
EM yantaoli@foxmail.com
RI Zhou, Gang/T-7901-2017
OI Zhou, Gang/0000-0002-4425-9837
FU National Natural Science Foundation of China [61402380]; U.S. National
   Science Foundation [CNS-1253506, CNS-1250180]; Fundamental Research
   Funds for the Central Universities [XDJK2015B030]; State Ethnic Affairs
   Commission of China [14GZZ012]; Science and Technology Foundation of
   Guizhou [LH20147386]
FX The work is supported in part by the National Natural Science Foundation
   of China Grant 61402380, U.S. National Science Foundation Grants
   CNS-1253506 (CAREER) and CNS-1250180, the Fundamental Research Funds for
   the Central Universities Grant XDJK2015B030, the State Ethnic Affairs
   Commission of China Grant 14GZZ012, and the Science and Technology
   Foundation of Guizhou Grant LH20147386.
CR Acampora G, 2013, P IEEE, V101, P2470, DOI 10.1109/JPROC.2013.2262913
   [Anonymous], 2011 3 INT C GAM VIR
   Barry RJ, 2002, CLIN NEUROPHYSIOL, V113, P579, DOI 10.1016/S1388-2457(02)00036-6
   Barry RJ, 2002, APPL PSYCHOPHYS BIOF, V20, P83
   Birbaumer N, 2003, IEEE T NEUR SYS REH, V11, P120, DOI 10.1109/TNSRE.2003.814439
   Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581
   Blankertz B, 2008, IEEE T BIO-MED ENG, V55, P2452, DOI 10.1109/TBME.2008.923152
   Buttfield A, 2006, IEEE T NEUR SYS REH, V14, P164, DOI 10.1109/TNSRE.2006.875555
   Cernea D., 2011, HCI International 2011-Posters' Extended Abstracts, P279
   Choi K, 2008, LECT NOTES COMPUT SC, V5326, P330, DOI 10.1007/978-3-540-88906-9_42
   Duvinage M, 2012, BIOMED ENG
   Fortino G, 2014, WIREL NETW, V20, P1925, DOI 10.1007/s11276-014-0714-1
   Friman O, 2007, 2007 3RD INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING, VOLS 1 AND 2, P354, DOI 10.1109/CNE.2007.369683
   Hayajneh T, 2014, WIREL NETW, V20, P2165, DOI 10.1007/s11276-014-0736-8
   Hill NJ, 2006, IEEE T NEUR SYS REH, V14, P183, DOI 10.1109/TNSRE.2006.875548
   Kalcher J, 1996, MED BIOL ENG COMPUT, V34, P382, DOI 10.1007/BF02520010
   Kübler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D
   Lalor EC, 2005, EURASIP J APPL SIG P, V2005, P3156, DOI 10.1155/ASP.2005.3156
   Leeb R, 2007, IEEE T NEUR SYS REH, V15, P473, DOI 10.1109/TNSRE.2007.906956
   Martin AR, 2012, CAN J NEUROL SCI, V39, P11, DOI 10.1017/S0317167100012622
   Martinez Pablo, 2007, Comput Intell Neurosci, P94561, DOI 10.1155/2007/94561
   Min Chen, 2011, Mobile Networks and Applications, V16, P171, DOI 10.1007/s11036-010-0260-8
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Müller-Putz GR, 2008, IEEE T BIO-MED ENG, V55, P361, DOI 10.1109/TBME.2007.897815
   Müller-Putz GR, 2005, J NEURAL ENG, V2, P123, DOI 10.1088/1741-2560/2/4/008
   Neuper C, 2003, CLIN NEUROPHYSIOL, V114, P399, DOI 10.1016/S1388-2457(02)00387-5
   Nijholt A, 2008, IEEE INTELL SYST, V23, P72, DOI 10.1109/MIS.2008.41
   Pedrycz W, 1999, IEEE T SYST MAN CY B, V29, P745, DOI 10.1109/3477.809029
   Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829
   Piccione F, 2006, CLIN NEUROPHYSIOL, V117, P531, DOI 10.1016/j.clinph.2005.07.024
   Salameh HB, 2007, AD HOC NETW, V5, P844, DOI 10.1016/j.adhoc.2007.02.011
   Scherer R, 2004, IEEE T BIO-MED ENG, V51, P979, DOI 10.1109/TBME.2004.827062
   Sugiarto I, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND TECHNOLOGY, VOL I, PROCEEDINGS, P223, DOI 10.1109/ICCET.2009.189
   Trejo LJ, 2006, IEEE T NEUR SYS REH, V14, P225, DOI 10.1109/TNSRE.2006.875578
   Ullah S, 2014, INFORM SCIENCES, V284, P81, DOI 10.1016/j.ins.2014.07.050
   VAROL E, 2010, THESIS
   Vaughan TM, 2006, IEEE T NEUR SYS REH, V14, P229, DOI 10.1109/TNSRE.2006.875577
   Yao JT, 2013, IEEE T CYBERNETICS, V43, P1977, DOI 10.1109/TSMCC.2012.2236648
   Zhang ZY, 2012, IEEE T INF TECHNOL B, V16, P1070, DOI 10.1109/TITB.2012.2206115
NR 39
TC 21
Z9 22
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7999
EP 8017
DI 10.1007/s11042-015-2717-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600026
DA 2024-07-18
ER

PT J
AU Liu, H
   Xiao, D
   Xiao, YP
   Zhang, YS
AF Liu, Hong
   Xiao, Di
   Xiao, Yunpeng
   Zhang, Yushu
TI Robust image hashing with tampering recovery capability via low-rank and
   sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image hashing; Low-rank representation; Compressive sensing; Tampering
   recovery
ID MATRIX; SECURE; RECONSTRUCTION
AB Multimedia hash is an effective solution to image authentication and tampering identification. We propose an image hashing scheme based on Low-Rank and Sparse Representation. Low-Rank Representation is applied to the attacked image to obtain image feature matrix and error matrix. Then the properties of dimension reduction and tampering recovery inherent in Low-Rank Representation and Compressive Sensing are exploited for hash design. We use Compressive Sensing to recover the primary feature of image. Furthermore we use Low-Rank Representation to recover the image from tampering. Thanks to the error correction and structure recover capabilities of Low-Rank Representation, experiments reveal that our proposed hashing scheme is robust to content preserving modifications and has better image recovery performance compared with existing hashing schemes.
C1 [Liu, Hong; Xiao, Di] Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Liu, Hong; Xiao, Yunpeng] Chongqing Univ Posts & Telecommun, Coll Software Engn, Chongqing 400065, Peoples R China.
   [Zhang, Yushu] Southwest Univ, Sch Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Chongqing University; Chongqing University of Posts &
   Telecommunications; Southwest University - China
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
OI Liu, Hong/0000-0002-1260-5360; Xiao, Yunpeng/0000-0002-2846-3571
FU Chongqing Youth Innovative Talent Project [cstc2013kjrc-qnrc40004]; open
   research fund of Chongqing Key Laboratory of Emergency Communications
   [CQKLEC, 201405041]; Fundamental Research Funds for the Central
   Universities [106112013CDjZR180005, 106112014CDjZR185501, XDJK2015C077];
   Natural Science Foundation of Chongqing Science and Technology
   Commission [cstc2013jcyjA40017, cstc2013jjB40009]; National Natural
   Science Foundation of China [61173178, 61272043, 61302161, 61472464]
FX The work was supported by Chongqing Youth Innovative Talent Project
   (Grant No. cstc2013kjrc-qnrc40004), the open research fund of Chongqing
   Key Laboratory of Emergency Communications (Grant No. CQKLEC, 201405041,
   Project Nos. 106112013CDjZR180005, 106112014CDjZR185501, XDJK2015C077
   supported by the Fundamental Research Funds for the Central
   Universities, the Natural Science Foundation of Chongqing Science and
   Technology Commission (Grant Nos. cstc2013jcyjA40017, cstc2013jjB40009)
   and the National Natural Science Foundation of China (Grant Nos.
   61173178, 61272043, 61302161, 61472464).
CR [Anonymous], EURASIP J INF SECUR
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Cox I., 2001, Digital Watermarking
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Kailasanathan C, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P562
   KAILASANATHAN C, 2001, P IEEE EURASIP WORK
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2012, NEURAL COMPUT, V24, P3371, DOI 10.1162/NECO_a_00369
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 23
TC 12
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7681
EP 7696
DI 10.1007/s11042-015-2688-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600011
DA 2024-07-18
ER

PT J
AU Nguyen, TD
   Arch-int, S
   Arch-int, N
AF Tuan Duc Nguyen
   Arch-int, Somjit
   Arch-int, Ngamnij
TI An adaptive multi bit-plane image steganography using block data-hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Muli bit-plane; Adaptive; Block data-hiding; Steganography
AB Embedding a secret message into the pixels of a cover image yields a visual distortion if these pixels belong to smooth regions. Thus, this prompted the development of some edge-based approaches in which only the edge pixels are used to hide secret bits. As a result, the visual quality of stego images is improved. However, the capacity is limited due to some unused regions in cover images. In this paper, an adaptive multi bit-planes image steganography using block data-hiding (MPBDH) is proposed. This method employs more than one bit-plane and applies an adaptive complexity threshold computation to select the complex regions of a cover image used in data hiding. Consequently, the embedding capacity and security performance are significantly improved in comparison with previous approaches based on pixel and block complexity. The results, which are obtained from experiments performed on 10,000 natural gray-images, indicate that the embedding capacity and security introduced in the proposed approach overcome the problems of previous approaches. The proposed approach is hence suitable for secure communications.
C1 [Tuan Duc Nguyen] Khon Kaen Univ, Dept Comp Sci, Fac Sci, Khon Kaen, Thailand.
   [Arch-int, Somjit; Arch-int, Ngamnij] Khon Kaen Univ, Dept Comp Sci, Khon Kaen, Thailand.
C3 Khon Kaen University; Khon Kaen University
RP Nguyen, TD (corresponding author), Khon Kaen Univ, Dept Comp Sci, Fac Sci, Khon Kaen, Thailand.
EM nguyenductuan1982@gmail.com; somjit@kku.ac.th; ngamnij@kku.ac.th
OI DUC TUAN, NGUYEN/0000-0001-5261-271X
FU Department of Computer Science
FX We gratefully acknowledge Department of Computer Science for financial
   support and Khon Kaen University for their assistance.
CR [Anonymous], 1997, SIPI IMAGE DATABASE
   Battisti F, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/938515
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Chang K-C, 2007, ADAPTIVE IMAGE STEGA, P1165
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hirohisa H, 2002, P PAC RIM WORKSH DIG, P30
   Hong W, 2012, SIGNAL PROCESS-IMAGE, V27, P1123, DOI 10.1016/j.image.2012.09.002
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Kawaguchi E, 1998, PRINCIPLE APPL BPCS
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Munoz A, 2007, STEGSECRET SIMPLE ST
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pevny Tomas, 2013, BREAK OUR STEGANOGRA
   Pour A. H., 2012, J INFORM SECURITY, V3, P202
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Rose NicholasJ., 2001, Hilbert-type space-filling curves
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sur A, 2014, MULTIMED TOOLS APPL, V68, P805, DOI 10.1007/s11042-012-1078-0
   Nguyen TD, 2015, MULTIMED TOOLS APPL, V74, P5661, DOI 10.1007/s11042-014-1877-6
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
NR 26
TC 28
Z9 28
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8319
EP 8345
DI 10.1007/s11042-015-2752-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300009
DA 2024-07-18
ER

PT J
AU Wehbe, H
   Haidar, B
   Joly, P
AF Wehbe, Hassan
   Haidar, Bassem
   Joly, Philippe
TI Action boundaries detection in a video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video analysis; Action detection; Segmentation; Codebook quantization
ID SEGMENTATION; TRACKING
AB In the video analysis domain, automatic detection of actions performed in a recorded video represents an important scientific and industrial challenge. This paper presents a new method to approximate the boundaries of actions performed by a person while interacting with his environment (such as moving objects). This method relies on a Codebook quantization method to analyze the rough evolution of each pixel and then decide whether this evolution corresponds to an action or not; this decision is taken by an automated system. Statistics are then produced - at the scale of the whole frame - to estimate the start and the end of an action. According to our proposed evaluation protocol, this method produces interesting results on both real and simulated videos. This statistic-based protocol is discussed at the end of this paper. The interpretation of this evaluation protocol nominates this method to be a solid base to localize the exact boundaries of actions or-in the framework of this research activity to associate prescriptive text with a visual content.
C1 [Wehbe, Hassan; Joly, Philippe] Toulouse Univ, IRIT, 118 Route Narbonne, F-31062 Toulouse 9, France.
   [Haidar, Bassem] Lebanese Univ, Fac Sci, Beirut, Lebanon.
C3 Universite Federale Toulouse Midi-Pyrenees (ComUE); Lebanese University
RP Wehbe, H (corresponding author), Toulouse Univ, IRIT, 118 Route Narbonne, F-31062 Toulouse 9, France.
EM hassan.wehbe@univ-tlse3.fr; bassem.haidar@ul.edu.lb;
   Philippe.Joly@irit.fr
CR Ambata LU, 2012, TENCON 2012 IE REG 1, P1, DOI [10.1109/tencon.2012.6412298, DOI 10.1109/TENCON.2012.6412298]
   [Anonymous], 1999, P IEEE C COMPUTER VI
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Fihl P, 2006, LECT NOTES COMPUT SC, V4291, P60
   Geng L, 2011, INT C CONTR AUT SYST, V1, P1, DOI [10.1109/ICCASE.2011.5997546, DOI 10.1109/ICCASE.2011.5997546]
   Gibbins D, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P22, DOI 10.1109/ACV.1996.571990
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Leykin A., 2007, 2007 IEEE C COMP VIS, P1, DOI [DOI 10.1109/CVPR.2007.383444, 10.1109/CVPR.2007.383444]
   MathWorks laboratories, 2013, SCEN CHANG DET SYST
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rodriguez-Gomez R, 2015, J REAL-TIME IMAGE PR, V10, P43, DOI 10.1007/s11554-012-0249-6
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sigari MH, 2008, LECT NOTES ENG COMP, P717
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subudhi BN, 2013, MACH VISION APPL, V24, P795, DOI 10.1007/s00138-012-0475-8
   Sudhir G, 1998, P IEEE INT WORKSH CO, V1, P81, DOI [10.1109/caivd.1998.646036, DOI 10.1109/CAIVD.1998.646036]
   Szwoch G, 2016, J REAL-TIME IMAGE PR, V11, P111, DOI 10.1007/s11554-012-0310-5
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yihong Gong, 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P167, DOI 10.1109/MMCS.1995.484921
   Zhang D., 2002, ACM Multimedia, P315
NR 22
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8239
EP 8266
DI 10.1007/s11042-015-2748-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300006
DA 2024-07-18
ER

PT J
AU Nam, Y
AF Nam, Yunyoung
TI Real-time abandoned and stolen object detection based on spatio-temporal
   features in crowded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abandoned object; Stolen object; Left object; Background subtraction;
   Video surveillance
ID SURVEILLANCE; CALIBRATION; MODEL
AB Abandoned and stolen object detection is a challenging task due to occlusion, changes in lighting, large perspective distortion, and the similarity in appearance of different people. This paper presents real-time detection methods of abandoned and stolen objects in a complex video. The adaptive background modeling method is applied to stable tracking and the ghost image removing. To detect abandoned and stolen objects, the methods determine spatio-temporal relationship between moving people and suspicious drops. The space first detection method measures the distance between a moving object and a non-moving object in spatial change analysis. The time first detection method conducts temporal change analysis and then spatial change analysis. The potential abandoned object is classified as a definite abandoned or stolen object by two-level detection approach. The time-to-live timer is applied by adjusting several key parameters on each camera and environment. In experiments, we show the experimental results to evaluate our proposed methods using benchmark datasets.
C1 [Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 336745, South Korea.
C3 Soonchunhyang University
RP Nam, Y (corresponding author), Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 336745, South Korea.
EM ynam@sch.ac.kr
RI Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
FU Soonchunhyang University [20140226]; MSIP(Ministry of Science,
   ICT&Future Planning), Korea, under the C-ITRC(Convergence Information
   Technology Research Center) [NIPA-2014-H0401-14-1022]
FX This research was supported by the Soonchunhyang University Research
   Fund (No. 20140226) and also was supported by the MSIP(Ministry of
   Science, ICT&Future Planning), Korea, under the C-ITRC(Convergence
   Information Technology Research Center) support program
   (NIPA-2014-H0401-14-1022) supervised by the NIPA(National IT Industry
   Promotion Agency).
CR [Anonymous], AM NUCL SOC 8 INT TO
   [Anonymous], 2007, 2007 IEEE WORKSH MOT, DOI DOI 10.1109/WMVC.2007.1
   [Anonymous], EFFICIENT METHOD DET
   [Anonymous], 8 INT WORKSH VIS SUR
   [Anonymous], PETS 2006 PERFORMANC
   [Anonymous], I LIDS I LIDS DATASE
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], 2013, 4 NAT C COMP VIS PAT, DOI DOI 10.1109/NCVPRIPG.2013.6776161
   [Anonymous], PETS 2007 PERFORMANC
   Beyan C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3602204
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Cho SH, 2010, KSII T INTERNET INF, V4, P358, DOI 10.3837/tiis.2010.06.010
   Evangelio RH, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/858502
   Fan QF, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P58, DOI 10.1109/AVSS.2012.62
   Ferrando Silvia., 2006, VIDEO SIGNAL BASED S, P21
   Hassanpour R, 2004, PATTERN RECOGN LETT, V25, P989, DOI 10.1016/j.patrec.2004.02.011
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Lucchese L, 2005, IMAGE VISION COMPUT, V23, P517, DOI 10.1016/j.imavis.2005.01.001
   Maddalena L, 2013, IEEE T NEUR NET LEAR, V24, P723, DOI 10.1109/TNNLS.2013.2242092
   Mathisen R., 2005, MEDIEVAL ED, P1
   Nam Y, 2013, MULTIMED TOOLS APPL, V67, P289, DOI 10.1007/s11042-012-0997-0
   Porikli F, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P236, DOI 10.1109/AVSS.2007.4425316
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Quanfu Fan, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P36, DOI 10.1109/AVSS.2011.6027290
   SanMiguel JC, 2012, COMPUT VIS IMAGE UND, V116, P937, DOI 10.1016/j.cviu.2012.04.005
   Thiel G, 2000, IEEE AERO EL SYS MAG, V15, P3, DOI 10.1109/62.854018
   Tian YL, 2012, MACH VISION APPL, V23, P967, DOI 10.1007/s00138-011-0377-1
   Wang J, 2008, PATTERN RECOGN, V41, P607, DOI 10.1016/j.patcog.2007.06.012
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 29
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7003
EP 7028
DI 10.1007/s11042-015-2625-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400016
DA 2024-07-18
ER

PT J
AU Vadlamudi, LN
   Vaddella, RPV
   Devara, V
AF Vadlamudi, Lokanadham Naidu
   Vaddella, Rama Prasad V.
   Devara, Vasumathi
TI Robust hash generation technique for content-based image authentication
   using histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Histogram; Secure image hash; Image manipulations;
   Robustness and discriminate
ID SCHEME
AB In this paper, a robust hash technique for image content authentication using histogram is proposed. The histogram based hash techniques reported in the literature are robust against Content Preserving Manipulations as well as incidental distortion. The major drawback of these techniques is that, they are not sensitive to Content Changing Manipulations and also un-altered histogram image modifications. To overcome these drawbacks, we present a novel hash technique which divides the image into non-overlapped blocks and distributes histogram bins of the image block into larger containers based on the Partial Sum of pixel count of histogram bins. An intermediate hash is produced by computing the ratio of pixel count between two neighbouring containers. The intermediate image hash is obtained by concatenating intermediate hashes of image blocks. Finally, the intermediate image hash is normalized and randomly permuted with a secret key to produce a robust and secure hash. The results shows that, the proposed method performs better when compared to the existing methods against the Content Preserving manipulations. Besides, the proposed method is more sensitive to Content Changing manipulations as well as un-altered histogram image modifications. The performance results on image authentication indicate that, the proposed method has high discriminative capability and strong robustness.
C1 [Vadlamudi, Lokanadham Naidu; Vaddella, Rama Prasad V.] Sree Vidyanikethan Engn Coll Autonomous, Tirupati 517102, Andhra Pradesh, India.
   [Devara, Vasumathi] JNT Univ, JNTU Coll Engn, Hyderabad 500085, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Hyderabad
RP Vadlamudi, LN (corresponding author), Sree Vidyanikethan Engn Coll Autonomous, Tirupati 517102, Andhra Pradesh, India.
EM vlnaidu1982@gmail.com; vvramaprasad@rediffmail.com;
   vasu_devara@yahoo.co.in
CR Black PE, 2005, NATL I STAND TECHNOL
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hassan AM, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P133, DOI 10.1109/ICMV.2009.66
   Jamil N., 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P274, DOI 10.1109/CISP.2010.5648278
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Matsuo T, 2004, P IEICE T FUNDAM E A, V87, P76
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   Saad SM, 2009, IET INFORM SECUR, V3, P1, DOI 10.1049/iet-ifs:20070112
   Skala V, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P167, DOI 10.1109/CGI.2001.934671
   Sun R, 2012, INT J MULTIMEDIA TOO, P1
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   van Leest A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P731
   Wang LN, 2011, SOFT COMPUT, V15, P493, DOI 10.1007/s00500-009-0529-7
   Weng L, 2011, LECT NOTES COMPUT SC, V7025, P108, DOI 10.1007/978-3-642-24712-5_9
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Zhang HL, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL II, P105, DOI 10.1109/ISECS.2009.118
NR 20
TC 13
Z9 14
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6585
EP 6604
DI 10.1007/s11042-015-2591-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700026
DA 2024-07-18
ER

PT J
AU Zha, Y
   Cao, TY
   Huang, H
   Song, ZJ
   Liang, WH
   Li, FB
AF Zha, Yi
   Cao, Tieyong
   Huang, Hui
   Song, Zhijun
   Liang, Wenhui
   Li, Feibin
TI Robust object tracking via local constrained and online weighted
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Local constrained; Sparse reconstruction; Weight
   distribution model
AB Accounting for most recent tracking algorithms just only handle one specified challenge, in order to adjust to diverse scenarios in object tracking, we propose a discriminative tracking algorithm based on a collaborative model. In order to account for drastic appearance change, the visual prior have been learned offline by adding the locality regularization term. We transfer the visual prior to represent object and learn a basic discriminative classifier. Next we employ minimal sparse reconstruction error to find the best candidate with the learned classifier. In addition, we derive a parameter update strategy which is based on the candidates' distribution. With this strategy, the candidates' weight can be calculated according to the candidates' distribution online. The tracking is carried out within a Bayesian inference framework with this representation. We use the learned classifier and sparse template to construct the dynamic parameter observation model. Furthermore, the particle filter is used to estimate the tracking result sequentially. Both qualitative and quantitative evaluations on variety of challenging benchmark sequences demonstrate that the proposed tracking algorithm achieves more robust object tracking than the state-of-the-art methods.
C1 [Zha, Yi; Cao, Tieyong; Huang, Hui; Liang, Wenhui; Li, Feibin] PLA Univ Sci & Technol, Coll Command Informat Syst, Nanjing, Jiangsu, Peoples R China.
   [Song, Zhijun] 28th Res Inst China Elect Technol Grp Corp, Nanjing, Jiangsu, Peoples R China.
C3 Army Engineering University of PLA; China Electronics Technology Group
RP Song, ZJ (corresponding author), 28th Res Inst China Elect Technol Grp Corp, Nanjing, Jiangsu, Peoples R China.
EM 124150153@qq.com; cty_ice@sina.com; huanghui_pla@163.com;
   jason@xmu.edu.cn; liangwenhui2008@qq.com; liverpoolfans@yeah.net
CR Adam A, 2003, 798805 CVPR
   [Anonymous], 2012, CVPR
   Avidan S, 2005, PROC CVPR IEEE, P494
   Avidan S, 2001, PROC CVPR IEEE, P184
   Black MJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P660, DOI 10.1109/ICCV.1998.710788
   Camplani M, PATTERN RECOGNITION
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Everingham M, 2010, PASCAL VIS OBJECT CL
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jia X., 2012, P IEEE C COMP VIS PA
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Roccetti M, 2014, MULTIMED TOOLS APPL, V69, P1131, DOI 10.1007/s11042-013-1512-y
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Q, 2012, IEEE T IMAGE P, V21
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang K, 2010, P ECCV
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 23
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6481
EP 6503
DI 10.1007/s11042-015-2584-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700021
DA 2024-07-18
ER

PT J
AU Chae, YN
   Han, T
   Seo, YH
   Yang, HS
AF Chae, Yeong Nam
   Han, Taewoo
   Seo, Yong-Ho
   Yang, Hyun S.
TI An efficient face detection based on color-filtering and its application
   to smart devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Facial color filtering; Region selection; Face tracking
AB This paper proposes a means of using facial color to enhance conventional face detectors. To detect face rapidly, the proposed approach adopts a color filtering based efficient region scanning method. The scanning method skips over regions that do not contain candidate faces, based on a facial color membership function. Then it adopts a face/non-face classifier using facial color at the preprocessor of the face detector. This classifier has low computational cost and can reject non-face regions at an early stage of face detection. By integrating the proposed face detector with a kernel based object tracker, a real-time face detection and tracking application is implemented for smart devices. The proposed method considerably reduces the overall computation time and reduces the number of false alarms.
C1 [Chae, Yeong Nam; Yang, Hyun S.] Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea.
   [Han, Taewoo] Woosong Univ, Dept Game & Multimedia, Daejeon, South Korea.
   [Seo, Yong-Ho] Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Woosong
   University; Mokwon University
RP Seo, YH (corresponding author), Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
EM ynchae@gmail.com; bluebird@wsu.ac.kr; yhseo@mokwon.ac.kr;
   hsyang@kaist.ac.kr
RI Yang, Hyun Seung/C-1984-2011
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and Future Planning
   [2013R1A1A2064233]; IT R&D program of MKE KEIT [10041610]; NAP (National
   Agenda Project) of the Korea Research Council of Fundamental Science
   Technology
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and Future Planning (2013R1A1A2064233) and the IT R&D
   program of MKE & KEIT [10041610, The development of the recognition
   technology for user identity, behavior and location that has a
   performance approaching recognition rates of 99 % on 30 people by using
   perception sensor network in the real environment] and the NAP (National
   Agenda Project) of the Korea Research Council of Fundamental Science &
   Technology.
CR [Anonymous], 2010, SURVEY RECENT ADV FA
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jang JS, 2008, IEEE T EVOLUT COMPUT, V12, P562, DOI 10.1109/TEVC.2007.910140
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Messer K., 1999, 2 INT C AUD VID BAS
   Singn SK, 2003, P TAMKANG J SCI ENG, V6, P227
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
NR 14
TC 0
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4867
EP 4886
DI 10.1007/s11042-013-1786-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700003
DA 2024-07-18
ER

PT J
AU Zheng, XG
   Ritz, C
   Xi, JT
AF Zheng, Xiguang
   Ritz, Christian
   Xi, Jiangtao
TI Encoding and communicating navigable speech soundfields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive audio/visual conferencing; Interactive audio/ visual
   applications; Spatial audio; Speech soundfields
ID BLIND SOURCE SEPARATION; PANNED VIRTUAL SOURCES; LOCALIZATION; MIXTURES
AB This paper describes a system for encoding and communicating navigable speech soundfields for applications such as immersive audio/visual conferencing, audio surveillance of large spaces and free viewpoint television. The system relies on recording speech soundfields using compact co-incident microphone arrays that are then processed to identify sources and their spatial location using the well-known assumption that speech signals are sparse in the time-frequency domain. A low-delay Direction of Arrival (DOA)-based frequency domain sound source separation approach is proposed that requires only 250 ms of speech signal. Joint compression is achieved through a previously proposed perceptual analysis-by-synthesis spatial audio coding scheme that encodes sources into a mixture signal that can be compressed by a standard speech codec at 32 kbps. By also transmitting side information representing the original spatial location of each source, the received mixtures can be decoded and then flexibly reproduced using loudspeakers at a chosen listening point within a synthesised speech scene. The system was implemented based on this framework for an example application encoding a three-talker navigable speech scene at a total bit rate of 48 kbps. Subjective listening tests were conducted to evaluate the quality of the reproduced speech scenes at a new listening point as compared to a true recording at that point. Results demonstrate the approach successfully encodes multiple spatial speech scenes at low bit rates whilst maintaining perceptual quality in both anechoic and reverberant environments.
C1 [Zheng, Xiguang; Ritz, Christian; Xi, Jiangtao] Univ Wollongong, ICT Res Inst, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2522, Australia.
   [Zheng, Xiguang] Dolby Labs Beijing, 1 East 3rd Ring Middle Rd, Beijing 100020, Peoples R China.
C3 University of Wollongong; Dolby Laboratories, Inc.
RP Ritz, C (corresponding author), Univ Wollongong, ICT Res Inst, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2522, Australia.
EM xzhen@dolby.com; critz@uow.edu.au; jiangtao@uow.edu.au
RI Ritz, Christian H/AGE-1439-2022
OI Ritz, Christian H/0000-0002-3768-7569; Xi, Jiangtao/0000-0002-5550-1975;
   Zheng, Xiguang/0000-0003-3103-9090
FU Australian Research Council (ARC) [DP1094053]; Australian Research
   Council [DP1094053] Funding Source: Australian Research Council
FX This work has been supported by the Australian Research Council (ARC)
   through the grant DP1094053.
CR ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], 2011, P 2011 IEEE 13 INT W
   [Anonymous], MICROPHONE ARRAY SIG
   [Anonymous], AUD DEF MOD VER 1 0
   Baldis J. J., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P166, DOI 10.1145/365024.365092
   Bosi B, 2003, INTRO DIGITAL AUDIO
   CAMPBELL D, 2005, COMPUT INF SYST J IS, V9, P1352
   Cheng B, 2007, INT CONF ACOUST SPEE, P13
   Do H, 2007, INT CONF ACOUST SPEE, P121
   Dolby Laboratories, 2012, DOLB ATMOS CIN TECHN
   Eargle John., 2004, The Microphone Book, V2nd
   Elko G.W., 2008, Springer Handbook of Speech Processing, P1021
   Evans MJ, 2000, J AUDIO ENG SOC, V48, P771
   Gannot S., 2008, Springer Handbook of Speech Processing, P945, DOI DOI 10.1007/978-3-540-49127-9_47
   Givens G.H., 2005, Computational statistics
   Günel B, 2009, INT CONF ACOUST SPEE, P41, DOI 10.1109/ICASSP.2009.4959515
   Günel B, 2008, IEEE T AUDIO SPEECH, V16, P748, DOI 10.1109/TASL.2008.918967
   Herre J, 2015, IEEE J-STSP, V99, P1
   Howard D.M., 2009, Acoustics and Psychoacoustics
   Huang Y., 2008, Springer Handbook of Speech Processing, P1043
   Jia MS, 2015, IEEE-ACM T AUDIO SPE, V23, P1082, DOI 10.1109/TASLP.2015.2419980
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830
   Kowalczyk K, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2014.2369531
   Mieczakowski A, 2013, CONV C COLL EFF DIST
   MILLAR JB, 1994, INT CONF ACOUST SPEE, P97
   Oldfield R, 2015, MULTIMED TOOLS APPL, V74, P2717, DOI 10.1007/s11042-013-1472-2
   Ozerov A, 2013, IEEE T AUDIO SPEECH, V21, P1699, DOI 10.1109/TASL.2013.2260153
   Pedersen M.S., 2008, Springer Handbooks, P1065, DOI [DOI 10.1007/978-3-540-49127-952, DOI 10.1007/978-3-540-49127-9_52]
   Pulkki V, 2001, J AUDIO ENG SOC, V49, P739
   Pulkki V, 2001, J AUDIO ENG SOC, V49, P753
   Rabenstein R., 2008, Springer Handbook of Speech Processing, P1095, DOI DOI 10.1007/978-3-540-49127-9_53
   Rozgic V, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P60, DOI 10.1109/MMSP.2007.4412818
   Ward DB, 1999, J ACOUST SOC AM, V105, P1099
   Wrigley SN, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2903
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Zheng XG, 2013, IEEE SIGNAL PROC LET, V20, P83, DOI 10.1109/LSP.2012.2229977
   Zheng XG, 2013, IEEE T AUDIO SPEECH, V21, P27, DOI 10.1109/TASL.2012.2211015
NR 37
TC 16
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5183
EP 5204
DI 10.1007/s11042-015-2989-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700021
DA 2024-07-18
ER

PT J
AU Djaziri-Larbi, S
   Zaien, A
   Sevestre-Ghalila, S
AF Djaziri-Larbi, Sonia
   Zaien, Awatef
   Sevestre-Ghalila, Sylvie
TI Voicing of animated GIF by data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GIF format; Animated GIF; GIF voicing; Data hiding; Steganography; Sound
   embedding
AB GIF animations are silent image sequences widely used on the web thanks to their wide support and portability. In this work, we propose an original technique based on data hiding, to add sound tracks in GIF animations. Data hiding is usually used to embed security codes in a host medium to prevent from illegal copying or to protect copyrights (watermarking) or to send secret messages to a dedicated receiver (steganography). We propose to use host GIF images as a "transmission channel" to convey "hidden" sound bits with lowest perceptual image distortion and without altering the wide portability of the GIF format, by means of data hiding. The inserted bits are neither secret nor intended for security issues. They are intended to be played by an audio player synchronously with the GIF player to add sound to the GIF animation. The embedding process is a low complexity, luminance based steganography algorithm, that slightly modifies the pixels colors of the GIF images to insert the sound bits. The extraction of the inserted audio is completely blind: the audio is directly extracted from the pixels of each cover image. The proposed GIF voicing was tested with different GIF sequences (cartoons and real scenes) and no audio degradation was reported while a slight, most imperceptible, color modification was noticed in case of an important amount of inserted data. The cover images have undergone objective quality criteria and informal subjective evaluation and has proved to be of good quality.
C1 [Djaziri-Larbi, Sonia] Univ Tunis El Manar, Ecole Natl Ingn Tunis, Signals & Syst Lab, BP37, Belvedere 1002, Tunisia.
   [Zaien, Awatef; Sevestre-Ghalila, Sylvie] Telnet Innovat Labs, CEA Linklab, Ariana 2083, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Djaziri-Larbi, S (corresponding author), Univ Tunis El Manar, Ecole Natl Ingn Tunis, Signals & Syst Lab, BP37, Belvedere 1002, Tunisia.
EM sonia.larbi@enit.rnu.tn; zaien.awatef@gmail.com; sylvie.ghalila@cea.fr
RI Sevestre-Ghalila, Sylvie/AAM-7324-2020
OI sevestre, sylvie/0000-0002-8887-089X
FU Company Telnet Innovation Labs
FX The authors would like to thank Rabaa Youssef, CEA-LinkLab, for her very
   useful advices on HTML5 as well as the Company Telnet Innovation Labs
   for financial and technology support of this project.
CR [Anonymous], 2000, Digital Watermarking
   Cazenave F, 2011, 11 ACM S DOC ENG NEW
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   Djaziri-Larbi S, 2011, 7 INT WORKSH SYST SI
   Fridrich J, 1999, IS T PICS C
   Fridrich J, 2000, SECURE STEGANOGRAPHI
   Johnson S, 2010, ADOBE ILLUSTRATOR CS
   Kim S-M, 2009, 6 INT C INF TECHN LA
   Krasner J, 2004, MOTION GRAPHICS DESI
   Kwan M, 2010, GIFSHUFFLE 2 0
   Mantiuk RK, COMP 4 SUBJECTIVE ME
   Morkel T., 2005, ISSA, V1, P1
   Mukherjee D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P348, DOI 10.1109/ICIP.1998.723494
   Niederst J., 2001, Web design in a nutshell: A desktop quick reference, V2
   Sagi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/64921
   Tzeng CH, 2004, IEEE T COMMUN, V52, P791, DOI 10.1109/TCOMM.2004.826379
   Wang X, 2005, IEEE INT C IM PROC
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HJ, 2015, MOL NEUROBIOL, V52, P1284, DOI 10.1007/s12035-014-8933-0
   Wu HZ, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P224, DOI 10.1109/ISBAST.2013.39
   Wu MY, 2004, PATTERN RECOGN LETT, V25
   Zhang DF, 2010, INT CONF COMP SCI, P216, DOI 10.1109/ICCSIT.2010.5563723
   Zhang XP, 2008, IEEE SIGNAL PROC LET, V15, P553, DOI 10.1109/LSP.2008.2001117
NR 24
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4559
EP 4575
DI 10.1007/s11042-015-2491-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700019
DA 2024-07-18
ER

PT J
AU Spampinato, C
   Palazzo, S
   Joalland, PH
   Paris, S
   Glotin, H
   Blanc, K
   Lingrand, D
   Precioso, F
AF Spampinato, C.
   Palazzo, S.
   Joalland, P. H.
   Paris, S.
   Glotin, H.
   Blanc, K.
   Lingrand, D.
   Precioso, F.
TI Fine-grained object recognition in underwater visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object classification; Marine ecosystem analysis; Environmental
   monitoring
ID CLASSIFICATION
AB In this paper we investigate the fine-grained object categorization problem of determining fish species in low-quality visual data (images and videos) recorded in real-life settings. We first describe a new annotated dataset of about 35,000 fish images (MA-35K dataset), derived from the Fish4Knowledge project, covering 10 fish species from the Eastern Indo-Pacific bio-geographic zone. We then resort to a label propagation method able to transfer the labels from the MA-35K to a set of 20 million fish images in order to achieve variability in fish appearance. The resulting annotated dataset, containing over one million annotations (AA-1M), was then manually checked by removing false positives as well as images with occlusions between fish or showing partially fish. Finally, we randomly picked more than 30,000 fish images distributed among ten fish species and extracted from about 400 10-minute videos, and used this data (both images and videos) for the fish task of the LifeCLEF 2014 contest. Together with the fine-grained visual dataset release, we also present two approaches for fish species classification in, respectively, still images and videos. Both approaches showed high performance (for some fish species the precision and recall were close to one) in object classification and outperformed state-of-the-art methods. In addition, despite the fact that dataset is unbalanced in the number of images per species, both methods (especially the one operating on still images) appear to be rather robust against the long-tail curse of data, showing the best performance on the less populated object classes.
C1 [Spampinato, C.; Palazzo, S.] Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
   [Joalland, P. H.; Paris, S.; Glotin, H.] Aix Marseille Univ, CNRS, ENSAM, LSIS,UMR 7296, F-13397 Marseille, France.
   [Joalland, P. H.; Paris, S.; Glotin, H.] Univ Toulon & Var, CNRS, LSIS, UMR 7296, F-83957 La Garde, France.
   [Paris, S.] Inst Univ France, F-75005 Paris, France.
   [Blanc, K.; Lingrand, D.; Precioso, F.] Univ Nice Sophia Antipolis, I3S, UNS CNRS, UMR 7271, F-06189 Nice, France.
C3 University of Catania; Aix-Marseille Universite; Centre National de la
   Recherche Scientifique (CNRS); Arts et Metiers Institute of Technology;
   Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); Universite de Toulon; Institut Universitaire de France;
   Universite Cote d'Azur; Centre National de la Recherche Scientifique
   (CNRS)
RP Spampinato, C (corresponding author), Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
EM cspampin@dieei.unict.it; simone.palazzo@dieei.unict.it;
   joalland@univ-tln.fr; sebastien.paris@lsis.org; glotin@univ-tln.fr;
   kblanc@i3s.unice.fr; lingrand@i3s.unice.fr; precioso@i3s.unice.fr
OI Precioso, Frederic/0000-0001-8712-1443; Palazzo,
   Simone/0000-0002-2441-0982; JOALLAND, Pierre-Hugues/0009-0009-5503-0569;
   Glotin, Herve/0000-0001-7338-8518
FU Ministere du Redressement Productif (DGCIS)
FX We thank the Ministere du Redressement Productif (DGCIS) for the support
   to the RAPID PHRASE project, and the BPI, PACA, TPM for the FUI14 SYCIE
   project.
CR [Anonymous], HUMAN CTR SOCIAL MED
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Blanc FPK, 2014, LIFECLEF 14
   Boom BJ, 2014, ECOL INFORM, V23, P83, DOI 10.1016/j.ecoinf.2013.10.006
   Boureau Y, 2012, THESIS NEW YORK U
   Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Giordano D, 2015, COMPUT VIS IMAGE UND, V131, P116, DOI 10.1016/j.cviu.2014.06.005
   Huang P.X., 2012, Comput. Vision-ACCV, P422, DOI DOI 10.1007/978-3-642-37331-2_32
   Huang PX, 2015, MACH VISION APPL, V26, P89, DOI 10.1007/s00138-014-0641-2
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Joalland P, 2014, LIFECLEF 14
   Joly A, 2014, P CLEF 2014, V1
   Khan FS., 2011, Advances in Neural Information Processing Systems 24 (NIPS-2011), P1323
   Kumar N., 2012, 12 EUR C COMP VIS EC
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mairal J., 2009, ICML 09
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paris Sebastien, 2013, Proceedings of the 2nd International Conference on Pattern Recognition Applications and Methods. ICPRAM 2013, P335
   Paris S, 2012, INT C PATT RECOG, P2817
   PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1109/CVPR.2012.6248092, 10.1109/CVPR.2012.6248092]
   Sánchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   Spampinato Concetto, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P409
   Spampinato C, 2014, P CLEF 2014, V1
   Spampinato C, 2014, MACH VISION APPL, V25, P99, DOI 10.1007/s00138-013-0509-x
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wah C, 2011, 2011 IEEE INT C COMP
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088
   Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368
   YAO BP, 2010, PROC CVPR IEEE, P9, DOI DOI 10.1109/CVPR.2010.5540234
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 40
TC 15
Z9 16
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1701
EP 1720
DI 10.1007/s11042-015-2601-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600019
DA 2024-07-18
ER

PT J
AU Sarafianos, N
   Giannakopoulos, T
   Petridis, S
AF Sarafianos, Nikolaos
   Giannakopoulos, Theodoros
   Petridis, Sergios
TI Audio-visual speaker diarization using fisher linear semi-discriminant
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker diarization; FLsD; FLD; Audio-visual fusion
ID SEGMENTATION; CLASSIFICATION
AB Speaker diarization aims to automatically answer the question "who spoke when" given a speech signal. In this work, we have focused on applying the FLsD approach, a semi-supervised version of Fisher Linear Discriminant analysis, both in the audio and the video signals to form a complete multimodal speaker diarization system. Extensive experiments have proven that the FLsD method boosts the performance of the face diarization task (i.e. the task of discovering faces over time given only the visual signal). In addition, we have proven through experimentation that applying the FLsD method for discriminating between faces is also independent of the initial feature space and remains relatively unaffected as the number of faces increases. Finally, a fusion method is proposed that leads to performance improvement in comparison to the best individual modality, which is the audio signal.
C1 [Sarafianos, Nikolaos; Giannakopoulos, Theodoros; Petridis, Sergios] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens, Greece.
C3 National Centre of Scientific Research "Demokritos"
RP Sarafianos, N (corresponding author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens, Greece.
EM nsarafianos@iit.demokritos.gr; tyiannak@gmail.com;
   petridis@iit.demokritos.gr
OI Petridis, Sergios/0000-0001-8926-7382
CR Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   [Anonymous], RT 04F WORKSH
   [Anonymous], 2002, NEOPLASIA
   [Anonymous], P 5 AS C COMP VIS
   [Anonymous], IDIAP SMART M ROOM
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   [Anonymous], 2010, International Journal of Computer Science and Applications, Techno mathematics Research Foundation vol
   Babuska R, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P1081, DOI 10.1109/FUZZ.2002.1006654
   Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261
   Carletta J., 2006, Machine Learning for Multimodal Interaction. Second International Workshop, MLMI 2005. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3869), P28
   Castaldo F, 2008, INT CONF ACOUST SPEE, P4133, DOI 10.1109/ICASSP.2008.4518564
   Chu SM, 2009, INT CONF ACOUST SPEE, P4089, DOI 10.1109/ICASSP.2009.4960527
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dielmann Alfred, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P177, DOI 10.1109/MMSP.2010.5662015
   Fleck M. M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P593
   FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208
   Friedland G, 2009, INT CONF ACOUST SPEE, P4069, DOI 10.1109/ICASSP.2009.4960522
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Garau G, 2010, INT CONF ACOUST SPEE, P4942, DOI 10.1109/ICASSP.2010.5495101
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Giannakopoulos T, 2012, IEEE T AUDIO SPEECH, V20, P1913, DOI 10.1109/TASL.2012.2191285
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Noulas A, 2012, IEEE T PATTERN ANAL, V34, P79, DOI 10.1109/TPAMI.2011.47
   Pardo JM, 2007, IEEE T COMPUT, V56, P1212, DOI 10.1109/TC.2007.1077
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Seichepine N, 2013, INT CONF ACOUST SPEE, P3537, DOI 10.1109/ICASSP.2013.6638316
   Soetedjo A, 2008, IEICE T INF SYST, VE91D, P2493, DOI 10.1093/ietisy/e91-d.10.2493
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vajaria H, 2006, INT C PATT RECOG, P1150
   Vallet F, 2013, IEEE T MULTIMEDIA, V15, P509, DOI 10.1109/TMM.2012.2233724
   Vendramin Lucas., 2009, Proceedings of the 2009 SIAM International Conference on Data Mining, P733, DOI 10.1137/1.9781611972795.63.
   Vinciarelli A., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1
   Vinciarelli A, 2009, IEEE SIGNAL PROC MAG, V26, P133, DOI 10.1109/MSP.2009.933382
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
NR 38
TC 13
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 115
EP 130
DI 10.1007/s11042-014-2274-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500006
DA 2024-07-18
ER

PT J
AU Ling, Q
   Xu, LX
   Yan, JF
   Zhang, YC
AF Ling, Qiang
   Xu, Lixiang
   Yan, Jinfeng
   Zhang, Yicheng
TI An adaptive caching algorithm suitable for time-varying user accesses in
   VOD systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caching; Segmentation; Average access interval; Byte-hit ratio
ID VIDEO; WORKLOADS
AB With the fast progresses of network technology, Video-On-Demand (VOD) service has found more and more applications. The transmission of multimedia files places heavy burdens on the Internet owing to their large sizes. To resolve this issue, caching servers are deployed at the edge of the Internet to meet most needs of local users by caching some popular videos. This paper provides an approach to choose the cached videos under the time-varying user behavior. Our approach estimates the average access intervals of a video with an Exponential Weighted Moving Average (EWMA) approach and furthermore predicts the video's future popularity based on its historical access intervals. The forgetting and predicting operations enable the algorithm to not only track the change of the time-varying user accesses, but also reduce the effects of the randomness of a single user access on the caching performance. In addition, we propose a new segmentation approach, which makes the storage granularity independent from the management granularity and can make a better use of the cache space. Simulation results show that our segmentation approach has a higher Byte-Hit Ratio than uniform segmentation and chunk segmentation, and our caching algorithm outperforms Least Recently Used (LRU), Least Frequently Used (LFU) and EWMA.
C1 [Ling, Qiang; Xu, Lixiang; Yan, Jinfeng; Zhang, Yicheng] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ling, Q (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
EM qling@ustc.edu.cn
RI Zhang, yicheng/HNC-5513-2023; Zhang, Yicheng/E-2098-2016
OI Zhang, Yicheng/0000-0001-5979-793X
FU National Natural Science Foundation of China [61273112]; Young
   Innovation Promotion Association of CAS; 973 Program [2013CB733100]
FX This work was partially supported by National Natural Science Foundation
   of China under Grant 61273112, the fund from Young Innovation Promotion
   Association of CAS and 973 Program under Grant 2013CB733100.
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   [Anonymous], NETWORKING STORAGE S
   [Anonymous], P 1990 ACM SIGMETRIC
   Brampton A, 2009, MULTIMEDIA SYST, V15, P3, DOI 10.1007/s00530-008-0126-0
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Cao P., 1997, P USENIX S INT TECHN
   Chen S., 2003, P 13 INT WORKSH NETW, P22
   Chen SQ, 2005, IEEE MULTIMEDIA, V12, P59, DOI 10.1109/MMUL.2005.56
   Chen T, 2007, EUR J OPER RES, V181, P828, DOI 10.1016/j.ejor.2006.05.034
   Cherkasova L, 2004, IEEE ACM T NETWORK, V12, P781, DOI 10.1109/TNET.2004.836125
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Elias B, 1999, IEEE 10 INT C TEL, P1367
   Guo L, 2007, SIGMETRICS07, P35
   Hartanto F, 2006, MULTIMED TOOLS APPL, V31, P221, DOI 10.1007/s11042-006-0037-z
   Hofmann M, 1999, CACHING TECHNIQUES S
   Jiang Yu, 2006, Proceedings. 20th International Conference on Advanced Information Networking and Applications
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   LI FB, 2009, 2009 INT C WEB INF S, P748, DOI DOI 10.1109/WISM.2009.154
   Liu JC, 2004, IEEE COMMUN MAG, V42, P88, DOI 10.1109/MCOM.2004.1321397
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   MUHAMMAD M, 2008, IEEE INT C MULT EXP, P1093
   Nair TR, 2010, J COMPUT, V2, P14
   Park SH, 2001, IEEE INT PAR DISTR P, P11
   Phooi Yee Lau, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P809, DOI 10.1109/ICNIDC.2010.5657984
   Reisslein M, 2002, INFORM SCIENCES, V140, P3, DOI 10.1016/S0020-0255(01)00179-7
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   SHEIKH R, 2010, IEEE INT C COMP DES, P76
   Shen L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P76
   Sokolinsky LB, 2004, LECT NOTES COMPUT SC, V2973, P670
   Tang W., 2003, HPL200323
   Tu W, 2009, IEEE T MULTIMEDIA, V11, P716, DOI 10.1109/TMM.2009.2017621
   Vakali AI, 2000, LECT NOTES COMPUT SC, V1875, P409
   Wolf JL, 1997, MULTIMEDIA SYST, V5, P358, DOI 10.1007/s005300050067
   Wu KL, 2004, IEEE T MULTIMEDIA, V6, P770, DOI 10.1109/TMM.2004.834870
   Wu Kun-Lung., 2001, P 10 INT C WORLD WID, P36
   Yu J, 2006, MULTIMEDIA SYST, V12, P135, DOI 10.1007/s00530-006-0045-x
   [No title captured]
NR 37
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11117
EP 11137
DI 10.1007/s11042-014-2220-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600008
DA 2024-07-18
ER

PT J
AU Schoeffmann, K
   Del Fabro, M
   Szkaliczki, T
   Böszörmenyi, L
   Keckstein, J
AF Schoeffmann, Klaus
   Del Fabro, Manfred
   Szkaliczki, Tibor
   Boeszoermenyi, Laszlo
   Keckstein, Joerg
TI Keyframe extraction in endoscopic video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyframe extraction; Video segmentation; Endoscopy; Medical imaging
ID KEY-FRAMES; ABSTRACTION; SELECTION
AB In medical endoscopy more and more surgeons archive the recorded video streams in a long-term storage. One reason for this development, which is enforced by law in some countries, is to have evidence in case of lawsuits from patients. Another more practical reason is to allow later inspection of previous procedures and also to use parts of such videos for research and for training. However, due to the dramatic amount of video data recorded in a hospital on a daily basis, it is very important to have good preview images for these videos in order to allow for quick filtering of undesired content and for easier browsing through such a video archive. Unfortunately, common shot detection and keyframe extraction methods cannot be used for that video data, because these videos contain unedited and highly similar content, especially in terms of color and texture, and no shot boundaries at all. We propose a new keyframe extraction approach for this special video domain and show that our method is significantly better than a previously proposed approach.
C1 [Schoeffmann, Klaus; Del Fabro, Manfred; Boeszoermenyi, Laszlo] Alpen Adria Univ Klagenfurt, Klagenfurt, Austria.
   [Szkaliczki, Tibor] Hungarian Acad Sci, Inst Comp Sci & Control, MTA SZTAKI, Budapest, Hungary.
   [Keckstein, Joerg] Villach Gen Hosp, Ctr Endometriosis Stage 3, Villach, Austria.
C3 University of Klagenfurt; Hungarian Academy of Sciences; Hungarian
   Research Network; HUN-REN Institute for Computer Science & Control
RP Schoeffmann, K (corresponding author), Alpen Adria Univ Klagenfurt, Klagenfurt, Austria.
EM ks@itec.uni-klu.ac.at
RI Keckstein, Joerg/K-1747-2019; Szkaliczki, Tibor/JHT-3607-2023;
   Szkaliczki, Tibor/H-6155-2019
OI Keckstein, Joerg/0000-0002-3943-3300; Szkaliczki,
   Tibor/0000-0002-7699-8132
FU Lakeside Labs GmbH, Klagenfurt, Austria; European Regional Development
   Fund; Carinthian Economic Promotion Fund (KWF) [KWF-20214 22573 33955];
   Hungarian National Development Agency [HUMAN_MB08-1-2011-0010]
FX This work was supported by Lakeside Labs GmbH, Klagenfurt, Austria,
   funding from the European Regional Development Fund and the Carinthian
   Economic Promotion Fund (KWF) under grant KWF-20214 22573 33955 and
   partially by the Hungarian National Development Agency under grant
   HUMAN_MB08-1-2011-0010.
CR [Anonymous], P IEEE INT S MULT IS
   [Anonymous], TELEMED E HLTH
   [Anonymous], P MULT MOD C
   [Anonymous], P INT WORKSH CONT BA
   [Anonymous], P IEEE INT S COMP BA
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Cooper M., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Del Fabro M, 2013, MULTIMEDIA SYST, V19, P427, DOI 10.1007/s00530-013-0306-4
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Doulamis ND, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P875, DOI 10.1109/ICIP.1998.723660
   Gibson D, 2002, INT C PATT RECOG, P814, DOI 10.1109/ICPR.2002.1048427
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Harris C., 1988, P ALV VIS C, P5210
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Lee HC, 2002, ELECTRON LETT, V38, P217, DOI 10.1049/el:20020112
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lux M, 2010, MULTIMED TOOLS APPL, V46, P521, DOI 10.1007/s11042-009-0353-1
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Spyrou E, 2009, MULTIMED TOOLS APPL, V41, P337, DOI 10.1007/s11042-008-0237-9
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   unzer M, 2013, IEEE INT C MULTIMEDI, P1, DOI [10.1109/ICMEW.2013.6618304, DOI 10.1109/ICMEW.2013.6618304]
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   Yong SP, 2013, MULTIMED TOOLS APPL, V62, P359, DOI 10.1007/s11042-011-0902-2
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang XD, 2003, PATTERN RECOGN LETT, V24, P1523, DOI 10.1016/S0167-8655(02)00391-4
NR 34
TC 27
Z9 27
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11187
EP 11206
DI 10.1007/s11042-014-2224-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600011
DA 2024-07-18
ER

PT J
AU Hu, ZZ
   Matsuyama, T
AF Hu, Zhaozheng
   Matsuyama, Takashi
TI Bayesian perspective-plane (BPP) with maximum likelihood searching for
   visual localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual localization; Bayesian Perspective-Plane (BPP); Generalized
   constraints; Maximum likelihood searching, Perspective-Three-Point (P3P)
ID SINGLE VIEW METROLOGY; CALIBRATION; ORIENTATION
AB The proposed "Perspective-Plane" in this paper is similar to the well-known "Perspective-n-Point (PnP)" or "Perspective-n-Line (PnL)" problems in computer vision. However, it has broader applications and potentials, because planar scenes are more widely available than control points or lines in daily life. We address this problem in the Bayesian framework and propose the "Bayesian Perspective-Plane (BPP)" algorithm, which can deal with more generalized constraints rather than type-specific ones. The BPP algorithm consists of three steps: 1) plane normal computation by maximum likelihood searching from Bayesian formulation; 2) plane distance computation; and 3) visual localization. In the first step, computation of the plane normal is formulated within the Bayesian framework, and is solved by using the proposed Maximum Likelihood Searching Model (MLS-M). Two searching modes of 2D and 1D are discussed. MLS-M can incorporate generalized planar and out-of-plane deterministic constraints. With the computed normal, the plane distance is recovered from a reference length or distance. The positions of the object or the camera can be determined afterwards. Extensions of the proposed BPP algorithm to deal with un-calibrated images and for camera calibration are discussed. The BPP algorithm has been tested with both simulation and real image data. In the experiments, the algorithm was applied to recover planar structure and localize objects by using different types of constraints. The 2D and 1D searching modes were illustrated for plane normal computation. The results demonstrate that the algorithm is accurate and generalized for object localization. Extensions of the proposed model for camera calibration were also illustrated in the experiment. The potential of the proposed algorithm was further demonstrated to solve the classic Perspective-Three-Point (P3P) problem and classify the solutions in the experiment. The proposed BPP algorithm suggests a practical and effective approach for visual localization.
C1 [Hu, Zhaozheng] Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Peoples R China.
   [Hu, Zhaozheng; Matsuyama, Takashi] Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
C3 Wuhan University of Technology; Kyoto University
RP Hu, ZZ (corresponding author), Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Peoples R China.
EM zhaozheng.hu@gmail.com
RI Hu, Zhaozheng/AGC-2475-2022
OI Hu, Zhaozheng/0000-0002-7204-2459
FU National Natural Science Foundation of China (NSFC) [51208168]; Tianjin
   Natural Science Foundation [13JCYBJC37700]; Youth Top-Notch Talent Plan
   of Hebei Province, China; Fundamental Research Funds for the Central
   Universities [WUT: 2014-IV-068]; Japan Society for the Promotion of
   Science (JSPS) [10049]
FX The work presented in this paper was sponsored by National Natural
   Science Foundation of China (NSFC) ( No. 51208168), Tianjin Natural
   Science Foundation (No. 13JCYBJC37700), the Youth Top-Notch Talent Plan
   of Hebei Province, China, the Fundamental Research Funds for the Central
   Universities (WUT: 2014-IV-068), and the Grant-in-Aid for Scientific
   Research Program (No. 10049) from the Japan Society for the Promotion of
   Science (JSPS).
CR Adan A, 2009, LANDMARK REAL TIME R
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Cham T, 2010, ESTIMATING CAMERA PO
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Guan P, 2009, ESTIMATING HUMAN SHA
   Guo F, 2010, IEEE T PATTERN ANAL, V32, P1329, DOI 10.1109/TPAMI.2010.26
   Hallquist A, 2013, IEEE WORK APP COMP, P347, DOI 10.1109/WACV.2013.6475039
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Hu Z, 2012, BAYESIAN PERSPECTIVE, P241
   Kneip L., 2011, P 24 IEEE C COMP VIS
   Lategahn H., 2014, TRANSPORTATION SYSTE, DOI [10.1109/TITS.2014.2298492, DOI 10.1109/TITS.2014.2298492]
   Lee D., 2009, IEEE INT C COMP VIS
   Leopardi P, 2006, ELECTRON T NUMER ANA, V25, P309
   Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41
   Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774
   Liebowitz D, 1998, METRIC RECTIFICATION
   Pretto Alberto, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P168, DOI 10.1109/CoASE.2013.6654067
   Schneider D, 2010, RECONSTRUCTION DISPL
   Shi F, 2004, PATTERN RECOGN, V25, P805
   Sun Y, 2008, AUTOMATIC POSE ESTIM
   Wang GH, 2005, IMAGE VISION COMPUT, V23, P831, DOI 10.1016/j.imavis.2005.04.002
   Wang RY, 2012, MACH VISION APPL, V23, P579, DOI 10.1007/s00138-010-0316-6
   WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9
   WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P319, DOI 10.1016/j.imavis.2005.11.008
   Zhang BW, 2008, J OPT SOC AM A, V25, P612, DOI 10.1364/JOSAA.25.000612
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhu X., 2012, Face Detection, Pose Estimation, and Landmark Localization in the Wild
NR 30
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9547
EP 9572
DI 10.1007/s11042-014-2134-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200023
DA 2024-07-18
ER

PT J
AU Han, LZ
   Kang, SS
   In, HP
AF Han, Longzhe
   Kang, Seung-Seok
   In, Hoh Peter
TI An adaptive loss protection for video transmission over content-centric
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-centric networks; Forward error correction; Packet loss
   recovery; Video streaming
AB Content-Centric Networking (CCN) is an emerging communication paradigm that is built on a central component, named data. The advantages of CCN provide new opportunities for Internet multimedia applications. The retransmission-based loss recovery approach used by CCN, however, is not efficient enough for delay-sensitive video streaming services. This paper proposes an Adaptive Loss Protection scheme for video transmission over Content-Centric Networks (ALP-CCN). The proposed ALP-CCN introduces the Forward Error Correction (FEC) mechanism with the CCN retransmission approach. By monitoring the packet loss rate and transmission delay, our proposed ALP-CCN coordinates FEC and retransmission adaptively. The experimental results demonstrate that the ALP-CCN is able adaptively to adjust and control the redundancy rate and achieve better video quality than the existing approaches under various network conditions.
C1 [Han, Longzhe] Nanchang Inst Technol, Sch Informat Engn, Nanchang 330099, Peoples R China.
   [Kang, Seung-Seok] Seoul Womens Univ, Dept Comp Sci, Seoul 139774, South Korea.
   [In, Hoh Peter] Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea.
C3 Nanchang Institute Technology; Seoul Women's University; Korea
   University
RP In, HP (corresponding author), Korea Univ, Dept Comp Sci & Engn, 1,5 Ka, Seoul 136701, South Korea.
EM longzhehan@gmail.com; msukang@swu.ac.kr; hoh_in@korea.ac.kr
FU Next-Generation Information Computing Development Program through
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT
   Future Planing [2012M3C4A7033345]; Basic Science Research Program
   through National Research Foundation of Korea (NRF) - Ministry of
   Education, Science and Technology [2012R1A1A2009021]; Seoul Women's
   University
FX All this research work has been done in Korea University, Seoul, South
   Korea. This research was supported in part by the Next-Generation
   Information Computing Development Program through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Science, ICT &
   Future Planing (2012M3C4A7033345), and by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (2012R1A1A2009021), and by
   a special research grant from Seoul Women's University (2013).
CR Basalamah A, 2007, GLOB TELECOMM CONF, P4702
   Breslau L, 2000, COMPUTER, V33, P59, DOI 10.1109/2.841785
   Detti A., 2012, Proc. WOWMOM, P1
   Han L, 2010, KSII T INTERNET INF, V4, P341, DOI 10.3837/tiis.2010.06.009
   Handley M, 2006, 4566 RFC
   Li ZQ, 2011, INT J POLYM SCI, V2011, DOI 10.1155/2011/803428
   Lin CH, 2008, IEEE T BROADCAST, V54, P517, DOI 10.1109/TBC.2008.2001713
   Lu Z, 2013, IEEE INFOCOM SER, P2706
   Paxson Vern., 2000, Computing tcp's retransmission timer
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Tsai MF, 2010, MULTIMED TOOLS APPL, V47, P49, DOI 10.1007/s11042-009-0406-5
   Wang X, 2013, IEEE WIREL COMMUN, V20, P72, DOI 10.1109/MWC.2013.6549285
   Wicker S.B., 1999, Reed-Solomon codes and their applications
NR 13
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8279
EP 8292
DI 10.1007/s11042-014-1874-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600003
DA 2024-07-18
ER

PT J
AU Ribón, JCR
   Villalba, LJG
   Kim, TH
AF Rodriguez Ribon, Julio Cesar
   Garcia Villalba, Luis Javier
   Kim, Tai-hoon
TI Virtual learning communities: unsolved troubles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Architectures for educational technology system;
   Cooperative/collaborative learning; Distributed learning environments;
   Learning communities
AB Virtual learning communities are defined as groups where multiple organizations share learning resources and make collaborative learning activities. The Learning Management Systems (LMS) are technological platforms that allow the realization of these spaces in a cooperative cloud of e-learning. In the present paper it is highlighted that despite the fact that organizations agree to cooperate with each other, to develop virtual learning communities, the generation of these spaces are not common, for this reason the paper raises the Ho hypothesis: The LMS present inability to cooperating to generate virtual learning communities that are developed among multiple organizations. The main objective in the present work is to corroborate the hypothesis raised, for which the problem is described and also to review the state of the art is made, noticing that it appears recurrently. Besides, the degree of fitness in current LMS is valued, verifying if they possess functionalities in their architectures to enable communities in a cooperative cloud of e-learning. This paper is useful for organizations that want to develop cooperative learning tasks for their members (students, teachers, directors) given that it identifies functional requirements that LMS must attend in order to make such communities possible. In this paper the problem is divided in variables that facilitate its comprehension and allow validating the hypothesis raised.
C1 [Rodriguez Ribon, Julio Cesar] Univ Cartagena, Fac Ingn, Programa Ingn Sistemas, Cartagena De Indias, Colombia.
   [Garcia Villalba, Luis Javier] Univ Complutense Madrid, Fac Informat, Dept Ingn Software Inteligencia Artificial, E-28040 Madrid, Spain.
   [Kim, Tai-hoon] Sungshin Womens Univ, Dept Convergence Secur, Seoul 136742, South Korea.
C3 Universidad de Cartagena; Complutense University of Madrid; Sungshin
   Women's University
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, Fac Informat, Dept Ingn Software Inteligencia Artificial, Despacho 431, E-28040 Madrid, Spain.
EM jrodriguezr@unicartagena.edu.co; javiergv@fdi.ucm.es; taihoonn@daum.net
RI Garcia Villalba, Luis Javier/N-4631-2014
OI Garcia Villalba, Luis Javier/0000-0001-7573-6272
FU Agencia Espanola de Cooperacion Internacional para el Desarrollo (AECID,
   Spain) through Accion Integrada MAEC-AECID MEDITERRANEO [A1/037528/11];
   Security Engineering Research Center - Ministry of Knowledge Economy
   (MKE, Korea)
FX This work was supported by the Agencia Espanola de Cooperacion
   Internacional para el Desarrollo (AECID, Spain) through Accion Integrada
   MAEC-AECID MEDITERRANEO A1/037528/11. This work was also supported by
   the Security Engineering Research Center, granted by the Ministry of
   Knowledge Economy (MKE, Korea).
CR Akram A, 2006, P 4 INT WORKSH MIDDL, V194, DOI [10.1145/1186675.1186697, DOI 10.1145/1186675.1186697]
   [Anonymous], SCORM SHAR CONT OBJ
   Bleiholder J, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456651
   Booth D., 2004, WEB SERVICES ARCHITE
   Chang CK, 2008, COMPUT EDUC, V50, P235, DOI 10.1016/j.compedu.2006.05.003
   CHEON E, 2009, P 3 INT C UB INF MAN
   Colace F., 2003, 36th Hawaii International Conference on Systems Sciences
   Drira K, 2000, P 26 EUROMICRO, V2, P2158
   Ferretti S., 2008, P 2008 INT CROSS DIS, P116
   Guo Y, 2008, 17TH IEEE INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURES FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P165, DOI 10.1109/WETICE.2008.26
   Hara N, 2009, J INF SCI, V35, P740, DOI 10.1177/0165551509342361
   Haslhofer B, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1667062.1667064
   Intapong P., 2010, INT J ADV SCI TECHNO, V22, P37
   Iriberri A, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459356
   Kim KR, 2013, MULTIMED TOOLS APPL, V64, P423, DOI 10.1007/s11042-012-1014-3
   Liu IF, 2010, COMPUT EDUC, V54, P600, DOI 10.1016/j.compedu.2009.09.009
   Liu Xiaofei., 2003, CCECE 2003 CANADIAN, P717, DOI DOI 10.1109/CCECE.2003.1225995
   Minovic M, 2013, MULTIMED TOOLS APPL, V63, P927, DOI 10.1007/s11042-011-0964-1
   Nagarajan D., 2010, International Journal of u-and e-Service, Science Technology, V3, P37
   Ribón JCR, 2011, COMM COM INF SC, V263, P295
   Simon B., 2005, SIMPLE QUERY INTERFA
   Sung J, 2009, IJUNESST, V2, P63
   Venugopal S, 2006, ACM COMPUT SURV, V38, pB1, DOI 10.1145/1132952.1132955
NR 23
TC 6
Z9 6
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8505
EP 8519
DI 10.1007/s11042-013-1543-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600017
DA 2024-07-18
ER

PT J
AU Takahashi, M
   Clippingdale, S
   Naemura, M
   Shibata, M
AF Takahashi, Masaki
   Clippingdale, Simon
   Naemura, Masahide
   Shibata, Masahiro
TI Estimation of viewers' ratings of TV programs based on behaviors in home
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interface; Attention; Gaze; Face tracking; Head pose
   estimation
ID FACE TRACKING; RECOGNITION; ATTENTION; MODELS
AB A system is described that can estimate a viewer's ratings of TV programs on the basis of his/her behaviors in a home environment. A Kinect sensor, a motion-sensing device developed by Microsoft for its Xbox game console, is used to measure various behavioral parameters. The system first detects whether a viewer is present by extracting keypoint trajectories in video sequences captured by the sensor's video camera. It then identifies whether the viewer is gazing at the TV screen or not by extracting head pose information. The extraction is carried out using two modules: a color-image-based module and a color- and depth-image-based module. The two modules share their parameters and complement each other's characteristics. The proposed system was evaluated by having 30 participants individually spend about 2 h watching 15 TV programs in a simulated home environment, capturing video images of their behaviors, and having them rate each program on a five-point scale. Comparison of the system's estimated ratings with the actual viewer ratings demonstrated that the system can robustly estimate a viewer's ratings of TV programs in a home environment.
C1 [Takahashi, Masaki; Clippingdale, Simon; Naemura, Masahide; Shibata, Masahiro] Japan Broadcasting Corp NHK, Sci & Technol Res Labs, Setagaya Ku, Tokyo, Japan.
C3 NHK Japan Broadcasting Corp
RP Takahashi, M (corresponding author), Japan Broadcasting Corp NHK, Sci & Technol Res Labs, Setagaya Ku, 1-10-11 Kinuta, Tokyo, Japan.
EM takahashi.m-iu@nhk.or.jp
RI Clippingdale, Simon/Y-4491-2019
FU Strategic Information and Communications R&D Promotion Programme (SCOPE)
   of the Ministry of Internal Affairs and Communication of Japan
FX Part of this work was supported by the Strategic Information and
   Communications R&D Promotion Programme (SCOPE) of the Ministry of
   Internal Affairs and Communication of Japan.
CR AlMejrad A.S., 2010, Eur J Sci Res, V44, P640
   [Anonymous], WORLD ACAD SCI ENG T
   [Anonymous], 2013, THESIS ROCHESTER I T
   [Anonymous], INTERSPEECH
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], TR9608 RUHR U BOCH I
   [Anonymous], PROGR GUID FAC TRACK
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Clippingdale S, 2012, INT J MULTIMED DATA, V3, P36, DOI 10.4018/jmdem.2012010103
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Felfernig A., 2007, OEGAI journal, V25, P17
   Funes Mora KennethAlberto., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P25, DOI DOI 10.1109/CVPRW.2012.6239182
   Grafsgaard JF, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P145
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Hernandez J, 2013, PROC AUTOMATIC FACE, P1
   Kimura A, 2013, IEICE T INF SYST, VE96D, P562, DOI 10.1587/transinf.E96.D.562
   Leavitt N, 2006, COMPUTER, V39, P13, DOI 10.1109/MC.2006.176
   Lu K, 2012, IEEE IMAGE PROC, P2589, DOI 10.1109/ICIP.2012.6467428
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nakano T, 2009, P ROY SOC B-BIOL SCI, V276, P3635, DOI 10.1098/rspb.2009.0828
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stiefelhagen R, 2002, IEEE T NEURAL NETWOR, V13, P928, DOI 10.1109/TNN.2002.1021893
   Takahashi M, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P6, DOI 10.1109/SITIS.2013.13
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yamamoto M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1165, DOI 10.1109/ICME.2008.4607647
   Yasuma Y, 2011, LECT NOTES COMPUT SC, V6770, P234, DOI 10.1007/978-3-642-21708-1_27
NR 28
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8669
EP 8684
DI 10.1007/s11042-014-2352-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600027
DA 2024-07-18
ER

PT J
AU Pozueco, L
   Pañeda, XG
   García, R
   Melendi, D
   Cabrero, S
   Orueta, GD
AF Pozueco, Laura
   Garcia Paneda, Xabiel
   Garcia, Roberto
   Melendi, David
   Cabrero, Sergio
   Diaz Orueta, Gabriel
TI Adaptation engine for a streaming service based on MPEG-DASH
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic adaptive streaming over HTTP (DASH); Scalable video coding
   (SVC); Adaptation algorithms; Bandwidth estimation
ID VIDEO
AB HTTP Video streaming has become a strong candidate for video transmission on the Internet thanks to the abundance of web infrastructure. With the recent standardization of the new MPEG Dynamic Adaptive Streaming over HTTP (DASH), the flexibility and implantation of adaptive video systems has increased due to the fact that DASH can operate on a conventional web infrastructure. In this paper we propose an estimation and adaptation system for DASH. The proposed adaptive algorithm is based on client buffer threshold and smooth throughput measures (based on the throughput of previous segments). Before DASH, the standard of Scalable Video Coding (SVC) also arose from the idea of adaptation. Both systems (adaptive system based on SVC and the proposed system for DASH) are compared in terms of Video Quality (VQ) metrics. The results show that the proposed system reacts properly to changes in the network capacity, while maintaining a minimum level of segments in the buffer. The user-perceived quality is better than in the SVC-based adaptive system although the generated traffic is higher.
C1 [Pozueco, Laura; Garcia Paneda, Xabiel; Garcia, Roberto; Melendi, David; Cabrero, Sergio] Univ Oviedo, Dept Informat, Gijon, Spain.
   [Diaz Orueta, Gabriel] Spanish Univ Distance Educ UNED, Elect & Comp Dept, Madrid, Spain.
C3 University of Oviedo; Universidad Nacional de Educacion a Distancia
   (UNED)
RP Pozueco, L (corresponding author), Univ Oviedo, Dept Informat, Gijon, Spain.
EM pozuecolaura.uo@uniovi.es; xabiel@uniovi.es; garciaroberto@uniovi.es;
   melendi@uniovi.es; cabrerosergio@uniovi.es; gdiaz@ieec.uned.es
RI Pozueco, Laura/AAV-1452-2020; Cabrero-Barros, Sergio/AAR-4882-2020;
   Garcia, Roberto/KVY-3276-2024; ORUETA, GABRIEL DIAZ/ABF-9707-2020;
   Melendi, David/H-5592-2013
OI Cabrero-Barros, Sergio/0000-0002-3734-577X; Garcia,
   Roberto/0000-0002-5042-8684; ORUETA, GABRIEL DIAZ/0000-0001-9246-351X;
   Melendi, David/0000-0001-8251-5646; Pozueco, Laura/0000-0002-7918-0141;
   Garcia-Paneda, Xicu Xabiel/0000-0001-6381-5459
FU University of Oviedo; Principality of Asturias [SV-PA-13-ECOEMP-75]
FX This work was partially supported by the University of Oviedo and the
   Principality of Asturias through the SV-PA-13-ECOEMP-75 project.
CR Akhshabi S, 2012, SIGNAL PROCESS-IMAGE, V27, P271, DOI 10.1016/j.image.2011.10.003
   Alvarez A, 2013, COMPUT COMMUN, V36, P1608, DOI 10.1016/j.comcom.2013.07.005
   Andelin T., 2012, Proceedings of the 3rd ACM Multimedia Systems Conference, P149
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 2012, 2300912012 ISOIEC
   [Anonymous], P 2 ANN ACM C MULT S
   Arsan T, 2012, INT SYM HIGH CAPAC, P152
   Begen AC, 2011, IEEE INTERNET COMPUT, V15, P54, DOI 10.1109/MIC.2010.155
   Biernacki A, 2014, MULTIMED TOOLS APPL, V72, P1143, DOI 10.1007/s11042-013-1424-x
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Famaey J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P419
   Fraga A, 2011, MULTIMED TOOLS APPL, V54, P569, DOI 10.1007/s11042-010-0566-3
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Kantarci A, 2008, MULTIMED TOOLS APPL, V36, P303, DOI 10.1007/s11042-007-0147-2
   Kofler I, 2012, CONSUM COMM NETWORK, P549, DOI 10.1109/CCNC.2012.6180986
   Lederer S., 2012, P 3 MULT SYST C, P89
   Lohmar T., 2011, IEEE INT S WORLD WIR, P1, DOI DOI 10.1109/WOWMOM.2011.5986186
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Mueller C., 2013, Proceedings of the IEEE International Conference on Multimedia and Expo (ICME) 2013, P1
   Pozueco L, 2013, COMPUT ELECTR ENG, V39, P775, DOI 10.1016/j.compeleceng.2013.01.015
   Schierl T, 2011, MULTIMED TOOLS APPL, V55, P227, DOI 10.1007/s11042-010-0572-5
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Tian G., 2012, P 8 INT C EM NETW EX, P109
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Wang B, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352020
   Wu DP, 2000, IEEE T CIRC SYST VID, V10, P923, DOI 10.1109/76.867930
   Zhou C., 2012, 2012 Visual Communications and Image Processing, P1
NR 28
TC 2
Z9 2
U1 6
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7983
EP 8002
DI 10.1007/s11042-014-2034-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200026
DA 2024-07-18
ER

PT J
AU Sun, Y
   Feng, ZD
   Ginnavaram, RR
AF Sun, Yu
   Feng, Zhidan
   Ginnavaram, Reshma R.
TI A direct non-buffer rate control algorithm for real time video
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; PID bit controller; Bit allocation; Video compression
ID INCREMENTAL RATE CONTROL; RATE CONTROL SCHEME; BIT ALLOCATION; FRAME
   RATE; OPTIMIZATION; H.264; MODEL
AB Rate control (RC) is crucial in controlling compression bitrates and encoding qualities for networked video applications. In this paper, we propose a direct non-buffer real-time rate control algorithm for video encoding, which has two unique features. First, unlike traditional algorithms which adopt buffers in rate control, the proposed algorithm does not use a buffer in rate regulation which can reduce the delay and improve real-time response. Second, we propose a new Proportional-Integral-Derivative (PID) bit controller to directly control encoding bitrates. In addition, we also develop a simple but effective method for real-time target bit allocation. To the best of our knowledge, this is the first work that conducts video rate control without using a buffer. Our extensive experimental results have demonstrated that the proposed algorithm outperforms the MPEG-4 rate control algorithm by achieving more accurate rate regulation and improving overall coding quality.
C1 [Sun, Yu; Ginnavaram, Reshma R.] Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA.
   [Feng, Zhidan] Univ Arkansas, Sch Med, IT Res Grp, Little Rock, AR 72204 USA.
C3 University of Central Arkansas; University of Arkansas System;
   University of Arkansas Little Rock; University of Arkansas Fayetteville
RP Sun, Y (corresponding author), Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA.
EM yusun@uca.edu; zfeng@uams.edu
FU NASA EPSCoR [NNX13AD32A]; Uni. of Central Arkansas; NASA [475328,
   NNX13AD32A] Funding Source: Federal RePORTER
FX This work is partially supported by NASA EPSCoR 2012 Award (No.
   NNX13AD32A) and faculty sabbatical leave fund from Uni. of Central
   Arkansas.
CR [Anonymous], 1999, N3093 ISOIEC JTC1SC2
   [Anonymous], 1993, ISOIECJTCISC29WG1193
   Chen ZZ, 2007, SIGNAL PROCESS-IMAGE, V22, P19, DOI 10.1016/j.image.2006.11.002
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Leontaris A., 2007, 23 M SAN JOS CAL US
   Leontaris A, 2007, 24 M SAN JOS US
   Li Z., 2003, 7 M PATT THAIL
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Ruan R, 2011, P 6 INT C COMP SCI E
   [沈礼权 SHEN Liquan], 2006, [光电子·激光, Journal of Optoelectronics·Laser], V17, P948
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Sun Y, 2005, IEEE T CIRC SYST VID, V15, P1007, DOI 10.1109/TCSVT.2005.852415
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   Sun Y, 2009, IET IMAGE PROCESS, V3, P286, DOI 10.1049/iet-ipr.2009.0037
   Tan E, 2012, IEEE T MULTIMEDIA, V14, P910, DOI 10.1109/TMM.2011.2180706
   Tao B, 2000, IEEE T CIRC SYST VID, V10, P147, DOI 10.1109/76.825868
   Tian L, 2012, J VIS COMMUN IMAGE R, V23, P873, DOI 10.1016/j.jvcir.2012.05.005
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P140, DOI 10.1109/TCSVT.2007.913757
   Yang J, 2012, IET IMAGE PROCESS, V6, P43, DOI 10.1049/iet-ipr.2009.0366
   Yang J, 2013, MULTIMED TOOLS APPL, V64, P581, DOI 10.1007/s11042-011-0967-y
   Zhou YM, 2011, IEEE T CIRCUITS-II, V58, P184, DOI 10.1109/TCSII.2011.2106350
   Zhou YM, 2009, SIGNAL PROCESS-IMAGE, V24, P345, DOI 10.1016/j.image.2009.02.014
NR 26
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6623
EP 6639
DI 10.1007/s11042-014-1913-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800002
DA 2024-07-18
ER

PT J
AU Hong, CP
   Kim, CG
   Kim, KJ
   Kim, SD
AF Hong, Chung-Pyo
   Kim, Cheong-Ghil
   Kim, Kuinam J.
   Kim, Shin-Dug
TI A polymorphic service management scheme based on virtual object for
   ubiquitous computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous computing; Virtual object; Virtual Personal World;
   Polymorphism
AB For the ubiquitous computing environment, an important assumption is that all the components in any specific environment are connected with each other. With this assumption, we introduce an effective scheme to provide a personalized service based on Virtual Personal World (VPW). Virtual Personal World (VPW) which is a model focused on service continuity with specially designed components. Previous ubiquitous frameworks have been concerned with the location where a user is provided any specific service. However those questions above are not the most important problems anymore in VPW. It concentrates on the point whether the services are successive or not, wherever a user goes to any place. Services are not regarded as a sum of functions which is embedded on any objects in any certain place. We conceptually define a resource management scheme based on a unified form of the object which participates in service provision, so called virtual object (VO). Thus the service can be described as the sum of functions of VOs. With our resource management scheme, users can utilize their required object as VO wherever it is located. And also, for better utilization of VPW service, we introduce a novel form of profiles and service provision scheme based on the polymorphism. Our simulation result shows that the Ratio of VPW pure service time is 0.15 % higher than conventional location based service. And also the possibility that users can meet adequate service he wants raised 29 % in our proposed VPW environment.
C1 [Hong, Chung-Pyo; Kim, Shin-Dug] Yonsei Univ, Dept Comp Sci, Sch Engn C532, Seoul 120749, South Korea.
   [Kim, Cheong-Ghil] Namseoul Univ, Dept Comp Sci, Cheonan Si 331707, Chungcheongnam, South Korea.
   [Kim, Kuinam J.] Kyonggi Univ, Dept Convergence Secur, Suwon 443760, Gyeonggi Do, South Korea.
C3 Yonsei University; Namseoul University; Kyonggi University
RP Kim, SD (corresponding author), Yonsei Univ, Dept Comp Sci, Sch Engn C532, Shinchon Dong 134, Seoul 120749, South Korea.
EM hulkboy@yonsei.ac.kr; cgkim@nsu.ac.kr; harap123@hanmail.net;
   sdkim@yonsei.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012R1A1A2043400]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (No. 2012R1A1A2043400).
CR Baldauf M, 2007, INT J AD HOC UBIQ CO, V2, P263, DOI 10.1504/IJAHUC.2007.014070
   Ballagas R, 2006, IEEE PERVAS COMPUT, V5, P70, DOI 10.1109/MPRV.2006.18
   Harter A, 2002, WIREL NETW, V8, P187, DOI 10.1023/A:1013767926256
   Mohapatra D, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON PERSONAL WIRELESS COMMUNICATIONS, P358, DOI 10.1109/ICPWC.2005.1431366
   Mori G, 2004, IEEE T SOFTWARE ENG, V30, P507, DOI 10.1109/TSE.2004.40
   Park KL, 2008, IEEE T SYST MAN CY A, V38, P1295, DOI 10.1109/TSMCA.2008.2003468
   Ponnekanti Shankar., 2001, P 3 INT C UBIQUITOUS, P56
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Schilke SW, 2004, INTERNET RES, V14, P379, DOI 10.1108/10662240410566980
   Scholtz J, 2004, TECHNICAL REPORT
   Singh MunindarP., 2005, SERVICE ORIENTED COM
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
NR 12
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6183
EP 6196
DI 10.1007/s11042-014-2090-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700004
DA 2024-07-18
ER

PT J
AU Choi, CR
   Jeong, HY
   Park, JH
   Jeong, YS
AF Choi, Cheol-Rim
   Jeong, Hwa-Young
   Park, Jong Hyuk
   Jeong, Young-Sik
TI Relative weight evaluation of the factors inducing social media service
   use
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media service; Relative importance degree; Analytic network
   process
ID INFORMATION-TECHNOLOGY; ACCEPTANCE
AB As an influence of social media service (SMS) is extending enormously and SMS becomes an important marketing way and a field of modern industry beyond a method to transfer informations. Under these circumstances that the influence of SMS is getting bigger bigger, which factors make users participate and work in the social media service and how relatively important these factors are between them need to be examined. But SMS are different from the existing information systems. Most information systems are task-oriented, that is, the systems aim to provide users with useful information for better decision making. Therefore, a different approach is required. In this research, we examine and select the main factors which affect users' social media service use, and evaluate relative importance degrees of each factor on the basis of relationships between the factors with Analytic Network Process (ANP).
C1 [Choi, Cheol-Rim; Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Young-Sik] Dongguk Univ, Dept Multimedia Engn, Seoul, South Korea.
C3 Kyung Hee University; Seoul National University of Science & Technology;
   Dongguk University
RP Jeong, YS (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul, South Korea.
EM cr_brian@khu.ac.kr; hyjeong@khu.ac.kr; parkjonghyuk1@hotmail.com;
   ysjeong@dongguk.edu
OI Jeong, Hwa-Young/0000-0002-5017-934X
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under ITRC
   (Information Technology Research Center) [NIPA-2013-H0301-13-4007];
   National Research Foundation of Korea [22A20130012202] Funding Source:
   Korea Institute of Science & Technology Information (KISTI), National
   Science & Technology Information Service (NTIS)
FX This research supported by the MSIP (Ministry of Science, ICT and Future
   Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2013-H0301-13-4007) supervised by the NIPA
   (National IT Industry Promotion Agency).
CR Agarwal R, 2000, MIS QUART, V24, P665, DOI 10.2307/3250951
   Agarwal R, 1999, DECISION SCI, V30, P361, DOI 10.1111/j.1540-5915.1999.tb01614.x
   ASHTONA MC, 1988, EVOL HUM BEHAV, V19, P243
   BARD JF, 1990, IEEE T ENG MANAGE, V37, P222, DOI 10.1109/17.104292
   Clément R, 2001, J SOC ISSUES, V57, P559, DOI 10.1111/0022-4537.00229
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Erickson T, 2002, COMMUN ACM, V45, P102, DOI 10.1145/503124.503154
   Evans D., 2008, Social media marketing: an hour a day, V1st
   Gallego D., 2012, J CONVERGENCE, V3, P41
   HEITZMANN CA, 1988, HEALTH PSYCHOL, V7, P75, DOI 10.1037/0278-6133.7.1.75
   Hyde K., 2003, Journal of Multi-criteria Decision Analysis, V12, P245, DOI DOI 10.1002/MCDA.361
   Kailiponi P, 2010, PROCEDIA ENGINEER, V3, P163, DOI 10.1016/j.proeng.2010.07.016
   KIM T, 2004, J COMPUTER MEDIATED, V3
   Kim Y., 2012, Journal of Computational Science Education, V3, P47, DOI DOI 10.22369/ISSN.2153-4136/3/1/6
   Kwon OB, 2004, EXPERT SYST APPL, V27, P609, DOI 10.1016/j.eswa.2004.06.008
   Kwon O, 2010, COMPUT HUM BEHAV, V26, P254, DOI 10.1016/j.chb.2009.04.011
   McDowell M., 2011, SOCIALIZING SECURELY
   Oommen BJ, 2012, J INF PROCESS SYST, V8, P191, DOI 10.3745/JIPS.2012.8.2.191
   Rau PLP, 2008, COMPUT HUM BEHAV, V24, P2757, DOI 10.1016/j.chb.2008.04.001
   Riedlinger ME, 2004, J APPL COMMUN RES, V32, P55, DOI 10.1080/0090988042000178130
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   Sin SS, 2012, PROCD SOC BEHV, V40, P326, DOI 10.1016/j.sbspro.2012.03.195
   TANG XL, 2006, STAT DECISION MAKING, V12, P138
   Turban E., 2009, Introduction to Electronic Commerce
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 1999, MIS QUART, V23, P239, DOI 10.2307/249753
   Yu RC, 2006, APPL MATH COMPUT, V180, P63, DOI 10.1016/j.amc.2005.11.163
   Zhu YH, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-15
NR 28
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5041
EP 5054
DI 10.1007/s11042-013-1713-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900004
DA 2024-07-18
ER

PT J
AU Ikegami, Y
   Tsuruta, S
AF Ikegami, Yukino
   Tsuruta, Setsuo
TI Hybrid method for modeless Japanese input using N-gram based binary
   classification and dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilingual documents; Modeless Japanese input
AB The rapid growth of globalization requires handling a large number of multilingual documents, where Japanese input co-exist with English and other languages, which use the Roman alphabet. Conventional methods for Japanese input require Japanese users to switch the input mode between Japanese and the Latin alphabet. As current solution, there is a modeless Japanese input method that automatically switches the input mode. However, those need training with a large amount of text data for improving the performance. This paper proposes a hybrid modeless Japanese input method that is based on the non-Japanese word dictionary and n-gram character sequence features to decide whether to convert and switch to Kana input or not. The aim of using the non-Japanese word dictionary is decreasing false positive against non-Japanese language words. This dictionary is composed by text data available on the Web. The n-gram based discriminative model are learned by a Support Vector Machine from a balanced corpus, which contains various domain texts. The evaluation of our method has shown that its statistical accuracy according to F-measure for prediction of non-Kana characters improves 7.7 % compared to n-gram only based method. In addition, the real user test has shown the average value of inputted time was agreeside for our method, against disagree side for conventional Japanese input method that requires switching input mode.
C1 [Ikegami, Yukino; Tsuruta, Setsuo] Tokyo Denki Univ, Inzai, Chiba, Japan.
C3 Tokyo Denki University
RP Ikegami, Y (corresponding author), Tokyo Denki Univ, 2-1200 MuzaiGakuendai, Inzai, Chiba, Japan.
EM 12jkm03@ms.dendai.ac.jp; tsuruta@sie.dendai.ac.jp
FU Scientific Research of the government of Japan [KAKENHI 24700214]
FX This work was supported by Grant-in-Aid for Scientific Research of the
   government of Japan (KAKENHI 24700214). The authors are also thankful to
   Ms. Yukiko Yamamoto, a student of Tokyo Denki University, for her
   miscellaneous help such as English translation and check.
CR [Anonymous], 1983, Cognitive aspects of skilled typewriting, DOI DOI 10.1007/978-1-4612-5470-6_6
   Beesley Kenneth., 1988, Proceedings of the 29th Annual Conference of the American Translators Association, P47
   Bellandi V, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P637, DOI 10.1109/SITIS.2012.96
   Cavnar W.B., 1994, Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval, V48113, P161
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Damiani E, 2004, PARALLEL AND DISTRIBUTED COMPUTING SYSTEMS, P559
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   Dumais S, 1998, IEEE INTELL SYST APP, V13, P21
   Ehara Y., 2008, P 3 INT JOINT C NAT, P441
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hakkani-Tür DZ, 2002, COMPUT HUMANITIES, V36, P381, DOI 10.1023/A:1020271707826
   Ikegami Y, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P613, DOI 10.1109/SITIS.2012.93
   Internet.com K.K. (Japan), 2009, ROM KAN INP US 90 DI
   Japanese Ministry of Internal Affairs and Communications, 2009, UT SIT INT
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI [10.1145/1150402.1150429, DOI 10.1145/1150402.1150429]
   Kasahara S., 2011, P WORKSH ADV TEXT IN, P38
   Kerkhofs R, 2006, BRAIN RES, V1068, P170, DOI 10.1016/j.brainres.2005.10.087
   Kudo T, 2004, P 2004 C EMP METH NA, P230
   Maekawa Kikuo, 2008, P 3 INT JOINT C NAT, P101
   Neubig G, 2013, P AAAI 13 SPRING S A
   Neubig G., 2011, P 49 ANN M ASS COMP, P529
   Pouliquen B, 2006, ARXIVCS0609059
   Roeber H., 2003, CHI'03 extended abstracts on Human factors in computing systems, P712, DOI DOI 10.1145/765891.765944
   Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807
   Suzumegano F., 1995, IPSJ SIG Tech. Rep. 1995-HI-42, P9
   Teahan W.J., 2000, Content-Based Multimedia Information Access-Volume, V2, P943
   Zheng C, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P241
   Zheng YF, 2002, P SOC PHOTO-OPT INS, V4670, P49
NR 28
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3933
EP 3946
DI 10.1007/s11042-013-1805-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800015
DA 2024-07-18
ER

PT J
AU Nam, Y
AF Nam, Yunyoung
TI Loitering detection using an associating pedestrian tracker in crowded
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormality; Loitering; Optimal threshold; Moving objects; Object
   identification; Spatio-temporal database; HSI color model
ID REAL-TIME; ABANDONED OBJECTS; ROBUST
AB This paper presents a loitering detection method using an associating pedestrian tracker in public areas. We analyze the spatio-temporal characteristics to perform monitoring of people and generate alerts when loitering persons are detected. To determine and adjust a time threshold for raising an alarm, we obtain the mean time of stay for normal and abnormal situation. In addition, we consider an optimal threshold for staying time and escaping time to deal with various conditions. For object identification, we measure the mean square error and histogram of oriented gradients. In order to trace moving objects continuously, the HSI color model and a combination of Euclidean distance, color difference, and shape difference are measured based on consistent labeling tracking. To evaluate the performance of our method, we showed detection results of the PETS2007 dataset using thresholds obtained by our proposed methods. Our experiments show promising results with 75.45 % averaged recall rate and 87.12 % averaged precision rate were obtained in loitering objects. We also compared the proposed method to other reported methods. The experimental results showed a significant improvement on precision.
C1 Worcester Polytech Inst, Dept Biomed Engn, Worcester, MA 01607 USA.
C3 Worcester Polytechnic Institute
RP Nam, Y (corresponding author), Worcester Polytech Inst, Dept Biomed Engn, Worcester, MA 01607 USA.
EM young022@gmail.com
RI Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
FU International Collaborative R&D Program of the Ministry of Knowledge
   Economy (MKE), the Korean government [2010-TD-300802-002]
FX This research is supported by the International Collaborative R&D
   Program of the Ministry of Knowledge Economy (MKE), the Korean
   government, as a result of Development of Security Threat Control System
   with Multi-Sensor Integration and Image Analysis Project,
   2010-TD-300802-002.
CR [Anonymous], 2002, P IEEE COMP SOC C CO, DOI [DOI 10.1109/CVPR.1997.609310, 10.1109/CVPR.1997.609310]
   [Anonymous], 10 IEEE INT WORKSH P
   Beynon MD, 2003, P IEEE C ADV VID SIG, P221
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Black J, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P189
   Choi YJ, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P818, DOI 10.1109/ICCIT.2008.116
   Corporation I, 2012, SOURC OP COMP VIS LI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalley G, 2007, PETS WORKSH IEEE, P71
   Dalley GE, 2009, THESIS MIT
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Gabriel PF, 2003, CITESEER, P166
   Gasser G, 2004, IEEE INT CONF ROBOT, P90, DOI 10.1109/ROBOT.2004.1307134
   Huang CH, 2009, LECT NOTES COMPUT SC, V5414, P771, DOI 10.1007/978-3-540-92957-4_67
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Porikli F, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P236, DOI 10.1109/AVSS.2007.4425316
   Sacchi C, 2000, IEEE T VEH TECHNOL, V49, P2013, DOI 10.1109/25.892603
   Siebel NT, 2002, LECT NOTES COMPUT SC, V2353, P373
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tian YL, 2005, PROC CVPR IEEE, P1182
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Welch G., 1995, An introduction to the kalman filter
NR 27
TC 10
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2939
EP 2961
DI 10.1007/s11042-013-1763-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800005
DA 2024-07-18
ER

PT J
AU Park, RC
   Jung, H
   Chung, K
   Yoon, KH
AF Park, Roy C.
   Jung, Hoill
   Chung, Kyungyong
   Yoon, Kun-Ho
TI Picocell based telemedicine health service for human UX/UI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE u-Healthcare; Heterogeneous network; Telemedicine; Human UX/UI; Picocell
ID ENERGY-EFFICIENT; WIRELESS; SELECTION
AB Telemedicine health created from the combination of IT and BT technologies has received increased attention for improved quality of life in medically vulnerable regions. As the health care paradigm shifts to preventive management in diagnosis and treatment, the importance of prevention of chronic diseases such as obesity is growing. In this paper, we proposed a picocell-based telemedicine health service for the human UX/UI based on a BT-IT fusion technology considering user convenience. The proposed medical service is a BT-IT fusion technology based on the telemedicine health service that can overcome the spatial limitations of hospital-oriented medical services in order to improve user convenience while naturally combining life and medical service spaces. Human UX/UI technology, which is based on sensor network and biomedical technology, requires next generation wireless communication between devices that connects the inside of the human body with the outside. A heterogeneous network is composed within a single domain, as the frequency bandwidth used by the medical device in the ISM bandwidth is different. If a wireless device and low output ISM device spatially access a heterogeneous network, then an interference problem will occur between the small cells. Additionally, there can be interference as the traffic is off-loaded from the base station at the grouped region of a hotspot. A fatal problem may occur due to an information error of the patient due to interference. To solve the interference problem generated by the telemedicine health platform, the performance of the picocell-based telemedicine health service can be improved by applying scheduling using ABS(Almost Blank Subframe) in the time domain. Therefore, the human UX/UI and the provided guidelines can quickly provide patient information, thereby increasing safety of patients.
C1 [Park, Roy C.] Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, Inchon 402207, South Korea.
   [Jung, Hoill] Sangji Univ, Sch Comp Informat Engn, Intelligent Syst Lab, Wonju 220702, Gangwon Do, South Korea.
   [Chung, Kyungyong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Yoon, Kun-Ho] Catholic Univ Korea, Coll Med, Seoul St Marys Hosp, Dept Endocrinol, Seoul 137701, South Korea.
C3 Sangji University; Sangji University; Catholic University of Korea;
   Seoul St. Mary's Hospital
RP Park, RC (corresponding author), Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, 1446-2,Juan 7 Dong, Inchon 402207, South Korea.
EM roypark.asap@gmail.com; hijung1982@gmail.com; kyungyong.chung@gmail.com;
   yoonk@catholic.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
FU R&D Program for Society of the National Research Foundation (NRF) -
   Ministry of Science, ICT & Future Planning [2013M3C8A2A02078523]
FX This research was supported by the R&D Program for Society of the
   National Research Foundation (NRF) funded by the Ministry of Science,
   ICT & Future Planning (No. 2013M3C8A2A02078523).
CR Ahmed A, 2010, INT CONF COMP SCI, P26, DOI 10.1109/ICCSIT.2010.5564669
   Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Berndt R-D, 2011, 2011 IEEE 13th International Conference on e-Health Networking, Applications and Services (Healthcom 2011), P118, DOI 10.1109/HEALTH.2011.6026726
   Cheng SH, 2013, IEEE T PARALL DISTR, V24, P250, DOI 10.1109/TPDS.2012.133
   Costin H, 2008, REC ADV BIOL BIOMED, P183
   De Vleeschauwer B., 2008, P INT C INF NETW, p1 
   DeVaul R, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P4, DOI 10.1109/ISWC.2003.1241386
   Dini P, 2010, INT J COMMUN NETW DI, V5, P46, DOI 10.1504/IJCNDS.2010.033967
   Han D, 2010, COMPUT METH PROG BIO, V97, P178, DOI 10.1016/j.cmpb.2009.08.004
   Huyu Qu, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P1081, DOI 10.1109/CSE.2009.60
   Jokic S., 2012, 2012 11th Symposium on Neural Network Applications in Electrical Engineering (NEUREL 2012). Proceedings, P231, DOI 10.1109/NEUREL.2012.6420018
   Jung-Yeol Oh, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P28, DOI 10.1109/ICTC.2010.5674733
   Kamel MI, 2012, IEEE GLOB COMM CONF, P5326, DOI 10.1109/GLOCOM.2012.6503967
   Kang SK, 2013, WIRELESS PERS COMMUN, V73, P341, DOI 10.1007/s11277-013-1242-5
   Kang SW, 2013, ELECT TELECOMMUN TRE, V28, P70
   Karim S., 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P16, DOI 10.1109/IHMSC.2011.11
   Khan JY, 2012, J MED SYST, V36, P1441, DOI 10.1007/s10916-010-9605-x
   Khan P, 2011, J MED SYST, V35, P1313, DOI 10.1007/s10916-011-9756-4
   Kim JY, 2014, MULTIMED TOOLS APPL, V68, P465, DOI 10.1007/s11042-013-1357-4
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P827, DOI 10.1007/s11042-012-1195-9
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Kugsang Jeong, 2009, 2009 9th International Symposium on Communications and Information Technology. ISCIT 2009, P829, DOI 10.1109/ISCIT.2009.5341125
   Kukawka B, 2012, LECT N BIOINFORMAT, V7339, P603
   Lee JC, 2012, COMPUT COMMUN, V35, P2106, DOI 10.1016/j.comcom.2012.06.014
   López G, 2010, IEEE T INF TECHNOL B, V14, P1446, DOI 10.1109/TITB.2010.2058812
   Lu N, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P545
   Meikui Zhang, 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P534, DOI 10.1109/HealthCom.2012.6379480
   Misook S., 2006, Technology Management for the Global Future, P1931
   Mutafungwa Edward, 2010, 2010 12th IEEE International Conference on e-Health Networking, Applications and Services (Healthcom 2010), P283, DOI 10.1109/HEALTH.2010.5556554
   Park CY, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P547, DOI 10.1109/ICCE.2011.5722731
   Rho MJ, 2015, MULTIMED TOOLS APPL, V74, P2391, DOI 10.1007/s11042-013-1772-6
   Soh YS, 2013, IEEE J SEL AREA COMM, V31, P840, DOI 10.1109/JSAC.2013.130503
   Taha A.M., 2009, the 2009 Conference on Information Science, Technology and Applications, Kuwait, Kuwait, P1
   Xiao Y, 2011, INT J SENS NETW, V10, P202, DOI 10.1504/IJSNET.2011.042770
   Yen Y.-C., 2011, P 2011 INT C INF SCI, P1
   Zois DS, 2013, IEEE T SIGNAL PROCES, V61, P1581, DOI 10.1109/TSP.2012.2236320
NR 36
TC 16
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2519
EP 2534
DI 10.1007/s11042-014-1964-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200021
DA 2024-07-18
ER

PT J
AU Kourouthanassis, PE
   Boletsis, C
   Lekakos, G
AF Kourouthanassis, Panos E.
   Boletsis, Costas
   Lekakos, George
TI Demystifying the design of mobile augmented reality applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; Design principles; Field study; User
   experience
ID SYSTEM; USER; CONTEXT; ACCEPTANCE
AB This research proposes a set of interaction design principles for the development of mobile augmented reality (MAR) applications. The design recommendations adopt a user-centered perspective and, thus, they focus on the necessary actions to ensure high-quality MAR user experiences. To formulate our propositions we relied on theoretical grounding and an evaluation of eight MAR applications that provide published records of their design properties. The design principles have then been applied to guide the development of a MAR travel application. We performed a field study with 33 tourists in order to elicit whether our design choices effectively lead to enhanced satisfaction and overall user experience. Results suggest that the proposed principles contribute to ensuring high usability and performance of the MAR application as well as evoking positive feelings during user and system interactions. Our prescriptions may be employed either as a guide during the initial stages of the design process (ex-ante usage) or as a benchmark to assess the performance (ex-post usage) of MAR applications.
C1 [Kourouthanassis, Panos E.] Ionian Univ, Dept Informat, Corfu, Greece.
   [Boletsis, Costas] Gjovik Univ Coll, Fac Comp Sci & Media Technol, Gjovik, Norway.
   [Lekakos, George] Athens Univ Econ & Business, Dept Management Sci & Technol, Athens, Greece.
C3 Ionian University; Norwegian University of Science & Technology (NTNU);
   Athens University of Economics & Business
RP Kourouthanassis, PE (corresponding author), Ionian Univ, Dept Informat, Corfu, Greece.
EM pkour@ionio.gr; konstantinos.boletsis@hig.no; glekakos@aueb.gr
RI Kourouthanassis, Panos/L-2955-2018; Lekakos, George/AAK-7008-2020
OI Kourouthanassis, Panos/0000-0003-2048-9694; Boletsis,
   Costas/0000-0003-2741-8127
CR Abowd G. D., 2000, ACM Transactions on Computer-Human Interaction, V7, P29, DOI 10.1145/344949.344988
   Anacleto R, 2010, IFIP ADV INF COMM TE, V332, P301
   Anastassova M, 2007, LECT NOTES COMPUT SC, V4550, P383
   [Anonymous], 2013, Personalized services BT-Collaborative, trusted and privacy-aware e/m-services. I3E 2013
   Arvanitis TN, 2011, ADV SCI LETT, V4, P3342, DOI 10.1166/asl.2011.2044
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Aryan A., 2010, IND INF SYST ICIIS 2, DOI [10.1109/ICIINFS.2010.5578714, DOI 10.1109/ICIINFS.2010.5578714]
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Baldauf M., 2012, P 11 INT C MOB UB MU
   Balduini M, 2012, J WEB SEMANT, V16, P33, DOI 10.1016/j.websem.2012.06.004
   Biocca F, 2001, LECT NOTES ARTIF INT, V2117, P117
   Bolter Jay David, 2013, Interactions, V20, P36, DOI 10.1145/2405716.2405726
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   D?nser Andreas, 2007, APPLYING HCI PRINCIP, P37
   Dähne P, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P263, DOI 10.1109/ISMAR.2002.1115103
   Dix A., 2000, ACM Transactions on Computer-Human Interaction, V7, P285, DOI 10.1145/355324.355325
   Dubois E., 2000, P DARE 2000 DESIGNIN, P165
   Emmanouilidis C, 2013, J NETW COMPUT APPL, V36, P103, DOI 10.1016/j.jnca.2012.04.007
   Gammeter S., 2010, CVPR Workshops, P1
   Ganapathy S., 2013, Human factors in augmented reality environments, P165, DOI DOI 10.1007/978-1-4614-4205-9_7
   Gavalas D, 2014, J NETW COMPUT APPL, V39, P319, DOI 10.1016/j.jnca.2013.04.006
   Gonzalez-Sanchez Javier, 2012, International Journal of Cyber Behavior, Psychology and Learning, V2, P86, DOI 10.4018/ijcbpl.2012070107
   Hagbi N, 2011, IEEE T VIS COMPUT GR, V17, P1369, DOI 10.1109/TVCG.2010.241
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   Höllerer TH, 2004, TELEGEOINFORMATICS: LOCATION-BASED COMPUTING AND SERVICES, P221
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kalkofen D, 2007, P 2007 6 IEEE ACM IN
   Karpischek S, 2009, 3 EUR C AMB INT AMI
   Keil Jens, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P49, DOI 10.1007/978-3-642-39405-8_6
   Kim MJ, 2013, AUTOMAT CONSTR, V33, P79, DOI 10.1016/j.autcon.2012.10.020
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Langlotz T, 2012, PERS UBIQUIT COMPUT, V16, P623, DOI 10.1007/s00779-011-0430-0
   Lee JY, 2011, COMPUT IND, V62, P107, DOI 10.1016/j.compind.2010.07.003
   Linaza MT, 2012, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2012, P260
   Liu C, 2012, P SIGCHI C HUM FACT
   López MB, 2014, MULTIMED TOOLS APPL, V69, P31, DOI 10.1007/s11042-012-1252-4
   Md Sa, 2012, P 14 INT C HUM COMP
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nilsson EG, 2009, ADV ENG SOFTW, V40, P1318, DOI 10.1016/j.advengsoft.2009.01.017
   Oh S, 2012, STUD COMPUT INTELL, V413, P41
   Oinas-Kukkonen H., 2003, P IASTED INT C COMP, P50
   Olsson T., 2013, HUMAN FACTORS AUGMEN, P203
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Olsson T, 2012, J AMB INTEL SMART EN, V4, P29, DOI 10.3233/AIS-2011-0127
   Papakonstantinou S, 2009, VISUAL COMPUT, V25, P1121, DOI 10.1007/s00371-009-0391-8
   Piekarski W, 2002, COMMUN ACM, V45, P36, DOI 10.1145/502269.502291
   Qian X, 2011, P 10 INT C VIRT REAL
   Ray B, 2012, LECT NOTES I COMPUTE, V85, P515, DOI [10.1007/978-3-642-27308-7_55, DOI 10.1007/978-3-642-27308-7_55]
   Rosenblum L.J., 2012, EXPANDING FRONTIERS, P431, DOI DOI 10.1007/978-1-4471-2804-5_24
   Sa M. D., 2013, Human factors in augmented reality environments, P139, DOI [10.1007/978-1-4614-4205-9, DOI 10.1007/978-1-4614-4205-9]
   Sadeh N, 2009, PERS UBIQUIT COMPUT, V13, P401, DOI 10.1007/s00779-008-0214-3
   Savio N, 2007, MOBILE HCI, P284
   Shokri R., 2010, Proceedings of the 9th International Symposium on Privacy Enhancing Technologies (PETS'10), P203
   Sigg S, 2012, LECT NOTES I COMPUTE, V104, P314, DOI [10.1007/978-3-642-30973-1_31, DOI 10.1007/978-3-642-30973-1_31]
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Venkatesh V, 2012, MIS QUART, V36, P157
   Verbelen T, 2011, J SYST SOFTWARE, V84, P1871, DOI 10.1016/j.jss.2011.06.063
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Walls JG, 1992, INFORM SYST RES, V3, P36, DOI 10.1287/isre.3.1.36
   Wei C, 2012, P 27 ANN ACM S APPL
   World Tourism Organization & European Travel Commission, 2007, HDB TOUR MARK SEGM M
   Zhu W, 2008, IGI GLOBAL, DOI [10.4018/joeuc.2008070103, DOI 10.4018/JOEUC.2008070103]
NR 64
TC 51
Z9 60
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1045
EP 1066
DI 10.1007/s11042-013-1710-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400018
DA 2024-07-18
ER

PT J
AU Zhang, HL
   Tao, F
   Yang, GB
AF Zhang, Hanling
   Tao, Fei
   Yang, Gaobo
TI Robust visual tracking based on structured sparse representation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Sparse representation; Block division; Particle filter;
   Template update
AB Sparse representation has been one of the most influential frameworks for visual tracking. However, most tracking methods based on sparse representation only consider the holistic representation and lack local information, which may lead to fail when there is similar object or occlusion in the scene. In this paper, we present a novel robust visual tracking algorithm based on structured sparse representation model. This model includes one fixed template, nine variational templates and the background templates, which are selectively updated to adapt to the appearance change of the target. And the update scheme is developed by exploiting the strength of the incremental PCA learning and sparse representation. By incorporating the block-division feature into sparse representation framework, it can capture the intrinsic structured distribution of sparse coefficients effectively and reduce the influence of the occluded target template. In addition, we propose a sparsity-based discriminative classifier, which employ the distinction of reconstruction error between the foreground and the background to improve discrimination performance for object tracking. Both qualitative and quantitative evaluations on benchmark challenging sequences demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art tracking methods.
C1 [Zhang, Hanling; Tao, Fei; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Tao, F (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM jt_hlzhang@hnu.edu.cn; rexue34fei@126.com; yanggaobo@hnu.edu.cn
FU Chinese Forestry Industry Research Special Funds for Public Welfare
   [201104090]; Specialized Research Fund for the Doctoral Program of
   Higher Education (SRFDP) [20120161110014]; New Century Excellent Talents
   in University [NCET-11-0134]; National Natural Science Foundation of
   China [61072122]; Key Project of Hunan Provincial Natural Science
   Foundation [11JJ2053]
FX This work was supported by Chinese Forestry Industry Research Special
   Funds for Public Welfare (Grant No. 201104090). The Specialized Research
   Fund for the Doctoral Program of Higher Education
   (SRFDP)(20120161110014), New Century Excellent Talents in University
   (NCET-11-0134), National Natural Science Foundation of China (61072122),
   and Key Project of Hunan Provincial Natural Science Foundation
   (11JJ2053).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Chen J, 2006, INT C PATT RECOG, P516
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Eldar YC, 2010, IEEE T SIGNAL PROCES, V58, P3042, DOI 10.1109/TSP.2010.2044837
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Zhang HL, 2013, ELECTRON LETT, V49, P109, DOI 10.1049/el.2012.2286
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang S, 2010, SPIE INT C VIS COMM
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 34
TC 8
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1021
EP 1043
DI 10.1007/s11042-013-1709-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400017
DA 2024-07-18
ER

PT J
AU Zhang, WZ
   Mo, ZC
   Chen, C
   Zheng, QH
AF Zhang, Weizhan
   Mo, Zhichao
   Chen, Cheng
   Zheng, Qinghua
TI CBC: Caching for cloud-based VOD systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caching; Cloud computing; VOD
ID VIDEO; DEMAND; INTERNET
AB Cloud-based video on demand (VOD) service is a promising next-generation media streaming service paradigm. Being a resource-intensive application, how to maximize resource utilization is a key issue of designing such an application. Due to the special cloud-based VOD system architecture consisting of cloud storage cluster and media server cluster, existing techniques such as traditional caching strategies are inappropriate to be adopted by a cloud-based VOD system directly in practice. Therefore, in this study, we have proposed a systemic caching scheme, which seamlessly integrates a caching algorithm and a cache deployment algorithm together to maximize the resources utilization of cloud-based VOD system. Firstly, we have proposed a cloud-based caching algorithm. The algorithm models the cloud-based VOD system as a multi-constraint optimization problem, so as to balance the resource utilization between cloud storage cluster and media server cluster. Secondly, we have proposed a cache deployment algorithm. The algorithm further manages the bandwidth and cache space resource utilization inside the media server cluster in a more fine-grained manner, and achieves load balancing performance. Our evaluation results show that the proposed scheme enhances the resource utilization of the cloud-based VOD system under resource-constrained situation, and cuts down the reject ratio of user requests.
C1 [Zhang, Weizhan; Mo, Zhichao; Chen, Cheng; Zheng, Qinghua] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, SKLMS Lab, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Zhang, WZ (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, SKLMS Lab, Xian 710049, Peoples R China.
EM zhangwzh@mail.xjtu.edu.cn; mozhichao@stu.xjtu.edu.cn;
   ccnopro@stu.xjtu.edu.cn; qhzheng@mail.xjtu.edu.cn
FU National Science Foundation of China [61103239, 61221063]; National High
   Technology Research and Development Program 863 of China [2012AA011003];
   Cheung Kong Scholar's Program; Fundamental Research Funds for the
   Central Universities; Key Projects in the National Science and
   Technology Pillar Program [2012BAH16F02]
FX The research was supported in part by National Science Foundation of
   China under Grant Nos. 61103239, 61221063; National High Technology
   Research and Development Program 863 of China under Grant No.
   2012AA011003; Cheung Kong Scholar's Program; the Fundamental Research
   Funds for the Central Universities; Key Projects in the National Science
   and Technology Pillar Program under Grant Nos. 2012BAH16F02.
CR Abboud O., 2011, Proceedings of the second annual ACM conference on Multimedia systems, MMSys '11, P223, DOI DOI 10.1145/1943552.1943582
   Aggarwal V., 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P637, DOI 10.1109/INFCOMW.2011.5928890
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Carlsson N, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671955
   Chen SQ, 2005, IEEE MULTIMEDIA, V12, P59, DOI 10.1109/MMUL.2005.56
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Dan A, 1996, P SOC PHOTO-OPT INS, V2667, P344, DOI 10.1117/12.235887
   Di Niu, 2012, Performance Evaluation Review, V40, P151, DOI 10.1145/2318857.2254776
   Garcia A., 2010, Proc. ACM Multimedia Workshop on Mobile Cloud Media Computing (MCMC), P13, DOI DOI 10.1145/1877953.1877959
   Haitao Li, 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P203, DOI 10.1109/CLOUD.2011.41
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Jha R. K., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P011, DOI 10.1109/RAICS.2011.6069264
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Liu JC, 2004, IEEE COMMUN MAG, V42, P88, DOI 10.1109/MCOM.2004.1321397
   Meskill B, 2011, C LOCAL COMPUT NETW, P255, DOI 10.1109/LCN.2011.6115202
   Nan XM, 2011, IEEE INT WORKSH MULT
   Niu D, 2012, IEEE INFOCOM SER, P460, DOI 10.1109/INFCOM.2012.6195785
   Papakos P., 2010, Proceedings of the 9th International Workshop on Adaptive and Reflective Middleware, P32
   Pawar S, 2011, CODES DISTRIBUTED CA
   Phooi Yee Lau, 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P272, DOI 10.1109/ICEIE.2010.5559876
   Shu C, 2011, P SOC PHOTO-OPT INS, P83
   Tewari R., 1998, P SPIE ACM C MULT CO, P191
   Tu W, 2009, IEEE T MULTIMEDIA, V11, P716, DOI 10.1109/TMM.2009.2017621
   Wu Y, 2011, INT CON DISTR COMP S, P268, DOI 10.1109/ICDCS.2011.50
   Zhang Q, 2012, PEER PEER NETW APPL, V27, P484
   Zhang WZ, 2011, MULTIMED TOOLS APPL, V53, P97, DOI 10.1007/s11042-010-0492-4
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 28
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1663
EP 1686
DI 10.1007/s11042-013-1663-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200025
DA 2024-07-18
ER

PT J
AU Hopfgartner, F
   Jose, JM
AF Hopfgartner, Frank
   Jose, Joemon M.
TI An experimental evaluation of ontology-based user profiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Multiple time series study; Personalisation
ID NEWS; WEB
AB In recent years, a number of research works have been carried out to improve the information retrieval process by exploiting external knowledge, e. g. by employing ontologies. Even though ontologies seem to be a promising technique to improve the retrieval process, hardly any study has been performed to evaluate the use of ontologies over a longer time period to model user interests. In this work we introduce an ontology based video recommender system that exploits implicit relevance feedback to capture users' evolving information needs. The system exploits a generic ontology to organise users' interests. We evaluate the recommendations by performing a user-centred multiple time-series study where participants were asked to include the system into their daily news gathering routine. The results of this study suggest that the system can be successfully employed to improve personal information seeking tasks in news domain.
C1 [Hopfgartner, Frank] Int Comp Sci Inst, Berkeley, CA 94704 USA.
   [Jose, Joemon M.] Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
C3 University of Glasgow
RP Hopfgartner, F (corresponding author), Int Comp Sci Inst, Berkeley, CA 94704 USA.
EM fh@icsi.berkeley.edu
RI Hopfgartner, Frank/H-4598-2014
OI Hopfgartner, Frank/0000-0003-0380-6088; Jose, Joemon/0000-0001-9228-1759
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], P 2008 ACM MULT VANC
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Belkin Nicholas J., 2008, SIGIR Forum, V42, P47, DOI 10.1145/1394251.1394261
   Bharat K, 1998, MULTIMEDIA SYST, V6, P349, DOI 10.1007/s005300050098
   Borlund P, 2003, INFORM RES, V8
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, P132, DOI 10.1145/280765.280789
   Christel M. G., 2007, P ACM MM 2007, P707
   Christel MG, 2007, SPIE 06 P SPIE MULT, V6506
   Dudev M, 2008, P PERSDB
   Fernandez M., 2009, SEMSEARCH 09
   Fernández N, 2006, LECT NOTES COMPUT SC, V4273, P778
   Hopfgartner F, 2011, LWA 11 P WORKSH INF
   Hopfgartner F., 2011, SEMAIS, P21
   Hopfgartner F, 2010, MULTIMEDIA SYST, V16, P255, DOI 10.1007/s00530-010-0189-6
   Hopfgartner F, 2010, LECT NOTES COMPUT SC, V5916, P336, DOI 10.1007/978-3-642-11301-7_35
   KELLY D, 2004, THESIS RUTGERS U
   Kelly D, 2009, COMPUTER, V42, P60, DOI 10.1109/MC.2009.82
   Liu JJ, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P26
   Misra H, 2010, MMM 10 16 INT C MULT, V1, P347
   Perez-Aguera JR, 2010, SEM SEARCH 2010 WORK
   Ruthven Ian, 2011, Interactive Information Seeking, Behaviour and Retrieval
   Shneiderman B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168158
   Vallet D, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961214
NR 25
TC 1
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 1029
EP 1051
DI 10.1007/s11042-012-1254-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700025
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Jalal, AS
   Singh, V
AF Jalal, Anand Singh
   Singh, Vrijendra
TI A framework for background modelling and shadow suppression for moving
   object detection in complex wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Shadow suppression; Complex Wavelet domain
ID DENSITY-ESTIMATION; SEGMENTATION; TRACKING; MOTION
AB This paper describes a simple, robust and efficient framework for background subtraction and cast shadow suppression in complex wavelet domain. A background subtraction approach exploiting noise resilience capability of wavelet domain combined with local spatial coherence and median filter in the training stage is proposed. A novel shadow suppression scheme based on directional coefficients of Daubechies complex wavelet transform is introduced. The effectiveness of the proposed approach is demonstrated via qualitative and quantitative evaluation measures on both indoor and outdoor video sequences. The experimental results show that the proposed approach outperforms state-of-the-art methods.
C1 [Jalal, Anand Singh; Singh, Vrijendra] GLA Univ, Mathura 281406, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Mathura 281406, India.
EM anandsinghjalal@gmail.com; vrij@iiita.ac.in
RI singh, vrijendra/AAC-7170-2020
OI singh, vrijendra/0000-0002-8818-5673; Jalal, Anand/0000-0002-7469-6608
CR Avery RP, 2007, J TRANSPORT RES BOAR
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Clonda D, 2004, SIGNAL PROCESS, V84, P1, DOI 10.1016/j.sigpro.2003.06.001
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Fang LZ, 2008, PATTERN RECOGN LETT, V29, P2182, DOI 10.1016/j.patrec.2008.08.009
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang J, 2004, IEE ELECT LETT, V40
   Huang JC, 2003, ELECTRON LETT, V39, P1380, DOI 10.1049/el:20030909
   Kim H, 2007, OPT ENG, V46, DOI 10.1117/1.2779030
   Lina JM, 1997, J MATH IMAGING VIS, V7, P211, DOI 10.1023/A:1008274210946
   Lu Y., 2006, P INT C COMP INT MOD, P37
   McKenna S. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P348, DOI 10.1109/AFGR.2000.840658
   Parks Donovan H., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P192, DOI 10.1109/AVSS.2008.19
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Romberg JK, 2001, IEEE IMAGE PROC, P614, DOI 10.1109/ICIP.2001.959120
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 27
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 779
EP 801
DI 10.1007/s11042-012-1326-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700009
DA 2024-07-18
ER

PT J
AU Trindade, DR
   Raposo, AB
AF Trindade, Daniel Ribeiro
   Raposo, Alberto Barbosa
TI Improving 3D navigation techniques in multiscale environments: a
   cubemap-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Navigation; Multiscale environments; Cubemap; Interaction techniques
AB Navigation in virtual 3D environments, especially those with multiscale features, is still a problem for many users. In this regard, a good design of the navigation interfaces is critical to ensure that the users navigate with the best possible efficiency and comfort. In this paper, we present improvements for two well-known interfaces: fly, including support to collision treatment and automatic navigation speed adjustment in relation to scale, and examine, with automatic pivot point. Such techniques are based on the cubemap structure, which provides information about the surrounding environment at each instant. Usability tests with both beginner and advanced users revealed that the proposed techniques created a significant improvement in the execution of navigation tasks and a reduction in navigation errors.
C1 [Trindade, Daniel Ribeiro; Raposo, Alberto Barbosa] Pontifical Catholic Univ Rio de Janeiro, Tecgraf Dept Informat, Rio De Janeiro, Brazil.
C3 Pontificia Universidade Catolica do Rio de Janeiro
RP Raposo, AB (corresponding author), Pontifical Catholic Univ Rio de Janeiro, Tecgraf Dept Informat, Rio De Janeiro, Brazil.
EM danielrt@tecgraf.puc-rio.br; abraposo@tecgraf.puc-rio.br
RI Raposo, Alberto B/G-3204-2012
OI Raposo, Alberto/0000-0001-7279-1823
FU Petrobras; CAPES; FAPERJ; CNPq
FX The authors thank Petrobras for this research support and for the
   software used in this research (SiVIEP). D. Trindade thanks CAPES and A.
   Raposo, FAPERJ and CNPq for the individual support granted to this
   research.
CR [Anonymous], 2008, Measuring the User Experience Collecting, Analyzing, and Presenting Usability Metrics
   [Anonymous], 2009, P S INT 3D GRAPH GAM, DOI DOI 10.1145/1507149.1507186
   Baciu G, 1998, PACIFIC GRAPHICS '98, PROCEEDINGS, P125, DOI 10.1109/PCCGA.1998.732079
   Baciu G, 1997, FIFTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P51, DOI 10.1109/PCCGA.1997.626171
   Bederson B. B., 1994, C COMP HUM FACT COMP, V24, P315, DOI DOI 10.1145/259963.260379
   Calomeni A., 2006, PROC S INTERACTIVE 3, P175
   Fitzmaurice G, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P7
   Furnas G. W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P234
   Jul S., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P97, DOI 10.1145/288392.288578
   Khan A, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P17
   Khan Azam., 2005, Proceedings of the 2005 symposium on Interactive 3D graphics and games, I3D '05, P73, DOI DOI 10.1145/1053427.1053439
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Mackinlay J. D., 1990, Computer Graphics, V24, P171, DOI 10.1145/97880.97898
   McCrae James., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P7, DOI [10.1145/1507149.1507151, DOI 10.1145/1507149.1507151, 10.1145/1507149.15071512, DOI 10.1145/1507149.15071512]
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   ROCHA RD, 2008, SAC 08 P 2008 ACM S, P1241, DOI DOI 10.1145/1363686.1363972
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Tan D. S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P418, DOI 10.1145/365024.365307
   Ware C., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P127, DOI 10.1145/253284.253319
   Ware C., 1990, Computer Graphics, V24, P175, DOI 10.1145/91394.91442
   Xiao D., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P179, DOI 10.1145/274644.274671
   Zhang XL, 2009, VIRTUAL REAL-LONDON, V13, P101, DOI 10.1007/s10055-009-0114-5
NR 22
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 939
EP 959
DI 10.1007/s11042-012-1127-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700020
DA 2024-07-18
ER

PT J
AU Chen, B
   Zhang, WM
   Ma, KD
   Yu, NH
AF Chen, Biao
   Zhang, Weiming
   Ma, Kede
   Yu, Nenghai
TI Recursive code construction for reversible data hiding in DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Ternary cover; Recursive code construction;
   JPEG; DCT domain
ID SCHEME
AB Reversible data hiding has extensive applications in fields like data authentication, medical data management and error concealment. In this paper, we formulate the model of reversible data hiding over a special ternary cover that is suitable for any transform domain, such as DCT domain, where the probability density function of the transformed coefficients has a Laplacian distribution with a small variance. After deriving rate-distortion function for this model, we propose a code construction that can approach the rate-distortion bound. Based on the code construction, a reversible data hiding method for JPEG images is proposed. Experimental results demonstrate that proposed method has a good balance among image quality, filesize increment and computation time. The excellent performance of proposed method also demonstrate the power of our code construction for reversible data hiding on DCT based media.
C1 [Chen, Biao] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
   [Zhang, Weiming; Ma, Kede; Yu, Nenghai] Univ Sci & Technol China, Dept Informat Sci, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Dept Informat Sci, Hefei 230027, Peoples R China.
EM chb893@mail.ustc.edu.cn; weimingzhang@yahoo.cn; kdma@mail.ustc.edu.cn;
   ynh@ustc.edu.cn
OI Ma, Kede/0000-0001-8608-1128
FU Natural Science Foundation of China [61170234, 60803155]; CAS
   [XDA06030601]; Science and Technology on Information Assurance
   Laboratory [KJ-13-02]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61170234 and Grant 60803155, by the Strategic and
   Piloted Project of CAS under Grant XDA06030601, and by the funding of
   Science and Technology on Information Assurance Laboratory under Grant
   KJ-13-02.
CR Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Feng J.B., 2006, IJ Network Security, V2, P161
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Kalker T, 2003, PROC SPIE, V5020, P604, DOI 10.1117/12.473164
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Weiming Zhang, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P255, DOI 10.1007/978-3-642-24178-9_18
   Wong K., 2010, International Symposium on Communications, Control, and Signal Processing, P1, DOI DOI 10.1109/ISCCSP.2010.5463307
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
NR 26
TC 6
Z9 6
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1985
EP 2009
DI 10.1007/s11042-013-1493-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300042
DA 2024-07-18
ER

PT J
AU Chun, S
   Kang, D
   Choi, HR
   Park, A
   Lee, KK
   Kim, J
AF Chun, Sungkuk
   Kang, Donghoon
   Choi, Hyeong-Rae
   Park, Anjin
   Lee, Ki-Kwang
   Kim, Jinwook
TI A sensor-aided self coaching model for uncocking improvement in golf
   swing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Golf coaching; Sensor system; IMU; Uncocking
ID WEIGHT TRANSFER PATTERNS; VELOCITIES; ROTATION
AB This paper describes an autonomous kinematic analysis platform for wrist angle measurement that is capable of evaluating a user's uncocking motion in his or her golf swing and providing instructional multimodal feedback to improve his or her skills. This uncocking motion, which is a characteristic movement of the wrist during the golf swing, is an important factor in achieving accurate ball hitting and long driving distances, but is difficult to measure. In order to efficiently compute the wrist angle for uncocking evaluation, we present a sensor-based intelligent Inertial Measurement Unit (IMU) agent that collects three-dimensional orientation data during the golf swing from two IMU sensors placed on the forearm and on the golf club. It accurately analyzes changes in wrist angle to detect uncocking throughout the sequence of golf swing motions. In this paper, we first introduce the design considerations based on the concept of the uncocking motion and explain the system architecture with the sensors used for quantitative measurement and qualitative feedback generation. Then, we illustrate the detailed algorithms for wrist angle computation, golf swing motion segmentation based on key pose detection, and uncocking evaluation. A multimodal feedback-based user interface for our system is also presented. Experimental results show that the proposed system has the ability to accurately calculate the wrist angle in real time and also that it can be applied to a practical self-coaching system to improve the uncocking motion.
C1 [Chun, Sungkuk; Kang, Donghoon; Choi, Hyeong-Rae; Park, Anjin; Kim, Jinwook] Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
   [Chun, Sungkuk] Univ Sci & Technol, Dept HCI & Robot, Seoul, South Korea.
   [Lee, Ki-Kwang] Kookmin Univ, Dept Sport Sci, Seoul, South Korea.
C3 Korea Institute of Science & Technology (KIST); Kookmin University
RP Chun, S (corresponding author), Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
EM k612051@imrc.kist.re.kr
RI liu, ting/AAA-1112-2022; Lee, KiKwang/JCO-5828-2023
OI Kang, Donghoon/0000-0003-4362-1029
FU IT R&D program of MKE/MCST/IITA (Development of Real-time Physics
   Simulation Engine for e-Entertainment) [2008-F-033-02]; Sports Industry
   R&D program of MCST (Development of VR based Tangible Sports System)
FX This work was supported in part by the IT R&D program of MKE/MCST/IITA
   (2008-F-033-02, Development of Real-time Physics Simulation Engine for
   e-Entertainment) and the Sports Industry R&D program of MCST
   (Development of VR based Tangible Sports System).
CR Ball KA, 2007, J SPORT SCI, V25, P771, DOI 10.1080/02640410600875002
   Barrón C, 2001, COMPUT VIS IMAGE UND, V81, P269, DOI 10.1006/cviu.2000.0888
   Fossati A, 2010, IEEE T PATTERN ANAL, V32, P1165, DOI 10.1109/TPAMI.2009.108
   Ghasemzadeh H., 2009, P 4 INT C BODY AREA, P1, DOI [DOI 10.4108/ICST.BODYNETS2009.6035, 10.4108/ICST.BODYNETS2009.6035]
   Ghasemzadeh H, 2009, J AMB INTEL SMART EN, V1, P173, DOI 10.3233/AIS-2009-0021
   Gulgin H, 2009, J SPORT SCI MED, V8, P296
   Hume PA, 2005, SPORTS MED, V35, P429, DOI 10.2165/00007256-200535050-00005
   Huyghe B, 2012, IEEE T INSTRUM MEAS, V61, P2274, DOI 10.1109/TIM.2012.2187248
   Ing WK, 2011, PROTOTYPING BODY SEN
   Joyce C, 2010, SPORT BIOMECH, V9, P206, DOI 10.1080/14763141.2010.516446
   MCTEIGUE M, 1994, SCIENCE AND GOLF II, P50
   MILBURN PD, 1982, MED SCI SPORT EXER, V14, P60, DOI 10.1249/00005768-198201000-00012
   Negoro H., 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1111
   Okuda I, 2010, J SPORT SCI MED, V9, P127
   Park A, 2012, IEEE IMAGE PROC, P573, DOI 10.1109/ICIP.2012.6466924
   RICHARDS J, 1985, RES Q EXERCISE SPORT, V56, P361, DOI 10.1080/02701367.1985.10605341
   Shen Y., 2008, IEEE C COMPUTER VISI, P1, DOI DOI 10.1109/CVPR.2008.4587755
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Tessendorf B., 2011, Proceedings of the 2011 Seventh International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), P253, DOI 10.1109/ISSNIP.2011.6146535
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006
   Watanabe K, 2006, IEEE T SYST MAN CY A, V36, P549, DOI 10.1109/TSMCA.2005.855777
   Wheeler K, 2006, SPORT SOC, V9, P427, DOI 10.1080/17430430600673449
   Yujin Jung, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1746, DOI 10.1109/ROBIO.2010.5723595
NR 24
TC 14
Z9 19
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 253
EP 279
DI 10.1007/s11042-013-1359-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800013
DA 2024-07-18
ER

PT J
AU Liu, NH
AF Liu, Ning-Han
TI Design of an intelligent car radio and music player system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Radio recommendation; Car audio system; Artificial
   intelligence
ID RECOMMENDER SYSTEMS; TAXONOMY
AB With the rapid development of the Internet and digital technology, digital music and Internet radio stations have come to attract increasing investment from various sources. Through the Internet, users are able to listen to music and radio stations without geographical limitations. The Internet also provides users more options in their music and radio station choices. The technological developments in this field allow for improvements in car audio systems. However, across all relevant studies, the question of how best to recommend radio or music choices to users remains an important topic in the research relating to digital music and radio. Therefore, in this paper, we try to improve these recommendations by recording user behavior and analyzing the music preferences of users with similar background information. This is different to traditional recommendation mechanisms as we simplify the feedback procedure for users. In addition, by adjusting the weightings in the formula for calculating the recommendations, we are able to provide personalized recommendations. This would better satisfy the needs of different types of users. Through experimental results, we prove that our recommendation mechanism significantly helps users to select radio stations and music.
C1 Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung, Taiwan.
C3 National Pingtung University Science & Technology
RP Liu, NH (corresponding author), Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung, Taiwan.
EM gregliu@mail.npust.edu.tw
FU NSC in Taiwan [NSC100-2218-E-020-003, NSC101-2221-E-020-025]
FX This work was supported in part by the NSC in Taiwan under the contact
   numbers NSC100-2218-E-020-003 and NSC101-2221-E-020-025.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Aizenberg N., 2012, P 21 INT C WORLD WID, P1, DOI DOI 10.1145/2187836.2187838
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bogdanov D, 2013, INFORM PROCESS MANAG, V49, P13, DOI 10.1016/j.ipm.2012.06.004
   Bogdanov Dmitry., 2011, 12th International Society for Music Information Retrieval Conference, number ISMIR 2011, P97
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Chen HC, 2005, J INTELL INF SYST, V24, P113, DOI 10.1007/s10844-005-0319-3
   Chen HC, 2001, ACM INT C INF KNOWL
   Cho YH, 2004, EXPERT SYST APPL, V26, P233, DOI 10.1016/S0957-4174(03)00138-6
   CLAYPOOL M, 1999, ACM SIGIR WORKSH REC
   Domingues MA, 2013, INT J MULTIMED INF R, V2, P3, DOI 10.1007/s13735-012-0025-1
   Dror G, 2011, INT C REC SYST ACM
   Fischer P, 2010, LECT NOTES COMPUT SC, V6075, P315, DOI 10.1007/978-3-642-13470-8_29
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Kautz H, 1997, COMMUN ACM, V40, P63, DOI 10.1145/245108.245123
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Kostov V, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P378
   Krulwich B, 1997, IEEE EXPERT, V12, P22, DOI 10.1109/64.621224
   Lai S., 2011, KDD CUP
   Lawrence RD, 2001, DATA MIN KNOWL DISC, V5, P11, DOI 10.1023/A:1009835726774
   Lee SK, 2010, INFORM SCIENCES, V180, P2142, DOI 10.1016/j.ins.2010.02.004
   Li Q, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P33
   Li YM, 2010, APPL INTELL, V33, P117, DOI 10.1007/s10489-008-0153-8
   LIU NH, 2013, J APPL INTELL, V38, P160
   Liu NH, 2009, INT J COMPUTER SCI N, V9
   Liu NH, 2010, EXPERT SYST APPL, V37, P2815, DOI 10.1016/j.eswa.2009.09.009
   Montaner M, 2003, ARTIF INTELL REV, V19, P285, DOI 10.1023/A:1022850703159
   Nanopoulos A, 2010, IEEE T AUDIO SPEECH, V18, P407, DOI 10.1109/TASL.2009.2033973
   Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125
   Sarwar B, 2000, ACM C ELECT COMM
   SCHEIN AI, 2001, SIGIR WORKSH REC SYS
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.34
   Terveen L, 1997, COMMUN ACM, V40, P59, DOI 10.1145/245108.245122
   Tzeng YS, 2004, IASTED C INT MULT SY
   Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091
   Yoshii K, 2006, 7 INT C MUS INF RETR
   Zaharchuk V, 2012, P INT WORKSH EXP EC, P72
NR 38
TC 5
Z9 6
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1341
EP 1361
DI 10.1007/s11042-013-1467-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300015
DA 2024-07-18
ER

PT J
AU Shen, LQ
   Zhang, ZY
AF Shen, Liquan
   Zhang, Zhaoyang
TI Efficient depth coding in 3D video to minimize coding bitrate and
   complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth coding; Low-complexity; Mode decision; Color video-depth
   correlation
ID INFORMATION; COLOR
AB In three-dimensional video (3DV) coding, color videos and depth maps both need to be coded. Usually, two-channel coding method is used in the system of 3DV coding which encodes color videos and depth maps based on two parallel codec implements. The complexity and hardware requirements are nearly two times higher than coding the 2D color video. Meanwhile, depth maps in 3DV usually are estimated from color video data and the estimated depth itself can be very noisy. In this paper, we propose fast and effective depth coding to minimize depth coding bitrate and the coding complexity. The 3 x 3 bilateral filter is first utilized to pre-process depth maps to reduce noises from the depth estimation procedure, and thus unnecessary bits to code depth noises can be reduced. Meanwhile, there is a high correlation among motion information from color videos and depth maps. Coding information including motion vectors and the prediction mode is drawn from the color video to accelerate the mode decision procedure of depth coding and reduce the temporal variation of depth maps. Experimental results show that the proposed algorithm can reduce 70% computational complexity of depth coding and 20% depth bitrate.
C1 [Shen, Liquan; Zhang, Zhaoyang] Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Shen, LQ (corresponding author), Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai 200072, Peoples R China.
EM jsslq@163.com
RI Zhang, Zhaoyang/AFQ-9161-2022; Shen, Liquan/D-4832-2012
FU Shanghai Rising-Star Program [11QA1402400]; Innovation Program of
   Shanghai Municipal Education Commission [13ZZ069]; National Natural
   Science Foundation of China [60832003, 60902085, 61171084, 61171096]
FX This work is sponsored by Shanghai Rising-Star Program (11QA1402400) and
   Innovation Program of Shanghai Municipal Education Commission (No.
   13ZZ069), and is supported by the National Natural Science Foundation of
   China under grant No. 60832003, 60902085, 61171084 and 61171096.
CR [Anonymous], 2001, ITU-T SG16/Q6
   De Silva DVSX, 2010, INT CONF ACOUST SPEE, P686, DOI 10.1109/ICASSP.2010.5495093
   Grewatsch S, 2004, IEEE IMAGE PROC, P3271
   Kim WS, 2009, IEEE IMAGE PROC, P721, DOI 10.1109/ICIP.2009.5414304
   Konrad J, 2007, IEEE SIGNAL PROC MAG, V24, P97, DOI 10.1109/MSP.2007.905706
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Lin YH, 2011, IEEE T BROADCAST, V57, P542, DOI 10.1109/TBC.2011.2131510
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Minghui Wang, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P502, DOI 10.1109/PCS.2010.5702547
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Oh H, 2006, LECT NOTES COMPUT SC, V4319, P898
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   POURAZAD MT, 2006, EUR SIGN PROC C EUSI
   Seo J., 2010, 3DTV C TRUE VISION C, P1
   Shen LQ, 2010, IEEE SIGNAL PROC LET, V17, P887, DOI 10.1109/LSP.2010.2066966
   Sung-Yeol Kim, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P117
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   VETRO A, 2007, JVTX207
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Yoon SU, 2007, IEEE T CIRC SYST VID, V17, P1450, DOI 10.1109/TCSVT.2007.905363
   Zhang QW, 2011, IEEE T CONSUM ELECTR, V57, P1857, DOI 10.1109/TCE.2011.6131164
NR 23
TC 5
Z9 5
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1639
EP 1652
DI 10.1007/s11042-013-1455-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300027
DA 2024-07-18
ER

PT J
AU Yan, DQ
   Wang, RD
AF Yan, Diqun
   Wang, Rangding
TI Detection of MP3Stego exploiting recompression calibration-based feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; MP3; Calibration; Sensitivity
ID AUDIO STEGANALYSIS; STEGANOGRAPHY
AB MP3Stego is a typical steganographic tool for MP3 audio. Once the cover audio is unavailable, it is hard to distinguish between background noise and steganographic distortion. In this work, the MP3Stego algorithm has been analyzed from a warden's perspective. It is observed that the number of bits in the bit reservoir will be disturbed when the secret message is embedded. In addition, a reliable estimation of cover audio is obtained by the proposed recompression calibration. The calibrated features are classified with support vector machine technique. Experimental results show that the proposed scheme is effective and gets good performance, especially when the embedding rate is not less than 0.01 %. The results also shows that the proposed scheme can achieve lower false positive rate comparing to the existing algorithms.
C1 [Yan, Diqun; Wang, Rangding] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Yan, DQ (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM yandiqun@nbu.edu.cn; wangrangding@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of China [6117037]; Doctoral Fund of
   Ministry of Education of China [20103305110002]; Ningbo University Fund
   [XK1087, XYL10002]; Zhejiang Scientific and Technical Key Innovation
   Team of New Generation Mobile Internet Client Software [2010R50009];
   Scientific Research Fund of Zhejiang Provincial Education Department
   [Y201119434]; K.C. Wong Magna Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 6117037), Doctoral Fund of Ministry of Education of
   China (Grant No. 20103305110002), Ningbo University Fund (Grant No.
   XK1087, XYL10002), Zhejiang Scientific and Technical Key Innovation Team
   of New Generation Mobile Internet Client Software (Grant No.
   2010R50009), Scientific Research Fund of Zhejiang Provincial Education
   Department (Grant No. Y201119434) and K.C. Wong Magna Fund in Ningbo
   University.
CR [Anonymous], UNDERMP3COVER
   [Anonymous], P SPIE SEC FOR STEG
   Avcibas I, 2006, IEEE SIGNAL PROC LET, V13, P92, DOI 10.1109/LSP.2005.862152
   Bohme R., 2004, Proceedings of the 2004 Workshop on Multimedia and Security, MMSEC'04, (Magdeburg, Germany), P25
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dittmann J, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P343
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   *ISO IEC, 1993, 111723 ISO IEC
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kraetzer C, 2007, LECT NOTES COMPUT SC, V4567, P359
   Malik H, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P149, DOI 10.1145/1411328.1411355
   Mengyu Qiao, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2566, DOI 10.1109/IJCNN.2009.5178971
   Özer H, 2006, DIGIT SIGNAL PROCESS, V16, P389, DOI 10.1016/j.dsp.2005.12.001
   Petitcolas F. A. P., 2002, MP3STEGO
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qiao MY, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P627, DOI 10.1109/IJCBS.2009.119
   Westfeld A, 2003, LECT NOTES COMPUT SC, V2578, P324
   Yan DQ, 2011, MULTIMED TOOLS APPL, V52, P291, DOI 10.1007/s11042-009-0430-5
   Yan DQ, 2009, FUND INFORM, V97, P1, DOI 10.3233/FI-2009-190
NR 21
TC 17
Z9 19
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 865
EP 878
DI 10.1007/s11042-013-1406-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800039
DA 2024-07-18
ER

PT J
AU Zou, JN
   Jiang, L
   Li, CL
AF Zou, Junni
   Jiang, Lu
   Li, Chenglin
TI Content-aware optimization on rate-distortion and network traffic for
   scalable video multicast networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Multicast; Network coding; Rate distortion;
   Distributed algorithm
ID CONGESTION CONTROL; RESOURCE-ALLOCATION; ALGORITHM; PATH
AB This paper aims to optimize the content-aware prioritization of scalable video multicast, which is coupled with multipath streaming and network coding based routing. It constructs multiple layer distribution meshes for the scalable video stream to minimize the total video distortion at all the receivers, determines the base layer meshes with minimum costs to maintain application-layer QoS and the layer synchronization of SVC streaming, and improves the network throughput by encouraging path-overlapping transmissions and thus allowing bandwidth sharing among different receivers for the same video layer by utilizing network coding. The targeted problem is formulated into a minimization programming in which the quality variation between layers, the transmission cost of the base layer, as well as the efficient resource utilization are jointly considered. By decomposition and dual approach, the global convex problem is solved by a two-level decentralized iterative algorithm. The implementation of the distributed algorithm is discussed with regard to the communication overhead, and the convergence performance is validated by numerical experiments. Packet-level simulations demonstrate that the proposed algorithm could approximately achieve the maximum flow rates determined by Max-Flow Min-Cut Theorem and benefit the overall received video quality.
C1 [Zou, Junni] Univ Calif San Diego, Dept Elect & Comp Engn, San Diego, CA 92093 USA.
   [Zou, Junni] Shanghai Univ, Key Lab Special Fiber Opt & Opt Access Networks, Shanghai 200072, Peoples R China.
   [Jiang, Lu] Shanghai Univ, Dept Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Li, Chenglin] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
C3 University of California System; University of California San Diego;
   Shanghai University; Shanghai University; Shanghai Jiao Tong University
RP Zou, JN (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, San Diego, CA 92093 USA.
EM zoujunni@gmail.com
RI LI, CHENGLIN/JUF-8254-2023
FU NSFC [61271211, 60972055]; Shanghai Science and Technology Commission
   [11510707000, 11QA1402600]
FX The work has been partially supported by the NSFC grants (No. 61271211,
   No. 60972055), and the Research Program from Shanghai Science and
   Technology Commission (No. 11510707000, No. 11QA1402600).
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   Amon P, 2007, IEEE T CIRC SYST VID, V17, P1174, DOI 10.1109/TCSVT.2007.905521
   BANERJEE S, 2002, P ACM SIGCOMM PITTSB
   Bertsekas D.P., 1989, Parallel and Distributed Computation: Numerical Methods
   Bertsekas D. P., 2003, CONVEX ANAL OPTIMIZA
   Boyd S., 2004, CONVEX OPTIMIZATION
   CHEN L, 2007, P IEEE INF
   Chou P.A., 2003, Proc. Annual Allerton Conference on Communication control and Computing, V41, P40
   Deb S, 2004, IEEE ACM T NETWORK, V12, P274, DOI 10.1109/TNET.2004.826293
   Fazel M, 2005, P C DEC CONTR
   Fu FW, 2007, IEEE J-STSP, V1, P264, DOI 10.1109/JSTSP.2007.901519
   Han HZ, 2006, IEEE ACM T NETWORK, V14, P1260, DOI 10.1109/TNET.2006.886738
   Jeong J, 2009, P IEEE INT S BROADB
   Kar K, 2002, IEEE J SEL AREA COMM, V20, P1541, DOI 10.1109/JSAC.2002.803988
   Kar K., 2001, P IEEE INFOCOM
   Kleinrock L, 1976, Queueing Systems, V2
   Lai WK, 2002, IEEE T BROADCAST, V48, P215, DOI 10.1109/TBC.2002.804065
   Li B, 2003, IEEE NETWORK, V17, P24
   Li SYR, 2003, IEEE T INFORM THEORY, V49, P371, DOI 10.1109/TIT.2002.807285
   Low SH, 1999, IEEE ACM T NETWORK, V7, P861, DOI 10.1109/90.811451
   Lun DS, 2006, IEEE T INFORM THEORY, V52, P2608, DOI 10.1109/TIT.2006.874523
   Lun DS, 2005, P WINMEE NETCOD 2005
   Palomar DP, 2006, IEEE J SEL AREA COMM, V24, P1439, DOI 10.1109/JSAC.2006.879350
   Sarkar S, 2005, IEEE ACM T NETWORK, V13, P121, DOI 10.1109/TNET.2004.842234
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   van der Schaar M, 2006, IEEE T MOBILE COMPUT, V5, P755, DOI 10.1109/TMC.2006.81
   Wu Y, 2006, THESIS PRINCETON U
   Zhao J, 2006, IEEE T MULTIMEDIA, V8, P1021, DOI 10.1109/TMM.2006.879847
   ZHU X, 2008, P VIS COMM IM PROC V
   Zou JN, 2011, IEEE T CIRC SYST VID, V21, P259, DOI 10.1109/TCSVT.2010.2077576
NR 31
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1975
EP 1998
DI 10.1007/s11042-012-1321-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000045
DA 2024-07-18
ER

PT J
AU Li, JH
   Yin, BC
   Wang, LC
   Kong, DH
AF Li, Jinghua
   Yin, Baocai
   Wang, Lichun
   Kong, Dehui
TI Chinese Sign Language animation generation considering context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese Sign Language synthesis; Context; Manual gesture; Non-manual
   gesture; CSLML
ID RECOGNITION
AB Sign language (SL) is a kind of natural language for the deaf. Chinese Sign Language (CSL) synthesis aims to translate text into virtual human animation, which makes information and service accessible to the deaf. Generally, sign language animation based on key frames is realized by concatenating sign words captured independently. That means a sign language word has the same pattern in diverse context, which is different from realistic sign language expression. This paper studies the effect of context on manual gesture and non-manual gesture, and presents a method for generating stylized manual gesture and non-manual gesture according to the context. Experimental results show that synthesized sign language animation considering context based on the proposed method is more accurate and intelligible than that irrespective of context.
C1 [Li, Jinghua; Yin, Baocai; Wang, Lichun; Kong, Dehui] Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, LC (corresponding author), Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
EM lijinghua@bjut.edu.cn; ybc@bjut.edu.cn; wanglc@bjut.edu.cn;
   kdh@bjut.edu.cn
FU NSFC [U0935004, 61170104]; Beijing Municipal Natural Science Foundation
   [4112008]
FX This research is supported by NSFC (Nos. U0935004 and 61170104) and
   Beijing Municipal Natural Science Foundation (4112008). The authors
   thank Beijing 3rd School for the Deaf, who gave them a great help for
   Chinese sign language data collection and advice.
CR Amaya K, 1996, GRAPHICS INTERFACE
   [Anonymous], INT GEST WORKSH
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   BECKER CA, 1980, MEM COGNITION, V8, P493, DOI 10.3758/BF03213769
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   CONRAD C, 1974, MEM COGNITION, V2, P130, DOI 10.3758/BF03197504
   ELLIOTT R, 2004, WORKSH REPR PROC SIG, P98
   Fugen C, 2004, 8 INT C SPOK LANG PR, P169
   Gao W, 2004, HANDTALKER 2 CHINESE
   Hartmann B, 2006, LECT NOTES ARTIF INT, V3881, P188
   Huenerfauth M, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P99
   IRVING A, 2005, ASSETS 2005 7 INT AC, P212
   Kennaway R, 2001, INT GEST WORKSH CIT, P146
   Lebourque T, 1999, LECT NOTES ARTIF INT, V1739, P227
   Lemon O, 2004, P CATALOG 8 WORKSH S
   Li Jing-hua, 2012, Journal of Beijing University of Technology, V38, P1665
   Li S, 2012, ICGG2012, P397
   Ma B, 1996, INT CONF ACOUST SPEE, P455, DOI 10.1109/ICASSP.1996.541131
   Mancini M, 2008, THESIS U PARIS 8, P8
   Sutton V., 1999, LESSONS SIGNWRITING
   Trevor J, 2007, AUSTR SIGN LANGUAGE
   Wang CL, 2005, 6 INT WORKSH GEST HU, P84
   Wang R, 2012, MULTIMED TOOLS APPL, V60, P483, DOI 10.1007/s11042-011-0819-9
   Wang R, 2011, CHINA COMMUN, V8, P139
   Ye KJ, 2009, COMPUT ANIMAT VIRT W, V20, P237, DOI 10.1002/cav.307
   Zhang XW, 2012, CSSS 2012, P576
NR 27
TC 6
Z9 7
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 469
EP 483
DI 10.1007/s11042-013-1541-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400006
DA 2024-07-18
ER

PT J
AU Sun, R
   Zeng, WJ
AF Sun, Rui
   Zeng, Wenjun
TI Secure and robust image hashing via compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Fourier-Mellin transform; Image hashing; Image
   identification
AB Image hash functions find extensive applications in content authentication, database search. This paper develops a novel algorithm for generating a secure and robust image hash based on compressive sensing and Fourier-Mellin transform. Firstly, we incorporate Fourier-Mellin transform into our method to improve its performance under rotation, scale, transition attacks. Secondly, we exploit the property of dimension reduction inherent in compressive sensing for hash design. The statistic structure and sparse of the wavelet coefficients assure efficient compression in situation of including maximum the image features. The hashing method is computationally secure without additional randomization process. Such a combined approach is capable of tackling all types of attacks and thus can yield a better overall performance in multimedia identification. To demonstrate the superior performance of the proposed schemes, receiver operating characteristics analysis over a large image database is performed. Experimental results show that the proposed image hashing is robust to a wide range of distortions and attacks. When compared with the current state-of-the-art methods, the proposed method yields better identification performances under geometric attacks such as rotation attacks and brightness changes.
C1 [Sun, Rui] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Zeng, Wenjun] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
C3 Hefei University of Technology; University of Missouri System;
   University of Missouri Columbia
RP Sun, R (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM sunziyun@yahoo.com.cn; zengw@missouri.edu
FU Natural Science Foundation of China [61001201]
FX This work was supported by the Natural Science Foundation of China
   (61001201). The authors appreciate the anonymous reviewers for their
   constructive comments.
CR Ababneh S, 2008, INT CONF ELECTRO INF, P263, DOI 10.1109/EIT.2008.4554310
   [Anonymous], EURASIP J INF SECUR
   [Anonymous], OBJ CONC REC CONT BA
   Blumensath T., 2009, IEEE T INF THEORY, V55
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Kailasanathan C, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P562
   KAILASANATHAN C, 2001, P IEEE EURASIP WORK
   Kang LW, 2009, IEEE IMAGE PROC, P1285, DOI 10.1109/ICIP.2009.5413606
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   LIN S, 2001, P 27 VER LARG DAT BA
   Lv XD, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/859859
   Menezes A., 1998, HDB APPL CRYPTOGRAPH
   Mihcak KM, 2001, VIDEO WATERMARKING U
   Monga V., 2005, THESIS U TEXAS
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0
   Wu CW, 2002, IEEE T MULTIMEDIA, V4, P385, DOI 10.1109/TMM.2002.802018
   Wu D, 2009, SIGNAL PROCESS, V89, P2415, DOI 10.1016/j.sigpro.2009.05.016
   Xudong Lv, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P725, DOI 10.1109/MMSP.2008.4665170
NR 30
TC 37
Z9 47
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1651
EP 1665
DI 10.1007/s11042-012-1188-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500013
DA 2024-07-18
ER

PT J
AU Wu, LF
   Gong, Y
   Yuan, XD
   Zhang, XZ
   Cao, LC
AF Wu, Lifang
   Gong, Yu
   Yuan, Xingdi
   Zhang, Xiuzhen
   Cao, Lianchao
TI Semantic aware sport image resizing jointly using seam carving and
   warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic aware seam carving (SASC); Semantic aware image resizing;
   Semantic weight function (SWF); Deformation of Semantic Edge (DSE)
AB In content aware image resizing, saliency map or gradient is usually used to determine the important regions of images. But for sport images such as basketball and football images, these methods may falsely classify parts of court fields as unimportant regions, while parts of grandstands as important regions. Such results are not consistent with human perception. In this paper, a semantic aware image resizing approach is proposed. We extract the semantic information automatically. We segment the court fields as important regions and detect the boundary of court fields as the semantic edges. Considering the complementary characteristic of discrete image resizing approaches such as seam carving and continuous approaches such as warping, seam carving and warping are jointly used in our scheme. We define the Semantic Weight Function (SWF) based on the semantically important regions. Then semantic aware seam carving (SASC) is proposed based on the SWF. Next we define the Deformation of Semantic Edges (DSE) to assess the image deformation caused by seam carving. Finally seam carving and warping are joined using the DSE. We compare our approach with approaches like scaling, seam carving and semantic aware seam carving (SASC). Experimental results show that our approach preserves more semantically important regions with less deformation. Our approach also preserves the aspect ratio of key objects.
C1 [Wu, Lifang; Gong, Yu; Yuan, Xingdi; Cao, Lianchao] Beijing Univ Technol, Beijing 100124, Peoples R China.
   [Zhang, Xiuzhen] RMIT Univ, Sch CS&IT, Melbourne, Vic 3001, Australia.
C3 Beijing University of Technology; Royal Melbourne Institute of
   Technology (RMIT)
RP Wu, LF (corresponding author), Beijing Univ Technol, Pingleyuan 100, Beijing 100124, Peoples R China.
EM lfwu@bjut.edu.cn; gy86922@163.com; takethateasy@hotmail.com;
   xiuzhen.zhang@rmit.edu.au; caolianchao@emails.bjut.edu.cn
OI Zhang, Xiuzhen (Jenny)/0000-0001-5558-3790
FU National Science Foundation [61040052]; Beijing Municipal Talent
   Training Program [2009D005015000010]
FX This paper is partially supported by National Science Foundation under
   grant No 61040052 and program of Beijing Municipal Talent Training
   Program under Grant No 2009D005015000010.
CR Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815
   [Anonymous], 2009, ACM SIGGRAPH ASIA CO
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Domingues D, 2010, IEEE IMAGE PROC, P901, DOI 10.1109/ICIP.2010.5653984
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Huang H, 2009, SCI CHINA SER F, V52, P172, DOI 10.1007/s11432-009-0041-9
   Hwang DS, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1029, DOI 10.1109/ICME.2008.4607613
   Li B., 2011, OPT LASER TECHNOL, V11, P1
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Toony Z., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P175, DOI 10.1109/ICSIP.2010.5697464
   Wang Y, 2008, CELL POLYM, V27, P1
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang YF, 2008, COMPUT GRAPH FORUM, V27, P1797, DOI 10.1111/j.1467-8659.2008.01325.x
NR 19
TC 6
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 721
EP 739
DI 10.1007/s11042-012-1002-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900007
DA 2024-07-18
ER

PT J
AU Calumby, RT
   Torres, RD
   Gonçalves, MA
AF Calumby, Rodrigo Tripodi
   Torres, Ricardo da Silva
   Goncalves, Marcos Andre
TI Multimodal retrieval with relevance feedback based on genetic
   programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal retrieval; Learn to rank; Image retrieval; Relevance
   feedback; Genetic programming
ID IMAGE RETRIEVAL; PHOTOGRAPHIC RETRIEVAL; TEXTURE DESCRIPTORS;
   SIMILARITY; ANNOTATION; COLOR; SHAPE; QUERY
AB This paper presents a framework for multimodal retrieval with relevance feedback based on genetic programming. In this supervised learning-to-rank framework, genetic programming is used for the discovery of effective combination functions of (multimodal) similarity measures using the information obtained throughout the user relevance feedback iterations. With these new functions, several similarity measures, including those extracted from different modalities (e.g., text, and content), are combined into one single measure that properly encodes the user preferences. This framework was instantiated for multimodal image retrieval using visual and textual features and was validated using two image collections, one from the Washington University and another from the ImageCLEF Photographic Retrieval Task. For this image retrieval instance several multimodal relevance feedback techniques were implemented and evaluated. The proposed approach has produced statistically significant better results for multimodal retrieval over single modality approaches and superior effectiveness when compared to the best submissions of the ImageCLEF Photographic Retrieval Task 2008.
C1 [Calumby, Rodrigo Tripodi] Univ Feira de Santana, Dept Exact Sci, Feira De Santana, Brazil.
   [Calumby, Rodrigo Tripodi; Torres, Ricardo da Silva] Univ Estadual Campinas, Inst Comp, RECOD Lab, Campinas, SP, Brazil.
   [Goncalves, Marcos Andre] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.
C3 Universidade Estadual de Campinas; Universidade Federal de Minas Gerais
RP Calumby, RT (corresponding author), Univ Feira de Santana, Dept Exact Sci, Feira De Santana, Brazil.
EM rtcalumby@ecomp.uefs.br; rtorres@ic.unicamp.br; mgoncalv@dcc.ufmg.br
RI Calumby, Rodrigo/ABB-5699-2020; Torres, Ricardo da S./C-4526-2012
OI Calumby, Rodrigo/0000-0001-8515-265X; Goncalves, Marcos
   Andre/0000-0002-2075-3363
FU National Council for Scientific and Technological Development (CNPq);
   Coordination for the Improvement of Higher Level Personnel (CAPES); Sao
   Paulo Research Foundation (FAPESP) [2007/52015-0, 2009/18438-7]; Minas
   Gerais Agency for Research and Development (FAPEMIG); projects INCT-Web
   (MCT/CNPq) [57.3871/2008-6]; CNPq; CAPES; FAPEMIG; Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [09/18438-7] Funding Source:
   FAPESP
FX We would like to thank all partners from LIS (Laboratory of Information
   Systems -IC/UNICAMP), RECOD (Reasoning for Complex Data -IC/UNICAMP),
   LDB (Databases Lab - DCC/UFMG). This work was supported by The National
   Council for Scientific and Technological Development (CNPq),
   Coordination for the Improvement of Higher Level Personnel (CAPES), Sao
   Paulo Research Foundation (FAPESP grants 2007/52015-0 and 2009/18438-7),
   and Minas Gerais Agency for Research and Development (FAPEMIG). This
   work was partially supported by the projects INCT-Web (MCT/CNPq grant
   57.3871/2008-6) and by the authors' individual grants and scholarships
   from CNPq, CAPES and FAPEMIG
CR Agrawal R, 2006, IEEE INT SYM MULTIM, P817
   Ah-Pine J, 2008, CLEF 2008 WORKSH
   [Anonymous], 2006, P 14 ACM INT C MULT, DOI DOI 10.1145/1180639.1180661
   [Anonymous], 1997, An Algorithm for Suffix Stripping, page
   Arni T, 2009, LECT NOTES COMPUT SC, V5706, P500
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Banzhaf W., 1998, GENETIC PROGRAMMING
   Bhanu B, 2004, APPL SOFT COMPUT, V4, P175, DOI 10.1016/j.asoc.2004.01.004
   Bottoni P, 2009, UNIVERSAL ACCESS INF, V8, P137, DOI 10.1007/s10209-008-0142-z
   Bruno E., 2007, Proceedings of the international workshop on Workshop on multimedia information retrieval, P71, DOI DOI 10.1145/1290082.1290095
   Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P25, DOI 10.1145/1008992.1009000
   Caschera MC, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P114, DOI 10.1109/DEXA.2007.95
   Chai J., 2004, P C INTELLIGENT USER, P70
   Clinchant S, 2010, CLEF LABS WORKSH
   Clough P, 2007, LECT NOTES COMPUT SC, V4730, P579
   Coelho TAS, 2004, IEEE T KNOWL DATA EN, V16, P408, DOI 10.1109/TKDE.2004.1269666
   Cooke T, 2007, NEUROPSYCHOLOGIA, V45, P484, DOI 10.1016/j.neuropsychologia.2006.02.009
   Corradini A, 2003, P NATO ASI C DAT FUS
   D'Ulizia A, 2010, IEEE T SYST MAN CY A, V40, P1130, DOI 10.1109/TSMCA.2010.2041227
   da Silva Torres R, 2004, THESIS U CAMPINAS
   Deb S, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P59
   Dorairaj R, 2004, CONF REC ASILOMAR C, P387
   Equitz W, 1994, 9805 IBM RJ
   Fan WG, 2004, J AM SOC INF SCI TEC, V55, P628, DOI 10.1002/asi.20009
   Ferreira CD, 2011, PATTERN RECOGN LETT, V32, P27, DOI 10.1016/j.patrec.2010.05.015
   Ferri F, 2002, J VISUAL LANG COMPUT, V13, P355, DOI 10.1006/S1045-926X(02)00006-X
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Freitas RB, 2005, P WORKSH BIBL DIG UB, P60
   Grubinger M, 2008, LECT NOTES COMPUT SC, V5152, P433, DOI 10.1007/978-3-540-85760-0_57
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   HARMAN D, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1
   Huang CB, 2007, INT C COMMUN CIRCUIT, P772
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jiang W, 2005, PATTERN RECOGN, V38, P2007, DOI 10.1016/j.patcog.2005.03.007
   Johnston M., 2005, Natural Language Engineering, V11, P159, DOI 10.1017/S1351324904003572
   Kak A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P138, DOI 10.1109/TDPVT.2002.1024053
   Kim DH, 2005, J SYST SOFTWARE, V78, P9, DOI 10.1016/j.jss.2005.02.005
   Kovacevic A, 2010, MULTIMED TOOLS APPL, V47, P525, DOI 10.1007/s11042-009-0336-2
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Lew M.S., 2001, PRINCIPLES VISUAL IN
   Lewis J, 2006, BIOINFORMATICS, V22, P2298, DOI 10.1093/bioinformatics/btl388
   Li B, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P120
   Lieberman H, 2001, COMPUTER, V34, P57, DOI 10.1109/2.933504
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Lu K, 2005, PATTERN RECOGN, V38, P2047, DOI 10.1016/j.patcog.2005.05.005
   Mankoff J., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P368, DOI 10.1145/332040.332459
   Meffert K., 2010, JGAP java genetic algorithms package
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Oviatt S., 2008, The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications, V2, p413 432
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Santos KL, 2009, BRAZ S DAT FORT BRAZ, P91
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Torres R. S. D., 2006, RITA, V13, P161
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Vadivel A, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P127
   Williams A, 2007, MULTIMED TOOLS APPL, V34, P239, DOI 10.1007/s11042-006-0087-2
   Wu P, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P3, DOI 10.1109/IVL.1999.781114
   Xu Z, 2003, LECT NOTES COMPUT SC, V2633, P281
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   ZHAI C.X., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in informaion Retrieval (Toronto, Canada, July 28 - August 01, 2003), P10, DOI [10.1145/860435.860440, DOI 10.1145/860435.860440]
   Zhang B, 2004, P 13 ACM C INF KNOWL, P162
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang RF, 2006, MULTIMEDIA SYST, V12, P27, DOI 10.1007/s00530-006-0025-1
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 73
TC 14
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 991
EP 1019
DI 10.1007/s11042-012-1152-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300019
DA 2024-07-18
ER

PT J
AU Karaman, S
   Benois-Pineau, J
   Dovgalecs, V
   Mégret, R
   Pinquier, J
   André-Obrecht, R
   Gaëstel, Y
   Dartigues, JF
AF Karaman, Svebor
   Benois-Pineau, Jenny
   Dovgalecs, Vladislavs
   Megret, Remi
   Pinquier, Julien
   Andre-Obrecht, Regine
   Gaestel, Yann
   Dartigues, Jean-Francois
TI Hierarchical Hidden Markov Model in detecting activities of daily living
   in wearable videos for studies of dementia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activities of daily living; Wearable videos; Video indexing; Hidden
   Markov Model
ID CLASSIFICATION; SEGMENTATION; RECOGNITION; TUTORIAL; AUDIO
C1 [Karaman, Svebor; Benois-Pineau, Jenny] Univ Bordeaux, LaBRI, F-33405 Talence, France.
   [Dovgalecs, Vladislavs; Megret, Remi] Univ Bordeaux, IMS, Talence, France.
   [Pinquier, Julien; Andre-Obrecht, Regine] Univ Toulouse, IRIT, F-31062 Toulouse 9, France.
   [Gaestel, Yann; Dartigues, Jean-Francois] Univ Bordeaux 2, INSERM, U897, F-33076 Bordeaux, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); Universite de Bordeaux; Universite de Toulouse; Universite
   Toulouse III - Paul Sabatier; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Institut National Polytechnique de Toulouse; Universite de
   Bordeaux; Institut National de la Sante et de la Recherche Medicale
   (Inserm)
RP Benois-Pineau, J (corresponding author), Univ Bordeaux, LaBRI, 351 Cours Liberat, F-33405 Talence, France.
EM svebor.karaman@labri.fr; jenny.benois@labri.fr;
   vladislavs.dovgalecs@ims-bordeaux.fr; remi.megret@ims-bordeaux.fr;
   pinquier@irit.fr; andre-obrecht@irit.fr;
   yann.gaestel@isped.u-bordeaux2.fr;
   jean-francois.dartigues@isped.u-bordeaux2.fr
RI DARTIGUES, Jean François/T-4513-2019; PINQUIER, Julien/HGB-7599-2022;
   Karaman, Svebor/I-4929-2019; Benois-Pineau, Jenny/ABG-6325-2020
OI PINQUIER, Julien/0000-0003-1556-1284; Karaman,
   Svebor/0000-0002-2496-5822; Benois-Pineau, Jenny/0000-0003-0659-8894;
   Megret, Remi/0000-0003-0127-5885
FU ANR (Agence Nationale de la Recherche) within the IMMED project
   [ANR-09-BLAN-0165-02]; Agence Nationale de la Recherche (ANR)
   [ANR-09-BLAN-0165] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX This work is partly supported by a grant from the ANR (Agence Nationale
   de la Recherche) with reference ANR-09-BLAN-0165-02, within the IMMED
   project.
CR Amieva H, 2008, ANN NEUROL, V64, P492, DOI 10.1002/ana.21509
   ANDREOBRECHT R, 1988, IEEE T ACOUST SPEECH, V36, P29, DOI 10.1109/29.1486
   [Anonymous], 2009, 1 WORKSH EG VIS HELD
   [Anonymous], P 6 INT 9 EUR C SPEE
   [Anonymous], P TRECVID 2010 WORKS
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V207, P519
   Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Byrne D., 2008, Proceedings of the 22nd British HCI Group Annual Conference on People and Computers: Culture, Creativity, Interaction - BCS-HCI '08 - Volume 2, V2, P19, DOI [10.14236/ewic/HCI2008.24, DOI 10.14236/EWIC/HCI2008.24]
   Chatzis SP, 2009, IEEE T PATTERN ANAL, V31, P1657, DOI 10.1109/TPAMI.2008.215
   Delakis M, 2008, COMPUT VIS IMAGE UND, V111, P142, DOI 10.1016/j.cviu.2007.09.002
   Doherty AR, 2011, COMPUT HUM BEHAV, V27, P1948, DOI 10.1016/j.chb.2011.05.002
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Gaestel Y, 2011, IMMED PROJ ALZH ASS
   Gales M.J., 1993, The theory of segmental hidden Markov models
   Gao Z, 2010, LECT NOTES COMPUT SC, V6219, P88
   Gorisse D, 2010, P TRECVID 2010 WORKS
   Guyot P, 2012, CBMI 2012 IEEE UNPUB
   Hamid R, 2009, ARTIF INTELL, V173, P1221, DOI 10.1016/j.artint.2009.05.002
   Harte N, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/924287
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Karaman S, 2011, CONT BAS MULT IND RE
   Kijak E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P309
   Lan ZZ, 2012, LECT NOTES COMPUT SC, V7131, P173
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Megret R., 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P101, DOI 10.1109/CBMI.2008.4564934
   Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930
   Piccardi L, 2007, INT S ROB HUM INT CO, P177
   Pinquier J, 2006, MULTIMED TOOLS APPL, V30, P313, DOI 10.1007/s11042-006-0027-1
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Quenot G, 2008, VS 08 TREC VID SUMM
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sikora T, 2002, INTRO MPEG 7 MULTIME
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Sundaram S, 2010, LECT NOTES COMPUT SC, V6454, P596, DOI 10.1007/978-3-642-17274-8_58
   Sundararn S, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2009.5204355
   Surie D, 2007, LECT NOTES COMPUT SC, V4611, P246
   Young S., 1994, HTK HIDDEN MARKOV MO
   Young S., 1997, HTK BOOK
   Zouba N, 2010, GERONTECHNOLOGY, V9, P263
NR 47
TC 31
Z9 34
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 743
EP 771
DI 10.1007/s11042-012-1117-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300009
DA 2024-07-18
ER

PT J
AU Benmokhtar, R
AF Benmokhtar, Rachid
TI Robust human action recognition scheme based on high-level feature
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical flow; Trajectory; Spatio-temporal description; Self-similarity
   matrix; Classification; Fusion; Weizmann dataset; KTH dataset
ID CLASSIFIER FUSION; MOTION; POINTS; MODELS
AB This paper presents our research on the human action recognition which employs different low-level local and spatio-temporal descriptors. The motivation is that these descriptors emphasize different aspects of actions. We investigate a generic approach applied to different periodic and non-periodic actions in the same framework defined by Weizmann and KTH datasets. So, we explore the notion of self-similarity descriptor over time. Then, non-linear chi (2) kernel-based Support Vector Machines are used to perform classification. Individual actions are modeled independently. Finally, classifier outputs are fused using our proposed neural network based on Evidence theory method, trying to improve the classification rate by pushing classifiers into an optimized structure. Experimental results report the efficiency and the significant improvement of the proposed scheme.
C1 IRISA INRIA Bretagne Athlantique, F-35042 Rennes, France.
C3 Universite de Rennes
RP Benmokhtar, R (corresponding author), IRISA INRIA Bretagne Athlantique, Campus Univ Beaulieu, F-35042 Rennes, France.
EM rachid.benmokhtar@inria.fr
CR Aggarwal JK, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P640
   Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859
   Ahmad M, 2006, INT C PATT RECOG, P263
   [Anonymous], MULT COMP ENG APPL S
   [Anonymous], INT C COMP VIS
   [Anonymous], P 1 ACM INT WORKSH A
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], INT C COMP VIS
   [Anonymous], P WORKSH VID OR OBJ
   [Anonymous], INT WORKSH COMP VIS
   [Anonymous], NEURAL COMPUT
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2002, REGULARIZATION OPTIM
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], P HUM MOT UND MOD CA
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], INFORM RETRIEVAL INT
   [Anonymous], EUR SIGN PROC C
   [Anonymous], ITN C COMP VIS
   [Anonymous], INT C COMP VIS
   Bach FR, 2004, ADV NEUR IN, V16, P305
   Benmokhtar R, 2007, LECT NOTES COMPUT SC, V4352, P196
   Benmokhtar R, 2006, LECT NOTES COMPUT SC, V4132, P65
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chua TW, 2011, IEEE INT CONF FUZZY, P484
   Cilla R, 2010, LECT NOTES ARTIF INT, V6077, P436, DOI 10.1007/978-3-642-13803-4_54
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Doulamis AD, 2000, IEEE T CONSUM ELECTR, V46, P758, DOI 10.1109/30.883444
   Doulamis N. D., 2010, P 1 ACM INT WORKSH A, P39, DOI [10.1145/1877868.1877880, DOI 10.1145/1877868.1877880]
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fablet R, 2003, IEEE T PATTERN ANAL, V25, P1619, DOI 10.1109/TPAMI.2003.1251155
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jia K., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587732
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Krausz B, 2010, MULTIMED TOOLS APPL, V50, P123, DOI 10.1007/s11042-009-0367-8
   Kuncheva LI, 2001, FUZZY SET SYST, V122, P401, DOI 10.1016/S0165-0114(99)00161-X
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Mikolajczyk K, 2008, INT C COMPUTER VISIO, P1
   Murphy K. P., 2002, Ph.D. Thesis,
   NIEBLES J, 2006, BRIT MACH VIS C
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pundlik SJ, 2008, IEEE T SYST MAN CY B, V38, P731, DOI 10.1109/TSMCB.2008.919229
   Roth D, 2010, MULTIMED TOOLS APPL, V50, P29, DOI 10.1007/s11042-009-0365-x
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seidenari L., 2010, P 1 ACM INT WORKSHOP, P27, DOI DOI 10.1145/1877868.1877877
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4
   Stokman H, 2007, IEEE T PATTERN ANAL, V29, P371, DOI 10.1109/TPAMI.2007.58
   Sun BY, 2010, IEEE T NEURAL NETWOR, V21, P163, DOI 10.1109/TNN.2009.2036363
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Voulodimos A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3249, DOI 10.1109/ICIP.2011.6116362
   Waltisberg D, 2010, LECT NOTES COMPUT SC, V6388, P306, DOI 10.1007/978-3-642-17711-8_31
   Wang H., 2009, BMVC
   Wang JJL, 2003, REAL-TIME IMAGING, V9, P321, DOI 10.1016/j.rti.2003.08.001
   Wang L., 2009, APPL COMPUTER VISION, P1
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wong K. O., 2007, ICCV, P1, DOI DOI 10.1109/VTSA.2007.378923
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zouhal L. M., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P310
NR 81
TC 17
Z9 19
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 253
EP 275
DI 10.1007/s11042-012-1022-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400002
DA 2024-07-18
ER

PT J
AU Han, SW
   Kim, J
AF Han, Sang Woo
   Kim, JongWon
TI A service composition oriented framework for configuring SMeet
   multiparty collaboration environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service composition oriented framework; Cyber infrastructure for
   collaboration; Distributed smart spaces; Multiparty collaboration
   environments
ID WEB SERVICES; COMMUNICATION
AB To enable remote collaboration among knowledge workers, there has been extensive research about prototyping network-based multiparty collaboration environments. Particularly, it is necessary to solve the configuration difficulties that arise from different settings of various tools in traditional room-based collaboration systems. To ease these difficulties, in this paper, we design a service composition oriented framework for the SMeet (Smart Meeting Space) multiparty collaboration environments by following the SOA (service oriented architecture) design principles. The proposed framework aims to facilitate the flexible configuration of diverse networked devices and associated application tools for successful multiparty collaboration. According to a pre-defined template, it helps the operators and users to compose services that are dispersed across remote sites. By leveraging open-source agent middleware, we also develop a SMeet toolkit with GUIs (graphical user interfaces) to assist the easily-configurable realization of SMeet multiparty collaboration environments. The developed SMeet toolkit is utilized to realize a remote collaboration scenario between two SMeet prototype sites, by enabling the network-based interactive sharing of HD-quality media on networked tiled displays (NeTDs).
C1 [Han, Sang Woo] Gwangju Inst Sci & Technol, Ctr Informat & Technol Educ, Kwangju 500712, South Korea.
   [Kim, JongWon] Gwangju Inst Sci & Technol, Sch Informat & Commun, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Gwangju Institute of
   Science & Technology (GIST)
RP Kim, J (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Commun, 123 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM swhan@nm.gist.ac.kr; jongwon@nm.gist.ac.kr
FU 2nd Brain Korea 21 Project; National Research Foundation of Korea(NRF);
   Korea government(MEST) [2011-0027558]
FX This work was supported by the 2nd Brain Korea 21 Project and the
   National Research Foundation of Korea(NRF) grant funded by the Korea
   government( MEST) (No. 2011-0027558).
CR [Anonymous], 2006, Business Process Execution Language for Web Services BPEL and BPEL4WS
   [Anonymous], 2007, Developing Multi-Agent Systems with JADE
   Becker C, 2004, P IEEE PERCOM 04 ORL
   Borthakur B, 2002, THESIS U ILLINOIS UR
   Cason J, 2011, INT J TELEREHABILITA, V3, P19, DOI 10.5195/ijt.2011.6071
   Chen H, 2004, IEEE INTERNET COMPUT, V8, P69, DOI 10.1109/MIC.2004.66
   Christensen E., 2001, WEB SERVICES DESCRIP
   Deelman E, 2009, FUTURE GENER COMP SY, V25, P528, DOI 10.1016/j.future.2008.06.012
   El Yamany HF, 2010, INFORM SOFTWARE TECH, V52, P220, DOI 10.1016/j.infsof.2009.10.005
   Elliot B., 2005, GARTNER RES, P1
   Eugster PT, 2003, ACM COMPUT SURV, V35, P114, DOI 10.1145/857076.857078
   Garlan D., 2002, IEEE Pervasive Computing, V1, P22, DOI 10.1109/MPRV.2002.1012334
   Gu XH, 2006, IEEE T MULTIMEDIA, V8, P141, DOI 10.1109/TMM.2005.861284
   Gudgin M., 2007, SIMPLE OBJECT ACCESS
   Han S, 2005, P IEEE INT C COMM SY
   Han SW, 2009, MULTIMED TOOLS APPL, V44, P133, DOI 10.1007/s11042-009-0276-x
   Han S, 2006, PROC SPIE, V6391, DOI 10.1117/12.688247
   Han SW, 2009, IEEE PERCOM 09 WORKS
   Handley M, 1998, 2327 IETF RFC
   HANDLEY M, 2000, 2974 IETF RFC
   Hess CK, 2002, CONTEXT FILE SYSTEM
   Huang AFM, 2009, INFORM SCIENCES, V179, P3309, DOI 10.1016/j.ins.2009.05.018
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   Jenks S, 2009, US Patent App., Patent No. [20,100/123,732, 20100123732]
   Johanson B., 2002, IEEE Pervasive Computing, V1, P67, DOI 10.1109/MPRV.2002.1012339
   Ko S, 2007, P INT C COLL TECHN, P128
   Ko S, 2008, P DES INT PRINC SMAR, P121
   Kong K, 2008, P INT C BIOC BIOINF
   LEYMANN F., 2001, WEB SERVICES FLOW LA
   Li Q, 2009, COMPUT SECUR, V28, P260, DOI 10.1016/j.cose.2008.12.004
   Maeda T, 2003, FUJITSU SCI TECH J, V39, P214
   Majithia S, 2004, IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P514, DOI 10.1109/ICWS.2004.1314777
   Masuoka R, 2003, IEEE INTELL SYST, V18, P68, DOI 10.1109/MIS.2003.1234773
   Matthew C., 2006, REFERENCE MODEL SERV
   Milanovic N, 2004, IEEE INTERNET COMPUT, V8, P51, DOI 10.1109/MIC.2004.58
   Milner Robin., 1993, The polyadic Pi-calculus: a tutorial
   Nahrstedt K, 2005, EMB SYST REAL TIME M, P3, DOI 10.1145/1099423.1099426
   O'Brien PD, 1998, BT TECHNOL J, V16, P51, DOI 10.1023/A:1009621729979
   Ooi W, 2002, INDIVA MIDDLEWARE MA
   Peltz C, 2003, COMPUTER, V36, P46, DOI 10.1109/MC.2003.1236471
   Ponnekanti S, 2002, P INT WORLD WID WEB
   Prinz W., 2006, P INT C COLL COMP NE
   Ramachandra V, 2009, P HCI PYEONGCH KOR
   Ranganathan A, 2005, P IEEE PERCOM 05 KAU
   Reuther B, 2008, J SYST ARCHITECT, V54, P594, DOI 10.1016/j.sysarc.2007.12.001
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   San-Yih Hwang, 2008, IEEE Transactions on Services Computing, V1, P104, DOI 10.1109/TSC.2008.2
   SMITH RG, 1980, IEEE T COMPUT, V29, P1104, DOI 10.1109/TC.1980.1675516
   Stevens R, 2003, IEEE INTERNET COMPUT, V7, P51, DOI 10.1109/MIC.2003.1215660
   Tan W, 2009, IEEE T AUTOM SCI ENG, V6, P94, DOI 10.1109/TASE.2008.916747
   Wang H., 2010, J INFORM HIDING MULT, V1, P36
NR 51
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 595
EP 622
DI 10.1007/s11042-012-1066-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000005
DA 2024-07-18
ER

PT J
AU Pogorelc, B
   Lugmayr, A
   Stockleben, B
   Vatavu, RD
   Tahmasebi, N
   Serral, E
   Stojmenova, E
   Imperl, B
   Risse, T
   Zenz, G
   Gams, M
AF Pogorelc, Bogdan
   Lugmayr, Artur
   Stockleben, Bjoern
   Vatavu, Radu-Daniel
   Tahmasebi, Nina
   Serral, Estefania
   Stojmenova, Emilija
   Imperl, Bojan
   Risse, Thomas
   Zenz, Gideon
   Gams, Matjaz
TI Ambient bloom: new business, content, design and models to increase the
   semantic ambient media experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic ambient media; Experience; Business; Ambient assisted living;
   Ambient content; Business models; Consumer experiences; Interaction
   design
AB Semantic ambient media are the novel trend in the world of media reaching from the pioneering subareas such as ambient advertising to the new and emerging subareas such as ambient assisted living. They will likely shape the upcoming years in terms of modeling smart environments and also media consumption and interaction. This work analyzes semantic ambient media by considering business models, content and media, interaction design and consumer experience, and methods and techniques that are important to create this new form of media. Discussion is led using the state-of-the-art event of the semantic ambient media, which is the annual international workshop on Semantic Ambient Media Experience (SAME). The study also creates a vision for how ambient media will evolve and how they will look like in the future decade.
C1 [Pogorelc, Bogdan; Gams, Matjaz] Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.
   [Stockleben, Bjoern; Gams, Matjaz] Spica Int Doo, Ljubljana 1231, Slovenia.
   [Pogorelc, Bogdan; Gams, Matjaz] Jozef Stefan Int Postgrad Sch, Ljubljana 1000, Slovenia.
   [Lugmayr, Artur] Tampere Univ Technol, EMMi Lab, Tampere, Finland.
   [Stockleben, Bjoern] Univ Appl Sci Magdeburg Stendal, New Master Program Cross Media, Magdeburg, Germany.
   [Vatavu, Radu-Daniel] Univ Stefan Cel Mare Suceava, Suceava, Romania.
   [Tahmasebi, Nina; Risse, Thomas; Zenz, Gideon] L3S Res Ctr, Hannover, Germany.
   [Serral, Estefania] Vienna Univ Technol, Christian Doppler Lab, Software Engn Integrat Flexible Automat Syst, A-1040 Vienna, Austria.
   [Stojmenova, Emilija; Imperl, Bojan] Iskratel Doo, Kranj, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute;
   Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute;
   Tampere University; Stefan cel Mare University of Suceava; Leibniz
   University Hannover; Technische Universitat Wien
RP Pogorelc, B (corresponding author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova C 39, Ljubljana 1000, Slovenia.
EM bogdan.pogorelc@ijs.si; artur.lugmayr@tut.fi;
   bjoern.stockleben@hs-magdeburg.de; vatavu@eed.usv.ro; tahmasebi@l3s.de;
   estefania.serral@tuwien.ac.at; stojmenova@iskratel.si;
   bojan.imperl@uni-mb.si; risse@l3s.de; zenz@l3s.de; matjaz.gams@ijs.si
RI Lugmayr, Artur/G-4357-2014; Vatavu, Radu-Daniel/AAA-3282-2022; Serral,
   Estefanía/I-8123-2018; Lugmayr, Artur/AAY-7738-2020; Vatavu,
   Radu-Daniel/F-1820-2017
OI Lugmayr, Artur/0000-0001-6994-4470; Serral,
   Estefanía/0000-0001-7579-910X; Vatavu, Radu-Daniel/0000-0002-7631-6445;
   Tahmasebi, Nina/0000-0003-1688-1845; Risse, Thomas/0000-0001-6248-1709
FU European Union; European Social Fund; European Commission under LiWA
   [IST 216267]; ARCOMEM [IST 270239]
FX This work is partially financed by the European Union, the European
   Social Fund and by the European Commission under LiWA (IST 216267) and
   ARCOMEM (IST 270239), the European Social Fund.
CR AMBI-SYS, 2012, INT C AMB MED SYST
   Ambient Assisted Living, 2011, AMB ASS LIV JOINT PR
   Angell A, 2011, APML SPECIFICATION
   Augusto JC, 2010, HANDBOOK OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS, P3, DOI 10.1007/978-0-387-93808-0_1
   Barnes J, 1999, ADMAP, V34, P46
   Davenport TH, 2002, ATTENTION EC, P22
   Dovgan E, 2011, ZDR VESTN, V80, P824
   Haesen M, 2013, MULTIMED TOOLS APPL, V63, P331, DOI 10.1007/s11042-011-0809-y
   ISTAG, 2010, ISTAG SCEN AMB INT 2
   ISTAG, 2010, ISTAG AMB INT VIS RE
   Karime A, 2012, MULTIMED TOOLS APPL, V59, P749, DOI 10.1007/s11042-011-0768-3
   Kononenko I, 2007, TEXTBOOK
   Lugmayr A, 2006, P SOC PHOTO-OPT INS, V6074, pJ740, DOI 10.1117/12.655169
   Lugmayr A, 2012, P SAME WORKSH CONJ A
   Lugmayr A, 2008, ACM MULT 2008 1 WORK, P1143
   Lugmayr A, 2009, AML 2009 2 WORKSH SE, P161
   Lugmayr A, 2009, 2 SAME 2009 WO UNPUB, P197
   Lugmayr A, 2007, ADJ P EUROITV 2007
   Lugmayr A, 2013, MULTIMED TOOLS APPL, V66, P33, DOI 10.1007/s11042-012-1143-8
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P289, DOI 10.1007/s11042-011-0899-6
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P385, DOI 10.1007/s11042-010-0671-3
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P331, DOI 10.1007/s11042-009-0283-y
   Lugmayr A, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, P516, DOI 10.1109/ISPA.2008.141
   Manovich Lev, 2001, The Language of new media
   Mujacic S, 2012, MULTIMED TOOLS APPL, V58, P435, DOI 10.1007/s11042-010-0665-1
   Mustaquim MM, 2010, P SAME WORKSH CONJ A
   Mustaquim MM, 2013, MULTIMED TOOLS APPL, V66, P131, DOI 10.1007/s11042-011-0918-7
   Oksman V, 2010, P SAME WORKSH CONJ A
   Peiris RL, 2010, P SAME WORKSH CONJ A
   Peiris RL, 2013, MULTIMED TOOLS APPL, V66, P81, DOI 10.1007/s11042-012-1142-9
   Pogorelc B, 2010, P SAME WORKSH CONJ A
   Pogorelc B, 2012, MULTIMED TOOLS APPL, DOI [10.1007/s11042-012-1230-x, DOI 10.1007/S11042-012-1230-X]
   Pogorelc B, 2012, J AMB INTEL SMART EN, V4, P415, DOI 10.3233/AIS-2012-0166
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Stojmenova E, 2010, P SAME WORKSH CONJ A
   Stojmenova E, 2013, MULTIMED TOOLS APPL, V66, P115, DOI 10.1007/s11042-011-0972-1
   Svahn M, 2010, P SAME WORKSH CONJ A
   Vatavu R-D, 2010, P SAME WORKSH CONJ A
   Vatavu RD, 2013, MULTIMED TOOLS APPL, V66, P59, DOI 10.1007/s11042-012-1140-y
   Vatavu RD, 2012, J AMB INTEL SMART EN, V4, P79, DOI 10.3233/AIS-2012-0137
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V59, P113, DOI 10.1007/s11042-010-0698-5
   Yahoo, 2012, YAH SEARCH
   Zenz G, 2010, P SAME WORKSH CONJ A
   Zenz G, 2013, MULTIMED TOOLS APPL, V66, P147, DOI 10.1007/s11042-011-0973-0
NR 46
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 7
EP 32
DI 10.1007/s11042-012-1228-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200002
DA 2024-07-18
ER

PT J
AU Zenz, G
   Tahmasebi, N
   Risse, T
AF Zenz, Gideon
   Tahmasebi, Nina
   Risse, Thomas
TI Towards mobile language evolution exploitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Language evolution; Mobile applications; Ambient media; Social networks
AB Knowing about the evolution of a term can significantly help when searching for relevant information, especially in case of sudden evolutions (e.g. as of dramatical changes in political situations). Here, some terms get a completely new meaning or are used in new or different ways. In mobile situations it is important to be able to effectively retrieve information, since this is usually done in a hurry and interaction possibilities with mobile devices are limited. In this paper we describe a methodology using word sense discrimination to discover term evolution. We present two mobile interfaces for easy access and exploration of this evolution, as well as a user-study to show its usefulness. We conclude the paper with an outlook of further research possibilities in this new topic.
C1 [Zenz, Gideon; Tahmasebi, Nina; Risse, Thomas] L3S Res Ctr, Hannover, Germany.
C3 Leibniz University Hannover
RP Zenz, G (corresponding author), L3S Res Ctr, Hannover, Germany.
EM zenz@L3S.de; tahmasebi@L3S.de; risse@L3S.de
OI Tahmasebi, Nina/0000-0003-1688-1845; Risse, Thomas/0000-0001-6248-1709
FU European Commission under ARCOMEM [IST 270239]; LiWA [IST 216267]
FX This work is partly funded by the European Commission under ARCOMEM (IST
   270239) and LiWA (IST 216267).
CR [Anonymous], WORKSH MEANING 2005
   [Anonymous], THESIS U STUTTGART
   [Anonymous], JCDL
   [Anonymous], COLING 05
   [Anonymous], KDD 02
   [Anonymous], P 22 INT C COMP LING
   Borlund P, 1997, J DOC, V53, P225, DOI 10.1108/EUM0000000007198
   Davidov D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P297
   Lappas T, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P477
   Lin D., 1998, P 36 ANN M ASS COMP, V2, P768, DOI DOI 10.3115/980432.980696
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Pedersen T., 1997, PROC EMPIRICAL METHO, P197
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
NR 15
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 147
EP 159
DI 10.1007/s11042-011-0973-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200009
DA 2024-07-18
ER

PT J
AU Lim, J
   Kim, W
AF Lim, JongSeok
   Kim, WookHyun
TI Detecting and tracking of multiple pedestrians using motion, color
   information and the AdaBoost algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Pedestrian tracking; Histogram of oriented
   gradient; AdaBoost
ID POSE
AB Robust detection and tracking of pedestrians in image sequences are essential for many vision applications. In this paper, we propose a method to detect and track multiple pedestrians using motion, color information and the AdaBoost algorithm. Our approach detects pedestrians in a walking pose from a single camera on a mobile or stationary system. In the case of mobile systems, ego-motion of the camera is compensated for by corresponding feature sets. The region of interest is calculated by the difference image between two consecutive images using the compensated image. Pedestrian detector is learned by boosting a number of weak classifiers which are based on Histogram of Oriented Gradient (HOG) features. Pedestrians are tracked by block matching method using color information. Our tracking system can track pedestrians with possibly partial occlusions and without misses using information stored in advance even after occlusion is ended. The proposed approach has been tested on a number of image sequences, and was shown to detect and track multiple pedestrians very well.
C1 [Lim, JongSeok; Kim, WookHyun] Yeungnam Univ, Dept Comp Engn, Gyongsan, Gyeongbuk, South Korea.
C3 Yeungnam University
RP Kim, W (corresponding author), Yeungnam Univ, Dept Comp Engn, 280 Daehak Ro, Gyongsan, Gyeongbuk, South Korea.
EM robertlim@yumail.ac.kr; whkim@yumail.ac.kr
FU Yeungnam University
FX This research was supported by the Yeungnam University research grants
   in 2010.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Broggi A, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P410, DOI 10.1109/IVS.2003.1212946
   Censi A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P665, DOI 10.1109/ICIAP.1999.797671
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   GUTMAN PO, 1990, IEEE T AERO ELEC SYS, V26, P691, DOI 10.1109/7.102704
   Harris C., 1988, ALVEY VISION C, P147151
   IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Jung B., 2004, International Conference on Intelligent Autonomous Systems, P980
   Jung JJ, 2012, EXPERT SYST APPL, V39, P4049, DOI 10.1016/j.eswa.2011.09.096
   Jung JJ, 2012, INFORM SCIENCES, V182, P30, DOI 10.1016/j.ins.2010.08.042
   Jung JJ, 2010, J UNIVERS COMPUT SCI, V16, P2099
   Lee MW, 2006, LECT NOTES COMPUT SC, V3953, P368
   Leibe B, 2005, PROC CVPR IEEE, P878
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Mohan A, 2001, IEEE T PAMI, V23, P156
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Peter JR, 2005, IEEE C COMP VIS PATT, P271
   Ramanan D, 2005, PROC CVPR IEEE, P271
   Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sigal L, 2004, PROC CVPR IEEE, P421
   Smith K, 2005, PROC CVPR IEEE, P962
   Srinivasan S, 1997, P IEEE INT C IM PROC, P420
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Zhao L, 2004, IEEE T PAMI, V26, P1208
   Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151
   Zhao T, 2004, PROC CVPR IEEE, P406
NR 32
TC 20
Z9 22
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 161
EP 179
DI 10.1007/s11042-012-1156-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800010
DA 2024-07-18
ER

PT J
AU Rho, S
   Song, S
   Nam, Y
   Hwang, E
   Kim, M
AF Rho, Seungmin
   Song, Seheon
   Nam, Yunyoung
   Hwang, Eenjun
   Kim, Minkoo
TI Implementing situation-aware and user-adaptive music recommendation
   service in semantic web and real-time multimedia computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Customization; Ontology; Reasoning; Semantic web; User profiles
ID TRACKING; SYSTEM; QUERY
AB With the advent of the ubiquitous era, many studies have been devoted to various situation-aware services in the semantic web environment. One of the most challenging studies involves implementing a situation-aware personalized music recommendation service which considers the user's situation and preferences. Situation-aware music recommendation requires multidisciplinary efforts including low-level feature extraction and analysis, music mood classification and human emotion prediction. In this paper, we propose a new scheme for a situation-aware/user-adaptive music recommendation service in the semantic web environment. To do this, we first discuss utilizing knowledge for analyzing and retrieving music contents semantically, and a user adaptive music recommendation scheme based on semantic web technologies that facilitates the development of domain knowledge and a rule set. Based on this discussion, we describe our Context-based Music Recommendation (COMUS) ontology for modeling the user's musical preferences and contexts, and supporting reasoning about the user's desired emotions and preferences. Basically, COMUS defines an upper music ontology that captures concepts on the general properties of music such as titles, artists and genres. In addition, it provides functionality for adding domain-specific ontologies, such as music features, moods and situations, in a hierarchical manner, for extensibility. Using this context ontology, we believe that logical reasoning rules can be inferred based on high-level (implicit) knowledge such as situations from low-level (explicit) knowledge. As an innovation, our ontology can express detailed and complicated relations among music clips, moods and situations, which enables users to find appropriate music. We present some of the experiments we performed as a case-study for music recommendation.
C1 [Rho, Seungmin; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Song, Seheon] Ajou Univ, Grad Sch Informat & Commun, Suwon 441749, South Korea.
   [Nam, Yunyoung] Ajou Univ, Ctr Excellence Ubiquitous Syst, Suwon 441749, South Korea.
   [Kim, Minkoo] Ajou Univ, Div Informat & Comp Engn, Suwon 441749, South Korea.
C3 Korea University; Ajou University; Ajou University; Ajou University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM ehwang04@korea.ac.kr
RI Nam, Yunyoung/AAI-4536-2020; Rho, Seungmin/HTP-6683-2023
OI Nam, Yunyoung/0000-0002-3318-9394; 
FU MKE(Ministry of Knowledge Economy), Korea, under the ITRC(Information
   Technology Research Center) [NIPA-2011-C1090-1101-0008]
FX "This research was supported by the MKE(Ministry of Knowledge Economy),
   Korea, under the ITRC(Information Technology Research Center) support
   program supervised by the NIPA (National IT Industry Promotion Agency)"
   (NIPA-2011-C1090-1101-0008)
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2011, Handbook of music and emotion: Theory, research, applications
   [Anonymous], IFIP WG 5 7 WORKSH B
   [Anonymous], 1990, COGNITIVE FDN MUSICA
   [Anonymous], P ISMIR
   [Anonymous], P 19 INT JOINT C ART
   Birmingham W, 2006, COMMUN ACM, V49, P49, DOI 10.1145/1145287.1145313
   Cano P, 2005, P ACM INT C MULT, P211
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Jun S., 2008, INT C VIS INF ENG JU, P673, DOI DOI 10.1049/CP:20080398
   Klaus RS, 2001, MUSIC EMOTION THEORY
   Krzysztof J, 2010, STUDIES COMPUTATIONA, V289, P275
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Ortony Andrew., 1998, COGNITIVE STRUCTURE
   Oscar C, 2008, J WEB SEMAN, V6, P256
   Oscar C, 2006, SEM DIG MED TECHN SA
   Paulo N, 2006, P EUR SIM MOD C, P5
   Rho S, 2008, J SYST SOFTWARE, V81, P1065, DOI 10.1016/j.jss.2007.05.038
   Richard A, 2009, HDB ONTOLOGIES, P403
   Ruebenstrunk G., 1998, Emotional Computers, Computer models of emotions and their meaning for emotion-psychological research
   Russell JA, 1980, J PERS SOC PSYCHOL, V39
   Song S, 2009, THIRD INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2009, PROCEEDINGS, P304, DOI 10.1109/ICDS.2009.50
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   W3C, RDF SPEC
   YVES R, 2007, P INT C MUS INF RETR, P417
   Yves R, MUSIC ONTOLOGY SPECI
NR 27
TC 9
Z9 12
U1 1
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 259
EP 282
DI 10.1007/s11042-011-0803-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100006
DA 2024-07-18
ER

PT J
AU Hsiao, KF
AF Hsiao, Kuei-Fang
TI Using augmented reality for students health - case of combining
   educational learning with standard fitness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; E-Learning; Fitness; Education; Health; Computer
   application
ID TRENDS; ADOLESCENTS; EXERCISE
AB Excessive use of non physical entertainments and lack of adequate indoors physical activities in conjunction with pressure from parents for a higher academic performance is creating serious health concerns amongst young students throughout the world. This problem is more sever in industrial societies such as Taiwan with warnings from the government. In order to solve this acute problem we propose a better use of computer technology in form of integrating the augmented reality (AR) with the regular educational process, where a newly designed AR-Fitness system combines physical exercises with academic lessons and associated tests. The new combined learning environment implements four standard physical fitness training schemes with cognitive learning in five categories of physical education (PE) knowledge including 'Cardiopulmonary Endurance', 'Flexibility', 'Explosiveness', 'Muscular Endurance' and 'Sport Injury' to test the new system.
C1 Ming Chuan Univ, Dept Informat Management, Gui Shan, Taoyuan County, Taiwan.
C3 Ming Chuan University
RP Hsiao, KF (corresponding author), Ming Chuan Univ, Dept Informat Management, Gui Shan, Taoyuan County, Taiwan.
EM kfhsiao@mail.mcu.edu.tw
FU National Science Council, Taiwan [NSC 100-2511-S-130-003-MY2]
FX This study is supported by the National Science Council, Taiwan, under
   contract numbers: NSC 100-2511-S-130-003-MY2. This research work has
   benefitted from Professor Habib F. Rashvand for his insightful
   discussions and valuable suggestions, Professor S.Y. Huang for his
   technical support, the PE specialist, Dr. K. B. Kuo and the AR research
   team in Ming-Chuan University, Taiwan.
CR [Anonymous], BOD MASS IND BMI
   [Anonymous], 2006, OB OV
   [Anonymous], 2007, PLAN HAPP LIF HIGH S
   [Anonymous], CARD FUNCT
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Chou C, 2007, COMPUT HUM BEHAV, V23, P812, DOI 10.1016/j.chb.2004.11.011
   Ekblom ÖB, 2004, SCAND J PUBLIC HEALT, V32, P257, DOI 10.1080/1403494031009498
   Ekblom ÖB, 2009, ACTA PAEDIATR, V98, P519, DOI 10.1111/j.1651-2227.2008.01154.x
   Halim Zahid, 2010, International Journal of Information Technology, Communications and Convergence, V1, P92, DOI 10.1504/IJITCC.2010.035229
   Heim Michael., 1998, Virtual Realism
   Hillman CH, 2008, NAT REV NEUROSCI, V9, P58, DOI 10.1038/nrn2298
   Hsiao HE, 2005, J ALETHELA, V8, P191
   Hsiao KF, 2010, J CYBERTHERAPY REHAB, V3, P51
   Hsiao KF, 2007, P INT AC C MCU TAIW
   Hsiao KF, 2010, INTERACTIVE LEARNING
   Ipsos MORI, 2009, 2008 SURV CHILDR US
   Kaufmann H, 2002, 10 ACM INT C MULT
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   MacQuarrie C, 2008, QUAL REP, V13, P262
   Manzoni GM, 2008, J CYBERTHER REHAB, V1, P11
   Muhlberger A., 2008, Journal of CyberTherapy and Rehabilitation, V1, P147
   O'Brien HL, 2005, ASIS T N CAR US
   Peters DM, 2010, KINESIOLOGY, V42, P36
   Rountree Janet, 2002, Educational Technology e+r Society, V5, P129
   Sale RA, 2010, J CONVERGENCE, V1, P9
   Shiuh-Jeng Wang, 2010, International Journal of Information Technology, Communications and Convergence, V1, P66, DOI 10.1504/IJITCC.2010.035227
   Swanton K., 2008, HLTH WEIGHT HLTH LIV
   Wang CN, 2003, FDN MED, V18, P210
   Westerstahl M, 2003, SCAND J MED SCI SPOR, V13, P128, DOI 10.1034/j.1600-0838.2003.10274.x
   Yang JC, 2010, COMPUT EDUC, V55, P1346, DOI 10.1016/j.compedu.2010.06.005
NR 31
TC 30
Z9 30
U1 5
U2 110
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 407
EP 421
DI 10.1007/s11042-011-0985-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200011
DA 2024-07-18
ER

PT J
AU Liu, XM
   Yao, HX
   Ji, RR
   Xu, PF
   Sun, XS
AF Liu, Xianming
   Yao, Hongxun
   Ji, Rongrong
   Xu, Pengfei
   Sun, Xiaoshuai
TI Bidirectional-isomorphic manifold learning at image semantic
   understanding & representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-training; Image annotation; Image retrieval; Manifold learning
AB From relevant textual information to improve visual content understanding and representation is an effective way for deeply understanding web image content. However, the description of images is usually imprecise at the semantic level, which is caused by the noisy and redundancy information in both text (such as surrounding text in HTML pages) and visual (such as intra-class diversity) aspects. This paper considers the solution from the association analysis for image content and presents a Bidirectional- Isomorphic Manifold learning strategy to optimize both visual feature space and textual space, in order to achieve more accurate comprehension for image semantics and relationships. To achieve this optimization between two different models, Bidirectional-Isomorphic Manifold Learning utilizes a novel algorithm to unify adjustments in both models together to a topological structure, which is called the reversed Manifold mapping. We also demonstrate its correctness and convergence from a mathematical perspective. Image annotation and keywords correlation analysis are applied. Two groups of experiments are conducted: The first group is carried on the Corel 5000 image database to validate our method's effectiveness by comparing with state-of-the-art Generalized Manifold Ranking Based Image Retrieval and SVM, while the second group carried on a web-downloaded Flickr dataset with over 6,000 images to testify the proposed method's effectiveness in real-world application. The promising results show that our model attains a significant improvement over state-of-the-art algorithms.
C1 [Liu, Xianming; Yao, Hongxun; Ji, Rongrong; Xu, Pengfei; Sun, Xiaoshuai] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150006, Peoples R China.
EM xmliu@hit.edu.cn; h.yao@hit.edu.cn; rrji@hit.edu.cn; pfxu@hit.edu.cn;
   xiaoshuaisun_hit@163.com
FU National Science Foundation of China [61071180]; Key Program Grant of
   National Science Foundation of China [61133003]
FX The work was supported in part by the National Science Foundation of
   China No. 61071180, and Key Program Grant of National Science Foundation
   of China No. 61133003.
CR [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2006, SEMISUPERVISED LEARN
   [Anonymous], TECHNICAL REPORT
   Barnard K, 2003, J MACH LEARNING RES, V1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Culp M, 2007, IEEE T PATTERN ANAL, V2, P856
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Goldman S., 2000, ICML, P327
   Guan Haiying., 2007, Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Ji R, 2008, P VIS COMM IM PROC
   Ji R, 2007, P ACM INT WORKSH MUL
   Jing F, 2005, IEEE T IMAGE PROCESS, V14, P979, DOI 10.1109/TIP.2005.847289
   Joachims T, 2003, P ACM INT C MACH LEA
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Lang S., 1996, DIFFERENTIAL RIEMANN
   Lee J. M., 2000, Introduction to Topological Manifolds
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu J., 2006, P ACM INT WORKSHOP M, P61, DOI DOI 10.1145/1178677.1178689
   LIU X, 2009, P ACM INT C MULT
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang X., 2004, ACM INT C MULTIMEDIA, P944
   Weinberger K.Q., 2008, Proceedings of Conference on Multimedia, P111
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhou ZH, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P908
   Zhou ZH, 2006, ACM T INFORM SYST, V24, P219, DOI 10.1145/1148020.1148023
NR 39
TC 2
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 53
EP 76
DI 10.1007/s11042-011-0947-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600004
DA 2024-07-18
ER

PT J
AU Haque, MA
   Kim, JM
AF Haque, Mohammad A.
   Kim, Jong-Myon
TI An analysis of content-based classification of audio signals using a
   fuzzy c-means algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio segmentation and classification; Fuzzy c-means algorithm;
   Multimedia; Database retrieval
ID MUSICAL GENRE CLASSIFICATION; RETRIEVAL; SEGMENTATION
AB Content-based audio signal classification into broad categories such as speech, music, or speech with noise is the first step before any further processing such as speech recognition, content-based indexing, or surveillance systems. In this paper, we propose an efficient content-based audio classification approach to classify audio signals into broad genres using a fuzzy c-means (FCM) algorithm. We analyze different characteristic features of audio signals in time, frequency, and coefficient domains and select the optimal feature vector by employing a noble analytical scoring method to each feature. We utilize an FCM-based classification scheme and apply it on the extracted normalized optimal feature vector to achieve an efficient classification result. Experimental results demonstrate that the proposed approach outperforms the existing state-of-the-art audio classification systems by more than 11% in classification performance.
C1 [Haque, Mohammad A.; Kim, Jong-Myon] Univ Ulsan, Sch Elect Engn, Ulsan 680749, South Korea.
C3 University of Ulsan
RP Kim, JM (corresponding author), Univ Ulsan, Sch Elect Engn, Ulsan 680749, South Korea.
EM jongmyon.kim@gmail.com
OI Haque, Mohammad Ahsanul/0000-0001-5613-2190
FU National Research Foundation of Korea(NRF); Korea government(MEST)
   [2011-0017941]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MEST) (No. 2011-0017941)
CR Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chen L, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P781, DOI 10.1109/ICME.2006.262954
   Haque MA, 2013, MULTIMED TOOLS APPL, V63, P485, DOI 10.1007/s11042-011-0921-z
   Khan MKS, 2006, MULTIMEDIA SYST, V12, P55, DOI 10.1007/s00530-006-0034-0
   Kim KM, 2006, IEEE T CONSUM ELECTR, V52, P200
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Krishnamoorthy P, 2011, MULTIMED TOOLS APPL, V54, P415, DOI 10.1007/s11042-010-0546-7
   Langlois T, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN MULTIMEDIA, P188, DOI 10.1109/MMEDIA.2009.42
   Lee CH, 2009, IEEE T MULTIMEDIA, V11, P670, DOI 10.1109/TMM.2009.2017635
   Li JB, 2005, ISTM/2005: 6th International Symposium on Test and Measurement, Vols 1-9, Conference Proceedings, P8414
   Li JB, 2006, INT C COMMUN CIRCUIT, P490
   Li W, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P627
   Liu M., 2002, Soft Computing, V6, P357, DOI 10.1007/s00500-002-0189-3
   Lopes Miguel, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4569, DOI 10.1109/ICPR.2010.1128
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Lu L, 2001, IEEE INT C MULT EXP, P191
   Luong HV, 2009, J ACOUST SOC AM, V125, P2699
   Mirceva G, 2010, J CONVERGENCE, V1, P57
   Mitra V, 2007, IEEE IJCNN, P1494, DOI 10.1109/IJCNN.2007.4371179
   Nguyen NTT, 2011, INT S NEUR IN PRESS
   Nitanda N., 2006, Systems and Computers in Japan, V37, P23, DOI 10.1002/scj.20491
   Park DC, 2005, LECT NOTES COMPUT SC, V3767, P698
   Park DC, 2011, IEEE INT S SIGN PROC, P394
   Park DC, 2006, LECT NOTES ARTIF INT, V4099, P1104, DOI 10.1007/978-3-540-36668-3_142
   Park DC, 2009, PATTERN RECOGN LETT, V30, P794, DOI 10.1016/j.patrec.2008.05.019
   Popescu A, 2009, P C SPEECH TECHN HUM, P1
   Pyshkin E, 2010, J CONVERG, V1, P1
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Simsekli Umut, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4137, DOI 10.1109/ICPR.2010.1006
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Turnbull D, 2005, IEEE T KNOWL DATA EN, V17, P580, DOI 10.1109/TKDE.2005.62
   TZAGKARAKIS C, 2006, INT CONF ACOUST SPEE, P217
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang JC, 2006, INT C PATT RECOG, P157
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Yunming Ye, 2011, International Journal of Information Technology, Communications and Convergence, V1, P206, DOI 10.1504/IJITCC.2011.039286
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
   Zhu YY, 2007, LECT NOTES COMPUT SC, V4577, P474
NR 39
TC 14
Z9 14
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 77
EP 92
DI 10.1007/s11042-012-1019-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400006
DA 2024-07-18
ER

PT J
AU Zhou, XK
   Yen, NY
   Jin, Q
   Shih, TK
AF Zhou, Xiaokang
   Yen, Neil Y.
   Jin, Qun
   Shih, Timothy K.
TI Enriching user search experience by mining social streams with heuristic
   stones and associative ripples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social stream; Information seeking; Search experience; Stream metaphor;
   SNS
ID SEMANTIC WEB
AB Recently, social networking sites such as Facebook and Twitter are becoming increasingly popular. The high accessibility of these sites has allowed the so-called social streams being spread across the Internet more quickly and widely, as more and more of the populations are being engaged into this vortex of the social networking revolution. Information seeking never means simply typing a few keywords into a search engine in this stream world. In this study, we try to find a way to utilize these diversified social streams to assist the search process without relying solely on the inputted keywords. We propose a method to analyze and extract meaningful information in accordance with users' current needs and interests from social streams using two developed algorithms, and go further to integrate these organized stream data which are described as associative ripples into the search system, in order to improve the relevance of the results obtained from the search engine and feedback users with a new perspective of the sought issues to guide the further information seeking process, which can benefit both search experience enrichment and search process facilitation.
C1 [Zhou, Xiaokang; Yen, Neil Y.; Jin, Qun] Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
   [Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Tao Yuan, Taiwan.
C3 Waseda University; National Central University
RP Jin, Q (corresponding author), Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
EM xkzhou@ruri.waseda.jp; neilyyen@ieee.org; jin@waseda.jp;
   timothykshih@gmail.com
RI Bennis, Mehdi/ABE-5838-2020
OI Bennis, Mehdi/0000-0003-0261-0171
CR [Anonymous], 2002, P 21 ACM SIGMOD SIGA
   [Anonymous], 2003, P 29 INT C VER LARG
   [Anonymous], 2008, P 17 INT C WORLD WID
   Bojars U, 2008, J WEB SEMANT, V6, P21, DOI 10.1016/j.websem.2007.11.010
   Buter B., 2011, J CONVERG, V2, P87
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chen H, 2010, 2 INT S MULT EM NETW
   Chi EH, 2009, COMPUTER, V42, P42, DOI 10.1109/MC.2009.87
   Ebner M., 2009, J RES INNOVATIVE TEA, V2, P108
   Ebner M., 2009, P 5 EDUMEDIA C, P145
   Ebner M, 2010, COMPUT EDUC, V55, P92, DOI 10.1016/j.compedu.2009.12.006
   Fang X, 2004, ACM Trans. Internet Tech., V4, P209
   Gaber MM, 2005, SIGMOD REC, V34, P18, DOI 10.1145/1083784.1083789
   Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387
   GUHA S, 2000, P ANN S FDN COMP SCI
   Jagadish H. V., 1995, Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1995, P113, DOI 10.1145/212433.220201
   Johnson KA, 2011, LEARN MEDIA TECHNOL, V36, P21, DOI 10.1080/17439884.2010.534798
   Junco R, 2011, J COMPUT ASSIST LEAR, V27, P119, DOI 10.1111/j.1365-2729.2010.00387.x
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   ORDONEZ C, 2003, P 8 ACM SIGMOD WORKS, P12, DOI DOI 10.1145/882082.882087
   Passant A, 2008, P ESWC SFSW2008 TEN
   Passant A, 2010, P AAAI ICWSM 2010
   Poblete B., 2008, PROCEEDING 17 INT C, P41
   Pyshkin E, 2010, J CONVERG, V1, P1
   Signorini A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019467
   Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12, DOI DOI 10.1145/846183.846188
   Stumme G, 2006, J WEB SEMANT, V4, P124, DOI 10.1016/j.websem.2006.02.001
   Yunming Ye, 2011, International Journal of Information Technology, Communications and Convergence, V1, P206, DOI 10.1504/IJITCC.2011.039286
   Zhou XK, 2011, ACM ICUIMC2011 5 INT
NR 29
TC 15
Z9 15
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 129
EP 144
DI 10.1007/s11042-012-1069-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400009
DA 2024-07-18
ER

PT J
AU Lin, YC
   Wang, HA
   Hsieh, YF
AF Lin, Yen-Chun
   Wang, Hsiang-An
   Hsieh, Yi-Fang
TI Image matting through a Web browser
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alpha matte; Foreground extraction; Image editing; Image matting;
   Multimedia; Web-based
AB Image matting is a process of foreground extraction from an image. An interactive, Web-based tool, called NIM 2.0, for image matting is presented in this paper. NIM is the first image matting tool accessible through a Web browser. Its algorithm has been improved from the first version to make it faster. How NIM is used, why it works, its architecture, and experimental results are described. It can extract a foreground with thin, thread-like shapes. It begins to process inputs immediately after the user has started to paint with a brush roughly along the boundary between the foreground and the background. While painting, the user can stop anywhere to change the width of brush as needed to achieve good matting quality. The quality of the foreground extracted by NIM is usually better or not worse than those done by the other two online tools and Photoshop. NIM is fast and the amount of time required to complete matting is essentially limited by the speed of brush movement only. Several variations of our algorithm are also discussed and experimented.
C1 [Lin, Yen-Chun; Wang, Hsiang-An; Hsieh, Yi-Fang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, YC (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43 Keelung Rd,Sec 4, Taipei 106, Taiwan.
EM y.lin@mail.ntust.edu.tw; D9215004@mail.ntust.edu.tw;
   M9515012@mail.ntust.edu.tw
FU National Science Council of Taiwan [NSC 96-2221-E-011-161, NSC
   97-2221-E-011-093]
FX This research was supported in part by the National Science Council of
   Taiwan under contracts NSC 96-2221-E-011-161 and NSC 97-2221-E-011-093.
CR Adobe, PROGR AD ACTIONSCRIP
   Amri S, 2010, MULTIMED TOOLS APPL, V46, P175, DOI 10.1007/s11042-009-0348-y
   Aviary, PHOEN IM ED
   Barrett R, 1994, TEMPLATES SOLUTION L, DOI DOI 10.1137/1.9781611971538
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Dayley Lisa DaNae, 2010, Photoshop CS5 Bible
   FotoFlexer, WORLDS MOST ADV ONL
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Lin Y-C, 2010, P 2010 ACM S APPL CO, P1905
   Qian R. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P143, DOI 10.1109/ICIP.1999.819566
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Shelly GB, 2008, ADOBE PHOTOSHOP CS3
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239460
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
NR 18
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 551
EP 570
DI 10.1007/s11042-010-0678-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700003
DA 2024-07-18
ER

PT J
AU Chen, HT
   Tsai, WJ
   Lee, SY
   Yu, JY
AF Chen, Hua-Tsung
   Tsai, Wen-Jiin
   Lee, Suh-Yin
   Yu, Jen-Yu
TI Ball tracking and 3D trajectory approximation with applications to
   tactics analysis from single-camera volleyball sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Sports video analysis; Content-based multimedia
   analysis; Camera calibration; 3D trajectory approximation
ID SHOT CLASSIFICATION; VIDEOS; FRAMEWORK; AUDIO
AB Providing computer-assisted tactics analysis in sports is a growing trend. This paper presents an automatic system for ball tracking and 3D trajectory approximation from single-camera volleyball sequences as well as demonstrates several applications to tactics analysis. Ball tracking in volleyball video has great complexity due to the high density of players on the court and the complicated overlapping of ball-player. The 2D-to-3D inference is intrinsically challenging due to the loss of 3D information in projection to 2D frames. To overcome these challenges, we propose a two-phase ball tracking algorithm in which we first detect ball candidates for each frame, and then use them to compute the ball trajectories. With the aid of camera calibration, we involve physical characteristics of ball motion to approximate the 3D ball trajectory from the 2D trajectory. The visualization of 3D trajectory and the applications to trajectory-based tactics analysis not only assist the coaches and players in game study but also make game watching a whole new experience. The experiments on international volleyball games show encouraging results. We believe that the proposed framework can be extended and applied to various kinds of sports games.
C1 [Chen, Hua-Tsung] Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
   [Tsai, Wen-Jiin; Lee, Suh-Yin] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Yu, Jen-Yu] ICL Ind Technol Res Inst, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw
FU National Science Council of Taiwan, R.O.C [NSC 95-2221-E-009-076-MY3];
   Lee and MTI center for Networking Research at National Chiao Tung
   University, Taiwan
FX The research is partially supported by the National Science Council of
   Taiwan, R.O.C, under the grant No. NSC 95-2221-E-009-076-MY3 and
   partially supported by Lee and MTI center for Networking Research at
   National Chiao Tung University, Taiwan.
CR [Anonymous], 2007, P 15 ACM INT C MULTI
   [Anonymous], QUESTEC UMPIRE INFOR
   [Anonymous], ACM INT C MULT
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Chen HT, 2008, IEEE INT SYMP CIRC S, P3522, DOI 10.1109/ISCAS.2008.4542219
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2007, INT CONF ACOUST SPEE, P1097
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Duan L.Y., 2003, Proc. ACM Int. Conf. Multimedia, P33
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Farin D, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P482, DOI 10.1109/ICME.2005.1521465
   Farin D, 2004, PROC SPIE, V5307, P80
   Forlines C, 2006, P SPIE INT SOC OPT E, V6073, P170
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guéziec A, 2002, COMPUTER, V35, P38, DOI 10.1109/2.989928
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Loui Alexander., 2007, MIR 07, P245
   Lu H, 2003, PATTERN RECOGN LETT, V24, P2651, DOI 10.1016/S0167-8655(03)00108-9
   Mei T, 2008, MULTIMED TOOLS APPL, V40, P89, DOI 10.1007/s11042-007-0186-8
   Oami R, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1475, DOI 10.1109/ICME.2004.1394514
   Owens N., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P182, DOI 10.1049/cp:20030517
   Seo Y., 1997, International Conference on Image Analysis and Processing, P196, DOI DOI 10.1007/3-540-63508-4
   Tien MC, 2007, INT CONF ACOUST SPEE, P1085
   Watanabe T, 2004, IEEE IMAGE PROC, P1633
   Xinguo Yu, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P93
   Xu M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P281
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1543
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Yu XG, 2009, COMPUT VIS IMAGE UND, V113, P643, DOI 10.1016/j.cviu.2008.01.006
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 34
TC 47
Z9 50
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 641
EP 667
DI 10.1007/s11042-011-0833-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300009
DA 2024-07-18
ER

PT J
AU Atrey, PK
   Ibrahim, H
   Hossain, MA
   Ramanna, S
   El Saddik, A
AF Atrey, Pradeep K.
   Ibrahim, Hicham
   Hossain, M. Anwar
   Ramanna, Sheela
   El Saddik, Abdulmotaleb
TI Determining trust in media-rich websites using semantic similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Web; Trust; Semantic similarity
ID IMAGE RETRIEVAL
AB Significant growth of multimedia content on the World Wide Web (or simply 'Web') has made it an essential part of peoples lives. The web provides enormous amount of information, however, it is very important for the users to be able to gauge the trustworthiness of web information. Users normally access content from the first few links provided to them by search engines such as Google or Yahoo!. This is assuming that these search engines provide factual information, which may be popular due to criteria such as page rank but may not always be trustworthy from the factual aspects. This paper presents a mechanism to determine trust of websites based on the semantic similarity of their multimedia content with already established and trusted websites. The proposed method allows for dynamic computation of the trust level of websites of different domains and hence overcomes the dependency on traditional user feedback methods for determining trust. In fact, our method attempts to emulate the evolving process of trust that takes place in a user's mind. The experimental results have been provided to demonstrate the utility and practicality of the proposed method.
C1 [Atrey, Pradeep K.; Ramanna, Sheela] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
   [Ibrahim, Hicham; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   [Hossain, M. Anwar] King Saud Univ, Software Engn Dept, CCIS, Riyadh, Saudi Arabia.
C3 University of Winnipeg; University of Ottawa; King Saud University
RP Atrey, PK (corresponding author), Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
EM p.atrey@uwinnipeg.ca; hibrahim@mcrlab.uottawa.ca; mahossain@ksu.edu.sa;
   s.ramanna@uwinnipeg.ca; abed@mcrlab.uottawa.ca
RI /D-4159-2009; Hossain, M. Anwar/J-9601-2013
OI /0000-0002-7690-8547; Hossain, M. Anwar/0000-0002-7673-8410
FU Natural Science and Engineering Research Council of Canada; King Saud
   University
FX Authors sincerely thank the Natural Science and Engineering Research
   Council of Canada and the King Saud University Visiting Professors
   Program for supporting this research.
CR Al-Ani B, 2008, ACM WORKSH HCI COMM
   Albertoni R, 2008, LECT NOTES COMPUT SC, V4900, P1
   Andreatta C, 2008, INT WORK CONTENT MUL, P54
   Ang L., 2001, BLED eConference, P43
   [Anonymous], 1971, OXFORD ENGLISH DICT, V9th
   [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   Barrington L, 2007, INT CONF ACOUST SPEE, P725
   Belanger F, 2002, J STRATEGIC INF SYST, V11, P245, DOI 10.1016/S0963-8687(02)00018-5
   Bizer Christian., 2004, P 13 INT WORLD WIDE, P228
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Buttler D., 2004, 5 INT C INT COMP
   Chen Wu, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P452, DOI 10.1109/ETCS.2010.404
   Chen X., 2007, INFORM MODELLING KNO, V154, P245
   Choi J, 2003, INT C COMP SCI ITS A, V2667, P967
   Daniel B. K, 2002, BUILDING SOCIAL CAPI
   Fox S., 2000, TRUST PRIVACY ONLINE
   Friedman B, 2000, COMMUN ACM, V43, P34, DOI 10.1145/355112.355120
   Golbeck J., 2006, ACM Transactions on Internet Technology, V6, P497, DOI 10.1145/1183463.1183470
   Husted B., 1998, Business Ethics Quarterly, V8, P233, DOI [10.2307/3857327, DOI 10.2307/3857327]
   Ibrahim H., 2007, The 1st ACM International Workshop on The Many Faces of Multimedia Semantics, P65
   Jung MY, 2009, STUD COMPUT INTELL, V226, P381
   Kaur I, 2005, P 2005 C HUMAN FACTO, P51
   Kobayashi N., 2007, Information and Media Technologies, V2, P326
   Lee Michael., 2005, Proceedings of the 27th Annual Conference of the Cognitive Science Society, P1254
   Li Y, 2008, 20 INT C SOFTW ENG K
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   NEILSEN J, 1999, TRUST BUST COMMUNICA
   Nissenbaum H, 2001, BOSTON U LAW REV, V81, P635
   Oommen BJ, 2005, ARTIF INTELL, V164, P1, DOI 10.1016/j.artint.2002.02.001
   Ramanna S, 2010, CH CRC MATH COMP IMA
   Ryan MJ, 2004, TRUSTING YOURSELF ST
   Schneider GK, 2008, ALGORITHMS LIB GUIDE
   Singh R, 2010, MULTIMED TOOLS APPL, V50, P491, DOI 10.1007/s11042-010-0487-1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torres V, 2005, IASTED C WEB TECHN A
   Wang YD, 2005, COMPUT HUM BEHAV, V21, P105, DOI 10.1016/j.chb.2003.11.008
   Wei Wei, 2010, 2010 2nd IEEE International Conference on Information Management and Engineering (ICIME 2010), P85, DOI 10.1109/ICIME.2010.5477506
NR 37
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 69
EP 96
DI 10.1007/s11042-011-0798-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500004
DA 2024-07-18
ER

PT J
AU Singh, J
   Garg, P
   De, AN
AF Singh, Jyotsna
   Garg, Parul
   De, Alok Nath
TI Audio watermarking based on quantization index modulation using combined
   perceptual masking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital audio watermarking; Masking threshold; Quantization index
   modulation; Subbands
ID SPREAD-SPECTRUM WATERMARKING
AB In this paper, a robust audio watermarking scheme for MPEG-1/ Audio Layer II compressed domain is proposed. The scheme is implemented by modifying the subband coefficients using adaptive quantization index modulation. The watermarking procedure exploits perceptual frequency and temporal masking of the human auditory system (HAS) of MPEG coder to satisfy the requirements of robustness, security and transparency. This reduces the computational complexity of proposed scheme. The paper investigates the use of elevated masking threshold to improve detection and achieve higher robustness against re-encoding and awgn attacks. Experimental results show that high capacity of 6,840 bps with ODG -0.5 without altering the MPEG/audio bitrate.
C1 [Singh, Jyotsna; Garg, Parul] Netaji Subhas Inst Technol, Div Elect & Commun Engn, New Delhi 110075, India.
   [De, Alok Nath] ST Ericsson India, SMIEEE, Greater Noida 201308, UP, India.
C3 Netaji Subhas University of Technology; Ericsson
RP Singh, J (corresponding author), Netaji Subhas Inst Technol, Div Elect & Commun Engn, Sect 3, New Delhi 110075, India.
EM jsingh.nsit@gmail.com; parul_saini@yahoo.co.in;
   aloknath.de@stericsson.com
CR Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Ching-Te Wang, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P984
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   De A, 2001, ITU T ITU D WORKSH B
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Gaorong Zeng, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P2193, DOI 10.1109/ICOSP.2008.4697583
   GUNAWAN TS, 2007, THESIS U NEW S WALES
   Ho RL, 2003, ICCE: 2003 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P212, DOI 10.1109/ICCE.2003.1218890
   ITU-R, 2001, METH OBJ MEAS PERC A
   JESTEADT W, 1982, J ACOUST SOC AM, V71, P950, DOI 10.1121/1.387576
   Garcia-Hernandez JJ, 2008, IEICE ELECTRON EXPR, V5, P217, DOI 10.1587/elex.5.217
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   LIU YW, 2004, P IEEE INT C AC SPEE, P221
   Matsuoka A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1585, DOI 10.1109/ICME.2006.262848
   Neubauer C, 2000, P AES 108 CONV PAR 1
   Noll P, 1998, ELEC ENG HANDB SER, P401
   PAN D, 1995, IEEE MULTIMEDIA, V2, P60, DOI 10.1109/93.388209
   Qiao LT, 1999, P SOC PHOTO-OPT INS, V3657, P194, DOI 10.1117/12.344669
   Senbin Yang, 2010, Journal of Multimedia, V5, P151, DOI 10.4304/jmm.5.2.151-158
   Sonoda Kotaro, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P72, DOI 10.1109/IIH-MSP.2009.89
   Tachibana R, 2002, SIGNAL PROCESS, V82, P1455, DOI 10.1016/S0165-1684(02)00284-0
   Takagi K, 2008, IEICE T FUND ELECTR, VE91A, P2546, DOI 10.1093/ietfec/e91-a.9.2546
   Vincent E, 2005, MUSHRAM A MATLAB INT
   Zwicker E., 2013, Psychoacoustics: Facts and Models
NR 25
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 921
EP 939
DI 10.1007/s11042-011-0783-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900009
DA 2024-07-18
ER

PT J
AU Codognet, P
   Pasquet, O
AF Codognet, Philippe
   Pasquet, Olivier
TI Ambient sound spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient multimedia installation; Media art; Multi-agent systems;
   Simulation; Computer-based music; Generative music; Real-time sound
   processing
ID PERCEPTION
AB We present in this paper a media installation creating in real-time ambient electronic music from a multi-agent simulation by associating agents with sounds. More specifically, we associate various sound parameters with the internal state of an agent at a given time (position, orientation, internal variables, etc.), and therefore the evolution of an agent during the simulation will modify the corresponding soundscape. The sound sources are dynamically spatialized in the actual installation space through several loudspeakers (24 loudspeakers+1 subwoofer) and modified in real-time, providing thus an ever-changing ambient soundscape. This generative music installation uses Nature-inspired simulations to drive the musical processes, and in particular the swarm intelligence metaphor.
C1 [Codognet, Philippe] Univ Tokyo, Ctr Informat Technol, JFLI,CNRS,UPMC, Bunkyo Ku, Tokyo 1138658, Japan.
   [Pasquet, Olivier] IRCAM, F-75004 Paris, France.
C3 University of Tokyo
RP Codognet, P (corresponding author), Univ Tokyo, Ctr Informat Technol, JFLI,CNRS,UPMC, Bunkyo Ku, 2-11-16 Yayoi, Tokyo 1138658, Japan.
EM codognet@jfli.itc.u-tokyo.ac.jp; olivier.pasquet@ircam.fr
FU Japanese Ministry of Education, Culture, Sports, Science and Technology
   (MEXT)
FX We would like to thank the Japanese Ministry of Education, Culture,
   Sports, Science and Technology (MEXT) for partly supporting this
   research in 2008 at Keio University Research Institute for Digital Media
   and Content.
CR [Anonymous], 1999, P GAM DEV C
   [Anonymous], Organised Sound, DOI DOI 10.1017/S1355771804000214
   [Anonymous], 1999, Swarm Intelligence
   ASHMEAD DH, 1990, PERCEPT PSYCHOPHYS, V47, P326, DOI 10.3758/BF03210871
   BECKERS R, 1992, INSECT SOC, V39, P59, DOI 10.1007/BF01240531
   Braitenberg V, 1984, Vehicles. Experiments in Synthetic Psychology
   Codognet P, 2009, P ISM2009 IEEE INT S
   Codognet P, 2010, LNCS
   Couzin ID, 2002, J THEOR BIOL, V218, P1, DOI 10.1006/jtbi.2002.3065
   Dahlstedt P, 2006, LEONARDO, V39, P469, DOI 10.1162/leon.2006.39.5.469
   Davis T, 2007, P SMC 07 4 SOUND MUS
   Jin XG, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P109
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Luke S., 2004, P SWARMFEST04 8 SWAR
   Murray-Rust D, 2005, P ICCIMA 05 6 INT C
   Noma T, 2000, IEEE COMPUT GRAPH, V20, P79, DOI 10.1109/38.851755
   Pachet F, 2000, P ICMC2000 INT C COM
   Panait L, 2004, P ALIFE9 9 INT C SIM
   Pedica C, 2008, LECT NOTES COMPUT SC, V5208, P104
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Robinson EJH, 2005, NATURE, V438, P442, DOI 10.1038/438442a
   Shao W., 2005, P ACM SIGGRAPH 2005
   Theile G, 2004, P DAFX 04 7 INT C DI
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wulfhorst R. D., 2003, P 2 INT JOINT C AUT, P584, DOI DOI 10.1145/860575.860669
   Xenakis Iannis., 1971, FORMALIZED MUSIC THO
   Xiao H., 2009, P 2009 INT C ADV COM
NR 27
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 355
EP 370
DI 10.1007/s11042-010-0666-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500004
DA 2024-07-18
ER

PT J
AU Gao, T
   Li, G
   Lian, SG
   Zhang, J
AF Gao, Tao
   Li, Guo
   Lian, Shiguo
   Zhang, Jun
TI Tracking video objects with feature points based particle filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving objects tracking; Motion detection; SIFT; Particle filtering;
   Video surveillance
ID MEAN SHIFT; ROBUST
AB For intelligent video surveillance, the adaptive tracking of multiple moving objects is still an open issue. In this paper, a new multi-object tracking method based on video frames is proposed. A type of particle filtering combined with the SIFT (Scale Invariant Feature Transform) is proposed for motion tracking, where SIFT key points are treated as parts of particles to improve the sample distribution. Then, a queue chain method is adopted to record data associations among different objects, which could improve the detection accuracy and reduce the computational complexity. By actual road tests and comparisons, the system tracks multi-objects with better performance, e.g., real time implementation and robust against mutual occlusions, indicating that it is effective for intelligent video surveillance systems.
C1 [Gao, Tao] Elect Informat Prod Supervis & Inspect Inst Hebei, Shijiazhuang 050071, Peoples R China.
   [Gao, Tao] Ind & Informat Technol Dept Hebei Prov, Shijiazhuang 050051, Peoples R China.
   [Li, Guo] Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
   [Lian, Shiguo] France Telecom Orange Labs Beijing, Beijing 100080, Peoples R China.
   [Zhang, Jun] Tianjin Univ, Sch Elect Engn & Automat, Tianjin 300072, Peoples R China.
C3 Beijing Institute of Technology; Tianjin University
RP Gao, T (corresponding author), Elect Informat Prod Supervis & Inspect Inst Hebei, Shijiazhuang 050071, Peoples R China.
EM gaotao231@yahoo.cn; lg4229682@163.com
RI Li, Guo/ACY-6481-2022
OI Li, Guo/0000-0002-7127-1102
FU National Science Foundation of China [70773008]; Program for New Century
   Excellent Talents in University [NCET-10-0048]; Fok Ying Tung Education
   Foundation [121079]; Science Foundations of Tianjin [10ZCKFSF01100]
FX This work is supported by the National Science Foundation of China under
   Grant No. 70773008, Program for New Century Excellent Talents in
   University under Grant No. NCET-10-0048, Fok Ying Tung Education
   Foundation under Grant No. 121079, and the Science Foundations of
   Tianjin under Grant No. 10ZCKFSF01100.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Ba Hong-xin, 2004, Journal of System Simulation, V16, P1563
   Babu RV, 2007, IMAGE VISION COMPUT, V25, P1205, DOI 10.1016/j.imavis.2006.07.016
   Belcher C, 2009, OPT LASER ENG, V47, P139, DOI 10.1016/j.optlaseng.2008.07.004
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Dahlkamp H, 2007, INT J COMPUT VISION, V73, P139, DOI 10.1007/s11263-006-9786-4
   Fazli S, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P89, DOI 10.1109/ICMV.2009.47
   Gao T, 2010, J CENT SOUTH UNIV T, V17, P187, DOI 10.1007/s11771-010-0029-z
   Gao T, 2009, J SYST ENG ELECTRON, V20, P1115
   Gao T, 2009, STUD COMPUT INTELL, V214, P39
   Guan Ye-peng, 2006, Acta Electronica Sinica, V34, P624
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   Jin Y., 2007, 2007 IEEE 11 INT C C, P1, DOI [10.1109/ICCV.2007.4408952, DOI 10.1109/ICCV.2007.4408952]
   Kilger M., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P11, DOI 10.1109/ACV.1992.240332
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lei BJ, 2006, PATTERN RECOGN LETT, V27, P1816, DOI 10.1016/j.patrec.2006.02.017
   Lin MX, 2006, P 6 INT C INT SYST D, V2, P373
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   [牛长锋 NIU Changfeng], 2008, [光电工程, Opto-Electronic Engineering], V35, P26
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Ottlik A, 2008, INT J COMPUT VISION, V80, P211, DOI 10.1007/s11263-007-0112-6
   Pinkiewicz Tomasz, 2008, 2008 Digital Image Computing: Techniques and Applications, P457, DOI 10.1109/DICTA.2008.28
   RECKLEITIS I, 2003, P INT C ROB AUT, V42, P1
   Ross D, 2004, LECT NOTES COMPUT SC, V3022, P470
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rowe D, 2006, LECT NOTES COMPUT SC, V4174, P505
   Shehata M., 2006, P IEEE INT TRANSP SY, P759
   Sidenbladh H., 2003, P INT C INF FUS, P1110
   Song X, 2007, J INFRARED MILLIM W, V26, P429
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun Zhi-hai, 2008, Journal of Zhejiang University, V42, P1631
   Wang Fa-Sheng, 2008, Chinese Journal of Computers, V31, P346, DOI 10.3724/SP.J.1016.2008.00346
   Wu PL, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P932, DOI 10.1109/ICALIP.2008.4590034
   Yang CL, 2000, J SYST ENG ELECTRON, V22, P11
   [杨俊 YANG Jun], 2007, [光电工程, Opto-Electronic Engineering], V34, P92
NR 43
TC 16
Z9 22
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 1
EP 21
DI 10.1007/s11042-010-0676-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600001
DA 2024-07-18
ER

PT J
AU Naaman, M
AF Naaman, Mor
TI Social multimedia: highlighting opportunities for search and mining of
   multimedia data in social media applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Flickr; Youtube; Multimedia; HCI; Data mining; Multimedia
   applications; Evaluation
ID RETRIEVAL; MODEL; QUALITY
AB In recent years, various Web-based sharing and community services such as Flickr and YouTube have made a vast and rapidly growing amount of multimedia content available online. Uploaded by individual participants, content in these immense pools of content is accompanied by varied types of metadata, such as social network data or descriptive textual information. These collections present, at once, new challenges and exciting opportunities for multimedia research. This article presents an approach for "social multimedia" applications. The approach is based on the experience of building a number of successful applications that are based on mining multimedia content analysis in social multimedia context.
C1 Rutgers State Univ, Sch Commun & Informat, New Brunswick, NJ 08903 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Naaman, M (corresponding author), Rutgers State Univ, Sch Commun & Informat, New Brunswick, NJ 08903 USA.
EM mor@rutgers.edu
OI Naaman, Mor/0000-0002-6436-3877
CR Abbasi R, 2009, LECT NOTES COMPUT SC, V5478, P654, DOI 10.1007/978-3-642-00958-7_62
   Adams B., 2006, MULTIMEDIA '06, P987, DOI DOI 10.1145/1180639.1180857
   Ahern S, 2007, WWW 07, P1325
   Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   Ahern Shane, 2007, CHI 07
   Ames M, 2007, CHI 07
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], P 17 ACM INT C MULT
   [Anonymous], P C ACM MULT
   [Anonymous], P ACM INT C MULT
   [Anonymous], 1981, Attention and Performance
   [Anonymous], 2009, P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC
   [Anonymous], P ACM MULT
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], 2006, P 17 C HYPERTEXT HYP
   [Anonymous], P IS T SPIE 18 ANN S
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2002, RES DESIGN QUALITATI
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Becker H, 2009, WEBDB 09
   BEERENDS JG, 1992, J AUDIO ENG SOC, V40, P963
   Berg T.L., 2007, Automatic ranking of iconic images
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Boll S, 2004, MULTIMEDIA 04, P868
   Boll S., 2007, P 15 ACM INT C MULTI, P641, DOI DOI 10.1145/1291233.1291385
   Boll S, 2007, LECT NOTES COMPUT SC, V4351, P332
   Boll S, 2007, IEEE MULTIMEDIA, V14, P9, DOI 10.1109/MMUL.2007.17
   Boutemedjet S, 2008, IEEE T MULTIMEDIA, V10, P52, DOI 10.1109/TMM.2007.911226
   Bulterman DCA, 2004, IEEE MULTIMEDIA, V11, P10, DOI 10.1109/MMUL.2004.29
   Cao L., 2008, Proc. ACM Multimedia, P121
   Chang E, 2008, CIVR 08, P569
   Chang EdwardY., 2005, CVDB'05: Proceedings of the 2nd International Workshop on Computer Vision Meets Databases, P5, DOI [10.1145/1160939.1160945, DOI 10.1145/1160939.1160945]
   Choudhury MD, 2009, WWW 09
   Christel M.G., 2002, ACM Multimedia, P561
   Crandall D. J., 2009, INT WORLD WID WEB C
   Cunningham SJ, 2008, JCDL 08
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   Dubinko Micah., 2006, WWW 06, P193
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elliott B, 2008, CIVR 08, P75
   Gallagher A., 2008, P 2008 INT C CONT BA, P339
   Graham A, 2002, JCDL 02
   Haitsma J, 2003, J NEW MUSIC RES, V32, P211, DOI 10.1076/jnmr.32.2.211.16746
   Hao Qiang., 2009, Proceedings of the ACM International Conference on Multimedia, P801
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Jaimes Alejandro., 2005, Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval, P3
   Ji Rongrong., 2009, P 17 ASS COMP MACH I, P105, DOI DOI 10.1145/1631272.1631289
   Joshi D., 2008, P INT C CONTENT BASE, P37
   Kennedy L, 2009, WWW 09
   Kennedy L.S., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P333
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2006, IEEE SIGNAL PROC MAG, V23, P101
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   NAAMAN M, 2003, 10 INT C COOP INF SY
   Naaman M, 2004, JCDL 04
   Naaman M, 2004, P 12 INT C MULT MM20
   Naaman M, 2008, IEEE MULTIMEDIA, V15, P34, DOI 10.1109/MMUL.2008.69
   Naaman M, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1739
   Naaman Mor., 2005, JCDL'05
   Naci S.U., 2007, Proceedings of the 15th international conference on Multimedia (MULTIMEDIA '07), P150, DOI [10.1145/1291233.1291264, DOI 10.1145/1291233.1291264]
   Nair R, 2005, P 13 INT C MULT MM20
   Negoescu R.A., 2008, Proc. Content-based Image and Video Retrieval, P417, DOI DOI 10.1145/1386352.1386406
   Nov O, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1097
   O'Hare N, 2005, 2 IEE EUR WORKSH INT
   O'Hare N, 2005, P 13 INT C MULT MM20
   O'Hare N, 2006, LECT NOTES COMPUT SC, V4071, P529
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Olsen DR, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P251
   PAILLARD B, 1992, J AUDIO ENG SOC, V40, P21
   Pigeau A, 2004, J VIS COMMUN IMAGE R, V15, P425, DOI 10.1016/j.jvcir.2004.04.002
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Salovaara A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1211
   SCHMITZ P, 2006, P WORKSH COLL WEB TA
   Setz AT, 2009, IEEE INT CON MULTI, P1460, DOI 10.1109/ICME.2009.5202778
   Shamma D. A., 2010, CSCW 10
   Shamma DA., 2007, P INT WORKSHOP WORKS, P275, DOI [10.1145/1290082.1290120, DOI 10.1145/1290082.1290120]
   Shamma David A., 2008, Enhancing online personal connections through the synchronized sharing of online video, P2931, DOI [10.1145/1358628.1358786, DOI 10.1145/1358628.1358786]
   SHAW R, 2006, P 1 ACM INT WORKSH H, P89
   Shneiderman B, 2008, SCIENCE, V319, P1349, DOI 10.1126/science.1153539
   Shrestha P., 2006, P 14 ANN ACM INT C M, V2, P137, DOI [10.1145/1180639.1180679, DOI 10.1145/1180639.1180679]
   Shrstha P., 2007, P ACM INT MULT C EXH, P545, DOI [10.1145/1291233.1291367, DOI 10.1145/1291233.1291367]
   Simon I., 2007, ICCV 07
   Sinha Pinaki., 2008, P 2008 INT C CONTENT, P309
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snavely N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360614
   Snoek CGM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P252
   Syeda-Mahmood T., 2001, PROC ACM MULITMEDIA, V9, P119, DOI DOI 10.1145/500141.500161
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Tsai C-M, 2005, IEEE INT C MULT EXP
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   van Houten Y., 2005, MULTIMEDIA EXPO 2005, P1561
   Wang A, 2003, ISMIR
   Wang M., 2009, Proc. Web-scale Multimedia Corpus, P1, DOI DOI 10.1109/ICMSS.2009.5302047
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Wu Lei., 2009, Proceedings of the 17th ACM international conference on Multimedia. ACM, P135
   Yi Wu, 2005, 13th Annual ACM International Conference on Multimedia, P872, DOI 10.1145/1101149.1101338
   Ying L., 2009, PATTERN RECOGN, V40, P262
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 107
TC 45
Z9 56
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 9
EP 34
DI 10.1007/s11042-010-0538-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500002
DA 2024-07-18
ER

PT J
AU Liu, YC
   Wu, HC
   Yu, SS
AF Liu, Yu-Chi
   Wu, Hsien-Chu
   Yu, Shyr-Shen
TI Adaptive DE-based reversible steganographic technique using bilinear
   interpolation and simplified location map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible steganographic technique; difference expansion; Bilinear
   interpolation
AB In this paper, an adaptive DE-based reversible steganographic scheme with bilinear interpolation and simplified location map is proposed. In traditional reversible difference expansion (DE) scheme, it suffers from two problems: the embeddable location is considered insufficient and the embedding payload control capability in single layer embedding is weak. For the first problem, the kernel of bilinear interpolation is applied to effectively improve the number of the embeddable location while the quality of the stego-image can be maintained at a good level. In addition, the proposed simplified location map is used for the existing adaptive embedding rule to improve the second problem where the secret data can be adaptively embedded and also the load of additional information can be reduced. The experimental results revealed that the proposed scheme presented better visual quality of the stego-image and carried larger embedding payload than some other revised DE schemes, such as Alattar's and Lee's schemes.
C1 [Liu, Yu-Chi; Yu, Shyr-Shen] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
   [Wu, Hsien-Chu] Natl Taichung Inst Technol, Dept Comp Sci & Informat Technol, Taichung, Taiwan.
C3 National Chung Hsing University
RP Yu, SS (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
EM phd9508@cs.nchu.edu.tw; wuhc@ntit.edu.tw; pyu@cs.nchu.edu.tw
RI Liu, Yu Chi/AAM-7010-2020
OI Liu, Yu Chi/0000-0001-5408-0382
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
NR 13
TC 22
Z9 24
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 263
EP 276
DI 10.1007/s11042-010-0496-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000002
DA 2024-07-18
ER

PT J
AU Cui, HX
   Wei, G
   Huang, QH
   Yu, YC
AF Cui, Haixia
   Wei, Gang
   Huang, Qinghua
   Yu, Yongcong
TI A game theoretic approach for power allocation with QoS constraints in
   wireless multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game theory; Power control; QoS; Nash equilibrium; WMSNs
ID ACCESS PROTOCOL
AB The distinctive features of wireless multimedia sensor networks (WMSNs) include application-specific quality-of-service (QoS) requirements and limited energy supply, with which each node makes its own decisions selfishly. Therefore this paper presents a power control game theoretic approach for WMSNs by studying the effect of transmission power on QoS and energy efficiency. The game approach determines the transmission strategy using utility optimization according to the fluctuation of channel states. Here, the utility function is defined by effective throughput per unit power while satisfying the user's delay QoS constraints. The existence and uniqueness of Nash equilibrium for the proposed game are proved. Finally, the simulation results show that each user chooses the optimal transmission power to maximize its utility based on other constant parameters and the effects of delay constraints on the user's utility are quantified as well.
C1 [Cui, Haixia; Wei, Gang; Huang, Qinghua; Yu, Yongcong] S China Univ Technol, Guangzhou Univ, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
C3 Guangzhou University; South China University of Technology
RP Cui, HX (corresponding author), S China Univ Technol, Guangzhou Univ, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
EM cuicuihang0715@gmail.com
RI Huang, Qinghua/L-8708-2019
OI Huang, Qinghua/0000-0003-1080-6940
FU National Hi-Tech Research and Development Program of China (863)
   [2007AA01Z210]
FX The authors are grateful to the Editor and anonymous reviewers for their
   valuable comments and suggestions which help to improve the quality of
   this paper. They also would like to thank the National Natural Science
   Foundation of China No. 60625101, 60901070 and the National Hi-Tech
   Research and Development Program of China (863) under Grant No.
   2007AA01Z210.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Gatsis N, 2008, INT CONF ACOUST SPEE, P2805, DOI 10.1109/ICASSP.2008.4518232
   Huang JW, 2005, IEEE MILIT COMMUN C, P2481
   Kawadia V, 2005, IEEE J SEL AREA COMM, V23, P76, DOI 10.1109/JSAC.2004.837354
   KUCERA S, 2006, P IEEE VTC FALL MONT, P1
   Long CN, 2007, IEEE J SEL AREA COMM, V25, P1101, DOI 10.1109/JSAC.2007.070805
   MESHKATI F, 2006, ENERGY EFFICIENCY DE
   MESHKATI F, 2005, INT S INF THEOR ISIT
   Meshkati F, 2007, IEEE SIGNAL PROC MAG, V24, P58, DOI 10.1109/MSP.2007.361602
   Messier GG, 2008, IEEE T WIREL COMMUN, V7, P2877, DOI 10.1109/TWC.2008.070208
   Monks JP, 2001, IEEE INFOCOM SER, P219, DOI 10.1109/INFCOM.2001.916704
   Muqattash A, 2003, IEEE INFOCOM SER, P470
   NATH S, 2004, IRPTR0416
   PURSLEY MB, 1977, IEEE T COMMUN, V25, P795, DOI 10.1109/TCOM.1977.1093915
   SHAKSHUKI E, 2008, INTRO WIRELESS MULTI
   Srivastava V, 2005, IEEE COMMUN SURV TUT, V7, P46, DOI 10.1109/COMST.2005.1593279
   SUN Q, 2008, P 2008 10 IEEE INT C, P478
   Tan CK, 2008, IET COMMUN, V2, P1159, DOI 10.1049/iet-com:20070547
NR 19
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 983
EP 996
DI 10.1007/s11042-009-0426-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100007
DA 2024-07-18
ER

PT J
AU Garcia-Sanchez, AJ
   Garcia-Sanchez, F
   Garcia-Haro, J
   Losilla, F
AF Garcia-Sanchez, Antonio-Javier
   Garcia-Sanchez, Felipe
   Garcia-Haro, Joan
   Losilla, Fernando
TI A cross-layer solution for enabling real-time video transmission over
   IEEE 802.15.4 networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; IEEE 802,15,4; Cross-Layer design; Video
   transmission
ID WIRELESS SENSOR NETWORKS; IEEE-802.15.4; MULTIMEDIA; PERFORMANCE
AB Over the last few years, the research community has devoted great attention to video transmission on wireless sensor networks, and in particular to their recent evolution, the one based on IEEE 802.15.4 standard. This cost-efficient wireless technology is aimed at transmitting information at low rates and short distances. Extending the use of this technology for intensive bandwidth applications is a challenge that offers the opportunity to support value-added services. This paper deals with this issue and evaluates, by analysis and computer simulation as well as by developing a first prototype, the feasibility of transmitting MPEG-4 video information over an IEEE 802.15.4 network. The study of power-consumption is also considered and so are the Quality of Service parameters together with the human quality perception of the received video streaming. A detailed cross-layer solution is offered, and the results obtained are presented and discussed.
C1 [Garcia-Sanchez, Antonio-Javier; Garcia-Sanchez, Felipe; Garcia-Haro, Joan; Losilla, Fernando] Tech Univ Cartagena, Dept Informat & Commun Technol, Cartagena 30202, Spain.
C3 Universidad Politecnica de Cartagena
RP Garcia-Sanchez, AJ (corresponding author), Tech Univ Cartagena, Dept Informat & Commun Technol, Campus Muralla del Mar, Cartagena 30202, Spain.
EM antoniojavier.garcia@upct.es; felipe.garcia@upct.es; joang.haro@upct.es;
   fernando.losilla@upct.es
RI Garcia-Sanchez, Antonio-Javier/F-5197-2019; Garcia-Haro,
   Joan/D-3503-2015; Losilla, Fernando/E-3688-2016
OI Garcia-Sanchez, Antonio-Javier/0000-0001-5095-3035; Garcia-Haro,
   Joan/0000-0003-0741-7530; Losilla, Fernando/0000-0001-6938-1540
FU  [TEC2007-67966-01/TCM];  [TIC-TEC 07/02-0002]
FX This research has been supported by project grant TEC2007-67966-01/TCM
   (CONPARTE-1) and TIC-TEC 07/02-0002 (PLEDAX) and it is also developed in
   the framework of "Programa de Ayudas a Grupos de Excelencia de la Region
   de Murcia, de la Fundacion Seneca, Agencia de Ciencia y Tecnologia de la
   RM". Authors want also to express their gratitude to three anonymous
   reviewers for their valuable comments.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2007, 802154A2007 IEEE
   Bougard B, 2005, DES AUT TEST EUROPE, P196, DOI 10.1109/DATE.2005.136
   Burda R, 2007, IEEE VTS VEH TECHNOL, P179
   DESHPANDE S, 2006, INT C COMM MOB COMP, P863
   Gutierrez J., 2007, LOW RATE WIRELESS PE
   *INT, INT PXA27X PROC FAM
   Jung D, 2007, LECT NOTES COMPUT SC, V4373, P277
   Jurcík P, 2007, I S MOD ANAL SIM COM, P109, DOI 10.1109/MASCOTS.2007.4
   Ke C.L., 2007, Journal of mobile multimedia, V3, P047
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Koh BKP, 2006, ETRI J, V28, P537, DOI 10.4218/etrij.06.0205.0118
   Koubaa A., 2006, 14 INT WORKSH PAR DI
   Koubâa A, 2008, REAL-TIME SYST, V39, P169, DOI 10.1007/s11241-007-9038-x
   Lie A, 2008, MULTIMEDIA SYST, V14, P33, DOI 10.1007/s00530-007-0110-0
   Liew CH, 2004, ELECTRON LETT, V40, P355, DOI 10.1049/el:20040231
   Liu YH, 2006, IEEE COMMUN MAG, V44, P142, DOI 10.1109/MCOM.2006.248177
   Park TR, 2005, ELECTRON LETT, V41, P1017, DOI 10.1049/el:20051662
   Pekhteryev G, 2005, IEEE INT SYMP CIRC S, P3539, DOI 10.1109/ISCAS.2005.1465393
   Ramachandran I, 2007, ACM T SENSOR NETWORK, V3, DOI 10.1145/1210669.1210673
   Shih E., 2001, PROC 7 ANN ACMIEEE I, P272
   Singh CK, 2008, WIREL NETW, V14, P543, DOI 10.1007/s11276-007-0043-8
   SOURAV P, 2007, INT IFIP NETW C ATL, P475
   Suh C, 2008, COMPUT NETW, V52, P2568, DOI 10.1016/j.comnet.2008.03.011
   Sundararaman B., 2005, Ad Hoc Networks, V3, P281, DOI 10.1016/j.adhoc.2005.01.002
   Vassiliou V, 2006, LECT NOTES COMPUT SC, V4132, P528
   YOUNGMIN J, 2007, INT C COMP SCI BEIJ, P869
   Zainaldin A., 2008, P INT WIR COMM MOB C, P882
   Zhao JA, 2004, WIREL NETW, V10, P133, DOI 10.1023/B:WINE.0000013078.74259.13
   ZHENG J, 2006, SENSOR NETWORK OPERA, P218
   2006, ENALAB REPORT POWER
   2005, NS MANUAL
NR 33
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1069
EP 1104
DI 10.1007/s11042-010-0460-z
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100011
DA 2024-07-18
ER

PT J
AU Lee, H
   Yu, J
   Im, Y
   Gil, JM
   Park, D
AF Lee, Hansung
   Yu, Jaehak
   Im, Younghee
   Gil, Joon-Min
   Park, Daihee
TI A unified scheme of shot boundary detection and anchor shot detection in
   news video story parsing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News video parsing; Shot boundary detection; Anchor shot detection;
   Adaptive resonance theory; Support vector data description
ID SEGMENTATION
AB In this paper, we propose an efficient one-pass algorithm for shot boundary detection and a cost-effective anchor shot detection method with search space reduction, which are unified scheme in news video story parsing. First, we present the desired requirements for shot boundary detection from the perspective of news video story parsing, and propose a new shot boundary detection method, based on singular value decomposition, and a newly developed algorithm, viz., Kernel-ART, which meets all of these requirements. Second, we propose a new anchor shot detection system, viz., MASD, which is able to detect anchor person cost-effectively by reducing the search space. It consists of skin color detector, face detector, and support vector data descriptions with non-negative matrix factorization sequentially. The experimental results with the qualitative analysis illustrate the efficiency of the proposed method.
C1 [Yu, Jaehak; Im, Younghee; Park, Daihee] Korea Univ, Dept Comp & Informat Sci, Jochiwon 339700, Chungnam, South Korea.
   [Lee, Hansung] Elect & Telecommun Res Inst, Taejon 305606, South Korea.
   [Gil, Joon-Min] Catholic Univ Daegu, Dept Comp Sci Educ, Gyongsan 712702, Gyeongbuk, South Korea.
C3 Korea University; Electronics & Telecommunications Research Institute -
   Korea (ETRI); Catholic University of Daegu
RP Park, D (corresponding author), Korea Univ, Dept Comp & Informat Sci, 208 Seochang Ri, Jochiwon 339700, Chungnam, South Korea.
EM mohan@etri.re.kr; dhpark@korea.ac.kr
RI Lee, Hansung/R-2247-2019
OI Lee, Hansung/0000-0002-6519-4120
FU Korea University; Ministry of Education, Science Technology (MEST);
   Korea Industrial Technology Foundation (KOTEF)
FX This research was supported by a Korea University Grant; This research
   was financially supported by the Ministry of Education, Science
   Technology (MEST) and Korea Industrial Technology Foundation (KOTEF)
   through the Human Resource Training Project for Regional Innovation.
CR BARALDI EC, 1998, 98004 TR INT COMP SC
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Cerneková Z, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P181
   Chaisorn L, 2003, WORLD WIDE WEB, V6, P187, DOI 10.1023/A:1023622605600
   Colace F, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1351
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Fang H, 2006, PATTERN RECOGN, V39, P2092, DOI 10.1016/j.patcog.2006.04.044
   Fang Y, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P397
   Feng HM, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1112
   Gao XB, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P108
   Gao XB, 2002, IEEE T CIRC SYST VID, V12, P765, DOI 10.1109/TCSVT.2002.800510
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GONG YH, 2000, P INT C COMP VIS PAT, V2, P174
   Hanjalic A, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P148, DOI 10.1109/ICIP.1998.727156
   KO C, 2008, P C IM SIGN PROC, V2, P530
   Lan DJ, 2004, INT C PATT RECOG, P890, DOI 10.1109/ICPR.2004.1334671
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Ling X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P445, DOI 10.1109/CISP.2008.605
   Luan XD, 2005, PDCAT 2005: SIXTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P840
   SANTO M, 2006, P 18 INT C PATT REC, V2, P1238
   SOLINA F, 2003, P MIR 2003 INRIA ROC, P10
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   ZURADA JM, 1992, INFO ACCESS DISTRIBU
NR 27
TC 30
Z9 30
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1127
EP 1145
DI 10.1007/s11042-010-0462-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100013
DA 2024-07-18
ER

PT J
AU Sawant, N
   Li, J
   Wang, JZ
AF Sawant, Neela
   Li, Jia
   Wang, James Z.
TI Automatic image semantic interpretation using social action and tagging
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web 2.0; Social media; Collaborative annotation; Image semantics;
   Folksonomic features; Survey
ID ANNOTATION; RETRIEVAL; SYSTEMS; TOOL
AB The plethora of social actions and annotations (tags, comments, ratings) from online media sharing Websites and collaborative games have induced a paradigm shift in the research on image semantic interpretation. Social inputs with their added context represent a strong substitute for expert annotations. Novel algorithms have been designed to fuse visual features with noisy social labels and behavioral signals. In this survey, we review nearly 200 representative papers to identify the current trends, challenges as well as opportunities presented by social inputs for research on image semantics. Our study builds on an interdisciplinary confluence of insights from image processing, data mining, human computer interaction, and sociology to describe the folksonomic features of users, annotations and images. Applications are categorized into four types: concept semantics, person identification, location semantics and event semantics. The survey concludes with a summary of principle research directions for the present and the future.
C1 [Sawant, Neela; Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA.
   [Li, Jia] Penn State Univ, Dept Stat, University Pk, PA 16802 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Sawant, N (corresponding author), Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA.
EM nks125@psu.edu; jiali@psu.edu; jwang@psu.edu
RI Wang, James/JAD-0675-2023
OI Wang, James/0000-0003-4379-4173
FU National Science Foundation [IIS-0949891, IIS-0347148]; Pennsylvania
   State University
FX The material was based upon work supported in part by the National
   Science Foundation under Grant Nos. IIS-0949891 and IIS-0347148, and by
   The Pennsylvania State University.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Aesthetics, AESTH
   Agichtein E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P19, DOI 10.1145/1148170.1148177
   Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   Allan J., 2002, INTRO TOPIC DETECTIO
   Allan M, 2009, P BR MACH VIS C
   Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Anguelov D., 2007, Computer Vision and Pattern Recognition, P1
   [Anonymous], 2007, Outlier detection: A survey
   [Anonymous], 1996, Sigmod Workshop on Research Issues on Data Mining and Knowledge Discovery (DMKD)
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2010, P ACM INT C MULT INF, DOI 10.1145/1743384.1743457
   [Anonymous], P MULT INF RETR 08 V
   [Anonymous], P INT C MULT INF RET
   [Anonymous], 1987, Term weighting approaches in automatic text retrieval
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2006, Book Annosearch: Image auto-annotation by search, DOI DOI 10.1109/CVPR.2006.58
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 2007, INFORM FORAGING THEO, DOI DOI 10.1093/ACPROF:OSO/9780195173321.001.0001
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], 1997, P 10 RES COMPUTATION
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], P ACM MULT
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], 1999, Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, DOI DOI 10.3115/1034678.1034693
   [Anonymous], 2006, FOLKRANK RANKING ALG
   [Anonymous], 2007, P 16 INT C WORLD WID
   [Anonymous], 2008, CHI 08 EXTENDED ABST
   [Anonymous], 1999, Communities in Cyberspace
   [Anonymous], WWW
   Bailloeul T., 2008, Proc. Multimedia Information Retrieval, P75, DOI DOI 10.1145/1460096.1460110
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barnard K, 2008, INT J COMPUT VISION, V77, P199, DOI 10.1007/s11263-007-0068-6
   Berg T.L., 2007, Automatic ranking of iconic images
   Bian J., 2008, AIRWeb '08, P53
   Bian Jiang., 2009, P 18 INT C WORLD WID, P51, DOI DOI 10.1145/1526709.1526717
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bottcher M., 2008, SIGKDD Explor. Newsl, V10, P3, DOI [10.1145/1540276.1540278, DOI 10.1145/1540276.1540278]
   Boutell M, 2004, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2004.1333918
   Brinker K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P702
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Budiu R, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P615
   Cao L, 2008, P COMP VIS PATT REC
   Cao L., 2008, Proc. ACM Multimedia, P121
   Cattuto C, 2008, P 3 WORKSH ONT LEARN, P39
   Cattuto C, 2007, AI COMMUN, V20, P245
   Chandramouli K, 2010, P ACM MULT INF RET, P507
   Chatzilari E., 2009, Proc. Int'l Conference on Digital Signal Processing, P1
   Chen H.M., 2008, MULTIMEDIA 2008, P737
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   Chi EdH., 2008, P 19 ACM C HYPERTEXT, P81, DOI DOI 10.1145/1379092.1379110
   Choi J.Y., 2008, MIR 08, P44
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Cristani M, 2008, P COMP VIS PATT REC
   CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318
   Datta R., 2007, Proc. ACM Multimedia, P393
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   Davis M, 2006, P S EL IM SCI TECH
   Dean Jeffrey, 2004, OSDI 04, P10
   Deng J., 2009, CONSTRUCTION ANAL LA, V186
   Dong W, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P981
   Donmez P, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P259
   Dubinko Micah., 2006, WWW 06, P193
   Duda R., 1973, Pattern Classification and Scene Analysis
   Ester M, 1999, LECT NOTES ARTIF INT, V1701, P61
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Fu WT, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P229
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Furnas GW., 1984, HUMAN FACTORS COMPUT, P187, DOI [DOI 10.1002/J.1538-7305.1983.TB03513.X, 10.1002/j.1538-7305.1983.tb03513.x]
   Gaber MM, 2005, SIGMOD REC, V34, P18, DOI 10.1145/1083784.1083789
   Garg N, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P67
   Giannakidou Eirini, 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P128, DOI 10.1109/ICSC.2008.73
   Girgensohn Andreas., 2004, MIR 04, P99
   Golder S, 2008, P 19 ACM C HYP HYP, P43, DOI 10.1145/1379092.1379104
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Goncalves D., 2008, Extended abstracts on Human Factors in Computing Systems, P2685
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hamilton J.D., 1994, Time series analysis
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Hua-Jun Zeng, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P210
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Ihler A., 2007, ACM Trans Knowl Discov Data, V1, P13, DOI 10.1145/1297332.1297337
   Ivanov I., 2010, P INT C MULT INF RET, P497, DOI [10.1145/1743384.1743471, DOI 10.1145/1743384.1743471]
   Jäschke R, 2007, LECT NOTES ARTIF INT, V4702, P506
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jones W., 1986, Proc. Human Factors in Computing Systems, P298
   Joshi D., 2008, P INT C CONTENT BASE, P37
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kennedy L., 2009, Proc. Workshop on Web-scale Multimedia Corpus, P17
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Koutrika G., 2007, Proc. Workshop on Adversarial Information Retrieval on the Web, P57
   Krestel R, 2008, P C PRACT KNOWL DISC
   Krishnapuram Raghu, 2005, P 22 INT C MACHINE L, P681
   Kucuktunc O, 2008, P SEM DIG MED TECHN
   Kustanowitz J., 2005, Motivating annotation for personal digital photo libraries: Lowering barriers while raising incentives
   Lambiotte R, 2006, LECT NOTES COMPUT SC, V3993, P1114
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Leskovec J., 2008, WWW
   Levi K, 2004, PROC CVPR IEEE, P53
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li QF, 2008, IEEE MULTIMEDIA, V15, P14, DOI 10.1109/MMUL.2008.54
   Li X., 2006, MULTIMEDIA 06, P607, DOI DOI 10.1145/1180639.1180764
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Lindstaedt S, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES (ICIW 2008), P506, DOI 10.1109/ICIW.2008.26
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liu D., 2009, Proc. ACM Multimedia, P809
   Liu D, 2009, IEEE INT CON MULTI, P350, DOI 10.1109/ICME.2009.5202506
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu Y, 2008, P COMP VIS PATT REC
   Manning C., 2008, Introduction to Information Retrieval, P85
   Marlow C., 2006, P 17 C HYP HYPERTEXT, P31, DOI [https://doi.org/10.1145/1149941.1149949, DOI 10.1145/1149941.1149949]
   Marques O., 2008, Proc. ACM Workshop on Multimedia Semantics, P40
   Miller GeorgeA., 1983, Machlup, Fritz; Mansfield, Una, The Study of Information: Interdisciplinary Messages, P111
   Miller H., 2001, GEOGRAPHIC DATA MINI
   Moxley Emily., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, P24
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   Naaman M, 2003, LECT NOTES COMPUT SC, V2888, P196
   Naaman M, 2008, IEEE MULTIMEDIA, V15, P34, DOI 10.1109/MMUL.2008.69
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Negoescu R.A., 2008, Proc. Content-based Image and Video Retrieval, P417, DOI DOI 10.1145/1386352.1386406
   Ng R.T., 1994, Proceedings of the 20th International Conference on Very Large Data Bases, VLDB '94, P144
   Nisbett RE, 2001, PSYCHOL REV, V108, P291, DOI 10.1037//0033-295X.108.2.291
   Noll MG, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P612, DOI 10.1145/1571941.1572046
   Nov O, 2010, COMMUN ACM, V53, P128, DOI 10.1145/1785414.1785450
   Nov O, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1097
   Nowak S., 2010, P INT C MULT INF RET, P557, DOI [10.1145/1743384.1743478, DOI 10.1145/1743384.1743478]
   Obrador P., 2009, PROC 1 ACM SIGMM WOR, P65
   Pedersen Ted., 2004, DEMONSTRATION PAPERS, P38
   Pirolli P, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P605
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Rebbapragada U, 2007, LECT NOTES ARTIF INT, V4701, P708
   Robertson S., 2009, P 27 INT C EXTENDED, P3937
   Roddick J.F., 2008, ACM SIGKDD Explorations Newsletter archive, V10, P5
   Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Sen S., 2009, Proc. Intelligent User Interfaces, P87
   Sen S, 2007, GROUP'07: PROCEEDINGS OF THE 2007 INTERNATIONAL ACM CONFERENCE ON SUPPORTING GROUP WORK, P361
   Seneviratne L., 2010, Proc. ACM Multimedia Information Retrieval, P517, DOI DOI 10.1145/1743384.1743473
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Shepitsen A, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P259
   Shilad S., 2006, 2006 ACM C COMPUTER, P181, DOI DOI 10.1145/1180875.1180904
   Sinha Pinaki., 2008, P 2008 INT C CONTENT, P309
   Sivic Josef., 2006, British Machine Vision Conference, P909
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Solli M., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P398
   Song Y, 2006, LECT NOTES COMPUT SC, V3953, P382, DOI 10.1007/11744078_30
   Suchanek FabianM., 2008, Proceedings of the 17th ACM conference on Information and Knowledge Management, CIKM '08 ACM, P223, DOI DOI 10.1145/1458082.1458114
   Suh B, 2007, INTERACT COMPUT, V19, P524, DOI 10.1016/j.intcom.2007.02.002
   Sun A., 2009, Proc. SIGMM Workshop on Social Media, P19
   Surowiecki James., 2004, WISDOM SHAPES BUSINE
   Sylvan E, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1913
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Truran M., 2005, 13th Annual ACM International Conference on Multimedia, P547, DOI 10.1145/1101149.1101273
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Vlachos M., 2004, P 2004 ACM SIGMOD IN, P131, DOI DOI 10.1145/1007568.1007586
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Wang C., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383221
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang M., 2009, Proc. Web-scale Multimedia Corpus, P1, DOI DOI 10.1109/ICMSS.2009.5302047
   Wang S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P587
   Weinberger K.Q., 2008, Proceedings of Conference on Multimedia, P111
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Xue G.-R., 2004, CIKM, P118
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Yan R, 2009, IEEE MULTIMEDIA, V16, P26, DOI 10.1109/MMUL.2009.28
   Yang Q, 2010, P ACM MULT INF RET, P397
   Yang Qingxiong., 2008, CIVR, CIVR'08, P591
   Yang Y., 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Zhang L., 2004, MULTIMEDIA 04, P716
   Zhang S, 2009, IONIC LIQUIDS: PHYSICOCHEMICAL PROPERTIES, P1
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 196
TC 21
Z9 24
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 213
EP 246
DI 10.1007/s11042-010-0650-8
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800009
DA 2024-07-18
ER

PT J
AU Kim, H
   Yeom, HY
   Kang, S
   Won, Y
AF Kim, Hyunjoo
   Yeom, Heon Y.
   Kang, Sooyong
   Won, Youjip
TI Inter-Object Layer Clustering for scalable video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Layered encoding; Video streaming; File system; Scalable video; Data
   placement
AB In this work, we develop an efficient storage technique to support real-time streaming of layer encoded video in a single hard disk. The size of a single hard disk drive will soon be able to hold multi-tera bytes and is going to handle relatively larger number of files. We expect that disk layout in a single disk will be rather critical issue in determining the efficiency of the storage system. We propose a novel storage technique, Inter-Object Layer Clustering for layer encoded video objects. In Inter-Object Layer Clustering, storage is partitioned into two regions: lower layer partition and upper layer partition. Lower and upper layer partition harbor the lower layer and upper layer data blocks across all video objects and cluster them together. We develop an elaborate performance model for this placement scheme. We examine the performance of the proposed technique using analytical formulation as well as a physical experiment. We found that clustering the layers across all objects brings 100% increase in the number of concurrent sessions compared to the case where file is stored in temporal order when the clients' access bandwidth is narrow. Inter-Object Layer Clustering shows 15% performance improvement compared to the clustering of layers within the objects.
C1 [Kim, Hyunjoo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   [Yeom, Heon Y.] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151742, South Korea.
   Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
   [Won, Youjip] Hanyang Univ, Dept Elect & Comp Engn, Seoul 133791, South Korea.
C3 Rutgers University System; Rutgers University New Brunswick; Seoul
   National University (SNU); Hanyang University; Hanyang University
RP Kang, S (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.
EM hyunjoo@cac.rutgers.edu; yeom@dcslab.snu.ac.kr; sykang@hanyang.ac.kr;
   yjwon@ece.hanyang.ac.kr
FU Korean Government [2009-0073575]
FX This work was supported by National Research Foundation of Korea Grant
   funded by the Korean Government (2009-0073575).
CR Anastasiadis S. V., 2006, ACM Transaction on Storage, V1, P419, DOI 10.1145/1111609.1111611
   Dai L, 2007, IEEE ICC, P1734, DOI 10.1109/ICC.2007.290
   de Cuetos P., 2002, NOSSDAV '02: Proceedings of the 12th international workshop on Network and operating systems support for digital audio and video, P3
   JIANG Q, 2007, INT C INF AC
   KANG S, 2006, P NOSSDAV RHOD ISL U
   KANG SR, 2004, P 24 INT C DISTR COM
   Liu JC, 2004, IEEE T WIREL COMMUN, V3, P656, DOI 10.1109/TWC.2003.821216
   MCCANNE S, 2002, NETWORK SIMULATOR
   Ng JKY, 2000, J SYST SOFTWARE, V51, P217, DOI 10.1016/S0164-1212(99)00125-9
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   *REAL NETW INC, 2002, HEL PROD US GUID
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   REJAIE R, 2003, P NOSS DAV MONT CA U
   SAPARILLA D, 2000, P IEEE INFOCOM
   Shenoy PJ, 2000, MULTIMEDIA SYST, V8, P1, DOI 10.1007/s005300050001
   SHI L, 2006, P ACM MULT SANT BARB
   SHIN D, 2006, INT S PERF EV COMP T
   SIAO X, 2008, IEEE INT C COMM
   Song MS, 2006, MULTIMED TOOLS APPL, V28, P347, DOI 10.1007/s11042-006-7718-5
NR 19
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2010
VL 50
IS 2
BP 313
EP 333
DI 10.1007/s11042-009-0384-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 622XE
UT WOS:000279698700002
DA 2024-07-18
ER

PT J
AU Kriechbaum, A
   Mörzinger, R
   Thallinger, G
AF Kriechbaum, Andreas
   Moerzinger, Roland
   Thallinger, Georg
TI A framework for unsupervised mesh based segmentation of moving objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object segmentation; Unsupervised system; Spatial segmentation;
   Motion extraction; Clustering; Optical flow
AB Multimedia analysis usually deals with a large amount of video data with a significant number of moving objects. Often it is necessary to reduce the amount of data and to represent the video in terms of moving objects and events. Event analysis can be built on the detection of moving objects. In order to automatically process a variety of video content in different domain, largely unsupervised moving object segmentation algorithms are needed. We propose a fully unsupervised system for moving object segmentation that does not require any restriction on the video content. Our approach to extract moving objects relies on a mesh-based combination of results from colour segmentation (Mean Shift) and motion segmentation by feature point tracking (KLT tracker). The proposed algorithm has been evaluated using precision and recall measures for comparing moving objects and their colour segmented regions with manually labelled ground truth data. Results show that the algorithm is comparable to other state-of-the-art algorithms. The extracted information is used in a search and retrieval tool. For that purpose a moving object representation in MPEG-7 is implemented. It facilitates high performance indexing and retrieval of moving objects and events in large video databases, such as the search for similar moving objects occurring in a certain period.
C1 [Kriechbaum, Andreas; Moerzinger, Roland; Thallinger, Georg] JOANNEUM RES, Inst Informat Syst, A-8010 Graz, Austria.
RP Kriechbaum, A (corresponding author), JOANNEUM RES, Inst Informat Syst, Steyrergasse 17, A-8010 Graz, Austria.
EM andreas.kriechbaum@joanneum.at; roland.moerzinger@joanneum.at;
   georg.thallinger@joanneum.at
FU European Community [FP7/2007-2013, 216465]
FX The authors would like to thank Werner Haas, Werner Bailer and Peter
   Schallauer as well as several other colleagues at JOANNEUM RESEARCH, who
   provided valuable feedback. The research leading to these results has
   received funding from the European Community's Seventh Framework
   Programme (FP7/2007-2013) under grant agreement n<SUP>o</SUP> 216465
   (ICT project SCOVIS).
CR [Anonymous], 1994, INT J COMPUTER VISIO
   [Anonymous], 2002, IEEE T PATTERN ANAL
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0
   Bailer W, 2005, PROC SPIE, V5685, P522, DOI 10.1117/12.586945
   BAILER W, 2006, INT C MULT MOD
   Bailer W., 2005, STATE ART CONTENT AN, V15, P3
   Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420
   CELASUN I, 2001, SIGNAL PROCESSING IM, V16
   COMANICIU D, 1997, ROBUST ANAL FEATURE
   Davis J.C, 2002, STAT DATA ANAL GEOLO, V3th
   DONOSER M, 2003, THESIS TU GRAZ
   Duda R. O., 2000, PATTERN CLASSIFICATI
   ERDEM CE, 2000, P 10 EUR SIGN PROC C, P917
   GALIC S, 2000, P 1 INT WORKSH IM SI
   GUO J, 1999, APPL INTELLIGENCE J
   HEIDRICH W, 1999, P SIGGRAPH 99
   Horn BertholdK.P., 1980, DETERMINING OPTICAL
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   KRIECHBAUM A, 2005, THESIS
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   LIU L, 2005, IEEE T CIRCUITS SYST
   Martinez J.M., 2002, MPEG 7 OVERVIEW
   OH J, 2003, ITCC 03 P INT C INF
   Rehatschek H, 2004, P SOC PHOTO-OPT INS, V5304, P160
   TSECHPENAKIS G, 2003, IEEE INT C MULT EXP
   WEI Z, 2005, REAL TIME IMAGING
   Xu N, 2003, PROC CVPR IEEE, P46
   Zhang DS, 2001, CIRC SYST SIGNAL PR, V20, P143, DOI 10.1007/BF01201137
NR 29
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 7
EP 28
DI 10.1007/s11042-009-0366-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900002
DA 2024-07-18
ER

PT J
AU Chen, YW
   Uemura, J
AF Chen, Yu-Wei
   Uemura, Jin
TI An interleaving crescent broadcasting protocol for near video-on-demand
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broadcasting protocol; Access latency; Maximum buffer requirement;
   Needed subscriber's bandwidth; Maximum disk I/O transfer rate
ID RECEIVING SCHEME; POPULAR VIDEOS; BUFFER DEMAND; SYSTEMS
AB This work presents a novel interleaving crescent broadcasting protocol for near video-on-demand service. The interleaving crescent broadcasting protocol is a trade-off among the subscriber's access latency, maximum buffer requirement, needed subscriber's bandwidth, and maximum disk I/O transfer rate. A longer subscriber's access latency may cause a subscriber to leave. A lower maximum buffer requirement, a lower needed subscriber's bandwidth, and a lower maximum disk I/O transfer rate reduce subscribers' costs. The interleaving crescent broadcasting protocol not only makes access latency shorter, but also lowers the overall system's cost. We prove the correctness of the interleaving crescent protocol; provide mathematical analyses to demonstrate its efficiency.
C1 [Chen, Yu-Wei] Natl Taipei Univ Technol, Taipei, Taiwan.
   [Uemura, Jin] Aletheia Univ, Taipei, Taiwan.
C3 National Taipei University of Technology; Aletheia University
RP Chen, YW (corresponding author), Natl Taipei Univ Technol, Taipei, Taiwan.
EM ywchen@ntut.edu.tw
RI 陈, 雨薇/HKF-1175-2023
FU  [NSC98-2221-E027-121]
FX This work was supported in part by NSC98-2221-E027-121.
CR CHANG YH, 1994, IEEE COMMUN MAG, V32, P68, DOI 10.1109/35.281581
   Chen YW, 2007, COMPUT COMMUN, V30, P807, DOI 10.1016/j.comcom.2006.10.002
   Chen YW, 2004, INFORM PROCESS LETT, V92, P299, DOI 10.1016/j.ipl.2004.09.010
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Gao LX, 2002, MULTIMEDIA SYST, V8, P284, DOI 10.1007/s005300100049
   Ghose D, 2000, MULTIMED TOOLS APPL, V11, P167, DOI 10.1023/A:1009681521536
   Guo Y, 2004, IEEE T MULTIMEDIA, V6, P387, DOI 10.1109/TMM.2003.822786
   Hu AL, 2001, IEEE INFOCOM SER, P508, DOI 10.1109/INFCOM.2001.916754
   Juhn LS, 1997, IEEE T CONSUM ELECTR, V43, P1110, DOI 10.1109/30.642378
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   LI ZN, 2004, FUNDAMENTALS MULTIME, pCH16
   Long A., 1999, MULTIMEDIA COMPUTING, P317
   Pâris JF, 2001, IEEE IC COMP COM NET, P418, DOI 10.1109/ICCCN.2001.956299
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Yan ME, 2006, DISCRETE APPL MATH, V154, P2418, DOI 10.1016/j.dam.2006.04.019
   Yang H.C., 2004, P INT C INT COMP LAS
   Yu HF, 2008, COMPUT COMMUN, V31, P2270, DOI 10.1016/j.comcom.2008.02.014
   Yu HF, 2008, IEEE T BROADCAST, V54, P304, DOI 10.1109/TBC.2008.915761
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
NR 19
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 299
EP 321
DI 10.1007/s11042-009-0359-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300003
DA 2024-07-18
ER

PT J
AU Zadeh, PB
   Akbari, AS
   Buggy, T
   Soraghan, J
AF Zadeh, Pooneh Bagheri
   Akbari, Akbar Sheikh
   Buggy, Tom
   Soraghan, John
TI Multiresolution HVS and statistically based image coding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Statistical parameters; Perceptual weights; Discrete
   wavelet transform
ID SUBBAND VECTOR QUANTIZATION; JPEG2000; CODEC
AB In this paper a novel multiresolution human visual system and statistically based image coding scheme is presented. It decorrelates the input image into a number of subbands using a lifting based wavelet transform. The codec employs a novel statistical encoding algorithm to code the coefficients in the detail subbands. Perceptual weights are applied to regulate the threshold value of each detail subband that is required in the statistical encoding process. The baseband coefficients are losslessly coded. An extension of the codec to the progressive transmission of images is also developed. To evaluate the performance of the coding scheme, it was applied to a number of test images and its performance with and without perceptual weights is evaluated. The results indicate significant improvement in both subjective and objective quality of the reconstructed images when perceptual weights are employed. The performance of the proposed technique was also compared to JPEG and JPEG2000. The results show that the proposed coding scheme outperforms both coding standards at low compression ratios, while offering satisfactory performance at higher compression ratios.
C1 [Zadeh, Pooneh Bagheri; Buggy, Tom] Glasgow Caledonian Univ, Div Commun Network & Elect Engn, Sch Engn & Comp, Glasgow G4 0BA, Lanark, Scotland.
   [Akbari, Akbar Sheikh] Univ Bristol, Dept Elect & Elect Engn, Bristol BS8 1UB, Avon, England.
   [Soraghan, John] Univ Strathclyde, Dept Elect & Elect Engn, Inst Commun & Signal Proc, Glasgow G1 1XW, Lanark, Scotland.
C3 Glasgow Caledonian University; University of Bristol; University of
   Strathclyde
RP Zadeh, PB (corresponding author), Glasgow Caledonian Univ, Div Commun Network & Elect Engn, Sch Engn & Comp, 70 Cowcaddens Rd, Glasgow G4 0BA, Lanark, Scotland.
EM pbz@dmu.ac.uk; A.SheikhAkbari@bristol.ac.uk; t.buggy@gcal.ac.uk;
   jjs@eee.strath.ac.uk
RI Sheikh-Akbari, Akbar/AAA-7302-2022
OI Sheikh-Akbari, Akbar/0000-0003-0677-7083
CR Akbari AS, 2003, ELECTRON LETT, V39, P1044, DOI 10.1049/el:20030673
   AKBARI AS, 2004, EUSIPCO 2004 AUSTR
   Andra K, 2003, IEEE T CIRC SYST VID, V13, P209, DOI 10.1109/TCSVT.2003.809834
   [Anonymous], 1994, 109181 ISOIEC
   BARUA S, 2004, ICASSP2004 MONTR CAN
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   Chang RF, 1993, IEEE T IMAGE PROCESS, V2, P104, DOI 10.1109/83.210870
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   FAHMY GF, 2004, J VISUAL COMMUN IMAG, V15
   HSONTSCH I, 2000, IEEE T IMAGE PROCESS, V9
   HWANG WJ, 1995, IEEE T IMAGE PROCESS, V4, P1128, DOI 10.1109/83.403418
   *ISO IEC, 2000, JTC1SC29WG1 ISOIEC
   Kai X, 2005, EUR J RADIOL, V55, P139, DOI 10.1016/j.ejrad.2004.09.007
   KOTTERI KA, 2005, IEEE T CIRCUITS SY 2, V52
   Lawson S, 2002, ELECTRON COMMUN ENG, V14, P112, DOI 10.1049/ecej:20020303
   LIAO H, 2004, IEEE T SIGNAL PROCES, V52
   LU ZM, 2002, IEICE T INFORM SYS D, V85
   LU ZM, 2000, IEICE T INFORM SYS D, V83
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Pastuszak G, 2005, IEEE T CIRC SYST VID, V15, P1182, DOI 10.1109/TCSVT.2005.852720
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SARYAZDI SM, 2002, EURASIA ICT 2002 SHI
   Scargall L. D., 2000, IEE P VISION IMAGE S, V147
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SKODRAS A, 2001, T IEEE SIGNAL PROCES, V18
   SWELDENS W, 1997, SIAM J MATH ANAL, V29
   Taubman D, 2002, SIGNAL PROCESS-IMAGE, V17, P49, DOI 10.1016/S0923-5965(01)00028-5
   TAUBMAN D, 2000, IEEE TRANSACTION IMA, V9
   Taubman D S, 2004, JPEG 2000 IMAGE COMP
   VANDYCK RE, 1994, IEEE T CIRCUITS SYST, V4
   Voukelatos SP, 1997, IEEE T CIRC SYST VID, V7, P424, DOI 10.1109/76.564121
   ZADEH PB, 2005, IMVIP2005 NO IR
NR 34
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 347
EP 370
DI 10.1007/s11042-009-0371-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300005
DA 2024-07-18
ER

PT J
AU Kawsar, F
   Fujinami, K
   Nakajima, T
   Park, JH
   Yeo, SS
AF Kawsar, Fahim
   Fujinami, Kaori
   Nakajima, Tatsuo
   Park, Jong Hyuk
   Yeo, Sang-Soo
TI A portable toolkit for supporting end-user personalization and control
   in context-aware applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-user; Personalization; Context-aware application; Toolkit
AB A context-aware application in the pervasive computing environment provides intuitive user centric services using implicit context cues. Personalization and control are important issues for this class of application as they enable end-users to understand and configure the behavior of an application. However most development efforts for building context-aware applications focus on the sensor fusion and machine learning algorithms to generate and distribute context cues that drive the application with little emphasis on user-centric issues. We argue that, to elevate user experiences with context-aware applications, it is very important to address these personalization and control issues at the system interface level in parallel to context centric design. Towards this direction, we present Persona, a toolkit that provides support for extending context-aware applications with end-user personalization and control features. Specifically, Persona exposes a few application programming interfaces that abstract end-user customization and control mechanisms and enables developers to integrate these user-centric aspects with rest of the application seamlessly. There are two primary advantages of Persona. First, it can be used with various existing middlewares as a ready-to-use plug-in to build customizable and controllable context-aware applications. Second, existing context-aware applications can easily be augmented to provide end-user personalization and control support. In this paper, we discuss the design and implementation of Persona and demonstrate its usefulness through the development and augmentation of a range of common context-aware applications.
C1 [Kawsar, Fahim] Univ Lancaster, Dept Comp, Lancaster, England.
   [Fujinami, Kaori] Tokyo Univ Agr & Technol, Dept Comp Informat & Commun Sci, Tokyo, Japan.
   [Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci, Tokyo, Japan.
   [Park, Jong Hyuk] Kyungnam Univ, Dept Comp Sci & Engn, Masan, South Korea.
   [Yeo, Sang-Soo] Mokwon Univ, Div Comp Engn, Taejon, South Korea.
C3 Lancaster University; Tokyo University of Agriculture & Technology;
   Waseda University; Kyungnam University; Mokwon University
RP Kawsar, F (corresponding author), Univ Lancaster, Dept Comp, Lancaster, England.
EM fahim.kawsar@comp.lancs.ac.uk; fujinami@cc.tuat.ac.jp;
   tasuo@dcl.info.waseda.ac.jp; parkjonghyuk1@hotmail.com; ssyeo@msn.com
RI Yeo, Sang-Soo/AAD-6176-2020; Fujinami, Kaori/B-9930-2013; Yeo,
   Sang-Soo/D-3216-2016
OI Fujinami, Kaori/0000-0002-5294-2812; Yeo, Sang-Soo/0000-0002-0224-0150
CR ASSAD M, 2007, 5 INT C PERV COMP PE, P55
   Bardram JE, 2005, LECT NOTES COMPUT SC, V3468, P98
   BARKHUUS L, 2003, 5 INT C UB COMP
   Bell G, 2007, PERS UBIQUIT COMPUT, V11, P133, DOI 10.1007/s00779-006-0071-x
   Bellotti V, 2001, HUM-COMPUT INTERACT, V16, P193, DOI 10.1207/S15327051HCI16234_05
   BROWN PJ, 1997, PERS UBIQUIT COMPUT, V5, P153
   Brumitt B, 2000, LECT NOTES COMPUT SC, V1927, P12
   CHEVERST K, 2001, MOBILE HCI
   DEY A, 2009, ACM C HUM FACT COMP
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   DEY AK, 2004, ACM C HUM FACT COMP, P33
   DEY AK, 2006, 4 INT C PERV COMP PE, P254
   DOURISH P, 2003, COMPUTER SUPPORTED C
   FARRELL S, 2002, INTELLIGENT USER INT
   FUJINAMI K, 2005, 3 INT C PERV COMP PE, P315
   GAJOS K, 2002, INT C PERV COMP PERV, P1
   HARPER RH, 1996, COMPUTER SUPPORTED C
   HILBERT D, 2004, ACM INTERACTIONS MAG
   HIROSHI S, 2004, NTT TECHNICAL REPORT
   HONG JI, 2004, 2 INT C MOB SYST APP, P177
   KAWSAR F, 2005, INT C EMB UB COMP EU
   KAWSAR F, 2005, 10 INT C UB COMP UB, P282
   KAWSAR F, 2005, 2005 JOINT C SMART O, P141
   Kazman R, 1996, IEEE SOFTWARE, V13, P47, DOI 10.1109/52.542294
   MARINILLI M, 2005, 10 INT C US MOD
   Matsushita N., 2000, P 4 INT S WEAR COMP
   MCNEE MS, 2003, 9 INT C US MOD
   MONTORO G, 2004, ADV PERVASIVE COMPUT
   NISHIGAKI K, 2005, 1 INT WORKSH SERV IN
   PASCOE J, 1997, 2 INT C INT US INT I, P261
   ROGERS Y, 2006, 8 INT C UB COMP UB 2, P404
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Schmidt A., 2002, THESIS LANCASTER U
   STIERMERLING O, 1997, DESIGNING INTERACTIV
   WANT R, 2002, 4 INT C UB COMP UB 2
NR 35
TC 2
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 409
EP 432
DI 10.1007/s11042-009-0330-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200004
DA 2024-07-18
ER

PT J
AU Laurier, C
   Meyers, O
   Serrà, J
   Blech, M
   Herrera, P
   Serra, X
AF Laurier, Cyril
   Meyers, Owen
   Serra, Joan
   Blech, Martin
   Herrera, Perfecto
   Serra, Xavier
TI Indexing music by mood: design and integration of an automatic
   content-based annotator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Mood annotation; Content-based audio;
   Social networks; User evaluation
ID INFORMATION-RETRIEVAL
AB In the context of content analysis for indexing and retrieval, a method for creating automatic music mood annotation is presented. The method is based on results from psychological studies and framed into a supervised learning approach using musical features automatically extracted from the raw audio signal. We present here some of the most relevant audio features to solve this problem. A ground truth, used for training, is created using both social network information systems (wisdom of crowds) and individual experts (wisdom of the few). At the experimental level, we evaluate our approach on a database of 1,000 songs. Tests of different classification methods, configurations and optimizations have been conducted, showing that Support Vector Machines perform best for the task at hand. Moreover, we evaluate the algorithm robustness against different audio compression schemes. This fact, often neglected, is fundamental to build a system that is usable in real conditions. In addition, the integration of a fast and scalable version of this technique with the European Project PHAROS is discussed. This real world application demonstrates the usability of this tool to annotate large-scale databases. We also report on a user evaluation in the context of the PHAROS search engine, asking people about the utility, interest and innovation of this technology in real world use cases.
C1 [Laurier, Cyril; Meyers, Owen; Serra, Joan; Blech, Martin; Herrera, Perfecto; Serra, Xavier] Univ Pompeu Fabra, Mus Technol Grp, Barcelona, Spain.
C3 Pompeu Fabra University
RP Laurier, C (corresponding author), Univ Pompeu Fabra, Mus Technol Grp, Barcelona, Spain.
EM cyril.laurier@upf.edu
RI Alidadi, Mehdi/HJZ-0235-2023; Serra, Xavier/C-9299-2014; Serrà,
   Joan/E-3250-2010; Serra, Xavier/JAN-6936-2023; Herrera,
   Perfecto/C-4658-2012
OI Alidadi, Mehdi/0000-0001-5183-7829; Serra, Xavier/0000-0003-1395-2345;
   Herrera, Perfecto/0000-0003-2799-7675
FU EU [PHAROS IST-2006-045035]
FX We are very grateful to all the human annotators that helped to create
   our ground truth dataset. We also want to thank all the people
   contributing to the Music Technology Group (Universitat Pompeu Fabra,
   Barcelona) technologies and, in particular, Nicolas Wack, Eduard Aylon
   and Robert Toscano. We are also grateful to the entire MIREX team,
   specifically Stephen Downie and Xiao. We finally want to thank Michel
   Plu and Valerie Botherel from Orange Labs for the user evaluation data
   and Piero Fraternali, Alessandro Bozzon and Marco Brambilla from
   WebModels for the user interface. This research has been partially
   funded by the EU Project PHAROS IST-2006-045035.
CR Andric A, 2006, MULTIMED TOOLS APPL, V29, P127, DOI 10.1007/s11042-006-0003-9
   [Anonymous], P INT C MACH LEARN A
   [Anonymous], 2003, Proceedings of the International Symposium on Music Information Retrieval
   [Anonymous], 2007, ISMIR
   [Anonymous], 2000, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations
   Berenson M.L., 1983, INTERMEDIATE STAT ME
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Downie JS, 2008, ACOUST SCI TECHNOL, V29, P247, DOI 10.1250/ast.29.247
   Duda R., 1973, Pattern Classification and Scene Analysis
   Farnsworth P.R., 1954, Journal of Aesthetics and Art Criticism, V13, P97, DOI [DOI 10.2307/427021, 10.2307/427021, 10.1111/1540_6245.jaac13.1.0097]
   Gouyon F., 2008, Content Processing of Music Audio Signals, P83
   Gutierrez E.G., 2006, Tonal description of music audio signals
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hu X., 2008, Proceedings of the International Society for Music Information Retrieval Conference, P462
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   JUSLIN PN, 2008, BEHAV BRAIN SCI, V31
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Laurier C., 2009, Handbook of Research on Synthetic Emotions and Sociable Robotics: New Applications in Affective Computing and Artificial Intelligence, P9
   LAURIER C, 2007, MUS INF RETR EV EXCH
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   LIDY T, 2007, MIREX 2007 COMBINING
   LINDSTROM E, 1997, P 3RD TRIENNIAL ESCO, P292
   Logan Beth, 2000, ISMIR, V270, P1
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   MANDEL M, 2007, LABROSAS AUDIO MUSIC
   MANDEL M, 2006, MULTIMEDIA SYSTEMS, V12
   Orio Nicola, 2006, Foundations and Trends in Information Retrieval, V1, P1, DOI 10.1561/1500000002
   Pachet F, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/153017
   Peeters G., 2004, CUIDADO Ist Project Report, V54, P1
   Peres Y, 1998, PROBAB THEORY REL, V111, P141, DOI 10.1007/s004400050165
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sethares W.A., 1998, TUNING TIMBRE SPECTR
   Shi YY, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P1085, DOI 10.1109/ICME.2006.262723
   Smith JO, 1999, IEEE T SPEECH AUDI P, V7, P697, DOI 10.1109/89.799695
   SORDO M, 2007, P 8 INT C MUS INF RE, P531
   Thayer R., 1996, The Origin of Everyday Moods
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G., 2007, INTELLIGENT MUSIC IN
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Wieezorkowska A, 2005, LECT NOTES COMPUT SC, V3488, P456
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
NR 47
TC 29
Z9 33
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 161
EP 184
DI 10.1007/s11042-009-0360-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ellouze, M
   Boujemaa, N
   Alimi, AM
AF Ellouze, Mehdi
   Boujemaa, Nozha
   Alimi, Adel M.
TI Scene pathfinder: unsupervised clustering techniques for movie scenes
   extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Scene detection; Video browsing; Movies-shots clustering; Video
   processing; Video segmentation
ID VIDEO; SEGMENTATION
AB The need for watching movies is in perpetual increase due to the widespread of the internet and the increasing popularity of the video on demand service. The important mass of movies stored in the Internet or in VOD servers need to be structured to accelerate the browsing operation. In this paper, we propose a new system called "The Scene Pathfinder" that aims at segmenting the movies into scenes to give users the opportunity to have a non-sequential access and to watch particular scenes of the movie. This helps them to judge quickly the movie and decide if they have to buy or to download it and avoiding waste of time and money. The proposed approach is multimodal. We use both of visual and auditory information to accomplish the segmentation. We base on the assumption that every movie scene is either action or non-action scene. Non-action scenes are generally characterized by static backgrounds and occur in the same place. For this reason, we base on the content information and on the Kohonen map to extract these kinds of scenes ( shots agglomerations). Action scenes are characterized by high tempo and motion. For this reason, we base on tempo features and on the Fuzzy CMeans to classify shots and to localize the action zones. The two processes are complementary. Indeed, the over segmentation that may occur in the extraction of action scenes by basing on the content information is repaired by the Fuzzy clustering. Our system is tested on a varied database and obtained results show the merit of our approach and that our assumptions are well-founded.
C1 [Ellouze, Mehdi; Alimi, Adel M.] Univ Sfax, REGIM Res Grp Intelligent Machines, ENIS, Sfax 3038, Tunisia.
   [Boujemaa, Nozha] INRIA, IMEDIA Team, F-78153 Le Chesnay, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Inria
RP Ellouze, M (corresponding author), Univ Sfax, REGIM Res Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM Mehdi.Ellouze@ieee.org; Nozha.Boujemaa@inria.fr; Adel.Alimi@ieee.org
RI Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384
FU ARUB [01/UR/11/02]
FX The authors would like to thank several individuals and groups for
   making the implementation of this system possible. The authors would
   like to acknowledge the financial support of this work by grants from
   the General Direction of Scientific Research and Technological
   Renovation (DGRSRT), Tunisia, under the ARUB program 01/UR/11/02. We are
   also grateful, to EGIDE and INRIA, France, for sponsoring this work and
   the three-month research placement of Mehdi Ellouze from 1/11/2007 to
   31/1/2008 in INRIA IMEDIA Team in which parts of this work were done.
CR [Anonymous], 1991, Grammar of the film language
   Bezdek James C., 1981, PATTERN RECOGN
   Bordwell D., 1997, FILM ART INTRO
   BOUJEMAA N, 2001, P INT WORKSH MULT
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   CHEN HW, 2004, P ACM SIGMM INT WORK, P251
   Chen L, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P737
   Chen LH, 2008, PATTERN RECOGN, V41, P1056, DOI 10.1016/j.patcog.2007.07.024
   CHEN SC, 2001, P 2001 IEEE INT C MU, P56
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Ellouze M., 2008, P INT C ACM MULT TRE
   Ellouze M., 2006, P INT C COMP VIS AEO, P303
   ELLOUZE M, 2007, TAIMA 07, P271
   GENG Y, 2005, P 9 INT C KNOWL BAS, P1197
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   HUANG J, 2008, P IEEE INT C IM PROC, P526
   KARRAY H, INDEXING VI IN PRESS
   KARRAY H, 2008, INT J INFORM COMMUNI, V1, P69
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   KHERALLAH M, 2008, P INT C PAT IN PRESS
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   LEHANE B, 2006, P WORKSH IM AN MULT, P1
   Lin T, 2000, INT C PATT RECOG, P39, DOI 10.1109/ICPR.2000.902860
   LIN T, 2001, P ICME TOK JAP, P753
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   NAGASAKA A, 1991, VISUAL DATABASE SYST, V2, P119
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   OH J, 2000, P IS T SPIE C MULT C, P254
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   RUI Y, 1998, ACM J MULTIMEDIA SYS, P359
   SMEATON AF, 2006, P ACM INT WORKSH MUL, P231
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Sundaram H, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1145, DOI 10.1109/ICME.2000.871563
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Truong BT, 2003, IEEE T CIRC SYST VID, V13, P5, DOI 10.1109/TCSVT.2002.808084
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Zhao L., 2001, IEEE INT C MULT EXP, P1171
   2008, YALE FILM STUDIES
NR 40
TC 10
Z9 10
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 325
EP 346
DI 10.1007/s11042-009-0325-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000006
DA 2024-07-18
ER

PT J
AU Lee, RS
   Chung, CW
   Lee, SL
   Kim, SH
AF Lee, Robert S.
   Chung, Chin-Wan
   Lee, Seok-Lyong
   Kim, Sang-Hee
TI Confidence interval approach to feature re-weighting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Relevance feedback; Feature re-weighting;
   Image databases
ID IMAGE RETRIEVAL-SYSTEM
AB Relevance feedback is commonly incorporated into content-based image retrieval systems with the objective of improving retrieval accuracy via user feedback. One effective method for improving retrieval performance is to perform feature re-weighting based on the obtained feedback. Previous approaches to feature re-weighting via relevance feedback assume the feature data for images can be represented in fixed-length vectors. However, many approaches are invalidated with the recent development of features that cannot be represented in fixed-length vectors. In addition, previous approaches use only the information from the set of images returned in the latest query result for feature re-weighting. In this paper, we propose a feature re-weighting approach that places no restriction on the representation of feature data and utilizes the aggregate set of images returned over the iterations of retrieval to obtain feature re-weighting information. The approach analyzes the feature distances calculated between the query image and the resulting set of images to approximate the feature distances for the entire set of images in the database. Two-sided confidence intervals are used with the distances to obtain the information for feature re-weighting. There is no restriction on how the distances are calculated for each feature. This provides freedom for how the feature representations are structured. The experimental results show the effectiveness of the proposed approach and in comparisons with other work, it is shown that our approach outperforms previous work.
C1 [Lee, Robert S.; Chung, Chin-Wan] Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon 305701, South Korea.
   [Lee, Seok-Lyong] Hankuk Univ Foreign Studies, Sch Ind Informat & Syst Engn, Seoul, South Korea.
   [Kim, Sang-Hee] Agcy Def Dev, Taejon 300600, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Hankuk
   University Foreign Studies; Agency of Defense Development (ADD),
   Republic of Korea
RP Chung, CW (corresponding author), Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon 305701, South Korea.
EM chungcw@cs.kaist.ac.kr
RI Chung, Chin-Wan/C-2029-2011
CR Aggarwal G, 2002, IEEE T MULTIMEDIA, V4, P201, DOI 10.1109/TMM.2002.1017734
   [Anonymous], 2003, PROC ACM SPECIAL INT, DOI [10.1145/872757.872829, DOI 10.1145/872757.872829]
   [Anonymous], 2002, PROBABILITY STAT ENG
   Cheikh FA, 2003, IEEE IMAGE PROC, P745
   Ciocca G, 2001, PATTERN RECOGN, V34, P1639, DOI 10.1016/S0031-3203(00)00055-8
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   FALOUTSOS C, 1994, J INTELL INF SYST, V4, P133
   Ghosh A, 2005, IEEE T PATTERN ANAL, V27, P1793, DOI 10.1109/TPAMI.2005.225
   Gondra I, 2004, P COMP VIS PATT REC, P149
   HEESCH R, 2003, LNCS, V2633, P363
   Huang PW, 2004, IEEE T KNOWL DATA EN, V16, P1486, DOI 10.1109/TKDE.2004.92
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   KWON YI, 2005, P INT S REM SENS, P575
   LATECKI LJ, 2002, SHAPE DATA MPEG 7 CO
   Lee KM, 2004, IEEE T MULTIMEDIA, V6, P817, DOI 10.1109/TMM.2004.837235
   Lee Robert Samuel, 2006, [Journal of KIISE : Databases, 정보과학회논문지 : 데이타베이스], V33, P372
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   PORKAEW K, 1999, TRDB9905 U CAL IRV
   PORKAEW K, 1999, TRDB9903 U CAL IRV
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Taycher L., 1997, P 2 INT C VIS INF SY, V97, P85
   Tusk C, 2003, INT GEOSCI REMOTE SE, P3691
   Wu YM, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P581
NR 25
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 385
EP 407
DI 10.1007/s11042-008-0212-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hauglid, JO
   Heggland, J
AF Hauglid, Jon Olav
   Heggland, Jon
TI Savanta - search, analysis, visualisation and navigation of temporal
   annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video database; metadata; browsing; filtering; temporal analysis
ID VIDEO DATA; SYSTEM
AB In this article, we present Savanta, an information gathering interface for temporal, semantic video annotations. In Savanta, we integrate various methods and paradigms for information gathering, including visualisation, filtering, data mining, navigation and search, in order to explore the possible advantages of doing so. We posit that a seamless integration of multiple access methods, combined with an improved interval visualisation scheme and dynamically generated metadata, will result in greater user satisfaction compared to conventional approaches for searching and querying video databases-despite the increased complexity that may result. We perform a formal usability evaluation comparing Savanta to systems based on traditional search/query paradigms, and conclude that Savanta outperforms them with regard to both power and usability, especially for complex and open-ended tasks.
C1 [Hauglid, Jon Olav; Heggland, Jon] Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Hauglid, JO (corresponding author), Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway.
EM joh@idi.ntnu.no; heggland@idi.ntnu.no
CR Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Anjulan A, 2006, LECT NOTES COMPUT SC, V4071, P183
   [Anonymous], 1997, DESIGNING USER INTER, DOI DOI 10.1145/25065.950626
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], 1998, Interactions, DOI DOI 10.1145/274430.274432
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Carrer M, 1997, MULTIMED TOOLS APPL, V5, P233, DOI 10.1023/A:1009647624347
   Catarci T, 2003, IEEE MULTIMEDIA, V10, P66, DOI 10.1109/MMUL.2003.1167924
   CHAN SSM, 2002, IEEE T MULTIMEDIA, P4
   CHRISTE Y, 1995, CAH CIVILIS MEDIEVAL, V38, P4
   Chua TS, 2002, MULTIMED TOOLS APPL, V16, P79, DOI 10.1023/A:1013293702591
   Dorado A, 2004, IEEE T CIRC SYST VID, V14, P622, DOI 10.1109/TCSVT.2004.826764
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   Frank Nack, 2002, SYNTAX MULTIMEDIA SE
   Hacid MS, 2000, IEEE T KNOWL DATA EN, V12, P729, DOI 10.1109/69.877505
   HAUGLID JO, 2002, P 2002 ACM S APPL CO, P418
   HAUGLID JO, 2005, THESIS NORWEGIAN U S
   Heggland J., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P118
   HEGGLAND J, 2005, THESIS NORWEGIAN U S
   Hjelsvold R, 1995, WORK COMP, P295
   HJELSVOLD R, 1995, VIDEOSTAR A DATABASE
   HJELSVOLD R, 1995, INTEGRATED VIDEO ARC, P283
   HJELSVOLD R, 1994, VLDB C SANT CHIL SEP, P686
   Kazman R, 1996, IEEE MULTIMEDIA, V3, P63, DOI 10.1109/93.486705
   Kokkoras F, 2002, MULTIMEDIA SYST, V8, P328, DOI 10.1007/s005300200054
   MACKAY WE, 1998, DIVA EXPLORATORY DAT, P416
   Mitchell M., 2001, Research Design Explained, V4th
   *NOLD INF TECHN, 2007, OBS
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Ponceleon D., 1998, Proceedings ACM Multimedia 98, P99, DOI 10.1145/290747.290760
   SANTINI S, 1999, P IS T SPIE C STOR R, P167
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SKOU CV, 2003, QUALITATIVE MEDIA AN
   SLAUGHTER L, 1998, P DIG LIB 98, P305
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Volkmer T., 2005, PROC 13 ANN ACM INT, P892, DOI DOI 10.1145/1101149.1101341
   Wactlar H.D., 1996, IEEE COMPUTER, P46
   WEISS R, 1995, IEEE MULTIMEDIA, V2, P12, DOI 10.1109/93.368596
   Whittaker S, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P26, DOI 10.1145/312624.312639
   Zhao Wei, 2006, Journal of Ecology and Rural Environment, V22, P6
NR 42
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 183
EP 210
DI 10.1007/s11042-008-0204-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200002
DA 2024-07-18
ER

PT J
AU Haouzia, A
   Noumeir, R
AF Haouzia, Adil
   Noumeir, Rita
TI Methods for image authentication: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE image authentication; image content; cryptography; fragile watermarking;
   semi-fragile watermarking; digital image signature
ID DIGITAL SIGNATURE SCHEME; WATERMARKING; ALGORITHM; SECURE
AB Image authentication techniques have recently gained great attention due to its importance for a large number of multimedia applications. Digital images are increasingly transmitted over non-secure channels such as the Internet. Therefore, military, medical and quality control images must be protected against attempts to manipulate them; such manipulations could tamper the decisions based on these images. To protect the authenticity of multimedia images, several approaches have been proposed. These approaches include conventional cryptography, fragile and semi-fragile watermarking and digital signatures that are based on the image content. The aim of this paper is to present a survey and a comparison of emerging techniques for image authentication. Methods are classified according to the service they provide, that is strict or selective authentication, tamper detection, localization and reconstruction capabilities and robustness against different desired image processing operations. Furthermore, we introduce the concept of image content and discuss the most important requirements for an effective image authentication system design. Different algorithms are described and we focus on their comparison according to the properties cited above.
C1 [Haouzia, Adil; Noumeir, Rita] Ecole Technol Super, Dept Elect Engn, Montreal, PQ H3C 1K3, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP Noumeir, R (corresponding author), Ecole Technol Super, Dept Elect Engn, 1100 Notre Dame W, Montreal, PQ H3C 1K3, Canada.
EM rita.noumeir@etsmtl.ca
CR [Anonymous], P EUR C EL IM VIS AR
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], P ICII2001
   [Anonymous], 1999, MICROSOFT CORPORATIO
   [Anonymous], P WORKSH THEOR APPL
   [Anonymous], P SPIE INT C SEC WAT
   [Anonymous], 20492 NPL DITC
   [Anonymous], P COMP GRAPH INT
   [Anonymous], IEICE T FUNDAM ELECT
   [Anonymous], 1993, DIGITAL IMAGE COMPUT
   [Anonymous], IEEE DIG SIGN PROC W
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P ICIP
   [Anonymous], SARI SELF AUTHENTICA
   [Anonymous], IEICE T FUNDAM ELECT
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P 3 INT C MACH LEARN
   [Anonymous], P 1990 BILK INT C NE
   [Anonymous], P ICIP 98 CHIC
   [Anonymous], SECURITY WATERMAKING
   [Anonymous], ICMCS 99 FLOR IT
   [Anonymous], P IFIP T COMPUTER SC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P ICIP 97 SANT BARB
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P 2 ANN FEDL S ATIRP
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P ICIP 98 CHIC US
   [Anonymous], P ICIP 97 SANT BARB
   [Anonymous], J AUTOMATA LANGUAGES
   [Anonymous], CRYPTOGRAPHY INFORM
   [Anonymous], P 4 ANN FEDL S ATIRP
   [Anonymous], P INT C IM PROC ICIP
   [Anonymous], P IEEE INT C MULT CO
   [Anonymous], P ICIP 03 SEPT
   [Anonymous], P IEICE T FUND EL CO
   [Anonymous], 4869719 CUCTR
   [Anonymous], MATH PHYS LECT RECEN
   [Anonymous], ONDELETTE ONDELETTE
   [Anonymous], P SPIE SECURITY WATE
   [Anonymous], P CAMBR SEC WORKSH
   [Anonymous], P SPIE SECURITY WA 2
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P IEEE CAN C EL COMP
   [Anonymous], P IEEE GLOBECOM 1998
   [Anonymous], P IEEE INT C SYST MA
   [Anonymous], P INT C SIGN PROC
   [Anonymous], DIG SIGN STAND
   [Anonymous], REV TRAITEMENT SIGNA
   [Anonymous], P SPIE INT C EL IM 2
   [Anonymous], P SPIE INT C SEC WAT
   [Anonymous], P ACM INT C MULT NOV
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], P ICIP 2000 VANC CAN
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], OPTICAL SECURITY C 2
   [Anonymous], 1972, PhD. dissertation
   [Anonymous], P INT C IM SCI SYST
   [Anonymous], 2001, Cryptographic Hardware and Embedded SystemsCHES 2001: Third International Workshop Paris, France, May 14-16, 2001 Proceedings 3
   [Anonymous], P ICIP 98
   [Anonymous], P CONTR AUT ROB VIS
   [Anonymous], P INT C IM PROC
   [Anonymous], APPRENDRE MAITRISER
   [Anonymous], 1997, P ICIP 97 SANT BARB
   [Anonymous], P SPIE
   [Anonymous], ATTACKS COPYRIGHT MA
   [Anonymous], 1999, P S CONT SEC DAT HID
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 1320 RFC MIT RSA DAT
   [Anonymous], THESIS ECOLE POLYTEC
   [Anonymous], P 14 INT C DIG SIGN
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P ANN ACM S PRIN DIS
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P SPIE SECURITY WATE
   [Anonymous], CRYPTOLOGIE CONT
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P SPIE INT C SEC WAT
   [Anonymous], AFRL TECHNOLOGY HORI
   [Anonymous], P IFIP C MOB COMM
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P ICIP CHIC IL US
   [Anonymous], P 6 IEEE INT WORKSH
   [Anonymous], J CRYPTOL
   [Anonymous], JPEG STILL IMAGE DAT
   [Anonymous], P ACM MULT WORKSH MU
   [Anonymous], 2000, P SPIE INT C SEC WAT
   [Anonymous], P INT C MACH LEARN C
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], P IS T PIC C PORTL O
   [Anonymous], P IEEE SIGN PROC SOC
   [Anonymous], P 4 INT WORKSH INF H
   [Anonymous], IEEE EURASIP WORKSH
   [Anonymous], P EUSIPCO 98
   [Anonymous], 2002, Introduction to Cryptography with Coding Theory
   [Anonymous], IM PROC TOOLB US GUI
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Bhattacharya D, 1997, PATTERN RECOGN, V30, P1373, DOI 10.1016/S0031-3203(96)00177-X
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Culik K, 1997, ACTA INFORM, V34, P151, DOI 10.1007/s002360050077
   Darnell D., 1999, EDI Forum: The Journal of Electronic Commerce, V12, P59
   Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195
   EIERMAN MA, 1995, DECIS SUPPORT SYST, V14, P1, DOI 10.1016/0167-9236(94)00012-H
   Evertse J. H., 1992, Journal of Cryptology, V5, P41, DOI 10.1007/BF00191320
   Fowler B., 1995, Proceedings. DCC '95 Data Compression Conference (Cat. No.95TH8037), P102, DOI 10.1109/DCC.1995.515500
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   FRIEDMAN GL, 1993, IEEE T CONSUM ELECTR, V39, P905, DOI 10.1109/30.267415
   Gao Qi, 2004, Journal of Xi'an Jiaotong University, V38, P119
   Gennaro R, 1996, LECT NOTES COMPUT SC, V1070, P354
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hampel H., 1992, Signal Processing: Image Communication, V4, P103, DOI 10.1016/0923-5965(92)90017-A
   HARN L, 1994, ELECTRON LETT, V30, P396, DOI 10.1049/el:19940317
   Helleseth T., 1994, Proceedings. 1994 IEEE International Symposium on Information Theory (Cat. No.94CH3467-8), DOI 10.1109/ISIT.1994.394710
   Hwang MS, 2003, IEEE T KNOWL DATA EN, V15, P1552, DOI 10.1109/TKDE.2003.1245292
   Inoue H, 2000, INTEGR COMPUT-AID E, V7, P105
   Inoue T., 1997, Bulletin of Aichi Institute of Technology, Part B, V32, P177
   Johnson N.F., 1999, INFORM TECHNIQUES ST, P43
   Knudsen LR, 1998, J CRYPTOL, V11, P59, DOI 10.1007/s001459900035
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu B, 2000, CHINESE J ELECTRON, V9, P144
   Liu Hailong, 2003, Journal of Beijing University of Aeronautics and Astronautics, V29, P278
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu HT, 2003, ELECTRON LETT, V39, P898, DOI 10.1049/el:20030589
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Lu ZM, 2003, ELECTRON LETT, V39, P35, DOI 10.1049/el:20030041
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Memon N, 2000, P SOC PHOTO-OPT INS, V3971, P164, DOI 10.1117/12.384970
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Queluz MP, 1999, PROC SPIE, V3657, P85, DOI 10.1117/12.344706
   Rao K.R, 2014, DISCRETE COSINE TRAN
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rogier N., 1997, Designs, Codes and Cryptography, V12, P245, DOI 10.1023/A:1008220711840
   ROTHAUS OS, 1993, IEEE T INFORM THEORY, V39, P654, DOI 10.1109/18.212299
   Sanchez-Avila C, 2001, 35TH ANNUAL 2001 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/CCST.2001.962837
   SARWATE DV, 1980, P IEEE, V68, P593, DOI 10.1109/PROC.1980.11697
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Shen L, 1997, J ELECTRON IMAGING, V6, P198, DOI 10.1117/12.269344
   Shin JB, 2002, LECT NOTES COMPUT SC, V2587, P35
   STALLINGS W, 1994, DR DOBBS J, V19, P32
   Sun QB, 2005, IEEE T MULTIMEDIA, V7, P480, DOI 10.1109/TMM.2005.846776
   Tanaka K., 1990, Electronics and Communications in Japan, Part 1 (Communications), V73, P46, DOI 10.1002/ecja.4410730505
   TANCEVSKI L, 1994, ELECTRON LETT, V30, P721, DOI 10.1049/el:19940500
   Tian J., 2002, Proceedings of workshop on multimedia and security p, P19
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wang XM, 2002, CHINESE J ELECTRON, V11, P186
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu CW, 2002, IEEE T MULTIMEDIA, V4, P385, DOI 10.1109/TMM.2002.802018
   Wu CW, 2001, P SOC PHOTO-OPT INS, V4314, P241, DOI 10.1117/12.435404
   Xiaotie Deng, 1999, Proceedings of 1999 International Workshop on Cryptographic Techniques and E-Commerce, P254
   Yeung MM, 1998, COMMUN ACM, V41, P30
   Zheng Q, 1993, IEEE T IMAGE PROCESS, V2, P311, DOI 10.1109/83.236535
   ZHU B, 1995, P SOC PHOTO-OPT INS, V2491, P173, DOI 10.1117/12.205384
NR 163
TC 111
Z9 123
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2008
VL 39
IS 1
BP 1
EP 46
DI 10.1007/s11042-007-0154-3
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 311TE
UT WOS:000256622500001
DA 2024-07-18
ER

PT J
AU Chorianopoulos, K
AF Chorianopoulos, Konstantinos
TI Personalized and mobile digital TV applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital TV; interactive TV; personalization; mobile TV
ID INTERNET
AB The introduction of mobile and broadband networks in complement to the existing satellite, cable, and terrestrial platforms, opens new opportunities for interactive TV (ITV) applications. In addition, the widespread adoption of multimedia computing has enabled the processing of TV content on personal devices such as mobile phones and PCs. The above developments raise novel issues and require the adoption of new multimedia standards and application frameworks. In particular, the explosion in the amount of available TV channels over digital television platforms (broadcast or internet protocol) makes searching and locating interesting content a cumbersome task. In this context, personalization research is concerned with the adaptation of content (e.g. movies, news, advertisements). Personalization is achieved with the employment of algorithms and data collection schemes that predict and recommend to television viewers content that match their interests. In addition, the distribution of TV content to mobile devices over broadband wireless raises the issue of video quality. Video quality depends on many aspects of the video encoding systems, such as bit rate and algorithms that model human perception of video on small screens. In this article, we examine contemporary research in personalized and mobile digital TV applications. Moreover, we present a critical survey of the most prominent research and provide directions for further research in personalized and mobile digital TV (DTV) applications.
C1 [Chorianopoulos, Konstantinos] Tech Univ Crete, Mus Lab, Dept Elect & Elect Engn, Hania, Greece.
   [Chorianopoulos, Konstantinos] Univ Aegean, Aegean, Germany.
C3 Technical University of Crete
RP Chorianopoulos, K (corresponding author), Tech Univ Crete, Mus Lab, Dept Elect & Elect Engn, Hania, Greece.
EM choko@ced.tuc.gr
RI Chorianopoulos, Konstantinos/I-7289-2013; Akalugwu, Kenneth/F-4815-2014;
   Chorianopoulos, Konstantinos/N-4943-2019
OI Chorianopoulos, Konstantinos/0000-0002-5999-9387
CR ARDISSONO L, 2004, PERSONALIZED DIGITAL
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Elliott MT, 1998, J ADVERTISING RES, V38, P29
   Furht B, 1999, IEEE MULTIMEDIA, V6, P85, DOI 10.1109/93.752968
   Furht B, 1998, IEEE MULTIMEDIA, V5, P78, DOI 10.1109/93.735871
   FURHT B, 1996, P ACM S APPL COMP PE, P7
   KAZASIS FG, 2003, WORKSH UB MOB INF CO
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
NR 10
TC 26
Z9 31
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 1
EP 10
DI 10.1007/s11042-006-0081-8
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600001
DA 2024-07-18
ER

PT J
AU Cheuk, WK
   Lun, DPK
AF Cheuk, W. K.
   Lun, Daniel P. K.
TI Throughput optimization for video streaming proxy servers based on video
   staging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE variable-bit-rate video; proxy server; video smoothing; video staging;
   video streaming
AB A video streaming proxy server needs to handle hundreds of simultaneous connections between media servers and clients. Inside, every video arrived at the server and delivered from it follows a specific arrival and delivery schedule. While arrival schedules compete for incoming network bandwidth, delivery schedules compete for outgoing network bandwidth. As a result, a proxy server has to provide sufficient buffer and disk cache for storage, together with memory space, disk space and disk bandwidth. In order to optimize the throughput, a proxy server has to govern the usage of these resources. In this paper, we first analyze the property of a traditional smoothing algorithm and a video staging algorithm. Then we develop, based on the smoothing algorithm, a video staging algorithm for video streaming proxy servers. This algorithm allows us to devise an arrival schedule based on the delivery schedule. Under this arrival and delivery schedule pair, we can achieve a better resource utilization rate gracefully between different parameter sets. It is also interesting to note that the usage of the resources such as network bandwidth, disk bandwidth and memory space becomes interchangeable. It provides the basis for inter-resource scheduling to further improve the throughput of a video streaming proxy server system.
C1 Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Lun, DPK (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
EM enpklun@polyu.edu.hk
RI Lun, Daniel Pak Kong/H-2120-2017
OI Lun, Daniel Pak Kong/0000-0003-3891-1363
CR CHANG SH, 2002, GLOBECOM 02, V2, P1733
   Cheuk WK, 2006, MULTIMED TOOLS APPL, V28, P69, DOI 10.1007/s11042-006-5118-5
   CHEUK WK, 2004, P IEEE INT C MULT EX, V1, P459
   Dogan S, 2002, IEEE T CIRC SYST VID, V12, P453, DOI 10.1109/TCSVT.2002.800308
   FABMI H, 2001, IEEE COMPUT, V34, P54
   Goose S, 2002, MDM 2002: THIRD INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, PROCEEDINGS, P169, DOI 10.1109/MDM.2002.994414
   Gorinsky S, 1997, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS, PROCEEDINGS, P285, DOI 10.1109/ICCCN.1997.623325
   Lombardo A, 2001, IEEE T MULTIMEDIA, V3, P5, DOI 10.1109/6046.909590
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   MA WH, 2000, IEEE INT C MULT EXP, V2, P991
   Mahanti A, 2000, IEEE NETWORK, V14, P16, DOI 10.1109/65.844496
   Rexford J, 1999, IEEE ACM T NETWORK, V7, P202, DOI 10.1109/90.769768
   Rexford J, 1999, GLOBECOM'99: SEAMLESS INTERCONNECTION FOR UNIVERSAL SERVICES, VOL 1-5, P1823, DOI 10.1109/GLOCOM.1999.832476
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 15
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2007
VL 35
IS 3
BP 311
EP 333
DI 10.1007/s11042-007-0134-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 228XS
UT WOS:000250766500004
DA 2024-07-18
ER

PT J
AU Yoo, HW
   Cho, SB
AF Yoo, Hun-Woo
   Cho, Sung-Bae
TI Video scene retrieval with interactive genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE emotion-based retrieval; video scene retrieval; commercial video
   retrieval; interactive genetic algorithm (IGA)
ID IMAGE CLASSIFICATION; SYSTEM; QUERY
AB This paper proposes a video scene retrieval algorithm based on emotion. First, abrupt/gradual shot boundaries are detected in the video clip of representing a specific story. Then, five video features such as "average color histogram," "average brightness," "average edge histogram," "average shot duration," and "gradual change rate" are extracted from each of the videos, and mapping through an interactive genetic algorithm is conducted between these features and the emotional space that a user has in mind. After the proposed algorithm selects the videos that contain the corresponding emotion from the initial population of videos, the feature vectors from them are regarded as chromosomes, and a genetic crossover is applied to those feature vectors. Next, new chromosomes after crossover and feature vectors in the database videos are compared based on a similarity function to obtain the most similar videos as solutions of the next generation. By iterating this process, a new population of videos that a user has in mind are retrieved. In order to show the validity of the proposed method, six example categories of "action," "excitement," "suspense," "quietness," "relaxation," and "happiness" are used as emotions for experiments. This method of retrieval shows 70% of effectiveness on the average over 300 commercial videos.
C1 Yonsei Univ, Ctr Cognit Sci, Seodaemun Ku, Seoul 120749, South Korea.
   Yonsei Univ, Dept Comp Sci, Seodaemun Ku, Seoul 120749, South Korea.
C3 Yonsei University; Yonsei University
RP Yoo, HW (corresponding author), Yonsei Univ, Ctr Cognit Sci, Seodaemun Ku, 134 Shinchon Dong, Seoul 120749, South Korea.
EM paulyhw@yonsei.ac.kr; sbcho@cs.yonsei.ac.kr
CR [Anonymous], IEEE COMPUT
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Ba Tu Truong, 2000, Proceedings ACM Multimedia 2000, P219, DOI 10.1145/354384.354481
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BANSHAF W, 1997, INTERACTIVE EVOLUTIO
   Biles John A., 1994, Proceedings of the International Computer Music Conference, V94, P131, DOI DOI 10.1145/192161.192189
   Caldwell C., 1991, Proceedings of the fourth international conference on genetic algorithms, P416
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Cho SB, 2002, APPL INTELL, V16, P129, DOI 10.1023/A:1013614519179
   Colombo C, 1999, IEEE MULTIMEDIA, V6, P38, DOI 10.1109/93.790610
   Colombo C, 2001, MULTIMED TOOLS APPL, V13, P93, DOI 10.1023/A:1009681324605
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Itten J., 1974, THE ART OF COLOR
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   JOSEPH T, 1988, IEEE T SOFTWARE ENG, V14, P630, DOI 10.1109/32.6140
   LEE JY, 1998, P AS FUZZ SYST S, P479
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Pickens J, 2002, P ISMIR, P13
   ROUSSOPOULOS N, 1988, IEEE T SOFTWARE ENG, V14, P639, DOI 10.1109/32.6141
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   SOEN T, 1987, COLOR RES APPL, V12, P187, DOI 10.1002/col.5080120406
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   Takagi H, 1999, P IEEE INT C SYST MA, P263
   TOIVANEN J, 2002, TMH QPSR, V44
   Um J, 2002, COLOR RES APPL, V27, P208, DOI 10.1002/col.10052
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yoo HW, 2004, INT J INF TECH DECIS, V3, P129, DOI 10.1142/S0219622004000957
   Yoo HW, 2002, PATTERN RECOGN, V35, P1115, DOI 10.1016/S0031-3203(01)00105-4
   Yoo HW, 2002, PATTERN RECOGN, V35, P749, DOI 10.1016/S0031-3203(01)00072-3
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
NR 39
TC 24
Z9 32
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 317
EP 336
DI 10.1007/s11042-007-0109-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500003
DA 2024-07-18
ER

PT J
AU Guo, Y
   Suh, K
   Kurose, J
   Towsley, D
AF Guo, Yang
   Suh, Kyoungwon
   Kurose, Jim
   Towsley, Don
TI P2Cast: peer-to-peer patching for video on demand service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2Cast; patching techniques; patch server; peer-to-peer network;
   video-on-demand service
AB Providing video on demand (VoD) service over the Internet in a scalable way is a challenging problem. In this paper, we propose P2Cast - an architecture that uses a peer-to-peer approach to cooperatively stream video using patching techniques, while only relying on unicast connections among peers. We address the following two key technical issues in P2Cast: (1) constructing an application overlay appropriate for streaming; and (2) providing continuous stream playback (without glitches) in the face of disruption from an early departing client. Our simulation experiments show that P2Cast can serve many more clients than traditional client-server unicast service, and that it generally out-performs multicast-based patching if clients can cache more than 10% of a stream's initial portion. We handle disruptions by delaying the start of playback and applying the shifted forwarding technique. The threshold in P2Cast, i.e., the length of time during which arriving clients form a single session, can serve as a "knob" to adjust the balance between the scalability and the clients' viewing quality.
C1 Thomson Inc, Corp Res, Princeton, NJ 08540 USA.
   Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.
C3 Thompson Management LLC; University of Massachusetts System; University
   of Massachusetts Amherst
RP Guo, Y (corresponding author), Thomson Inc, Corp Res, 2 Independence Way, Princeton, NJ 08540 USA.
EM Yang.Guo@thomson.net; kwsuh@cs.umass.edu; kurose@cs.umass.edu;
   towsley@cs.umass.edu
OI Towsley, Donald/0000-0002-7808-7375
CR BANERJEE S, 2002, P ACM SIGCOMM PITTSB
   CASTRO M, 2003, P IPTPS 03 BERK CA F
   CHU Y, 2001, P ACM SIGCOMM SAN DI
   Chu Y., 2000, P ACM SIGMETRICS SAN
   Deshpande H., 2002, 200221 STANF U
   EAGER D, 2000, P SPIE ACM C MULT CO
   Francis P., 2001, Yoid: Your Own Internet Distribution
   Gao L., 2001, IEEE T MULTIMEDIA, V3, P405
   GUO Y, 2002, P INT PACK WORKSH PI
   GUO Y, 2002, P2 CAST P2P PATCHING
   HU A, 2001, P IEEE INFOCOM ANCH
   HUA K, 1998, P ACM MULT BRIST ENG
   JAIN M, 2002, P ACM SIGCOMM PITTSB
   JANNOTTI J, 2000, P USENIX OSDI S SAN
   Mathy L., 2001, Networked Group Communication. Third International COST264 Workshop, NGC 2001. Proceedings (Lecture Notes in Computer Science Vol.2233), P76
   PADMANABHAN V, 2002, P IEEE WORKSH NOSSDA
   PENDARAKIS D, 2001, P USENIX S INT TECHN
   Rowstron A, 2003, IFIPACM INT C DISTRI
   TRAN DA, 2003, P IEEE INFOCOM SAN F
   Xu D., 2002, P IEEE ICDCS VIENN A
   ZEGURA E, 1996, P IEEE INFOCOM SAN F
NR 21
TC 18
Z9 21
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 109
EP 129
DI 10.1007/s11042-006-0067-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Panda, N
   Goh, KS
   Chang, EY
AF Panda, Navneet
   Goh, King-Shy
   Chang, Edward Y.
TI Active learning in very large databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Computer Vision Meets Databases
CY JUN 13, 2004
CL Paris, FRANCE
DE active learning; image retrieval; relevance feedback; support vector
   machines
AB Query-by-example and query-by-keyword both suffer from the problem of "aliasing," meaning that example-images and keywords potentially have variable interpretations or multiple semantics. For discerning which semantic is appropriate for a given query, we have established that combining active learning with kernel methods is a very effective approach. In this work, we first examine active-learning strategies, and then focus on addressing the challenges of two scalability issues: scalability in concept complexity and in dataset size. We present remedies, explain limitations, and discuss future directions that research might take.
C1 Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Panda, N (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
EM panda@cs.ucsb.edu
CR [Anonymous], IEEE COMPUT
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Brinker K., 2003, P 20 INT C MACHINE L, P59
   Chang E, 2003, ACM T INFORM SYST, V21, P347, DOI 10.1145/944012.944014
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   CHANG E, 2003, IEEE C IM PROC BARC, P606
   Goh K., 2004, PROC ACM INT C MULTI, P564
   Li BT, 2003, MULTIMEDIA SYST, V8, P512, DOI 10.1007/s00530-002-0069-9
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214
   PANDA N, 2005, SIAM C DAT MIN NEWP
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   TONG S, 2000, P 17 INT C MACH LEAR, P401
   Vapnik V., 1999, NATURE STAT LEARNING
   ZHANG Z, 2005, INT C MACH LEARN BON
NR 14
TC 20
Z9 24
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2006
VL 31
IS 3
BP 249
EP 267
DI 10.1007/s11042-006-0043-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 119XW
UT WOS:000243048800002
DA 2024-07-18
ER

PT J
AU Laurent, C
   Laurent, N
   Maurizot, M
   Dorval, T
AF Laurent, Christophe
   Laurent, Nathalie
   Maurizot, Mariette
   Dorval, Thierry
TI In depth analysis and evaluation of saliency-based color image indexing
   methods using wavelet salient features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image indexing and recognition; salient point detection; wavelet
   analysis; color and texture features
AB Nowadays, most of the research works in the area of image retrieval try to build an image signature by considering the image as a whole. In this paper, we proposed an alternative based on the detection of some salient points in the image. For this purpose, we propose a new efficient salient point detector based on a wavelet transform. The efficiency of our detector lies in the representation of the wavelet coefficients by a zerotree data structure and by a saliency formulation that does not favor any direction. Thus, the detected salient points are located on sharp region boundaries whatever their direction. From the detected salient points, we build a color/texture signature by using jointly the well-known color correlogram extended to salient features and rotated wavelet filter responses. Experimental results conducted by adopting a global salient approach and a local salient approach show the effectiveness of the proposed scheme.
C1 France Telecom, R&D, DIH, HDM, F-35512 Cesson Sevigne, France.
C3 Orange SA
RP Laurent, C (corresponding author), France Telecom, R&D, DIH, HDM, 4 Rue Clos Courtel, F-35512 Cesson Sevigne, France.
EM christophe2.laurent@francetelecom.com
CR ACHARD C, 2000, P INT C PATT REC
   [Anonymous], THESIS I NAT POLYTEC
   Bigorgne E, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P440, DOI 10.1109/ICIAP.2001.957049
   Bres S., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P427
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Gordon I., 1997, THEORIES VISUAL PERC
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huijsmans DP, 2001, PROC CVPR IEEE, P26
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JOLION JM, 1999, TRAIT SIGNAL, V15, P309
   Kim ND, 2000, IEEE T SYST MAN CY A, V30, P847, DOI 10.1109/3468.895915
   LAURENT C, 2003, 3 INT WORKSH CONT BA, P327
   LOUPIAS E, 2000, IEEE INT C IM PROC V
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mallat S.G. A., 1989, IEEE T PATTERN ANAL, V11, P7
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Marr D., 1982, Vision
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mikolajczyk K., 2002, P INT C COMPUTER VIS, P128
   MIKOLAJCZYK K, 2003, P IEEE INT C COMP VI
   MONTESINOS P, 1998, P IAPR C PATT REC BR
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7
   Sebe N, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P15, DOI 10.1109/IVL.2000.853833
   SEBE N, 2001, P BRIT MACH VIS C MA
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHIM S, 2002, IEEE INT C IM PROC R, V3, P957
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WECHSLER H, 1980, SIGNAL PROCESS, V2, P271, DOI 10.1016/0165-1684(80)90024-9
   Wolf C, 2000, INT C PATT RECOG, P234, DOI 10.1109/ICPR.2000.902902
NR 41
TC 6
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2006
VL 31
IS 1
BP 73
EP 94
DI 10.1007/s11042-006-0036-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 092QK
UT WOS:000241112200004
DA 2024-07-18
ER

PT J
AU Janvier, B
   Bruno, E
   Pun, T
   Marchand-Maillet, S
AF Janvier, Bruno
   Bruno, Eric
   Pun, Thierry
   Marchand-Maillet, Stephane
TI Information-theoretic temporal segmentation of video and applications:
   multiscale keyframes selection and shot boundaries detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based video analysis; temporal segmentation; keyframe selection;
   detection of shot boundaries
AB The first step in the analysis of video content is the partitioning of a long video sequence into short homogeneous temporal segments. The homogeneity property ensures that the segments are taken by a single camera and represent a continuous action in time and space. These segments can then be used as atomic temporal components for higher level analysis like browsing, classification, indexing and retrieval. The novelty of our approach is to use color information to partition the video into segments dynamically homogeneous using a criterion inspired by compact coding theory. We perform an information-based segmentation using a Minimum Message Length (MML) criterion and minimization by a Dynamic Programming Algorithm (DPA). We show that our method is efficient and robust to detect all types of transitions in a generic manner. A specific detector for each type of transition of interest therefore becomes unnecessary. We illustrate our technique by two applications: a multiscale keyframe selection and a generic shot boundaries detection.
C1 Univ Geneva, Comp Vis & Multimedia Lab, Viper Grp, Geneva, Switzerland.
C3 University of Geneva
RP Janvier, B (corresponding author), Univ Geneva, Comp Vis & Multimedia Lab, Viper Grp, Geneva, Switzerland.
EM janvier@cui.unige.ch
CR [Anonymous], P TRECVID 2003 WORKS
   BAXTER RA, 1994, P 4 IEEE DAT COMPR C
   FISHER W, 1958, J AM STAT ASS, V53
   FITZGIBBON OJ, 2000, P 11 INT C ALG LEARN, P56
   Gargi U, 1998, PROC CVPR IEEE, P559, DOI 10.1109/CVPR.1998.698661
   GUIGUES L, 2003, 19 C TRAIT SIGN IM G
   HANJALIC A, 2002, IEEE T CIRCUITS SYST, V12
   Heng WJ, 2002, IEEE T MULTIMEDIA, V4, P434, DOI 10.1109/TMM.2002.806532
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   LIENHART R, 1999, 7 P SPIE
   RUILOBA R, 1999, INT WORKSH CONT BAS
   WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240
NR 12
TC 15
Z9 18
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 273
EP 288
DI 10.1007/s11042-006-0026-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200004
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Yu, T
   Lin, KJ
AF Yu, Tao
   Lin, Kwei-Jay
TI QCWS: an implementation of QoS-capable multimedia web services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 5th IEEE International Symposium on Multimedia Software Engineeting
CY DEC 10-12, 2003
CL Tai Chung, TAIWAN
SP IEEE Comp Soc, Taichung Healthcare & Management Univ, Natl Tsing Hua Univ, Natl Cent Univ, Bioinformat Soc Taiwan, Univ Calif Irvine
DE QoS; web service; broker; QCWS; priority
AB QoS (Quality of Service), which defines service quality such as latency, availability, timeliness and reliability, is important for web applications that provide real-time information, multimedia content, or time-critical services. Many web applications are best implemented by servers with a guaranteed server processing capacity. In this research, we study the QoS control issues using the current Web services standards. We propose a QoS-capable Web service architecture, QCWS, by deploying a QoS broker between Web service clients and providers. The functions of the QoS broker module include tracking QoS information about servers, making selection decisions for clients, and negotiating with servers to get QoS agreements. We have implemented a QCWS prototype using IBM WSDK, enhanced with simple QoS capabilities. We have measured the performance running under different service priorities.
C1 Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.
C3 University of California System; University of California Irvine
RP Lin, KJ (corresponding author), Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.
EM tyu1@uci.edu; klin@uci.edu
CR AKBAR MM, 2001, P INT C COMP SCI SAN
   [Anonymous], 1998, THESIS
   CARDOSO J, 2002, THESIS U GEORGIA
   Chung JY, 2003, COMPUTER, V36, P35
   CONTI M, 2001, HP OP U ASS HP OVUA
   FYNFSTYCK F, 2001, P 8 INT C ADV COMM C
   Gudgin M., 2003, SIMPLE OBJECT ACCESS
   KORKMAZ T, 2001, P IEEE INFOCOM, V2, P22
   Martello Silvano, 1990, Knapsack Problems: Algorithms and Computer Implementations
   Menascé DA, 2002, IEEE INTERNET COMPUT, V6, P72, DOI 10.1109/MIC.2002.1067740
   Myerson JM, 2002, GUARANTEE YOUR WEB S
   Nahrstedt K, 2001, IEEE COMMUN MAG, V39, P140, DOI 10.1109/35.965372
   PISINGER D, 1995, EUR J OPER RES, V83, P394, DOI 10.1016/0377-2217(95)00015-I
   SCHANTZ RE, 2003, P 4 IFIP ACM USENIX
   SHANKAR M, 1999, P 5 REAL TIM TECHN A
   Widyono R., 1994, Technical Report TR-94-024
   YU T, 2004, P IEEE INT C E COMM
   ZENG L, 2003, P 12 INT WORLD WID W
NR 18
TC 9
Z9 10
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2006
VL 30
IS 2
BP 165
EP 187
DI 10.1007/s11042-006-0020-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 082CG
UT WOS:000240363500004
DA 2024-07-18
ER

PT J
AU Mingkhwan, A
   Fergus, P
   Abuelma'atti, O
   Merabti, M
   Askwith, B
   Hanneghan, MB
AF Mingkhwan, A.
   Fergus, P.
   Abuelma'atti, O.
   Merabti, M.
   Askwith, B.
   Hanneghan, M. B.
TI Dynamic service composition in home appliance networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE networked appliances; service descriptions; dynamic service composition;
   home networking; interoperability; networked entertainment systems;
   on-demand service discovery
ID STANDARDS
AB The proliferation of networked appliances and the complex functions they provide make it ever harder for a specialist, let alone an ordinary home user, to configure them to provide a given service. The use of flexible middleware architectures, combined with application level services will allow for better exploitation of these features both for the benefit of performance and simplicity. For example, a TV, DVD player and radio all have output speakers and are capable of producing sound, however there is no common framework to harness this functionality. In this paper we address this issue and propose a home network architecture that interconnects home appliances and their associated services using descriptive ontologies to guide the composition process itself. In this network, home appliances are interconnected using a Service Integration Controller (SIC), which discovers and dynamically composes the services they provide and efficiently coordinates the communications between all services independent of the protocol being used. The prototype we implemented uses a home entertainment system as a case study and shows that this framework fulfils the requirements of the system design.
C1 King Mongkuts Inst Technol N Bangkok, Fac Ind & Technol Management, Bangkok 10800, Thailand.
   Liverpool John Moores Univ, Sch Comp & Math Sci, Networked Appliances Lab, Liverpool L3 3AF, Merseyside, England.
C3 University of Liverpool; Liverpool John Moores University
RP Mingkhwan, A (corresponding author), King Mongkuts Inst Technol N Bangkok, Fac Ind & Technol Management, 1518 Pibulsongkram Rd, Bangkok 10800, Thailand.
EM anirach@ieee.org; P.Fergus@ljmu.ac.uk; O.E.Abuelma'atti@ljmu.ac.uk;
   M.B.Merabti@ljmu.ac.uk; R.J.Askwith@ljmu.ac.uk; M.B.Hanneghan@ljmu.ac.uk
RI Hanneghan, Martin/B-8426-2009
OI Hanneghan, Martin/0000-0003-1060-7132; Fergus, Paul/0000-0002-7070-4447
CR Abuelma'atti O, 2002, 5TH IEEE INTERNATIONAL WORKSHOP ON NETWORKED APPLIANCES, PROCEEDINGS, P96
   ABUELMAATTI O, 2002, P 3 INT S COMM SYST
   Askwith B, 2002, 5TH IEEE INTERNATIONAL WORKSHOP ON NETWORKED APPLIANCES, PROCEEDINGS, P29
   Bhatti G, 2002, 2002 IEEE 4TH INTERNATIONAL WORKSHOP ON NETWORKED APPLIANCES, PROCEEDINGS, P234, DOI 10.1109/IWNA.2001.980863
   CHEN XS, 2000, PETROLEUM REFINERY E, V30, P1
   Dutta-Roy A, 1999, IEEE SPECTRUM, V36, P26, DOI 10.1109/6.809120
   EVANS D, IEEE ELECT COMMUNICA, V13, P213
   Fergus P., 2003, Proceedings of the Second IASTED International Conference on Information and Knowledge Sharing, P75
   Fergus P, 2005, CONSUM COMM NETWORK, P229
   Fergus P, 2003, LECT NOTES COMPUT SC, V2775, P484
   *HAVI, HAVI AV DIG NETW REV
   Kolberg M, 2003, IEEE COMMUN MAG, V41, P136, DOI 10.1109/MCOM.2003.1244934
   Kolberg M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, CONFERENCE PROCEEDINGS, P2613, DOI 10.1109/ICC.2002.997315
   Kumar R, 2003, FIFTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, PROCEEDINGS, P150, DOI 10.1109/MCSA.2003.1240776
   MAEDCHE A, 2003, P 10 INT C INF TECHN, P124
   Marples D, 2001, IEEE COMMUN MAG, V39, P110, DOI 10.1109/35.968820
   MARSHALL P, IEEE ELECT COMMUNICA, V13, P209
   McBride B., 2001, ICSW, P23
   Miller B., IEEE COMMUN MAG, V39, P104
   Mingkhwan A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P43, DOI 10.1109/ICC.2004.1312449
   MINGKHWAN A, 2002, P EUR WIR FLOR IT
   Minoh M, 2001, IEEE COMMUN MAG, V39, P80, DOI 10.1109/35.956117
   Noy NF, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P450
   NOY NF, 2002, 94305 STANF U
   PAOLUCCI M, 2003, P 12 WORLD WID WEB C, P111
   Paolucci M, 2002, INT SEM WEB C, P333
   PATTENDEN S, 150451 HES
   Rose B, 2001, IEEE COMMUN MAG, V39, P78, DOI 10.1109/35.968816
   SIURU B, POPTRONICS, V1, P41
   *SUN I MICR, JAV MED FRAM
   TALEBBENDIAB YM, P INT C WEB INT HAL, P662
   Zahariadis T, 2002, COMPUT STAND INTER, V24, P425, DOI 10.1016/S0920-5489(02)00068-5
NR 32
TC 11
Z9 18
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 257
EP 284
DI 10.1007/s11042-006-0018-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600004
DA 2024-07-18
ER

PT J
AU Waharte, S
   Boutaba, R
   Iraqi, Y
   Ishibashi, B
AF Waharte, Sonia
   Boutaba, Raouf
   Iraqi, Youssef
   Ishibashi, Brent
TI Routing protocols in wireless mesh networks: challenges and design
   considerations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE wireless mesh networks; routing
AB Wireless Mesh Networks (WMNs) are an emerging technology that could revolutionize the way wireless network access is provided. The interconnection of access points using wireless links exhibits great potential in addressing the "last mile" connectivity issue. To realize this vision, it is imperative to provide efficient resource management. Resource management encompasses a number of different issues, including routing. Although a profusion of routing mechanisms has been proposed for other wireless networks, the unique characteristics of WMNs (e.g., wireless backbone) suggest that WMNs demand a specific solution. To have a clear and precise focus on future research in WMN routing, the characteristics of WMNs that have a strong impact on routing must be identified. Then a set of criteria is defined against which the existing routing protocols from ad hoc, sensor, and WMNs can be evaluated and performance metrics identified. This will serve as the basis for deriving the key design features for routing in wireless mesh networks. Thus, this paper will help to guide and refocus future works in this area.
C1 Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Waharte, S (corresponding author), Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM swaharte@bbcr.uwaterloo.ca; rboutaba@bbcr.uwaterloo.ca;
   iraqi@bbcr.uwaterloo.ca; bkishiba@bbcr.uwaterloo.ca
RI Iraqi, Youssef/A-4009-2015; Boutaba, Raouf/AAT-2801-2020; Boutaba,
   Raouf/G-8483-2017; Iraqi, Youssef/I-9066-2019
OI Iraqi, Youssef/0000-0003-0112-2600; Boutaba, Raouf/0000-0001-7936-6862; 
CR [Anonymous], 2005, IEEE Std 802.11
   [Anonymous], 2000, P 33 ANN HAW INT C S
   [Anonymous], 80216 IEEE
   Basagni Stefano., 1998, Proceedings of the 4th annual ACM/IEEE international conference on Mobile computing and networking, MobiCom '98, P76
   Braginsky David., 2002, PROC 1 ACM INT WORKS, P22, DOI DOI 10.1145/570738.570742
   Chen SG, 1998, IEEE NETWORK, V12, P64, DOI 10.1109/65.752646
   CHIANG CC, 1997, ROUTING MULTICAST MU, V2, P546
   CORSON MS, 1996, P MIL COMM C MILCOM, V1, P224
   De Couto D.S.J., 2003, P 9 ANN INT C MOB CO, P134
   Draves R., 2004, P 2004 C APPL TECHN
   Draves R., 2004, P 10 ANN INT C MOB C, P114, DOI 10.1145/1023720.1023732
   HONG X, 2002, IEEE NETW, V16
   *IEEE, 802151 IEEE
   Intanagonwiwat C, 2003, IEEE ACM T NETWORK, V11, P2, DOI 10.1109/TNET.2002.808417
   JIANG Q, 2004, P 1 CONS COMM NETW C
   Jun JG, 2003, IEEE WIREL COMMUN, V10, P8, DOI 10.1109/MWC.2003.1241089
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   Ko Y.-B., 1998, MobiCom'98. Proceedings of Fourth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P66, DOI 10.1145/288235.288252
   Kulik J, 2002, WIREL NETW, V8, P169, DOI 10.1023/A:1013715909417
   KUROSE JF, 2002, COMPUTER NETWORKING
   Lindsey S, 2002, IEEE T PARALL DISTR, V13, P924, DOI 10.1109/TPDS.2002.1036066
   Manjeshwar A., 2001, P 1 INT WORKSHOP PAR, P2009, DOI DOI 10.1109/IPDPS.2001.925197
   Navas J.C., 1997, PROC ACM MOBICOM97, P66
   NEWPORT C, 2003, TR2003467 DARTM CS D
   Park VD, 1997, IEEE INFOCOM SER, P1405, DOI 10.1109/INFCOM.1997.631180
   Pei G., 1999, WCNC. 1999 IEEE Wireless Communications and Networking Conference (Cat. No.99TH8466), P1538, DOI 10.1109/WCNC.1999.796996
   Pei GY, 2000, MOBIHOC: 2000 FIRST ANNUAL WORKSHOP ON MOBILE AND AD HOC NETWORKING AND COMPUTING, P11, DOI 10.1109/MOBHOC.2000.869208
   Pei GY, 2000, IEEE ICC, P70, DOI 10.1109/ICC.2000.853066
   Perkins C. E., 1994, Computer Communication Review, V24, P234, DOI 10.1145/190809.190336
   Ramjee R, 2002, IEEE ACM T NETWORK, V10, P396, DOI 10.1109/TNET.2002.1012370
   Raniwala A., 2004, SIGMOBILE MOB COMPUT, V8
   Rayner K., 2003, Communications Engineer, V1, P44, DOI 10.1049/ce:20030509
   Schrick B, 2002, IEEE SPECTRUM, V39, P38, DOI 10.1109/MSPEC.2002.1005637
   Servetto SergioD., 2002, P 1 ACM INT WORKSHOP, P12
   Valko A. G., 1999, Computer Communication Review, V29, P50, DOI 10.1145/505754.505758
   Whitehead P, 2000, RAWCON2000: 2000 IEEE RADIO AND WIRELESS CONFERENCE, PROCEEDINGS, P43, DOI 10.1109/RAWCON.2000.881849
   XUE Q, 2002, INT J WIRELESS INFOR, V9, P179, DOI DOI 10.1023/A:1016085627790
   Ye F., 2002, P 8 ANN INT C MOBILE, P148, DOI DOI 10.1145/570645.570664
NR 38
TC 57
Z9 74
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 285
EP 303
DI 10.1007/s11042-006-0012-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600005
DA 2024-07-18
ER

PT J
AU Bouras, C
   Tsiatsos, T
AF Bouras, C.
   Tsiatsos, T.
TI Educational virtual environments: design rationale and architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia application enabling software; virtual environments; distance
   and interactive training; E-learning; educational community
AB The use of collaborative virtual environments in e-learning is one of the most promising uses of virtual reality technology. While much research has been done in the area of networked virtual environments corresponding to the sharing of events, very little research has been done on specific services and functionality. However both the requirements and the kind of the offered services affect significantly the design of a system. In this paper we present the design and implementation of a platform suitable for educational virtual environments, which are collaborative virtual environments aiming at offering collaborative e-learning services to the users. Apart from the platform itself, we present the technological choices, and a new method for sharing virtual environments. Furthermore, we present an e-learning environment to support e-learning services using collaborative virtual environments from both the technical and functional point of view, along with the end-user evaluation results.
C1 Univ Patras, Res Acad Comp Technol Inst, GR-26500 Patras, Greece.
   Univ Patras, Comp Engn & Informat Dept, GR-26110 Patras, Greece.
C3 University of Patras; University of Patras
RP Bouras, C (corresponding author), Univ Patras, Res Acad Comp Technol Inst, Kazantzaki Str, GR-26500 Patras, Greece.
EM bouras@cti.gr
RI Tsiatsos, Thrasyvoulos/W-5386-2019
OI Tsiatsos, Thrasyvoulos/0000-0002-4946-9585
CR Bouras C, 2001, J NETW COMPUT APPL, V24, P175, DOI 10.1006/jnca.2001.0131
   Bouras C., 2002, P 1 INT C WEB BAS LE, P180
   BOURAS C, 2001, P 2001 INT C SOFTW T, V2, P659
   Broll W., 1998, Distributed Systems Engineering, V5, P118, DOI 10.1088/0967-1846/5/3/005
   BROLL W, 1997, P IEEE WE TICE 97 6
   Capin TolgaK., 1999, Avatars in Networked Virtual Environments
   CARLSSON C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P394, DOI 10.1109/VRAIS.1993.380753
   Chee Y.S., 2002, Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community, P687
   DALGARNO B, 2002, EJIST ELECT J, V5
   Dickey M.D., 1999, THESIS OHIO STATE U
   Dillenbourg P., 1999, Collaborative-learning: Cognitive and computational approaches, P1
   Fussell S.R., 2000, P CSCW 2000, P21, DOI DOI 10.1145/358916.358947
   GREENHALGH C, 2000, P WEB3D VRML 2000 5, P149
   KOUBEK A, 2001, T21T22D21TJ005 INVIT
   MOSHMAN D, 1982, DEV REV, V2, P371, DOI 10.1016/0273-2297(82)90019-3
   OLIVEIRA C, 2000, P WORKSH APPL VIRT R
   OLIVEIRA M, 2000, P 3 INT C COLL VIRT, P139
   PANDZIC I, 1998, VIRTUAL WORLDS INTER
   PANDZIC I, 2000, P INT C SOFTW TEL CO, P893
   PANDZIC I, 1996, P FIVE 96 PIS IT
   Redfern S., 2002, Journal of Information Technology Education, V1
   SPELLMAN PJ, 1997, P INT ACM SIGGROUP C, P197
NR 22
TC 22
Z9 25
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 153
EP 173
DI 10.1007/s11042-006-0005-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300004
DA 2024-07-18
ER

PT J
AU Chen, JZ
   Xun, OY
   Zheng, W
   Xu, J
   Zhou, JL
   Yu, SS
AF Chen, Jiazhong
   Xun, Ouyang
   Zheng, Wu
   Xu, Jun
   Zhou, Jingli
   Yu, Shengsheng
TI The application of symmetric orthogonal multiwavelets and prefilter
   technique for image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image compression; multiwavelets; prefilter technique
ID WAVELETS; TRANSFORMS; DESIGN
AB Multiwavelets are the new addition to the body of wavelet theory. There are many types of symmetric multiwavelets such as GHM and CL. However, the matrix filters generating the GHM system multiwavelets do not satisfy the symmetric property. Apparently, GHM cannot solve the edge problem accurately. For this reason, this paper presents some formulas for constructing the symmetric orthogonal matrix filters, which leads the symmetric orthogonal multiwavelets (SOM). Moreover, we analyze the frequency property by vanishing moments and prefilter technology to get a good combining frequency property. To prove the good property of SOM in image compression application, we compared the compression effect with other writers' work, which was in published literature. Extensive experimental results demonstrate that our new symmetric orthogonal matrix filters combining with the prefilter technology and coefficient reorganization exhibit performance equal to, or in several cases superior to the GHM and CL symmetric multiwavelets.
C1 Huazhong Univ Sci & Technol, Comp Sch, Wuhan 430074, Hubei, Peoples R China.
   Univ Derby, Fac Business Law & Comp, Derby DE22 1GB, England.
C3 Huazhong University of Science & Technology; University of Derby
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Comp Sch, Wuhan 430074, Hubei, Peoples R China.
EM chenjz70@263.net
RI Xu, Jun/F-5929-2012; Yu, Sheng-Sheng/AAE-4862-2022
OI Yu, Sheng-Sheng/0000-0003-1304-5630
CR Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Chui CK, 1996, APPL NUMER MATH, V20, P273, DOI 10.1016/0168-9274(95)00111-5
   Cotronei M, 2000, IEEE T IMAGE PROCESS, V9, P184, DOI 10.1109/83.821728
   Drouiche K, 1999, IEEE T SIGNAL PROCES, V47, P2220, DOI 10.1109/78.774765
   GERONIMO JS, 1994, J APPROX THEORY, V78, P373, DOI 10.1006/jath.1994.1085
   GOODMAN TNT, 1993, T AM MATH SOC, V338, P639, DOI 10.2307/2154421
   GOODMAN TNT, 1994, T AM MATH SOC, V342, P307, DOI 10.2307/2154695
   Hardin DP, 1998, IEEE T CIRCUITS-II, V45, P1106, DOI 10.1109/82.718820
   Hong D, 2000, COMPUT MATH APPL, V40, P1153, DOI 10.1016/S0898-1221(00)00229-7
   Jia RQ, 1998, MATH COMPUT, V67, P1533, DOI 10.1090/S0025-5718-98-00985-5
   Lin G, 2000, IEEE T IMAGE PROCESS, V9, P270, DOI 10.1109/83.821740
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 1999, IEEE T IMAGE PROCESS, V8, P1161, DOI 10.1109/83.784429
   STRANG G, 1995, IEEE T SIGNAL PROCES, V43, P108, DOI 10.1109/78.365291
   Strela V, 1999, IEEE T IMAGE PROCESS, V8, P548, DOI 10.1109/83.753742
   Tham JY, 2000, IEEE T SIGNAL PROCES, V48, P457, DOI 10.1109/78.823972
   Xia XG, 1998, IEEE T SIGNAL PROCES, V46, P1558, DOI 10.1109/78.678469
   Xia XG, 1996, IEEE T SIGNAL PROCES, V44, P25, DOI 10.1109/78.482009
NR 18
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 175
EP 189
DI 10.1007/s11042-006-0006-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300005
DA 2024-07-18
ER

PT J
AU Karpouzis, K
   Moschovitis, G
   Ntalianis, K
   Ioannou, S
   Kollias, S
AF Karpouzis, K
   Moschovitis, G
   Ntalianis, K
   Ioannou, S
   Kollias, S
TI Web access to large audiovisual assets based on user preferences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia databases; web access; video summarization; dynamic search;
   user profiling; query expansion
AB Current multimedia databases contain a wealth of information in the form of audiovisual as well as text data. Even though efficient search algorithms have been developed for either media, there still exists the need for abstract presentation and summarization of the results of database users' queries. Moreover, multimedia retrieval systems should be capable of providing the user with additional information related to the specific subject of the query, as well as suggest other topics which could be identified to attract the interest of users with a similar profile. In this paper, we present solutions to these issues, giving as an example an integrated architecture we have developed, along with notions that support efficient and secure Internet access to audiovisual/video databases. Segmentation of each video in shots is followed by shot classification in a number of predetermined categories. Generation of users' profiles according to the categories, enhanced by relevance feedback, permits an efficient presentation of retrieved video shots or characteristic frames in terms of the user interest in them. Moreover, this clustering scheme assists the notion of 'lateral' links that enable the user to continue retrieval with data of similar nature or content to those already returned. Furthermore, user groups are formed and modeled by registering actual preferences and practices. This enables the system to 'predict' information that is possibly relevant to the user's interest and present it along with the returned results. The concepts utilized in this system can be smoothly integrated in MPEG-7 compatible multimedia database systems.
C1 Natl Tech Univ Athens, Dept Elect & Comp Engn, Image Video & Multimedia Lab, Athens 15780, Greece.
C3 National Technical University of Athens
RP Karpouzis, K (corresponding author), Natl Tech Univ Athens, Dept Elect & Comp Engn, Image Video & Multimedia Lab, Heroon Polytech 9, Athens 15780, Greece.
EM kkarpou@image.ece.ntua.gr
RI Karpouzis, Kostas/AAQ-8018-2020; Kollias, Stefanos/ACY-7285-2022;
   Karpouzis, Kostas/A-1792-2008
OI Karpouzis, Kostas/0000-0002-4615-6751; Kollias,
   Stefanos/0000-0003-2899-0598
CR Akrivas G, 2000, IEEE MEDITERR ELECT, P677
   Avrithis YS, 1999, COMPUT VIS IMAGE UND, V75, P3, DOI 10.1006/cviu.1999.0761
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Basu C, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P714
   DOULAMIS A, P IEEE INT C MULT CO, V2, P954
   Frakes W.B., 1992, INFORM RETRIEVAL DAT, P131
   Haykin S., 1998, NEURAL NETWORKS COMP
   HILL, 1995, P CHII 95 C HUM FACT
   *IST PROGR, 2001, UN INT ACC HET AUD C
   Koenen R, 2000, SIGNAL PROCESS-IMAGE, V16, P5, DOI 10.1016/S0923-5965(00)00014-X
   KOLLIAS S, 2001, P INT WORKSH VER LOW
   KOTSANIS Y, 1987, LIT LINGUISTIC COMPU, V2
   Montebello M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P361, DOI 10.1145/290941.291052
   Moukas A., 1998, Autonomous agents and multiagent systems, V1, P59
   Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8
   Rivest R.L., 1321 RFC
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Salembier P, 2000, SIGNAL PROCESS-IMAGE, V16, P211, DOI 10.1016/S0923-5965(00)00026-6
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sanderson M., 2000, Information Retrieval, V2, P47, DOI 10.1023/A:1009933700147
   SHARDANAND U, 1995, P CHI 95 DENV CO MAY
   SIMPSON W, 1994, PPP CHALLENGE HANDSH
   Tsapatsoulis N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P247, DOI 10.1109/ICIP.2000.899289
   Tsapatsoulis N, 2001, PATTERN ANAL APPL, V4, P93, DOI 10.1007/PL00014577
   YAN TW, 1995, PROCEEDINGS OF THE 1995 USENIX TECHNICAL CONFERENCE, P177
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
NR 28
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2004
VL 22
IS 3
BP 215
EP 234
DI 10.1023/B:MTAP.0000017029.79209.7b
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 776VC
UT WOS:000189139200001
DA 2024-07-18
ER

PT J
AU Varlamis, I
   Vazirgiannis, M
   Lazaridis, I
   Papageorgiou, M
   Panayiotopoulos, T
AF Varlamis, I
   Vazirgiannis, M
   Lazaridis, I
   Papageorgiou, M
   Panayiotopoulos, T
TI Distributed virtual reality authoring interfaces for the WWW: The
   VR-Shop case
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE virtual reality; VRML; 3D world authoring; WWW; e-commerce
AB Electronic commerce is emerging as an important domain of integration and enhancement of more specific technologies and research efforts. It is clear that the role of WWW in this context is a cornerstone as the medium of information dissemination. A trend in e-commerce is to provide to the potential customers the ability to view and "try" the products in a persuasive 3D representation. We have designed and implemented a system for WWW enabled interactive design & visualization of a room, definition of pieces of furniture and placement of domestic appliances. The system conveys a generic approach for distributed creation and update of virtual worlds as means of interaction and information dissemination in an e-commerce context.
C1 Athens Univ Econ & Business, Dept Informat, Athens 10434, Hellas, Greece.
   Univ Calif Irvine, Irvine, CA USA.
   Univ Piraeus, Dept Informat, Hellas, Greece.
C3 Athens University of Economics & Business; University of California
   System; University of California Irvine; University of Piraeus
RP Varlamis, I (corresponding author), Athens Univ Econ & Business, Dept Informat, Patis 76, Athens 10434, Hellas, Greece.
RI Panayiotopoulos, Themis/AAR-2094-2021; Varlamis, Iraklis/Q-9191-2018
OI Varlamis, Iraklis/0000-0002-0876-8167
CR CREMER JF, 1994, P IMAGE 7 C TUCS AZ
   Del Bimbo A., 1995, IEEE T VISUALIZATION, V1
   DIAZ A, 1999, 2 WORKSH HYP DEV DES
   Dollner J, 1997, J VISUAL COMP ANIMAT, V8, P33, DOI 10.1002/(SICI)1099-1778(199701)8:1<33::AID-VIS153>3.0.CO;2-Z
   Erwig M., 1999, GeoInformatica, V3, P269, DOI 10.1023/A:1009805532638
   MELSTER R, 1998, 199815 TU BERL
   NAJORK M, 1995, IEEE T VISUALISATION, V1
   VAKALOUDIS A, 1998, CHOR WORKSH AALB DEN
NR 8
TC 10
Z9 10
U1 0
U2 13
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2004
VL 22
IS 1
BP 5
EP 30
DI 10.1023/B:MTAP.0000008657.07799.b0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 754MK
UT WOS:000187320800001
DA 2024-07-18
ER

PT J
AU Curran, K
   Parr, G
AF Curran, K
   Parr, G
TI An end to end adaptable architecture for streaming media over IP
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE middleware; QoS; adaptive protocol stacks
AB Wireless networks differ in bandwidth, size and access costs each requiring a set of protocol functions to enable devices to communicate efficiently. Portable multimedia devices such as PDA's and laptops will also vary greatly however all these devices will require optimal multimedia delivery. A traditional method is for sources to limit their transmission rates to accommodate lower bandwidth links, even though high-bandwidth connectivity is available to many participants. This method similar to others does not provide optimum throughput to heterogeneous clients due to its quest for a common denominator bandwidth. In addition, due to the divergence of users and applications, traditional protocol stacks are frequently enriched with additional functionality such as transport protocol functionality, synchronization and presentation coding which can lead to a performance bottleneck due to the insufficient processing power and memory of portable devices.
   Micro-protocols attempt to eradicate this bottleneck by optimising the protocol stack to the functionality that is actually required by the application. A side effect of this is that it allows a device such as a PDA to offer protocol functions, which would not normally be available due to its memory constraints achievable by downloading necessary micro-protocols for new environments and discarding previous micro-protocols. Multicast media groups overcome the heterogeneous client problem where clients subscribe to different quality of services in accordance with resource availability and move between groups according to bandwidth availability.
   Chameleon is 100% Java middleware for multimedia streaming to heterogeneous mobile clients, which allows the dynamic configuration of protocols with respect to application requirements and available network resources. We evaluate the dynamic reconfigurability of the middleware in order to demonstrate runtime adaptation. We especially concentrate on the primary quality transformation technique (PQT) of the middleware which enables clients to subscribe to media groups in accordance with available resources and network capacity.
C1 Univ Ulster, No Ireland Knowledge Engn Lab, Internet Technol Res Grp, Coleraine BT52 1SA, Londonderry, North Ireland.
C3 Ulster University
RP Univ Ulster, No Ireland Knowledge Engn Lab, Internet Technol Res Grp, Magee Campus, Coleraine BT52 1SA, Londonderry, North Ireland.
EM kj.curran@ulster.ac.uk; gp.parr@ulster.ac.uk
RI Curran, Kevin/AAC-4865-2019
OI Curran, Kevin/0000-0001-5237-5355; Parr, Gerard/0000-0002-9365-9132
CR CLARK DD, 1990, P ACM S COMM ARCH PR, P200
   GOLM M, 1997, STJA 97 ERF GERM
   Heinzelman W.B., 2000, Ph.D. thesis
   HUTCHINSON NC, 1991, IEEE T SOFTWARE ENG, V17, P64, DOI 10.1109/32.67579
   Joseph AD, 1997, IEEE T COMPUT, V46, P337, DOI 10.1109/12.580429
   KOJO M, 1997, IEEE J SELECTED AREA, V15
   MAFFEIS S, 1997, BUILDING RELIABLE DI, V3
   MODIANO E, 1999, US WIRELESS NETWORKS, V5
   Parr G, 2000, COMMUN ACM, V43, P103, DOI 10.1145/336460.336486
   POGER E, 1997, P USENIX S INT TECHN
   *SOC CABL TEL ENG, 2000, DSS0001 SCTE
   van Steen M, 1999, IEEE CONCURR, V7, P70, DOI 10.1109/4434.749137
   ZENEL B, 1997, P MOBICOM 97 BUD HUN
NR 13
TC 0
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2003
VL 20
IS 3
BP 225
EP 236
DI 10.1023/A:1024020221086
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 686QF
UT WOS:000183331900002
DA 2024-07-18
ER

PT J
AU Sahoo, PK
   Sheu, JP
AF Sahoo, PK
   Sheu, JP
TI An efficient channel allocation technique for multiple videos-on-demand
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE broadcasting; video-on-demand; channel allocation
ID SERVICE
AB There are several broadcasting protocols for video-on-demand (VOD). Most of these protocols are tailored to handle the distribution of single video for a specific range of request arrival rates. In order to distribute multiple videos, broadcasting protocols like fast broadcasting (FB), new pagoda broadcasting (NPB) and universal distribution (UD) require more channels that are proportional to the number of hot videos to be broadcast. We present here an efficient broadcasting protocol in which, channel numbers can be reduced when multiple videos are broadcast either simultaneously or asynchronously. During the low to moderate request rates, our protocol performs best as similar to other reactive protocols and saves bandwidth and requires lesser number of channels as compared to other proactive or reactive protocols.
C1 Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 32054, Taiwan.
C3 National Central University
RP Sahoo, PK (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 32054, Taiwan.
EM sheujp@csie.ncu.edu.tw
OI Sahoo, Prasan Kumar/0000-0003-3496-1195
CR Carter SR, 2001, INT CON DISTR COMP S, P657
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   DAN A, 1995, J PARALLEL DISTR COM, V30, P168, DOI 10.1006/jpdc.1995.1135
   EAGER DL, 1998, P 4 INT WORKSH MULT, P18
   Golubchik L, 1996, MULTIMEDIA SYST, V4, P140, DOI 10.1007/s005300050019
   Hua K., 1997, PROC SIGCOMM, P89
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   JUHN LS, 1997, REAL TIME COMPUTING, P237
   Pâris JF, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P189, DOI 10.1145/319463.319600
   PARIS JF, 1999, P 7 INT C COMP COMM, P690
   PARIS JF, 2000, P INT C MULT EXP 200, P657
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   WONG JW, 1988, P IEEE, V76, P1566, DOI 10.1109/5.16350
NR 13
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2003
VL 20
IS 1
BP 67
EP 81
DI 10.1023/A:1023422516947
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 671JW
UT WOS:000182462500005
DA 2024-07-18
ER

PT J
AU Albusac, J
   Herrera, V
   Schez-Sobrino, S
   Grande, R
   Monekosso, DN
   Vallejo, D
AF Albusac, Javier
   Herrera, Vanesa
   Schez-Sobrino, Santiago
   Grande, Ruben
   Monekosso, Dorothy N.
   Vallejo, David
TI Innovative haptic-based system for upper limb rehabilitation in visually
   impaired individuals: a multilayer approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Upper-limb rehabilitation; Visual impairments; Haptic feedback;
   Vibration guidance; Spinal cord injuries; Stroke
ID TECHNOLOGIES; NAVIGATION; PEOPLE
AB The integration of technology in healthcare has revolutionized physical rehabilitation of patients affected by neurological conditions, such as spinal cord injuries and strokes. However, a significant gap remains in addressing the needs of the visually impaired, as most current solutions are visually-centric. This paper presents a novel haptic-based system tailored for the visually impaired that aims to bridge this gap in upper limb rehabilitation. The system is underpinned by a multi-layer architecture that allows both patient guidance during rehabilitation and the definition and analysis of exercises by the therapist. The architecture design includes functionality to track the user's body by means of natural user interfaces, to register the user's movement, and to guide them through the vibrations of the haptic glove or through voice commands. Thus, the proposed solution empowers visually impaired individuals to perform therapist-defined hand exercises autonomously, fostering independence and optimizing therapeutic resources. The system captures detailed kinematic data, offering therapists a comprehensive insight into the patient's exercise execution. To assess the system's functionality, a pilot trial was conducted. This study also allowed us to compare the similarity of exercise performance under vibration-based guidance to the exercises defined by the therapist with that of verbal guidance. The results highlighted a significant increase in similarity to therapist-defined exercises when using the vibration-based guidance facilitated by the designed haptic glove.
C1 [Albusac, Javier; Herrera, Vanesa; Schez-Sobrino, Santiago; Grande, Ruben; Vallejo, David] Univ Castilla La Mancha, Dept Informat Technol & Syst, P Univ 4, Ciudad Real 13071, Spain.
   [Monekosso, Dorothy N.] Univ Durham, Dept Comp Sci, Stockton Rd, Durham DH1 3LE, England.
C3 Universidad de Castilla-La Mancha; Durham University
RP Vallejo, D (corresponding author), Univ Castilla La Mancha, Dept Informat Technol & Syst, P Univ 4, Ciudad Real 13071, Spain.
EM JavierAlonso.Albusac@uclm.es; Vanesa.Herrera@uclm.es;
   Santiago.Sanchez@uclm.es; Ruben.Grande@uclm.es;
   Dorothy.Monekosso@durham.ac.uk; David.Vallejo@uclm.es
OI Schez-Sobrino, Santiago/0000-0001-6620-1719; Herrera Tirado,
   Vanesa/0000-0002-6187-4794; Vallejo, David/0000-0002-6001-7192; Albusac
   Jimenez, Javier Alonso/0000-0003-1889-3065
FU Ministerio de Ciencia e Innovacin [MCIN/AEI/10.13039/501100011033,
   PID2020-117361RB-C21]; Spanish Ministry of Science and Innovation
   [2023-GRIN-34400]; University of Castilla-La Mancha (Spain)
FX This work has been founded by the Spanish Ministry of Science and
   Innovation MCIN/AEI/10.13039/501100011033 under the Research Project:
   Platform for Upper Extremity Rehabilitation based on Immersive Virtual
   Reality (Rehab-Immersive), PID2020-117361RB-C21, and by the University
   of Castilla-La Mancha (Spain), thanks to the call for proposals to
   support research groups (Ref. 2023-GRIN-34400).
CR Barcali E, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12146890
   Bravo VP, 2022, MED BIOL ENG COMPUT, V60, P1239, DOI 10.1007/s11517-022-02544-w
   Budrionis A, 2022, ASSIST TECHNOL, V34, P178, DOI 10.1080/10400435.2020.1743381
   Cardillo E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111281
   Carpinello A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112211053
   Creed C, 2024, UNIVERSAL ACCESS INF, V23, P59, DOI 10.1007/s10209-023-00969-0
   Debnath B, 2022, MULTIMEDIA SYST, V28, P209, DOI 10.1007/s00530-021-00815-4
   Demmin DL, 2020, CLIN OPHTHALMOL, V14, P4229, DOI 10.2147/OPTH.S258783
   Fernandes H, 2019, UNIVERSAL ACCESS INF, V18, P155, DOI 10.1007/s10209-017-0570-8
   García FM, 2023, IEEE ACCESS, V11, P59016, DOI 10.1109/ACCESS.2023.3285420
   Gmez-Portes C, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9121427
   Guerrón NE, 2020, INT J HUM-COMPUT ST, V133, P13, DOI 10.1016/j.ijhcs.2019.08.004
   Hao J, 2022, ARCH PHYS MED REHAB, V103, P523, DOI 10.1016/j.apmr.2021.06.024
   Herrera V, 2023, ICEIS 2, P231
   Herrera V, 2023, SOFTWAREX, V23, DOI 10.1016/j.softx.2023.101412
   Hodkin EF, 2018, IEEE T NEUR SYS REH, V26, P1067, DOI 10.1109/TNSRE.2018.2816238
   Howard J, 2022, DISABIL REHABIL-ASSI, V17, P390, DOI 10.1080/17483107.2020.1788181
   Jeong GY, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071070
   Kang Y, 2018, J NEURORESTORATOLOGY, V6, P1, DOI 10.2147/JN.S143236
   Katzschmann RK, 2018, IEEE T NEUR SYS REH, V26, P583, DOI 10.1109/TNSRE.2018.2800665
   Klinker K, 2020, INFORM SYST FRONT, V22, P1419, DOI 10.1007/s10796-019-09937-7
   Kuriakose B, 2022, IETE TECH REV, V39, P3, DOI 10.1080/02564602.2020.1819893
   de Araújo AVL, 2019, BIOMED RES INT-UK, V2019, DOI 10.1155/2019/7106951
   Lamash L, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Manjari K., 2020, INTERNET THINGS-NETH, V11, DOI [DOI 10.1016/j.iot.2020.100188, 10.1016/j.iot.2020.100188]
   Martiniello N, 2022, ASSIST TECHNOL, V34, P34, DOI 10.1080/10400435.2019.1682084
   Mekki M, 2018, NEUROTHERAPEUTICS, V15, P604, DOI 10.1007/s13311-018-0642-3
   Meshram VV, 2019, IEEE T HUM-MACH SYST, V49, P449, DOI 10.1109/THMS.2019.2931745
   Okonji PE, 2019, ASSIST TECHNOL, V31, P209, DOI 10.1080/10400435.2017.1421594
   Parisi A, 2022, J CLIN MED, V11, DOI 10.3390/jcm11216324
   Pereira MF, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201789
   Hassler AP, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0747-6
   dos Santos ADP, 2022, DISABIL REHABIL-ASSI, V17, P152, DOI 10.1080/17483107.2020.1768308
   Quero LC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030297
   Real S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153404
   Ren LM, 2019, IEEE ACCESS, V7, P77702, DOI 10.1109/ACCESS.2019.2922708
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Schez-Sobrino S, 2020, IEEE ACCESS, V8, P91424, DOI 10.1109/ACCESS.2020.2995119
   Spooren AIF, 2011, SPINAL CORD, V49, P1049, DOI 10.1038/sc.2011.54
   Tölgyessy M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020413
   World Health Organization, 2020, The top 10 causes of death: WHO
   Zhao Q, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-021-01607-7
NR 42
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17892-4
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hadi, S
   Shahbahrami, A
   Azgomi, H
AF Hadi, Soheib
   Shahbahrami, Asadollah
   Azgomi, Hossien
TI A video codec based on background extraction and moving object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video compression; Video surveillance; Background generation; Background
   extraction; Object detection; Object extraction
ID MULTISCALE STRUCTURAL SIMILARITY; MOTION
AB Cameras are the primary data sources in video surveillance systems and produce massive data every second. Video surveillance is an extremely beneficial functionality brought to us by modern technology. An essential application of video surveillance in public security is facilitating the observation and analysis of events. Video surveillance systems require high-bandwidth media to transfer, high-capacity media to store, and high-performance hardware to process data. Consequently, these systems impose many costs on organizations. Video compression techniques can reduce the amount of data transferred or stored by surveillance systems and, as a result, lower the costs. Fixed CCTV cameras are the largest category of surveillance cameras. Backgrounds in these videos are typically constant and saving them for every frame is redundant. Therefore, a background-aware approach can achieve a higher compression rate in compressing these cameras' videos than conventional approaches. This paper proposes a video codec for fixed cameras based on background extraction and moving-object detection algorithms. By background extraction, the pure backgrounds of the video are generated and stored in JPEG format for consecutive time intervals. By moving-object detection, the objects, and their coordinates are extracted in each frame using YOLOv7 and stored in JPEG format separately from the backgrounds. At the decoder side, each frame is built up using the generated background and detected objects which have been stored and transmitted as JPEG files. The evaluation of the proposed method on an appropriate set of videos from CDnet2014 and EWAP datasets shows that the proposed method can compress the videos effectively by significant compression ratios up to 46.76x, while the worst quality loss resulting from the compression is 0.99 according to the SSIM measure.
C1 [Hadi, Soheib; Shahbahrami, Asadollah; Azgomi, Hossien] Islamic Azad Univ, Dept Comp Engn, Rasht Branch, Rasht, Iran.
   [Shahbahrami, Asadollah] Univ Guilan, Fac Engn, Dept Comp Engn, Rasht, Iran.
C3 Islamic Azad University; University of Guilan
RP Shahbahrami, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Rasht Branch, Rasht, Iran.; Shahbahrami, A (corresponding author), Univ Guilan, Fac Engn, Dept Comp Engn, Rasht, Iran.
EM shahbahrami@guilan.ac.ir
RI Shahbahrami, Asadollah/ABD-2432-2020
OI Shahbahrami, Asadollah/0000-0002-5195-1688
CR Alipour Panteha., 2022 International Conference on Machine Vision and Image Processing (MVIP), V2022, P1, DOI DOI 10.1109/MVIP53647.2022.9738762
   [Anonymous], Image I and Video Compression
   [Anonymous], H.263: Video coding for low bit rate communication
   [Anonymous], H.261: Video codec for audiovisual services at p x 64 kbit/s
   [Anonymous], ISO/IEC ISO/IEC JTC 1: Information Technology
   Babu RV, 2006, ROB VIS 2006 9 INT C, P1, DOI [10.1109/ICARCV.2006.345186, DOI 10.1109/ICARCV.2006.345186]
   Becker S, 2019, LECT NOTES COMPUT SC, V11131, P138, DOI 10.1007/978-3-030-11015-4_13
   Bhojani DR, 2020, Hybrid video compression standard
   Bidwe RV, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6020044
   Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Bouwmans T, 2014, Background modeling and foreground detection for video surveillance
   Bull D.R, 2021, Intelligent image and video compression: communicating pictures
   Channappayya S, 2008, Encyclopedia of Multimedia, P832, DOI [10.1007/978-0-387-78414-4_67, DOI 10.1007/978-0-387-78414-4_67]
   Chen Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102685
   Chu WQ, 2018, NEUROCOMPUTING, V275, P1035, DOI 10.1016/j.neucom.2017.09.048
   De Gregorio M, 2015, LECT NOTES COMPUT SC, V9281, P493, DOI 10.1007/978-3-319-23222-5_60
   Dhungel Prasanga., 2020, Journal of Artificial Intelligence and Capsule Networks, V2, P131, DOI 10.36548/jaicn.2020.2.006
   Ding DD, 2021, P IEEE, V109, P1494, DOI 10.1109/JPROC.2021.3059994
   Dominguez HO, 2018, Versatile Video Coding: Latest Advances in Video Coding Standards, pi
   Fu ZH, 2019, IEEE T IMAGE PROCESS, V28, P6077, DOI 10.1109/TIP.2019.2922095
   Gonzalez RC, Digital Image Processing
   Haddad S, Situation-Aware Pedestrian Trajectory Prediction with Spatio-Temporal Attention Model, DOI [10.3217/978-3-85125-652-9, DOI 10.3217/978-3-85125-652-9]
   Hindawi AD, Encryption and fast transmission algorithm based on surveillance video, DOI [10.1155/2020/8842412, DOI 10.1155/2020/8842412]
   ITU-T and ISO/IEC JTC 1, ITU-T Rec. H.262 and ISO/IEC 13818-2 (MPEG-2 Video)
   ITU-T and ISO/IEC JTC 1, 2012, Advanced Video Coding for Generic Audiovisual Services
   Joint Collaborative Team on Video Coding (JCT-VC), 2019, of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 ISO/IEC 23008-2 and ITU-T Recommendation H.265, High Efficiency Video Coding (HEVC)
   Kalsotra R, 2022, VISUAL COMPUT, V38, P4151, DOI 10.1007/s00371-021-02286-0
   Kalsotra R, 2019, IEEE ACCESS, V7, P59143, DOI 10.1109/ACCESS.2019.2914961
   Kathuria A, 2018, Medium
   Kumar Ashwani, 2020, Procedia Computer Science, V171, P2610, DOI 10.1016/j.procs.2020.04.283
   Kumar S., 2016, Perspect. Sci., V8, P317
   Kusuma H, 2015, Int J Innovative Res Sci Eng Technol, V4, P8, DOI [10.15680/IJIRSET.2015.040613, DOI 10.15680/IJIRSET.2015.040613]
   Kwon O, 2014, INT J INFORM MANAGE, V34, P387, DOI 10.1016/j.ijinfomgt.2014.02.002
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Laugraud B, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070086
   Laugraud B, 2017, PATTERN RECOGN LETT, V96, P12, DOI 10.1016/j.patrec.2016.11.022
   Laugraud B, 2016, INT C PATT RECOG, P107, DOI 10.1109/ICPR.2016.7899617
   Nasr MAS, 2017, J KING SAUD UNIV-COM, V29, P399, DOI 10.1016/j.jksuci.2016.02.004
   Nilsson F, 2017, Intelligent network video: understanding modern video surveillance systems, V2nd
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-176
   Perumal B, 2016, FIRST INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING, TECHNOLOGY AND SCIENCE - ICETETS 2016
   Qiu S, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8842412
   Reddy V, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/164956
   Redmon J, 2016, Arxiv, DOI arXiv:1506.02640
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Savakis A, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P597, DOI 10.1109/SPIN.2018.8474279
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P15, DOI 10.1007/978-3-319-07386-6_3
   Shi Y.-Q., 2019, Image and Video Compression for Multimedia Engineering: Fundamentals, Algorithms, and Standards, V3rd
   Subudhi BN, 2019, MULTIMED TOOLS APPL, V78, P26129, DOI 10.1007/s11042-019-07793-w
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang HC, 2018, IEEE T CIRC SYST VID, V28, P3127, DOI 10.1109/TCSVT.2017.2733623
   Wang SH, 2022, MULTIMED TOOLS APPL, V81, P42713, DOI 10.1007/s11042-022-13484-w
   Wang SY, 2016, MATEC WEB CONF, V56, DOI 10.1051/matecconf/20165602008
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu LR, 2021, IEEE T CIRC SYST VID, V31, P2711, DOI 10.1109/TCSVT.2020.3027741
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P769, DOI 10.1109/TIP.2013.2294549
   Zhao Y, 2023, IEEE T BROADCAST, V69, P966, DOI 10.1109/TBC.2023.3280039
   Zheng WB, 2020, NEUROCOMPUTING, V394, P178, DOI 10.1016/j.neucom.2019.04.088
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
   Zuo JH, 2020, MULTIMED TOOLS APPL, V79, P29663, DOI 10.1007/s11042-020-09530-0
NR 62
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17933-y
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500010
DA 2024-07-18
ER

PT J
AU Bao, Y
   Wen, HB
   Zhang, BQ
AF Bao, Yong
   Wen, Haibiao
   Zhang, Baoqing
TI Semantic segmentation of large-scale point clouds with neighborhood
   uncertainty
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Point cloud; Segmentation; Uncertainty
AB Large-scale point cloud segmentation is one of the important research directions in the field of computer vision, aiming at segmenting 3D point cloud data into parts with semantic meaning, which is widely used in the fields of robot perception, automated driving, and virtual reality. In practical applications, intelligences often face various uncertainties such as sensor noise, missing data, and uncertain model parameter estimation. However, many current research works do not consider the effects of these uncertainties, which can cause the model to overfit the noisy data and thus affect the model performance. In this paper, we propose a point cloud segmentation method with domain uncertainty that can greatly improve the robustness of the model to noise. Specifically, we first compute the neighborhood uncertainty, which is more reflective of the semantics of a local region than the prediction of a single point, which will reduce the impact of noise. Next, we fuse the uncertainty into the objective function, which allows the model to focus more on relatively deterministic data. Finally, we validate on the large-scale datasets S3DIS and Toronto3D, and the segmentation performance is substantially improved in both cases.
C1 [Bao, Yong; Zhang, Baoqing] Nanning Univ, 8,Longting Rd, Nanning 541699, Peoples R China.
   [Wen, Haibiao] Guangzhou Coll Technol & Business, 166 Sanhua Rd,Leping Town, Foshan 510850, Peoples R China.
C3 Nanning University
RP Wen, HB (corresponding author), Guangzhou Coll Technol & Business, 166 Sanhua Rd,Leping Town, Foshan 510850, Peoples R China.
EM 864549591@qq.com; 845488427@qq.com; 359073191@qq.com
OI bao, yong/0009-0003-4337-0386
FU Natural Science Project of China for Young and middle-aged; 
   [2022KY1786]
FX This research was funded by the Natural Science Project of China for
   Young and middle-aged(No.2022KY1786).
CR Blanc T, 2020, NAT METHODS, V17, P1100, DOI 10.1038/s41592-020-0946-1
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chenfeng Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P1, DOI 10.1007/978-3-030-58604-1_1
   Cheng ZY, 2024, Arxiv, DOI arXiv:2304.14614
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   Cui YM, 2023, Arxiv, DOI arXiv:2305.07814
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Cui YM, 2021, NEUROCOMPUTING, V432, P300, DOI 10.1016/j.neucom.2020.12.067
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Hackel T, 2017, ISPRS ANN PHOTOGRAMM, P91, DOI 10.5194/isprs-annals-IV-1-W1-91-2017
   Huang SS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3453485
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Lei H, 2021, IEEE T PATTERN ANAL, V43, P3664, DOI 10.1109/TPAMI.2020.2983410
   Li Y., 2018, arXiv
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Lin YQ, 2020, PROC CVPR IEEE, P4292, DOI 10.1109/CVPR42600.2020.00435
   Liu D, 2020, AAAI C ARTIFICIAL IN
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Mildenhall B, 2020, Arxiv, DOI [arXiv:2003.08934, DOI 10.48550/ARXIV.2003.08934]
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Qingyong Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11105, DOI 10.1109/CVPR42600.2020.01112
   Savarese S., 2017, Joint 2d-3d-semantic data for indoor scene understanding
   Sirohi K, 2023, IEEE INT CONF ROBOT, P8277, DOI 10.1109/ICRA48891.2023.10160355
   Tan WK, 2020, IEEE COMPUT SOC CONF, P797, DOI 10.1109/CVPRW50498.2020.00109
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470
   Wang WG, 2022, Arxiv, DOI [arXiv:2210.00911, DOI 10.48550/ARXIV.2210.00911]
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu X., 2022, arXiv
   Yan LQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2220, DOI 10.1109/ICASSP39728.2021.9414517
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
NR 35
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17814-4
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200005
DA 2024-07-18
ER

PT J
AU Cao, G
AF Cao, Guo
TI A novel similarity measure between picture fuzzy sets based on
   transformation techniques and its applications in mobile multimedia
   healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile multimedia healthcare; Right-angled triangular-based pyramid
   fuzzy numbers; Picture fuzzy numbers; Picture fuzzy sets; Similarity
   measures
ID ATTRIBUTE DECISION-MAKING; SIMPLIFIED NEUTROSOPHIC SETS; DISTANCE
   MEASURE; AGGREGATION OPERATORS; CROSS-ENTROPY; INFORMATION; MANAGEMENT;
   FRAMEWORK; SELECTION; MODEL
AB With the development of mobile multimedia devices, mobile multimedia based mobile health healthcare has become a popular style. However, multimedia mobile health healthcare is not an easy task as it involves human decision making which is imprecise, vague and uncertain. To handle the uncertainty of information, picture fuzzy sets (PFSs) is a good choice. As one of the important topics in PFSs, the similarity measure between PFS has been assessed by several studies within the literature. Most existing measures of PFSs, however, cannot completely meet the properties of similarity measures in some special cases. In this paper, on the basic of the transformed right-angled triangular-based pyramids, a novel similarity measure is developed to handle pattern recognition problems. First, we originally present the conversion techniques between picture fuzzy numbers (PFNs) and their corresponding right-angled triangular-based pyramids fuzzy numbers. Then, we establish a new similarity measure for PFNs on the basic of the barycenter points of the corresponding right-angled triangular-based pyramids transformed from PFNs. Moreover, a comparison of different algorithms as regards PFSs and Neutrosophic sets (NSs) is performed to test performance of the established similarity measure within picture fuzzy environment. Finally, a new proposed TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) method is used to identifying the ranking order of the determinants of adoption of mobile multimedia healthcare services for the aged. The findings indicate that the established algorithm can fully fulfill the conditions of similarity measure, produce more reasonable and creditable results, and perform well in complex situations.
C1 [Cao, Guo] Changzhou Inst Technol, Res Inst Digital Commerce & Smart Logist, Changzhou 213032, Peoples R China.
C3 Changzhou Institute of Technology
RP Cao, G (corresponding author), Changzhou Inst Technol, Res Inst Digital Commerce & Smart Logist, Changzhou 213032, Peoples R China.
EM caog@czu.cn
FU National Social Science Fund of China [21BGL036]; National Social
   Science Fund of China
FX The author is very grateful to the anonymous reviewers and the editor
   for their insightful and constructive suggestions that have led to an
   improved version of this work. And this research was partially supported
   by The project of The National Social Science Fund of China (NO.
   21BGL036) during which the study was completed.
CR Akram M, 2020, COMPUT APPL MATH, V39, DOI 10.1007/s40314-020-01251-2
   Alkan N, 2023, APPL SOFT COMPUT, V145, DOI 10.1016/j.asoc.2023.110579
   [Anonymous], 2013, Neutrosophic Sets Syst
   Ashraf S, 2019, INT J FUZZY SYST, V21, P2448, DOI 10.1007/s40815-019-00681-3
   Ashraf Z, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105529
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Boran FE, 2014, INFORM SCIENCES, V255, P45, DOI 10.1016/j.ins.2013.08.013
   Cao G, 2020, INT J COMPUT COMMUN, V15, DOI 10.15837/ijccc.2020.1.3762
   Cao G, 2023, J INTELL FUZZY SYST, V44, P10213, DOI 10.3233/JIFS-224314
   Chen SM, 2016, INFORM SCIENCES, V343, P15, DOI 10.1016/j.ins.2016.01.040
   Chen SM, 2015, INFORM SCIENCES, V291, P96, DOI 10.1016/j.ins.2014.07.033
   Cui WH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10060225
   Cuong B.C., 2014, J. Compt. Sci. Cybern., V30, P409, DOI DOI 10.15625/1813-9663/30/4/5032
   De SK, 2001, FUZZY SET SYST, V117, P209, DOI 10.1016/S0165-0114(98)00235-8
   Dügenci M, 2016, APPL SOFT COMPUT, V41, P120, DOI 10.1016/j.asoc.2015.12.026
   Dutta Palash, 2018, International Journal of Fuzzy System Applications, V7, P15, DOI 10.4018/IJFSA.2018100102
   Fu J, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9080154
   Ganie AH, 2020, NEURAL COMPUT APPL, V32, P12609, DOI 10.1007/s00521-020-04715-y
   Garg H, 2017, INFORMATION, V8, DOI 10.3390/info8040162
   Garg H, 2017, ARAB J SCI ENG, V42, P5275, DOI 10.1007/s13369-017-2625-9
   Hoa ND., 2016, J Sci: Comput Sci Commun Eng, V32, P32
   Huang HL, 2016, INT J INTELL SYST, V31, P1021, DOI 10.1002/int.21815
   Jana C, 2019, APPL SOFT COMPUT, V74, P99, DOI 10.1016/j.asoc.2018.10.021
   Jiang Q, 2019, EXPERT SYST APPL, V116, P439, DOI 10.1016/j.eswa.2018.08.046
   Joshi R, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113228
   Ju YB, 2019, COMPUT IND ENG, V135, P1271, DOI 10.1016/j.cie.2018.07.048
   Khalil AM, 2019, IEEE ACCESS, V7, P51236, DOI 10.1109/ACCESS.2019.2910844
   Son LH, 2017, FUZZY OPTIM DECIS MA, V16, P359, DOI 10.1007/s10700-016-9249-5
   Son LH, 2016, APPL SOFT COMPUT, V46, P284, DOI 10.1016/j.asoc.2016.05.009
   Lin MW, 2020, SUSTAIN CITIES SOC, V53, DOI 10.1016/j.scs.2019.101873
   Liu PD, 2020, INT J APPROX REASON, V119, P177, DOI 10.1016/j.ijar.2019.12.020
   Liu PD, 2018, COGN COMPUT, V10, P242, DOI 10.1007/s12559-017-9523-z
   Luo MX, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103956
   Majumdar P, 2014, J INTELL FUZZY SYST, V26, P1245, DOI 10.3233/IFS-130810
   Mandal K, 2016, J INTELL FUZZY SYST, V31, P1721, DOI 10.3233/JIFS-152082
   Mondal K, 2018, NEUTROSOPHIC SETS SY, V20, P12
   Ngan SC, 2016, EXPERT SYST APPL, V60, P62, DOI 10.1016/j.eswa.2016.04.037
   Thong NT, 2015, EXPERT SYST APPL, V42, P3682, DOI 10.1016/j.eswa.2014.12.042
   Own CM, 2009, APPL INTELL, V31, P283, DOI 10.1007/s10489-008-0126-y
   Patel A, 2023, APPL SOFT COMPUT, V144, DOI 10.1016/j.asoc.2023.110521
   Peng SM, 2017, J INTELL FUZZY SYST, V33, P3451, DOI 10.3233/JIFS-16298
   Peng XD, 2020, ARTIF INTELL REV, V53, P3089, DOI 10.1007/s10462-019-09756-x
   Thong PH, 2016, SOFT COMPUT, V20, P3549, DOI 10.1007/s00500-015-1712-7
   Thong PH, 2016, KNOWL-BASED SYST, V109, P48, DOI 10.1016/j.knosys.2016.06.023
   Pramanik S, 2017, NEURAL COMPUT APPL, V28, P1163, DOI 10.1007/s00521-015-2125-3
   Ngan RT, 2018, APPL SOFT COMPUT, V69, P393, DOI 10.1016/j.asoc.2018.04.036
   Rong Y, 2022, INT J MACH LEARN CYB, V13, P633, DOI 10.1007/s13042-021-01280-1
   Sarkar S, 2020, INT J INFORM MANAGE, V50, P286, DOI 10.1016/j.ijinfomgt.2019.08.008
   Shen F, 2018, INFORM SCIENCES, V428, P105, DOI 10.1016/j.ins.2017.10.045
   Sindhu MS, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220957
   Singh A, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104395
   Singh P, 2018, AFR MAT, V29, P1019, DOI 10.1007/s13370-018-0597-x
   Singh P, 2015, J INTELL FUZZY SYST, V28, P591, DOI 10.3233/IFS-141338
   Smarandache F., 2019, J New Theory, V29, P1
   Son LH, 2015, EXPERT SYST APPL, V42, P51, DOI 10.1016/j.eswa.2014.07.026
   Song YF, 2015, APPL INTELL, V42, P252, DOI 10.1007/s10489-014-0596-z
   Sun RX, 2019, SOFT COMPUT, V23, P211, DOI 10.1007/s00500-017-2949-0
   Szmidt E, 2001, LECT NOTES COMPUT SC, V2074, P263
   Thao NX, 2020, PATTERN ANAL APPL, V23, P1203, DOI 10.1007/s10044-019-00861-9
   Thong P. H., 2015, Knowlegde and systems Engineering, P679, DOI [10.1007/978-3-319-11680-8_54, DOI 10.1007/978-3-319-11680-8_54]
   Tian C, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106037
   Tzeng GH, 2011, MULTIPLE ATTRIBUTE DECISION MAKING: METHODS AND APPLICATIONS, P1
   Uluçay V, 2018, NEURAL COMPUT APPL, V29, P739, DOI 10.1007/s00521-016-2479-1
   Vlachos IK, 2007, PATTERN RECOGN LETT, V28, P197, DOI 10.1016/j.patrec.2006.07.004
   Wang J, 2020, DEF TECHNOL, V16, P1073, DOI 10.1016/j.dt.2019.11.007
   Wang L, 2020, RAIRO-OPER RES, V54, P211, DOI 10.1051/ro/2019004
   Wang L, 2018, J CLEAN PROD, V191, P105, DOI 10.1016/j.jclepro.2018.04.169
   Wang L, 2018, APPL SOFT COMPUT, V64, P216, DOI 10.1016/j.asoc.2017.12.014
   Wang T, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106787
   Wei CP, 2011, INFORM SCIENCES, V181, P4273, DOI 10.1016/j.ins.2011.06.001
   Wei GW, 2018, IRAN J FUZZY SYST, V15, P77
   Wei GW, 2018, INFORMATICA-LITHUAN, V29, P555, DOI 10.15388/Informatica.2018.181
   Wei GW, 2018, INFORMATICA-LITHUAN, V29, P107, DOI 10.15388/Informatica.2018.160
   Wei GW, 2017, INFORMATICA-LITHUAN, V28, P547, DOI 10.15388/Informatica.2017.144
   Wei GW, 2017, J INTELL FUZZY SYST, V33, P713, DOI 10.3233/JIFS-161798
   Wei GW, 2018, INT J MACH LEARN CYB, V9, P713, DOI 10.1007/s13042-016-0604-1
   Wei GW, 2016, J BUS ECON MANAG, V17, P491, DOI 10.3846/16111699.2016.1197147
   Wei GW., 2017, J Intell Fuzzy Syst, V33, P1
   Wu HB, 2018, SOFT COMPUT, V22, P7367, DOI 10.1007/s00500-018-3073-5
   Xu Y, 2019, J INTELL FUZZY SYST, V36, P3833, DOI 10.3233/JIFS-172130
   Yang Y, 2019, J CLEAN PROD, V206, P631, DOI 10.1016/j.jclepro.2018.09.188
   Ye J, 2017, J CLASSIF, V34, P148, DOI 10.1007/s00357-017-9225-y
   Ye J, 2017, SOFT COMPUT, V21, P817, DOI 10.1007/s00500-015-1818-y
   Ye J, 2014, J INTELL SYST, V23, P379, DOI 10.1515/jisys-2013-0091
   Ye J, 2016, COMPUT METH PROG BIO, V123, P142, DOI 10.1016/j.cmpb.2015.10.002
   Ye J, 2015, ARTIF INTELL MED, V63, P171, DOI 10.1016/j.artmed.2014.12.007
   Ye J, 2014, J INTELL FUZZY SYST, V27, P2927, DOI 10.3233/IFS-141252
   Ye J, 2014, INT J FUZZY SYST, V16, P204
   Ye J, 2013, INT J GEN SYST, V42, P386, DOI 10.1080/03081079.2012.761609
   Yue C, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106056
   Zeng SZ, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7020191
   Zhang SQ, 2019, TECHNOL ECON DEV ECO, V25, P1123, DOI 10.3846/tede.2019.10714
   Zhang XY, 2018, J CLEAN PROD, V202, P980, DOI 10.1016/j.jclepro.2018.08.172
NR 93
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-17723-6
EA DEC 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DO9H2
UT WOS:001133108800005
DA 2024-07-18
ER

PT J
AU Khartheesvar, G
   Kumar, M
   Yadav, AK
   Yadav, D
AF Khartheesvar, G.
   Kumar, Mohit
   Yadav, Arun Kumar
   Yadav, Divakar
TI Automatic Indian sign language recognition using MediaPipe holistic and
   LSTM network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sign language recognition; Indian sign language; LSTM; MediaPipe
   holistic; INCLUDE; INCLUDE-50
ID HAND POSTURE; GESTURES
AB Sign language is a reliable medium of communication that deaf and mute individuals use to express themselves and connect with society. However, communication between a person who knows sign language and someone unfamiliar with sign language can be difficult. Indian Sign Language is slowly gaining popularity but faces similar problems. In this paper, a method for recognizing isolated words in Indian Sign Language (ISL) using MediaPipe holistic pipeline for feature extraction and Long-Short Term Memory (LSTM) network is proposed. The proposed method is evaluated on a large-scale ISL video dataset, INCLUDE, along with its smaller subset, INCLUDE-50. The proposed method achieves 94.8% and 87.4% accuracy on INCLUDE-50 and INCLUDE, respectively. Furthermore, a macro averaged F1-score of 93.5% and 86.6% is obtained on the INCLUDE-50 and INCLUDE, respectively. Both these results outperform the current state of the art performance on the respective datasets.
C1 [Khartheesvar, G.; Kumar, Mohit; Yadav, Arun Kumar] NIT Hamirpur, Dept Comp Sci & Engn, Hamirpur, HP, India.
   [Yadav, Divakar] Indira Gandhi Natl Open Univ, Sch Comp & Informat Sci, New Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), Indira Gandhi Natl Open Univ, Sch Comp & Informat Sci, New Delhi, India.
EM 17mi525@nith.ac.in; mohit@nith.ac.in; ayadav@nith.ac.in;
   dsy99@rediffmail.com
RI Yadav, DIVAKAR/AAF-1777-2020; Yadav, Dr. Arun/AAY-8539-2021
OI Yadav, DIVAKAR/0000-0001-6051-479X; Yadav, Dr. Arun/0000-0001-7457-8073;
   Kumar, Mohit/0000-0002-1304-151X
CR Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   [Anonymous], ASL alphabet dataset
   Athitsos V, 2008, PROC CVPR IEEE, P1666
   Barbhuiya AA, 2021, MULTIMED TOOLS APPL, V80, P3051, DOI 10.1007/s11042-020-09829-y
   Barczak A, 2011, A new 2D static hand gesture colour image dataset for ASL gestures
   Basiri S, 2021, Int J Soc Robot
   Bazarevsky V, 2020, Arxiv, DOI arXiv:2006.10204
   Das S, 2023, MULTIMED TOOLS APPL, V82, P16905, DOI 10.1007/s11042-022-14084-4
   Duan JL, 2016, Arxiv, DOI [arXiv:1611.06689, 10.48550/arXiv.1611.06689, DOI 10.48550/ARXIV.1611.06689]
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Ferreira PM, 2021, IEEE T SYST MAN CY-S, V51, P5830, DOI 10.1109/TSMC.2019.2957347
   Forster J, 2012, LREC
   github, Sign language digits dataset
   Grishchenko I, 2020, MediaPipe holistic
   He T, 2017, NEURAL COMPUT APPL, V28, P3827, DOI 10.1007/s00521-016-2277-9
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Indian Sign Language Research and Training Centre (ISLRTC), ABOUT US
   Jebali M, 2021, EVOL SYST-GER, V12, P1031, DOI 10.1007/s12530-020-09365-y
   kaggle, Sign language MNIST dataset
   Konstantinidis D, 2018, IEEE CONF IMAGING SY, P24
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kudrinko Karly, 2021, IEEE Rev Biomed Eng, V14, P82, DOI 10.1109/RBME.2020.3019769
   Kumar PP, 2010, INT J HUM ROBOT, V7, P331, DOI 10.1142/S0219843610002180
   Lee CKM, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114403
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, DOI 10.48550/ARXIV.1906.08172]
   Mariappan HM, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI [10.1109/MLUI52769.2019.10075566, 10.1109/iccids.2019.8862125]
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rastgoo R, 2020, MULTIMED TOOLS APPL, V79, P22965, DOI 10.1007/s11042-020-09048-5
   Sadeddine K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103193
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shin J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175856
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sridhar A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1366, DOI 10.1145/3394171.3413528
   Suneetha M, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103161
   Tan YS, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114797
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Xiao H, 2022, J Ambient Intell Human Comput, V13
   zenodo, INCLUDE dataset
   Zhang F, 2020, Arxiv, DOI arXiv:2006.10214
NR 45
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17361-y
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000003
DA 2024-07-18
ER

PT J
AU Gai, LL
   Xing, MM
   Chen, W
   Zhang, Y
   Qiao, X
AF Gai, Lulu
   Xing, Mengmeng
   Chen, Wei
   Zhang, Yi
   Qiao, Xu
TI Comparing CNN-based and transformer-based models for identifying lung
   cancer: which is more effective?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer identification; Convolutional neural networks; Vision
   transformers; Self-supervised learning; Sharpness-aware Minimizer
AB Lung cancer constitutes the most severe cause of cancer-related mortality. Recent evidence supports that early detection by means of computed tomography (CT) scans significantly reduces mortality rates. Given the remarkable progress of Vision Transformers (ViTs) in the field of computer vision, we have delved into comparing the performance of ViTs versus Convolutional Neural Networks (CNNs) for the automatic identification of lung cancer based on a dataset of 212 medical images. Importantly, neither ViTs nor CNNs require lung nodule annotations to predict the occurrence of cancer. To address the dataset limitations, we have trained both ViTs and CNNs with three advanced techniques: transfer learning, self-supervised learning, and sharpness-aware minimizer. Remarkably, we have found that CNNs achieve highly accurate prediction of a patient's cancer status, with an outstanding recall (93.4%) and area under the Receiver Operating Characteristic curve (AUC) of 98.1%, when trained with self-supervised learning. Our study demonstrates that both CNNs and ViTs exhibit substantial potential with the three strategies. However, CNNs are more effective than ViTs with the insufficient quantities of dataset.
C1 [Gai, Lulu; Qiao, Xu] Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.
   [Xing, Mengmeng] Shandong First Med Univ, Shandong Prov Hosp, Dept Thorac Surg, Tai An, Shandong, Peoples R China.
   [Chen, Wei] Shandong Univ, Dept Stomatol, Jinan 250012, Peoples R China.
   [Zhang, Yi] Shandong Prov Maternal & Child Hlth Care Hosp, Jinan, Peoples R China.
C3 Shandong University; Shandong First Medical University & Shandong
   Academy of Medical Sciences; Shandong University
RP Qiao, X (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.; Zhang, Y (corresponding author), Shandong Prov Maternal & Child Hlth Care Hosp, Jinan, Peoples R China.
EM 2927791087llg@gmail.com; 81115228@qq.com; ichenwei@sdu.edu.cn;
   zhangyisd@139.com; qiaoxu@sdu.edu.cn
FU Innovative Research Group Project of the National Natural Science
   Foundation of China [U1806202, 61533011]; Natural Science Foundation of
   China [ZR2019BF035, ZR2020ZD25, ZR2021QF042, 2022CXGC10501]; Natural
   Science Foundation of Shandong Province of China
FX This study was supported by the Natural Science Foundation of China
   under Grant U1806202, Grant 61533011 and the Natural Science Foundation
   of Shandong Province of China ZR2019BF035, ZR2020ZD25, ZR2021QF042,
   2022CXGC10501.
CR Aurna NF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105539
   Bardou D, 2018, ARTIF INTELL MED, V88, P58, DOI 10.1016/j.artmed.2018.04.008
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chen X., 2021, arXiv, DOI 10.48550/arXiv.2106.01548
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fraioli F, 2010, RADIOL MED, V115, P385, DOI 10.1007/s11547-010-0507-2
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2019, Arxiv, DOI arXiv:1903.12261
   Hendrycks D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8320, DOI 10.1109/ICCV48922.2021.00823
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hua YN, 2022, IEEE T IND INFORM, V18, P3248, DOI 10.1109/TII.2021.3107785
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kukreja V, 2023, Int J Comput Digit Syst
   Kukreja V, 2022, MULTIMED TOOLS APPL, V81, P28651, DOI 10.1007/s11042-022-12644-2
   Lei Ba J., 2016, arXiv
   Liu LY, 2021, Arxiv, DOI arXiv:1908.03265
   Loshchilov Ilya, 2016, arXiv
   Powers DMW, 2020, Arxiv, DOI arXiv:2010.16061
   Michieli U, 2020, IEEE T INTELL VEHICL, V5, P508, DOI 10.1109/TIV.2020.2980671
   Paszke A, 2019, ADV NEUR IN, V32
   Pérez-García F, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106236
   Raghu M, 2019, Arxiv, DOI arXiv:1902.07208
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosati R, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103912
   Rostami B, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104536
   Sakshi, 2023, ARCH COMPUT METHOD E, V30, P457, DOI 10.1007/s11831-022-09805-9
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Sakshi, 2023, ARTIF INTELL REV, V56, P7047, DOI 10.1007/s10462-022-10330-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2019, PR MACH LEARN RES, V97
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsao AS, 2016, J THORAC ONCOL, V11, P613, DOI 10.1016/j.jtho.2016.03.012
   Vaswani A, 2017, ADV NEUR IN, V30
   Vijaya G., 2014, IJRET: Int J Res Eng Technol, V3, P182
NR 46
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17644-4
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Isunuri, BV
   Kakarla, J
AF Isunuri, Bala Venkateswarlu
   Kakarla, Jagadeesh
TI Ensemble coupled convolution network for three-class brain tumor grade
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Coupled convolution network; Brain tumor grade classification; Transfer
   learning; Feature extraction
ID MRI
AB The brain tumor grade classification is one of the prevalent tasks in brain tumor image classification. The existing models have employed transfer learning and are unable to preserve semantic features. Moreover, the results are reported on small datasets with pre-trained models. Thus, there is a need for an optimized model that can exhibit superior performance on larger datasets. We have proposed an efficientnet and coupled convolution network for the grade classification of brain magnetic resonance images. The feature extraction is performed using a pre-trained EfficientNetB0. Then, we have proposed a coupled convolution network for feature enhancement. Finally, enhanced features are classified using a fully connected dense network. We have utilized a global average pooling and dropout layers to avoid model overfitting. We have evaluated the proposed model on the REMBRANDT dataset and have achieved 96.95% accuracy. The proposed model outperforms existing pre-trained models and state-of-the-art models in vital metrics.
C1 [Isunuri, Bala Venkateswarlu; Kakarla, Jagadeesh] Indian Inst Informat Technol Design & Mfg Kancheep, Chennai, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram
RP Isunuri, BV (corresponding author), Indian Inst Informat Technol Design & Mfg Kancheep, Chennai, India.
EM baluatresearch@gmail.com
RI B Venkateswarlu, Isunuri/ABD-7479-2020
OI B Venkateswarlu, Isunuri/0000-0002-7671-8831
CR Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Arif M, 2022, Comput Intell Neurosci CIN 2022
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cinarer G., 2020, Adv. Sci. Technol. Eng. Syst, V5, P765, DOI [10.25046/AJ050593, DOI 10.25046/AJ050593]
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Ghahfarrokhi SS, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102025
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Kumar R, 2020, IEEE ACCESS, V8, P79440, DOI 10.1109/ACCESS.2020.2989193
   Latif G, 2019, IEEE ACCESS, V7, P9634, DOI 10.1109/ACCESS.2018.2888488
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Madhavan S, 2009, MOL CANCER RES, V7, P157, DOI 10.1158/1541-7786.MCR-08-0435
   Naser MA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103758
   Scarpace Lisa, 2019, TCIA
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Sun P, 2019, IEEE ACCESS, V7, P102010, DOI 10.1109/ACCESS.2019.2928975
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tandel GS, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.104018
NR 24
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 18
PY 2023
DI 10.1007/s11042-023-17760-1
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CO5S9
UT WOS:001126208400003
DA 2024-07-18
ER

PT J
AU Babu, VS
   Vaidya, AS
AF Babu, Voruchu Sai
   Vaidya, Avinash S.
TI Ocular and muscle artifacts suppression from EEG through MEMD and
   statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electroencephalogram; Artifacts; Electrooculography; Electromyogram;
   MEMD; ICA; IVA
ID INDEPENDENT COMPONENT ANALYSIS; EMPIRICAL MODE DECOMPOSITION; VECTOR
   ANALYSIS; EYE BLINK; REMOVAL; IDENTIFICATION; ICA; ALGORITHM; FRAMEWORK
AB Electroencephalogram (EEG) is one of the Psycho-acoustic signals which is used in order to analyze brain activity. However, the EEG signal which frequently gets contaminated with several kinds of artifacts. Among these artifacts, Electrooculography (EOG) and Electromyogram (EMG) are the two wide artifacts that contaminate EEG unintentionally. The presence of such kind of artifacts in EEG shows a significant impact on the diagnosis results. Hence, this paper proposes a new and effective artifacts removal strategy in accordance with Multivariate Empirical Mode Decomposition (MEMD). For a given input EEG, the MEMD creates Multivariate Intrinsic Mode Functions (MIMFs) from it and process it through a Independent Vector Analysis (IVA) and statistical Independent Component Analysis (SICA) to eliminate EMGs and, EOGs respectively. Once the artifacts are removed, the signal will be reconstructed and processed for quality assessment. Three metrics, namely Relative Root Mean Square Error (RRMSE), Cross-Correlation Coefficient (CRC), and Signal to Noise Ratio (SNR) are utilized for assessment. The efficiency of the suggested approaches that are State-of-the-Art methods has been demonstrated through extensive simulations on both simulated and actual EEG data.
C1 [Babu, Voruchu Sai; Vaidya, Avinash S.] Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Vaidya, AS (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
EM sai.gnitc@gmail.com; avinash.s@klh.edu.in
RI Babu, Voruchu Sai/HTN-4766-2023
OI Babu, Voruchu Sai/0009-0008-5581-4307
CR Ahmed MA, 2020, IEEE ACCESS, V8, P202919, DOI 10.1109/ACCESS.2020.3036134
   Albera L, 2012, B POL ACAD SCI-TECH, V60, P407, DOI 10.2478/v10175-012-0052-3
   Anderson M, 2012, IEEE T SIGNAL PROCES, V60, P1672, DOI 10.1109/TSP.2011.2181836
   Urigüen JA, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/031001
   Barbati G, 2004, CLIN NEUROPHYSIOL, V115, P1220, DOI 10.1016/j.clinph.2003.12.015
   Chen X, 2019, IEEE SENS J, V19, P8420, DOI 10.1109/JSEN.2018.2872623
   Chen X, 2018, IEEE T INSTRUM MEAS, V67, P359, DOI 10.1109/TIM.2017.2759398
   Chen X, 2017, COMPUT BIOL MED, V88, P1, DOI 10.1016/j.compbiomed.2017.06.013
   Chen X, 2017, IEEE T INSTRUM MEAS, V66, P1770, DOI 10.1109/TIM.2016.2608479
   Chen X, 2016, IEEE SIGNAL PROC MAG, V33, P86, DOI 10.1109/MSP.2016.2521870
   Chen X, 2014, IEEE T BIO-MED ENG, V61, P2187, DOI 10.1109/TBME.2014.2319294
   Cheng J, 2019, IEEE ACCESS, V7, P60276, DOI 10.1109/ACCESS.2019.2915564
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Dai YX, 2015, MEASUREMENT, V74, P11, DOI 10.1016/j.measurement.2015.07.008
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Gao B, 2014, IEEE T INSTRUM MEAS, V63, P913, DOI 10.1109/TIM.2013.2285789
   Gao JF, 2010, CLIN EEG NEUROSCI, V41, P53, DOI 10.1177/155005941004100111
   Guo RS, 2020, STAT SCI, V35, P145, DOI 10.1214/19-STS763
   Hossain MS, 2022, IEEE ACCESS, V10, P29760, DOI 10.1109/ACCESS.2022.3159155
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Issa MF, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9120355
   Kim T, 2006, LECT NOTES COMPUT SC, V3889, P165
   Lay-Ekuakille A, 2014, IEEE T INSTRUM MEAS, V63, P1440, DOI 10.1109/TIM.2013.2287803
   Li XY, 2017, IEEE T BIO-MED ENG, V64, P1906, DOI 10.1109/TBME.2016.2628958
   Li YQ, 2023, IEEE SENS J, V23, P15115, DOI 10.1109/JSEN.2023.3276481
   Liang SF, 2012, IEEE T INSTRUM MEAS, V61, P1649, DOI 10.1109/TIM.2012.2187242
   Maddirala AK, 2016, IEEE SENS J, V16, P8279, DOI 10.1109/JSEN.2016.2560219
   Mahajan R, 2015, IEEE J BIOMED HEALTH, V19, P158, DOI 10.1109/JBHI.2014.2333010
   Mahmoud R, 2017, IEEE SENS J, V17, P7019, DOI 10.1109/JSEN.2017.2727539
   Mammone N, 2012, IEEE SENS J, V12, P533, DOI 10.1109/JSEN.2011.2115236
   McMenamin BW, 2011, NEUROIMAGE, V54, P4, DOI 10.1016/j.neuroimage.2010.07.057
   McMenamin BW, 2010, NEUROIMAGE, V49, P2416, DOI 10.1016/j.neuroimage.2009.10.010
   de Sa AMFLM, 2015, MEASUREMENT, V60, P121, DOI 10.1016/j.measurement.2014.09.079
   Mishra P, 2013, MEAS SCI REV, V13, P7, DOI 10.2478/msr-2013-0001
   Mowla MR, 2015, BIOMED SIGNAL PROCES, V22, P111, DOI 10.1016/j.bspc.2015.06.009
   Ranjan R, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3198441
   Ranjan R, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3142037
   Rehman N, 2010, P ROY SOC A-MATH PHY, V466, P1291, DOI 10.1098/rspa.2009.0502
   Sabato A, 2017, IEEE SENS J, V17, P226, DOI 10.1109/JSEN.2016.2630008
   Shahbakhti M, 2021, IEEE T NEUR SYS REH, V29, P408, DOI 10.1109/TNSRE.2021.3054733
   Sharma S, 2022, IEEE SENS J, V22, P5806, DOI 10.1109/JSEN.2022.3147010
   Siuly, 2016, MEASUREMENT, V86, P148, DOI 10.1016/j.measurement.2016.02.059
   Urrestarazu E, 2004, EPILEPSIA, V45, P1071, DOI 10.1111/j.0013-9580.2004.12104.x
   Wang G, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2450196
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Yasoda K, 2020, SOFT COMPUT, V24, P16011, DOI 10.1007/s00500-020-04920-w
   Yi CF, 2015, IEEE SENS J, V15, P5133, DOI 10.1109/JSEN.2015.2435814
   Yin J, 2022, IEEE SENS J, V22, P21855, DOI 10.1109/JSEN.2022.3209805
   Yu CY, 2015, REV SCI INSTRUM, V86, DOI 10.1063/1.4928815
   Zeng K, 2016, IEEE T NEUR SYS REH, V24, P630, DOI 10.1109/TNSRE.2015.2496334
   Zhang Y, 2016, IEEE T NEUR NET LEAR, V27, P2256, DOI 10.1109/TNNLS.2015.2476656
   Zhao QL, 2014, IEEE T NANOBIOSCI, V13, P109, DOI 10.1109/TNB.2014.2316811
NR 52
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-16863-z
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY3H0
UT WOS:001142451400004
DA 2024-07-18
ER

PT J
AU Sravani, M
   Murthy, MK
   Muppidi, S
AF Sravani, Meesala
   Murthy, Meesala Krishna
   Muppidi, Satish
TI Utilizing Visual Geometry Group (VGG16) and InceptionV3 convolutional
   Neural Network (CNN) models for accurate diagnosis of lung cancer: an
   Artificial Intelligence (AI)-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer; Pulmonary nodules; LUNA16; CNN; VGG16
ID NODULE DETECTION; CLASSIFICATION
AB In recent times, artificial intelligence (AI) has emerged in every field, and its applications are rapidly expanding in the medical sector, specifically for lung cancer. Different reasons can affect lung cancer, but most commonly, it occurs due to pulmonary nodules; they can be categorized into two types: noncancerous and cancerous. Pulmonary nodules are not dangerous until they are small and not grow rapidly. If they transform into cancer, they may experience symptoms such as chest pain, coughing up blood, fatigue, hoarseness, pneumonia, and dyspnea. In the present study, we have taken image data from the Lung Nodule Analysis (LUNA16) and applied it to the Visual Geometry Group (VGG16), a Convolutional Neural Network (CNN) model, to identify pulmonary nodules in the lungs. The performance of the VGG19 model on the training set was evaluated, and an accuracy score of 98.72% was obtained, indicating its robustness and efficiency compared with the InceptionV3 model, that had an accuracy of 88.33%. It demonstrates that the proposed method can obviously achieve accurate pulmonary nodule detection.
C1 [Sravani, Meesala; Muppidi, Satish] GMR Inst Technol, Dept Comp Sci & Engn, Rajam 532127, India.
   [Murthy, Meesala Krishna] Chitkara Univ, Chitkara Sch Hlth Sci, Dept Allied Hlth Sci, Rajpura 140401, Punjab, India.
C3 GMR Institute of Technology; Chitkara University, Punjab
RP Murthy, MK (corresponding author), Chitkara Univ, Chitkara Sch Hlth Sci, Dept Allied Hlth Sci, Rajpura 140401, Punjab, India.
EM krishnameesala6@gmail.com
OI Murthy, Meesala Krishna/0000-0002-3634-0053
FU Department of Computer Science and Engineering, GMRIT, Andhra Pradesh,
   India; Department of Allied Health Sciences, Chitkara University,
   Punjab, India
FX Authors thankful to the Department of Computer Science and Engineering,
   GMRIT, Andhra Pradesh, India and Department of Allied Health Sciences,
   Chitkara University, Punjab, India to support for facilities provided.
CR Ali I, 2020, IEEE ACCESS, V8, P175859, DOI 10.1109/ACCESS.2020.3026080
   Ali I, 2018, FRONT ONCOL, V8, DOI 10.3389/fonc.2018.00108
   Anand V, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13071320
   Cancer Facts and Figures, 2023, American Cancer Society 2022
   Cao HC, 2020, IEEE J BIOMED HEALTH, V24, P2006, DOI 10.1109/JBHI.2019.2963720
   Chen Y, 2021, IEEE ACCESS, V9, P50301, DOI 10.1109/ACCESS.2021.3068896
   Gu DD, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101886
   Harsono IW, 2020, J KING SAUD UNIV-COM, V34, P567, DOI 10.1016/j.jksuci.2020.03.013
   Koo YH, 2021, J MED IMAG RADIAT ON, V65, P15, DOI 10.1111/1754-9485.13105
   Kuang Y, 2020, IEEE ACCESS, V8, P77725, DOI 10.1109/ACCESS.2020.2987961
   Kumar A, 2021, Data science and its applications, P277
   Li YF, 2019, IEEE ACCESS, V7, P37822, DOI 10.1109/ACCESS.2019.2905574
   Majidpourkhoei R, 2021, MULTIMED TOOLS APPL, V80, P30539, DOI 10.1007/s11042-021-11066-w
   Naik A, 2021, WIRELESS PERS COMMUN, V119, P1209, DOI 10.1007/s11277-021-08258-w
   Naseer I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124426
   Nasrullah N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173722
   Patel B., 2023, Multimed Tools Appl, V7, P1
   Riquelme D, 2020, AI-BASEL, V1, P28, DOI 10.3390/ai1010003
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1455-6
   Saba T, 2019, MICROSC RES TECHNIQ, V82, P1601, DOI 10.1002/jemt.23326
   Sahu P, 2019, IEEE J BIOMED HEALTH, V23, P960, DOI 10.1109/JBHI.2018.2879834
   Siddiqui EA, 2023, CHEMOMETR INTELL LAB, V235, DOI 10.1016/j.chemolab.2023.104763
   Singh R, 2023, INT C DISTR COMP EL, P1
   Sreekumar Amrit, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0209, DOI 10.1109/ICCSP48568.2020.9182258
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Tang H, 2019, I S BIOMED IMAGING, P859, DOI [10.1109/isbi.2019.8759244, 10.1109/ISBI.2019.8759244]
   Traoré A, 2020, IEEE ENG MED BIO, P1335, DOI [10.1109/embc44109.2020.9175152, 10.1109/EMBC44109.2020.9175152]
   Wang J, 2019, IEEE ACCESS, V7, P46033, DOI 10.1109/ACCESS.2019.2908195
   Wang WL, 2021, APPL INTELL, V51, P2471, DOI 10.1007/s10489-020-01990-z
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Zhang BH, 2019, IEEE ACCESS, V7, P110358, DOI 10.1109/ACCESS.2019.2933670
   Zhang QH, 2020, IEEE ACCESS, V8, P90380, DOI 10.1109/ACCESS.2020.2993872
   Zheng J, 2020, IET IMAGE PROCESS, V14, P1481, DOI 10.1049/iet-ipr.2019.0248
   Zheng SY, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105620
   Zhu L, 2021, J SUPERCOMPUT, V77, P7584, DOI 10.1007/s11227-020-03538-x
NR 36
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17807-3
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L5
UT WOS:001155145700001
DA 2024-07-18
ER

PT J
AU Anbumani, P
   Selvaraj, K
AF Anbumani, P.
   Selvaraj, K.
TI Enhancing sentiment analysis classification for amazon product reviews
   using CNN- sigTan-Beta activation function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; CNN; Amazon review; ABO-RF algorithm; Neural
   networks
ID ENSEMBLE; MODEL
AB The rapid development of online products paves the way to share customers' opinions on amazon products. Unstructured text reviews and customer feedback are popular resources for customers when making decisions. However, reading through all the evaluations is tiresome, but the volume of customer feedback is enormous. The ability to forecast the precise sentiment polarities of user textual feedback evaluations for a particular entity is still difficult because of phrase length restrictions, textual order variations, and logical complexities. Therefore, an aspect level of analysis is needed, which support the retailers in understanding customer expectation and then modifying the product accordingly. However, many existing machine learning algorithms are available for sentiment detection but fail in accuracy rate. This paper proposes a novel sigTan-Beta Activation Function for Convolution Neural Networks (CNN) to attain remarkable and effective results. First, the sample dataset is pre-processed, and text strings are converted into the vector using Word2Vec, which computes the distance between words and groups them based on similarity. Afterwards, CNN extracts the sensitive features from the data and classifies the product reviews. The proposed model uses the sigTan-Beta Activation Function, which tunes the weight of the neurons to gain accurate performance. The proposed classified as positive or negative classes using the amazon review dataset. The proposed sigTan-Beta Activation Function for Convolution Neural Network (CNN) experiment performs better than existing methods in terms of accuracy, precision and F1-score. Our proposed sigTan-Beta Activation Function for Convolution Neural Network (CNN) achieves 94.5% accuracy to the existing ABO-RF algorithm (89.9%).
C1 [Anbumani, P.] Periyar Univ, Dept Comp Sci, Salem 636011, Tamil Nadu, India.
   [Selvaraj, K.] Arignar Anna Govt Arts Coll, Dept Comp Sci, Attur 636121, Tamil Nadu, India.
C3 Periyar University
RP Anbumani, P (corresponding author), Periyar Univ, Dept Comp Sci, Salem 636011, Tamil Nadu, India.
EM kanchianbu@gmail.com
CR Alharbi NM, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5536560
   Aljuhani SA, 2019, INT J ADV COMPUT SC, V10, P608
   [Anonymous], 2018, International Journal of Engineering and Technology (UAE), DOI DOI 10.14419/IJET.V7I2.24.11991
   Borg A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113746
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Eger S, 2019, Arxiv, DOI arXiv:1901.02671
   Fauzi M. A., 2019, Int. J. Electr. Comput. Eng., V9, P525, DOI DOI 10.11591/IJECE.V9I1.PP525-530
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Houshmand S-m, 2015, Applications of deep learning to sentiment analysis of movie reviews, P1
   Ireland R, 2018, CIRP J MANUF SCI TEC, V23, P128, DOI 10.1016/j.cirpj.2018.06.003
   Jagdale Rajkumar S., 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P639, DOI 10.1007/978-981-13-0617-4_61
   Kang H, 2012, EXPERT SYST APPL, V39, P6000, DOI 10.1016/j.eswa.2011.11.107
   Karlik B., 2011, INT J ARTIF INTELL E, V1, P111, DOI DOI 10.1088/1742-6596/1237/2/022030
   Katic T, 2018, I S INTELL SYST INFO, P283, DOI 10.1109/SISY.2018.8524814
   Kunal Sourav, 2018, Procedia Computer Science, V132, P307, DOI 10.1016/j.procs.2018.05.182
   Li Z, 2020, IEEE ACCESS, V8, P75073, DOI 10.1109/ACCESS.2020.2986582
   Mukherjee A, 2019, INT CONF AWARE SCI, P413, DOI 10.1109/icawst.2019.8923260
   Onan A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5909
   Rani S, 2019, ARAB J SCI ENG, V44, P3305, DOI 10.1007/s13369-018-3500-z
   Rathi M, 2018, INT CONF CONTEMP, P365
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Sadhasivam J, 2019, INT J MATH ENG MANAG, V4, P508, DOI 10.33889/IJMEMS.2019.4.2-041
   Smetanin S, 2019, CONF BUS INFORM, P482, DOI 10.1109/CBI.2019.00062
   Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6
   Souma W, 2019, J COMPUT SOC SCI, V2, P33, DOI 10.1007/s42001-019-00035-x
   Surya Prabha PM, 2019 INT C VIS EM TR
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Valencia F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060589
   Vidya K., 2022, Journal of Algebraic Statistics, V13, P1644
   Wassan S, 2021, Amazon product sentiment analysis using machine learning techniques, V30, P695, DOI [10.24205/03276716.2020.2065, DOI 10.24205/03276716.2020.2065]
   Xia R, 2016, INFORM PROCESS MANAG, V52, P36, DOI 10.1016/j.ipm.2015.04.003
   Xia R, 2011, INFORM SCIENCES, V181, P1138, DOI 10.1016/j.ins.2010.11.023
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang SM, 2023, IEEE T SYST MAN CY-S, V53, P7852, DOI 10.1109/TSMC.2023.3300318
   Zhao HL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102656
NR 37
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17555-4
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100008
DA 2024-07-18
ER

PT J
AU Singh, I
   Munjal, G
AF Singh, Inderpreet
   Munjal, Geetika
TI Modified YOLOv5 for small target detection in aerial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer vision; Object detection; Aerial images; Small target detection
ID CONVOLUTIONAL NETWORKS
AB Object detection is an important field in computer vision. Detecting objects in aerial images is an extremely challenging task as the objects can be very small compared to the size of the image, the objects can have any orientation, and depending upon the altitude, the same object can appear in different sizes. YOLOv5 is a recent object detection algorithm that has a good balance of accuracy and speed. This work focuses on enhancing the YOLOv5 object detection algorithm specifically for small target detection. The accuracy on small objects has been improved by adding a new feature fusion layer in the feature pyramid part of YOLOv5 and using compound scaling to increase the input size. The modified YOLOv5 demonstrates a remarkable 11% improvement in mAP 0.5 on the small vehicle class of the DOTA dataset while being 25% smaller in terms of GFLOPS and achieving a 10.52% faster inference time, making it well-suited for real-time applications. Furthermore, the modified YOLOv5 achieves a notable 45.2% mAP 0.5 compared to 31.7% mAP 0.5 of YOLOv5 on the challenging VisDrone dataset. The modified YOLOv5 outperforms many state-of-the-art algorithms in small target detection in aerial images. In addition to performance evaluation, we also present an analysis of object sizes in pixel areas in the VisDrone and DOTA datasets. The proposed modifications demonstrate the potential for significant advancements in small target detection in aerial images and provide valuable insights for further research in this area.
C1 [Singh, Inderpreet; Munjal, Geetika] Amity Univ, Amity Sch Engn & Technol, Noida 201303, UP, India.
C3 Amity University Noida
RP Singh, I (corresponding author), Amity Univ, Amity Sch Engn & Technol, Noida 201303, UP, India.
EM inderpreet1390@gmail.com; munjal.geetika@gmail.com
OI Singh, Inderpreet/0000-0001-9498-0107
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Clark Alex, 2015, Pillow (pil fork) documentation
   Dai JF, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding J, 2022, IEEE T PATTERN ANAL, V44, P7778, DOI 10.1109/TPAMI.2021.3117983
   Du DW, 2019, IEEE INT CONF COMP V, P213, DOI 10.1109/ICCVW.2019.00030
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jocher Glenn, 2021, Zenodo
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Mundhenk Nathan T, 2020, UCSDLDC, DOI 10.6075/J0CN72BC
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Razakarivony S, 2015, Journal of Visual Communication and Image Representation
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Umesh P., 2012, CSI Communications, V23, P2
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 40
TC 0
Z9 0
U1 48
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17625-7
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500005
DA 2024-07-18
ER

PT J
AU Talaat, FM
AF Talaat, Fatma M.
TI The effect of consanguineous marriage on reading disability based on
   deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dyslexia; Consanguineous Marriage; Orthography; Probabilistic Neural
   Network
ID REPRODUCTIVE-BEHAVIOR; HEALTH
AB For knowledge acquisition and social engagement, reading comprehension is essential. However, 20% or so of younger students have trouble with it. In order to predict the effects of consanguineous marriage on reading handicap and customize adaptive learning experiences, the study proposes an Intelligent Adaptive Learning and Prediction Framework (IALPF). This framework is proposed as a transformative solution that smoothly combines cutting-edge AI approaches. IALPF provides precise predictions and individualized learning pathways by utilizing extensive cognitive profiling, data gathering, and hybrid neural network design. It includes early warning systems, flexible content distribution, and ongoing development based on active learning and feedback loops. The IALPF represents a significant change in education that has wide-ranging effects. We evaluated reading skills among 770 students in a study that included two experimental groups, a control group, and 22 pupils from first-cousin marriages and 21 children of unrelated parents, respectively. Tests were given for word identification and reading comprehension, among other things. The findings showed that children of first cousin parents had a higher chance of reading difficulties than those of parents from other families. The outstanding performance of IALPF, which outperformed conventional techniques like Back Propagation (BP) and General Regression Neural Network (GRNN), was further supported by empirical evaluation. This demonstrates IALPF's success in reinventing personalized learning and predictive analysis, strengthening its potential to improve education in a variety of scenarios. The seamless integration of cutting-edge AI methods into IALPF, which forecasts the effect of consanguineous marriage on reading handicap, is a significant innovation. To set it apart from conventional approaches, this special framework integrates cognitive profile, information gathering, and hybrid neural networks for accurate predictions. The empirical analysis demonstrates the revolutionary potential of IALPF by demonstrating its improved predictive accuracy when compared to Back Propagation (BP) and General Regression Neural Network (GRNN).
C1 [Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
   [Talaat, Fatma M.] New Mansoura Univ, Fac Comp Sci & Engn, Gamasa 35712, Egypt.
   [Talaat, Fatma M.] Nile Higher Inst Engn & Technol, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; New Mansoura
   University
RP Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.; Talaat, FM (corresponding author), New Mansoura Univ, Fac Comp Sci & Engn, Gamasa 35712, Egypt.; Talaat, FM (corresponding author), Nile Higher Inst Engn & Technol, Mansoura, Egypt.
EM fatma.nada@ai.kfs.edu.eg
RI M. Talaat, Fatma/IYS-7614-2023
OI M. Talaat, Fatma/0000-0001-6116-2191
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB). The authors received no specific funding for this study.
CR Al-Abdulkareem AA, 1998, J COMMUN HEALTH, V23, P75, DOI 10.1023/A:1018727005707
   Al-Ansari A., 1994, J Ment Retard, V31, P140
   Alhussan AA, 2023, Computers Materials and Continua, V76
   Alnaggar M., 2023, Egypt. J Artif Intell., V2, P1, DOI [10.21608/ejai.2023.205554.1008, DOI 10.21608/EJAI.2023.205554.1008]
   Alnaggar M, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120135
   Alnaggar M, 2023, INT J ADV COMPUT SC, V14, P379
   Alshathri S, 2022, CMC-COMPUT MATER CON, V73, P5863, DOI 10.32604/cmc.2022.026547
   Alvermann DE., 2006, Handbook of educational psychology, V2
   ANSARI NA, 1978, INDIAN J MED RES, V68, P295
   BITTLES AH, 1993, INT J EPIDEMIOL, V22, P463, DOI 10.1093/ije/22.3.463
   BITTLES AH, 1991, SCIENCE, V252, P789, DOI 10.1126/science.2028254
   DRIVER ED, 1988, J COMP FAM STUD, V19, P229, DOI 10.3138/jcfs.19.2.229
   El-Rashidy N, 2023, NEURAL COMPUT APPL, V35, P7423, DOI 10.1007/s00521-022-08007-5
   El-Rashidy N, 2022, SOFT COMPUT, V26, P11435, DOI 10.1007/s00500-022-07420-1
   Eloranta AK, 2019, SCI STUD READ, V23, P273, DOI 10.1080/10888438.2018.1561698
   Gamel SA, 2024, MULTIMED TOOLS APPL, V83, P7295, DOI 10.1007/s11042-023-15803-1
   Gedik O, 2022, International Journal of Psychology and Education, V10, P265, DOI [10.29329/ijpe.2022.426.2, DOI 10.29329/IJPE.2022.426.2]
   Hallgren B, 1950, ACTA PSYCH NEUROL SU, P1
   Hanaa S., 2022, Bioengineering, V10, P18, DOI [10.3390/bioengineering10010018, DOI 10.3390/BIOENGINEERING10010018]
   Hassan E, 2022, Nile Journal of Communication and Computer Science Internet, V3, P17, DOI [10.21608/njccs.2022.280047, DOI 10.21608/NJCCS.2022.280047]
   Hunt F., 2008, DROPPING OUT SCH CRO
   Jaber L, 1997, J MED GENET, V34, P1000, DOI 10.1136/jmg.34.12.1000
   JABER L, 1992, AM J MED GENET, V44, P1, DOI 10.1002/ajmg.1320440102
   KHLAT M, 1986, J BIOSOC SCI, V18, P489
   Olson J.F., 2008, TIMSS 2007 TECHNICAL, DOI [10.1787/9789264130852-en, DOI 10.1787/9789264130852-EN]
   Olson R., 1994, The variety of orthographic knowledge 1: Theoretical and developmental issues, P27, DOI [10.1007/978-94-017-3492-9_2, DOI 10.1007/978-94-017-3492-9_2]
   RAO PSS, 1977, ANN HUM GENET, V41, P87, DOI 10.1111/j.1469-1809.1977.tb01964.x
   Siam AI, 2023, NEURAL COMPUT APPL, V35, P12891, DOI 10.1007/s00521-023-08428-w
   Talaat FM, 2023, NEURAL COMPUT APPL, DOI 10.1007/s00521-023-08809-1
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P18059, DOI 10.1007/s00521-023-08678-8
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P17281, DOI 10.1007/s00521-023-08619-5
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P39945, DOI 10.1007/s11042-022-13000-0
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P12717, DOI 10.1007/s00521-023-08372-9
   Uysal PK, 2020, PEGEM EGIT OGR DERG, V10, P1111, DOI 10.14527/pegegog.2020.034
   Uysal PK, 2019, EGIT BILIM, V44, P17, DOI 10.15390/EB.2019.8032
NR 36
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17587-w
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Wen, XL
   Wang, JF
   Yang, X
AF Wen, Xilin
   Wang, Jianfang
   Yang, Xu
TI Dynamic negative sampling for recommendation with feature matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommendation; Knowledge graph; Negative sampling; Reinforcement
   learning
AB Negative sampling is a strategy used to select nodes in unexposed items. Recently, most recommendation algorithms based on knowledge graph have adopted learning-effective sampling strategies. However, these methods regard negative sampling as a static process, assuming that the user's potential preferences remain unchanged, and ignoring the dynamic interaction between the user and the recommendation system. To solve the above limitations, we propose a Dynamic Negative Sampling for Recommendation with feature matching (DNSR) to explore high-quality negative examples. This method consists of two main components: the sampler and the recommender. Firstly, the sampler obtains the embedded representation of nodes through a simplified graph convolutional network, then perform node sampling in the collaborative knowledge graph based on the positive examples that users have interacted with. To improve the sampling process, we developed a multiple feature matching technique that calculates the probability distribution of candidate node sets. This technique allows the sampler to filter out representative negative examples. Secondly, the recommender with reinforcement learning aims to optimize the ranking of positive and negative examples by providing feedback in the form of reward signals. This incentivizes the sampler to generate negative examples with information value. On three real-world datasets, our proposed method performs remarkably better than the state-of-the-art baselines. We further verify DNSR model performance of feature matching through ablation experiments.
C1 [Wen, Xilin; Wang, Jianfang; Yang, Xu] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Peoples R China.
C3 Henan Polytechnic University
RP Wang, JF (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Peoples R China.
EM wangjianfang@hpu.edu.cn
OI wang, jianfang/0000-0002-6040-1012
FU We thank anonymous experts for their valuable suggestions and comments.
FX We thank anonymous experts for their valuable suggestions and comments.
CR Albalawi Rania, 2021, ICSIM 2021: 2021 The 4th International Conference on Software Engineering and Information Management, P145, DOI 10.1145/3451471.3451495
   Chen T, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P767, DOI 10.1145/3097983.3098202
   Chen XC, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207010
   Ding JT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488
   Gaonkar R, 2018, LECT NOTES COMPUT SC, V11191, P111, DOI 10.1007/978-3-030-01768-2_10
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Hu LM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4255
   Hu YJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P368, DOI 10.1145/3219819.3219846
   Intayoad W, 2020, WIRELESS PERS COMMUN, V115, P2917, DOI 10.1007/s11277-020-07199-0
   Khelloufi A, 2021, IEEE INTERNET THINGS, V8, P1859, DOI 10.1109/JIOT.2020.3016659
   Lee D, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P317, DOI 10.1145/3404835.3462935
   Liu DY, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P200, DOI 10.1145/3383313.3412237
   Mo F, 2020, IEEE INT CONF BIG DA, P5783, DOI 10.1109/BigData50022.2020.9378436
   Park DH, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1443, DOI 10.1145/3308558.3313416
   Polydoros AS, 2017, J INTELL ROBOT SYST, V86, P153, DOI 10.1007/s10846-017-0468-y
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Van den Broeck E, 2019, COMPUT HUM BEHAV, V98, P150, DOI 10.1016/j.chb.2019.04.009
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang QY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2467, DOI 10.1145/3219819.3220004
   Wang WJ, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P373, DOI 10.1145/3437963.3441800
   Wang X, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P99, DOI 10.1145/3366423.3380098
   Wang X, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P950, DOI 10.1145/3292500.3330989
   Wu F, 2019, PR MACH LEARN RES, V97
   Xu ZH, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1921, DOI 10.1145/2983323.2983874
   Yang Z, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1666, DOI 10.1145/3394486.3403218
   You CX, 2019, ROBOT AUTON SYST, V114, P1, DOI 10.1016/j.robot.2019.01.003
   Zhang WN, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P785
   Zhao XY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1040, DOI 10.1145/3219819.3219886
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
   Zhou MZ, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P727, DOI 10.1145/3159652.3159671
   Zhou X., 2023, ACM Trans. Recommender Syst., V1, P1, DOI 10.1145/3591469
   Zou LX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2810, DOI 10.1145/3292500.3330668
NR 33
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17521-0
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200007
DA 2024-07-18
ER

PT J
AU Liu, CH
   Li, SC
   Chen, L
AF Liu, Changhong
   Li, Shengchun
   Chen, Liang
TI Automatic statistical chart analysis based on deep learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Statistical chart analysis; Natural language generation; Quality control
   platform; Manufacturing enterprises; Knowledge distillation
AB In order to make full use of the decision support knowledge contained in the structured chart data that matches the needs of the enterprise, we propose a deep learning approach for automatic statistical chart analysis. This method uses LSTM as the basic model for chart analysis, and mainly makes the following improvements: (1) A discriminator layer is added after the embedding layer of the model, so that the model can perform more targeted semantic understanding and text prediction according to the knowledge of chart; (2) In the character sampling process of the model, a random cluster sampling strategy is proposed to improve the quality of chart description; (3) The model is optimized by using the knowledge distillation method, so that it can generate more valuable description text for manufacturing scenarios. Experiments show that this method improves the text quality by 12.4% compared with traditional LSTM. To further evaluate the analysis description quality of ASCAT, we use the same dataset to train RNN, LSTM, AISG, EICT, and AGNLD models. Experiment results show that our ASCAT model obtained better description quality evaluation scores in description quality under the METEOR criteria considering the precision and recall rate, or under the CIDEr criteria with the TF-IDF weight introduced.
C1 [Liu, Changhong; Li, Shengchun] China Tobacco Chongqing Ind Co Ltd, Qianjiang Cigarette Factory Chongqing, Chongqing 409000, Peoples R China.
   [Chen, Liang] Xian Polytech Univ, Sch Comp Sci, Dept Comp Applicat, Xian, Peoples R China.
C3 China National Tobacco Corporation; Xi'an Polytechnic University
RP Liu, CH (corresponding author), China Tobacco Chongqing Ind Co Ltd, Qianjiang Cigarette Factory Chongqing, Chongqing 409000, Peoples R China.
EM liuch02@cncqti.com
CR Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Bezerra A, 2020, IFAC PAPERSONLINE, V53, P11162, DOI 10.1016/j.ifacol.2020.12.292
   Breve B, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100240
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Cao S, 2022, IEEE T CIRC SYST VID, V32, P7005, DOI 10.1109/TCSVT.2022.3178844
   Chaudhry R, 2020, IEEE WINTER C APPL C
   [陈亮 Chen Liang], 2021, [计算机集成制造系统, Computer Integrated Manufacturing Systems], V27, P1641
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   Dou Xin, 2022, 2022 Global Conference on Robotics, Artificial Intelligence and Information Technology (GCRAIT), P414, DOI 10.1109/GCRAIT55928.2022.00094
   Emre O, arXiv, DOI [10.48550/arXiv.2307.08326, DOI 10.48550/ARXIV.2307.08326]
   Farahani AM, 2023, IEEE ACCESS, V11, P76202, DOI 10.1109/ACCESS.2023.3298050
   Kallimani JS, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P382, DOI 10.1109/ICACCI.2013.6637202
   Kannan R, 2022, INTEGR MATER MANUF I, V11, P57, DOI 10.1007/s40192-021-00243-2
   Li HJ, 2021, PROCEDIA COMPUT SCI, V187, P24, DOI 10.1016/j.procs.2021.04.029
   Li Q., 2021, Int Conf Adv Energy Resour Environ Eng (ICAESEE), V647
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Loredana C, 2023, P 26 INT C EXTENDING, P823
   Mahmood A, 2014, INT C INTEL HUM MACH, P376, DOI 10.1109/IHMSC.2014.192
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040615
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Song J, 2022, IEEE T IMAGE PROCESS, V31, P3359, DOI 10.1109/TIP.2022.3170728
   de Oliveira CLT, 2019, IEEE INT CON INF VIS, P163, DOI 10.1109/IV.2019.00036
   Tian G, 2017, KNOWL INF SYST, V53, P507, DOI 10.1007/s10115-017-1039-z
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wei L, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P44, DOI [10.1109/ICCCBDA.2019.8725665, 10.1109/icccbda.2019.8725665]
   Wu W., 2020, Sig Process, V36, P1525
   Xuemei Bai, 2018, 2018 Thirteenth International Conference on Digital Information Management (ICDIM), P29, DOI 10.1109/ICDIM.2018.8847061
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang ZB, 2021, NEUROCOMPUTING, V460, P84, DOI 10.1016/j.neucom.2021.07.002
   Zheng XR, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P162, DOI 10.1109/ASRU51503.2021.9688232
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17420-4
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900003
DA 2024-07-18
ER

PT J
AU Swetha, G
   Kumar, SP
AF Swetha, G.
   Kumar, S. Phani
TI A hierarchical framework based on transformer technology to achieve
   factual consistent and non-redundant abstractive text summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abstractive summarization; Hierarchical framework; Transformer
   technology; Multi-head self-attention mechanism; Sequential context;
   Local convolution
AB The Abstractive summarization is one of the popular topics that has been the researchers' attention for several years. This is because of the widespread application frameworks included in this field. Most of the existing summarization frameworks cannot provide effective abstracts as the contextual information of the input is not given importance. To deal with the problem, this work introduces a hierarchical framework using transformer technology to produce effective abstracts. The proposed framework includes preprocessing, extractive summarization, and abstractive summarization as the basic steps of the work. Initially, the input contents are preprocessed to obtain a clean document, and then the contents are provided to the extractive summarization unit. This unit consists of a fine-tuned BERTSum model (FTBS), which is a pre-trained model to produce the required extractive summary. The output is then provided to the proposed convolutional bidirectional gated recurrent unit transformer (CBi-GRUT) model, where an additional encoder model is introduced with the traditional transformer technology to obtain the output. The outcomes of the model are then assessed with the existing models to prove its efficacy, and the evaluations are carried out using the CNN/Daily Mail dataset. The proposed method achieved an average ROUGE-1 score of 0.78, average ROUGE-2 score of 0.68 and an average ROUGE-L score of 0.77.
C1 [Swetha, G.] GITAM Deemed Univ, CSE, Hyderabad 502329, Telangana, India.
   [Kumar, S. Phani] GITAM Deemed Univ, Dept Comp Sci & Engn, Hyderabad 502329, Telangana, India.
C3 Gandhi Institute of Technology & Management (GITAM); Gandhi Institute of
   Technology & Management (GITAM)
RP Kumar, SP (corresponding author), GITAM Deemed Univ, Dept Comp Sci & Engn, Hyderabad 502329, Telangana, India.
EM sgatla@gitam.in; psingams@gitam.edu
RI Gatla, swetha/JPL-9497-2023
OI Gatla, swetha/0000-0002-1014-8514
CR Abdi A, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106658
   Abu Nada AM, Arabic text summarization using arabert model using extractive text summarization approach
   Abualigah L., 2019, Recent Advances in NLP: The Case of Arabic Language, P1
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Afzal M, 2020, J MED INTERNET RES, V22, DOI 10.2196/19810
   Alahmadi D, 2022, J KING SAUD UNIV-COM, V34, P2651, DOI 10.1016/j.jksuci.2022.03.026
   Aliakbarpour H, 2022, J SUPERCOMPUT, V78, P2528, DOI 10.1007/s11227-021-03950-x
   Alomari A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101276
   Awasthi I, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1310, DOI 10.1109/ICICT50816.2021.9358703
   Belwal RC, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102536
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679
   Haider MM, 2020, IEEE REGION 10 SYMP, P283
   Huang YC, 2021, Arxiv, DOI arXiv:2104.14839
   Jia RP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3622
   Lamsiyah S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114152
   Li Y, 2023, Multimed Tools App, P1
   Liao WZ, 2021, NEUROCOMPUTING, V448, P228, DOI 10.1016/j.neucom.2021.02.028
   Ma CB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3529754
   Magdum P. G., 2021, Advances in artificial intelligence and data engineering, P377
   Mohsin M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210511
   Moradi M, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105117
   Moratanch N, 2023, MULTIMED TOOLS APPL, V82, P4569, DOI 10.1007/s11042-022-13299-9
   Muneera NM., 2022, Multimed Tools App, V82, P23331
   Nambiar Sindhya K., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P347, DOI 10.1109/ICACCS51430.2021.9442060
   Poornima M, 2022, ALGO INTELL SY, P57, DOI 10.1007/978-981-16-7389-4_6
   Saiyyad M. M., 2022, Applied Computational Technologies: Proceedings of ICCET 2022. Smart Innovation, Systems and Technologies (303), P434, DOI 10.1007/978-981-19-2719-5_41
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Suleiman D, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9365340
   Syed AA, 2021, IEEE ACCESS, V9, P13248, DOI 10.1109/ACCESS.2021.3052783
   Xu WT, 2022, MULTIMED TOOLS APPL, V81, P7419, DOI 10.1007/s11042-021-11762-7
   Yang M, 2020, INFORM SCIENCES, V521, P46, DOI 10.1016/j.ins.2020.02.040
   Zad Samira, 2021, 2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0466, DOI 10.1109/IEMCON53756.2021.9623078
NR 32
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17426-y
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300016
DA 2024-07-18
ER

PT J
AU Xu, FH
   Zeng, H
AF Xu, Feihong
   Zeng, Hui
TI On the security of two signature schemes for secure communication in IoT
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pairing; Certificateless signature; Aggregate signature; IoT
ID CERTIFICATELESS AGGREGATE SIGNATURE; EFFICIENT
AB Recently, Thumbur et al. (IEEE Commun Lett 24(8): 1641-1645, 2020) proposed a pairing-free certificateless signature (PF-CLS) scheme for secure communication in resource-constrained devices. Zhan et al. (IEEE Internet of Things Journal, pp 1-1, 2020) proposed a pairing-free certificateless aggregate signature (PF-CLAS) in healthcare wireless medical sensor networks. The authors proved the security of their schemes under the hardness of mathematical problems in the random oracle model respectively. Unfortunately, we find that the above two recent schemes are insecure. By providing concrete attacks, in this work, we show that an attacker with replacing public key ability can easily impersonate other legitimate users to upload some false messages by forging the target users' valid signatures on these messages. As a result, the above two signature schemes PF-CLS and PF-CLAS cannot solve the IoT data authenticity and integrity issues pointed out by them. Moreover, we discuss the reasons for our attacks and provide relevant improvements.
C1 [Xu, Feihong] Wuchang Univ Technol, Sch Artificial Intelligence, Wuhan, Peoples R China.
   [Zeng, Hui] Hubei Open Univ, Sch Software Engn, Wuhan, Peoples R China.
C3 Wuchang University of Technology
RP Xu, FH (corresponding author), Wuchang Univ Technol, Sch Artificial Intelligence, Wuhan, Peoples R China.
EM fhxuwyy@163.com
RI Zeng, Hui/AAB-7183-2022
FU The authors would like to thank anonymous reviewers for his/her valuable
   comments.
FX The authors would like to thank anonymous reviewers for his/her valuable
   comments.
CR Al-Riyami SS, 2003, LECT NOTES COMPUT SC, V2894, P452
   Boneh D, 2003, LECT NOTES COMPUT SC, V2656, P416
   Du HZ, 2020, AD HOC NETW, V100, DOI 10.1016/j.adhoc.2020.102074
   Gayathri NB, 2019, IEEE INTERNET THINGS, V6, P9064, DOI 10.1109/JIOT.2019.2927089
   Hess F, 2003, LECT NOTES COMPUT SC, V2595, P310, DOI 10.1007/3-540-36492-7_20
   Karati A, 2018, IEEE T IND INFORM, V14, P3701, DOI 10.1109/TII.2018.2794991
   Lee DH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143983
   Liu JH, 2020, IEEE INTERNET THINGS, V7, P5256, DOI 10.1109/JIOT.2020.2979613
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Shim KA, 2020, IEEE ACCESS, V8, P167203, DOI 10.1109/ACCESS.2020.3023093
   Su JS, 2014, FUTURE GENER COMP SY, V33, P11, DOI 10.1016/j.future.2013.10.016
   Thumbur G, 2020, IEEE COMMUN LETT, V24, P1641, DOI 10.1109/LCOMM.2020.2988818
   Zhan Y, 2021, IEEE INTERNET THINGS, V8, P5973, DOI 10.1109/JIOT.2020.3033337
   Zhu F, 2021, IEEE INTERNET THINGS, V8, P11678, DOI 10.1109/JIOT.2021.3059570
NR 14
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17312-7
EA OCT 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100004
DA 2024-07-18
ER

PT J
AU Madala, K
   Prasad, MSG
AF Madala, Kranthi
   Prasad, M. Siva Ganga
TI Crop mapping through hybrid capsule transient auto-encoder technique
   based on radar features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pre-processing; Clustering; Classification; Optimization; Auto-encoder;
   Radar features
ID FEATURE-SELECTION; COMBINED MODEL; CLASSIFICATION; PREDICTION; DROUGHT
AB Agriculture is considered as the important field which makes its huge contribution over the country's economic growth. The yield of food crops and the precise categorization of crops based on several characteristics are of primary importance in this agricultural industry. However, due to a lack of an effective classification method, this industry has significant issues correctly classifying the crops. In addition, classifying food crops using data mining is highly efficient as these techniques can deal with huge amounts of crop data. To this extent, this paper proposes an efficient classification model based on the cropland data extracted from the cropland images. Initially, the dataset is pre-processed based on data-mining techniques like data cleaning and data discretization. Then, the data are clustered based on their relevance using an Improved Density-based Spatial Clustering of Applications with Noise (IDBSCAN) clustering technique. Finally, classification is performed accurately using the Adaptive Capsule Transient Auto-Encoder (ACTAE). The experimental validation of a proposed approach proved its efficiency over the other existing models with an overall accuracy rate of 97% which is incomparable to the other crop classification models implemented over the cropland dataset.
C1 [Madala, Kranthi] Koneru Lakshmaiah Educ Fdn, Dept Elect & Comp Engn, Guntur 522302, Andhra Pradesh, India.
   [Madala, Kranthi; Prasad, M. Siva Ganga] VR Siddhartha Engn Coll, Dept Elect & Instrumentat Engn, Vijayawada 520007, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Velagapudi Ramakrishna Siddhartha Engineering College
RP Madala, K (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Elect & Comp Engn, Guntur 522302, Andhra Pradesh, India.; Madala, K (corresponding author), VR Siddhartha Engn Coll, Dept Elect & Instrumentat Engn, Vijayawada 520007, Andhra Pradesh, India.
EM kranthimadala16@gmail.com
RI Madala, Kranthi/HLQ-0789-2023
OI Madala, Kranthi/0000-0002-4277-6443
CR Agana Norbert A., 2017, P WORKSH MIN BIG DAT, P27
   Akbari E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091449
   Ali M, 2018, AGR FOREST METEOROL, V263, P428, DOI 10.1016/j.agrformet.2018.09.002
   Chen JY, 2020, IEEE T NEUR NET LEAR, V31, P2653, DOI 10.1109/TNNLS.2020.2984686
   Cooper M, 2020, CROP SCI, V60, P582, DOI 10.1002/csc2.20109
   Feng SW, 2019, IEEE J-STARS, V12, P3295, DOI 10.1109/JSTARS.2019.2922469
   Gao JF, 2018, INT J APPL EARTH OBS, V67, P43, DOI 10.1016/j.jag.2017.12.012
   Georganos S, 2018, GISCI REMOTE SENS, V55, P221, DOI 10.1080/15481603.2017.1408892
   Guo J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020321
   Hamidi M, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12112615
   Hariharan S, 2018, IEEE J-STARS, V11, P4244, DOI 10.1109/JSTARS.2018.2866407
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   Hu Q, 2019, INT J APPL EARTH OBS, V80, P218, DOI 10.1016/j.jag.2019.04.014
   Jia D, 2020, INT J REMOTE SENS, V41, P8096, DOI 10.1080/01431161.2020.1771790
   Khaki S, 2020, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01750
   Khan MMH, 2020, J HYDROL, V590, DOI 10.1016/j.jhydrol.2020.125380
   Khosravi I, 2019, INT J REMOTE SENS, V40, P7221, DOI 10.1080/01431161.2019.1601285
   Dang KB, 2019, ENVIRON MODELL SOFTW, V114, P166, DOI 10.1016/j.envsoft.2019.01.015
   Kogan F, 2019, GEOMAT NAT HAZ RISK, V10, P651, DOI 10.1080/19475705.2018.1541257
   Kwak GH, 2020, KOREAN J REMOTE SENS, V36, P515
   Li BJ, 2018, GREY SYST, V8, P25, DOI 10.1108/GS-07-2017-0020
   Li HP, 2020, INT J APPL EARTH OBS, V87, DOI 10.1016/j.jag.2019.102032
   Ma L, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6020051
   Mandal D, 2022, GEOCARTO INT, V37, P1547, DOI 10.1080/10106049.2020.1783577
   Navas-Palencia G, 2022, Arxiv, DOI arXiv:2001.08025
   Nikfalazar S, 2020, KNOWL INF SYST, V62, P2419, DOI 10.1007/s10115-019-01427-1
   Palanivel K., 2019, Int. J. Computer Eng. Technol., V10, P110, DOI [DOI 10.34218/IJCET.10.3.2019.013, 10.34218/IJCET.10.3.2019.013]
   Paul S, 2023, INT J REMOTE SENS, V44, P1628, DOI 10.1080/01431161.2023.2187724
   Qais MH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111807
   Qais MH, 2020, APPL INTELL, V50, P3926, DOI 10.1007/s10489-020-01727-y
   Qais MH, 2020, ENERG CONVERS MANAGE, V214, DOI 10.1016/j.enconman.2020.112904
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Song Q, 2019, INT J REMOTE SENS, V40, P2053, DOI 10.1080/01431161.2018.1475779
   Su JY, 2020, UNMANNED SYST, V8, P71, DOI 10.1142/S2301385020500053
   Sun YW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194227
   Tang ZW, 2020, IEEE J-STARS, V13, P1700, DOI 10.1109/JSTARS.2020.2983439
   Venkatanaresh M, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109881
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Wang ZJ, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/6943234
   Xu L, 2018, J HYDROL, V566, P235, DOI 10.1016/j.jhydrol.2018.09.020
   Yang N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121500
   Yin LK, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010162
   Zhang C, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.104989
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17327-0
EA OCT 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000020
DA 2024-07-18
ER

PT J
AU Sewal, P
   Singh, H
AF Sewal, Piyush
   Singh, Hari
TI Analyzing distributed Spark MLlib regression algorithms for accuracy,
   execution efficiency and scalability using best subset selection
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Covid-19; Machine Learning; Apache Spark; Cluster; Regression;
   Scalability; Distributed; Execution Time
AB Numerous studies emphasize accuracy in machine learning regression models, yet scalability and execution efficiency are often overlooked, critical for large datasets or extensive computations. This paper introduces a scalable, distributed Spark MLlib regression model through the best subset selection approach to predict Covid-19 statistics in India, demonstrating high accuracy, scalability, and execution efficiency. Notably, limited research focuses on tree-based regression, particularly gradient boost regression, in the context of the Covid-19 dataset. The proposed work optimizes regression models for accuracy and execution time on Spark clusters of varying sizes using the best subset selection approach. Evaluation encompasses Root Mean Square Error (RMSE), Mean Absolute Error (MAE), R-2 Error for accuracy, and execution time analysis. Results indicate superior prediction accuracy in tree-based regression, with Gradient Boosted Tree Regression (GBTR) leading, and Random Forest Regression (RFR) surpassing Decision Tree Regression (DTR). Accuracy remains consistent across Python library, Spark MLlib on a single machine, and clusters of varying sizes, with Spark MLlib displaying lower execution times than Python's machine learning library on a single machine. Furthermore, execution times decrease substantially within Spark clusters, particularly for the iterative GBTR. This research uncovers scalability and execution efficiency aspects, highlighting tree-based regression's accuracy and advocating for Spark MLlib's efficacy in enhancing execution efficiency, especially across multi-node clusters.
C1 [Sewal, Piyush; Singh, Hari] Jaypee Univ Informat Technol, Comp Sci & Engn Dept, Solan, Himachal Prades, India.
C3 Jaypee University of Information Technology
RP Sewal, P (corresponding author), Jaypee Univ Informat Technol, Comp Sci & Engn Dept, Solan, Himachal Prades, India.
EM piyush.sewal@gmail.com; hsrawat2016@gmail.com
RI Singh, Hari/C-9822-2019
OI Singh, Hari/0000-0002-4063-9533; Sewal, Piyush/0000-0002-9975-0906
CR Abkenar SB, 2021, TELEMAT INFORM, V57, DOI 10.1016/j.tele.2020.101517
   Agerri R, 2015, KNOWL-BASED SYST, V79, P36, DOI 10.1016/j.knosys.2014.11.007
   AL-Rousan N, 2020, J MED VIROL, V92, P1603, DOI 10.1002/jmv.25850
   Anastassopoulou C, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230405
   [Anonymous], 2012, P 9 USENIX S NETW SY
   Arpaci I, 2021, Studies in Systems, Decision and Control, V348, DOI [10.1007/978-3-030-67716-9, DOI 10.1007/978-3-030-67716-9]
   Assaf D, 2020, INTERN EMERG MED, V15, P1435, DOI 10.1007/s11739-020-02475-0
   Assefi Mehdi, 2017, 2017 IEEE International Conference on Big Data (Big Data), P3492, DOI 10.1109/BigData.2017.8258338
   Azeroual O, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5010012
   Brinati D, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01597-4
   Çakan S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110033
   Chicco D, 2023, PLOS COMPUT BIOL, V19, DOI 10.1371/journal.pcbi.1011272
   Cui SZ, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107946
   Ghosal S, 2020, DIABETES METAB SYND, V14, P311, DOI 10.1016/j.dsx.2020.03.017
   Gopalani S., 2015, Int. J. Comput. Appl., V113, P8, DOI [10.5120/19788-0531, DOI 10.5120/19788-0531]
   Gu L, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P721, DOI 10.1109/HPCC.and.EUC.2013.106
   Guo RX, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy098
   Han S., 2017, em Proceedings of the International Conference on Research in Adaptive and Convergent Systems, P275, DOI [10.1145/3129676, DOI 10.1145/3129676]
   Janssen M., 2015, Lect Notes Comput Sci, V3, P200, DOI [10.1007/978-3-319-25013-7, DOI 10.1007/978-3-319-25013-7]
   kaggle, Kaggle: Your Machine Learning and Data Science Community
   Kamalov F., 2023, Data Sci Genom, P277, DOI 10.1016/B978-0-323-98352
   Kamalov F, 2022, NEUROCOMPUTING, V511, P142, DOI 10.1016/j.neucom.2022.09.005
   Kwekha-Rashid AS, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-01868-7
   Lin XQ, 2013, 2013 5TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY (IC-BNMT), P273, DOI 10.1109/ICBNMT.2013.6823956
   Magdon-Ismail M, Machine Learning the Phenomenology of COVID-19 From Early Infection Dynamics, P1, DOI [10.48550/arXiv.2003.07602, DOI 10.48550/ARXIV.2003.07602]
   Manconi A, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e13368
   Mehta N, 2018, INT J MED INFORM, V114, P57, DOI 10.1016/j.ijmedinf.2018.03.013
   Melenli Sadettin, 2021, Trends in Data Engineering Methods for Intelligent Systems. Proceedings of the International Conference on Artificial Intelligence and Applied Mathematics in Engineering (ICAIAME 2020). Lecture Notes on Data Engineering and Communications Technologies (LNDECT 76), P578, DOI 10.1007/978-3-030-79357-9_55
   Mostafaeipour A, 2021, J SUPERCOMPUT, V77, P1273, DOI 10.1007/s11227-020-03328-5
   Muhammad L J, 2021, SN Comput Sci, V2, P11, DOI 10.1007/s42979-020-00394-7
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nabi KN, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110046
   Nayak Janmenjoy, 2022, Research on Biomedical Engineering, V38, P243, DOI 10.1007/s42600-021-00135-6
   Ostertagová E, 2012, PROCEDIA ENGINEER, V48, P500, DOI 10.1016/j.proeng.2012.09.545
   Peng YH, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110055
   Prietoid K, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0259958
   Sewal Piyush, 2022, 2022 Seventh International Conference on Parallel, Distributed and Grid Computing (PDGC), P331, DOI 10.1109/PDGC56933.2022.10053356
   Sewal Piyush, 2021, 2021 6th International Conference on Signal Processing, Computing and Control (ISPCC), P308, DOI 10.1109/ISPCC53510.2021.9609518
   Sharma Tapan, 2016, International Journal of Advanced Studies in Computer Science and Engineering, V5, P23
   Sharma VikasK., 2020, Trans Indian Natl. Acad. Eng, V5, P697
   Shinde Gitanjali R, 2020, SN Comput Sci, V1, P197, DOI 10.1007/s42979-020-00209-9
   SINGH H., 2018, Adv. Parallel Comput., V29, P1, DOI [10.3233/978-1-61499-814-3-1, DOI 10.3233/978-1-61499-814-3-1]
   Singh H, 2022, MULTIMEDIA SYST, V28, P113, DOI 10.1007/s00530-021-00798-2
   Singh H, 2017, FUTURE GENER COMP SY, V73, P32, DOI 10.1016/j.future.2017.03.028
   Singhal A, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.110023
   Sun JC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78084-w
   Le TM, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9050798
   Yadav RK, 2020, INT J MACH LEARN CYB, V11, P1571, DOI [10.1007/s13042-019-01059-5, 10.1007/s41870-020-00484-y]
NR 48
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17330-5
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000011
DA 2024-07-18
ER

PT J
AU Basarslan, MS
   Kayaalp, F
AF Basarslan, Muhammet Sinan
   Kayaalp, Fatih
TI Sentiment analysis using a deep ensemble learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment Analysis; Text Representation; Word Embedding; Ensemble
   Learning; Deep Learning; Machine Learning; Deep Ensemble Learning
ID COVID-19
AB The coronavirus pandemic has kept people away from social life and this has led to an increase in the use of social media over the past two years. Thanks to social media, people can now instantly share their thoughts on various topics such as their favourite movies, restaurants, hotels, etc. This has created a huge amount of data and many researchers from different sciences have focused on analysing this data. Natural Language Processing (NLP) is one of these areas of computer science that uses artificial technologies. Sentiment analysis is also one of the tasks of NLP, which is based on extracting emotions from huge post data. In this study, sentiment analysis was performed on two datasets of tweets about coronavirus and TripAdvisor hotel reviews. A frequency-based word representation method (Term Frequency-Inverse Document Frequency (TF-IDF)) and a prediction-based Word2Vec word embedding method were used to vectorise the datasets. Sentiment analysis models were then built using single machine learning methods (Decision Trees-DT, K-Nearest Neighbour-KNN, Naive Bayes-NB and Support Vector Machine-SVM), single deep learning methods (Long Short Term Memory-LSTM, Recurrent Neural Network-RNN) and heterogeneous ensemble learning methods (Stacking and Majority Voting) based on these single machine learning and deep learning methods. Accuracy was used as a performance measure. The heterogeneous model with stacking (LSTM-RNN) has outperformed the other models with accuracy values of 0.864 on the coronavirus dataset and 0.898 on the Trip Advisor dataset and they have been evaluated as promising results when compared to the literature. It has been observed that the use of single methods as an ensemble gives better results, which is consistent with the literature, which is a step forward in the detection of sentiments through posts. Investigating the performance of heterogeneous ensemble learning models based on different algorithms in sentiment analysis tasks is planned as future work.
C1 [Basarslan, Muhammet Sinan] Istanbul Medeniyet Univ, Nat Sci & Engn Fac, Dept Comp Engn, TR-34720 Istanbul, Turkiye.
   [Kayaalp, Fatih] Duzce Univ, Fac Engn, Dept Comp Engn, TR-81620 Duzce, Turkiye.
C3 Istanbul Medeniyet University; Duzce University
RP Basarslan, MS (corresponding author), Istanbul Medeniyet Univ, Nat Sci & Engn Fac, Dept Comp Engn, TR-34720 Istanbul, Turkiye.
EM muhammet.basarslan@medeniyet.edu.tr
RI BAŞARSLAN, MUHAMMET SİNAN/AAH-2116-2020
OI BAŞARSLAN, MUHAMMET SİNAN/0000-0002-7996-9169; Kayaalp,
   Fatih/0000-0002-8752-3335
CR Agbulut Ü, 2021, RENEW SUST ENERG REV, V135, DOI 10.1016/j.rser.2020.110114
   Alam MH, 2016, INFORM SCIENCES, V339, P206, DOI 10.1016/j.ins.2016.01.013
   [Anonymous], Keras
   Antonio VD, 2022, INT J NONLINEAR ANAL, V13, P1367, DOI 10.22075/ijnaa.2021.5735
   Bakay MS, 2021, J CLEAN PROD, V285, DOI 10.1016/j.jclepro.2020.125324
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Basarslan M.S., 2021, Sakarya University Journal of Computer and Information Sciences, V4, P35, DOI 10.35377/saucis.04.01.833026
   Basarslan MS., 2023, Turkish Journal of Engineering, V7, P141, DOI [10.31127/tuje.1079698, DOI 10.31127/TUJE.1079698]
   Basarslan MS, 2023, J CLOUD COMPUT-ADV S, V12, DOI 10.1186/s13677-022-00386-3
   Basarslan MS, 2020, ADCAIJ-ADV DISTRIB C, V9, P5, DOI 10.14201/ADCAIJ202093515
   Canli H, 2021, IEEE ACCESS, V9, P61171, DOI 10.1109/ACCESS.2021.3074887
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dang EL, 2022, Arxiv, DOI arXiv:2207.12883
   Dehkharghani R, 2012, INT CONF DAT MIN WOR, P669, DOI 10.1109/ICDMW.2012.121
   Dogan G, 2020, UBICOMP/ISWC '20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P301, DOI 10.1145/3410530.3414354
   Garg M., 2022, Graph Learning and Network Science for Natural Language Processing, V1st, DOI [10.1201/9781003272649, DOI 10.1201/9781003272649]
   Gaur M, 2022, IEEE INTERNET COMPUT, V26, P5, DOI 10.1109/MIC.2022.3179759
   Google Brain Team, 2021, Tensorflow
   Google LLC, Colab
   Huang ZL, 2019, IEEE ACCESS, V7, P93139, DOI 10.1109/ACCESS.2019.2928037
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Isnain AR, 2021, IJCCS (Indonesian Journal of Computing and Cybernetics Systems), V15, P55, DOI [10.22146/ijccs.60718, DOI 10.22146/IJCCS.60718]
   Karita S, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P449, DOI [10.1109/asru46091.2019.9003750, 10.1109/ASRU46091.2019.9003750]
   Khurram Iqbal M, Omicron Tweet Sentiment Analysis Using Ensemble Learning, DOI [10.56979/402/2023, DOI 10.56979/402/2023]
   Li C., 2021, arXiv, DOI [10.48550/arxiv.2109.08306, 10.48550/arXiv.2109.08306]
   Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643
   Machuca Cristian R., 2021, Journal of Physics: Conference Series, V1828, DOI 10.1088/1742-6596/1828/1/012104
   Mahendrajaya M. B. S. R., 2019, Komputek, V3, P52
   Mardikoraem M, 2023, PHARMACEUTICS, V15, DOI 10.3390/pharmaceutics15051337
   Miglani Aman., 2020, Coronavirus tweets nlp - text classification
   Mikolov JT, 2013, Advances in Neural Information Processing Systems
   Mohammed A, 2023, J KING SAUD UNIV-COM, V35, P757, DOI 10.1016/j.jksuci.2023.01.014
   Moreno-Sandoval LG, 2020, Assembly of polarity, emotion and user statistics for detection of fake profiles Notebook for PAN at CLEF
   Mostafa Lamiaa, 2021, Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2020. Advances in Intelligent Systems and Computing (AISC 1261), P195, DOI 10.1007/978-3-030-58669-0_18
   Mostafa L., 2020, Machine Learning-Based Sentiment Analysis for Analyzing the Travelers Reviews on Egyptian Hotels, P405, DOI [10.1007/978-3-030-44289-7_38., DOI 10.1007/978-3-030-44289-7_38]
   Puertas E, 2021, COGN COMPUT, V13, P518, DOI 10.1007/s12559-021-09818-9
   python, Welcome to Python.org
   Rahadiyan HO, 2016, P INT CONF INTELL, P78, DOI 10.1109/ISMS.2016.38
   Rahman Md Mahbubar, 2022, Sentimental Analysis and Deep Learning: Proceedings of ICSADL 2021. Advances in Intelligent Systems and Computing (1408), P383, DOI 10.1007/978-981-16-5157-1_30
   Raut VB, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P556, DOI 10.1109/CICN.2014.126
   Sahu TP, 2016, 2016 INTERNATIONAL CONFERENCE ON MICROELECTRONICS, COMPUTING AND COMMUNICATIONS (MICROCOM)
   Shah SR, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020085
   Siddiqua UA, 2016, INT CONF COMPUT INFO, P304, DOI 10.1109/ICCITECHN.2016.7860214
   Tiwari P, 2020, COGNITIVE ANALYTICS, P689, DOI DOI 10.4018/978-1-7998-2460-2.CH036
   Uzun E, 2012, 2012 20 SIGN PROC CO, DOI [10.1109/SIU.2012.6204476, DOI 10.1109/SIU.2012.6204476]
   Vernikou S, 2022, NEURAL COMPUT APPL, V34, P19615, DOI 10.1007/s00521-022-07650-2
   World Health Organization, WHO STAT REG CLUST P
   Yang H, 2022, MULTIMED TOOLS APPL, V81, P15439, DOI 10.1007/s11042-022-12629-1
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou Y, 2019, Sentiment Classification With Deep Nural Networks
   Zolfaghari B, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3580218
NR 51
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17278-6
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400018
DA 2024-07-18
ER

PT J
AU Behara, G
   Yannam, VR
   Nayyar, A
   Bagal, DK
AF Behara, Gopal
   Yannam, V. Ramanjaneyulu
   Nayyar, Anand
   Bagal, Dilip Kumar
TI Integrating metadata into deep autoencoder for handling prediction task
   of collaborative recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Collaborative Filtering; Recommender System; Deep Learning; Metadata;
   Autoencoder
ID MATRIX FACTORIZATION; IMAGE
AB Nowadays, Deep learning (DL) techniques have been proven successful as learning techniques in various research fields ranging from computer vision to social networks. The approach of DL is flourishing in the field of recommender systems (RS). Researchers have deployed metadata or auxiliary information using DL approaches in diverse applications in the last decade to achieve better recommendation accuracy. Thus, the metadata plays a vital role in obtaining a better user-item interaction. At the same time, existing techniques are based on fixed user and item factors. Therefore, the model does not correctly identify actual latent factors representation, resulting in a high prediction error. To handle this problem, a user metadata embedding using a deep autoencoder RS model called "Metadata Embedding Deep AutoEncoder (MEDAE)" based collaborative filtering is proposed. MEDAE model takes embeds user metadata such as demographics along with the rating data. The MEDAE model consists of an embedding layer, Encoder, and Decoder. The embedding layer generates embedding or latent features of the users, items, and metadata; Encoder receives concatenated features of the user, item, and metadata, then encodes the inputs and passes them to the decoder; and the decoder reconstructs the output. To test the effectiveness of proposed model Root Mean Squared Error and Mean Absolute Error measures are used. Different architectures (like Big-Small-Big (BSB) (5), BSB (3), Small-Big-Small (3), and SBS (5)) of the MEDAE model are evaluated on MovieLens datasets along with different parameters such as activation functions (ELU and SELU) and regularization and results concluded that the MEDAE with SBS (3) and ELU + SELU component improves 4% of RMSE and 2% MAE over the baseline methods.
C1 [Behara, Gopal] Govt Coll Engn Kalahandi, Dept Comp Sci & Engn, Bhawanipatna 766003, Orissa, India.
   [Yannam, V. Ramanjaneyulu] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 569008, Orissa, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
   [Bagal, Dilip Kumar] Govt Coll Engn Kalahandi, Dept Mech Engn, Bhawanipatna 766003, Orissa, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM gbehera@gcekbpatna.ac.in; ramanjaneyulu.yannam@gmail.com;
   anandnayyar@duytan.edu.vn; dilipbagal90@gmail.com
RI BAGAL, DILIP KUMAR/P-4303-2014
OI BAGAL, DILIP KUMAR/0000-0002-8105-2616
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Agarwal D, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P19
   Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Alagappan JK, 2023, Pract Exper, V35, P7505
   Alameda-Pineda X, 2016, PROC CVPR IEEE, P5240, DOI 10.1109/CVPR.2016.566
   Aljunid Mohammed Fadhel, 2020, Procedia Computer Science, V171, P829, DOI 10.1016/j.procs.2020.04.090
   Behera Gopal, 2022, International Journal of Information Technology, P3637, DOI 10.1007/s41870-022-00982-1
   Behera Gopal, 2023, Procedia Computer Science, P1366, DOI 10.1016/j.procs.2023.01.115
   Behera G., 2022, P INT C PAR COMM COM, P137
   Behera G, 2022, J KING SAUD UNIV-COM, V34, P9953, DOI 10.1016/j.jksuci.2021.12.021
   Behera G, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01924-0
   Bennett J., 2007, SIGKDD Explor. Newsl., V9, P51
   Bougteb Y, 2022, INT J MOB COMPUT MUL, V13, DOI 10.4018/IJMCMC.297963
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/3077136.3080777
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Jalali S, 2022, J SUPERCOMPUT, V78, P7410, DOI 10.1007/s11227-021-04178-5
   Jena Kalyan Kumar, 2022, International Journal of Information Technology, V14, P2067, DOI 10.1007/s41870-022-00858-4
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Kawale J, 2015, P 24 ACM INT C INF K, P811, DOI DOI 10.1145/2806416.2806527
   Kim D, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P233, DOI 10.1145/2959100.2959165
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kuchaiev O, 2017, Arxiv, DOI arXiv:1708.01715
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu X, 2022, 2022 INT JOINT C NEU, P1
   Mecheri Karima, 2022, 2022 First International Conference on Big Data, IoT, Web Intelligence and Applications (BIWA), P31, DOI 10.1109/BIWA57631.2022.10038127
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Nahta R, 2021, MULTIMED TOOLS APPL, V80, P18553, DOI 10.1007/s11042-021-10529-4
   Nirmala SG., 2014, Wireless Mobile Commun (IJCNWMC), V4, P65
   Nisha CC, 2019, APPL INTELL, V49, P1937, DOI 10.1007/s10489-018-1359-z
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Ratnakanth G, 2022, Information and communication technology for competitive strategies (ICTCS 2021) Intelligent Strategies for ICT, P341
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726
   Shambour Q, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106545
   Shang J, 2018, IEEE DATA MINING, P1218, DOI 10.1109/ICDM.2018.00162
   Shang MS, 2019, IEEE-CAA J AUTOMATIC, V6, P131, DOI 10.1109/JAS.2018.7511189
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Strub F., 2015, P NIPS WORKSHOP MACH
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Tahmasebi H, 2021, NEURAL COMPUT APPL, V33, P1607, DOI 10.1007/s00521-020-05085-1
   Volkovs M, 2017, ADV NEUR IN, V30
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Weinan Zhang, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P45, DOI 10.1007/978-3-319-30671-1_4
   Wu CY, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3018661.3018689
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Xia Ning, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P497, DOI 10.1109/ICDM.2011.134
   Xiao T, 2019, AAAI CONF ARTIF INTE, P5474
   Yengikand AK, 2021, IEEE SYS MAN CYBERN, P2485, DOI 10.1109/SMC52423.2021.9658978
   Ying H, 2016, LECT NOTES ARTIF INT, V9652, P555, DOI 10.1007/978-3-319-31750-2_44
   Yoon Y.C., 2018, 2018 INT C PLATFORM, P1
   Yu JB, 2019, J PROCESS CONTR, V79, P1, DOI 10.1016/j.jprocont.2019.05.002
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
   Zhang GJ, 2020, FRONT COMPUT SCI-CHI, V14, P430, DOI 10.1007/s11704-018-8052-6
   Zhang L, 2011, PALGR MAC SER INT PO, P13
   Zhang S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P957, DOI 10.1145/3077136.3080689
   Zhang W, 2019, PLoS One, V14
   Zhang YH, 2021, IEEE ACCESS, V9, P17641, DOI 10.1109/ACCESS.2021.3053291
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 69
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17029-7
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400005
DA 2024-07-18
ER

PT J
AU Jain, PK
   Tadepalli, KV
   Roy, S
   Sharma, N
AF Jain, Pankaj Kumar
   Tadepalli, Kalyan V.
   Roy, Sudipta
   Sharma, Neeraj
TI Exploring deep learning for carotid artery plaque segmentation:
   atherosclerosis to cardiovascular risk biomarkers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Carotid biomarkers; Atherosclerosis, cIMT; Plaque
   morphology
ID INTIMA-MEDIA THICKNESS; B-MODE ULTRASOUND; STROKE RISK; LUMEN DIAMETER;
   INTRAVASCULAR ULTRASOUND; CORONARY ATHEROSCLEROSIS; TISSUE
   CHARACTERIZATION; SURROGATE MARKERS; MOLECULAR-BIOLOGY; ISCHEMIC-STROKE
AB Atherosclerosis, caused by a variety of extrinsic risk factors, is the major cause of the cardiovascular and cerebrovascular diseases that bring high mortality and morbidity globally, with substantial socio-economic impact. The development and progression of atherosclerosis is insidious, and early detection and intervention is vital to prevent debilitating cardiovascular events like myocardial infarction and stroke. Imaging biomarkers like carotid intima-media thickness (cIMT) and plaque area/burden that can identify subclinical disease and stratify risk are therefore crucial. This comprehensive review focuses on these biomarkers, their imaging using ultrasound, assessment using machine learning and deep learning techniques, and their association with cardiovascular risk factors. Measurement of cIMT and plaque area/burden in the common carotid artery (CCA) using deep learning models built on convolutional neural networks like UNet have shown good accuracy and reliability compared to manual methods. Expanding the scope to include the internal carotid artery (ICA) and carotid bulb presents greater technical challenges due to image acquisition difficulties, but deep learning methods utilizing architectures like attention-UNet show promise. However, several biases exist in current deep learning systems stemming from limited multi-center datasets, as models trained on specific patient cohorts underperform when assessed on diverse unseen test data. Eliminating these biases through techniques like transfer learning, aggregating multi-ethnic data, comparing multiple models, and combining deep learning with optimization algorithms can make these AI systems more generalizable and robust. Moving forward, automated measurement of carotid ultrasound imaging biomarkers of subclinical atherosclerosis using bias-free deep learning approaches can enable large-scale screening to identify individuals at risk of cardiovascular events, allowing early intervention to modify risk and prevent disease progression.
C1 [Jain, Pankaj Kumar; Sharma, Neeraj] Indian Inst Technol BHU, Sch Biomed Engn, Varanasi, UP, India.
   [Jain, Pankaj Kumar; Tadepalli, Kalyan V.; Roy, Sudipta] Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai, MH, India.
   [Tadepalli, Kalyan V.] Sir HN Reliance Fdn Hosp, Mumbai, MH, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Jain, PK (corresponding author), Indian Inst Technol BHU, Sch Biomed Engn, Varanasi, UP, India.; Jain, PK; Roy, S (corresponding author), Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai, MH, India.
EM pankajkrjain.rs.bme17@iitbhu.ac.in; sudiptaroy01@yahoo.com
RI Roy, Sudipta/T-5231-2019
OI Roy, Sudipta/0000-0001-5161-9311
CR Acharya UR, 2013, IEEE T INSTRUM MEAS, V62, P392, DOI 10.1109/TIM.2012.2217651
   Amato M, 2007, EUR HEART J, V28, P2094, DOI 10.1093/eurheartj/ehm244
   Araki T, 2017, COMPUT BIOL MED, V80, P77, DOI 10.1016/j.compbiomed.2016.11.011
   Araki T, 2016, COMPUT METH PROG BIO, V128, P137, DOI 10.1016/j.cmpb.2016.02.004
   Araki T, 2016, COMPUT METH PROG BIO, V124, P161, DOI 10.1016/j.cmpb.2015.10.022
   Balaha HM, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102156
   Balakrishnan S, 2022, BIOMED ENG-BIOMED TE, V67, P391, DOI 10.1515/bmt-2021-0044
   Barnett HJM, 1998, NEW ENGL J MED, V339, P1415, DOI 10.1056/NEJM199811123392002
   Bartlett ES, 2006, AM J NEURORADIOL, V27, P638
   Benjamin EJ, 2019, CIRCULATION, V139, pE56, DOI [10.1161/CIR.0000000000000746, 10.1161/CIR.0000000000000659]
   Biswas M, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103847
   Biswas M, 2019, MED BIOL ENG COMPUT, V57, P543, DOI 10.1007/s11517-018-1897-x
   Biswas M, 2018, COMPUT BIOL MED, V98, P100, DOI 10.1016/j.compbiomed.2018.05.014
   Boi A, 2018, CURR ATHEROSCLER REP, V20, DOI 10.1007/s11883-018-0736-8
   Bots ML, 2007, EUR HEART J, V28, P398, DOI 10.1093/eurheartj/ehl482
   Cardiovascular diseases (CVDs), www who int en news room fact sheets detail cardiovascular diseases (cvds).
   Cau R, 2021, EUR J RADIOL, V140, DOI 10.1016/j.ejrad.2021.109767
   Chauhan S., 2015, Journal of Preventive Cardiology, V4, P735
   Chiu B, 2012, J ULTRAS MED, V31, P1567
   Chu BC, 2004, STROKE, V35, P1079, DOI 10.1161/01.STR.0000125856.25309.86
   Cohn JN, 2004, CIRCULATION, V109, P31, DOI 10.1161/01.CIR.0000133442.99186.39
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cuadrado-Godia E, 2018, COMPUT BIOL MED, V101, P128, DOI 10.1016/j.compbiomed.2018.08.008
   de Korte CL, 2016, IEEE T ULTRASON FERR, V63, P1613, DOI 10.1109/TUFFC.2016.2572260
   Dong Y., 2017, 2017 IEEE Int. Conf. Smart Comput. SMARTCOMP, DOI DOI 10.1109/SMARTCOMP.2017.7947015
   Dunbar SB, 2018, CIRCULATION, V137, pE558, DOI 10.1161/CIR.0000000000000570
   Gago L, 2022, COMPUT METH PROG BIO, V223, DOI 10.1016/j.cmpb.2022.106954
   Gangopadhyay T, 2022, NETW MODEL ANAL HLTH, V11, DOI 10.1007/s13721-022-00394-y
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Gupta A, 2015, STROKE, V46, P91, DOI 10.1161/STROKEAHA.114.006091
   Halder S., 2023, Data Management, Analytics and Innovation, DOI [10.1007/978-981-99-1414-2_28, DOI 10.1007/978-981-99-1414-2_28]
   Herder M, 2012, STROKE, V43, P1818, DOI 10.1161/STROKEAHA.111.646596
   Ho SSY, 2016, QUANT IMAG MED SURG, V6, P285, DOI 10.21037/qims.2016.05.03
   Hong JT, 2010, J NEUROSURG-SPINE, V12, P613, DOI 10.3171/2010.1.SPINE09409
   Hopkins PN, 2013, PHYSIOL REV, V93, P1317, DOI 10.1152/physrev.00004.2012
   Hunt KJ, 2001, STROKE, V32, P1120, DOI 10.1161/01.STR.32.5.1120
   Hyde DE, 2004, STROKE, V35, P2776, DOI 10.1161/01.STR.0000147037.12223.d5
   Jain PK, 2022, J CARDIOVASC DEV DIS, V9, DOI 10.3390/jcdd9100326
   Jain PK, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106017
   Jain PK, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122257
   Jain PK, 2022, INT ANGIOL, V41, P9, DOI 10.23736/S0392-9590.21.04771-4
   Jain PK, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104721
   Jashari F, 2016, EUR J NEUROL, V23, P1241, DOI 10.1111/ene.13017
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kamalakannan S, 2017, INDIAN J MED RES, V146, P175, DOI 10.4103/ijmr.IJMR_516_15
   Kamenskiy AV, 2015, J VASC SURG, V62, P1521, DOI 10.1016/j.jvs.2014.10.041
   Kamycheva E, 2013, INT J ENDOCRINOL, V2013, DOI 10.1155/2013/305141
   Khanna NN, 2019, CURR ATHEROSCLER REP, V21, DOI 10.1007/s11883-019-0766-x
   Kim GH, 2017, KOREAN CIRC J, V47, P1, DOI 10.4070/kcj.2016.0232
   Krejza J, 2006, STROKE, V37, P1103, DOI 10.1161/01.STR.0000206440.48756.f7
   Kumar PK, 2017, MED BIOL ENG COMPUT, V55, P1415, DOI 10.1007/s11517-016-1601-y
   Prabha PL, 2021, J SUPERCOMPUT, V77, P10289, DOI 10.1007/s11227-021-03676-w
   Lee W, 2014, ULTRASONOGRAPHY, V33, P11
   Lekadir K, 2017, IEEE J BIOMED HEALTH, V21, P48, DOI 10.1109/JBHI.2016.2631401
   Li R, 2023, FRONT CARDIOVASC MED, V10, DOI 10.3389/fcvm.2023.1127653
   Li YH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030887
   Liapi GD, 2022, IFIP ADV INF COMM TE, V652, P187, DOI 10.1007/978-3-031-08341-9_16
   Libby P, 2006, AM J CLIN NUTR, V83, p456S
   Libby P, 2009, J AM COLL CARDIOL, V54, P2129, DOI 10.1016/j.jacc.2009.09.009
   Lin YP, 2022, ULTRASOUND MED BIOL, V48, P469, DOI 10.1016/j.ultrasmedbio.2021.11.001
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Liu Y, 2019, J CARDIOVASC MAGN R, V21, DOI 10.1186/s12968-019-0548-1
   Lloyd KD, 2012, INT J VASC MED, V2012, DOI 10.1155/2012/169323
   Londhe ND, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0635-x
   Ma W, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/2014349
   Mancini GB, 2004, CIRCULATION, V109, P22, DOI 10.1161/01.CIR.0000133443.77237.2f
   Mannarino E, 2008, CLIN CASES MINER BON, V5, P57
   Mathiesen EB, 2011, STROKE, V42, P972, DOI 10.1161/STROKEAHA.110.589754
   Mavrogeni, 2018, J VASC ULTRASOUND, V42, P162, DOI [DOI 10.1177/1544316718806421, 10.1177/1544316718806421]
   Meena T, 2023, Infor Reuse and Inte, P309, DOI 10.1109/IRI58017.2023.00061
   Meiburger KM, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105333
   Menchón-Lara RM, 2016, APPL SOFT COMPUT, V49, P616, DOI 10.1016/j.asoc.2016.08.055
   Meshram NH, 2020, ULTRASONIC IMAGING, V42, P221, DOI 10.1177/0161734620951216
   Meyer P, 2018, COMPUT BIOL MED, V98, P126, DOI 10.1016/j.compbiomed.2018.05.018
   Mirek AM, 2013, KARDIOL POL, V71, P810, DOI 10.5603/KP.2013.0192
   Mohamed AAA, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101728
   Mohebali J, 2015, J VASC SURG, V62, P1236, DOI 10.1016/j.jvs.2015.06.137
   Molinari F, 2012, ULTRASOUND IMAGING: ADVANCES AND APPLICATIONS, P129, DOI 10.1007/978-1-4614-1180-2_6
   Molinari F, 2012, IEEE T IMAGE PROCESS, V21, P1211, DOI 10.1109/TIP.2011.2169270
   Molinari F, 2011, IEEE ENG MED BIO, P5149, DOI 10.1109/IEMBS.2011.6091275
   Molinari F, 2010, IEEE T ULTRASON FERR, V57, P1112, DOI 10.1109/TUFFC.2010.1522
   Naghavi M, 2003, CIRCULATION, V108, P1664, DOI 10.1161/01.CIR.0000087480.94275.97
   Naim C, 2014, CAN ASSOC RADIOL J, V65, P275, DOI 10.1016/j.carj.2013.05.003
   Nambi V, 2013, J AM HEART ASSOC, V2, DOI 10.1161/JAHA.113.000180
   Nillmani, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030652
   Ozdemir Huseyin, 2006, Diagn Interv Radiol, V12, P142
   Pal D, 2023, Infor Reuse and Inte, P261, DOI 10.1109/IRI58017.2023.00052
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Park JH, 2022, ULTRASONICS, V120, DOI 10.1016/j.ultras.2021.106636
   Park Tae Ho, 2016, J Cardiovasc Ultrasound, V24, P91, DOI 10.4250/jcu.2016.24.2.91
   Patel AK, 2016, CURR ATHEROSCLER REP, V18, DOI 10.1007/s11883-016-0635-9
   Picano E, 2015, INT J MOL SCI, V16, P10121, DOI 10.3390/ijms160510121
   Pleouras Dimitrios S, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P1590, DOI 10.1109/EMBC48229.2022.9871632
   Polak JF, 2016, GLOB HEART, V11, P295, DOI 10.1016/j.gheart.2016.08.006
   Prabhakaran D, 2016, CIRCULATION, V133, P1605, DOI 10.1161/CIRCULATIONAHA.114.008729
   Punn NS, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3376922
   Remington LA, 2021, Clinical anatomy and physiology of the visual system E-Book, P350
   Rothwell PM, 2000, STROKE, V31, P622, DOI 10.1161/01.STR.31.3.622
   Roy S, 2014, Smart innovation, systems and technologies, V27, DOI [10.1007/978-3-319-07353-8_53, DOI 10.1007/978-3-319-07353-8_53]
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Roy S, 2019, LECT NOTES COMPUT SC, V11663, P159, DOI 10.1007/978-3-030-27272-2_14
   Roy S, 2017, COMPUT METH PROG BIO, V140, P307, DOI 10.1016/j.cmpb.2017.01.003
   Ruan LT, 2009, STROKE, V40, P702, DOI 10.1161/STROKEAHA.108.531608
   Saba L, 2018, J Clin Diagn Res: JCDR, V12, DOI [10.1016/j.ihj.2018.01.024, DOI 10.1016/J.IHJ.2018.01.024]
   Saba Luca, 2021, JVS Vasc Sci, V2, P149, DOI 10.1016/j.jvssci.2021.03.001
   Saba L, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3052577
   Saba L, 2019, INT ANGIOL, V38, P451, DOI 10.23736/S0392-9590.19.04267-6
   Saba L, 2018, INDIAN HEART J, V70, P649, DOI 10.1016/j.ihj.2018.01.024
   Saba L, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0745-0
   Saba L, 2016, COMPUT BIOL MED, V75, P217, DOI 10.1016/j.compbiomed.2016.06.010
   Saba L, 2016, J CLIN ULTRASOUND, V44, P210, DOI 10.1002/jcu.22334
   Singh S, 2024, INTEL MED, V4, P83, DOI 10.1016/j.imed.2023.05.003
   Skandha SS, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105131
   Spence JD, 2004, ARTERIOSCL THROM VAS, V24, pE188, DOI 10.1161/01.ATV.0000146160.22637.33
   Sudha S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1001-y
   Suri JS, 2010, Atherosclerosis Disease Management, P944, DOI 10.1007/978-1-4419-7222-4
   Tajbakhsh N, 2017, ELS MIC SOC BOOK SER, P105, DOI 10.1016/B978-0-12-810408-8.00007-9
   Teng ZZ, 2014, ACTA BIOMATER, V10, P5055, DOI 10.1016/j.actbio.2014.09.001
   Togay-Isikay C, 2005, ACTA NEUROL BELG, V105, P68
   Tracqui P, 2011, J STRUCT BIOL, V174, P115, DOI 10.1016/j.jsb.2011.01.010
   Vila MD, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101784
   Virani SS, 2021, CIRCULATION, V143, pe254, DOI 10.1161/CIR.0000000000000950
   Wei JH, 2022, IEEE T MED IMAGING, V41, P292, DOI 10.1109/TMI.2021.3111679
   Yang J, 2019, ULTRASONICS, V96, P24, DOI 10.1016/j.ultras.2019.03.014
   Zhang Z, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105395
   Zhou R, 2021, ULTRASOUND MED BIOL, V47, P2723, DOI 10.1016/j.ultrasmedbio.2021.05.023
   Zhou R, 2021, IEEE J BIOMED HEALTH, V25, P2967, DOI 10.1109/JBHI.2021.3060163
   Zhou R, 2019, MED PHYS, V46, P3180, DOI 10.1002/mp.13581
   Zhou TS, 2021, QUANT IMAG MED SURG, V11, P67, DOI 10.21037/qims-20-286
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2019, J DIGIT IMAGING, V32, P290, DOI 10.1007/s10278-018-0143-2
   Zhu Y, 2022, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.1057800
   Zreik M, 2019, IEEE T MED IMAGING, V38, P1588, DOI 10.1109/TMI.2018.2883807
NR 133
TC 2
Z9 2
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17243-3
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800002
DA 2024-07-18
ER

PT J
AU Chaithanya, BN
   Brahmananda, SH
AF Chaithanya, B. N.
   Brahmananda, S. H.
TI Revolutionizing ransomware detection and criticality assessment:
   Multiclass hybrid machine learning and semantic similarity-based end2end
   solution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ransomware; Malicious files; Machine learning; Hybridization; Data
   processing; Infection identification system; Criticality identification;
   Semantic algorithms
AB In the digital environment, a ransomware detection and protection solution is crucial. Because it makes it possible for companies to combat the rising threat of ransomware attacks, prevent financial losses, preserve crucial systems, and satisfy legal requirements. The primary issue is that current ransomware detection and mitigation methods could be more effective due to its dynamic nature and an insufficient up-to-date understanding of its variants. To create more effective defenses and narrow the cybersecurity knowledge gap, interdisciplinary research that examines ransomware's coding, behavior, and goals is required. This paper seeks to improve methods of ransomware defense by analyzing the code, behavior, and goals of numerous ransomware variants. The study proposes using semantic similarity algorithms to estimate the severity of attacks and identify connections between existing attacks to enhance detection and mitigation measures. The objectives of this paper include developing an improved, all-inclusive multiclass ransomware detection and response generation model with automatic or semi-automatic response capabilities. The method combines artificial intelligence with semantic similarity detection techniques to automatically identify and classify ransomware attacks using predefined classifiers. Single machine learning techniques were initially trained on a dataset of ransomware samples; however, the accuracy was poor, ranging from 11% with the LGBM classifier to a maximum of 51% with the decision tree classifier. A hybridization of ML algorithms increases accuracy, leading to a notable improvement in classifier accuracy, with a Hybrid 3 obtaining 91% accuracy. Semantic algorithms periodically retrain the model to keep it current with new ransomware variations. These algorithms also provide the severity of the attack. If the criticality is low, the model notifies the administrator for additional analysis; if it is medium, sensitive data-related operations are stopped with automatic backups; and if it is high, all processes are controlled to prevent further harm. The key advantages of this model are its ability to identify 21 different ransomware classes, enhance training with new variants, and provide criticality recommendations for optimal decision-making during a ransomware assault.
C1 [Chaithanya, B. N.; Brahmananda, S. H.] Gitam Sch Technol, Dept Comp Sci & Engn, Bangalore, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Chaithanya, BN (corresponding author), Gitam Sch Technol, Dept Comp Sci & Engn, Bangalore, India.
EM cnagaraj@gitam.edu; bsavadat@gitam.edu
RI bn, chaithanya/AAW-6428-2020
OI bn, chaithanya/0000-0002-2459-104X
CR Ali A., 2022, 2022 International Conference on Business Analytics for Technology and Security (ICBATS), P1, DOI DOI 10.1109/ICBATS54253.2022.9759076
   Almomani I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062281
   Alwashali AAMA, 2021, I C DEV ESYST ENG, P92, DOI [10.1109/DESE54285.2021.9719456, 10.1109/DeSE54285.2021.9719456]
   [Anonymous], 2021, Adv Mach Learn Artif Intell, V2, DOI [10.33140/amlai.02.01.03, DOI 10.33140/AMLAI.02.01.03]
   August T., 2019, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3351416
   Baker T, 2023, GENEVA PAP R I-ISS P, V48, P275, DOI 10.1057/s41288-022-00281-7
   Brewer Ross, 2016, Network Security, V2016, P5, DOI 10.1016/S1353-4858(16)30086-1
   Chaithanya BN, 2022, J Cyber Secur Mobil, DOI [10.13052/jcsm2245-1439.1146, DOI 10.13052/JCSM2245-1439.1146]
   Chaithanya BN, 2022, Detecting ransomware attacks distribution through phishing URLs Using Machine Learning, DOI [10.1007/978-981-16-3728-5_61, DOI 10.1007/978-981-16-3728-5_61]
   Connolly LY, 2019, COMPUT SECUR, V87, DOI 10.1016/j.cose.2019.101568
   Deshmukh RV, 2015, PROCEDIA COMPUT SCI, V49, P202, DOI 10.1016/j.procs.2015.04.245
   Enbody R, 2018, 2018 APWG S EL CRIM, P1, DOI [10.1109/ECRIME.2018.8376213, DOI 10.1109/ECRIME.2018.8376213]
   Fu Y. Ding, 2021, J CYBERSECURITY, V1, P11, DOI DOI 10.32604/JCS.2021.016632
   Bastos AF, 2021, ENERGIES, V14, DOI 10.3390/en14020463
   Humayun M, 2021, EGYPT INFORM J, V22, P105, DOI 10.1016/j.eij.2020.05.003
   Ismail I, 2015, INT J NETW MANAG, V25, P471, DOI 10.1002/nem.1913
   Jethva B, 2020, J COMPUT SECUR, V28, P337, DOI 10.3233/JCS-191346
   Jiang J, 2020, ANN INTERN MED, V172, P159, DOI 10.7326/M19-1759
   Kadavath R, 2022, SSRN Electron J, DOI [10.2139/ssrn.4294646, DOI 10.2139/SSRN.4294646]
   Kara I, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116198
   Kharraz A, 2018, IEEE SECUR PRIV, V16, P103, DOI 10.1109/MSP.2018.2701165
   Kumari S., 2021, INT J COGN COMPUT EN, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Lakhan A, 2023, IEEE T NETW SCI ENG, V10, P2466, DOI 10.1109/TNSE.2022.3213651
   Manickam S, 2022, IET NETW, V11, P169, DOI 10.1049/ntw2.12043
   Meland PH, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101762
   Mohammed MA, 2023, CAAI T INTELL TECHNO, DOI 10.1049/cit2.12200
   Nicol DM, 2021, IEEE SECUR PRIV, V19, P24, DOI [10.1109/MSEC.2021.30636780, 10.1109/MSEC.2021.3063678]
   Parkinson Simon, 2017, Network Security, V2017, P5, DOI 10.1016/S1353-4858(17)30069-7
   Pitropakis N, 2019, COMPUT SCI REV, V34, DOI 10.1016/j.cosrev.2019.100199
   Ramesh G, 2020, DECIS SUPPORT SYST, V138, DOI 10.1016/j.dss.2020.113400
   Sahs J., 2012, 2012 European Intelligence and Security Informatics Conference (EISIC), P141, DOI 10.1109/EISIC.2012.34
   Salitin MA, 2018, IEEE 2018 INT C INN, P1, DOI [10.1109/3ICT.2018.8855782, DOI 10.1109/3ICT.2018.8855782]
   Shi HB, 2014, IEEJ T ELECTR ELECTR, V9, P621, DOI 10.1002/tee.22018
   Simmonds M, 2017, COMPUT FRAUD SECUR, P9, DOI 10.1016/S1361-3723(17)30023-4
   Steingartner W, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040597
   Subedi KP, 2017, IEEE 2017 IEEE S SER, P1, DOI [10.1109/SSCI.2017.8280842, DOI 10.1109/SSCI.2017.8280842]
   Subedi KP, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P180, DOI 10.1109/SPW.2018.00033
   Tiu YL., 2021, J IT ASIA, V9, P133, DOI DOI 10.33736/JITA.3402.2021
   Wade M, 2021, BUS HORIZONS, V64, P787, DOI 10.1016/j.bushor.2021.07.014
   Wazid M, 2023, IEEE T CONSUM ELECTR, V69, P18, DOI 10.1109/TCE.2022.3208795
   Zhang HQ, 2019, FUTURE GENER COMP SY, V90, P211, DOI 10.1016/j.future.2018.07.052
   Zimba A, 2019, KSII T INTERNET INF, V13, P3258, DOI 10.3837/tiis.2019.06.027
NR 42
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-16946-x
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600015
DA 2024-07-18
ER

PT J
AU Singh, SA
   Devi, ND
   Singh, KN
   Thongam, K
   Reddy, B
   Majumder, S
AF Singh, Sinam Ajitkumar
   Devi, Ningthoujam Dinita
   Singh, Khuraijam Nelson
   Thongam, Khelchandra
   Reddy, Balakrishna
   Majumder, Swanirbhar
TI An ensemble-based transfer learning model for predicting the imbalance
   heart sound signal using spectrogram images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heard sound recording; Spectrogram; CNN; PhysioNet-2016; Transfer
   learning; Ensemble learning algorithm
ID CLASSIFICATION; RECOGNITION; NETWORKS
AB Heart sound signal analysis is an important area in healthcare, and the detection of imbalanced heart sounds can provide valuable diagnostic information. However, due to heart sound variability, accurate prediction of imbalanced signals remains challenging. The issue of class inequality has received much attention from numerous scientific domains. The correct classification becomes increasingly challenging as data scale and data imbalance increase. Traditional classifiers tend to favor the dominant class and overlook the minority class, which is frequently considerably more significant when dealing with imbalanced learning problems. We propose an ensemble learning algorithm based on a transfer learning convolutional neural network (CNN) model to solve these challenges to predict imbalanced heart sound signals. We employ spectrogram images and STFT to extract the relevant features from Phonocardiogram (PCG) data. Our model leverages the pre-trained CNN architecture and fine-tunes it on the spectrogram images to improve the prediction performance. Moreover, we incorporate an ensemble approach to improve the model's robustness and accuracy. Our experimental results on a publicly available PhysioNet PCG dataset demonstrate that the proposed algorithm outperforms existing state-of-the-art methods in terms of accuracy, sensitivity, and specificity. The ensemble methodology comprising AlexNet, SqueezeNet, and VGG19 models was proposed and achieved the highest level of performance, resulting in an accuracy of 99.20% and a sensitivity rate of 99.47%. Our study showcases the potential of leveraging technological advancements to predict unbalanced Phonocardiogram (PCG) signals using spectrogram images. This research opens up promising avenues for future exploration in cardiac diagnostics. Specifically, the ensemble-based transfer learning model proposed in this study holds great promise.
C1 [Singh, Sinam Ajitkumar; Thongam, Khelchandra] NIT Manipur, Dept Comp Sci & Engn, Imphal 795004, Manipur, India.
   [Devi, Ningthoujam Dinita] RIMS Imphal, Dept Radiat Oncol, Imphal 795004, Manipur, India.
   [Singh, Khuraijam Nelson] IIIT Nagpur, Dept Elect & Commun Engn, Nagpur 441108, Maharastra, India.
   RGMCET, Dept Elect & Commun Engn, Nandyal 518501, Andhra Pradesh, India.
   [Majumder, Swanirbhar] Tripura Univ, Dept Informat Technol, Suryamani Nagar, Agartala 799022, Tripura, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur; Regional Institute of Medical Sciences, Imphal;
   Tripura University
RP Majumder, S (corresponding author), Tripura Univ, Dept Informat Technol, Suryamani Nagar, Agartala 799022, Tripura, India.
EM ajit_sinam@yahoo.com; dini.ji2019@gmail.com;
   nelsonkhuraijam16@hotmail.com; thongam@gmail.com;
   balakrishna478@gmail.com; swanirbhar@ieee.org
RI Singh, Sinam Ajitkumar/AAA-7379-2020; Majumder, Swanirbhar/E-4772-2012;
   Nelson, Khuraijam/AAV-7769-2020
OI Singh, Sinam Ajitkumar/0000-0001-7148-1233; Majumder,
   Swanirbhar/0000-0002-1046-1682; Nelson, Khuraijam/0000-0001-5093-1784
CR Azam FB, 2022, ARTIF INTELL MED, V133, DOI 10.1016/j.artmed.2022.102417
   Babaei S, 2009, COMPUT BIOL MED, V39, P8, DOI 10.1016/j.compbiomed.2008.10.004
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen YC, 2020, MED BIOL ENG COMPUT, V58, P2039, DOI 10.1007/s11517-020-02218-5
   Ding HW, 2023, INFORM SCIENCES, V629, P184, DOI 10.1016/j.ins.2023.01.147
   Dominguez-Morales JP, 2018, IEEE T BIOMED CIRC S, V12, P24, DOI 10.1109/TBCAS.2017.2751545
   Er MB, 2021, APPL ACOUST, V180, DOI 10.1016/j.apacoust.2021.108152
   Gupta S, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102947
   Hamidi M, 2018, BIOMED SIGNAL PROCES, V39, P351, DOI 10.1016/j.bspc.2017.08.002
   Hazeri H, 2021, ANALOG INTEGR CIRC S, V109, P459, DOI 10.1007/s10470-021-01867-2
   Ismail S, 2023, BIOCYBERN BIOMED ENG, V43, P313, DOI 10.1016/j.bbe.2023.01.004
   Ismail S, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104075
   Jablonski A, 2022, MECH SYST SIGNAL PR, V167, DOI 10.1016/j.ymssp.2021.108554
   Jamil S, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106734
   Karhade J, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3163156
   Khan JS, 2022, COMPUT METH PROG BIO, V219, DOI 10.1016/j.cmpb.2022.106727
   Krishnan PT, 2020, PHYS ENG SCI MED, V43, P505, DOI 10.1007/s13246-020-00851-w
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103733
   Li RL, 2023, INFORM SCIENCES, V624, P833, DOI 10.1016/j.ins.2022.12.088
   Liu CY, 2016, PHYSIOL MEAS, V37, P2181, DOI 10.1088/0967-3334/37/12/2181
   Maity A, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104805
   Martínez-Alajarín J, 2005, PROC SPIE, V5839, P398, DOI 10.1117/12.608203
   Mishra M, 2018, IEEE T INSTRUM MEAS, V67, P1713, DOI 10.1109/TIM.2018.2805198
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Pathak A, 2022, IEEE J BIOMED HEALTH, V26, P2804, DOI 10.1109/JBHI.2022.3140277
   Pathak A, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102055
   peterjbentley.com, Classifying heart sounds challenge
   Ren JJ, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108295
   Riccio D, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105186
   Samanta P, 2019, BIOCYBERN BIOMED ENG, V39, P426, DOI 10.1016/j.bbe.2019.02.003
   Sawant NK, 2021, BIOCYBERN BIOMED ENG, V41, P111, DOI 10.1016/j.bbe.2020.12.007
   Schmidt SE, 2008, COMPUTERS IN CARDIOLOGY 2008, VOLS 1 AND 2, P345, DOI 10.1109/CIC.2008.4749049
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinam SA, 2020, TURK J ELECTR ENG CO, V28, P875, DOI 10.3906/elk-1905-165
   Singh SA, 2023, COMPUT J, V66, P1525, DOI 10.1093/comjnl/bxac025
   Singh SA, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500258
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Wang C, 2021, INFORM FUSION, V69, P81, DOI 10.1016/j.inffus.2020.10.017
   Xiao B, 2020, NEUROCOMPUTING, V392, P153
   Xie YT, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2022.119469
   Yaseen, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122344
   Zang JB, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104934
   Zeng W, 2021, ARTIF INTELL REV, V54, P1613, DOI 10.1007/s10462-020-09875-w
   Zhang WJ, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101560
   Zhou R, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104673
   Zhou XK, 2020, IEEE INTERNET THINGS, V7, P6429, DOI 10.1109/JIOT.2020.2985082
NR 47
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17186-9
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200007
DA 2024-07-18
ER

PT J
AU Alkhawaldeh, RS
   Al-Dabet, S
AF Alkhawaldeh, Rami S.
   Al-Dabet, Saja
TI Unified framework model for detecting and organizing medical cancerous
   images in IoMT systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Supervised transfer learning model; Cancerous images; IoMT; Two-stage
   classification; Storage organization
ID BREAST-CANCER; CLASSIFICATION
AB One of the challenges that arise when utilizing real-time reaction services, such as constructing deep learning models within the Internet of Medical Things (IoMT) infrastructure, is effectively balancing the computation load between the cloud and fog computing layers. This paper proposes a unified framework of offline training and online response to the healthcare professional. The framework gathers medical images from various heterogeneous IoMT devices and then arranges them into homogeneous locations in the cloud, using a stage-one classification stage (or offline training). Furthermore, the stage-two classification (or online response) is employed to detect the type of cancer for each homogeneous location containing the same image type within the cloud. To evaluate the framework, we conducted extensive experiments on six well-known cancer datasets of multiple types. The stage-one classification shows superior results of the error rates for the InceptionResNetV2 and DenseNet201 pre-trained transfer learning models of 0.33% and 0.43% with accuracy values of 99.67% and 99.57% respectively. In the stage-two classification, the results show different performances on each dataset. The point is that each dataset is organized separately which helps in studying the influence of pre-trained transfer learning models and improving their performance in the absence of intervention and bias in datasets.
C1 [Alkhawaldeh, Rami S.] Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
   [Al-Dabet, Saja] United Arab Emirates Univ, Coll Informat Technol, Dept Comp Sci & Software Engn, Al Ain, U Arab Emirates.
C3 University of Jordan; United Arab Emirates University
RP Alkhawaldeh, RS (corresponding author), Univ Jordan, Dept Comp Informat Syst, Aqaba 77110, Jordan.
EM r.alkhawaldeh@ju.edu.jo; 700039885@uaeu.ac.ae
RI Alkhawaldeh, Rami S/O-2950-2018
OI Alkhawaldeh, Rami S/0000-0002-2413-7074
CR Borkowski AA, 2019, Arxiv, DOI [arXiv:1912.12142, DOI 10.48550/ARXIV.1912.12142]
   Ahmed M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111756
   Ali YH, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10030320
   Alkhawaldeh RS, 2022, NEURAL COMPUT APPL, V34, P705, DOI 10.1007/s00521-021-06423-7
   Alkhawaldeh RS, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/7213717
   Alkhawaldeh RS, 2019, IET COMMUN, V13, P2609, DOI 10.1049/iet-com.2018.5430
   Amin SU, 2021, IEEE ACCESS, V9, P45, DOI 10.1109/ACCESS.2020.3045115
   [Anonymous], 2020, Sartaj: Brain tumor classification (mri)
   Bajaj A, 2021, Advances in Machine Learning and Computational Intelligence: Proceedings of ICMLCI, P645
   Bibi N, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/6648574
   Boumaraf S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102192
   Chai JY, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100134
   Chakrabarty N, 2019, Brain MRI Images for Brain Tumor Detection
   Chang ZQ, 2021, IEEE INTERNET THINGS, V8, P13849, DOI 10.1109/JIOT.2021.3088875
   Chapala V, 2021, INT J PERVASIVE COMP, V17, P549, DOI 10.1108/IJPCC-10-2020-0160
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dai XF, 2019, 2019 FOURTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P301, DOI [10.1109/fmec.2019.8795362, 10.1109/FMEC.2019.8795362]
   Gupta KD, 2023, NEURAL PROCESS LETT, V55, P205, DOI 10.1007/s11063-021-10555-1
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Hayyolalam V, 2021, IEEE WIREL COMMUN, V28, P6, DOI 10.1109/MWC.001.2000345
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain S, 2021, BIOSENS BIOELECTRON, V179, DOI 10.1016/j.bios.2021.113074
   Khamparia A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3963
   Khan SU, 2019, FUTURE GENER COMP SY, V98, P286, DOI 10.1016/j.future.2019.01.033
   Khan TA, 2023, IEEE ACCESS, V11, P39418, DOI 10.1109/ACCESS.2023.3266156
   Kim T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093001
   Kudin A, 2019, C-nmc leukemia
   Kumar S, 2021, Cogn Internet Med Things Smart Healthc, P1
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin J, 2020, Gastrointestinal cancer msi mss prediction
   Luongo F, 2021, SURGERY, V169, P1240, DOI 10.1016/j.surg.2020.08.016
   Masood A, 2018, J BIOMED INFORM, V79, P117, DOI 10.1016/j.jbi.2018.01.005
   Ogundokun RO, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020656
   Ohata EF, 2021, J SUPERCOMPUT, V77, P9494, DOI 10.1007/s11227-020-03575-6
   Parvathy VS, 2021, Cognitive Internet of Medical Things for Smart Healthcare, P117
   Pati Abhilash, 2023, Designs, DOI 10.3390/designs7030057
   Pradhan A, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1804953
   Pushpa B., 2021, Proceedings of International Conference on Intelligent Computing, Information and Control Systems. (ICICCS 2020). Advances in Intelligent Systems and Computing (AISC 1272), P275, DOI 10.1007/978-981-15-8443-5_22
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P15847, DOI 10.1109/JIOT.2021.3051080
   Rajan JP, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1500-5
   RajaSubramanian R, 2021, Modern Approaches in Machine Learning and Cognitive Science: A Walkthrough, P127
   Sadad T, 2021, Microsc Res Tech
   Saeik F, 2021, COMPUT NETW, V195, DOI 10.1016/j.comnet.2021.108177
   Sahu P, 2018, PROC SPIE, V10579, DOI 10.1117/12.2293350
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Srinivasulu A, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-01897-2
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang S., 2021, IEEE/ACM Trans Networking
   Wang Y., 2021, Computational and Mathematical Methods in Medicine, V2021
   Zhang J, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3464419
NR 55
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16883-9
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100002
DA 2024-07-18
ER

PT J
AU Vidyadhari, C
   Karrothu, A
   Manickavasagam, P
   Devi, SA
AF Vidyadhari, Ch
   Karrothu, Aravind
   Manickavasagam, Prabhakar
   Devi, S. Anjali
TI Autism Spectrum Disorder Detection Using Fractional Social Driving
   Training-Based Optimization Enabled Deep Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gaussian filter; Social Optimization Algorithm; Autism Spectrum
   Disorder; Driving Training-Based Optimization; Fractional Calculus
AB Autism Spectrum Disorder (ASD) is neurodevelopment-based impact on interactive communication and social skills. Diagnosing ASD is one of serious issues that start manifesting at low ages, and is difficult to diagnose at early stages. Autism is characterized by both environmental and genetic factors. Lack of communication issues, social interaction, and limited interest behaviors are possible individuality of autism noticed in children, along other symptoms. This paper aims at ASD detection by Deep Quantum Neural Network (DQNN), wherein this network is trained by proposed Fractional Social Driving Training-Based Optimization (FSDTBO). The initial stage of this processing starts with acquisition of image from dataset, and further pre-processing is carried out using Gaussian filter, and this filtered image is suspended for Regions of Interest (ROI) extraction. Also, extraction of nub region is done by proposed Social Driving Training-Based Optimization (SDTBO), from which classification process is done by considering extracted features too. Here, proposed FSDTBO is integration process among Fractional Calculus (FC) and SDTBO, wherein SDTBO is collaboration between Social Optimization Algorithm (SOA) and Driving Training-Based Optimization (DTBO). Moreover, classification performance of ASD is found based on three metrics, like accuracy, specificity, and sensitivity with superior values of 0.90, 0.94, and 0.96.
C1 [Vidyadhari, Ch] Gokaraju Rangaraju Inst Engn & Technol, Dept Informat Technol, Hyderabad, India.
   [Karrothu, Aravind] GMR Inst Technol, Dept Informat Technol, Rajam 532127, Andhra Pradesh, India.
   [Manickavasagam, Prabhakar] REVA Univ, Sch Comp Sci & Engn, Bangalore 560064, India.
   [Devi, S. Anjali] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; GMR Institute
   of Technology; REVA University; Koneru Lakshmaiah Education Foundation
   (K L Deemed to be University)
RP Vidyadhari, C (corresponding author), Gokaraju Rangaraju Inst Engn & Technol, Dept Informat Technol, Hyderabad, India.
EM chalasanividyadhari@gmail.com
RI S, ANJALI DEVI/U-5973-2018
OI Chalasani, Vidyadhari/0000-0001-7514-2693
FU I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
FX I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Ali N A., 2020, IAES International Journal of Artificial Intelligence, V9, P91, DOI DOI 10.11591/IJAI.V9.I1.PP91-99
   Bhaladhare PR., 2014, Adv Comput Eng, V2014, P1, DOI [DOI 10.1155/2014/396529, 10.1155/2014/396529]
   Dehghani M, 2022, Driving training-based optimization: A new human-based metaheuristic algorithm for solving optimization problems, scientific reports, P1
   Erkan U, 2019, CURR PSYCHIAT RES RE, V15, P297, DOI 10.2174/2666082215666191111121115
   github, about us
   Hemanth DJ., 2020, Journal of Artificial Intelligence and Systems, V2, P13, DOI [10.33969/AIS.2020.21001, DOI 10.33969/AIS.2020.21001]
   Husna RNS, 2021, J TEKNOL, V83, P45, DOI 10.11113/jurnalteknologi.v83.16389|
   Karimi N., 2022, Int Trans Electr Energy Systems, V30, pe12593
   Kerstin B., 2019, Nature
   Khairandish MO, 2022, IRBM, V43, P290, DOI 10.1016/j.irbm.2021.06.003
   Khodatars M, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104949
   Kim B, 2013, IEEE ENG MED BIO, P3658, DOI 10.1109/EMBC.2013.6610336
   Kumar A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P45, DOI [10.23919/INDIACom49435.2020.9083712, 10.23919/indiacom49435.2020.9083712]
   Lakshmiprabha NS, 2012, INT CONF INTELL SYST, P258, DOI 10.1109/ISDA.2012.6416547
   Lee JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236762
   Liu G., 2017, P 2017 10 INT C IM S, pIEEE.1
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Lord C, 2018, LANCET, V392, P508, DOI 10.1016/S0140-6736(18)31129-2
   Minarno AE, 2016, IOP CONF SER-MAT SCI, V105, DOI 10.1088/1757-899X/105/1/012022
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Mohanty AS., 1921, J Phys: Conf Ser, V1
   Pan JS, 2022, MATH COMPUT SIMULAT, V202, P343, DOI 10.1016/j.matcom.2022.06.007
   Radhakrishnan M, 2021, TRAIT SIGNAL, V38, P853, DOI 10.18280/ts.380332
   Saranya A, 2022, DISTRIB PARALLEL DAT, V40, P753, DOI 10.1007/s10619-021-07361-y
   Subah FZ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083636
   Tian Y, 2019, IEEE INT CON MULTI, P272, DOI 10.1109/ICME.2019.00055
   Xie J, 2019, Arxiv, DOI arXiv:1911.11393
   Xu LY, 2020, J NEUROSCI METH, V331, DOI 10.1016/j.jneumeth.2019.108538
   Yin WT, 2021, J COMPUT BIOL, V28, P146, DOI 10.1089/cmb.2020.0252
   Yuan JB, 2017, EURASIP J BIOINFORM, DOI 10.1186/s13637-017-0057-1
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16784-x
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100004
DA 2024-07-18
ER

PT J
AU Pandey, M
   Litoriya, R
   Pandey, P
AF Pandey, Mamta
   Litoriya, Ratnesh
   Pandey, Prateek
TI An integrated MCDM approach for mobile app cost predictor based on
   DEMATEL extended with choquet integral
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile apps; Cost predictors; Rough DEMATEL; Hesitant DEMATEL; Choquet
   integral
ID SUPPLIER SELECTION; FUZZY-SETS; ISSUES
AB An integral part of developing any mobile app is determining how much time and money will be needed to complete the task. Inaccuracy and imprecision will have serious consequences for the project's timeline and cost. Estimating how much work will go into making an app can be done in a number of ways. The accuracy of the COCOMO II app's effort estimation is very sensitive to the input parameters, which include things like the scope of the project, the coefficients used, and the cost predictors. In this research, author apply a multi-criteria decision-making algorithm Interval valued intuinistic fuzzy Decision Making Trial and Evaluation Laboratory (IVIF-DEMATEL) to determine the relationship between 16 different cost predictors, thereby decreasing the margin of estimating error (MMRE). In this work, author provide the results of an empirical investigation into the relationship between the impact cost predictors in app development methods and the cost predictors, as well as the development in app productivity over time. IVIF-DEMATEL with choquet integral was then used to analyze the mobiles cost predictors and divide them into cause/effect groups. As a first step, a group of experts examine how mobile app cost predictors are linked to each other in terms of direct correlation. Floppy triangle numbers display the findings of the evaluation (TFN). The second step is to translate the linguistic terms into TFN. According to DEMATEL, the cause-effect classifications of cost predictors can be determined. Finally, CMIs in mobile apps are identified as the cost predictors in the cause category. The IVIF-DEMATEL with choquet integral is found to be the most appropriate method for analyzing the interrelationship between DEMATEL variants such as Rough-DEMATEL and Hesitant-DEMATEL.
C1 [Pandey, Mamta] Mahatma Gandhi Inst Technol, Hyderabad, India.
   [Litoriya, Ratnesh] Med Caps Univ, Indore, India.
   [Pandey, Prateek] Jaypee Univ Engn & Technol, Guna, India.
RP Litoriya, R (corresponding author), Med Caps Univ, Indore, India.; Pandey, P (corresponding author), Jaypee Univ Engn & Technol, Guna, India.
EM mamta.pandey07@gmail.com; litoriya.ratnesh@gmail.com;
   pandeyprat@yahoo.com
RI Pandey, Prateek/AGQ-1450-2022; Pandey, Dr. Mamta/AAQ-2725-2021
OI Litoriya, Ratnesh/0000-0002-7285-422X; Pandey,
   Prateek/0000-0001-5384-6606
CR Al-Subaihin A., 2015, P 3 INT WORKSH SOFTW, P1
   Ashraf S, 2019, J INTELL FUZZY SYST, V36, P6089, DOI 10.3233/JIFS-181941
   Barack O., 2020, J SOFTW ENG APPL, V13, P179, DOI [10.4236/jsea.2020.139012, DOI 10.4236/JSEA.2020.139012]
   Batra Shivani, 2019, International Journal of High Performance Computing and Networking, V15, P91
   Boran FE, 2009, EXPERT SYST APPL, V36, P11363, DOI 10.1016/j.eswa.2009.03.039
   Brans Patrick D., 2008, Information.Knowledge.Systems Management, V7, P145
   Bustince H, 1996, FUZZY SET SYST, V79, P403, DOI 10.1016/0165-0114(95)00154-9
   Catolino Gemma, 2017, 2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems (MOBILESoft). Proceedings, P194, DOI 10.1109/MOBILESoft.2017.31
   Chang B, 2011, EXPERT SYST APPL, V38, P1850, DOI 10.1016/j.eswa.2010.07.114
   da Silva LP, 2014, PROCEEDINGS OF THE 2014 2ND INTERNATIONAL CONFERENCE ON MODEL-DRIVEN ENGINEERING AND SOFTWARE DEVELOPMENT (MODELSWARD 2014), P400
   Ebrahimi F, 2021, INFORM SOFTWARE TECH, V133, DOI 10.1016/j.infsof.2020.106466
   Flora Harleen K., 2014, International Journal of Modern Education and Computer Science, V6, P1, DOI 10.5815/ijmecs.2014.06.01
   Flora K., 2014, International Journal of Computer Applications in Technology, V94, P43, DOI DOI 10.5120/16454-6199
   Gül S, 2021, INT J INF TECH DECIS, V20, P1011, DOI 10.1142/S0219622021500267
   Gündogdu FK, 2019, J INTELL FUZZY SYST, V37, P1197, DOI 10.3233/JIFS-182651
   Heriyanto AndriP., 2013, Procedures and Tools For Acquisition And Analysis Of Volatile Memory On Android Smartphones
   Hoffman L, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00094
   Huebner J, 2021, IEEE SOFTWARE, V38, P96, DOI 10.1109/MS.2020.3014669
   Huebner J, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P293, DOI 10.1145/3282894.3282895
   Inukollu VN, 2014, ARXIV
   Jabangwe R, 2018, J SYST SOFTWARE, V145, P98, DOI 10.1016/j.jss.2018.08.028
   Joorabchi Mona Erfani, 2013, 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), P15, DOI 10.1109/ESEM.2013.9
   Kalaichelavan K, 2020, PROCEDIA COMPUT SCI, V170, P547, DOI 10.1016/j.procs.2020.03.124
   Kang Bingyi., 2012, J. Inf. Comput. Sci., V9, P703, DOI [10.51582/interconf.19-20.05.2022.045, DOI 10.51582/INTERCONF.19-20.05.2022.045]
   Khalid Mubasher, 2015, International Journal of Information Technology and Computer Science, V7, P35, DOI 10.5815/ijitcs.2015.10.05
   Latif M, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY FOR ORGANIZATIONS DEVELOPMENT (IT4OD)
   Martin W, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), P123, DOI 10.1109/MSR.2015.19
   Munoz Sergio, 2018, 2018 4th International Conference on Big Data Innovations and Applications (Innovate-Data). Proceedings, P17, DOI 10.1109/Innovate-Data.2018.00010
   Murad Maisarah Adibah, 2021, 2021 IEEE 11th International Conference on System Engineering and Technology (ICSET), P106, DOI 10.1109/ICSET53708.2021.9612528
   Natalie V, 2018, FOOD CHEM TOXICOL, V118, P532, DOI 10.1016/j.fct.2018.05.060
   Pandey M, 2018, INGENIERIE SYSTEMES, V23, P19
   Pandey M., 2019, SMART COMPUTATIONAL, P121, DOI DOI 10.1007/978-981-13-6295-8_11
   Pandey M, 2023, J INTELL FUZZY SYST, V44, P4041, DOI 10.3233/JIFS-190357
   Pandey M, 2020, WIRELESS PERS COMMUN, V110, P1659, DOI 10.1007/s11277-019-06805-0
   Pandey M, 2019, PROGRAM COMPUT SOFT+, V45, P268, DOI 10.1134/S0361768819050050
   Pandey M, 2019, WIRELESS PERS COMMUN, V108, P683, DOI 10.1007/s11277-019-06424-9
   Pandey M, 2019, WIRELESS PERS COMMUN, V107, P1687, DOI 10.1007/s11277-019-06351-9
   Pandey M, 2018, INT J SOFTW ENG KNOW, V28, P937, DOI 10.1142/S0218194018400119
   Pandey M, 2016, 2016 SYMPOSIUM ON COLOSSAL DATA ANALYSIS AND NETWORKING (CDAN)
   Riegler A, 2018, INTERACT COMPUT, V30, P207, DOI 10.1093/iwc/iwy008
   Rodríguez RM, 2012, IEEE T FUZZY SYST, V20, P109, DOI 10.1109/TFUZZ.2011.2170076
   Shahwaiz SA, 2016, 2016 19 INT MULT C I, P1
   Si SL, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3696457
   Tarokh M, 2010, ARTIF INTELL REV, V34, P289, DOI 10.1007/s10462-010-9173-y
   Vu PM, 2013, ARXIV
   Wang MY, 2017, ELECTRON COMMER RES, V17, P83, DOI 10.1007/s10660-016-9245-4
   Wei CP, 2011, INFORM SCIENCES, V181, P4273, DOI 10.1016/j.ins.2011.06.001
   Widnall E, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/18140
   Williams G, 2018, INT REQUIR ENG CONF, P64, DOI 10.1109/RE.2018.00-51
   Yüksel S, 2022, INT J ENERG RES, V46, P10796, DOI 10.1002/er.7880
   Zhang L, 2017, J COMPUT SCI TECH-CH, V32, P1076, DOI 10.1007/s11390-017-1784-1
   Zuo CS, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P867, DOI 10.1145/3038912.3052609
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16856-y
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200012
DA 2024-07-18
ER

PT J
AU Bramesh, SM
   Kumar, KMA
   Nayyar, A
AF Bramesh, S. M.
   Kumar, K. M. Anil
   Nayyar, Anand
TI An effective rule- and network-based approach for identification of
   gender- and age-dependent comorbidity patterns in diabetic patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetes; Comorbidity patterns; Rule-based; MIMIC and Network-based
ID DISEASE; MULTIMORBIDITY; HEALTH; IMPACT; HEART
AB Diabetes is a chronic (long-lasting) condition, and it is becoming more and more common in both developed and developing countries. Compared to people without diabetes, people with diabetes are more likely to have various illnesses. Comorbidity is the term used in clinical literature to describe this phenomenon in general. The majority of the recent studies have made considerable strides in extracting comorbidity patterns, but all the studies have some limitations in terms of: identifying interesting gender- and age-dependent diabetes-specific comorbidities patterns; little is known about differences in gender- and age-dependent diabetes-specific comorbidities patterns. The objective of this research paper is to identify and explore interesting gender- and age-dependent diabetes-specific comorbidities patterns from large Medical Information Mart for Intensive Care (MIMIC) datasets. An effective rule-based approach is proposed to identify interesting gender- and age-dependent diabetes-specific comorbidities patterns by considering all diagnosis information of a patient i.e., primary diagnosis, secondary diagnosis and so on of a patient. The proposed approach performs sorting to identify interesting gender- and age-dependent diabetes-specific comorbidities patterns. Finally, extracted interesting comorbidities patterns are validated using a network-based method in a non-traditional manner. The experimental results showed that the occurrence of comorbidity rises with age both in case of male and female patients and also showed that some conditions like hypertensive renal disease will co-occur with diabetes in almost all age groups both in case of male and female patients. In addition, it is also observed that the comorbid conditions depends on gender. Notably, our findings identify new, intriguing, and clinically significant gender- and age-dependent patterns of diabetes-specific comorbidities, assisting clinical practitioners in recommending the best course of treatment for diabetic patients.
C1 [Bramesh, S. M.] PES Coll Engn, Dept Informat Sci & Engn, Mandya 571401, Karnataka, India.
   [Kumar, K. M. Anil] JSS Sci & Technol Univ, Dept Comp Sci & Engn, Mysuru 570006, Karnataka, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 JSS Science & Technology University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM smb@pesce.ac.in; anilkm@sjce.ac.in; anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146
CR Abdalrada AS, 2022, J DIABETES METAB DIS, V21, P251, DOI 10.1007/s40200-021-00968-z
   Backenroth D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164304
   Bagley SC, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004885
   Bonavita V, 2008, NEUROL SCI, V29, pS99, DOI 10.1007/s10072-008-0898-1
   Bratzke LC, 2015, INT J NURS STUD, V52, P744, DOI 10.1016/j.ijnurstu.2014.10.010
   Campbell AW, 2011, ALTERN THER HEALTH M, V17, P8
   Chan CL, 2008, IEEE IJCNN, P856, DOI 10.1109/IJCNN.2008.4633898
   Chen Yang, 2015, AMIA Jt Summits Transl Sci Proc, V2015, P201
   Cheraghi-Sohi S, 2013, SAGE OPEN MED, V1, DOI 10.1177/2050312113503955
   Doshi-Velez F, 2014, PEDIATRICS, V133, pE54, DOI 10.1542/peds.2013-0819
   Druss BG, 2001, HEALTH AFFAIR, V20, P233, DOI 10.1377/hlthaff.20.6.233
   Farran B, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2012-002457
   Feng J, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17239119
   Fortin Martin, 2005, Can Fam Physician, V51, P244
   Gijsen R, 2001, J CLIN EPIDEMIOL, V54, P661, DOI 10.1016/S0895-4356(00)00363-2
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Han XY, 2022, ASIAN J PSYCHIATR, V67, DOI 10.1016/j.ajp.2021.102927
   Harahap M, 2018, J PHYS CONF SER, V1007, DOI 10.1088/1742-6596/1007/1/012017
   Himes BE, 2009, J AM MED INFORM ASSN, V16, P371, DOI 10.1197/jamia.M2846
   Holmes AB, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021132
   Jacob R, 2014, AM J HEALTH BEHAV, V38, P297, DOI 10.5993/AJHB.38.2.15
   Jakovljevic M, 2013, PSYCHIAT DANUB, V25, P18
   Johnson A., 2016, Physio Net, V10
   Kerr EA, 2007, J GEN INTERN MED, V22, P1635, DOI 10.1007/s11606-007-0313-2
   Lan W, 2018, IEEE ACM T COMPUT BI, V15, P1774, DOI 10.1109/TCBB.2016.2586190
   Lkhagva D, 2012, J DIABETES COMPLICAT, V26, P129, DOI 10.1016/j.jdiacomp.2011.12.004
   Ma W, 2017, BRIEF BIOINFORM, V18, P85, DOI 10.1093/bib/bbw005
   Marengoni A, 2011, AGEING RES REV, V10, P430, DOI 10.1016/j.arr.2011.03.003
   Mezzich JE, 2008, WORLD PSYCHIATRY, V7, P1
   Nahar J, 2013, EXPERT SYST APPL, V40, P1086, DOI 10.1016/j.eswa.2012.08.028
   Piette JD, 2006, DIABETES CARE, V29, P725, DOI 10.2337/diacare.29.03.06.dc05-2078
   Prather JC, 1997, J AM MED INFORM ASSN, P101
   Schoenberg NE, 2009, J HEALTH CARE POOR U, V20, P134, DOI 10.1353/hpu.0.0115
   Singh B, 2012, MAYO CLIN PROC, V87, P817, DOI 10.1016/j.mayocp.2012.04.015
   Tandan M, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104249
   Taylor AW, 2010, BMC PUBLIC HEALTH, V10, DOI 10.1186/1471-2458-10-718
   Tinetti ME, 2004, NEW ENGL J MED, V351, P2870, DOI 10.1056/NEJMsb042458
   Valderas JM, 2009, ANN FAM MED, V7, P357, DOI 10.1370/afm.983
   Van Den Akker M, 1996, Eur J Gen Pract, V2, P65, DOI DOI 10.3109/13814789609162146
   wikipedia, List of ICD-9 Codes
   Wolff JL, 2002, ARCH INTERN MED, V162, P2269, DOI 10.1001/archinte.162.20.2269
   Yang JY, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-113
   Yang Jianji, 2006, AMIA Annu Symp Proc, P829
   Zhang JH, 2020, IEEE INT C BIOINFORM, P885, DOI 10.1109/BIBM49941.2020.9313227
NR 45
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16943-0
EA SEP 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000006
DA 2024-07-18
ER

PT J
AU Farah, T
   Alshammari, BM
AF Farah, Tarek
   Alshammari, Badr M.
TI A novel image encryption scheme based on a new hyperchaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE S-box; Chaos; Hyperchaotic map; Encryption; Chaos-based cryptography
ID S-BOXES; MEGAPTERA-NOVAEANGLIAE; CHAOTIC SYSTEMS; ALGORITHM
AB This paper proposes a robust chaotic encryption algorithm based on substitution and permutation. We offer hyperchaotic maps with high ergodicity and large keyspace with a maximum value of 10(14). Also, we propose an optimization S-box with a high nonlinearity value and without fixed and reverse fixed points. The critical sensitivity test of the proposed algorithm shows that the sensitivity of the keys dynamic scheme is 10(-14). Comparative analysis of our proposed encryption scheme with other existing image encryption methods shows that the proposed method also has better correlation values between two-pixel adjacents, better UACI and NPCR values, and acceptable speed. The proposed encryption algorithm can resist several attacks and has high security. We can apply our robust scheme in applications requiring increased protection and ensuring secure communication by images.
C1 [Farah, Tarek] Univ Tunis ElManar, Ecole Natl Ingn Tunis, Informat & Syst Complexes, LR16ES07 Robot, BP 37 Belvedere, Tunis 1002, Tunisia.
   [Alshammari, Badr M.] Univ Hail, Dept Elect Engn, Hail 2240, Saudi Arabia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); University Ha'il
RP Farah, T (corresponding author), Univ Tunis ElManar, Ecole Natl Ingn Tunis, Informat & Syst Complexes, LR16ES07 Robot, BP 37 Belvedere, Tunis 1002, Tunisia.
EM frhtarek@gmail.com; bms.alshammari@uoh.edu.sa
RI Farah, Tarek/ABP-7163-2022
OI Alshammari, Dr. Badr/0000-0001-6819-3695
CR ADAMS C, 1990, LECT NOTES COMPUT SC, V435, P612
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biham E., 2012, DIFFERENTIAL CRYPTAN
   Cao WJ, 2022, CHAOS SOLITON FRACT, V163, DOI 10.1016/j.chaos.2022.112519
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   DAWSON MH, 1991, LECT NOTES COMPUT SC, V547, P352
   Ding DW, 2023, CHAOS SOLITON FRACT, V174, DOI 10.1016/j.chaos.2023.113841
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gao S, 2023, SIGNAL PROCESS, V202, DOI 10.1016/j.sigpro.2022.108745
   He YY, 2013, COMMUN NONLINEAR SCI, V18, P1746, DOI 10.1016/j.cnsns.2012.11.003
   Hof PR, 2007, ANAT REC, V290, P1, DOI 10.1002/ar.a.20407
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   IEEE Computer Society, 2015, IEEE Standard for Binary Floating-Point Arithmetic
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jalal AA, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109712
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Keshta I, 2023, PHYS COMMUN-AMST, V58, DOI 10.1016/j.phycom.2023.102048
   Khan H, 2023, MULTIMED TOOLS APPL, V82, P6943, DOI 10.1007/s11042-022-13612-6
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kumar K, 2022, J KING SAUD UNIV-COM, V34, P3878, DOI 10.1016/j.jksuci.2020.08.005
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li Z., 2023, Neural Netw
   Liang Q, 2023, OPT LASER TECHNOL, V160, DOI 10.1016/j.optlastec.2022.109033
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Ma B, 2023, Digit Signal Process
   Matsui M., 1994, Advances in Cryptology, P386
   Ostrovskii VY, 2022, CHAOS SOLITON FRACT, V165, DOI 10.1016/j.chaos.2022.112794
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Qamar S, 2023, COMPUT ELECTR ENG, V110, DOI 10.1016/j.compeleceng.2023.108883
   Rahul B.K., 2023, Optik
   Rakheja P, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-023-05131-x
   Shahna KU, 2023, CHAOS SOLITON FRACT, V170, DOI 10.1016/j.chaos.2023.113383
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Sun Baichao, 2023, Optik, DOI 10.1016/j.ijleo.2023.171132
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Tong HW, 2024, MULTIMED TOOLS APPL, V83, P20861, DOI 10.1007/s11042-023-16240-w
   Vadivel R, 2022, CHAOS SOLITON FRACT, V164, DOI 10.1016/j.chaos.2022.112741
   Vengadapurvaja AM, 2017, PROCEDIA COMPUT SCI, V115, P643, DOI 10.1016/j.procs.2017.09.150
   Wang B, 2017, COMPUT ELECTR ENG, V62, P414, DOI 10.1016/j.compeleceng.2017.01.015
   Wang J, 2019, INT J THEOR PHYS, V58, P308, DOI 10.1007/s10773-018-3932-y
   Wang J, 2022, OPT COMMUN, V525, DOI 10.1016/j.optcom.2022.128834
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2022, VISUAL COMPUT, V38, P763, DOI 10.1007/s00371-020-02048-4
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2009, ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS, P125, DOI 10.1109/ECBI.2009.15
   WATKINS WA, 1979, J MAMMAL, V60, P155, DOI 10.2307/1379766
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Xiao X, 2023, IET Blockchain
   Xie D, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.102587
   Xiong LZ, 2019, J INF SECUR APPL, V47, P78, DOI 10.1016/j.jisa.2019.04.005
   Yan MX, 2022, CHAOS SOLITON FRACT, V160, DOI 10.1016/j.chaos.2022.112161
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang B, 2023, MED BIOL ENG COMPUT, V61, P2971, DOI 10.1007/s11517-023-02874-3
   Zhang XQ, 2022, INT J DYNAM CONTROL, V10, P525, DOI 10.1007/s40435-021-00816-1
   Zhang X, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108580
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhao MD, 2023, INTEGRATION, V92, P91, DOI 10.1016/j.vlsi.2023.05.006
   Zhu D, 2022, J INF SECUR APPL, V69, DOI 10.1016/j.jisa.2022.103289
   Zhu SL, 2023, MATH COMPUT SIMULAT, V207, P322, DOI 10.1016/j.matcom.2022.12.025
NR 78
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16873-x
EA SEP 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700015
DA 2024-07-18
ER

PT J
AU Pramanik, S
AF Pramanik, Sabyasachi
TI A new method for locating data hiding in image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Extreme machine learning; Artificial neural network;
   PSNR; SSIM; MSE
AB In the steganographic picture, it remains a challenging problem to determine the best place for inserting the hidden message with a minimum distortion of the host medium. However, there is a long way to go to select the right embedding position with less distortion. To accomplish this goal, we suggest a new high performance image steganography method in which extreme machine learning algorithms (ELM) are updated to build a supervised mathematical model. The ELM is initially checked in regression mode on a portion of the picture or host medium. This helped us to determine the best place to embed the message with the best values in the expected assessment measurements. For practicing on a new metric, contrast, homogeneity and other texture characteristics are used. In addition, the established ELM is used to tackle over fitting during workout. The findings are analyzed using the correlation, the structural similarity measure, fusion matrices and mean square error in the efficiency of the proposed steganography approach. In terms of imperceptibility, the adjusted ELM has been found to transcend current approaches. Excellent characteristics of the findings indicate that the proposed steganographic method is highly capable of retaining the visual image detail. In accordance with the current state of the art approaches, an increase of 28 per cent of imperceptibility is achieved.
C1 [Pramanik, Sabyasachi] Haldia Inst Technol, Haldia, India.
C3 Haldia Institute of Technology
RP Pramanik, S (corresponding author), Haldia Inst Technol, Haldia, India.
EM sabyalnt@gmail.com
RI Pramanik, Sabyasachi/AAR-1342-2020
OI Pramanik, Sabyasachi/0000-0002-9431-8751
CR Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Alanazi N, 2021, MULTIMED TOOLS APPL, V80, P1403, DOI 10.1007/s11042-020-09667-y
   Alhaddad MJ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122071
   Alia AS., 2020, Int J Innov, Creat Change, V11, P80
   AlKhamese AY, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P549, DOI [10.1109/itce.2019.8646434, 10.1109/ITCE.2019.8646434]
   Ambika Biradar RL, 2020, Heal Technol
   Amine K., 2020, Ann Sci, V8, P143, DOI [10.21467/ias.8.1.143-149, DOI 10.21467/IAS.8.1.143-149]
   Amsden ND, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P67, DOI 10.1109/ICCNC.2015.7069317
   Artiemjew P, 2020, COMPUTERS, V9, DOI 10.3390/computers9020038
   Atee HA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170329
   Ayub N, 2020, J INTERDISCIP MATH, V23, P357, DOI 10.1080/09720502.2020.1731949
   Banik BG., 2020, Int J Electronic Sec Digital Forensics, V12, P147
   Baziyad M, 2021, MULTIMED TOOLS APPL, V80, P8611, DOI 10.1007/s11042-020-10008-2
   Benedict A. G., 2019, PROC ICDSC, P1
   Bikku T, 2019, TRAIT SIGNAL, V36, P109, DOI 10.18280/ts.360114
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Chaharlang J, 2020, MULTIMED TOOLS APPL, V79, P17551, DOI 10.1007/s11042-020-08694-z
   Cheng J, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0306-6
   Cogranne Remi, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P161, DOI 10.1145/3369412.3395075
   Darbani A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P617, DOI 10.1109/KBEI.2019.8735054
   Deshmukh D, 2020, Int J Innovative Technol Exploring Eng, V9, DOI [10.35940/ijitee.E2856.039520, DOI 10.35940/IJITEE.E2856.039520]
   Dhivya N, 2020, Int J Eng Res Technol (IJERT) ICATCT, V8
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Duan XT, 2020, IEEE ACCESS, V8, P170174, DOI 10.1109/ACCESS.2020.3024193
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   El-Khamy SE, 2020, IEEE ACCESS, V8, P148935, DOI 10.1109/ACCESS.2020.3015687
   El-Khamy SE, 2017, 32 GEN ASS SCI S INT, P1, DOI [10.23919/URSIGASS.2017.8105191, DOI 10.23919/URSIGASS.2017.8105191]
   Elmahi MY, 2019, INT C COMP CONTR EL, P1, DOI [10.1109/ICCCEEE46830.2019.9071188, DOI 10.1109/ICCCEEE46830.2019.9071188]
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Eyssa AA, 2020, WIRELESS PERS COMMUN, V110, P321, DOI 10.1007/s11277-019-06730-2
   Fu ZJ, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00534-2
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Hanseong Lee, 2020, ICSCA 2020: Proceedings of the 2020 9th International Conference on Software and Computer Applications, P212, DOI 10.1145/3384544.3384571
   Jain T, 2020, 2020 INT C EM TRENDS, P1, DOI [10.1109/ic-ETITE47903.2020.416, DOI 10.1109/IC-ETITE47903.2020.416]
   Ji-hwei Horng, 2019, 2019 8th International Conference on Innovation, Communication and Engineering (ICICE). Proceedings, P169, DOI 10.1109/ICICE49024.2019.9117372
   Jin ZJ, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720911002
   Joshi SV, 2012, Int J Comput Appl, V53
   Kar Dulal Chandra, 2018, International Journal of Information and Computer Security, V10, P276
   Karakus S, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109691
   Khan S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050781
   Koptyra K, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22060600
   Kumar Pala Mahesh, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P365, DOI 10.1109/ICSSIT46314.2019.8987785
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Li DP, 2018, BIOMED ENG-APP BAS C, V30, DOI 10.4015/S1016237218500382
   Liu HH, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0458-z
   Liu Q, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00521-7
   López-Hernández A, 2020, IEEE LAT AM T, V18, P495, DOI 10.1109/TLA.2020.9082720
   Malathi M., 2020, Int J Grid Disribut Comput, V13, P524
   Park J, 2020, COMPUTERS, V9, DOI 10.3390/computers9040103
   Pichardo-Méndez JL, 2020, ARAB J SCI ENG, V45, P3055, DOI 10.1007/s13369-019-04272-0
   Pramanik S., 2020, Advan Math: Sci J, V9, P4533, DOI [10.37418/amsj.9.7.22, DOI 10.37418/AMSJ.9.7.22]
   Pramanik S., 2013, Int J Comput Technol, V10, P1791, DOI [10.24297/ijct.v10i7.7027, DOI 10.24297/IJCT.V10I7.7027]
   Pramanik S., 2014, Eng Technol, V1, P553
   Pramanik S., 2019, Science, V14, P1412, DOI [10.11591/ijeecs.v13.i3.pp1412-1419, DOI 10.11591/IJEECS.V13.I3.PP1412-1419]
   Pramanik S, 2020, MULTIMED TOOLS APPL, V79, P17463, DOI 10.1007/s11042-020-08676-1
   Prasad S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.161066
   Priya L, 2019, Int J Comput Aided Eng Technol, V11, DOI [10.1504/IJCAET.2019.098153, DOI 10.1504/IJCAET.2019.098153]
   Rachmawanto EH, 2019, 2019 INT SEM APPL TE, P1, DOI [10.1109/ISEMANTIC.2019.8884266, DOI 10.1109/ISEMANTIC.2019.8884266]
   Ramya G., 2018, 2018 International Conference on Intelligent Computing and Communication for Smart World (I2C2SW). Proceedings, P131, DOI 10.1109/I2C2SW45816.2018.8997153
   Rashid M, 2020, Am J Comp Sci Inform Technol, V8, DOI [10.36648/2349-3917.8.2.51, DOI 10.36648/2349-3917.8.2.51]
   Ruan F, 2020, J REAL-TIME IMAGE PR, V17, P149, DOI 10.1007/s11554-019-00915-5
   SHAH PD, 2020, 2020 INT C EMERGING, P1, DOI DOI 10.1109/INCET49848.2020.9154032
   Shang YY, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091446
   Sharifzadeh M, 2020, IEEE T INF FOREN SEC, V15, P867, DOI 10.1109/TIFS.2019.2929441
   Sharma S, 2020, Int J Advanc Eng Res Dev, V7
   Siddiqui GF, 2020, IEEE ACCESS, V8, P181893, DOI 10.1109/ACCESS.2020.3028315
   Sindhu R, 2020, Int J Eng AdvancTechnol, V9, DOI [10.35940/ijeat.D8760.049420, DOI 10.35940/IJEAT.D8760.049420]
   Song HT, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3546367
   Stoyanov B, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050501
   Sukumar A, 2020, MULTIMED TOOLS APPL, V79, P10825, DOI 10.1007/s11042-019-08476-2
   Suresh M, 2022, J KING SAUD UNIV-COM, V34, P3489, DOI 10.1016/j.jksuci.2020.08.007
   Suryawanshi GR., 2018, Int J Appl Eng Res, V13, P634
   Tiwari A., 2020, Int J Advanc Sci Technol, V29, P3900
   Uday KK., 2020, Int J Advanc Sci Technol, V29, P304
   Verma V, 2020, MULTIMED TOOLS APPL, V79, P7471, DOI 10.1007/s11042-019-08283-9
   Xue BW, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P68, DOI 10.1109/IIH-MSP.2015.80
   Yang JH, 2020, INT CONF ACOUST SPEE, P2827, DOI [10.1109/icassp40776.2020.9054397, 10.1109/ICASSP40776.2020.9054397]
   Yeung YL, 2020, IEEE T CIRC SYST VID, V30, P1423, DOI 10.1109/TCSVT.2019.2903432
   Younus ZS, 2020, J INTELL SYST, V29, P1216, DOI 10.1515/jisys-2018-0225
   Zhang Y, 2020, IEEE T CIRC SYST VID, V30, P2750, DOI 10.1109/TCSVT.2019.2923980
NR 81
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16762-3
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700004
DA 2024-07-18
ER

PT J
AU Fida, A
   Umer, M
   Saidani, O
   Hamdi, M
   Alnowaiser, K
   Bisogni, C
   Abate, AF
   Ashraf, I
AF Fida, Alisha
   Umer, Muhammad
   Saidani, Oumaima
   Hamdi, Monia
   Alnowaiser, Khaled
   Bisogni, Carmen
   Abate, Andrea F.
   Ashraf, Imran
TI Real time emotions recognition through facial expressions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human behavior; Facial expressions; Emotions detection; Online learning;
   Design science research
ID HIGHER-EDUCATION; CLASSIFICATION
AB Human behavior is deeply influenced by emotions. Detection of emotions plays a pivotal role in understanding how individuals respond to various stimuli, such as reading text, encompassing feelings of anger, anxiety, confusion, or nervousness. Real-time facial emotion detection during online text reading represents an innovative approach for receiving immediate feedback based on readers' emotional responses. Real-time emotion detection finds applications in interactive displays and holds immense potential for online learning platforms, where it can be utilized to analyze students' emotional states and gauge their level of comprehension. Despite vast existing literature on emotion detection, real-time emotion detection is not very well studied. This study demonstrates the design and implementation of face emotion detection for students while they are using online learning platforms. The primary objective is capturing human emotions and storing them in the database after five seconds while they are reading online text. The system is implemented using SSD based on VB.NetV1. The proposed system has strong relevance for integration with online web applications to detect learners' real-time emotions. Experiments are performed using CK+ and JAFFE face datasets and results show 96.46% and 98.43% accuracy, respectively. The system not only provides accurate results but also enables high-quality, robust, and real-time feedback based on the facial expressions of readers, facilitating a deeper understanding of students' emotional engagement during their online learning experiences.
C1 [Fida, Alisha; Umer, Muhammad] Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur, Pakistan.
   [Saidani, Oumaima] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh 11671, Saudi Arabia.
   [Hamdi, Monia] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
   [Alnowaiser, Khaled] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Engn, Al Kharj 11942, Saudi Arabia.
   [Bisogni, Carmen; Abate, Andrea F.] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan, South Korea.
C3 Islamia University of Bahawalpur; Princess Nourah bint Abdulrahman
   University; Princess Nourah bint Abdulrahman University; Prince Sattam
   Bin Abdulaziz University; University of Salerno; Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan, South Korea.
EM Alisha.fida@iub.edu.pk; umer.sabir@iub.edu.pk; ocsaidani@pnu.edu.sa;
   MSHamdi@pnu.edu.sa; k.alnowaiser@psau.edu.sa; cbisogni@unisa.it;
   abate@unisa.it; imranashraf@ynu.ac.kr
RI Alnowaiser, Khaled/GQY-5062-2022; Umer, Muhammad/AAX-4594-2020; Hamdi,
   Monia/ABG-1263-2021; Umer, Muhammad/KHU-2339-2024
OI Alnowaiser, Khaled/0009-0007-2717-6902; Umer,
   Muhammad/0000-0002-6015-9326; Hamdi, Monia/0000-0003-3690-9868; Umer,
   Muhammad/0009-0001-8751-6100; Ashraf, Imran/0000-0002-8271-6496;
   Saidani, Oumaima/0000-0001-9520-3174
FU Princess Nourah bint Abdulrahman University Researchers Supporting
   Project number (PNURSP2023R125), Princess Nourah bint Abdulrahman
   University, Riyadh, Saudi Arabia. [PNURSP2023R125]; Princess Nourah bint
   Abdulrahman University Researchers Supporting Project; Princess Nourah
   bint Abdulrahman University, Riyadh, Saudi Arabia
FX Princess Nourah bint Abdulrahman University Researchers Supporting
   Project number (PNURSP2023R125), Princess Nourah bint Abdulrahman
   University, Riyadh, Saudi Arabia.
CR Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Al-Saqqa S, 2018, INT CONF COMP SCI, P136, DOI 10.1109/CSIT.2018.8486405
   Alluqmani A, 2018, SCIENTOMETRICS, V115, P1071, DOI 10.1007/s11192-018-2688-8
   Altameem T, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104044
   AlZu'bi S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182964
   [Anonymous], 2014, Int. J. Eng. & Technol.
   [Anonymous], 2016, Advances in Face Detection and Facial Image Analysis
   [Anonymous], 2016, Handbook of human motion
   Bandhakavi A, 2017, IEEE INTELL SYST, V32, P102, DOI 10.1109/MIS.2017.22
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Breuer R.Kimmel., 2017, A deep learning perspective on the origin of facial expressions
   Chatterjee A., 2019, P 13 INT WORKSH SEM, P39, DOI DOI 10.18653/V1/S19-2005
   Chen X, 2022, LEARN INDIVID DIFFER, V98, DOI 10.1016/j.lindif.2022.102183
   Cohn JF, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P396, DOI 10.1109/AFGR.1998.670981
   Díaz-Aristizabal U, 2019, NEUROLOGIA, V34, P423, DOI 10.1016/j.nrl.2017.03.004
   Edwards G. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P581, DOI 10.1007/BFb0054766
   Ekman P., 2006, Darwin and facial expression: A century of research in review
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Ge HL, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106621
   Georgiev S, 2018, CARDIOL YOUNG, V28, P955, DOI 10.1017/S1047951118000586
   Gleaves A, 2008, ASSESS EVAL HIGH EDU, V33, P219, DOI 10.1080/02602930701292761
   Hasani B, 2017, IEEE INT CONF AUTOMA, P790, DOI 10.1109/FG.2017.99
   Herzig J, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P269, DOI 10.1145/3121050.3121093
   Hong H, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P354, DOI 10.1109/AFGR.1998.670974
   Huang CL, 1997, J VIS COMMUN IMAGE R, V8, P278, DOI 10.1006/jvci.1997.0359
   Jin H, 2019, VISUAL COMPUT, V35, P535, DOI 10.1007/s00371-018-1482-1
   Khassawneh O, 2022, BEHAV SCI-BASEL, V12, DOI 10.3390/bs12120511
   Kimura S, 1997, PROC CVPR IEEE, P295, DOI 10.1109/CVPR.1997.609338
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Kolog EA, 2018, ADV INTELL SYST, V721, P453, DOI 10.1007/978-3-319-73450-7_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Muhler V, 2020, justadudewhohacks/face-api.js
   Munezero M., 2013, Proceedings of the 13th Koli Calling International Conference on Computing Education Research, P145, DOI [10.1145/2526968.2526984, DOI 10.1145/2526968.2526984]
   Shivhare SN, 2012, Arxiv, DOI arXiv:1205.4944
   Ononye U., 2022, Knowledge and Performance Management, V6, P1, DOI [10.21511/kpm.06, DOI 10.21511/KPM.06]
   Otsuka T, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P442, DOI 10.1109/AFGR.1998.670988
   Oyelere SS, 2018, EDUC INF TECHNOL, V23, P467, DOI 10.1007/s10639-017-9613-2
   Padgett C, 1996, Advances in neural information processing systems, V9
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Pekrun R, 2023, LEARN INSTR, V83, DOI 10.1016/j.learninstruc.2022.101626
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Praveen RG, 2022, IEEE COMPUT SOC CONF, P2485, DOI 10.1109/CVPRW56347.2022.00278
   Ragheb W, 2019, Arxiv, DOI arXiv:1906.07020
   Refat CMM, 2019, 2019 7 INT C MECH EN, P1
   Sander P, 2022, CURR PSYCHOL, V41, P4329, DOI 10.1007/s12144-020-00957-0
   Sathik M, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-455
   Sawyer R, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P192, DOI 10.1145/3079628.3079686
   Seyeditabari A, 2018, Arxiv, DOI [arXiv:1806.00674, DOI 10.48550/ARXIV.1806.00674, 10.48550/arXiv.1806.00674]
   Smythe R, 2021, Delivering Health Care By Drone
   Wang M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P324, DOI 10.1109/AFGR.1998.670969
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yoneyama M, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P117, DOI 10.1109/ICIP.1997.647398
   Yu JS, 2016, CHIN CONT DECIS CONF, P5242, DOI 10.1109/CCDC.2016.7531935
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
   Zhang MX, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P38, DOI 10.1145/3368089.3409747
   Zhang YY, 2016, NEURAL PROCESS LETT, V43, P389, DOI 10.1007/s11063-015-9420-y
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao J., 1996, Progress in Neural Information Processing. Proceedings of the International Conference on Neural Information Processing, P454
   Zhu YH, 2022, EDUC INF TECHNOL, V27, P8921, DOI 10.1007/s10639-022-10961-5
NR 61
TC 0
Z9 0
U1 12
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 22
PY 2023
DI 10.1007/s11042-023-16722-x
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S3BY0
UT WOS:001069968300009
DA 2024-07-18
ER

PT J
AU Singh, AK
   Koundal, D
AF Singh, Aradhana Kumari
   Koundal, Deepika
TI Attention guided spatio-temporal network for 3D signature recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D signature; Spatio-temporal; Attention; Deep-learning; HCI
ID VERIFICATION
AB Signatures are considered one of the simplest way to verify a personal identity in many day-to-day application that are ranging from a student's classroom to a more sophisticated banking operation. However, signatures are prone to various attacks such as shoulder surfing, copying, etc. In order to restrict these attacks, advanced gesture based 3D signature systems have been introduced recently. The performance of these systems have low recognition rates and are still based on traditional feature engineering mechanisms. In this paper, we propose an attention guided spatio-tempotal deep neural network to model the 3D signature trajectories with the help of Convolutional Neural Networks (CNNs) and Long-Short-Term Memory (LSTM). The inclusion of an attention network, which focuses on important features within sequences, enhances the system's performance. We evaluate our model using a publicly available dataset consisting 1600 signatures from 80 signers where an average recognition rate of 93.37% was recorded. The proposed model also demonstrate its superior efficacy when compared to existing state-of-the-art solutions. Our findings highlight the potential of the proposed system in advancing the field of 3D signature recognition and authentication.
C1 [Singh, Aradhana Kumari; Koundal, Deepika] Univ Petr & Energy Studies, SoCS, Dehra Dun, Uttarakhand, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Singh, AK (corresponding author), Univ Petr & Energy Studies, SoCS, Dehra Dun, Uttarakhand, India.
EM singh.aradhana29@gmail.com; dkoundal@ddn.upes.ac.in
RI Koundal, Deepika/I-9927-2019
OI Koundal, Deepika/0000-0003-1688-8772
CR Ahrabian K., 2018, Neural Computing, V31, P1
   Alonso-Fernandez F, 2009, IEEE IMAGE PROC, P2725, DOI 10.1109/ICIP.2009.5414157
   Behera SK, 2018, INT C PATT RECOG, P3525, DOI 10.1109/ICPR.2018.8546265
   Behera SK, 2021, IEEE T CONSUM ELECTR, V67, P58, DOI 10.1109/TCE.2021.3055419
   Behera SK, 2017, MULTIMED TOOLS APPL, P1
   Chahar A, 2015, INT CONF BIOMETR THE
   Dolfing JGA, 1998, INT C PATT RECOG, P1309, DOI 10.1109/ICPR.1998.711942
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Ghosh S, 2021, PATTERN RECOGN LETT, V144, P13, DOI 10.1016/j.patrec.2021.01.012
   Guerra-Segura E, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113797
   Guru DS, 2009, IEEE T PATTERN ANAL, V31, P1059, DOI 10.1109/TPAMI.2008.302
   Hao S., 2021, P 2020 IEEE INT C E, P1
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Hu Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206049
   Jain AK, 2002, PATTERN RECOGN, V35, P2653, DOI 10.1016/S0031-3203(01)00218-7
   Josephs D, 2020, PR MACH LEARN RES, V136, P126
   Kaur H, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03356-w
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Kumar P, 2018, SIGN LANGUAGE RECOGN
   Kumar P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P995, DOI 10.1109/ICASSP39728.2021.9413989
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P8823, DOI 10.1007/s11042-017-4776-9
   Kumar P, 2018, PATTERN RECOGN LETT, V103, P1, DOI 10.1016/j.patrec.2017.12.014
   Kumar P, 2018, INFORM SCIENCES, V428, P30, DOI 10.1016/j.ins.2017.10.046
   Kumar P, 2017, IEEE SENS J, V17, P1293, DOI 10.1109/JSEN.2016.2643165
   Lee-Wen Chiu, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P260, DOI 10.1007/978-3-030-04375-9_22
   Lu D, 2018, ARXIV
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Mukherjee S, 2019, INT CONF ACOUST SPEE, P2027, DOI [10.1109/ICASSP.2019.8682158, 10.1109/icassp.2019.8682158]
   Nigam I, 2014, IEEE IMAGE PROC, P5012, DOI 10.1109/ICIP.2014.7026015
   Rahman A, 2019, PATTERN RECOGN, P76
   Cordeiro JR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237990
   Rehman IU, 2022, MULTIMED TOOLS APPL, P1
   Roy PP, 2021, MULTIMED TOOLS APPL, V80, P11671, DOI 10.1007/s11042-020-10229-5
   Roy PP., 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-021-00485-Z
   Sekhar C, 2019, ARXIV
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P3232, DOI 10.1109/TGRS.2019.2951160
   Tolosana R, 2018, IEEE ACCESS, V6, P5128, DOI 10.1109/ACCESS.2018.2793966
   Wu XM, 2019, INT CONF ACOUST SPEE, P2467, DOI [10.1109/icassp.2019.8683036, 10.1109/ICASSP.2019.8683036]
   Zhang X, 2013, IEEE MULTIMEDIA, V20, P85, DOI 10.1109/MMUL.2013.50
NR 39
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33985
EP 33997
DI 10.1007/s11042-023-16573-6
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100002
DA 2024-07-18
ER

PT J
AU Revathi, A
   Sasikaladevi, N
   Raju, N
AF Revathi, A.
   Sasikaladevi, N.
   Raju, N.
TI Real time implementation of voice based robust person authentication
   using T-F features and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensic investigation; Spectrogram; CNN; Machine learning; Person
   authentication; Raspberry Pi hardware
AB A forensic investigation uses personal traits to identify the persons involved in criminal offences. In this work on person authentication, the recorded voice samples can also be used to narrow down the search to identify persons. Time-frequency (T-F) features obtained from the concatenated training set of utterances are given to the convolutional neural networks (CNN), with layers configured for creating templates. Testing utterances are tied, and T-F features are derived. These features are applied to the CNN templates, and based on the match claimed, recognition accuracy is computed to validate the feature selection and CNN technique. Decision-level fusion of features with CNN for modelling and classification provides an overall authentication rate of 98%. This system is also implemented in real-time using Raspberry Pi hardware. This automated system would be helpful in identifying convicts in forensic sectors and perform secured online transactions against fraudulent attacks in financial sectors.
C1 [Revathi, A.; Raju, N.] SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
   [Sasikaladevi, N.] SASTRA Deemed Univ, Dept CSE SEEE, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
EM revathi@ece.sastra.edu
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Albuquerque RQ, 2021, NEURAL COMPUT APPL, V33, P9993, DOI 10.1007/s00521-021-05767-4
   Bigun J, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P2, DOI 10.1109/ICIAP.2003.1234017
   Das RK, 2017, J SIGNAL PROCESS SYS, V88, P259, DOI 10.1007/s11265-016-1148-z
   Dey S, 2014, NATL CONF COMMUN
   Duc B, 1997, PATTERN RECOGN LETT, V18, P835, DOI 10.1016/S0167-8655(97)00071-8
   Gonzalez-Huitron V, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105951
   Gunawan TS, 2020, PROCEEDING OF 2020 6TH INTERNATIONAL CONFERENCE ON WIRELESS AND TELEMATICS (ICWT), DOI 10.1109/icwt50448.2020.9243633
   Hu FH, 2020, ADV INTELL SYST COMP, V1039, P1, DOI 10.1007/978-3-030-30465-2_1
   Johnston SJ, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6030051
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   Pal M, 2015, APPL SOFT COMPUT, V30, P214, DOI 10.1016/j.asoc.2015.01.036
   Ramos-Lara R, 2013, J SIGNAL PROCESS SYS, V71, P89, DOI 10.1007/s11265-012-0683-5
   Rani R, 2016, International Research J Eng Tech
   Safavi S, 2016, INT CONF DAT MIN WOR, P1074, DOI [10.1109/ICDMW.2016.115, 10.1109/ICDMW.2016.0155]
   Sanderson C, 2004, DIGIT SIGNAL PROCESS, V14, P449, DOI 10.1016/j.dsp.2004.05.001
   Sarria-Paja M, 2015, CAN CON EL COMP EN, P1254, DOI 10.1109/CCECE.2015.7129458
   Suri M, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1206, DOI 10.1109/SSCI.2015.173
   Telmem M., 2021, Telecommunication Computing Electronics and Control, V19, P515
   Vashistha Piyush, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P974, DOI 10.1109/ICECA.2019.8821892
   Vázquez-Romero A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22060688
   Yamanoor NS, 2017, IEEE GLOB HUMANIT C
   Yang SZ, 2020, IEEE ACCESS, V8, P81468, DOI 10.1109/ACCESS.2020.2990974
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31587
EP 31601
DI 10.1007/s11042-023-16811-x
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200006
DA 2024-07-18
ER

PT J
AU Akram, A
   Khan, N
AF Akram, Arbish
   Khan, Nazar
TI LSRF: localized and sparse receptive fields for linear facial expression
   synthesis based on global face context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression synthesis; Linear formulation; Generative adversarial
   network; Orthogonal matching pursuit
ID TRANSLATION
AB Existing generative adversarial network-based methods for facial expression synthesis require larger datasets for training. Their performance tends to decrease noticeably when trained on smaller datasets. Moreover, they demand higher computational and spatial complexity at inference, making them unsuitable for resource-constrained devices. To address these limitations, this paper presents a linear formulation to learn Localized and Sparse Receptive Fields (LSRF) for facial expression synthesis considering global face context. In this approach, we extend the sparsity-inducing formulation of the Orthogonal Matching Pursuit (OMP) algorithm by incorporating a locality constraint. This constraint ensures that i) each output pixel observes a localized region and ii) neighboring output pixels attend proximate regions of the input face image. Extensive qualitative as well as quantitative experiments demonstrate that the proposed method generates realistic facial expressions and outperforms existing methods. Further, the proposed method can be trained by employing significantly smaller datasets while exhibiting good generalization capabilities for out-of-distribution images.
C1 [Akram, Arbish; Khan, Nazar] Univ Punjab, Dept Comp Sci, Lahore, Pakistan.
C3 University of Punjab
RP Akram, A (corresponding author), Univ Punjab, Dept Comp Sci, Lahore, Pakistan.
EM arbishakram@pucit.edu.pk; nazarkhan@pucit.edu.pk
OI Akram, Arbish/0000-0003-2661-4855
CR AKRAM A, 2023, MULTIMED TOOLS APPL
   Akram A, 2021, INT C PATT RECOG, P9733, DOI 10.1109/ICPR48806.2021.9413065
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Chen CF, 2021, PROC CVPR IEEE, P11891, DOI 10.1109/CVPR46437.2021.01172
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen YC, 2020, PROC CVPR IEEE, P5273, DOI 10.1109/CVPR42600.2020.00532
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   d'Apolito S, 2021, PROC CVPR IEEE, P568, DOI 10.1109/CVPR46437.2021.00063
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Gao Y, 2021, PROC CVPR IEEE, P16110, DOI 10.1109/CVPR46437.2021.01585
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hou H, 2023, IEEE T IMAGE PROCESS, V32, P1184, DOI 10.1109/TIP.2023.3240845
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jun Ling, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P37, DOI 10.1007/978-3-030-58604-1_3
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Khan N, 2023, IEEE TCSVT
   Khan N, 2020, INT J COMPUT VISION, V128, P1433, DOI 10.1007/s11263-019-01256-3
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Megvii Inc, 2019, FAC
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nirkin Y, 2023, IEEE T PATTERN ANAL, V45, P560, DOI 10.1109/TPAMI.2022.3155571
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Perarnau G, 2016, ARXIV
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Qiao F, 2018, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Song LX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P627, DOI 10.1145/3240508.3240612
   Tang H, 2022, IEEE T AFFECT COMPUT, V13, P1986, DOI 10.1109/TAFFC.2022.3207007
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wu RL, 2020, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR42600.2020.00507
   Xia YF, 2022, IEEE T CIRC SYST VID, V32, P1443, DOI 10.1109/TCSVT.2021.3074032
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
NR 43
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31341
EP 31360
DI 10.1007/s11042-023-16822-8
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500007
DA 2024-07-18
ER

PT J
AU Shoukat, MU
   Yan, LR
   Zhang, JW
   Cheng, Y
   Raza, MU
   Niaz, A
AF Shoukat, Muhammad Usman
   Yan, Lirong
   Zhang, Jiawen
   Cheng, Yu
   Raza, Muhammad Umair
   Niaz, Ashfaq
TI Smart home for enhanced healthcare: exploring human machine interface
   oriented digital twin model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Home-devices' digital twin; Human-machine interface; Human
   cyber-physical system; Internet of things; Game theory model
ID INTERNET
AB Digital twin (DT) and other emerging technologies such as the Internet of Things (IoT), data mining, reinforcement learning, remote intelligent control, and machine learning offer enormous potential for transforming today's equipment model into intelligent devices. It is one of the key technologies to endorse the virtual and remote intelligent control system for home-devices (HD) in human comfort (disabled/elderly). The relevant research is in the initial stage, and how to realize the DT of home-equipment control has become a vital problem to be solved. This study expounds on the suggestion and application of the DT model and summarizes the research and application progress from the aspect of the home-devices' DT (HDDT) modeling. This modelling approach is three-staged: in terms of physical entities, virtual entities, and connectivity (data communication). The proposed model utilizes an interactive mechanism for the intelligent control of HD, by integrating DT and virtual simulation technologies to establish a human cyber-physical system (HCPS), specifically addressing the challenges associated with remote-control problems. The HCPS aims to achieve a deep integration and interface between the physical and virtual spaces of smart-device information. Using the game theory approach to create multi-physical entities and DT entities of IoT-based HD like washing machines, lamps, breakers, heaters, kitchen equipment, TV, AC, etc. The next step is to develop high-performance smart devices and build a reasonable sensing network to improve the depth and range of connection. The equipment tracking test showed that the system could control virtual reality synchronization, positional accuracy, and quality control for smart-devices development in HDDT modeling.
C1 [Shoukat, Muhammad Usman; Yan, Lirong; Zhang, Jiawen; Cheng, Yu] Wuhan Univ Technol, Sch Automot Engn, Hubei Key Lab Adv Technol Automot Components, Wuhan 430070, Peoples R China.
   [Raza, Muhammad Umair] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Niaz, Ashfaq] Taiyuan Univ Technol, Coll Elect & Power Engn, Taiyuan 030024, Peoples R China.
C3 Wuhan University of Technology; Shenzhen University; Taiyuan University
   of Technology
RP Yan, LR (corresponding author), Wuhan Univ Technol, Sch Automot Engn, Hubei Key Lab Adv Technol Automot Components, Wuhan 430070, Peoples R China.
EM lirong.yan@whut.edu.cn
RI zhang, jiawen/IVU-8151-2023
OI Shoukat, Muhammad Usman/0000-0001-8543-8439
CR Bauters K, 2019, THESIS GHENT U
   Bianco S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227453
   Bruynseels K, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00031
   Casadei R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010349
   Jimenez IAC, 2023, INT J INTERACT DES M, V17, P45, DOI 10.1007/s12008-022-01087-6
   Cheng J, 2020, ROBOT CIM-INT MANUF, V62, DOI 10.1016/j.rcim.2019.101881
   Cimino C, 2019, COMPUT IND, V113, DOI 10.1016/j.compind.2019.103130
   Dalmarco Gustavo, 2019, Journal of High Technology Management Research, V30, P69, DOI 10.1016/j.hitech.2019.100355
   Demiris George, 2004, Int J Electron Healthc, V1, P4, DOI 10.1504/IJEH.2004.004655
   Esposito C, 2018, J PARALLEL DISTR COM, V118, P328, DOI 10.1016/j.jpdc.2017.12.010
   Fernández A, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.5.053107
   Kaushik H, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108788
   Li W, 2019, P IEEE C COMP VIS PA, DOI DOI 10.48550/ARXIV.1901.00148
   Lui Sha, 2008, 2008 IEEE International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing (SUTC '08), P1
   Mihai S, 2022, IEEE COMMUN SURV TUT, V24, P2255, DOI 10.1109/COMST.2022.3208773
   Pires F, 2019, IEEE INTL CONF IND I, P721, DOI [10.1109/indin41052.2019.8972134, 10.1109/INDIN41052.2019.8972134]
   Qazi AM, 2022, MATER TODAY-PROC, V62, P18, DOI 10.1016/j.matpr.2022.01.387
   Qin W, 2020, DIGIT COMMUN NETW, V6, P1, DOI 10.1016/j.dcan.2019.07.001
   Shoukat MU, 2021, 2021 5 CAA INT C VEH, P1, DOI [10.1109/CVCI54083.2021.9661190, DOI 10.1109/CVCI54083.2021.9661190]
   Tao F, 2019, INT J PROD RES, V57, P3935, DOI 10.1080/00207543.2018.1443229
   Tao Fei, 2018, Computer Integrated Manufacturing Systems, V24, P1, DOI 10.13196/j.cims.2018.01.001
   Thomas H., 2020, GERMAN CHINESE CONTR, P49
   WAGNER C, 2017, 2017 22 IEEE INT C E, P1, DOI DOI 10.1109/ETFA.2017.8247583
   Wang BC, 2021, ENGINEERING-PRC, V7, P738, DOI 10.1016/j.eng.2020.07.017
   Wu M., 2020, Meitan Xuebao/Journal China Coal Soc., V45, P506
   YuanL Fu Z, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2001.07752
   Zhuang CB, 2018, INT J ADV MANUF TECH, V96, P1149, DOI 10.1007/s00170-018-1617-6
NR 27
TC 4
Z9 4
U1 13
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31297
EP 31315
DI 10.1007/s11042-023-16875-9
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066762000015
DA 2024-07-18
ER

PT J
AU Ray, HS
   Bose, S
   Mukherjee, N
   Neogy, S
   Chattopadhyay, S
AF Ray, Himadri Sekhar
   Bose, Sunanda
   Mukherjee, Nandini
   Neogy, Sarmistha
   Chattopadhyay, Samiran
TI A cross-layer fragmentation approach to video streaming over mobile
   ad-hoc network using BATMAN-Adv
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transmission; Fragmentation; Adhoc network; BATMAN-ADV
AB The growing popularity of mobile devices equipped with wireless interfaces makes Mobile Ad-hoc Networks (MANET) an interesting architecture for the rapid deployment of related applications without relying on any infrastructure. This is a self-healing architecture that attracts this network in a challenging environment. Node mobility causes an ad-hoc network's topology to be in a constant state of flux. Route changes and link failures are the most common problems in communication over ad hoc networks, causing an increase in delay, delay variation (jitter) and packet loss. In these networks, in the absence of a central scheduling node, the nodes must be always available to receive and forward packets even when they are not the origin or destination of transmission. When the MANET is dense, and the source is located more than one hop away from the destination, providing delivery ratios that meet real-time video streaming constraints is still an open issue. In this paper, we have used a cross-layered fragmentation approach to transmit high-resolution real-time multimedia data with minimal delay, high throughput and high fps despite limited bandwidth. Here image frames or video frames are segmented into smaller chunks and sent to the network as a payload of a network packet. This ensures that the data lost in our network is less compared to non-segmented frames.
C1 [Ray, Himadri Sekhar; Bose, Sunanda; Mukherjee, Nandini; Neogy, Sarmistha] Jadavpur Univ, Dept Comp Sci & Engn, 132,Raja Subodh Chandra Mallick Rd, Kolkata 700032, W Bengal, India.
   [Chattopadhyay, Samiran] Jadavpur Univ, Dept Informat Technol, LB Block, Kolkata 700098, W Bengal, India.
C3 Jadavpur University; Jadavpur University
RP Ray, HS (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, 132,Raja Subodh Chandra Mallick Rd, Kolkata 700032, W Bengal, India.
EM himadri.1111@gmail.com; sunanda.bose@msn.com; nmukherjee@cse.jdvu.ac.in;
   sarmisthaneogy@gmail.com; samirancju@gmail.com
RI Chattopadhyay, Samiran/AAW-3145-2021
OI Chattopadhyay, Samiran/0000-0002-8929-9605
CR Aziz HM, 2010, WONS 2010: SEVENTH INTERNATIONAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES, P53, DOI 10.1109/WONS.2010.5437132
   Haratcherev I, 2005, 2005 International Conference on Wireless Networks, Communications and Mobile Computing, Vols 1 and 2, P1522
   Hung-Chin Jang, 2008, 2008 22nd International Conference on Advanced Information Networking and Applications - Workshops, P560, DOI 10.1109/AINA.2008.88
   Ibrahim N. K., 2012, 2012 IEEE Symposium on Wireless Technology & Applications (ISWTA 2012), P142, DOI 10.1109/ISWTA.2012.6373829
   Jian Liu, 2010, 2010 Proceedings of 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing (UIC/ATC 2010), P165, DOI 10.1109/UIC-ATC.2010.9
   Joshi J, 2015, 2015 IEEE 3 INT C SM, P1, DOI [10.1109/ICSIMA.2015.7559039, DOI 10.1109/ICSIMA.2015.7559039]
   Kacianka S, 2015, P 7 ACM INT WORKSH M, DOI [10.1145/2727040.2727043, DOI 10.1145/2727040.2727043]
   Kathuria A, 2017, 2017 INT C BIG DAT A, DOI [10.1109/icbdaci.2017.8070867, DOI 10.1109/ICBDACI.2017.8070867]
   Kondo Y, 2022, 2022 IEEE 19 ANN CON, P937, DOI [10.1109/CCNC49033.2022.9700496, DOI 10.1109/CCNC49033.2022.9700496]
   Phakathi T, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P886, DOI [10.1109/CSCI.2016.171, 10.1109/CSCI.2016.0172]
   Prasad A, 2021, IEEE ACCESS, V9, P152408, DOI 10.1109/ACCESS.2021.3127079
   Qadri NN, 2009, P 6 INT C FRONT INF, DOI [10.1145/1838002.1838076, DOI 10.1145/1838002.1838076]
   Rozy NF, 2019, PROC 7 INT C CYBER I, DOI [10.1109/citsm47753.2019.8965386, DOI 10.1109/CITSM47753.2019.8965386]
   Sheltami TR., 2008, J MOB MULTIMED, V4, P59
   Takahata K, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P340
   Tian Bo, 2021, 2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID), P701, DOI 10.1109/AIID51893.2021.9456493
   Zheng Hancong, 2022, 2022 IEEE Globecom Workshops (GC Wkshps), P1273, DOI 10.1109/GCWkshps56602.2022.10008657
   Zhou H, 2021, IEEE WIREL COMMUN LE, V10, P1657, DOI 10.1109/LWC.2021.3076415
NR 18
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29547
EP 29567
DI 10.1007/s11042-023-16658-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900006
DA 2024-07-18
ER

PT J
AU Malik, DS
   Shah, TR
AF Malik, Dania Saleem
   Shah, Tariq
TI 4D-dynamical system and convolution codes based colored image encryption
   scheme: information security perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Convolution codes; Chaotic maps
ID OPERATION; MAP
AB A novel color image encryption based on permutation and bit-wise exclusive OR (XOR) operation is introduced in this work. The main objective of the proposed scheme is to provide techniques for safe transmission of image data. A novel technique for generating relation between image pixels and key initial values is proposed in this work to minimize the image attacks, as the sensitivity of key to image pixels is enhanced in such a way that if an attacker slightly changes the image pixel, key values are changed too. For this purpose, two random numbers are derived from novel convolution codes technique. These random numbers are then utilized as initial values of four-dimensional (4-D) dynamical system for generation of the chaotic sequences. These sequences are then deployed in confusion and diffusion phase for segmented images. For the illustration of security level, the proposed scheme is validated via different analysis that includes histogram, correlation, entropy, differential attacks (number of pixel change rate (NPCR), unified average changing intensity (UACI)), key space and key sensitivity analysis. Proposed technique achieves encrypted images RGB (red, green, blue) channel entropy values lie between 7.99791 and 7.9990, NPCR values between 99.5873% and 99.7341%, UACI values between 33.051% and 33.422% and Peak signal noise ratio (PSNR) values between 7.8218 and 9.3821. Also, in key sensitivity analysis a slight alteration in key does not provide any information for the decryption of image. The simulation analysis of proposed scheme confirmed the high sensitivity, image pixels uniform distribution and randomness. Also, the classical attack analysis is performed to check security of proposed ciphered image.
C1 [Malik, Dania Saleem] HITEC Univ, Dept Math, Taxila, Pakistan.
   [Shah, Tariq] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 NITEC University; Quaid I Azam University
RP Malik, DS (corresponding author), HITEC Univ, Dept Math, Taxila, Pakistan.
EM daniasaleem44@gmail.com; stariqshah@gmail.com
RI Saleem, Dania/JFJ-2776-2023
CR Ababneh M, 2018, AIN SHAMS ENG J, V9, P1849, DOI 10.1016/j.asej.2016.08.020
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Biryukov A, 2000, LECT NOTES COMPUT SC, V1807, P589
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dholakia A, 2012, INTRO CONVOLUTIONAL, V275
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Essaid M, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723717
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Jahangir S, 2020, MULTIMED TOOLS APPL, V79, P26885, DOI 10.1007/s11042-020-08995-3
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Kaur M, 2018, IMAGING SCI J, V66, P453, DOI 10.1080/13682199.2018.1505327
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Menon AS., 2013, INT J SCI ENG TECHNO, V2, P1328
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shah D, 2021, MULTIMED TOOLS APPL, V80, P22251, DOI 10.1007/s11042-021-10697-3
   Shah D, 2020, MULTIMED TOOLS APPL, V79, P28023, DOI 10.1007/s11042-020-09182-0
   Shi DF, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12664-1
   ul Haq T, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102931
   Vidhya R., 2020, J KING SAUD UNIV-COM
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Yuan X, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7286-9
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
NR 30
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29353
EP 29375
DI 10.1007/s11042-023-16648-4
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400008
DA 2024-07-18
ER

PT J
AU Wu, XW
   Chen, TH
AF Wu, Xi-Wen
   Chen, Tzung-Her
TI Security enhancement of an (n, n) threshold non-expansible XOR-based
   visual cryptography with unique meaningful shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE XOR-based visual cryptography; Perfect reconstruction; Meaningful share
AB More and more visual cryptography (VC) schemes have been engaged by introducing computational operations, such as XOR, in the secret decoding phase. To our best knowledge, Singh et al.'s scheme is the very first attempt to present an XOR-based VC scheme with the goals of both unique meaningful shares and perfect secret reconstruction. Thus, it's worthwhile to further examine and enhance the security of Singh et al.'s scheme. This paper highlights shortcomings in Singh et al.'s XOR-based VC scheme, including the risk of revealing the secret via a single share and the absence of an (n,n) case. The paper also presents security enhancements. In addition, the related experiments are conducted to ensure the validity of the algorithms in Singh et al.'s scheme.
C1 [Wu, Xi-Wen; Chen, Tzung-Her] Natl Chiayi Univ, Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Comp Sci & Informat Engn, Chiayi, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology of Taiwan
   [MOST~110-2221-E-415-006-MY2]; National Science and Technology Council
   of Taiwan [NSTC 112-2221-E-415-005]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under Grant MOST~110-2221-E-415-006-MY2, and in
   part by the National Science and Technology Council of Taiwan under
   Grant NSTC 112-2221-E-415-005.
CR Chang CC, 2002, PATTERN RECOGN LETT, V23, P1847, DOI 10.1016/S0167-8655(02)00157-5
   Chen TH, 2021, MULTIMED TOOLS APPL, V80, P1901, DOI 10.1007/s11042-020-09484-3
   Chen TH, 2020, MULTIMED TOOLS APPL, V79, P13247, DOI 10.1007/s11042-019-08524-x
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Li P, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103513
   Lin CS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060612
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Ma XH, 2022, RESULTS PHYS, V43, DOI 10.1016/j.rinp.2022.106065
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Paul A, 2023, MATH OPER RES, V48, P2304, DOI 10.1287/moor.2022.1340
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Tsai CS, 2002, J SYST SOFTWARE, V64, P163, DOI 10.1016/S0164-1212(02)00034-1
   Zhao YK, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103408
NR 16
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28913
EP 28926
DI 10.1007/s11042-023-16657-3
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060281300001
DA 2024-07-18
ER

PT J
AU Bakkouri, S
   Elyousfi, A
AF Bakkouri, Siham
   Elyousfi, Abderrahmane
TI An adaptive CU size decision algorithm based on gradient boosting
   machines for 3D-HEVC inter-coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Machine learning; Gradient boosting machines; CU size;
   Inter-coding
ID TEXTURE CORRELATION; MULTIVIEW VIDEO; DEPTH
AB 3D high-efficiency video coding (3D-HEVC) is an extension of the HEVC standard for coding of texture videos and depth maps. 3D-HEVC inherits the same quadtree coding structure as HEVC for both texture and depth components, in which the coding units (CUs) are recursively conducted on different sizes, namely, depth levels. However, the recursive splitting process of the CU causes extensive computational complexity. To reduce this computational burden, this paper presents an adaptive CU size decision algorithm for texture videos and depth maps. The proposed algorithm is divided into three steps. In the first step, the average local variance (ALV) is extracted from each CU size to define their homogeneity. Then, a classification-based gradient boosting machines (GBM) is employed to analyze and build a binary classification model from the extracted ALV features. The GBM model is employed to extract and efficiently get suitable thresholds for texture and depth map CUs. In the last step, a fast CU size decision algorithm is performed based on adaptive thresholds for texture videos and depth maps. The experimental results show that the proposed algorithm reduces a significant amount of encoding time, while the loss in coding efficiency is negligible.
C1 [Bakkouri, Siham] Sultan Moulay Slimane Univ, Higher Sch Technol, Beni Mellal 23000, Morocco.
   [Elyousfi, Abderrahmane] Ibn Zohr Univ, Dept Comp Sci, Natl Engn Sch Appl Sci, Agadir 80000, Morocco.
   [Elyousfi, Abderrahmane] Ibn Zohr Univ, Comp Syst & Vis Lab, Fac Sci, Agadir 80000, Morocco.
C3 Sultan Moulay Slimane University of Beni Mellal; Ibn Zohr University of
   Agadir; Ibn Zohr University of Agadir
RP Bakkouri, S (corresponding author), Sultan Moulay Slimane Univ, Higher Sch Technol, Beni Mellal 23000, Morocco.
EM siham.bakkouri@gmail.com
RI BAKKOURI, Siham/AAY-8778-2021
OI BAKKOURI, Siham/0000-0003-3443-7756
CR Ahn YJ, 2016, J REAL-TIME IMAGE PR, V12, P419, DOI 10.1007/s11554-015-0487-5
   [Anonymous], 2008, Tech. Rep ISO/IEC JTC1/SC29/WG11 M16090
   Bahad P., 2020, International Conference on Intelligent Computing and Smart Communication 2019, DOI [10.1007/978-981-15-0633-8_22, DOI 10.1007/978-981-15-0633-8_22]
   Bakkouri S, 2020, 2020 INT C INT SYST, DOI [10.1109/iscv49265.2020.9204037, DOI 10.1109/ISCV49265.2020.9204037]
   Bakkouri S, 2020 IEEE ACS 17 INT, DOI [10.1109/aiccsa50499.2020.9316455, DOI 10.1109/AICCSA50499.2020.9316455]
   Bakkouri S, 2022, IEEE ACCESS, V10, P13870, DOI 10.1109/ACCESS.2022.3147502
   Bakkouri S, 2021, J REAL-TIME IMAGE PR, V18, P983, DOI 10.1007/s11554-020-01059-7
   Bakkouri S, 2020, MULTIMED TOOLS APPL, V79, P6987, DOI 10.1007/s11042-019-08461-9
   Bjntegaard G, 2001, Document VCEGM33
   Bjntegaard G, 2008, 35 VCEG M BERL
   Bocher PK, 2006, IEEE T IMAGE PROCESS, V15, P300, DOI 10.1109/TIP.2005.860623
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Chen J, 2019, MULTIMED TOOLS APPL, V78, P29291, DOI 10.1007/s11042-018-6832-5
   Chen M, 2016, OPTIK, V127, P4758, DOI 10.1016/j.ijleo.2016.01.204
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Guelman L, 2012, EXPERT SYST APPL, V39, P3659, DOI 10.1016/j.eswa.2011.09.058
   Islam N, 2016, SIGNAL PROCESS-IMAGE, V41, P15, DOI 10.1016/j.image.2015.11.003
   Joint Collaborative Team on 3D video coding (JCT-3V), 2016, HTM 16.2 Reference Software
   Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332
   Li Y, 2020, J REAL-TIME IMAGE PR, V17, P1227, DOI 10.1007/s11554-019-00876-9
   Li Y, 2017, IEEE T BROADCAST, V63, P535, DOI 10.1109/TBC.2017.2704423
   Liao YW, 2019, MULTIMED TOOLS APPL, V78, P10181, DOI 10.1007/s11042-018-6547-7
   Lin JR, 2021, IEEE ACCESS, V9, P100081, DOI 10.1109/ACCESS.2021.3093950
   Mayr A, 2014, METHOD INFORM MED, V53, P428, DOI 10.3414/ME13-01-0123
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Saldanha M, 2020, IEEE T CIRC SYST VID, V30, P850, DOI 10.1109/TCSVT.2019.2898122
   Sapountzoglou N, 2020, ELECTR POW SYST RES, V182, DOI 10.1016/j.epsr.2020.106254
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Si MX, 2020, ENVIRON TECHNOL INNO, V20, DOI 10.1016/j.eti.2020.101028
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Tai KH, 2017, IEEE T BROADCAST, V63, P680, DOI 10.1109/TBC.2017.2722239
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   WOODCOCK CE, 1987, REMOTE SENS ENVIRON, V21, P311, DOI 10.1016/0034-4257(87)90015-0
   Zhang QW, 2017, J VIS COMMUN IMAGE R, V45, P170, DOI 10.1016/j.jvcir.2017.03.004
   Zhang X, 2011, Encycl Mach Learn,, P456
NR 38
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32539
EP 32557
DI 10.1007/s11042-023-14540-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LE2R0
UT WOS:001185043200001
DA 2024-07-18
ER

PT J
AU Wang, FP
   Ben, KR
   Peng, H
   Yang, MN
AF Wang, Feipeng
   Ben, Kerong
   Peng, Hu
   Yang, Meini
TI NeighborMix data augmentation for image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data augmentation; NeighborMix; Image recognition; Convolutional neural
   network
ID NEURAL-NETWORKS
AB Data augmentation can effectively enrich the diversity of training datasets to improve the generalization ability of deep learning models. Existing augmentation methods have achieved excellent performance on image recognition. However, the images generated by them can not well improve the accuracy and robustness of the model trained with natural scene data. In this paper, an augmentation method called NeighborMix is proposed to address this problem. NeighborMix only performs simple operations on the original image. Specifically, NeighborMix selects and pastes an occlusion object closely related to the original input image in a successive two-stage fashion. In the first stage, a block from a single original image is selected as the occlusion object. In the second stage, the occlusion object is copied and pasted into the original image to generate a new image. Finally, extensive experiments on benchmark datasets demonstrate that NeighborMix achieves top-1 results of 93.54%, 70.62%, and 89.30% superior model generalization performance on CIFAR-10, CIFAR-100, and STL-10, respectively, and performs the most robustness with a standard error of 0.05%, outperforms state-of-the-art data augmentation techniques.
C1 [Wang, Feipeng; Ben, Kerong; Yang, Meini] Naval Univ Engn, Coll Elect Engn, Qiaokou Dist Hanshui Bridge St, Wuhan 430074, Hubei, Peoples R China.
   [Wang, Feipeng; Peng, Hu] Jiujiang Univ, Sch Comp & Big Data Sci, Shili St, Jiujiang 332005, Jiangxi, Peoples R China.
C3 Wuhan Naval University of Engineering; Jiujiang University
RP Wang, FP; Ben, KR (corresponding author), Naval Univ Engn, Coll Elect Engn, Qiaokou Dist Hanshui Bridge St, Wuhan 430074, Hubei, Peoples R China.; Wang, FP (corresponding author), Jiujiang Univ, Sch Comp & Big Data Sci, Shili St, Jiujiang 332005, Jiangxi, Peoples R China.
EM wfpyufei@163.com; benkerong08@163.com; hu_peng@whu.edu.cn;
   ymn_411@126.com
RI Wang, Feipeng/AAJ-3068-2020
OI Wang, Feipeng/0000-0003-2905-3723
FU National Natural Science Foundation of China [61763019]
FX This work was produced in part by the National Natural Science
   Foundation of China under Grants 61763019.
CR Brandt A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2101485118
   Brendel W, 2019, PREPRINT
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T, 2022, IEEE T MULTIMEDIA, V24, P968, DOI 10.1109/TMM.2021.3061816
   Coates A., 2011, P 14 INT C ART INT S, P215
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk Ekin D, 2018, ARXIV180509501
   Dash T, 2021, PREPRINT
   DeVries T, 2017, PREPRINT
   DHondt M, 1999, LNCS, V1743, P293
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Han J, 2022, PREPRINT
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kim UH, 2022, IEEE T PATTERN ANAL, V44, P428, DOI 10.1109/TPAMI.2020.3007546
   Kim Y, 2021, IEEE ACCESS, V9, P15191, DOI 10.1109/ACCESS.2021.3050758
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Lopes RG, 2019, PREPRINT
   [马岽奡 Ma Dongao], 2021, [中国图象图形学报, Journal of Image and Graphics], V26, P487
   Pan Y, 2022, RELIAB ENG SYST SAFE, V217, DOI 10.1016/j.ress.2021.108114
   Pawar K, 2021, COMPUT MED IMAG GRAP, V92, DOI 10.1016/j.compmedimag.2021.101968
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang YX, 2016, ADV NEUR IN, V29
   Welch DM, 2000, SCIENCE, V288, P1211, DOI 10.1126/science.288.5469.1211
   Wu ZY, 2022, IEEE T MULTIMEDIA, V24, P73, DOI 10.1109/TMM.2020.3046871
   Xu K, 2021, IEEE T MULTIMEDIA, V23, P3530, DOI 10.1109/TMM.2020.3026913
   Yi JR, 2021, IEEE T MED IMAGING, V40, P2403, DOI 10.1109/TMI.2021.3077285
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhan C, 2020, IEEE T MULTIMEDIA, V22, P795, DOI 10.1109/TMM.2019.2931441
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang HZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P430, DOI 10.1145/3394171.3413582
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 38
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26581
EP 26598
DI 10.1007/s11042-023-16603-3
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400006
DA 2024-07-18
ER

PT J
AU Montanaro, M
   Rinaldi, AM
   Russo, C
   Tommasino, C
AF Montanaro, Marco
   Rinaldi, Antonio Maria
   Russo, Cristiano
   Tommasino, Cristian
TI A rule-based obfuscating focused crawler in the audio retrieval domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio retrieval; Information retrieval; Deep neural networks; Web
   crawler; Focused crawler; Indexing; Pattern recognition; Copyright
   infringement
ID MULTIMEDIA; SEARCH; CLASSIFICATION
AB The detection of violations of intellectual properties on multimedia files is a critical problem for the current infrastructure of the Internet, especially within very large document collections. To contrast such a problem, either proactive or reactive methods are used. The first category prevents the upload of infringing files themselves by comparing illegal files with a reference collection, while the second one responds to reports made by third parties or artificial intelligence systems in order to delete files deemed illegal. In this article we propose an approach that is both reactive and proactive at the same time, with the aim of preventing the deletion of legal uploads of files (or modifications of such files, such as remixes, parodies and other edits) due to the presence of illegal uploads on a platform. We developed a rule-based obfuscating focused crawler able to work with audio files in the Audio Information Retrieval (AIR) domain, but its use can be easily extended to other multimedia file types, such as videos or textual documents. Our proposed model automatically scans multimedia files uploaded to the public collection only when a user query is submitted to it. We will also show experimental results obtained during tests on a known musical collection. Several combinations of specific Neural Network-Similarity Scorer solutions are shown, and we will discuss the strength and efficiency of each combination.
C1 [Montanaro, Marco; Rinaldi, Antonio Maria; Russo, Cristiano; Tommasino, Cristian] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
C3 University of Naples Federico II
RP Rinaldi, AM (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
EM marco.montanaro@unina.it; antoniomaria.rinaldi@unina.it;
   cristiano.russo@unina.it; cristian.tommasino@unina.it
RI Rinaldi, Antonio M./O-7452-2019
OI Rinaldi, Antonio M./0000-0001-7003-4781
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Baeza-Yates R., 1999, MODERN INFORM RETRIE, V463
   Bartlett P, 2012, 26 ANN C NEURAL INFO
   Beckert S, 2018, Columbia Stud Hist U, P1
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bogert B., 1963, P S TIME SERIES ANAL, P209
   Bokhari M.U., 2013, Int. J. Comput. Appl., V74
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Burguet R, 2015, INT J IND ORGAN, V39, P44, DOI 10.1016/j.ijindorg.2015.02.003
   Caldarola EG., 2016, Commun. Comput. Inform. Sci, V631, P80, DOI [10.1007/978-3-319-52758-16, DOI 10.1007/978-3-319-52758-16]
   Capuano A, 2020, MULTIMED TOOLS APPL, V79, P7577, DOI 10.1007/s11042-019-08252-2
   Celma O, 2006, 7 INT C MUS INF RETR
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dhar PK, 2011, INT J SECUR APPL, V5, P33
   Diligenti Michelangelo., 2000, VLDB
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Furht B., 2008, Encyclopedia of Multimedia, P651, DOI 10.1007/978-0-387-78414-4_159
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henaff M., 2011, ISMIR, V11, P2011
   Hersovici M, 1998, COMPUT NETWORKS ISDN, V30, P317, DOI 10.1016/S0169-7552(98)00038-5
   Jordan MI., 1997, ADV PSYCHOL, V121, P471, DOI [DOI 10.1016/S0166-4115(97)80111-2, 10.1016/s0166-4115(97)80111-2]
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Klapuri A., 2004, SIGNAL PROCESSING ME
   Knees Peter, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P447, DOI 10.1145/1277741.1277818
   Kumar M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1218
   Lazaridis M, 2013, SIGNAL PROCESS-IMAGE, V28, P351, DOI 10.1016/j.image.2012.04.001
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Mun S, 2017, INT CONF ACOUST SPEE, P796, DOI 10.1109/ICASSP.2017.7952265
   Nair UR, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Olteanu A, 2019, GTZAN DATASET MUSIC
   Oppenheim C, 1997, COPYRIGHT ELECT AGE, P97
   Organisation for Economic Co-operation and Development, 2015, ENQ INT PROP EC IMP
   Pan B, 2007, J COMPUT-MEDIAT COMM, V12, P801, DOI 10.1111/j.1083-6101.2007.00351.x
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Purificato E, 2018, MULTIMED TOOLS APPL, V77, P27447, DOI 10.1007/s11042-018-5931-7
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Rajanna AR, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P655, DOI 10.1109/ICMLA.2015.160
   Rinaldi AM, 2021, MULTIMED TOOLS APPL, V80, P3885, DOI 10.1007/s11042-020-09761-1
   Rinaldi AM, 2014, IEEE INT CONGR BIG, P242, DOI 10.1109/BigData.Congress.2014.43
   Safadi B, 2015, MULTIMED TOOLS APPL, V74, P1267, DOI 10.1007/s11042-014-2071-6
   Sak H, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1402.1128
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sturm BLT, 2019, ARTS, V8, DOI 10.3390/arts8030115
   Sumanth T., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1813, DOI 10.1109/ICECA.2018.8474758
   Tindall L, 2015, Plankton classification using vgg16 network
   Turek W, 2011, COMM COM INF SC, V149, P183
   Udapur T.V., 2014, INT ORG SCI RES J CO, V16, P1, DOI DOI 10.9790/0661-16160105
   Van der Ende M, 2014, ESTIMATING DISPLACEM
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Yang C, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P123, DOI 10.1109/ASPAA.2001.969558
NR 53
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25231
EP 25260
DI 10.1007/s11042-023-16155-6
EA AUG 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060705500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Dhal, KG
   Das, A
   Sasmal, B
   Ray, S
   Rai, R
   Garai, A
AF Dhal, Krishna Gopal
   Das, Arunita
   Sasmal, Buddhadev
   Ray, Swarnajit
   Rai, Rebika
   Garai, Arpan
TI Fuzzy C-Means for image segmentation: challenges and solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram clustering; Image segmentation; Optimization; Swarm
   intelligence; Noise
ID MEANS CLUSTERING-ALGORITHM; RANDOM-FIELD MODELS; LOCAL INFORMATION;
   FIREFLY ALGORITHM; OPTIMIZATION; FCM; IDENTIFICATION; MAHALANOBIS;
   SEARCH; FUSION
AB Image segmentation is considered a pertinent prerequisite for numerous tasks in digital image processing. The procedure through which identical segments in an image are identified is termed digital image segmentation and well-known clustering techniques are incorporated for the same. The Fuzzy C-Means algorithm, popularly known as FCM, is one of the most extensively employed clustering methodologies, but it has several drawbacks, including a costly computational time complexity, initial cluster centers, membership matrix reliance, and noise sensitivity. An up-to-date review of the solutions mentioned in recent literature to overcome the issues has been presented in this paper. Further, the main issues involved in the development of these improved FCM variants are deliberated.
C1 [Dhal, Krishna Gopal; Das, Arunita; Sasmal, Buddhadev] Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Midnapore, West Bengal, India.
   [Ray, Swarnajit] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
   [Rai, Rebika] Sikkim Univ, Dept Comp Applicat, Sikkim, India.
   [Garai, Arpan] Indian Inst Technol, Dept Comp Sci & Engn, Delhi, India.
C3 Midnapore College; Maulana Abul Kalam Azad University of Technology;
   Sikkim University; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Delhi
RP Dhal, KG (corresponding author), Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Midnapore, West Bengal, India.
EM krishnagopal.dhal@midnaporecollege.ac.in;
   arunita.das@midnaporecollege.ac.in;
   buddhadev.sasmal@midnaporecollege.ac.in; swarnajit32@gmail.com;
   rrai@cus.ac.in; arpangarai@gmail.com
RI Dhal, Krishna Gopal/JCD-8250-2023; Sasmal, Buddhadev/ABH-2481-2021
OI Sasmal, Buddhadev/0009-0009-4244-9897; dhal, krishna
   gopal/0000-0002-6748-0569
FU RUSA 2.0 component 8, Govt. of India, New Delhi
FX This work has been partially supported with the grant received in a
   research project under RUSA 2.0 component 8, Govt. of India, New Delhi.
CR Abdellahoum H, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114063
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Alruwaili M, 2020, EGYPT INFORM J, V21, P51, DOI 10.1016/j.eij.2019.10.005
   Anter AM, 2019, ARTIF INTELL MED, V97, P105, DOI 10.1016/j.artmed.2018.11.007
   Anter AM, 2019, EXPERT SYST APPL, V118, P340, DOI 10.1016/j.eswa.2018.10.009
   Bai XZ, 2016, IEEE T CYBERNETICS, V46, P3259, DOI 10.1109/TCYB.2015.2501848
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bong CW, 2012, IET IMAGE PROCESS, V6, P1, DOI 10.1049/iet-ipr.2010.0122
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Chatzis SP, 2008, IEEE T FUZZY SYST, V16, P1351, DOI 10.1109/TFUZZ.2008.2005008
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   COLORNI A, 1992, FROM ANIM ANIMAT, P134
   Das A, 2022, NEURAL COMPUT APPL, V34, P4531, DOI 10.1007/s00521-021-06610-6
   Das S., 2006, IEEE CONGRES EVOLUT, V2006, P2026, DOI [10.1109/CEC.2006.1688556, DOI 10.1109/CEC.2006.1688556]
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Devi SS, 2020, INT J INTERACT MULTI, V6, P26, DOI 10.9781/ijimai.2020.01.001
   Dhal KG, 2022, ARCH COMPUT METHOD E, V29, P1643, DOI 10.1007/s11831-021-09629-z
   Dhal KG, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106814
   Dhal KG, 2020, MULTIMED TOOLS APPL, V79, P12227, DOI 10.1007/s11042-019-08417-z
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, IJST-T ELECTR ENG, V43, P645, DOI 10.1007/s40998-019-00175-w
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Feng CL, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107347
   Ganesan P, 2020, INT CONF ADVAN COMPU, P357, DOI [10.1109/ICACCS48705.2020.9074333, 10.1109/icaccs48705.2020.9074333]
   García-Lamont F, 2020, PATTERN ANAL APPL, V23, P59, DOI 10.1007/s10044-018-0729-9
   GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2565, DOI 10.1109/TGRS.2013.2263282
   Ghosal D, 2022, PATTERN RECOGN IMAGE, V32, P129, DOI 10.1134/S1054661821040118
   Ghosh P, 2018, J VIS COMMUN IMAGE R, V54, P63, DOI 10.1016/j.jvcir.2018.04.007
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gueorguieva N, 2017, PROCEDIA COMPUT SCI, V114, P224, DOI 10.1016/j.procs.2017.09.064
   Guo FF, 2016, IET IMAGE PROCESS, V10, P272, DOI 10.1049/iet-ipr.2015.0236
   Kahali S, 2019, SOFT COMPUT, V23, P10407, DOI 10.1007/s00500-018-3594-y
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaufman L., 2009, FINDING GROUPS DATA
   Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar SN, 2019, J DIGIT IMAGING, V32, P322, DOI 10.1007/s10278-018-0149-9
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Lei T, 2020, IEEE T FUZZY SYST, V28, P2078, DOI 10.1109/TFUZZ.2019.2930030
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lin PL, 2014, PATTERN RECOGN, V47, P2042, DOI 10.1016/j.patcog.2013.11.031
   Liu GY, 2015, IEEE T IMAGE PROCESS, V24, P3990, DOI 10.1109/TIP.2015.2456505
   Liu GY, 2015, IEEE GEOSCI REMOTE S, V12, P1770, DOI 10.1109/LGRS.2015.2425225
   Liu HC, 2007, P 10 JOINT C 12 INT, P1398, DOI 10.1142/9789812709677_0199
   Liu HC, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P422
   Liu JJ, 2012, INT C WIREL COMM NET
   Manor LZ., 2005, Proceedings of the Advances in Neural Information Processing Systems, V27, P1601
   May V, 2016, IEEE T IMAGE PROCESS, V25, P1340, DOI 10.1109/TIP.2016.2518805
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Nguyen MP, 2017, IEEE T IMAGE PROCESS, V26, P1637, DOI 10.1109/TIP.2017.2658941
   Noordam JC, 2002, CHEMOMETR INTELL LAB, V64, P65, DOI 10.1016/S0169-7439(02)00052-7
   Özdemir D, 2002, PATTERN RECOGN, V35, P1785, DOI 10.1016/S0031-3203(01)00170-4
   Pakhira MK, 2015, INT J ENG-IRAN, V28, P35, DOI 10.5829/idosi.ije.2015.28.01a.05
   Price K.V, 1999, New Ideas in Optimization, P79
   Rai R, 2022, EVOL SYST-GER, V13, P889, DOI 10.1007/s12530-022-09425-5
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Rundo L, 2018, SMART INNOV SYST TEC, V69, P23, DOI 10.1007/978-3-319-56904-8_3
   Santos L, 2018, IEEE IJCNN
   Saranathan AM, 2016, IEEE T GEOSCI REMOTE, V54, P1419, DOI 10.1109/TGRS.2015.2480863
   Singh Chandan, 2021, Expert Systems with Applications, V164, DOI 10.1016/j.eswa.2020.113989
   Singh C, 2019, EXPERT SYST APPL, V118, P625, DOI 10.1016/j.eswa.2018.10.023
   Singh TI., 2019, SMART COMPUTATIONAL
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Tongbram S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02762-w
   Tseng LY, 2001, PATTERN RECOGN, V34, P415, DOI 10.1016/S0031-3203(00)00005-4
   Wan L, 2018, IEEE J-STARS, V11, P896, DOI 10.1109/JSTARS.2018.2792841
   Wang C., 2020, ARXIV
   Wang GT, 2016, IEEE T KNOWL DATA EN, V28, P1971, DOI 10.1109/TKDE.2016.2535209
   Wang QS, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106318
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wong CC, 2001, PATTERN RECOGN, V34, P425, DOI 10.1016/S0031-3203(00)00002-9
   Wu C, 2019, IEEE IMAGE PROC, P1455, DOI [10.1109/icip.2019.8803039, 10.1109/ICIP.2019.8803039]
   Yang MS, 2017, PATTERN RECOGN, V71, P45, DOI 10.1016/j.patcog.2017.05.017
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   YANG XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI [DOI 10.1504/IJBIC.2010.032124, 10.1504/IJBIC.2010.032124]
   Zhang H, 2017, IEEE T GEOSCI REMOTE, V55, P5057, DOI 10.1109/TGRS.2017.2702061
   Zhang H, 2014, IET IMAGE PROCESS, V8, P571, DOI 10.1049/iet-ipr.2013.0178
   Zhang MX, 2019, SOFT COMPUT, V23, P2033, DOI 10.1007/s00500-017-2916-9
   Zhang XJ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107767
   Zhao QH, 2017, PATTERN RECOGN LETT, V85, P49, DOI 10.1016/j.patrec.2016.11.019
   Zhao XM, 2015, DIGIT SIGNAL PROCESS, V43, P8, DOI 10.1016/j.dsp.2015.04.009
   Zhao ZX, 2014, IET IMAGE PROCESS, V8, P150, DOI 10.1049/iet-ipr.2011.0128
   Zhi H, 2020, J INTELL FUZZY SYST, V38, P3647, DOI 10.3233/JIFS-179587
NR 100
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27935
EP 27971
DI 10.1007/s11042-023-16569-2
EA AUG 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700004
DA 2024-07-18
ER

PT J
AU Rout, S
   Mohapatra, RK
AF Rout, Sonali
   Mohapatra, Ramesh Kumar
TI Secure video steganographic model using framelet transform and elliptic
   curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Stego key; Framelet transform; Elliptic curve
   cryptography
AB Information security holds a quintessential role in the era of digital communication. Nowadays, social media has become the new platform to share a massive length of digitally transmitted multimedia files without being suspected. Hence, it can hide data, enabling the security providers to add an extra layer to the existing traditional framework. Videos are the most shared digital content and carry the maximum payload, which is best suitable for steganography. This paper suggests a secured stego key-based video steganographic method that uses Framelet Transform to embed secret data in the cover media. Here the main focus is to reduce the computational cost by introducing the stego key, which reserves the information regarding the location of the secret data. For an additional layer of security, the stego key is encrypted using Elliptic Curve Cryptography (ECC) based encryption scheme. The robustness of the scheme is enhanced by introducing a large prime number for the stego key sharing using the Elliptic Curve Diffie Hellman Key Exchange Protocol. Performance measures, including PSNR, MSE, SSIM, and BER, are compared with the traditional state-of-the-art methods, which produce significant results without tampering with the visual quality and perceptual characteristics of the stego video.
C1 [Rout, Sonali; Mohapatra, Ramesh Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Orissa, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Rout, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Orissa, India.
EM sonalirout105@gmail.com
FU Ministry of Electronics and Information Technology (MeitY), Government
   of India
FX This work has been accomplished under the project "Information Security
   Education Awareness (ISEA)" Phase-II funded by the Ministry of
   Electronics and Information Technology (MeitY), Government of India
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Balu S, 2019, CLUSTER COMPUT, V22, pS4057, DOI 10.1007/s10586-018-2639-4
   Bhatnagar G, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691311004444
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Cao MY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185242
   Chang CC, 2006, PATTERN RECOGN, V39, P1155, DOI 10.1016/j.patcog.2005.12.011
   Chen Y, 2021, IEEE T DEPEND SECURE
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Evsutin O, 2021, MULTIMED TOOLS APPL, V80, P11217, DOI 10.1007/s11042-020-10316-7
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Fateh M, 2021, SECUR COMMUN NETW, V2021
   Forouzan B.A., 2007, Cryptography and Network Security
   Ghamsarian N, 2021, MULTIMED TOOLS APPL, V80, P9137, DOI 10.1007/s11042-020-10001-9
   Huang ZH, 2018, NEUROCOMPUTING, V314, P154, DOI 10.1016/j.neucom.2018.06.063
   Jalali A, 2020, MULTIMED TOOLS APPL, V79, P1821, DOI 10.1007/s11042-019-08233-5
   Jangid S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P589, DOI 10.1109/ICCONS.2017.8250530
   Jiao RH, 2015, OPTIK, V126, P3197, DOI 10.1016/j.ijleo.2015.07.084
   Kessler GaryC., 2016, An Overview of Cryptography
   Khedmati Y, 2020, INFORM SCIENCES, V512, P855, DOI 10.1016/j.ins.2019.10.028
   Kolakalur Anush, 2016, International Journal of Engineering and Technology, V8, P165, DOI 10.7763/IJET.2016.V8.878
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Martinez Victor Gayoso, 2010, A survey of the elliptic curve integrated encryption scheme
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mittal M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050822
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P14495, DOI 10.1007/s11042-020-10424-4
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Pan N, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00512-8
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P5881, DOI 10.1007/s11042-019-08525-w
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Selesnick IW, 2004, APPL COMPUT HARMON A, V17, P211, DOI 10.1016/j.acha.2004.05.003
   Su Weijie, 2020, ICLR
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Suresh M, 2020, J KING SAUD UNIV-COM
   Suresh M, 2020, MULTIMED TOOLS APPL, V79, P27023, DOI 10.1007/s11042-020-09330-6
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Thakur A, 2015, INT J COMPUTER APPL, V123
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Weber A. G., 1997, USC-SIPI Report, V315
   Xiao MY, 2015, PROC SPIE, V9811, DOI 10.1117/12.2205279
   Yadav P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P436
   Yadav SK, 2018, 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT CIRCUITS AND SYSTEMS (ICICS 2018), P258, DOI 10.1109/ICICS.2018.00060
   Yao YZ, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102986
   Zhang CE, 2008, IEEE T INF FOREN SEC, V3, P611, DOI 10.1109/TIFS.2008.2004288
NR 52
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25191
EP 25212
DI 10.1007/s11042-023-16531-2
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001063782500001
DA 2024-07-18
ER

PT J
AU Asadianfam, S
   Talebi, MJ
   Nikougoftar, E
AF Asadianfam, Shiva
   Talebi, Mohammad Javad
   Nikougoftar, Elaheh
TI ECG-based authentication systems: a comprehensive and systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE ECG; Authentication; Biometric; Feature selection; Systematic review
ID CONVOLUTION NEURAL-NETWORK; BIOMETRIC AUTHENTICATION; HUMAN
   IDENTIFICATION; IDENTITY VERIFICATION; ELECTROCARDIOGRAM; RECOGNITION;
   CLASSIFICATION; EFFICIENT; SIGNALS; ROBUST
AB In recent years, security systems based on biometric features have become a promising solution to identify humans, and it is preferred over traditional methods working based on what we know. With the rapid growth of such identification methods, ECG authentication approaches as an emerging biometric recognition scheme is developed. It can be efficiently used to identify individuals, specifically for continuous authentication to allow particular access privileges for users. In comparison with other biometric features even in abnormal conditions, it gives more valid and better results. Although there are several works that have offered some techniques in order to overcome the various issues affecting the ECG authentication schemes' outputs, there are still many concerns to be considered. How can we see, there are not many studies that deal with all aspects of ECG authentication techniques? The objective this paper is to evaluate some surveys related to ECG authentication domain since 2010. We have done a comprehensive taxonomy including existing methods and techniques in ECG based authentication domain. With the aim of providing a classical taxonomy form, this study presents a Systematic Literature Review (SLR) on ECG-based authentication schemes to introduce the state-of-the-art approaches in this domain. We have done the selection of journals and conference proceedings using the standard systematic literature review methodology in order to find and assess the studies related to ECG authentication. Finally, the paper is concluded with a summary of the content of the paper, and open issues and future research challenges are discussed.
C1 [Asadianfam, Shiva] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
   [Asadianfam, Shiva; Talebi, Mohammad Javad] Islamic Azad Univ, Qom Branch, Dept Comp Engn, Qom, Iran.
   [Nikougoftar, Elaheh] Taali Inst Higher Educ, Dept Comp & Elect, Qom, Iran.
C3 Islamic Azad University
RP Asadianfam, S (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.; Asadianfam, S (corresponding author), Islamic Azad Univ, Qom Branch, Dept Comp Engn, Qom, Iran.
EM sh_asadianfam@yahoo.com; javad.talebi.55@gmail.com;
   e.nikougoftar@gmail.com
RI asadianfam, shiva/ABF-1231-2021
OI asadianfam, shiva/0000-0002-0062-7079
CR Abd El-Rahiem B, 2022, MULTIMEDIA SYST, V28, P1325, DOI 10.1007/s00530-021-00810-9
   Abo-Zahhad M, 2014, SIGNAL IMAGE VIDEO P, V8, P739, DOI 10.1007/s11760-013-0593-4
   Abo-Zahhad M, 2015, IET BIOMETRICS, V4, P179, DOI 10.1049/iet-bmt.2014.0040
   Adeoye O. S., 2010, Int. J. Comput. Appl., V9, P1
   Afsaneh S, 2021, IET COMMUN, V15, P2390, DOI 10.1049/cmu2.12278
   Agrafioti F, 2010, INT CONF ACOUST SPEE, P1734, DOI 10.1109/ICASSP.2010.5495461
   Ahuja P, REV ECG BASED HUMAN
   Al Alkeem E, 2021, AD HOC NETW, V121, DOI 10.1016/j.adhoc.2021.102581
   Albuquerque Silas L., 2021, Engineering Research Express, V3, DOI 10.1088/2631-8695/abffa6
   AlDuwaile DA, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060733
   Alotaiby TN, 2019, J SENSORS, V2019
   Alsuhibany SA, 2021, IET INFORM SECUR, V15, P191, DOI 10.1049/ise2.12018
   Altan G, 2019, COMPUT METH PROG BIO, V170, P81, DOI 10.1016/j.cmpb.2019.01.010
   Amiruddin AB, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, CONTROL, NETWORKING, ELECTRONICS AND EMBEDDED SYSTEMS ENGINEERING (ICCNEEE), P479, DOI 10.1109/ICCNEEE.2015.7381417
   [Anonymous], 2011, Online J Electron Electr Eng (OJEEE)
   [Anonymous], 2010, ENG TECHNOL
   Araújo T, 2015, ADV INTELL SYST, V318, P301, DOI 10.1007/978-3-319-12610-4_19
   Arteaga-Falconi JS, 2018, SUSTAIN CITIES SOC, V40, P274, DOI 10.1016/j.scs.2017.12.023
   Arteaga-Falconi JS, 2016, IEEE T INSTRUM MEAS, V65, P591, DOI 10.1109/TIM.2015.2503863
   Assadi I, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P248, DOI 10.1109/ICSIPA.2015.7412198
   Atilla DC, 2021, PRODUCING SECURE MUL
   Baaqeel H., 2021, SPOOFING DETECTION A
   Bahaj AbuBakr S., 2017, 2017 10th Jordanian International Electrical and Electronics Engineering Conference (JIEEEC)
   Bassiouni M, 2018, SIGNAL IMAGE VIDEO P, V12, P941, DOI 10.1007/s11760-018-1237-5
   Beck N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), P207, DOI [10.1109/PerComWorkshops51409.2021.9430964, 10.1109/PERCOMWORKSHOPS51409.2021.9430964]
   Belgacem N., 2012, Int. J. Comput. Sci. Eng, V4, P974
   Belgacem N., 2012, International Journal on Cryptography and Information Security, V2, P1, DOI [DOI 10.5121/IJCIS.2012.2201, 10.5121/ijcis .2012.2201]
   Belgacem Noureddine, 2015, Journal of Medical Engineering & Technology, V39, P226, DOI 10.3109/03091902.2015.1021429
   Belo D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154078
   Benouis M, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102226
   Berkaya SK, 2018, BIOMED SIGNAL PROCES, V43, P216, DOI 10.1016/j.bspc.2018.03.003
   Bernal-Romero JC., 2021, IEEE MEX HUM TECHN C, V2021, P19
   Bhattacharyya D, 2009, INT J GRID DISTRIB, V2, P13
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Boumbarov O., 2011, Face and ECG Based Multi-Modal Biometric Authentication, Advanced Biometric Technologies
   Boumbarov O, 2009, INT WORKSH INT DATA, P446, DOI 10.1109/IDAACS.2009.5342942
   Bui M-H, 2021, ARXIV
   Butt MM, 2015, INT C COMP COMM CONT, P264, DOI DOI 10.1109/I4CT.2015.7219578
   Camara C, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0323-2
   Carreiras C, 2016, LECT NOTES ELECTR EN, V370, P111, DOI 10.1007/978-3-319-26453-0_7
   Chahal R., 2017, INT J ENG APPL SCI T
   Chamatidis I, 2017, INT CARN CONF SECU
   Chan ADC, 2008, IEEE T INSTRUM MEAS, V57, P248, DOI 10.1109/TIM.2007.909996
   Chantaf S, 2010, INT J BIOMETRICS, V2, P236, DOI 10.1504/IJBM.2010.033388
   Chatterjee S, 2020, IET SIGNAL PROCESS, V14, P569, DOI 10.1049/iet-spr.2020.0104
   Chauhan S, 2010, PROCEDIA COMPUT SCI, V2, P213, DOI 10.1016/j.procs.2010.11.027
   Chen HL, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2021.107659
   Chen SW, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103493
   ChenXing Zhao, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P150, DOI 10.1109/BTAS.2012.6374570
   Chenyu Huang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191744
   Cherifi F, 2021, MULTIMED TOOLS APPL, V80, P14807, DOI 10.1007/s11042-021-10524-9
   Chun SY, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P656, DOI 10.1109/TSP.2016.7760964
   Ciocoiu IB, 2017, IET BIOMETRICS, V6, P495, DOI 10.1049/iet-bmt.2016.0177
   Coutinho David Pereira, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3858, DOI 10.1109/ICPR.2010.940
   Coutinho DP, 2013, IET BIOMETRICS, V2, P64, DOI 10.1049/iet-bmt.2012.0055
   Coutinho DP, 2011, BIOSIGNALS 2011, P354
   Coutinho DP, 2010, PATTERN RECOGNITION IN INFORMATION SYSTEMS, P15
   Daas S, 2020, IET IMAGE PROCESS, V14, P3859, DOI 10.1049/iet-ipr.2020.0491
   Dahia G, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1365
   de Lannoy G, 2011, COMM COM INF SC, V127, P212
   Diab M.O., 2020, HIDDEN BIOMETRICS BI, P17, DOI DOI 10.1007/978-981-13-0956-4_2
   Dvorak M, 2021, IET BIOMETRICS, V10, P315, DOI 10.1049/bme2.12024
   Ebrahimi Z., 2020, Expert Syst. Appl.: X, V7, P100033, DOI [10.1016/j.eswax.2020.100033, DOI 10.1016/J.ESWAX.2020.100033]
   El-Rahiem A, 2022, MULTIFUSION IOT AUTH, P53
   Eldesouky S, 2022, SECUR PRIVACY, Ve198
   Elshahed MA., 2020, INT J ELECTR COMPUT, V10, P3007, DOI DOI 10.11591/IJECE.V10I3.PP3007-3013
   Enamamu TS, 2017, INT CONF INTERNET, P283, DOI 10.23919/ICITST.2017.8356401
   Fairhurst M, 2017, IET BIOMETRICS, V6, P369, DOI 10.1049/iet-bmt.2016.0169
   Fang SC, 2013, PATTERN RECOGN LETT, V34, P595, DOI 10.1016/j.patrec.2012.11.005
   Fang SC, 2009, PATTERN RECOGN, V42, P1824, DOI 10.1016/j.patcog.2008.11.020
   Fatemian SZ, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P323
   Flores N, 2018, J ELECTROCARDIOL, V51, P1095, DOI 10.1016/j.jelectrocard.2018.09.012
   Fratini A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0072-y
   Fratini A, 2013, IEEE INT SYM MED MEA, P107, DOI 10.1109/MeMeA.2013.6549716
   Fratini A, 2014, COMPUT METH PROG BIO, V113, P314, DOI 10.1016/j.cmpb.2013.10.009
   Gang Zheng, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P503, DOI 10.1007/978-3-319-69923-3_54
   Gao JX, 2011, INT CONF ACOUST SPEE, P1916
   Gao YL, 2018, IEEE INT CONF BIG DA, P1272, DOI 10.1109/BigData.2018.8622111
   Garg N, 2019, INT J INTEGR ENG, V11, P184
   Gargiulo F, 2015, COMPUT METH PROG BIO, V121, P127, DOI 10.1016/j.cmpb.2015.05.012
   Ghofrani Nahid., 2010, 2010 17th Iranian Conference of Biomedical Engineering, ICBME 2010 - Proceedings November, P3, DOI [DOI 10.1109/ICBME.2010.5704918, 10.1109/ICBME.2010.5704918]
   Goshvarpour A, 2019, EXPERT SYST APPL, V127, P25, DOI 10.1016/j.eswa.2019.02.038
   Guglielmi AV, 2021, ARXIV
   Guven G, 2022, DIGIT SIGNAL PROCESS, V121, DOI 10.1016/j.dsp.2021.103306
   Hadiyoso Sugondo, 2019, Journal of Physics: Conference Series, V1367, DOI 10.1088/1742-6596/1367/1/012014
   Hadiyoso S, 2019, INT J ADV COMPUT SC, V10, P276
   HAMDI T, 2014, IM PROC APPL SYST C, P1
   Hammad M, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.004
   Hammad M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12547
   Hammad M, 2019, FUTURE GENER COMP SY, V101, P180, DOI 10.1016/j.future.2019.06.008
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hanilci A., 2019, J INNOV SCI ENG, V3, P11, DOI [10.38088/jise.559236, DOI 10.38088/JISE.559236]
   Hegde C, 2010, COMM COM INF SC, V122, P197
   Hejazi M, 2016, DIGIT SIGNAL PROCESS, V52, P72, DOI 10.1016/j.dsp.2016.02.008
   Hinatsu S, 2021, ADV BIOMED ENG, V10, P101, DOI 10.14326/abe.10.101
   Hoekema R, 2001, IEEE T BIO-MED ENG, V48, P551, DOI 10.1109/10.918594
   Hong SD, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103801
   Hosseinzadeh M, 2021, ARTIF INTELL REV, V54, P667, DOI 10.1007/s10462-020-09863-0
   Hou LS, 2011, 2011 IEEE REGION 10 CONFERENCE TENCON 2011, P1159, DOI 10.1109/TENCON.2011.6129294
   Huang DY., 2021, SECURABLE NETWORKED
   Huang JS, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02110-y
   Huang P, 2019, IEEE INTERNET THINGS, V6, P9200, DOI 10.1109/JIOT.2019.2929087
   Huang YW, 2021, J COMPUT SCI TECH-CH, V36, P617, DOI 10.1007/s11390-021-1033-5
   Huang YW, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108376
   Hwang HB, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21216966
   Ibrahim AE., 2020, INT J ADV COMPUT RES, V10, P89, DOI [10.19101/IJACR.2019.940129, DOI 10.19101/IJACR.2019.940129]
   Ibtehaz N, 2021, ARXIV
   Ihsanto E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093304
   Ingale M, 2020, IEEE ACCESS, V8, P117853, DOI 10.1109/ACCESS.2020.3004464
   Irvine JM, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/243215
   Israel SA, 2005, PATTERN RECOGN, V38, P133, DOI 10.1016/j.patcog.2004.05.014
   Ivanciu L., 2018, ACTA TECHNICA NAPOCE, V59, P1
   Jain Kusum Lata, 2022, Data Engineering for Smart Systems: Proceedings of SSIC 2021. Lecture Notes in Networks and Systems (238), P299, DOI 10.1007/978-981-16-2641-8_29
   Jang D, 2010, PROC SPIE, V7667, DOI 10.1117/12.850619
   Jayapranata WS., 2021, JURNAL INFRA, V9, P141
   Jianchu Yao, 2010, International Journal of Computer and Network Security, V2, P15
   Jianchu Yao, 2008, 2008 5th International Summer School and Symposium on Medical Devices and Biosensors, P297, DOI 10.1109/ISSMDBS.2008.4575078
   Jomaa RM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072085
   Karegar FP, 2017, 2017 2ND CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC), P66, DOI 10.1109/CSIEC.2017.7940172
   Karimian N., 2016, P 11 IEEE ACM IFIP I, P1
   Kaveh A., 2013, IEEE WORSH BIOM MEAS, V2013, P17
   Keshishzadeh S, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P118, DOI 10.1109/ICCKE.2015.7365870
   Keshishzadeh S, 2014, IRAN CONF ELECTR ENG, P1873, DOI 10.1109/IranianCEE.2014.6999845
   Kim BH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113069
   Kim HJ, 2018, IOP CONF SER-MAT SCI, V317, DOI 10.1088/1757-899X/317/1/012030
   Kim J, 2019, IET BIOMETRICS, V8, P401, DOI 10.1049/iet-bmt.2018.5183
   Kim J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051568
   Kim KS, 2005, P ANN INT IEEE EMBS, P1114
   Kim SK, 2019, IEEE ACCESS, V7, P94858, DOI 10.1109/ACCESS.2019.2927079
   Krak I, 2020, 15TH INTERNATIONAL CONFERENCE ON ADVANCED TRENDS IN RADIOELECTRONICS, TELECOMMUNICATIONS AND COMPUTER ENGINEERING (TCSET - 2020), P930, DOI 10.1109/TCSET49122.2020.235573
   Krasteva V, 2017, J ELECTROCARDIOL, V50, P847, DOI 10.1016/j.jelectrocard.2017.08.021
   Kyoso M, 2001, P ANN INT IEEE EMBS, V23, P3721, DOI 10.1109/IEMBS.2001.1019645
   Labati RD, 2019, PATTERN RECOGN LETT, V126, P78, DOI 10.1016/j.patrec.2018.03.028
   Lee J, 2023, BIOMETRICS, V79, P2458, DOI 10.1111/biom.13738
   Lei Wang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264950
   Li X, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3120370
   Lin CH, 2022, IET SIGNAL PROCESS, V16, P267, DOI 10.1049/sil2.12089
   Lin SL, 2014, IET BIOMETRICS, V3, P257, DOI 10.1049/iet-bmt.2013.0014
   Liu J, 2017, IEEE INT CONF SENS, P1
   Liu SQ, 2022, DIGIT SIGNAL PROCESS, V125, DOI 10.1016/j.dsp.2021.103120
   Lourenço A, 2011, BIOSIGNALS 2011, P348
   Luz EJD, 2016, COMPUT METH PROG BIO, V127, P144, DOI 10.1016/j.cmpb.2015.12.008
   Lynn HM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031125
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Marques Francisco, 2015, BIOSIGNALS 2015. 8th International Conference on Bio-Inspired Systems and Signal Processing. Proceedings, P350
   Matos AC, 2014, PROC TECH, V17, P265, DOI 10.1016/j.protcy.2014.10.236
   Matta R., 2011, 2011 24 CANADIAN C E
   Mazumdar J.B., 2018, International Journal of Advanced Research in Computer Science, V9
   Merone M, 2017, EXPERT SYST APPL, V67, P189, DOI 10.1016/j.eswa.2016.09.030
   Miao YM, 2018, IEEE ACCESS, V6, P4759, DOI 10.1109/ACCESS.2017.2771220
   Ming Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3769, DOI 10.1109/ICASSP.2014.6854306
   Ming Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1326, DOI 10.1109/ICPR.2010.330
   Modu F, 2021, IET BIOMETRICS, V10, P625, DOI 10.1049/bme2.12028
   Mohebbanaaz, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103221
   Moorthy R., 2020, P 2 C CONVERSATIONAL, P1, DOI [DOI 10.1145/3405755.3406150, 10.1145/3405755.3406150]
   Morampudi MK, 2022, IET BIOMETRICS, V11, P35, DOI 10.1049/bme2.12042
   Mostefai L, 2021, ENHANCED LOCAL PATTE
   Muratyan A, 2021, ARXIV
   Narwal B, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101883
   Nawal M., 2014, INT J EMERG ENG RES, V2, P178
   Neehal N., 2019, PROC INT C ELECT COM, P1
   Nor R.M., 2016, Recent Advances in Information and Communication Technology 2016, P139, DOI 10.1007/ 978-3-319- 40415-8_14
   Odinaka I, 2012, IEEE T INF FOREN SEC, V7, P1812, DOI 10.1109/TIFS.2012.2215324
   Oliveira C, 2009, BIOSIGNALS 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P163
   Page Adam, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348372
   Pal A., 2018, INT C MATH COMPUTING, P61, DOI DOI 10.1007/978-981-13-0023-37
   Pal S, 2012, MEASUREMENT, V45, P1927, DOI 10.1016/j.measurement.2012.03.005
   Palaniappan R, 2004, INT CO SIG PROC COMM, P569, DOI 10.1109/SPCOM.2004.1458524
   Panzino A, 2022, IET BIOMETRICS, V11, P63, DOI 10.1049/bme2.12050
   Patro KK, 2017, J ENG SCI TECHNOLOGY, V10
   Peris-Lopez P, 2018, FUTURE GENER COMP SY, V81, P67, DOI 10.1016/j.future.2017.11.037
   Pinto JR, 2018, IEEE ACCESS, V6, P34746, DOI 10.1109/ACCESS.2018.2849870
   Pinto JR, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102228
   Pioner MS, 2021, 2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2021), P974
   Plataniotis Konstantinos N., 2006, Biometrics Symposium: Special Session on Research at the Biometric Consortium Conference, P1
   Prakash AJ, 2023, INFORMATION, V14, DOI 10.3390/info14020065
   Progonov D, USER AUTHENTICATION
   Raheja N, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103481
   Ramli DA, 2016, PROCEDIA COMPUT SCI, V96, P314, DOI 10.1016/j.procs.2016.08.143
   Regouid M, 2018, INT S MOD IMPL COMPL, P168, DOI [DOI 10.1007/978-3-030-05481-6_13, 10.1007/ 978-3-030-05481-6_13]
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Rehman A, 2017, INT CONF SOFTW ENG, P91, DOI 10.1109/ICSESS.2017.8342871
   Rehman ZU, 2021, IEEE ACCESS, V9, P133809, DOI 10.1109/ACCESS.2021.3115706
   Repcik T, 2020, COMPUT CARDIOL CONF, DOI 10.22489/CinC.2020.321
   Rezgui D, 2016, IEEJ T ELECTR ELECTR, V11, pS94, DOI 10.1002/tee.22241
   Ryu R, 2021, IEEE ACCESS
   Safie S. I., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P16, DOI 10.1109/ICSIPA.2011.6144124
   Safie S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P165, DOI 10.1109/ICSIPA.2015.7412183
   Safie S, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P156, DOI 10.1109/ICE2T.2014.7006238
   Safie SI, 2011, EUR SIGNAL PR CONF, P2274
   Safie SI, 2011, IEEE T INF FOREN SEC, V6, P1315, DOI 10.1109/TIFS.2011.2162408
   Safie SI., 2011, SYST SIGN IM PROC IW, P1
   Saini R., 2014, International Journal of Advances in Science and Technology, V2, P24
   Sakr AS, 2022, INFORM SCIENCES, V585, P127, DOI 10.1016/j.ins.2021.11.066
   Sansone M, 2013, J HEALTHC ENG, V4, P465, DOI 10.1260/2040-2295.4.4.465
   Santos A, 2018, PROCEEDINGS OF THE 10TH LATIN AMERICAN NETWORKING CONFERENCE (LANC 2018), P119, DOI 10.1145/3277103.3277138
   Sarkisyan Allen., 2015, 2015 IEEE international workshop on information forensics and security (WIFS), P1, DOI DOI 10.1109/WIFS.2015.7368569
   Serhani MA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061796
   Shao HK, 2021, IET BIOMETRICS, V10, P246, DOI 10.1049/bme2.12014
   Sharma M., 2014, INT J COMPUTER SCI E, V5, P743
   Shdefat A.Y, 2021, Indonesian Journal of Electrical Engineering and Informatics (IJEEI), V9, P394
   Shdefat A.Y., 2018, Int. J. Electr. Comput. Eng. (IJECE), V8, P658, DOI DOI 10.11591/IJECE.V8I2.PP658-665
   Shen T.-W. D., 2010, J ENG COMPUTER INNOV, V2, P12
   Shen TW, 2002, P ANN INT IEEE EMBS, P62
   Shukla S, 2021, IET INFORM SECUR, V15, P256, DOI 10.1049/ise2.12024
   Sidek KA, 2014, J NETW COMPUT APPL, V44, P83, DOI 10.1016/j.jnca.2014.04.008
   Singh YN, 2011, EVALUATION ELECTROCA
   Singh YN, 2012, PATTERN RECOGN LETT, V33, P1932, DOI 10.1016/j.patrec.2012.03.010
   Singh YN, 2011, SOFT COMPUT, V15, P449, DOI 10.1007/s00500-009-0525-y
   Sprager S., 2017, 40 INT CONV INF COMM, V2017, P264
   Srivastva R, 2021, INFORM SCIENCES, V558, P208, DOI 10.1016/j.ins.2021.01.001
   Srivastva R, 2019, IET BIOMETRICS, V8, P295, DOI 10.1049/iet-bmt.2018.5093
   Sufi F, 2010, HANDBOOK OF INFORMATION AND COMMUNICATION SECURITY, P309, DOI 10.1007/978-3-642-04117-4_17
   Sufi F, 2010, SECUR COMMUN NETW, V3, P303, DOI 10.1002/sec.76
   Sun L, 2023, IEEE J BIOMED HEALTH, V27, P866, DOI 10.1109/JBHI.2022.3171402
   Tantawi M, 2014, COMM COM INF SC, V488, P199
   Tantawi M., 2013, Proc. 7th Eur. Comput. Conf.(ECC), P100
   Tantawi MM, 2013, J INTELL INF SYST, V40, P17, DOI 10.1007/s10844-012-0214-7
   Tarannum A, 2020, IEEE SENS J, V20, P15014, DOI 10.1109/JSEN.2020.3012536
   Tarek M, 2021, IET BIOMETRICS, V10, P654, DOI 10.1049/bme2.12034
   THENTU S, 2021, 2021 IEEE INT C CONS, P1
   Tse KW, 2022, IET BIOMETRICS, V11, P157, DOI 10.1049/bme2.12065
   Uwaechia AN, 2021, IEEE ACCESS, V9, P97760, DOI 10.1109/ACCESS.2021.3095248
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Vats S, 2016, INT J ADV RES COMPUT, V7
   Vivaracho-Pascual C, 2021, IET BIOMETRICS, V10, P127, DOI 10.1049/bme2.12011
   Wan T, 2021, PEER PEER NETW APPL, V14, P3473, DOI 10.1007/s12083-021-01190-7
   Wang WQ, 2016, AER ADV ENG RES, V59, P497
   Ye C., 2010, SIGNALS 2010 4 IEEE, P1
   Ying BD, 2021, IEEE OPEN J COMP SOC, V2, P130, DOI 10.1109/OJCS.2021.3055365
   Zaghouani EK, 2017, INT WIREL COMMUN, P1777, DOI 10.1109/IWCMC.2017.7986553
   Zemzemi M, 2018, INT MULTICONF SYST, P55, DOI 10.1109/SSD.2018.8570470
   Zhang L, 2016, P 1 ACM WORKSH PRIV, P21
   Zhang YF, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102689
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhang YM, 2015, IET BIOMETRICS, V4, P162, DOI 10.1049/iet-bmt.2014.0044
   Zhang Y, 2019, PATTERN RECOGN LETT, V125, P668, DOI 10.1016/j.patrec.2019.07.009
   Zhang Y, 2016, INT CONF SOFTW ENG, P300
   Zhang Z., 2006, Proc. IEEE Region 10 Conf, P1, DOI DOI 10.1109/RAMECH.2006.252704
   Zhang ZY, 2012, IEEE T INF TECHNOL B, V16, P1070, DOI 10.1109/TITB.2012.2206115
   Zhao ZD, 2018, COMPUT BIOL MED, V102, P168, DOI 10.1016/j.compbiomed.2018.09.027
   Zokaee S., 2012, J ELECTR COMPUT ENG, V2, P261
NR 244
TC 0
Z9 0
U1 12
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27647
EP 27701
DI 10.1007/s11042-023-16506-3
EA AUG 2023
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100003
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Xue, BX
   Wang, H
   Zhao, JW
AF Zhou, Zhenghua
   Xue, Boxiang
   Wang, Hai
   Zhao, Jianwei
TI Bidirectional Multi-scale Deformable Attention for Video
   Super-Resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video super-resolution; Multi-scale deformable convolution; Multi-scale
   attention; Bidirectional propagation
AB Video super-resolution aims to generate a high-resolution video frame from its low-resolution video sequences. Video super-resolution is still a challenging problem due to performing the temporal frame alignment and spatial feature fusion during the process of spatial-temporal modeling. Existing deep learning based methods have limitations in handling accurate alignment and effective fusion of frames with multi-scale feature information. In this paper, we propose Bidirectional Multi-scale Deformable Attention (BMDA) for video Super-Resolution in terms of propagation, alignment and fusion. More specifically, the developed Deformable Alignment Module (DAM) in BMDA contains two kinds of modules: Multi-scale Deformable Convolution Module (MDCM) and Multi-scale Attention Module (MAM). MDCM is leveraged to deal with the offset information in different scales and align adjacent frames at the feature level, improving the robustness of the alignment among adjacent frames. MAM is designed to extract the local and global features of the aligned features for aggregation, such that the feature information compensation between pixels is achieved. Additionally, in order to make full use of shallow features, dense connection structure between each layer is adopted in the framework of bidirectional propagation to achieve better visual performance on video super-resolution. In particular, our proposed BDAM outperforms BasicVSR by up to 1.28dB in PSNR when batch size is set to 2. Experimental results on public video benchmark datasets demonstrate that the proposed method can achieve superior performance on large motion videos as compared with the state-of-the art methods.
C1 [Zhou, Zhenghua] Zhejiang Univ Finance & Econ, Sch Data Sci, Hangzhou 310018, Peoples R China.
   [Xue, Boxiang] China Jiliang Univ, Coll Sci, Dept Data Sci, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Hai] Murdoch Univ, Discipline Engn & Energy, Perth, WA 6150, Australia.
   [Zhao, Jianwei] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang University of Finance & Economics; China Jiliang University;
   Murdoch University; China Jiliang University
RP Zhao, JW (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM zzh2023@zufe.edu.cn; 15558036326@163.com; hai.wang@murdoch.edu.au;
   zhaojw@cjlu.edu.cn
RI WANG, HAI/ABB-7581-2022
OI WANG, HAI/0000-0003-2789-9530
FU Natural Science Foundation of Zhejiang Province [Nos.LSY19F020001,
   LY22F020002]
FX AcknowledgementsThis research was supported by the Natural Science
   Foundation of Zhejiang Province (Nos.LSY19F020001, LY22F020002). We
   thank Lim, Ledig, Yapeng Tian, Xintao Wang for their core codes. Thanks
   for Xue providing the dataset.
CR Bi ZQ, 1999, IEEE T AERO ELEC SYS, V35, P267, DOI 10.1109/7.745697
   Cao J, 2021, arXiv
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chan KCK, 2021, PROC CVPR IEEE, P4945, DOI 10.1109/CVPR46437.2021.00491
   Chan Kelvin CK, 2022, P IEEE CVF C COMP VI, P5972
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Chen J, 2014, IEEE T CIRC SYST VID, V24, P905, DOI 10.1109/TCSVT.2014.2302549
   Chen Jingrun, 2020, arXiv
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dosovitskiy Alexey, 2021, ICLR
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Y, 2018, IEEE T PATTERN ANAL, V40, P1015, DOI 10.1109/TPAMI.2017.2701380
   Isobe Takashi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P645, DOI 10.1007/978-3-030-58610-2_38
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kim TH, 2018, LECT NOTES COMPUT SC, V11207, P111, DOI 10.1007/978-3-030-01219-9_7
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2523, DOI 10.1109/ICCV48922.2021.00254
   Liang J., 2022, ARXIV
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   Liu CX, 2022, PROC CVPR IEEE, P5677, DOI 10.1109/CVPR52688.2022.00560
   Lu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Nah S, 2019, IEEE COMPUT SOC CONF, P1996, DOI 10.1109/CVPRW.2019.00251
   Neimark D, 2021, IEEE INT CONF COMP V, P3156, DOI [arXiv:2102.00719, 10.1109/ICCVW54120.2021.00355]
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LD, 2018, IEEE ENG MED BIO, P514, DOI 10.1109/EMBC.2018.8512300
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xue Boxiang, 2022, 2022 7th International Conference on Image, Vision and Computing (ICIVC), P682, DOI 10.1109/ICIVC55077.2022.9886289
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yi P, 2022, IEEE T PATTERN ANAL, V44, P2264, DOI 10.1109/TPAMI.2020.3042298
   Yi P, 2019, IEEE I CONF COMP VIS, P3106, DOI 10.1109/ICCV.2019.00320
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Zaremba W., 2014, ARXIV
   Zhang H., 2021, arXiv
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 49
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27809
EP 27830
DI 10.1007/s11042-023-16072-8
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800003
DA 2024-07-18
ER

PT J
AU Kaur, A
   Kaur, L
   Singh, A
AF Kaur, Amrita
   Kaur, Lakhwinder
   Singh, Ashima
TI DeepCONN: patch-wise deep convolutional neural networks for the
   segmentation of multiple sclerosis brain lesions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lesions; Multiple sclerosis; Segmentation; Convolutional neural
   networks; Magnetic resonance imaging; Deep learning; Brain
ID WHITE-MATTER LESIONS; CLASSIFICATION; ALGORITHM; TOOL; CNN
AB Segmentation is a critical process for examining Multiple Sclerosis (MS) brain lesions for diagnosis, follow-up, and prognosis of the disease. The complexity of the manual segmentation increases due to the variability in size, shape, location, intensity, and texture of lesions. It is also subjected to intra and inter-observer variability. It is, therefore desirable to develop an automatic segmentation pipeline that gives an accurate and reliable performance to diagnose the disease at an early stage. This paper presents a Patch-wise Deep Convolutional Neural Network (DeepCONN) to extract the brain lesions of Multiple Sclerosis (MS) from Magnetic Resonance Images (MRI). To enhance the reliability, the DeepCONN framework uses separate convolutional pathways for T1 and T2 sequences with different convolutional filters, and concatenated output is further passed through another set of convolutional filters to get the final resultant output. The performance of the DeepCONN framework is evaluated on medical image computing and computer-assisted intervention (MICCAI 2008 and 2016) challenges which yield less False Positive Rate (FPR) of 0.5% and a high True Positive Rate (TPR) of 74%. Also, the results show that DeepCONN outperforms other methods in terms of accuracy, i.e., 97%, which indicates a more accurate segmentation of MS brain lesions.
C1 [Kaur, Amrita; Singh, Ashima] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
   [Kaur, Lakhwinder] Punjabi Univ, Univ Coll Engn, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Punjabi University
RP Kaur, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
EM amrita@thapar.edu
CR Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Anbeek P, 2008, MIDAS J
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Aslani S, 2019, NEUROIMAGE, V196, P1, DOI 10.1016/j.neuroimage.2019.03.068
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Beaumont J., 2016, P 1 MICCAI CHALL MUL, P1
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Benali L, 2019, RENEW ENERG, V132, P871, DOI 10.1016/j.renene.2018.08.044
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Birenbaum A, 2017, ENG APPL ARTIF INTEL, V65, P111, DOI 10.1016/j.engappai.2017.06.006
   Boix X, 2012, INT J COMPUT VISION, V96, P83, DOI 10.1007/s11263-011-0449-8
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Carass A, 2011, NEUROIMAGE, V56, P1982, DOI 10.1016/j.neuroimage.2011.03.045
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Clevert DA, 2016, Arxiv, DOI arXiv:1511.07289
   Coupé P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Depeursinge A, 2012, IEEE T INF TECHNOL B, V16, P665, DOI 10.1109/TITB.2012.2198829
   Deshpande H, 2015, I S BIOMED IMAGING, P136, DOI 10.1109/ISBI.2015.7163834
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   García-Lorenzo D, 2011, IEEE T MED IMAGING, V30, P1455, DOI 10.1109/TMI.2011.2114671
   Geremia E, 2011, NEUROIMAGE, V57, P378, DOI 10.1016/j.neuroimage.2011.03.080
   Ghafoorian M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05300-5
   Ghribi O, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P249, DOI 10.1109/ATSIP.2014.6834616
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guizard N, 2015, NEUROIMAGE-CLIN, V8, P376, DOI 10.1016/j.nicl.2015.05.001
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hao ZH, 2012, LECT NOTES COMPUT SC, V7510, P504, DOI 10.1007/978-3-642-33415-3_62
   Harmouche R, 2015, IEEE T BIO-MED ENG, V62, P1281, DOI 10.1109/TBME.2014.2385635
   HASEGAWA A, 1994, PROC SPIE, V2167, P654
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Inglese M, 2011, J NEUROL SCI, V311, pS16, DOI 10.1016/S0022-510X(11)70004-1
   Jain S, 2015, NEUROIMAGE-CLIN, V8, P367, DOI 10.1016/j.nicl.2015.05.003
   Jerman T, 2016, 2 INT C PERS TECHN, V1, P45
   Jesson A., 2015, proceedings of the 2015 longitudinal multiple sclerosis lesion segmentation challenge, P1
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kingma D. P., 2014, arXiv
   Knight J., 2016, P 1 MICCAI CHALL MUL, P21
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, TENCON IEEE REGION, P662, DOI [10.1109/TENCON.2019.8929615, 10.1109/tencon.2019.8929615]
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lao ZQ, 2008, ACAD RADIOL, V15, P300, DOI 10.1016/j.acra.2007.10.012
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CH, 2005, LECT NOTES COMPUT SC, V3765, P469
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Liu F, 2018, RADIOLOGY, V286, P676, DOI 10.1148/radiol.2017170700
   Lo SCB, 1995, IEEE T MED IMAGING, V14, P711, DOI 10.1109/42.476112
   Malandain G, 2008, MICCAI MULT SCIER LE
   McClelland J.L., 1986, Parallel Distributed Processing, V2, P20
   McKinley R, 2016, LECT NOTES COMPUT SC, V10154, P119, DOI 10.1007/978-3-319-55524-9_12
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moeskops Pim, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P478, DOI 10.1007/978-3-319-46723-8_55
   Mordvintsev Alexander, 2015, GOOGLE RES BLOG, V2015, P3
   Morra J., 2008, GRAND CHALLENGE WORK, P1
   Mortazavi D, 2012, NEURORADIOLOGY, V54, P299, DOI 10.1007/s00234-011-0886-7
   msif, US
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Oishi K, 2009, NEUROIMAGE, V46, P486, DOI 10.1016/j.neuroimage.2009.01.002
   Piao J, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060570
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roura E, 2015, NEURORADIOLOGY, V57, P1031, DOI 10.1007/s00234-015-1552-2
   Roy S, 2014, MED IMAGING 2014 IMA, V9034, P503
   Roy S, 2018, Arxiv, DOI arXiv:1803.09172
   Roy S, 2015, IEEE J BIOMED HEALTH, V19, P1598, DOI 10.1109/JBHI.2015.2439242
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmidt M.W., 2008, COMPUTER VISION PATT, P1
   Schmidt P, 2012, NEUROIMAGE, V59, P3774, DOI 10.1016/j.neuroimage.2011.11.032
   Shiee N, 2010, NEUROIMAGE, V49, P1524, DOI 10.1016/j.neuroimage.2009.09.005
   Simon JH, 2006, AM J NEURORADIOL, V27, P455
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547
   Song Y, 2013, LECT NOTES COMPUT SC, V8150, P452, DOI 10.1007/978-3-642-40763-5_56
   Song Y, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1439, DOI 10.1109/ISBI.2012.6235841
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strumia M, 2016, IEEE T MED IMAGING, V35, P1636, DOI 10.1109/TMI.2016.2522178
   Styner M, 2008, The MIDAS Journal, V2008, P1
   Sudre CH, 2015, IEEE T MED IMAGING, V34, P2079, DOI 10.1109/TMI.2015.2419072
   Sujit SJ, 2018, CAIRO INT BIOM ENG, P33, DOI 10.1109/CIBEC.2018.8641830
   Sweeney EM, 2013, NEUROIMAGE-CLIN, V2, P402, DOI 10.1016/j.nicl.2013.03.002
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tan WR, 2017, IEEE IMAGE PROC, P3760, DOI 10.1109/ICIP.2017.8296985
   Tomas-Fernandez X, 2015, IEEE T MED IMAGING, V34, P1349, DOI 10.1109/TMI.2015.2393853
   towardsdatascience, About us
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Valverde S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101638
   Valverde S, 2017, NEUROIMAGE, V155, P159, DOI 10.1016/j.neuroimage.2017.04.034
   Vera-Olmos F., 2016, P 1 MICCAI CHALLENGE, P81
   Wachinger C, 2018, NEUROIMAGE, V170, P434, DOI 10.1016/j.neuroimage.2017.02.035
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang ZL, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917400450
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang F, 2014, IEEE T BIO-MED ENG, V61, P1155, DOI 10.1109/TBME.2013.2295593
NR 106
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16292-y
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100003
DA 2024-07-18
ER

PT J
AU Saroj, A
   Pal, S
AF Saroj, Anita
   Pal, Sukomal
TI Ensemble-based domain adaptation on social media posts for irony
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Irony; Tweet; Machine learning; Deep learning; Classification; Ensemble
AB Social media provide platforms to express opinions on different issues or aspects like politics, products, brands, news events and so on. People often use irony while expressing their opinions. Verbal irony, an utterance that conveys a spirit completely opposed to the surface meaning expressed, is usually understood from the speaker's body language and/or the context of the conversation. However, it is challenging to detect irony from a limited amount of written text automatically. In this paper, we study the issue of irony detection in social media posts collected during the 2019 general election in India. We use various machine learning and deep learning models (Bidirectional Encoder Representations from Transformers (BERT) and Embeddings fromLanguage Models (ELMo)) to classify them into irony and non-irony. We propose an ensemble model of machine learning and deep learning approaches. The classifiers are trained using a combined word embedding representation obtained from both BERT and ELMo.We create a dataset on the Indian General Election 2019 (IGE 2019 data) and then perform a series of experiments on irony detection, including a domain adaptation with the SemEval-2018 Task-3 (Sub-task A) dataset (SE-2018 T3 data). Our best performing model from machine learning based techniques as well as from deep learning based ones outperforms the state-of-the-art model in terms of accuracy, precision, recall, and F-1 (metrics)
C1 [Saroj, Anita; Pal, Sukomal] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Saroj, A (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM anitas.rs.cse16@itbhu.ac.in; spal.cse@iitbhu.ac.in
CR Ahmed U., 2018, P 12 INT WORKSH SEM, P581
   González JA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102262
   Bagheri B, 2010, 19 INT C ELECT MACHI, P1
   Baziotis C, 2018, Arxiv, DOI arXiv:1804.06659
   Bouazizi M, 2016, IEEE ACCESS, V4, P5477, DOI 10.1109/ACCESS.2016.2594194
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cvijikj I. P., 2011, Proceedings of the 2011 IEEE 9th International Conference on Dependable, Autonomic and Secure Computing (DASC 2011), P895, DOI 10.1109/DASC.2011.150
   Deng ZY, 2016, NEUROCOMPUTING, V195, P143, DOI 10.1016/j.neucom.2015.08.112
   Fersini E, 2014, P 1 IT C COMP LING C
   Gashler M., 2008, DECISION TREE ENSEMB
   Ghosh Aniruddha, 2018, SemEval, P570
   Gonzalez J.-A., 2018, P 12 INT WORKSHOP SE, P565
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hercig T, 2018, P 12 INT WORKSH SEM, P520, DOI [10.18653/v1/S18-1084, DOI 10.18653/V1/S18-1084]
   Hernandez Farias DI, 2018, P 12 INT WORKSHOP SE, P594, DOI [10.18653/v1/S18-1097, DOI 10.18653/V1/S18-1097]
   Hutchens EleanorN., 1960, ELH, V21, P352
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Junger J, 2018, APPL GENERIC DATA RE
   Kenton J. D. M.-W. C., 2019, P NAACL HLT, V1, P2
   Komarek P, 2003, P NIPS2003
   Kotsiantis S, 2011, ARTIF INTELL REV, V35, P223, DOI 10.1007/s10462-010-9192-8
   Kunneman F, 2015, INFORM PROCESS MANAG, V51, P500, DOI 10.1016/j.ipm.2014.07.006
   Lebedev AV, 2014, NEUROIMAGE-CLIN, V6, P115, DOI 10.1016/j.nicl.2014.08.023
   Leggitt JS, 2000, DISCOURSE PROCESS, V29, P1, DOI 10.1207/S15326950dp2901_1
   Lei Ba J., 2016, arXiv
   Maheswari S. Uma, 2022, Innovations in Computational Intelligence and Computer Vision: Proceedings of ICICV 2021. Advances in Intelligent Systems and Computing (1424), P141, DOI 10.1007/978-981-19-0475-2_13
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Naseem U, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207237
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peng B, 2018, P 12 INT WORKSH SEM, P622
   Porter MF, 2001, Snowball: a language for stemming algorithms
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rajalakshm S, 2018, P 12 INT WORKSHOP SE, P633, DOI 10.18653/v1/S18-1103
   Redko I, 2019, ADV DOMAIN ADAPTATIO, P208
   Riloff E., 2013, P 2013 C EMP METH NA, P704
   Rohanian O., 2018, P 12 INT WORKSH SEM, P553, DOI DOI 10.18653/V1/S18-1090
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   San A, 2018, P 12 INT WORKSH SEM, P560, DOI [10.18653/v1/S18-1091, DOI 10.18653/V1/S18-1091]
   Saroj A, 2020, SENTIMENT ANAL MULTI
   Shamay-Tsoory SG, 2005, COGN BEHAV NEUROL, V18, P55, DOI 10.1097/01.wnn.0000152228.90129.99
   Singh V., 2021, Recent Adv Comput Sci Commun (Formerly: Recent Patents on Computer Science), V14, P43, DOI DOI 10.2174/2213275912666181207154754
   Van Hee C., 2017, THESIS GHENT U
   VanHee C., 2018, P 12 INT WORKSH SEM, P39, DOI DOI 10.18653/V1/S18-1005
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu T., 2018, Proceedings of the 12nd International Workshop on Semantic Evaluation (SemEval-2018), P525
   Wahiba BA, 2016, 1 INT C ADV INT SYST, P309
   Wigand F, 2010, P 11 ANN INT DIG GOV, P66
   WILSON D, 1992, LINGUA, V87, P53, DOI 10.1016/0024-3841(92)90025-E
   Zhang SW, 2019, INFORM PROCESS MANAG, V56, P1633, DOI 10.1016/j.ipm.2019.04.006
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 51
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16180-5
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900006
DA 2024-07-18
ER

PT J
AU Wee, BF
   Sivakumar, S
   Lim, KH
   Wong, WK
   Juwono, FH
AF Wee, Boon Feng
   Sivakumar, Saaveethya
   Lim, King Hann
   Wong, W. K.
   Juwono, Filbert H.
TI Diabetes detection based on machine learning and deep learning
   approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetes detection; Machine learning; Deep learning; Feature selection;
   Anthropometric measurement
ID MELLITUS; CLASSIFICATION; ALGORITHMS; MORTALITY; NETWORK
AB The increasing number of diabetes individuals in the globe has alarmed the medical sector to seek alternatives to improve their medical technologies. Machine learning and deep learning approaches are active research in developing intelligent and efficient diabetes detection systems. This study profoundly investigates and discusses the impacts of the latest machine learning and deep learning approaches in diabetes identification/classifications. It is observed that diabetes data are limited in availability. Available databases comprise lab-based and invasive test measurements. Investigating anthropometric measurements and non-invasive tests must be performed to create a cost-effective yet high-performance solution. Several findings showed the possibility of reconstructing the detection models based on anthropometric measurements and non-invasive medical indicators. This study investigated the consequences of oversampling techniques and data dimensionality reduction through feature selection approaches. The future direction is highlighted in the research of feature selection approaches to improve the accuracy and reliability of diabetes identifications.
C1 [Wee, Boon Feng; Sivakumar, Saaveethya; Lim, King Hann; Wong, W. K.] Curtin Univ, Dept Elect & Comp Engn, Kent St, Bentley, WA 6102, Australia.
   [Juwono, Filbert H.] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, 111 Renai Rd, Suzhou 215123, Jiangsu, Peoples R China.
C3 Curtin University; Xi'an Jiaotong-Liverpool University
RP Wee, BF (corresponding author), Curtin Univ, Dept Elect & Comp Engn, Kent St, Bentley, WA 6102, Australia.
EM 19966010@student.curtin.edu.au; saaveethya.s@curtin.edu.my;
   glkhann@curtin.edu.my; weikitt.w@curtin.edu.my; filbert@ieee.org
RI Lim, Hann/AAI-9930-2020; Wong, Wing-Keung/AAI-9296-2020; Juwono,
   Filbert/AFN-4051-2022
OI Lim, Hann/0000-0002-5679-7747; Wong, Wing-Keung/0000-0001-6755-572X;
   Juwono, Filbert/0000-0002-2596-8101; WEE, BOON FENG/0000-0003-0861-7868
CR Abdulhadi Nour, 2021, 2021 International Conference on Information Technology (ICIT), P350, DOI 10.1109/ICIT52682.2021.9491788
   Alaa Khaleel Fayroza, 2023, Materials Today: Proceedings, P3200, DOI 10.1016/j.matpr.2021.07.196
   Albawi S, 2017, I C ENG TECHNOL
   Ali J., 2012, International Journal of Computer Science Issues (IJCSI), V9, P272
   Arcadu F, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0172-3
   Bala P, 2020, Int. J. Cogn. Comput. Eng., V1, P55, DOI [10.1016/j.ijcce.2020.10.002, DOI 10.1016/J.IJCCE.2020.10.002]
   Birjais R, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1117-9
   Chawla R, 2020, INT J DIABETES DEV C, V40, pS1, DOI [10.1007/s13410-020-00819-2, 10.4103/ijem.IJEM_225_20]
   Czmil A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122555
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Das K., 2017, Int. J. Innov. Res. Comput. Commun. Eng., V5, P1301, DOI [10.15680/IJIRCCE.2017.0502001, DOI 10.15680/IJIRCCE.2017.0502001]
   Dinh A, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0918-5
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Dua D., 2017, UCI MACHINE LEARNING
   El Jerjawi NS, 2018, Int J Adv Sci Technol, V121
   Fengxi Song, 2010, Proceedings of the 2010 International Conference on System Science, Engineering Design and Manufacturing Informatization (ICSEM 2010), P27, DOI 10.1109/ICSEM.2010.14
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   García-Ordás MT, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.105968
   Ge Q, 2019, J DIABETES RES, V2019, DOI 10.1155/2019/3256060
   Ghosh S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P24, DOI 10.1109/iss1.2019.8908018
   Hou JJ, 2020, PSYCHOL HEALTH MED, V25, P1106, DOI 10.1080/13548506.2019.1709652
   Hu JY, 2016, NEUROCOMPUTING, V171, P63, DOI 10.1016/j.neucom.2015.06.017
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Kaul K, 2013, ADV EXP MED BIOL, V771, P1
   Kaur H, 2020, APPL COMPUT INFORM, V1330
   Kazmi Nasir Hussain Shah, 2013, J Ayub Med Coll Abbottabad, V25, P86
   Kopitar L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68771-z
   Krishnappa M, 2020, CARDIOVASC DIABETOL, V19, DOI 10.1186/s12933-020-01073-w
   Kumar Santosh, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0651, DOI 10.1109/ICCSP48568.2020.9182293
   Kumari S., 2021, INT J COGN COMPUT EN, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Lai H, 2019, BMC ENDOCR DISORD, V19, DOI 10.1186/s12902-019-0436-6
   Lam Carson, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P147
   Liu G, 2018, J AM COLL CARDIOL, V71, P2867, DOI 10.1016/j.jacc.2018.04.027
   Lukmanto RB, 2019, PROCEDIA COMPUT SCI, V157, P46, DOI 10.1016/j.procs.2019.08.140
   Mallone R, 2011, CLIN EXP IMMUNOL, V163, P33, DOI 10.1111/j.1365-2249.2010.04272.x
   Maratni NPT, 2021, J NUTR METAB, V2021, DOI 10.1155/2021/5527736
   Mathis D, 2001, NATURE, V414, P792, DOI 10.1038/414792a
   Mathuria M., 2013, Int. J. Adv. Res. Comput. Sci. Softw. Eng., V3
   Mercaldo F, 2017, PROCEDIA COMPUT SCI, V112, P2519, DOI 10.1016/j.procs.2017.08.193
   Nadeem MW, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9101393
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Naz H, 2020, J DIABETES METAB DIS, V19, P391, DOI 10.1007/s40200-020-00520-5
   Prabhu P, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P138, DOI [10.1109/icispc.2019.8935838, 10.1109/ICISPC.2019.8935838]
   Rani DVV., 2021, J U SHANGHAI SCI TEC, V23, P148, DOI [10.51201/JUSST/21/08358, DOI 10.51201/JUSST/21/08358]
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Rubaiat SY, 2018, 2018 INT C INNOVATIO, P1
   Ryu KS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010421
   Sacks D.B., 2011, Diabetes Care, V34, P61, DOI [10.2337/dc11-9998, DOI 10.2337/DC11-9998]
   Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843
   Sandhiya S, 2020, J AMB INTEL HUM COMP, V11, P5547, DOI 10.1007/s12652-020-01910-6
   Sarwar Muhammad Azeem, 2018, 2018 24th International Conference on Automation and Computing (ICAC). Proceedings, DOI 10.23919/IConAC.2018.8748992
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Sivaranjani S., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P141, DOI 10.1109/ICACCS51430.2021.9441935
   Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261
   Somnath M., 2017, P 2017 INT C COMPUTA, P65
   Swapna G, 2018, ICT EXPRESS, V4, P243, DOI 10.1016/j.icte.2018.10.005
   Tao KM, 2019, ANESTHESIOLOGY, V130, P312, DOI 10.1097/ALN.0000000000002469
   Taunk K, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1255, DOI [10.1109/iccs45141.2019.9065747, 10.1109/ICCS45141.2019.9065747]
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Ul Haq A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092649
   Vidhya K, 2020, J AMB INTEL HUM COMP, V11, P5691, DOI 10.1007/s12652-020-01930-2
   Wang GM, 2019, IEEE T AUTOM SCI ENG, V16, P874, DOI 10.1109/TASE.2018.2865663
   Yahyaoui A., 2019, 1st Int Inf Softw Eng Conf Innov Technol Digit Transform IISEC 2019-Proc, P1, DOI DOI 10.1109/UBMYK48245.2019.8965556
   Yang G, 2022, DIABET EPIDEMIOL MAN, V6, DOI 10.1016/j.deman.2022.100050
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
   Yuan G.-X., 2011, Proceedings of the Seventeenth ACM SIGKDD International Con- ference on Knowledge Discovery and Data Mining, P33, DOI DOI 10.1145/2020408.2020421
   Zaccardi F, 2017, DIABETOLOGIA, V60, P240, DOI 10.1007/s00125-016-4162-6
   Zhou L, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01525-7
   Zhu TY, 2021, IEEE J BIOMED HEALTH, V25, P2744, DOI 10.1109/JBHI.2020.3040225
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 71
TC 9
Z9 9
U1 11
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16407-5
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000006
OA hybrid
DA 2024-07-18
ER

PT J
AU da Silva, DRB
   de Araujo, TMU
   do Rego, TG
   Brandao, MAC
   Goncalves, LMG
AF da Silva, Diego R. B.
   de Araujo, Tiago Maritan U.
   do Rego, Thais Gaudencio
   Brandao, Manuella Aschoff Cavalcanti
   Goncalves, Luiz Marcos Garcia
TI A multiple stream architecture for the recognition of signs in Brazilian
   sign language in the context of health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Datasets; Deep learning; Neural networks; Libras
ID RECOMMENDATION SYSTEM; MEDICAL IMAGES
AB Deaf people communicate naturally through sign languages and often face barriers to communicating with hearing people and accessing information in written languages. These communication difficulties are aggravated in the health domain, especially in a hospital emergency, when human sign language interpreters are unavailable. This paper proposes a solution for automatically recognizing signs in Brazilian Sign Language (Libras) in the health context to reduce this problem. The idea is that the system could assist in the communication between a Deaf patient and his doctor in the future. Our solution involves a multiple-stream architecture that combines convolutional and recurrent neural networks, dealing with sign languages' visual phonemes individual and specialized ways. The first stream uses the optical flow as input for capturing information about the "movement" of the sign; the second stream extracts kinematic and postural features, including "handshapes" and "facial expressions"; and the third stream process the raw RGB images to address additional attributes about the sign not captured in the previous streams. Thus, we can process more spatiotemporal features that discriminate the classes during the training stage. The computational results show that the solution can recognize signs in Libras in the health context, with an average accuracy, precision, recall, and f1-score of 99.80%, 99.81%, 99.80%, and 99.80%, respectively. Our system also performed better than other works in the literature, obtaining an average accuracy of 100% in an Argentine Sign Language (LSA) dataset, which is usually used for comparison purposes.
C1 [da Silva, Diego R. B.; Goncalves, Luiz Marcos Garcia] Univ Fed Rio Grande do Norte, Natal, Brazil.
   [de Araujo, Tiago Maritan U.; do Rego, Thais Gaudencio; Brandao, Manuella Aschoff Cavalcanti] Univ Fed Paraiba, Joao Pessoa, Brazil.
C3 Universidade Federal do Rio Grande do Norte; Universidade Federal da
   Paraiba
RP da Silva, DRB (corresponding author), Univ Fed Rio Grande do Norte, Natal, Brazil.
EM diego.silva@lavid.ufpb.br; tiagomaritan@lavid.ufpb.br;
   gaudenciothais@gmail.com; manuella.lima@lavid.ufpb.br;
   lmarcos@dca.ufrn.br
RI Gonçalves, Luiz Marcos Garcia/C-3786-2009
OI Gonçalves, Luiz Marcos Garcia/0000-0002-7735-5630; Bezerra da Silva,
   Diego Ramon/0000-0002-1037-9953
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.& nbsp;
CR Akmeliawati R, 2007, IEEE IMTC P, P1169
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   Aragao JD, 2015, REV LAT-AM ENFERM, V23, P1014, DOI 10.1590/0104-1169.0325.2644
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Binh N D., 2005, Conference on graphics, vision and image proces, P1
   Bohácek M, 2022, IEEE WINT CONF APPL, P182, DOI 10.1109/WACVW54805.2022.00024
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cao Z., 2018, ARXIV
   Carneiro SB, 2016, IEEE SENSOR
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Castiglioni I, 2021, PHYS MEDICA, V83, P9, DOI 10.1016/j.ejmp.2021.02.006
   Cavararo R, 2010, CARACTERISTICAS GERA
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chollet F, 2015, KERAS
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   CNsaude, 2022, CEN HOSP BRAS
   Cooper H, 2011, READING SIGNS VIDEO, DOI [10.1109/iccvw.2011.6130349, DOI 10.1109/ICCVW.2011.6130349]
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   de Araújo TMU, 2014, INFORM SCIENCES, V281, P762, DOI 10.1016/j.ins.2014.04.008
   de Araujo TMU, 2012, J BRAZILIAN COMPUTER, V19, P107, DOI DOI 10.1007/S13173-012-0086-2
   Dignan C, 2022, MULTIMED TOOLS APPL, V81, P34525, DOI 10.1007/s11042-021-11830-y
   Donahue J, 2014, PREPRINT
   Elemento O, 2021, NAT REV CANCER, V21, P747, DOI 10.1038/s41568-021-00399-1
   Fakhfakh S, 2022, INT ARAB J INF TECHN, V19, P660, DOI 10.34028/iajit/19/4/10
   Galicia R, 2015, PROC IEEE INT SYMP, P573, DOI 10.1109/ISIE.2015.7281531
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huenerfauth Matt, 2008, Universal Access in the Information Society, V6, P419, DOI 10.1007/s10209-007-0095-7
   Huenerfauth M, 2004, P STUD RES WORKSH HL, DOI [10.3115/1614038.1614043, DOI 10.3115/1614038.1614043]
   Jani AB, 2018, IEEE SENSOR, P1523
   Kau Lih-Jen., 2015, CIRCUITS SYSTEMS MWS, P1
   KAYAALP F, 2018, 2018 EL EL COMP SCI, P1
   Konstantinidis D, 2018, 3DTV CONF
   Lab C, 2015, RANK WEB WORLD HOSP
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   López-Ludeña V, 2014, ENG APPL ARTIF INTEL, V32, P258, DOI 10.1016/j.engappai.2014.02.006
   López-Ludeña V, 2014, KNOWL-BASED SYST, V56, P240, DOI 10.1016/j.knosys.2013.11.017
   Machado MC, 2018, THESIS
   Masood Sarfaraz, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P623, DOI 10.1007/978-981-10-7566-7_63
   Mistree K, 2021, INT J ADV COMPUT SC, V12, P697
   Morrissey S, 2013, MACH TRANSL, V27, P25, DOI 10.1007/s10590-012-9133-1
   Nguyen M., 2021, Geometry and Vision, P108
   Ong EJ, 2014, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2014.248
   Oszust M, 2013, C HUM SYST INTERACT, P219, DOI 10.1109/HSI.2013.6577826
   Parelli Maria, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P249, DOI 10.1007/978-3-030-66096-3_18
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Rastgoo R, 2022, J AMB INTEL HUM COMP, V13, P591, DOI 10.1007/s12652-021-02920-8
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Ronchetti F, 2016, 22 C ARG CIENC COMP
   Ronchetti Franco, 2016, 20 2 C ARG CIENC COM
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shoaib U, 2014, EXPERT SYST APPL, V41, P2300, DOI 10.1016/j.eswa.2013.09.027
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Souza Maria Fernanda Neves Silveira de, 2017, Rev. CEFAC, V19, P395, DOI 10.1590/1982-0216201719317116
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tran WT, 2021, CAN ASSOC RADIOL J, V72, P98, DOI 10.1177/0846537120949974
   Vazquez-Enriquez M., 2021, P IEEECVF C COMPUTER, P3462
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   World Health Organization, 2013, MILL PEOPL WORLD HAV
   Wu J, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2016.2598302
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Yadav AK, 2021, MATER TODAY CHEM, V20, DOI 10.1016/j.mtchem.2021.100443
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
NR 66
TC 2
Z9 2
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19767
EP 19785
DI 10.1007/s11042-023-16332-7
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037377100001
DA 2024-07-18
ER

PT J
AU Rai, CK
   Pahuja, R
AF Rai, Chitranjan Kumar
   Pahuja, Roop
TI Northern maize leaf blight disease detection and segmentation using deep
   convolution neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention U-Net; Deep learning; Plant segmentation; Maize; Real-time
ID IDENTIFICATION; CLASSIFICATION
AB Maize is ranked as the third most important food crop in India after rice and wheat. The cultivation of this particular crop and its associated agricultural practices have faced many challenges over the centuries. Maize is susceptible to Northern Leaf Blight (NLB), a highly contagious fungal foliar disease. The primary reason for the reduction in yield resulting from NLB is the loss of photosynthetic leaf area. Therefore, identifying diseases at an early stage is critical to ensure that the treatment process is carried out correctly and that the quality of results is maintained. This research uses a deep learning-based Attention U-Net model to explore a real-time, effective approach for segmentation and detecting NLB diseases in maize crops. Data augmentation is performed after image annotation to increase the model's effectiveness, and the model is trained from scratch. The model was trained for a maximum of 50 epochs using an initial learning rate of 0.0001 with Adam as an optimizer, and its performance was tested on the test dataset. This study shows that the Attention U-Net model outperformed other image segmentation methods, such as Res U-Net and Plain U-Net, and showed better results with an Intersection over Union (IoU) of 72.41%, 70.91% and 51.95%, respectively. The proposed model achieves an average pixel-wise F1 score of 85.23%. The diseased segmentation accuracy clenched to 98.97%, and the Dice coefficient (DC) of disease spot segmentation is 81.39%. Adding an attention mechanism to the U-Net architecture improves its ability to express local features, resulting in improved NLB disease image segmentation performance.
C1 [Rai, Chitranjan Kumar; Pahuja, Roop] Dr B R Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Rai, CK (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
EM chitranjankrai@gmail.com
RI Rai, Chitranjan Kumar/IUN-0382-2023; Pahuja, Roop/X-8544-2019
OI Pahuja, Roop/0000-0002-1575-9349; Rai, Chitranjan/0000-0003-1446-3631
CR Afzaal U, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196565
   [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Azath M, 2021, J ELECTR COMPUT ENG, V2021, DOI 10.1155/2021/9981437
   Bi CK, 2022, MOBILE NETW APPL, V27, P172, DOI 10.1007/s11036-020-01640-1
   Buslaev A, 2018, IEEE COMPUT SOC CONF, P197, DOI 10.1109/CVPRW.2018.00035
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen S, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11050420
   Chung CL, 2010, THEOR APPL GENET, V121, P205, DOI 10.1007/s00122-010-1303-z
   Dande SC, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1466, DOI 10.1109/ICCSP.2016.7754401
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Donatelli M, 2017, AGR SYST, V155, P213, DOI 10.1016/j.agsy.2017.01.019
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gajjar R, 2022, VISUAL COMPUT, V38, P2923, DOI 10.1007/s00371-021-02164-9
   Haque MA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10140-z
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hooda K. S., 2017, Proceedings of the Indian National Science Academy Part B Biological Sciences, V87, P1041, DOI 10.1007/s40011-015-0688-5
   Hooda KS, 2017, J PLANT DIS PROTECT, V124, P101, DOI 10.1007/s41348-016-0054-8
   Huang MF, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11121216
   Hughes D., 2015, ABS151108060 CORR
   Jagtap SB, 2014, IOSR Journal of VLSI and Signal Processing, V4, P24, DOI [DOI 10.9790/4200-04512430, 10.9790/4200-04512430]
   Jamann TM, 2016, THEOR APPL GENET, V129, P591, DOI 10.1007/s00122-015-2650-6
   Jasim Marwan Adnan, 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P259, DOI 10.1109/CSASE48920.2020.9142097
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kumar rai Chitranjan, 2021, 2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT), P472, DOI 10.1109/ICIIP53038.2021.9702652
   Li ZY, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11223174
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mallowa SO, 2015, PHYTOPATHOLOGY, V105, P1080, DOI 10.1094/PHYTO-08-14-0210-R
   Mitra M., 1931, Transactions of the British Mycological Society, V15, P254
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Patki SS., 2016, International Journal of Advanced Research in Computer and Communication Engineering, V5, P165, DOI [10.17148/IJARCCE.2016.51034, DOI 10.17148/IJARCCE.2016.51034]
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Rai CK, 2023, MULTIMED TOOLS APPL, V82, P25307, DOI 10.1007/s11042-023-14933-w
   Rai CK., 2022, J E CHINA U SCI TECH, V65, P877, DOI [10.5281/ZENODO.7081544, DOI 10.5281/ZENODO.7081544]
   Reddy T R., 2013, International Journal of Applied Biology and Pharmaceutic technology, V5, P54
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rothe PR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Sagar A., 2020, bioRxiv, DOI [10.1101/2020.05.22.110957, DOI 10.1101/2020.05.22.110957]
   Savary S, 2019, NAT ECOL EVOL, V3, P430, DOI 10.1038/s41559-018-0793-y
   Sibiya J., 2013, African Journal of Agricultural Research, V8, P1790
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Springer M, 2019, JOHN BANVILLE AND HIS PRECURSORS, P1
   Stewart EL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192209
   Sun J, 2020, IEEE ACCESS, V8, P33679, DOI 10.1109/ACCESS.2020.2973658
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Toda Y, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9237136
   Tzounis A, 2017, BIOSYST ENG, V164, P31, DOI 10.1016/j.biosystemseng.2017.09.007
   Vallabhajosyula S, 2022, J PLANT DIS PROTECT, V129, P545, DOI 10.1007/s41348-021-00465-8
   Wang Guan, 2017, Comput Intell Neurosci, V2017, P2917536, DOI 10.1155/2017/2917536
   Wang Z, 2018, Acad J Comput Inform Sci, V1, DOI [10.25236/AJCIS.010002, DOI 10.25236/AJCIS.010002]
   Wiesner-Hanks Tyr, 2018, BMC Res Notes, V11, P440, DOI 10.1186/s13104-018-3548-6
   Yuan M, 2019, REMOTE SENS LETT, V10, P506, DOI 10.1080/2150704X.2019.1574990
   Zhang JY, 2021, INT J DISTRIB SENS N, V17, DOI 10.1177/15501477211007407
   Zhang SW, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107511
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
NR 67
TC 1
Z9 1
U1 9
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19415
EP 19432
DI 10.1007/s11042-023-16398-3
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900002
DA 2024-07-18
ER

PT J
AU Jahromi, ZT
   Hasheminejad, SMH
   Shojaedini, SV
AF Jahromi, Zeinab Torabi
   Hasheminejad, Seyed Mohammad Hossein
   Shojaedini, Seyed Vahab
TI Deep learning semantic image synthesis: a novel method for unlimited
   capacity, high noise resistance coverless video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Coverless information hiding; Video steganography; Deep neural network;
   Semantic segmentation; Semantic synthesis
ID NETWORK; SYSTEM; WATERMARKING
AB Nowadays coverless steganography has fascinated huge attentiveness in the field of information security as it does not modify the transmission carrier of the secret information so it won't be detected by steganalysis algorithms constructively. Yet, the present techniques have a limited capacity for transferring bits and a few of them use deep neural networks, plus most coverless techniques don't use videos as carriers and benefit from the privilege of having more abundant content. To address these problems, a coverless video steganography technique is proposed that has unlimited hiding capacity and provides effective resistance against different noises. This paper utilizes two different deep neural networks to alter the video frames to new ones and extract information. The first one is a deep high-resolution network that segments the input frame and converts it to a label map. Then with a generative adversarial network, the semantic label is synthesized into a new frame from which the receiver acquires information in a way that makes it independent of using other frames. The sender should also dispatch the receiver some auxiliary info about each frame. The method is evaluated on two popular datasets: common objects in context (COCO), and the densely annotated video segmentation (DAVIS) dataset. Ostensibly, this is the first method with infinite capacity per each video frame. The proposed has great noise robustness of more than 29% compared to its rival on the DAVIS dataset, and also about 12% stronger against common noise compared to some state of art methods. Besides this technique can effectively resist steganalysis tools. Some methods have also been introduced to limit the effect of noise in the proposed method.
C1 [Jahromi, Zeinab Torabi; Hasheminejad, Seyed Mohammad Hossein] Alzahra Univ, Comp Engn Dept, Tehran, Iran.
   [Shojaedini, Seyed Vahab] Iranian Res Org Sci & Technol, Elect & Comp Engn Dept, Tehran, Iran.
C3 Alzahra University
RP Jahromi, ZT (corresponding author), Alzahra Univ, Comp Engn Dept, Tehran, Iran.
EM ztorabi08@gmail.com; smh.hasheminejad@alzahra.ac.ir; shojadini@irost.ir
CR Ahmed B. T., 2021, International Journal of Advances in Applied Sciences (IJAAS), P8814
   Al Fararni K, 2021, BIG DATA MIN ANAL, V4, P47, DOI 10.26599/BDMA.2020.9020015
   Alshinina R, A High Payload Video Steganography algorithm in DWT Domain based on BCH (15, 11)
   Anggriani K, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020395
   Barra S, 2020, IEEE-CAA J AUTOMATIC, V7, P683, DOI 10.1109/JAS.2020.1003132
   Barz B, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060041
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Din R., 2009, International Journal of Computers, V3, P161
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Duan XT, 2018, Arxiv, DOI arXiv:1802.03528
   Duta IC, 2021, INT C PATT RECOG, P9415, DOI 10.1109/ICPR48806.2021.9412193
   Feng Q, 2020, IEEE T INF FOREN SEC, V15, P3709, DOI 10.1109/TIFS.2020.2997134
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Huang K, 2020, MULTIMED TOOLS APPL, V79, P31147, DOI 10.1007/s11042-020-09435-y
   Kim WJ, 2022, IEEE T PARALL DISTR, V33, P1605, DOI 10.1109/TPDS.2021.3122454
   Kwon OY, 2020, IEEE T NEUR NET LEAR, V31, P3839, DOI 10.1109/TNNLS.2019.2946869
   Li J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051253
   Li QJ, 2021, IEEE SIGNAL PROC LET, V28, P1095, DOI 10.1109/LSP.2021.3083546
   Liu Q, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00521-7
   Liu Q, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105375
   Lu SP, 2021, PROC CVPR IEEE, P10811, DOI 10.1109/CVPR46437.2021.01067
   Luo Y, 2020, IEEE Trans Circ Syst Vid Technol
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Mary Jenifer J., 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P627, DOI 10.1109/ICOEI.2018.8553847
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Meng L, 2020, arXiv
   Mstafa RJ, 2020, IEEE ACCESS, V8, P161825, DOI 10.1109/ACCESS.2020.3021356
   Mstafa RJ, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Pan N, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00512-8
   Peng F, 2022, IEEE T CIRC SYST VID, V32, P5817, DOI 10.1109/TCSVT.2022.3161419
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin JH, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091394
   Ruan S., 2017, Commun Technol, V50, P1506
   Saad AS, 2021, IEEE ACCESS, V9, P16522, DOI 10.1109/ACCESS.2021.3050737
   Shyla M. K. K., 2021, Soft. Comput., V3, DOI DOI 10.1016/J.SOCL.2021.100021
   Soundararajan D, 2023, INT ARAB J INF TECHN, V20, P190, DOI 10.34028/iajit/20/2/5
   Sun K, 2019, Arxiv, DOI arXiv:1904.04514
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sushko V, 2021, Arxiv, DOI arXiv:2012.04781
   Tan Y., 2021, Secur Commun Netw, V22, P2021
   Valueva MV, 2020, MATH COMPUT SIMULAT, V177, P232, DOI 10.1016/j.matcom.2020.04.031
   Wang J, 2021, IEEE J-STARS, V14, P283, DOI 10.1109/JSTARS.2020.3041859
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Xu XK, 2012, IEEE IMAGE PROC, P245, DOI 10.1109/ICIP.2012.6466841
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yin PS, 2020, IEEE ACCESS, V8, P116106, DOI 10.1109/ACCESS.2020.3002835
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zheng S., 2017, INT C INT COMP 2017
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhou ZL, 2019, IEEE ACCESS, V7, P179891, DOI 10.1109/ACCESS.2019.2955990
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 58
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 20
PY 2023
DI 10.1007/s11042-023-16278-w
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8JR9
UT WOS:001032628900003
DA 2024-07-18
ER

PT J
AU Meikap, S
   Jana, B
AF Meikap, Sudipta
   Jana, Biswapati
TI Reference pixel-based reversible data hiding scheme using multi-level
   pixel value ordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reference Pixel; Multi-Level PVO; Embedding capacity; Steganalysis;
   Reversible data hiding; Steganographic Attacks
ID PREDICTION-ERROR; WATERMARKING SCHEME; IMAGE WATERMARKING; PVO;
   EXPANSION
AB Traditional PVO (Pixel Value Ordering) can embed at most two data bits in a row or column of a smooth image block, which is unable to fulfil current demands. To improve embedding capacity, we propose a reference pixel-based reversible data hiding scheme using multi-level PVO with PEE (Prediction Error Expansion) wheremore than two data bits can be embedded in a smooth block in each iteration while maintaining good visual quality and security. This scheme is different because it uses smooth block selection and takes bin difference (-1) into account when embedding secret data within more than two pixels. By choosing the neighbouring and current block's pixel, this technique determines the smooth block. The reference pixel-based Multi-Level PVO(MPVO) method enhances the embedding performance as well as the image quality. With a block size of mu = (3 x 3), the suggested technique has an average embedding capacity (EC) of over 70,000 bits and an average PSNR of over 40 dB. The experimental results shows that the proposed scheme is relatively greater in concentration with security, image quality and capacity of secrets than the other state-of-the-art schemes. The desired result highlighted certain impressive magnificent qualities in the areas of steganography, security controls, and digitally fraud identification, without which the development of technology would be severely hindered. This programme has significant benefits for both the public and private sectors in the areas of intellectual property rights and health care units.
C1 [Meikap, Sudipta] Hijli Coll, Dept Comp Sci, Rangamatia 721306, West Bengal, India.
   [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721306, West Bengal, India.
C3 Vidyasagar University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721306, West Bengal, India.
EM sudiptameikap@gmail.com; biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], The USC-SIPI Image Database
   Benseddik ML, 2022, MULTIMED TOOLS APPL, V81, P20329, DOI 10.1007/s11042-022-12288-2
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chang J, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103097
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Jain NK, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S021812661850175X
   Jana Biswapati, 2016, International Journal of Network Security, V18, P633
   Jana B., 2016, Int. J. Electron. Inf. Eng, V5, P6
   Jana B., 2017, MULTIMED TOOLS APPL, P1
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Kaur G, 2021, MULTIDIM SYST SIGN P, V32, P533, DOI 10.1007/s11045-020-00748-7
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kumar R, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P306, DOI 10.1109/itc-cscc.2019.8793412
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee GJ, 2015, MULTIMED TOOLS APPL, V74, P7261, DOI 10.1007/s11042-014-1980-8
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Lee SK, 2004, LECT NOTES COMPUT SC, V3333, P340
   Li S, 2020, IEEE ACCESS, V8, P214732, DOI 10.1109/ACCESS.2020.3040048
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu GY, 2014, MED BIOL ENG COMPUT, V52, P741, DOI 10.1007/s11517-014-1177-3
   Liu HJ, 2013, COMPUT ELECTR ENG, V39, P1164, DOI 10.1016/j.compeleceng.2013.01.017
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Mao NX, 2023, MULTIMED TOOLS APPL, V82, P10553, DOI 10.1007/s11042-022-13705-2
   Meikap Sudipta, 2017, Communication, Devices, and Computing. ICCDC 2017. Proceedings: LNEE 470, P47, DOI 10.1007/978-981-10-8585-7_5
   Meikap S, 2021, MULTIMED TOOLS APPL, V80, P5617, DOI 10.1007/s11042-020-09823-4
   Meikap S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0659-1
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Nottingham Trent University, UCID IM DAT
   Openi, NAT LIB MED PRES MED
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   r0k, Kodak Lossless True Color Image Suite
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sudipta Meikap, 2021, Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2020. Advances in Intelligent Systems and Computing (AISC 1255), P659, DOI 10.1007/978-981-15-7834-2_61
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Turner LF., 1989, PATENT IPN, V89, P21
   University of California Berkeley, BERK SEGM DAT BENCHM
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Xiang HY, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2585983
   Yao H, 2021, INFORM SCIENCES, V563, P130, DOI 10.1016/j.ins.2021.02.015
   Zhao W., 2018, J INF HIDING MULTIME, V9, P918
NR 61
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16895
EP 16928
DI 10.1007/s11042-023-16171-6
EA JUL 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500005
DA 2024-07-18
ER

PT J
AU Wang, T
   Zhang, SQ
AF Wang, Tao
   Zhang, Shiqing
TI DSC-Ghost-Conv: A compact convolution module for building efficient
   neural network architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural networks; Compact convolution module; Ghost
   convolution module; Depthwise separable convolution; Resource costs
AB Convolutional Neural Networks (CNNs) have achieved remarkable results in many application fields. However, these CNNs have a large number of network parameters, thereby consuming a lot of computation and storage resources. This makes CNNs unable to be effectively applied to these platforms with limited storage and computation resources. To address this issue, this paper proposes a new compact convolution module called DSC-Ghost-Conv, which combines the advantages of both depthwise separable convolution (DSC) and Ghost convolution module (Ghost-Conv). DSC-Ghost-Conv replaces the standard convolution used in the Ghost convolution module with depthwise separable convolution so as to reduce resource costs of the Ghost convolution module. DSC-Ghost-Conv can be used as a plug-and-play component to implement ordinary convolutional layers in typical CNNs such as VGG-16, ResNet-50 and GoogleNet. Experimental results on the MNIST and CIFAR-10 datasets show that implementing the ordinary convolutional layers of CNNs with DSC-Ghost-Conv not only obtains the competitive performance to typical CNNs, but also greatly reduces the number of network parameters and floating point operations (FLOPs) of CNNs. This demonstrates that the proposed DSC-Ghost-Conv can effectively reduce the resource costs of CNNs.
C1 [Wang, Tao; Zhang, Shiqing] Taizhou Univ, Sch Elect & Informat Engn, Taizhou 318000, Zhejiang, Peoples R China.
C3 Taizhou University
RP Zhang, SQ (corresponding author), Taizhou Univ, Sch Elect & Informat Engn, Taizhou 318000, Zhejiang, Peoples R China.
EM tzczsq@163.com
RI Wang, Tao/AAW-7703-2021
OI Wang, Tao/0000-0001-7756-9711
FU Scientific and Technological Project of Taizhou City of Zhejiang
   Province [2003gy04]; Cultivation Foundation of Taizhou University
   [Z2018049]; Zhejiang Provincial National Science Foundation of China
   [LZ20F020002]
FX This paper was supported by Scientific and Technological Project of
   Taizhou City of Zhejiang Province (2003gy04), Cultivation Foundation of
   Taizhou University (Z2018049), Zhejiang Provincial National Science
   Foundation of China (LZ20F020002).
CR [Anonymous], 2017, INT C LEARN REPRESEN
   [Anonymous], 2015, TORCH BLOG
   Chen ZQ, 2021, IEEE T NEUR NET LEAR, V32, P799, DOI 10.1109/TNNLS.2020.2979517
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Courbariaux M, 2016, Arxiv, DOI [arXiv:1602.02830, 10.48550/arXiv.1602.02830]
   Courbariaux M, 2015, ADV NEUR IN, V28
   McDonnell MD, 2018, Arxiv, DOI arXiv:1802.08530
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gong XY, 2019, IEEE I CONF COMP VIS, P3223, DOI 10.1109/ICCV.2019.00332
   Gong YC, 2014, Arxiv, DOI arXiv:1412.6115
   Guo JY, 2021, IEEE T CIRC SYST VID, V31, P1114, DOI 10.1109/TCSVT.2020.2996231
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu QH, 2018, AAAI CONF ARTIF INTE, P3247
   Hu YM, 2018, Arxiv, DOI [arXiv:1805.11394, 10.48550/arXiv.1805.11394]
   Huang WK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68453-w
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jie H.O.U., 2020, COMMUNICATIONS TECHN, V53, P1127, DOI 10.3969/j.issn.1002-0802.2020.05.012
   Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2016, Arxiv, DOI arXiv:1605.04711
   Li H, 2017, INT C LEARN REPRESEN
   Li SJ, 2023, IEEE T NEUR NET LEAR, V34, P8743, DOI 10.1109/TNNLS.2022.3152732
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P4439, DOI 10.1109/TCYB.2020.3035613
   Luo JH, 2017, Arxiv, DOI arXiv:1706.05791
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Nagi R, 2022, MULTIMED TOOLS APPL, V81, P24995, DOI 10.1007/s11042-022-12662-0
   Qiushan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11017, DOI 10.1109/CVPR42600.2020.01103
   Qu X, 2022, COMPUTER ENG APPL
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabour S, 2017, ADV NEUR IN, V30
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang ML, 2022, IEEE T PARALL DISTR, V33, P3249, DOI 10.1109/TPDS.2022.3149787
   weiaicunzai, 2018, PYTORCH CIFAR100
   Wen W, 2016, ADV NEUR IN, V29
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang ZH, 2020, PROC CVPR IEEE, P1826, DOI 10.1109/CVPR42600.2020.00190
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zeleznik R, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-20966-2
   Zhang C, 2021, P IEEE CVF C COMP VI, P3012
   Zhang LF, 2022, IEEE T PATTERN ANAL, V44, P4388, DOI 10.1109/TPAMI.2021.3067100
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao CL, 2019, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2019.00289
   Zhu CZ, 2017, Arxiv, DOI arXiv:1612.01064
NR 55
TC 2
Z9 2
U1 11
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 14
PY 2023
DI 10.1007/s11042-023-16120-3
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M5HW6
UT WOS:001030536100005
DA 2024-07-18
ER

PT J
AU Goyal, A
   Gupta, V
   Kumar, M
AF Goyal, Archana
   Gupta, Vishal
   Kumar, Manish
TI A deep neural framework for named entity recognition with boosted word
   embeddings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Named entity recognition (NER); Deep neural network (DNN); Convolutional
   neural network (CNN); Bidirectional long short-term memory (bi-LSTM);
   Boosted word embeddings
AB The upcoming deep neural architectures overpower other previously proposed techniques for named entity recognition by involving fewer efforts but improving accuracy. In the present study, an important variant of recurrent neural network namely, a Bidirectional Long Short-Term Memory which is specially used for sequence classification problems has been used for the NER task. Word contextual features play an important role in the correct prediction of named entities. The present work contributes to developing novel word embeddings i.e. boosted word embeddings which can learn contextual features efficiently. Boosted word embeddings are the combination of character-based convolutional embeddings, part of speech embeddings, and word length embeddings. The results obtained using boosted word embeddings include f-score values of 73.99%, 66.94% and 77.95% respectively for Hindi, Punjabi and bilingual Hindi and Punjabi named entity recognition system. Boosted word embeddings are found effective in raising the accuracy of the named entity recognition model as compared to other models already present in the literature.
C1 [Goyal, Archana] Goswami Ganesh Dutta Sanatan Dharma Coll, Chandigarh, India.
   [Gupta, Vishal] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
   [Kumar, Manish] Panjab Univ Reg Ctr, Muktsar, Punjab, India.
C3 Goswami Ganesh Dutta S. D. College; Panjab University; Panjab University
RP Goyal, A (corresponding author), Goswami Ganesh Dutta Sanatan Dharma Coll, Chandigarh, India.
EM id.archana@yahoo.co.in
CR acure, About us
   Alfred Rayner, 2014, International Journal of Machine Learning and Computing, V4, P103, DOI 10.7763/IJMLC.2014.V4.428
   [Anonymous], 2017, INT C COMPUTATIONAL
   Bam SB., 2014, INTELLIGENT INFORM M, V6, P21, DOI DOI 10.4236/IIM.2014.62004
   Bharati A, 2007, SSF SHAKTI STANDARD, P1
   bitbucket, About Us
   Chen YK, 2015, J BIOMED INFORM, V58, P11, DOI 10.1016/j.jbi.2015.09.010
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3015467
   Ekbal A, 2008, P IJCNLP 08 WORKSH N, P33
   Gangadharan Veena, 2020, Procedia Computer Science, V171, P1337, DOI 10.1016/j.procs.2020.04.143
   Goyal A, 2021, KNOWL-BASED SYST, V234, DOI 10.1016/j.knosys.2021.107601
   Goyal A, 2019, COMM COM INF SC, V1075, P184, DOI 10.1007/978-981-15-0108-1_18
   Goyal AK, 2022, INDIAN J OTOLARYNGOL, V74, P2912, DOI 10.1007/s12070-021-02545-5
   Gupta PK, 2009, P ASCNT 2009, P103
   learnpunjabi, PUNJ POS TAGG
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nasar Z, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3445965
   Saha SK, 2012, KNOWL-BASED SYST, V27, P322, DOI 10.1016/j.knosys.2011.09.015
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195
   Schweter S, 2020, ARXIV
   Shaalan K, 2009, J AM SOC INF SCI TEC, V60, P1652, DOI 10.1002/asi.21090
   Shah B, 2019, ARXIV
   Sharma R, 2011, COMM COM INF SC, V139, P31
   Sharma R, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101356
   Shelke R., 2020, INT J NAT LANG COMPU, V9, P1, DOI [10.5121/ijnlc.2020.9201, DOI 10.5121/IJNLC.2020.9201]
   Tan Z., 2021, P 30 INT JOINT C ART, P3936, DOI [10.24963/ijcai.2021/542, DOI 10.24963/IJCAI.2021/542]
   Hanh TTH, 2021, LECT NOTES COMPUT SC, V13133, P264, DOI 10.1007/978-3-030-91669-5_21
   Vishal G., 2011, International Journal of Computer Applications, V33, P28
NR 29
TC 0
Z9 0
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15533
EP 15546
DI 10.1007/s11042-023-16176-1
EA JUL 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001026771300002
DA 2024-07-18
ER

PT J
AU Kalla, J
   Punia, P
   Dutta, T
   Biswas, S
AF Kalla, Jayateja
   Punia, Prishruit
   Dutta, Titir
   Biswas, Soma
TI Generalized semi-supervised class incremental learning in presence of
   outliers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Class-incremental learning; Semi-supervised learning; Selective
   pseudo-labelling
AB In this work, we focus on addressing the challenging real-world problem of generalized semi-supervised class-incremental learning (GSS-CIL), which has received relatively little attention in the research community. This involves having a limited number of labeled samples from the new classes at each incremental step, along with a large number of unlabeled samples from these new-classes, previously seen (older-tasks) or completely unseen classes (outliers). Our contributions are three-fold: Firstly, we provide a comprehensive definition and motivation of the GSS-CIL protocol and evaluate the performance of existing state-of-the-art class incremental learning (CIL) methods under this protocol. Secondly, we propose a simple yet effective framework called the Expert-Suggested Pseudo-labelling Network (ESPN) to tackle the GSS-CIL problem by leveraging the information contained in the unlabeled training data. Finally, we use task-wise Harmonic Mean as an additional evaluation metric to capture performance on both new and older tasks. We conduct extensive experiments on three standard large-scale datasets to demonstrate the effectiveness of our proposed ESPN approach, which can serve as a strong baseline for future research in this challenging real-world scenario.
C1 [Kalla, Jayateja; Punia, Prishruit; Dutta, Titir; Biswas, Soma] Indian Inst Sci, Dept Elect Engn, Bangalore 560012, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Biswas, S (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, India.
EM jayatejak@iisc.ac.in; prishruitpunia@iisc.ac.in; titird@iisc.ac.in;
   somabiswas@iisc.ac.in
FU SERB, Government of India
FX This work was partially funded by SERB, Government of India.
CR Abati D, 2020, PROC CVPR IEEE, P3930, DOI 10.1109/CVPR42600.2020.00399
   Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Belouadah E, 2019, IEEE I CONF COMP VIS, P583, DOI 10.1109/ICCV.2019.00067
   Berthelot D, 2021, ARXIV
   Berthelot D, 2019, ADV NEUR IN, V32
   Bhat SD, 2021, BRIT MACH VIS C
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Cheraghian A, 2021, PROC CVPR IEEE, P2534, DOI 10.1109/CVPR46437.2021.00256
   Dean J., 2015, NIPS DEEP LEARNING R
   Dhar P, 2019, PROC CVPR IEEE, P5133, DOI 10.1109/CVPR.2019.00528
   Douillard Arthur, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P86, DOI 10.1007/978-3-030-58565-5_6
   Guo LZ, 2020, PR MACH LEARN RES, V119
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Kalla J, 2022, LECT NOTES COMPUT SC, V13685, P432, DOI 10.1007/978-3-031-19806-9_25
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Komodakis N, 2018, INT C LEARN REPRESEN
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A, 2020, ADV NEURAL INFORM PR
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Mallya A, 2018, LECT NOTES COMPUT SC, V11208, P72, DOI 10.1007/978-3-030-01225-0_5
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Paszke A, 2019, ADV NEUR IN, V32
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Rusu A.A., 2016, ARXIV
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang LY, 2021, PROC CVPR IEEE, P5379, DOI 10.1109/CVPR46437.2021.00534
   Wang YH, 2022, LECT NOTES COMPUT SC, V13437, P431, DOI 10.1007/978-3-031-16449-1_41
   Wu Y, 2019, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.2019.00046
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xiaoyu Tao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12180, DOI 10.1109/CVPR42600.2020.01220
   Yoon J., 2017, arXiv
   Yu L, 2020, PROC CVPR IEEE, P6980, DOI 10.1109/CVPR42600.2020.00701
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang B, 2021, ADV NEURAL INF PROCE, V34, P18408
   Zhang C, 2021, PROC CVPR IEEE, P12450, DOI 10.1109/CVPR46437.2021.01227
   Zheng MK, 2022, PROC CVPR IEEE, P14451, DOI 10.1109/CVPR52688.2022.01407
   Zhu Fei, 2021, Advances in Neural Information Processing Systems, V34, P2
NR 42
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13707
EP 13723
DI 10.1007/s11042-023-15975-w
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025717900004
DA 2024-07-18
ER

PT J
AU Li, AN
   Ma, XN
   Guo, JX
   Zhang, JY
   Wang, J
   Zhao, K
   Li, YC
AF Li, Anna
   Ma, Xinnan
   Guo, Jiaxin
   Zhang, Jingyue
   Wang, Jing
   Zhao, Kai
   Li, Yaochen
TI Driver fatigue detection and human-machine cooperative decision-making
   for road scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fatigue detection; Human-machine Collaborative Decision-making;
   DenseNet; Guided policy search
ID NEURAL-NETWORK
AB Driver fatigue detection and human-machine cooperative decision-making are key issues in intelligent transportation systems. The proposed method consists of two main stages.In the first stage, we propose an improved DenseNet-based method for driver fatigue detection. We propose a model representation enhancement module to improve the model's adaptability to multi-scale features. Additionally, we propose an improved channel attention mechanism to enhance channel dependencies and spatial encoding capabilities. In the second stage, we propose a human-machine collaborative decision-making method based on guided policy search (GPS). Our method utilizes a reinforcement learning algorithm based on actor-critic and design an improved actor network based on the iLQR-based GPS. Finally, we propose an adaptive module that enables the vehicle to make decisions based on the driver's fatigue state. The effectiveness of the proposed method is demonstrated through experimental results and comparisons.
C1 [Li, Anna; Ma, Xinnan; Guo, Jiaxin; Zhang, Jingyue; Wang, Jing; Zhao, Kai; Li, Yaochen] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, YC (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
EM yaochenli@mail.xjtu.edu.cn
RI Wang, zhenhua/KFA-8731-2024; zhang, jiahao/KEE-9357-2024; Zhang,
   Lijuan/KAM-0174-2024; zhang, xiaoyu/KEJ-0657-2024; Lu, Yi/KEJ-2560-2024;
   xu, liu/KCL-1154-2024; SUN, YANLING/JTT-9082-2023; Yun,
   Wang/KHM-3009-2024; wang, wenjing/KEH-0575-2024; Qi, Ling/KHE-3068-2024;
   Yang, Ning/KHD-1133-2024; Yuan, Ye/KBC-9835-2024
OI Yuan, Ye/0009-0008-1640-7047
FU Key Research and Development Plan of Shaanxi Province (China)
   [2022GY-080]
FX AcknowledgementsThis work is supported by Key Research and Development
   Plan of Shaanxi Province (China) under grant no. 2022GY-080.
CR Alioua N., 2014, International journal of vehicular technology, V2014, P1, DOI [10.1155/2014/678786, DOI 10.1155/2014/678786]
   Chen JY, 2018, IEEE INT VEH SYM, P1239, DOI 10.1109/IVS.2018.8500368
   Choi IH, 2014, INT CONF BIG DATA, P241, DOI 10.1109/BIGCOMP.2014.6741444
   Ghourabi A, 2020, INT C INTELL COMP CO, P407, DOI [10.1109/iccp51029.2020.9266160, 10.1109/ICCP51029.2020.9266160]
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Guo Wen, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1982/1/012067
   Kendall A, 2019, IEEE INT CONF ROBOT, P8248, DOI [10.1109/ICRA.2019.8793742, 10.1109/icra.2019.8793742]
   Li G, 2013, SENSORS-BASEL, V13, P16494, DOI 10.3390/s131216494
   Li Y, 2019, ASSEMBLY AUTOM
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Mandal B, 2017, IEEE T INTELL TRANSP, V18, P545, DOI 10.1109/TITS.2016.2582900
   Mania H., 2018, ADV NEURAL INFORM PR, V31, P2746
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Peng KY, 2022, IEEE T INTELL TRANSP, V23, P15824, DOI 10.1109/TITS.2022.3145588
   Pomerleau DA., 1989, ADV NEURAL INFORM PR, V1, P305
   Shah S, 2018, FIELD SERVICE ROBOTI, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40]
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Vu TH, 2019, IEICE T INF SYST, VE102D, P2637, DOI 10.1587/transinf.2019EDL8079
   Wolf P, 2017, IEEE INT VEH SYM, P244, DOI 10.1109/IVS.2017.7995727
   Wu J., 2021, ARXIV
   Xie YQ, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P532, DOI 10.1109/SSCI.2018.8628881
   Yang H, 2021, IEEE T MULTIMEDIA, V23, P572, DOI 10.1109/TMM.2020.2985536
   Zhao L, 2020, MULTIMED TOOLS APPL, V79, P26683, DOI 10.1007/s11042-020-09259-w
NR 23
TC 1
Z9 1
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12487
EP 12518
DI 10.1007/s11042-023-15994-7
EA JUL 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800007
DA 2024-07-18
ER

PT J
AU Yang, GM
   Zhang, SC
   Fang, XJ
   Zhang, J
AF Yang, Gaoming
   Zhang, Shicheng
   Fang, Xianjin
   Zhang, Ji
TI Pyramid style-attentional network for arbitrary style transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style transfer; Pyramid pooling; Self-attention; Image processing
AB At present, the self-attention mechanism represented by the non-local network has been applied in style transfer widely. Models can achieve good style transfer effects by considering long-range dependencies between content images and style images while well maintaining semantic content information. However, the self-attention mechanism has to calculate the relationship between all positions between the content feature maps and style feature maps. The associated computational complexity of the mechanism is rather high, which will consume a lot of computing resources and adversely impact the efficiency of style transfer of high-resolution images. To solve this problem, we propose a novel Pyramid Style-attentional Network (PSANet) to reduce the computational complexity of the self-attention network by using pyramid pooling on feature maps. We compare our method with the vanilla style-attentional network in terms of speed and quality. The experimental results show that our model can significantly reduce the computational complexity and achieve good transfer effects. Especially for handling high-resolution images, the execution time of our method can reduce by 34.7%.
C1 [Yang, Gaoming; Zhang, Shicheng; Fang, Xianjin] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan, Peoples R China.
   [Zhang, Ji] Univ Southern Queensland, Sch Math Phys & Comp, Darling Hts, Qld, Australia.
C3 Anhui University of Science & Technology; University of Southern
   Queensland
RP Fang, XJ (corresponding author), Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan, Peoples R China.
EM xjfang@aust.edu.cn
RI wang, shuo/KCL-3379-2024; xie, jing/KDO-9486-2024
OI fang, xian jin/0000-0002-3894-2007
FU Natural Science Foundation of Anhui Province of China [2008085MF220]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Anhui Province of China under Grant No. 2008085MF220.
CR Changqian Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P379, DOI 10.1007/978-3-030-58571-6_23
   Chen DD, 2021, IEEE T PATTERN ANAL, V43, P2373, DOI 10.1109/TPAMI.2020.2964205
   Chen T., 2016, ARXIV
   Deng YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2719, DOI 10.1145/3394171.3414015
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li XT, 2019, PROC CVPR IEEE, P3804, DOI 10.1109/CVPR.2019.00393
   Li YJ, 2017, ADV NEUR IN, V30
   Li ZX, 2020, MULTIMED TOOLS APPL, V79, P4347, DOI 10.1007/s11042-018-6929-x
   Lin TW, 2021, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR46437.2021.00510
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6629, DOI 10.1109/ICCV48922.2021.00658
   Liu SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6578, DOI 10.1109/ICCV48922.2021.00653
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Paszke A, 2019, ADV NEUR IN, V32
   Phillips F, 2011, ISS ACCOUNT EDUC, V26, P593, DOI 10.2308/iace-50038
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Virtusio JJ, 2021, IEEE T MULTIMEDIA, V23, P2245, DOI 10.1109/TMM.2021.3087026
   Wang P, 2021, PROC CVPR IEEE, P124, DOI 10.1109/CVPR46437.2021.00019
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZZ, 2020, IET COMPUT VIS, V14, P575, DOI 10.1049/iet-cvi.2019.0844
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu H, 2019, NEUROCOMPUTING, V370, P39, DOI 10.1016/j.neucom.2019.08.075
   Wu XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14598, DOI 10.1109/ICCV48922.2021.01435
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang YL, 2019, IEEE I CONF COMP VIS, P5942, DOI 10.1109/ICCV.2019.00604
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhizhong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7786, DOI 10.1109/CVPR42600.2020.00781
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 40
TC 0
Z9 0
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13483
EP 13502
DI 10.1007/s11042-023-15650-0
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800004
DA 2024-07-18
ER

PT J
AU Firdaus, M
   Madasu, A
   Ekbal, A
AF Firdaus, Mauajama
   Madasu, Avinash
   Ekbal, Asif
TI A Unified Framework for Slot based Response Generation in a Multimodal
   Dialogue System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conversational AI; Multimodal Dialogue System; Response Generation;
   DialoGPT
ID NETWORKS
AB Natural Language Understanding (NLU) and Natural Language Generation (NLG) are the two critical components of every conversational system that handles the task of understanding the user by capturing the necessary information in the form of slots and generating an appropriate response in accordance with the extracted information. Recently, dialogue systems integrated with complementary information such as images, audio, or video have gained immense popularity. In this work, we propose an end-to-end framework with the capability to extract necessary slot values from the utterance and generate a coherent response, thereby assisting the user to achieve their desired goals in a multimodal dialogue system having both textual and visual information. The task of extracting the necessary information is dependent not only on the text but also on the visual cues present in the dialogue. Similarly, for the generation, the previous dialog context comprising multimodal information is significant for providing coherent and informative responses. We employ a multimodal hierarchical encoder using pre-trained DialoGPT and also exploit the knowledge base (Kb) to provide a stronger context for both the tasks. Finally, we design a slot attention mechanism to focus on the necessary information in a given utterance. Lastly, a decoder generates the corresponding response for the given dialogue context and the extracted slot values. Experimental results on the Multimodal Dialogue Dataset (MMD) show that the proposed framework outperforms the baselines approaches in both the tasks.
C1 [Firdaus, Mauajama] Univ Alberta, Dept Comp Sci, Edmonton, AB T6T0S8, Canada.
   [Madasu, Avinash] Intel Labs, Cognit Comp Res, Santa Clara, CA 95054 USA.
   [Ekbal, Asif] Indian Inst Technol Patna, Comp Sci & Engn, Patna 801103, Bihar, India.
C3 University of Alberta; Intel Corporation; Indian Institute of Technology
   (IIT) - Patna; Indian Institute of Technology System (IIT System)
RP Firdaus, M (corresponding author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6T0S8, Canada.; Ekbal, A (corresponding author), Indian Inst Technol Patna, Comp Sci & Engn, Patna 801103, Bihar, India.
EM mauzama.03@gmail.com; avinashmadasu17@gmail.com; asif@iitp.ac.in
RI Ekbal, Asif/JKI-7638-2023
OI Firdaus, Mauajama/0000-0001-7485-5974
CR Agarwal S., 2018, ARXIV
   Akbari S, 2021, ADV NEUR IN, V34
   Alamri H, 2018, DSTC7 AAAI2019 WORKS, V2
   [Anonymous], 2019, DSTC7 AAAI2019 WORKS
   Budzianowski P., 2019, ARXIV
   Budzianowski Pawel, 2018, ARXIV
   Chauhan H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5437
   Chen M., 2019, ARXIV
   Chen W., 2020, PROC INT C LEARN REP
   Chen XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2687
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Cui C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P445, DOI 10.1145/3331184.3331226
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   Deng L, 2012, IEEE W SP LANG TECH, P210, DOI 10.1109/SLT.2012.6424224
   Deoras A, 2013, INTERSPEECH, P2712
   Doddington G., 2002, P 2 INT C HUM LANG T, P138
   Dongwook Lee, 2019, arXiv
   Firdaus M., 2020, IEEE Transactions on Affective Computing
   Firdaus M, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2318
   Firdaus M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241271
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gan Z, 2019, ARXIV
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Herdade S, 2019, ADV NEUR IN, V32
   Huang PP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3595
   Ju D., 2019, ARXIV
   Kaisheng Yao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4077, DOI 10.1109/ICASSP.2014.6854368
   Lan OY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6049, DOI 10.1109/ICASSP.2018.8462669
   Le H., 2019, ARXIV
   Li X., 2020, P EUR C COMP VIS, DOI DOI 10.1007/978-3-030-58577-8_8
   Li X., 2017, arXiv
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin K.Y., 2019, ARXIV
   Lin Z., 2019, arXiv
   Liu B., 2017, arXiv
   Loshchilov I., 2018, arXiv
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Madotto A., 2018, ARXIV
   Mesnil G, 2013, INTERSPEECH, P3738
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   Mi F., 2019, ARXIV
   Moon S., 2020, ARXIV
   Mostafazadeh N., 2017, ARXIV
   Nie LQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1098, DOI 10.1145/3343031.3350923
   Niu P, 2019, ARXIV
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Peng B., 2018, ARXIV
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qian K., 2019, ARXIV
   Qin L, 2020, ARXIV
   Qiu L., 2018, ARXIV
   Radford A., 2019, LANGUAGE MODELS ARE
   Raghu D., 2018, ARXIV
   Raghu Dinesh, HIERARCHICAL POINTER
   Rastogi A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P561, DOI 10.1109/ASRU.2017.8268986
   Reddi SJ, 2019, ARXIV
   Reddy R., 2018, ARXIV
   Saha A, 2018, AAAI CONF ARTIF INTE, P696
   Serban I.V., 2015, HIERARCHICAL NEURAL, V7, P434
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3295
   Shang L., 2015, ARXIV
   Shin Y, 2018, INTERSPEECH, P2082
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sordoni A., 2015, ARXIV
   Sordoni Alessandro, 2015, A hierarchical recurrent encoder-decoder for generative context-aware query suggestion, P553
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su S.Y., 2019, ARXIV
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan HH, 2019, arXiv
   Tian ZL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3816
   Tseng B.H., 2020, ARXIV
   Vinyals O., 2015, ICLR
   Wang J, 2020, AAAI CONF ARTIF INTE, V34, P9169
   Weidong He, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2755, DOI 10.1145/3394171.3413679
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.2307/2332510
   Wen T.H., 2016, ARXIV
   Williams K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES(NAACL HLT 2019), VOL. 2 (INDUSTRY PAPERS), P83
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu C, 2019, ARXIV
   Wu JX, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2018), P22, DOI 10.1109/BIGCOM.2018.00010
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xia C., 2018, ARXIV
   Xu HT, 2020, WORLD WIDE WEB, V23, P1989, DOI 10.1007/s11280-019-00688-8
   Yao KS, 2013, INTERSPEECH, P2523
   Yao KS, 2014, IEEE W SP LANG TECH, P189, DOI 10.1109/SLT.2014.7078572
   Zhang Y., 2019, arXiv
   Zhang Z, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2401, DOI 10.1145/3308558.3313598
   Zhao L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P426
   Zhao S., 2019, arXiv
   Zhong V., 2018, ARXIV
   Zhu CG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1261
   Zhu S., 2017, ARXIV
   Zhu S, 2017, INT CONF ACOUST SPEE, P5675, DOI 10.1109/ICASSP.2017.7953243
NR 96
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11643
EP 11667
DI 10.1007/s11042-023-15915-8
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU El Habouz, Y
   El Mourabit, Y
   Iggane, M
   El Habouz, H
   Lukumon, G
   Nouboud, F
AF El Habouz, Youssef
   El Mourabit, Yousef
   Iggane, Mbark
   El Habouz, Hammou
   Lukumon, Gafari
   Nouboud, Fathallah
TI Efficient semi-supervised learning model for limited otolith data using
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Otoliths Classification; Semi-supervised Classification; Generative
   Adversarial Networks; Shape recognition
ID SHAPE-ANALYSIS; MORPHOLOGY
AB Otolith shape recognition is one of the relevant tool to ensure the sustainability of maritime resources. It is used to study taxonomy, age estimation and discrimination of stocks of fish species. The most performant otolith image classification models are based on convolutional neural network approaches. To build an efficient system, these models require a large number of labeled images, which is hard to obtain. The lack of data became a big challenge, and a real problem of otolith images classification models, it causes the over-fitting issue, which is the main trouble of deep convolutional neural network based models. In this paper, we present a relevant solution for the insufficiency of data. We propose a new semi-supervised classification model based on generative adversarial network. Our results showed that the model is more efficient and also perform better than convolutional neural network system even with a small training dataset. With this efficiency and performance, we found in addition that the accuracy of the model reached 80% on training set of say, 75 images compared to other models such as a convolutional neural network model which accuracy is limited to 60%.
C1 [El Habouz, Youssef] Rennes 1 Univ, IGDR, Rennes, France.
   [El Mourabit, Yousef] Sultan Moulay SLimane Univ, Sci & Technol Fac, TIAD Lab, Beni Mellal, Morocco.
   [Iggane, Mbark] IBN ZOHR Univ, IRF SIC, Agadir, Morocco.
   [El Habouz, Hammou] INRH, Agadir, Morocco.
   [Lukumon, Gafari] Mohammed VI Polytech, Sch Collect Intelligence, Ben Guerir, Morocco.
   [Nouboud, Fathallah] UQTR Univ, LIRIC, Trois Rivieres, PQ, Canada.
C3 Universite de Rennes; Sultan Moulay Slimane University of Beni Mellal;
   Ibn Zohr University of Agadir; Mohammed VI Polytechnic University
RP El Habouz, Y (corresponding author), Rennes 1 Univ, IGDR, Rennes, France.
EM youssef.elhabouz@univ-rennes1.fr
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abu-Mostafa YS, 1989, NEURAL COMPUT, V1, P312, DOI 10.1162/neco.1989.1.3.312
   [Anonymous], 2017, ADV NEURAL INFORM PR
   Bose APH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69701-9
   Bryant JM, 2019, TRIBUTE UNDERWORLD H
   CAMPANA SE, 1993, CAN J FISH AQUAT SCI, V50, P1062, DOI 10.1139/f93-123
   Cerda JM, 2021, J SEA RES, V173, DOI 10.1016/j.seares.2021.102063
   Chollet F, 2015, KERAS
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Ding LY, 2019, ECOL FRESHW FISH, V28, P132, DOI 10.1111/eff.12437
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   El Habouz Y, 2018, INT J IMAG ROBOT, V18
   Ghanbarifardi M, 2021, IRAN J FISH SCI, V20, P333, DOI 10.22092/ijfs.2021.123784
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harbitz A, 2015, ICES J MAR SCI
   Jónsdóttir IG, 2006, ICES J MAR SCI, V63, P1501, DOI 10.1016/j.icesjms.2006.05.006
   Keating JP, 2014, FISH RES, V157, P1, DOI 10.1016/j.fishres.2014.03.009
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Li H., 2018, ARXIV
   LOMBARTE A, 1993, ENVIRON BIOL FISH, V37, P297, DOI 10.1007/BF00004637
   Mahé K, 2019, ICES J MAR SCI, V76, P232, DOI 10.1093/icesjms/fsy163
   Moreira C, 2019, FISH RES, V209, P40, DOI 10.1016/j.fishres.2018.09.010
   Nasreddine K, 2009, FISH RES, V98, P8, DOI 10.1016/j.fishres.2009.03.008
   Neves J, 2021, FISH RES, V243, DOI 10.1016/j.fishres.2021.106050
   Odena A, 2016, ARXIV
   Odena A, 2017, PR MACH LEARN RES, V70
   Panfili J., 2002, MANUAL FISH SCLEROCH
   Pavlov DA, 2021, J ICHTHYOL+, V61, P33, DOI 10.1134/S0032945221010100
   Platt C., 1981, P LIFE SCI, P3
   Popper AN, 2000, FISH RES, V46, P15, DOI 10.1016/S0165-7836(00)00129-6
   Reichenbacher B, 2009, PALAEOGEOGR PALAEOCL, V281, P43, DOI 10.1016/j.palaeo.2009.07.008
   Reig-Bolaño R, 2010, ADV INTEL SOFT COMPU, V79, P9
   Rubin M, 2019, MED IMAGE ANAL, V57, P176, DOI 10.1016/j.media.2019.06.014
   Sadeghi P, 2019, MAR POLLUT BULL, V140, P248, DOI 10.1016/j.marpolbul.2019.01.048
   Schmidt W., 1969, P393
   Schulz-Mirbach T, 2019, BIOL REV, V94, P457, DOI 10.1111/brv.12463
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025
   Youssef El Habouz, 2016, Journal of Theoretical and Applied Information Technology, V84, P19
   Youssef EH, 2016, LECT NOTES COMPUT SC, V9680, P30, DOI 10.1007/978-3-319-33618-3_4
NR 40
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11909
EP 11922
DI 10.1007/s11042-023-16007-3
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900017
DA 2024-07-18
ER

PT J
AU Che, ML
   Wu, ZH
   Wang, XW
   Zhang, C
   Yang, F
AF Che, Mingliang
   Wu, Zhenhua
   Wang, Xiaowen
   Zhang, Chi
   Yang, Fan
TI Designing lightweight small object detection models using attention and
   context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Attention mechanism; Contextual
   information; Lightweight; Small object detection
AB Existing deep learning models have made some progress in improving detection accuracy for small objects, but there remains much work to be done in coordinating the practical factors involved in real object detection: accuracy, running time, model parameters and complexity. In this study, we designed multiple lightweight models and evaluated their detection performance by constructing a lightweight backbone network and embedding different combinations of attention and context modules. The results show that 1) The introduction of an attention mechanism and context information into the backbone network helps to improve the detection accuracy of the model for small objects, but the degree of improvement varies depending on the structure of the model. 2) The introduction of a context fusion network is more helpful for improving the detection performance than the introduction of an attention module. 3) The joint use of an attention mechanism and contextual information requires careful consideration of the model structure. Moreover, the designed models are lightweight. This makes the program very fast when reading and writing the parameter file. The feedforward time of the model is very short.
C1 [Che, Mingliang; Zhang, Chi; Yang, Fan] Nantong Univ, Coll Geog Sci, Nantong Key Lab Spatial Informat Technol R&D & App, Nantong 226019, Peoples R China.
   [Che, Mingliang; Yang, Fan] Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.
   [Che, Mingliang; Zhang, Chi; Yang, Fan] Jiangsu Yangtze River Econ Belt Res Inst, Nantong 226019, Peoples R China.
   [Wu, Zhenhua] China Univ Min & Technol, Sch Econ & Management, Xuzhou 221116, Peoples R China.
   [Wang, Xiaowen] Nantong Urban Planning & Design Inst Co Ltd, Nantong 226004, Peoples R China.
C3 Nantong University; Ministry of Natural Resources of the People's
   Republic of China; China University of Mining & Technology
RP Che, ML (corresponding author), Nantong Univ, Coll Geog Sci, Nantong Key Lab Spatial Informat Technol R&D & App, Nantong 226019, Peoples R China.; Che, ML (corresponding author), Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.; Che, ML (corresponding author), Jiangsu Yangtze River Econ Belt Res Inst, Nantong 226019, Peoples R China.
EM dawnche@163.com; wuzhenhua@cumt.edu.cn; shuchangs@126.com;
   benz1983@163.com; yhlx125@ntu.edu.cn
RI Yang, Fan/GRJ-6470-2022; Wang, Xiao-Wen/HTL-3465-2023; Wu,
   Zhenhua/ABB-7053-2021
OI Wang, Xiao-Wen/0000-0002-0543-2537; Che, Mingliang/0000-0002-6388-1744
FU Open Fund of Key Laboratory of Urban Land Resources Monitoring and
   Simulation, Ministry of Natural Resources [KF-2021-06-022]; Fundamental
   Research Funds for the Central Universities of China University of
   Mining and Technology [2021QN1058]; Project of Nantong Science and
   Technology Bureau [JC2020174]; Project of Taizhou Natural Resources and
   Planning Bureau [JSJWZBDL2020-62]; Nantong Key Laboratory Project
   [CP12016005]
FX This research is supported by the Open Fund of Key Laboratory of Urban
   Land Resources Monitoring and Simulation, Ministry of Natural Resources
   (No. KF-2021-06-022), Fundamental Research Funds for the Central
   Universities of China University of Mining and Technology (No.
   2021QN1058), Project of Nantong Science and Technology Bureau (No.
   JC2020174), Project of Taizhou Natural Resources and Planning Bureau
   (No. JSJWZBDL2020-62), and Nantong Key Laboratory Project (No.
   CP12016005). We thank Dr. B. Chen for providing the rain grate dataset.
   We thank Dr. J. Zhang for his technical support in data processing.
CR [Anonymous], 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.683
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Castellano Giovanna, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12538), P588, DOI 10.1007/978-3-030-66823-5_35
   Che ML, 2020, COMPUT INFORM, V39, P439, DOI 10.31577/cai_2020_3_439
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Everaert M., 2012, The Theta System: Argument Structure at the Interface, P1, DOI [10.1093/acprof:oso/9780199602513.001.0001, DOI 10.1093/ACPROF:OSO/9780199602513.001.0001]
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kisantal M., 2019, P CS IT C, V9, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lim J-S, 2019, 2021 INT C ART INT I, P4321
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Qin PL, 2019, MULTIMED TOOLS APPL, V78, P913, DOI 10.1007/s11042-018-5870-3
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Yan JJ, 2015, PROC CVPR IEEE, P5107, DOI 10.1109/CVPR.2015.7299146
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhang YQ, 2020, INT J COMPUT VISION, V128, P1810, DOI 10.1007/s11263-020-01301-6
NR 32
TC 0
Z9 0
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9523
EP 9546
DI 10.1007/s11042-023-15847-3
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600005
DA 2024-07-18
ER

PT J
AU Dhasarathan, C
   Shanmugam, M
   Kumar, M
   Tripathi, D
   Khapre, S
   Shankar, A
AF Dhasarathan, Chandramohan
   Shanmugam, M.
   Kumar, Manish
   Tripathi, Diwakar
   Khapre, Shailesh
   Shankar, Achyut
TI A nomadic multi-agent based privacy metrics for e-health care: a deep
   learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy Preserving; Deep learning system; Multi-Agent; Knowledgebase;
   Security
ID SCHEME; EFFICIENT; PUBLICATION; CLOUD
AB In recent years, there has been a surge in the use of deep learning systems for e-healthcare applications. While these systems can provide significant benefits regarding improved diagnosis and treatment, they also pose substantial privacy risks to patients' sensitive data. Privacy is a crucial issue in e-healthcare, and it is essential to keep patient information secure. A new approach based on multi-agent-based privacy metrics for e-healthcare deep learning systems has been proposed to address this issue. This approach uses a combination of deep learning and multi-agent systems to provide a more robust and secure method for e-healthcare applications. The multi-agent system is designed to monitor and control the access to patients' data by different agents in the system. Each agent is assigned a specific role and has specific data access permissions. The system employs a set of privacy metrics to a substantial privacy level of the data accessed by each agent. These metrics include confidentiality, integrity, and availability, evaluated in real-time and used to identify potential privacy violations. In addition to the multi-agent system, the deep learning component is also integrated into the system to improve the accuracy of diagnoses and treatment plans. The deep learning model is trained on a large dataset of medical records and can accurately predict the diagnosis and treatment plan based on the patient's symptoms and medical history. The multi-agent-based privacy metrics for the e-healthcare deep learning system approach have several advantages. It provides a more secure system for e-healthcare applications by ensuring only authorized agents can access patients' data. Privacy metrics enable the system to identify potential privacy violations in real-time, thereby reducing the risk of data breaches. Finally, integrating deep learning improves the accuracy of diagnoses and treatment plans, leading to better patient outcomes.
C1 [Dhasarathan, Chandramohan; Kumar, Manish] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Shanmugam, M.] Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
   [Tripathi, Diwakar] Indian Inst Informat Technol, Comp Sci & Engn Dept, Sonepat, Hariyana, India.
   [Khapre, Shailesh] Dr SP Mukherjee IIIT, Dept Data Sci & Artificial Intelligence, Naya Raipur, Chhattisgarh, India.
   [Shankar, Achyut] Univ Warwick, WMG, Coventry, England.
   [Shankar, Achyut] Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun 248002, India.
   [Shankar, Achyut] Lovely Profess Univ, Sch Comp Sci Engn, Phagwara 144411, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Pondicherry University;
   University of Warwick; Graphic Era University; Lovely Professional
   University
RP Shankar, A (corresponding author), Univ Warwick, WMG, Coventry, England.; Shankar, A (corresponding author), Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun 248002, India.; Shankar, A (corresponding author), Lovely Profess Univ, Sch Comp Sci Engn, Phagwara 144411, Punjab, India.
EM pdchandramohan@gmail.com; shaninfo247@gmail.com; mk9309@gmail.com;
   diwakarnitgoa@gmail.com; shailesh@iiitnr.edu.in; ashankar2711@gmail.com
RI DHASARATHAN, CHANDRAMOHAN/E-3555-2015
OI DHASARATHAN, CHANDRAMOHAN/0000-0002-5279-950X; Shankar,
   Achyut/0000-0003-3165-3293
CR Alam GR, 2018, J PARALLEL DISTR COM, P1
   Alcaraz J.J., 2014, SELECTED AREAS COMMU, V32, P488
   Alguliyev RM, 2019, J IND INF INTEGR, V15, P1, DOI 10.1016/j.jii.2019.07.002
   Benharref A, 2014, IEEE J BIOMED HEALTH, V18, P46, DOI 10.1109/JBHI.2013.2262659
   Bewong M, 2019, INFORM SYST, V82, P53, DOI 10.1016/j.is.2019.01.001
   Boussada R, 2019, COMPUT NETW, V162, DOI 10.1016/j.comnet.2019.106866
   Chamikara MAP, 2019, COMPUT SECUR, V87, DOI 10.1016/j.cose.2019.101570
   Chandramohan D, 2014, INT J MODEL SIMUL SC, V5, DOI [10.1109/MPUL.2014.2355298, 10.1142/S1793962313500165]
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Clementi A, 2013, IEEE ACM T NETWORK, V21, P610, DOI 10.1109/TNET.2012.2204407
   D'Agostino D, 2019, FUTURE GENER COMP SY, V90, P79, DOI 10.1016/j.future.2018.07.036
   Deng ZL, 2019, J INF SECUR APPL, V47, P120, DOI 10.1016/j.jisa.2019.04.011
   Dhasarathan C, 2023, COMPUT COMMUN, V199, P87, DOI 10.1016/j.comcom.2022.12.004
   Dhasarathan C, 2021, J SUPERCOMPUT, V77, P11099, DOI 10.1007/s11227-021-03720-9
   Dhasarathan C, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.32
   Dhasarathan C, 2015, EGYPT INFORM J, V16, P151, DOI 10.1016/j.eij.2015.02.002
   Ding XF, 2019, INFORM SCIENCES, V493, P20, DOI 10.1016/j.ins.2019.03.035
   Groba C, 2014, IEEE T SERV COMPUT, V7, P642, DOI 10.1109/TSC.2013.2295811
   Guo SW, 2019, SIGNAL PROCESS, V164, P320, DOI 10.1016/j.sigpro.2019.06.024
   Gupta P, 2013, IEEE T COMPUT AID D, V32, P8, DOI 10.1109/TCAD.2012.2223467
   Hackmann G., 2010, P 1 ACMIEEE INT C CY, P119, DOI [10.1145/1795194.1795211, DOI 10.1145/1795194.1795211]
   Hu L, 2019, FUTURE GENER COMP SY, V90, P569, DOI 10.1016/j.future.2018.08.006
   Josh Wall, 2011, PERVASIVE COMPUT IEE, V10, P58
   Kang QM, 2013, INTELL AUTOM SOFT CO, V19, P69, DOI 10.1080/10798587.2013.771438
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kumar SA, 2019, ICT EXPRESS, V5, P266, DOI 10.1016/j.icte.2018.03.003
   Li DM, 2019, J INF SECUR APPL, V47, P59, DOI 10.1016/j.jisa.2019.03.020
   Li SX, 2019, COMPUT SECUR, V84, P17, DOI 10.1016/j.cose.2019.03.008
   Li YC, 2019, NEUROCOMPUTING, V363, P212, DOI 10.1016/j.neucom.2019.07.039
   Lopes F, 2014, INT J PARALLEL EMERG, V29, P178, DOI 10.1080/17445760.2013.831415
   Ma ZR, 2019, INFORM SCIENCES, V496, P225, DOI 10.1016/j.ins.2019.05.025
   Mehta NB, 2013, IEEE T COMMUN, V61, P2735, DOI 10.1109/TCOMM.2013.043013.120517
   Nobre J, 2018, VEHICULAR SOFTWARE D, P1
   Puri V, 2019, COMPUT SCI REV, V32, P45, DOI 10.1016/j.cosrev.2019.02.001
   Rahman MS, 2019, KNOWL-BASED SYST, V180, P104, DOI 10.1016/j.knosys.2019.05.022
   Rashidibajgan S, 2019, COMPUT SECUR, V84, P244, DOI 10.1016/j.cose.2019.03.020
   Sajjad H, 2019, COMPUT SECUR, V86, P358, DOI 10.1016/j.cose.2019.06.017
   Shen H, 2019, J SYST ARCHITECT, V97, P130, DOI 10.1016/j.sysarc.2019.01.005
   Singh C, 2012, IEEE ACM T NETWORK, V20, P69, DOI 10.1109/TNET.2011.2159735
   Uchiyama A, 2013, IEEE T MOBILE COMPUT, V12, P1009, DOI 10.1109/TMC.2012.86
   Verba N, 2018, FUTURE GENER COMP SY, P1
   Wang GM, 2019, J INF SECUR APPL, V46, P271, DOI 10.1016/j.jisa.2019.03.009
   Wang SL, 2013, IEEE J SEL AREA COMM, V31, P369, DOI 10.1109/JSAC.2013.SUP.0513033
   Wang ZH, 2011, IEEE COMMUN LETT, V15, P1184, DOI 10.1109/LCOMM.2011.092011.111200
   Xiao MJ, 2014, IEEE T COMPUT, V63, P1682, DOI 10.1109/TC.2013.55
   Yang TF, 2019, INFORM SCIENCES, V505, P198, DOI 10.1016/j.ins.2019.07.078
   Yargic A, 2019, INFORM PROCESS MANAG, V56, P994, DOI 10.1016/j.ipm.2019.02.009
   Zhang Q, 2019, INFORM SCIENCES, V480, P1, DOI 10.1016/j.ins.2018.12.016
   Zheng X, 2019, INFORM SCIENCES, V493, P91, DOI 10.1016/j.ins.2019.04.036
   Zhong H, 2019, INFORM SCIENCES, V476, P211, DOI 10.1016/j.ins.2018.10.021
   Zhou YS, 2019, J INF SECUR APPL, V47, P295, DOI 10.1016/j.jisa.2019.05.018
NR 51
TC 9
Z9 9
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7249
EP 7272
DI 10.1007/s11042-023-15363-4
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600004
PM 37362729
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ghandour, C
   El-Shafai, W
   El-Rabaie, EM
   Elshazly, EA
AF Ghandour, C.
   El-Shafai, Walid
   El-Rabaie, El-Sayed M.
   Elshazly, E. A.
TI Applying medical image fusion based on a simple deep learning principal
   component analysis network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image applications; MFMI; PCA filters; PCANET; Nuclear norm
ID CHALLENGES
AB Deep learning model training is known to be difficult and time-consuming. The principal component analysis network (PCANET) is a reasonably straightforward deep learning model that we use in this study to extract medical image features from multi-focus medical images (MFMI). The medical input images are divided into image features using a PCA filter, and activity level maps are constructed using the nuclear norm. This work applies nuclear norm and PCANET to build a usable feature space for medical image fusion. Particularly, the extracted PCANET characteristics can perform similarly to a convolutional neural network (CNN). Eventually, the final decision map (FDM) is assessed using the focus score map (FSM) produced by post-processing activities. The fused image is created by merging the two input medical images together using FDM. The PCANET features that are extracted in particular, can perform like a CNN-based network. According to the experimental outcomes, the findings of the fusion can better preserve the crucial data in the source images. This study shows the appearance of PCANET for a superior performance regarding the medical image fusion and good restoration quality. It also accomplishes the superior average values: AG of 8.419538, EI of 86.33734, and MI of 3.112971 for the SET1 (MRI and CT), in addition to the Q(AB/F) superior average values of 0.68963 for the SET 2 (MRI and SPECT). Finally, the Q(CB) superior average values of 0.754868, Q(CV) of 157.9377, and SF of 26.02398 are accomplished for the SET 3 (MRI and PET).
C1 [Ghandour, C.; El-Shafai, Walid; El-Rabaie, El-Sayed M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Ghandour, C.] Int Acad Engn & Media Sci IAEMS, Fac Engn, Dept Elect & Elect Commun Engn, Cairo, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [Elshazly, E. A.] Egyptian Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Prince Sultan
   University; Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy
   Authority (EAEA)
RP Ghandour, C (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.; Ghandour, C (corresponding author), Int Acad Engn & Media Sci IAEMS, Fac Engn, Dept Elect & Elect Commun Engn, Cairo, Egypt.
EM christ.ghandour@yahoo.com; eng.waled.elshafai@gmail.com;
   elsayedelrabaie@gmail.com; eaeshazly@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120
FU Prince Sultan University
FX The authors are very grateful to all the institutions in the affiliation
   list for successfully performing this research work. The authors would
   like to thank Prince Sultan University for their support.
CR Alseelawi N, 2022, INT J ONLINE BIOMED, V18, P114, DOI 10.3991/ijoe.v18i03.28011
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Ghandour C., 2021, 2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC), P159, DOI 10.1109/JAC-ECC54461.2021.9691453
   Ghandour C., 2021, 2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC), P164, DOI 10.1109/JAC-ECC54461.2021.9691439
   Guo K, 2022, MMFGAN NOVEL MULTIMO, V81
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kaur M, 2020, CLUSTER COMPUT, V23, P1439, DOI 10.1007/s10586-019-02999-x
   Khalil A, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.037001
   Khalil A, 2017, MED BIOL ENG COMPUT, V55, P1317, DOI 10.1007/s11517-016-1594-6
   Kong WW, 2019, IEEE T INSTRUM MEAS, V68, P938, DOI 10.1109/TIM.2018.2865046
   Lepcha DC, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.015
   Li H, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103039
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Liu YY, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.101996
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Maqsood S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101810
   Rahimi A, 2022, CURR MED IMAGING, V18, P61, DOI 10.2174/1573405617666210825155659
   SivaSai JG, 2021, AUTOMATED SEGMENTATI, V903
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tirupal T, 2020, MULTIMODAL MEDICAL I, DOI [10.2174/1574362415666200226103116, DOI 10.2174/1574362415666200226103116]
   Wang GF, 2022, NEUROCOMPUTING, V480, P61, DOI 10.1016/j.neucom.2022.01.059
   Wang KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082169
   Wang SH, 2021, INFORM FUSION, V76, P376, DOI 10.1016/j.inffus.2021.07.001
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Xu H, 2021, INFORM FUSION, V76, P177, DOI 10.1016/j.inffus.2021.06.001
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhao C, 2021, NEURAL COMPUT APPL, V33, P6595, DOI 10.1007/s00521-020-05421-5
   Zhu R, 2022, BIOINFORMATICS, V38, P818, DOI [10.1093/bioinformatics/btab721, DOI 10.1093/bioinformatics/btab721]
NR 35
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15856-2
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700013
DA 2024-07-18
ER

PT J
AU Panchikkil, S
   Manikandan, VM
AF Panchikkil, Shaiju
   Manikandan, V. M.
TI A prediction error based reversible data hiding scheme in encrypted
   image using block marking and cover image pre-processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image transmission; Snake scan; Prediction error strategy; High
   quality DICOM image; Reversible data hiding
ID MSB PREDICTION; EXPANSION
AB A drastic change in communication is happening with digitization. Technological advancements will escalate its pace further. The human health care systems have improved with technology, remodeling the traditional way of treatments. There has been a peak increase in the rate of telehealth and e-health care services during the coronavirus disease 2019 (COVID-19) pandemic. These implications make reversible data hiding (RDH) a hot topic in research, especially for medical image transmission. Recovering the transmitted medical image (MI) at the receiver side is challenging, as an incorrect MI can lead to the wrong diagnosis. Hence, in this paper, we propose a MSB prediction error-based RDH scheme in an encrypted image with high embedding capacity, which recovers the original image with a peak signal-to-noise ratio (PSNR) of 8 dB and structural similarity index (SSIM) value of 1. We scan the MI from the first pixel on the top left corner using the snake scan approach in dual modes: i) performing a rightward direction scan and ii) performing a downward direction scan to identify the best optimal embedding rate for an image. Banking upon the prediction error strategy, multiple MSBs are utilized for embedding the encrypted PHR data. The experimental studies on test images project a high embedding rate with more than 3 bpp for 16-bit high-quality DICOM images and more than 1 bpp for most natural images. The outcomes are much more promising compared to other similar state-of-the-art RDH methods.
C1 [Panchikkil, Shaiju; Manikandan, V. M.] SRM Univ AP, Amaravati, Andhra Prades, India.
C3 SRM University-AP
RP Manikandan, VM (corresponding author), SRM Univ AP, Amaravati, Andhra Prades, India.
EM shaiju_panchikkil@srmap.edu.in; manikandan.v@srmap.edu.in
CR Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Al-Haj A, 2021, MULTIMED TOOLS APPL, V80, P26021, DOI 10.1007/s11042-021-10801-7
   Albertina B., 2016, Cancer Imaging Arch
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Bhardwaj R, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102276
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   DICOM, 2022, US
   Dragoi IC, 2021, IEEE T INF FOREN SEC, V16, P187, DOI 10.1109/TIFS.2020.3006382
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Huang D., 2020, SIGNAL PROCESS-IMAGE, V80, P115
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Malik A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102374
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Panchikkil S, 2022, OPTIK, V261, DOI 10.1016/j.ijleo.2022.169211
   Panchikkil S, 2022, MULTIMED TOOLS APPL, V81, P16279, DOI 10.1007/s11042-022-12350-z
   Panchikkil S, 2022, OPTIK, V250, DOI 10.1016/j.ijleo.2021.168137
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Shimizu K, 1999, IEEE ENG MED BIOL, V18, P32, DOI 10.1109/51.775487
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   USC, 2022, US
   Wang, 2021, IEEE T MULTIMEDIA
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xie XZ, 2020, IEEE ACCESS, V8, P52028, DOI 10.1109/ACCESS.2020.2980302
   Xiong LZ, 2018, MULTIDIM SYST SIGN P, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
NR 50
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15319-8
EA MAY 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700006
PM 37362638
OA Green Published
DA 2024-07-18
ER

PT J
AU Araghi, TK
   Megias, D
AF Araghi, Tanya Koohpayeh
   Megias, David
TI Analysis and effectiveness of deeper levels of SVD on performance of
   hybrid DWT and SVD watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hybrid image watermarking; DWT; SVD1; SVD2; Security; Robustness;
   Imperceptibility
ID SINGULAR-VALUE DECOMPOSITION; INTEGER WAVELET TRANSFORM; SCHEME;
   SECURITY; ROBUST
AB In this paper, an analysis on hybrid Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) for image watermarking is carried out to investigate the effect of a deeper level of the SVD on imperceptibility and robustness to resist common signal processing and geometric attacks. For this purpose, we have designed two hybrid watermarking schemes, the first one with DWT and first level of SVD, whereas, in the second scheme, the same design is employed with a second level of SVD. In this experiment, a comprehensive analysis is performed on the two designed schemes and the effect of robustness and imperceptibility is compared in the first and second levels of SVD in each DWT sub-band. Having analyzed more than 100 medical and non-medical images in standard datasets and real medical samples of patients, the experimental outcomes show a remarkable increase in both imperceptibility and robustness in the second level of SVD, in comparison to the first level. In addition, the achieved result shows that the SVD2 scheme offers the highest imperceptibility in the LL sub-band (more than 60 dB on average PSNR), with satisfactory robustness against noise attacks, but less persistence in some geometric attacks such as cropping. For the HH sub-band, strong robustness against all types of tested of attacks is obtained, though its imperceptibility is slightly lower than the achieved PSNR in the LL sub-band. In HH sub-band, an average growth of 5 dB in PSNR and 2% in NC can be observed from the second level of SVD in comparison to the first level. These results make SVD2 a good candidate for content protection, especially for medical images.
C1 [Araghi, Tanya Koohpayeh; Megias, David] Univ Oberta Catalunya UOC, Internet Interdisciplinary Inst IN3, Barcelona, Spain.
   [Araghi, Tanya Koohpayeh; Megias, David] CYBERCAT Ctr Cybersecur Res Catalunya, Barcelona, Spain.
C3 UOC Universitat Oberta de Catalunya
RP Araghi, TK (corresponding author), Univ Oberta Catalunya UOC, Internet Interdisciplinary Inst IN3, Barcelona, Spain.; Araghi, TK (corresponding author), CYBERCAT Ctr Cybersecur Res Catalunya, Barcelona, Spain.
EM tkoohpayeharaghi@uoc.edu
RI Megías, David/L-1720-2014
OI Megías, David/0000-0002-0507-7731; Koohpayeh araghi,
   Tanya/0000-0002-1391-7657
FU EIG CONCERT-Japan [PCI2020-120689-2]; Spanish Ministry of Science and
   Innovation [RTI2018-095094-B-C22, PID2021-125962OB-C31]
FX The authors acknowledge the funding obtained by the Detection of fake
   newS on SocIal MedIa pLAtfoRms project from the EIG CONCERT-Japan with
   grant PCI2020-120689-2 (Government of Spain), and to the
   RTI2018-095094-B-C22 "CONSENT" and PID2021-125962OB-C31 "SECURING"
   projects granted by the Spanish Ministry of Science and Innovation.
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Akhaee MA, 2013, ISECURE-ISC INT J IN, V5, P5
   Ali M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091428
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Anand A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P366, DOI 10.1109/BigMM50055.2020.00063
   [Anonymous], 2017, INT C RELIABLE INFOR
   [Anonymous], 2011, INT J SIGNAL PROCESS
   Araghi T. K., 2021, Innovative Systems for Intelligent Health Informatics, P807
   Araghi T.K., 2016, Int. J. Adv. Image Process. Tech, V3, P6
   Araghi T. K., 2016, Int. J. Image Process. Techn., V3, P20
   Araghi TK, 2019, ADV INTELL SYST, V858, P631, DOI 10.1007/978-3-030-01174-1_49
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Araghi TK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/1609378
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   Arora SM, 2022, WIRELESS COMMUNICATI, P35
   Bansal M, 2020, LECT NOTES COMPUT SC, V12254, P862, DOI 10.1007/978-3-030-58817-5_61
   Bhuyan HK, 2024, IEEE T COMPUT SOC SY, V11, P3131, DOI 10.1109/TCSS.2022.3164993
   Chakraborty C, 2023, IEEE T IND INFORM, V19, P2099, DOI 10.1109/TII.2022.3173899
   Chandrakar N., 2013, INT J COMPUTER APPL, V2, P126, DOI DOI 10.7753/IJCATR0202.1008
   Chaturvedi N, 2012, IMAGE, V2, P1
   Danyali H, 2012, INT J INNOV COMPUT I, V8, P4691
   Dhawan S., 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13798-9
   Dittmann J, 2006, LECT NOTES COMPUT SC, V4300, P1
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Gupta M, 2015, INT J COMPUT INT SYS, V8, P364, DOI 10.1080/18756891.2015.1001958
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hussein E., 2012, Threshold, V5, P6
   Khanam T, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010052
   Mahajan PH, 2014, INT J ADV RES COMPUT
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Mohammed AA, 2020, MULTIMED TOOLS APPL, V79, P32095, DOI 10.1007/s11042-020-09694-9
   Moon Sunil K., 2022, Inventive Systems and Control: Proceedings of ICISC 2022. Lecture Notes in Networks and Systems (436), P157, DOI 10.1007/978-981-19-1012-8_11
   Moon SK, 2022, COMM COM INF SC, V1604, P11, DOI 10.1007/978-3-031-10551-7_2
   Nikolaidis A, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-97
   Nyeem H, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1136, DOI 10.1109/ICIEV.2012.6317496
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V26, P14, DOI 10.1016/j.jvcir.2014.09.005
   Qian ZX, 2015, J VIS COMMUN IMAGE R, V26, P9, DOI 10.1016/j.jvcir.2014.10.008
   Rawat N., 2014, INT J EMERG TECHNOL, V4, P237
   Shojanazeri Hamid, 2013, International Journal of Computer Information Systems and Industrial Management Applications, V5, P652
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   sipi, USC-SIPI image database
   Thapa M, 2011, INT J ADV COMPUT SC, V2, P14
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang BW, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050691
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Zeng FF, 2022, SECUR PRIVACY, V5, DOI 10.1002/spy2.223
   US
NR 51
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15554-z
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY7
UT WOS:000990968000002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wang, XY
   Ma, B
   Li, Q
   Wang, CP
   Xian, YJ
   Han, B
AF Wang, Xiaoyu
   Wang, Xingyuan
   Ma, Bin
   Li, Qi
   Wang, Chunpeng
   Xian, Yongjin
   Han, Bing
TI Reversible data hiding algorithm based on adaptive prediction and code
   division multiplexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding (RDH); Code division multiplexing (CDM); Least
   square predictor; Prediction error
ID DIFFERENCE EXPANSION; SCHEME; MATRIX
AB A good predictor is crucial for reversible data hiding (RDH). At the same time, the RDH based on code division multiplexing (CDM) has been extensively researched and developed due to its outstanding performance. This paper proposes a high performance RDH algorithm based on adaptive predictor and code division multiplexing. The least square (LS) predictor is firstly employed to predict the target pixels according to the local consistency of pixels adaptively. The most correlated pixels are selected to enable the presented predictor to achieve high pixel prediction accuracy and efficiency, so that, the prediction errors are minimized and a more sparse error image is generated. Then, the minimized prediction errors are further collected to form base vectors for data embedding, and the CDM algorithm is utilized to embed secret data into the cover image. Due to the orthogonality of the spreading sequences, most elements of the selected vector are mutually canceled, therefore, high image quality can be maintained even at large data embedding capacity. Experimental results show that the proposed method is superior to Ma's CDM-based RDH scheme, and can provide competitive performances compared with other state-of-the-art RDH schemes.
C1 [Wang, Xiaoyu; Wang, Xingyuan; Li, Qi; Xian, Yongjin] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Ma, Bin; Wang, Chunpeng; Han, Bing] Qilu Univ Technol, Sch Cyber Secur, Jinan 250353, Shandong, Peoples R China.
C3 Dalian Maritime University; Qilu University of Technology
RP Ma, B (corresponding author), Qilu Univ Technol, Sch Cyber Secur, Jinan 250353, Shandong, Peoples R China.
EM sddxmb@126.com
FU National Natural Science Foundation of China [61672124, 61802212,
   61872203]; Password Theory Project of the 13th Five-Year Plan National
   Cryptography Development Fund [MMJJ20170203]; Liaoning Province Science
   and Technology Innovation Leading Talents Program Project [XLYC1802013];
   Key R&D Projects of Liaoning Province [2019020105-JH2/103]; Jinan City
   20 universities' Funding Projects Introducing Innovation Team Program
   [2019GXRC031]; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining Security [MIMS20-M-02]
FX This research presented in this work was supported by the National
   Natural Science Foundation of China (No: 61672124, 61802212, 61872203),
   the Password Theory Project of the 13th Five-Year Plan National
   Cryptography Development Fund (No: MMJJ20170203), Liaoning Province
   Science and Technology Innovation Leading Talents Program Project (No:
   XLYC1802013), Key R & D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City 20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen XY, 2019, MULTIMED TOOLS APPL, V78, P7499, DOI 10.1007/s11042-018-6446-y
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Gujjunoori S, 2019, MULTIMED TOOLS APPL, V78, P25889, DOI 10.1007/s11042-019-07767-y
   Huang DL, 2020, MULTIMED TOOLS APPL, V79, P20881, DOI 10.1007/s11042-020-08623-0
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Ma B, 2021, MULTIMED TOOLS APPL, V80, P17569, DOI 10.1007/s11042-021-10532-9
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P857, DOI 10.1007/s11554-019-00884-9
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2020, IEEE T CIRC SYST VID, V30, P2329, DOI 10.1109/TCSVT.2019.2921812
   Ou B, 2017, NEUROCOMPUTING, V226, P23, DOI 10.1016/j.neucom.2016.11.017
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Qin JQ, 2019, IEEE SIGNAL PROC LET, V26, P843, DOI 10.1109/LSP.2019.2909080
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang DW, 2019, IEEE SIGNAL PROC LET, V26, P1713, DOI 10.1109/LSP.2019.2940873
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P5965, DOI 10.1007/s11042-019-08255-z
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xuan G, 2013, LNCS, P368
   Xue BW, 2017, MULTIMED TOOLS APPL, V76, P13473, DOI 10.1007/s11042-016-3763-x
   Zhang C, 2022, IEEE T CIRC SYST VID, V32, P4174, DOI 10.1109/TCSVT.2021.3125711
   Zhang TC, 2022, IEEE T CIRC SYST VID, V32, P5041, DOI 10.1109/TCSVT.2022.3146159
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
NR 41
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15354-5
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G6US0
UT WOS:000990491400001
DA 2024-07-18
ER

PT J
AU Yousaf, K
   Nawaz, T
   Habib, A
AF Yousaf, Kanwal
   Nawaz, Tabassam
   Habib, Adnan
TI Using two-stream EfficientNet-BiLSTM network for multiclass
   classification of disturbing YouTube videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video classification; Deep learning; Convolutional neural network;
   YouTube
ID PORNOGRAPHY DETECTION; DESCRIPTORS; SYSTEM
AB YouTube video recommendation algorithm plays an important role in enhancing user engagement and profitability (or monetization), yet it struggles to deal with disturbing visual content. Real-time analysis using deep learning techniques can play a vital role to identify and filter the disturbing content in online videos. In this paper, we propose an end-to-end trainable two-stream deep learning framework that analyzes and classifies the different categories of disturbing content embedded in child-friendly cartoon videos on YouTube and YouTube Kids platforms. At first, the model extracts the static and motion features from videos through an individual pretrained convolutional neural network (CNN) i.e., EfficientNet-B7. In the next phase, the extracted features are processed by spatio-temporal bidirectional long short-term memory (BiLSTM) network to capture the long-term global temporal dependencies of videos. The learned video representations are forwarded to the classifier for multiclass classification into six categories. Three different types of fusion strategies are investigated to combine the spatial and temporal streams. The evaluation of these methods is performed through extensive experiments on a customized large-scale dataset-YouTube cartoon content filtering (YT-C2F) dataset. The spatio-temporal EfficientNet-BiLSTM network with feature-level fusion displays the best results (f1-score = 0.9316) and shows the efficiency of using a two-stream network compared to single-stream baseline methods. This paper makes two-fold contributions. First, using only static information from videos in a deep learning framework is less effective than using both static and motion information. Second, the feature-level fusion of two streams of networks generates better classification results than early and late fusion techniques. The performance comparison of the proposed model with existing state-of-the-art techniques confirmed the competitive or even better results of our framework.
C1 [Yousaf, Kanwal; Nawaz, Tabassam] Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
   [Habib, Adnan] Univ Engn & Technol, Dept Comp Engn, Taxila 47050, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila
RP Yousaf, K (corresponding author), Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
EM kanwal.yousaf@uettaxila.edu.pk
RI Yousaf, Kanwal/AAB-6350-2019
OI Yousaf, Kanwal/0000-0003-2198-6932
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abu-El-Haija Sami, 2016, arXiv, DOI [DOI 10.48550/ARXIV.1609.08675, DOI 10.48550/-ARXIV.1609.08675]
   Aldahoul N, 2021, IEEE ACCESS, V9, P39910, DOI 10.1109/ACCESS.2021.3064392
   Alghowinem S, 2019, ADV INTELL SYST COMP, V868, P294, DOI 10.1007/978-3-030-01054-6_21
   Ali A, 2018, ADV INTELL SYST, V700, P225, DOI 10.1007/978-3-319-72550-5_22
   Alshamrani S, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P508, DOI 10.1145/3442442.3452314
   Ariel Y, 2015, ATL J COMMUN, V23, P19, DOI 10.1080/15456870.2015.972404
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Brandom R, 2021, Verge
   Burroughs B, 2017, SOC MEDIA SOC, V3, DOI 10.1177/2056305117707189
   Bushman BJ, 2006, ARCH PEDIAT ADOL MED, V160, P348, DOI 10.1001/archpedi.160.4.348
   Caetano C, 2014, EUR SIGNAL PR CONF, P1681
   Ceci L, 2021, Statista
   Ceci L, 2021, GLOBAL NUMBER YOUTUB
   Craig D, 2017, MEDIA INT AUST, V163, P77, DOI 10.1177/1329878X17693700
   Dadvar M, 2020, LECT NOTES COMPUT SC, V12393, P245, DOI 10.1007/978-3-030-59065-9_20
   Defendant's opposition WDI, 2018, YOUTUBE SERV TERMS U
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Ding CH, 2014, LECT NOTES COMPUT SC, V8888, P551, DOI 10.1007/978-3-319-14364-4_53
   Elias N, 2017, CYBERPSYCHOLOGY, V11, DOI 10.5817/CP2017-3-2
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Ferchaud A, 2018, COMPUT HUM BEHAV, V80, P88, DOI 10.1016/j.chb.2017.10.041
   Fleck M. M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P593
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hanson A, 2019, LECT NOTES COMPUT SC, V11130, P280, DOI 10.1007/978-3-030-11012-3_24
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou CC, 2018, LECT NOTES COMPUT SC, V11256, P501, DOI 10.1007/978-3-030-03398-9_43
   Ishikawa A, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739202
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Jung S, 2014, IEEE T CONSUM ELECTR, V60, P696, DOI 10.1109/TCE.2014.7027345
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kaushal Rishabh, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P157, DOI 10.1109/PST.2016.7906950
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee HE, 2020, FORENS SCI INT-DIGIT, V34, DOI 10.1016/j.fsidi.2020.301022
   Lee S, 2009, IEEE T CONSUM ELECTR, V55, P677, DOI 10.1109/TCE.2009.5174439
   Liu YZ, 2014, FUTURE GENER COMP SY, V31, P69, DOI 10.1016/j.future.2012.08.012
   Liu YZ, 2011, IEEE INT CONF TRUST, P1488, DOI 10.1109/TrustCom.2011.205
   Livingstone S., 2011, Risks And Safety on the Internet: The Perspective of European Children: Full Findings and Policy Implications from the EU Kids Online Survey of 9-16 Year Olds and Their Parents in 25 Countries Monograph
   Lopes APB, 2009, SIBGRAPI, P224, DOI 10.1109/SIBGRAPI.2009.32
   Maheshwari S, 2017, The New York Times
   Mariconti Enrico, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359309
   Mohaouchane Hanane, 2019, 2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS), P466, DOI 10.1109/SNAMS.2019.8931839
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Moustafa M, 2015, Arxiv, DOI arXiv:1511.08899
   Neumann M., 2020, Childhood Education, V96, P72, DOI DOI 10.1080/00094056.2020.1796459
   Neumann MM, 2020, EDUC INF TECHNOL, V25, P4459, DOI 10.1007/s10639-020-10183-7
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ochoa VMT, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P967, DOI 10.1109/SITIS.2012.143
   Papadamou K, 2020, P INT AAAI C WEB SOC, P522, DOI DOI 10.1609/ICWSM.V14I1
   Peixoto BM, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3232809
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Rea N, 2006, P IET C PUBL LEEL PA, DOI [10.1049/cp:20061978, DOI 10.1049/CP:20061978]
   Reddit, 2017, REDDIT
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2104, DOI 10.1145/3297280.3297487
   Smith AN, 2012, J INTERACT MARK, V26, P102, DOI 10.1016/j.intmar.2012.01.002
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sumon SA, 2019, LECT NOTES ARTIF INT, V11431, P613, DOI 10.1007/978-3-030-14799-0_53
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tahir R, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P464, DOI 10.1145/3341161.3342913
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang S, 2009, P 17 ACM INT C MULT, P1003, DOI [10.1145/1631272.1631490, DOI 10.1145/1631272.1631490]
   Trana Rachel E., 2021, Advances in Artificial Intelligence, Software and Systems Engineering. Proceedings of the AHFE 2020 Virtual Conferences on Software and Systems Engineering, and Artificial Intelligence and Social Computing. Advances in Intelligent Systems and Computing (AISC 1213), P9, DOI 10.1007/978-3-030-51328-3_2
   Ulges A, 2012, P 2012 ACM WORKSH AU, P21, DOI [10.1145/2390214.2390222, DOI 10.1145/2390214.2390222]
   Vitorino P, 2018, J VIS COMMUN IMAGE R, V50, P303, DOI 10.1016/j.jvcir.2017.12.005
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Wikipedia, 2019, TV PAR GUID
   Wilson H., 2020, Seattle J Technol Environ Innov Law, V10, P8
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wu ZX, 2015, Arxiv, DOI arXiv:1509.06086
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Yenala H, 2018, INT J DATA SCI ANAL, V6, P273, DOI 10.1007/s41060-017-0088-4
   Yousaf K, 2022, IEEE ACCESS, V10, P16283, DOI 10.1109/ACCESS.2022.3147519
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhao YX, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00501-x
NR 88
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15774-3
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100011
DA 2024-07-18
ER

PT J
AU Yan, CM
   Zhang, QQ
AF Yan, Chunman
   Zhang, Qianqian
TI Jointly projection and graph-regularization coupled discriminative
   dictionary learning for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE dictionary learning; dimensionality reduction; graph regularization;
   structural consistency term
ID K-SVD; SPARSE REPRESENTATION; FACE RECOGNITION
AB Analysis synthesis dictionary pair learning methods have achieved good performance in image classification. Due to the redundancy contained in the original data, learning a more compact and discriminative analysis synthesis dictionary is still open. In this paper, we propose a jointly projection and graph-regularized coupled discriminative dictionary learning (JPGCDDL) for image classification.Specifically, JPGCDDL obtains feature more suitable for dictionary learning via simultaneously learning the projection matrix and analysis synthesis dictionary pair. Then in the low-dimensional subspace, we consider improving the discriminability of the analysis dictionary by introducing a constraint term on the coding coefficients, which can ensure both the within-class compactness and between-class separation. And the synthesis dictionary atoms are utilized to construct the graph regularization term to obtain a robust and discriminative synthesis dictionary. Moreover, the structural consistency term of the projection samples is introduced to make the low-dimensional data features have a common sparsity structure in each class, so that the final classification is focused on more important low-dimensional features. Finally, an effective iterative algorithm is devised to solve the optimization problem. Experimental results on several benchmark databases show the superior performance of JPGCDDL.
C1 [Yan, Chunman; Zhang, Qianqian] Northwest Normal Univ, Sch Phys & Elect Engn, Lanzhou, Peoples R China.
C3 Northwest Normal University - China
RP Zhang, QQ (corresponding author), Northwest Normal Univ, Sch Phys & Elect Engn, Lanzhou, Peoples R China.
EM Yancha02@163.com; zqqian1126@163.com
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Chang HY, 2019, IEEE ACCESS, V7, P55398, DOI 10.1109/ACCESS.2019.2912932
   Creswell A., 2016, IEEE T NEUR NET LEAR
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du HS, 2016, OPTIK, V127, P3605, DOI 10.1016/j.ijleo.2015.12.169
   Gu SH, 2014, ADV NEUR IN, V27
   Guo J, 2016, AAAI CONF ARTIF INTE, P1617
   He R, 2014, IEEE T PATTERN ANAL, V36, P770, DOI 10.1109/TPAMI.2013.188
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kong S., 2012, LEARNING INTERRELATE
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Rubinstein R, 2014, IEEE T SIGNAL PROCES, V62, P5962, DOI 10.1109/TSP.2014.2360157
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Tang W, 2019, IEEE T IMAGE PROCESS, V28, P6035, DOI 10.1109/TIP.2019.2919409
   Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654
   Wang JJ, 2017, IEEE SIGNAL PROC LET, V24, P1822, DOI 10.1109/LSP.2017.2734860
   Wang QY, 2018, MULTIMED TOOLS APPL, V77, P17023, DOI 10.1007/s11042-017-5269-6
   Wang Y, 2021, DIGITAL SIGNAL PRO35
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2017, NEUROCOMPUTING, V269, P13, DOI 10.1016/j.neucom.2016.08.146
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang SY, 2011, NEUROCOMPUTING, V74, P3193, DOI 10.1016/j.neucom.2011.04.014
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zheng H, 2015, NEUROCOMPUTING, V162, P9, DOI 10.1016/j.neucom.2015.03.071
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 38
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15579-4
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800014
DA 2024-07-18
ER

PT J
AU Mirzaei, S
AF Mirzaei, Sayeh
TI Hyperspectral image classification using K-plane clustering and kernel
   principal component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image (HSI) classification; K-plane clustering (KPC);
   Kernel principal component analysis (KPCA)
ID PROFILES
AB In this paper, we present a new approach for hyperspectral image classification. The pixels' spectra are grouped into clusters in an unsupervised manner using an improved version of plane based clustering. Since the pixels containing the same substances are linearly correlated, the proposed plane-based clustering can effectively group the data points. Plane-based clustering is a more appropriate choice than point based clustering schemes for grouping the datasets which are distributed around hyperplanes instead of hyperspheres. Then, Kernel Principal Component Analysis (KPCA) is applied to each cluster individually to obtain multiple kernel vectors for each data point. Applying non-linear kernels, can greatly increase the discrimination power of the acquired features. The feature vectors are extracted by a weighted linear combination of the kernel components obtained from each cluster. We compute optimal weights using the cluster hyperplane parameters. Since the whole procedure is performed in an unsupervised manner, the proposed approach can enhance the generalization power of the extracted features. Then, morphological attribute filters are applied to the feature maps to effectively utilize spatial relations. Hence, the acquired compact feature vectors include both spectral and spatial information. SVM is used for classification. The experiments performed on three well-known hyperspectral datasets reveal the effectiveness of the proposed feature extraction approach.
C1 [Mirzaei, Sayeh] Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
C3 University of Tehran
RP Mirzaei, S (corresponding author), Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
EM s.mirzaei@ut.ac.ir
OI Mirzaei, Sayeh/0000-0003-1174-2280
CR Binol H, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/9632569
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Bradley PS, 2000, J GLOBAL OPTIM, V16, P23, DOI 10.1023/A:1008324625522
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Fang LY, 2019, IEEE T GEOSCI REMOTE, V57, P1291, DOI 10.1109/TGRS.2018.2865953
   Fauvel M, 2006, P 7 NORD SIGN PROC S, DOI 10.1109/NORSIG.2006.275232
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Fauvel M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/783194
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   Gu YF, 2016, IEEE T GEOSCI REMOTE, V54, P3235, DOI 10.1109/TGRS.2015.2514161
   He Z, 2018, SIGNAL PROCESS, V145, P12, DOI 10.1016/j.sigpro.2017.11.007
   He Z, 2016, SIGNAL PROCESS, V120, P209, DOI 10.1016/j.sigpro.2015.09.004
   Iordache MD, 2011, IEEE T GEOSCI REMOTE, V49, P2014, DOI 10.1109/TGRS.2010.2098413
   Jia S, 2021, NEUROCOMPUTING, V448, P179, DOI 10.1016/j.neucom.2021.03.035
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Kuo BC, 2014, IEEE J-STARS, V7, P317, DOI 10.1109/JSTARS.2013.2262926
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li Y, 2021, IEEE T GEOSCI REMOTE, V59, P7803, DOI 10.1109/TGRS.2020.3038425
   Manolakis D. G., 2016, Hyperspectral Imaging Remote Sensing: Physics, Sensors, and Algorithms, DOI DOI 10.1017/CBO9781316017876
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mirzaei S, 2019, SIGNAL PROCESS-IMAGE, V76, P178, DOI 10.1016/j.image.2019.05.004
   Mirzaei S, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.026501
   Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Pande S, 2022, ISPRS J PHOTOGRAMM, V183, P422, DOI 10.1016/j.isprsjprs.2021.11.021
   Richards J.A., 1999, Remote Sensing Digital Image Analysis, 3, DOI [https://doi.org/10.1007/978-3-662-03978-6, DOI 10.1007/978-3-662-03978-6]
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Yang ZM, 2015, NEURAL COMPUT APPL, V26, P199, DOI 10.1007/s00521-014-1707-9
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
NR 35
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47387
EP 47403
DI 10.1007/s11042-023-15437-3
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985378600008
DA 2024-07-18
ER

PT J
AU Zachariah, RA
   Sharma, S
   Kumar, V
AF Zachariah, Renju Aleyamma
   Sharma, Sahil
   Kumar, Vijay
TI Systematic review of passenger demand forecasting in aviation industry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Aviation demand forecasting; Deep learning; Passenger throughput;
   Statistical approach
ID AIR-TRAVEL DEMAND; LOW-COST CARRIERS; NEURAL-NETWORK; TOURISM;
   TRANSPORTATION; MODELS; IMPACT; DETERMINANTS; AIRPORT
AB Forecasting aviation demand is a significant challenge in the airline industry. The design of commercial aviation networks heavily relies on reliable travel demand predictions. It enables the aviation industry to plan ahead of time, evaluate whether an existing strategy needs to be revised, and prepare for new demands and challenges. This study examines recently published aviation demand studies and evaluates them in terms of the various forecasting techniques used, as well as the advantages and disadvantages of each. This study investigates numerous forecasting techniques for passenger demand, emphasizing the multiple factors that influence aviation demand. It examined the benefits and drawbacks of various models ranging from econometric to statistical, machine learning to deep neural networks, and the most recent hybrid models. This paper discusses multiple application areas where passenger demand forecasting is used effectively. In addition to the benefits, the challenges and potential future scope of passenger demand forecasting were discussed. This study will be helpful to future aviation researchers while also inspiring young researchers to pursue careers in this industry.
C1 [Zachariah, Renju Aleyamma] Sabre Travel Technol India Pvt Ltd, Bengaluru, Karnataka, India.
   [Sharma, Sahil] Punjab Engn Coll, Comp Sci & Engn Dept, Chandigarh, India.
   [Kumar, Vijay] Dr B R Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
C3 Punjab Engineering College (Deemed University); National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Sharma, S (corresponding author), Punjab Engn Coll, Comp Sci & Engn Dept, Chandigarh, India.
EM zac.renju@gmail.com; sahil301290@gmail.com; vijaykumarchahar@gmail.com
RI Kumar, Vijay/A-2782-2015; Sharma, Sahil/JXM-8658-2024; Sharma, Dr.
   Sahil/AAI-2846-2021
OI Sharma, Sahil/0000-0002-3187-4929; Sharma, Dr. Sahil/0000-0002-6694-3365
CR Abdella JA, 2021, J KING SAUD UNIV-COM, V33, P375, DOI 10.1016/j.jksuci.2019.02.001
   Addepalli S, 2018, PROCEDIA MANUF, V19, P2, DOI 10.1016/j.promfg.2018.01.002
   Ahmed NK, 2010, ECONOMET REV, V29, P594, DOI 10.1080/07474938.2010.481556
   Airports Comission, 2013, 01 AIRP COMM, P1
   Akinyemi YC, 2019, GEOJOURNAL, V84, P1239, DOI 10.1007/s10708-018-9918-8
   Al-Ruzeiqi S, 2019, THESIS LOUGHBOROUGH
   Alarfaj E, 2019, ADV INTELL SYST, V868, P1208, DOI 10.1007/978-3-030-01054-6_84
   Albayrak MBK, 2020, J AIR TRANSP MANAG, V86, DOI 10.1016/j.jairtraman.2020.101818
   Ali J., 2012, International Journal of Computer Science Issues (IJCSI), V9, P272
   Allen PG, 2001, ECONOMETRIC FORECAST
   Alsumairi M, 2017, J AIR TRANSP MANAG, V62, P129, DOI 10.1016/j.jairtraman.2017.04.001
   Amadou B., 2021, BRAZ J DEV, V7, P303, DOI [10.34117/bjdv7n1-023, DOI 10.34117/BJDV7N1-023]
   Baikgaki O.A., 2013, Mediterr. J. Soc. Sci, V4, P389, DOI [10.5901/mjss.2013.v4n13p389, DOI 10.5901/MJSS.2013.V4N13P389]
   Bandara K, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112896
   Banerjee N, 2020, EUR J OPER RES, V286, P797, DOI 10.1016/j.ejor.2019.10.032
   BARCZAK A., 2018, Transport Economics and Logistics, V80, P1725, DOI [10.26881/etil.2018.80.02, DOI 10.26881/ETIL.2018.80.02]
   Bastola DP, 2017, INT J ACAD RES PSYCH, V1, P76
   Bermúdez JD, 2007, J APPL STAT, V34, P1075, DOI 10.1080/02664760701592125
   Carmona-Benítez RB, 2020, J AIR TRANSP MANAG, V82, DOI 10.1016/j.jairtraman.2019.101736
   Carmona-Benítez R, 2017, TRANSP RES PROC, V25, P17, DOI 10.1016/j.trpro.2017.05.191
   Bontempi G, 2013, LECT NOTES BUS INF P, V138, P62
   Boonekamp T, 2018, TRANSPORT RES A-POL, V112, P18, DOI 10.1016/j.tra.2018.01.004
   Brause LM, 2020, EUR TRANSP RES REV, V12, DOI 10.1186/s12544-020-00446-2
   Chakrabarty Navoneel, 2019, 2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON), P102, DOI 10.1109/IEMECONX.2019.8876970
   Chen JH, 2020, J AIR TRANSP MANAG, V82, DOI 10.1016/j.jairtraman.2019.101743
   Cho W, 2015, TRANSPORT RES E-LOG, V81, P141, DOI 10.1016/j.tre.2015.06.004
   Chudy-Laskowska K., 2017, P 4 INT MULT SCI C S, P681, DOI [10.5593/sgemsocial2017/14/S04.089, DOI 10.5593/SGEMSOCIAL2017/14/S04.089]
   Dama F., 2021, ARXIV
   Dantas TM, 2017, J AIR TRANSP MANAG, V59, P116, DOI 10.1016/j.jairtraman.2016.12.006
   Das AK, 2022, CASE STUD TRANSP POL, V10, P637, DOI 10.1016/j.cstp.2022.01.024
   Ding Y, 2017, PREDICTING FLIGHT DE, DOI [10.1088/1755-1315/81/1/012198, DOI 10.1088/1755-1315/81/1/012198]
   Divisekera S, 2016, TOURISM ECON, V22, P1191, DOI 10.1177/1354816616669007
   Djakaria I., 2021, Journal of Physics: Conference Series, V1882, DOI 10.1088/1742-6596/1882/1/012033
   Do QH., 2020, J HIGH ENERGY PHYS, V16, P1063, DOI [10.3844/jcssp.2020.1063.1084, DOI 10.3844/JCSSP.2020.1063.1084]
   Eric TN, 2020, TOURISM MANAGE, V78, DOI 10.1016/j.tourman.2019.104033
   Firat M, 2021, J UNIVERS COMPUT SCI, V27, P564, DOI 10.3897/jucs.68185
   Flores C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157080
   Gallet CA, 2014, ANN TOURISM RES, V49, P141, DOI 10.1016/j.annals.2014.09.006
   Garrow L, 2021, J REVENUE PRICING MA, V20, P3, DOI 10.1057/s41272-020-00271-1
   Gelhausen MC, 2018, J AIR TRANSP MANAG, V71, P140, DOI 10.1016/j.jairtraman.2018.04.001
   Gelhausen MC, 2017, 21 AIR TRANSP RES SO, P1
   Gelhausen MC, GRAVITY MODEL ESTIMA
   Ghalehkhondabi I, 2019, J TOUR FUTURES, V5, P75, DOI 10.1108/JTF-10-2018-0061
   Ghosh R, 2015, FUTURE PASSENGER AIR, DOI [10.1504/ijam.2017.10010463, DOI 10.1504/IJAM.2017.10010463]
   Goh C, 2011, J TRAVEL TOUR MARK, V28, P296, DOI 10.1080/10548408.2011.562856
   Gosling G., 2019, USING DISAGGREGATED, DOI [10.17226/25411, DOI 10.17226/25411]
   Gosling GD, 2019, TRANSPORT RES REC, V2673, P491, DOI 10.1177/0361198118823197
   Gössling S, 2021, J SUSTAIN TOUR, V29, P1, DOI 10.1080/09669582.2020.1758708
   Greunen J., 2014, Studies in Economics and Econometrics, V38, P1, DOI [DOI 10.1080/10800379.2014.12097260, 10.1080/10800379.2014.12097260]
   Gunter U, 2021, ANN TOURISM RES, V89, DOI 10.1016/j.annals.2021.103252
   Guo R., 2017, MAT INT J SCI TECHNO, V3, P123, DOI [10.20319/mijst.2017.31.123139, DOI 10.20319/MIJST.2017.31.123139]
   Hakim MM, 2019, TRANSPORT POLICY, V83, P120, DOI 10.1016/j.tranpol.2017.12.003
   Iacus SM, 2020, SAFETY SCI, V129, DOI 10.1016/j.ssci.2020.104791
   Inan TT, 2021, INT J AVIAT AERONAUT, V8
   Jafari N, 2022, CHAOS US DOMESTIC AI
   Jin F, 2020, J AIR TRANSP MANAG, V83, DOI 10.1016/j.jairtraman.2019.101744
   Kamal S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10122001
   Kanavos A, 2021, NEURAL COMPUT APPL, V33, P16329, DOI 10.1007/s00521-021-06232-y
   Kim S, 2016, AUTOMAT CONSTR, V70, P98, DOI 10.1016/j.autcon.2016.06.009
   Kluge U, 2017, AIR TRANSP RES SOC W, P1
   koc A., 2016, Actual problems of Economics, V5, P412
   Koç I, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING & INFORMATION TECHNOLOGY (CEIT)
   Lamb TL, 2021, J AIR TRANSP MANAG, V94, DOI 10.1016/j.jairtraman.2021.102079
   Lemke C, 2008, FORECASTING FORECAST
   Li C, 2019, INT J SYST ASSUR ENG, V10, P945, DOI 10.1007/s13198-019-00825-6
   Li HY, 2020, ANN TOURISM RES, V83, DOI 10.1016/j.annals.2020.102912
   Liasidou S, 2017, TOUR REV, V72, P28, DOI 10.1108/TR-10-2016-0044
   Liu J, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3078845
   Liu X, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY (CYBERC), P298, DOI 10.1109/CyberC.2017.62
   Lwesya F, 2017, COMP ANAL APPL SEASO
   Madhavan M, 2023, GLOB BUS REV, V24, P1145, DOI 10.1177/0972150920923316
   Manca F, 2023, TRANSPORT RES REC, V2677, P105, DOI 10.1177/03611981211025287
   Milenkovic M, 2018, TRANSPORT-VILNIUS, V33, P1113, DOI 10.3846/16484142.2016.1139623
   Mohd Lip N., 2020, J TOUR HOSP ENV MANA, V5, P41, DOI [10.35631/jthem.518004, DOI 10.35631/JTHEM.518004]
   Monahan KM, 2016, SCHOLARWORKS UMASS A
   Monmousseau P, 2020, P 2020 INT C ARTIFIC, P1
   Mostafaeipour A, 2018, J SUPERCOMPUT, V74, P5461, DOI 10.1007/s11227-018-2452-0
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Papatheodorou A, 2021, ANN TOURISM RES, V87, DOI 10.1016/j.annals.2021.103151
   Peeters P., 2018, Research for TRAN Committee-Overtourism: impact and possible policy responses, P1, DOI [10.2861/919195, DOI 10.2861/919195]
   Prabhakar E., 2019, International Journal of Engineering Research & Technology (IJERT), V7, P1
   Pratt S, 2019, TOURISM ECON, V25, P149, DOI 10.1177/1354816618793771
   Prentice C, 2019, J RETAIL CONSUM SERV, V47, P40, DOI 10.1016/j.jretconser.2018.10.006
   Ramadhani S, 2020, 7 INT C ICT SMART SO, P1, DOI [10.1109/ICISS50791.2020.9307571, DOI 10.1109/ICISS50791.2020.9307571]
   Rodriguez Y, 2020, AVIATION, V24, P10, DOI 10.3846/aviation.2020.12273
   Rodriguez-Sanz A, 2018, IEEE J BIOMED HEALTH, DOI [10.3390/AEROSPACE5020059, DOI 10.3390/AEROSPACE5020059]
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Sharma J, 2022, TRAIT SIGNAL, V39, P1027, DOI 10.18280/ts.390330
   Sharma S, TRANSFER LEARNING 2, P97, DOI [10.4018/978-1-5225-7862-8.CH006, DOI 10.4018/978-1-5225-7862-8.CH006]
   Slotkis SJ, 2020, FOUND INTER, P378, DOI [10.5040/9781501316050.ch-013, DOI 10.5040/9781501316050.CH-013]
   Solvoll G, 2020, RES TRANSP ECON, V82, DOI 10.1016/j.retrec.2020.100873
   Song H, 2008, TOURISM MANAGE, V29, P203, DOI 10.1016/j.tourman.2007.07.016
   Stavelin Abhinandithe K, 2021, INT REV RES OPEN DIS, V5, P409
   Suh DY, 2019, TRANSPORT RES E-LOG, V128, P400, DOI 10.1016/j.tre.2019.06.016
   Sulistyowati Ratna, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P442, DOI 10.1109/ICOIACT.2018.8350816
   Sun SL, 2019, J AIR TRANSP MANAG, V78, P54, DOI 10.1016/j.jairtraman.2019.04.005
   Sun XQ, 2020, J AIR TRANSP MANAG, V89, DOI 10.1016/j.jairtraman.2020.101928
   Suryan Viktor., 2017, Journal of the Civil Engineering Forum, V3, P33, DOI DOI 10.22146/JCEF.26594
   Tascón DC, 2021, J AIR TRANSP MANAG, V90, DOI 10.1016/j.jairtraman.2020.101946
   Hoyos DT, 2020, TRANSP TELECOMMUN J, V21, P1, DOI 10.2478/ttj-2020-0001
   Tolcha TD, 2020, J TRANSP GEOGR, V86, DOI 10.1016/j.jtrangeo.2020.102771
   Transportation Research Board National Research Council (U.S.), 2002, EC040 TRANSP RES, VE-C040, P44
   Tsafarakis S, 2018, J AIR TRANSP MANAG, V68, P61, DOI 10.1016/j.jairtraman.2017.09.010
   Tsui WHK, 2016, J AIR TRANSP MANAG, V50, P1, DOI 10.1016/j.jairtraman.2015.09.001
   Wallström P, 2010, INT J PROD ECON, V128, P625, DOI 10.1016/j.ijpe.2010.07.013
   Wang M, 2010, J CHINA TOUR RES, V6, P29, DOI 10.1080/19388160903586562
   Wang S, 2021, J AIR TRANSP MANAG, V97, DOI 10.1016/j.jairtraman.2021.102135
   Wang Y, 2021, J AIR TRANSP MANAG, V91, DOI 10.1016/j.jairtraman.2020.101995
   Warnock-Smith D, 2021, J AIR TRANSP MANAG, V94, DOI 10.1016/j.jairtraman.2021.102085
   Webster C, 2019, AIR TRANSPORT TOURIS, V22
   Xie G, 2014, J AIR TRANSP MANAG, V37, P20, DOI 10.1016/j.jairtraman.2014.01.009
   Xiong HL, 2022, SAGE OPEN, V12, DOI 10.1177/21582440211071102
   Xu SJ, 2019, TRANSPORT RES E-LOG, V122, P169, DOI 10.1016/j.tre.2018.12.005
   Yan WL, 2017, IN C IND ENG ENG MAN, P828, DOI 10.1109/IEEM.2017.8290007
   Yingying Wei, 2020, 2020 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS), P266, DOI 10.1109/ICPICS50287.2020.9202007
   Yuanxun Li, 2020, IOP Conference Series: Materials Science and Engineering, V780, DOI 10.1088/1757-899X/780/6/062006
   Zhang XY, 2019, J SYST SCI COMPLEX, V32, P615, DOI 10.1007/s11424-018-7093-0
   Zhou Y., 2016, INT J SMART HOME, V10, P187, DOI [10.14257/ijsh.2016.10.6.19, DOI 10.14257/IJSH.2016.10.6.19]
NR 119
TC 7
Z9 7
U1 21
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46483
EP 46519
DI 10.1007/s11042-023-15552-1
EA MAY 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000979963000001
PM 37362707
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU AlAli, ZT
   Alabady, SA
AF AlAli, Zahraa Tarik
   Alabady, Salah Abdulghani
TI Fire and blood detection system in disaster environment using UAV and
   FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color detection; Image processing; Convolution; Disaster management;
   Search and rescue; System Generator; FPGA
AB Over the years, the world has witnessed many natural or man-made disasters, whether they are accidents, military operations, or terrorism. Researchers and activists in various civil, medical, engineering, and other fields have worked to reduce the occurrence of these disasters or manage them effectively to ensure the least damage and fewer injuries. In this study, a system was proposed that is capable of detecting the presence of fires that may accompany various types of disasters in a way that ensures the safety of the disaster management team, as well as detecting injured or bleeding people by detecting the presence of blood to speed up their rescue. The system relies on processing images taken from unmanned aerial vehicles (UAVs) over the disaster site. The processing reveals the color gradients of fire and blood using color detection and convolution with an edge detection filter in MATLAB, and then synthesis of the architecture using Excel DSP. The system is then built using System Generator to be implemented on the Field Programmable Gate Array (FPGA). The proposed algorithm was implemented under multiple conditions for both fire and blood, and its implementation was in real-time with a low device utilization of 64.381 MHz and 69.86 frames per second. The results showed the ability of the system to detect fires and the blood of the injured at a high speed and under certain conditions, and it could be developed to become a system approved for most conditions and to be a more comprehensive system in terms of transmitting information wirelessly.
C1 [AlAli, Zahraa Tarik] Univ Mosul, Coll Engn, Mechatron Engn Dept, Mosul, Iraq.
   [Alabady, Salah Abdulghani] Univ Mosul, Coll Engn, Comp Engn Dept, Mosul, Iraq.
C3 University of Mosul; University of Mosul
RP Alabady, SA (corresponding author), Univ Mosul, Coll Engn, Comp Engn Dept, Mosul, Iraq.
EM zahraata.eng@uomosul.edu.iq; eng.salah@uomosul.edu.iq
RI Abdulghani, Salah/B-6684-2018
OI Abdulghani, Salah/0000-0001-9687-2724; AlAli, Zahraa
   Tarik/0000-0001-6079-0153
CR Al-Naji A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202441
   AlAli ZT, 2022, REMOTE SENS APPL, V28, DOI 10.1016/j.rsase.2022.100873
   AlAli ZT, 2022, INT J DISAST RISK RE, V82, DOI 10.1016/j.ijdrr.2022.103295
   [Anonymous], 2020, FIRE EXTINGUISHERS A
   [Anonymous], SEARCH OUR WORLD DAT
   Arnold R.D., 2018, J. Int. Humanit. Action, V3, P18, DOI [DOI 10.1186/S41018-018-0045-4, 10.1186/s41018-018-0045-4]
   Burger W., 2016, DIGITAL IMAGE PROCES, DOI [10.1007/978-1-4471-6684-9, DOI 10.1007/978-1-4471-6684-9]
   Chen Hui, 2015, Chinese Journal of Liquid Crystals and Displays, V30, P143, DOI 10.3788/YJYXS20153001.0143
   Chen X, 2010, INT CONF SIGN PROCES, P793, DOI 10.1109/ICOSP.2010.5655926
   Chowdhury S, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P2218
   Doulamis N, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P311, DOI 10.1145/3056540.3076201
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Hiraiwa J, 2010, P 17 INT C SYSTEMS S
   Ibraheem N.A., 2012, ARPN J. Sci. Technol., V2, P265
   Kumah C., 2019, J TEXTILE SCI TECHNO, V5, P1, DOI [10.4236/jtst.2019.51001, DOI 10.4236/JTST.2019.51001]
   Kumar Kaushal, 2020, Procedia Computer Science, V171, P2008, DOI 10.1016/j.procs.2020.04.215
   Shimoda M, 2019, I C FIELD PROG LOGIC, P413, DOI 10.1109/FPL.2019.00072
   Spyridis Y, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102232
   Toda H, 2012, INT J SOC ROBOT, V4, P101, DOI 10.1007/s12369-011-0132-9
   Vincent S, 2019, INT J ELECTRON TELEC, V65, P217, DOI 10.24425/ijet.2019.126304
   Yin TS., 2017, INDONES J ELECT ENG, V6, P139
   Yong S., 2018, 4 INT C COMPUTER INF, P1, DOI [DOI 10.1109/ICCOINS.2018.8510564, 10.1109/ICCOINS.2018.8510564]
   ZTA Ali, 2022, QUANTUM J ENG SCI TE, V3
NR 23
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43315
EP 43333
DI 10.1007/s11042-023-15507-6
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000978477000008
DA 2024-07-18
ER

PT J
AU Ding, WJ
   Zhang, HY
   Reulke, R
   Wang, YL
AF Ding, Wenjia
   Zhang, Huyin
   Reulke, Ralf
   Wang, Yulin
TI Large-capacity image data hiding based on table look-up
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image data hiding; Digital watermarking; Steganography; Information
   encoding
ID SIGNIFICANT-BIT SUBSTITUTION; ENCRYPTED IMAGES; WATERMARKING; SCHEME;
   TRANSFORM; SECURITY; ROBUST
AB Data hiding, also known as information hiding and digital watermarking, refers to the technology of hiding secret information in publicly available media and making it difficult for people to feel its existence. According to the survival result of the hidden information when the stego media is processed, this technology can be divided into robust, semi-fragile, and fragile watermarking. Strong robust digital watermarking is technically difficult to achieve, so it is unrealistic to apply it for digital copyright protection at present. In contrast, fragile (and semi-fragile) watermarking has good feasibility and has been used for authentication and tamper localization of the stego media. However, the existing technology has limitations. To improve the sensitivity and positioning accuracy of tampering, some algorithms embed excessive data, which greatly reduces the fidelity of stego media. To prevent third parties from bypassing integrity authentication and tamper localization, some algorithms add complex encryption algorithms to achieve the confidentiality of hidden data, which not only greatly increases the computational cost, but also destroys the blindness of data extraction. To overcome these shortcomings, this paper proposes a lightweight large-capacity image data-hiding technology. Both the data hiding and data extraction are based on looking up a shared codebook table, so the computational cost on both sides is low. The codebook table can be flexibly customized according to the agreement of the sender and receiver of the stego image. It not only ensures the fidelity of stego image but also naturally provides the confidentiality of hidden data. The experimental results and analysis show that its comprehensive performance, including imperceptibility, capacity, complexity, security, and customizability, is better than various state-of-the-art fragile watermarking techniques. Thus, the proposed technique has obvious advantages when used in image authentication, tampering localization, source tracing, and steganography. The proposed technique can be flexibly extended to hide data in other media.
C1 [Ding, Wenjia; Zhang, Huyin; Wang, Yulin] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Reulke, Ralf] Humboldt Univ, Inst Informat, Berlin, Germany.
C3 Wuhan University; Humboldt University of Berlin
RP Zhang, HY; Wang, YL (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM huyinzhang@whu.edu.cn; yulinwang@whu.edu.cn
FU Key R&D Program of Hubei Province, China [2021BAA039]
FX AcknowledgmentThe authors are grateful to anonymous reviewers for useful
   suggestions. This research was sponsored by the Key R&D Program of Hubei
   Province, China (Grant number 2021BAA039). Thank Prof. Xiaochuan Shi,
   who works at the School of Cyber Science and Engineering of Wuhan
   University, for helping to obtain the funding.
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Akgul A, 2017, NONLINEAR DYNAM, V90, P1123, DOI 10.1007/s11071-017-3714-8
   Akhtarkavan E, 2023, IEEE ACCESS, V11, P9701, DOI 10.1109/ACCESS.2023.3238575
   AlShehri L, 2020, MULTIMED TOOLS APPL, V79, P29199, DOI 10.1007/s11042-020-09441-0
   Anand A, 2022, IEEE T COMPUT SOC SY, V9, P1265, DOI 10.1109/TCSS.2021.3125025
   Asad NM., 2012, ASIAN J INFORM TECHN, V11, P151, DOI [10.3923/ajit.2012.151.152, DOI 10.3923/AJIT.2012.151.152]
   Basu S, 2022, MULTIMED TOOLS APPL, V81, P39995, DOI 10.1007/s11042-022-12557-0
   Bose A, 2022, J INF SECUR APPL, V68, DOI 10.1016/j.jisa.2022.103255
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen B, 2023, MULTIMED TOOLS APPL, V82, P1203, DOI 10.1007/s11042-022-13266-4
   Chen Yung-Yao, 2023, Journal of Ambient Intelligence and Humanized Computing, P14785, DOI 10.1007/s12652-018-1048-0
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Dragoi IC, 2021, IEEE T INF FOREN SEC, V16, P187, DOI 10.1109/TIFS.2020.3006382
   Huang, 2015, INT SOC OPTICS PHOT, V2015, P315
   Jhong CL, 2022, IEEE T CIRC SYST VID, V32, P5888, DOI 10.1109/TCSVT.2022.3164013
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2010, IMAGING SCI J, V58, P213, DOI 10.1179/136821910X12651933390584
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Khadse DB, 2023, ARAB J SCI ENG, V48, P1793, DOI 10.1007/s13369-022-06961-9
   Khan LS, 2023, MULTIMED TOOLS APPL, V82, P6917, DOI 10.1007/s11042-022-13623-3
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kim DS, 2018, J REAL-TIME IMAGE PR, V14, P137, DOI 10.1007/s11554-015-0548-9
   Kim HW, 2010, SIGNAL PROCESS, V90, P2605, DOI 10.1016/j.sigpro.2010.02.007
   Kumar S, 2022, APPL INTELL, V52, P7373, DOI 10.1007/s10489-021-02789-2
   Leelavathi R, 2023, MULTIMED TOOLS APPL, V82, P9459, DOI 10.1007/s11042-022-13765-4
   Lefèvre P, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108342
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Li YH, 2020, IEEE ACCESS, V8, P32226, DOI 10.1109/ACCESS.2020.2973179
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Liu JL, 2006, COMPUT STAND INTER, V28, P356, DOI 10.1016/j.csi.2005.07.001
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   Luo YL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114272
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Mandal J., 2017, SIGNAL PROCESS, V122, P234
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   N.R. Neena Raj, 2022, Journal of Visual Communication and Image Representation, DOI 10.1016/j.jvcir.2022.103500
   Patel R, 2021, MULTIMEDIA SYST, V27, P417, DOI 10.1007/s00530-020-00735-9
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P20897, DOI 10.1007/s11042-020-08715-x
   RoselinKiruba R, 2023, VISUAL COMPUT, V39, P59, DOI 10.1007/s00371-021-02312-1
   Singla D., 2012, INT J COMPUTATIONAL, V2, P359
   Sisaudia V, 2022, J INF SECUR APPL, V69, DOI 10.1016/j.jisa.2022.103296
   Tsai CS, 2022, MULTIMED TOOLS APPL, V81, P18807, DOI 10.1007/s11042-022-12684-8
   Wang J, 2019, IEEE T IND INFORM, V15, P6560, DOI 10.1109/TII.2019.2924083
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang ZH, 2012, INFORM SCIENCES, V192, P98, DOI 10.1016/j.ins.2010.07.011
   Xia ZY, 2022, MULTIMED TOOLS APPL, V81, P6477, DOI 10.1007/s11042-021-11704-3
   Yadav GS, 2023, MULTIMED TOOLS APPL, V82, P20233, DOI 10.1007/s11042-022-14322-9
   Yang HF, 2009, RADIOENGINEERING, V18, P509
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yu MJ, 2023, IEEE T CIRC SYST VID, V33, P648, DOI 10.1109/TCSVT.2022.3207270
   Zaid AO, 2009, SIGNAL IMAGE VIDEO P, V3, P197, DOI 10.1007/s11760-008-0094-z
   Zhang H, 2023, MULTIMED TOOLS APPL, V82, P18727, DOI 10.1007/s11042-022-14235-7
NR 56
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44123
EP 44146
DI 10.1007/s11042-023-15514-7
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000977296200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fu, JW
   Cheng, AS
   Yan, ZY
   Zhu, SJ
   Zhang, X
   Thanh, DNH
AF Fu, Junwei
   Cheng, Aosheng
   Yan, Zhenyu
   Zhu, Shenji
   Zhang, Xiang
   Thanh, Dang N. H.
TI Visual analytics of spatio-temporal urban mobility patterns via network
   representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual analytics; Urban mobility pattern; Network representation
   learning; Spatio-temporal evolution
ID VISUALIZATION
AB Bicycle-sharing systems play an essential role in the transportation system of urban cities due to their outstanding advantages such as more convenience and less pollution. The visualization of large-scale and complex spatio-temporal characteristics of bicycle borrowing and returning data can help analyze citizens' travel patterns and explore work-life patterns. However, as the scale of data increases and complex spatio-temporal features emerge, analyzing the spatio-temporal patterns of urban transport based on bike-sharing data remains a daunting task. In this paper, we present a novel approach to analyze spatio-temporal patterns and simultaneously construct a visual analysis system. First, node2vec is employed to learn the vectorized representation of spatial correlation characteristics to build a bicycle-sharing network. The t-SNE is adopted to transform high-dimensional vectors into two-dimensional space. Then, the human mobility patterns are extracted by k-means based on the constructed network. A set of visualization and interaction interfaces are provided to explore the pattern evolutions over time with multiple-view collaboration, enabling users to perceive apparent differences between patterns in detail. Case studies based on real-world datasets and interviews with domain experts demonstrate the effectiveness of our system in providing insight into co-occurrence and facilitating various analytical tasks.
C1 [Fu, Junwei] Zhejiang Univ, State Key Lab Ind Control Technol, Zhejiang Energy Grp R&D Inst, Hangzhou 310012, Peoples R China.
   [Cheng, Aosheng; Yan, Zhenyu; Zhu, Shenji; Zhang, Xiang] Zhejiang Univ Finance & Econ, Sch Informat Management & Artificial Intelligence, Hangzhou 310018, Peoples R China.
   [Zhang, Xiang] Hangzhou Dianzi Univ, Shangyu Sci & Engn Res Inst Co Ltd, Shaoxing 312399, Peoples R China.
   [Thanh, Dang N. H.] Univ Econ Ho Chi Minh City, Coll Technol & Design, Ho Chi Minh City, Vietnam.
C3 Zhejiang University; Zhejiang University of Finance & Economics;
   Hangzhou Dianzi University; Ho Chi Minh City University Economics
RP Zhang, X (corresponding author), Zhejiang Univ Finance & Econ, Sch Informat Management & Artificial Intelligence, Hangzhou 310018, Peoples R China.; Zhang, X (corresponding author), Hangzhou Dianzi Univ, Shangyu Sci & Engn Res Inst Co Ltd, Shaoxing 312399, Peoples R China.; Thanh, DNH (corresponding author), Univ Econ Ho Chi Minh City, Coll Technol & Design, Ho Chi Minh City, Vietnam.
EM fujunwei@zju.edu.cn; 18846920302@163.com; yzy15858923586@163.com;
   z1240401229@163.com; zxiang1216@126.com; thanhdnh@ueh.edu.vn
RI Yan, Zhenyu/U-2106-2019; Thanh, Dang Ngoc Hoang/J-4415-2015
OI Yan, Zhenyu/0000-0002-4433-5211; Thanh, Dang Ngoc
   Hoang/0000-0003-2025-8319
FU University of Economics Ho Chi Minh City (UEH), Vietnam
FX This research is funded by University of Economics Ho Chi Minh City
   (UEH), Vietnam. Fund receiver: Dr. Dang N. H. Thanh.
CR AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bai ZH, 2019, J VISUAL-JAPAN, V22, P927, DOI 10.1007/s12650-019-00578-1
   Burch M, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00088-8
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Chen JG, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3446342
   Feng SS, 2017, AAAI CONF ARTIF INTE, P102
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Jiménez P, 2016, J TRANSP GEOGR, V54, P228, DOI 10.1016/j.jtrangeo.2016.06.010
   Kaltenbrunner A, 2010, PERVASIVE MOB COMPUT, V6, P455, DOI 10.1016/j.pmcj.2010.07.002
   Kim S, 2018, IEEE T VIS COMPUT GR, V24, P1287, DOI 10.1109/TVCG.2017.2666146
   Lee M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140152
   Liu JM, 2015, IEEE DATA MINING, P883, DOI 10.1109/ICDM.2015.99
   Liu YH, 2019, J VISUAL-JAPAN, V22, P1021, DOI 10.1007/s12650-019-00579-0
   Loaiza-Monsalve D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213106
   Mateo-Babiano I, 2017, TRANSP RES PROC, V25, P4970, DOI 10.1016/j.trpro.2017.05.375
   Pan G, 2013, IEEE T INTELL TRANSP, V14, P113, DOI 10.1109/TITS.2012.2209201
   Pucher J, 2011, J TRANSP GEOGR, V19, P332, DOI 10.1016/j.jtrangeo.2010.02.007
   Purnama IBI, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P159, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.46
   Rainer-Harbach M, 2013, LECT NOTES COMPUT SC, V7832, P121, DOI 10.1007/978-3-642-37198-1_11
   Shen ZQ, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P175
   Soh H, 2010, PHYSICA A, V389, P5852, DOI 10.1016/j.physa.2010.08.015
   Song CM, 2010, SCIENCE, V327, P1018, DOI 10.1126/science.1177170
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Wang HD, 2020, IEEE T VEH TECHNOL, V69, P10155, DOI 10.1109/TVT.2020.3002222
   [王云晴 Wang Yunqing], 2019, [膜科学与技术, Membrane Science and Technology], V39, P1
   Wu Y.-H., 2019, Int. J. Transp. Sci. Technol, V8, P318, DOI DOI 10.1016/J.IJTST.2019.05.003
   Xia F, 2020, IEEE T INTELL TRANSP, V21, P2840, DOI 10.1109/TITS.2019.2920962
   Yang X, 2020, P 9 ACM SIGKDD INT W
   Yang ZW, 2022, J TRANSP GEOGR, V100, DOI 10.1016/j.jtrangeo.2022.103318
   Yu DH, 2016, LECT NOTES COMPUT SC, V9931, P92, DOI 10.1007/978-3-319-45814-4_8
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang XH, 2021, TRANSPORT RES D-TR E, V98, DOI 10.1016/j.trd.2021.102961
   Zhang X, 2024, COMPUT J, V67, P236, DOI 10.1093/comjnl/bxac171
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P4839, DOI 10.1109/TVCG.2021.3107297
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhou ZG, 2020, NEUROCOMPUTING, V376, P244, DOI 10.1016/j.neucom.2019.10.072
   Zhou ZG, 2018, J VISUAL LANG COMPUT, V48, P134, DOI 10.1016/j.jvlc.2018.08.007
   Zhou ZG, 2018, J VISUAL LANG COMPUT, V48, P169, DOI 10.1016/j.jvlc.2018.08.009
   Zhou ZG, 2018, J VISUAL-JAPAN, V21, P885, DOI 10.1007/s12650-018-0499-x
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
   Zhou ZG, 2018, J VISUAL LANG COMPUT, V46, P43, DOI 10.1016/j.jvlc.2017.10.003
   Zhou ZG, 2018, J VISUAL-JAPAN, V21, P337, DOI 10.1007/s12650-017-0449-z
   Zhou ZG, 2017, IEEE COMPUT GRAPH, V37, P98, DOI 10.1109/MCG.2017.3621228
   Zhu R, 2020, COMPUT ENVIRON URBAN, V81, DOI 10.1016/j.compenvurbsys.2020.101483
NR 48
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 24
PY 2023
DI 10.1007/s11042-023-15314-z
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E7HY6
UT WOS:000977223400003
DA 2024-07-18
ER

PT J
AU Goyal, R
   Kumar, P
   Singh, VP
AF Goyal, Rupali
   Kumar, Parteek
   Singh, V. P.
TI A Systematic survey on automated text generation tools and techniques:
   application, evaluation, and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Text Generation (ATG); Text Generation Methods; Text
   Generation Tools; Application-Specific Standard Datasets; Text Decoding
   Techniques; Automatic Text Evaluation Methods
ID NEURAL-NETWORK MODELS; GRADIENT DESCENT; TERM; REVIEWS; METRICS
AB Automatic text generation is the generation of natural language text by machines. Enabling machines to generate readable and coherent text is one of the most vital yet challenging tasks. Traditionally, text generation has been implemented either by using production rules of a predefined grammar or performing statistical analysis of existing human-written texts to predict sequences of words. Recently a paradigm change has emerged in text generation, induced by technological advancements, including deep learning methods and pre-trained transformers. However, many open challenges in text generation need to be addressed, including the generation of fluent, coherent, diverse, controllable, and consistent human-like text. This survey aims to provide a comprehensive overview of current advancements in automated text generation and introduce the topic to researchers by offering pointers and synthesis to pertinent studies. This paper studied the relevant twelve years of articles from 2011 onwards in the field of text generation and observed a total of 146 prime studies relevant to the objective of this survey that has been thoroughly reviewed and discussed. It covers core text generation applications, including text summarization, question-answer generation, story generation, machine translation, dialogue response generation, paraphrase generation, and image/video captioning. The most commonly used datasets for text generation and existing tools with their application domain have also been mentioned. Various text decoding and optimization methods have been provided with their strengths and weaknesses. For evaluating the effectiveness of the generated text, automatic evaluation metrices have been discussed. Finally, the article discusses the main challenges and notable future directions in the field of automated text generation for potential researchers.
C1 [Goyal, Rupali; Kumar, Parteek; Singh, V. P.] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Goyal, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rrupali20_phd17@thapar.edu
RI Goyal, Rupali/JZQ-4913-2024
OI Goyal, Rupali/0000-0003-3133-3046; Singh, V. P./0000-0001-7648-9170
CR Abrishami M, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P52, DOI [10.1109/ICWR49608.2020.9122317, 10.1109/icwr49608.2020.9122317]
   Acharya M, 2019, AAAI CONF ARTIF INTE, P8076
   Agrawal R., 2017, INT J ARTIF INTELL A, V8, P45, DOI [10.5121/ijaia.2017.8504, DOI 10.5121/IJAIA.2017.8504]
   Alloatti F, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P250
   Alomari A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101276
   Alsaleh A, 2022, P OSACT 2022 WORKSH, P120
   Ammanabrolu P, 2019, GUIDED NEURAL LANGUA, P46, DOI [10.18653/v1/w19-3405, DOI 10.18653/V1/W19-3405]
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1003
   [Anonymous], 2014, ARXIV14063830
   [Anonymous], 2013, EMNLP
   [Anonymous], 2015, ARXIV
   [Anonymous], 2016, 2016 IEEE Global Communications Conference (GLOBECOM)
   Asghar N, 2018, LECT NOTES COMPUT SC, V10772, P154, DOI 10.1007/978-3-319-76941-7_12
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bapna A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3028
   Barrull R, 2020, ARXIV
   Basu S., 2021, ARXIV
   Baumel T, 2018, ARXIV
   Bott Stefan., 2012, Proceedings of the Third Workshop on Speech and Language Processing for Assistive Technologies, SLPAT'12, P75
   Bowman S. R., 2015, GENERATING SENTENCES
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Buck Christian, 2018, 6 INT C LEARN REPR I
   Cao S, 2021, ARXIV
   Cao ZQ, 2017, AAAI CONF ARTIF INTE, P3152
   Celikyilmaz A, 2020, EVALUATION TEXT GENE, P1
   Chen J, 2021, IEEE ACCESS, V9, P96692, DOI 10.1109/ACCESS.2021.3094263
   Chen S, 1998, P DARPA BROADC NEWS, P275
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Cheng JP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P484
   Cho K., 2014, ARXIV14061078
   Cho WS, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P12
   Chopra S., 2015, C TRACK P
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Chung JY, 2015, PR MACH LEARN RES, V37, P2067
   Clark E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2748
   Clark Elizabeth., 2018, P 2018 C N AM CHAPT, P2250, DOI 10.18653/v1/N18-1204
   Clinchant S, 2019, P 3 WORKSH NEUR GEN, P108, DOI DOI 10.18653/V1/D19-5611
   Cui Q, 2020, IEEE T KNOWL DATA EN, V32, P317, DOI 10.1109/TKDE.2018.2881260
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dinan Emily, 2019, ICLR
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Dong L., 2017, ARXIV
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dozat T., 2016, INT C LEARN REPR SAN
   Du X., 2017, arXiv
   Du X., 2017, P 2017 C EMP METH NA, P2067, DOI 10.18653/v1/D17-1219
   Duan Nan, 2017, P 2017 C EMP METH NA, P866, DOI [10.18653/v1/D17-1090, DOI 10.18653/V1/D17-1090]
   Duchi JC, 2012, IEEE DECIS CONTR P, P5442, DOI 10.1109/CDC.2012.6426698
   Dwivedi SK, 2013, PROC TECH, V10, P417, DOI 10.1016/j.protcy.2013.12.378
   Eddine MK, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1305
   Evans R, 2018, J ARTIF INTELL RES, V61, P1
   Faizan A., 2018, ACM INT C P SER, V10, P3227656
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Feng Ben, 2021, GECCO '21: Proceedings of the Genetic and Evolutionary Computation Conference Companion, P273, DOI 10.1145/3449726.3459441
   Frome A., 2018, PHYSICA C, DOI [10.1016/0921-4534(95)00110-7, DOI 10.1016/0921-4534(95)00110-7]
   Fung P, 2014, INT C LANG RES EV
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gao P, 2018, LECT NOTES COMPUT SC, V11205, P485, DOI 10.1007/978-3-030-01246-5_29
   Garbacea C, 2020, ARXIV
   Gardent C, 2007, ACL 2007 P 45 ANN M, P328
   Gehring J., 2017, P MACHINE LEARNING R, P1243
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Goodrich Ben, 2018, ARXIV180110198
   Goyal T., 2022, ARXIV, p2209.12356
   Grechishnikova D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79682-4
   Gu J, 2017, PROC 2018 C EMPIR ME, P479
   Guan J, 2019, AAAI CONF ARTIF INTE, P6473
   Gupta A, 2018, AAAI CONF ARTIF INTE, P5149
   Harrison B, 2021, AAAI C ARTIFICIAL IN, P191
   Harrison V., 2018, P 11 INT C NAT LANG, P296, DOI DOI 10.18653/V1/W18-6536
   Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689
   He XD, 2017, IEEE SIGNAL PROC MAG, V34, P109, DOI 10.1109/MSP.2017.2741510
   Helel J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1780
   Hidasi B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P241, DOI 10.1145/2959100.2959167
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holtzman Ari, 2019, ARXIV190409751
   Huang C, 2018, P C N AM CHAPT ASS C, V2, P49, DOI DOI 10.18653/V1/N18-2008
   Iyyer M, 2018, P 2018 C N AM CHAPT, V1, P1875, DOI DOI 10.18653/V1/N18-1170
   Jain P, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1707.05501
   Jha S, 2018, ARXIV, P1, DOI DOI 10.15398/JLM.V7I2.214
   Jin Jin, 2015, AIAA SPACE 2015 Conference and Exposition, P1
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Jozefowicz R., 2016, ARXIV
   Kannan A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P955, DOI 10.1145/2939672.2939801
   Karpathy A, 2014, ADV NEUR IN, V27
   KENESHLOO Y, 2020, DEEP REINFORCEMENT L, V31, P2469
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P776, DOI 10.1007/s00034-019-01306-8
   Kim Y, 2019, AAAI CONF ARTIF INTE, P6602
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kiros Ryan., 2014, ABS14112539 CORR
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Knight K, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P703
   Kumar A, 2016, 33 INT C MACH LEARN, V3, P2068
   Kumar V, 2019, P 23 C COMP NAT LANG, P812, DOI [DOI 10.18653/V1/K19-1076, 10.18653/v1/K19-1076, 10.18653/v1/k19-1076]
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lavie A., 2005, P 2 WORKSHOP STAT MA
   Lee J, 2021, NAT ELECTRON, V4, P604, DOI 10.1038/s41928-021-00631-8
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lelkes AD, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2501, DOI 10.1145/3442381.3449892
   Lemberger P, 2020, ARXIV
   Lewis M, 2017, P C EMP METH NAT LAN, P2443
   Lewis M, 2020, P 58 ANN M ASS COMP, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Li B, 2013, P 27 AAAI C ART INT, P598
   Li J., 2016, P 2016 C N AM CHAPT, P110, DOI [10.18653/v1/N16-1014, DOI 10.18653/V1/N16-1014]
   Li J., 2016, EMNLP, DOI [DOI 10.18653/V1/D16-1127.URL, 10.18653/v1/D16-1127, DOI 10.18653/V1/D16-1127]
   Li JW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1106, DOI 10.3115/v1/p15-1107
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li S, 2019, IEEE T EM TOP COMP I, V3, P297, DOI 10.1109/TETCI.2019.2892755
   Li YR, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2041, DOI 10.1145/3404835.3463042
   Li ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3865
   Liao Kexin, 2018, P 27 INT C COMPUTATI, P1178
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100
   Liu P, 2022, ARXIV, DOI [10.18653/v1/2022.acl-long.545, DOI 10.18653/V1/2022.ACL-LONG.545]
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu Xianggen, 2022, P 31 INT JOINT C ART, P4273, DOI DOI 10.24963/IJCAI.2022/593
   Liu Yinhan, 2019, ARXIV190711692
   Lu JS, 2016, ADV NEUR IN, V29
   Lu S., 2018, ARXIV
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Ma S, 2018, P C N AM ASS CHAPT A, V1, P196, DOI [DOI 10.18653/V1/N18-1018, 10.18653/v1/N18-1018]
   Makav B, 2019, 2019 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO 2019), P945, DOI [10.23919/eleco47770.2019.8990630, 10.23919/ELECO47770.2019.8990630]
   Martin LJ, 2018, AAAI CONF ARTIF INTE, P868
   Mehta P, 2018, ASS COMPUT MACH, P2, DOI [10.48550/arXiv.1802.04675, DOI 10.48550/ARXIV.1802.04675]
   Michalopoulos G, 2020, ACM SIGGRAPH 2020 EM, P215, DOI [10.18653/v1/2020.clinicalnlp-1.24, DOI 10.18653/V1/2020.CLINICALNLP-1.24]
   Mou Lili, 2016, P 26 INT C COMP LING, P3349
   Mridha MF, 2021, IEEE ACCESS, V9, P156043, DOI 10.1109/ACCESS.2021.3129786
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan S., 2020, Synthesis Lectures on Human Language Technologies, V13, P1, DOI 10.2200/ S00979ED1V01Y201912HLT044
   Narayan S, 2015, P 52 ANN M ASS COMPU
   Narayan S., 2012, 24 INT C COMP LING C, P100
   Narayan Shashi, 2018, NAACL HLT, DOI DOI 10.18653/V1/N18-1158
   Nguyen A. T., 2021, ARXIV
   Niu Tong, 2018, Transactions of the Association for Computational Linguistics, V6, P373
   PadmaPriya G., 2014, Journal of Computer Science, V10, P1, DOI 10.3844/jcssp.2014.1.9
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park H, 2020, INT CONF COMMUN SYST, DOI 10.1109/comsnets48256.2020.9027420
   Parveen Daraksha., 2016, P OFTHE 2016 C EMPIR, P772
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Paulus Romain, 2017, ARXIV170504304
   Pauws S, 2019, Data Science for Healthcare, P119, DOI [10.1007/978-3-030-05249-2_4, DOI 10.1007/978-3-030-05249-2_4]
   Pawade Dipti, 2018, International Journal of Information Technology and Computer Science, V10, P44, DOI 10.5815/ijitcs.2018.06.05
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Peng B, 2015, ARXIV
   Peng DL, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105319
   Peng Nanyun., 2018, P 1 WORKSHOP STORYTE, P43
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Prakash Aaditya, 2016, P COLING 2016 26 INT
   Przybocki M, 2009, MACH TRANSL, V23, P71, DOI 10.1007/s10590-009-9065-6
   Qi W, 2021, BANG BRIDGING AUTORE
   Qian LH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1993
   Qian LH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3173
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Qian Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4279
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Raffel C, 2020, ARXIV
   Rajasekar AA, 2021, P 12 ACM INT C WEB S, V1
   Rajpurkar P., 2016, P 2016 C EMP METH NA, V2016, P2383
   Ranzato M, 2016, 4 INT C LEARN REPR I
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   REN Z, 2017, PROC CVPR IEEE, P1151, DOI DOI 10.1109/CVPR.2017.128
   Roemmele M., 2015, LECT NOTES COMPUT SC
   Roemmele M, 2016, AAAI CONF ARTIF INTE, P4311
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santhanam S, 2019, SURVEY NATURAL LANGU, DOI [10.5087/dad.DOINUMBER, DOI 10.5087/DAD.DOINUMBER]
   Saxena SS., 2020, INT J ADV SCI TECHNO, V29, P2770
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Scialom T, 2021, ARXIV
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Shetty R, 2017, IEEE I CONF COMP VIS, P4155, DOI 10.1109/ICCV.2017.445
   Song L., 2018, P 2018 C N AM CHAP A, V2, P569, DOI DOI 10.18653/V1/N18-2090
   Sordoni Alessandro, 2015, P 2015 C N AM CHAPT, P196, DOI [10.3115/v1/N15-1020, DOI 10.3115/V1/N15-1020]
   Sriram A, 2018, INTERSPEECH, P387
   Stasaski K., 2021, P 16 WORKSHOP INNOVA, P158
   Su YX, 2021, IEEE-ACM T AUDIO SPE, V29, P2152, DOI 10.1109/TASLP.2021.3087948
   Subramanian S, 2018, MACHINE READING FOR QUESTION ANSWERING, P78
   Sun XW, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3930
   Sutskever I, 2014, ADV NEUR IN, V27
   Tambwekar P, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5982
   Tian C., 2020, P 28 INT C COMP LING, P280
   Tian ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P231, DOI 10.18653/v1/P17-2036
   Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76
   Upadhya BS, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944861
   Vasisht S, 2022, 2022 3 INT C EM TECH, P1, DOI [10.1109/INCET54531.2022.9823967, DOI 10.1109/INCET54531.2022.9823967]
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vijayakumar AK, 2016, 32 AAAI C ARTIFICIAL, P7371
   Vijayakumar AK, 2018, 32 AAAI C ARTIFICIAL, P1
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C., 2016, P 2016 ACM MULT C, P988, DOI 10.1145/2964284.2964299
   Wang P, 2022, 39 INT C MACHINE LEA
   Wang Q, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1810
   Wang T., 2017, ARXIV
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Welleck S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5553
   Wilt C, 2010, P 3 ANN S COMBINATOR, P129
   Wiseman S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3174
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wolk K, 2017, COMPUT SCI-AGH, V18, P129, DOI 10.7494/csci.2017.18.2.129
   Woodsend K, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P565
   Wu Jeff, 2021, Recursively summarizing books with human feedback
   Wu Y, 2016, arXiv, P1
   Wu YX, 2018, AAAI CONF ARTIF INTE, P5602
   Xiao Y, 2022, ACTA MECH SOLIDA SIN, V35, P647, DOI 10.1007/s10338-021-00303-2
   Xie Y., 2018, HDB STAT, V38, P317, DOI [10.1016/bs.host.2018.05.001, DOI 10.1016/BS.HOST.2018.05.001]
   Xing C, 2017, AAAI CONF ARTIF INTE, P3351
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu WR, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00674-7
   Yamada K, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P523
   Yan Z, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P516
   Yang Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3132
   Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72
   Yao K, 2015, ARXIV
   Yao LL, 2019, AAAI CONF ARTIF INTE, P7378
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Yin CC, 2019, IEEE DATA MINING, P728, DOI 10.1109/ICDM.2019.00083
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu L, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23241
   Yu WH, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3512467
   Yuan Xingdi, 2017, P 2 WORKSHOP REPRESE, P15
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang J, 2019, 37 INTCONF MACH LEAR, P11265
   Zhang L., 2017, arXiv
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang T, 2020, ARXIV
   Zhang Xingxing, 2017, P 2017 C EMP METH NA, P584, DOI DOI 10.18653/V1/D17-1062
   Zhao Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3901
   Zhou H, 2018, AAAI CONF ARTIF INTE, P730
   Zhou QY, 2018, LECT NOTES ARTIF INT, V10619, P662, DOI 10.1007/978-3-319-73618-1_56
   Zhou XD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1128
NR 241
TC 5
Z9 5
U1 10
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43089
EP 43144
DI 10.1007/s11042-023-15224-0
EA APR 2023
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000973330100003
DA 2024-07-18
ER

PT J
AU Gupta, A
   Barthwal, A
   Vardhan, H
   Kakria, S
   Kumar, S
   Parihar, AS
AF Gupta, Anshula
   Barthwal, Anurag
   Vardhan, Harsh
   Kakria, Shivani
   Kumar, Sumit
   Parihar, Ashish Singh
TI Evolutionary study of distributed authentication protocols and its
   integration to UAV-assisted FANET
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication protocol; Cryptography; Distributed system; Flying ad hoc
   network; Security; Unmanned aerial vehicle
AB An authentication protocol is one of the fundamental security mechanisms in distributed systems to ensure the integrity and trust level of the nodes during communication. Since message passing is the only way of communication among the systems covered under such an environment, it becomes a necessary condition to check the valid authenticity of the nodes before sending any sensitive information. Such kind of communication between any homogeneous and heterogenous entities (also principals) like, clients, servers, processes etc., must be secure by differentiating the actual legitimate node and intruder node. This process seems to be complex due to the absence of any centralized authority. Nowadays, unmanned aerial vehicle (also, drone)-based network (flying ad hoc network) is in trend due to their versatile dynamic behavior and high applicability region in real-time applications and can be viewed as a special form of distributed network with flying objects. This technology itself is highly capable of carrying any sensitive information from one location to another and also requires much attention for node authentication during the information exchange, which is limited in the existing literature. Hence through our presented work, we studied various distributed authentication protocols and analyzed their possible exposure to flying ad hoc networks. This proposed art-of-study helps to build a sequential relationship to evolve such authentication protocols and opens a unique dimension for flying networks with secure data transfer using these protocols.
C1 [Gupta, Anshula; Vardhan, Harsh; Kakria, Shivani] KIET Grp Inst, Dept Comp Sci, Ghaziabad, Uttar Pradesh, India.
   [Barthwal, Anurag] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Ghaziabad, Uttar Pradesh, India.
   [Kumar, Sumit] Coll Engn, Roorkee, Uttarakhand, India.
   [Parihar, Ashish Singh] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Sect 62, Noida 201309, Uttar Pradesh, India.
C3 KIET Group of Institutions; SRM Institute of Science & Technology Delhi
   NCR (Ghaziabad); Jaypee Institute of Information Technology (JIIT)
RP Parihar, AS (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Sect 62, Noida 201309, Uttar Pradesh, India.
EM anshula.gupta@kiet.edu; ab414@snu.edu.in; harsh.vardhan@kiet.edu;
   shivani.cs@kiet.edu; dr.sumit@coer.ac.in; ashishparihar.cs@gmail.com
RI Parihar, Ashish Singh/AAR-5709-2021; Barthwal, Anurag/AAR-3478-2021
OI Parihar, Ashish Singh/0000-0003-3451-1557; Barthwal,
   Anurag/0000-0002-9499-6851; Kumar, Dr. Sumit/0000-0002-1906-5539
CR Baksi A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530054
   Butila EV, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030620
   Cacacho HRG, 2019, IEEE 11 INT C HUM NA, P1, DOI [10.1109/HNICEM48295.2019.9072807, DOI 10.1109/HNICEM48295.2019.9072807]
   Chen K, 2021, ARXIV
   Euchner F, 2022, ARXIV
   Jackman A., 2021, CRIT MIL STUD, DOI 10.1080/23337486.2020.1846955
   Jan SU, 2021, IEEE ACCESS, V9, P69287, DOI 10.1109/ACCESS.2021.3076692
   Khairallah M, 2022, IACR T SYMMETRIC CRY, V2022, P138, DOI 10.46586/tosc.v2022.i1.138-157
   Limniotis K, 2021, CRYPTOGRAPHY-BASEL, V5, DOI 10.3390/cryptography5040034
   Lindsay D, 2021, COMPUTING, V103, P1859, DOI 10.1007/s00607-020-00900-y
   Mohsan SAH, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6060147
   Naha A, 2023, IEEE T AUTOMAT CONTR, V68, P1941, DOI 10.1109/TAC.2022.3174004
   Nurgaliyev A., 2021, INT C NETWORKING NET, P107, DOI DOI 10.1109/NANA53684.2021.00026
   Parihar A.S., 2021, P INT C MACHINE INTE, DOI [10.1007/978-981-33- 4087-9_5, DOI 10.1007/978-981-33-4087-9_5]
   Parihar A.S., 2022, Lecture Notes in Electrical Engineering, V888, DOI [10.1007/978-981-19-1520-8_3, DOI 10.1007/978-981-19-1520-8_3]
   Parihar AS, 2022, IN PRESS
   Parihar AS, 2023, INT J COMPUT SCI ENG, V26, P78, DOI 10.1504/IJCSE.2023.129149
   Parihar AS, 2022, WIRELESS PERS COMMUN, V126, P3693, DOI 10.1007/s11277-022-09886-6
   Parihar AS, 2022, MULTIMED TOOLS APPL, V81, P18641, DOI 10.1007/s11042-022-11950-z
   Parihar AS, 2021, J SUPERCOMPUT, V77, P14305, DOI 10.1007/s11227-021-03802-8
   Rajasekaran AS, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6010014
   Ravinder N, 2021, DATA SCI COMPUTATION, V1483, DOI [10.1007/978-3-030-91244-4_39, DOI 10.1007/978-3-030-91244-4_39]
   Schindler C., 2022, P7 INT C MOB SEC SER, P1, DOI [10.1109/mobisecserv50855.2022.9727217, DOI 10.1109/MOBISECSERV50855.2022.9727217]
   Shen Y, 2021, INT C EL INF ENG COM, P464, DOI [10.1109/EIECS53707.2021.9588106, DOI 10.1109/EIECS53707.2021.9588106]
   Shenets NN, 2019, AUTOM CONTROL COMPUT, V53, P857, DOI 10.3103/S0146411619080297
   Srivastava A, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100359
   Thomas L, 2022, COMPUT SECUR, V116, DOI 10.1016/j.cose.2022.102657
   Underwood RG, 2022, LECT NOTES COMPUT SC, DOI [10.1007/978-3-030-97902-7_9, DOI 10.1007/978-3-030-97902-7_9]
   Yuan Y, 2020, SCI CHINA TECHNOL SC, V63, P1637, DOI 10.1007/s11431-020-1621-y
   Zukarnain ZA, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040821
NR 30
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42311
EP 42330
DI 10.1007/s11042-023-15197-0
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300004
DA 2024-07-18
ER

PT J
AU Chen, Z
   Ma, CC
   Feng, YJ
   Hou, XS
   Qian, XM
AF Chen, Zan
   Ma, Chaocheng
   Feng, Yuanjing
   Hou, Xingsong
   Qian, Xueming
TI Directional lifting wavelet transform domain image steganography with
   deep-based compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; DLWT; Compressive sensing; Deep-based
ID DCT; REGULARIZATION; ENCRYPTION; ALGORITHM
AB For image steganography, it is necessary to improve the quality of the reconstructed image and stego image as high as possible while maintaining the security of the system. To achieve this goal, we propose a novelty image steganography via deep-based compressive sensing (CS) for the reconstructed image and directional lifting wavelet transform (DLWT) for the stego image. The plain image is first randomly under-sampled and diffused by the measurement matrix and simulated noise to generate the secret image. And the above two matrices were created using a logistic map with two initial values. Then, we embed the secret image into the DLWT domain of the carrier image by singular value decomposition (SVD), resulting in the meaningful stego image. Finally, for enhancing the quality of the reconstructed image from the extracted secret image, we present the deep-based CS reconstruction algorithm. Experimental results verify the effectiveness that the proposed scheme can achieve visual quality, robustness, and security.
C1 [Chen, Zan; Ma, Chaocheng; Feng, Yuanjing] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
   [Hou, Xingsong; Qian, Xueming] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian, Peoples R China.
C3 Zhejiang University of Technology; Xi'an Jiaotong University
RP Feng, YJ (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
EM fyjing@zjut.edu.cn
RI Ma, Chaocheng/HZJ-1495-2023
OI Ma, Chaocheng/0000-0002-4229-4321
FU National Natural Science Foundation of China [62002327, 61976190,
   62073294, 61872286]; Natural Science Foundation of Zhejiang Province
   [LQ21F020017, LZ21F030003]; agricultural and social development
   foundation of Hangzhou [202004A07]
FX This research was sponsored in part by the National Natural Science
   Foundation of China (Grant Nos. 62002327, 61976190, 62073294, 61872286),
   Natural Science Foundation of Zhejiang Province (Grant No. LQ21F020017,
   LZ21F030003), and agricultural and social development foundation of
   Hangzhou (Grant No. 202004A07).
CR Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chen Z, 2021, IEEE T IMAGE PROCESS, V30, P7112, DOI 10.1109/TIP.2021.3088611
   Chen Z, 2020, IEEE T CIRC SYST VID, V30, P1109, DOI 10.1109/TCSVT.2019.2898908
   Chen Z, 2019, ELECTRON LETT, V55, P384, DOI 10.1049/el.2018.8019
   Chen Z, 2018, IEEE T MULTIMEDIA, V20, P1610, DOI 10.1109/TMM.2017.2774004
   Chen Z, 2016, MULTIMED TOOLS APPL, V75, P2565, DOI 10.1007/s11042-015-2578-5
   Christopher M., 2017, P NIPS, P1770
   Cui JB, 2021, IEEE T IMAGE PROCESS, V30, P8567, DOI 10.1109/TIP.2021.3107999
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Evsutin O, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107811
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Kadhim IJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107481
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2013, IEICE T FUND ELECTR, VE96A, P2731, DOI 10.1587/transfun.E96.A.2731
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683
   Mukherjee N, 2021, INFORM SCIENCES, V552, P278, DOI 10.1016/j.ins.2020.11.044
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Ray B, 2021, MULTIMED TOOLS APPL, V80, P33475, DOI 10.1007/s11042-021-11177-4
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Srinivasu LN, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169398
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang BA, 2020, IEEE T NEUR NET LEAR, V31, P4688, DOI 10.1109/TNNLS.2019.2957276
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
   Zhang J, 2020, IEEE J-STSP, V14, P765, DOI 10.1109/JSTSP.2020.2977507
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang ZH, 2021, IEEE T IMAGE PROCESS, V30, P1487, DOI 10.1109/TIP.2020.3044472
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 41
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40891
EP 40912
DI 10.1007/s11042-023-14939-4
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900008
DA 2024-07-18
ER

PT J
AU Yadav, P
   Singh, H
   Khanna, K
AF Yadav, Poonam
   Singh, Hukum
   Khanna, Kavita
TI Introducing real-time image encryption technology using key vault,
   various transforms, and phase masks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear canonical transform; Image scrambling; Metadata security; Key
   vault; Real-time encryption system
ID PLAINTEXT ATTACK; MAP; PLANE; ALGORITHM; SYSTEM; VORTEX
AB In today's world achieving safe and efficient image transmission is a major issue. The image is encrypted by using some encryption technique and each algorithm has its strengths and weaknesses no single encryption mechanism can get the maximum security with minimum execution time. This paper proposes that it is possible to develop a Real-Time encryption algorithm system that uses multiple encryption algorithms in one system and provides adequate means of efficiency with security. In this system, we introduce a key vault that holds information of multiple encryption algorithms with a unique key. For every input image, the system selects a random algorithm for encryption from the key vault, encrypts the image with the selected encryption algorithm, and attached the key generated in the key vault to the encrypted image. At the receiver end first, we find out the key to identify the algorithm by which the image is encrypted, then get encryption algorithm details and perform decryption accordingly. We can increase the rate of its difficulty to improve its resistance against attacks by adding more and more encryption algorithms. It is quite impossible to break the proposed encryption technique as it randomly changes the encryption algorithm for each input image in randomly at run-time. The proposed cryptosystem can resist most of the existing attacks, as proved by using performance metrics and results. The aim is to provide a more secure image encryption system with reasonable computational complexity. This project has been implemented, key vault in ASP.NET and transforms and masks in MATLAB (2019a). Experiments confirm the feasibility and efficiency of the proposed real-time encryption system.
C1 [Yadav, Poonam] NorthCap Univ, Dept Comp Sci Engn, Gurugram, India.
   [Singh, Hukum] NorthCap Univ, Dept Appl Sci, Gurugram, India.
   [Khanna, Kavita] Delhi Skill & Entrepreneurship Univ, Delhi, India.
C3 The Northcap University; The Northcap University
RP Yadav, P (corresponding author), NorthCap Univ, Dept Comp Sci Engn, Gurugram, India.
EM poonam17csd011@ncuindia.edu; hukumsingh@ncuindia.edu;
   Kavita.khanna@dseu.ac.in
OI yadav, Poonam/0000-0001-7405-0797
CR Akhavan A, 2006, LECT NOTES COMPUT SC, V4263, P963
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Azzaz MS, 2013, J REAL-TIME IMAGE PR, V8, P297, DOI 10.1007/s11554-011-0219-4
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Behnia S, 2013, J SYST SOFTWARE, V86, P2429, DOI 10.1016/j.jss.2013.04.088
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Dhopavkar TA, 2022, MULTIMED TOOLS APPL, V81, P43189, DOI 10.1007/s11042-022-13162-x
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar M., 2019, HDB MULTIMEDIA INFOR
   Diwakar M., 2019, SOFT COMPUTING THEOR
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Duan XT, 2019, J REAL-TIME IMAGE PR, V16, P765, DOI 10.1007/s11554-018-0826-4
   Elrefaey A, 2021, J REAL-TIME IMAGE PR, V18, P1897, DOI 10.1007/s11554-020-01064-w
   Girija R, 2019, OPTIK, V187, P238, DOI 10.1016/j.ijleo.2019.04.090
   Girija R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0192-9
   Girija R, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1472-6
   Goodman J. W., 2005, INTRO FOURIER OPTICS, DOI DOI 10.1117/1.601121
   Gopinathan U, 2006, OPT EXPRESS, V14, P3181, DOI 10.1364/OE.14.003181
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kaur A, 2022, ECOL INFORM, V68, DOI 10.1016/j.ecoinf.2021.101549
   Kaur M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5012496
   Khurana M., 2019, RECENT PATENTS COMPU, V12, P80, DOI [10.2174/2213275911666181030111102, DOI 10.2174/2213275911666181030111102]
   Khurana M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0190-y
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P9791, DOI 10.1007/s11042-018-6599-8
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li FY, 2019, J REAL-TIME IMAGE PR, V16, P775, DOI 10.1007/s11554-018-0801-0
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Maan P, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0205-8
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Shah AA, 2020, J REAL-TIME IMAGE PR, V17, P2139, DOI 10.1007/s11554-020-01008-4
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Singh H., 2014, ASIAN J PHYS, V23, P597
   Singh H, 2018, IET IMAGE PROCESS, V12, P1994, DOI 10.1049/iet-ipr.2018.5399
   Singh H, 2018, J MOD OPTIC, V65, P2065, DOI 10.1080/09500340.2018.1496286
   Singh H, 2017, OPT APPL, V47, P557, DOI 10.5277/oa170406
   Singh H, 2016, OPT LASER ENG, V81, P125, DOI 10.1016/j.optlaseng.2016.01.014
   Singh H, 2015, INT J OPT, V2015, DOI 10.1155/2015/926135
   Srinivasu PN, GAZI U J SCI
   Sun FY, 2007, CHINESE PHYS, V16, P3616, DOI 10.1088/1009-1963/16/12/011
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang XY, 2018, IEEE ACCESS, V6, P62272, DOI 10.1109/ACCESS.2018.2875676
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Zhang CG, 2013, OPT EXPRESS, V21, P28523, DOI 10.1364/OE.21.028523
NR 58
TC 0
Z9 0
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39099
EP 39117
DI 10.1007/s11042-023-14715-4
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983783100007
DA 2024-07-18
ER

PT J
AU Wang, CX
   Qin, JW
   Fu, XS
AF Wang, Chuanxu
   Qin, Jianwei
   Fu, Xiaoshan
TI OA-Net: outlier weakening and adaptive voxel encoding-based 3d object
   detection network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D object detection; Outlier weakening; Attention mechanism; Adaptive
   pooling; Spatial voxel coding
AB This paper focuses on the adverse impact of outlier points and the ambiguity of candidate localizations in 3D object detection in terms of point cloud dataset. First, outlier points can disperse real feature extracting and mislead object detection, we propose an outlier weakening strategy. The neighborhood points of each point in the point set can be established via multi-directional search algorithm, and the correlations among points in the neighborhood are figured out via self-attention mechanism, then each point representation can be enhanced with the key information from its neighborhood, thus the negative impact of outlier points will be weakened due to obtaining real knowledge of object from neighborhood context. Second, multiple proposed boxes for object localization usually containing the same sampling points, this causes vagueness in differing them from each other and leads to incorrect object positioning. This paper proposes a voxel coding strategy with adaptive pooling, the candidate boxes are divided into voxels, and each voxel is further divided into multiple columns, then they are weighted and aggregated according to the importance of each column, thus can pop out the most confident spatial voxel encodings as reliable object localization nominees. This algorithm achieves an average accuracy of 82.98% and 93.2% on the KITTI dataset Car category and ModelNet40 dataset, respectively.
C1 [Wang, Chuanxu; Qin, Jianwei; Fu, Xiaoshan] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Zhonghan St, Qingdao 266100, Shandong, Peoples R China.
C3 Qingdao University of Science & Technology
RP Qin, JW (corresponding author), Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Zhonghan St, Qingdao 266100, Shandong, Peoples R China.
EM wangchuanxu_qd@qust.edu.cn; Qustqin@gmail.com; 247862158@qq.com
OI Qin, Jianwei/0000-0002-4411-6203
FU National Science Foundation of China [61672305]
FX The authors gratefully acknowledge the National Science Foundation of
   China's financial support under Grant number 61672305. Thanks are due to
   Peng Liu and Hao Zhang for assistance with the experiments, and to Sifan
   Liu, Guocheng Lin, Huiru Wang, and Jing Wang for valuable discussion.
   Simultaneously, thanks to 511 Laboratory for providing experimental
   equipment support. Finally, I'd like to express my gratitude to the
   editor and all of the reviewers who will be contributing to this
   article.
CR Aggarwal AK, 2017, ADV LIBR INF SCI, P242, DOI 10.4018/978-1-5225-1653-8.ch013
   Ali W, 2019, LECT NOTES COMPUT SC, V11131, P716, DOI 10.1007/978-3-030-11015-4_54
   Aranjuelo N, 2020, INT WORKSH SOFT COMP, P813
   Bhattacharyya P, 2021, IEEE INT CONF COMP V, P3022, DOI 10.1109/ICCVW54120.2021.00337
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Guan TR, 2022, IEEE WINT CONF APPL, P2293, DOI 10.1109/WACV51458.2022.00235
   Ji CF, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103634
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Li B, 2016, Arxiv, DOI arXiv:1608.07916
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li Y., 2018, Adv. Neural Inf. Process. Syst., V31
   Li ZC, 2021, PROC CVPR IEEE, P7542, DOI 10.1109/CVPR46437.2021.00746
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Lu Q, 2020, COMPUT GRAPH-UK, V86, P42, DOI 10.1016/j.cag.2019.11.005
   Notchenko A., 2017, INT C AN IM SOC NETW, P245
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Simon M, 2019, LECT NOTES COMPUT SC, V11129, P197, DOI 10.1007/978-3-030-11009-3_11
   Sun F, 2020, MULTIMED TOOLS APPL, P1
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie L, 2020, AAAI CONF ARTIF INTE, V34, P12460
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhou Yin, 2020, C ROBOT LEARNING, P923
NR 50
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 28
PY 2023
DI 10.1007/s11042-023-15094-6
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C0BC9
UT WOS:000958668000001
DA 2024-07-18
ER

PT J
AU Viji, D
   Revathy, S
AF Viji, D.
   Revathy, S.
TI A hybrid approach of Poisson distribution LDA with deep Siamese Bi-LSTM
   and GRU model for semantic similarity prediction for text data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Siamese; TF-IDF-term frequency inverse-document frequency; Poisson
   distribution; LDA; Log-likelihood; Bi-LSTM-bidirectional long-short term
   memory network; GRU; Feature vectors; Semantic text-similarity; NLP-
   natural language processing
ID IDENTIFICATION; SYSTEM
AB Prediction of semantic similarity between text data is an open and challenging research issue in the NLP-Natural Language-processing field. Traditional semantic text-similarity techniques capturing text lexical features neglect syntactic and semantic text properties and are exhibited with higher dimensions of feature vectors. To overcome these issues, the present study aims to develop a hybrid approach integrating Deep Siamese Bi-LSTM-Bidirectional Long-short term Memory network and GRU-Gated Recurrent-Unit neural network training model. The proposed model is employed in the weight estimation of vectors and minimizing feature vector dimension before the training phases. Initially, Pre-processing phase, eliminates special characters from text form, converting them to feature vectors through vectorization and weight values are updated using Weighted TF-IDF-Term Frequency Inverse-Document Frequency aided by the log-likelihood Weight calculation method. The Poisson Normal LDA-Linear-discriminant analysis technique reduced the dimensions of the feature vector. Such embedded vectors as weight values are fed into the training model, wherein the trained model estimates similarity scores of input data and performs text classification using Deep Siamese Bi-LSTM and GRU classifiers. The proposed model undergoes performance assessment by attaining 19% improved accuracy rate by using STS Dataset than the existing methods. The model also showed better results for the other datasets. The higher accuracy and F1 score elucidated the efficiency of the proposed framework.
C1 [Viji, D.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
   [Viji, D.] SRM Inst Technol, Dept Comp Technol, Chengalpattu, India.
   [Revathy, S.] Sathyabama Inst Sci & Technol, Dept Informat Technol, Chennai, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Viji, D (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.; Viji, D (corresponding author), SRM Inst Technol, Dept Comp Technol, Chengalpattu, India.
EM dviji2k@gmail.com; ramesh.revathy@gmail.com
CR [Anonymous], 2018, 2018 4 INT C OPT APP
   Araque O, 2019, KNOWL-BASED SYST, V165, P346, DOI 10.1016/j.knosys.2018.12.005
   Avasthi Sandhya, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1387), P343, DOI 10.1007/978-981-16-2594-7_28
   Avasthi Sandhya, 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence (ICIMMI 2020). Lecture Notes in Networks and Systems (LNNS 166), P21, DOI 10.1007/978-981-15-9689-6_3
   Avasthi S, 2021, ADV INFORM COMMUNICA, P385
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bicici E., 2022, SN COMPUT SCI, V3, P1, DOI [10.1007/s42979-022-01183-0, DOI 10.1007/S42979-022-01183-0]
   Bin Sarwar T, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1024
   Bollegala D, 2020, Arxiv, DOI arXiv:2002.11004
   Camacho-Collados J, 2018, Arxiv, DOI [arXiv:1707.01780, DOI arXiv:1707.01780.v3]
   Choi H, 2019, INFORM SCIENCES, V485, P413, DOI 10.1016/j.ins.2019.02.026
   Dias L, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.171545
   Gudakahriz S.J., 2020, INF SYST TELECOMMUN, V29, P45, DOI DOI 10.7508/JIST.2020.01.005
   Hu P, 2019, IEEE T IMAGE PROCESS, V28, P5352, DOI 10.1109/TIP.2019.2913511
   Huang X, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419500174
   Jia Guo, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P246, DOI 10.1109/DSC50466.2020.00044
   Li X, 2020, IEEE ACCESS, V8, P60790, DOI 10.1109/ACCESS.2020.2984009
   Li X, 2019, INT J INNOV COMPUT I, V15, P1685, DOI 10.24507/ijicic.15.05.1685
   Liu YY, 2022, PHYSICA A, V590, DOI 10.1016/j.physa.2021.126744
   Luo LX, 2019, PERS UBIQUIT COMPUT, V23, P405, DOI 10.1007/s00779-018-1183-9
   Mahmoud A, 2021, ARAB J SCI ENG, V46, P4163, DOI 10.1007/s13369-020-05320-w
   Meenakshi D., 2022, B ELECT ENG INFORM, V11, P2124, DOI [10.11591/eei.v11i4.3284, DOI 10.11591/EEI.V11I4.3284]
   Nanda R, 2019, ARTIF INTELL LAW, V27, P199, DOI 10.1007/s10506-018-9236-y
   Tien NH, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102090
   Othman N, 2022, DATA KNOWL ENG, V138, DOI 10.1016/j.datak.2021.101962
   Pavan Kumar C. S., 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P309, DOI 10.1007/978-981-13-1927-3_33
   Prasetya DD., 2018, International Journal of Advances in Intelligent Informatics, V4, P63
   Rahim MMAA, 2021, Measuring semantic similarity for arabic sentences using machine learning
   ROUL R.K., 2017, 2017 14th IEEE India council international conference (INDICON), P1
   Shihab MSH, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392734
   Singh A.K., 2019, International Journal of Advanced Computer Science and Applications, V10, P7, DOI [DOI 10.14569/IJACSA.2019.0100742, 10.14569/IJACSA.2019.0100742]
   Sogancioglu G, 2017, BIOINFORMATICS, V33, pI49, DOI 10.1093/bioinformatics/btx238
   Song H-J, 2021, J INTELL FUZZY SYST, P1
   Sravanthi P., 2017, International Research Journal of Engineering and Technology (IRJET), V4, P156
   Sun FK, 2018, C IND ELECT APPL, P1189, DOI 10.1109/ICIEA.2018.8397890
   Tao J., 2020, J PHYS C SER, V1601, P042007, DOI [10.1088/1742-6596/1601/4/042007, DOI 10.1088/1742-6596/1601/4/042007]
   Tomer M, 2020, ARAB J SCI ENG, V45, P10743, DOI 10.1007/s13369-020-04827-6
   Townes FW, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-019-1861-6
   Vekariya DV, 2020, INT CONF ADVAN COMPU, P518, DOI [10.1109/ICACCS48705.2020.9074471, 10.1109/icaccs48705.2020.9074471]
   Wu J, 2020, 2020 5 INT C CONTROL, P1
   Xiong CZ, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/6074840
   Xu CL, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115182
   Xu GX, 2019, IEEE ACCESS, V7, P21527, DOI 10.1109/ACCESS.2019.2897475
   Yang JQ, 2021, FUTURE GENER COMP SY, V114, P169, DOI 10.1016/j.future.2020.07.043
   Yang YF, 2018, Arxiv, DOI arXiv:1804.07754
   Yang ZC, 2018, 32 C NEURAL INFORM P, V31
   Yu SJ, 2020, J INTELL FUZZY SYST, V39, P333, DOI 10.3233/JIFS-191171
   Yuanyu Yang, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P22, DOI 10.1109/DSC50466.2020.00012
   Zhang PY, 2021, IEEE ACCESS, V9, P8433, DOI 10.1109/ACCESS.2021.3049378
   Zhang XS, 2021, Arxiv, DOI arXiv:2008.11869
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhao X, 2022, ANN OPER RES, P1
   Zheng T, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0880-2
   Zhu Z., 2018, CCKS TASKS, V2242, P44
   Zulqarnain M., 2019, Int. J. Inf. Vis., V3, P377, DOI 10.30630/joiv.3.4.289
NR 59
TC 1
Z9 1
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15050-4
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900003
DA 2024-07-18
ER

PT J
AU Shi, H
   Zhou, SQ
   Chen, MH
   Li, MC
AF Shi, Hui
   Zhou, Shouquan
   Chen, Meihan
   Li, Mingchu
TI A novel zero-watermarking algorithm based on multi-feature and DNA
   encryption for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermarking; Multi-feature; DNA encryption; Hyperchaotic system
ID MRI; CT; SCHEME; CHAOS
AB Different from the traditional watermarking schemes, zero-watermarking schemes are lossless embedding methods, which are applicable to be used in medical and other fields requiring high-integrity image copyright protection. However, with the improvement of telemedicine in the cloud, problems such as the leakage of patients' personal information, the theft, and tamper have become increasingly prominent. How to more effectively ensure the information security and the copyright of medical images has attracted great attention of scholars in relevant fields. In this paper, combined with the characteristics of medical images, a robustness zero-watermarking scheme for medical images based on multi-feature and DNA encryption is proposed, focusing on how to improve its security and robustness. First, the medical image is divided into ROI (region of interest) and RONI (region of non-interest), and the ROI is further divided into layers. Then, CNN feature of ROI, the LBP, Gabor and variance features of each layer are extracted to enhance distinguishability and robustness. Moreover, a sine system based chaotic map is used to improve security of features and watermarks. Finally, DNA-based encryption, Zig-Zag and chaotic map are used to ensure the security of medical images. The proposed scheme can encrypt the features, watermarks and medical images effectively. The evaluation of the performance of encryption algorithms is compreshensive, including correlation analysis, which is close to 0 for the encrypted image; key sensitivity analysis, in which the similarity with slightly wrong key is below 0.5; information entropy, which is close to the theoretical value of 8 for encrypted images; encryption quality analysis with EQ of 380 and histogram analysis. The experimental results also show that this algorithm is highly robust to geometric attacks and common attacks, and most BER values and NC values under different attacks are about 0.01 and 0.99, respectively. It further highlights that the proposed scheme not only ensures the robustness and security, but also satisfies the lossless quality requirement, which outperforms the state-of-the-art schemes.
C1 [Shi, Hui; Zhou, Shouquan; Chen, Meihan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Shi, Hui; Li, Mingchu] Dalian Univ Technol, Sch Software Technol, Dalian 116029, Peoples R China.
   [Shi, Hui] Dalian Yongjia Elect Technol Co LTD, Dalian 116029, Peoples R China.
C3 Liaoning Normal University; Dalian University of Technology
RP Shi, H (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.; Shi, H (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian 116029, Peoples R China.; Shi, H (corresponding author), Dalian Yongjia Elect Technol Co LTD, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com
RI l, m/JAC-6601-2023
OI Shi, Hui/0000-0001-5029-7461
FU National Science Foundation of China [61976109, 62006108, 61601214,
   61877007]; Liaoning Revitalization Talents Program [XLYC2006005];
   Liaoning Provincial Education Department [WQ2020014]; Scientific
   Research Project of Liaoning Province [LJKZ0963]; Key R&D projects of
   Liaoning Provincial Department of Science and Technology; Liaoning
   Provincial Key Laboratory Special Fund
FX Supported by National Science Foundation of China (No.61976109,
   62006108, 61601214, 61877007); Liaoning Revitalization Talents Program
   (No.XLYC2006005); Liaoning Provincial Education Department (Grant No.
   WQ2020014); Scientific Research Project of Liaoning
   Province(No.LJKZ0963); Key R&D projects of Liaoning Provincial
   Department of Science and Technology; Liaoning Provincial Key Laboratory
   Special Fund.
CR Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Erasmus JJ, 2008, CLIN CHEST MED, V29, P39, DOI 10.1016/j.ccm.2007.11.004
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Gong LH, 2022, PHYSICA A, V591, DOI 10.1016/j.physa.2021.126793
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Han Baoru, 2016, International Journal of Bioautomation, V20, P69
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2021, IEEE T SYST MAN CY-S, V51, P3713, DOI 10.1109/TSMC.2019.2932616
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   [黄林荃 Huang Linquan], 2020, [小型微型计算机系统, Journal of Chinese Computer Systems], V41, P1959
   Issar Pratibha, 2017, J Assoc Physicians India, V65, P16
   Khan MS, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P971, DOI 10.1109/NGCT.2015.7375265
   LAISSY JP, 1989, MAGN RESON IMAGING, V7, P55, DOI 10.1016/0730-725X(89)90324-X
   Liu FN, 2019, RES MED IMAGE SEGMEN
   Liu J, 2020, IEEE ACCESS, V8, P93939, DOI 10.1109/ACCESS.2020.2995015
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Liu LF, 2018, MULTIMED TOOLS APPL, V77, P21445, DOI 10.1007/s11042-017-5594-9
   Liu X, 2018, PROC SPIE, P381
   Liu XY, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116124
   Ma B, 2021, J MATH IMAGING VIS, V63, P1160, DOI 10.1007/s10851-021-01048-w
   Millon D, 2018, EUR RADIOL, V28, P770, DOI 10.1007/s00330-017-5021-7
   Niu Y, 2020, J ELECTRON INF TECHN, V42, P1383, DOI 10.11999/JEIT190849
   Pelkonen O, 2004, ACTA RADIOL, V45, P259, DOI 10.1080/02841850410004184
   Pezeshk A, 2019, IEEE J BIOMED HEALTH, V23, P2080, DOI 10.1109/JBHI.2018.2879449
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P1355, DOI 10.1007/s11517-021-02374-2
   Ren H., 2022, P 43 INT ACM SIGIR C, V43, P45, DOI DOI 10.11959/J.ISSN.1000-436X.2022101
   Schelkens P, 2003, IEEE T MED IMAGING, V22, P441, DOI 10.1109/TMI.2003.809582
   Singh A, 2020, J KING SAUD UNIV-COM, V32, P895, DOI 10.1016/j.jksuci.2017.12.008
   Wang L, 2018, IEICE T INF SYST, VE101D, P261, DOI 10.1587/transinf.2017EDL8188
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang XY, 2019, CHINESE PHYS B, V28, DOI 10.1088/1674-1056/28/4/040504
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 41
TC 7
Z9 7
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36507
EP 36552
DI 10.1007/s11042-023-15074-w
EA MAR 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950119600001
DA 2024-07-18
ER

PT J
AU Idrizi, E
   Filiposka, S
   Trajkovikj, V
AF Idrizi, Ermira
   Filiposka, Sonja
   Trajkovikj, Vladimir
TI Gender impact on STEM online learning- a correlational study of gender,
   personality traits and learning styles in relation to different online
   teaching modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online education; STEM; Big five; Gender; Learning style
ID TECHNOLOGY; SUCCESS; SCIENCE
AB STEM (science, technology, engineering and mathematics) education benefits both individuals and society. It supports individuals by increasing their critical-thinking skills, encouraging creativity, as well as providing a basis for new inventions. The underrepresentation of women in STEM is a complex issue with various causes and different approaches of addressing it, where most likely gender differences are caused by desires and choice rather than abilities and performance. This paper explores differences in online and traditional STEM learning based on gender. It examines in detail recently identified patterns of women's success, their access to STEM online courses, and their overall course experience during such courses. We analyzed results from a case study in which students were enrolled for one semester in two STEM online courses and completed questionnaires about their character traits and learning styles and how they relate to academic performance. The objective of our research is to analyze academic success during traditional classes and online classes, with focus on gender and identify how character traits and learning styles correlate with gender in online classes. The main outcome of our research is that female students, which study in the field of STEM in particular computer science, are trustworthy and autonomous students who can outperform their male counterparts during traditional courses, where during online courses male students still exceed slightly female students. The trait of Consciousness is a success predictor regardless of gender and learning environment, while the trait of Neuroticism has negative impact the traditional learning environment, Extraversion shows negative impact in online learning. Learning styles show gender differences, where female students prefer the style of read/write while male students favor kinesthetic.
C1 [Idrizi, Ermira; Filiposka, Sonja; Trajkovikj, Vladimir] South East European Univ, Fac Contemporary Sci & Technol, Tetovo, North Macedonia.
RP Idrizi, E (corresponding author), South East European Univ, Fac Contemporary Sci & Technol, Tetovo, North Macedonia.
EM ermiraidrizi@gmail.com; sonja.filiposka@finki.ukim.mk;
   trvlado@finki.ukim.mk
RI Idrizi, Ermira/JZD-2687-2024; Filiposka, Sonja/AAA-1343-2019; Trajkovik,
   Vladimir/K-9758-2019
OI Filiposka, Sonja/0000-0003-0034-2855; Idrizi, Ermira/0000-0002-6663-4773
CR Abidin Z, 2018, INT J INF LEARN TECH, V35, P266, DOI 10.1108/IJILT-11-2017-0109
   Abzug R, 2015, J APPL RES HIGH EDUC, V7, P400, DOI 10.1108/JARHE-03-2014-0042
   Adedoyin Olasile Babatunde, 2023, Interactive Learning Environments, P863, DOI 10.1080/10494820.2020.1813180
   Ahmedien DAM, 2021, MED HUMANIT, V47, P283, DOI 10.1136/medhum-2020-011862
   Alam A., 2022, PSYCHOL SOCIOCULTURA, DOI [10.2991/ahsseh.k.220105.012, DOI 10.2991/AHSSEH.K.220105.012]
   [Anonymous], 2019, J MANAG SCI, DOI [10.34038/jms.2019.01.002, DOI 10.34038/JMS.2019.01.002]
   Balasubramaniam G., 2016, Education in Medicine Journal, V8, P15, DOI DOI 10.5959/EIMJ.V8I4.440
   Baloglu M, 2020, CURR OPIN PSYCHOL, V36, P124, DOI 10.1016/j.copsyc.2020.05.008
   Bhagat KK, 2019, AUSTRALAS J EDUC TEC, V35, P98, DOI 10.14742/ajet.4162
   Bird SR, 2021, GENDER SOC, V35, P422, DOI 10.1177/08912432211008814
   Card D, 2021, ECON INQ, V59, P9, DOI 10.1111/ecin.12934
   Ceci SJ, 2010, CURR DIR PSYCHOL SCI, V19, P275, DOI 10.1177/0963721410383241
   Cheryan S, 2017, PSYCHOL BULL, V143, P1, DOI 10.1037/bul0000052
   Cuadrado-García M, 2010, PROCD SOC BEHV, V2, P367, DOI 10.1016/j.sbspro.2010.03.027
   Cvencek D, 2011, CHILD DEV, V82, P766, DOI 10.1111/j.1467-8624.2010.01529.x
   Dag F, 2009, PROCD SOC BEHV, V1, P862, DOI 10.1016/j.sbspro.2009.01.155
   Dasgupta N., 2014, Policy Insights Behav. Brain Sci, V1, P21, DOI [10.1177/2372732214549471, DOI 10.1177/2372732214549471]
   Delaney J, 2019, ECON EDUC REV, DOI [10.2139/ssrn.3390163, DOI 10.2139/SSRN.3390163]
   Eddy SL, 2016, PHYS REV PHYS EDUC R, V12, DOI 10.1103/PhysRevPhysEducRes.12.020106
   Etzkowitz H., 2000, ATHENA UNBOUND ADV W, DOI DOI 10.1017/CBO9780511541414
   Fleming N., 2006, Educational development, SEDA, V7, P4, DOI DOI 10.1111/1467-8535.00173
   Furnham A, 2013, INSTR SCI, V41, P975, DOI 10.1007/s11251-012-9259-9
   Ghazvini SD, 2011, PROCD SOC BEHV, V15, P1040, DOI 10.1016/j.sbspro.2011.03.236
   Hoyles C, 1992, LEARNING MATH LOGO, DOI [10.7551/mitpress/4171.003.0016, DOI 10.7551/MITPRESS/4171.003.0016]
   Idrizi E, 2018, COMM COM INF SC, V940, P247, DOI 10.1007/978-3-030-00825-3_21
   Idrizi E, 2021, INT REV RES OPEN DIS, V22, P205
   Kausar A., 2019, INT J PHYSL, V7, P61, DOI [10.5958/2320-608X.2019.00140.9, DOI 10.5958/2320-608X.2019.00140.9]
   Keller H, 2013, COMPUT HUM BEHAV, V29, P2494, DOI 10.1016/j.chb.2013.06.007
   Khodabandelou R., 2014, Contemporary Educational Technology, V5, P257
   Korkmaz G., 2020, INT J TECH EDUC SCI, V4, P293
   Korpershoek H, 2012, SEX ROLES, V67, P630, DOI 10.1007/s11199-012-0222-7
   Kuchynka SL, 2022, SOC ISS POLICY REV, V16, P252, DOI 10.1111/sipr.12087
   Kurtz S, 2007, J BONE JOINT SURG AM, V89A, P780, DOI 10.2106/JBJS.F.00222
   Lim K, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12114465
   Little-Wiles Julie, 2014, 2014 IEEE Frontiers in Education Conference (FIE). Proceedings, P1, DOI 10.1109/FIE.2014.7044069
   Malisch JL, 2020, P NATL ACAD SCI USA, V117, P15378, DOI 10.1073/pnas.2010636117
   Master A, 2021, CHILD DEV PERSPECT, V15, P203, DOI 10.1111/cdep.12424
   McCrae R., 2013, Personality disorders and the five-factor model of personality, V3rd, P15, DOI DOI 10.1037/13939-002
   Mccrae R.R., 2004, PsycTESTS Dataset, DOI DOI 10.1037/T07553-000
   McLure FI, 2022, LEARNING ENVIRON RES, V25, P917, DOI 10.1007/s10984-021-09392-9
   Peri G, 2015, J LABOR ECON, V33, pS225, DOI 10.1086/679061
   Pilotti MAE, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041671
   Rosenzweig EQ, 2016, EDUC PSYCHOL-US, V51, P146, DOI 10.1080/00461520.2016.1154792
   Sáiz-Manzanares MC, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031166
   Sarabi-Asiabar A, 2015, IRAN RED CRESCENT ME, V17, DOI 10.5812/ircmj.18250
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Shea P, 2019, ONLINE LEARN, V23
   Shuib M., 2015, The Journal of Educators Online-JEO, V13, P103, DOI DOI 10.9743/JEO.2015.2.3
   Soric I, 2017, LEARN INDIVID DIFFER, V54, P126, DOI 10.1016/j.lindif.2017.01.024
   Steenwyk JL, 2021, MICROBIOL RESOUR ANN, V10, DOI 10.1128/MRA.00871-21
   Stoet G, 2018, PSYCHOL SCI, V29, P581, DOI 10.1177/0956797617741719
   Torres-Torres YD, 2021, TEEM'21: NINTH INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY, P25, DOI 10.1145/3486011.3486414
   Trull TJ, 1995, PSYCHOL ASSESSMENT, V7, P508, DOI 10.1037/1040-3590.7.4.508
   Wang MT, 2013, PSYCHOL SCI, V24, P770, DOI 10.1177/0956797612458937
   Wang XL, 2013, AM EDUC RES J, V50, P1081, DOI 10.3102/0002831213488622
   Wehrwein EA, 2007, ADV PHYSIOL EDUC, V31, P153, DOI 10.1152/advan.00060.2006
   WILLIAMSON DF, 1989, ANN INTERN MED, V110, P916, DOI 10.7326/0003-4819-110-11-916
   Zapata-Cáceres M, 2021, IEEE ACCESS, V9, P123588, DOI 10.1109/ACCESS.2021.3110475
NR 58
TC 0
Z9 0
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30201
EP 30219
DI 10.1007/s11042-023-14908-x
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000945313000009
PM 37362705
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Shukla, AK
   Seth, T
   Muhuri, PK
AF Shukla, Amit K.
   Seth, Taniya
   Muhuri, Pranab K.
TI Artificial intelligence centric scientific research on COVID-19: an
   analysis based on scientometrics data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Bibliometric analysis; Computer science
   research; Coronavirus research; COVID-19; Publications; Research
   analysis
ID BIBLIOMETRIC ANALYSIS; AI; PUBLICATIONS; PREDICTION; FRAMEWORK
AB With the spread of the deadly coronavirus disease throughout the geographies of the globe, expertise from every field has been sought to fight the impact of the virus. The use of Artificial Intelligence (AI), especially, has been the center of attention due to its capability to produce trustworthy results in a reasonable time. As a result, AI centric based research on coronavirus (or COVID-19) has been receiving growing attention from different domains ranging from medicine, virology, and psychiatry etc. We present this comprehensive study that closely monitors the impact of the pandemic on global research activities related exclusively to AI. In this article, we produce highly informative insights pertaining to publications, such as the best articles, research areas, most productive and influential journals, authors, and institutions. Studies are made on top 50 most cited articles to identify the most influential AI subcategories. We also study the outcome of research from different geographic areas while identifying the research collaborations that have had an impact. This study also compares the outcome of research from the different countries around the globe and produces insights on the same.
C1 [Shukla, Amit K.] Univ Jyvaskyla, Fac Informat Technol, Box 35 Agora, Jyvaskyla 40014, Finland.
   [Seth, Taniya; Muhuri, Pranab K.] Akbar Bhawan, South Asian Univ, Dept Comp Sci, Chanakyapuri, New Delhi 110021, India.
C3 University of Jyvaskyla; South Asian University (SAU)
RP Shukla, AK (corresponding author), Univ Jyvaskyla, Fac Informat Technol, Box 35 Agora, Jyvaskyla 40014, Finland.
EM amit.k.shukla@jyu.fi; taniya.seth@students.sau.ac.in;
   pranabmuhuri@cs.sau.ac.in
RI MUHURI, PRANAB K./F-4301-2015
OI MUHURI, PRANAB K./0000-0001-7122-7622; Shukla, Amit
   K./0000-0002-7581-782X
FU University of Jyvaskyla (JYU)
FX Open Access funding provided by University of Jyvaskyla (JYU).
CR Abumalloh RA, 2022, J INFECT PUBLIC HEAL, V15, P75, DOI 10.1016/j.jiph.2021.11.013
   Ahmad M, 2021, ARXIV
   Albuquerque PC, 2017, PLOS NEGLECT TROP D, V11, DOI 10.1371/journal.pntd.0005132
   Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   Allam Z, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8010046
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Atlasi R, 2021, J DIABETES METAB DIS, V20, P107, DOI 10.1007/s40200-020-00718-7
   Ayyoubzadeh SM, 2020, JMIR PUBLIC HLTH SUR, V6, P192, DOI 10.2196/18828
   Bai HX, 2020, RADIOLOGY, V296, pE156, DOI 10.1148/radiol.2020201491
   Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552
   Blanco-Mesa F, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105488
   Brann DH, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abc5801
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Budd J, 2020, NAT MED, V26, P1183, DOI 10.1038/s41591-020-1011-4
   Chamola V, 2020, IEEE ACCESS, V8, P90225, DOI 10.1109/ACCESS.2020.2992341
   Chang S, 2021, NATURE, V589, P82, DOI 10.1038/s41586-020-2923-3
   Chen JH, 2020, J MOL BIOL, V432, P5212, DOI 10.1016/j.jmb.2020.07.009
   Chen XL, 2021, MULTIMED TOOLS APPL, V80, P17335, DOI 10.1007/s11042-020-09062-7
   Chicaiza J, 2022, IEEE ACCESS, V10, P33281, DOI 10.1109/ACCESS.2022.3159025
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Ciotti Marco, 2020, Crit Rev Clin Lab Sci, V57, P365, DOI 10.1080/10408363.2020.1783198
   Clarivate, 2019, WEB SCI WEB SCI GROU
   Colavizza G, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0244839
   Cosic K, 2020, PSYCHIAT DANUB, V32, P25, DOI 10.24869/psyd.2020.25
   Cui FY, 2020, BIOSENS BIOELECTRON, V165, DOI 10.1016/j.bios.2020.112349
   Cunningham E, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00922-7
   Ribeiro MHD, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109853
   Dulebohn S. C., 2020, FEATURES EVALUATION
   Dunis C., 2016, Artificial intelligence in financial markets, DOI [10.1057/978-1-137-48880-0, DOI 10.1057/978-1-137-48880-0]
   Dwivedi YK, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102211
   Eck NJV, 2011, arXiv
   Ezugwu AE, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/5546790
   Ezugwu AE, 2020, MEDRXIV, DOI [10.1101/2020.05.18.20105577, DOI 10.1101/2020.05.18.20105577]
   Franch-Pardo I, 2020, SCI TOTAL ENVIRON, V739, DOI 10.1016/j.scitotenv.2020.140033
   Garg KC, 2009, HEALTH INFO LIBR J, V26, P22, DOI 10.1111/j.1471-1842.2008.00779.x
   Garg S, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105915
   Haghani M, 2020, SAFETY SCI, V129, DOI 10.1016/j.ssci.2020.104806
   Haug N, 2020, NAT HUM BEHAV, V4, DOI 10.1038/s41562-020-01009-0
   Hua JL, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072309
   Islam MM, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9040441
   Jiang XG, 2020, CMC-COMPUT MATER CON, V63, P537, DOI 10.32604/cmc.2020.010691
   Jiang YY, 2020, INT J CONTEMP HOSP M, V32, P2563, DOI 10.1108/IJCHM-03-2020-0237
   Jin YR, 2019, MULTIMED TOOLS APPL, V78, P1289, DOI 10.1007/s11042-018-6172-5
   Kalra G, 2021, INDIAN J OPHTHALMOL, V69, P1234, DOI 10.4103/ijo.IJO_3284_20
   Labhart N, 2012, J UNIVERS COMPUT SCI, V18, P2542
   Lalmuanawma S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110059
   Li JH, 2018, FRONT INFORM TECH EL, V19, P1462, DOI 10.1631/FITEE.1800573
   Li L., 2020, Radiology, V296, DOI 10.1148/radiol.2020200905
   Li SJ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17062032
   Liu FJ, 2020, THERANOSTICS, V10, P5613, DOI 10.7150/thno.45985
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Malik AA, 2021, J INFECT PUBLIC HEAL, V14, P311, DOI 10.1016/j.jiph.2020.12.008
   MARTYN J, 1964, J DOC, V20, P236, DOI 10.1108/eb026352
   Mazzeo D, 2021, ENERGY, V232, DOI 10.1016/j.energy.2021.120999
   McCall B, 2020, LANCET DIGIT HEALTH, V2, pE166, DOI 10.1016/S2589-7500(20)30054-6
   Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1038/s41591-020-0931-3, 10.1101/2020.04.12.20062661]
   Muhuri PK, 2019, ENG APPL ARTIF INTEL, V78, P218, DOI 10.1016/j.engappai.2018.11.007
   Muhuri PK, 2018, APPL SOFT COMPUT, V69, P381, DOI 10.1016/j.asoc.2018.03.041
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pech G, 2021, J INFORMETR, V15, DOI 10.1016/j.joi.2021.101161
   Qian Y, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2020.101047
   Randhawa GS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232391
   Rodríguez-Rodríguez I, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18168578
   Sahoo S, 2020, ONLINE INFORM REV, V44, P1443, DOI 10.1108/OIR-06-2020-0252
   Santosh KC, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01562-1
   Shen B, 2020, CELL, V182, P59, DOI 10.1016/j.cell.2020.05.032
   Shrock E, 2020, SCIENCE, V370, P1058, DOI 10.1126/science.abd4250
   Shukla AK, 2020, ENG APPL ARTIF INTEL, V88, DOI 10.1016/j.engappai.2019.103315
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Rao ASRS, 2020, INFECT CONT HOSP EP, V41, P826, DOI 10.1017/ice.2020.61
   Stebbing J, 2020, EMBO MOL MED, V12, DOI 10.15252/emmm.202012697
   Tang XL, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2020.101094
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Touret F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70143-6
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang C, 2020, LANCET, V395, P470, DOI 10.1016/S0140-6736(20)30185-9
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang XG, 2020, IEEE T MED IMAGING, V39, P2615, DOI 10.1109/TMI.2020.2995965
   WHO, 2020, Coronavirus disease (COVID-19) pandemic
   Worldometer, 2022, WORLD
   Wu WZ, 2020, J MED VIROL, V92, P1962, DOI 10.1002/jmv.25914
   Wu ZS, 2022, ENVIRON SCI POLLUT R, V29, P26396, DOI 10.1007/s11356-021-17800-z
   Wynants L, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1328
   Yan L, 2020, NAT MACH INTELL, V2, P283, DOI 10.1038/s42256-020-0180-7
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   Yi Fengyun, 2016, BMC Res Notes, V9, P221, DOI 10.1186/s13104-016-2026-2
   Zeng ZJ, 2020, TOURISM GEOGR, V22, P724, DOI 10.1080/14616688.2020.1762118
   Zurita G, 2020, J NETW COMPUT APPL, V165, DOI 10.1016/j.jnca.2020.102695
   Zyoud SH, 2016, VIROL J, V13, DOI 10.1186/s12985-016-0534-2
NR 92
TC 2
Z9 2
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32755
EP 32787
DI 10.1007/s11042-023-14642-4
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100006
PM 37362722
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Zhang, L
   Yuan, FN
   Xia, X
AF Zhang, Lin
   Yuan, Feiniu
   Xia, Xue
TI Edge-reinforced attention network for smoke semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke semantic segmentation; Edge-reinforced attention; Self-attention;
   Sample imbalance
AB This paper proposes a smoke semantic segmentation framework EANet based on boundary enhancement and attention mechanism. It integrates semantic segmentation and semantic boundary detection tasks into a framework, and distinguishes the features on both sides of the boundary with the help of the supervision of the semantic boundary, so as to guide the semantic segmentation task to determine whether the features on both sides of the boundary belong to the same object. At the same time, three attention mechanisms are proposed, which are used to capture the long-range context-dependent information of the object, strengthen the boundary semantic information of the segmentation feature, and enhance the attention to the key features of the channel domain. Finally, an adaptive fusion layer is used to fuse the prediction results of the two sub-networks to further improve the details of the segmentation results and obtain sharper object boundaries. In addition, in order to solve the problem of sample imbalance in the semantic boundary detection task, we designed a boundary loss function EL. By improving the standard binary cross-entropy, the network can focus more on difficult-to-classify samples and improve the network's ability to deal with sample imbalance problems. A large number of experimental results show that our method is better than the state-of-art algorithms, and the proposed loss function can also help the algorithm to obtain more accurate and clear object boundaries.
C1 [Zhang, Lin] Jiangxi Sci & Technol Normal Univ, Sch Math & Comp Sci, Nanchang 330045, Jiangxi, Peoples R China.
   [Yuan, Feiniu] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai 201418, Peoples R China.
   [Xia, Xue] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Jiangxi, Peoples R China.
C3 Jiangxi Science & Technology Normal University; Shanghai Normal
   University; Jiangxi University of Finance & Economics
RP Zhang, L (corresponding author), Jiangxi Sci & Technol Normal Univ, Sch Math & Comp Sci, Nanchang 330045, Jiangxi, Peoples R China.
EM zymm_nc@163.com
RI Xia, Xue/HWQ-3435-2023
OI Xia, Xue/0000-0002-2872-7151
FU National Natural Science Foundation of China [62262027, 62162029];
   Research Startup Fund [2020BSQD013]; Jiangxi Provincial Natural Science
   Foundation [20212BAB202012]; Science Technology Application Projects of
   Jiangxi Province [GJJ2201311]
FX This work was supported by [The National Natural Science Foundation of
   China (No. 62262027 and No. 62162029), Ph.D. Research Startup Fund (No.
   2020BSQD013), Jiangxi Provincial Natural Science Foundation (No.
   20212BAB202012) and the Key Science Technology Application Projects of
   Jiangxi Province (GJJ2201311)].
CR [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.28
   [Anonymous], 2017, LABEL REFINEMENT NET
   Chen BK, 2019, IEEE T INTELL TRANSP, V20, P137, DOI 10.1109/TITS.2018.2801309
   Chen JZ, 2022, IEEE T INTELL TRANSP, V23, P23194, DOI 10.1109/TITS.2022.3194931
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Filonenko A, 2018, IEEE T IND INFORM, V14, P725, DOI 10.1109/TII.2017.2757457
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gu JY, 2018, LECT NOTES COMPUT SC, V11216, P392, DOI 10.1007/978-3-030-01258-8_24
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jia Yang, 2016, Computer Engineering, V42, P206, DOI 10.3969/j.issn.1000-3428.2016.02.037
   Kaabi R., 2018, International Conference on Advanced Technologies for Signal and Image Processing, P1, DOI 10.1109/ATSIP.2018.8364446
   Li XQ, 2020, IEEE T CIRC SYST VID, V30, P89, DOI 10.1109/TCSVT.2018.2889193
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin ZJ, 2019, IEEE T IND ELECTRON, V66, P606, DOI 10.1109/TIE.2018.2823658
   Liu H., 2022, arXiv
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Mahmoud MAI, 2019, J INF PROCESS SYST, V15, P159, DOI 10.3745/JIPS.01.0038
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Sagar A., 2018, Int Res J Eng Technol, V5, P3843
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie E, 2021, LECT NOTES COMPUT SC
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Yuan C, 2019, J INTELL ROBOT SYST, V93, P337, DOI 10.1007/s10846-018-0803-y
   Yuan FN, 2021, IEEE T IMAGE PROCESS, V30, P4409, DOI 10.1109/TIP.2021.3069318
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2019, NEUROCOMPUTING, V357, P248, DOI 10.1016/j.neucom.2019.05.011
   Yuan YH, 2021, INT J COMPUT VISION, V129, P2375, DOI 10.1007/s11263-021-01465-9
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang N., 2015, J FRONT COMPUT SCI T, V11, P1296
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Y, 2015, J ELECTR COMPUT ENG, V11
   Zhen M, AAAI CONF ARTIF INTE
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
NR 55
TC 0
Z9 0
U1 7
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31259
EP 31284
DI 10.1007/s11042-023-14879-z
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940725400004
DA 2024-07-18
ER

PT J
AU Bajpai, S
AF Bajpai, Shrish
TI Low complexity image coding technique for hyperspectral image sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossy hyperspectral image compression; Wavelet transform; Computational
   complexity; Zero block cube tree; Parallel processing
ID COMPRESSION; LOSSLESS
AB Memory management and coding complexity are the major challenging issues of any hyperspectral image sensor. The hyperspectral image compression algorithm plays a greater role to improve the hyperspectral image sensor performance and save sensor memory. Many compression algorithms for hyperspectral images were proposed in past. The wavelet transform-based set partitioned hyperspectral image compression algorithms generate embedded output bit stream and also perform both lossy & lossless compression which makes them an ideal choice for any type of image sensor. The set portioned image compression algorithms use linked list or state table or markers to track the significance or insignificance of the block cube or coefficients. The linked lists grow with the bit rate which creates memory management issue while state tables or marker size is fixed which is not favorable with the low bit rate. In this study, a novel implementation of the set partitioned compression algorithm is proposed which employs parallel processing to reduce the coding complexity and exploits the linear indexing of the wavelet transform to track the set or coefficients to save the coding memory. The simulation results show the proposed compression algorithm 3D-BCP-ZM-SPECK reduces the coding complexity multiple folds with no need of coding memory.
C1 [Bajpai, Shrish] Integral Univ, Fac Engn & Informat Technol, Elect & Commun Engn, Lucknow, Uttar Pradesh, India.
C3 Integral University
RP Bajpai, S (corresponding author), Integral Univ, Fac Engn & Informat Technol, Elect & Commun Engn, Lucknow, Uttar Pradesh, India.
EM shrishbajpai@gmail.com
RI Bajpai, Shrish/GPC-4732-2022
OI Bajpai, Shrish/0000-0001-5598-1940
FU  [D/2022-MCN0001700]
FX AcknowledgementsI am sincerely thankful to the anonymous reviewers for
   their critical comments and suggestions to improve the quality of the
   paper. The author wants to express his gratitude to Integral University,
   Lucknow for providing manuscript number IU/R&D/2022-MCN0001700 for the
   present research work.
CR Bajpai S., 2019, INT J INNOVATIVE TEC, V8, P64
   Bajpai S., 2019, INDONESIAN J ELECT E, V15, P1001, DOI [10.11591/ijeecs.v15.i2.pp1001-1008, DOI 10.11591/IJEECS.V15.I2.PP1001-1008]
   Bajpai S, 2022, MULTIMED TOOLS APPL, V81, P841, DOI 10.1007/s11042-021-11456-0
   Bajpai S, 2019, MULTIMED TOOLS APPL, V78, P27193, DOI 10.1007/s11042-019-07797-6
   Bajpai S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P97, DOI 10.1109/MSPCT.2017.8363982
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, V12, P2915, DOI 10.1007/s12652-020-02449-2
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Bilgin A, 2000, APPL OPTICS, V39, P1799, DOI 10.1364/AO.39.001799
   Boettcher JB, 2007, INT GEOSCI REMOTE SE, P1033, DOI 10.1109/IGARSS.2007.4422977
   Bose S, 2022, EARTH MOON PLANETS, V126, DOI 10.1007/s11038-021-09544-0
   Cheng KJ, 2014, IEEE T GEOSCI REMOTE, V52, P5765, DOI 10.1109/TGRS.2013.2292366
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Das S, 2021, IET IMAGE PROCESS, V15, P964, DOI 10.1049/ipr2.12077
   Datta A, 2017, IEEE GEOSCI REMOTE S, V14, P82, DOI 10.1109/LGRS.2016.2628078
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Dua Y, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116255
   Dua Y, 2021, J PARALLEL DISTR COM, V150, P60, DOI 10.1016/j.jpdc.2020.12.004
   Dua Y, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.9.090902
   Gunasheela KS., 2019, INF COMMUN TECHNOL I, DOI [10.1007/978-981-13-1742-2_49, DOI 10.1007/978-981-13-1742-2_49]
   Hou Y, 2007, PROC SPIE, V6790, DOI 10.1117/12.750975
   Hou Y, 2008, 2008 INTERNATIONAL WORKSHOP ON EARTH OBSERVATION AND REMOTE SENSING APPLICATIONS, P106
   Jiang ZC, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060038
   Kumar RS, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101862
   Kumar V, 2022, SIGNAL PROCESS-IMAGE, V101, DOI 10.1016/j.image.2021.116549
   Kumari Shringi, 2018, P 13 INT C FDN DIG G, DOI [10.1145/3235765.3235788, DOI 10.1145/3235765.3235788]
   Li R, 2019, MULTIMED TOOLS APPL, V78, P11701, DOI 10.1007/s11042-018-6724-8
   Mei SH, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111139
   Mishra MK, 2019, CURR SCI INDIA, V116, P1089, DOI 10.18520/cs/v116/i7/1089-1100
   Mitran T, 2021, J INDIAN SOC REMOTE, V49, P2611, DOI 10.1007/s12524-021-01415-5
   Mohan BK, 2015, CURR SCI INDIA, V108, P833
   Nagendran R, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S021969131941008X
   Ngadiran R., 2010, IEEE INT C COMP COMM, P1, DOI [10.1109/ICCCE.2010.5556843, DOI 10.1109/ICCCE.2010.5556843]
   Nian YJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/825673
   Pan W, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1237, DOI 10.1109/ISKE.2008.4731119
   Plaza Antonio, 2009, Remote Sensing of Environment, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Quesada-Barriuso P., 2014, Recent Advances in Knowledge-Based Paradigms and Applications, P19, DOI [DOI 10.1007/978-3-319-01649-8_2, 10.1007/978-3-319-01649-8_2]
   Ramakrishnan D, 2015, CURR SCI INDIA, V108, P879
   Rucker JT, 2005, INT GEOSCI REMOTE SE, P128
   Schelkens P, 2001, THESIS VRIJE U BRUSS
   Sharma D, 2020, IETE TECH REV, V37, P36, DOI 10.1080/02564602.2018.1557569
   Sharma D, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.076102
   Singh PS, 2022, REMOTE SENS LETT, V13, P184, DOI 10.1080/2150704X.2021.2005270
   Sudha VK, 2013, J SCI IND RES INDIA, V72, P735
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Tang XL, 2004, IEEE IMAGE PROC, P3283
   Uddin MP, 2021, IETE TECH REV, V38, P377, DOI 10.1080/02564602.2020.1740615
   Wang L, 2015, SIGNAL PROCESS-IMAGE, V36, P63, DOI 10.1016/j.image.2015.06.002
   Wang XH, 2018, J INDIAN SOC REMOTE, V46, P667, DOI 10.1007/s12524-017-0735-1
   Wang YH, 2004, IEEE GEOSCI REMOTE S, V1, P136, DOI 10.1109/LGRS.2004.824762
   Wu JJ, 2006, OPT ENG, V45, DOI 10.1117/1.2173996
   Xiao Jiang, 2005, Journal of Xidian University, V32, P549
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
   Yang J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010053
   Ying Hou, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P963, DOI 10.1109/CSSE.2008.1351
   Zhang J, 2008, IGARSS 2008 2008 IEE, DOI [10.1109/IGARSS.2008.4779161, DOI 10.1109/IGARSS.2008.4779161]
   Zhang J, 2008, IEEE GEOSCI REMOTE S, V5, P814, DOI 10.1109/LGRS.2008.2006571
   Zikiou N, 2020, VISUAL COMPUT, V36, P1473, DOI 10.1007/s00371-019-01753-z
NR 58
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31233
EP 31258
DI 10.1007/s11042-023-14738-x
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500003
DA 2024-07-18
ER

PT J
AU Rai, CK
   Pahuja, R
AF Rai, Chitranjan Kumar
   Pahuja, Roop
TI Classification of Diseased Cotton Leaves and Plants Using Improved Deep
   Convolutional Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Image classification; Deep learning; Image
   processing; Plant leaf disease
ID IDENTIFICATION; SYSTEM
AB The automated detection and classification of plant diseases based on images of leaves is a significant milestone in agriculture. Due to the increasing popularity of digital image processing, machine learning, and computer vision techniques, it has been proposed that these could be used for the early detection of diseases. However, the accuracy of these techniques is still considered to be a challenge. In this paper, the concept of deep learning was used to identify and predict cotton plant disease status using images of leaves and plants collected in an uncontrolled environment. This paper focuses on solving the problem of cotton plants disease detection and classification using an improved Deep Convolution Neural Network based model. Three different experimental configurations were investigated to study the impacts of different data split ratios, different choices of pooling layer (max-pooling vs. average-pooling), and epoch sizes. The models were trained using a database of 2293 images of cotton leaves and plants. The data included four distinct classes of leaves, plant disease combinations, and their respective categories. For classifying leaves and plant diseases in cotton plants, our model attained an accuracy of 97.98%. The proposed technique outperformed the recent approaches indicated in earlier literature for relevant parameters. As a result, the technique is intended to reduce the time spent identifying cotton leaf disease in significant production regions and human error and the time spent determining its severity.
C1 [Rai, Chitranjan Kumar; Pahuja, Roop] Dr B R Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Rai, CK (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
EM chitranjanr.ic.18@nitj.ac.in
RI Pahuja, Roop/X-8544-2019; Rai, Chitranjan Kumar/IUN-0382-2023
OI Pahuja, Roop/0000-0002-1575-9349; Rai, Chitranjan/0000-0003-1446-3631
CR [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   Azath M, 2021, J ELECTR COMPUT ENG, V2021, DOI 10.1155/2021/9981437
   Caldeira RF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093169
   Chockalingam SMM, 2015, PROFILE INDIAN COTTO, P1
   D3v, 2020, COTT DIS DAT
   da Silva LA, 2019, COMPUT ELECTRON AGR, V156, P360, DOI 10.1016/j.compag.2018.11.040
   Dande SC, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1466, DOI 10.1109/ICCSP.2016.7754401
   Das S, 2022, MULTIMED TOOLS APPL, V81, P8007, DOI 10.1007/s11042-021-11824-w
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gupta H, 2019, INT J AGRIC ENVIRON, V10, P30, DOI 10.4018/IJAEIS.2019070103
   Hati S., 2013, International Journal of Computer Applications, V62, P15, DOI [DOI 10.5120/10172-4897, 10.5120/10172-4897]
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Jagtap SB, 2014, IOSR Journal of VLSI and Signal Processing, V4, P24, DOI [DOI 10.9790/4200-04512430, 10.9790/4200-04512430]
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kaur S, 2021, MULTIMED TOOLS APPL, V80, P10113, DOI 10.1007/s11042-020-10114-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Rai C, 2022, INT C IMAGE INFORM P, P472, DOI [10.1109/iciip53038.2021.9702652, DOI 10.1109/ICIIP53038.2021.9702652]
   Kumar R, 2021, J PLANT DIS PROTECT, V128, P897, DOI 10.1007/s41348-021-00463-w
   Kutty SB, 2013, 2013 IEEE BUSINESS ENGINEERING AND INDUSTRIAL APPLICATIONS COLLOQUIUM (BEIAC 2013), P459
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mallick MT, 2023, MULTIMED TOOLS APPL, V82, P12017, DOI 10.1007/s11042-022-13673-7
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Parikh A, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P594, DOI 10.1109/DSAA.2016.81
   Patki SS., 2016, International Journal of Advanced Research in Computer and Communication Engineering, V5, P165, DOI [10.17148/IJARCCE.2016.51034, DOI 10.17148/IJARCCE.2016.51034]
   Rajasekar V., 2022, Journal of Mobile Multimedia, V18, P307, DOI [10.13052/jmm1550-4646.1828, DOI 10.13052/JMM1550-4646.1828]
   Revathi P., 2012, INT C EM TRENDS SCI, P169, DOI [10.1109/INCOSET.2012.6513900, DOI 10.1109/INCOSET.2012.6513900]
   Rothe PR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Sekeroglu B, 2016, PROCEDIA COMPUT SCI, V102, P578, DOI 10.1016/j.procs.2016.09.445
   Sengar N, 2018, COMPUTING, V100, P1189, DOI 10.1007/s00607-018-0638-1
   Shrivastava S, 2015, MULTIMED TOOLS APPL, V74, P11467, DOI 10.1007/s11042-014-2239-0
   Sivasangari A., 2017, INT J ENG RES GEN SC, V117, P119
   Sun J, 2020, IEEE ACCESS, V8, P33679, DOI 10.1109/ACCESS.2020.2973658
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Vallabhajosyula S, 2022, J PLANT DIS PROTECT, V129, P545, DOI 10.1007/s41348-021-00465-8
   Vishnoi VK, 2022, MULTIMED TOOLS APPL, V81, P367, DOI 10.1007/s11042-021-11375-0
   Wang GQ, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2373818
   Wankhade DS, 2017, COLOR RES APPL, V5, P182
   Xiao BX, 2014, INT J AGR BIOL ENG, V7, P75, DOI 10.3965/j.ijabe.20140704.008
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 45
TC 4
Z9 5
U1 8
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25307
EP 25325
DI 10.1007/s11042-023-14933-w
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000940729500011
DA 2024-07-18
ER

PT J
AU Fan, CL
AF Fan, Ching-Lung
TI Evaluation of machine learning in recognizing images of reinforced
   concrete damage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Maximum likelihood; Support vector machine; Random
   forest; Image quality
ID SUPPORT-VECTOR-MACHINE; CRACK DETECTION; MODEL; VISION; RECOGNITION;
   QUANTIFICATION; CLASSIFICATION; ALGORITHM
AB Damage to reinforced concrete (RC) facilities occurs through the process of natural deterioration. Machine learning can be employed to effectively identify various damage areas and ensure safety. The performance of machine vision methods depends on image quality. In this study, five image types (Types I-V) with combinations of image deficiencies pertaining to uniform illuminance, uneven illuminance, orthoimage, tilt angle, and image blur were used to evaluate the damage recognition capabilities of maximum likelihood (MLH), support vector machine (SVM), and random forest (RF) methods. Type I images were orthoimages with uniform illuminance, Type II images were tilted images with uniform illuminance, Type III images were orthoimages with uneven illuminance, Type IV images were tilted images with uneven illuminance, and Type V images were tilted, blurred images with uneven illuminance. MLH was most accurate (98.6%) in Type I images, and RF was the least accurate (62.8%) in Type V images. Image tilt (in Type II images) did not diminish the damage recognition capabilities of the three types of machine learning methods (mean accuracy = 97.2%). For tilted images with uneven illuminance (Type IV), a severe expansion effect was produced, reducing the mean accuracy to 70.1%. Type III images were recognized with a mean accuracy of 87.1%; uneven illuminance increased the error rate for three classes of damage. By testing various image types, the impact of image quality on the variability of machine learning recognition is understood, and the ability of automated machine learning recognition in the future is improved.
C1 [Fan, Ching-Lung] Republ China Mil Acad, Dept Civil Engn, 1 Weiwu Rd,Fengshan, Kaohsiung 83059, Taiwan.
RP Fan, CL (corresponding author), Republ China Mil Acad, Dept Civil Engn, 1 Weiwu Rd,Fengshan, Kaohsiung 83059, Taiwan.
EM p93228001@ntu.edu.tw
RI Fan, Ching Lung/AAI-9443-2020
OI Fan, Ching Lung/0000-0001-9022-120X
CR Abdel-Qader I, 2006, ADV ENG SOFTW, V37, P771, DOI 10.1016/j.advengsoft.2006.06.002
   Abid MA, 2022, MULTIMED TOOLS APPL, V81, P39853, DOI 10.1007/s11042-022-12991-0
   Adhikari RS, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000566
   Alzubi JA, 2015, P INT C ENG MIS, P1
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi O, 2018, INT ARAB J INF TECHN, V15, P76
   Annadurai S, 2023, MULTIMED TOOLS APPL, V82, P1333, DOI 10.1007/s11042-022-13210-6
   Athanasiou A, 2020, COMPUT-AIDED CIV INF, V35, P565, DOI 10.1111/mice.12509
   Babu GH, 2022, MULTIMED TOOLS APPL, V81, P43897, DOI 10.1007/s11042-022-13222-2
   Bae H, 2021, STRUCT HEALTH MONIT, V20, P1428, DOI 10.1177/1475921720917227
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bu GP, 2015, ELECTRON J STRUCT EN, V14, P41
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chen JH, 2017, AUTOMAT CONSTR, V73, P58, DOI 10.1016/j.autcon.2016.08.033
   Chen PH, 2012, AUTOMAT CONSTR, V23, P9, DOI 10.1016/j.autcon.2011.12.001
   Chun PJ, 2020, CONSTR BUILD MATER, V253, DOI 10.1016/j.conbuildmat.2020.119238
   Cord A, 2012, COMPUT-AIDED CIV INF, V27, P244, DOI [10.1111/j.1467-8667.2011.00736.x, 10.1111/j.1467-8667.2011-00736.x]
   Dawood T, 2017, AUTOMAT CONSTR, V81, P149, DOI 10.1016/j.autcon.2017.06.008
   Erkal BG, 2017, AUTOMAT CONSTR, V83, P285, DOI 10.1016/j.autcon.2017.08.004
   Fan CL, 2021, STRUCT CONTROL HLTH, V28, DOI 10.1002/stc.2841
   Fan XN, 2018, MULTIMED TOOLS APPL, V77, P26581, DOI 10.1007/s11042-018-5880-1
   Fang Q, 2018, AUTOMAT CONSTR, V85, P1, DOI 10.1016/j.autcon.2017.09.018
   German S, 2012, ADV ENG INFORM, V26, P846, DOI 10.1016/j.aei.2012.06.005
   Gui GQ, 2017, KSCE J CIV ENG, V21, P523
   Gupta P, 2022, MULTIMED TOOLS APPL, V81, P40181, DOI 10.1007/s11042-022-13152-z
   Hüthwohl P, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.04.019
   Jahanshahi MR, 2012, AUTOMAT CONSTR, V22, P567, DOI 10.1016/j.autcon.2011.11.018
   Jain DK, 2020, J REAL-TIME IMAGE PR, V17, P2113, DOI 10.1007/s11554-019-00889-4
   Jang K, 2019, STRUCT HEALTH MONIT, V18, P1722, DOI 10.1177/1475921718821719
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kim H, 2019, STRUCT HEALTH MONIT, V18, P725, DOI 10.1177/1475921718768747
   Koch C, 2015, ADV ENG INFORM, V29, P196, DOI 10.1016/j.aei.2015.01.008
   Laory I, 2013, J COMPUT CIVIL ENG, V27, P657, DOI 10.1061/(ASCE)CP.1943-5487.0000289
   Lattanzi D, 2014, J COMPUT CIVIL ENG, V28, P253, DOI 10.1061/(ASCE)CP.1943-5487.0000257
   Li G, 2017, AUTOMAT CONSTR, V78, P51, DOI 10.1016/j.autcon.2017.01.019
   Li SY, 2019, COMPUT-AIDED CIV INF, V34, P616, DOI 10.1111/mice.12433
   Figueredo JSL, 2022, MULTIMED TOOLS APPL, V81, P42991, DOI 10.1007/s11042-022-13050-4
   Liu CF, 2019, KSCE J CIV ENG, V23, P4407, DOI 10.1007/s12205-019-2353-7
   Ma YF, 2015, J MATER CIVIL ENG, V27, DOI 10.1061/(ASCE)MT.1943-5533.0001096
   Mathavan S, 2015, J INFRASTRUCT SYST, V21, DOI 10.1061/(ASCE)IS.1943-555X.0000237
   MCNEIL S, 1991, J TRANSP ENG-ASCE, V117, P224, DOI 10.1061/(ASCE)0733-947X(1991)117:2(224)
   Meijer D, 2019, AUTOMAT CONSTR, V104, P281, DOI 10.1016/j.autcon.2019.04.013
   Mizoguchi T, 2013, AUTOMAT CONSTR, V35, P263, DOI 10.1016/j.autcon.2013.05.022
   Mohan A, 2018, ALEX ENG J, V57, P787, DOI 10.1016/j.aej.2017.01.020
   Moselhi O., 2000, J INFRASTRUCT SYST, P97, DOI DOI 10.1061/(ASCE)1076-0342(2000)6:3(97)
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Mustafa S, 2015, INT J STEEL STRUCT, V15, P473, DOI 10.1007/s13296-015-6016-3
   Nishikawa T, 2012, COMPUT-AIDED CIV INF, V27, P29, DOI 10.1111/j.1467-8667.2011.00716.x
   Okazaki Y, 2020, COMPUT-AIDED CIV INF, V35, P775, DOI 10.1111/mice.12532
   Omar T, 2017, AUTOMAT CONSTR, V83, P360, DOI 10.1016/j.autcon.2017.06.024
   Prasanna P, 2016, IEEE T AUTOM SCI ENG, V13, P591, DOI 10.1109/TASE.2014.2354314
   Rashidi A, 2016, KSCE J CIV ENG, V20, P1178, DOI 10.1007/s12205-015-0726-0
   Rodríguez-Martín M, 2016, AUTOMAT CONSTR, V61, P58, DOI 10.1016/j.autcon.2015.10.012
   Rubio JJ, 2019, COMPUT IND, V112, DOI 10.1016/j.compind.2019.08.002
   Schnebele E, 2015, EUR TRANSP RES REV, V7, DOI 10.1007/s12544-015-0156-6
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P73, DOI 10.1016/j.autcon.2005.02.005
   Son H, 2012, J COMPUT CIVIL ENG, V26, P421, DOI 10.1061/(ASCE)CP.1943-5487.0000141
   Spencer BF, 2019, ENGINEERING-PRC, V5, P199, DOI 10.1016/j.eng.2018.11.030
   Taffese WZ, 2017, AUTOMAT CONSTR, V77, P1, DOI 10.1016/j.autcon.2017.01.016
   Valero E, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102846
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Wang WC, 2022, MULTIMED TOOLS APPL, V81, P39873, DOI 10.1007/s11042-022-12300-9
   Wang WX, 2022, MULTIMED TOOLS APPL, V81, P43657, DOI 10.1007/s11042-022-12994-x
   Yao Y, 2014, STRUCT CONTROL HLTH, V21, P1387, DOI 10.1002/stc.1655
   Yeum CM, 2015, COMPUT-AIDED CIV INF, V30, P759, DOI 10.1111/mice.12141
   Zakeri H, 2017, ARCH COMPUT METHOD E, V24, P935, DOI 10.1007/s11831-016-9194-z
   Zalama E, 2014, COMPUT-AIDED CIV INF, V29, P342, DOI 10.1111/mice.12042
   Zhang CB, 2020, COMPUT-AIDED CIV INF, V35, P389, DOI 10.1111/mice.12500
   Zhu ZH, 2011, AUTOMAT CONSTR, V20, P874, DOI 10.1016/j.autcon.2011.03.004
NR 69
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30221
EP 30246
DI 10.1007/s11042-023-14911-2
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000940065100014
DA 2024-07-18
ER

PT J
AU Li, JD
   Hu, JY
   Zhang, PP
   Yang, L
AF Li, Jiandun
   Hu, Jingyi
   Zhang, Pengpeng
   Yang, Liu
TI Exposing collaborative spammer groups through the review-response graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Review spam; Opinion spam; Responsive spam; Collaborative spam; Spammer
   group; Review-response graph
AB Deceptive opinions of online merchandises, also known as review spams, cause great loss for consumers, manufacturers and even business-to-customer platforms. However, due to the weak supervision problem, especially the lack of ground-truth labels, identifying these untruthful reviews is challenging. What's even worse is that crowdsourcing workers out of manipulation campaigns always collaborate to distort an item's reputation, rendering the product together with its brand difficult to be rehabilitated. State-of-the-art solutions on spammer group recognition highlight co-reviewing behaviours or sentiment similarity to cluster reviews, which can only yield loosely-coupled candidates of reviewer sets. In this paper, we highlight the commenting interaction between reviews and model it as a bipartite graph and discover a new low-budget spam, i.e., responsive spam. Furthermore, we recognize strong-correlated groups of spam through a propagation technique upon two widely adopted spam indicators, i.e., text duplication and posting burstiness. Comparative results show that our approach is effective and outperforms state-of-the-art solutions with great significance.
C1 [Li, Jiandun; Hu, Jingyi; Zhang, Pengpeng; Yang, Liu] Shanghai Dianji Univ, Sch Elect Informat Engn, Shanghai 201306, Peoples R China.
C3 Shanghai Dianji University
RP Li, JD (corresponding author), Shanghai Dianji Univ, Sch Elect Informat Engn, Shanghai 201306, Peoples R China.
EM lijd@sdju.edu.cn
RI pengpeng, zhang/ABF-9611-2020
OI Li, Jiandun/0000-0002-0935-7757
FU National Nature Science Foundation of China [61801285, 61802247]
FX AcknowledgementsThis work was supported in part by the National Nature
   Science Foundation of China, under grant 61801285 and 61802247.
CR Akoglu L., 2013, P 7 INT AAAI C WEBLO
   Allahbakhsh Mohammad, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P196, DOI 10.1007/978-3-642-37401-2_21
   Asghar MZ, 2020, SOFT COMPUT, V24, P3475, DOI 10.1007/s00500-019-04107-y
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Chakrabarti D, 2004, KDD 2004 P 10 ACM SI
   Choo E, 2015, LECT NOTES COMPUT SC
   Choo E, 2015, LECT NOTES COMPUT SC, V9149, P170, DOI 10.1007/978-3-319-20810-7_11
   Dewang RK, 2018, J INTELL INF SYST, V50, P231, DOI 10.1007/s10844-017-0454-7
   Fahfouh A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113517
   Gao Y, 2021, IEEE T MULTIMEDIA, V23, P784, DOI 10.1109/TMM.2020.2990085
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Lee K, 2018, ASSESSMENT, V25, P543, DOI 10.1177/1073191116659134
   Li J., 2013, P 51 ANN M ASS COMP, VVolume 2, P217
   Li J, 2020, CODE DETECTING GOUPE
   Li JN, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2020.101186
   Li JD, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114585
   Li JD, 2020, APPL INTELL, V50, P3554, DOI 10.1007/s10489-020-01764-7
   Li Q, 2019, LECT NOTES ARTIF INT, V11439, P222, DOI 10.1007/978-3-030-16148-4_18
   Liu YC, 2018, EXPERT SYST APPL, V112, P148, DOI 10.1016/j.eswa.2018.06.028
   Mo D, 2020, CHINA ONLINE RETAIL
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee Arjun., 2011, P 20 INT C COMPANION, P93
   Neisari A, 2021, COMPUT SECUR, V106, DOI 10.1016/j.cose.2021.102274
   Noekhah S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102140
   Oh YW, 2021, AM BEHAV SCI, V65, P389, DOI 10.1177/0002764219878238
   Do QNT, 2017, IEEE INT CONF FUZZY
   Do QNT, 2016, IEEE IJCNN, P3642, DOI 10.1109/IJCNN.2016.7727668
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Sandulescu V, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P971, DOI 10.1145/2740908.2742570
   Vidanagama DU, 2019, APPL ECON LETT, P1
   Wang Z, 2018, APPL INTELL, V48, P3094, DOI 10.1007/s10489-018-1142-1
   Wang Z, 2018, KNOWL INF SYST, V55, P571, DOI 10.1007/s10115-017-1068-7
   Wang Z, 2016, COMPUT J, V59, P861, DOI 10.1093/comjnl/bxv068
   Xu C, 2015, IEEE DATA MINING, P1051, DOI 10.1109/ICDM.2015.62
   Xu C, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P979, DOI 10.1145/2505515.2505700
   Ye JT, 2015, LECT NOTES ARTIF INT, V9284, P267, DOI 10.1007/978-3-319-23528-8_17
   You L, 2020, FUTURE GENER COMP SY, V102, P163, DOI 10.1016/j.future.2019.07.044
   Zhang FZ, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2020.105520
   Zhang L, 2018, IEEE ACCESS, V6, P2559, DOI 10.1109/ACCESS.2017.2784370
NR 39
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21687
EP 21700
DI 10.1007/s11042-023-14650-4
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934222700002
DA 2024-07-18
ER

PT J
AU Kinariwala, S
   Deshmukh, S
AF Kinariwala, Supriya
   Deshmukh, Sachin
TI Short text topic modelling using local and global word-context semantic
   correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Short text; Text mining; Topic modelling; Word embedding; Non-negative
   matrix factorization; Global corpus
AB Nowadays, people use short text to portray their opinions on platforms of social media such as Twitter, Facebook, and YouTube, as well as on e-commerce websites such as Amazon and Flipkart to share their commercial purchasing experiences. Every day, billions of short texts are created worldwide in tweets, tags, keywords, search queries etc. However, this short text possesses inadequate contextual information, which can be ambiguous, sparse, noisy, remains a major challenge. State-of-the-art strategies of topic modeling such as Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis are not suitable as it contains a limited number of words in a single document. This work proposes a new model named G_SeaNMF (Gensim_SeaNMF) to improve the word-context semantic relationship by using local and global word embedding techniques. Word embeddings learned from a large corpus provide general semantic and syntactic information about words; it can guide topic modeling for short text collections as supporting information for sparse co-occurrence patterns. In the proposed model, SeaNMF (Semantics-assisted Non-negative Matrix Factorization) is incorporated with word2vec model of Gensim library to strengthen the word's semantic relationship. In this article, a short text topic modeling techniques based on DMM (Dirichlet Multinomial Mixture), self-aggregation and global word co-occurrence were explored. These are evaluated using different measures to gauge cluster coherence on real-world datasets such as Search Snippet, Biomedicine, Pascal Flickr, Tweet and TagMyNews. Empirical evaluation shows that a combination of local and global word embedding provides more appropriate words under each topic with improved outcomes.
C1 [Kinariwala, Supriya] Maharashtra Inst Technol, Aurangabad, Maharashtra, India.
   [Deshmukh, Sachin] Dr Babasaheb Ambedkar Marathwada Univ, Aurangabad, Maharashtra, India.
C3 Dr. Babasaheb Ambedkar Marathwada University (BAMU)
RP Kinariwala, S (corresponding author), Maharashtra Inst Technol, Aurangabad, Maharashtra, India.
EM sakinariwala@gmail.com
CR A3 Lab, TAGMYNEWS DATASET
   Albalawi R, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00042
   Asmussen CB, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0255-7
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen Xiao, 2014, Reluctance torque evaluation for interior permanent magnet machines using frozen permeability, DOI 10.1049/iet-tv.50.19173
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gao W, 2019, KNOWL INF SYST, V61, P1123, DOI 10.1007/s10115-018-1314-7
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hofstatter Sebastian, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P810, DOI 10.1007/978-3-030-15712-8_57
   Huang PX, 2014, PROCEEDINGS OF THE ASME TURBO EXPO: TURBINE TECHNICAL CONFERENCE AND EXPOSITION, 2014, VOL 2D
   Huang RZ, 2013, IEEE T KNOWL DATA EN, V25, P1748, DOI 10.1109/TKDE.2012.27
   Jin O., 2011, CIKM 11, P775, DOI DOI 10.1145/2063576.2063689
   Kinariwala SA., 2020, INDIAN J COMP SCI EN, V11, P510, DOI [10.21817/indjcse/2020/v11i5/201105168, DOI 10.21817/INDJCSE/2020/V11I5/201105168]
   Kuang Da, 2015, PARTITIONAL CLUSTERI, P215, DOI DOI 10.1007/978-3-319-09259-1_7
   Li CL, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P165, DOI 10.1145/2911451.2911499
   Liang WX, 2018, IEEE ACCESS, V6, P43612, DOI 10.1109/ACCESS.2018.2863260
   Ligutom C, 2016, INT CONF ASIAN LANG, P362, DOI 10.1109/IALP.2016.7876006
   Liu Z, 2020, IEEE ACCESS, V8, P99141, DOI 10.1109/ACCESS.2020.2997973
   Mahmoud H., 2008, Polya urn Models, DOI [10.1201/9781420059847, DOI 10.1201/9781420059847]
   Mazarura JR, 2015, THESIS
   Murakami R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030852
   Nguyen D. Q., 2015, Transactions of the Association for Computational Linguistics, V3, P299, DOI DOI 10.1162/TACL_A_00140
   Nikolenko SI, 2017, J INF SCI, V43, P88, DOI 10.1177/0165551515617393
   Qiang JP, 2017, LECT NOTES ARTIF INT, V10235, P363, DOI 10.1007/978-3-319-57529-2_29
   Qiang JP, 2016, PROC INT C TOOLS ART, P196, DOI [10.1109/ICTAI.2016.36, 10.1109/ICTAI.2016.0039]
   Quan XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2270
   RADEV D, 2016, PROCEED 54 ANN M ASS, V1, P654
   Rashid J, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102060
   Roccetti Marco, 2017, JMIR Public Health Surveill, V3, pe51, DOI 10.2196/publichealth.7004
   ROLIM V, 2019, IEEE INT CONF ADV LE, V2161, P163
   Shi T, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1105, DOI 10.1145/3178876.3186009
   Singhal T, 2021, IEEE INT CONF BIG DA, P4965, DOI 10.1109/BigData52589.2021.9671598
   Yan XH, 2015, AAAI CONF ARTIF INTE, P353
   Yang SQ, 2019, IEEE ACCESS, V7, P92037, DOI 10.1109/ACCESS.2019.2927345
   Yi F, 2020, IEEE ACCESS, V8, P30692, DOI 10.1109/ACCESS.2020.2973207
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zuo Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2105, DOI 10.1145/2939672.2939880
   Zuo Y, 2016, KNOWL INF SYST, V48, P379, DOI 10.1007/s10115-015-0882-z
NR 39
TC 1
Z9 2
U1 7
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26411
EP 26433
DI 10.1007/s11042-023-14352-x
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000924073200001
PM 36747894
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Khan, A
   Li, JP
   Husain, MA
AF Khan, Asif
   Li, Jian Ping
   Husain, Mohammed Aslam
TI Power grid stability analysis using pipeline machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Power grid stability assessment; Machine learning techniques; Algorithm;
   Energy information; Database
ID SYSTEM; CLASSIFICATION
AB The problems associated with the stability analysis of power system are very important and has a wide scope of improvement. Severity of the transient disturbances arising in power system are usually studied through critical contingencies simulation. There proper study and assessment is extremely important for a reliable, uninterrupted operation, along with ensuring that no generating unit get desynchronized. The main objective of this research is to develop a fast and robust online transient stability assessment tool to classify the system operating states and to identify system critical generators in case of instability. This research proposes a pipeline machine learning multi-feature hybrid network framework that captures the phasor measurement unit (PMU) measurements and monitor the system transient stability in real-time. The test results verified that our proposed framework is fast and accurate, thereby a viable approach for system stability monitoring applications.
C1 [Khan, Asif; Li, Jian Ping] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Husain, Mohammed Aslam] REC Ambedkar Nagar, Dept Elect Engn, Akbarpur, India.
C3 University of Electronic Science & Technology of China
RP Khan, A (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM asifkhan@uestc.edu.cn
RI KHAN, Asif/AAX-4255-2021; li, jianping/A-9544-2012; HUSAIN, Dr. MOHAMMED
   ASLAM/AAV-3826-2021
OI KHAN, Asif/0000-0001-5009-3290; HUSAIN, Dr. MOHAMMED
   ASLAM/0000-0002-6106-7896
FU Key Laboratory of Wavelet Active Media Technology; National Natural
   Science Foundation of China [61370073]; National High Technology
   Research and Development Program of China [2007AA01Z423]; School of
   Computer Science, University of Electronic Science and Technology of
   China (UESTC), Xiyuan Avenue, West Hi-Tech Zone, Chengdu, Sichuan, P. R.
   China
FX This work supported by "Key Laboratory of Wavelet Active Media
   Technology" with the National Natural Science Foundation of China (Grant
   No. 61370073), the National High Technology Research and Development
   Program of China (Grant No. 2007AA01Z423), Room No: B1301, School of
   Computer Science, University of Electronic Science and Technology of
   China (UESTC), No. 2006, Xiyuan Avenue, West Hi-Tech Zone, Chengdu,
   Sichuan, 611731, P. R. China.
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Abdelgayed TS, 2018, IEEE T IND ELECTRON, V65, P1595, DOI 10.1109/TIE.2017.2726961
   Alimi OA, 2020, IEEE ACCESS, V8, P113512, DOI 10.1109/ACCESS.2020.3003568
   Arora S, 2020, CLUSTER COMPUT, V23, P3157, DOI 10.1007/s10586-020-03077-3
   Bendong Tan, 2017, The Journal of Engineering, DOI 10.1049/joe.2017.0651
   Castillo C., 2014, P 17 ACM C COMP SUPP, P211, DOI [10.1145/2531602.2531623, DOI 10.1145/2531602.2531623]
   CHEN CR, 1991, IEEE T ENERGY CONVER, V6, P12, DOI 10.1109/60.73784
   Deo R., 2020, Predictive modelling for energy management and power systems engineering
   Dharmapala KD, 2020, IEEE ACCESS, V8, P222544, DOI 10.1109/ACCESS.2020.3043935
   Gao DW, 2019, FRONT ENERGY, V13, P71, DOI 10.1007/s11708-018-0589-4
   Geeganage J, 2015, IEEE T POWER SYST, V30, P1957, DOI 10.1109/TPWRS.2014.2353048
   Geetha R, 2021, MULTIMED TOOLS APPL, V80, P19675, DOI 10.1007/s11042-021-10696-4
   Geurts P., 1998, Proceedings of the ICML98/AAAI98 Workshop on "Predicting the future: AI Approaches to time series analysis, P24
   Gupta A, 2019, IEEE T POWER SYST, V34, P864, DOI 10.1109/TPWRS.2018.2872505
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Hossain E, 2019, IEEE ACCESS, V7, P13960, DOI 10.1109/ACCESS.2019.2894819
   Khan A, 2020, IEEE ACCESS, V8, P39635, DOI 10.1109/ACCESS.2020.2976134
   Liu R, 2018, POWER SYSTEM STABILI
   Maharjan L, 2019, IET SMART GRID, V2, P172, DOI 10.1049/iet-stg.2018.0043
   Malbasa V, 2017, IEEE T SMART GRID, V8, P3117, DOI 10.1109/TSG.2017.2693394
   Miraftabzadeh SM, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ENVIRONMENT AND ELECTRICAL ENGINEERING AND 2019 IEEE INDUSTRIAL AND COMMERCIAL POWER SYSTEMS EUROPE (EEEIC / I&CPS EUROPE)
   Naftel A, 2006, MULTIMEDIA SYST, V12, P227, DOI [10.1007/s00530-006-0058-5, 10.1007/S00530-006-0058-5]
   Paital S. R., 2018, 2018 IEEMA ENG INF C, P1, DOI DOI 10.1109/ETECHNXT.2018.8385324
   Peiwen L, 2020, TRANSFORMERS FAULT P, V2, P1
   Qijiu Yang, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/3/032011
   Sarajcev P, 2021, ENERGIES, V14, DOI 10.3390/en14113148
   Schäfer B, 2016, EUR PHYS J-SPEC TOP, V225, P569, DOI 10.1140/epjst/e2015-50136-y
   Shenoy NK, 2015, THESIS OKLAHOMA STAT
   Xu Y, 2013, NEURAL COMPUT APPL, V22, P501, DOI 10.1007/s00521-011-0803-3
   Yang HC, 2021, ENERGY REP, V7, P111, DOI 10.1016/j.egyr.2021.02.015
   Zhang Y, 2017, ADV MECH ENG, V9, DOI 10.1177/1687814017711389
   Zhang YJ, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/529724
   Zhou Y., 2021, ARXIV
NR 33
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25651
EP 25675
DI 10.1007/s11042-023-14384-3
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000924075600001
DA 2024-07-18
ER

PT J
AU Parthiban, K
   Kamarasan, M
AF Parthiban, K.
   Kamarasan, M.
TI Diabetic retinopathy detection and grading of retinal fundus images
   using coyote optimization algorithm with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal fundus image; Diabetic retinopathy; Image segmentation; Optimal
   parameter tuning; Decision making; Deep learning
ID DIAGNOSIS
AB Diabetic retinopathy (DR) is a major reason of preventable blindness for diabetic patients. Regular retinal screening is recommended for diabetic persons to detect DR at the earlier stages. Manual retinal screening of DR is a difficult and laborious process, computer aided diagnosis models become essential. Recently deep learning (DL) methods enable effectual detection and classification of medical images, particularly retinal fundus images. With this motivation, this work presents an intelligent coyote optimization algorithm with DL based DR detection and grading (ICOA-DLDRD) model on retinal fundus images. The purpose of the ICOA-DLDRD approach is to identify the presence of DR on retinal fundus images. Primarily, the ICOA-DLDRD algorithm comprises Gabor filtering (GF) based noise removal and optimal region growing segmentation technique. Further, the primary seed points and thresholds of the region growing segmentation technique are optimally created utilizing the glowworm swarm optimization (GSO) algorithm. In addition, SqueezeNet with class attention learning (CAL) layer is derived for the extraction of feature vectors. Lastly, COA with a deep extreme learning machine (DELM) classifier is applied for the detection and grading of DR, in which the penalty parameter C and kernel parameter gamma gamma of the DELM model are optimally adjusted by the use of COA. The performance validation of the ICOA-DLDRD method occurs utilizing the benchmark MESSIDOR dataset and the outcomes reported the betterment of the ICOA-DLDRD approach on the recent methods with maximum accuracy of 99.65%.
C1 [Parthiban, K.; Kamarasan, M.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, India.
C3 Annamalai University
RP Parthiban, K (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, India.
EM rkparthiban2013@gmail.com; smkrasan@yahoo.com
CR Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Bhardwaj C, 2021, J DIGIT IMAGING, V34, P440, DOI 10.1007/s10278-021-00418-5
   Chen K, 2021, ARXIV
   Dai L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23458-5
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Das S, 2022, MULTIMED TOOLS APPL, V81, P8007, DOI 10.1007/s11042-021-11824-w
   Ding SF, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/129021
   Elsharkawy M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020461
   Fatima, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105424
   Gangwar Akhilesh Kumar, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), P679, DOI DOI 10.1007/978-981-15-5788-064
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Kauppi T., 2021, DIARETDB1 DIABETIC R
   Kaushik H, 2021, IEEE ACCESS, V9, P108276, DOI 10.1109/ACCESS.2021.3101142
   Koonce B., 2021, Convolutional Neural Networks with Swift for Tensorflow, P73, DOI [DOI 10.1007/978-1-4842-6168-2_7, 10.1007/978-1-4842-6168-2_7]
   Li F, 2022, EYE, V36, P1433, DOI 10.1038/s41433-021-01552-8
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Majumder S, 2021, IEEE ACCESS, V9, P123220, DOI 10.1109/ACCESS.2021.3109240
   Pierce J., 2010, Proceedings of the 8th ACM Conference on Designing Interactive Systems, P1, DOI DOI 10.1007/978-3-319-77158-8_1
   Punitha S., 2018, Future Computing and Informatics Journal, V3, P348, DOI 10.1016/j.fcij.2018.10.005
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Ryu G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02479-6
   Saeed F, 2021, IEEE ACCESS, V9, P41344, DOI 10.1109/ACCESS.2021.3065273
   Saranya P, 2022, VISUAL COMPUT, V38, P977, DOI 10.1007/s00371-021-02062-0
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Song ZJ, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.759485
   Tang MCS, 2022, IEEE ACCESS, V10, P20247, DOI 10.1109/ACCESS.2022.3151644
   Vaishnavi J, 2020, MULTIMED TOOLS APPL, V79, P30439, DOI 10.1007/s11042-020-09288-5
   Wang XY, 2019, ENERGY STRATEG REV, V26, DOI 10.1016/j.esr.2019.100425
   Wu T, 2022, INTELLIGENCE BASED M
NR 31
TC 10
Z9 10
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18947
EP 18966
DI 10.1007/s11042-022-14234-8
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887890400002
DA 2024-07-18
ER

PT J
AU Ranjan, R
   Thakur, A
AF Ranjan, Rajeev
   Thakur, Abhishek
TI Image encryption using discrete orthogonal Stockwell transform with
   fractional Fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-frequency analysis; Stockwell transform; Fractional Fourier
   transform; Encryption; NPCR; UACI
ID ALGORITHM
AB In this article, a new image encryption algorithm has been proposed for image security. This algorithm is created with discrete orthogonal Stockwell transform (DOST) and fractional Fourier transform (FrFT). It has been used for image encryption and decryption. The DOST has improved computational efficiency and delivered a spatial time-frequency depiction similar to the other transform like discrete wavelet transform (DWT). In this method, encryption of the image has been used DOST with independent specific keys and its fractional-order and analyzed the effect of DOST. Thereafter, decrypted the image through the inverse process of the image encryption. The encrypted image has been achieved using the correct order and keys. We used different images and plotted their encrypted histogram and scatter, respectively. Then, calculate the correlation coefficient of the original, encryption image, encryption time, and entropy. Moreover, evaluate the variation between encrypted and original images using the number of pixel change rates (NPCR) and unified average changing intensity (UACI). Also, it compared the results of the proposed algorithm with the existing algorithm.
C1 [Ranjan, Rajeev; Thakur, Abhishek] Chandigarh Univ, Dept Elect & Commun Engn, Mohali, Punjab, India.
C3 Chandigarh University
RP Ranjan, R (corresponding author), Chandigarh Univ, Dept Elect & Commun Engn, Mohali, Punjab, India.
EM rajeevranjan1134@gmail.com; abhithakur25@gmail.com
RI Ranjan, Rajeev/GMX-0032-2022
OI Ranjan, Rajeev/0000-0003-2359-4879; -, Abhishek/0000-0002-9955-9693
CR Ansari N, 2016, PROCEDIA COMPUT SCI, V78, P125, DOI 10.1016/j.procs.2016.02.021
   Drabycz S, 2009, J DIGIT IMAGING, V22, P696, DOI 10.1007/s10278-008-9138-8
   Elkady Mona M., 2016, 2016 26th International Conference on Computer Theory and Applications (ICCTA), P20, DOI 10.1109/ICCTA40200.2016.9512943
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Jiang MH, 2012, OPT COMMUN, V285, P209, DOI 10.1016/j.optcom.2011.09.015
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kumar M, 2017, OPT LASER ENG, V88, P51, DOI 10.1016/j.optlaseng.2016.07.009
   Kumar HSR, 2017, CYBERN INF TECHNOL, V17, P134, DOI 10.1515/cait-2017-0046
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mukherjee I, 2018, MULTIMED TOOLS APPL, V77, P5281, DOI 10.1007/s11042-017-4431-5
   Musheer A, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1403.6626
   Nithya B, 2015, PROCEDIA COMPUT SCI, V45, P290, DOI 10.1016/j.procs.2015.03.143
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   Raghunandan KR, 2020, CYBERN INF TECHNOL, V20, P86, DOI 10.2478/cait-2020-0030
   Ranjan Rajeev, 2018, 2018 2nd International Conference on Micro-Electronics and Telecommunication Engineering (ICMETE), P260, DOI 10.1109/ICMETE.2018.00064
   Ranjan R, 2019, INT J RECENT TECHNOL, V1, P2277
   Ranjan R, 2022, MULTIMED TOOLS APPL, V81, P16661, DOI 10.1007/s11042-022-12757-8
   Ranjan R, 2020, WIRELESS PERS COMMUN, V113, P2519, DOI 10.1007/s11277-020-07339-6
   Ranjan R, 2019, INTEGR TRANSF SPEC F, V30, P471, DOI 10.1080/10652469.2019.1590353
   Ranjan R, 2018, OPTIK, V168, P913, DOI 10.1016/j.ijleo.2018.05.009
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Wang YW, 2008, AIP CONF PROC, V1048, P585, DOI 10.1063/1.2990992
   Wang YW, 2009, PROC SPIE, V7245, DOI 10.1117/12.806005
   Wang YW, 2009, SIAM J SCI COMPUT, V31, P4000, DOI 10.1137/080737113
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
NR 30
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18517
EP 18527
DI 10.1007/s11042-022-14240-w
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000885231500010
DA 2024-07-18
ER

PT J
AU Muneera, MN
   Sriramya, P
AF Muneera, Nafees M.
   Sriramya, P.
TI Abstractive text summarization employing ontology-based knowledge-aware
   multi-focus conditional generative adversarial network (OKAM-CGAN) with
   hybrid pre-processing methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-processing; Ontology; Adversarial network; Text summarization;
   Multi-focus; Deep learning
AB Over the past few years, the explainable artificial intelligence (XAI) model receives a broad desire for investigation. The natural language processing (NLP) commune is reaching the fundamental change too - constructing a set of paradigms, which describe the preference on a few chief jobs devoid of influencing the execution. Abstractive Text Summarization (ATS) remains the job of building summary sentences by fusing factualities out of disparate source sentences and compressing them into a smaller portrayal when sustaining data content and comprehensive sense. This remains extremely arduous and long-drawn-out for people to physically summarize huge text documents. This study proffers Ontology-based Knowledge Aware Multi-focus Conditional Generative Adversarial Network (OKAM-CGAN) for novel documents. This could build novel sentences by analyzing many finer pieces than sentences, especially, semantic phrases. The proffered OKAM-CGAN comprises 3 prime portions - ontology aware knowledge-based document representation module, multitask and multi-focus learning unit, and an adversarial network unit. Experiential assessment is performed by correlating with advanced methodologies like RNN-W, CopyNet, GCU, Seq2Seq, and KESG concerning ROUGE scores. Consequently, it is observed that the proffered OKAM-CGAN attains 42.1% of ROUGE-L, 40% of accuracy, 45%of precision, and 53% of recall for the CNN/Daily Mail database and 45% of ROUGE-L, 4% of accuracy, 54% of precision, and 57% of recall for the Edmunds database.
C1 [Muneera, Nafees M.; Sriramya, P.] Saveetha Univ, Saveetha Sch Engn, Saveetha Inst Med & Tech Sci, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Muneera, MN (corresponding author), Saveetha Univ, Saveetha Sch Engn, Saveetha Inst Med & Tech Sci, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
EM nafeesmuneera@gmail.com
RI P, Sriramya/AAB-4205-2019
OI P, Sriramya/0000-0002-2849-7093
CR Afzal M, 2020, J MED INTERNET RES, V22, DOI 10.2196/19810
   Amirian S, 2021, TRANS COMP SCI C INT, P17, DOI 10.1007/978-3-030-70296-0_2
   Aribandi V, 2021, ARXIV
   Belwal RC, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102536
   Curiel A, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101143
   del Arco FMP, 2021, MULTITASK LEARNING S
   Fornaciari T, 2022, 2021 C N AM CHAPTER
   Ganesan K, 2010, P 23 INT C COMP LING, P340
   Genest P.-E., 2012, P 50 ANN M ASS COMP, V2, P354
   Le HT, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P371, DOI 10.1109/SOCPAR.2013.7054161
   John A, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P31, DOI 10.1109/RAICS.2013.6745442
   Kaliapan M, 2016, SCI WORLD J
   Kotadiya R, 2020, P 1 INT C COMPUTING
   Lan LB, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106971
   Lee S., 2021, IEEE Access, VPP, P1
   Lloret, 1 INT C ADV INFO MIN
   Mohanty SN, 2019, J INTELL FUZZY SYST, V37, P205, DOI 10.3233/JIFS-179078
   Muthu B, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3392048
   Rekabdar B, 2019, IEEE INT C SEMANT CO, P204, DOI [10.1109/ICSC.2019.00047, 10.1109/ICOSC.2019.8665583]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Satapathy, 2021, DATA ANALYTICS BIOIN, P431, DOI [10.1002/9781119785620.ch17, DOI 10.1002/9781119785620.CH17]
   Steedman M, 2011, NON-TRANSFORMATIONAL SYNTAX: FORMAL AND EXPLICIT MODELS OF GRAMMAR, P181
   Suleiman D, 2017, PROCEDIA COMPUT SCI, V113, P240, DOI 10.1016/j.procs.2017.08.363
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Tarchi C, 2017, ISS EDUC RES, V27, P600
   Tomer M., 2021, Journal of King Saud University-Computer and Information Sciences
   Verma S, 2017, ARXIV170804439
   Wang DD, 2012, INFORM PROCESS MANAG, V48, P513, DOI 10.1016/j.ipm.2011.07.003
   Wang HY, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5426795
   Xu H, 2018, PROC INT C TOOLS ART, P242, DOI 10.1109/ICTAI.2018.00045
   Yang M, 2020, INFORM SCIENCES, V521, P46, DOI 10.1016/j.ins.2020.02.040
   Zhao W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1205
NR 32
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23305
EP 23331
DI 10.1007/s11042-022-14155-6
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884646200006
DA 2024-07-18
ER

PT J
AU Chakraborty, P
   Nama, S
   Saha, AK
AF Chakraborty, Prasanjit
   Nama, Sukanta
   Saha, Apu Kumar
TI A hybrid slime mould algorithm for global optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metaheuristics; Swarm intelligence; Slime Mould algorithm; Quadratic
   approximation; Hybrid algorithm
ID DIFFERENTIAL EVOLUTION; SEARCH ALGORITHM
AB The local optima stagnation is a major issue with all meta-heuristic algorithms. In this paper, a hybrid slime mould algorithm (SMA) is proposed with the aid of quadratic approximation to address the aforesaid problem to expedite the explorative strength of slime mould in nature. As quadratic approximation performs better within the local confinement region, so the QA has been incorporated with SMA to propose the hybrid HSMA to improve the exploitation ability of the algorithm so that global optimum can be achieved. The effectiveness of the proposed algorithm has been compared with classical SMA, some state-of-the-art metaheuristics, some PSO variants using 20 benchmark problems and IEEE CEC 2017 suite. Convergence analysis and statistical tests are performed to validate the supremacy of the proposed algorithm. Moreover, three real-world engineering optimization problems are solved, and solutions are compared with various algorithms. Results and their analyses convey the fruitfulness of the proposed algorithm by showing encouraging performance on different search landscapes.
C1 [Chakraborty, Prasanjit; Saha, Apu Kumar] Natl Inst Technol Agartala, Dept Math, Agartala 799046, Tripura, India.
   [Nama, Sukanta] Gomati Dist Polytech, Dept Sci & Humanities, Udaipur 799013, Tripura, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala
RP Saha, AK (corresponding author), Natl Inst Technol Agartala, Dept Math, Agartala 799046, Tripura, India.
EM apusaha_nita@yahoo.co.in
RI Saha, Apu Kumar/ABE-6548-2021
OI Saha, Apu Kumar/0000-0002-3475-018X
CR Civicioglu P, 2013, APPL MATH COMPUT, V219, P8121, DOI 10.1016/j.amc.2013.02.017
   Das S., 2010, Problem definitions and evaluation criteria for CEC 2011 competition on testing evolutionary algorithms on real world optimization problems, P341
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Draz A, 2021, NEURAL COMPUT APPL, V33, P11875, DOI 10.1007/s00521-021-05879-x
   Ewees AA, 2022, ENG COMPUT-GERMANY, V38, P2407, DOI 10.1007/s00366-021-01342-6
   Formato RA, 2007, PROG ELECTROMAGN RES, V77, P425, DOI 10.2528/PIER07082403
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Gupta J, 2021, INT J ENERG RES, V45, P14732, DOI 10.1002/er.6750
   Gush T, 2021, IEEE ACCESS, V9, P52164, DOI 10.1109/ACCESS.2021.3070155
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Houssein EH, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114689
   Karaboga D., 2010, Scholarpedia, V5, P6915, DOI [DOI 10.4249/SCHOLARPEDIA.6915, 10.4249/scholarpedia.6915]
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Kaveh A, 2022, COMPUT STRUCT, V264, DOI 10.1016/j.compstruc.2022.106760
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Liang XD, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/5333278
   Lin Q, 2015, COMPUT IND ENG, V85, P437, DOI 10.1016/j.cie.2015.04.009
   Lin WY, 2010, MECH MACH THEORY, V45, P1096, DOI 10.1016/j.mechmachtheory.2010.03.011
   Lozano M, 2010, COMPUT OPER RES, V37, P481, DOI 10.1016/j.cor.2009.02.010
   Lynden JM, 2019, THESIS
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Moosavian N., 2014, Int. J. Intell. Sci, V4, P7, DOI [DOI 10.4236/IJIS.2014.41002, 10.4236/ijis.2014.41002, 10.4236/ijis.2014]
   Mortazavi A, 2019, ADV ENG SOFTW, V127, P106, DOI 10.1016/j.advengsoft.2018.11.004
   Nama S., 2016, DECIS SCI LETT, V5, P361, DOI [10.5267/j.dsl.2016.2.004, DOI 10.5267/J.DSL.2016.2.004]
   Nama S., 2018, Decis. Sci. Lett., V7, P103, DOI [10.5267/J.DSL.2017.6.006, DOI 10.5267/J.DSL.2017.6.006]
   Nama S., 2019, Decis. Sci. Lett., V8, P163, DOI [10.5267/j.dsl.2018.7.002, DOI 10.5267/J.DSL.2018.7.002]
   Nama S, 2022, APPL SOFT COMPUT, V118, DOI 10.1016/j.asoc.2022.108483
   Nama S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03183-z
   Nama S, 2020, INTEL SYST REF LIBR, V172, P291, DOI 10.1007/978-3-030-32644-9_30
   Nama S, 2021, APPL INTELL, V51, P7881, DOI 10.1007/s10489-020-01974-z
   Nama S, 2020, INT J MODEL SIMUL SC, V11, DOI 10.1142/S1793962320500294
   Nama S, 2018, APPL INTELL, V48, P1657, DOI 10.1007/s10489-017-1016-y
   Nama S, 2017, MEMET COMPUT, V9, P261, DOI 10.1007/s12293-016-0194-1
   Örnek BN, 2022, MATH COMPUT SIMULAT, V198, P253, DOI 10.1016/j.matcom.2022.02.030
   Pan JS, 2022, ELECTR POW SYST RES, V208, DOI 10.1016/j.epsr.2022.107925
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Precup RE, 2021, INT J COMPUT INT SYS, V14, P1042, DOI 10.2991/ijcis.d.210309.001
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Rao S. S., 2009, ENG OPTIMIZATION THE, DOI DOI 10.1002/9781119454816
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ren LL, 2022, MEASUREMENT, V192, DOI 10.1016/j.measurement.2022.110884
   Sadollah A, 2013, APPL SOFT COMPUT, V13, P2592, DOI 10.1016/j.asoc.2012.11.026
   Saha A, 2021, INT J GEOTECH ENG, V15, P1298, DOI 10.1080/19386362.2019.1598015
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P12035, DOI 10.1007/s11042-020-10053-x
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun KJ, 2021, J INTELL FUZZY SYST, V40, P1667, DOI 10.3233/JIFS-201755
   Tan Y, 2010, LECT NOTES COMPUT SC, V6145, P355
   Tiachacht S, 2022, ENG COMPUT-GERMANY, V38, P2205, DOI 10.1007/s00366-021-01378-8
   Vashishtha G, 2021, MEASUREMENT, V178, DOI 10.1016/j.measurement.2021.109389
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yi WC, 2015, APPL INTELL, V42, P642, DOI 10.1007/s10489-014-0620-3
   Zhang CS, 2009, OPER RES LETT, V37, P117, DOI 10.1016/j.orl.2008.12.008
   Zhao SW, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104427
   Zheng-Ming Gao, 2020, Journal of Physics: Conference Series, V1631, DOI 10.1088/1742-6596/1631/1/012083
   Zobaa AM, 2021, 2021 IEEE TEXAS POWER AND ENERGY CONFERENCE (TPEC), P160, DOI 10.1109/TPEC51183.2021.9384950
   Zubaidi SL, 2020, WATER-SUI, V12, DOI 10.3390/w12102692
NR 57
TC 14
Z9 14
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22441
EP 22467
DI 10.1007/s11042-022-14077-3
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000881891300002
DA 2024-07-18
ER

PT J
AU Binsch, O
   Oudejans, N
   van der Kuil, MNA
   Landman, A
   Smeets, MMJ
   Leers, MPG
   Smit, AS
AF Binsch, Olaf
   Oudejans, Nanco
   van der Kuil, Milan N. A.
   Landman, Annemarie
   Smeets, Math M. J.
   Leers, Mathie P. G.
   Smit, Annika S.
TI The effect of virtual reality simulation on police officers' performance
   and recovery from a real-life surveillance task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Navigation; Stress; Workload; Recuperation; Heart rate variability;
   Salivary cortisol
ID HEART-RATE-VARIABILITY; SPATIAL NAVIGATION; CORTISOL RESPONSES; MENTAL
   WORKLOAD; WORKING-MEMORY; EXPERIENCE; STRESS; ROUTE; KNOWLEDGE; STRATEGY
AB Virtual reality (VR) simulation tools, in combination with miniaturized sensor and geo-technology, represent an opportunity to prepare high-risk professionals better for uncertain situations. In the current study, we tested whether VR preparation for a police surveillance task leads to increased performance and decreased stress, workload, and a faster recuperation. Police officers (n = 46) were either prepared with a 3D interactive VR simulation of the venue, or received the standard preparation using a 2D paper-based map. Then, officers individually conducted a surveillance scenario during a real live-music concert. Position tracking, heart rate, heart rate variability (HRV), salivary cortisol levels (SCL) and self-perceived stress were assessed. Results showed that police officers with the VR preparation made less direction changes when finding target locations, had lower HRV during the surveillance, and had lower SCL during their recuperation. These results indicate that VR preparation may increase police officers' performance and improve their recovery.
C1 [Binsch, Olaf; Landman, Annemarie] Netherlands Org Appl Sci Res TNO, Kampweg 55, NL-3769 ZG Soesterberg, Netherlands.
   [Binsch, Olaf] Dutch Minist Def, Dept Social Cultural & Humanitarian Ailairs, Civil Mil Interact Command, Apeldoorn, Netherlands.
   [Oudejans, Nanco] Dutch Natl Police, Police Dept Nijmegen South, Nijmegen, Netherlands.
   [van der Kuil, Milan N. A.] Leiden Univ, Dept Hlth Med & Neuropsychol, Leiden, Netherlands.
   [Smeets, Math M. J.; Leers, Mathie P. G.] Zuyderland Med Ctr, Dept Clin Chem & Hematol, Sittard Geleen, Netherlands.
   [Smit, Annika S.] Police Acad, Dept Knowledge & Res, Apeldoorn, Netherlands.
   [Smit, Annika S.] Univ Humanist Studies, Utrecht, Netherlands.
C3 Netherlands Organization Applied Science Research; Leiden University -
   Excl LUMC; Leiden University; Zuyderland Medical Center
RP Binsch, O (corresponding author), Netherlands Org Appl Sci Res TNO, Kampweg 55, NL-3769 ZG Soesterberg, Netherlands.; Binsch, O (corresponding author), Dutch Minist Def, Dept Social Cultural & Humanitarian Ailairs, Civil Mil Interact Command, Apeldoorn, Netherlands.
EM olaf.binsch@tno.nl; Nanco.Oudejans@politie.nl;
   m.n.a.van.der.kuil@fsw.leidenuniv.nl; Annemarie.landman@tno.nl;
   mathsmeets@hetnet.nl; mat.leers@zuyderland.nl;
   Annika.Smit@politieacademie.nl
RI Leers, Mathie/AFV-8239-2022
OI Leers, Mathie/0000-0001-5186-5600
FU Dutch Police Departement
FX Funding for this project was provided by the Dutch Police Departement.
CR Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Alikhani I, 2017, IEEE ENG MED BIO, P3993, DOI 10.1109/EMBC.2017.8037731
   Almousa O, 2019, SIMULAT GAMING, V50, P6, DOI 10.1177/1046878118820905
   [Anonymous], 2018, P 2018 IEEE INT C CO, DOI DOI 10.1109/ICC.2018.8423003
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Binsch O, 2017, J SCI MED SPORT, V20, P141
   Binsch O, 2021, MIL PSYCHOL, V33, P182, DOI 10.1080/08995605.2021.1897494
   Binsch O, 2017, MIL PSYCHOL, V29, P99, DOI 10.1037/mil0000146
   Bitters B, 2019, P ENV SYSTEMS RES I
   Bonny JW, 2016, APPL COGNITIVE PSYCH, V30, P664, DOI 10.1002/acp.3234
   Bostock S, 2011, PSYCHONEUROENDOCRINO, V36, P1175, DOI 10.1016/j.psyneuen.2011.02.009
   Brooks BM, 1999, MEMORY, V7, P65, DOI 10.1080/741943713
   Brunyé TT, 2008, ACTA PSYCHOL, V127, P340, DOI 10.1016/j.actpsy.2007.07.002
   Buckley MG, 2015, DEV PSYCHOL, V51, P771, DOI 10.1037/a0039054
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chernyuk DP, 2021, J EVOL BIOCHEM PHYS+, V57, P289, DOI 10.1134/S0022093021020113
   Cinaz B, 2013, PERS UBIQUIT COMPUT, V17, P229, DOI 10.1007/s00779-011-0466-1
   Claessen MHG, 2017, NEUROSCI BIOBEHAV R, V73, P81, DOI 10.1016/j.neubiorev.2016.12.015
   Claessen MHG, 2016, NEUROPSYCHOL REHABIL, V26, P822, DOI 10.1080/09602011.2015.1045910
   Dickerson SS, 2004, PSYCHOL BULL, V130, P355, DOI 10.1037/0033-2909.130.3.355
   Eccles DW, 2015, J SPORT SCI, V33, P609, DOI 10.1080/02640414.2014.951953
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Fan YC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030451
   Franz MO, 2000, ROBOT AUTON SYST, V30, P133, DOI 10.1016/S0921-8890(99)00069-X
   Gagnon KT, 2018, COGNITION, V180, P108, DOI 10.1016/j.cognition.2018.06.020
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Guyton A.C., 2006, Textbook of Medical Physiology
   Hamilton DA, 2002, BEHAV BRAIN RES, V129, P159, DOI 10.1016/S0166-4328(01)00343-6
   Hancock P.A., 2008, Performance under stress
   Hansen AL, 2003, INT J PSYCHOPHYSIOL, V48, P263, DOI 10.1016/S0167-8760(03)00073-4
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Harvey DR, 2008, NEUROBIOL LEARN MEM, V89, P462, DOI 10.1016/j.nlm.2007.08.013
   Harvey DR, 2009, BEHAV PROCESS, V82, P190, DOI 10.1016/j.beproc.2009.06.008
   Hellhammer DH, 1997, PSYCHONEUROENDOCRINO, V22, P643, DOI 10.1016/S0306-4530(97)00063-2
   Hellhammer DH, 2009, PSYCHONEUROENDOCRINO, V34, P163, DOI 10.1016/j.psyneuen.2008.10.026
   HOUTMAN ILD, 1991, J PSYCHOSOM RES, V35, P323, DOI 10.1016/0022-3999(91)90087-5
   Howard MC, 2021, COMPUT HUM BEHAV, V121, DOI 10.1016/j.chb.2021.106808
   Hsu BW, 2015, PERCEPT MOTOR SKILL, V121, P94, DOI 10.2466/22.PMS.121c12x5
   Huang CJ, 2013, FRONT PHYSIOL, V4, DOI 10.3389/fphys.2013.00314
   Iglói K, 2009, HIPPOCAMPUS, V19, P1199, DOI 10.1002/hipo.20595
   Ishikawa T., 2014, CARTOGRAPHIC PERSPEC, V75, P17, DOI [10.14714/CP75.82, DOI 10.14714/CP75.82]
   Jaskiewicz Filip, 2019, EMERG MED SERV, V6, P32
   Jordan K, 2002, NEUROPSYCHOLOGIA, V40, P2397, DOI 10.1016/S0028-3932(02)00076-3
   Kaminska D, 2020, IEEE ACCESS, V8, P200351, DOI 10.1109/ACCESS.2020.3035540
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Khan N, 2018, INT J HUM-COMPUT INT, V34, P1135, DOI 10.1080/10447318.2017.1418804
   Khan R, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008237.pub3
   Kinnear P, 2006, SPSS 12 MADE SIMPLE, DOI [10.4324/9780203497388, DOI 10.4324/9780203497388]
   KIRSCHBAUM C, 1989, NEUROPSYCHOBIOLOGY, V22, P150, DOI 10.1159/000118611
   Kober SE, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-17
   Kudielka BM, 2009, PSYCHONEUROENDOCRINO, V34, P2, DOI 10.1016/j.psyneuen.2008.10.004
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Lee ACH, 2010, J COGNITIVE NEUROSCI, V22, P2823, DOI 10.1162/jocn.2009.21396
   Lloyd J, 2009, NEUROPSYCHOL REHABIL, V19, P98, DOI 10.1080/09602010802117392
   Luft CD, 2009, BIOL PSYCHOL, V82, P196, DOI 10.1016/j.biopsycho.2009.07.007
   Maggio MG, 2019, J NEUROSCI NURS, V51, P101, DOI 10.1097/JNN.0000000000000423
   Maguire EA, 1999, CURR OPIN NEUROBIOL, V9, P171, DOI 10.1016/S0959-4388(99)80023-3
   Marre Q, 2021, INT J HUM-COMPUT INT, V37, P1089, DOI 10.1080/10447318.2020.1870819
   MATTHEWS JNS, 1990, BMJ-BRIT MED J, V300, P230, DOI 10.1136/bmj.300.6719.230
   McAllister MJ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17145042
   McCraty Rollin, 2015, Glob Adv Health Med, V4, P46, DOI 10.7453/gahmj.2014.073
   Meilinger T, 2015, PSYCHOL RES-PSYCH FO, V79, P1000, DOI 10.1007/s00426-014-0629-6
   Merino M, 2015, MED ENG PHYS, V37, P605, DOI 10.1016/j.medengphy.2015.03.019
   Middleton HC, 1999, PSYCHOPHYSIOLOGY, V36, P610, DOI 10.1017/S0048577299981726
   MOESER SD, 1988, ENVIRON BEHAV, V20, P21, DOI 10.1177/0013916588201002
   Mottet M, 2016, SPAT COGN COMPUT, V16, P220, DOI 10.1080/13875868.2016.1166229
   Münzer S, 2006, J ENVIRON PSYCHOL, V26, P300, DOI 10.1016/j.jenvp.2006.08.001
   Muffato V, 2019, PSYCHOL RES-PSYCH FO, V83, P1836, DOI 10.1007/s00426-018-1033-4
   Noordzij ML, 2006, COGNITION, V100, P321, DOI 10.1016/j.cognition.2005.05.006
   Perini R, 2000, EUR J APPL PHYSIOL, V82, P8, DOI 10.1007/s004210050645
   Peters A, 2004, NEUROSCI BIOBEHAV R, V28, P143, DOI 10.1016/j.neubiorev.2004.03.002
   Ryff CD, 2004, PHILOS T R SOC B, V359, P1383, DOI 10.1098/rstb.2004.1521
   Salahuddin L, 2007, P ANN INT IEEE EMBS, P4656, DOI 10.1109/IEMBS.2007.4353378
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Smeets MMJ, 2021, EMERG MED J, V38, P297, DOI 10.1136/emermed-2019-209205
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Thayer JF, 2006, ANN NY ACAD SCI, V1088, P361, DOI 10.1196/annals.1366.014
   Thiruvengada Hari, 2011, Virtual and Mixed Reality - Systems and Applications. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P100, DOI 10.1007/978-3-642-22024-1_12
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Tozman T, 2015, COMPUT HUM BEHAV, V52, P408, DOI 10.1016/j.chb.2015.06.023
   Trifonova ST, 2013, PSYCHONEUROENDOCRINO, V38, P1090, DOI 10.1016/j.psyneuen.2012.10.016
   van den Berg ME, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00424
   van der Kuil MNA, 2021, PSYCHOL RES-PSYCH FO, V85, P2137, DOI 10.1007/s00426-020-01389-y
   van der Kuil MNA, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00846
   van der Vijgh B, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00400
   Vermetten E, 2020, J MIL VETERAN FAM HL, V6, P26, DOI 10.3138/jmvfh.2019-0033
   Vincent A, 1996, INT J PSYCHOPHYSIOL, V23, P181, DOI 10.1016/S0167-8760(96)00058-X
   Waller D, 2003, PSYCHON B REV, V10, P987, DOI 10.3758/BF03196563
   Wang F, 1998, COMPUT CARDIOL, V25, P97, DOI 10.1109/CIC.1998.731734
   Wiener JM, 2013, J NEUROSCI, V33, P6012, DOI 10.1523/JNEUROSCI.0717-12.2013
   Wolbers T, 2010, TRENDS COGN SCI, V14, P138, DOI 10.1016/j.tics.2010.01.001
   Wood PJ, 1997, ANN CLIN BIOCHEM, V34, P222, DOI 10.1177/000456329703400302
   Zhang H, 2014, MEM COGNITION, V42, P1106, DOI 10.3758/s13421-014-0418-x
NR 95
TC 3
Z9 3
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17471
EP 17492
DI 10.1007/s11042-022-14110-5
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000878461100001
DA 2024-07-18
ER

PT J
AU Buono, P
   De Carolis, B
   D'Errico, F
   Macchiarulo, N
   Palestra, G
AF Buono, Paolo
   De Carolis, Berardina
   D'Errico, Francesca
   Macchiarulo, Nicola
   Palestra, Giuseppe
TI Assessing student engagement from facial behavior in on-line learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Engagement measurement; Face behavior; Computer vision; LSTM
ID RECOGNITION; EMOTIONS; INDEXES; SCHOOL; FLOW
AB The automatic monitoring and assessment of the engagement level of learners in distance education may help in understanding problems and providing personalized support during the learning process. This article presents a research aiming to investigate how student engagement level can be assessed from facial behavior and proposes a model based on Long Short-Term Memory (LSTM) networks to predict the level of engagement from facial action units, gaze, and head poses. The dataset used to learn the model is the one of the EmotiW 2019 challenge datasets. In order to test its performance in learning contexts, an experiment, involving students attending an online lecture, was performed. The aim of the study was to compare the self-evaluation of the engagement perceived by the students with the one assessed by the model. During the experiment we collected videos of students behavior and, at the end of each session, we asked students to answer a questionnaire for assessing their perceived engagement. Then, the collected videos were analyzed automatically with a software that implements the model and provides an interface for the visual analysis of the model outcome. Results show that, globally, engagement prediction from students' facial behavior was weakly correlated to their subjective answers. However, when considering only the emotional dimension of engagement, this correlation is stronger and the analysis of facial action units and head pose (facial movements) are positively correlated with it, while there is an inverse correlation with the gaze, meaning that the more the student's feels engaged the less are the gaze movements.
C1 [Buono, Paolo; De Carolis, Berardina; Macchiarulo, Nicola] Univ Bari Aldo Moro, Dept Comp Sci, Via Orabona 4, I-70125 Bari, Italy.
   [D'Errico, Francesca] Univ Bari Aldo Moro, Dept Educ Psychol & Commun, Via Crisanzio 42, I-70122 Bari, Italy.
   [Palestra, Giuseppe] HERO Srl, Rome, Italy.
C3 Universita degli Studi di Bari Aldo Moro; Universita degli Studi di Bari
   Aldo Moro
RP Buono, P (corresponding author), Univ Bari Aldo Moro, Dept Comp Sci, Via Orabona 4, I-70125 Bari, Italy.
EM paolo.buono@uniba.it; berardina.decarolis@uniba.it;
   francesca.derrico@uniba.it; nicola.macchiarulo@uniba.it;
   giuseppepalestra@gmail.com
RI D'Errico, Francesca/HRA-2118-2023; D'ERRICO, FRANCESCA/AAD-7165-2019;
   Buono, Paolo/E-9803-2014; Palestra, Giuseppe/HLW-6307-2023
OI D'Errico, Francesca/0000-0002-8957-665X; D'ERRICO,
   FRANCESCA/0000-0002-8957-665X; 
FU Universit`a degli Studi di Bari Aldo Moro within the CRUICARE Agreement
FX Open access funding provided by Universit`a degli Studi di Bari Aldo
   Moro within the CRUICARE Agreement.
CR Appleton JJ, 2008, PSYCHOL SCHOOLS, V45, P369, DOI 10.1002/pits.20303
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Behera A, 2020, INT J ARTIF INTELL E, V30, P236, DOI 10.1007/s40593-020-00195-2
   Berka C, 2004, INT J HUM-COMPUT INT, V17, P151, DOI 10.1207/s15327590ijhc1702_3
   Bosch N, 2014, LECT NOTES COMPUT SC, V8474, P39, DOI 10.1007/978-3-319-07221-0_5
   Bridle J.S, 1990, NEUROCOMPUTING, P227, DOI DOI 10.1007/978-3-642-76153-9_28
   Carofiglio V, 2019, GHITALY CHITALY
   Chang C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P616, DOI 10.1145/3242969.3264986
   D'Errico F, 2018, INT J EMOT EDUC, V10, P89
   D'Errico F, 2016, J E-LEARN KNOWL SOC, V12, P9
   D'Mello S., 2007, P 29 ANN COGNITIVE S, P905
   D'Mello S, 2017, EDUC PSYCHOL-US, V52, P104, DOI 10.1080/00461520.2017.1281747
   De Carolis B, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WI 2019 COMPANION), P80, DOI 10.1145/3358695.3361748
   Dennen VP., 2007, Distance Education, V28, P65, DOI [DOI 10.1080/01587910701305319, 10.1080/01587910701305319]
   Dermouche S, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P440, DOI 10.1145/3340555.3353765
   DeVellis R. F., 2016, Scale development: Theory and applications, DOI DOI 10.1037/CCP0000482
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Dhall A, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P546, DOI 10.1145/3340555.3355710
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Esposito A, 2021, LECT NOTES COMPUT SC, V12936, P63, DOI 10.1007/978-3-030-85607-6_4
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Fredricks JA, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P763, DOI 10.1007/978-1-4614-2018-7_37
   Gena C, 2019, ADJUNCT PUBLICATION OF THE 27TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (ACM UMAP '19 ADJUNCT), P387, DOI 10.1145/3314183.3323865
   Ghergulescu I, 2016, INT J ARTIF INTELL E, V26, P821, DOI 10.1007/s40593-016-0111-2
   Guo P. J., 2014, P 1 ACM C LEARN SCAL, P41, DOI DOI 10.1145/2556325.2566239
   Gupta A., 2016, ARXIV
   Hadfield J, 2019, IEEE INT C INT ROBOT, P1251, DOI [10.1109/iros40897.2019.8968443, 10.1109/IROS40897.2019.8968443]
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Handelsman MM, 2005, J EDUC RES, V98, P184, DOI 10.3200/JOER.98.3.184-192
   Helme S., 2001, MATH EDUC RES J, V13, P133, DOI [10.1007/BF03217103, DOI 10.1007/BF03217103]
   Henrie CR, 2015, COMPUT EDUC, V90, P36, DOI 10.1016/j.compedu.2015.09.005
   Herbig N, 2020, UMAP'20: PROCEEDINGS OF THE 28TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P88, DOI 10.1145/3340631.3394861
   Hew KF, 2018, INT REV RES OPEN DIS, V19, P69
   Holmes L, 2013, WALL STREET J
   Hussain M, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6347186
   Kapoor A., P 13 ANN ACM INT C M, P677
   Kaur A., 2018, 2018 DIGITAL IMAGE C, P1, DOI DOI 10.1109/DICTA.2018.8615851
   Kingma D. P., 2014, arXiv
   Lala Divesh, 2017, ARXIV
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Pérez JM, 2008, IEEE T KNOWL DATA EN, V20, P940, DOI 10.1109/TKDE.2007.190746
   Nicholls MER, 2015, Q J EXP PSYCHOL, V68, P10, DOI 10.1080/17470218.2014.925481
   Niu XS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P599, DOI 10.1145/3242969.3264982
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Poggi I, 2010, P 2 INT WORKSH SOC S, DOI [10.1145/1878116.1878124, DOI 10.1145/1878116.1878124]
   Poggi I, 2013, J MULTIMODAL USER IN, V7, P67, DOI 10.1007/s12193-012-0102-z
   POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3
   Raca M, 2015, THESIS ECOLE POLYTEC
   Thomas C, 2017, P 1 ACM SIGCHI INT W, P33, DOI DOI 10.1145/3139513.3139514
   Huynh VT, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P567, DOI 10.1145/3340555.3355714
   Wang K, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P551, DOI 10.1145/3340555.3355711
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Yang JF, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P594, DOI 10.1145/3242969.3264981
NR 56
TC 7
Z9 7
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12859
EP 12877
DI 10.1007/s11042-022-14048-8
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000871318500002
PM 36313482
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Ge, HW
   Su, SZ
   Wang, SX
AF Liu, Guoqing
   Ge, Hongwei
   Su, Shuzhi
   Wang, Shuangxi
TI Multi-view clustering via dual-norm and HSIC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Complementary information; Multi-view clustering; HSIC; l(1)-norm;
   Frobenius norm
ID CLASSIFICATION; ALGORITHM; ROBUST
AB Fully capturing valid complementary information in multi-view data enhances the connection between similar data points and weakens the correlation between different data point categories. In this paper, we propose a new multi-view clustering via dual-norm and Hilbert-Schmidt independence criterion (HSIC) induction (MCDHSIC) approach, which can enhance the complementarity, reduce the redundancy between multi-view representations, and improve the accuracy of the clustering results. This model uses the HSIC as the diversity regularization term to capture the nonlinear relationship between different views. In addition, l(1)-norm and Frobenius norm constraints are imposed to obtain a subspace representation matrix with inter-class sparsity and intra-class consistency. Moreover, we also designed a valuable approach to optimizing the proposed model and theoretically analyzing the convergence of the MCDHSIC method. The results of extensive experiments conducted on five challenging data sets show that the proposed method objectively achieves a highly competent performance compared with several other state-of-the-art multi-view clustering methods.
C1 [Liu, Guoqing; Ge, Hongwei; Wang, Shuangxi] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Liu, Guoqing; Ge, Hongwei; Wang, Shuangxi] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
   [Su, Shuzhi] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan 232001, Anhui, Peoples R China.
C3 Jiangnan University; Jiangnan University; Anhui University of Science &
   Technology
RP Ge, HW (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Ge, HW (corresponding author), Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
EM ghw8601@163.com
RI Zhang, Xiaoxi/KBP-8753-2024; ZHANG, YINGFANG/JQW-2816-2023; Wang,
   Siying/KHX-1894-2024; chen, wang/KGK-5932-2024; liu,
   wenli/JRW-0517-2023; Wang, Yuchen/JPW-9345-2023; Wang,
   lingyu/JLM-2013-2023
FU National Natural Science Foundation of China [61806006]; China
   Postdoctoral Science Foundation [2019 M660149]; 111 Project [B12018];
   PAPD of Jiangsu Higher Education Institutions
FX The National Natural Science Foundation of China under Grants 61806006,
   China Postdoctoral Science Foundation under Grant No. 2019 M660149, the
   111 Project under Grants No. B12018, and PAPD of Jiangsu Higher
   Education Institutions support this work. Guoqing Liu:
   Conceptualization, Methodology, Validation, Software, Formal analysis,
   Data curation, Investigation, Writing-original draft. Hongwei Ge:
   Resources, Review, Supervision, Project administration, Funding
   acquisition. Shuzhi Su: Review. Shuangxi Wang: Software, Visualization.
CR Avants BB, 2021, NAT COMPUT SCI, V1, P143, DOI 10.1038/s43588-021-00029-8
   BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Chauhan S, 2021, STRUCT HEALTH MONIT, V20, P2525, DOI 10.1177/1475921720962419
   Chauhan S, 2021, WIRELESS PERS COMMUN, V119, P585, DOI 10.1007/s11277-021-08225-5
   Chauhan S, 2021, CIRC SYST SIGNAL PR, V40, P3374, DOI 10.1007/s00034-020-01625-1
   Chen MS, 2021, INFORM FUSION, V68, P8, DOI 10.1016/j.inffus.2020.10.013
   De Sa V. R., 2005, ICML WORKSH LEARN MU, P20
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Hu J, 2020, IEEE ACM T COMPUT BI, V17, P1419, DOI 10.1109/TCBB.2019.2893634
   Hu ZX, 2020, NEUROCOMPUTING, V384, P1, DOI 10.1016/j.neucom.2019.12.004
   Huang AP, 2020, IEEE T IMAGE PROCESS, V29, P9600, DOI 10.1109/TIP.2020.3029883
   Hussain SF, 2022, APPL INTELL, V52, P14756, DOI 10.1007/s10489-021-03087-7
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kumar A., 2011, P 28 INT C MACHINE L, P393
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu GF, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01247-w
   Ng A. Y., 2002, PROC ADV NEURAL INF, P849
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan GX, 2021, IEEE T BIO-MED ENG, V68, P2529, DOI 10.1109/TBME.2020.3048594
   Sun YQ, 2019, J VIS COMMUN IMAGE R, V62, P253, DOI 10.1016/j.jvcir.2019.05.016
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Tzortzis G, 2012, IEEE DATA MINING, P675, DOI 10.1109/ICDM.2012.43
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Loon W, 2020, INFORM FUSION, V61, P113, DOI 10.1016/j.inffus.2020.03.007
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wang HX, 2014, PROC CVPR IEEE, P4106, DOI 10.1109/CVPR.2014.523
   Wang SQ, 2022, APPL INTELL, V52, P14935, DOI 10.1007/s10489-022-03816-6
   Wang XL, 2022, IEEE T CIRC SYST VID, V32, P6425, DOI 10.1109/TCSVT.2022.3159371
   Xu YJ, 2021, FUTURE GENER COMP SY, V117, P138, DOI 10.1016/j.future.2020.11.005
   Yin QY, 2015, NEUROCOMPUTING, V156, P12, DOI 10.1016/j.neucom.2015.01.017
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang CJ, 2020, IEEE T IMAGE PROCESS, V29, P617, DOI 10.1109/TIP.2019.2934576
NR 41
TC 0
Z9 0
U1 4
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 22
PY 2022
DI 10.1007/s11042-022-14057-7
EA OCT 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5M2JA
UT WOS:000870927200001
DA 2024-07-18
ER

PT J
AU Karn, AL
   Sengan, S
   Pustokhin, DA
   Pustokhina, IV
AF Karn, Arodh Lal
   Sengan, Sudhakar
   Pustokhin, Denis A.
   Pustokhina, Irina, V
TI Software-defined network-based dynamic access control mechanism for
   internet of vehicles using Adaboost
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of vehicles; AdaBoost algorithm; Software defined network;
   Machine learning; Internet of things
ID SERVICE FRAMEWORK; IOT
AB Access Control Models (ACM) must secure the communication system of devices in Internet of Vehicles (IoV) under cloud computing architecture. Existing ACM, on the other hand, struggles to determine the right granularity of permissions when dealing with vast numbers of data in the IoV. Furthermore, IoV is vulnerable to attacks, as attackers can readily exploit existing flaws. Due to insufficient or inefficient ACM, some attacks may succeed. As a result, the authentication mechanism must be reinforced as much as possible using cutting-edge ACM. Methods have been applied to Decisions Making System (DMS) about who has access to what in open distributed information systems like big data, the Internet of Things (IoT), and the cloud experience performance issues because of the number and complexity of the rules and regulations governing who has significant exposure to what. The reasonably significant Access Control (AC) time operational costs have a negative impact on the regular functioning of business services as a consequence. This paper presents a framework for an efficient SDN-involved Dynamic Access system based on AdaBoost (SDNDAAB) model. The challenges related to the ACM is changed by this proposed model into a Binary Classification Problem (BCP) that either permit access permission or deny them. So, apart from providing dynamic support for the AC's efficient execution amidst IoV, the AdaBoost algorithm also supports the disseminated application of the decision engine via a Software Defined Network (SDN) controller for predicting the AC. The results show that the proposed model supports better permission decision accuracy than the other models.
C1 [Karn, Arodh Lal] Xian Jiaotong Liverpool Univ, Sch Math & Phys, Dept Financial & Actuarial Math, Suzhou, Peoples R China.
   [Sengan, Sudhakar] PSN Coll Engn & Technol, Dept Comp Sci & Engn, Tirunelveli, India.
   [Pustokhin, Denis A.] State Univ Management, Dept Logist, Moscow 109542, Russia.
   [Pustokhina, Irina, V] Plekhanov Russian Univ Econ, Dept Entrepreneurship & Logist, Moscow 117997, Russia.
C3 Xi'an Jiaotong-Liverpool University; State University of Management;
   Plekhanov Russian University of Economics
RP Sengan, S (corresponding author), PSN Coll Engn & Technol, Dept Comp Sci & Engn, Tirunelveli, India.
EM ArodhLalKarn@xjilu.edu.cn; sudhasengan@gmail.com; dpustolchin@yandex.ru;
   ivpustokhina@yandex.ru
RI Pustokhina, Irina/D-3508-2019; Pustokhin, Denis/AEU-9889-2022;
   Pustokhin, Denis/D-3509-2019
OI Pustokhina, Irina/0000-0001-5480-8871; Pustokhin,
   Denis/0000-0002-8138-8494; KARN, ARODH LAL/0000-0003-4557-1889
CR Ali ES, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/8868355
   [Anonymous], AMAZONCOM EMPLOYEE A
   Azees M, 2016, IET INTELL TRANSP SY, V10, P379, DOI 10.1049/iet-its.2015.0072
   Diro Abebe Abeshu, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1353, DOI 10.1007/s12652-017-0677-z
   El Madani S, 2022, MULTIMED TOOLS APPL, V81, P16563, DOI 10.1007/s11042-022-12386-1
   Gupta M, 2018, SACMAT'18: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON ACCESS CONTROL MODELS & TECHNOLOGIES, P193, DOI 10.1145/3205977.3205994
   Hakiri A, 2015, Arxiv, DOI arXiv:1506.02876
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   He ZJ, 2016, IEEE NETWORK, V30, P10, DOI 10.1109/MNET.2016.7513858
   Jain R, 2013, IEEE COMMUN MAG, V51, P24, DOI 10.1109/MCOM.2013.6658648
   Jararweh Y, 2015, J AMB INTEL HUM COMP, V6, P453, DOI 10.1007/s12652-015-0290-y
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Kumar N. V. Narendra, 2017, Software Engineering and Formal Methods. 15th International Conference, SEFM 2017. Proceedings: Lecture Notes in Computer Society (LNCS 10469), P35, DOI 10.1007/978-3-319-66197-1_3
   Longo F, 2017, ANN TELECOMMUN, V72, P53, DOI 10.1007/s12243-016-0528-5
   Ma L, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1578-z
   Mohammadi R, 2017, MULTIMED TOOLS APPL, V76, P23627, DOI 10.1007/s11042-016-4137-0
   Nife F, 2018, COMM COM INF SC, V860, P74, DOI 10.1007/978-3-319-92459-5_7
   Pérez-Ortiz M, 2016, LECT NOTES ARTIF INT, V9648, P597, DOI 10.1007/978-3-319-32034-2_50
   Routledge R, 2008, WILEY ENCY CLIN TRIA, DOI [10.1002/9780471462422.eoct959, DOI 10.1002/9780471462422.EOCT959]
   Salahuddin MA, 2015, IEEE INTERNET THINGS, V2, P133, DOI 10.1109/JIOT.2014.2368356
   Sandhu RS, 1996, COMPUTER, V29, P38, DOI 10.1109/2.485845
   SANDHU RS, 1994, IEEE COMMUN MAG, V32, P40, DOI 10.1109/35.312842
   Singh I, 2022, MULTIMED TOOLS APPL, V81, P26685, DOI 10.1007/s11042-020-10493-5
   Tao M, 2018, FUTURE GENER COMP SY, V78, P1040, DOI 10.1016/j.future.2016.11.011
   Wang F, 2021, MOBILE NETW APPL, V26, P669, DOI 10.1007/s11036-019-01422-4
   Zhang J, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3679, DOI 10.1109/ICMLC.2008.4621044
   Zheng K, 2016, IEEE NETWORK, V30, P72, DOI 10.1109/MNET.2016.7513867
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 19
PY 2022
DI 10.1007/s11042-022-14078-2
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K3EU
UT WOS:000869613100001
DA 2024-07-18
ER

PT J
AU Kumar, C
   Kumar, M
AF Kumar, Chhotelal
   Kumar, Mukesh
TI User session interaction-based recommendation system using various
   machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session-based recommendation system; Next item recommendation; Machine
   learning; KNN
AB A recommendation system can help users to find relevant products or services that they might want to buy or consume. In most of the real-world applications, user's long-term profiles may not exist for a large number of users, which might be the reason that they are visiting the website for the first time or they may not be logged in. The frequent change in user's behavior requires a system which captures the present context or the short time behavior in real time. To predict the short-term interest of a user in an online session is a very relevant problem in practice. In this paper, we have applied eight machine learning models on the different datasets from different domains to check the performance of models and compared the results. From the obtained results, it is observed that the session-based KNN (SKNN) and its variants give promising results compared to the other's methods.
C1 [Kumar, Chhotelal; Kumar, Mukesh] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Kumar, C (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM chhotelalk.phd18.cs@nitp.ac.in
RI Kumar, Mukesh/HKE-0793-2023
OI Kumar, Mukesh/0000-0002-4727-5648; Kumar, Dr.
   Chhotelal/0000-0003-4218-2351
FU TEQIP-III, NIT Patna; Department of Computer Science and Engineering,
   NIT Patna
FX The authors are grateful to the reviewers for their careful reviews and
   highly helpful comments. The authors are also grateful to the Seed
   project, funded by TEQIP-III, NIT Patna, the Department of Computer
   Science and Engineering, NIT Patna, for providing all facilities and
   guidance.
CR Adamczak J, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3412379
   [Anonymous], 2011, P 12 ISMIR C
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bellini P, 2021, P 27 INT DMS C VISUA, P29
   Bellini P, 2023, MULTIMED TOOLS APPL, V82, P9989, DOI 10.1007/s11042-021-11837-5
   Ben-Shimon David, 2015, P 9 ACM C REC SYST, P357
   Bonnin G, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2652481
   Breese J., 1998, P 14 C UNC ART INT, P43
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Cheng C, 2013, 23 INT JOINT C ARTIF
   Gantz J., 2012, The Digital Universe in 2020: Big Data, Bigger Digital Shadows, and Biggest Growth in the Far East, V2012, P1
   Garcin F., 2013, P 7 ACM C REC SYST R, P105
   Garcin F, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P437, DOI 10.1109/WI-IAT.2012.95
   Grbovic M, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1809, DOI 10.1145/2783258.2788627
   Guo L, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1569, DOI 10.1145/3292500.3330839
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Hidasi B, 2016, Arxiv, DOI arXiv:1511.06939
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Hidasi B, 2016, DATA MIN KNOWL DISC, V30, P342, DOI 10.1007/s10618-015-0417-y
   Hu L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1858
   Jannach D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P306, DOI 10.1145/3109859.3109872
   Jannach Dietmar, 2015, P 9 ACM C REC SYST, P211
   Kamehkhosh I, 2017, RECTEMP RECSYS, P50
   Knees P, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P570, DOI 10.1145/3298689.3346974
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li Y, 2005, EXPERT SYST APPL, V28, P67, DOI 10.1016/j.eswa.2004.08.013
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu SY, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P509, DOI 10.1145/3383313.3412222
   Ludewig M, 2021, USER MODEL USER-ADAP, V31, P149, DOI 10.1007/s11257-020-09277-1
   Ludewig M, 2018, USER MODEL USER-ADAP, V28, P331, DOI 10.1007/s11257-018-9209-6
   Mobasher B, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P669, DOI 10.1109/ICDM.2002.1184025
   Mooney R. J., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P195, DOI 10.1145/336597.336662
   Quadrana M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190616
   Shani G, 2005, J MACH LEARN RES, V6, P1265
   Sharma R., 2017, 2017 3 INT C COMPUTA, P1, DOI [10.1109/ciact.2017.7977363, DOI 10.1109/CIACT.2017.7977363]
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Tavakol M, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P33, DOI 10.1145/2645710.2645739
   Turrin R., 2015, RecSys posters, P75
   Verstrepen K, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P177, DOI 10.1145/2645710.2645731
   Wang N, 2022, WORLD WIDE WEB, V25, P425, DOI 10.1007/s11280-021-00930-2
   Wang SJ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3465401
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
NR 43
TC 4
Z9 4
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21279
EP 21309
DI 10.1007/s11042-022-13993-8
EA OCT 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000870100300003
DA 2024-07-18
ER

PT J
AU Zhu, DL
   Zhou, CJ
   Qiu, YX
   Tang, F
   Yan, SQ
AF Zhu, Donglin
   Zhou, Changjun
   Qiu, Yaxian
   Tang, Feng
   Yan, Shaoqiang
TI Kapur's entropy underwater image segmentation based on multi-strategy
   Manta ray foraging optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Kapur's entropy; Manta ray foraging optimization;
   Saltation learning; Tent disturbance; Gaussian mutation; CEC 2017;
   Underwater image
ID ALGORITHM
AB Image segmentation is an important part of image processing, which directly affects the quality of image processing results. Threshold segmentation is the simplest and most widely used segmentation method. However, the best method to determine the threshold has always been a NP-hard problem. Therefore, this paper proposes Kapur's entropy image segmentation based on multi-strategy manta ray foraging optimization, which has a good effect in CEC 2017 test function and image segmentation. Manta ray foraging optimization (MRFO) is a new intelligent optimization algorithm, which has good searchability, but the local development ability is insufficient, so it can not effectively find a reliable point. To solve this defect, this paper proposes a multi-strategy learning manta ray foraging optimization algorithm, referred to as MSMRFO, which uses saltation learning to speed up the communication within the population and improve the convergence speed, and then puts forward a behavior selection strategy to judge the current situation of the population, Tent disturbance and Gaussian mutation are used to avoid the algorithm falling into local optimization and improve the convergence speed of the algorithm. In the complete CEC 2017 test set, MSMRFO is compared with 8 algorithms, including FA_CL and ASBSO are variants of new algorithms proposed in recent years. The results show that MSMRFO has good optimization ability and universality. In nine underwater image data sets, MSMRFO has better segmentation quality than the other eight algorithms, and the segmentation indicators under high threshold processing has better advantages.
C1 [Zhu, Donglin; Zhou, Changjun] Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.
   [Qiu, Yaxian; Tang, Feng] Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou 341000, Jiangxi, Peoples R China.
   [Yan, Shaoqiang] Xian Res Inst High Technol, Xian 710025, Shanxi, Peoples R China.
C3 Zhejiang Normal University; Jiangxi University of Science & Technology;
   Rocket Force University of Engineering
RP Zhu, DL; Zhou, CJ (corresponding author), Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.
EM 6920190624@mail.jxust.edu.cn; zhou-chang231@163.com
RI Zhu, Donglin/GWZ-7301-2022
OI zhu, donglin/0000-0001-9868-8103
FU National Natural Science Foundation of China [62002046, 62006106];
   Zhejiang Provincial Natural Science Foundation of China [LQ21F020005];
   Basic public welfare research program of Zhejiang Province
   [LGG18E050011]
FX This work is supported by the National Natural Science Foundation of
   China (Nos.62002046,62006106),The Project Supported by Zhejiang
   Provincial Natural Science Foundation of China(No.LQ21F020005), Basic
   public welfare research program of Zhejiang Province(No.LGG18E050011).
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd Elaziz M, 2021, ENG APPL ARTIF INTEL, V98, DOI 10.1016/j.engappai.2020.104105
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Akdag O, 2021, ELECTR POW SYST RES, V192, DOI 10.1016/j.epsr.2020.106998
   Aly M, 2021, INT J ENERG RES, V45, P13897, DOI 10.1002/er.6728
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Ben UC, 2021, J APPL GEOPHYS, V192, DOI 10.1016/j.jappgeo.2021.104405
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Ekinci S, 2021, ARAB J SCI ENG, V46, P1395, DOI 10.1007/s13369-020-05050-z
   Elmaadawy K, 2021, J ENVIRON MANAGE, V298, DOI 10.1016/j.jenvman.2021.113520
   Erdmann H, 2015, L N COMPUT VIS BIOME, V19, P279, DOI 10.1007/978-3-319-13407-9_17
   Fathy A, 2020, SOL ENERGY, V207, P305, DOI 10.1016/j.solener.2020.06.108
   Fayad H, 2015, J NUCL MED, V56
   FOGEL DB, 1990, BIOL CYBERN, V63, P111, DOI 10.1007/BF00203032
   Ghosh KK, 2021, NEURAL COMPUT APPL, V33, P11027, DOI 10.1007/s00521-020-05560-9
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   Hassan MH, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104155
   Hemeida MG, 2021, AIN SHAMS ENG J, V12, P609, DOI 10.1016/j.asej.2020.07.009
   Hemeida MG, 2020, ENERGIES, V13, DOI 10.3390/en13153847
   Higashi N, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P72, DOI 10.1109/SIS.2003.1202250
   Houssein EH, 2021, NEURAL COMPUT APPL, V33, P16899, DOI 10.1007/s00521-021-06273-3
   Houssein EH, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107304
   Houssein EH, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115131
   Islam MJ, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2002.01155
   Jena B, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104293
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121421
   Jin HY, 2016, J INTELL FUZZY SYST, V31, P3075, DOI 10.3233/JIFS-169193
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Lyu xin, 2021, Journal of Beijing University of Aeronautics and Astronautics, P1712, DOI 10.13700/j.bh.1001-5965.2020.0298
   Lyu Xin, 2021, Systems Engineering and Electronics, P318, DOI 10.12305/j.issn.1001-506X.2021.02.05
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Micev M, 2021, AIN SHAMS ENG J, V12, P641, DOI 10.1016/j.asej.2020.07.010
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Peng H, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106729
   Peng H, 2021, INFORM SCIENCES, V543, P18, DOI 10.1016/j.ins.2020.05.111
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rather SA, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12717
   Saleh S., 2010, J. Comput., V2, P2151
   Salgotra R, 2019, NEURAL COMPUT APPL, V31, P8837, DOI 10.1007/s00521-019-04464-7
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P7633, DOI 10.1007/s00521-018-3597-8
   Shaheen AM, 2020, IEEE ACCESS, V8, P208281, DOI 10.1109/ACCESS.2020.3038740
   Upadhyay P, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105522
   Wang SK, 2020, MATH BIOSCI ENG, V17, P700, DOI 10.3934/mbe.2020036
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   Xu HT, 2020, INT J HYDROGEN ENERG, V45, P30932, DOI 10.1016/j.ijhydene.2020.08.053
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang ZL, 2020, NEURAL COMPUT APPL, V32, P12011, DOI 10.1007/s00521-019-04210-z
   Yu Y, 2018, IEEE ACCESS, V6, P36977, DOI 10.1109/ACCESS.2018.2852640
   Zhao D, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114122
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
   Zhou YQ, 2018, MULTIMED TOOLS APPL, V77, P23699, DOI 10.1007/s11042-018-5637-x
NR 58
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21825
EP 21863
DI 10.1007/s11042-022-14024-2
EA OCT 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000865376900002
DA 2024-07-18
ER

PT J
AU Ahire, N
   Awale, RN
   Patnaik, S
   Wagh, A
AF Ahire, Nitin
   Awale, R. N.
   Patnaik, Suprava
   Wagh, Abhay
TI A comprehensive review of machine learning approaches for dyslexia
   diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE EEG; Dyslexia; Brain wave; Machine learning; SVM; KNN
ID EEG SIGNAL; DEVELOPMENTAL DYSLEXIA; FEATURE-EXTRACTION; CHILDREN;
   CLASSIFICATION; RECOGNITION; ACTIVATION; GENES
AB Electroencephalography (EEG) is the commonly employed electro-biological imaging technique for diagnosing brain functioning. The EEG signals are used to determine head injury, ascertain brain cell functioning, and monitor brain development. EEG can add multiple dimensions towards the identification of learning disability being an abnormality of the brain. Early and accurate detection of brain diseases can significantly reduce the mortality rate with a lesser treatment cost. The machine learning techniques can examine, classify, and process EEG signals to accurately understand brain activities and disorders. This paper is a comprehensive review of the application of machine learning techniques in the classification of EEG signals of dyslexia and analysis of an improved framework to extemporize the classifier's performance and accuracy in discriminating between dyslexics and controls. The presence of noises and artefacts often reduces the performance of classifiers and hampers results. This study reviews input pre-processing, feature selection, feature extraction techniques and machine learning algorithms for the early detection of disorder. The SVM was found to be outperforming other machine learning techniques for the classification of EEG signals.
C1 [Ahire, Nitin; Awale, R. N.] VJTI, Mumbai, Maharashtra, India.
   [Ahire, Nitin] Xavier Inst Engn, Mumbai, Maharashtra, India.
   [Patnaik, Suprava] KIIT, Sch Elect, Bhubaneswar, India.
   [Wagh, Abhay] DTE, Mumbai, Maharashtra, India.
C3 Veermata Jijabai Technological Institute (VJTI); Kalinga Institute of
   Industrial Technology (KIIT)
RP Ahire, N (corresponding author), VJTI, Mumbai, Maharashtra, India.; Ahire, N (corresponding author), Xavier Inst Engn, Mumbai, Maharashtra, India.
EM nitin.a@xavier.ac.in
RI Ahire, Nitin/HSG-1728-2023
OI Wagh, Dr. Abhay/0000-0002-3985-7090; Ahire, Nitin/0000-0001-7140-2814;
   Patnaik, Suprava/0000-0002-7068-5960
CR Agnihotri P, 2010, IEEE ENG MED BIO, P3029, DOI 10.1109/IEMBS.2010.5626144
   Al-Barhamtoshy H.M., 2017, International Conference on Informatics, Health Technology (ICIHT), Riyadh, Saudi Arabia, P1, DOI [10.1109/ICIHT.2017.7899141, DOI 10.1109/ICIHT.2017.7899141, 10.1109/iciht.2017.7899141]
   Alfadda Assim A, 2014, Int J Endocrinol, V2014, P794943, DOI [10.1155/2014/730218, 10.1155/2014/794943]
   Amin HU, 2015, AUSTRALAS PHYS ENG S, V38, P139, DOI 10.1007/s13246-015-0333-x
   Andreadis II, 2009, IEEE ENG MED BIO, P6292, DOI 10.1109/IEMBS.2009.5332798
   Anwar SM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010018
   Arns Martijn, 2007, Journal of Integrative Neuroscience, V6, P175, DOI 10.1142/S0219635207001404
   Asvestopoulou T, 2019, ARXIV
   Becker J, 2014, EUR J HUM GENET, V22, P675, DOI 10.1038/ejhg.2013.199
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Ben Slimen I, 2020, J BIOMED RES, V34, P151, DOI 10.7555/JBR.34.20190026
   Benfatto MN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165508
   Biswal S, 2018, J AM MED INFORM ASSN, V25, P1643, DOI 10.1093/jamia/ocy131
   Breznitz Z, 2003, BRAIN LANG, V85, P486, DOI 10.1016/S0093-934X(03)00071-3
   Cavalli E, 2018, J LEARN DISABIL-US, V51, P268, DOI 10.1177/0022219417704637
   Chakraborty V., 2020, Kristu Jayanti J Comput Sci (KJCS), V1, P29, DOI [10.59176/kjcs.v1i1.1264, DOI 10.59176/KJCS.V1I1.1264]
   Che Wan Fadzal C. W. N. F., 2012, 2012 IEEE Symposium on Computer Applications and Industrial Electronics (ISCAIE), P202, DOI 10.1109/ISCAIE.2012.6482096
   Costa M, 2013, COMP MED SY, P565, DOI 10.1109/CBMS.2013.6627879
   Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5
   Djemal R, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/9816591
   Fletcher J.M., 2012, Learning about learning disabilities, P1, DOI DOI 10.1016/B978-0-12-388409-1.00001-1
   Frid A., 2012, 2012 IEEE 27th Convention of Electrical Electronics Engineers in Israel (IEEEI), P1, DOI [DOI 10.1109/EEEI.2012.6377068, 10.1109/EEEI.2012, DOI 10.1109/EEEI.2012]
   Frid A, 2018, ARXIV
   Frisoni GB, 2017, LANCET NEUROL, V16, P661, DOI 10.1016/S1474-4422(17)30159-X
   Fuad N, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P359, DOI 10.1109/CSPA.2013.6530072
   Gaggi O, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/2629558
   Gandhi T, 2011, NEUROCOMPUTING, V74, P3051, DOI 10.1016/j.neucom.2011.04.029
   Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441
   Gevins A, 1998, ELECTROEN CLIN NEURO, V106, P165, DOI 10.1016/S0013-4694(97)00120-X
   Grigorenko EL, 2001, J CHILD PSYCHOL PSYC, V42, P91, DOI 10.1111/1469-7610.00704
   Gupta A, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), P829, DOI 10.1109/CoCoNet.2015.7411284
   Gupta A, 2015, SOFT COMPUT, V19, P2799, DOI 10.1007/s00500-014-1443-1
   Hallenbarter D., 2002, Informationsblatt Forschungsbereich Wald, P1
   Hamid SSA, 2018, ADV INTELL SYST, V700, P372, DOI 10.1007/978-3-319-72550-5_36
   Harrison AG, 2008, DYSLEXIA, V14, P228, DOI 10.1002/dys.366
   Heim S, 2004, EUR CHILD ADOLES PSY, V13, P125, DOI 10.1007/s00787-004-0361-7
   Ho TKK, 2019, IEEE ACCESS, V7, P24392, DOI 10.1109/ACCESS.2019.2900127
   Hong KS, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00246
   Honke G, 2020, ARXIV
   Hossain MS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3241056
   Hosseini MP, 2021, IEEE REV BIOMED ENG, V14, P204, DOI 10.1109/RBME.2020.2969915
   Jahankhani P, 2006, IEEE JOHN VINCENT ATANASOFF 2006 INTERNATIONAL SYMPOSIUM ON MODERN COMPUTING, PROCEEDINGS, P120, DOI 10.1109/JVA.2006.17
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Kahrizi M.R., 2018, J INF SYST TELECOMMU, V6, P204, DOI [10.7508/jist.2018.04.003, DOI 10.7508/JIST.2018.04.003]
   Karim I, 2013, INT CONF INFORM COMM
   Kast M, 2010, INT J PSYCHOPHYSIOL, V77, P59, DOI 10.1016/j.ijpsycho.2010.04.003
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kumar KRA., 2011, INT J SCI ENG RES, V2, P1
   Lakretz Y, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1919, DOI 10.1145/2783258.2788604
   Li MM, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113277
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01
   Mahmoodin Z, 2015, 2015 IEEE STUDENT SYMPOSIUM IN BIOMEDICAL ENGINEERING & SCIENCES (ISSBES), P113, DOI 10.1109/ISSBES.2015.7435879
   Mahmoodin Z, 2016, J TEKNOL, V78, P119
   Mammarella IC, 2019, NEUROPSYCHOLOGY, V33, P123, DOI 10.1037/neu0000492
   Mane A.R., 2015, INT J EMERGING TREND, V2, P545
   Masulli F, 2018, VISION RES, V153, P24, DOI 10.1016/j.visres.2018.09.008
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Mohamad S., 2013, 2013 IEEE 3rd International Conference on System Engineering and Technology (ICSET), P389, DOI 10.1109/ICSEngT.2013.6650206
   Murugappan M., 2012, 2012 International Conference on Biomedical Engineering (ICoBE), P203, DOI 10.1109/ICoBE.2012.6179005
   Ojeda-Castelo JJ, 2021, MULTIMED TOOLS APPL, V80, P6675, DOI 10.1007/s11042-020-10026-0
   Perera H, 2018, INT J INTERACT MULTI, V5, P62, DOI 10.9781/ijimai.2018.04.005
   Perera H, 2016, LECT NOTES COMPUT SC, V9950, P626, DOI 10.1007/978-3-319-46681-1_74
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Plonski P, 2017, HUM BRAIN MAPP, V38, P900, DOI 10.1002/hbm.23426
   Raatikainen P., 2021, Array, DOI DOI 10.1016/J.ARRAY.2021.100087
   Ram S, 2018, DESIDOC J LIB INF TE, V38, P286, DOI 10.14429/djlit.38.4.12791
   Rani MFCA, 2014, I C INF TECH MULTIM, P157, DOI 10.1109/ICIMU.2014.7066622
   Razi NIM., 2020, INDONES J ELECT ENG, V19, P163
   Reiter A, 2005, DYSLEXIA, V11, P116, DOI 10.1002/dys.289
   Rello L, 2015, P 12 INT WEB ALL C, P1, DOI DOI 10.1145/2745555.2746644
   Rello L, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P80, DOI 10.1145/3194658.3194675
   Rezvani Z, 2019, 569996 BIORXIV, DOI DOI 10.1101/569996
   Richards TL, 2006, J NEUROLINGUIST, V19, P56, DOI 10.1016/j.jneuroling.2005.07.003
   Rodrigues JD, 2019, PATTERN RECOGN LETT, V125, P140, DOI 10.1016/j.patrec.2019.04.019
   Selvi H, 2018, INT J ENG TECHNOL, P3406
   Simkin DR, 2014, CHILD ADOL PSYCH CL, V23, P427, DOI 10.1016/j.chc.2014.03.001
   Smith-Spark JH, 2007, MEMORY, V15, P34, DOI 10.1080/09658210601043384
   Snowling MJ, 2013, J RES SPEC EDUC NEED, V13, P7, DOI 10.1111/j.1471-3802.2012.01262.x
   Soetraprawata D., 2013, MECHATRON ELECT POWE, V4, P1, DOI [10.14203/j.mev.2013.v4.1-8, DOI 10.14203/J.MEV.2013.V4.1-8]
   Sornmo L., 2005, Bioelectrical signal processing in cardiac and neurological applications, V8
   Spoon K., 2019, INT C MACH LEARN AI, P1
   Sun YF, 2010, PEDIATR NEONATOL, V51, P89, DOI 10.1016/S1875-9572(10)60017-4
   Swartz BE, 1998, ELECTROEN CLIN NEURO, V106, P113, DOI 10.1016/S0013-4694(97)00113-2
   Tayeb Z, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010210
   Teplan M., 2002, Measurement science review, V2, DOI DOI 10.1021/PR070350L
   ter Braack EM, 2013, IEEE T NEUR SYS REH, V21, P376, DOI 10.1109/TNSRE.2012.2228674
   Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014
   Upadhyay D., 2013, INT J SCI ENG TECHNO, V2, P256
   Usman OL, 2021, IEEE ACCESS, V9, P36879, DOI 10.1109/ACCESS.2021.3062709
   van den Heuvel MP, 2010, EUR NEUROPSYCHOPHARM, V20, P519, DOI 10.1016/j.euroneuro.2010.03.008
   Vandermosten M, 2016, CURR OPIN BEHAV SCI, V10, P155, DOI 10.1016/j.cobeha.2016.06.007
   Vellutino FR., 1979, DYSLEXIA THEORY RES
   Wahab A., 2018, INDONES J ELECT ENG, V12, P542
   Xiaoxi Kang, 2021, IOP Conference Series: Materials Science and Engineering, V1077, DOI 10.1088/1757-899X/1077/1/012024
   Yang K, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00089
   Yosi A. N. N. M., 2019, INDONES J ELECT ENG, V15, P786, DOI [10.11591/ijeecs.v15.i2.pp786-793, DOI 10.11591/IJEECS.V15.I2.PP786-793]
   Zabidi A., 2012, 2012 international conference on system engineering and technology (ICSET), P1, DOI [DOI 10.1109/ICSENGT.2012.6339284, 10.1109/ICSEngT.2012.6339284]
   Zainuddin AZA, 2019, IEEE ENG MED BIO, P4513, DOI [10.1109/EMBC.2019.8857569, 10.1109/embc.2019.8857569]
   Zainuddin AZA, 2018, ADV SCI LETT, V24, P1402, DOI 10.1166/asl.2018.10758
   Zainuddin Z, 2016, COMPUT ELECTR ENG, V53, P143, DOI 10.1016/j.compeleceng.2016.02.009
   Zerbin-Rudin E., 1986, SCHIZOAFFECTIVE PSYC, P225, DOI [10.1007/978-3-642-71443-6_16, DOI 10.1007/978-3-642-71443-6_16]
   Zhang KS, 2021, NEURAL NETWORKS, V136, P1, DOI 10.1016/j.neunet.2020.12.013
   Zuhair M., 2017, Adv. Sci., Technol. Eng. Syst. J., V2, P1280
NR 104
TC 6
Z9 6
U1 12
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13557
EP 13577
DI 10.1007/s11042-022-13939-0
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600008
DA 2024-07-18
ER

PT J
AU Chhikara, S
   Kumar, R
AF Chhikara, Sonam
   Kumar, Rajeev
TI Information theoretic steganalysis of processed image LSB steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Steganography; Information theory; Joint entropy;
   Steganalysis; Classifier
ID DIGITAL IMAGES; JPEG IMAGES
AB The preprocessing of a digital image affects the statistical properties of image pixels and steganographic security. Modification of digital media is quite a trivial task nowadays, and it is required intentionally for various reasons. Therefore, it is significant to discuss the usage of the preprocessed image in steganography and its impact on the security of embedded secret information. In this work, we attempt to estimate the impact of image operations, namely scaling, cropping, and contrast enhancement over LSB steganography. We first attack the original image dataset to produce a cover image dataset, then we apply steganography methods and measure their detection accuracy concerning the original image dataset. Steganalysis is conducted by utilizing the higher-order Markov features and newly introduced Joint Entropy-based features with SVM and ensemble classifiers. Experimental results show that the detection rate of embedding degrades by 20% to 40% due to preprocessing of cover images. Results also indicate that the Markov-based SPAM and Joint Entropy-based features work well for steganalysis.
C1 [Chhikara, Sonam; Kumar, Rajeev] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Data Knowledge D2K Lab, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, R (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Data Knowledge D2K Lab, New Delhi 110067, India.
EM rajeevkumar.cse@gmail.com
RI Kumar, Rajeev/I-3506-2019
OI Kumar, Rajeev/0000-0001-5545-6919; Kumar, Rajeev/0000-0003-0233-6563
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cao B, 2017, IEICE T INF SYST, VE100D, P1144, DOI 10.1587/transinf.2017EDL8011
   Carpentieri B, 2019, FUTURE GENER COMP SY, V90, P222, DOI 10.1016/j.future.2018.07.051
   Chandramouli R., 2003, International Workshop on Digital Watermarking, P35
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Chhikara S, 2021, MULTIMED TOOLS APPL, V80, P31865, DOI 10.1007/s11042-021-11118-1
   Chhikara S, 2020, ACTA CYBERN, V24, P593, DOI 10.14232/actacyb.279174
   Chhikara S, 2020, MULTIMED TOOLS APPL, V79, P29723, DOI 10.1007/s11042-020-09328-0
   Christaline JA, 2017, J COMPUT SCI-NETH, V21, P182, DOI 10.1016/j.jocs.2017.06.014
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   Cox I, 2008, MORGAN KAUFMANN, DOI [10.1016/B978-0-12-372585-1.X5001-3, DOI 10.1016/B978-0-12-372585-1.X5001-3]
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Farhat F, 2015, IET IMAGE PROCESS, V9, P31, DOI 10.1049/iet-ipr.2013.0877
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Filler Tomas, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.805911
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J, 2013, IEEE T INF FOREN SEC, V8, P361, DOI 10.1109/TIFS.2012.2235832
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guettari N, 2016, IEEE IMAGE PROC, P2742, DOI 10.1109/ICIP.2016.7532858
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Holub V, 2012, PROC SPIE, V8303, DOI 10.1117/12.905753
   Johnson NF, 1998, 1998 IEEE INFORMATION TECHNOLOGY CONFERENCE, PROCEEDINGS, P113, DOI 10.1109/IT.1998.713394
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Jung KH, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P12, DOI 10.1145/3310986.3311000
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Karimi H, 2015, IET IMAGE PROCESS, V9, P545, DOI 10.1049/iet-ipr.2013.0823
   Ker AD, 2007, IEEE T INF FOREN SEC, V2, P140, DOI 10.1109/TIFS.2007.897265
   Kim CR, 2018, ELECTRON LETT, V54, P626, DOI 10.1049/el.2017.4276
   Kim DH, 2017, 2017 EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (EECS), P1, DOI 10.1109/EECS.2017.9
   Kittawi Nour, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P808, DOI 10.1109/ICITECH.2017.8079951
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2014, IEEE T INF FOREN SEC, V9, P752, DOI 10.1109/TIFS.2014.2309054
   Kodovsky J, 2013, INT CONF ACOUST SPEE, P2857, DOI 10.1109/ICASSP.2013.6638179
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li NN, 2017, IEEE ACCESS, V5, P24457, DOI 10.1109/ACCESS.2017.2767072
   Liu QZ, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P77
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Ramezani M, 2010, CONSUM COMM NETWORK, P239
   Reinel TS, 2019, IEEE ACCESS, V7, P68970, DOI 10.1109/ACCESS.2019.2918086
   Soria-Lorente A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5397082
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Tzschoppe R, 2003, PROC SPIE, V5020, P156, DOI 10.1117/12.477301
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Zarmehi N, 2016, IET IMAGE PROCESS, V10, P1, DOI 10.1049/iet-ipr.2014.1019
   Zhang MM, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053015
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhao XX, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P84, DOI 10.1109/WKDD.2009.105
   Zhou WB, 2019, IET IMAGE PROCESS, V13, P24, DOI 10.1049/iet-ipr.2018.5401
NR 54
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13595
EP 13615
DI 10.1007/s11042-022-13931-8
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600002
DA 2024-07-18
ER

PT J
AU Malik, H
   Anees, T
   Din, M
   Naeem, A
AF Malik, Hassaan
   Anees, Tayyaba
   Din, Muizzud
   Naeem, Ahmad
TI CDC_Net: multi-classification convolutional neural network model for
   detection of COVID-19, pneumothorax, pneumonia, lung Cancer, and
   tuberculosis using chest X-rays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Pneumonia; Deep learning; Chest x-rays; Coronavirus
ID DEEP; DIAGNOSIS; RADIOGRAPHS; FEATURES; HEALTH
AB Coronavirus (COVID-19) has adversely harmed the healthcare system and economy throughout the world. COVID-19 has similar symptoms as other chest disorders such as lung cancer (LC), pneumothorax, tuberculosis (TB), and pneumonia, which might mislead the clinical professionals in detecting a new variant of flu called coronavirus. This motivates us to design a model to classify multi-chest infections. A chest x-ray is the most ubiquitous disease diagnosis process in medical practice. As a result, chest x-ray examinations are the primary diagnostic tool for all of these chest infections. For the sake of saving human lives, paramedics and researchers are working tirelessly to establish a precise and reliable method for diagnosing the disease COVID-19 at an early stage. However, COVID-19's medical diagnosis is exceedingly idiosyncratic and varied. A multi-classification method based on the deep learning (DL) model is developed and tested in this work to automatically classify the COVID-19, LC, pneumothorax, TB, and pneumonia from chest x-ray images. COVID-19 and other chest tract disorders are diagnosed using a convolutional neural network (CNN) model called CDC Net that incorporates residual network thoughts and dilated convolution. For this study, we used this model in conjunction with publically available benchmark data to identify these diseases. For the first time, a single deep learning model has been used to diagnose five different chest ailments. In terms of classification accuracy, recall, precision, and f1-score, we compared the proposed model to three CNN-based pre-trained models, such as Vgg-19, ResNet-50, and inception v3. An AUC of 0.9953 was attained by the CDC Net when it came to identifying various chest diseases (with an accuracy of 99.39%, a recall of 98.13%, and a precision of 99.42%). Moreover, CNN-based pre-trained models Vgg-19, ResNet-50, and inception v3 achieved accuracy in classifying multi-chest diseases are 95.61%, 96.15%, and 95.16%, respectively. Using chest x-rays, the proposed model was found to be highly accurate in diagnosing chest diseases. Based on our testing data set, the proposed model shows significant performance as compared to its competitor methods. Statistical analyses of the datasets using McNemar's, and ANOVA tests also showed the robustness of the proposed model.
C1 [Malik, Hassaan; Naeem, Ahmad] Univ Management & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
   [Anees, Tayyaba] Univ Management & Technol, Dept Software Engn, Lahore 54000, Pakistan.
   [Din, Muizzud] Ghazi Univ, Dept Comp Sci, Dera Ghazi Khan 32200, Pakistan.
C3 University of Management & Technology (UMT); University of Management &
   Technology (UMT)
RP Malik, H (corresponding author), Univ Management & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
EM f2019288004@umt.edu.pk
RI Anees, Tayyaba/GWR-3575-2022
OI Anees, Tayyaba/0000-0003-2266-9322; Malik, Hassaan/0000-0002-4402-5088
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Alqudah AM, 2021, J MED BIOL ENG, V41, P599, DOI 10.1007/s40846-021-00631-1
   Alqudah AM., 2020, Augmented COVID-19 X-ray images dataset, V4, DOI [10.17632/2FXZ4PX6D8.4, DOI 10.17632/2FXZ4PX6D8.4]
   [Anonymous], 2020, PEDIATR MED RODZ, V16, P9, DOI 10.15557/PiMR.2020.0003
   [Anonymous], COVID 19 DAT
   [Anonymous], COVID 19 CHEST XRAY
   [Anonymous], 2021, TUB TB CHEST XRAY DA
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ayan E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741582
   Aydogdu M, 2010, TUBERK TORAK, V58, P25
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Bezier C, 2020, Int. J. Metrol. Qual. Eng, V11, P16, DOI DOI 10.1051/IJMQE/2020014
   Canayaz M, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111310
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Chowdhury NK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.551
   Cifci MA., 2020, INT J SCI ENG RES, V11, P273
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Cohen J.P., 2020, arXiv
   Corman VM, 2020, EUROSURVEILLANCE, V25, P23, DOI 10.2807/1560-7917.ES.2020.25.3.2000045
   Cuevas A, 2004, COMPUT STAT DATA AN, V47, P111, DOI 10.1016/j.csda.2003.10.021
   Dadario A. M., 2020, Kaggle, DOI DOI 10.34740/KAGGLE/DSV/1019469
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dunnmon JA, 2019, RADIOLOGY, V290, P537, DOI 10.1148/radiol.2018181422
   El Asnaoui K, 2021, INT J MULTIMED INF R, V10, P55, DOI 10.1007/s13735-021-00204-7
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   *FRED NAT LAB, 2018, CANC IM ARCH TCIA, P1
   Gaillard F, 2014, RADIOPAEDIA ORG WIKI
   Grewal M, 2018, I S BIOMED IMAGING, P281, DOI 10.1109/ISBI.2018.8363574
   Guan Q A, 2018, ARXIV
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hammoudi K, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01745-4
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Hassantabar S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110170
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermann S, 2014, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2014.393
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hui DS, 2020, INT J INFECT DIS, V91, P264, DOI 10.1016/j.ijid.2020.01.009
   Hwang EJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1095
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jaeger S, 2014, IEEE T MED IMAGING, V33, P233, DOI 10.1109/TMI.2013.2284099
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   JANIZEK JD, 2020, P ACM C HLTH INF LEA, P69, DOI DOI 10.1145/3368555.3384458
   Kermany Daniel, 2018, Mendeley Data, V3
   Kermany Daniel, 2018, Mendeley Data, V2
   King BF, 2018, J AM COLL RADIOL, V15, P501, DOI 10.1016/j.jacr.2017.11.017
   Komal Ayesha, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P145, DOI 10.1007/978-981-16-7618-5_13
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu J, 2014, CHEST, V146, P383, DOI 10.1378/chest.13-2852
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Lu HZ, 2020, J MED VIROL, V92, P401, DOI [10.1002/jmv.2567, 10.1002/jmv.25678]
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Malik H, 2020, MENDELEY DATA, VV1, DOI [10.17632/67dmnmx33v.1, DOI 10.17632/67DMNMX33V.1]
   Malik H, 2022, MULTIMEDIA SYST, V28, P815, DOI 10.1007/s00530-021-00878-3
   Malik H, 2020, IEEE ACCESS, V8, P139367, DOI 10.1109/ACCESS.2020.3004766
   Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691
   Melendez J, 2015, IEEE T MED IMAGING, V34, P179, DOI 10.1109/TMI.2014.2350539
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Mooney P, 2020, Chest x-ray images (pneumonia)
   National Institutes of Health, 2019, CHEST XRAY DAT
   NIH Chest X-rays, 2018, Kaggle
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Pneumothorax Database, 2021, KAGGLE
   Quang D, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw226
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rajaraman S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101715
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Refaeilzadeh P., 2016, Encyclopedia of database systems, P1, DOI [DOI 10.1007/978-0-387-39940-9, 10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_565]
   Resnick S, 2017, AM J SURG, V214, P19, DOI 10.1016/j.amjsurg.2016.09.059
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stephen O, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4180949
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tahamtan A, 2020, EXPERT REV MOL DIAGN, V20, P453, DOI 10.1080/14737159.2020.1757437
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Tsiknakis N, 2020, EXP THER MED, V20, P727, DOI 10.3892/etm.2020.8797
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang QL, 2020, IEEE ACCESS, V8, P78530, DOI 10.1109/ACCESS.2020.2990423
   Wang S., 2020, medRxiv
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Worldometer, 2020, COR UPD LIV CAS DEAT
   Xiao B, 2022, IEEE T ANTENN PROPAG, V70, P1643, DOI 10.1109/TAP.2021.3111231
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zakirov A., 2015, Appl. Math. Sci, V9, P4361, DOI 10.12988/ams.2015.54348
   Zhang J, 2002, ARXIV
NR 104
TC 31
Z9 31
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13855
EP 13880
DI 10.1007/s11042-022-13843-7
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000855612200004
PM 36157356
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Montalvo, J
   García-Martín, A
   Bescós, J
AF Montalvo, Javier
   Garcia-Martin, Alvaro
   Bescos, Jesus
TI Exploiting semantic segmentation to boost reinforcement learning in
   video game environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Reinforcement learning; Domain adaptation;
   Synthetic data
AB In this work we explore enhancing performance of reinforcement learning algorithms in video game environments by feeding it better, more relevant data. For this purpose, we use semantic segmentation to transform the images that would be used as input for the reinforcement learning algorithm from their original domain to a simplified semantic domain with just silhouettes and class labels instead of textures and colors, and then we train the reinforcement learning algorithm with these simplified images. We have conducted different experiments to study multiple aspects: feasibility of our proposal, and potential benefits to model generalization and transfer learning. Experiments have been performed with the Super Mario Bros video game as the testing environment. Our results show multiple advantages for this method. First, it proves that using semantic segmentation enables reaching higher performance than the baseline reinforcement learning algorithm without modifying the actual algorithm, and in fewer episodes; second, it shows noticeable performance improvements when training on multiple levels at the same time; and finally, it allows to apply transfer learning for models trained on visually different environments. We conclude that using semantic segmentation can certainly help reinforcement learning algorithms that work with visual data, by refining it. Our results also suggest that other computer vision techniques may also be beneficial for data prepossessing. Models and code will be available on github upon acceptance.
C1 [Montalvo, Javier; Garcia-Martin, Alvaro; Bescos, Jesus] Univ Autonoma Madrid, VPULab, Ciudad Univ Cantoblanco, E-28049 Madrid, Spain.
C3 Autonomous University of Madrid
RP Montalvo, J (corresponding author), Univ Autonoma Madrid, VPULab, Ciudad Univ Cantoblanco, E-28049 Madrid, Spain.
EM javier.montalvor@estudiante.uam.es; alvaro.garcia@uam.es;
   j.bescos@uam.es
RI Garcia-Martin, Alvaro/P-8502-2019; Bescos, Jesus/C-4327-2014
OI Garcia-Martin, Alvaro/0000-0002-1705-3972; Montalvo,
   Javier/0000-0001-6610-1566
FU Ministerio de Ciencia e Innovacin of the Spanish Government
   [PID2021125051OB-I00]; CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work is part of the preliminary tasks related to
   the Harvesting Visual Data (HVD) project (PID2021125051OB-I00) funded by
   the Ministerio de Ciencia e Innovacin of the Spanish Government.
CR Blum H, 2021, INT J COMPUT VISION, V129, P3119, DOI 10.1007/s11263-021-01511-6
   Brockman Greg, 2016, OPENAI GYM
   Chen L.Z, 2017, CORR ABS170605587
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y., 2019, P IEEECVF C COMPUTER, P0
   Cobbe K, 2019, PR MACH LEARN RES, V97
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dabney W, 2018, PR MACH LEARN RES, V80
   Deschaud JE, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224713
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hasselt H., 2010, Advances in neural information processing systems, V23
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang Z., 2019, P IEEECVF INT C COMP
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu X, 2021, IEEE VTS VEH TECHNOL, DOI 10.1109/VTC2021-FALL52928.2021.9625558
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Mnih V, 2013, ARXIV
   Muthalagu R, 2021, MULTIMED TOOLS APPL, V80, P11201, DOI 10.1007/s11042-020-10248-2
   Ng M. H., 2020, ARXIV
   Niranjan D. R., 2021, 2021 2nd International Conference on Smart Electronics and Communication (ICOSEC), P1251, DOI 10.1109/ICOSEC51865.2021.9591747
   Paszke A, 2019, ADV NEUR IN, V32
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4
   Schulman J., 2017, ARXIV
   Sekkat AR, 2020, IEEE INT CONF ROBOT, P1603, DOI [10.1109/ICRA40945.2020.9197144, 10.1109/icra40945.2020.9197144]
   Sun JC, 2021, MULTIMED TOOLS APPL, V80, P34203, DOI 10.1007/s11042-020-09840-3
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Xie EZ, 2021, ADV NEUR IN, V34
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang JM, 2021, IEEE INT CONF COMP V, P1760, DOI 10.1109/ICCVW54120.2021.00202
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
NR 40
TC 1
Z9 1
U1 10
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10961
EP 10979
DI 10.1007/s11042-022-13695-1
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854695000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Mulimani, M
   Nandi, R
   Koolagudi, SG
AF Mulimani, Manjunath
   Nandi, Ritika
   Koolagudi, Shashidhar G.
TI Acoustic scene classification using projection Kervolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Projection Kervolutional Neural Network (ProKNN); Projection layers;
   Kervolutional Neural Network (KNN); Acoustic Scene Classification (ASC)
AB In this paper, a novel Projection Kervolutional Neural Network (ProKNN) is proposed for Acoustic Scene Classification (ASC). ProKNN is a combination of two special filters known as the left and right projection layers and Kervolutional Neural Network (KNN). KNN replaces the linearity of the Convolutional Neural Network (CNN) with a non-linear polynomial kernel. We extend the ProKNN to learn from the features of two channels of audio recordings in the initial stage. The performance of the ProKNN is evaluated on the two publicly available datasets: TUT Urban Acoustic Scenes 2018 and TUT Urban Acoustic Scenes Mobile 2018 development datasets. Results show that the proposed ProKNN outperforms the existing systems with an absolute improvement of accuracy of 8% and 14% on TUT Urban Acoustic Scenes 2018 and TUT Urban Acoustic Scenes Mobile 2018 development datasets respectively, as compared to the baseline model of Detection and Classification of Acoustic Scene and Events (DCASE) - 2018 challenge.
C1 [Mulimani, Manjunath; Nandi, Ritika] Manipal Acad Higher Educ, Manipal Inst Technol, Dept Comp Sci & Engn, Manipal 576104, India.
   [Koolagudi, Shashidhar G.] Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Surathkal 575025, India.
C3 Manipal Academy of Higher Education (MAHE); National Institute of
   Technology (NIT System); National Institute of Technology Karnataka
RP Mulimani, M (corresponding author), Manipal Acad Higher Educ, Manipal Inst Technol, Dept Comp Sci & Engn, Manipal 576104, India.
EM manjunath.gec@gmail.com; ritika.nandi77@gmail.com; koolagudi@nitk.edu.in
CR Barchiesi D, 2015, IEEE SIGNAL PROC MAG, V32, P16, DOI 10.1109/MSP.2014.2326181
   Basbug AM, 2019, IEEE INT C SEMANT CO, P128, DOI [10.1109/ICSC.2019.00029, 10.1109/ICOSC.2019.8665547]
   Bisot V, 2017, IEEE-ACM T AUDIO SPE, V25, P1216, DOI 10.1109/TASLP.2017.2690570
   Chu S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P885, DOI 10.1109/ICME.2006.262661
   Damnjanovic I, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1597, DOI 10.1109/ICME.2008.4607756
   Geiger JT, 2013, IEEE WORK APPL SIG
   Han Y., 2017, DCASE
   Heittola Toni., 2018, Computational Analysis of Sound Scenes and Events, P13
   Koutini K, 2019, P DETECTION CLASSIFI, P25
   Mesaros A, 2018, ARXIV
   Mesaros A., 2018, Computational Analysis of Sound Scenes and Events, P147
   Mesaros A, 2018, IEEE-ACM T AUDIO SPE, V26, P379, DOI 10.1109/TASLP.2017.2778423
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Mulimani M, 2020, INT CONF ACOUST SPEE, P291, DOI [10.1109/ICASSP40776.2020.9054208, 10.1109/icassp40776.2020.9054208]
   Mulimani M, 2019, DIGIT SIGNAL PROCESS, V87, P1, DOI 10.1016/j.dsp.2019.01.001
   Mulimani M, 2018, INTERSPEECH, P3319, DOI 10.21437/Interspeech.2018-1905
   Mulimani M, 2019, EXPERT SYST APPL, V120, P413, DOI 10.1016/j.eswa.2018.12.004
   OPPENHEIM AV, 1970, IEEE SPECTRUM, V7, P57, DOI 10.1109/MSPEC.1970.5213512
   Phaye SSR, 2019, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2019.8683288
   Ren Z, 2019, INT CONF ACOUST SPEE, P56, DOI 10.1109/ICASSP.2019.8683434
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Schmitt M, 2016, INTERSPEECH, P495, DOI 10.21437/Interspeech.2016-1124
   Wang C, 2019, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2019.00012
   Xu Y., 2008, Intelligent wearable interfaces
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
NR 25
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9447
EP 9457
DI 10.1007/s11042-022-13763-6
EA SEP 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854682700005
DA 2024-07-18
ER

PT J
AU Li, Y
   Li, JG
   Meng, P
AF Li, Yi
   Li, Jinguo
   Meng, Ping
TI Attention-YOLOV4: a real-time and high-accurate traffic sign detection
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic signs detection; YOLO V4; Real-time and accuracy detection
AB The technology of traffic sign detection is an important technology in autonomous driving. However due to the small size of traffic signs and the complicated background there are some problems in the practical application of traffic sign detection technology: the detection accuracy of one-stage traffic sign detection algorithm is low, the detection speed of two-stage traffic sign detection algorithm is slow. To achieve real-time and accuracy detection for traffic signs, we treat traffic sign detection as an end-to-end problem in this paper and proposed an improved one-stage traffic sign detection algorithm: Attention-YOLO V4. In order to achieve real-time and high-accurate detection of traffic signs so we analyzed the principle of YOLO V4 for small objects detection: in order to improve the ability of YOLO V4 backbone network extracting traffic sign features we decide to combine channel attention mechanism with residual block, in order to improve the ability of YOLO Head detect traffic signs we combine channel attention mechanism with YOLO head. We used TT100K dataset to evaluate Attention-YOLO V4 algorithm, compared with the existing methods, our method achieve real-time and accurately performance in complex backgrounds.
C1 [Li, Yi; Li, Jinguo; Meng, Ping] Shanghai Univ Elect Power, Shanghai, Peoples R China.
C3 Shanghai University of Electric Power
RP Li, JG (corresponding author), Shanghai Univ Elect Power, Shanghai, Peoples R China.
EM YukoAmamiya@mail.shiep.edu.cn; lijg@shiep.edu.cn
FU National Natural Science Foundation of China [61702321, U1936213]
FX This work was supported by grants from the National Natural Science
   Foundation of China(61702321,U1936213).
CR [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao JH, 2021, IEEE ACCESS, V9, P122774, DOI 10.1109/ACCESS.2021.3109606
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Huang WQ, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012159
   Jin YM, 2020, IEEE ACCESS, V8, P38931, DOI 10.1109/ACCESS.2020.2975828
   Li HJ, 2015, NEUROCOMPUTING, V169, P77, DOI 10.1016/j.neucom.2014.12.111
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang Q, 2021, IEEE ACCESS, V9, P117784, DOI 10.1109/ACCESS.2021.3106350
   Tsai YC, 2009, J COMPUT CIVIL ENG, V23, P266, DOI 10.1061/(ASCE)0887-3801(2009)23:5(266)
   Wei LJ, 2020, IEEE ACCESS, V8, P83611, DOI 10.1109/ACCESS.2020.2991195
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang Y, 2014, CHINESE C PATTERN RE
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang HB, 2020, IEEE ACCESS, V8, P64145, DOI 10.1109/ACCESS.2020.2984554
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhao ZJ, 2020, IEEE ACCESS, V8, P114044, DOI 10.1109/ACCESS.2020.3002860
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 26
TC 17
Z9 17
U1 50
U2 275
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7567
EP 7582
DI 10.1007/s11042-022-13251-x
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000849298700002
DA 2024-07-18
ER

PT J
AU Kour, N
   Gupta, S
   Arora, S
AF Kour, Navleen
   Gupta, Sunanda
   Arora, Sakshi
TI Sensor technology with gait as a diagnostic tool for assessment of
   Parkinson's disease: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Sensor-based; Gait; Machine learning; Sensor
   datasets; Clinical gait analysis
ID INERTIAL SENSORS; OLDER-ADULTS; TIME-SERIES; CLASSIFICATION; SYMPTOMS;
   DYNAMICS; PEOPLE; QUANTIFICATION; FLUCTUATION; ALGORITHMS
AB Parkinson's Disease (PD) is the most precarious chronic disorder of the human brain affecting millions of people globally. In today's world of technical inventions, the diagnosis of PD at its initial stage is a serious issue. The high dependency on the patient's medical history and clinical rating scales have certain limitations as they are very tiring and include recall bias. Therefore, more stable and objective measurements are needed to execute automated and effective detection of PD. The biometric gait has been developed as a reliable diagnostic tool for such a purpose because of its unobtrusiveness. In past years, the applications of sensor devices have been utilized the most to evaluate PD via gait. So, the purpose of this article is to analyze the past and current research toward sensor-based (SB) diagnosis of PD motor symptoms. In this article, we provide a brief description of PD and the related concepts also defining its impact on human gait. This article comprehensively surveys the SB technology and the role of different sensors in PD gait recognition. This study investigates the machine learning paradigms used in PD analysis and their performance evaluation. Several SB PD gait datasets are surveyed and explored considering literature from the last ten years. Also, we exhaustively provide a discussion section in this article to give a clear picture of the results concluded from the analysis of prior sections. At last, this article examines some gaps in the existing studies that need to be addressed and also suggests some measures to tackle such issues using advanced paradigms.
C1 [Kour, Navleen; Gupta, Sunanda; Arora, Sakshi] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
C3 Shri Mata Vaishno Devi University
RP Gupta, S (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
EM Sunanda.gupta@smvdu.ac.in
CR Abdulhay E, 2018, FUTURE GENER COMP SY, V83, P366, DOI 10.1016/j.future.2018.02.009
   Açici K, 2017, COMM COM INF SC, V744, P609, DOI 10.1007/978-3-319-65172-9_51
   Ahn D, 2017, IEEE T BIO-MED ENG, V64, P2394, DOI 10.1109/TBME.2017.2655344
   Alafeef M, 2019, J AMB INTEL HUM COMP, V10, P2805, DOI 10.1007/s12652-018-1014-x
   Alam MN, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175951
   Nguyen A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0548-2
   Pérez-Toro PA, 2018, COMM COM INF SC, V916, P268, DOI 10.1007/978-3-030-00353-1_24
   Arora S, 2015, PARKINSONISM RELAT D, V21, P650, DOI 10.1016/j.parkreldis.2015.02.026
   Arrazaq GA., 2018, INT J APPL ENG RES, V13, P2648
   Ascioglu G, 2018, J FASHION TECHNOL TE, VS4
   Asuroglu T, 2018, BIOCYBERN BIOMED ENG, V38, P760, DOI 10.1016/j.bbe.2018.06.002
   Baby MS, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Bächlin M, 2010, IEEE T INF TECHNOL B, V14, P436, DOI 10.1109/TITB.2009.2036165
   Baker R, 2007, GAIT POSTURE, V26, P331, DOI 10.1016/j.gaitpost.2006.10.014
   Barth J., 2013, BASAL GANGLIA, V1, P52, DOI [10.1016/j.baga.2013.01.037, DOI 10.1016/J.BAGA.2013.01.037]
   Barth J, 2011, IEEE ENG MED BIO, P868, DOI 10.1109/IEMBS.2011.6090226
   Béné R, 2009, ACTA CLIN CROAT, V48, P377
   Benedette, 2018, AZO SENS RIS FLOOR S
   Benson LC, 2018, GAIT POSTURE, V63, P124, DOI 10.1016/j.gaitpost.2018.04.047
   Bertoli M, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0488-2
   Bhat S, 2018, COMPUT BIOL MED, V102, P234, DOI 10.1016/j.compbiomed.2018.09.008
   Bo Li, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1640, DOI 10.1109/IMCEC.2018.8469471
   Borzi Luigi, 2019, Journal of Reliable Intelligent Environments, V5, P145, DOI 10.1007/s40860-019-00086-x
   Brognara L, 2019, DISEASES-BASEL, V7, DOI 10.3390/diseases7010018
   Buckley C, 2017, GAIT POSTURE, V52, P265, DOI 10.1016/j.gaitpost.2016.11.047
   Butt AH, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717707417
   Caetano MJD, 2018, PARKINSONISM RELAT D, V47, P32, DOI 10.1016/j.parkreldis.2017.11.340
   Camps J, 2018, KNOWL-BASED SYST, V139, P119, DOI 10.1016/j.knosys.2017.10.017
   Capecci M, 2016, GAIT POSTURE, V50, P28, DOI 10.1016/j.gaitpost.2016.08.018
   Caramia C, 2018, IEEE J BIOMED HEALTH, V22, P1765, DOI 10.1109/JBHI.2018.2865218
   Chan PY, 2018, IEEE T NEUR SYS REH, V26, P460, DOI 10.1109/TNSRE.2017.2782361
   Chang D, 2014, DIAGNOSING PARKINSON
   Chen PH, 2013, INT J GERONTOL, V7, P189, DOI 10.1016/j.ijge.2013.03.005
   Chen X, 2018, LECT NOTES COMPUT SC, V10927, P263, DOI 10.1007/978-3-319-92037-5_20
   Chomiak T, 2019, J NEURAL TRANSM, V126, P1029, DOI 10.1007/s00702-019-02020-0
   Christofoletti G, 2016, HUM MOVEMENT SCI, V49, P308, DOI 10.1016/j.humov.2016.08.007
   Coste CA, 2014, SENSORS-BASEL, V14, P6819, DOI 10.3390/s140406819
   Davie CA, 2008, BRIT MED BULL, V86, P109, DOI 10.1093/bmb/ldn013
   de Lima ALS, 2020, MOVEMENT DISORD, V35, P109, DOI 10.1002/mds.27830
   De Venuto D, 2018, IEEE T COMP PACK MAN, V8, P1167, DOI 10.1109/TCPMT.2018.2810103
   Del Din S, 2019, ANN NEUROL, V86, P357, DOI 10.1002/ana.25548
   Del Din S, 2016, IEEE J BIOMED HEALTH, V20, P838, DOI 10.1109/JBHI.2015.2419317
   Delval A, 2015, NEUROPHYSIOL CLIN, V45, P305, DOI 10.1016/j.neucli.2015.09.009
   Dewey DC, 2014, J NEUROL SCI, V345, P131, DOI 10.1016/j.jns.2014.07.026
   Dijkstra B, 2010, AGE AGEING, V39, P259, DOI 10.1093/ageing/afp249
   Drotár P, 2016, ARTIF INTELL MED, V67, P39, DOI 10.1016/j.artmed.2016.01.004
   Elden RH, 2018, MID EAST CONF BIO, P116, DOI 10.1109/MECBME.2018.8402417
   Electronic Products, 2013, DES COMB SENS
   Ellis AM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0114805
   Ertugrul ÖF, 2016, EXPERT SYST APPL, V56, P156, DOI 10.1016/j.eswa.2016.03.018
   European Parkinson's Disease Association, 2017, PARK
   Exarchos TP, 2012, COMPUT BIOL MED, V42, P195, DOI 10.1016/j.compbiomed.2011.11.008
   Fang FH, 2017, WOODH PUBL SER BIOM, P167, DOI 10.1016/B978-0-08-100717-4.00023-5
   Farnsworth B., 2018, What is GSR (galvanic skin response) and how does it work?
   Fietzek UM, 2017, CLIN NEUROPHYSIOL, V128, P1954, DOI 10.1016/j.clinph.2017.07.399
   Gassner H, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00005
   GBD 2016 Disease and Injury Incidence and Prevalence Collaborators, 2017, Lancet, V390, P1211, DOI 10.1016/S0140-6736(17)32154-2
   Ghassemi NH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010145
   Godinho C, 2016, 2016 1 INT C TECHNOL, P1, DOI [10.1109/TISHW.2016.7847783, DOI 10.1109/TISHW.2016.7847783]
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Griskevicius, 2018, GEDIMINAS GAIDULIS
   Gupta D, 2018, COMPUT ELECTR ENG, V68, P412, DOI 10.1016/j.compeleceng.2018.04.014
   Hao Hu, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P191, DOI 10.1109/ICCE-TW.2014.6904053
   Hausdorff JM, 1997, J APPL PHYSIOL, V82, P262
   Heijmans M, 2019, NPJ PARKINSONS DIS, V5, DOI 10.1038/s41531-019-0093-5
   Hobert MA, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00022
   Hori K, 2017, J NEUROL SCI, V381, P348, DOI 10.1016/j.jns.2017.08.989
   Huh YE, 2016, PARKINSONISM RELAT D, V25, P72, DOI 10.1016/j.parkreldis.2016.02.004
   Hundza SR, 2014, IEEE T NEUR SYS REH, V22, P127, DOI 10.1109/TNSRE.2013.2282080
   Nguyen H, 2018, IEEE T NEUR SYS REH, V26, P197, DOI 10.1109/TNSRE.2017.2745418
   Isenkul Muhammed, 2014, 2 INT C E HLTH TELEM, V5, P171, DOI DOI 10.13140/RG.2.1.1898.6005
   Jankovic J, 2008, J NEUROL NEUROSUR PS, V79, P368, DOI 10.1136/jnnp.2007.131045
   Jehu D, 2018, GAIT POSTURE, V65, P246, DOI 10.1016/j.gaitpost.2018.07.181
   Jimenez-Ferrer I., 2018, Parkinson's Disease: Pathogenesis and Clinical Aspects
   Kharb A., 2011, IJCEM Int. J. Comput. Eng. Manag., V13, P78
   Khorasani A, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0147-5
   Khoury N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020242
   Kim D, 2010, IET COMPUT VIS, V4, P25, DOI 10.1049/iet-cvi.2009.0009
   Kim H, 2015, IEEE ENG MED BIO, P3751, DOI 10.1109/EMBC.2015.7319209
   Kleiner A, 2017, FUNCT NEUROL, V32, P17, DOI 10.11138/FNeur/2017.32.1.017
   Klucken J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056956
   Koop MM, 2018, IBRO REP, V5, P10, DOI 10.1016/j.ibror.2018.06.002
   Kouli A., 2018, Parkinson's Disease: Pathogenesis and Clinical Aspects, DOI [10.17305/bjbms.2020.5181, DOI 10.15586/CODONPUBLICATIONS.PARKINSONSDISEASE.2018.CH1]
   Kour N, 2021, ARCH COMPUT METHOD E, V28, P345, DOI 10.1007/s11831-019-09379-z
   Kour N, 2019, IEEE ACCESS, V7, P156620, DOI 10.1109/ACCESS.2019.2949744
   Kugler P, 2013, IEEE ENG MED BIO, P5781, DOI 10.1109/EMBC.2013.6610865
   Kwon Y, 2014, CLIN INTERV AGING, V9, P1709, DOI 10.2147/CIA.S69773
   Lan KC, 2015, I CONF SENS TECHNOL, P461, DOI 10.1109/ICSensT.2015.7438443
   Lee SH, 2012, EXPERT SYST APPL, V39, P7338, DOI 10.1016/j.eswa.2012.01.084
   Lin WY, 2016, IEEE SYS MAN CYBERN, P3577, DOI 10.1109/SMC.2016.7844788
   Lonini L, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0071-z
   Lorenzi P, 2015, 2015 6TH IEEE INTERNATIONAL WORKSHOP ON ADVANCES IN SENSORS AND INTERFACES (IWASI), P131, DOI 10.1109/IWASI.2015.7184973
   Maculewicz J, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00001
   Masiala S, 2017, DISSERTATION
   Masiala S., 2019, Feature-set-engineering for detectingfreezing of gait in parkinson's disease using deep recurrent neural networks
   MASPARK, 2015, FREEZING PARKINSONS
   Mayo Clinic, 2019, PARKINSONS DIS-US
   Mazilu Sinziana, 2013, Machine Learning and Data Mining in Pattern Recognition. 9th International Conference, MLDM 2013. Proceedings: LNCS 7988, P144, DOI 10.1007/978-3-642-39712-7_11
   Mazilu S., 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P123, DOI 10.4108/icst.pervasivehealth.2012.248680
   Mazilu S., 2013, AH 13, P124, DOI [10.1145/2459236.2459257, DOI 10.1145/2459236.2459257]
   Mazilu S, 2016, PERVASIVE MOB COMPUT, V33, P1, DOI 10.1016/j.pmcj.2015.12.007
   Mazilu S, 2015, IEEE J BIOMED HEALTH, V19, P1843, DOI 10.1109/JBHI.2015.2465134
   Medeiros L, 2016, COMP MED SY, P48, DOI 10.1109/CBMS.2016.14
   Micó-Amigo ME, 2017, ANN BIOMED ENG, V45, P1266, DOI 10.1007/s10439-017-1794-8
   Micó-Amigo ME, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00059
   Mileti I, 2017, IEEE INT SYM MED MEA, P402, DOI 10.1109/MeMeA.2017.7985910
   Mileti I, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030919
   Minamisawa T, 2012, GAIT POSTURE, V35, P308, DOI 10.1016/j.gaitpost.2011.09.106
   Mitoma H, 2010, INTERNAL MED, V49, P2401, DOI 10.2169/internalmedicine.49.3511
   Mittra Y, 2018, 2018 INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTATIONAL ENGINEERING (ICACE), P84, DOI 10.1109/ICACE.2018.8687022
   Moore ST, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-19
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Myers PS, 2018, PARKINSONISM RELAT D, V53, P89, DOI 10.1016/j.parkreldis.2018.05.006
   Nantel J, 2011, GAIT POSTURE, V34, P329, DOI 10.1016/j.gaitpost.2011.05.020
   Niazmand K, 2011, BIOMED CIRC SYST C, P201, DOI 10.1109/BioCAS.2011.6107762
   Nixon MS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P139, DOI 10.1109/AFGR.2004.1301521
   Okuda S, 2016, NEUROL CLIN NEUROSCI, V4, P93, DOI 10.1111/ncn3.12043
   Okuma Y, 2015, J NEUROL SCI, V357, pE281, DOI 10.1016/j.jns.2015.08.984
   Ornelas-Vences C, 2017, COMPUT BIOL MED, V89, P379, DOI 10.1016/j.compbiomed.2017.08.026
   Orozco-Arroyave J.R., 2014, LREC 2014 9 INT C, P342
   Ortells J, 2018, MED BIOL ENG COMPUT, V56, P1553, DOI 10.1007/s11517-018-1795-2
   Ossig C, 2016, J NEURAL TRANSM, V123, P57, DOI 10.1007/s00702-015-1439-8
   Ota L, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P343, DOI 10.1109/SII.2012.6427372
   Oung Q.W., 2018, 2018 International Conference on Computational Approach in Smart Systems Design and Applications, ICASSDA 2018, DOI DOI 10.1109/ICASSDA.2018.8477606
   Paragliola G, 2018, IEEE ACCESS, V6, P73280, DOI 10.1109/ACCESS.2018.2882245
   Pardoel S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235141
   Parkinson's Progression Markers Initiative, 2018, LANDM STUD PARK DIS
   Pepa L, 2014, 2014 IEEE/ASME 10TH INTERNATIONAL CONFERENCE ON MECHATRONIC AND EMBEDDED SYSTEMS AND APPLICATIONS (MESA 2014)
   Pepa L., 2018, ANN PHYS REHABIL MED, V61, pe437, DOI [10.1016/j.rehab.2018.05.1017, DOI 10.1016/J.REHAB.2018.05.1017]
   Pereira CR, 2019, ARTIF INTELL MED, V95, P48, DOI 10.1016/j.artmed.2018.08.007
   Pereira MP, 2016, PARKINSONISM RELAT D, V29, P78, DOI 10.1016/j.parkreldis.2016.05.021
   Perumal SV, 2016, ICT EXPRESS, V2, P168, DOI 10.1016/j.icte.2016.10.005
   Perumal SV, 2016, 2016 IEEE HEALTHCARE INNOVATION POINT-OF-CARE TECHNOLOGIES CONFERENCE (HI-POCT), P21, DOI 10.1109/HIC.2016.7797687
   Pham TT, 2017, IEEE T BIO-MED ENG, V64, P2719, DOI 10.1109/TBME.2017.2665438
   Pham TD, 2018, IEEE T NEUR SYS REH, V26, P188, DOI 10.1109/TNSRE.2017.2732448
   Pichler D., 2017, BASAL GANGLIA, V8, P22, DOI [10.1016/j.baga.2017.02.066, DOI 10.1016/J.BAGA.2017.02.066]
   Piro NE, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060930
   Prakash C, 2018, ARTIF INTELL REV, V49, P1, DOI 10.1007/s10462-016-9514-6
   Prateek GV, 2018, IEEE T BIO-MED ENG, V65, P2152, DOI 10.1109/TBME.2017.2785625
   Protokinetics Team, 2018, UND PHAS GAIT CYCL
   Pun UK, 2016, IEEE ENG MED BIO, P2407, DOI 10.1109/EMBC.2016.7591215
   Punin C, 2017, 2017 GLOBAL MEDICAL ENGINEERING PHYSICS EXCHANGES/PAN AMERICAN HEALTH CARE EXCHANGES (GMEPE/PAHCE)
   Punin C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030737
   Putri FT, 2016, MAJALAH ILMIAH MOMEN, V12, DOI [10.36499/jim.v12i2.1630, DOI 10.36499/JIM.V12I2.1630]
   Raccagni C, 2018, BRAIN BEHAV, V8, DOI 10.1002/brb3.977
   Ravi T., 2018, INT J ENG TECHNOL, V7, P119, DOI [10.14419/ijet.v7i3.6.14953, DOI 10.14419/IJET.V7I3.6.14953]
   Raykov, 2018, ARXIV
   Rehman RZU, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245363
   Ren P, 2017, IEEE T BIO-MED ENG, V64, P52, DOI 10.1109/TBME.2016.2536438
   Ren P, 2016, IEEE T NEUR SYS REH, V24, P291, DOI 10.1109/TNSRE.2015.2477325
   Rennie L, 2018, GAIT POSTURE, V62, P505, DOI 10.1016/j.gaitpost.2018.04.011
   Rennie L, 2017, GAIT POSTURE, V54, P311, DOI 10.1016/j.gaitpost.2017.03.023
   Rewar S., 2015, Indian J. Res. Pharm. Biotechnol., V3, P176
   Rizek P, 2016, CAN MED ASSOC J, V188, P1157, DOI 10.1503/cmaj.151179
   Rocchi L, 2014, IEEE T NEUR SYS REH, V22, P1064, DOI 10.1109/TNSRE.2013.2292496
   Rodríguez-Martín D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171764
   Rodríguez-Martín D, 2015, NEUROCOMPUTING, V164, P144, DOI 10.1016/j.neucom.2014.09.084
   Roggendorf J, 2012, GAIT POSTURE, V35, P116, DOI 10.1016/j.gaitpost.2011.08.020
   Rovini E, 2018, ANN BIOMED ENG, V46, P2057, DOI 10.1007/s10439-018-2104-9
   Saad A, 2016, DISSERTATION
   Sakar BE, 2013, IEEE J BIOMED HEALTH, V17, P828, DOI 10.1109/JBHI.2013.2245674
   Samà A, 2017, COMPUT BIOL MED, V84, P114, DOI 10.1016/j.compbiomed.2017.03.020
   Samà A, 2018, PATTERN RECOGN LETT, V105, P135, DOI 10.1016/j.patrec.2017.05.009
   Sarbaz Y, 2012, NEUROSCI LETT, V509, P72, DOI 10.1016/j.neulet.2011.10.002
   Schlachetzki JCM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183989
   Segovia F, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00023
   Seidenberg PH., 2008, SPORTS MED RESOURCE, DOI [10.1016/B978-1-4160-3197-0.X1000-2, DOI 10.1016/B978-1-4160-3197-0.X1000-2]
   Sereix JC, 2017, APPLYING DEEP LEARNI
   Shanahan CJ, 2018, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00708
   Shawn, 2019, WHAT IS EMG SENSOR M
   Shetty S., 2016, INPROC INT C INVENTI, P2, DOI 10.1109/INVENTIVE.2016.7824836
   Shiwani B, 2017, MOVEMENT DISORDERS 3
   Shrivastava P, 2017, COMPUT METH PROG BIO, V139, P171, DOI 10.1016/j.cmpb.2016.07.029
   Shu L, 2010, IEEE T INF TECHNOL B, V14, P767, DOI 10.1109/TITB.2009.2038904
   Sijobert B, 2014, 2014 IEEE 19TH INTERNATIONAL FUNCTIONAL ELECTRICAL STIMULATION SOCIETY ANNUAL CONFERENCE (IFESS)
   de Lima ALS, 2018, GAIT POSTURE, V62, P388, DOI 10.1016/j.gaitpost.2018.03.045
   Soubra R., 2016, 2016 International Conference on Bio-engineering for Smart Technologies (BioSMART), P1, DOI DOI 10.1109/BIOSMART.2016.7835604
   Stamatakis J, 2011, IEEE ENG MED BIO, P7900, DOI 10.1109/IEMBS.2011.6091948
   Statista Research Department, 2010, PARK DIS PROJ WORLDW
   Su RH, 2014, BIOMED ENG-APP BAS C, V26, DOI 10.4015/S1016237214500318
   Tay A., 2015, Control Conference (ASCC), 2015 10th Asian, P1
   Tekscan, WHY IS GAIT AN IMP
   Thompson E, 2017, GAIT POSTURE, V58, P46, DOI 10.1016/j.gaitpost.2017.07.001
   Tien I, 2010, IEEE ENG MED BIO, P3353, DOI 10.1109/IEMBS.2010.5627904
   Torvi VG, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1001, DOI 10.1109/ICMLA.2018.00163
   Tripoliti EE, 2013, COMPUT METH PROG BIO, V110, P12, DOI 10.1016/j.cmpb.2012.10.016
   Tzallas AT, 2014, SENSORS-BASEL, V14, P21329, DOI 10.3390/s141121329
   UCI Machine Learning Respository, 2017, PARKINSONS DATASET
   Uustal H, NORMAL GAIT
   van Wegen EEH, 2018, PARKINSONISM RELAT D, V46, pS57, DOI 10.1016/j.parkreldis.2017.07.024
   Verlekar TT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092743
   Wadhwani A, 2013, INT J ADV BIOL BIOME, V1, P624
   Wang K, 2017, I C COMM SOFTW NET, P1529, DOI 10.1109/ICCSN.2017.8230364
   Wang Y, 2017, BIOMED SIGNAL PROCES, V38, P400, DOI 10.1016/j.bspc.2017.06.015
   Watelain E., 2017, MOVEMENT SPORT SCI, V4, P3, DOI [10.3917/sm.098.0003, DOI 10.3917/SM.098.0003]
   Weber S. A. T., 2014, GLOBAL ADV RES J MED, V11, P362
   Woolf AD., 2015, BMC Musculoskeletal Disorders, V16, pS3, DOI 10.1186/1471-2474-16-S1-S3
   Wu X, 2017, IEEE INT C BIOINFORM, P2330, DOI 10.1109/BIBM.2017.8218048
   Wu YF, 2017, BIOMED SIGNAL PROCES, V31, P265, DOI 10.1016/j.bspc.2016.08.022
   Xia Y, 2018, BIOMED SIGNAL PROCES, V46, P221, DOI 10.1016/j.bspc.2018.07.015
   Xu C, 2018, PROCEDIA COMPUT SCI, V129, P21, DOI 10.1016/j.procs.2018.03.038
   Yang K, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.03.09
   Yoneyama M, 2014, IEEE T NEUR SYS REH, V22, P613, DOI 10.1109/TNSRE.2013.2260561
   Yoneyama M, 2013, IEEE T NEUR SYS REH, V21, P999, DOI 10.1109/TNSRE.2013.2268251
   Zach H, 2015, PARKINSONISM RELAT D, V21, P1362, DOI 10.1016/j.parkreldis.2015.09.051
   Zeng W, 2019, NEURAL NETWORKS, V111, P64, DOI 10.1016/j.neunet.2018.12.012
   Zhang YMZ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.83
   Zhao AT, 2018, NEUROCOMPUTING, V315, P1, DOI 10.1016/j.neucom.2018.03.032
   Zhao AT, 2018, PROC SPIE, V10615, DOI 10.1117/12.2305277
   Zijlstra A, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-75
NR 210
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10211
EP 10247
DI 10.1007/s11042-022-13398-7
EA AUG 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000847198200001
DA 2024-07-18
ER

PT J
AU Zeng, QZ
   Hu, YS
   Li, D
   Sun, DY
AF Zeng, Qingzhi
   Hu, Yingsong
   Li, Dan
   Sun, Dongya
TI Multi-person pose estimation based on graph grouping optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Graph construction; Deconvolution module;
   Grouping; Pose optimization
AB Multi-person pose estimation has been an increasingly popular topic with the advancements of all kinds of computer vision and human-machine interaction tasks. This study field could further enhance the understanding of human poses and activities. The current mainstream multi-person pose estimation methods are generally divided into two categories: top-down and bottom-up methods. Although top-down methods are capable of achieving better performance by simplifying the problem to single-person pose estimation, while this strategy somewhat greatly increases the time complexity as a trade-off for better accuracy. The bottom-up methods could directly locate all the keypoints in the image, which can be potentially more effective and can be made real-time. However, most of the current bottom-up methods have separated the detection and grouping of keypoints into two independent steps. This greatly hindered the overall performance and computation efficiency of the algorithms. To address this issue, our study proposes an end-to-end bottom-up framework for multi-person pose estimation. Using the HRNet as the backbone structure, we add a deconvolution module to acquire high-resolution feature maps in the keypoints proposal stage. The graph neural network is leveraged in the grouping stage, which is integrated to the backbone so that the whole framework can be trained in an end-to-end manner. Using the keypoint candidates as nodes, two discriminators are exploited to supervise the grouping process. Lastly, a graph-based pose optimization algorithm is explored to refine the results. Experiments on the COCO and CrowdPose datasets show that our method achieves better accuracy and greatly reduce the computation time as well.
C1 [Zeng, Qingzhi; Hu, Yingsong; Li, Dan; Sun, Dongya] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Hu, YS (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM huys@hust.edu.cn
CR Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   GORI M, 2005, IEEE IJCNN, P729, DOI DOI 10.1109/IJCNN.2005.1555942
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
   Jin S, 2019, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2019.00581
   Kipf TN, 2017, INT C LEARN REPR
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
NR 28
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7039
EP 7053
DI 10.1007/s11042-022-13445-3
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840056400002
DA 2024-07-18
ER

PT J
AU Ali, G
   Malik, MSI
AF Ali, Ghulam
   Malik, Muhammad Shahid Iqbal
TI Rumour identification on Twitter as a function of novel textual and
   language-context features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Language context; Detection; Twitter; Rumour
AB Social microblogs are one of the popular platforms for information spreading. However, with several advantages, these platforms are being used for spreading rumours. At present, the majority of existing approaches identify rumours at the topic level instead of at the tweet/post level. Moreover, prior studies used the sentiment and linguistic features for rumours identification without considering discrete positive and negative emotions and effective part-of-speech features in content-based approaches. Similarly, the majority of prior studies used content-based approaches for feature generation, and recent context-based approaches were not explored. To cope with these challenges, a robust framework for rumour detection at the tweet level is designed in this paper. The model used word2vec embeddings and bidirectional encoder representations from transformers method (BERT) from context-based and discrete emotions, linguistic, and metadata characteristics from content-based approaches. According to our knowledge, we are the first ones who used these features for rumour identification at the tweet/post level. The framework is tested on four real-life twitter microblog datasets. The results show that the detection model is capable of detecting 97%, 86%, 85%, and 80% of rumours on four datasets respectively. In addition, the proposed framework outperformed the three latest state-of-the-art baselines. BERT model presented the best performance among context-based approaches, and linguistic features are best performing among content-based approaches as a stand-alone model. Moreover, the utilization of two-step feature selection further improves the detection model performance.
C1 [Ali, Ghulam] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Islamabad, Pakistan.
   [Malik, Muhammad Shahid Iqbal] Capital Univ Sci & Technol, Dept Comp Sci, Kahuta Rd, Islamabad 44000, Pakistan.
C3 COMSATS University Islamabad (CUI); Capital University of Science &
   Technology
RP Malik, MSI (corresponding author), Capital Univ Sci & Technol, Dept Comp Sci, Kahuta Rd, Islamabad 44000, Pakistan.
EM ghulamali007@yahoo.com; msi_id@yahoo.com
RI Ali, Ghulam/AAO-3519-2021; Malik, Muhammad Shahid Iqbal/AAU-9291-2020
OI Malik, Muhammad Shahid Iqbal/0000-0001-8396-3344; Ali,
   Ghulam/0000-0002-5890-370X
CR Alzanin SM, 2019, KNOWL-BASED SYST, V185, DOI 10.1016/j.knosys.2019.104945
   Bai N, 2020, IEEE ACCESS, V8, P80771, DOI 10.1109/ACCESS.2020.2990770
   Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Bird S., 2009, NATURAL LANGUAGE PRO
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BRILL E, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P152, DOI 10.3115/974499.974526
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen YX, 2019, LECT NOTES ARTIF INT, V11776, P105, DOI 10.1007/978-3-030-29563-9_11
   Devlin J., 2018, BERT PRE TRAINING DE
   Domm P, 2013, CNBC, V23
   Figueira A, 2017, PROCEDIA COMPUT SCI, V121, P817, DOI 10.1016/j.procs.2017.11.106
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Hamidian S., 2019, ARXIV
   He XX, 2022, IEEE ACCESS, V10, P25605, DOI 10.1109/ACCESS.2022.3152842
   HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0
   Huang Q, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207582
   Huang Q, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852468
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lotfi S, 2021, APPL INTELL, V51, P4774, DOI 10.1007/s10489-020-02036-0
   Ma J., 2018, Rumor Detection on Twitter with Tree-Structured Recursive Neural Networks
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Malik MSI, 2017, COMPUT HUM BEHAV, V73, P290, DOI 10.1016/j.chb.2017.03.053
   Malik MSI, 2020, SOFT COMPUT, V24, P13913, DOI 10.1007/s00500-020-04767-1
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mihalcea Rada, 2009, P ACL IJCNLP 2009 C, P309, DOI [10.3115/1667583.1667679, DOI 10.3115/1667583.1667679]
   Nayak P., 2019, The keyword
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Sicilia R, 2018, EXPERT SYST APPL, V110, P33, DOI 10.1016/j.eswa.2018.05.019
   Song CH, 2021, IEEE T KNOWL DATA EN, V33, P3035, DOI 10.1109/TKDE.2019.2961675
   Tian Y, 2020, IEEE ACCESS, V8, P87121, DOI 10.1109/ACCESS.2020.2989180
   Turney P.D., 2013, NRC EMOTION LEXICON, V2
   Vijeev A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P337, DOI 10.1109/ICACCI.2018.8554371
   Wang S, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P41, DOI [10.1109/ISI.2019.8823266, 10.1109/isi.2019.8823266]
   Wang W., 2017, ARXIV
   WHO, 2020, FACT BEING ABL HOLD
   Wikipedia, 2021, About us
   World Health Organization, 2020, ALC DOES NOT PROT CO
   Xu RF, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1625
   Zhang YX, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206739
   Zhou YS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102179
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 47
TC 3
Z9 3
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7017
EP 7038
DI 10.1007/s11042-022-13595-4
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516800001
PM 35974894
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Fang, W
   Yi, WN
   Pang, L
   Sheng, VS
AF Fang, Wei
   Yi, Weinan
   Pang, Lin
   Sheng, Victor S.
TI Study of cross-domain person re-identification based on DCGAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person Re-identification; Unsupervised learning; Domain shifting; Deep
   convolutional generative adversarial network
AB Person re-identification(re-ID) techniques have been rapidly improving with the development of deep neural networks, and the accuracy of fully supervised re-ID models is already very high. However, when person re-identification models with supervised learning are used directly in unlabeled target scenes, the accuracy is greatly reduced. This is due to the large disparity between the domains of different datasets, such as resolution, lighting changes and occlusion. At the same time, the existing re-ID methods based on domain transfer have the problem of blurred images due to big gap between domains. Therefore, in this paper, a DCGAN (Deep Convolutional Generative Adversarial Network) is added to the unsupervised cross-domain re-ID model, which can allow the target domain distribution to be adequately fitted to the labeled domain distribution, so that the re-ID model trained in source domain can be used on the target domain without large fluctuations due to domain shift. By comparing with the UMDL(Unsupervised Multi-task Dictionary Learning) method, rank-1 and rank-5 are improved by 9.61% and 17.81%, respectively, when the model trained from Market-1501 is used in the GRID dataset, and by 9.52% and 14.14%, respectively, when compared with the GAN(Generative Adversarial Networks)-based method under the same experiment.
C1 [Fang, Wei; Yi, Weinan; Pang, Lin] Nanjing Univ Informat Sci Technol, Minist Educ, Sch Comp Software, Engn Res Ctr Digital Forens, Nanjing, Peoples R China.
   [Fang, Wei] Chinese Acad Meteorol Sci, State Key Lab Severe Weather, Beijing, Peoples R China.
   [Fang, Wei] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou, Peoples R China.
   [Sheng, Victor S.] Texas Tech Univ, Lubbock, TX 79409 USA.
C3 Nanjing University of Information Science & Technology; China
   Meteorological Administration; Chinese Academy of Meteorological
   Sciences (CAMS); Soochow University - China; Texas Tech University
   System; Texas Tech University
RP Yi, WN (corresponding author), Nanjing Univ Informat Sci Technol, Minist Educ, Sch Comp Software, Engn Res Ctr Digital Forens, Nanjing, Peoples R China.
EM Fangwei@nuist.edu.cn; 924985817@qq.com
FU National Natural Science Foundation of China [42075007]; Open Grants of
   the State Key Laboratory of Severe Weather [2021LASW-B19]; Open Project
   of Provincial Key Laboratory for Computer Information Processing
   Technology, Soochow University [KJS1935]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions, Graduate
   Scientific Research Innovation Program of Jiangsu Province [KYCX21_1015]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.42075007), the Open Grants of the State Key Laboratory
   of Severe Weather(No.2021LASW-B19), the Open Project of Provincial Key
   Laboratory for Computer Information Processing Technology under Grant
   KJS1935, Soochow University, and the Priority Academic Program
   Development of Jiangsu Higher Education Institutions, Graduate
   Scientific Research Innovation Program of Jiangsu Province under Grant
   no. KYCX21 1015.
CR Bousmalis K, 2016, ADV NEUR IN, V29
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Dai Y, ARXIV
   Fan Lijie, 2020, P IEEE CVF C COMP VI, P10699
   Fang W, 2018, CMC-COMPUT MATER CON, V57, P167, DOI 10.32604/cmc.2018.02356
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Fu K, 2020, CMC-COMPUT MATER CON, V64, P1977, DOI 10.32604/cmc.2020.09882
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hermans Alexander, 2017, ARXIV170307737
   Huang Y, 2019, IEEE I CONF COMP VIS, P9526, DOI 10.1109/ICCV.2019.00962
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Shu R., 2018, ARXIV
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su KH, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P1028, DOI 10.1109/ICECC.2011.6066743
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zhao S, 2020, arXiv
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36551
EP 36565
DI 10.1007/s11042-022-13526-3
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000838552200001
DA 2024-07-18
ER

PT J
AU Ansari, MSA
   Pal, K
   Govil, P
   Govil, MC
   Awasthi, LK
AF Ansari, Md Sarfaraj Alam
   Pal, Kunwar
   Govil, Prajjval
   Govil, Mahesh Chandra
   Awasthi, Lalit Kumar
TI A statistical analysis of SAMPARK dataset for peer-to-peer traffic and
   selfish-peer identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dataset; Peer-to-peer (P2P); Traffic analysis; Feature correlation;
   Machine learning
ID DETECTION SYSTEMS; INTERNET; NETWORK; SELECTION; SCHEME
AB The popularity of peer-to-peer (P2P) network can be attributed to their inherent advantages such as resource utilization, scalability and better response. At the same time modern networks have become highly complex and need better approaches for management and monitoring of traffic. The use of machine learning (ML) techniques is inevitable due to their inherent advantages. The ML-based model needs a reliable dataset for training and testing of the developed approaches. This paper addresses the unavailability of a comprehensive labelled dataset to enable the researcher to evaluate their machine learning based solutions. The proposed SAMPARK dataset is constructed by capturing the traces by running various P2P and Non-P2P applications in real time. The generated dataset consists of the normal traffic pattern and 24 attributes that comprise the basic, flow, and packet-based general features. The major contribution in the work presented lies in building of an exclusive dataset to address important issues in P2P network such as selfish peer, flash crowd, as no dataset is being constructed explicitly to address these important problems in P2P network. The validity of the constructed SAMPARK dataset is carried out by using statistical analysis of probability distribution and feature correlation.The statistical evaluation of SAMPARK dataset shows non-linearity and non-normality characteristics. The correlation rate among features without labelling and with labels are determined using Pearson's Correlation Coefficient (PCC) and Gain Ratio (GR) and the acceptable rates are 84% and 68% respectively. The effectiveness of the dataset is demonstrated by applying machine learning method. The labelling of dataset is done using port-based technique and performance is determining by calculated Accuracy and False Alarm Rate (FAR) for various proposed ML-model developed to identify P2P traffic and selfish peers. The comparative analysis is also done with UNIBS dataset. The highest accuracy achieved for RF technique on SAMPARK dataset is 99.13% which is better compare to UNIBS dataset. The experimental results also exhibit the usefulness and efficacy of the proposed SAMPARK dataset for various analysis of P2P networks.
C1 [Ansari, Md Sarfaraj Alam; Govil, Mahesh Chandra] Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Sikkim 737139, Gangtok, India.
   [Pal, Kunwar; Awasthi, Lalit Kumar] Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144011, Punjab, India.
   [Govil, Prajjval] JK Lakshmipat Univ, Dept Comp Sci & Engn, Jaipur 302026, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim; National Institute of Technology (NIT System); Dr B R
   Ambedkar National Institute of Technology Jalandhar
RP Ansari, MSA (corresponding author), Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Sikkim 737139, Gangtok, India.
EM sarfaraj@nitsikkim.ac.in
RI Ansari, Md. Sarfaraj Alam/JBJ-3548-2023; Awasthi, Lalit
   Kumar/V-3485-2019
OI Ansari, Md. Sarfaraj Alam/0000-0002-9716-7012; Awasthi, Lalit
   Kumar/0000-0001-8396-9025
CR Abbasi M, 2019, J SUPERCOMPUT, V75, P6574, DOI 10.1007/s11227-019-02861-2
   Abbasi M, 2021, IEEE T INTELL TRANSP, V22, P5283, DOI 10.1109/TITS.2020.3038250
   Abbasi M, 2020, J SUPERCOMPUT, V76, P3105, DOI 10.1007/s11227-019-03090-3
   Abbasi M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.185
   Adar E., 2000, First Monday, V5, DOI 10.5210/fm.v5i10.792
   Alpaydin E., 2020, INTRO MACHINE LEARNI, DOI DOI 10.7551/MITPRESS/13811.001.0001
   [Anonymous], 2020, IQIYI
   [Anonymous], 2020, PPTV
   [Anonymous], 2020, JAMI
   [Anonymous], 2015, AFR J COMPUT ICTS
   [Anonymous], 2020, YOUTUBE
   [Anonymous], 1999, KDD99 KDD CUP 1999 D
   [Anonymous], 2020, HOTSTAR
   [Anonymous], 2020, YUPPTV
   [Anonymous], CSE-CIC-IDS2018 Dataset
   [Anonymous], CISCO VNI GLOBAL 202
   [Anonymous], 2020, FUNSHION
   [Anonymous], 2017, The Zettabyte Era: Trends and analysis
   [Anonymous], 2020, VUZE
   Ansari SA, 2021, MULTIMED TOOLS APPL, V80, P19263, DOI 10.1007/s11042-021-10709-2
   Bhatia M, 2017, PEER PEER NETW APPL, V10, P1182, DOI 10.1007/s12083-016-0471-2
   Biaou BOS, 2022, J KING SAUD UNIV-COM, V34, P2451, DOI 10.1016/j.jksuci.2020.09.015
   Biryukov A, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P15, DOI 10.1145/2660267.2660379
   Biswas NK, 2021, INT J INTERACT MULTI, V6, P49, DOI 10.9781/ijimai.2021.04.004
   BLAND JM, 1995, BRIT MED J, V310, P633, DOI 10.1136/bmj.310.6980.633
   Byun H, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P840
   Carela-Espanol Valentin, 2014, Passive and Active Measurement. 15th International Conference, PAM 2014. Proceedings: LNCS 8362, P98, DOI 10.1007/978-3-319-04918-2_10
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chen YS, 2014, IEEE ACM T NETWORK, V22, P1106, DOI 10.1109/TNET.2013.2272056
   Cherkassky Vladimir, 2007, Learning from data: Concepts, theory, and methods
   Cohen B., 2003, WORKSH EC PEER TO PE
   Dusi M, 2011, COMPUT NETW, V55, P1158, DOI 10.1016/j.comnet.2010.11.006
   Eggert L., 2011, RFC, P1
   Elmasri R., 2008, FUNDAMENTALS DATABAS
   Fujita S, 2019, IEICE T INF SYST, VE102D, P261, DOI 10.1587/transinf.2018EDP7238
   Garcia S, 2014, COMPUT SECUR, V45, P100, DOI 10.1016/j.cose.2014.05.011
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Gomes JV, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480747
   Gringoli F, 2009, ACM SIGCOMM COMP COM, V39, P13
   Gupta A, 2011, COMPUT INFORM, V30, P559
   Hall MA, 1998, AUST COMP S, V20, P181
   HECKMANN O, 2002, KOMTR082002 DARMST U
   Internet Assigned Numbers Authority (IANA), SERV NAM TRANSP NUMB
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Justel A, 1997, STAT PROBABIL LETT, V35, P251, DOI 10.1016/S0167-7152(97)00020-5
   Karagiannis T., 2004, The 4th ACM SIGCOMM conference on Internet measurement, P121
   King S., 2012, Self-Published Paper
   Krishnan R., 2004, Proceedings of the 37th Annual Hawaii International Conference on System Sciences
   Kulbak Y, 2005, EMULE PROTOCOL SPECI
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Liao X., 2006, P IEEE INFOCOM, P1
   Liu H, 2007, INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, PROCEEDINGS, P155
   Madhukar A., 2006, 14th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems, P179
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Manju N, 2020, INT J INTERACT MULTI, V6, P117, DOI 10.9781/ijimai.2019.11.002
   MARDIA KV, 1970, BIOMETRIKA, V57, P519, DOI 10.1093/biomet/57.3.519
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mohammadi M, 2011, EXPERT SYST APPL, V38, P6417, DOI 10.1016/j.eswa.2010.09.114
   Mohri M., 2012, Foundations of Machine Learning
   Moore A., 2013, Discriminators for Use in Flowbased Classification
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Moustafa N, 2016, INF SECUR J, V25, P18, DOI 10.1080/19393555.2015.1125974
   Nguyen TTT, 2008, IEEE COMMUN SURV TUT, V10, P56, DOI 10.1109/SURV.2008.080406
   Ojo OE, 2020, PEER PEER NETW APPL, V13, P1672, DOI 10.1007/s12083-020-00913-6
   Olson DL., 2008, Advanced data mining techniques, V1st, P138, DOI [10.1007/978-3-540-76917-0, DOI 10.1007/978-3-540-76917-0]
   Pal K, 2018, MULTIMED TOOLS APPL, V77, P24427, DOI 10.1007/s11042-018-5741-y
   Pal K, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3440
   Perenyi M., 2006, Journal of Communications, V1, P36, DOI 10.4304/jcm.1.7.36-46
   Pouwelse JA, 2008, CONCURR COMP-PRACT E, V20, P127, DOI 10.1002/cpe.1189
   Pouyanfar S, 2019, WORLD WIDE WEB, V22, P1893, DOI 10.1007/s11280-018-0636-4
   Reddy JM, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON EMERGING INFORMATION TECHNOLOGY AND ENGINEERING SOLUTIONS (EITES 2015), P38, DOI 10.1109/EITES.2015.16
   Ripeanu M, 2002, FIRST INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING, P99, DOI 10.1109/P2P.2001.990433
   Salem M, 2012, ARXIV
   Saroiu S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FIFTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P315, DOI 10.1145/1060289.1060319
   Saroiu S, 2003, MULTIMEDIA SYST, V9, P170, DOI 10.1007/s00530-003-0088-1
   Sherwood R, 2006, COMPUT NETW, V50, P523, DOI 10.1016/j.comnet.2005.07.012
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Tada H, 2021, IEICE T INF SYST, VE104D, P63, DOI 10.1587/transinf.2020MPP0003
   Thampi SM, 2013, ARXIV
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Verma A, 2019, WIRELESS PERS COMMUN, V108, P1571, DOI 10.1007/s11277-019-06485-w
   Zhang HL, 2012, COMPUT COMMUN, V35, P1457, DOI 10.1016/j.comcom.2012.04.012
NR 82
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8507
EP 8535
DI 10.1007/s11042-022-13556-x
EA AUG 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000838552300005
DA 2024-07-18
ER

PT J
AU Hong, YF
   Zhang, GS
   Wei, BZ
   Cong, JY
   Xu, YF
   Zhang, KX
AF Hong, Yanfei
   Zhang, Guisheng
   Wei, Benzheng
   Cong, Jinyu
   Xu, Yunfeng
   Zhang, Kuixing
TI Weakly supervised semantic segmentation for skin cancer via CNN
   superpixel region response
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Computer-aided diagnosis; Skin lesions; Weakly
   supervised segmentation; Region response
ID BORDER DETECTION; LESION SEGMENTATION; DERMOSCOPY IMAGES; ATTENTION;
   MELANOMA
AB Precise segmentation for skin cancer lesions at different stages is conducive to early detection and further treatment. We propose a weakly supervised semantic segmentation algorithm (CNN-SRR) for dermoscopy images through CNN responding superpixel regions, given that the substantial cost of obtaining perfect pixel annotation for these tasks. CNN-SRR combines a modified classifier based on deep learning and unsupervised superpixel algorithm. The former leverages abundant image-level labeled data to tune parameters to focalize on lesion regions. The extraction of lesion region responses consists of two stages, training a modified CNN classifier and back-propagate peak values of the classifier top layer. Afterward, a test image is over-segmented to a set of primitive superpixels that are merged into a few regions as proposals, several of which are activated as the segmented mask by lesion region responses via non-maximal suppression. Quantified experiments on ISBI2017 and PH2 datasets prove that the proposed algorithm can effectively discriminate lesion regions and the segmentation results even achieve competitive accuracy to the supervised segmentation approaches. We evaluate the proposed CNN-SRR algorithm on ISBI2017 and achieve that the Jaccard coefficient and Accuracy of segmentation task are improved by 12.4% and 3.3% compared with the unsupervised superpixel segmentation algorithm.
C1 [Hong, Yanfei; Zhang, Guisheng; Wei, Benzheng; Cong, Jinyu; Xu, Yunfeng; Zhang, Kuixing] Shandong Univ Tradit Chinese Med, Ctr Med Artificial Intelligence, Qingdao 266112, Peoples R China.
   [Zhang, Guisheng] Shandong Univ Tradit Chinese Med, Coll Intelligence & Informat Technol, Jinan, Shandong, Peoples R China.
   [Wei, Benzheng; Cong, Jinyu; Zhang, Kuixing] Shandong Univ Tradit Chinese Med, Qingdao Acad Chinese Med Sci, Qingdao 266112, Peoples R China.
C3 Shandong University of Traditional Chinese Medicine; Shandong University
   of Traditional Chinese Medicine; Shandong University of Traditional
   Chinese Medicine
RP Wei, BZ (corresponding author), Shandong Univ Tradit Chinese Med, Ctr Med Artificial Intelligence, Qingdao 266112, Peoples R China.; Wei, BZ (corresponding author), Shandong Univ Tradit Chinese Med, Qingdao Acad Chinese Med Sci, Qingdao 266112, Peoples R China.
EM wbz99@sina.com
OI Wei, Benzheng/0000-0001-9640-4947
FU Natural Science Foundation of China [61872225]; Introduction and
   Cultivation Program for Young Creative Talents in Colleges and
   Universities of Shandong Province [173]; Natural Science Foundation of
   Shandong Province [ZR2019ZD04, ZR201 5FM010]; Project of Science and
   technology plan of Shandong higher education institutions Program
   [J15LN20]; Project of Shandong Province Medical and Health Technology
   Development Program [2016WS0577]
FX This work was partly funded by Natural Science Foundation of China
   (No.61872225); Introduction and Cultivation Program for Young Creative
   Talents in Colleges and Universities of Shandong Province (No.173); the
   Natural Science Foundation of Shandong Province (No.ZR2019ZD04, No.ZR201
   5FM010); the Project of Science and technology plan of Shandong higher
   education institutions Program (No.J15LN20); the Project of Shandong
   Province Medical and Health Technology Development Program
   (No.2016WS0577).
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Abbas Q, 2011, COMPUT METH PROG BIO, V104, pE1, DOI 10.1016/j.cmpb.2010.06.016
   Abuzaghleh O, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akram MU, 2013, ENG COMPUT-GERMANY, V29, P165, DOI 10.1007/s00366-011-0253-7
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   [Anonymous], 2001, JSEG METHOD IMPLEMEN
   [Anonymous], 2015, Dermoscopy image analysis, DOI DOI 10.1201/B19107
   ARGENIANO G, 2002, INTERACTIVE ATLAS DE
   Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balch CM, 2001, J CLIN ONCOL, V19, P3635, DOI 10.1200/JCO.2001.19.16.3635
   Barata C, 2015, IEEE ENG MED BIO, P2653, DOI 10.1109/EMBC.2015.7318937
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Bi L, 2019, PATTERN RECOGN, V85, P78, DOI 10.1016/j.patcog.2018.08.001
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   Celebi ME, 2019, IEEE J BIOMED HEALTH, V23, P474, DOI 10.1109/JBHI.2019.2895803
   Celebi ME, 2009, COMPUT MED IMAG GRAP, V33, P148, DOI 10.1016/j.compmedimag.2008.11.002
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Combalia M, 2019, ARXIV
   Crandall, LEVEL SET IMPLEMENTA
   Feng Xinyang, 2017, Med Image Comput Comput Assist Interv, V10435, P568, DOI 10.1007/978-3-319-66179-7_65
   Freedberg KA, 1999, J AM ACAD DERMATOL, V41, P738, DOI 10.1016/S0190-9622(99)70010-1
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Gessert N, 2020, IEEE T BIO-MED ENG, V67, P495, DOI 10.1109/TBME.2019.2915839
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Greer RO, 2016, PEDIAT HEAD NECK PAT, DOI 10.1017/9781316661949
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Jaworek-Korjakowska J, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512804
   Karim AM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216378
   Karim AM, 2019, BIOCYBERN BIOMED ENG, V39, P148, DOI 10.1016/j.bbe.2018.11.004
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Li X, 2018, ARXIV
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Oliveira RB, 2018, NEURAL COMPUT APPL, V29, P613, DOI 10.1007/s00521-016-2482-6
   Patiño D, 2018, LECT NOTES COMPUT SC, V11073, P728, DOI 10.1007/978-3-030-00937-3_83
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Schaefer G, 2011, COMPUT MED IMAG GRAP, V35, P99, DOI 10.1016/j.compmedimag.2010.08.004
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   VEZHNEVETS A, 2010, PROC CVPR IEEE, P3249, DOI DOI 10.1109/CVPR.2010.5540060
   Wei ZH, 2019, IEEE ACCESS, V7, P136616, DOI 10.1109/ACCESS.2019.2940794
   Xie FY, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105241
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Yuan Y, 2017, ARXIV170305165
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 56
TC 5
Z9 5
U1 6
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6829
EP 6847
DI 10.1007/s11042-022-13606-4
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000838552300013
DA 2024-07-18
ER

PT J
AU Gupta, V
   Jain, N
   Sachdeva, J
   Gupta, M
   Mohan, S
   Bajuri, MY
   Ahmadian, A
AF Gupta, Vedika
   Jain, Nikita
   Sachdeva, Jatin
   Gupta, Mudit
   Mohan, Senthilkumar
   Bajuri, Mohd Yazid
   Ahmadian, Ali
TI Improved COVID-19 detection with chest x-ray images using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Chest X-ray; Deep learning; Transfer learning; Convolutional
   neural network (CNN); Multi-class classification
ID NEURAL-NETWORKS; CLASSIFICATION
AB The novel coronavirus disease, which originated in Wuhan, developed into a severe public health problem worldwide. Immense stress in the society and health department was advanced due to the multiplying numbers of COVID carriers and deaths. This stress can be lowered by performing a high-speed diagnosis for the disease, which can be a crucial stride for opposing the deadly virus. A good large amount of time is consumed in the diagnosis. Some applications that use medical images like X-Rays or CT-Scans can pace up the time used in diagnosis. Hence, this paper aims to create a computer-aided-design system that will use the chest X-Ray as input and further classify it into one of the three classes, namely COVID-19, viral Pneumonia, and healthy. Since the COVID-19 positive chest X-Rays dataset was low, we have exploited four pre-trained deep neural networks (DNNs) to find the best for this system. The dataset consisted of 2905 images with 219 COVID-19 cases, 1341 healthy cases, and 1345 viral pneumonia cases. Out of these images, the models were evaluated on 30 images of each class for the testing, while the rest of them were used for training. It is observed that AlexNet attained an accuracy of 97.6% with an average precision, recall, and F1 score of 0.98, 0.97, and 0.98, respectively.
C1 [Jain, Nikita; Sachdeva, Jatin; Gupta, Mudit] Bharati Vidyapeeths Coll Engn, Delhi, India.
   [Mohan, Senthilkumar] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Bajuri, Mohd Yazid] Univ Kebangsaan Malaysia UKM, Dept Orthopaed & Traumatol, Fac Med, Kuala Lumpur, Malaysia.
   [Ahmadian, Ali] Mediterranea Univ Reggio Calabria, Decis Lab, I-89124 Reggio Di Calabria, Italy.
   [Ahmadian, Ali] Near East Univ, Dept Math, Mersin 10, Nicosia, Trnc, Turkey.
   [Gupta, Vedika] OP Jindal Global Univ, Jindal Global Business Sch, Sonipat, Haryana, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Universiti
   Kebangsaan Malaysia; Universita Mediterranea di Reggio Calabria; Near
   East University; O.P. Jindal Global University
RP Ahmadian, A (corresponding author), Mediterranea Univ Reggio Calabria, Decis Lab, I-89124 Reggio Di Calabria, Italy.; Ahmadian, A (corresponding author), Near East Univ, Dept Math, Mersin 10, Nicosia, Trnc, Turkey.
EM vgupta2@jgu.edu.in; nikita.jain@bharatividyapeeth.edu;
   ahmadian.hosseini@unirc.it
RI Gupta, Vedika/JXL-2328-2024; , m.senthilkumar/L-5551-2015; Ahmadian,
   Ali/N-3697-2015; Gupta, Vedika/JNR-1706-2023
OI , m.senthilkumar/0000-0002-8114-3147; Ahmadian, Ali/0000-0002-0106-7050;
   
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Asnaoui K.E., 2020, Automated methods for detection and classification pneumonia based on x-ray images using deep learning, P257
   Chaudhary A, 2021, COVID 19 PREDICTION, V60, DOI [10.1007/978-981-15-9682-7_14, DOI 10.1007/978-981-15-9682-7_14]
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Duran-Lopez L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165683
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Elfiky AA, 2021, J BIOMOL STRUCT DYN, V39, P2923, DOI 10.1080/07391102.2020.1758789
   Fouladi S, 2021, COMPUT COMMUN, V176, P234, DOI 10.1016/j.comcom.2021.06.011
   Ghorui N, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2020.103811
   Gupta V, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110708
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Jain N, 2020, INTELL DECIS TECHNOL, V14, P55, DOI 10.3233/IDT-190079
   Jain N, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2021.103813
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Jain R, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120768
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Ko H, 2020, J MED INTERNET RES, V22, DOI 10.2196/25442
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Kundu R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93658-y
   Misra S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091388
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Piryani R, 2018, J INTELL FUZZY SYST, V34, P3101, DOI 10.3233/JIFS-169494
   Piryani R, 2018, COMPUT SIST, V22, P83, DOI [10.13053/CyS-22-1-2784, 10.13053/cys-22-1-2784]
   Polsinelli M, 2020, PATTERN RECOGN LETT, V140, P95, DOI 10.1016/j.patrec.2020.10.001
   Raza A, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2020.103771
   Razzaq OA, 2021, RESULTS PHYS, V20, DOI 10.1016/j.rinp.2020.103715
   Rowan NJ, 2020, SCI TOTAL ENVIRON, V725, DOI 10.1016/j.scitotenv.2020.138532
   Salman F.M., 2020, Covid-19 detection using artificial intelligence, V4, P18
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shariq M, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103354
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Singh P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92006-4
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zamir M, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2020.103784
NR 45
TC 14
Z9 14
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37657
EP 37680
DI 10.1007/s11042-022-13509-4
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840140800006
PM 35968409
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumar, N
   Kumar, U
AF Kumar, Neeraj
   Kumar, Upendra
TI Comparative analysis of CN2 rule induction with other classification
   algorithms for network security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Intrusion detection; CN2; Feature reduction;
   Classification
AB Network Intrusion Detection (NID) is an important domain of research and as the network traffic is growing enormously, new challenges are emerging forth in terms of quality of service and security thus a reliable and robust network intrusion detection system (NIDS) has become an inevitable requirement. Researchers have developed and implemented many rule-based and statistical-based techniques, as well as machine learning (ML) approaches such as K-Nearest Neighbour (K-NN), Decision Tree (DT), Random Forest (RF), Multi-Layer Perceptron (MLP) and Naive-Bayes for this pursuit. But, a method is still in need that entails certain required characteristics like low computational cost, high classification accuracy, able to deal efficiently with large datasets having redundant data and high dimensionality. In this paper, a novel method is proposed that includes all these characteristics. Further, the proposed method is based on the rule induction technique using separate and-conquer algorithm known as CN2 for a network intrusion detection system. The performance of the proposed CN2 rule induction algorithm is also compared experimentally with K-NN, DT, RF, MLP and Naive-Bayes classifiers for the Kddcup99 dataset and it has been observed that the performance of the CN2 rule induction algorithm is better in comparison to other classifiers considered in this experimentation.
C1 [Kumar, Neeraj; Kumar, Upendra] Birla Inst Technol, Comp Sci & Engn Dept, Ranchi Patna Campus, Patna, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Kumar, N (corresponding author), Birla Inst Technol, Comp Sci & Engn Dept, Ranchi Patna Campus, Patna, Bihar, India.
EM phdcs100009.16@bitmesra.ac.in; upendrakr@bitmesra.ac.in
RI Kumar, Upendra/ABR-3521-2022; Kumar, Neeraj/L-3500-2016
OI Kumar, Upendra/0000-0002-6607-0453; Kumar, Neeraj/0000-0002-3020-3947;
   Kumar, Neeraj/0000-0001-8922-4059
CR Abu Taher K, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P643, DOI [10.1109/ICREST.2019.8644161, 10.1109/icrest.2019.8644161]
   Akashdeep, 2017, EXPERT SYST APPL, V88, P249, DOI 10.1016/j.eswa.2017.07.005
   AlMana A., 2014, International Journal of Computer Applications, V88, P20
   Alqahtani H., 2020, INT C COMP SCI COMM, P121, DOI DOI 10.1007/978-981-15-6648-6_10
   Alzahrani AO, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13050111
   Andresini G, 2020, IEEE ACCESS, V8, P53346, DOI 10.1109/ACCESS.2020.2980937
   Basori AH, 2020, EAI SPRINGER INNOVAT, P15, DOI 10.1007/978-3-030-19353-9_2
   Clark P., 1989, Machine Learning, V3, P261, DOI 10.1007/BF00116835
   Clark P, 1991, Proceedings of the Fifth European Working Session on Learning, P151, DOI DOI 10.1007/BFB0017011
   Ghanem WAHM, 2020, NEURAL PROCESS LETT, V51, P905, DOI 10.1007/s11063-019-10120-x
   Hakim Lukman, 2019, 2019 International Conference on Computer Science, Information Technology, and Electrical Engineering (ICOMITEE). Proceedings, P217, DOI 10.1109/ICOMITEE.2019.8920961
   Hosseini SMH, 2022, MECH BASED DES STRUC, V50, P2779, DOI 10.1080/15397734.2020.1784205
   Jia Y, 2019, IET INFORM SECUR, V13, P48, DOI 10.1049/iet-ifs.2018.5258
   Knutas A, 2019, MULTIMED TOOLS APPL, V78, P13593, DOI 10.1007/s11042-018-6913-5
   Liu H, 2019, GRANULAR COMPUT, V4, P275, DOI 10.1007/s41066-018-0097-2
   Liu H, 2016, GRANULAR COMPUT, V1, P259, DOI 10.1007/s41066-016-0021-6
   Martinez MAQ, 2020, ADV INTELLIGENT SYST, P173, DOI DOI 10.1007/978
   Meira J, 2020, J AMB INTEL HUM COMP, V11, P4477, DOI 10.1007/s12652-019-01417-9
   Nanda NB, 2019, COMM COM INF SC, V1076, P274, DOI 10.1007/978-981-15-0111-1_25
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Radha Krishnan S, 2020, EARTH SCI INFORM, P1
   Sangeetha S, 2010, COMM COM INF SC, V89, P27
   Sikora M, 2019, KNOWL-BASED SYST, V173, P1, DOI 10.1016/j.knosys.2019.02.019
   Sun C, 2018, 2018 27TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN)
   Teli M, 2020, ADV COMPUTING TECHNO, DOI 10.1007/978-981-15-3242-9_25
   Thakkar A, 2021, J AMB INTEL HUM COMP, V12, P1249, DOI 10.1007/s12652-020-02167-9
   Waskita AA, 2013, 2013 IEEE CONFERENCE ON SYSTEMS, PROCESS & CONTROL (ICSPC), P193, DOI 10.1109/SPC.2013.6735130
   Wazirali R, 2020, ARAB J SCI ENG, V45, P10859, DOI 10.1007/s13369-020-04907-7
NR 28
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37119
EP 37135
DI 10.1007/s11042-022-13542-3
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840140800004
DA 2024-07-18
ER

PT J
AU Chi, CL
   Zhang, D
   Zhu, ZS
   Wang, XZ
   Lee, DJ
AF Chi, Cailong
   Zhang, Dong
   Zhu, Zhesi
   Wang, Xingzhi
   Lee, Dah-Jye
TI Human pose estimation for low-resolution image using 1-D heatmaps and
   offset regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Heatmap-based regression; 1-D heatmap; Offset
   regression
ID RECOMMENDATION SYSTEM
AB Running a reliable network on resource-limited platforms for a low-resolution image is a great challenge for heatmap-based human pose estimation (HPE). Scale mismatch between the input image and heatmaps and the intrinsic quantization effect induced by the 'argmax' function hinder the performance of heatmap-based human pose estimation for low-resolution image. In this paper, we propose a coordinate-decoupled and offset-revised module (CDORM) to tackle these challenges. The proposed CDORM uses two coordinate-decoupled 1-D heatmaps to supervise the regression process of determining the horizontal and vertical locations of human joints, and employs offset regressing to alleviate the effect of quantization. The CDORM can be integrated with any current heatmap-based HPE network without increasing the size of network significantly. Experimental results on the COCO and MPII datasets show that CDORM helps heatmap-based regression approaches obtain high estimation accuracy from the low-resolution image and only slightly increases the size and runtime of the network.
C1 [Chi, Cailong; Zhang, Dong; Zhu, Zhesi; Wang, Xingzhi] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lee, Dah-Jye] Brigham Young Univ, Dept Elect & Comp Engn, Provo, UT 84602 USA.
C3 Sun Yat Sen University; Brigham Young University
RP Zhang, D (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM chiclong@mail2.sysu.edu.cn; zhangd@mail.sysu.edu.cn;
   zhuzhs@mail2.sysu.edu.cn; wangxzh58@mail2.sysu.edu.cn; djlee@byu.edu
OI Zhang, Dong/0000-0003-0825-3400; wang, xingzhi/0009-0007-5901-8888
FU National Natural Science Foundation of China [62173353]; Guangzhou
   Municipal People's Livelihood Science and Technology Plan
   [201903010040]; Science and Technology Program of Guangzhou, China
   [202007030011]
FX This work was supported by National Natural Science Foundation of China
   (62173353), Guangzhou Municipal People's Livelihood Science and
   Technology Plan (201903010040), Science and Technology Program of
   Guangzhou, China (202007030011).
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fangyun Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P527, DOI 10.1007/978-3-030-58607-2_31
   Feng ZX, 2021, IEEE T IMAGE PROCESS, V30, P6985, DOI 10.1109/TIP.2021.3101158
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guesdon R, 2021, IEEE INT CONF COMP V, P2865, DOI 10.1109/ICCVW54120.2021.00321
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Li K, 2021, PROC CVPR IEEE, P1944, DOI 10.1109/CVPR46437.2021.00198
   Li W., 2019, ARXIV
   Li Y., 2021, ARXIV
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P396, DOI 10.1007/978-3-030-58565-5_24
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nibali A., 2018, arXiv
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Tian L, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107863
   Tian Z., 2019, arXiv
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tompson J, 2014, ADV NEUR IN, V27
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C, 2021, ENG APPL ARTIF INTEL, V102, DOI 10.1016/j.engappai.2021.104260
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yu CQ, 2021, PROC CVPR IEEE, P10435, DOI 10.1109/CVPR46437.2021.01030
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang R, 2019, ARXIV
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
NR 44
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6289
EP 6307
DI 10.1007/s11042-022-13468-w
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400001
DA 2024-07-18
ER

PT J
AU Sun, Z
   Peng, QK
   Mou, X
   Bashir, MF
AF Sun, Zhao
   Peng, Qinke
   Mou, Xu
   Bashir, Muhammad Fiaz
TI Generic and scalable periodicity adaptation framework for time-series
   anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multivariate time series; Convolutional attention-skip network; Periodic
   pattern; Anomaly detection
AB Nowadays, multivariate time series data is increasingly collected in many large-scale application systems, which often has periodic, repetitive patterns that can be affected by advertisements, workdays, holidays, and some user behavior activities. However, existing density and distance-based anomaly detection approaches suffer from detecting anomalies related to periodicity and seasonality. To address this problem, we propose a generic and scalable adaptation framework (GSPAD) for unsupervised anomaly detection in time series with periodic patterns. Our framework mainly consists of a time series predictor and an anomaly detector. Therefore, we present a Convolutional Attention-skip Network (CASNet) as a predictor responsible for predicting both short- and long-term patterns. These two types of patterns are modeled by the CASNet combining the Convolutional Neural Network (CNN) and the Dual Branch Attention-skip Network. Moreover, the proposed anomaly detector can deduce the anomaly according to the severity of the deviations between the actual and predicted values. Compared with other related researches on public datasets, GSPAD shows better performance with an average F-score over 0.76.
C1 [Sun, Zhao; Peng, Qinke; Mou, Xu; Bashir, Muhammad Fiaz] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Syst Engn Inst, Xianning Rd, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Sun, Z (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Syst Engn Inst, Xianning Rd, Xian 710049, Peoples R China.
EM sunzhao@stu.xjtu.edu.cn; qkpeng@xjtu.edu.cn;
   muxu19950916@stu.xjtu.edu.cn; mfiaz1996@gmail.com
OI sun, zhao/0000-0001-6083-593X
FU National Key R&D Program of China [2018YFC0809001]
FX This research is supported by the National Key R&D Program of China
   (2018YFC0809001).
CR Abbasi Raza Abid, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P1120, DOI 10.1007/978-3-030-15035-8_108
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Blázquez-García A, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444690
   Buda TS, 2018, LECT NOTES ARTIF INT, V10937, P577, DOI 10.1007/978-3-319-93034-3_46
   Canizo M, 2019, NEUROCOMPUTING, V363, P246, DOI 10.1016/j.neucom.2019.07.034
   Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Devlin J., 2018, BERT PRE TRAINING DE
   Dudek G, 2015, ADV INTELL SYST COMP, V323, P821, DOI 10.1007/978-3-319-11310-4_71
   Durbin J., 2001, TIME SERIES ANAL STA
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Goldstein M., 2012, KI-2012: poster and demo track, V1, P59, DOI DOI 10.1007/978-3-642-21329-8_4
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang ST, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2129, DOI 10.1145/3357384.3358132
   Kim TY, 2018, EXPERT SYST APPL, V106, P66, DOI 10.1016/j.eswa.2018.04.004
   Kingma D. P., 2014, arXiv
   Kwon D, 2019, CLUSTER COMPUT, V22, P949, DOI 10.1007/s10586-017-1117-8
   Li Z, 2020, IEEE DATA MINING, P1118, DOI 10.1109/ICDM50108.2020.00135
   Liao MZ, 2019, MULTIMED TOOLS APPL, V78, P4155, DOI 10.1007/s11042-017-5384-4
   Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012
   Liu DP, 2015, IMC'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON INTERNET MEASUREMENT CONFERENCE, P211, DOI 10.1145/2815675.2815679
   Liu YZ, 2020, IEEE T ENG MANAGE, V67, P483, DOI 10.1109/TEM.2018.2887118
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mikalef P, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.05.004
   Munir M, 2019, IEEE ACCESS, V7, P1991, DOI 10.1109/ACCESS.2018.2886457
   Munz G., 2007, GI ITG WORKSH MMBNET, P13
   Pecht M. G., 2019, IEEE PROGNOSTICS HLT, P131, DOI 10.1002/9781119515326
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Rathore S, 2018, APPL SOFT COMPUT, V72, P79, DOI 10.1016/j.asoc.2018.05.049
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Turner CJ, 2019, INT J COMPUT INTEG M, V32, P936, DOI 10.1080/0951192X.2019.1667033
   Vaswani A, 2017, ADV NEUR IN, V30
   Wulsin DF, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036015
   Zeng S, 2013, KNOWL INF SYST, V35, P585, DOI 10.1007/s10115-012-0521-x
   Zhang J, 2006, IEEE ICC, P2388
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao Y., 2021, P MACHINE LEARNING S, V3
   Zhou B, 2006, MODELING AND SIMULATION TOOLS FOR EMERGING TELECOMMUNICATION NETWORKS: NEEDS, TRENDS, CHALLENGES AND SOLUTIONS, P101, DOI 10.1007/0-387-34167-6_5
NR 39
TC 1
Z9 1
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2731
EP 2748
DI 10.1007/s11042-022-13304-1
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000820945600004
DA 2024-07-18
ER

PT J
AU Karbalaie, A
   Abtahi, F
   Sjöström, M
AF Karbalaie, Abdolamir
   Abtahi, Farhad
   Sjostrom, Marten
TI Event detection in surveillance videos: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Event detection; Surveillance videos system; Action and activity
   recognition
ID HUMAN ACTIVITY RECOGNITION; BEHAVIOR RECOGNITION; VISUAL SURVEILLANCE;
   ABNORMAL-BEHAVIOR; ANOMALY DETECTION; FRAMEWORK; TRACKING; SYSTEMS;
   MOTION
AB Since 2008, a variety of systems have been designed to detect events in security cameras. There are also more than a hundred journal articles and conference papers published in this field. However, no survey has focused on recognizing events in the surveillance system. Thus, motivated us to provide a comprehensive review of the different developed event detection systems. We start our discussion with the pioneering methods that used the TRECVid-SED dataset and then developed methods using VIRAT dataset in TRECVid evaluation. To better understand the designed systems, we describe the components of each method and the modifications of the existing method separately. We have outlined the significant challenges related to untrimmed security video action detection. Suitable metrics are also presented for assessing the performance of the proposed models. Our study indicated that the majority of researchers classified events into two groups on the basis of the number of participants and the duration of the event for the TRECVid-SED Dataset. Depending on the group of events, one or more models to identify all the events were used. For the VIRAT dataset, object detection models to localize the first stage activities were used throughout the work. Except one study, a 3D convolutional neural network (3D-CNN) to extract Spatio-temporal features or classifying different activities were used. From the review that has been carried, it is possible to conclude that developing an automatic surveillance event detection system requires three factors: accurate and fast object detection in the first stage to localize the activities, and classification model to draw some conclusion from the input values.
C1 [Karbalaie, Abdolamir; Sjostrom, Marten] Mid Sweden Univ, Dept Informat Syst & Technol, SE-85170 Sundsvall, Sweden.
   [Abtahi, Farhad] KTH Royal Inst Technol, Div Ergon, Halsovagen 11C, S-14157 Huddinge, Sweden.
   [Abtahi, Farhad] Karolinska Inst, Unit Occupat Med, Solnavagen 4, SE-11365 Stockholm, Sweden.
C3 Mid-Sweden University; Royal Institute of Technology; Karolinska
   Institutet
RP Karbalaie, A (corresponding author), Mid Sweden Univ, Dept Informat Syst & Technol, SE-85170 Sundsvall, Sweden.
EM abdolamir.karbalie@miun.se
RI Karbalaie, Abdolamir/B-6201-2016
OI Karbalaie, Abdolamir/0000-0001-7320-2306; Sjostrom,
   Marten/0000-0003-3751-6089
FU Mid Sweden University
FX Open access funding provided by Mid Sweden University.
CR Afiq AA, 2019, J VIS COMMUN IMAGE R, V58, P285, DOI 10.1016/j.jvcir.2018.11.035
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Al-fedaghi, 2020, MODELING EVENTS EVEN
   Ameya M., 2012, Proceedings of the 2012 6th European Conference on Antennas and Propagation (EuCAP), P2574, DOI 10.1109/EuCAP.2012.6206542
   [Anonymous], 2012, TUM KITCH DAT SET
   [Anonymous], 2016, HRI TEAM TRECVID 201
   Awad G, 2019, TRECVID 2019 23 INT
   Awad G, 2018, P TRECVID 2018, P1
   Awad G., 2016, Trecvid 2016: Evaluating video search, video event detection, localization, and hyperlinking
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Beigi M, 2018, OBJECT CENTRIC SPATI
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhatt P, 2013, AIP CONF PROC, V1512, P1082, DOI 10.1063/1.4791421
   Bux A, 2017, ADV INTELL SYST COMP, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang Xiaojun, 2019, TRECVID
   Chen J, 2017, IEEE INFOCOM SER
   de Campos TE, 2014, 34 C SOC BRAS COMP C, P1123, DOI DOI 10.1142/S0218213013500309
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Gleason J, 2019, IEEE WINT CONF APPL, P141, DOI 10.1109/WACV.2019.00021
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Hassan M., 2014, J. Image Graph, V2, P28, DOI DOI 10.12720/JOIG.2.1.28-32
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hou, 2017, ARXIV 171201111
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang Y.-G., 2013, THUMOS challenge: Action recognition with a large number of classes
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kay W., 2017, ARXIV170506950
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Ko T, 2008, IEEE APP IMG PAT, P84
   Kong, 2018, HUMAN ACTION RECOGNI, V13
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WH, 2017, IEEE WINT CONF APPL, P187, DOI 10.1109/WACV.2017.28
   Martin A., 1997, P EUR 97 RHOD GREEC, P1895
   Metaxas D, 2013, IMAGE VISION COMPUT, V31, P421, DOI 10.1016/j.imavis.2013.03.005
   Oh S., 2011, 2011 8 IEEE INT C AD, V2, P527
   Onofri L, 2016, EXPERT SYST APPL, V63, P97, DOI 10.1016/j.eswa.2016.06.011
   Over P, 2013, 2013 TREC VIDEO RETR
   Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001
   Phan, 2017, NII HITACHI UIT TREC
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Quenot, 2012, EVALUATION VISUAL IN, P83
   Ramzan M, 2019, IEEE ACCESS, V7, P107560, DOI 10.1109/ACCESS.2019.2932114
   Rana, 2019, ONLINE SYSTEM REAL T
   Ranjan R, 2020, 2018 TREC VIDEO RETR
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rose T., 2009, WORKSHOP APPL COMPUT, P1
   Sangeetha V, 2006, INDIAN J CHEM B, V45, P1951
   Sch, RECOGNIZING HUMAN AC, P3
   Scherp A, 2009, K-CAP'09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P137
   Sharif HU, 2011, EVENT DETECTION VIDE, V1
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255
   Tani MYK, 2017, INT J MULTIMED INF R, V6, P295, DOI 10.1007/s13735-017-0133-z
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Tong W, 2014, MACH VISION APPL, V25, P5, DOI 10.1007/s00138-013-0529-6
   Tripathi RK, 2019, MULTIMED TOOLS APPL, V78, P7585, DOI 10.1007/s11042-018-6472-9
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Tzelepis C, 2016, IMAGE VISION COMPUT, V53, P3, DOI 10.1016/j.imavis.2016.05.005
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xu Jiajun., 2016, APPLYING GROWTH IDEN, P1
   Xu JX, 2015, IEEE T CIRC SYST VID, V25, P1063, DOI 10.1109/TCSVT.2014.2367352
   Yao L, 2018, LECT NOTES COMPUT SC, V11164, P622, DOI 10.1007/978-3-030-00776-8_57
   Yogameena B, 2017, INT J DISAST RISK RE, V22, P95, DOI 10.1016/j.ijdrr.2017.02.021
   Yongqiang Zhao, 2019, 2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS). Proceedings, P428, DOI 10.1109/ICVRIS.2019.00110
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Zablocki M., 2014, Journal of Theoretical and Applied Computer Science, V8, P13
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhao ZC, 2018, NEUROCOMPUTING, V278, P62, DOI 10.1016/j.neucom.2017.04.079
   Zhu YD, 2019, MULTIMED TOOLS APPL, V78, P817, DOI 10.1007/s11042-018-6163-6
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 98
TC 4
Z9 5
U1 10
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35463
EP 35501
DI 10.1007/s11042-021-11864-2
EA JUN 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000815440600001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Yin, MS
   Haddawy, P
   Ziemer, T
   Wetjen, F
   Supratak, A
   Chiamsakul, K
   Siritanakorn, W
   Chantanalertvilai, T
   Sriwichai, P
   Sa-ngamuang, C
AF Yin, Myat Su
   Haddawy, Peter
   Ziemer, Tim
   Wetjen, Fabian
   Supratak, Akara
   Chiamsakul, Kanrawee
   Siritanakorn, Worameth
   Chantanalertvilai, Tharit
   Sriwichai, Patchara
   Sa-ngamuang, Chaitawat
TI A deep learning-based pipeline for mosquito detection and classification
   from wingbeat sounds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mosquitoes; Vector-borne disease; Deep learning; Audio event detection
AB Mosquito vector-borne diseases such as malaria and dengue constitute some of the most serious public health burdens in tropical and sub-tropical countries. Effective targeting of disease control efforts requires accurate estimates of mosquito vector population density. The traditional, and still most common, approach to this involves the use of traps along with manual counting and classification of mosquito species. This process is costly and labor-intensive, which hinders its widespread use. In this paper we present a software pipeline for detection and classification of mosquito wingbeat sounds. Since our target platform is low-cost IoT devices, we explore the tradeoff between accuracy and efficiency. When a fast binary mosquito detector precedes the classifier, we can reduce the computational demand compared with use of the classifier alone by a factor of 10. While the accuracy of traditional machine learning model drops from 90% to 64% when reducing the sample rate from 96 kHz to 8 kHz, our deep-learning models maintain an accuracy of almost 83%, even when additionally reducing the bit depth from 24 to 16 bits. We conclude that the combination of an efficient mosquito detector with a convolutional neural network provides for an excellent trade-off between accuracy and efficiency to detect, classify and count mosquitoes.
C1 [Yin, Myat Su; Haddawy, Peter; Supratak, Akara; Chiamsakul, Kanrawee; Siritanakorn, Worameth; Chantanalertvilai, Tharit; Sa-ngamuang, Chaitawat] Mahidol Univ, Fac ICT, 999 Phuttamonthon 4 Rd, Salaya, Nakhon Pathom, Thailand.
   [Yin, Myat Su; Haddawy, Peter; Ziemer, Tim; Wetjen, Fabian] Univ Bremen, Bremen Spatial Cognit Ctr, Enrique Schmidt Str 5, Bremen, Germany.
   [Sriwichai, Patchara] Mahidol Univ, Fac Trop Med, Bangkok, Thailand.
C3 Mahidol University; University of Bremen; Mahidol University
RP Haddawy, P (corresponding author), Mahidol Univ, Fac ICT, 999 Phuttamonthon 4 Rd, Salaya, Nakhon Pathom, Thailand.
EM myatsu.yin@mahidol.ac.th; peter.had@mahidol.ac.th; ziemer@uni-bremen.de;
   fwetjen@uni-bremen.de; akara.sup@mahidol.ac.th;
   kanrawee.chi@student.mahidol.ac.th; worameth.sir@student.mahidol.ac.th;
   tharit.cha@student.mahidol.ac.th; patchara.sri@mahidol.ac.th;
   chaitawat.chat@gmail.com
RI Sriwichai, Patchara/HGA-8991-2022; Ziemer, Tim/A-9356-2017
OI Ziemer, Tim/0000-0001-6821-7327; Haddawy, Peter/0000-0003-2203-006X
FU Mahidol University Office of International Relations;
   Hanse-Wissenschaftskolleg Institute for Advanced Study; Mahidol
   University
FX This work was partially supported by a grant from the Mahidol University
   Office of International Relations to Haddawy in support of the
   Mahidol-Bremen Medical Informatics Research Unit (MIRU), by a fellowship
   from the Hanse-Wissenschaftskolleg Institute for Advanced Study to Su
   Yin, and by a Young Researcher grant from Mahidol University to Su Yin.
CR Adavanne S, 2017, INT CONF ACOUST SPEE, P771, DOI 10.1109/ICASSP.2017.7952260
   Alar HS, 2021, PROCEDIA COMPUT SCI, V193, P453, DOI 10.1016/j.procs.2021.10.047
   [Anonymous], Teensy 4.0 development board
   Arthur BJ, 2014, J ACOUST SOC AM, V135, P933, DOI 10.1121/1.4861233
   Chen YP, 2014, J INSECT BEHAV, V27, P657, DOI 10.1007/s10905-014-9454-4
   Dombois F, 2011, SONIFICATION HDB, P301
   Fanioudakis E, 2018, EUR SIGNAL PR CONF, P2410, DOI 10.23919/EUSIPCO.2018.8553542
   Fernandes MS, 2021, COMPUT BIOL MED, V129, DOI 10.1016/j.compbiomed.2020.104152
   Genoud AP, 2020, ECOL INFORM, V58, DOI 10.1016/j.ecoinf.2020.101090
   Goodwin A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92891-9
   Göpfert MC, 1999, J EXP BIOL, V202, P2727
   Joshi A, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101241
   Kiskin I, 2021, LECT NOTES ARTIF INT, V12978, P351, DOI 10.1007/978-3-030-86514-6_22
   Kiskin I, 2020, NEURAL COMPUT APPL, V32, P915, DOI 10.1007/s00521-018-3626-7
   Kittichai V, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84219-4
   Lemon SM, 2008, VECTOR BORNE DIS UND, DOI 10.17226/11950
   Lostanlen V, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214168
   Loureiro P, 2019, IEEE CONF COMPUT, P572, DOI [10.1109/infcomw.2019.8845197, 10.1109/INFCOMW.2019.8845197]
   Mauch M, 2014, IEEE INT C ACOUSTICS, DOI DOI 10.1109/ICASSP.2014.6853678
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Morales N, 2007, IEEE SIGNAL PROC LET, V14, P70, DOI 10.1109/LSP.2006.881516
   Motta D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234959
   Mukundarajan H, 2017, ELIFE, V6, DOI 10.7554/eLife.27854
   OFFENHAUSER WH, 1949, J ACOUST SOC AM, V21, P259, DOI 10.1121/1.1906505
   OFFENHAUSER WH, 1965, ACUSTICA, V16, P238
   Okayasu K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183935
   Potamitis I, 2014, ECOL INFORM, V21, P40, DOI 10.1016/j.ecoinf.2013.11.005
   Ravi P., 2016, P 7 ANN S COMP DEV, P3, DOI DOI 10.1145/3001913.3001917
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Saraceno C, 1997, INT CONF ACOUST SPEE, P2597, DOI 10.1109/ICASSP.1997.595320
   Vasconcelos Dinarte, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P43, DOI 10.1145/3462203.3475914
   Vasconcelos D, 2019, CONSUM COMM NETWORK, DOI 10.1109/ccnc.2019.8651767
   Yin MS, 2021, P C INF TECHN SOC GO, P37, DOI DOI 10.1145/3462203.3475908
   Ziemer T., 2020, J ACOUST SOC AM, V148, P2480, DOI DOI 10.1121/1.5146873
   Ziemer T., 2022, Front. Trop. Dis, V3, P803611, DOI [10.3389/fitd.2022.803611, DOI 10.3389/FITD.2022.803611]
NR 35
TC 8
Z9 8
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5189
EP 5205
DI 10.1007/s11042-022-13367-0
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000814042800003
DA 2024-07-18
ER

PT J
AU Huang, XB
   Chen, AB
   Zhou, GX
   Zhang, X
   Wang, JW
   Peng, N
   Yan, N
   Jiang, CH
AF Huang, Xibei
   Chen, Aibin
   Zhou, Guoxiong
   Zhang, Xin
   Wang, Jianwu
   Peng, Ning
   Yan, Na
   Jiang, Canhui
TI Tomato Leaf Disease Detection System Based on FC-SNDPN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant diseases; Disease detection; Image recognition; Deep learning
ID PLANTS
AB In this study, taking the common diseases in tomato leaves, which are typical crops in southern China, as the research object, a FC-SNDPN (Fully Convolutional - Switchable Normalization Dual Path Networks) -based method for automatic identification and detection of crop leaf diseases is proposed to solve the problem that traditional image identification methods for crop diseases and insect pests heavily rely on artificial feature extraction and have a poor generalization ability for image recognition with a complex background. In order to reduce the influence of the complicated background on the recognition of crops diseases and insect pests image, A full convolutional network (FCN) algorithm based on VGG-16 model is used to segment the target crop image. Then an improved DPN (Dual-Path Networks) model is proposed to improve the ability of feature extraction. SNDPN combines the connection method between Desnet and Resnet layers, forms a neural network by using SN layer, and adaptively optimizes the parameters of the dual-path neural network by switching the normalized layer, which improves the versatility of the network for different types of diseases and insect pests and the training speed of the network. Finally, the identification accuracy of the proposed method of using FCN for foreground segmentation and SNDPN for identification is 97.59% on the augmentation data set, the result proves the effectiveness of our method.
C1 [Huang, Xibei; Chen, Aibin; Zhou, Guoxiong; Zhang, Xin; Peng, Ning; Yan, Na] Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Coll Comp & Informat Engn, Changsha, Peoples R China.
   [Huang, Xibei] Hunan Int Econ Univ, Coll Informat & Mech Engn, Changsha, Peoples R China.
   [Chen, Aibin] Cent South Univ Forestry & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha, Peoples R China.
   [Wang, Jianwu] HuangFengQiao State Owned Forest Farm, Youxian, Hunan, Peoples R China.
   [Jiang, Canhui] BJUT, Beijing DubIin Int Coll, Beijing, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Coll Comp & Informat Engn, Changsha, Peoples R China.; Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha, Peoples R China.
EM touchangel@outlook.com; hotaibin@163.com; zhougx01@163.com;
   meetdevin.zh@outlook.com; 274046311@qq.com; 595230772@qq.com;
   1428619434@qq.com; jch3232140645@163.com
RI yan, na/JAC-6056-2023; wang, jianwu/KBB-3546-2024; yan, na/HDM-3747-2022
OI Zhang, Xin/0000-0001-8339-2457; Zhou, Guoxiong/0000-0002-5142-4845
FU China's national 948 program
FX The author would like to thank China's national 948 program for its
   funding. Meanwhile, the author would also like to thank Yang Xiaobo for
   his illustrations and experimental assistance, as well as Yi jizheng, a
   professor at Central South University of Forestry and Technology, for
   some helpful suggestions. The references are arranged according to the
   citations in the paper.
CR Alenyà G, 2013, IEEE ROBOT AUTOM MAG, V20, P50, DOI 10.1109/MRA.2012.2230118
   [Anonymous], 2017, Dual path networks
   [Anonymous], COMPUT VIS PATTERN R
   Belasque J, 2008, APPL OPTICS, V47, P1922, DOI 10.1364/AO.47.001922
   Bharate AA, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P103, DOI 10.1109/ISS1.2017.8389326
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Bravo C, 2004, AGR ENG INT CIGR J S, V6
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Chaerle L, 2007, J PLANT PHYSIOL, V164, P253, DOI 10.1016/j.jplph.2006.01.011
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   El Houby EMF, 2018, J APPL BIOMED, V16, P165, DOI 10.1016/j.jab.2018.01.002
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hughes D, 2015, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1511.08060, DOI 10.48550/ARXIV.1511.08060]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Luo P, 2019, INT C LEARNING REPRE
   Mahmoud MAB, 2020, MULTIMED TOOLS APPL, V79, P26245, DOI 10.1007/s11042-020-09239-0
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Moshou D, 2005, REAL-TIME IMAGING, V11, P75, DOI 10.1016/j.rti.2005.03.003
   Moshou D, 2004, COMPUT ELECTRON AGR, V44, P173, DOI 10.1016/j.compag.2004.04.003
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.75, 10.1109/ICTAI.2016.0078]
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qin JW, 2009, J FOOD ENG, V93, P183, DOI 10.1016/j.jfoodeng.2009.01.014
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang DY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40066-y
   Wang JL, 2013, COMPUT ELECTRON AGR, V96, P23, DOI 10.1016/j.compag.2013.04.014
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wason R, 2018, COGN SYST RES, V52, P701, DOI 10.1016/j.cogsys.2018.08.023
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang M, 2011, PATTERN RECOGN LETT, V32, P2036, DOI 10.1016/j.patrec.2011.08.003
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 50
TC 21
Z9 22
U1 4
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2121
EP 2144
DI 10.1007/s11042-021-11790-3
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000812603300007
DA 2024-07-18
ER

PT J
AU Khosla, T
   Verma, OP
AF Khosla, Tejna
   Verma, Om Prakash
TI An adaptive rejuvenation of bacterial foraging algorithm for global
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptation; Bacterial foraging algorithm; Firefly algorithm;
   Hybridization; Optimization
ID DIFFERENTIAL EVOLUTION; EDGE-DETECTION; FUZZY SYSTEM; HYBRID; SEARCH;
   SWARM
AB Bacterial foraging algorithm (BFA) is a novel nature-inspired algorithm that mimics the social foraging behavior of E. coli. Bacteria. However, it gets stuck in the local optima trap and yields poor convergence in complex landscapes. To improve the exploration-exploitation balance and achieve the global optima quickly, this paper proposes a novel hybrid called the Bacterial foraging algorithm-firefly algorithm (BFA-FA). In this work, two strategies namely adaptive strategy and leadership strategy are applied on conventional BFA. The performance is examined on standard, non-linear and CEC_2017 benchmark functions over several evaluation parameters. The results on benchmark functions show that BFA-FA provides accurate solutions, avoids local optima, works well on multimodal and multidimensional landscapes, and converges faster. It also shows the statistically significant difference among other algorithms. The proposed algorithm is applied on two classical engineering problems to validate its robustness and applicability.
C1 [Khosla, Tejna] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Verma, Om Prakash] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Khosla, T (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM patoditejna@gmail.com; opverma.dce@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X
CR Banerjee S, 2021, MULTIMED TOOLS APPL, V80, P8377, DOI 10.1007/s11042-020-09794-6
   Biswas A, 2007, ADV SOFT COMP, V44, P255
   Chen HN, 2009, CCDC 2009: 21ST CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-6, PROCEEDINGS, P3896, DOI 10.1109/CCDC.2009.5191509
   Chen HN, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1026, DOI 10.1109/ISKE.2008.4731080
   Chen HL, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105884
   Cheng MY, 2014, COMPUT STRUCT, V139, P98, DOI 10.1016/j.compstruc.2014.03.007
   Cheng R., 2017, Benchmark functions for the cec'2017 competition on many-objective optimization
   Chickermane H, 1996, INT J NUMER METH ENG, V39, P829, DOI 10.1002/(SICI)1097-0207(19960315)39:5<829::AID-NME884>3.0.CO;2-U
   Dasgupta S, 2009, IEEE T EVOLUT COMPUT, V13, P919, DOI 10.1109/TEVC.2009.2021982
   Datta T., 2008, Progress In Electromagnetics Research C, V1, P143, DOI 10.2528/PIERC08011705
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Fuad MMM, 2014, PROCEDIA COMPUT SCI, V35, P101, DOI 10.1016/j.procs.2014.08.089
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P245, DOI 10.1007/s00366-012-0308-4
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Hernández-Ocaña B, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2695
   Hollander M., 2013, Nonparametric statistical methods
   Imran AM, 2014, SWARM EVOL COMPUT, V15, P58, DOI 10.1016/j.swevo.2013.12.001
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Khodabakhshian A, 2013, SIMUL-T SOC MOD SIM, V89, P1041, DOI 10.1177/0037549713495741
   Kim DH, 2005, LECT NOTES COMPUT SC, V3528, P231
   Kim DH, 2007, INFORM SCIENCES, V177, P3918, DOI 10.1016/j.ins.2007.04.002
   Kora P, 2020, EVOL SYST-GER, V11, P15, DOI 10.1007/s12530-019-09312-6
   Kora P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1240-z
   Li L, 2015, IEEE ANN INT CONF CY, P127, DOI 10.1109/CYBER.2015.7287922
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Liu Y, 2002, J OPTIMIZ THEORY APP, V115, P603, DOI 10.1023/A:1021207331209
   Majhi R, 2009, EXPERT SYST APPL, V36, P10097, DOI 10.1016/j.eswa.2009.01.012
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mishra S, 2005, IEEE T EVOLUT COMPUT, V9, P61, DOI 10.1109/TEVC.2004.840144
   Nasir ANK, 2012, 2012 12 UK WORKSHOP, P17
   Niu B, 2013, NEUROCOMPUTING, V116, P336, DOI 10.1016/j.neucom.2012.01.044
   Pal Saibal K., 2012, International Journal of Intelligent Systems and Applications, V4, P50, DOI 10.5815/ijisa.2012.10.06
   Ray T, 2001, ENG OPTIMIZ, V33, P735, DOI 10.1080/03052150108940941
   Sadollah A, 2013, APPL SOFT COMPUT, V13, P2592, DOI 10.1016/j.asoc.2012.11.026
   Tan LJ, 2015, NEUROCOMPUTING, V151, P1208, DOI 10.1016/j.neucom.2014.03.082
   Tang KZ, 2017, APPL INTELL, V46, P214, DOI 10.1007/s10489-016-0832-9
   Tripathy M, 2006, LECT NOTES COMPUT SC, V4193, P222
   Tsai JF, 2005, ENG OPTIMIZ, V37, P399, DOI 10.1080/03052150500066737
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Verma OP, 2012, PROC TECH, V1, P315, DOI 10.1016/j.protcy.2012.10.038
   Verma OP, 2013, MULTIDIM SYST SIGN P, V24, P181, DOI 10.1007/s11045-011-0164-1
   Verma OP, 2011, PATTERN RECOGN LETT, V32, P1187, DOI 10.1016/j.patrec.2011.03.008
   Wang DX, 2018, IEEE ACCESS, V6, P65260, DOI 10.1109/ACCESS.2018.2878520
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu G., 2017, Problem definitions and evaluation criteria for the CEC 2017 competition on constrained real-parameter optimization
   Ya-lin T, 2015, VALUE ENG, P11
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zhang M, 2008, INFORM SCIENCES, V178, P3043, DOI 10.1016/j.ins.2008.02.014
   Zhang Q, 2018, IEEE ACCESS, V6, P64905, DOI 10.1109/ACCESS.2018.2876996
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao WG, 2016, INFORM SCIENCES, V329, P719, DOI 10.1016/j.ins.2015.10.001
   Zhou Qiang, 2013, Application Research of Computers, V30, P2629, DOI 10.3969/j.issn.1001-3695.2013.09.018
NR 54
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1965
EP 1993
DI 10.1007/s11042-022-13313-0
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000810821800006
DA 2024-07-18
ER

PT J
AU Yi, DR
   Kong, LH
   Wright, GA
AF Yi, Dingrong
   Kong, Linghua
   Wright, Graham A.
TI Visual-motor control methods for interactive real-time MRI-cardiac
   imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Usability test; Real-time MRI; Interactive scan plane prescription;
   Arm-like mechatronic armature; Plane navigator; Virtual 3D space;
   3D-user interface; 3D manipulation tool
ID VISUALIZATION; GUIDANCE; TRACKING
AB The purpose of this study was to evaluate and compare three kinds of scan plane manipulation tools for real-time magnetic resonance imaging (MRI). The first one was a Line-Projection tool which was clinically used on a General Electric's MRI system (Signa((TM))) in its real-time imaging mode. The second one was called rtViewer, which was a custom designed tri-planner graphical user interface for volumetric image visualization. The third kind, using a Plane Navigator (PN) as a representative, was an arm-like mechanical armature with coordinated 6-degree-of-freedom (DoF) input capability. Two usability experiments were conducted to compare their effects in a simulated interactive MRI setting. Twelve cardiac practitioners were recruited to prescribe diagnostic views of a familiar object, i.e., a beating heart, and to prescribe an unfamiliar object, i.e., a custom designed phantom. Results indicated that the coordinated 6-DoF Plane Navigator outperformed both the Line-Projection tool and rtViewer in terms of task completion time and accuracy for prescribing both simple and complex views, though rtViewer performed best for through plane translation. The Plane Navigator saved about 50% of the time needed by the Line-Projection tool or rtViewer for prescribing unfamiliar double-oblique phantom views. Thanks to its desirable features including coordinated 6-DoF input, rich kinesthetic feedback, visual cue, and stay-put due to its static balance, the Plane Navigator tool may be used to manipulate the scan plane for fast visualization of a dynamic beating heart during real-time cardiac MRI and for the visualization of a surgical tool during an interventional MRI-guided minimum invasive surgery, or for interactive visualization of large-sized volumetric dataset including pre-acquired medical volumetric images.
C1 [Yi, Dingrong] Huaqiao Univ, Coll Mech Engn & Automat, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Kong, Linghua] Fujian Univ Technol, Sch Mech & Automot Engn, 33rd South Xuefu Rd, Fuzhou 350118, Peoples R China.
   [Wright, Graham A.] Sunnybrook Hlth Sci Ctr, Imaging Res, S6-65 Res Bldg,2075 Bayview Ave, Toronto, ON M4N 3M5, Canada.
C3 Huaqiao University; Fujian University of Technology; University of
   Toronto; Sunnybrook Health Science Center; Sunnybrook Research Institute
RP Yi, DR (corresponding author), Huaqiao Univ, Coll Mech Engn & Automat, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
EM yidr@hqu.edu.cn; klh@fjut.edu.cn; gawright@sri.utoronto.ca
RI Yi, Dingrong/Q-5081-2018
OI Yi, Dingrong/0000-0002-6993-6857
FU National Natural Science Foundation of China (NSFC) [51775200]; Digital
   Fujian Industrial Manufacturing IOT Lab
FX This study was sponsored by the National Natural Science Foundation of
   China (NSFC) (grant no. 51775200). Dr. Linghua Kong was also supported
   by the Digital Fujian Industrial Manufacturing IOT Lab. The authors are
   grateful to Dr. Ranjith Kumar Kankala for his proofreading of this
   manuscript.
CR Caputo FM, 2018, COMPUT GRAPH-UK, V74, P225, DOI 10.1016/j.cag.2018.05.019
   Debbins JP, 1996, MAGN RESON MED, V36, P588, DOI 10.1002/mrm.1910360414
   DiMaio S, 2007, LECT NOTES COMPUT SC, V4792, P50
   Gobbi DG, 2003, COMPUT MED IMAG GRAP, V27, P255, DOI 10.1016/S0895-6111(02)00091-5
   Hayward V, 1998, LECT NOTES CONTR INF, V232, P445
   Hernoux F, 2015, VIRTUAL REAL-LONDON, V19, P1, DOI 10.1007/s10055-014-0255-z
   Kerr AB, 1997, MAGNET RESON MED, V38, P355, DOI 10.1002/mrm.1910380303
   Kim HS, 2014, IEEE-ASME T MECH, V19, P1756, DOI 10.1109/TMECH.2014.2308312
   Kim M, 2020, MULTIMED TOOLS APPL, V79, P5941, DOI 10.1007/s11042-019-08324-3
   Krishna, 2005, CURR CARDIOL REP, V7, P7, DOI [10.1007/s11886-005-0003-9, DOI 10.1007/S11886-005-0003-9]
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lo J, 2009, STUD HEALTH TECHNOL, V142, P162, DOI 10.3233/978-1-58603-964-6-162
   Moore JT, 2013, IEEE T BIO-MED ENG, V60, P1034, DOI 10.1109/TBME.2012.2222405
   Paul, 2016, J CARDIOVASC MAGN R, V18, pQ1, DOI [10.1186/1532-429X-18-S1-Q1, DOI 10.1186/1532-429X-18-S1-Q1]
   Perrin DP, 2009, CURR PROB SURG, V46, P730, DOI 10.1067/j.cpsurg.2009.04.001
   Peters TM, 2006, PHYS MED BIOL, V51, pR505, DOI 10.1088/0031-9155/51/14/R01
   Radau PaH, 2004, 12 SCI M EXHIBITION
   Rogers, 2015, J CARDIOVASC MAGN R, V17, pP235, DOI [10.1186/1532-429X-17-S1-P235, DOI 10.1186/1532-429X-17-S1-P235]
   Salerno M, 2017, CIRC-CARDIOVASC IMAG, V10, DOI 10.1161/CIRCIMAGING.116.003951
   Sohns JM., 2013, J CARDIOVASC MAGN R, V15, pE17, DOI [10.1186/1532-429X-15-S1-E17, DOI 10.1186/1532-429X-15-S1-E17]
   Teistler M, 2008, J DIGIT IMAGING, V21, pS2, DOI 10.1007/s10278-007-9025-8
   Voit D, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-79
   Wacker FK, 2004, AM J ROENTGENOL, V183, P391, DOI 10.2214/ajr.183.2.1830391
   Walczak P, 2017, J CEREBR BLOOD F MET, V37, P2346, DOI 10.1177/0271678X16665853
   Xu, 2015, J CARDIOVASC MAGN R, V17, pO24, DOI [10.1186/1532-429X-17-S1-O24, DOI 10.1186/1532-429X-17-S1-O24]
   Yi DR, 2004, LECT NOTES COMPUT SC, V3217, P430
   Zhang Q, 2019, COMPUT MED IMAG GRAP, V72, P34, DOI 10.1016/j.compmedimag.2019.01.004
   Zhang Q, 2011, J DIGIT IMAGING, V24, P640, DOI 10.1007/s10278-010-9321-6
NR 28
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1087
EP 1103
DI 10.1007/s11042-022-13239-7
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809708000001
DA 2024-07-18
ER

PT J
AU Jian, MW
   Wang, RH
   Xu, H
   Yu, H
   Dong, JY
   Li, GF
   Yin, YL
   Lam, M
AF Jian, Muwei
   Wang, Ruihong
   Xu, Hong
   Yu, Hui
   Dong, Junyu
   Li, Gongfa
   Yin, Yilong
   Lam, Kin-Man
TI Robust seed selection of foreground and background priors based on
   directional blocks for saliency-detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Foreground seeds; Background prior; Orientational
   blocks
ID VISUAL SALIENCY; ATTENTION; CONTRAST; SEGMENTATION; MODEL
AB Visual perception modelling of saliency detection has received widespread concerns recently from both the cybernetics and computational intelligence domains. In particular, those distinct background and foreground-oriented models are capable of engendering competitive results. The implicitly vital issue of the above computing approaches is how to reliably choose seeds of the foreground and background cues for kicking off the subsequent saliency-detection procedure. To address this barrier, this paper explores the local geometry and statistical attribute of the detected orientational blocks via an improved discrete wavelet frame transform algorithm to estimate the center position of individual salient object in the original input. Specially, the calculated centroid can be regarded as the prominent focus of visual perception in the initial image, which is beneficial to choose the credible seed during the computing of the superpixel-based foreground and background cues. Then, both sides of the complementary and visually oriented cues are integrated concurrently into a dependable and robust saliency map with reliability. Substantial experimental evaluations in term of freely open-access databases testify the effectiveness of the designed framework, and have prove that the designed algorithm is accurate and outperforms the other distinct representative saliency detection algorithms.
C1 [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Jian, Muwei] Linyi Univ, Sch Informat Sci & Engn, Linyi, Peoples R China.
   [Jian, Muwei; Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   [Wang, Ruihong; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Xu, Hong] Shandong Inst Commerce & Technol, Jinan 250103, Peoples R China.
   [Xu, Hong; Yin, Yilong] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Li, Gongfa] Wuhan Univ Sci & Technol, Key Lab Met Equipment & Control Technol, Wuhan, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Shandong University of Finance & Economics; Linyi University; University
   of Portsmouth; Ocean University of China; Shandong Institute of Commerce
   & Technology; Shandong University; Wuhan University of Science &
   Technology; Hong Kong Polytechnic University
RP Yu, H (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.; Xu, H (corresponding author), Shandong Inst Commerce & Technol, Jinan 250103, Peoples R China.; Xu, H (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
EM xuhonglele@163.com; hui.yu@port.ac.uk
RI Jian, Muwei/Q-8319-2018; Yu, Hui/G-1115-2018
OI Yu, Hui/0000-0002-7655-9228
FU National Natural Science Foundation of China (NSFC) [61976123, 61601427,
   61876098]; Taishan Young Scholars Program of Shandong Province; Royal
   Society -K. C. Wong International Fellowship [NIF\R1\180909]; Key
   Development Program for Basic Research of Shandong Province [ZR2020ZD44]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61976123, 61601427, 61876098); the Taishan Young Scholars
   Program of Shandong Province; Royal Society -K. C. Wong International
   Fellowship (NIF\R1\180909); and Key Development Program for Basic
   Research of Shandong Province (ZR2020ZD44).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Cai X, 2017, P SPIE 9 INT C GRAPH
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cholakkal H., 2015, BMVC
   Deng T, 2016, IEEE T INTELL TRANSP, V17, P2051, DOI 10.1109/TITS.2016.2535402
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J., 2006, ADV NEURAL INF PROCE
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang K, 2018, IEEE IMAGE PROC, P2341, DOI 10.1109/ICIP.2018.8451046
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian M, 2019, APSIPA797801
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2020, MULTIMED TOOLS APPL, V79, P33467, DOI 10.1007/s11042-019-07842-4
   Jian MW, 2020, IEEE T MULTIMEDIA, V22, P970, DOI 10.1109/TMM.2019.2937187
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Li L, 2018, NEUROCOMPUTING, V301, P46, DOI 10.1016/j.neucom.2018.03.049
   Li Z, 2018, J VIS COMMUN IMAGE R, V50, P16, DOI 10.1016/j.jvcir.2017.11.004
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu ZX, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820744
   Ma YF, 2003, P 11 ACM INT C MULT
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mazza V, 2005, PSYCHOL RES-PSYCH FO, V69, P201, DOI 10.1007/s00426-004-0174-9
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Oszust M, 2019, INFORM SCIENCES, V482, P334, DOI 10.1016/j.ins.2019.01.034
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Wang GD, 2019, MULTIMED TOOLS APPL, V78, P29007, DOI 10.1007/s11042-018-6294-9
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhai Y., 2006, ACM Multimedia, P815824
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 54
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 427
EP 451
DI 10.1007/s11042-022-13125-2
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806706600003
DA 2024-07-18
ER

PT J
AU Pritom, AI
   Al Mashuk, MA
   Ahmed, S
   Monira, N
   Islam, MZ
AF Pritom, Ahmed Iqbal
   Al Mashuk, Md Abdullah
   Ahmed, Somi
   Monira, Nazifa
   Islam, Md Zahidul
TI GESTCHA: a gesture-based CAPTCHA design for smart devices using angular
   velocity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; Gesture recognition; Angular velocity; Gyroscope sensor;
   Feature extraction; Web security; Ratio over sum; Human computer
   interaction
ID EFFICIENT
AB The "Completely Automated Public Turing test to Tell Computers and Human Apart" (CAPTCHA) is a standard security protocol, wildly used to distinguish between human and malicious computer program, known as bot. This paper presents a gesture-based CAPTCHA system i.e. GESTCHA utilizing angular velocity data from embedded gyroscope sensors of handheld touch-sensitive devices. The angular velocity data collected within a short exposure of time was processed as gesture input. Several discriminatory feature sets were extracted from stable gyroscope reading by applying a newly proposed gesture feature extraction algorithm. We analyzed the performance of two different machine learning algorithms, i.e. Naive Bayes and Random Forest, over the training gesture pattern which led to the development of a robust gesture recognition model. Using the model, final prototype of GESTCHA was proposed. Based on findings from a comparative usability study with 850 participants, GESTCHA shows significant improvement in terms of solving rate and solving time compared to Google's reCAPTCHA v3 i.e. NoCAPTCHA.
C1 [Pritom, Ahmed Iqbal] Islamic Univ Technol, Dept Comp Sci & Engn, Gazipur, Bangladesh.
   [Al Mashuk, Md Abdullah; Ahmed, Somi; Monira, Nazifa; Islam, Md Zahidul] Green Univ Bangladesh, Dept Comp Sci & Engn, Dhaka, Bangladesh.
RP Pritom, AI (corresponding author), Islamic Univ Technol, Dept Comp Sci & Engn, Gazipur, Bangladesh.
EM pritom@iut-dhaka.edu; mashuk.cse.gub@gmail.com; somiislam8@gmail.com;
   nazifa.monira@gmail.com; zahid@cse.green.edu.bd
RI Islam, Zahid/AAN-1431-2021
OI Islam, Zahid/0000-0002-9209-9524
CR Acien A, 2020, ARXIV 200200918
   Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Aiken W, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P797, DOI 10.1145/3196494.3201581
   Aldwairi M, 2020, J PARALLEL DISTR COM, V142, P27, DOI 10.1016/j.jpdc.2020.03.020
   Alqahtani FH, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101635
   Amelio A, 2019, INFORMATION, V10, DOI 10.3390/info10070221
   [Anonymous], 2014, International Journal of Computer Science and Information Technologies
   [Anonymous], 2016, BLACK HAT
   Arsic S, 2021, MULTIMED TOOLS APPL, V80, P9393, DOI 10.1007/s11042-020-10054-w
   Azad S, 2013, GLOB J COMPUT SCI TE
   Bai YT, 2020, ISA T, V101, P430, DOI 10.1016/j.isatra.2020.01.030
   Bursztein E., 2014, P 8 USENIX WORKSH OF
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Chen J, 2019, IEEE ACCESS, V7, P22246, DOI 10.1109/ACCESS.2019.2899044
   Chu YC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186507
   Conti M, 2016, LECT NOTES COMPUT SC, V9696, P611, DOI 10.1007/978-3-319-39555-5_33
   Dudheria Rishabh, 2018, International Journal of Computer Network and Information Security, V10, P23, DOI 10.5815/ijcnis.2018.07.03
   Dwivedi Utkarsh., 2017, P 22 INT C INTELLIGE, P53, DOI [10.1145/3030024.3038266, DOI 10.1145/3030024.3038266]
   Ferrari A, 2019, LECT NOTES COMPUT SC, V11912, P357, DOI 10.1007/978-3-030-34255-5_28
   Fidas CA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2623
   Gao S, 2015, P 31 ANN COMP SEC AP, P1120
   Google, REC V2 REC GOOGL DEV
   Google, REC EAS HUM HARD BOT
   Haichang Gao, 2010, Proceedings 2010 IEEE 13th International Conference on Computational Science and Engineering (CSE 2010), P351, DOI 10.1109/CSE.2010.53
   Han H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112562
   Jiang N, 2015, BRITISH HCI 2015, P202, DOI 10.1145/2783446.2783578
   Kheshaifaty N, 2020, INT J COMPUT SCI NET, V20, P16, DOI 10.22937/IJCSNS.2020.20.09.3
   Kluever KA, 2009, P 5 S US PRIV SEC SO, P111
   Li CH, 2021, NEUROCOMPUTING, V433, P223, DOI 10.1016/j.neucom.2020.11.057
   [李秋洁 Li Qiujie], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P469
   Ogiela MR, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4769
   Osadchy M, 2017, IEEE T INF FOREN SEC, V12, P2640, DOI 10.1109/TIFS.2017.2718479
   Ouyang ZY, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2021.102178
   Pakdel R., 2011, RES J INFORM TECHNOL, V3, P215, DOI DOI 10.3923/rjit.2011.215.228
   Parvez MT, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101829
   Pritom Ahmed Iqbal, 2020, ICSCA 2020: Proceedings of the 2020 9th International Conference on Software and Computer Applications, P351, DOI 10.1145/3384544.3384584
   Reynaga G, 2013, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY (SECRYPT 2013), P427
   Shah Abdul Rouf, 2021, Advances in Computational Intelligence and Communication Technology. Proceedings of CICT 2019. Advances in Intelligent Systems and Computing (AISC 1086), P381, DOI 10.1007/978-981-15-1275-9_31
   Shirali-Shahreza S., 2013, P SIGCHI C HUM FACT, P2147
   Tootaghaj DZ, 2017, ARXIV 171009441
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   Wang P, 2020, IEEE ACCESS, V8, P59044, DOI 10.1109/ACCESS.2020.2982945
   Wu YH, 2016, IEEE SENS J, V16, P7753, DOI 10.1109/JSEN.2016.2599019
   Xie RQ, 2016, IEEE SENS J, V16, P4537, DOI 10.1109/JSEN.2016.2546942
   Xu RZ, 2012, IEEE SENS J, V12, P1166, DOI 10.1109/JSEN.2011.2166953
   Xu Y, 2012, 21 USENIX SEC S USEN, P4964
   Yang XC, 2018, IEEE T NEUR SYS REH, V26, P1199, DOI 10.1109/TNSRE.2018.2829913
NR 47
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 521
EP 549
DI 10.1007/s11042-022-13272-6
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806706600002
DA 2024-07-18
ER

PT J
AU Babu, GH
   Venkatram, N
AF Babu, Harish G.
   Venkatram, N.
TI An efficient image dahazing using Googlenet based convolution neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hazy image; CNN; GoogleNet; Dehazing; Deep learning
ID CONTRAST RESTORATION; WEATHER; HAZE
AB The dehazing is a significant colour image-processing technique for attaining a high quality of images from haze images. Now a day's digital cameras are playing an important key role in many applications, such as scanning, HD image generation, traffic user, tourists, especially in hilly areas satellite and radar applications. The dehazing is a complex function for digital cameras since it converts a bayers mosaic image into a final color image and then estimates the output image. The full colour image cannot be reconstructed from incomplete samples due to haze problem, and hence appropriate dehazing models are implemented to overcome this problem. In this work, a dehazing algorithm is proposed with GoogleNet deep learning mechanism for getting the improved quality of the image. In this investigation, GoogleNet deep learning model is used to reconstruct the full color image without degrading the sensitivity and resolution. In this proposed work, the deep learning based convolutional networks are realized using demosaicking for pre-processing to reproduce the dehaged full color images from the incomplete samples. In this demosaicking task, the first step is demosaicking to produce a rough image consists of unwanted color artifacts. Second step is the refining step, in which, the deep residual estimation is used to decrese the color artifacts along with the multi model fusion concept to produce good quality output images. The performance measures, viz., Peak-Signal to Noise Ratio (PSNR), Structural similarity Index (SSIM), and Mean Square Error (MSE) are evaluated and compared with existing models. The PSNR is 32.78, SSIM is 0.9412, MSE is 0.098, F1-score is 0.989, sensitivity is 0.972, and CC is 0.978 have been attained by this optimized algorithm. The GoogleNet technology outperforms the existing methods. This deep learning mechanism does process the input hazy images and decomposes the smoothness hazy free elements from texture elements.
C1 [Babu, Harish G.] Koneru Laskshmaiah Educ Fdn, Dept ECE, Guntur, Andhra Pradesh, India.
   [Babu, Harish G.] CVR Coll Engn, Dept ECE, Hyderabad, India.
   [Venkatram, N.] Koneru Lakshmaiah Educ Fdn, Dept Elect & Comp Engn, Guntur, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Babu, GH (corresponding author), Koneru Laskshmaiah Educ Fdn, Dept ECE, Guntur, Andhra Pradesh, India.; Babu, GH (corresponding author), CVR Coll Engn, Dept ECE, Hyderabad, India.
EM harish.sidhu12@gmail.com
RI GADE, Dr HARISH BABU/AAU-8202-2020
OI GADE, Dr HARISH BABU/0000-0001-7496-5946
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Berman D, 2016, P IEEE C COMPUTER VI
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He LY, 2017, IEEE T IMAGE PROCESS, V26, P1063, DOI 10.1109/TIP.2016.2644267
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Lin Z., 2012, Open J. Appl. Sci, V2, P123
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Minaei S, 2022, INT J SPORT NUTR EXE, V32, P16, DOI 10.1123/ijsnem.2021-0090
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Negru M, 2015, IEEE T INTELL TRANSP, V16, P2257, DOI 10.1109/TITS.2015.2405013
   Raj RJS, 2020, IEEE ACCESS, V8, P58006, DOI 10.1109/ACCESS.2020.2981337
   Ren W., 2016, EUROPEAN C COMPUTER
   Sandeep M., 2014, INT J RES STUD COMPU, V1, P44
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tan DS, 2018, IEEE T IMAGE PROCESS, V27, P2408, DOI 10.1109/TIP.2018.2803341
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 29
TC 5
Z9 5
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43897
EP 43917
DI 10.1007/s11042-022-13222-2
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802892700001
DA 2024-07-18
ER

PT J
AU Kumar, V
   Gaur, M
AF Kumar, Vinay
   Gaur, Manish
TI Multiple forgery detection in video using inter-frame correlation
   distance with dual-threshold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensic; Forgery detection; Correlation coefficient; Video
   authentication; Video processing
ID DUPLICATION FORGERY; DOUBLE COMPRESSION; LOCALIZATION; DELETION
AB Video forgery can be defined as the modification of the video contents. The alteration of the video by deletion and modification in the sequence of frames is a trivial task, which has made the authentication and originality detection more important. Frame insertion and deletion are the most common type of video forgery. The proposed method can identify these types of forgery along with its forged location, which makes this unique method. It defines the relationship between the adjacent frames using the correlation coefficient, finds the inter-frame correlation distance between the frames, calculates the minimum distance score, statistical features, and computes upper-bound, lower-bound threshold and sigma coefficient for the identification of forgery location. The proposed method defines insertion and deletion type forgery by using threshold controlled parameters and it is validated on the VIFFD dataset. The proposed method has also identified forgery with 97% accuracy at the frame level and 83% accuracy at the video level. The result analysis shows the superiority of the proposed method over the existing methods. This method is very effective in identifying the forgery type with its frame location.
C1 [Kumar, Vinay; Gaur, Manish] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
   [Kumar, Vinay] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); GLA University
RP Kumar, V (corresponding author), Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.; Kumar, V (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM vinay.kumar@cas.res.in; manish.gaur@ietlucknow.ac.in
OI Gaur, Manish/0000-0002-4161-2789; kumar, vinay/0000-0001-7060-7586
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Baghel N, 2020, ARXIV PREPRINT ARXIV
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Guo-Shiang Lin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P1396, DOI 10.1109/ICCSE.2011.6028891
   Huang TQ, 2018, COMPUT SECUR, V77, P412, DOI 10.1016/j.cose.2018.04.013
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1763, DOI 10.1007/s11277-020-07126-3
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Kumar V., 2014, International Journal of Computational Vision and Robotics, P349
   Kumar V., 2021, RECENT STUDIES COMPU
   Luo WQ, 2008, PROC SPIE, V6819, DOI 10.1117/12.767112
   Nguyen X.H, 2020, VIFFD-A dataset for detecting video inter-frame forgeries
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Sharma H, 2021, J COMPUT SECUR, V29, P531, DOI 10.3233/JCS-200105
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Su Y, 2010, INT WORKSHOP INTELLI
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wu YX, 2014, INT CONF ACOUST SPEE
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
NR 31
TC 6
Z9 6
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43979
EP 43998
DI 10.1007/s11042-022-13284-2
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802134900003
DA 2024-07-18
ER

PT J
AU Qiu, LJ
   Zhao, WZ
   Liu, XZ
AF Qiu, Lijian
   Zhao, Wenzheng
   Liu, Xuezhi
TI Does subtitle size in teaching video influence learning outcomes?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Teaching video; Subtitle size; Learning results; Learning satisfaction
ID COGNITIVE LOAD; CAPTIONS
AB Learning through video is an important learning method at present. In various teaching videos, subtitle size varies greatly. Therefore, it is essential to evaluate the influence of subtitle size on different teaching videos. In this paper, 90 college students from a Chinese University were randomly divided into three groups: small subtitle teaching video group, middle subtitle teaching video group and large subtitle teaching video group. The experiment was conducted to explore the effect of subtitle size on learners' cognitive load, academic performance, and learning satisfaction. The results showed that: (1) compared with the large subtitle teaching video, learners had lower cognitive load when watching small and medium subtitles teaching videos; (2) compared with the large subtitle teaching video, the learners who watched the small subtitle teaching video had better performance; (3) compared with the large subtitle teaching video, the learners who watched the small and medium subtitle teaching video had higher learning satisfaction. Based on these results, this paper emphasizes the importance of subtitle size in teaching video. We suggest that the relevant departments should further refine the production standards of teaching videos; teachers should try to make teaching videos with smaller subtitles; students should choose teaching videos with smaller subtitles; researchers and technical teams should strengthen the research and development of personalized subtitle technology, so as to allow the private customization of subtitle size based on learners' needs and preferences.
C1 [Qiu, Lijian; Liu, Xuezhi] Northeast Normal Univ, Fac Educ, Changchun 130024, Peoples R China.
   [Zhao, Wenzheng] Shaanxi Normal Univ, Fac Educ, 199 Changan South Rd, Xian 710062, Peoples R China.
C3 Northeast Normal University - China; Shaanxi Normal University
RP Zhao, WZ (corresponding author), Shaanxi Normal Univ, Fac Educ, 199 Changan South Rd, Xian 710062, Peoples R China.
EM zhaowenzheng2004@126.com
CR Ashtiani F.T., 2017, International Journal of Applied Linguistics and English Literature, V6, P122, DOI DOI 10.7575/AIAC.IJALEL.V.6N.7P.122
   Bernard M., 2001, CHI 01 HUM FACT COMP, P175, DOI [DOI 10.1145/634067.634173, https://doi.org/10.1145/634067.634173, 10.1145/634164.634173, DOI 10.1145/634164.634173]
   Carmichael M., 2018, Assessing the impact of educational video on student engagement, critical thinking and learning
   Chen MP, 2022, COMPUT ASSIST LANG L, V35, P381, DOI 10.1080/09588221.2019.1704787
   Choi HJ, 2005, AM J DISTANCE EDUC, V19, P215, DOI 10.1207/s15389286ajde1904_3
   Crabb M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P215, DOI 10.1145/2700648.2809866
   Cunyou, 2015, CHINA DISTANCE ED, V12, P61
   Cunyou W, 2018, CHINA ED INFORM, V24, P59
   Cunyou Wang, 2016, E ED RES, V37, P59
   Department of higher education Ministry of education., TECHN STAND SHOOT MA
   DYdewalle G., 1987, Eye Movements: From Physiology to Cognition, P313, DOI [DOI 10.1016/B978-0-444-70113-8.50047-3, 10.1016/B978-0-444-70113-8.50047-3]
   García B, 2017, COMPUT APPL ENG EDUC, V25, P468, DOI 10.1002/cae.21814
   Gengsheng X., 2020, MOD ED TECHNOL, V30, P81
   Greco GM, 2016, PALGR STUD TRANSL, P11, DOI 10.1057/978-1-137-56917-2_2
   Ho CL, 2010, COMPUT EDUC, V55, P858, DOI 10.1016/j.compedu.2010.03.017
   Jamet E, 2007, CONTEMP EDUC PSYCHOL, V32, P588, DOI 10.1016/j.cedpsych.2006.07.001
   Jian W., 2014, AUDIO VIS ED RES, V35
   Jung Y, 2018, COMPUT EDUC, V122, P9, DOI 10.1016/j.compedu.2018.02.013
   Kalyuga S, 2012, EDUC RES REV-NETH, V7, P145, DOI 10.1016/j.edurev.2011.12.002
   Karakas A.Saricoban., 2012, Teaching English with Technology, V12, P3
   KARAMITROGLOU F., 1998, TRANSLATION J, V2
   Kirkland CE, 1999, AM ANN DEAF, V144, P250, DOI 10.1353/aad.2012.0140
   Leveridge AN, 2014, COMPUT ASSIST LANG L, V27, P545, DOI 10.1080/09588221.2013.776968
   Li, 1997, TV SUBTITLES SPECIAL, V02, P23
   Manchón LM, 2018, TRANSL SPACES, V7, P263, DOI 10.1075/ts.18016.man
   Mayer R. E., 2020, Multimedia Learning, V3rd
   Mayer RE, 2003, WEB-BASED LEARNING: WHAT DO WE KNOW? WHERE DO WE GO?, P23
   Montagud M, 2020, MULTIMED TOOLS APPL, V79, P21889, DOI 10.1007/s11042-020-08955-x
   Ni Z, 2021, RES AUDIO VISUAL ED, V42, P85
   Ovharhe O. J., 2020, International Journal of Agricultural Technology, V16, P1463
   Ozcelik E, 2009, COMPUT EDUC, V53, P445, DOI 10.1016/j.compedu.2009.03.002
   PAAS FGWC, 1994, PERCEPT MOTOR SKILL, V79, P419, DOI 10.2466/pms.1994.79.1.419
   Perez MM, 2019, LANG LEARN J, V47, P460, DOI 10.1080/09571736.2019.1638623
   Pujadas G, 2019, LANG LEARN J, V47, P479, DOI 10.1080/09571736.2019.1616806
   Ritzhaupt AD, 2015, COMPUT HUM BEHAV, V45, P222, DOI 10.1016/j.chb.2014.12.020
   Roshier AL, 2011, BMC MED EDUC, V11, DOI 10.1186/1472-6920-11-1
   Rudd RE, 2007, AM J HEALTH BEHAV, V31, pS8
   Sears Taylor Peplau, 2004, SOC PSYCHOL-GERMANY, P296
   Shouju C, 2007, MEDIA ART DESIGN, P47
   Shu H, 2011, ATTEN PERCEPT PSYCHO, V73, P482, DOI 10.3758/s13414-010-0029-y
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Sweller J, 2011, LECT NOTES ARTIF INT, V6738, P5, DOI 10.1007/978-3-642-21869-9_3
   Szarkowska A, 2019, PERSPECT STUD TRANSL, V27, P144, DOI 10.1080/0907676X.2018.1520267
   Teng F, 2022, COMPUT ASSIST LANG L, V35, P518, DOI 10.1080/09588221.2020.1720253
   Ting, 2006, J HENAN RADIO TV U, V03, P59
   Tisdell C, 2017, INT J MATH EDUC SCI, V48, P229, DOI 10.1080/0020739X.2016.1238518
   Utray F, 2010, 2010 LISTENING SUBTI, P59
   Wenjing, 2018, CHINA ED TECHNOL, V04, P66
   Xiaoqing X., 2017, CHINA 501 ED, V05
   Yang Y, 2019, CHINA ED TECHNOL, V8, P123
   Yuan, 2004, HEILONGJIANG ED MIDD, V35, P4
   Yuxiang, 1994, AUDIO VIS ED, V03, P33
NR 52
TC 0
Z9 0
U1 8
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43253
EP 43266
DI 10.1007/s11042-022-13212-4
EA MAY 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800827500001
DA 2024-07-18
ER

PT J
AU Huo, G
   Lin, DW
   Yuan, M
AF Huo, Guang
   Lin, Dawei
   Yuan, Meng
TI Iris segmentation method based on improved UNet plus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris segmentation; Iris recognition; CNNs; UNet plus plus
ID RECOGNITION
AB With the increasing demand for identity authentication, iris recognition systems are gradually applied in various scenarios. Iris segmentation is the basis of the iris recognition system. Iris images taken in non-ideal situations contain much irrelevant noise. In addition, the quality of iris images varies greatly under different shooting conditions. These factors seriously affect the accuracy of iris segmentation. However, traditional algorithms are not adaptable enough, and the algorithms based on convolutional neural networks (CNNs) are not efficient enough. Inspired by the success of U-shaped network++ (UNet++) in image segmentation, in this paper, an end-to-end encoder-decoder model based on improved UNet++ is proposed to perform the iris segmentation, referred to as Attention Mechanism UNet++ (AM-UNet++). The main contributions are as follows: firstly, EfficientNetV2 is selected as convolutional blocks of UNet++ to improve training speed and reduce the number of network parameters. Secondly, an attention module is embedded into the down-sampling process of UNet++ to suppress irrelevant noise interference and strengthen the ability to learn the discriminability of the iris region. Finally, the algorithm adopts a pruning scheme to get four different performance networks, which can meet the needs of iris recognition in multiple scenarios. The experimental results on two near-infrared illumination iris databases and one visible light illumination iris database demonstrate that the method has good iris segmentation ability and generalization performance. The iris segmentation accuracy and efficiency of the proposed method are higher than the state-of-the-art fusion method.
C1 [Huo, Guang; Lin, Dawei] Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Peoples R China.
   [Yuan, Meng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Northeast Electric Power University; Jilin University
RP Lin, DW (corresponding author), Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Peoples R China.
EM da_wei_lin@126.com
RI Lin, Dawei/GQQ-5561-2022
OI Lin, Dawei/0000-0001-6788-4566
FU Science and technology project of the Jilin Provincial Education
   Department [JJKH20220118KJ]
FX This research was supported by the Science and technology project of the
   Jilin Provincial Education Department under Grant No. JJKH20220118KJ.
CR Ahmad S, 2019, LECT NOTES COMPUT SC, V11367, P450, DOI 10.1007/978-3-030-21074-8_36
   Bazrafkan S, 2018, NEURAL NETWORKS, V106, P79, DOI 10.1016/j.neunet.2018.06.011
   Bhadauria HS, 2014, SIGNAL IMAGE VIDEO P, V8, P357, DOI 10.1007/s11760-012-0298-0
   Bhadauria NS, 2021, INT J SYST ASSUR ENG, V12, P1296, DOI 10.1007/s13198-021-01269-7
   [陈功 Chen Gong], 2004, [华东理工大学学报. 自然科学版, Journal of East China University of Science and Technoloy.Natural Sciences Edition], V30, P230
   Chen Y, 2019, IEEE ACCESS, V7, P64517, DOI 10.1109/ACCESS.2019.2917153
   Chinese Academy of ScienceInstitute of Automation, CASIA IRIS V4 IR IM
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Fernando AF, 2012, IEEE 5 INT C BIOMETR, P426, DOI [10.1109/BTAS.2012.6374610, DOI 10.1109/BTAS.2012.6374610]
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Jalilian E, 2017, ADV COMPUT VIS PATT, P133, DOI 10.1007/978-3-319-61657-5_6
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Lian S, 2018, J VIS COMMUN IMAGE R, V56, P296, DOI 10.1016/j.jvcir.2018.10.001
   Liu J, 2010, INT CONF COMP SCI, P145, DOI 10.1109/ICCSIT.2010.5563638
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lozej J, 2018, 2018 IEEE INT WORK C, P16, DOI [DOI 10.1109/IWOBI.2018.8464213, 10.1109/IWOBI.2018.8464213]
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Othman N, 2016, BIOMETRIC REFERENCE
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Rathgeb C., 2013, COMPUT REV, V54, P672, DOI DOI 10.1007/978-1-4614-5571-4
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Ryan WJ, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P54
   Tan CW, 2012, IEEE T IMAGE PROCESS, V21, P4068, DOI 10.1109/TIP.2012.2199125
   Tan M, 2021, ARXIV210400298V3
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P283, DOI 10.1109/ICB.2012.6199821
   Uhl A, 2012, LECT NOTES COMPUT SC, V7325, P1, DOI 10.1007/978-3-642-31298-4_1
   Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059
   Wang Q, 2022, VISUAL COMPUT, V38, P2591, DOI 10.1007/s00371-021-02134-1
   Wild P, 2015, INT CONF BIOMETR, P31, DOI 10.1109/ICB.2015.7139072
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yin XY, 2003, ANN BOT-LONDON, V91, P361, DOI 10.1093/aob/mcg029
   You XAN, 2022, LASER OPTOELECTRON P, V59, DOI 10.3788/LOP202259.0410006
   Zhang W, 2019, IEEE ACCESS, V7, P85082, DOI 10.1109/ACCESS.2019.2924464
   Zhou Ruiye, 2021, Computer Engineering and Applications, V57, P223, DOI 10.3778/j.issn.1002-8331.2005-0068
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 44
TC 10
Z9 10
U1 11
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41249
EP 41269
DI 10.1007/s11042-022-13198-z
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797298300002
DA 2024-07-18
ER

PT J
AU Hwang, S
   Jeon, S
   Ma, YS
   Byun, H
AF Hwang, Sunhee
   Jeon, Seogkyu
   Ma, Yu-Seung
   Byun, Hyeran
TI WeatherGAN: Unsupervised multi-weather image-to-image translation via
   single content-preserving UResNet generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-to-image translation; Data augmentation; Generative model;
   Adversarial learning
AB In this paper, we propose an unsupervised and unified multi-domain Image-to-Image translation model for an image weather domain translation. Most existing multi-domain Image-to-Image translation methods are capable of translating fine details such as facial attributes. However, the image translation model between multiple weather domains, e.g., sunny-to-snowy, or sunny-to-rainy, have to consider the large domain gap. To address the challenging problem, in this paper, we propose WeatherGAN based on a proposed UResNet generator. Our model consists of the UResNet generator, a PatchGAN discriminator, and a VGG perceptual encoder. UResNet is a combined model of U-Net and ResNet to address the ability of each model, that preserve input context information and generate realistic images. The PatchGAN discriminator encourages the generator to produce realistic images of the target domain by criticizing patch-wise details. We also leverage VGG perceptual encoder as a loss network, which guides the generator to minimize the perceptual distance between an input image and generated images to enhance the quality of outputs. Through the extensive experiments on Alps, YouTube driving (our benchmark dataset), and BDD datasets, we demonstrate that WeatherGAN produces more satisfactory results of the target domain compared to the baselines. Besides, we also conduct a data augmentation task to show the usability of our generated images by WeatherGAN, and it shows the overall object detection performance of YOLO v3 is improved in our results on BDD dataset.
C1 [Hwang, Sunhee; Jeon, Seogkyu; Byun, Hyeran] Yonsei Univ, Seoul, South Korea.
   [Hwang, Sunhee] LG Uplus, Seoul, South Korea.
   [Ma, Yu-Seung] Elect & Telecommun Res Inst, Daejeon, South Korea.
C3 Yonsei University; Electronics & Telecommunications Research Institute -
   Korea (ETRI)
RP Byun, H (corresponding author), Yonsei Univ, Seoul, South Korea.
EM sunny16@yonsei.ac.kr; jone9312@yonsei.ac.kr; ysma@etri.re.kr;
   hrbyun@yonsei.ac.kr
RI Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Ma, Yu-Seung/0000-0002-4168-5515
FU National Research Foundation of Korea - Korea government (MSIT)
   [2022R1A2B5B02001467]; Institute for Information & Communications
   Technology Planning & Evaluation (IITP) - Korea government
   [2018-0-00769, 2020-0-01361]
FX This project was partly supported by the National Research Foundation of
   Korea grant funded by the Korea government (MSIT) (No.
   2022R1A2B5B02001467) and the Institute for Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (No.2018-0-00769: Neuromorphic Computing Software Platform
   for Artificial Intelligence Systems, No. 2020-0-01361: Artificial
   Intelligence Graduate School Program (YONSEI UNIVERSITY)).
CR Anoosheh A, 2018, 2018 IEEECVF C COMPU
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bikowski M., 2018, INT C LEARN REPR
   Chen Q, 2017, IEEE INT C COMPUTER
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Choi Y, 2018, 2018 IEEECVF C COMPU
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, ADV NEURAL INFORM PR
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hensel M, 2017, ADV NEUR IN, V30
   Hoffman J, ARXIV 171103213
   Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145
   Huang X, 2018, P EUR C COMP VIS ECC
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isokane T, 2018, IEEE C COMPUTER VISI
   Isola P, 2017, 2017 IEEE C COMP VIS
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kazemi H, 2018, ADV NEURAL INFORM PR, V31
   Kohl SAA, 2018, ADV NEUR IN, V31
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Liu AH, 2018, ADV NEUR IN, V31
   Mejjati YA, 2018, ADV NEUR IN, V31
   Mo S, 2019, P INT C LEARN REPR
   Redmon J, 2020, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Siddiquee MMR, 2019, P IEEE INT C COMPUTE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tulyakov S, 2018, P IEEE C COMPUTER VI
   Wang T, 2018, 2018 IEEECVF C COMPU
   Wang Y, 2018, IEEE C COMPUTER VISI
   Wang Y, 2018, ADV NEUR IN, V31
   Yi Z, 2017, P IEEE INT C COMPUTE
   Yu F, ARXIV 180504687
   Yu J, 2018, 2018 IEEECVF C COMPU, p5505 5514
   Zhang R., 2018, P IEEE C COMPUTER VI
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40269
EP 40288
DI 10.1007/s11042-022-12934-9
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300007
DA 2024-07-18
ER

PT J
AU Kaur, M
   Vijay, S
AF Kaur, Maninder
   Vijay, Sandip
TI Underwater images quality improvement techniques for feature extraction
   based on comparative analysis for species classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image processing; Image quality improvement techniques;
   Feature extraction methods; PCA; SIFT; SURF
ID RECOGNITION; ENHANCEMENT; ACCURATE; FILTER
AB The object recognition under the sea is a difficult task due to the presence of different environmental conditions around oceans. Various techniques have been used to enhance the properties of underwater images. This paper proposed the pre-processing and feature extraction techniques for object recognition under the seawater. The proposed methodology consists of several pre-processing steps for underwater images to make a compatible image for feature extraction purposes, which helps in object recognition. The proposed pre-processing works on the intensity, contrast, and sharpness of the object to improve their visualization quality. We compared the proposed ALE algorithm (Atmospheric-Light-Enhancement Algorithm) with existing image enhancement techniques such as Intensity-based, Histogram based, Contrast-based image enhancement techniques. From the analysis, the ALE algorithm is most effective for underwater images. Also, a comparative analysis has been presented for feature extraction from underwater images using PCA (Principal Component Analysis), SIFT (Scale-Invariant Feature Transform), and SURF (Speeded up Robust Features) to extract the unique feature. The proposed technique SURF shows better results attainment in contrary to other feature extraction techniques. At last, in simulation analysis, we observed that the error rate and feature extraction time taken by SURF is better than PCA as well as SIFT, due to the speed up methodology of SURF during the feature points filtration.
C1 [Kaur, Maninder; Vijay, Sandip] Tulas Inst, Dehra Dun, Uttarakhand, India.
C3 Tula's Institute
RP Vijay, S (corresponding author), Tulas Inst, Dehra Dun, Uttarakhand, India.
EM dhaliwalmaninderkaur@gmail.com; vijaysandip@gmail.com
RI vijay, sandip/GLV-3370-2022; Kaur, Maninder/IXD-4944-2023; Vijay,
   Sandip/F-7922-2010
OI vijay, sandip/0000-0002-8996-7263; Kaur, Maninder/0000-0001-7948-8085;
   Vijay, Sandip/0000-0002-8996-7263; kaur, maninder/0000-0003-4097-6764
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Gao SB, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919947
   Iqbal N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030395
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HM, 2020, MOBILE NETW APPL, V25, P1008, DOI 10.1007/s11036-018-1117-9
   Mayer P, 2019, IEEE T INSTRUM MEAS, V68, P2346, DOI 10.1109/TIM.2018.2890187
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Salman A, 2016, LIMNOL OCEANOGR-METH, V14, P570, DOI 10.1002/lom3.10113
   Srividhya K, 2017, MULTIMED TOOLS APPL, V76, P25679, DOI 10.1007/s11042-017-4459-6
   Verma K, 2015, PROCEDIA COMPUT SCI, V48, P29, DOI 10.1016/j.procs.2015.04.106
   Villon S, 2018, ECOL INFORM, V48, P238, DOI 10.1016/j.ecoinf.2018.09.007
   Wang NB, 2019, CMC-COMPUT MATER CON, V58, P169, DOI 10.32604/cmc.2019.03709
   Wong SL, 2018, ADV ELECTR COMPUT EN, V18, P109, DOI 10.4316/AECE.2018.02014
   Xu L., 2019, HDB DEEP LEARNING AP, V136, P129, DOI [10.1007/978-3-030-11479-4_7, DOI 10.1007/978-3-030-11479-4_7]
   Yang HG, 2018, J SOUND VIB, V421, P205, DOI 10.1016/j.jsv.2018.01.051
   Yang HH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051104
   Zhao MH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020350
   Zhu M, 2017, OCEANS 2017 ABERDEEN, P14
NR 19
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19445
EP 19461
DI 10.1007/s11042-022-12535-6
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000791885300002
DA 2024-07-18
ER

PT J
AU Shalini, P
   Shankaraiah
AF Shalini, P.
   Shankaraiah
TI Social behavioral biometric multimodal union to evade fake account
   creation in Facebook
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social behavioral biometric (SBB); Online social networks (OSNs);
   Authentication; Social networking site (SNS); Union
ID NEURAL SYSTEMS; RECOGNITION
AB In the present world scenario, people spend most of their time browsing on Social Networking Site (SNS) such as Facebook, Twitter, WhatsApp etc., thus increasing the distribution of sensitive personal information online which goes viral. Facebook fake account creation is one of hazards created by cybercriminals, that has to be overcome. The human brain has the most powerful decision-making capability based on social interaction, visual signs, contextual and spatio-temporal data. Thus, in this paper, an automated intelligent biometric system is designed based on the social behavioral traces available on Online Social Networks (OSNs) that depend on human thinking capability which increases the performance of the conventional biometric system, this system is applied in creation of unique Facebook account. Experimental results achieved from semi-real databases are Genuine Acceptance Rate (GAR) of 100% with 2% False Acceptance Rate (FAR) and Cumulative Recognition Rate (CRR) of 100% at Rank 5.
C1 [Shalini, P.; Shankaraiah] JSS Sci & Technol Univ, Sri Jayachamarajendra Coll Engn, Mysore, Karnataka, India.
C3 Sri Jayachamarajendra College of Engineering; JSS Science & Technology
   University
RP Shalini, P (corresponding author), JSS Sci & Technol Univ, Sri Jayachamarajendra Coll Engn, Mysore, Karnataka, India.
EM shalini.prabhakar@gmail.com; shankaraiah@sjce.ac.in
RI Hanok, Shalini/GRO-7241-2022; Ningaiah, shankaraiah/HME-0374-2023;
   Prince dr k Vasudevan college of engineering, Prince dr k Vasudevan
   college of engineering/JFB-2865-2023
CR Adolphs R, 1999, TRENDS COGN SCI, V3, P469, DOI 10.1016/S1364-6613(99)01399-6
   Albayati MB, 2019, J ICT RES APPL, V13, P107, DOI 10.5614/itbj.ict.res.appl.2019.13.2.2
   [Anonymous], 2010, CONSTINE
   [Anonymous], 2006, Handbook of Multibiometrics
   backlinko, FACEBOOK USERS
   Dewan P, 2015, ANN CONF PRIV SECUR, P85, DOI 10.1109/PST.2015.7232958
   Gavrilova M.L., 2013, Multimodal biometrics and intelligent image processing for security systems
   Gobbini MI, 2007, NEUROPSYCHOLOGIA, V45, P32, DOI 10.1016/j.neuropsychologia.2006.04.015
   Gupta A, FACEBOOK NEWSROOM
   Haxby JV, 2002, BIOL PSYCHIAT, V51, P59, DOI 10.1016/S0006-3223(01)01330-0
   Hube JP, 2006, USING BIOMETRIC VERI
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2012, BIOMETRIC RECOGNITIO, P4979
   Kaur M, 2008, FINGERPRINT VERIFICA
   Ma L, 2002, ACCV2002 5 AS C COMP
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Paul PP, 2014, IEEE T SYST MAN CY-S, V44, P1522, DOI 10.1109/TSMC.2014.2331920
   Rahman S, 2015, DETECTING MALICIOUS
   Ross, RELATING ROC CMC CUR
   Sahoo, 2020, ADV INTELLIGENT SYST, V1045, DOI 10.1007/978-981-15-0029-9-13
   Sahoo Somya Ranjan, 2020, International Journal of Information and Computer Security, V12, P303
   scribbr, STATISTICSVARIANCE
   Sohrabi MK, 2018, ARAB J SCI ENG, V43, P949, DOI 10.1007/s13369-017-2855-x
   Statista, about as
   Sultana M, 2018, IEEE T SYST MAN CY-S, V48, P2176, DOI 10.1109/TSMC.2017.2690321
   Sultana M, 2017, IEEE T HUM-MACH SYST, V47, P356, DOI 10.1109/THMS.2017.2681673
   Sultana M, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415560133
   Sultana M, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P271, DOI 10.1109/CW.2014.44
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Umair A, 2017, C PAP, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.364
   Wani MA, 2019, INT CONF COMMUN SYST, P145, DOI [10.1109/comsnets.2019.8711124, 10.1109/COMSNETS.2019.8711124]
   wikipedia, WIKIFACEBOOK
   Wu SH, 2017, IEEE SYST J, V11, P2432, DOI 10.1109/JSYST.2015.2504102
   Yang Z, 2014, ACM T KNOWL DISCOV D, V8, P5, DOI 10.1145/2556609
NR 35
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39715
EP 39751
DI 10.1007/s11042-022-13104-7
EA MAY 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789768900002
DA 2024-07-18
ER

PT J
AU Lakhili, Z
   El Alami, A
   Mesbah, A
   Berrahou, A
   Qjidaa, H
AF Lakhili, Zouhir
   El Alami, Abdelmajid
   Mesbah, Abderrahim
   Berrahou, Aissam
   Qjidaa, Hassan
TI Rigid and non-rigid 3D shape classification based on 3D Hahn moments
   neural networks model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object classification; 3D Hahn moments neural networks; 3D discrete
   Hahn moments; Rigid 3D dataset; Non-rigid 3D dataset; Noisy conditions;
   Complexity
ID IMAGE-ANALYSIS; OBJECT CLASSIFICATION; RETRIEVAL; RECOGNITION;
   KRAWTCHOUK
AB With the rapid development of 3D technology, 3D object classification has recently become a popular research topic in computer graphics and pattern recognition. Analyzing the shape of 3D models has become a common concern for researchers. A crucial technique for analyzing these 3D shapes is to capture features from 3D models that can sufficiently distinguish their shapes. While the 3D discrete orthogonal moments are powerful for the analysis and representation of 3D objects. It was proved that they have a better feature representation capability than the continuous orthogonal moments. This paper presents a new model for 3D shape classification named 3D Hahn moments neural networks (3DHMNNs) to improve the classification accuracy and decrease the computational complexity of 3D pattern recognition process. The proposed model is derived by introducing 3D Hahn moments as an input layer in neural network, largely utilized in various applications related to the pattern recognition. In fact, the advantages of image moments, especially discrete orthogonal moments have the property to extract relevant features from an object in lower orders and their robustness against image noise. Along with the efficiency of the neural networks, we can construct the proposed robust model. The main purpose of this work is to investigate the classification capabilities of the proposed model on rigid and non-rigid 3D shape datasets. The experiment simulations are conducted on the Articulated of McGill Princeton Shape Benchmark (PSB), SHREC'2011, ModelNet10 and ModelNet40 databases to assess the effectiveness of our proposed model. Two structures of the proposed model are constructed as noted 3DHMNNs(6 layers) and 3DHMNNs(7 layers). The obtained results indicate that the proposed model provide a reasonable performance in terms of classification accuracy by achieving 90.96% on ModelNet10, 83.87% on ModelNet40, 97.66% on SHREC'2011 and over 90.16% on Articulated McGill outperforming other existing methods as well as being more robust under noisy conditions.
C1 [Lakhili, Zouhir; El Alami, Abdelmajid; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
   [Mesbah, Abderrahim; Berrahou, Aissam] Mohammed V Univ, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed V University in
   Rabat
RP Lakhili, Z (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
EM zouhir.lakhili@usmba.ac.ma
RI El Alami, Abdelmajid/CAF-5211-2022; El Alami, Abdelmajid/CAI-1690-2022
OI EL ALAMI, Abdelmajid/0000-0002-2489-661X
CR Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], MCGILL 3D SHAPE BENC
   Arora Simrann, 2021, Micro-Electronics and Telecommunication Engineering. Proceedings of 4th ICMETE 2020. Lecture Notes in Networks and Systems (LNNS 179), P89, DOI 10.1007/978-981-33-4687-1_10
   Batioua I, 2020, MULTIMED TOOLS APPL, V79, P13217, DOI 10.1007/s11042-019-08083-1
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Ben Hamza A, 2016, NEUROCOMPUTING, V211, P11, DOI 10.1016/j.neucom.2015.12.130
   Benouini R, 2018, MULTIMED TOOLS APPL, V77, P27517, DOI 10.1007/s11042-018-5937-1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Canterakis N., 1999, PROC 11 SCANDINAVIAN, P85
   Chen, 2020, JNI, V5, P122
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Cyganski D., 1988, Advances in computer vision and image processing, P101
   El Alami A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723788
   Ezuz D, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13244
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hoang L, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101196
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Lakhili Z, 2020, INT C EL ENG REN EN, P151, DOI [10.1007/978-981-15-6259-4_14, DOI 10.1007/978-981-15-6259-4_14]
   Lakhili Z, 2020, MULTIMED TOOLS APPL, V79, P18883, DOI 10.1007/s11042-020-08654-7
   Lakhili Z, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEMS & SECURITY (NISS19), DOI 10.1145/3320326.3320398
   Lakhili Z, 2019, PROCEDIA COMPUT SCI, V148, P12, DOI 10.1016/j.procs.2019.01.002
   Lian Z., 2011, EUR WORKSH 3D OBJ RE
   Liao S, 2002, INT C PATT RECOG, P485, DOI 10.1109/ICPR.2002.1047982
   Liu SK, 2018, INT CONF 3D VISION, P542, DOI 10.1109/3DV.2018.00068
   Liu ZS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196735
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Loffe S., 2015, P 32 INT C MACH LEAR
   Masoumi M, 2016, PATTERN RECOGN LETT, V83, P339, DOI 10.1016/j.patrec.2016.04.009
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Milano F., 2020, C NEUR INF PROC SYST
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nie WZ, 2019, MULTIMED TOOLS APPL, V78, P16979, DOI 10.1007/s11042-018-7102-2
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Patil S, 2005, INT C COMP AID DES C, P415, DOI 10.1109/CAD-CG.2005.86
   Reverdy P, 2016, IEEE T AUTOM SCI ENG, V13, P54, DOI 10.1109/TASE.2015.2499244
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Shen L, 2006, IMAGE VISION COMPUT, V24, P743, DOI 10.1016/j.imavis.2006.01.011
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Singh C, 2012, OPT LASER ENG, V50, P655, DOI 10.1016/j.optlaseng.2011.11.012
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suk T, 2015, PATTERN RECOGN, V48, P3516, DOI 10.1016/j.patcog.2015.05.007
   Suk T, 2011, LECT NOTES COMPUT SC, V6855, P212, DOI 10.1007/978-3-642-23678-5_24
   Svirsky Y, 2021, IEEE T VIS COMPUT GR, V27, P3238, DOI 10.1109/TVCG.2020.2968062
   Valverde I, 2017, REV ESP CARDIOL, V70, P282, DOI 10.1016/j.rec.2017.01.012
   Wu H., 2013, MATH PROBL ENG, V1
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001
   Xuan Guo, 1993, Computer Analysis of Images and Patterns. 5th International Conference, CAIP '93 Proceedings, P518
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang Lisha., 2007, FundaAgao para a Cincia ea Tecnologia, P3
   Zhao DM, 2005, COMPUT IND, V56, P975, DOI 10.1016/j.compind.2005.05.021
   Zheng Q., 2018, MATH PROBL ENG, V2018, P1
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhou Y, 2019, INFORM SCIENCES, V474, P205, DOI 10.1016/j.ins.2018.09.051
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 70
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38067
EP 38090
DI 10.1007/s11042-022-12125-6
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700018
DA 2024-07-18
ER

PT J
AU Chatterjee, SK
   Vittapu, SK
AF Chatterjee, Sumit Kumar
   Vittapu, Sravan Kumar
TI FPGA implementation of EFSME for high efficient video coding standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE High efficiency video coding (HEVC); Full search motion estimation
   (FSME); Sum of absolute difference (SAD); Particle swarm optimization
   (PSO); Field programmable gate Array (FPGA)
ID MOTION ESTIMATION; ARCHITECTURE; ALGORITHM
AB Nowadays. High Efficiency Video Coding (HEVC) is widely used in video compression techniques due to the utilization of less bit rate than Advanced Video Coding (AVC) encoders. Motion Estimation (ME) is a vital task in HEVC video compression technique which consumes more encoding time. Various algorithms are proposed in existing studies to deal with ME process in HEVC. Full Search Motion Estimation (FSME) method is most suitable for HEVC because, it is better in terms of high data flow and operating speed. In this work, Particle Swarm Optimization (PSO) is proposed to optimize Sum of Absolute Difference (SAD) calculation value hence, it is named as Enhanced FSME (EFSME). SAD calculation of EFSME not requires adder tree, comparison block and control unit. Hence, there is great reduction in area, power and operating frequency. Proposed work is implemented in Xilinx ZYNQ XA7Z010 FPGA board and it is evaluated by means of power, area and operational frequency. For HEVC, EFSME outputs 65 mW as power consumption rate which is 28.94% lower than Vayalil et al. (2017), 3.03% lesser than Xu et al. (2018) and 80.05% lesser than Singh and Ahamed (2018). Moreover, the proposed design accomplishes 431.906 MHz as operating speed that is 0.44% greater than Vayalil et al. (2017), 20.95% higher than Xu et al. (2018) and 53.35% higher than Singh and Ahamed (2018). Overall, the simulation results proved that the proposed enhanced architecture is better than the existing methodologies in terms of different parameters.
C1 [Chatterjee, Sumit Kumar; Vittapu, Sravan Kumar] BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Chatterjee, SK (corresponding author), BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India.
EM sumit2702@hyderabad.bits-pilani.ac.in
RI Vittapu, Sravankumar/AIE-2505-2022
OI Vittapu, Sravankumar/0000-0002-9627-8562
CR AlQaralleh EA, 2018, PROCEDIA COMPUT SCI, V141, P40, DOI 10.1016/j.procs.2018.10.147
   Bakir N., 2020, PROC IEEE INT C MULT, P1
   Braly M, 2017, DEPENDABLE SECURE CO
   Çetinkaya E, 2020, IEEE I C VI COM I PR, P87, DOI 10.1109/vcip49819.2020.9301850
   Chen YH, 2017, INT J CIRC THEOR APP, V45, P2260, DOI 10.1002/cta.2376
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Fan R, 2017, IEEE T MULTIMEDIA, V19, P893, DOI 10.1109/TMM.2016.2642786
   Goel S, 2012, COMPUT J, V55, P35, DOI 10.1093/comjnl/bxr034
   Hiramori M, 2016, CONS EL 2016 IEEE 5, P1
   Ismail Y, 2016, INT J COMPUTING DIGI
   Jia LH, 2020, IEEE T CIRC SYST VID, V30, P243, DOI 10.1109/TCSVT.2018.2890204
   Kumar BS, 2020, J KING SAUD UNIV-COM, V32, P784, DOI 10.1016/j.jksuci.2017.11.004
   Lu GL, 2018, OPT LASER ENG, V111, P246, DOI 10.1016/j.optlaseng.2018.08.011
   Makryniotis T., 2017, MOD CIRC SYST TECHN, P1
   Rufenacht D, 2017, MULTIMEDIA SIGNAL PR, P1
   Shah NN, 2018, IET COMPUT DIGIT TEC, V12, P95, DOI 10.1049/iet-cdt.2016.0178
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Singh K, THESIS
   Singh K, 2018, IEEE T CONSUM ELECTR, V64, P267, DOI 10.1109/TCE.2018.2867823
   Siqueira I, 2020, IEEE LAT AMER SYMP
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Trudeau L, 2018, IEEE T BROADCAST, V64, P922, DOI 10.1109/TBC.2018.2847444
   Tseng YH, 2019, IEEE INT SYMP CIRC S
   Vayalil NC, 2017, IEEE T CIRC SYST VID
   Wang Y, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P407, DOI 10.1109/CISP-BMEI51763.2020.9263529
   Wu MH, 2019, J AMB INTEL HUM COMP, V10, P439, DOI 10.1007/s12652-017-0660-8
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Xue YG, 2017, SCI PROGRAMMING-NETH, V2017, DOI 10.1155/2017/1431574
   Zhu SP, 2017, MULTIMED TOOLS APPL, V76, P21707, DOI 10.1007/s11042-016-4056-0
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 APR 21
PY 2022
DI 10.1007/s11042.022-13051-3
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Q1IV
UT WOS:000784679300002
DA 2024-07-18
ER

PT J
AU Rahman, AU
   Halim, Z
AF Rahman, Atta Ur
   Halim, Zahid
TI Predicting the big five personality traits from hand-written text
   features through semi-supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Writer-identification; Graph-based feature; Personality prediction;
   Semi-supervised learning; Semi-supervised generative adversarial network
ID EMOTIONAL STATE RECOGNITION; CLASSIFICATION
AB Handwriting analysis is a systematic study of preserved graphic structures. Which are generated in the human brain and produced on paper in cursive or printed style. The style in which a text is written reflects an array of meta-information. Personality is a combination of an individual's behavior, emotion, motivation, and thought-pattern characteristics. It has an impact on one's life choices, well-being, health, and numerous other preferences. This study investigates the correlation between handwriting features and personality characteristics. The prediction of personality through handwriting analysis needs to investigate the style and structure of writing. This study extracts eleven features from handwriting samples using a graph-based writing representation approach. The Big Five model of personality traits is utilized to find the personality of the writer. To improve classification accuracy utilizes a Semi-supervised Generative Adversarial Network (SGAN). This network uses a small amount of labeled data and a larger amount of unlabeled data to train the classifier. The discriminator works as a multi-class classifier and is trained on labeled, unlabeled, and generator created data. The proposed system predicts 91.3% correct personality results by utilizing the writing features of 173 participants.
C1 [Rahman, Atta Ur; Halim, Zahid] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi 23460, Pakistan.
C3 GIK Institute Engineering Science & Technology
RP Halim, Z (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi 23460, Pakistan.
EM atta.rahman@giki.edu.pk; zahid.halim@giki.edu.pk
FU GIK Institute
FX This research work is supported by the GIK Institute graduate program
   research fund under GA-4 schemes. The authors would like to thank GIK
   Institute for providing research facilities.
CR [Anonymous], 2010, International Journal of Computer Applications
   Champa H. N., 2010, Proceedings of the 2010 First International Conference on Integrated Intelligent Computing (ICIIC 2010), P160, DOI 10.1109/ICIIC.2010.29
   Chaudhari K, 2019, EXPERT SYST APPL, V124, P282, DOI 10.1016/j.eswa.2019.01.028
   Chen Z, 2017, BEHAV INFORM TECHNOL, V36, P839, DOI 10.1080/0144929X.2017.1304994
   Chitlangia A, 2019, PROCEDIA COMPUT SCI, V165, P384, DOI 10.1016/j.procs.2020.01.034
   Costa P.T., 1992, REVISED NEO PERSONAL
   Dai Z. H., 2017, NIPS
   Esposito A, 2019, INT CONF COGN INFO, P79, DOI [10.1109/coginfocom47531.2019.9089985, 10.1109/CogInfoCom47531.2019.9089985]
   Fallah B, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P120, DOI 10.1109/RIOS.2016.7529501
   Freud S, 1925, SIGMUND FREUDS LECT
   Gahmousse A, 2020, 2020 INT C DATA ANAL, P1
   Gavrilescu M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0297-3
   Helli B, 2010, PATTERN RECOGN, V43, P2199, DOI 10.1016/j.patcog.2009.11.026
   Impedovo D, 2019, IEEE REV BIOMED ENG, V12, P209, DOI 10.1109/RBME.2018.2840679
   Jianqiang Shen, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P318, DOI 10.1007/978-3-642-38844-6_29
   Kumar R, 2014, PATTERN RECOGN LETT, V35, P105, DOI 10.1016/j.patrec.2013.07.001
   Li W, 2019, CVPR WORKSHOPS, P1
   Likforman-Sulem L, 2017, IEEE T HUM-MACH SYST, V47, P273, DOI 10.1109/THMS.2016.2635441
   Lima ACES, 2014, NEURAL NETWORKS, V58, P122, DOI 10.1016/j.neunet.2014.05.020
   Loconsole C, 2019, PATTERN RECOGN LETT, V121, P28, DOI 10.1016/j.patrec.2018.04.006
   Lokhande VR, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P44, DOI 10.1109/ICISIM.2017.8122145
   Mekhaznia T, 2021, PATTERN RECOGN, P155
   Mercer K, 2016, JMIR MHEALTH UHEALTH, V4, P168, DOI 10.2196/mhealth.4225
   Mostafa MA, 2019, SPRINGER PR COMPLEX, P557, DOI 10.1007/978-3-030-30809-4_51
   Mukherjee S, 2020, INT CONF COMPUT INT, DOI 10.1109/CINE48825.2020.234387
   Nolazco-Flores JA, 2021, IEEE ACCESS, V9, P28496, DOI 10.1109/ACCESS.2021.3058443
   Odena Augustus., 2016, Semi-supervised learning with generative adversarial networks
   Pathak AR, 2020, J DISCRET MATH SCI C, V23, P19, DOI 10.1080/09720529.2020.1721856
   Prasad S., 2010, INT J COMPUTER APPL, V8, P25, DOI [10.5120/1256-1758, DOI 10.5120/1256-1758]
   Samsuryadi RK., 2021, INDONESIAN J ELECT E, V1, P196, DOI [10.11591/ijeecs.v22.i1.pp196-206, DOI 10.11591/IJEECS.V22.I1.PP196-206]
   Sricharan K., 2017, SEMISUPERVISED CONDI, P1
   Stangor C., 2019, OUR BRAINS CONTROL O
   Wang Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124081
   Willett FR, 2021, NATURE, V593, P249, DOI 10.1038/s41586-021-03506-2
   Wright WR, 2014, LECT NOTES COMPUT SC, V8538, P243
   Xue D, 2018, APPL INTELL, V48, P4232, DOI 10.1007/s10489-018-1212-4
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
NR 37
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33671
EP 33687
DI 10.1007/s11042-022-13114-5
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200001
DA 2024-07-18
ER

PT J
AU Gill, HS
   Murugesan, G
   Khehra, BS
   Sajja, GS
   Gupta, G
   Bhatt, A
AF Gill, Harmandeep Singh
   Murugesan, Ganpathy
   Khehra, Baljit Singh
   Sajja, Guna Sekhar
   Gupta, Gaurav
   Bhatt, Abhishek
TI Fruit recognition from images using deep learning applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; CNN; RNN; Fruit images; Recognition; Classification
ID COMPUTER VISION; CLASSIFICATION
AB Smart imaging devices have been used at a rapid rate in the agriculture sector for the last few years. Fruit recognition and classification is noticed as one of the looming sectors in computer vision and image classification. A fruit classification may be adopted in the fruit market for consumers to determine the variety and grading of fruits. Fruit quality is a prerequisite property from a health viewpoint. Classification systems described so far are not adequate for fruit recognition and classification during accuracy and quantitative analysis. Deep learning models have the ability to extract the potential image features without using handcrafted features. In this paper, Type-II Fuzzy, TLBO (Teacher-learner based optimization), and deep learning Convolution Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM) applications proposed to enhance, segment, recognize and classify the fruit images. Thus, the examination of new proposals for fruit recognition and classification is worthwhile. In the present time, automatic fruit recognition and classification is though a demanding task. Deep learning is a powerful state-of-the-art approach for image classification. This task incorporates deep learning models: CNN, RNN, LSTM for classification of fruits based on chosen optimal and derived features. As preliminary arises, it has been recognized that the recommended procedure has effective accuracy and quantitative analysis results. Moreover, the comparatively high computational momentum of the proposed scheme will promote in the future.
C1 [Gill, Harmandeep Singh] Bibi Sharan Kaur Khalsa Coll, Chamkaur Sahib, Punjab, India.
   [Murugesan, Ganpathy] St Josephs Coll Engn, Dept CSE, Chennai, Tamil Nadu, India.
   [Khehra, Baljit Singh] BAM khalsa Coll, Garhshankar, Punjab, India.
   [Sajja, Guna Sekhar] Univ Cumberlands, Dept Informat Technol, Williamsburg, KY USA.
   [Gupta, Gaurav] Shoolini Univ, Yogananda Sch Comp & Data Sci, Solan, India.
   [Bhatt, Abhishek] Coll Engn, Dept Elect & Telecommun, Pune, Maharashtra, India.
C3 St. Joseph's College of Engineering, Chennai; University of the
   Cumberlands; Shoolini University; College of Engineering Pune
RP Gill, HS (corresponding author), Bibi Sharan Kaur Khalsa Coll, Chamkaur Sahib, Punjab, India.
EM profhdsgill@gmail.com; murugesang@stjosephs.ac.in;
   baljitkhehra74@gmail.com; gsajja1524@ucumberlands.edu;
   gaurav@shooliniuniversity.com; bhatta.extc@coep.ac.in
RI bhatt, abhishek/G-5819-2015; G, Murugesan/T-3387-2019; GUPTA,
   GAURAV/B-3566-2012; Sajja, Guna Sekhar/KDB-7843-2024; Gill, Harmandeep
   singh/AAY-9120-2020
OI bhatt, abhishek/0000-0001-7743-6070; G, Murugesan/0000-0001-7793-3691;
   GUPTA, GAURAV/0000-0002-5192-4428; Sajja, Guna
   Sekhar/0000-0003-0327-2450; Gill, Harmandeep singh/0000-0001-8699-2087
CR Altaheri H, 2019, IEEE ACCESS, V7, P117115, DOI 10.1109/ACCESS.2019.2936536
   Benalia S, 2016, COMPUT ELECTRON AGR, V120, P17, DOI 10.1016/j.compag.2015.11.002
   Gill, 2021 IEEE INT MIDW S, P549
   Gill, 2021, SPAST ABSTRACTS, V1
   Gill H S., 2021, ALGORITHMS INTELLIGE, P1
   Gill HS, 2022, MATER TODAY-PROC, V51, P591, DOI 10.1016/j.matpr.2021.06.016
   Gill HS, 2021, MULTIMED TOOLS APPL, V80, P27495, DOI 10.1007/s11042-021-10772-9
   Gill HS, 2019, EGYPT INFORM J, V20, P11, DOI 10.1016/j.eij.2018.03.006
   Gill HK., 2021, 2021 INT C EL COMM C, P1
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Hameed K, 2018, IMAGE VISION COMPUT, V80, P24, DOI 10.1016/j.imavis.2018.09.016
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149
   Kang HW, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105108
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li C, 2016, NEUROCOMPUTING, V215, P196, DOI 10.1016/j.neucom.2015.07.156
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Momeny M, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111204
   Nasiri A, 2019, POSTHARVEST BIOL TEC, V153, P133, DOI 10.1016/j.postharvbio.2019.04.003
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rasti P, 2017, IET COMPUT VIS, V11, P567, DOI 10.1049/iet-cvi.2016.0463
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Sen AAA, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P235, DOI [10.23919/indiacom49435.2020.9083706, 10.23919/INDIACom49435.2020.9083706]
   Gill HS, 2020, IET IMAGE PROCESS, V14, P3463, DOI 10.1049/iet-ipr.2018.5310
   Singh H, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501300
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Steinbrener J, 2019, COMPUT ELECTRON AGR, V162, P364, DOI 10.1016/j.compag.2019.04.019
   Teena MA, 2014, J STORED PROD RES, V59, P306, DOI 10.1016/j.jspr.2014.09.005
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Woodford B.J., 1999, Proceedings of the Iconip/Anziis/Annes, V99, P88
   Yang J, 2020, PROCESSES, V8, DOI 10.3390/pr8030295
   Yin QW, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927702001
   Zawbaa HM, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P164, DOI 10.1109/HIS.2014.7086191
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zhou, 2020, MATEC WEB C, V327
NR 37
TC 10
Z9 10
U1 25
U2 105
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33269
EP 33290
DI 10.1007/s11042-022-12868-2
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800013
DA 2024-07-18
ER

PT J
AU Bui, V
   Alaei, A
AF Bui, Vinh
   Alaei, Alireza
TI Virtual reality in training artificial intelligence-based systems: a
   case study of fall detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Training Artificial Intelligence; Fall dataset;
   Vision-based fall detection
ID EPIDEMIOLOGY; CARE
AB Artificial Intelligent (AI) systems generally require training data of sufficient quantity and appropriate quality to perform efficiently. However, in many areas, such training data is simply not available or incredibly difficult to acquire. The recent developments in Virtual Reality (VR) have opened a new door for addressing this issue. This paper demonstrates the use of VR for generating training data for AI systems through a case study of human fall detection. Fall detection is a challenging problem in the public healthcare domain. Despite significant efforts devoted to introducing reliable and effective fall detection algorithms and enormous devices developed in the literature, minimal success has been achieved. The lack of recorded fall data and the data quality have been identified as major obstacles. To address this issue, this paper proposes an innovative approach to remove the afformentioned obstacle using VR technology. In this approach, a framework is, first, proposed to generate human fall data in virtual environments. The generated fall data is then tested with state-of-the-art visual-based fall detection algorithms to gauge its effectiveness. The results have indicated that the virtual human fall data generated using the proposed framework have sufficient quality to improve fall detection algorithms. Although the approach is proposed and verified in the context of human fall detection, it is applicable to other computer vision problems in different contexts, including human motion detection/recognition and self-driving vehicles.
C1 [Bui, Vinh; Alaei, Alireza] Southern Cross Univ, Fac Sci & Engn, Gold Coast, Australia.
C3 Southern Cross University
RP Bui, V (corresponding author), Southern Cross Univ, Fac Sci & Engn, Gold Coast, Australia.
EM vinh.bui@scu.edu.au; ali.alaei@scu.edu.au
RI Alaei, Alireza/Q-7083-2019
OI Alaei, Alireza/0000-0003-1669-2606; BUI, VINH/0000-0002-8962-157X
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abdel-Malek K., 2006, International Journal of Human Factors Modelling and Simulation, V1, P2, DOI 10.1504/IJHFMS.2006.011680
   AbdelMalek KA, 2013, HUMAN MOTION SIMULATION: PREDICTIVE DYNAMICS, P1
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Aslan M, 2017, J FAC ENG ARCHIT GAZ, V32, P1025
   Auvinet Edouard., 2010, Multiple cameras fall dataset, P1350
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Bhowmik A.K., 2018, Inf Disp, V34, P18, DOI 10.1002/j.2637-496X.2018.tb01117.x
   Boulay B, 2006, PATTERN RECOGN LETT, V27, P1788, DOI 10.1016/j.patrec.2006.02.008
   Buss S. R., 2004, IEEE J ROBOTIC AUTOM, V17, P16
   Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cassola VF, 2010, PHYS MED BIOL, V55, P133, DOI 10.1088/0031-9155/55/1/009
   Charfi I, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041106
   Cipresso P, 2015, STUD HEALTH TECHNOL, V219, P177, DOI 10.3233/978-1-61499-595-1-177
   Cortes C., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining, P57
   De Falco I, 2020, NEURAL COMPUT APPL, V32, P747, DOI 10.1007/s00521-018-03973-1
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Geijtenbeek T, 2012, COMPUT GRAPH FORUM, V31, P2492, DOI 10.1111/j.1467-8659.2012.03189.x
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gross R, 2001, CITESEER
   Hossain Ekram, 2019, ARXIV PREPRINT ARXIV
   Huang, 2019, REV FAC AGRON LUZ, V36
   Igual R, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-66
   Khan SS, 2017, MED ENG PHYS, V39, P12, DOI 10.1016/j.medengphy.2016.10.014
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Li X, 2019, IEEE T VEH TECHNOL, V68, P9619, DOI 10.1109/TVT.2019.2936227
   Li X, 2019, IEEE T INTELL TRANSP, V20, P2072, DOI 10.1109/TITS.2018.2857566
   Malleson C, 2017, INT CONF 3D VISION, P449, DOI 10.1109/3DV.2017.00058
   Marín J, 2010, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2010.5540218
   Masud T, 2001, AGE AGEING, V30, P3, DOI 10.1093/ageing/30.suppl_4.3
   McCarthy C.J., 2019, J RADIOLOGY NURSING, V38, P104, DOI DOI 10.1016/J.JRADNU.2019.01.008
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Ozcanhan MH, 2020, NEURAL COMPUT APPL, V32, P9369, DOI 10.1007/s00521-019-04451-y
   Peel NM, 2011, CAN J AGING, V30, P7, DOI 10.1017/S071498081000070X
   Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151
   Pillai A.S., 2019, Impact of Virtual Reality in Healthcare, P17, DOI [10.4018/978-1-5225-7168-1.ch002, DOI 10.4018/978-1-5225-7168-1.CH002]
   Ren LM, 2019, IEEE ACCESS, V7, P77702, DOI 10.1109/ACCESS.2019.2922708
   Robinovitch SN, 2013, LANCET, V381, P47, DOI 10.1016/S0140-6736(12)61263-X
   Rodrigues TB, 2018, PROCEDIA COMPUT SCI, V141, P358, DOI 10.1016/j.procs.2018.10.189
   Rozantsev A, 2015, COMPUT VIS IMAGE UND, V137, P24, DOI 10.1016/j.cviu.2014.12.006
   Schneider S, 2020, ECOL EVOL, V10, P3503, DOI 10.1002/ece3.6147
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tian YL, 2018, IEEE-CAA J AUTOMATIC, V5, P539, DOI 10.1109/JAS.2017.7510841
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Trumble M., 2016, P 13 EUR C VIS MED P
   Vallabh P, 2018, J AMB INTEL HUM COMP, V9, P1809, DOI 10.1007/s12652-017-0592-3
   World Health Organization (WHO), 2015, FALLS PREV OLD AG
   Xu T, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030418
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zidek K, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040496
NR 56
TC 1
Z9 1
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32625
EP 32642
DI 10.1007/s11042-022-13080-y
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782551600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Keshri, S
   Lal, S
   Shukla, KK
AF Keshri, Sarika
   Lal, Shyam
   Shukla, K. K.
TI Picture quality and compression analysis of multilevel legendre wavelet
   transformation based image compression technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB Colour image compression; Lossy compression; Wavelet transformation;
   Multiresolution analysis; Run Length Encoding; Compression ratio;
   Picture quality; Sparse matrix
AB A novel lossy RGB (Red, Green, Blue) colour still image compression algorithm is proposed. The intended method introduces Legendre wavelet-based image transformation technique integrated with vector quantization and run length encoding. High performance is guaranteed by lowering degradation in picture quality with desired compression. Transformation (Specifically) and Quantisation (implicitly) phases focus on reducing number of pixel values from pixel set and contribute in attaining higher compression ratio. Out of these two phases of image compression technique, the phase of transformation should be more effective with a view to implement its functionality because the lossless nature of this phase does not perturb the quality of reconstructed image. Image transformation via Legendre wavelet functions, along with self organizing map based quantization, proposed method for scanning of quantized values and run lenght encoding, tends to produce much sparser matrix when measured against Haar wavelet based compression. Due to the combined effect of curvilinearity nature of their component wavelets, the proposed Legendre wavelet based transformation provides comparatively much more higher PSNR of 225(average) with satisfactory compression of 0.41 bits per pixel(average). In this paper, image transformations are conducted using Haar wavelet, Legendre wavelets and transformation method presented in [7]. Experimental results have been analysed and compared in terms of qualitative and quantitative measure which are PSNR (Peak Signal to Noise Ratio) and bpp (bits per pixel). The performance of proposed algorithm is compared with existing Haar wavelet transformation-based image compression algorithm, compression based on transformation method [7], DCT and adaptive scanning based compression [12] and JPEG [5] compression. Picture quality achieved in the experiments clearly show that the proposed Legendre wavelet -oriented image transformation based image compression technique remarkably outperforms the above mentioned compression techniques.
C1 [Keshri, Sarika] Banaras Hindu Univ, Inst Sci, DST CIMS, Varanasi 221005, Uttar Pradesh, India.
   [Lal, Shyam] Banaras Hindu Univ, Inst Sci, Dept Math, Varanasi 221005, Uttar Pradesh, India.
   [Shukla, K. K.] Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Banaras Hindu University (BHU); Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu University
   (BHU)
RP Keshri, S (corresponding author), Banaras Hindu Univ, Inst Sci, DST CIMS, Varanasi 221005, Uttar Pradesh, India.
EM sarikakeshri00@gmail.com; shyam_lal@rediffmail.com;
   kkshukla.cse@iitbhu.ac.in
RI Shukla, Kaushal Kumar/HGU-3317-2022
OI Shukla, Kaushal Kumar/0000-0002-8756-6474; Keshri, Dr
   Sarika/0000-0001-9441-8624
CR Aghazadeh, 2015, 46 ANN IR MATH C, P1299
   Amerijckx C., 2003, SYST ANAL MODEL SIM, V43, P1529
   Danlami M., 2020, 2020 IEEE 6 INT C OP, P1
   Debnath JK, 2008, IEEE IJCNN, P171, DOI 10.1109/IJCNN.2008.4633785
   Dhara BC, 2007, PATTERN RECOGN, V40, P2408, DOI 10.1016/j.patcog.2006.12.022
   Grgic S., 1999, ISIE '99. Proceedings of the IEEE International Symposium on Industrial Electronics (Cat. No.99TH8465), P99, DOI 10.1109/ISIE.1999.801765
   Hashemizadeh E, 2016, J MOD APPL STAT METH, V15, P510, DOI 10.22237/jmasm/1478003340
   Jayanthi R., 2018, TAGA J GRAPHIC TECHN, V14, P3462
   Kale V. U., 2010, INT J COMPUT SCI COM, V1, P179
   Kathirvalavakumar T, 2013, INT J MACH LEARN CYB, V4, P319, DOI 10.1007/s13042-012-0099-3
   Krishnamoorthi R., 2009, INT J SIGNAL PROCESS, V5, P67
   Messaoudi A, 2019, SIGNAL IMAGE VIDEO P, V13, P1441, DOI 10.1007/s11760-019-01492-7
   Muktar D, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P174, DOI 10.1145/3309074.3309090
   Mulcahy C., 1997, SPELMAN SCI MATH J, V1, P22
   Raviraj P., 2007, Middle East Journal of Scientific Research, V2, P73
   Xinwu L, 2007, SNPD 2007: Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, Vol 2, Proceedings, P70, DOI 10.1109/SNPD.2007.352
NR 16
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29799
EP 29845
DI 10.1007/s11042-022-12675-9
EA APR 2022
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500017
DA 2024-07-18
ER

PT J
AU Sharma, K
   Rao, BM
   Marwaha, P
   Kumar, A
AF Sharma, Kavya
   Rao, B. Mohan
   Marwaha, Puneeta
   Kumar, Aman
TI Accurate detection of congestive heart failure using electrocardiomatrix
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiomatrix (ECM); Electrocardiogram (ECG); Congestive heart
   failure (CHF); Accuracy; Sensitivity; Specificity; Precision; F1-Score
ID CLASSIFICATION; RECOGNITION; SIGNALS
AB Congestive Heart Failures (CHFs) are prevalent, expensive, and deadly, causing damage or overload to the pumping power of the heart muscles. These leads to severe medical issues amongst humans and contribute to a greater death risk of numerous diseases at a later stage. We need accurate and less difficult techniques to detect these problems in our world with a growing population which will prevent many diseases and reduce deaths. In this work, we have developed a technique to diagnose CHF using the Electrocardiomatrix (ECM) technique. The 1-D ECG signals are transformed to a colourful 3D matrix to diagnose CHF. The detection of CHF using ECM are then compared with annotated CHF Electrocardiogram (ECG) signals manually. It has been found that ECM is able to detect the affected CHF duration from the ECG signals. Also, the ECM provides the reduction in both false positive and false negative which in turn improves the detection accuracy. The performance of the proposed approach has been tested on BIDMC CHF database. The proposed method achieved an accuracy of 97.6%, sensitivity of 98.0%, specificity of 97.0%, precision of 99.4%, and F1-Score of 98.3% . From this study, it has been revealed that the ECM technique allows the accurate, intuitive, and efficient detection of CHF and using ECM practitioners can diagnose the CHF without sacrificing the accuracy.
C1 [Sharma, Kavya; Rao, B. Mohan; Kumar, Aman] Natl Inst Technol, Dept Elect & Commun, Hamirpur, Himachal Prades, India.
   [Marwaha, Puneeta] Natl Inst Technol Karnatka, Dept Elect & Commun, Surathkal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System);
   National Institute of Technology Karnataka
RP Rao, BM (corresponding author), Natl Inst Technol, Dept Elect & Commun, Hamirpur, Himachal Prades, India.
EM skavya38@gmail.com; brao@nith.ac.in; puneetamarwaha@gmail.com;
   akumar@nith.ac.in
RI Kumar, Aman/AAZ-9928-2021
OI Kumar, Aman/0000-0001-9347-2506; MOHANRAO, BADAVATH/0000-0002-4159-3119
CR Acharya UR, 2019, APPL INTELL, V49, P16, DOI 10.1007/s10489-018-1179-1
   Altan G, 2016, COMPUT METH PROG BIO, V137, P23, DOI 10.1016/j.cmpb.2016.09.003
   Awan I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196823
   Aziz W, 2014, ACTA BIOL HUNG, V65, P252, DOI 10.1556/ABiol.65.2014.3.2
   Brown DL, 2019, STROKE, V50, P1676, DOI 10.1161/STROKEAHA.119.025361
   Choudhary GI, 2019, IEEE ACCESS, V7, P9926, DOI 10.1109/ACCESS.2018.2890542
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   ENGEL TR, 1978, ANN INTERN MED, V88, P221, DOI 10.7326/0003-4819-88-2-221
   Gaur L, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.024
   Hossen A, 2007, BIOMED SIGNAL PROCES, V2, P135, DOI 10.1016/j.bspc.2007.05.008
   Hussain L, 2020, MATH BIOSCI ENG, V18, P69, DOI 10.3934/mbe.2021004
   Isler Y, 2007, COMPUT BIOL MED, V37, P1502, DOI 10.1016/j.compbiomed.2007.01.012
   Isler Y, 2019, CHAOS SOLITON FRACT, V118, P145, DOI 10.1016/j.chaos.2018.11.020
   j frankel cardiovascular center j michigan medicine, PREMATURE VENTRICULA
   Jagric T, 2007, TRANSL RES, V149, P145, DOI 10.1016/j.trsl.2006.09.004
   Jelinek HF, 2017, ECG TIME SERIES VARI
   Kumar M, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19030092
   Li D., 2015, J. Integr. Cardiol, V1, P124, DOI DOI 10.15761/JIC.1000133
   Mahajan R, 2017, INT J MED INFORM, V108, P55, DOI 10.1016/j.ijmedinf.2017.09.006
   Marwaha P, 2021, MULTIMED TOOLS APPL, V80, P7675, DOI 10.1007/s11042-020-10104-3
   Masetic Z, 2016, COMPUT METH PROG BIO, V130, P54, DOI 10.1016/j.cmpb.2016.03.020
   O'Connell JB, 2000, CLIN CARDIOL, V23, P6, DOI 10.1002/clc.4960231503
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Pecchia L, 2011, IEEE T INF TECHNOL B, V15, P40, DOI 10.1109/TITB.2010.2091647
   Rich MW, 1997, J AM GERIATR SOC, V45, P968, DOI 10.1111/j.1532-5415.1997.tb02968.x
   Seely AJE, 2004, CRIT CARE, V8, pR367, DOI 10.1186/cc2948
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Surawicz B, 2009, J AM COLL CARDIOL, V53, P976, DOI 10.1016/j.jacc.2008.12.013
   Thakur S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102920
   Thuraisingham RA, 2009, CARDIOL RES PRACT, V2009, DOI 10.4061/2009/807379
   Tripathy RK, 2019, COMPUT METH PROG BIO, V173, P53, DOI 10.1016/j.cmpb.2019.03.008
   Wang LD, 2019, IEEE ACCESS, V7, P69559, DOI 10.1109/ACCESS.2019.2912226
   Yoon KH, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING IMIS 2015, P452, DOI 10.1109/IMIS.2015.88
   Yu SN, 2012, COMPUT METH PROG BIO, V108, P299, DOI 10.1016/j.cmpb.2011.12.015
NR 36
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30007
EP 30023
DI 10.1007/s11042-022-12773-8
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500014
DA 2024-07-18
ER

PT J
AU Xue, JB
   Wu, S
   Wang, ZS
   Wang, HN
   Hu, QC
AF Xue, Jianbin
   Wu, Shang
   Wang, Zesen
   Wang, Hainiu
   Hu, Qingchun
TI Research on energy transmission strategy based on MEC in green
   communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy harvesting; Mobile edge computing; Energy transmission; Wireless
   power transmission
ID RESOURCE-ALLOCATION; WIRELESS; MANAGEMENT
AB Mobile edge computing (MEC) can provide rich computing services near mobile terminals, making it possible for computing intensive tasks to be performed at the edge, however, when renewable energy is the main power supply method for MEC servers, due to the unpredictability of renewable energy, the server will generate additional processing delays due to low energy. In this paper, in order to solve this problem, we incorporate renewable energy into the mobile edge computing, and use wireless power transmission technology to realize energy transmission between MEC servers. By optimizing offloading and wireless resource allocation, the total delay of the system is minimized. The main difficulty of this paper is the combination of unloading decision and its strong coupling with wireless resource allocation. In order to solve this problem, we use Lagrange multiplier method to get the optimal allocation of computing resources, and proposes an effective offloading exclusion algorithm (OEA) to determine the optimal offloading decision. Finally, the experimental results show that compared with other comparison schemes, the proposed scheme can effectively improve the performance of MEC and reduce the time consumption of the system.
C1 [Xue, Jianbin; Wu, Shang; Wang, Zesen; Wang, Hainiu; Hu, Qingchun] Lanzhou Univ Technol, Coll Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Wu, S (corresponding author), Lanzhou Univ Technol, Coll Comp & Commun, Lanzhou 730050, Peoples R China.
EM wus_lut@163.com
FU National Natural Science Foundation of China [61841107, 61461026]
FX This research was supported by the National Natural Science Foundation
   of China (grant nos. 61841107 and 61461026).
CR Bi SZ, 2018, IEEE T WIREL COMMUN, V17, P4177, DOI 10.1109/TWC.2018.2821664
   Bi SZ, 2016, IEEE T WIREL COMMUN, V15, P2351, DOI 10.1109/TWC.2015.2503334
   Bi SZ, 2015, IEEE COMMUN MAG, V53, P117, DOI 10.1109/MCOM.2015.7081084
   Cecchinato D, 2020, INT CONF ACOUST SPEE, P8971, DOI [10.1109/icassp40776.2020.9054410, 10.1109/ICASSP40776.2020.9054410]
   Chen X, 2016, IEEE ACM T NETWORK, V24, P2827, DOI 10.1109/TNET.2015.2487344
   Choi KW, 2018, IEEE INTERNET THINGS, V5, P2657, DOI 10.1109/JIOT.2018.2790578
   Guo JF, 2017, IEEE GLOB COMM CONF
   Hu XY, 2018, IEEE T WIREL COMMUN, V17, P2375, DOI 10.1109/TWC.2018.2794345
   Ji LY, 2019, IEEE INTERNET THINGS, V6, P4744, DOI 10.1109/JIOT.2018.2880812
   Kai CH, 2021, IEEE T COGN COMMUN, V7, P624, DOI 10.1109/TCCN.2020.3018159
   Li ML, 2021, IEEE T VEH TECHNOL, V70, P10941, DOI 10.1109/TVT.2021.3108619
   Lyu XC, 2017, IEEE T VEH TECHNOL, V66, P3435, DOI 10.1109/TVT.2016.2593486
   Malik R, 2021, IEEE J-STSP, V15, P1110, DOI 10.1109/JSTSP.2021.3098963
   Mao YY, 2017, IEEE T WIREL COMMUN, V16, P5994, DOI 10.1109/TWC.2017.2717986
   OUEIS J, 2015, 2015 IEEE 82 VEH TEC, P1, DOI DOI 10.1109/VTCFALL.2015.7391144
   Oueis J, 2015, IEEE VTS VEH TECHNOL
   Qin M, 2021, IEEE INTERNET THINGS, V8, P1896, DOI 10.1109/JIOT.2020.3015970
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Teng YL, 2019, IEEE ACCESS, V7, P74640, DOI 10.1109/ACCESS.2019.2921317
   Wang F, 2020, IEEE T COMMUN, V68, P7140, DOI 10.1109/TCOMM.2020.3011990
   Wang F, 2018, IEEE T WIREL COMMUN, V17, P1784, DOI 10.1109/TWC.2017.2785305
   Wu BW, 2019, IEEE ACCESS, V7, P121982, DOI 10.1109/ACCESS.2019.2938186
   Xia SC, 2021, IEEE T WIREL COMMUN, V20, P6743, DOI 10.1109/TWC.2021.3076201
   Xu J, 2017, IEEE T COGN COMMUN, V3, P361, DOI 10.1109/TCCN.2017.2725277
   Yang XT, 2019, IEEE ACCESS, V7, P117054, DOI 10.1109/ACCESS.2019.2936435
   Zhang GL, 2018, IEEE T IND INFORM, V14, P4642, DOI 10.1109/TII.2018.2843365
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhang T, 2021, IEEE T GREEN COMMUN, V5, P552, DOI 10.1109/TGCN.2021.3050414
   Zhang WW, 2013, IEEE T WIREL COMMUN, V12, P4569, DOI 10.1109/TWC.2013.072513.121842
NR 29
TC 1
Z9 2
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29731
EP 29751
DI 10.1007/s11042-022-12997-8
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500006
DA 2024-07-18
ER

PT J
AU Hooda, H
   Verma, OP
AF Hooda, Heena
   Verma, Om Prakash
TI Fuzzy clustering using gravitational search algorithm for brain image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Brain image segmentation; Gravitational
   search algorithm; Fuzzy clustering; Fuzzy inference rules
ID C-MEANS; MRI
AB Clustering is a key activity in numerous data mining applications such as information retrieval, text mining, image segmentation. Clustering also plays a major role in medical image processing. Manual image segmentation is very tedious and time consuming task and the results of manual segmentation are subjected to errors due to huge and varying data. Therefore, automated segmentation systems are gaining enormous importance nowadays. This paper presents an automated system for segmentation of brain tissues namely white matter, gray matter and cerebrospinal fluid from brain MRI images. In this work, we propose a novel clustering approach, Fuzzy-Gravitational Search Algorithm(GSA) for MRI brain image segmentation. The proposed approach is based on GSA, and uses fuzzy inference rules for controlling the parameter alpha as search progresses. The results of the system are compared with GSA and recent work on brain image segmentation algorithms for both real and simulated database on the basis of Dice Coefficient values. The performance of the Fuzzy-GSA algorithm is also evaluated against four benchmark datasets from the UC Irvine repository. The results illustrate that the Fuzzy-GSA approach attains the highest quality clustering over the selected datasets when compared with several other clustering algorithms.
C1 [Hooda, Heena] Delhi Technol Univ, Dept IT, Delhi, India.
   [Verma, Om Prakash] Delhi Technol Univ, Dept ECE, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Hooda, H (corresponding author), Delhi Technol Univ, Dept IT, Delhi, India.
EM heenahooda@gmail.com; opverma.dce@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X; Hooda, Heena/0000-0003-4465-5546
CR ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Blake Catherine, UCI repository of machine learning databases
   BLASHFIELD RK, 1991, J CLASSIF, V8, P277
   Chen Y, 2012, IET COMPUT VIS, V6, P610, DOI 10.1049/iet-cvi.2011.0263
   Chen Y, 2016, IET IMAGE PROCESS, V10, P865, DOI 10.1049/iet-ipr.2016.0271
   Ching-Yi C, 2004, IEEE INT C NETW SENS
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Fathian M, 2007, APPL MATH COMPUT, V190, P1502, DOI 10.1016/j.amc.2007.02.029
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Hatamlou A, 2012, SWARM EVOL COMPUT, V6, P47, DOI 10.1016/j.swevo.2012.02.003
   Hatamlou A, 2011, LECT NOTES ARTIF INT, V6954, P337, DOI 10.1007/978-3-642-24425-4_44
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   JARDINE N, 1971, INFORM STORAGE RET, V7, P217, DOI 10.1016/0020-0271(71)90051-9
   Kalaiselvi T, 2016, INT J INNOVATIVE SCI, V3, P2348
   Kerr G, 2008, COMPUT BIOL MED, V38, P283, DOI 10.1016/j.compbiomed.2007.11.001
   Liao L, 2008, PATTERN RECOGN LETT, V29, P1580, DOI 10.1016/j.patrec.2008.03.012
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mahmood Q, 2015, IRBM, V36, P185, DOI 10.1016/j.irbm.2015.01.007
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nakib A, 2009, IMAGE VISION COMPUT, V27, P1343, DOI 10.1016/j.imavis.2008.12.004
   Namburu A, 2017, IET IMAGE PROCESS, V11, P777, DOI 10.1049/iet-ipr.2016.0891
   Noback C.R., 2005, The Human Nervous System: Structure and Function
   Ortiz A, 2011, ELECTRON LETT, V47, P585, DOI 10.1049/el.2011.0322
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Roy S, 2016, PROCEDIA COMPUT SCI, V85, P362, DOI 10.1016/j.procs.2016.05.244
   Saglam B, 2006, EUR J OPER RES, V173, P866, DOI 10.1016/j.ejor.2005.04.048
   Saneipour K, 2019, IRAN J RADIOL, V16, DOI 10.5812/iranjradiol.69063
   SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O
   Shelokar PS, 2004, ANAL CHIM ACTA, V509, P187, DOI 10.1016/j.aca.2003.12.032
   Sung CS, 2000, PATTERN RECOGN, V33, P849, DOI 10.1016/S0031-3203(99)00090-4
   Tombros A, 2002, INFORM PROCESS MANAG, V38, P559, DOI 10.1016/S0306-4573(01)00048-6
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Verma OP, 2020, MULTIMED TOOLS APPL, V79, P31517, DOI 10.1007/s11042-020-09320-8
   Wahba M, 2008, THESIS U WATERLOO WA
   Xia Y, 2007, PATTERN RECOGN LETT, V28, P1548, DOI 10.1016/j.patrec.2007.03.012
NR 37
TC 14
Z9 14
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29633
EP 29652
DI 10.1007/s11042-022-12336-x
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700001
DA 2024-07-18
ER

PT J
AU Li, X
   Meng, LL
   Tan, YY
   Zhang, J
   Wan, WB
   Zhang, HX
AF Li, Xue
   Meng, Lili
   Tan, Yanyan
   Zhang, Jia
   Wan, Wenbo
   Zhang, Huaxiang
TI Multiple description coding network based on semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description feature generator network; Semantic segmentation
   encoder network; Decoder network; Multiple description coding (MDC)
AB Considering semantic information in the image compression can prominently improve the quality of synthesized image. In this paper, we propose a multiple description coding network based on semantic segmentation. In the proposed scheme, the semantic segmentation map of input image is encoded as side information to improve the coding efficiency. Firstly, multiple description feature generator network is used to produce multiple description information. Secondly, the produced multiple description information and the semantic segmentation map are fed into the semantic segmentation encoder network to obtain encoded information. Thirdly, we propose side decoder networks and central decoder network, which are used to decode the image. In the proposed architecture, the semantic information is auxiliary information, which is used to compensate the difference between the input image and generated image. After testing the two datasets, it can be seen that when the bit rate is greater than 1BPP, the PSNR can exceed 40. Therefore, the proposed method is feasible.
C1 [Li, Xue; Meng, Lili; Tan, Yanyan; Zhang, Jia; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Li, Xue; Meng, Lili; Tan, Yanyan; Zhang, Jia; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Meng, LL (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.; Meng, LL (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Peoples R China.
EM rosylixue@hotmail.com; mengll_83@hotmail.com
RI meng, li/HTQ-7341-2023; meng, li/GVT-2063-2022
CR Agustsson E., 2017, Soft-to-hard vector quantization for end-to-end learning compressible representations
   Agustsson Eirikur, 2018, GENERATIVE ADVERSARI
   Akbari M., 2018, ARXIV180603348
   [Anonymous], 2014, P NIPS
   Balle J., 2016, 5 INT C LEARNING REP
   Cao Sheng, 2020, ARXIV200402872, P1
   Christopoulos CA, 2000, P ACM MULT 2000 WORK
   Goodfellow IJ, 2014, GENERATIV ADVERSARIA
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2018, IEEE
   Hinton GE, IMAGENET CLASSIFICAT
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Liu ML, 2009, IEEE SIGNAL PROC LET, V16, P253, DOI 10.1109/LSP.2009.2014104
   Lu X, 2020, VIDEO OBJECT SEGMENT
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Mentzer Fabian, 2020, HIGH FIDELITY GENERA
   Minnen David, 2018, ABS180902736 CORR
   Ollivier Y, 2014, COMPUTERENCE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sukthankar R., 2015, INT C LEARN REPR
   Theis L., 2017, ICLR
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao L, 2018, DEEP MULTIPLE DESCRI
   Zhao L, 2019, INT J HYPERTHER, V35, P528, DOI 10.1080/02656736.2018.1511836
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zong JX, 2017, KSII T INTERNET INF, V11, P3935, DOI 10.3837/tiis.2017.08.010
NR 34
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29075
EP 29091
DI 10.1007/s11042-022-12654-0
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375700003
DA 2024-07-18
ER

PT J
AU Ghous, M
   Khan, A
AF Ghous, Mujtaba
   Khan, Ahmed
TI Efficient image enhancement using improved RIQMC based ROHIM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Optimal histogram; RIQMC; ROHIM; PSNR; Image quality
AB Images play a vital role in scientific research and its capturing are different in nature, so that few images are bad in quality because of bad circumstances like bad lightening, undesirable conditions, error in capturing device itself etc. Contrast enhancement plays an important role for better visualization, to get suitable results and for the improvement of quality of image. In this paper, we proposed a technique for the contrast enhancement of both types of images the color images as well as gray scale images. The proposed method calculate two parameters statistics and phase congruency of the image. Furthermore we use optimal histogram method which is RIQMC (reduced reference image quality metric for contrast changes) based and histogram equalization which is non parametric is used to perform the contrast enhancement. We presented two methodologies, purpose of one is the brightness of the image remain preserve and other is used to adaptively increase its brightness. Subjective comparison is performed by considering the improved contrast and absence of useless artifacts. Analyses of the contrast enhancement images are also perform by the quantitative measure. Simulation results on the different images conclude the significance of our proposed model.
C1 [Ghous, Mujtaba] Ghulam Ishaq Khan Inst Engn Sci & Technol, Sawabi, Pakistan.
   [Khan, Ahmed] Monash Univ Malaysia, Sch Informat Technol, Kuala Lumpur, Selangor, Malaysia.
C3 GIK Institute Engineering Science & Technology; Monash University;
   Monash University Malaysia
RP Khan, A (corresponding author), Monash Univ Malaysia, Sch Informat Technol, Kuala Lumpur, Selangor, Malaysia.
EM mujtaba.ghous@giki.edu.pk; ahmed.khan1@monash.edu
CR Ching-Hsi Lu, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P407, DOI 10.1109/IST.2009.5071676
   Chuan, 2014, IEEE INT C CONS EL, V16, P107
   Codruta AO, 2020, IEEE T IMAGE PROCESS, V29, P2653, DOI 10.1109/TIP.2019.2951304
   de Haan K, 2020, P IEEE, V108, P30, DOI 10.1109/JPROC.2019.2949575
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Gao SB, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919947
   Garcia, 2014, IEEE INT C COMP COMM, V6, P28
   Gómez P, 2019, MED BIOL ENG COMPUT, V57, P1451, DOI 10.1007/s11517-019-01965-4
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Gupta B, 2019, MULTIDIM SYST SIGN P, V30, P1829, DOI 10.1007/s11045-019-00630-1
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Ignatov A, 2019, IEEE COMPUT SOC CONF, P2224, DOI 10.1109/CVPRW.2019.00275
   Jadiya S, 2013, 2013 4TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT), P54, DOI 10.1109/ICCCT.2013.6749603
   Kim W, 2019, IEEE ACCESS, V7, P129150, DOI 10.1109/ACCESS.2019.2940452
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Lecca M, 2020, IET IMAGE PROCESS, V14, P4329, DOI 10.1049/iet-ipr.2020.1129
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu, 2015, SPRINGAL OPTICAL SO, P246
   Liu SG, 2019, IEEE T CONSUM ELECTR, V65, P303, DOI 10.1109/TCE.2019.2893644
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Qiu T, 2019, IET IMAGE PROCESS, V13, P1736, DOI 10.1049/iet-ipr.2018.6380
   Rehman, 2015, IEEE INT C DIG INF C, V326, P86
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Rundo L, 2019, EXPERT SYST APPL, V119, P387, DOI 10.1016/j.eswa.2018.11.013
   Sengee N, 2010, IEEE T CONSUM ELECTR, V56, P2727, DOI 10.1109/TCE.2010.5681162
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh H, 2019, COMPUT ELECTR ENG, V75, P245, DOI 10.1016/j.compeleceng.2017.11.014
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Trindade AJ, 2019, GASTROENTEROLOGY, V157, P303, DOI 10.1053/j.gastro.2019.04.048
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Wang YF, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922106
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yang JW, 2003, PATTERN RECOGN LETT, V24, P1805, DOI 10.1010/S0167-8655(03)00005-9
   Yang KF, 2020, IEEE T IMAGE PROCESS, V29, P1493, DOI 10.1109/TIP.2019.2938310
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
NR 38
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28823
EP 28847
DI 10.1007/s11042-022-12721-6
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900006
DA 2024-07-18
ER

PT J
AU Coelho, H
   Monteiro, P
   Gonçalves, G
   Melo, M
   Bessa, M
AF Coelho, Hugo
   Monteiro, Pedro
   Goncalves, Guilherme
   Melo, Miguel
   Bessa, Maximino
TI Authoring tools for virtual reality experiences: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Systematic review; Virtual reality; Immersive experiences; Authoring
   tools
ID ENVIRONMENTS; GAMES
AB Virtual reality (VR) is used in different application fields like health, tourism, or training. Most VR applications for these fields have been built from the ground up without any authoring tool to help the process. This systematic review surveys the existing literature on authoring tools for immersive content and critically analyzes its features and how they are evaluated. It proposes a research agenda with key contribution opportunities for the field. An analysis of the 29 studies that met the eligibility criteria revealed that four records did not present any evaluation regarding the authoring tools' evaluation, and only five records used specialized users to evaluate their authoring tools; all the others used non-specialized users. The most evaluated metrics were usability, effectiveness, efficiency, and satisfaction. The data collected to evaluate the metrics consisted mainly of Likert scales and reported mean opinion score (MOS). However, few records used well-established questionnaires to evaluate those metrics like System Usability Scale, Post-Study System Usability Questionnaire, After-Scenario Questionnaire and Igroup Presence Questionnaire. Additionally, five of the analyzed records included stimuli other than audiovisual. More research is recommended about the usage of ontologies in authoring tools to comprehend the full potential of its usage since none of them had ontologies.
C1 [Coelho, Hugo; Monteiro, Pedro; Goncalves, Guilherme; Melo, Miguel; Bessa, Maximino] Inst Syst & Comp Engn Technol & Sci, Porto, Portugal.
   [Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
C3 INESC TEC; University of Tras-os-Montes & Alto Douro
RP Coelho, H (corresponding author), Inst Syst & Comp Engn Technol & Sci, Porto, Portugal.
EM hugo.r.mendes@inesctec.pt
RI Gonçalves, Guilherme/ISS-7521-2023
OI Gonçalves, Guilherme/0000-0002-3264-587X; Melo,
   Miguel/0000-0003-4050-3473; Monteiro, Pedro/0000-0002-9072-6264; Bessa,
   Maximino/0000-0002-3002-704X
FU FCT - FundacAo para a Ciencia e a Tecnologia [SFRH/BD/147913/2019];
   European Union's Horizon 2020 - The EU Framework Programme for Research
   and Innovation 2014-2020 [833573]; Fundação para a Ciência e a
   Tecnologia [SFRH/BD/147913/2019] Funding Source: FCT
FX This work was done partially funded by the project SFRH/BD/147913/2019
   entitled Authoring Framework for Interactive and Immersive Virtual
   Reality Training financed by the FCT - FundacAo para a Ciencia e a
   Tecnologia. This work was also partially funded by the European Union's
   Horizon 2020 - The EU Framework Programme for Research and Innovation
   2014-2020, under grant agreement No. 833573.
CR Arndt T, 2010, J VISUAL LANG COMPUT, V21, P184, DOI 10.1016/j.jvlc.2009.12.005
   Bassbouss L, 2019, 2019 IEEE 23RD INTERNATIONAL SYMPOSIUM ON CONSUMER TECHNOLOGIES (ISCT), P113, DOI 10.1109/ISCE.2019.8901006
   Bessa M, 2018, COMPUT GRAPH-UK, V71, P35, DOI 10.1016/j.cag.2017.11.003
   Blonna R, 2018, 2018 IEEE REGION TEN SYMPOSIUM (TENSYMP), P118, DOI 10.1109/TENCONSpring.2018.8692018
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cassola F., 2021, P IEEE C VIRTUAL REA, DOI [10.1109/VRW52623.2021.00014, DOI 10.1109/VRW52623.2021.00014]
   Chu J, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P250, DOI 10.1145/3083187.3084015
   Coelho Hugo, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P309, DOI 10.1007/978-3-319-77712-2_30
   Coelho H, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12418
   Coelho H, 2019, MULTIMED TOOLS APPL, V78, P19473, DOI 10.1007/s11042-019-7309-x
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Nguyen C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5428, DOI 10.1145/3025453.3025675
   Danieau F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281518
   de Barros P G, 2013, P 1 S SPAT US INT SU
   De Leon JDO, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3708, DOI 10.1109/TENCON.2016.7848751
   Feng M, 2016, P IEEE VIRT REAL ANN, P173, DOI 10.1109/VR.2016.7504709
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Fidas C, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS (IISA)
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   Gonçalves G, 2020, MULTIMED TOOLS APPL, V79, P22905, DOI 10.1007/s11042-020-09026-x
   Horst R, 2020, LECT NOTES COMPUT SC, V11844, P515, DOI 10.1007/978-3-030-33720-9_40
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kaskalis TH, 2007, EDUC TECHNOL SOC, V10, P135
   Khundam C., 2020, ECTI Trans. Comput. Inf. Technol. (ECTI-CIT), V15, P34
   Kim J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040490
   Kodama R, 2017, IEEE SYMP 3D USER, P130, DOI 10.1109/3DUI.2017.7893329
   Lan GJ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P481
   Lee J, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1756
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Meira J, 2016, 2016 23 ENC PORT COM
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Mendieta Andrade Patricio Esteban, 2020, Podium, P1, DOI 10.31095/podium.2020.37.1
   Mo Y, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: SAFETY AND DISASTER MANAGEMENT, P116
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Narciso D, 2020, MULTIMED TOOLS APPL, V79, P6227, DOI 10.1007/s11042-019-08323-4
   Office I., 2012, INT STANDARD CLASSIF
   Puget J, 2019, TEI'19: PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P197, DOI 10.1145/3294109.3300977
   Seo J, 2001, VR OBJECT REUSE COMP
   Shah SHH., 2019, LECT NOTES ELECT ENG, V536, P73, DOI [10.1007/978-981-13-9341-9_13, DOI 10.1007/978-981-13-9341-9_13]
   Shah SHH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072248
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Torres A, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201707
   van der Meij E, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158612
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Wang J, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND MANAGEMENT INNOVATION, P70
   Wilcocks K, 2020, IEEE T GAMES, V12, P361, DOI 10.1109/TG.2020.3003315
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zarraonandia T, 2016, LECT NOTES COMPUT SC, V10069, P450, DOI 10.1007/978-3-319-48746-5_46
   Zhang L, 2020, P 33 ANN ACM S US IN
   Zhao ZJ, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3352590
   Zidianakis E, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030363
   Zikas P, 2020, VISUAL COMPUT, V36, P1965, DOI 10.1007/s00371-020-01919-0
NR 56
TC 14
Z9 14
U1 10
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 28037
EP 28060
DI 10.1007/s11042-022-12829-9
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100015
DA 2024-07-18
ER

PT J
AU Harizi, R
   Walha, R
   Drira, F
AF Harizi, Riadh
   Walha, Rim
   Drira, Fadoua
TI Deep-learning based end-to-end system for text reading in the wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text reading; Convolutional Neural Networks; Selective search;
   End-to-end system; Characters sequence detection and recognition
ID RESOLUTION ENHANCEMENT; SCENE IMAGES; CHARACTER-RECOGNITION; SPARSE
   REPRESENTATION; LOCALIZATION; DICTIONARIES; HISTOGRAM
AB Scene text reading includes both scene text detection and recognition tasks. These tasks face several challenges including text pattern variability, background complexity and scene image quality. Efficient state-of-the-art scene text reading systems are deep learning based methods. They have shown substantial performance at the cost of a complex architecture with high computational time. This paper introduces a deep learning based end-to-end system to improve text detection and recognition efficiency under a unified framework with a low computational cost. In comparison with existing systems, the main characteristics of the proposed system are four. First, we propose a refined patch based selective search to localize all text instances in a scene image. Second, we propose a unified trainable framework taking scene text detection and recognition. This framework is built using a single yet much smaller Convolutional Neural Networks (CNN). Third, we propose a character segmentation free based approach with no scale normalization. Fourth, we use a spanning tree-based algorithm for character grouping to enhance the word recognition process. The comparative study performed on standard benchmarks, including ICDAR 2003, ICDAR 2013, ICDAR 2015, and SVT datasets, demonstrates that the proposed scene text reading system achieves very promising results mainly in both reduced and generic lexicon-based recognition.
C1 [Harizi, Riadh; Walha, Rim; Drira, Fadoua] Univ Sfax, REGIM Lab, ENIS, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Walha, R (corresponding author), Univ Sfax, REGIM Lab, ENIS, BP 1173, Sfax 3038, Tunisia.
EM riadh.harizi@isimg.tn; rim.walha@isims.usf.tn; fadoua.drira@ieee.org
RI WALHA, RIM/D-9499-2013; harizi, riadh/IQT-8744-2023; Harizi,
   Riadh/JXM-5960-2024
OI DRIRA, Fadoua/0000-0001-6706-4218; Harizi, Riadh/0000-0003-4096-8959;
   Walha, Rim/0000-0002-0483-6329
FU Ministry of Higher Education and Scientific Research
FX This work was carried out with the support of the Ministry of Higher
   Education and Scientific Research and within the framework of
   Tunisian-Indian cooperation in the field of scientific research and
   technology.
CR Ahmed SB, 2017, ARXIV170406821 CORR
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Alsharif O, 2014, 2 INT C LEARN REPR
   Arafat SY, 2020, IEEE ACCESS, V8, P96787, DOI 10.1109/ACCESS.2020.2994214
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Bartz C, 2018, AAAI CONF ARTIF INTE, P6674
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Chen XX, 2020, NEUROCOMPUTING, V381, P261, DOI 10.1016/j.neucom.2019.11.049
   Chen XR, 2004, PROC CVPR IEEE, P366
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elagouni K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P120, DOI 10.1109/DAS.2012.26
   Gao S, 2013, PROC INT CONF DOC, P388, DOI 10.1109/ICDAR.2013.85
   Ghanei S, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417530020
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Goel V, 2013, PROC INT CONF DOC, P398, DOI 10.1109/ICDAR.2013.87
   Gomez L, 2014, ACCV WORKSH
   Gómez L, 2017, PATTERN RECOGN, V70, P60, DOI 10.1016/j.patcog.2017.04.027
   Gómez L, 2013, PROC INT CONF DOC, P467, DOI 10.1109/ICDAR.2013.100
   Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914
   Guemri K, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P174, DOI 10.5220/0006129001740181
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   Harizi R, 2022, MULTIMED TOOLS APPL, V81, P3091, DOI 10.1007/s11042-021-10663-z
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jiang F, 2017, ARXIV170805133 CORR
   Jiri Matase., 2002, BMVC
   Karatzas D, 2015, ICDAR 2015 ROBUST RE
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kimura F., 1992, 5th USPS Advanced Technical Conference, P199
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Lee WT, 2009, PROC CVPR IEEE, P1590, DOI 10.1109/CVPRW.2009.5206521
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long S, 2018, 181104256 ARXIV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5
   Mallek A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P243, DOI 10.5220/0006129102430250
   Minetto R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P227, DOI 10.1109/ICCVW.2011.6130247
   Mishra A., 2012, CVPR
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Raisi Z, 2020, ARXIV200604305 CORR
   Raisi Z., 2021, Journal of Computational Vision and Imaging Systems, V6, P1, DOI [10.15353/jcvis.v6i1.3533, DOI 10.15353/JCVIS.V6I1.3533]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Smith Raymond, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P411, DOI 10.1007/978-3-319-46604-0_30
   Tian SX, 2013, PROC INT CONF DOC, P912, DOI 10.1109/ICDAR.2013.186
   Tong GF, 2020, INT J DOC ANAL RECOG, V23, P103, DOI 10.1007/s10032-019-00348-7
   Tounsi M, 2018, 180607374 CORR ARXIV
   Turki H, 2017, PROC INT CONF DOC, P949, DOI 10.1109/ICDAR.2017.159
   Walha R, 2018, INT J DOC ANAL RECOG, V21, P137, DOI 10.1007/s10032-017-0294-6
   Walha R, 2014, INT CONF FRONT HAND, P696, DOI 10.1109/ICFHR.2014.122
   Walha R, 2015, PROC INT CONF DOC, P871, DOI 10.1109/ICDAR.2015.7333886
   Walha R, 2015, INT J DOC ANAL RECOG, V18, P87, DOI 10.1007/s10032-014-0235-6
   Walha R, 2014, INT C PATT RECOG, P4459, DOI 10.1109/ICPR.2014.763
   Walha R, 2013, LECT NOTES COMPUT SC, V8157, P439, DOI 10.1007/978-3-642-41184-7_45
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang QQ, 2015, PROC INT CONF DOC, P106, DOI 10.1109/ICDAR.2015.7333735
   Wang SW, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107230
   Wang T, 2012, INT C PATT RECOG, P3304
   Ye QX, 2014, LECT NOTES COMPUT SC, V8357, P47, DOI 10.1007/978-3-319-05167-3_4
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yi CC, 2013, PROC INT CONF DOC, P907, DOI 10.1109/ICDAR.2013.185
   Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327
   Yin F, 2017, 170901727 CORR ARXIV
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhao M, 2010, IMAGE VISION COMPUT, V28, P1590, DOI 10.1016/j.imavis.2010.04.002
   Zhong Z, 2016, 160507314 CORR ARXIV
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 85
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24691
EP 24719
DI 10.1007/s11042-022-11998-x
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960000002
DA 2024-07-18
ER

PT J
AU Tang, LL
   Li, ZY
   Liu, Y
   Qi, SH
   Zhang, JJ
   Pan, JC
   Shi, SJ
AF Tang, Linlin
   Li, Zhangyan
   Liu, Yang
   Qi, Shuhan
   Zhang, Jiajia
   Pan, Jiancheng
   Shi, Shuaijie
TI 3D face recognition algorithm based on nose tip contour and radial curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; Radical curve; Geodesic contour
ID FEATURES; SHAPE
AB Human expression variations will cause non-rigid deformation of face scans, this is a challenge in face recognition research. Many rigid registration methods can not achieve good results in dealing with this problem. In this article, a novel method to avoid the influence of non rigid deformation on face recognition which uses radial curve and geodesic contour as features for matching is proposed. It can also reduce data size and speed up calculation. Shape analysis algorithm is also introduced to calculate geodesic distance of corresponding 3D curve of the simplified face as the basis of classification. Experimental results show its high efficiency.
C1 [Tang, Linlin; Li, Zhangyan; Liu, Yang; Qi, Shuhan; Zhang, Jiajia; Pan, Jiancheng; Shi, Shuaijie] Harbin Inst Technol, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology
RP Tang, LL (corresponding author), Harbin Inst Technol, Shenzhen, Peoples R China.
EM hittang@126.com
RI zhao, yujie/JLL-1283-2023; li, zhang/JHV-1750-2023
FU Shenzhen Science and Technology Plan Fundamental Research Funding
   [JCYJ20180507183527919]; Shenzhen Foundational Research Funding
   [JCYJ20180306171938767]
FX This work was supported by Shenzhen Science and Technology Plan
   Fundamental Research Funding JCYJ20180507183527919 and Shenzhen
   Foundational Research Funding JCYJ20180306171938767.
CR [Anonymous], 1986, Curve and Surface Fitting: An Introduction
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   Colombo A, 2011, J MATH IMAGING VIS, V40, P105, DOI 10.1007/s10851-010-0252-0
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Emambakhsh M, 2017, IEEE T PATTERN ANAL, V39, P995, DOI 10.1109/TPAMI.2016.2565473
   Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li XX, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P21, DOI 10.1109/SMI.2007.4
   Li Y, 2018, NEUROCOMPUTING, V275, P1295, DOI 10.1016/j.neucom.2017.09.070
   Liu PJ, 2013, IEEE T IMAGE PROCESS, V22, P914, DOI 10.1109/TIP.2012.2222897
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu H, 2008, IEEE T VLSI SYST, V16, P1346, DOI 10.1109/TVLSI.2008.2002047
   Maes C., 2010, BIOMETRICS THEORY AP, DOI [DOI 10.1109/BTAS.2010.5634543, 10.1109/BTAS.2010.5634543]
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]
   Moenning C., 2003, Proc. Int. Conf. on Visualization, P1027
   Pan G, 2005, INT J IMAGE GRAPH, V5, P573, DOI 10.1142/S0219467805001884
   Roberts A., 2001, First Break, V19, P85, DOI [DOI 10.1046/J.0263-5046.2001.00142.X, 10.1046/j.0263-5046.2001.00142.x, 10.1046/J.0263-5046.2001.00142.X]
   RUSS T, 2006, COMP VIS PATT REC 20, V2, P1391
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Wu YJ, 2003, LECT NOTES COMPUT SC, V2688, P515
   Xu CH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P308
   Xu CH, 2006, PATTERN RECOGN LETT, V27, P1487, DOI 10.1016/j.patrec.2006.02.015
   Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685
NR 25
TC 1
Z9 1
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23889
EP 23912
DI 10.1007/s11042-022-12730-5
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000009
DA 2024-07-18
ER

PT J
AU Hsu, IC
   Yu, JD
AF Hsu, I-Ching
   Yu, Jiun-De
TI A medical Chatbot using machine learning and natural language
   understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language understanding; Chatbot; Cloud computing; Machine
   learning
AB For people with busy schedules, travelling to and from a hospital for treatment is considerably time consuming, which leads them to ignore their health problems. People avoid hospital treatments for small problems, which may eventually develop into major diseases. In terms of time, cost, and convenience, the potential solution for these people to overcome the aforementioned problems is to interact with chatbots to obtain useful medical information. This study proposes a Machine-Learning-based Chatbot Framework that integrates statistical analysis, machine learning and natural language understanding technologies into the Spark cluster to facilitate the development of intelligent chatbot. Based on the proposed framework, this study develops a Medical and Health Information Platform that provides a chatbot interface on LINE messaging app to interact with users to offer useful medical information for user needs. The performance and accuracy of machine learning, namely the decision tree, random forest, and logistic regression algorithms, operating in different Spark cluster computing environments were compared. The test results show that the decision tree algorithm has the best computing performance and the random forest algorithm has better prediction accuracy.
C1 [Hsu, I-Ching; Yu, Jiun-De] Natl Formosa Univ, Dept Comp Sci & Informat Engn, 64 Wenhua Rd, Huwei Township 632, Yunlin, Taiwan.
C3 National Formosa University
RP Hsu, IC (corresponding author), Natl Formosa Univ, Dept Comp Sci & Informat Engn, 64 Wenhua Rd, Huwei Township 632, Yunlin, Taiwan.
EM hsuic@nfu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 110-2637-E-150-004 -]
FX This study was financially supported in part by the Ministry of Science
   and Technology of Taiwan under Contract No. MOST 110-2637-E-150-004 -.
CR Akter, 2016, 2016 19 INT C COMP I
   [Anonymous], 2018, Apache spark, DOI [10.1007/978-3-319-63962-8_37-1, DOI 10.1007/978-3-319-63962-8_37-1]
   Apache, 2018, HAD AP
   Bao QM, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020)
   Bapat R, 2018, 18 INT C WEB ENG
   Bates M, 2019, IEEE PULSE, V10, P12, DOI 10.1109/MPULS.2019.2911816
   Boisvert R, 1997, MATRIX MARKET EXCHAN
   Bouras C, 2010, LECT NOTES ARTIF INT, V6278, P379, DOI 10.1007/978-3-642-15393-8_43
   Chen IC, 2019, INT J WEB INF SYST, V15, P236, DOI 10.1108/IJWIS-02-2018-0015
   Cuzzocrea A, 2020, CEUR WORKSHOP PROC, V2646, P334
   DBPEDIA, 2020, DBPEDIA
   Domann J, 2017, HIGHLY AVAILABLE REA, V10456, P161
   Gambhir S, 2018, INT J HEALTHC INF SY, V13, P1, DOI 10.4018/IJHISI.2018070101
   García-Pedrajas N, 2017, IEEE T NEUR NET LEAR, V28, P470, DOI 10.1109/TNNLS.2015.2506821
   Gupta A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P759
   Harilal, 2020, ACM IND JOINT 7 ACM
   García-Ortega RH, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12525
   Hsu IC, 2020, SOFTWARE PRACT EXPER, V50, P2293, DOI 10.1002/spe.2892
   Hsu IC, 2021, J AMB INTEL HUM COMP, V12, P1023, DOI 10.1007/s12652-020-02119-3
   Ishwarappa, 2015, PROCEDIA COMPUT SCI, V48, P319, DOI 10.1016/j.procs.2015.04.188
   Jambak, 2019, 3 INT C REL INF COMM
   Janwe NJ, 2018, APPL INTELL, V48, P2047, DOI 10.1007/s10489-017-1033-x
   Lavanya PM, 2021, INT CO SIG PROC COMM, P603, DOI 10.1109/ICSPC51351.2021.9451752
   Lokman A.S., 2019, P FUT TECHN C FTC 20
   Maeda H, 2019, 2019 TWELFTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORK (ICMU)
   Mathew, 2019, 3 INT C TRENDS EL IN
   Okuda T, 2018, FUJITSU SCI TECH J, V54, P4
   Pai FP, 2016, APPL INTELL, V44, P1, DOI 10.1007/s10489-015-0690-x
   Paikari E, 2018, 2018 IEEE/ACM 11TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING (CHASE), P13, DOI 10.1145/3195836.3195859
   Park ST, 2020, J AMB INTEL HUM COMP, V11, P1405, DOI 10.1007/s12652-018-0998-6
   Paulheim Heiko, 2018, Reasoning Web. Learning, Uncertainty, Streaming, and Scalability. 14th International Summer School 2018. Tutorial Lectures: Lecture Notes in Computer Science (LNCS 11078), P110, DOI 10.1007/978-3-030-00338-8_5
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pico-Valencia P, 2019, FUTURE GENER COMP SY, V94, P250, DOI 10.1016/j.future.2018.11.042
   Rahman MR, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P138, DOI 10.1109/fie43999.2019.9028657
   Rosruen N, 2018, 2018 3RD TECHNOLOGY INNOVATION MANAGEMENT AND ENGINEERING SCIENCE INTERNATIONAL CONFERENCE (TIMES-ICON)
   Rubiolo M, 2012, INFORM SCIENCES, V194, P107, DOI 10.1016/j.ins.2011.08.008
   Rychalska B., 5 INT C SOC NETW AN
   Swaminathan R, 2019, J TEST EVAL, V47, P4054, DOI 10.1520/JTE20180414
   Tripathi BK, 2017, APPL INTELL, V47, P382, DOI 10.1007/s10489-017-0902-7
   Valtolina S, 2020, BEHAV INFORM TECHNOL, V39, P108, DOI 10.1080/0144929X.2019.1637025
   Van Woensel W, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101931
   Vrancken C, 2019, EXPERT SYST APPL, V125, P268, DOI 10.1016/j.eswa.2019.01.077
   Wen TX, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105432
   Wikipeda, 2020, LAT SEM IND
   Wikipedia, 2016, JIEBA
   Yang, 2018, INT J WIREL MOB COMP, V14, P312, DOI [10.1504/IJWMC.2018.093856, DOI 10.1504/IJWMC.2018.093856]
   Yao L, 2019, 2019 IEEE ACIS 18 IN
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
NR 48
TC 5
Z9 5
U1 12
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23777
EP 23799
DI 10.1007/s11042-022-12820-4
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800023
DA 2024-07-18
ER

PT J
AU Das, D
   Biswas, SK
   Bandyopadhyay, S
AF Das, Dolly
   Biswas, Saroj Kumar
   Bandyopadhyay, Sivaji
TI Perspective of AI system for COVID-19 detection using chest images: a
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Artificial intelligence; COVID-19; Chest images; Image processing;
   Feature extraction; Classification
ID CORONAVIRUS DISEASE 2019; SCENARIO; FEATURES; CT
AB Coronavirus Disease 2019 (COVID-19) is an evolving communicable disease caused due to Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) which has led to a global pandemic since December 2019. The virus has its origin from bat and is suspected to have transmitted to humans through zoonotic links. The disease shows dynamic symptoms, nature and reaction to the human body thereby challenging the world of medicine. Moreover, it has tremendous resemblance to viral pneumonia or Community Acquired Pneumonia (CAP). Reverse Transcription Polymerase Chain Reaction (RT-PCR) is performed for detection of COVID-19. Nevertheless, RT-PCR is not completely reliable and sometimes unavailable. Therefore, scientists and researchers have suggested analysis and examination of Computing Tomography (CT) scans and Chest X-Ray (CXR) images to identify the features of COVID-19 in patients having clinical manifestation of the disease, using expert systems deploying learning algorithms such as Machine Learning (ML) and Deep Learning (DL). The paper identifies and reviews various chest image features using the aforementioned imaging modalities for reliable and faster detection of COVID-19 than laboratory processes. The paper also reviews and compares the different aspects of ML and DL using chest images, for detection of COVID-19.
C1 [Das, Dolly; Biswas, Saroj Kumar; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Assamsilchar, Cachar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, D (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Assamsilchar, Cachar, India.
EM dolly_rs@cse.nits.ac.in; saroj@nits.ac.in; director@nits.ac.in
OI Das, Dolly/0000-0003-1518-3332
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ahmad T, 2020, TRAVEL MED INFECT DI, V36, DOI 10.1016/j.tmaid.2020.101607
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 2020, PEDIATR MED RODZ, V16, P9, DOI 10.15557/PiMR.2020.0003
   [Anonymous], 2021, STRENGTHENING MED IM
   [Anonymous], 2018, IMP ROL MED IM PLAYS
   [Anonymous], 2021, SARS COV 2 VAR CLASS
   [Anonymous], 2020, Laboratory testing for 2019 novel coronavirus (2019-nCoV) in suspected human cases
   [Anonymous], 2021, TRACKING SARS COV 2
   [Anonymous], 2021, TREATM COVID 19
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Aslan MF, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106912
   Backer JA, 2020, EUROSURVEILLANCE, V25, P10, DOI 10.2807/1560-7917.ES.2020.25.5.2000062
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Barstugan M, 2020, ARXIV200309424
   Begley, 2020, COVID 19 TESTING ISS
   Caruso D, 2020, RADIOLOGY, V296, pE79, DOI 10.1148/radiol.2020201237
   Chan JFW, 2020, J CLIN MICROBIOL, V58, DOI 10.1128/JCM.00310-20
   Chan JFW, 2020, LANCET, V395, P514, DOI 10.1016/S0140-6736(20)30154-9
   Chatterjee P, 2020, INDIAN J MED RES, V151, P147, DOI 10.4103/ijmr.IJMR_519_20
   Chowdhury NK, 2020, ARXIV200911850V2, P7, DOI [10.7717/peerj-cs.551, DOI 10.7717/PEERJ-CS.551]
   Corman V M, 2012, Euro Surveill, V17
   Coutard B, 2020, ANTIVIR RES, V176, DOI 10.1016/j.antiviral.2020.104742
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   Dhama K, 2020, TRAVEL MED INFECT DI, V37, DOI 10.1016/j.tmaid.2020.101755
   Dhama K, 2020, CLIN MICROBIOL REV, V33, DOI 10.1128/CMR.00028-20
   Duan YN, 2020, RADIOLOGY, V295, P21, DOI 10.1148/radiol.2020200323
   Elaziz MA, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235187
   Evangelin MP, 2020, J MED BIOMED APPL SC, V8, P354, DOI [10.15520/jmbas.v8i4.217, DOI 10.15520/JMBAS.V8I4.217]
   Gaillard, CASE STUDY
   Global Situation, WHO WHO COR COVID 19
   Guan WJ, 2020, NEW ENGL J MED, V382, P1861, DOI 10.1056/NEJMc2005203
   Gupta, 2020, TREND ANAL FORECASTI, DOI [10.24321/2455.7048.202013, DOI 10.24321/2455.7048.202013, 10.1101/2020.03.26.20044511]
   Hoffmann Markus, 2020, bioRxiv, DOI 10.1101/2020.08.05.237651
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Jadhav S, 2021, ARXIV PREPRINT ARXIV
   Jain G, 2020, BIOCYBERN BIOMED ENG, V40, P1391, DOI 10.1016/j.bbe.2020.08.008
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Ji W, 2020, J MED VIROL, V92, P433, DOI 10.1002/jmv.25682
   Kamal KC, 2021, SIGNAL IMAGE VIDEO P, V15, P959, DOI 10.1007/s11760-020-01820-2
   Ke RA, 2021, J THEOR BIOL, V517, DOI 10.1016/j.jtbi.2021.110621
   Kitchener, 2013, IMPORTANCE MED IMAGI
   Lalmuanawma S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110059
   Lee KS, 2020, J PERS MED, V10, DOI 10.3390/jpm10040213
   Lee PI, 2020, J MICROBIOL IMMUNOL, V53, P365, DOI 10.1016/j.jmii.2020.02.001
   Lei Junqiang, 2020, Radiology, V295, P18, DOI 10.1148/radiol.2020200236
   Letko M, 2020, NAT MICROBIOL, V5, P562, DOI [10.1038/s41564-020-0688-y, 10.1101/2020.01.22.915660]
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li X, 2020, SCI CHINA LIFE SCI, V63, P461, DOI 10.1007/s11427-020-1645-7
   Li XG, 2020, J MED VIROL, V92, P602, DOI 10.1002/jmv.25731
   Li Yan, 2020, American Journal of Roentgenology, V214, P1280, DOI 10.2214/AJR.20.22954
   Liu K, 2020, J INFECTION, V80, pE14, DOI 10.1016/j.jinf.2020.03.005
   Lu RJ, 2020, LANCET, V395, P565, DOI 10.1016/S0140-6736(20)30251-8
   Malik YS, 2020, VET QUART, V40, P68, DOI 10.1080/01652176.2020.1727993
   Marimuthu S, 2021, CLIN EPIDEMIOL GLOB, V9, P57, DOI 10.1016/j.cegh.2020.06.012
   Murdoch DR, 2020, NEW ZEAL MED J, V133, P12
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Pandey Kirti, 2021, COVID VACCINES APPRO
   Qian LJ, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200033
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rajaraman Sivaramakrishnan, 2020, medRxiv, DOI 10.1101/2020.05.04.20090803
   Ranjan R, 2021, CURR SCI INDIA, V121, P85, DOI 10.18520/cs/v121/i1/85-93
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rodriguez-Morales AJ, 2020, J PURE APPL MICROBIO, V14, P5, DOI 10.22207/JPAM.14.1.02
   Rodriguez-Morales Alfonso J, 2020, Infez Med, V28, P3
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Schwartz DA, 2020, ARCH PATHOL LAB MED, V144, P799, DOI 10.5858/arpa.2020-0901-SA
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   Sitaula C, 2021, APPL INTELL, V51, P2850, DOI 10.1007/s10489-020-02055-x
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Tan WJ, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00140-0
   Tang ZY, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbf9e
   Walls AC, 2020, CELL, V181, P281, DOI [10.1016/j.cell.2020.02.058, 10.1016/j.cell.2020.11.032]
   Wan YS, 2020, J VIROL, V94, DOI [10.1128/JVI.00127-20, 10.1128/JVI.02015-19]
   Wang C, 2020, LANCET, V395, P470, DOI 10.1016/S0140-6736(20)30185-9
   Wang LS, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.20
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang Yuhui, 2020, Radiology, V296, pE55, DOI 10.1148/radiol.2020200843
   Wrapp D, 2020, SCIENCE, V367, P1260, DOI [10.1126/science.abb2507, 10.1101/2020.02.11.944462]
   Xiao K., 2020, ISOLATION CHARACTERI, DOI [DOI 10.1101/2020.02.17.951335, 10.1101/2020.02.17.951335]
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Xu YH, 2020, J INFECTION, V80, P394, DOI 10.1016/j.jinf.2020.02.017
   Young BE, 2020, JAMA-J AM MED ASSOC, V323, P1488, DOI 10.1001/jama.2020.3204
   Yu L, 2020, CLIN CHEM, V66, P975, DOI 10.1093/clinchem/hvaa102
   Zhang J., 2020, arXiv preprint arXiv:2003.12338, P1
   Zhang NR, 2020, J MED VIROL, V92, P408, DOI 10.1002/jmv.25674
   Zhao D, 2020, OXFORD ACAD CLIN INF
   Zhou P, 2020, NATURE, V579, P270, DOI 10.1038/s41586-020-2012-7
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
   Zu ZY, 2020, RADIOLOGY, V296, pE15, DOI 10.1148/radiol.2020200490
NR 98
TC 11
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21471
EP 21501
DI 10.1007/s11042-022-11913-4
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700005
PM 35310889
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Jokar, E
   Mosleh, M
   Kheyrandish, M
AF Jokar, Ehsan
   Mosleh, Mohammad
   Kheyrandish, Mohammad
TI Discovering community structure in social networks based on the synergy
   of label propagation and simulated annealing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex networks; Social networks; Community detection; Clustering;
   Label propagation; Simulated annealing
ID GENETIC ALGORITHM; OPTIMIZATION; MODULARITY; NODE
AB Community detection is one of the critical research areas in the analysis of complex networks. Numerous algorithms have been devised for this purpose. Despite advances in this field, existing methods are far from accurately identifying the ground-truth community structures of many complex networks. In this paper, we propose a hybrid community detection method, named LPASA, to uncover communities in complex networks accurately. The proposed method is based on label propagation and the simulated annealing algorithm. Label propagation is a fast and straightforward community detection approach that utilizes the topological features of the input network. LPASA uses label propagation to provide the initial population and choose the best starting point for the next phase. Since community detection is an NP-complete problem, meta-heuristic methods such as Simulated Annealing (SA) can also be used for this problem. The SA Algorithm is a renowned and influential meta-heuristic algorithm for finding the global optimal. The proposed method uses a problem-specific variant of the SA algorithm to efficiently convergence to the best possible solution. To this end, instead of a completely random move from the current solution to a neighboring one, a pseudo-random motion is used that considers the network structure. LPASA needs no prior information to discover network communities. The experiments on synthetic and known real-world networks have shown that LPASA is accurate and comparable with the state-of-the-art community detection methods. The results showed that LPASA could improve the mean modularity up to 49.27% on real-world networks compared to various tested methods.
C1 [Jokar, Ehsan; Mosleh, Mohammad; Kheyrandish, Mohammad] Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
C3 Islamic Azad University
RP Mosleh, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
EM Mosleh@iaud.ac.ir
RI Jokar, Ehsan/ISU-7387-2023
OI Jokar, Ehsan/0000-0001-5499-8409; Mosleh, Mohammad/0000-0002-0991-1623
CR Attal JP, 2021, APPL INTELL, V51, P8067, DOI 10.1007/s10489-021-02250-4
   Behera RK, 2020, NEURAL COMPUT APPL, V32, P9649, DOI 10.1007/s00521-019-04487-0
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Cai B, 2020, PHYSICA A, V556, DOI 10.1016/j.physa.2020.124826
   Cai Q, 2014, NEURAL NETWORKS, V58, P4, DOI 10.1016/j.neunet.2014.04.006
   Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008
   Donath WE, 2003, Selected Papers Of Alan J Hoffman: With Commentary, P437
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gabardo AC, 2020, MEMET COMPUT, V12, P87, DOI 10.1007/s12293-020-00300-x
   Garza SE, 2019, PHYSICA A, V534, DOI 10.1016/j.physa.2019.122058
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Gleiser PM, 2003, ADV COMPLEX SYST, V6, P565, DOI 10.1142/S0219525903001067
   Gui Q, 2018, PATTERN RECOGN LETT, V109, P103, DOI 10.1016/j.patrec.2017.12.018
   Guimerà R, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.025101
   Jin D, 2019, INT C ART NEUR NETW
   Jin D, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9203-0
   Jokar E, 2019, PHYS LETT A, V383, P718, DOI 10.1016/j.physleta.2018.11.033
   Kernighan B. W., 1970, The Bell System Technical Journal, V49, P291, DOI [10.1002/j.1538-7305.1970.tb01770.x, DOI 10.1002/J.1538-7305.1970.TB01770.X]
   Kipf TN, 2016, ARXIV
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kouni IB, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2019.113020
   Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.016118
   Leskovec J, 2016, ACM T INTEL SYST TEC, V8, DOI 10.1145/2898361
   Li WZ, 2020, CMC-COMPUT MATER CON, V63, P755, DOI 10.32604/cmc.2020.07984
   Li YF, 2018, PHYSICA A, V510, P219, DOI 10.1016/j.physa.2018.06.091
   Li ZT, 2016, PHYSICA A, V449, P336, DOI 10.1016/j.physa.2015.12.126
   Liu X, 2017, INFORM SCIENCES, V381, P304, DOI 10.1016/j.ins.2016.11.028
   Lu H, 2020, NEURAL PROCESS LETT, V51, P1731, DOI 10.1007/s11063-019-10170-1
   Lusseau D, 2003, BEHAV ECOL SOCIOBIOL, V54, P396, DOI 10.1007/s00265-003-0651-y
   Meng YY, 2018, PHYS LETT A, V382, P2305, DOI 10.1016/j.physleta.2018.05.044
   Messaoudi I, 2019, APPL INTELL, V49, P2119, DOI 10.1007/s10489-018-1386-9
   Mu CH, 2019, SOFT COMPUT, V23, P12683, DOI 10.1007/s00500-019-03820-y
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Pizzuti C, 2008, LECT NOTES COMPUT SC, V5199, P1081, DOI 10.1007/978-3-540-87700-4_107
   Pizzuti C, 2012, IEEE T EVOLUT COMPUT, V16, P418, DOI 10.1109/TEVC.2011.2161090
   Poaka V, 2016, INT C CONC MOD
   Psorakis I, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.066114
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Shang RH, 2013, PHYSICA A, V392, P1215, DOI 10.1016/j.physa.2012.11.003
   Wang T, 2020, PHYSICA A, V551, DOI 10.1016/j.physa.2020.124137
   Xu Y, 2020, PHYSICA A, V537, DOI 10.1016/j.physa.2019.122751
   Xu Y, 2019, PHYSICA A, V515, P112, DOI 10.1016/j.physa.2018.09.191
   You XM, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.030
   Yuan Q, 2021, COMPUT STAT DATA AN, V157, DOI 10.1016/j.csda.2020.107163
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zadeh PM, 2015, 2015 INT C COLL TECH
   Zalik KR, 2018, INFORM SCIENCES, V445, P38, DOI 10.1016/j.ins.2018.02.063
   Zhang B, 2020, COMMUNITY CENTRIC GR
   Zhang Y, 2020, NEUROCOMPUTING, V413, P107, DOI 10.1016/j.neucom.2020.06.088
   Zhang Y, 2020, PHYSICA A, V539, DOI 10.1016/j.physa.2019.122937
   Zhou XJ, 2019, NEUROCOMPUTING, V334, P89, DOI 10.1016/j.neucom.2019.01.009
   Zhou X, 2015, PHYSICA A, V427, P289, DOI 10.1016/j.physa.2015.02.020
NR 54
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21449
EP 21470
DI 10.1007/s11042-022-12745-y
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700002
DA 2024-07-18
ER

PT J
AU Cho, S
   Kim, H
   Kim, JS
   Kim, H
   Kwon, J
AF Cho, Sungmin
   Kim, Hyeseong
   Kim, Ji Soo
   Kim, Hyomin
   Kwon, Junseok
TI Adversarial attack can help visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial Attack; Visual Tracking; Noise-injected Markov chain Monte
   Carlo
AB We present a novel noise-injected Markov chain Monte Carlo (NMCMC) method for visual tracking, which enables fast convergence through adversarial attacks. The proposed NMCMC consists of three steps: noise-injected proposal, acceptance, and validation. We intentionally inject noise into the proposal function to cause a shift in a direction that is opposite to the moving direction of a target, which is viewed in the context of an adversarial attack. This noise injection mathematically induces the proposed visual tracker to find a target proposal distribution using a small number of samples, which allows the tracker to be robust to drifting. Experimental results demonstrate that our method achieves state-of-the-art performance, especially when severe perturbations caused by an adversarial attack exist in the target state.
C1 [Cho, Sungmin; Kim, Hyeseong; Kim, Ji Soo; Kim, Hyomin; Kwon, Junseok] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Kwon, J (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM jskwon@cau.ac.kr
OI kwon, junseok/0000-0001-9526-7549
FU Institute of Information communications Technology Planning Evaluation
   (IITP) - Korea government(MSIT) [2021-0-01341]
FX U This work was supported by Institute of Information communications
   Technology Planning Evaluation (IITP) grant funded by the Korea
   government(MSIT) (No.2021-0-01341, Artificial Intelligence Graduate
   School Program(ChungAng university)).
CR Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eykholt K., 2017, ARXIV PREPRINT ARXIV
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Franzke B, 2019, PHYS REV E, V100, DOI 10.1103/PhysRevE.100.053309
   Huang L, 2019, AAAI CONF ARTIF INTE, P9945
   Jia Shuai, 2020, ECCV
   Jia Y, 2020, ICLR
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kwon J., 2016, SPL, V23, P1514
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang Siyuan, 2020, ECCV
   Pu S, 2018, ADV NEUR IN, V31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wei XX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P954
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yan XY, 2020, INT CONF ACOUST SPEE, P2897, DOI [10.1109/ICASSP40776.2020.9053574, 10.1109/icassp40776.2020.9053574]
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang Z, 2019, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2019.00519
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 27
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35283
EP 35292
DI 10.1007/s11042-022-12789-0
EA MAR 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000770061500005
DA 2024-07-18
ER

PT J
AU Chen, WR
   Chen, JD
   Zeb, A
   Yang, SY
   Zhang, DF
AF Chen, Weirong
   Chen, Junde
   Zeb, Adnan
   Yang, Shuangyuan
   Zhang, Defu
TI Mobile convolution neural network for the recognition of potato leaf
   disease images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Potato crop diseases; Mobile neural network; Octave convolution;
   Attention module; Image identification
AB Plant disease management plays a crucial role in food security as diverse diseases can cause a substantial reduction of crop yield. As an important staple, potatoes are highly consumed over the entire world, while they are easy to be infected by various diseases too. The early recognition and warning can suppress the outbreak of potato diseases and increase the yield of crops. For this purpose, the paper proposes a novel network architecture named MobOca_Net to recognize potato diseases. The lightweight MobileNet V2 was chosen as the foundation network, and to improve the learning capability of minute crop lesion features, we modified the classical MobileNet-V2 by incorporating the attention mechanism behind the pre-trained network, which was followed by an octave convolution block for extracting high-dimensional features. Moreover, the transfer learning from the PlantVillage dataset was applied for model training. The proposed procedure delivered a superior performance gain over other compared methods, and it realized an average identification accuracy of 97.73% on different potato disease types. Experimental findings present a competitive performance and prove the validity of the proposed procedure.
C1 [Chen, Weirong] Ningde Normal Univ, Dept Informat & Elect Engn, Ningde 352100, Peoples R China.
   [Chen, Junde; Zeb, Adnan; Yang, Shuangyuan; Zhang, Defu] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
C3 Ningde Normal University; Xiamen University
RP Yang, SY (corresponding author), Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
EM chen2wo@126.com; yangshuangyuan@xmu.edu.cn
RI Chen, Wei/GZK-7348-2022
FU Fundamental Research Funds for the Central Universities [20720181004]
FX The authors would like to thank Fundamental Research Funds for the
   Central Universities (No. 20720181004) and the authors also thank
   editors and anonymous reviewers for providing constructive advice.
CR Al-Amin M., 2019, 2019 22 INT C COMP I, P1, DOI DOI 10.1109/ICCIT48885.2019.9038229
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Athanikar G., 2016, International Journal of Computer Science and Mobile Computing, V5, P76
   Barman U., 2020, INT C COMPUTATIONAL, P682, DOI [DOI 10.1109/COMPE49325.2020.9200015, 10.1109/ComPE49325.2020.9200015]
   Biswas S, 2014, 2014 IEEE CANADA INTERNATIONAL HUMANITARIAN TECHNOLOGY CONFERENCE (IHTC)
   Chen J, 2020, PLANT PATHOL
   Chen JD, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114514
   Chen JD, 2021, IET IMAGE PROCESS, V15, P1115, DOI 10.1049/ipr2.12090
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen JD, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053023
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   El Massi I, 2017, INT J COMPUT APPL, V975, P8887
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hughes A, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.17
   Islam F, 2019 IEEE INT C ROB
   Islam M, 2017, CAN CON EL COMP EN
   Ji YM, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103054
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Khalifa, MACHINE LEARNING BIG, P63
   Kingma D. P., 2014, arXiv
   Marino S, 2019, PROC SPIE, V11172, DOI 10.1117/12.2521264
   Oppenheim D, 2019, PHYTOPATHOLOGY, V109, P1083, DOI 10.1094/PHYTO-08-18-0288-R
   Patil P, 2017, IEEE I C COMP INT CO, P1071
   Pattnaik G, 2020, APPL ARTIF INTELL, V34, P981, DOI 10.1080/08839514.2020.1792034
   Radford A., 2015, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sholihati RA, 2020, 2020 INT EL S IES
   Shrivastava V.K., 2019, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V42, P631, DOI 10.5194/isprs-archives-XLII-3-W6-631-2019
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 40
TC 15
Z9 15
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20797
EP 20816
DI 10.1007/s11042-022-12620-w
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000005
DA 2024-07-18
ER

PT J
AU Bansal, R
   Badal, N
AF Bansal, Reena
   Badal, Neelendra
TI A novel approach for dual layer security of message using Steganography
   and Cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Data hiding; Data embedding; Elliptic Curve
   Cryptography; LSB Inversion; Cryptography; Steganography; Histogram etc
AB It is well known that the world is becoming more interconnected with the help of World Wide Web in distributed environment. Persons and Organizations want to share their valuable information over World Wide Web through internet in reliable and secure manner. The Steganography is an elegant strategy to pass on the private data to an approved beneficiary with the most solid wellbeing measure which prompts maintaining a strategic distance from the breaks of information security. These days the meaning of taking solid assurance measures in information correspondence medium has a difficult undertaking on account of security issues created by unapproved intercession. This introduction expects to provide another methodology dependent on a combination of Cryptography and Steganography system to hide the secret information into a cover object (Image, Text, Video etc.) with an improved level of security. In proposed methodology, the Elliptic Curve Cryptography (ECC) is used to encode the secret data and LSB Inversion method for embedding the scrambled information into a cover object. Proposed methodology based on two different techniques has achieved some fundamental characteristics known as information classification, respectability check, limit and heartiness which are the proof of successful execution of this proposed methodology. This new methodology strongly tried through a few steganalysis assaults like investigation of Chi-square, Visual and Histogram. Results show that stego picture has strong resistance power against all assaults.
C1 [Bansal, Reena] Hindustan Aeronaut Ltd Sch, Amethi, UP, India.
   [Badal, Neelendra] Rajkiya Engn Coll, Bijnor, UP, India.
RP Bansal, R (corresponding author), Hindustan Aeronaut Ltd Sch, Amethi, UP, India.
EM bansalrina26@gmail.com
RI Badal, Neelendra/KCX-8244-2024
CR [Anonymous], INFORM HIDING APPL
   [Anonymous], INFORM MED UNLOCKED
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Das R, 2019, COMPUT SYST SCI ENG, V34, P23
   Desoky Abdelrahman, 2008, Journal of Digital Forensic Practice, V2, P132, DOI 10.1080/15567280802558818
   HSU CH, 2018, J AMB INTEL HUM COMP, P111
   Kekre HB, 2009, P ACM INT C ADV COMP, P342
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Mandal JK, 2012, COMPUTER SCI INFORM, P93
   Mathan K, 2018, DES AUTOM EMBED SYST, V22, P225, DOI 10.1007/s10617-018-9205-4
   Meng RH, 2020, CMC-COMPUT MATER CON, V63, P183, DOI 10.32604/cmc.2020.05317
   Pan J-S, 2013, RECENT ADV INFORM HI
   PAN JS, 2007, INTELLIGENT MULTIMED
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0043-3
   Parthasarathy P., 2018, Int. J. Comput. Appl, V42, P222, DOI [10.1080/1206212X.2018.1457471, DOI 10.1080/1206212X.2018.1457471]
   Rahman S, 2020, CMC-COMPUT MATER CON, V64, P31, DOI 10.32604/cmc.2020.09186
   RajeshKumar N, 2020, CMC-COMPUT MATER CON, V65, P1283, DOI 10.32604/cmc.2020.011226
   Shanthakumari R., 2017, ASIAN J RES SOC SCI, V7, P198, DOI DOI 10.5958/2249-7315.2017.00015.6
   Shanthakumari R, 2015, INT J INNOV RES COMP, V3
   Shanthakumari R., 2014, INT J COMPUT SCI ENG, V4, P400
   Sharmila B., 2012, ICTACT J IMAGE VIDEO, V02, P03
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Tyagi V., 2012, J GLOBAL RES COMP SC, V3, P53
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P18503, DOI 10.1007/s11042-018-5866-z
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu MY, 2004, PATTERN RECOGN LETT, V25, P301, DOI 10.1016/j.patrec.2003.10.013
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 31
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20669
EP 20684
DI 10.1007/s11042-022-12084-y
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600005
DA 2024-07-18
ER

PT J
AU Naiemi, F
   Ghods, V
   Khalesi, H
AF Naiemi, Fatemeh
   Ghods, Vahid
   Khalesi, Hassan
TI Scene text detection and recognition: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text localization; Text image detection; End-to-end recognition;
   Multi oriented; Convolutional neural network; Text recognition
ID CHARACTER-RECOGNITION; NEURAL-NETWORK; IMAGES; LOCALIZATION; TRANSFORM;
   SPARSE
AB Scene text detection and recognition have been given a lot of attention in recent years and have been used in many vision-based applications. In this field, there are various types of challenges, including images with wavy text, images with text rotation and orientation, changing the scale and variety of text fonts, noisy images, wild background images, which make the detection and recognition of text from the image more complex and difficult. In this article, we first presented a comprehensive review of recent advances in text detection and recognition and described the advantages and disadvantages. The common datasets were introduced. Then, the recent methods compared together and analyzed the text detection and recognition systems. According to the recent decade studies, one of the most important challenges is curved and vertical text detection in this field. We have expressed approaches for the development of the detection and recognition system. Also, we have described the methods that are robust in the detection and recognition of curved and vertical texts. Finally, we have presented some approaches to develop text detection and recognition systems as the future work.
C1 [Naiemi, Fatemeh; Ghods, Vahid] Islamic Azad Univ, Dept Elect & Comp Engn, Semnan Branch, Semnan, Iran.
   [Khalesi, Hassan] Islamic Azad Univ, Dept Elect & Comp Engn, Garmsar Branch, Garmsar, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Ghods, V (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Semnan Branch, Semnan, Iran.
EM daneshjo_naimi@yahoo.com; v.ghods@semnaniau.ac.ir;
   h.khalesi@iau-garmsar.ac.ir
RI Naiemi, fatemeh/AAR-7469-2020
OI Naiemi, fatemeh/0000-0001-5571-8560
CR Ali, 2015, VFAST T SOFT ENG, V3, P67
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Alsharif Ouais, 2013, ARXIV PREPRINT ARXIV
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163
   Bai Nong, 2016, ARXIV160609002
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Baran R, 2018, ADV INTELL SYST COMP, V722, P42, DOI 10.1007/978-3-319-73888-8_8
   Ben Ayed A, 2015, PROCEDIA COMPUT SCI, V53, P216, DOI 10.1016/j.procs.2015.07.297
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chen J, 2017, SOFT COMPUT, V21, P753, DOI 10.1007/s00500-015-1811-5
   Chen YX, 2019, I C COMM SOFTW NET, P688, DOI [10.1109/ICCSN.2019.8905316, 10.1109/iccsn.2019.8905316]
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dai YC, 2018, INT C PATT RECOG, P3604, DOI 10.1109/ICPR.2018.8546066
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Feng W, 2019, IEEE I CONF COMP VIS, P9075, DOI 10.1109/ICCV.2019.00917
   Goel V, 2013, PROC INT CONF DOC, P398, DOI 10.1109/ICDAR.2013.87
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   Han JW, 2022, IEEE T PATTERN ANAL, V44, P579, DOI 10.1109/TPAMI.2019.2933510
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   He WH, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107026
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Islam MR, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P15, DOI 10.1109/ICIEV.2016.7760054
   Jaderberg M., 2014, CORR
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Jiang YY, 2018, INT C PATT RECOG, P3610, DOI 10.1109/ICPR.2018.8545598
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Kumar S., 2016, INT J COMPUT APPL, V137, P40
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Liao MH, 2019, AAAI CONF ARTIF INTE, P8714
   Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liu FG, 2019, IEEE ACCESS, V7, P44219, DOI 10.1109/ACCESS.2019.2908933
   Liu XY, 2019, INT J DOC ANAL RECOG, V22, P143, DOI 10.1007/s10032-019-00320-5
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Long Shangbang, 2020, ICASSP 2020 2020 IEE
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Mishra A., 2012, CVPR
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Naiemi F, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114549
   Naiemi F, 2021, CIRC SYST SIGNAL PR, V40, P4452, DOI 10.1007/s00034-021-01674-0
   Naiemi F, 2020, MULTIMED TOOLS APPL, V79, P27137, DOI 10.1007/s11042-020-09318-2
   Naiemi F, 2019, SOFT COMPUT, V23, P11759, DOI 10.1007/s00500-018-03728-z
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Neycharan JG, 2018, MULTIMED TOOLS APPL, V77, P7615, DOI 10.1007/s11042-017-4663-4
   Novikova T., 2012, EUR C COMP VIS
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Qin SY, 2019, IEEE I CONF COMP VIS, P4703, DOI 10.1109/ICCV.2019.00480
   Ranjbarzadeh R, 2020, MEASUREMENT, V150, DOI 10.1016/j.measurement.2019.107086
   Ren XH, 2017, IEEE ACCESS, V5, P3193, DOI 10.1109/ACCESS.2017.2676158
   Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Sung MC, 2015, PROC INT CONF DOC, P426, DOI 10.1109/ICDAR.2015.7333797
   Tabassum Adiba, 2015, 2015 5 INT C COMM SY
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Vasilopoulos N, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013009
   Veit A, 2016, ADV NEUR IN, V29
   Wahyono, 2015, KOR-JPN JT WORKS FR
   Wang H, 2017, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND MACHINE LEARNING (IML'17), DOI 10.1145/3109761.3158411
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang QQ, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2713-1
   Wang RM, 2015, NEUROCOMPUTING, V157, P153, DOI 10.1016/j.neucom.2015.01.023
   Wang T, 2012, INT C PATT RECOG, P3304
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang QP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1071
   Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216
   Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
   Zhang YP, 2019, PROC CVPR IEEE, P2735, DOI 10.1109/CVPR.2019.00285
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zheng YC, 2019, PATTERN RECOGN, V93, P558, DOI 10.1016/j.patcog.2019.05.014
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong ZY, 2019, INT J DOC ANAL RECOG, V22, P315, DOI 10.1007/s10032-019-00335-y
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182227
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
   Zhu Zhen, 2018, 2018 13 IAPR INT WOR
NR 114
TC 12
Z9 13
U1 9
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20255
EP 20290
DI 10.1007/s11042-022-12693-7
EA MAR 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600015
DA 2024-07-18
ER

PT J
AU Yang, JH
   Hu, K
   Wang, XC
   Wang, HF
   Liu, Q
   Mao, Y
AF Yang, Jinhui
   Hu, Kun
   Wang, Xiaochao
   Wang, Hongfei
   Liu, Qiong
   Mao, Yao
TI An efficient and robust zero watermarking algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial domain; Zero watermarking; Geometric attack; Logistic chaotic
   encryption
ID PROTECTION SCHEME; IMAGE; INVARIANTS; MOMENTS
AB To improve the resistance to geometric rotation attacks and to solve the problem of high computational complexity of existing watermarking algorithms, a novel efficient and robust zero watermarking algorithm in spatial domain is proposed. First, the central pixels of different channels of colorful host image are taken as the center of the circle, and the features of the image are constructed by the pixels covered by rings with different radius and width. The binary feature image is obtained by binary operation on the constructed image features. Then, the zero watermark image is constructed by XOR operation for the scrambled binary feature image and copyright watermark image encrypted Logistic chaotic algorithm. Finally, the zero watermark image is stored in the intellectual property database for copyright certification in possible copyright disputes. Experimental results show that the proposed algorithm is robust to geometric rotation attacks and common image processing attacks. Compared with similar zero watermarking schemes, the proposed algorithm has lower computational complexity and better robustness.
C1 [Yang, Jinhui; Hu, Kun; Wang, Hongfei; Liu, Qiong; Mao, Yao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Yang, Jinhui; Liu, Qiong; Mao, Yao] Chinese Acad Sci, Inst Opt & Elect, Chengdu 610209, Peoples R China.
   [Yang, Jinhui; Liu, Qiong; Mao, Yao] Chinese Acad Sci, Key Lab Opt Engn, Chengdu 610209, Peoples R China.
   [Hu, Kun; Wang, Hongfei] Chinese Acad Sci, Technol & Engn Ctr Space Utilizat, Key Lab Space Utilizat, Beijing 100094, Peoples R China.
   [Wang, Xiaochao] Tiangong Univ, Sch Math Sci, Tianjin 300387, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Optics & Electronics,
   CAS; Chinese Academy of Sciences; Chinese Academy of Sciences;
   Technology & Engineering Center for Space Utilization, CAS; Tiangong
   University
RP Mao, Y (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Mao, Y (corresponding author), Chinese Acad Sci, Inst Opt & Elect, Chengdu 610209, Peoples R China.; Mao, Y (corresponding author), Chinese Acad Sci, Key Lab Opt Engn, Chengdu 610209, Peoples R China.
EM yangjinhui19@mails.ucas.ac.cn; hukun19@mails.ucas.ac.cn;
   wangxiaochao18@163.com; whf@csu.ac.cn; Liuqiong04@163.com;
   maoyao@ioe.ac.cn
RI Wang, Hongfei/JCF-2357-2023
OI Hu, Kun/0000-0002-5159-1141; Mao, Yao/0000-0003-1785-2018
CR Boland F. M., 1995, Fifth International Conference on Image Processing and its Applications (Conf. Publ. No.410), P326, DOI 10.1049/cp:19950674
   Chang CC, 2002, PATTERN RECOGN LETT, V23, P931, DOI 10.1016/S0167-8655(02)00023-5
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kang XB, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102804
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Prasetyo H, 2019, 2019 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD 2019), DOI [10.1109/isesd.2019.8909613, 10.1109/ispacs48206.2019.8986253, 10.1109/ICITAET47105.2019.9170223]
   Prasetyo H, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P181, DOI 10.1109/IC3INA.2018.8629513
   Priya C, 2021, CIRC SYST SIGNAL PR, V40, P2464, DOI 10.1007/s00034-020-01585-6
   Rosiyadi D, 2020, 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS, AND TELECOMMUNICATIONS (ICRAMET), P343, DOI [10.1109/ICRAMET51080.2020.9298671, 10.1109/icramet51080.2020.9298671]
   Roy SS, 2020, MULTIMED TOOLS APPL, V79, P13125, DOI 10.1007/s11042-020-08652-9
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Voyatzis G, 1999, P IEEE, V87, P1197, DOI 10.1109/5.771072
   Wang BW, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050691
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Xiong X G, 2018, ACTA AUTOMAT SIN, V44
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 30
TC 6
Z9 6
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20127
EP 20145
DI 10.1007/s11042-022-12115-8
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600006
DA 2024-07-18
ER

PT J
AU Arora, N
   Kumar, Y
   Karkra, R
   Kumar, M
AF Arora, Nitika
   Kumar, Yogesh
   Karkra, Rashmi
   Kumar, Munish
TI Automatic vehicle detection system in different environment conditions
   using fast R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transport system; Deep learning; Fast R-CNN; Vehicle
   detection; Traffic management
AB Vehicle detection and classification is a challenging move in the field of traffic management and surveillance. With the rapid increase in the number of vehicles on roads, streets, and highways, the Intelligent Transport System (ITS) requirement has become inevitable. Vehicle detection and recognition systems have their roots embedded in ITS. It has been observed that different researchers have done much work in Day mode detection using Machine and Deep learning techniques. However, most of them faced difficulty in detection due to inadequate data, low illumination conditions, misclassification due to long shadows of vehicles, and testing on static frames. On the other hand, night vision detection is also facing difficulty due to low illumination conditions. The proposed work focuses on detecting moving vehicles in both day and night mode using a region-based deep learning technique called fast region based convolutional neural network (fast R-CNN). The proposed work has achieved promising results in situations like detection in the presence of long shadows, cloudy weather, detections in dense traffic during day vision, and pioneers the results in night mode conditions. Four evaluation parameters were used to test the system's efficiency, mainly Recall, Accuracy, Precision, and Processing time. The proposed work achieved an overall average computation time of 0.59 s. Overall average Recall, accuracy, and precision of vehicle detection in day and night mode achieved were 98.44%, 94.20%, and 90%, respectively.
C1 [Arora, Nitika; Karkra, Rashmi] Chandigarh Engn Coll, Dept Comp Sci & Engn, Landran, Mohali, India.
   [Kumar, Yogesh] Indus Univ, Dept Comp Engn, Ahmadabad, Gujarat, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM anitika.26@gmail.com; yogesh.arora10744@gmail.com; munishcse@gmail.com
RI kumar, yogesh/AAD-8469-2021; Kumar, Munish/P-7756-2018
OI kumar, yogesh/0000-0002-2879-0441; Kumar, Munish/0000-0003-0115-1620
CR Aqel S, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Billones RKC, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666357
   Charouh, 2019, IEEE INT S INN INT S
   Chen LK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0350-2
   Chen ZZ, 2011, IEEE INT C INTELL TR, P74, DOI 10.1109/ITSC.2011.6083075
   Du XX, 2017, IEEE INT C INT ROBOT, P749, DOI 10.1109/IROS.2017.8202234
   Fu T, 2017, J ADV TRANSPORT, P1, DOI 10.1155/2017/5142732
   Nguyen H, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3808064
   Indrabayu, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS, P115, DOI 10.1109/CyberneticsCom.2016.7892577
   Jabri S, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P121, DOI 10.1109/IPAS.2018.8708898
   Jin LS, 2018, IEEE ACCESS, V6, P4287, DOI 10.1109/ACCESS.2018.2790407
   Juric D, 2014, INT CONF CONNECT VEH, P655, DOI 10.1109/ICCVE.2014.7297630
   Kim MS, 2016, J MECH SCI TECHNOL, V30, P2783, DOI 10.1007/s12206-016-0539-1
   Kuang HL, 2019, IEEE T SYST MAN CY-S, V49, P71, DOI 10.1109/TSMC.2018.2872891
   Kuang HL, 2017, IEEE T INTELL TRANSP, V18, P927, DOI 10.1109/TITS.2016.2598192
   Kul S, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417720782
   Kumar Yogesh, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P150, DOI 10.1109/ICCAKM46823.2020.9051502
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Manana M., 2018, 2018 INT C INT INN C
   Manzoor MA, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Oliveira M, 2015, INFORM FUSION, V24, P108, DOI 10.1016/j.inffus.2014.09.003
   Pawar, 2017, INT C BIG DAT AN COM
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Sakhare KV, 2020, ARCH COMPUT METHOD E, V27, P591, DOI 10.1007/s11831-019-09321-3
   Satzoda RK, 2019, IEEE T INTELL TRANSP, V20, P4297, DOI 10.1109/TITS.2016.2614545
   Shaheen S., 2013, Intelligent transportation systems
   Soetedjo, 2018, 3 ASIA PACIFIC C INT
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Tu CL, 2018, LECT NOTES COMPUT SC, V11241, P147, DOI 10.1007/978-3-030-03801-4_14
   Wang J., 2020, IEEE Access, V8
   Wei Y, 2019, MATH COMPUT SIMULAT, V155, P130, DOI 10.1016/j.matcom.2017.12.011
   Yang B, 2018, LECT NOTES COMPUT SC, V10799, P241, DOI 10.1007/978-3-319-92753-4_20
   Zhang FK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030594
   Zhang RH, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141850009X
NR 36
TC 23
Z9 23
U1 10
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18715
EP 18735
DI 10.1007/s11042-022-12347-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800006
DA 2024-07-18
ER

PT J
AU Dua, N
   Singh, SN
   Semwal, VB
   Challa, SK
AF Dua, Nidhi
   Singh, Shiva Nand
   Semwal, Vijay Bhaskar
   Challa, Sravan Kumar
TI Inception inspired CNN-GRU hybrid network for human activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; HAR; Inception; Gated recurrent unit;
   Wearable sensors; Human-computer interaction; Pattern recognition
ID TIME-SERIES; SYSTEM; MODEL
AB Human Activity Recognition (HAR) involves the recognition of human activities using sensor data. Most of the techniques for HAR involve hand-crafted features and hence demand a good amount of human intervention. Moreover, the activity data obtained from sensors are highly imbalanced and hence demand a robust classifier design. In this paper, a novel classifier "ICGNet" is proposed for HAR, which is a hybrid of Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU). The CNN block used in the proposed network derives its inspiration from the famous Inception module. It uses multiple-sized convolutional filters simultaneously over the input and thus can capture the information in the data at multiple scales. These multi-sized filters introduced at the same level in the convolution network helps to compute more abstract features for local patches of data. It also makes use of 1 x 1 convolution to pool the input across channel dimension, and the intuition behind it is that it helps the model extract the valuable information hidden across the channels. The proposed ICGNet leverages the strengths of CNN and GRU and hence can capture local features and long-term dependencies in the multivariate time series data. It is an end-to-end model for HAR that can process raw data captured from wearable sensors without using any manual feature engineering. Integrating the adaptive user interfaces, the proposed HAR system can be applied to Human-Computer Interaction (HCI) fields such as interactive games, robot learning, health monitoring, and pattern-based surveillance. The overall accuracies achieved on two benchmark datasets viz. MHEALTH and PAMAP2 are 99.25% and 97.64%, respectively. The results indicate that the proposed network outperformed the similar architectures proposed for HAR in the literature.
C1 [Dua, Nidhi; Singh, Shiva Nand; Challa, Sravan Kumar] Natl Inst Technol Jamshedpur, Dept ECE, Jamshedpur, Jharkhand, India.
   [Semwal, Vijay Bhaskar] Maulana Azad Natl Inst Technol, Dept CSE, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; National Institute of Technology (NIT System);
   Maulana Azad National Institute of Technology Bhopal
RP Dua, N (corresponding author), Natl Inst Technol Jamshedpur, Dept ECE, Jamshedpur, Jharkhand, India.
EM 2016rsec001@nitjsr.ac.in; snsingh.ece@nitjsr.ac.in; vsemwal@gmail.com;
   2016rsee002@nigsr.ac.in
RI Dua, Nidhi/KGL-6182-2024; Semwal, Vijay Bhaskar/B-5628-2017
OI Semwal, Vijay Bhaskar/0000-0003-0767-6057; Dua,
   Nidhi/0000-0001-9812-9141
FU SERB, DST, Government of India [ECR/2018/000203]
FX This project is funded under the schema of Early Career Award (DST No:
   ECR/2018/000203) by SERB, DST, Government of India.
CR Ahad A R., 2020, Intelligent systems reference library, P13, DOI DOI 10.1007/978-3-030-51379-5_2
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   Arifoglu D, 2017, PROCEDIA COMPUT SCI, V110, P86, DOI 10.1016/j.procs.2017.06.121
   Asteriadis S, 2017, MULTIMED TOOLS APPL, V76, P4505, DOI 10.1007/s11042-016-3945-6
   Banos Oresti, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P91, DOI 10.1007/978-3-319-13105-4_14
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Catal C, 2015, APPL SOFT COMPUT, V37, P1018, DOI 10.1016/j.asoc.2015.01.025
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Chen L, 2021, APPL INTELL, V51, P4029, DOI 10.1007/s10489-020-02005-7
   Chen YH, 2016, ENERGIES, V9, DOI 10.3390/en9020070
   Cheng Xuelian, 2020, ARXIV PREPRINT ARXIV
   Cho H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041055
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Dewangan DK, 2021, INTEL SERV ROBOT, V14, P199, DOI 10.1007/s11370-020-00343-6
   Dewangan DK, 2021, ELECTRON LETT, V57, P53, DOI 10.1049/ell2.12062
   Dinarevic E. C., 2019, 2019 18 INT S INFOTE, P1
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fawaz HI, 2020, DATA MIN KNOWL DISC, V34, P1936, DOI 10.1007/s10618-020-00710-y
   Gumaei A, 2020, CMC-COMPUT MATER CON, V65, P1033, DOI 10.32604/cmc.2020.011740
   Gumaei A, 2019, IEEE ACCESS, V7, P99152, DOI 10.1109/ACCESS.2019.2927134
   Ha S, 2016, IEEE IJCNN, P381, DOI 10.1109/IJCNN.2016.7727224
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jalal A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207122
   Kang T, 2016, INT WINT WORKSH BR
   Karpathy A, 2016, 4 INT C LEARN REPR W
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lara OD, 2012, PERVASIVE MOB COMPUT, V8, P717, DOI 10.1016/j.pmcj.2011.06.004
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu CL, 2019, IEEE T IND ELECTRON, V66, P4788, DOI 10.1109/TIE.2018.2864702
   Lyu LJ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1219, DOI 10.1145/3132847.3132990
   Malazi HT, 2018, APPL INTELL, V48, P315, DOI 10.1007/s10489-017-0976-2
   Meng Yuanliang, 2018, P 56 ANN M ASS COMP, V1
   Mutegeki Ronald, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P362, DOI 10.1109/ICAIIC48513.2020.9065078
   Nguyen HD, 2019, ARXIV190503809
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Ramesh S, 2021, MULTIMED TOOLS APPL, V80, P11789, DOI 10.1007/s11042-020-10351-4
   Rautaray S.S., 2012, 2012 IEEE International Conference on Technology Enhanced Education (ICTEE), P1, DOI DOI 10.1109/ICTEE.2012.6208628
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Ronald M, 2021, IEEE ACCESS, V9, P68985, DOI 10.1109/ACCESS.2021.3078184
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Saha J, 2021, MULTIMED TOOLS APPL, V80, P9895, DOI 10.1007/s11042-020-10046-w
   Sajjad M, 2020, IEEE ACCESS, V8, P143759, DOI 10.1109/ACCESS.2020.3009537
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tahir SBUD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050579
   Tsai TH, 2020, MULTIMED TOOLS APPL, V79, P5989, DOI 10.1007/s11042-019-08274-w
   Uddin MZ, 2019, IEEE SENS J, V19, P8413, DOI 10.1109/JSEN.2018.2871203
   Ullah M, 2019, EUR W VIS INF PROCES, P175, DOI [10.1109/euvip47703.2019.8946180, 10.1109/EUVIP47703.2019.8946180]
   Nguyen V, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P66, DOI 10.1145/3357254.3357276
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
   Yang Z, 2018, IEEE ACCESS, V6, P56750, DOI 10.1109/ACCESS.2018.2873315
   Yin W., 2017, CoRR
   Yu JX, 2021, AGR WATER MANAGE, V245, DOI 10.1016/j.agwat.2020.106649
   Yu SL, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE), P219, DOI 10.1109/ICMCCE.2018.00052
   Zeng M, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P56, DOI 10.1145/3267242.3267286
   Zhao Y, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7316954
   Zheng Y, 2014, LECT NOTES COMPUT SC, V8485, P298, DOI 10.1007/978-3-319-08010-9_33
NR 71
TC 46
Z9 46
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5369
EP 5403
DI 10.1007/s11042-021-11885-x
EA MAR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000766438300003
DA 2024-07-18
ER

PT J
AU Grzywalski, T
   Drgas, S
AF Grzywalski, Tomasz
   Drgas, Szymon
TI Speech enhancement using U-nets with wide-context units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; U-nets; DNN
ID NEURAL-NETWORK; COMPLEX-DOMAIN; TIME; FREQUENCY; SEPARATION; MASKS
AB In this article a new neural network for speech enhancement is proposed where single-channel noisy speech is processed in order to improve its intelligibility and quality. It is based on the U-net architecture, i.e. it is composed of two main blocks: encoder and decoder. Some of the corresponding layers in the encoder and decoder are connected with skip connections. In most of the encoder-decoder neural networks for speech enhancement known from the literature, the time-frequency resolution of the hidden feature maps is reduced. The main strategy in the presented approach is to maintain the time-frequency resolution of feature maps at all levels of the network while having large receptive field at the same time. In order to obtain features dependent on wide context we propose neural network units based on recurrent cells or dilated convolutions. The proposed neural network was evaluated using WSJ0 and TIMIT speech data mixed with noises from Noisex, DCASE and field recordings from Freesound online database. The results showed improvement over the baseline networks based on gated dilated convolutions or long-short term memory (LSTM) in terms of scale-independent speech-to-distortion ratio (SI-SDR), spectro-temporal objective intelligibility (STOI) and perceptual evaluation of speech quality (PESQ) measures.
C1 [Grzywalski, Tomasz] StethoMe, Poznan, Poland.
   [Drgas, Szymon] Poznan Univ Tech, Inst Automat Control & Robot, Poznan, Poland.
C3 Poznan University of Technology
RP Grzywalski, T (corresponding author), StethoMe, Poznan, Poland.
EM grzywalski@stethome.com; szymon.drgas@put.poznan.pl
RI Grzywalski, Tomasz/KII-3357-2024
OI Grzywalski, Tomasz/0000-0002-9388-0494
FU  [0211/SBAD/0222]
FX The work of Szymon Drgas was supported by grant 0211/SBAD/0222.
CR Ananthakrishnan KS, 2009, TENCON 2009 2009 IEE, P1
   [Anonymous], 2018, ARXIV180907454
   Bai S., 2018, CoRR
   Chen JT, 2017, J ACOUST SOC AM, V141, P4705, DOI 10.1121/1.4986931
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Garofalo John, 2007, Csr-i (wsj0) complete
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Grais EM, 2017, IEEE GLOB CONF SIG, P1265, DOI 10.1109/GlobalSIP.2017.8309164
   Grzywalski T, 2019, INT CONF ACOUST SPEE, P6970, DOI 10.1109/ICASSP.2019.8682830
   Grzywalski T, 2018, SIG P ALGO ARCH ARR, P82, DOI 10.23919/SPA.2018.8563364
   Guido RC, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691320300017
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang P.-S., 2014, P ICASSP, DOI DOI 10.1109/ICASSP.2014.6853860
   Huang PS, 2015, IEEE-ACM T AUDIO SPE, V23, P2136, DOI 10.1109/TASLP.2015.2468583
   Hui LK, 2015, IEEE INT SYMP SIGNAL, P24, DOI 10.1109/ISSPIT.2015.7394335
   Kingma D. P., 2014, arXiv
   Le Roux J, 2019, INT CONF ACOUST SPEE, P66, DOI 10.1109/ICASSP.2019.8682587
   Le Roux J, 2019, INT CONF ACOUST SPEE, P626, DOI 10.1109/ICASSP.2019.8683855
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Mowlaee P, 2012, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.2012.6287819
   Nicolson A, 2020, SPEECH COMMUN, V125, P80, DOI 10.1016/j.specom.2020.10.004
   Nicolson A, 2019, SPEECH COMMUN, V111, P44, DOI 10.1016/j.specom.2019.06.002
   Pandey A, 2019, INT CONF ACOUST SPEE, P6875, DOI [10.1109/ICASSP.2019.8683634, 10.1109/icassp.2019.8683634]
   Pandey A, 2019, IEEE-ACM T AUDIO SPE, V27, P1179, DOI [10.1109/taslp.2019.2913512, 10.1109/TASLP.2019.2913512]
   Park SR, 2017, INTERSPEECH, P1993, DOI 10.21437/Interspeech.2017-1465
   Pirhosseinloo S, 2019, INTERSPEECH, P3143, DOI 10.21437/Interspeech.2019-2782
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Stowell D, 2013, ARXIV13095275
   Sun Y, 2019, IEEE J-STSP, V13, P359, DOI 10.1109/JSTSP.2019.2908760
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tan K, 2018, INTERSPEECH, P3229
   Tan K, 2019, IEEE-ACM T AUDIO SPE, V27, P189, DOI 10.1109/TASLP.2018.2876171
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang DeLiang, 2017, IEEE Spectr, V54, P32, DOI 10.1109/MSPEC.2017.7864754
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961
   Wang ZQ, 2019, INT CONF ACOUST SPEE, P71, DOI 10.1109/ICASSP.2019.8683231
   Wang ZQ, 2018, INTERSPEECH, P2708, DOI 10.21437/Interspeech.2018-1629
   Williamson DS, 2017, IEEE-ACM T AUDIO SPE, V25, P1492, DOI 10.1109/TASLP.2017.2696307
   Yu F., 2015, ARXIV
   Yuan WH, 2020, SPEECH COMMUN, V124, P75, DOI 10.1016/j.specom.2020.09.002
   Yuxuan Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6107, DOI 10.1109/ICASSP.2014.6854777
   Zhang R, 2019, PR MACH LEARN RES, V97
NR 46
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18617
EP 18639
DI 10.1007/s11042-022-12632-6
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800002
DA 2024-07-18
ER

PT J
AU Hussan, M
   Parah, SA
   Jan, A
   Qureshi, GJ
AF Hussan, Muzamil
   Parah, Shabir A.
   Jan, Aiman
   Qureshi, G. J.
TI Self-embedding framework for tamper detection and restoration of color
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Tamper detection; Tamper recovery; Image restoration
ID FRAGILE WATERMARKING SCHEME; AUTHENTICATION; RECONSTRUCTION; PROTECTION;
   CHAOS
AB The present era is paving huge expansion to the transmission of digital data in fields like health, military intelligence, scientific research, and publication media, etc. The nature of digital data makes it more vulnerable to various intentional and unintentional attacks and hence increases the necessity of verifying its integrity and authenticity. In this paper, a novel image watermarking method for tamper detection and recovery of color images has been proposed. The color image is primarily separated into three planes, and then each plane is divided into four equal halves. We sub-divide each half into 4 x 4 non-overlapping blocks. Further, from a group of four corresponding sub-blocks, a 32-bit watermark comprising of the arithmetic mean value along with the 8-bit data containing the location of the mapped block is generated. This 32-bit generated watermark is embedded into the two least significant bits (LSB) of the mapped block after being encrypted using gray code. The information is embedded in such a way using chaotic sequence such that a full restoration process can be carried out, even if 75% of blocks in any of the three planes get tampered with. This method obtains a high-quality restored image with an average PSNR value of 39.22 dB for the RGB model and 39.37 dB for the YCbCr model. The performance of the proposed method for various collage attacks shows its efficacy over other state-of-art techniques, making it a suitable candidate for the recovery of tampered color images.
C1 [Hussan, Muzamil; Parah, Shabir A.; Jan, Aiman] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
   [Qureshi, G. J.] Higher Educ Dept, Kashmir, Jammu & Kashmir, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
RI Jan, Aiman/ABD-2918-2021
OI Parah, Shabir/0000-0001-5983-0912
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2015, 2015 12 INT C EL ENG
   [Anonymous], 2014, AM J ENG TECHNOL RES
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Bhat GM, 2010, MAEJO INT J SCI TECH, V4, P125
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Cruz-Ramos C, 2021, APPLIES SCI, V11, P3189
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Dadkhah S, 2014, LECT NOTES COMPUT SC, V8814, P504, DOI 10.1007/978-3-319-11758-4_55
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Feng B, 2020, MOBILE NETW APPL, V25, P82, DOI 10.1007/s11036-018-1186-9
   Gull S, 2021, MULTIMED TOOLS APPL, V80, P29939, DOI 10.1007/s11042-021-11170-x
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Hassan FS, 2022, CAAI T INTELL TECHNO, V7, P56, DOI 10.1049/cit2.12053
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Huang SC, 2012, J MAR SCI TECH-TAIW, V20, P49
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Hussan M, 2021, ARAB J SCI ENG, V46, P3465, DOI 10.1007/s13369-020-05135-9
   Kabir MA, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04387-w
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Kumar A, 2017, PERTANIKA J SCI TECH, V25, P57
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li YW, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7100955
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Patra B, 2012, I S INTELL SIG PROC
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Sahu AK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03365-9
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shivani Shivendra, 2013, Pattern Recognition and Image Analysis. 6th Iberian Conference, IbPRIA 2013. Proceedings. LNCS 7887, P640
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Stergiou CL, 2021, IEEE INTERNET THINGS, V8, P5164, DOI 10.1109/JIOT.2020.3033131
   Sunesh, 2020, PROCEDIA COMPUT SCI, V167, P1505, DOI 10.1016/j.procs.2020.03.361
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
NR 51
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18563
EP 18594
DI 10.1007/s11042-022-12545-4
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766063900004
DA 2024-07-18
ER

PT J
AU Saeed, S
   Abdullah, A
   Jhanjhi, NZ
   Naqvi, M
   Nayyar, A
AF Saeed, Soobia
   Abdullah, Afnizanfaizal
   Jhanjhi, N. Z.
   Naqvi, Mehmood
   Nayyar, Anand
TI New techniques for efficiently k-NN algorithm for brain tumor detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain Tumor; MRI; Laplacian; K-Nearest Neighbor
ID CLASSIFICATION
AB The k-NN algorithm missing values is one of the current research issues, especially in 4D frequency. This study addresses the accuracy of the images, increases the efficiency of missing k-NN hybrid values, and constructs a research framework that can identify cancer-damaged areas isolated from non-tumors areas using 4D image light field tools. Additionally, we propose a new approach to detect brain tumors or cerebrospinal fluid (CSF) development in the early stages of formation. We apply a combination of the hybrid K-Nearest Neighbor (k-NN) algorithm, Fast Fourier Transform, and the Laplace Transform techniques on four-dimensional (4D) MRI (Magnetic Resonance Imaging) images. These approaches use a 4D modulation method that dictates the light field used for the Light Editing Field (LEF) tool. Depending on the user's input, an objective evaluation of each ray is calculated using the k-NN method to maintain the 4D frequency redundant light fields. We suggest that light field methods can improve the quality of images through LEF since the light field composite pipelines reduce the borders of artifacts.
C1 [Saeed, Soobia; Abdullah, Afnizanfaizal] Univ Teknol Malaysia UTM, Dept Software Engn, Skudai 81310, Malaysia.
   [Jhanjhi, N. Z.] SCE Taylors Univ, Sch Comp Sci & Engn, Subang Jaya, Malaysia.
   [Naqvi, Mehmood] Mohawk Coll, Sch Engn Technol, 135 Fennell Ave W, Hamilton, ON, Canada.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 Universiti Teknologi Malaysia; Duy Tan University; Duy Tan University
RP Saeed, S (corresponding author), Univ Teknol Malaysia UTM, Dept Software Engn, Skudai 81310, Malaysia.
EM saeed.soobia@graduate.utm.my; afnizanfaizal@utm.my;
   noorzanam.jhanjhi@taylors.edu.my; syed.naqvi4@mohawkcollege.ca;
   anandnayyar@duytan.edu.vn
RI Jhanjhi, Prof Dr Noor Zaman/F-3051-2011; Nayyar, Anand/F-3732-2015
OI Jhanjhi, Prof Dr Noor Zaman/0000-0001-8116-4733; Nayyar,
   Anand/0000-0002-9821-6146
CR Alhroob A, 2020, INT J ADV COMPUT SC, V11, P703
   Altaf I, 2016, PAK J MED SCI, V32, P1439, DOI 10.12669/pjms.326.9956
   Armina R, 2017, J PHYS CONF SER, V892, DOI 10.1088/1742-6596/892/1/012004
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bertsimas D, 2018, J MACH LEARN RES, V18
   Bharadwaj C. Anil, 2018, PROC 2 INT C POWER E, P1
   Cameron JM, 2020, CANCERS, V12, DOI 10.3390/cancers12071710
   Chowdhary S, 2017, CANCER CONTROL, V24, pS1, DOI 10.1177/107327481702400118
   Garg G., ARXIV PREPRINT ARXIV, V2021
   Huang S, 2019, IEEE ACCESS, V7, P66739, DOI 10.1109/ACCESS.2019.2917868
   Khotanlou H., 2016, FUZZY SET SYST, V60, P1
   Kinaci A, 2018, WORLD NEUROSURG, V118, P368, DOI 10.1016/j.wneu.2018.06.196
   Kombo OH, 2020, HYDROLOGY-BASEL, V7, DOI 10.3390/hydrology7030059
   Latha R. S., 2020, J CRIT REV, V7, P1
   Lavanya SR, 2020, EUR J MOL CLIN MED, V7, P2053
   Liang F, 2018, ARTIF INTELL MED, V90, P34, DOI 10.1016/j.artmed.2018.07.001
   Liu J, 2018, IEEE T BIO-MED ENG, V65, P1943, DOI 10.1109/TBME.2018.2845706
   Liu ZG, 2016, PATTERN RECOGN, V52, P85, DOI 10.1016/j.patcog.2015.10.001
   Mendrik AM, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/813696
   Nasor M, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/9035096
   Odde, 2018, GLIOMA CELL MIGRATIO, P1, DOI [10.1101/500843, DOI 10.1101/500843]
   Ranjini KSS, 2017, EXPERT SYST APPL, V83, P63, DOI 10.1016/j.eswa.2017.04.033
   Saeed S., 2019, INDIAN J SCI TECHNOL, V12, P37, DOI [10.17485/ijst/2019/v12i37/146151, DOI 10.17485/ijst/2019/v12i34/146150]
   Sargolzaei S, 2015, NEUROINFORMATICS, V13, P427, DOI 10.1007/s12021-015-9266-5
   Saunders NR, 2018, J PHYSIOL-LONDON, V596, P5723, DOI 10.1113/JP275376
   Schievink WI, 2016, NEUROLOGY, V87, P673, DOI 10.1212/WNL.0000000000002986
   Srinivas B., 2019, Int J Recent Technol Engg (IJRTE) ISSN, V2, P2277, DOI [10.35940/ijrte.B1051.078219, DOI 10.35940/IJRTE.B1051.078219]
   Ueno M, 2016, BRAIN TUMOR PATHOL, V33, P89, DOI 10.1007/s10014-016-0255-7
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Wang, 2019, IOP C SERIES MAT SCI, V677
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
NR 31
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18595
EP 18616
DI 10.1007/s11042-022-12271-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300008
DA 2024-07-18
ER

PT J
AU Shelke, S
   Attar, V
AF Shelke, Sushila
   Attar, Vahida
TI Rumor detection in social network based on user, content and lexical
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Lexical features; Rumor; Rumor detection; Social network
ID FAKE NEWS; INFORMATION
AB Emergence in the social network leads to the extensive and faster diffusion of news than conventional news channels. Verification of data is challenging due to massive information on a social network. Unverified information can be a rumor or fake news that causes damage to an individuals and organizations, revealing the harmful impact on humanity. Therefore, it is vital to combat rumor diffusion to minimize the adverse effects on society. Despite vigorous efforts to deal with this issue, researchers mainly focussed on temporal dynamics of posts and other features like a user, network, content-based, which demonstrate a moderate accuracy. The time series features are associated with an event that suppresses the other quality features related to each post. There is a scope for improvement in the accuracy, so this paper focuses on post-wise features such as user-based, content-based and lexical-based features along with post sequences. We proposed a framework that uses various essential features and combines two deep learning models. Word embedding is utilized with bidirectional long short-term memory (BiLSTM) and combined with post-wise features using a multilayer perceptron (MLP), which improves accuracy. The experiments on the real-world dataset of Twitter demonstrate a notable improvement in accuracy compared to state-of-the-art approaches.
C1 [Shelke, Sushila; Attar, Vahida] Savitribai Phule Pune Univ, Coll Engn Pune, Dept Comp Engn & Informat Technol, Pune, Maharashtra, India.
   [Shelke, Sushila] Savitribai Phule Pune Univ, Cummins Coll Engn Women, Dept Comp Engn, Pune, Maharashtra, India.
C3 College of Engineering Pune; Savitribai Phule Pune University;
   Savitribai Phule Pune University
RP Shelke, S (corresponding author), Savitribai Phule Pune Univ, Coll Engn Pune, Dept Comp Engn & Informat Technol, Pune, Maharashtra, India.; Shelke, S (corresponding author), Savitribai Phule Pune Univ, Cummins Coll Engn Women, Dept Comp Engn, Pune, Maharashtra, India.
EM sss17.comp@coep.ac.in; vahida.comp@coep.ac.in
RI Attar, Vahida Z/AAX-4198-2021
OI Attar, Vahida Z/0000-0002-2285-7393; Shelke, Sushila/0000-0001-9045-7810
CR Al-Sarem M, 2019, IEEE ACCESS, V7, P152788, DOI 10.1109/ACCESS.2019.2947855
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Freire PJ, 2021, J LIGHTWAVE TECHNOL, V39, P6085, DOI 10.1109/JLT.2021.3096286
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Jogalekar NS, 2020, IEEE INT CONF BIG DA, P3877, DOI 10.1109/BigData50022.2020.9378149
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kotteti CMM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217541
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Li X, 2021, MULTIMED TOOLS APPL
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   Sharaff Aakanksha., 2016, Emerging Research in Computing, Information. Communication and Applications, P237, DOI DOI 10.1007/978-81-322-2553-9_23
   Sharma A., 2020, 2020 IEEE 9 POWER IN, P1
   Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001
   Shelke S., 2020, CYBERNETICS COGNITIO, P89, DOI DOI 10.1007/978-981-15-1632-0_10
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Song CW, 2019, INT CONF IMAG VIS, DOI 10.1109/ivcnz48456.2019.8960965
   Srinivasarao U, 2021, INTELLIGENT COMPUTIN, P211, DOI [10.1007/978-981-16-1295-4_22, DOI 10.1007/978-981-16-1295-4_22]
   Tchakounté F, 2022, J KING SAUD UNIV-COM, V34, P3070, DOI 10.1016/j.jksuci.2020.09.001
   van der Lee C., 2017, P 4 WORKSHOP NLP SIM, P190
   Xiang Lin, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P338, DOI 10.1007/978-3-030-32236-6_30
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 33
TC 13
Z9 14
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17347
EP 17368
DI 10.1007/s11042-022-12761-y
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765198400002
PM 35282405
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Magdi, A
   Lashin, NA
   El-Komy, O
   Salah, A
AF Hosny, Khalid M.
   Magdi, Amal
   Lashin, Nabil A.
   El-Komy, Osama
   Salah, Ahmad
TI Robust color image watermarking using multi-core Raspberry pi cluster
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion Legendre-Fourier moments; Image watermarking; Raspberry pi;
   Cluster; Parallel computing; Message passing interface; MPI; OpenMP
ID FAST COMPUTATION; MOMENTS; GPU
AB Image authentication approaches have gotten a lot of interest recently as a way to safeguard transmitted images. Watermarking is one of the many ways used to protect transmitted images. Watermarking systems are pc-based that have limited portability that is difficult to use in harsh environments as military use. We employ embedded devices like Raspberry Pi to get around the PC's mobility limitations. Digital image watermarking technology is used to secure and ensure digital images' copyright by embedding hidden information that proves its copyright. In this article, the color images Parallel Robust watermarking algorithm using Quaternion Legendre-Fourier Moment (QLFM) in polar coordinates is implemented on Raspberry Pi (RPi) platform with parallel computing and C++ programming language. In the host image, a binary Arnold scrambled image is embedded. Watermarking algorithm is implemented and tested on Raspberry Pi model 4B. We can combine many Raspberry Pi's into a 'cluster' (many computers working together as one) for high-performance computation. Message Passing Interface (MPI) and OpenMP for parallel programming to accelerate the execution time for the color image watermarking algorithm implemented on the Raspberry Pi cluster.
C1 [Hosny, Khalid M.; Magdi, Amal; Lashin, Nabil A.; El-Komy, Osama] Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
   [Salah, Ahmad] Zagazig Univ, Dept Comp Sci, Zagazig, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Zagazig University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
EM k_hosny@yahoo.com
RI Hosny, Khalid M./B-1404-2008; Salah, Ahmad/K-8761-2017; magdi,
   amal/CAF-8082-2022; Salah, Ahmad/GPT-0358-2022
OI Hosny, Khalid M./0000-0001-8065-8977; Salah, Ahmad/0000-0003-3433-7640;
   magdi, amal/0000-0001-7871-8520; 
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abrahamsson P, 2013, INT CONF CLOUD COMP, P170, DOI 10.1109/CloudCom.2013.121
   Ahmad Irfan, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P107, DOI 10.1109/ICSSIT48917.2020.9214125
   Akour M., 2020, Int. J. Adv. Trends Comput. Sci. Eng, V9, P1, DOI [10.30534/ijatcse/2020/196932020, DOI 10.30534/IJATCSE/2020/196932020]
   [Anonymous], 2019, HDB MULTIMEDIA INFOR, DOI DOI 10.1007/978-3-030-15887-3_8
   Atmaja AP., 2020, J ROBOT CONTROL JRC, V2, P297
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Cloutier MF, 2016, ELECTRONICS-SWITZ, V5, DOI 10.3390/electronics5040061
   Cox SJ, 2014, CLUSTER COMPUT, V17, P349, DOI 10.1007/s10586-013-0282-7
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Darwish M.M., 2020, Multimedia security using chaotic maps: principles and methodologies, P137
   Gupta S, 2018, INT J RES APPL SCI E, V6, P66
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosny KM, 2019, J REAL-TIME IMAGE PR, V16, P2027, DOI 10.1007/s11554-017-0708-1
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2019, PATTERN ANAL APPL, V22, P1105, DOI 10.1007/s10044-018-0740-1
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z
   Iromini NA., 2020, J EMBED SYST, V8, P1
   Manikandan LC, 2021, J AMB INTEL HUM COMP, V12, P4689, DOI 10.1007/s12652-020-01871-w
   Mittal M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050822
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Petrovic N., 2020, Iot-based system for covid-19 indoor safety monitoring
   Puri Satish, 2019, GEOGRAPHIC INFORM SC, VQ2
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Sagar S, 2020, P INT C INNOVATIVE C
   Sajjad M, 2020, FUTURE GENER COMP SY, V108, P995, DOI 10.1016/j.future.2017.11.013
   Salah A, 2020, FUTURE GENER COMP SY, V107, P368, DOI 10.1016/j.future.2020.01.051
   Sathik M.M., 2010, International Journal of Advanced Science and Technology, V24, P61
   Senthilkumar G., 2014, Int. J. Emerg. Trends Technol. Comput. Sci, V3, P213
   Shilpashree K., 2015, Int. J. Adv. Res. Comput. Commun Eng., V4, P199, DOI DOI 10.17148/IJARCCE.2015.4545
   Walter J, 2014, 2 WORKSH HIGH PERF R
   [王向阳 Wang Xiangyang], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P651
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Widodo CE, 2020, J PHYS C SERIES, V1524
   Wu Q, 2020, INT J RAIL TRANSP, V8, P111, DOI 10.1080/23248378.2018.1553115
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Xuan YB, 2018, J PARALLEL DISTR COM, V111, P104, DOI 10.1016/j.jpdc.2017.07.008
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yang Z, 2020, IEEE ACCESS, V8, P95099, DOI 10.1109/ACCESS.2020.2995392
   Yu XY, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040056
NR 46
TC 4
Z9 4
U1 6
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17185
EP 17204
DI 10.1007/s11042-022-12037-5
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200010
OA hybrid
DA 2024-07-18
ER

PT J
AU Fkirin, A
   Attiya, G
   El-Sayed, A
   Shouman, MA
AF Fkirin, Alaa
   Attiya, Gamal
   El-Sayed, Ayman
   Shouman, Marwa A.
TI Copyright protection of deep neural network models using digital
   watermarking: a comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNN; Black-box; White-box; Deep learning; Copyright protection; Digital
   watermarking
ID IMAGE; SCHEME; DCT; SVD
AB Nowadays, deep learning achieves higher levels of accuracy than ever before. This evolution makes deep learning crucial for applications that care for safety, like self-driving cars and helps consumers to meet most of their expectations. Further, Deep Neural Networks (DNNs) are powerful approaches that employed to solve several issues. These issues include healthcare, advertising, marketing, computer vision, speech processing, natural language processing. The DNNs have marvelous progress in these different fields, but training such DNN models requires a lot of time, a vast amount of data and in most cases a lot of computational steps. Selling such pre-trained models is a profitable business model. But, sharing them without the owner permission is a serious threat. Unfortunately, once the models are sold, they can be easily copied and redistributed. This paper first presents a review of how digital watermarking technologies are really very helpful in the copyright protection of the DNNs. Then, a comparative study between the latest techniques is presented. Also, several optimizers are proposed to improve the accuracy against the fine-tuning attack. Finally, several experiments are performed with black-box settings using several optimizers and the results are compared with the SGD optimizer.
C1 [Fkirin, Alaa] Fayoum Univ, Fac Engn, Dept Elect Engn, Al Fayyum, Egypt.
   [Attiya, Gamal; El-Sayed, Ayman; Shouman, Marwa A.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia Govemorate, Menouf, Egypt.
C3 Egyptian Knowledge Bank (EKB); Fayoum University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Fkirin, A (corresponding author), Fayoum Univ, Fac Engn, Dept Elect Engn, Al Fayyum, Egypt.
EM alaa.fkirin@fayoum.edu.eg; gamal.mahous@el-eng.menofia.edu.eg;
   ayman.elsayed@el-eng.menofia.edu.eg; marwa.shouman@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022; Fkirin, Alaa/AAO-5567-2021
OI EL-SAYED, Ayman E./0000-0002-4437-259X; Fkirin,
   Alaa/0000-0002-7958-5501; ATTIYA, Gamal/0000-0002-4771-9165
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615
   AL-Mansoori S, 2012, INT J COMPUT SCI NET, V12, P1
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Bordes Antoine, 2014, P C EMP METH NAT LAN, P615
   Ciodaro T, 2012, J PHYS CONF SER, V368, DOI 10.1088/1742-6596/368/1/012030
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Deeba Farah, 2020, International Journal of Machine Learning and Computing, P277, DOI 10.18178/ijmlc.2020.10.2.932
   Fkirin A., 2016, COMMUN APPL ELECT, V5, P13, DOI [10.5120/cae2016652384, DOI 10.5120/CAE2016652384]
   Fkirin A, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02875-2
   Fkirin A, 2017, OPT QUANT ELECTRON, V49, DOI 10.1007/s11082-017-1120-6
   Ghozia A., 2019, Menoufia Journal of Electronic Engineering Research, V28, P217
   Gupta L., 2021, ADV INTELLIGENT SYST, P207
   Han S, 2015, ADV NEUR IN, V28
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helmstaedter M, 2013, NATURE, V500, P168, DOI 10.1038/nature12346
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A., 2009, Tech. Rep.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Merrer E, 2020, NEURAL COMPUT APPL, V32, P9233, DOI 10.1007/s00521-019-04434-z
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Z, 2019, DEEPSTEGO PROTECTING
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu W, 2010, COMPUT ELECTR ENG, V36, P2, DOI 10.1016/j.compeleceng.2009.04.002
   Ma JS, 2015, J CHEM INF MODEL, V55, P263, DOI 10.1021/ci500747n
   Maheshwari A., 2019, Digital Transformation: Building Intelligent Enterprises
   Meng RH, 2018, CMES-COMP MODEL ENG, V117, P425, DOI 10.31614/cmes.2018.04765
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Nagai Y, 2018, INT J MULTIMED INF R, V7, P3, DOI 10.1007/s13735-018-0147-1
   Naor D., 2001, Advances in Cryptology - CRTPTO 2001. 21st Annual International Cryptology Conference, Proceedings (Lecture Notes in Computer Science Vol.2139), P41
   Ouhsain M, 2009, EXPERT SYST APPL, V36, P2123, DOI 10.1016/j.eswa.2007.12.046
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Pittaras N., 2017, P INT C MULT MOD, P226
   Polson NG, 2017, TRANSPORT RES C-EMER, V79, P1, DOI 10.1016/j.trc.2017.02.024
   Rouhani B., 2018, P 24 INT C ARCHITECT, P485
   Rouhani BD, 2018, COMPUT SCI, P1
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh V, 2011, CYBER J MULTIDISCIPL, P10
   Srinivas S., 2015, P BRIT MACH VIS C 20, DOI DOI 10.5244/C.29.31
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Uchida Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P274, DOI 10.1145/3078971.3078974
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Wang BL, 2019, P IEEE S SECUR PRIV, P707, DOI 10.1109/SP.2019.00031
   Wang JY, 2023, INTERACT LEARN ENVIR, V31, P836, DOI [10.1080/10494820.2020.1813178, 10.1109/TASE.2020.2976560]
   Wang X., 2012, RECENT ADV COMPUTER, P223
   Werbos P. J., 1974, REGRESSION NEW TOOLS
   Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806
   Yosinski J, 2014, ADV NEUR IN, V27
   Zaheer Raniah, 2019, 2019 Third International Conference on Inventive Systems and Control (ICISC), P536, DOI 10.1109/ICISC44355.2019.9036442
   Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P159, DOI 10.1145/3196494.3196550
   Zhong Q, 2020, LECT NOTES ARTIF INT, V12085, P462, DOI 10.1007/978-3-030-47436-2_35
NR 65
TC 15
Z9 15
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15961
EP 15975
DI 10.1007/s11042-022-12566-z
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902100003
PM 35250360
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Rawas, S
   El-Zaart, A
AF Rawas, Soha
   El-Zaart, Ali
TI Towards an early diagnosis of Alzheimer disease: a precise and parallel
   image segmentation approach via derived hybrid cross entropy
   thresholding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; Segmentation; Entropy thresholding; Hybrid
   distributions; Parallel computing
AB Alzheimer's disease (AD) is an irreversible and progressive brain disease causing brain degenerative disorder and dementia. An early diagnosis of AD provides the individual an opportunity to participate in clinical trials. Computer Aided Diagnosis (CAD) system in the health care sector has been widely used and plays an important role in detecting such diseases. However, the main challenge of such systems is through identifying the region of interest obtained through precise segmentation. This paper attempts to solve the segmentation issue by developing a precise image segmentation model. The proposed model used a derivation of a hybrid cross entropy thresholding technique for the precise extraction of infected regions. In other words, a novel segmentation methodology has been proposed using the output derivation of both Gamma and Gaussian distributions. Moreover, to tackle the performance and time-consuming problems in digital image segmentation, a parallel boosting methodology has been developed and implemented. Through using the ADNI, OASIS, and MIRIAD benchmark datasets, the experimentation results validate the effectiveness of the proposed model through achieving more than 90% accuracy with 2x times speed improvement compared to other benchmark segmentation methods.
C1 [Rawas, Soha; El-Zaart, Ali] Beirut Arab Univ, Dept Math & Comp Sci, Beirut, Lebanon.
C3 Beirut Arab University
RP Rawas, S (corresponding author), Beirut Arab Univ, Dept Math & Comp Sci, Beirut, Lebanon.
EM soha.rawas2@bau.edu.lb; Elzaart@bau.edu.lb
OI Rawas, Soha/0000-0001-5128-6529
CR Al-Osaimi G, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES: FROM THEORY TO APPLICATIONS, VOLS 1-5, P1245
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Benes M, 2015, J MICROSC-OXFORD, V257, P65, DOI 10.1111/jmi.12186
   Chehade WEH., 2018, 2018 INT C INF COMM
   Elnakib A, 2011, MULTI MODALITY STATE-OF-THE-ART MEDICAL IMAGE SEGMENTATION AND REGISTRATION METHODOLOGIES, VOL II, P1, DOI 10.1007/978-1-4419-8204-9_1
   Forouzannezhad P, 2020, J NEUROSCI METH, V333, DOI 10.1016/j.jneumeth.2019.108544
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Hameurlaine M., 2019, NANO BIOMED ENG, V11, P178, DOI DOI 10.5101/NBE.V11I2.P178-191
   Hao XK, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101625
   Hazarika Ruhul Amin, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P279, DOI 10.1007/978-981-15-1286-5_24
   Janghel R.R., 2020, DEEP LEARNING BASED, P1358
   Khairuzzaman AKM, 2019, INT J APPL METAHEUR, V10, P91, DOI 10.4018/IJAMC.2019070105
   Khan NM, 2019, IEEE ACCESS, V7, P72726, DOI 10.1109/ACCESS.2019.2920448
   Lella E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030934
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237420
   Malarvel M., 2020, EXAMINING FRACTAL IM, P100, DOI [10.4018/978-1-7998-0066-8.ch005, DOI 10.4018/978-1-7998-0066-8.CH005]
   Mukherjee S., 2020, SMART HEALTHCARE ANA, P91, DOI [10.1007/978-3-030-37551-5_6, DOI 10.1007/978-3-030-37551-5_6]
   Oliva D, 2019, SOFT COMPUT, V23, P431, DOI 10.1007/s00500-017-2794-1
   Priyanka NA, 2018, SOFT COMPUTING PROBL, V1, P377
   Rawas S, 2020, APPL COMPUTING INFOR
   Rawas S, 2019, 2019 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS 2019)
   Roels J, 2016, LECT NOTES COMPUT SC, V10016, P147, DOI 10.1007/978-3-319-48680-2_14
   Satpute N, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105285
   Seyfollahi M., 2020, KOOMESH, V22, P10, DOI [10.29252/koomesh.22.1.10, DOI 10.29252/KOOMESH.22.1.10]
   Somasundaram K, 2013, J COMPUT ASSIST TOMO, V37, P353, DOI 10.1097/RCT.0b013e3182888256
   Sun H, 2019, NEUROCOMPUTING, V331, P50, DOI 10.1016/j.neucom.2018.10.039
   Trobec R., 2018, INTRO PARALLEL COMPU, DOI DOI 10.1007/978-3-319-98833-7.594,596
   Weiss A, 2019, 2019 INTERNATIONAL APPLIED COMPUTATIONAL ELECTROMAGNETICS SOCIETY SYMPOSIUM (ACES)
NR 29
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12619
EP 12642
DI 10.1007/s11042-022-12575-y
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758073800001
DA 2024-07-18
ER

PT J
AU Elaggoune, H
   Belahcene, M
   Bourennane, S
AF Elaggoune, Hocine
   Belahcene, Mebarka
   Bourennane, Salah
TI Hybrid descriptor and optimized CNN with transfer learning for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Descriptor; Hybrid; Optimization; Deep learning; Transfer learning;
   Thermal face
ID REPRESENTATION; CLASSIFICATION
AB This work focuses on the development of optimized algorithms applied in the field of Face Recognition (FR). The strategy adopted represents the contribution of hybrid face descriptors followed by the selection of optimal characteristics for significantly improving systems performance. The hybrid descriptors use the combination of several pieces of information and their optimization. Indeed, these are two hybrid structures developed and implemented. The first supports the combination of several classic descriptors Gabor filter with Histogram Oriented Gradient (HOG), Local Phase Quantization (LPQ) or Principal Component Analysis (PCA) for the facial features extraction. The second structure relies on Deep Learning (Transfer Learning (TL)) by relying on the Convolutional Neural Networks (CNN) named AlexNet without its last layers and this in order to extract the most relevant face characteristics. The Particle Swarm Optimization (PSO) algorithm optimizes these characteristics extracted from these two algorithms. The first structure is followed by a data reduction step based on Linear Discriminant Analysis (LDA). The classification is carried out by the cosine distance measurement with the data normalization. A two-part data division algorithm, one part for training and one part for testing, will follow the second structure and a "Softmax" single-layer classifier is added to its output. The experimentation is conducted on existing dataset: Labeled Faces in the Wild (LFW), as well as on databases (ORL, AR and Thermal Tufts Face) and good performance is obtained.
C1 [Elaggoune, Hocine; Belahcene, Mebarka] Biskra Univ, LI3C Lab, Elect Engn Dept, RB IAIM, BP 145 RP, Biskra 07000, Algeria.
   [Bourennane, Salah] Ecole Cent, Marseille, France.
   [Bourennane, Salah] GSM Inst Fresnel Marseille, Marseille, France.
C3 Universite Mohamed Khider Biskra
RP Elaggoune, H (corresponding author), Biskra Univ, LI3C Lab, Elect Engn Dept, RB IAIM, BP 145 RP, Biskra 07000, Algeria.
EM elaggoune.hocine@gmail.com; mebarka.belahcene@univ-biskra.dz;
   Salah.bourennane@fresnel.fr
OI Elaggoune, Hocine/0000-0001-8661-6532
CR Abu Mallouh A, 2019, IMAGE VISION COMPUT, V88, P41, DOI 10.1016/j.imavis.2019.05.001
   Adjabi I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081188
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Almabdy S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204397
   Ameur B, 2017, INT C ADV TECHN SIGN, P1, DOI [10.1109/ATSIP.2017.8075591, DOI 10.1109/ATSIP.2017.8075591]
   Ameur B, 2019, INT J MULTIMED INF R, V8, P143, DOI 10.1007/s13735-019-00175-w
   [Anonymous], 1973, THESIS KYOTO U
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Ayyavoo T, 2018, IET BIOMETRICS, V7, P380, DOI 10.1049/iet-bmt.2016.0092
   Balaban S, 2015, PROC SPIE, V9457, DOI 10.1117/12.2181526
   Ballardini, 2018, ABS180901942 ARXIV
   Belahcene, 2013, THESIS U MOHAMED KHI
   Benavente R, 1998, 24 COMP VIS CTR
   Bessaoudi M, 2019, LECT NOTE NETW SYST, V50, P215, DOI 10.1007/978-3-319-98352-3_23
   Bledsoe W.W., 1968, Semiautomatic facial recognition. S
   Bruner J., 1954, HDB SOCIAL PSYCHOL, P634
   Cheng EJ, 2019, PATTERN RECOGN LETT, V125, P71, DOI 10.1016/j.patrec.2019.03.006
   Damer, 2019, ABS191009524 ARXIV
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Du LS, 2020, IEEE T CIRC SYST VID, V30, P2830, DOI 10.1109/TCSVT.2019.2923262
   Du Q, 2021, VISUAL COMPUT, V37, P663, DOI 10.1007/s00371-020-01802-y
   Elaggoune H, 2021, 1 INT C CYB MAN ENG, P1, DOI [10.1109/CyMaEn50288.2021.9497271, DOI 10.1109/CYMAEN50288.2021.9497271]
   FORSYTH GA, 1981, J NONVERBAL BEHAV, V6, P115, DOI 10.1007/BF00987287
   Heidari M, 2020, The palgrave encyclopedia of interest groups, P1, DOI DOI 10.1007/978-3-030-13895-076-1
   Hermosilla G, 2018, IEEE ACCESS, V6, P42800, DOI 10.1109/ACCESS.2018.2850281
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang G.B., 2014, LABELED FACES WILD U
   Keinert F, 2019, IEEE T IMAGE PROCESS, V28, P2785, DOI 10.1109/TIP.2018.2890312
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li SJ, 2019, IEEE ACCESS, V7, P20225, DOI 10.1109/ACCESS.2019.2894589
   Liu JJ, 2019, INT J MACH LEARN CYB, V10, P1051, DOI 10.1007/s13042-017-0782-5
   Liu XB, 2018, IEEE ACCESS, V6, P2389, DOI 10.1109/ACCESS.2017.2782884
   Malhotra P, 2019, J INTELL SYST, V28, P321, DOI 10.1515/jisys-2017-0127
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Meng Huang, 2021, Journal of Physics: Conference Series, V1780, DOI 10.1088/1742-6596/1780/1/012034
   Michelucci U., 2019, Professional and Applied Computing, DOI [https://doi.org/10.1007/978-1-4842-4976-5, DOI 10.1007/978-1-4842-4976-5]
   Muhammad HI., 2021, EUROPEAN J ELECT ENG, V5, P9, DOI [10.24018/ejece.2021.5.3.321, DOI 10.24018/EJECE.2021.5.3.321]
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Ouyang AJ, 2020, NEUROCOMPUTING, V393, P214, DOI 10.1016/j.neucom.2019.01.117
   Panetta K, 2020, IEEE T PATTERN ANAL, V42, P509, DOI 10.1109/TPAMI.2018.2884458
   Peng YL, 2018, SIGNAL PROCESS, V147, P101, DOI 10.1016/j.sigpro.2018.01.013
   Preeti, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P322, DOI 10.1109/ICCMC.2018.8487835
   Rikhtegar A, 2020, INT J NONLINEAR ANAL, V11, P301, DOI 10.22075/ijnaa.2020.4296
   Samma H, 2019, NEURAL COMPUT APPL, V31, P6493, DOI 10.1007/s00521-018-3475-4
   Sasirekha K, 2020, INT J BIOMETRICS, V12, P193
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   Shang K, 2018, APPL MATH COMPUT, V320, P99, DOI 10.1016/j.amc.2017.07.058
   Song XN, 2019, SIGNAL PROCESS, V161, P101, DOI 10.1016/j.sigpro.2019.03.007
   Sun Y, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P103, DOI 10.1109/ICMIP.2017.32
   Talab MA, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P331, DOI [10.1109/I2CACIS.2019.8825083, 10.1109/i2cacis.2019.8825083]
   VANDERPLOEG RD, 1987, INT J PSYCHOPHYSIOL, V5, P193, DOI 10.1016/0167-8760(87)90006-7
   Wu H, 2018, IEEE ACCESS, V6, P49563, DOI 10.1109/ACCESS.2018.2869465
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xing Di, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P266, DOI 10.1109/TBIOM.2021.3060641
   Yin, 2018, ABS180309014 ARXIV
   Zhou GY, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420560091
NR 59
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9403
EP 9427
DI 10.1007/s11042-021-11849-1
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756332700019
DA 2024-07-18
ER

PT J
AU Nachar, R
   Inaty, E
AF Nachar, Rabih
   Inaty, Elie
TI An effective segmentation method for iris recognition based on fuzzy
   logic using visible feature points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature points; iris features; Artificial intelligence; Fuzzy logic;
   iris segmentation; iris recognition
ID NORMALIZATION; IMAGES; SYSTEM
AB In this paper, the edge corners (ECs) are proposed as new visible feature points located at the edges of visible iris features such as crypts, pigment spots and stripes. A new technique is developed to segment the iris using the ECs. In addition, an efficient artificial intelligence based fuzzy logic system for the iris recognition stage is used to mitigate the randomness of the iris's visible features due to pupil dilations and elastic distortions. Iris recognition is achieved by comparing the distribution pattern of the ECs using the proposed fuzzy logic system with four linguistic variables. The first goal is to achieve a high recognition rate with very low computational time. The second goal is to facilitate the use of iris recognition in forensics by using only ECs of the visible features of the iris rather than using full images of those features. Therefore, the proposed fuzzy logic based iris segmentation and recognition (FLISR) system can be used for automatic evaluation and manual verification. In the automatic evaluation, the system finds the best gallery iris image(s) matching the input probe image. Manual verification is done when trained examiners perform independent inspections to determine the best matching iris image. Extensive experiments with different data sets demonstrate the efficiency of the proposed FLISR. In terms of iris segmentation, the iris localization has reached an average accuracy of 99.85%. In addition, the average matching accuracy of the iris recognition has achieved 99.83% with very low computational time as compared to similar algorithms available in the literature.
C1 [Nachar, Rabih] Univ Balamand, Dept Telecommun & Networks, POB 33, Elkoura, Lebanon.
   [Inaty, Elie] Univ Balamand, Dept Comp Engn, POB 33, Elkoura, Lebanon.
C3 University Balamand; University Balamand
RP Nachar, R (corresponding author), Univ Balamand, Dept Telecommun & Networks, POB 33, Elkoura, Lebanon.
EM rabih.nachar@balamand.edu.lb
CR Adhau AS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P75, DOI 10.1109/INFOP.2015.7489354
   Adler, 1959, PHYSL EYE CLIN APPL
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   [Anonymous], 2012, Wkly Epidemiol Rec, V87, P1
   [Anonymous], IIT DELH IR DAT
   Arora S, 2018, IEEE INT ADV COMPUT, P157, DOI 10.1109/IADCC.2018.8692114
   Barra S, 2019, MULTIMED TOOLS APPL, V78, P14045, DOI 10.1007/s11042-019-7156-9
   Belcher C, 2009, OPT LASER ENG, V47, P139, DOI 10.1016/j.optlaseng.2008.07.004
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Chen JX, 2016, IEEE T INF FOREN SEC, V11, P1476, DOI 10.1109/TIFS.2016.2535901
   Chinese Academy of Sciences; Institute of Automation, 2015, BIOM ID TEST
   Cui JL, 2004, LECT NOTES COMPUT SC, V3072, P442
   Darabkh KA, 2014, 2014 11TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   Dillak RY, 2016, IEEE REGION 10 SYMP, P231, DOI 10.1109/TENCONSpring.2016.7519410
   Faundra MR, 2017, J PHYS CONF SER, V795, DOI 10.1088/1742-6596/795/1/012049
   Freeman H, 1997, IEEE T COMPUT, V26, P303
   Garibaldi JM, 2003, IEEE INT CONF FUZZY, P578
   Haiqing Li, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P317, DOI 10.1109/ICB.2012.6199826
   Happold M., 2015, International Conference of the Biometrics Special Interest Group (CCPR), page, P28
   Harifi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P115, DOI 10.1109/ICCTIM.2015.7224603
   He F, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023005
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Joshi Kalpesh A., 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7285673
   Khalighi S, 2015, J SIGNAL PROCESS SYS, V81, P111, DOI 10.1007/s11265-014-0911-2
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Li CC, 2015, VISUAL COMPUT, V31, P1419, DOI 10.1007/s00371-014-1023-5
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liu CH, 2015, SECUR COMMUN NETW, V8, P727, DOI 10.1002/sec.1020
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Mehrotra H, 2013, MATH COMPUT MODEL, V58, P132, DOI 10.1016/j.mcm.2012.06.034
   Minaee S, 2019, ARXIV190709380V1
   Nachar R, 2019, PATTERN ANAL APPL
   Naderi H, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P327, DOI 10.1109/CRV.2016.18
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Qiaoli G, 2018, P INT C INT TRANSP B
   Radman A, 2017, DIGIT SIGNAL PROCESS, V64, P60, DOI 10.1016/j.dsp.2017.02.003
   RAVI J., 2009, INT J ENG SCI TECHNO, V1, P35
   Roy DA, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2668, DOI 10.1109/ICEEOT.2016.7755178
   Shen F, 2014, THESIS U NOTRE DAME
   Shen F, 2012, P IEEE C TECHN HOM S
   Shen F, 2014, IEEE WINT CONF APPL, P977, DOI 10.1109/WACV.2014.6835998
   Shen F, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Shen F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P208, DOI 10.1109/THS.2012.6459851
   Umer S, 2016, PATTERN ANAL APPL, V19, P283, DOI 10.1007/s10044-015-0482-2
   Wang C, 2019, ARXIV190111195V2
   Wildes RP, 1996, MACH VISION APPL, V9, P1, DOI 10.1007/BF01246633
   Yang GP, 2013, INT J MACH LEARN CYB, V4, P401, DOI 10.1007/s13042-012-0101-0
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhao J, 2002, IEEE IND ELEC, P229, DOI 10.1109/IECON.2002.1187512
NR 54
TC 6
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9803
EP 9828
DI 10.1007/s11042-022-12204-8
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800019
DA 2024-07-18
ER

PT J
AU Zhang, J
   Zhou, KN
   Luximon, Y
   Li, P
   Iftikhar, H
AF Zhang, Jie
   Zhou, Kangneng
   Luximon, Yan
   Li, Ping
   Iftikhar, Hassan
TI 3D-guided facial shape clustering and analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial shape clustering; Facial shape analysis; 3D face reconstruction;
   Facial beauty analysis
ID 3D; FIT
AB Facial shape classification is of crucial importance in facial characteristics analysis and product recommendation. In this paper, we develop a 3D-guided facial shape clustering and analysis method to classify facial shapes without supervision, which is more reliable and accurate. This method consists of four steps: 3D face reconstruction, facial shape normalization, facial feature extraction and facial contour clustering. Firstly, we incorporate two 3D face reconstruction methods to reconstruct 3D face mesh without expression component from 1997 male and 2493 female facial images. Secondly, we normalize these 3D facial contours by translation and scaling. Thirdly, we propose two facial contour representations: geometric and anthropometric features. Fourthly, we use and compare three clustering methods to cluster these facial contours based on the extracted contour features by using Silhouette Coefficient and Calinski-Harabasz Index. The Circular Dendrogram of the hierarchical clustering result based on geometric features shows the optimal cluster number is 6 for 3D female and male faces and the analysis results demonstrate the K-means clustering on geometric features can achieve better performance. A further investigation between the beauty distribution and facial shape clusters reveals that the facial shapes with more pointed chin have higher beauty ratings, regardless of male or female. The facial shape analysis results can be applied in face-related product design, hairstyle recommendation and cartoon character creation. The code will be released to the public for research purpose: https://github.com/Easy-Shu/facial_shape_clustering
C1 [Zhang, Jie; Luximon, Yan; Iftikhar, Hassan] Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
   [Zhou, Kangneng] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; University of Science & Technology
   Beijing; Hong Kong Polytechnic University
RP Luximon, Y (corresponding author), Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
EM yan.luximon@polyu.edu.hk
RI Zhang, Jie/I-1032-2019; Iftikhar, Hassan/GSN-5463-2022; Li,
   Ping/AAO-2019-2020; Luximon, Yan/A-7946-2010
OI Zhang, Jie/0000-0001-8219-5590; Iftikhar, Hassan/0000-0003-4187-8082;
   Li, Ping/0000-0002-1503-0240; Luximon, Yan/0000-0003-2843-847X
FU Research Grants Council (RGC) of Hong Kong [15603419]
FX This work was financially supported by the Research Grants Council (RGC)
   of Hong Kong to conduct General Research Fund (GRF) (15603419).
CR Alzahrani T., 2019, 2019 INT C INT SYST, P1
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210
   Bansode N., 2016, Int J Comput Sci Issue (IJCSI), V13, P24, DOI DOI 10.20943/IJCSI-201602-2431
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chu CH, 2015, INT J PRECIS ENG MAN, V16, P487, DOI 10.1007/s12541-015-0066-5
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dornaika F, 2020, MULTIMED TOOLS APPL, V79, P3005, DOI 10.1007/s11042-019-08206-8
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Ellena Thierry, 2018, Computer-Aided Design and Applications, V15, P25, DOI 10.1080/16864360.2017.1353727
   Ellena T, 2016, APPL ERGON, V55, P194, DOI 10.1016/j.apergo.2016.02.008
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gu ZG, 2014, BIOINFORMATICS, V30, P2811, DOI 10.1093/bioinformatics/btu393
   Guo J, 2020, ARXIV PREPRINT ARXIV
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Joblove G.H., 1978, P 5 ANN C COMP GRAPH, VVolume 12, P20, DOI DOI 10.1145/965139.807362
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Liang LY, 2018, INT C PATT RECOG, P1598, DOI 10.1109/ICPR.2018.8546038
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P16633, DOI 10.1007/s11042-016-3830-3
   Luximon Y., 2015, Computer-Aided Design and Applications, V13, P153
   Murtagh F., 2011, Computer, V38, P1
   Pasupa K, 2019, EXPERT SYST APPL, V120, P14, DOI 10.1016/j.eswa.2018.11.011
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Rahmat Romi Fadillah, 2018, IOP Conference Series: Materials Science and Engineering, V420, DOI 10.1088/1757-899X/420/1/012095
   Ren WQ, 2019, IEEE I CONF COMP VIS, P9387, DOI 10.1109/ICCV.2019.00948
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Shu-Cong Zhang, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P44, DOI 10.1109/ICWAPR.2011.6014478
   Skals S, 2016, INT J IND ERGONOM, V55, P86, DOI 10.1016/j.ergon.2016.08.009
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Sunhem W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P390, DOI 10.1109/ICACI.2016.7449857
   Tio A. E., 2019, Face Shape Classification Using Inception V3
   Xiao Y, 2012, WIRES DATA MIN KNOWL, V2, P209, DOI 10.1002/widm.1049
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Yanqiu Xu, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2588, DOI 10.1109/CISP.2010.5648207
   Zhang J, 2020, JOINT C AS COUNC ERG, P357
   Zhao J, 2020, COGN NEURODYNAMICS, V14, P643, DOI 10.1007/s11571-020-09591-9
   Zhao J, 2019, IEEE ACCESS, V7, P10956, DOI 10.1109/ACCESS.2019.2892137
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
NR 44
TC 7
Z9 7
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8785
EP 8806
DI 10.1007/s11042-022-12190-x
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751584600002
DA 2024-07-18
ER

PT J
AU Long, XZ
   Zhang, ZY
   Li, Y
AF Long, Xianzhong
   Zhang, Zhiyi
   Li, Yun
TI A singular value decomposition representation based approach for robust
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Sparse representation; Collaborative representation;
   Singular value decomposition; Robustness
ID CLASSIFICATION; SPARSE; ILLUMINATION; MODELS
AB In the field of face recognition, sparse representation based classification (SRC) and collaborative representation based classification (CRC) have been widely used. Although both SRC and CRC have shown good classification results, it is still controversial whether it is sparse representation or collaborative representation that helps face recognition. In this paper, a new singular value decomposition based classification (SVDC) is proposed for face recognition. The proposed approach performs SVD on the training data of each class, and then determines the class of a test sample by comparing in which class of singular vectors it can be better represented. Experimental results on Yale B, PIE and UMIST datasets show that the proposed method achieves better recognition performance compared with several existing representation based classification algorithms. In addition, by adding Gaussian noise and Salt pepper noise to these datasets, it is proved that SVDC has better robustness. At the same time, the experimental results show that the recognition accuracy of the method acting on the training samples constructed by each class is higher than that of the method acting on the training sets constructed by all classes.
C1 [Long, Xianzhong; Zhang, Zhiyi; Li, Yun] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Long, XZ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing 210023, Peoples R China.
EM lxz@njupt.edu.cn; 1020041208@njupt.edu.cn; liyun@njupt.edu.cn
OI Long, Xianzhong/0000-0001-6281-0832
FU National Natural Science Foundation of China [61906098]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61906098).
CR Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Chi YJ, 2014, IEEE T PATTERN ANAL, V36, P1519, DOI 10.1109/TPAMI.2013.236
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lan RS, 2020, IEEE T CYBERNETICS, V50, P1498, DOI 10.1109/TCYB.2018.2880290
   Lin GJ, 2018, PATTERN RECOGN, V81, P341, DOI 10.1016/j.patcog.2018.03.021
   Liu SG, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01067-4
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Selvan S, 2007, IEEE T IMAGE PROCESS, V16, P2688, DOI 10.1109/TIP.2007.908082
   Shao CB, 2017, INFORM SCIENCES, V393, P1, DOI 10.1016/j.ins.2017.02.017
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Slawski M, 2013, ELECTRON J STAT, V7, P3004, DOI 10.1214/13-EJS868
   Song XN, 2018, IEEE T INF FOREN SEC, V13, P2734, DOI 10.1109/TIFS.2018.2833052
   Wei Liu, 2012, AI 2012: Advances in Artificial Intelligence. 25th Australasian Conference. Proceedings, P649, DOI 10.1007/978-3-642-35101-3_55
   Wright JD, 2011, ANN SURG, V253, P1140, DOI 10.1097/SLA.0b013e31821287ac
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu J, 2019, PATTERN RECOGN, V88, P679, DOI 10.1016/j.patcog.2018.12.023
   Yin HF, 2020, AFFINE NONNEGATIVE C
   Zhang GY, 2018, MULTIMED TOOLS APPL, V77, P7171, DOI 10.1007/s11042-017-4627-8
   Zhang GY, 2017, DIGIT SIGNAL PROCESS, V62, P150, DOI 10.1016/j.dsp.2016.11.004
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 27
TC 2
Z9 2
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8283
EP 8308
DI 10.1007/s11042-022-12199-2
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800015
DA 2024-07-18
ER

PT J
AU Barlaskar, SA
   Singh, SV
   Monsley, KA
   Laskar, RH
AF Barlaskar, Saharul Alom
   Singh, Sajai Vir
   Monsley, Anish K.
   Laskar, Rabul Hussain
TI Genetic algorithm based optimized watermarking technique using hybrid
   DCNN-SVR and statistical approach for watermark extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Deep convolution and neural network; Support
   vector regression; Genetic algorithm
ID DCT BASED ROBUST; WAVELET TRANSFORM; SCHEME; SECURE
AB This paper presents a watermark embedding and extraction technique using DWT-DCT framework. In digital image watermarking, one of the major challenge is to provide adequate robustness while preserving the image imperceptibility and security in the presence of geometric and non-geometric attack condition. Geometric attacks deform the geometrical shape of watermarked images and non-geometric attacks degrade its visual quality, extracting the watermark in such condition is futile. In this work, we propose a watermarking technique that uses DWT for decomposition of cover image up to 3rd-level sub bands. DCT is applied on the sub band coefficient and the watermark is embedded by replacing the mid band frequency components. Genetic algorithm has been used for optimized selection of gain factor (alpha(opt)) that will help to reduce the influence of channel distortion. Bottleneck features extracted through a deep convolutional neural network (DCNN) helps the support vector regressor (SVR) to estimate the degree of various geometric attacks. A statistical non-geometric correction (SNC) algorithm has also been incorporated to extract the watermark under various non-geometric attack conditions. To enhance the security, three secure keys are used in this proposed work. Experimenting with the geometric attack image database (GAID-RST) prepared at NIT Silchar, the proposed watermarking technique is able to overcome the geometric attacks (translation, rotation) with a mean error rate (MER) of 8.32 and is capable of extracting watermark in the presence of non-geometric attacks (noisy attack, median filtering, JPEG compression, etc.). The proposed technique provides an average imperceptibility of 47.81 dB and robustness (NC similar to 0.9784). Comparative performance indicates that the proposed technique is relatively better than the existing state-of-the-art watermarking schemes.
C1 [Barlaskar, Saharul Alom; Monsley, Anish K.; Laskar, Rabul Hussain] NIT Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
   [Singh, Sajai Vir] JIIT, Dept Elect & Commun Engn, Noida 201304, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; Jaypee Institute of Information Technology (JIIT)
RP Barlaskar, SA (corresponding author), NIT Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM saharul_rs@ece.nits.ac.in
RI Laskar, Rabul Hussain/AFU-7180-2022; KIRUPAKARAN, ANISH
   MONSLEY/AFT-0411-2022; Singh, Sajai vir/AGT-2658-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; KIRUPAKARAN, ANISH
   MONSLEY/0000-0002-4927-3785; Barlaskar, Saharul Alom/0000-0002-2654-2073
FU speech and image processing laboratory, ECE Department, National
   Institute of Technology Silchar (NITS), India; ECE Department of Barak
   Valley Engineering College, Assam;  [IMP/2018/000098]
FX The authors would like to acknowledge the speech and image processing
   laboratory, ECE Department, National Institute of Technology Silchar
   (NITS), India, and ECE Department of Barak Valley Engineering College,
   Assam for providing the necessary support and facilities to carry out
   this research work. The author would like to thank Mr. Kuldeep Yadav of
   the same lab for his valuable suggestion and advice. The authors are
   very much grateful to the anonymous reviewers for their valuable
   comments. We would also like to thank the IMP/2018/000098 project for
   providing high-end computational equipment.
CR Ahmad A, 2014, INT J COMPUT NETWORK
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   [Anonymous], 2006, GENETIC ALGORITHMS
   Bhatnagar G, 2013, MATH COMPUT MODEL, V58, P204, DOI 10.1016/j.mcm.2012.06.002
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Gangadhar Y, 2017, 2016 IEEE INT C COMP, DOI [10.1109/ICCIC.2016.7919557, DOI 10.1109/ICCIC.2016.7919557]
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Gunjal B., 2011, SECURED COLOR IMAGE, V1, P36
   Guo ZW, 2022, INT J INTELL SYST, V37, P10423, DOI 10.1002/int.22540
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   ImageProcessingPlace, IM DAT
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Islam M, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053008
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Islam M, 2018, J INTELL FUZZY SYST, V34, P1691, DOI 10.3233/JIFS-169462
   Kasana G, 2017, OPTIK, V142, P191, DOI 10.1016/j.ijleo.2017.05.027
   Keping Yu, 2021, IEEE Wireless Communications, V28, P54, DOI 10.1109/MWC.001.2000374
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Laskar RH, 2011, COMM COM INF SC, V157, P482
   Lee CF, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), P207, DOI 10.1109/CCOMS.2018.8463259
   Li JZ, 2010, INT CONF COMP SCI, P367, DOI 10.1109/ICCSIT.2010.5564713
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Navas KA, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P271, DOI 10.1109/COMSWA.2008.4554423
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Punidha R., 2017, INT J PURE APPL MATH, V116, P295
   Rachmawanto EH., 2019, TELKOMNIKA TELECOMMU, V17, P1750, DOI [10.12928/telkomnika.v17i4.9227, DOI 10.12928/TELKOMNIKA.V17I4.9227]
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Salama AS, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P557, DOI 10.1109/CompComm.2016.7924763
   Santhi V, 2009, HYBRID BLOCK BASED W, P1, DOI [10.1109/icccnet.2008.4907259, DOI 10.1109/ICCCNET.2008.4907259]
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh C, 2013, OPT LASER TECHNOL, V54, P176, DOI 10.1016/j.optlastec.2013.05.016
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tan L, 2023, NEURAL COMPUT APPL, V35, P13921, DOI 10.1007/s00521-021-06219-9
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang B, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1034, DOI 10.1109/ICNIDC.2009.5360866
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Yu KP, 2021, IEEE T INTELL TRANSP, V22, P4337, DOI 10.1109/TITS.2020.3042504
   Yu KP, 2022, IEEE INTERNET THINGS, V9, P2698, DOI 10.1109/JIOT.2021.3079574
   Zhang WY, 2016, 2016 17TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT), P167, DOI [10.1109/PDCAT.2016.046, 10.1109/PDCAT.2016.45]
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   Zhou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10030077
   Zhu HQ, 2010, DIGIT SIGNAL PROCESS, V20, P1612, DOI 10.1016/j.dsp.2010.01.010
NR 61
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7461
EP 7500
DI 10.1007/s11042-021-11798-9
EA JAN 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000750324700001
DA 2024-07-18
ER

PT J
AU AlShaikh, M
AF AlShaikh, Muath
TI A novel tamper detection watermarking approach for improving image
   integrity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Watermarking; Code division multiple access; Integrity
ID FORGERY DETECTION; LSB WATERMARKING; IMPLEMENTATION; ALGORITHM; SCHEME;
   CRYPTOSYSTEM; SECURE; DCT
AB Internet use has become a staple of our lives to transfer data. Although anyone can alter or modify these data, as image modifying tools are readily available. The slightest change in the medical image can lead to a wrong diagnosis, and the vital goal is not achieved. Tamper detection has been proposed as a solution for ensuring the integrity and authenticity of digital images. The goal is to identify and pinpoint any image changes that have taken place after transmission. An innovative watermarking technique is presented in this paper for detecting tampering. The approach relies on the Code Division Multiple Access (CDMA) technique. In order to generate the Common Code (watermark) data, the blocks must be encoded, followed by a Walsh table. This embedding process occurs in the LSB of each block. During the semi-blind detection step, the encode (data representation) matrix is necessary during the verification and detection steps. The proposed approach evaluated various types of attacks and tampered processes. According to the results of the experiments, the proposed approach outperforms existing and related approaches in terms of quality, imperceptibility, capacity, and tamper detection. The proposed method is evaluated using the Stirmark benchmark and CASIA v2 dataset. The approach provides a high quality and there is no degradation after embedding the watermark in the original image. Also, the watermarked approach is imperceptible where the PSNR is 56.4 dB and the SSIM is 0.9983, it consumes less space in the original image, its bPP is 0.85. In addition, it requires less computational resources than other approaches with an embedding and extraction time of 3.798 s. Further, the detection performance of the tampered data is 99.965. In addition, the approach provides promising results against spliced tampering, with an average F1 score of 0.8969.
C1 [AlShaikh, Muath] Saudi Elect Univ, Coll Comp & Informat, Comp Sci Dept, Riyadh 11673, Saudi Arabia.
C3 Saudi Electronic University
RP AlShaikh, M (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Comp Sci Dept, Riyadh 11673, Saudi Arabia.
EM m.alshaikh@seu.edu.sa
OI Alshaikh, Muath/0000-0002-1520-9814; AlShaikh, Muath/0000-0001-5550-7659
CR AlShaikh M., 2016, INT J COMPUT SCI INF, V14, P261
   AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   AlShaikh M, 2016, INT J COMPUT SCI NET, V16, P62
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Alshaykh M. S., 2019, 2019 1 INT C INT COM, P1, DOI DOI 10.1109/ICOICE48418.2019.9035193
   Nguyen AH, 2016, J REAL-TIME IMAGE PR, V11, P799, DOI 10.1007/s11554-014-0420-3
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Bikov D, 2018, CYBERN INF TECHNOL, V18, P21, DOI 10.2478/cait-2018-0018
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chen TS, 2019, IEEE T VLSI SYST, V27, P2485, DOI 10.1109/TVLSI.2019.2933722
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Cheraghchi M, 2017, ACM T ALGORITHMS, V13, DOI 10.1145/3029050
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Faragallah OS, 2018, WIRELESS PERS COMMUN, V98, P2009, DOI 10.1007/s11277-017-4960-2
   Farid H., 1999, DETECTING DIGITAL FO
   Farid H, 2017, AM SCI, V105, P77
   Haghighi BB, 2019, INFORM SCIENCES, V486, P204, DOI 10.1016/j.ins.2019.02.055
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Jun-Dong Chang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P173, DOI 10.1109/ISNE.2013.6512330
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Pham NT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010083
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Park CS, 2018, MULTIMED TOOLS APPL, V77, P16795, DOI 10.1007/s11042-017-5248-y
   Park CS, 2016, MULTIMED TOOLS APPL, V75, P16577, DOI 10.1007/s11042-016-3575-z
   Park TH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0136-3
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Prucnal PR, 2018, OPTICAL CODE DIVISIO
   Rao Y, 2016, IEEE INT WORKS INFOR
   Robles A, 2018, IEEE SOUTHEASTCON
   Roy D, 2017, FUTURE GENER COMP SY, V71, P89, DOI 10.1016/j.future.2017.01.021
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Sharma S, 2022, J BIOMOL STRUCT DYN, V40, P3003, DOI 10.1080/07391102.2020.1844058
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Singhal Sakshi, 2021, Mobile Radio Communications and 5G Networks. Proceedings of MRCN 2020. Lecture Notes in Networks and Systems (LNNS 140), P237, DOI 10.1007/978-981-15-7130-5_18
   Sun XC, 2021, MULTIMED TOOLS APPL, V80, P13491, DOI 10.1007/s11042-020-10392-9
   Teng L, 2013, AEU-INT J ELECTRON C, V67, P540, DOI 10.1016/j.aeue.2012.12.001
   Ulutas G, 2017, J DIGIT IMAGING, V30, P695, DOI 10.1007/s10278-017-9961-x
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Zhang H, 2017, J INF PROCESS SYST, V13, P385, DOI 10.3745/JIPS.03.0070
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang S, 2021, IEEE WIREL COMMUN, V28, P160, DOI 10.1109/MWC.001.2000534
   Zheng Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777
NR 50
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10039
EP 10060
DI 10.1007/s11042-021-11840-w
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000745425000004
DA 2024-07-18
ER

PT J
AU Keerti, G
   Vaishnavi, AN
   Mukherjee, P
   Vidya, AS
   Sreenithya, GS
   Nayab, D
AF Keerti, Gullapalli
   Vaishnavi, A. N.
   Mukherjee, Prerana
   Vidya, A. Sree
   Sreenithya, Gattineni Sai
   Nayab, Deeksha
TI Attentional networks for music generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent neural network (RNN); Long short term memory (LSTM);
   Attention; Bidirectional LSTM; MIDI format
AB Realistic music generation has always remained as a challenging problem as it may lack structure or rationality. In this work, we propose a deep learning based music generation method in order to produce old style music particularly JAZZ with rehashed melodic structures utilizing a Bi-directional Long Short Term Memory (Bi-LSTM) Neural Network with attention. Owing to the success in modelling long-term temporal dependencies in sequential data and its success in case of videos, Bi-LSTMs with attention serves as a natural choice and early utilization in music generation. We validate in our experiments that Bi-LSTMs with attention are able to preserve the richness and technical nuances of the music performed.
C1 [Keerti, Gullapalli; Vaishnavi, A. N.; Vidya, A. Sree; Sreenithya, Gattineni Sai; Nayab, Deeksha] Indian Inst Informat Technol, Sri City, Andhra Pradesh, India.
   [Mukherjee, Prerana] Jawaharlal Nehru Univ, Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Mukherjee, P (corresponding author), Jawaharlal Nehru Univ, Delhi, India.
EM keerti.g17@iiits.in; vaishnavi.a17@iiits.in; prerana@jnu.ac.in;
   sreevidya.a17@iiits.in; saisreenithya.g17@iiits.in; deeksha.n17@iiits.in
CR Abraham A, 2005, HDB MEASURING SYSTEM
   Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR
   Browne CB, 2001, US Patent, Patent No. [6, 297, 439, 6297439]
   Chen CCJ, 2001, IEEE IJCNN, P2241, DOI 10.1109/IJCNN.2001.938515
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Douglas Eck, 2002, Istituto Dalle Molle Di Studi Sull'Intelligenza Artificiale, V103, P48
   Drewes F, 2007, LECT NOTES COMPUT SC, V4728, P172
   Eck D, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P747, DOI 10.1109/NNSP.2002.1030094
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Johnson DD, 2017, LECT NOTES COMPUT SC, V10198, P128, DOI 10.1007/978-3-319-55750-2_9
   Lee HT, 2009, ACM T WEB, V3, DOI 10.1145/1541822.1541823
   Lewis J. P., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P229, DOI 10.1109/ICNN.1988.23933
   Liu I, 2014, ARXIV14123191
   Nielsen, 2017, ARXIV170906404
   Oord A., 2016, ARXIV160903499
   Schulze W, 2011, IEEE MULTIMEDIA, V18, P78, DOI 10.1109/MMUL.2010.44
   Todd P, 1988, P 1988 CONN MOD SUMM, P76
   Vaswani A, 2017, ADV NEUR IN, V30
   Yang Li-Chia, 2017, ARXIV170310847
   Ycart A., 2017, Proceedings of the 18th International Society for Music Information Retrieval Conference
NR 23
TC 8
Z9 8
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5179
EP 5189
DI 10.1007/s11042-021-11881-1
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000745425000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dey, S
   Roychoudhury, R
   Malakar, S
   Sarkar, R
AF Dey, Subhrajit
   Roychoudhury, Rajarshi
   Malakar, Samir
   Sarkar, Ram
TI Screening of breast cancer from thermogram images by edge detection
   aided deep transfer learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermogram image; Breast cancer; Transfer learning; Edge detection;
   DenseNet121; DMR-IR dataset
ID CLASSIFICATION; FEATURES; CNN
AB Breast cancer, the most common invasive cancer, causes deaths of thousands of women in the world every year. Early detection of the same is a remedy to lessen the death rate. Hence, screening of breast cancer in its early stage is utmost required. However, in the developing nations not many can afford the screening and detection procedures owing to its cost. Hence, an effective and less expensive way of detecting breast cancer is performed using thermography which, unlike other methods, can be used on women of various ages. To this end, we propose a computer aided breast cancer detection system that accepts thermal breast images to detect the same. Here, we use the pre-trained DenseNet121 model as a feature extractor to build a classifier for the said purpose. Before extracting features, we work on the original thermal breast images to get outputs using two edge detectors - Prewitt and Roberts. These two edge-maps along with the original image make the input to the DenseNet121 model as a 3-channel image. The thermal breast image dataset namely, Database for Mastology Research (DMR-IR) is used to evaluate performance of our model. We achieve the highest classification accuracy of 98.80% on the said database, which outperforms many state-ofthe-art methods, thereby confirming the superiority of the proposed model. Source code of this work is available here: https://github.com/subro608/thermogram
C1 [Dey, Subhrajit] Jadavpur Univ, Dept Elect Engn, Kolkata, India.
   [Roychoudhury, Rajarshi; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
C3 Jadavpur University; Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM subhrajitdey.agt@gmail.com; rroychoudhury2@gmail.com;
   malakarsamir@gmail.com; raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Malakar, Samir/A-8021-2017
OI Sarkar, Ram/0000-0001-8813-4086; Malakar, Samir/0000-0003-4217-2372
CR Abdel-Nasser M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010100
   Acharya UR, 2012, J MED SYST, V36, P1503, DOI 10.1007/s10916-010-9611-z
   Araújo MC, 2014, EXPERT SYST APPL, V41, P6728, DOI 10.1016/j.eswa.2014.04.027
   Borchartt TB, 2013, SIGNAL PROCESS, V93, P2785, DOI 10.1016/j.sigpro.2012.08.012
   Chaib S, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281755
   Cho N, 2017, JAMA ONCOL, V3, P1495, DOI 10.1001/jamaoncol.2017.1256
   Das S, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100233
   Deepak A., 2020, THERMAL IMAGES BREAS
   Dey S, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104585
   Dorafshan S, 2018, CONSTR BUILD MATER, V186, P1031, DOI 10.1016/j.conbuildmat.2018.08.011
   Ekici S, 2020, MED HYPOTHESES, V137, DOI 10.1016/j.mehy.2019.109542
   da Silva TAE, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143866
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Francis SV, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0023-3
   Gao F, 2018, COMPUT MED IMAG GRAP, V70, P53, DOI 10.1016/j.compmedimag.2018.09.004
   Hela Boulehmi, 2013, 2013 10th International Multi-Conference on Systems, Signals and Devices (SSD 2013), P1
   Herry CL, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-19
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Fernández-Ovies FJ, 2019, LECT N BIOINFORMAT, V11466, P514, DOI 10.1007/978-3-030-17935-9_46
   Jinda Hu, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P1, DOI 10.1109/ICIVC50857.2020.9177438
   Jones BF, 2002, IEEE ENG MED BIOL, V21, P41, DOI 10.1109/MEMB.2002.1175137
   Kennedy DA, 2009, INTEGR CANCER THER, V8, P9, DOI 10.1177/1534735408326171
   Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lin CJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072591
   Mambou SJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092799
   Okuniewski R, 2016, PROC SPIE, V10031, DOI 10.1117/12.2249065
   Pramanik S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P8, DOI 10.1109/ICACCI.2016.7732018
   Pramanik S, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), P205, DOI 10.1109/ISACC.2015.7377343
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Sayed GI, 2016, STUD COMPUT INTELL, V651, P487, DOI 10.1007/978-3-319-33793-7_21
   Schaefer G, 2009, PATTERN RECOGN, V42, P1133, DOI 10.1016/j.patcog.2008.08.007
   Shahari S, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P1577, DOI 10.1109/IIC.2015.7151001
   Silva LF, 2014, J MED IMAG HEALTH IN, V4, P92, DOI 10.1166/jmihi.2014.1226
   Silva LF, 2015, STUD HEALTH TECHNOL, V216, P746, DOI 10.3233/978-1-61499-564-7-746
   Tello-Mijares Santiago, 2019, J Healthc Eng, V2019, P9807619, DOI 10.1155/2019/9807619
   Vijayarani, 2013, International Journal of Innovative Research in Computer and Communication Engineering, V1, P1760
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zuluaga-Gomez J, 2021, COMP M BIO BIO E-IV, V9, P131, DOI 10.1080/21681163.2020.1824685
NR 39
TC 21
Z9 21
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9331
EP 9349
DI 10.1007/s11042-021-11477-9
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000740429700012
PM 35035264
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Fang, LL
   Yao, YB
   Zhang, LR
   Wang, X
   Zhang, QL
AF Fang, Lingling
   Yao, Yibo
   Zhang, Lirong
   Wang, Xin
   Zhang, Qile
TI Energy functional driven by multiple features for brain lesion
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI brain tumor; CT encephalorrhagia; Image segmentation; Energy
   functional; Multiple features
ID ACTIVE CONTOURS DRIVEN; LEVEL SET EVOLUTION; IMAGE SEGMENTATION; FITTING
   ENERGY; LOCALIZING REGION; TUMOR; TEXTURE; MODEL
AB Brain lesion segmentation can provide useful information for diagnosis and treatment planning. The extracted features are beneficial to the accuracy of brain lesion segmentation. However, due to complex structures of different tissues in different brain modalities, i.e., magnetic resonance imaging (MRI) and computed tomography (CT), the extraction of useful features is a challenging task. In this paper, the effectiveness of four different features, i.e., local intensity, shape, and area to discriminate brain lesion from other normal tissues is explored. Here, the performance of each feature in brain images is analyzed. Next, an energy functional framework integrated with multiple features is implemented. The experiments show that the proposed method can perform well in both real MRI brain tumor and other CT encephalorrhagia segmentation obtained from Quzhou People's hospital. The concrete innovations are as follows: (1) in view of the complexity of brain imaging and the difficulty of identifying lesion region, the proposed method can be applied to the segmentation of more complex brain lesions; (2) multiple features, i.e., local intensity, shape, and area are extracted to construct the proposed energy functional; (3) the proposed model is demonstrated using 32 real MRI images from ten pediatric patients and three different similarity metrics are evaluated. To verify the performance of the proposed algorithm, more than representative 20 images are randomly selected in databases of Quzhou People's hospital for evaluation. The average DICE coefficient, the Jaccard (JAC) distance, the Recall, and Root Mean Square Error (RMSE) are 0.95, 0.90, 0.92, and 0.07, respectively. The proposed method can reach better accuracy performance than the traditional energy functional-based methods and other state-of-the-art brain lesion segmentation methods.
C1 [Fang, Lingling; Yao, Yibo; Zhang, Lirong; Wang, Xin] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
   [Fang, Lingling] Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
   [Zhang, Qile] Quzhou Peoples Hosp, Rehabil Dept, Quzhou, Zhejiang, Peoples R China.
C3 Liaoning Normal University; Nanchang Institute Technology
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.; Fang, LL (corresponding author), Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI zhang, lin/IZQ-4870-2023; Zhang, Liqun/JDN-3523-2023; Zhang,
   Li/GWM-7501-2022; Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU Natural Science Foundations of China [6180120]; Dalian Youth Science and
   Technology Star [2019RQ021]
FX This work was supported by the Natural Science Foundations of China
   [Grant Number 6180120] and Dalian Youth Science and Technology Star
   [Grant Number 2019RQ021].
CR Ahmed S, 2011, IEEE T INF TECHNOL B, V15, P206, DOI 10.1109/TITB.2011.2104376
   Fang JX, 2021, INFORM SCIENCES, V546, P397, DOI 10.1016/j.ins.2020.08.078
   Feng CL, 2018, J MED IMAG HEALTH IN, V8, P1655, DOI 10.1166/jmihi.2018.2488
   Foster B, 2014, COMPUT BIOL MED, V50, P76, DOI 10.1016/j.compbiomed.2014.04.014
   He JW, 2019, MULTIMED TOOLS APPL, V78, P8669, DOI 10.1007/s11042-018-5952-2
   Ilunga-Mbuyamba E, 2016, EXPERT SYST APPL, V56, P59, DOI 10.1016/j.eswa.2016.02.048
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Kanas VG, 2015, BIOMED SIGNAL PROCES, V22, P19, DOI 10.1016/j.bspc.2015.06.004
   Kanmani P, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0915-8
   Khadidos A, 2017, IEEE T IMAGE PROCESS, V26, P1979, DOI 10.1109/TIP.2017.2666042
   Ladgham A, 2015, SIGNAL IMAGE VIDEO P, V9, P1113, DOI 10.1007/s11760-013-0546-y
   Lan JH, 2013, OPTIK, V124, P3756, DOI 10.1016/j.ijleo.2012.11.023
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li BN, 2016, IEEE ACCESS, V4, P4777, DOI 10.1109/ACCESS.2016.2590440
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Menze BH, 2016, IEEE T MED IMAGING, V35, P933, DOI 10.1109/TMI.2015.2502596
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Sawlani V, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-020-00888-1
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Shyu KK, 2012, NONLINEAR DYNAM, V69, P295, DOI 10.1007/s11071-011-0265-2
   STEIGER JH, 1990, MULTIVAR BEHAV RES, V25, P173, DOI 10.1207/s15327906mbr2502_4
   Toth R, 2012, IEEE T MED IMAGING, V31, P1638, DOI 10.1109/TMI.2012.2201498
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wang J, 2018, INT J RADIAT ONCOL, V102, pE548, DOI 10.1016/j.ijrobp.2018.07.1529
   Wang LF, 2014, MAGN RESON IMAGING, V32, P71, DOI 10.1016/j.mri.2013.01.010
   Wang LF, 2013, PATTERN RECOGN LETT, V34, P637, DOI 10.1016/j.patrec.2012.12.022
   Zhang D, 2015, PHYS MED BIOL, V60, P1807, DOI 10.1088/0031-9155/60/5/1807
   Zhang M, 2020, J MAGN RESON IMAGING, V52, P1227, DOI 10.1002/jmri.27129
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
NR 34
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36195
EP 36215
DI 10.1007/s11042-021-11620-6
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000740429700033
DA 2024-07-18
ER

PT J
AU Rai, M
   Sharma, R
   Satapathy, SC
   Yadav, DK
   Maity, T
   Yadav, RK
AF Rai, Mritunjay
   Sharma, Rohit
   Satapathy, Suresh Chandra
   Yadav, Dileep Kumar
   Maity, Tanmoy
   Yadav, R. K.
TI An improved statistical approach for moving object detection in thermal
   video frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal video surveillance; Object detection; Background modeling;
   Morphological tool; Gaussian mixture model
ID BACKGROUND SUBTRACTION METHOD; TARGET DETECTION; NEURAL-NETWORK;
   TRACKING; EXTRACTION
AB In a video surveillance system, background modeling is assumed to be a fundamental technique for moving object detection. The surveillance system based on thermal video overcomes many challenges, such as background variations, varying light intensity, external illumination source, and so on. This paper presents a new method for background modeling and background subtraction. The method utilizes the combined approach of Fisher's Linear Discriminant and Relative Entropy for pixel based classification and detection of moving objects in thermal video frames. The experimental results show the higher average value of various performance indicators like Accuracy, ROC, and F-measure. In contrast, the percentage of false classification and total error is minimum and also has lesser execution time. The method outperforms when compared with the other existing methods.
C1 [Rai, Mritunjay] Indian Inst Technol ISM, Dhanbad, Jharkhand, India.
   [Sharma, Rohit] SRM Inst Sci & Technol, Dept Elect & Commun Engn, NCR Campus, Ghaziabad, India.
   [Satapathy, Suresh Chandra] KIIT, Bhubaneswar, Orissa, India.
   [Yadav, Dileep Kumar] Galgotias Univ, Dept CSE, Gautam Budha Nagar, Uttar Pradesh, India.
   [Maity, Tanmoy] Indian Inst Technol ISM, Dept MME, Dhanbad, Jharkhand, India.
   [Yadav, R. K.] RKGIT, Dept ECE, Ghaziabad, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; SRM Institute of Science &
   Technology Delhi NCR (Ghaziabad); Kalinga Institute of Industrial
   Technology (KIIT); Galgotias University; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (Indian School of
   Mines) Dhanbad
RP Sharma, R (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, NCR Campus, Ghaziabad, India.
EM er.mritunjayrai@gmail.com; rohitapece@gmail.com;
   sureshsatapathy@ieee.org; dileep252000@gmail.com; tanmoy1826@gmail.com
RI Yadav, Dr. Dileep Kumar/AAI-6235-2020; sharma, rohit/AAM-7855-2020; Rai,
   Dr. Mritunjay/C-5116-2018
OI Yadav, Dr. Dileep Kumar/0000-0003-1469-9433; sharma,
   rohit/0000-0002-1600-5039; Rai, Dr. Mritunjay/0000-0002-8911-4826;
   Yadav, Dr Ravindra Kuamr/0000-0003-4628-0688
CR Akula A, 2014, INFRARED PHYS TECHN, V63, P103, DOI 10.1016/j.infrared.2013.12.012
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans T, 2014, Background modeling and foreground detection for video surveillance
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   CUI YY, 2012, RES J APPL SCI ENG T, V4, P2639
   Dong XB, 2014, INFRARED PHYS TECHN, V65, P36, DOI 10.1016/j.infrared.2014.03.007
   FRIEDMAN N, 1997, P 13 C UNC ART INT U
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Hao JY, 2013, IEEE T INTELL TRANSP, V14, P295, DOI 10.1109/TITS.2012.2212432
   Haque Mahfuzul, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P41, DOI 10.1109/AVSS.2008.12
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Huang SC, 2014, IEEE T CYBERNETICS, V44, P114, DOI 10.1109/TCYB.2013.2248057
   Husain AA, 2020, IET IMAGE PROCESS, V14, P1, DOI 10.1049/iet-ipr.2018.5351
   Jung CR, 2009, IEEE T MULTIMEDIA, V11, P571, DOI 10.1109/TMM.2009.2012924
   Kijanka P, 2021, ULTRASONICS, V109, DOI 10.1016/j.ultras.2020.106257
   Kim JY, 2020, IEEE ACCESS, V8, P159864, DOI 10.1109/ACCESS.2020.3020818
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Mandal M, 2021, IEEE T IMAGE PROCESS, V30, P546, DOI 10.1109/TIP.2020.3037472
   Prativadibhayankaram S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070090
   Qiu S, 2019, INFRARED PHYS TECHN, V98, P285, DOI 10.1016/j.infrared.2019.03.022
   Rai M., 2018, J ENG TECHNOL-US, V6, P290
   Rai M, 2016, INT J SIGNAL IMAGING, V9, P165, DOI 10.1504/IJSISE.2016.076226
   Saboo S, 2021, MULTIMED TOOLS APPL, V80, P20579, DOI 10.1007/s11042-021-10669-7
   Sharma L., 2019, Int. J. Spatio-Temporal Data Sci, V1, P22, DOI DOI 10.1504/IJSTDS.2019.097607
   Sharma L, 2016, INFRARED PHYS TECHN, V78, P118, DOI 10.1016/j.infrared.2016.07.012
   Shi DF, 2019, OPT COMMUN, V440, P155, DOI 10.1016/j.optcom.2019.02.006
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Supreeth HSG, 2018, SIGNAL IMAGE VIDEO P, V12, P1097, DOI 10.1007/s11760-018-1259-z
   Tattersall GJ, 2020, J THERM BIOL, V91, DOI 10.1016/j.jtherbio.2020.102611
   Teju V, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920944434
   Tezcan MO, 2021, IEEE ACCESS, V9, P53849, DOI 10.1109/ACCESS.2021.3071163
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xu YP, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2020.164195
   Yadav DK, 2016, INFRARED PHYS TECHN, V76, P21, DOI 10.1016/j.infrared.2015.12.027
   Yadav DK, 2003, 2014 14 INT C HYBRID, V1, P79, DOI 10.1109/HIS.2014.7086176
   Yadav DK., 2015, P 2 INT C COMP COMM, DOI [10.1007/978-81-322-2526-3_25, DOI 10.1007/978-81-322-2526-3_25]
   Zhou H, 2013, COMPUT VIS IMAGE UND, V117, P1589, DOI 10.1016/j.cviu.2013.07.008
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 43
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9289
EP 9311
DI 10.1007/s11042-021-11548-x
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000739790800001
DA 2024-07-18
ER

PT J
AU Bao, N
   Chen, YY
   Liu, Y
   Chakraborty, C
AF Bao, Nan
   Chen, Yueyao
   Liu, Yu
   Chakraborty, Chinmay
TI Multi-objective path planning for lung biopsy surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surgical path planning; Lung biopsy; CT image-guided surgery; Pareto
   optimization
ID CT; OPTIMIZATION; PNEUMOTHORAX; HEMORRHAGE; PLACEMENT; EXISTENCE;
   ABLATION; CANCER; SPACE; RISK
AB CT image-guided lung biopsy surgery is the gold standard for lung tumor diagnosis. The preoperative path planning of the surgery is necessary, which aims to find some optimal needle insertion points on the patient's skin. The traditional path planning method is that the surgeons estimate the puncture paths by observing the patient's CT images, which is highly dependent on the experience of surgeons and affects the success rate of the surgery due to improper path selection. In this work, we proposed an intelligent lung biopsy surgical path planning method, which solved a multi-objective optimization problem. We segmented some chest important organs based on CT images, and quantitatively analyzed multiple clinical criteria. The concept of Pareto optimization was introduced to solve the multi-objective optimization problem in the method. Finally, some optimal surgery paths were provided for the surgeons. The retrospective evaluation of clinical data was performed, which was proved that the proposed method could be accepted in lung biopsy surgery.
C1 [Bao, Nan; Chen, Yueyao; Liu, Yu] Northeastern Univ, Coll Med & Biol Informat Engn, Shenyang 110004, Peoples R China.
   [Chakraborty, Chinmay] Birla Inst Technol Mesra, Dept Elect & Commun Engn, Ranchi 835215, Bihar, India.
C3 Northeastern University - China; Birla Institute of Technology Mesra
RP Bao, N (corresponding author), Northeastern Univ, Coll Med & Biol Informat Engn, Shenyang 110004, Peoples R China.
EM baonan@bmie.neu.edu.cn
RI Chakraborty, Chinmay/N-3608-2017
OI Chakraborty, Chinmay/0000-0002-4385-0975
CR Arnolli MM, 2015, INT J MED ROBOT COMP, V11, P458, DOI 10.1002/rcs.1630
   Baegert C, 2007, COMPUT AIDED SURG, V12, P82, DOI 10.1080/10929080701312000
   Baegert C, 2007, LECT NOTES COMPUT SC, V4792, P676
   BENSON HP, 1978, J OPTIMIZ THEORY APP, V26, P569, DOI 10.1007/BF00933152
   CESARI L, 1978, T AM MATH SOC, V244, P37, DOI 10.2307/1997888
   Chen J., 2021, IEEE SENS J
   Chen JX, 2022, IEEE T IND INFORM, V18, P2000, DOI 10.1109/TII.2021.3088465
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Coello CAC, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.1597059
   Couckuyt I, 2014, J GLOBAL OPTIM, V60, P575, DOI 10.1007/s10898-013-0118-2
   Craven BD., 2005, OPTIMIZATION EC FINA
   DICK R, 1984, BRONCHIAL CARCINOMA, P77
   Fonseca CM, 1995, EVOL COMPUT, V3, P1, DOI 10.1162/evco.1995.3.1.1
   Gao CW, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P617, DOI 10.1109/BMEI.2014.7002848
   Hamze Noura, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P534, DOI 10.1007/978-3-319-46720-7_62
   Hamze N, 2017, IEEE C EVOL COMPUTAT, P1087, DOI 10.1109/CEC.2017.7969428
   Hiraki T, 2010, AM J ROENTGENOL, V194, P809, DOI 10.2214/AJR.09.3224
   Khan MF, 2008, EUR RADIOL, V18, P1356, DOI 10.1007/s00330-008-0893-1
   Laspas F, 2008, J MED IMAG RADIAT ON, V52, P458, DOI 10.1111/j.1440-1673.2008.01990.x
   Li L, 2014, IEEE T EVOLUT COMPUT, V18, P827, DOI 10.1109/TEVC.2013.2287153
   Ma WP, 2006, LECT NOTES ARTIF INT, V4099, P661
   Manhire A, 2003, THORAX, V58, P920, DOI 10.1136/thorax.58.11.920
   Marz Keno, 2013, Information Processing in Computer-Assisted Interventions. Proceedings of 4th International Conference (IPCAI 2013): LNCS 7915, P71, DOI 10.1007/978-3-642-38568-1_8
   McGuire S, 2016, ADV NUTR, V7, P418, DOI 10.3945/an.116.012211
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Schumann C, 2015, INT J COMPUT ASS RAD, V10, P879, DOI 10.1007/s11548-015-1201-6
   Seitel A, 2011, MED PHYS, V38, P3246, DOI 10.1118/1.3590374
   Stoll M, 2012, BIOMED ENG-BIOMED TE, V57, P901, DOI 10.1515/bmt-2012-4279
   Sun Y, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7020148
   Taleb S, 2017, CARDIOVASC INTER RAD, V40, P1415, DOI 10.1007/s00270-017-1632-2
   Wharton EJ, 2008, PROC SPIE, V6812, DOI 10.1117/12.766893
   Yamaura H, 2000, BRIT J RADIOL, V73, P1105, DOI 10.1259/bjr.73.874.11271905
   Yan G., 2016, J PRACT RADIOL, V32, P768
   [郑建国 Zheng Jianguo], 2012, [软件学报, Journal of Software], V23, P2374
NR 35
TC 11
Z9 11
U1 9
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36153
EP 36170
DI 10.1007/s11042-021-11476-w
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000737741900013
DA 2024-07-18
ER

PT J
AU Ch, MMI
   Ghafoor, A
   Bakhshi, AD
   Saghir, NJ
AF Ch, M. Munawwar Iqbal
   Ghafoor, Abdul
   Bakhshi, Asim Dilawar
   Saghir, Nuwayrah Jawaid
TI Medical image fusion using non subsampled contourlet transform and
   iterative joint filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NSCT's samples; Medical image fusion; Box filter; Iterative joint filter
ID GENERAL FRAMEWORK
AB This study proposes an improved medical image fusion scheme based on components of non subsampled contourlet transform (NSCT) and iterative joint filter. Multimodal images are split into approximation and detail components using NSCT. The former are subsequently normalized and further smoothed using box filter. The underlying morphological structure of the smoothened components is obtained with the help of gradient operator using Wiener filter. The filtered structures are then used to compute decision map. Iterative joint filter is finally applied on the decision map along with input guidance image to compute the resultant image. Eight performance metrics as well as qualitative visual evaluation shows the efficacy of the proposed fusion scheme.
C1 [Ch, M. Munawwar Iqbal] Quaid I Azam Univ, Inst Informat Technol, Islamabad, Pakistan.
   [Ghafoor, Abdul; Bakhshi, Asim Dilawar] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Saghir, Nuwayrah Jawaid] Fdn Univ Med Coll, Rawalpindi, Pakistan.
   [Saghir, Nuwayrah Jawaid] Fauji Fdn Hosp, Rawalpindi, Pakistan.
C3 COMSATS University Islamabad (CUI); Quaid I Azam University; National
   University of Sciences & Technology - Pakistan
RP Ch, MMI (corresponding author), Quaid I Azam Univ, Inst Informat Technol, Islamabad, Pakistan.
EM mmic@qau.edu.pk; abdulghafoor-mcs@nust.edu.pk; asim.dilawar@mcs.edu.pk;
   nuwayrah.jawaid@fui.edu.pk
CR Barra V, 2001, NEUROIMAGE, V13, P410, DOI 10.1006/nimg.2000.0707
   Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   CH MMI, 2019, SIGNAL IMAGE VIDEO P, P1
   FATTAL R., 2007, ACM Transactions on Graphics, V26, p95:1
   Gambhir D, 2019, SIGNAL IMAGE VIDEO P, V13, P321, DOI 10.1007/s11760-018-1360-3
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   Hill P., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P487
   Jose J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102480
   Kong WW, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107921
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Langari B, 2016, IEEE T IMAGE PROCESS, V25, P4394, DOI 10.1109/TIP.2016.2590825
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li W, 2018, OPTIK, V172, P1, DOI 10.1016/j.ijleo.2018.06.123
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2014, COMM COM INF SC, V484, P372
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Polinati S, 2020, OPTIK, V205, DOI 10.1016/j.ijleo.2019.163947
   Rajasekhar G, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P246, DOI 10.1109/CSPC.2017.8305847
   Shah P, 2014, SIGNAL IMAGE VIDEO P, V8, P723, DOI 10.1007/s11760-013-0585-4
   Shahdoosti HR, 2018, MULTIMED TOOLS APPL, V77, P22649, DOI 10.1007/s11042-017-5067-1
   Shen R, 2013, IEEE T BIO-MED ENG, V60, P1069, DOI 10.1109/TBME.2012.2211017
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tuba E, 2019, IEEE C EVOL COMPUTAT, P234, DOI [10.1109/cec.2019.8790206, 10.1109/CEC.2019.8790206]
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
NR 34
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4495
EP 4509
DI 10.1007/s11042-021-11753-8
EA DEC 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000729210700001
DA 2024-07-18
ER

PT J
AU Vedantham, R
AF Vedantham, Ramachandran
TI Adaptive increasing-margin adversarial neural iterative system based on
   facial expression recognition feature models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resistive median filter; Advance histogram equalization; Angular Viola
   John; Modified scaling density-based spatial clustering of noise;
   Zernike model; SIFT; Elastic weight constrained based neural network
AB Face expression recognition has been proved as a challenging task in image processing. Many related works on facial expression recognition had done but they faced several challenges during the classification of data with the stored database. It carried out various workflows on improvisation of classifiers based on deep learning but they have been lagging in understanding facial expression mainly because of disastrous forgetting, time management, data mixing, and data overfitting, etc. Ignoring all these challenges would lead to inaccurate recognition of facial expressions. Hence to overcome all the above issues this work proposed a model named adaptive increasing-margin adversarial neural iterative model involves triple threat filtration techniques along with modified scaling density-based spatial clustering of applications with noise and dual feature model for obtaining a better quality featured image. Advance back propagation artificial neural network model is initiated to overcome catastrophic forgetting, underfitting of data, over fitting of data, etc. Thus, the proposed work achieves better efficiency as well as high accuracy in terms of facial expression recognition.
C1 [Vedantham, Ramachandran] Vasireddy Venkatadri Inst Technol, Pedakakani Mandal 522008, Andrapradhesh, India.
RP Vedantham, R (corresponding author), Vasireddy Venkatadri Inst Technol, Pedakakani Mandal 522008, Andrapradhesh, India.
EM vrc.bhatt@vvit.net
RI Vedantham, Ramachandran/GLN-5792-2022; Ramachandran,
   Vedantham/E-7627-2016
OI Ramachandran, Vedantham/0000-0002-3857-8145
CR Aljundi R, 2017, ARXIV PREPRINT ARXIV
   Bah SM, 2020, ARRAY-NY, V5, DOI 10.1016/j.array.2019.100014
   Bi YM, 2016, ANAL CHIM ACTA, V909, P30, DOI 10.1016/j.aca.2016.01.010
   Cai JR, 2019, IEEE I CONF COMP VIS, P3086, DOI 10.1109/ICCV.2019.00318
   Gao T., 2020, INT J SECUR PRIVACY, V12, P17, DOI [10.4018/ijsppc.2020040102, DOI 10.4018/IJSPPC.2020040102]
   Goodrich Ben, 2018, ARXIV180110198
   Gopalakrishnan K, 2018, DATA-BASEL, V3, DOI 10.3390/data3030028
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Khan K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020328
   Kim Yoon, 2017, arXiv preprint, arXiv170200887, P2
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lalitha SD, 2020, ARXIV PREPRINT ARXIV
   Li S, 2020, IEEE TRANSACT AFFECT
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Liu YW, 2017, TRENDS FOOD SCI TECH, V69, P25, DOI 10.1016/j.tifs.2017.08.013
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Maciel JM, 2017, OPT INTERFEROMET, V1
   Mane S., 2019, Data management, analytics and innovation, P275, DOI DOI 10.1007/978-981-13-1402-5_21
   Serra J., 2018, CCIA, P120, DOI 10.3233/978-1-61499-918-8-120
   Timchenko LI, 2017, PROC SPIE, V10445, DOI 10.1117/12.2280976
   Pham TTD, 2019, IEEE ACCESS, V7, P5200, DOI 10.1109/ACCESS.2018.2889852
   Wang Y, 2018, MULTIMED TOOLS APPL, V77, P31447, DOI 10.1007/s11042-018-6198-8
   Wong WK, 2017, IEEE T IMAGE PROCESS, V26, P2905, DOI 10.1109/TIP.2017.2691543
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zenke F, 2018, NEURAL COMPUT, V30, P1514, DOI 10.1162/neco_a_01086
   Zhang CS, 2017, J SYST ENG ELECTRON, V28, P784, DOI 10.21629/JSEE.2017.04.18
NR 30
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3793
EP 3830
DI 10.1007/s11042-021-11320-1
EA NOV 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000721459800001
DA 2024-07-18
ER

PT J
AU Pérez-Núnez, P
   Díez, J
   Luaces, O
   Bahamonde, A
AF Perez-Nunez, Pablo
   Diez, Jorge
   Luaces, Oscar
   Bahamonde, Antonio
TI User encoding for clustering in very sparse recommender systems tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Preference learning; Matrix factorization;
   Clustering; Scalability; User encoding
ID ART
AB Recommender Systems are a very useful tool which let companies and service providers focus in the preferences of their customers, helping them to avoid an overwhelming variety of choices. In this context, clustering tools can play an important role to detect groups of customers with similar tastes. Thus, companies can make personalized marketing campaigns, offering to their users new products which have been consumed by other users with comparable preferences. In this paper we present a general framework to cluster users with respect to their tastes when the registers stored about the interactions between users and products are extremely scarce. Commonly, clustering methods employ the values of features describing the samples to be clustered (users in our case), but such features are not always available. We propose some alternative representations for users, in which their tastes are gathered to some extent, so that clustering algorithms can take advantage and make more homogeneous groups in this regard. To illustrate the performance of the whole framework, we tested it on six popular datasets commonly used as a benchmark for recommender systems, as well as on an extremely sparse real-world dataset that records the preferences of readers to click promoted links in digital publications. In the experimental section we compare our proposed representations to other common user encodings. We show that clustering users attending only to their feature values or to the items they have evaluated gives rise to the worst scores in terms of taste homogeneity.
C1 [Perez-Nunez, Pablo; Diez, Jorge; Luaces, Oscar; Bahamonde, Antonio] Univ Oviedo, Artificial Intelligence Ctr, Gijon 33204, Spain.
C3 University of Oviedo
RP Díez, J (corresponding author), Univ Oviedo, Artificial Intelligence Ctr, Gijon 33204, Spain.
EM pabloperez@uniovi.es; jdiez@uniovi.es; oluaces@uniovi.es;
   abahamonde@uniovi.es
RI Pérez-Núñez, Pablo/ABD-9853-2021; Díez, Jorge/G-7806-2015; Luaces,
   Oscar/C-6009-2018
OI Pérez-Núñez, Pablo/0000-0002-4259-9504; Díez, Jorge/0000-0002-1314-2441;
   Luaces, Oscar/0000-0001-8476-9412
FU Springer Nature; CRUE-CSIC agreement
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ali Z, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113790
   Bahamonde A., 2004, P 21 INT C MACH LEAR, P49
   Boratto L, 2010, STUD COMPUT INTELL, V324, P1
   Bu JJ, 2016, IEEE T KNOWL DATA EN, V28, P2363, DOI 10.1109/TKDE.2016.2566622
   Da'u A, 2020, ARTIF INTELL REV, V53, P2709, DOI 10.1007/s10462-019-09744-1
   Dara S, 2020, J INTELL INF SYST, V54, P271, DOI 10.1007/s10844-018-0542-3
   Fan B, 2009, DECIS SUPPORT SYST, V47, P343, DOI 10.1016/j.dss.2009.03.002
   Fang H, 2020, ACM T INFORM SYST, V39, DOI 10.1145/3426723
   García S, 2008, J MACH LEARN RES, V9, P2677
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   Guo G., 2013, P 23 INT JOINT C ART, P2619, DOI DOI 10.5555/2540128.2540506
   Guo GB, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P540, DOI 10.1109/ASONAM.2014.6921639
   Gupta U, 2015, IEEE INT ADV COMPUT, P1006, DOI 10.1109/IADCC.2015.7154856
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Herbrich R, 1999, IEE CONF PUBL, P97, DOI 10.1049/cp:19991091
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hiziroglu A, 2013, EXPERT SYST APPL, V40, P6491, DOI 10.1016/j.eswa.2013.05.052
   Jiang SH, 2020, IEEE T PATTERN ANAL, V42, P1097, DOI 10.1109/TPAMI.2019.2894137
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Katarya R, 2017, MULTIMED TOOLS APPL, V76, P21481, DOI 10.1007/s11042-016-4078-7
   Kingma D. P., 2014, arXiv
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Liao CL, 2016, ELECTRON COMMER R A, V18, P1, DOI 10.1016/j.elerap.2016.05.001
   Liu JT, 2017, LECT NOTES ELECTR EN, V424, P451, DOI 10.1007/978-981-10-4154-9_52
   Luaces O, 2015, EXPERT SYST APPL, V42, P8588, DOI 10.1016/j.eswa.2015.07.013
   OConnor M, 1999, P ACM SIGIR WORKSH R
   Park YJ, 2013, IEEE T KNOWL DATA EN, V25, P1904, DOI 10.1109/TKDE.2012.119
   Park YJ, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P11
   Lucas JP, 2012, INT J UNCERTAIN FUZZ, V20, P579, DOI 10.1142/S0218488512500274
   Reddy S, 2015, P 31 ICML WORKSH MAC
   Reddy S, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P93, DOI 10.1145/2876034.2893375
   Roy S, 2020, MULTIMED TOOLS APPL, V79, P24119, DOI 10.1007/s11042-020-09126-8
   Sculley D., 2010, P 19 INT C WORLD WID, P1177, DOI DOI 10.1145/1772690.1772862
   Selvi C, 2019, MULTIMED TOOLS APPL, V78, P14303, DOI 10.1007/s11042-018-6790-y
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SongJie Gong, 2010, Journal of Software, V5, P745, DOI 10.4304/jsw.5.7.745-752
   Wu RS, 2011, ELECTRON COMMER R A, V10, P331, DOI 10.1016/j.elerap.2010.11.002
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P73, DOI 10.1145/2835776.2835836
   Xu B., 2012, P 21 INT C WORLD WID, P21
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Ziegler C.-N., 2005, P 14 INT C WORLD WID, P22, DOI [10.1145/1060745.1060754, DOI 10.1145/1060745.1060754]
NR 42
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2467
EP 2488
DI 10.1007/s11042-021-11564-x
EA OCT 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712714400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chaurasia, SK
   Reddy, SRN
AF Chaurasia, Sunita Kumari
   Reddy, S. R. N.
TI State-of-the-art survey on activity recognition and classification using
   smartphones and wearable sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity classification; Activity recognition; Smartphone sensors;
   Wearables
ID FEATURE-SELECTION; ACCELEROMETER DATA; DEPTH CAMERA; SMART HOMES;
   MOBILE; ALGORITHMS; CONTEXT; NETWORKS; BEHAVIOR; FUSION
AB Activity Recognition and Classification (ARC) have enabled growth of many automated applications like recommender services, old age assistance, health monitoring, security and surveillance etc. This becomes possible due to advancement of technology in wearable devices and smartphones. The small size, easy availability of various relevant sensors, ever decreasing cost, ability to monitor continuously and handy to use features have made them prominent devices to use in ARC. In this work, we provide a comprehensive survey on ARC using smartphones and wearable sensors. The work begins with the understanding of the ARC process followed by description of inertial sensors present in the smartphones and wearables. It covers the various feature extraction methods and the models used in traditional methods and the trending deep learning based methods. It is observed that, performance of any ARC method largely depends on number of sensors, classification technique, kind of device and placement and orientation of the device among many other parameters considered in the work. In our study, we present a detailed comparison of work done in this area considering ten such important parameters, which, to the best of our knowledge, is the first of its kind of surveys. Finally, we present ten challenges in this area and provide prospective dimensions that can be explored in future research.
C1 [Chaurasia, Sunita Kumari; Reddy, S. R. N.] Indira Gandhi Delhi Tech Univ Women IGDTUW, Dept Comp Sci & Engn, Delhi 110006, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Chaurasia, SK (corresponding author), Indira Gandhi Delhi Tech Univ Women IGDTUW, Dept Comp Sci & Engn, Delhi 110006, India.
EM sunita.ait@gmail.com
OI Chaurasia, Sunita/0000-0003-4623-3814
CR Agarwal P, 2020, PROCEDIA COMPUT SCI, V167, P2364, DOI 10.1016/j.procs.2020.03.289
   Almaslukh B, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113726
   Almaslukh B, 2017, INT J COMPUT SCI NET, V17, P160
   Alshurafa N, 2014, IEEE J BIOMED HEALTH, V18, P1636, DOI 10.1109/JBHI.2013.2287504
   Analog Devices, 2010, ADXL335 SMALL LOW PO, P16
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   [Anonymous], INT J DISTRIB SENS N
   Archana H.T., 2015, International Journal of Computer Applications, V122, P975, DOI [10.5120/21790-5104, DOI 10.5120/21790-5104]
   Asghari P, 2020, J AMB INTEL HUM COMP, V11, P1141, DOI 10.1007/s12652-019-01380-5
   ATMEL, 2009, 8 BIT AVR MICR ATMEG, P1
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Avilés-Cruz C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071556
   Ayu MA, 2012, PROCEDIA ENGINEER, V41, P224, DOI 10.1016/j.proeng.2012.07.166
   Banos Oresti, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P91, DOI 10.1007/978-3-319-13105-4_14
   Baños O, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1026
   Barnes, 2019, SMART HEAL, V14, DOI 10.1016/j.smhl.2019.100082
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   Bharatula NB, 2008, PERS UBIQUIT COMPUT, V12, P123, DOI 10.1007/s00779-006-0106-3
   Bharti P, 2019, IEEE T MOBILE COMPUT, V18, P857, DOI 10.1109/TMC.2018.2841905
   BHAT G, 2018, ICCAD-IEEE ACM INT
   Buxton B, 2001, INTRO SUPPORT VECTOR, P2
   Casale P, 2011, LECT NOTES COMPUT SC, V6669, P289
   Casale P, 2012, PERS UBIQUIT COMPUT, V16, P563, DOI 10.1007/s00779-011-0415-z
   Chahuara P, 2016, J AMB INTEL SMART EN, V8, P399, DOI 10.3233/AIS-160386
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chathuramali KGM, 2012, INT CONF ADV ICT, P197, DOI 10.1109/ICTer.2012.6421415
   CHAURASIA SK, 2019, INT J ENG ADV TECHNO, V8, P2143, DOI DOI 10.35940/IJEAT.F8575.088619
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Chen T. Y. H., 2015, DESIGNING CONTEXT SE
   Chen YF, 2017, IEEE ACCESS, V5, P3095, DOI 10.1109/ACCESS.2017.2676168
   Chen ZH, 2020, IEEE T INSTRUM MEAS, V69, P3992, DOI 10.1109/TIM.2019.2945467
   Chernbumroong S., 2011, ACTIVITY CLASSIFICAT
   Chernbumroong S, 2013, EXPERT SYST APPL, V40, P1662, DOI 10.1016/j.eswa.2012.09.004
   Chetty G, 2015, PROCEDIA COMPUT SCI, V46, P1181, DOI 10.1016/j.procs.2015.01.031
   Chung S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071716
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Lu DN, 2017, ADV INTELL SYST, V538, P357, DOI 10.1007/978-3-319-49073-1_39
   de Miguel K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122864
   Debes C, 2016, IEEE SIGNAL PROC MAG, V33, P81, DOI 10.1109/MSP.2015.2503881
   Demidova L, 2016, INT J ADV COMPUT SC, V7, P16
   Doewes Afrizal, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P171, DOI 10.1109/ICCE-China.2017.7991050
   Tran DN, 2016, P INT CONF INTELL, P64, DOI 10.1109/ISMS.2016.51
   Fan S., 2019, INF, V10
   Fan XH, 2017, 2017 IEEE 6TH INTERNATIONAL CONFERENCE ON AI & MOBILE SERVICES (AIMS), P54, DOI 10.1109/AIMS.2017.29
   Feng ZT, 2015, IEEE ENG MED BIO, P5074, DOI 10.1109/EMBC.2015.7319532
   Fortin-Simard D, 2015, IEEE INTELL SYST, V30, P7, DOI 10.1109/MIS.2015.18
   Gao L, 2014, MED ENG PHYS, V36, P779, DOI 10.1016/j.medengphy.2014.02.012
   Ghayvat H, 2015, SENSORS-BASEL, V15, P10350, DOI 10.3390/s150510350
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   He ZY, 2009, IEEE SYS MAN CYBERN, P5041, DOI 10.1109/ICSMC.2009.5346042
   Hemminki S., 2013, P 11 ACM C EMB NETW, P1, DOI [10.1145/2517351.2517367, DOI 10.1145/2517351.2517367]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hramov AE, 2018, CHAOS, V28, DOI 10.1063/1.5002892
   Hssina B, 2014, Int J Adv Comput Sci Appl, V4, P13, DOI [10.14569/SpecialIssue.2014.040203, DOI 10.14569/SPECIALISSUE.2014.040203]
   Hsu YL, 2018, IEEE ACCESS, V6, P31715, DOI 10.1109/ACCESS.2018.2839766
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Inoue M, 2018, ARTIF LIFE ROBOT, V23, P173, DOI 10.1007/s10015-017-0422-x
   Jiang M, 2011, PHYSIOL MEAS, V32, P347, DOI 10.1088/0967-3334/32/3/006
   Jordao Artur., 2018, Signal, Image and Video Processing, P1
   Jothi R., 2020, Intelligent Systems Design and Applications. Proceedings of 18th International Conference on Intelligent Systems Design and Applications (ISDA 2018). Advances in Intelligent Systems and Computing (AISC 940), P708, DOI 10.1007/978-3-030-16657-1_66
   Khusainov R, 2013, SENSORS-BASEL, V13, P12852, DOI 10.3390/s131012852
   Krishnan, 2015, WILEY SERIES
   Kropf J, 2017, MACH LEARN KNOW EXTR, V410, P267, DOI [10.1007/978-3-319-66808-6, DOI 10.1007/978-3-319-66808-6]
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lee WP, 2017, KNOWL-BASED SYST, V131, P70, DOI 10.1016/j.knosys.2017.06.002
   Leutheuser H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075196
   Lima WG, 2019, SYNTHETIC COMMUN, V49, P286, DOI 10.1080/00397911.2018.1554146
   LIN ZD, 2019, ACM INT C PROCEEDING, P368
   Lockhart J. W., 2011, P 5 INT WORKSHOP KNO, P25, DOI [DOI 10.1145/2003653.2003656, 10.1145/2003653.2003656]
   Mannini A, 2013, MED SCI SPORT EXER, V45, P2193, DOI 10.1249/MSS.0b013e31829736d6
   Manual R, 2009, BEAGLEBOARD SYSTEM R, P1
   Mathie MJ, 2003, MED BIOL ENG COMPUT, V41, P296, DOI 10.1007/BF02348434
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Mehr HD, 2016, 2016 4TH INTERNATIONAL ISTANBUL SMART GRID CONGRESS AND FAIR (ICSG), P75
   Micucci D, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101101
   Minarno AE, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS'2020), P19, DOI [10.1109/icoias49312.2020.9081858, 10.1109/ICoIAS49312.2020.9081858]
   Moran K, 2015, PROCEDIA ENGINEER, V112, P180, DOI 10.1016/j.proeng.2015.07.196
   Nam Y, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423644
   Nandy A, 2020, MICROSYST TECHNOL, V26, P1889, DOI 10.1007/s00542-019-04738-z
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Ogbuabor G, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P41, DOI 10.1145/3195106.3195157
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Oreski S, 2014, EXPERT SYST APPL, V41, P2052, DOI 10.1016/j.eswa.2013.09.004
   Plötz T, 2018, COMPUTER, V51, P50, DOI 10.1109/MC.2018.2381112
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Prati A, 2019, J AMB INTEL SMART EN, V11, P5, DOI 10.3233/AIS-180510
   Ramasamy Ramamurthy S, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1254
   Reddy, 2018, EAI ENDORSED T PERVA, V4, P1, DOI [10.4108/eai.30-10-2018.160460, DOI 10.4108/EAI.30-10-2018.160460]
   Reddy, 2018, COMP SUST GLOB DEV I
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Sánchez-Maroño N, 2007, LECT NOTES COMPUT SC, V4881, P178
   Sarirete A, 2020, HUMAN ACTIVITY RECOG
   Scherr SA, 2019, EUROMICRO CONF PROC, P169, DOI 10.1109/SEAA.2019.00034
   Shi JH, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3823
   Shoaib M, 2015, SENSORS-BASEL, V15, P2059, DOI 10.3390/s150102059
   Shoaib M, 2014, SENSORS-BASEL, V14, P10146, DOI 10.3390/s140610146
   Shoaib M, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P80, DOI 10.1109/UIC-ATC.2013.43
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Storm FA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118723
   Su X, 2014, TSINGHUA SCI TECHNOL, V19, P235, DOI 10.1109/TST.2014.6838194
   Subasi A, 2018, PROCEDIA COMPUT SCI, V140, P104, DOI 10.1016/j.procs.2018.10.298
   Suto J, 2017, INT J COMPUT COMMUN, V12, P116
   Suto J, 2016, 2016 6TH INTERNATIONAL CONFERENCE ON COMPUTERS COMMUNICATIONS AND CONTROL (ICCCC), P124, DOI 10.1109/ICCCC.2016.7496749
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   Taraldsen K, 2012, MATURITAS, V71, P13, DOI 10.1016/j.maturitas.2011.11.003
   Tsai CF, 2014, APPL SOFT COMPUT, V24, P977, DOI 10.1016/j.asoc.2014.08.047
   Twomey N, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020027
   Ugulino Wallace, 2012, Advances in Artificial Intelligence - SBIA 2012. Proceedings 21th Brazilian Symposium on Artificial Intelligence, P52, DOI 10.1007/978-3-642-34459-6_6
   Vaizman Y, 2017, IEEE PERVAS COMPUT, V16, P62, DOI 10.1109/MPRV.2017.3971131
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Wang JS, 2012, IEEE T IND ELECTRON, V59, P2998, DOI 10.1109/TIE.2011.2167895
   Wang JD, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON CROWD SCIENCE AND ENGINEERING (ICCSE 2018), DOI 10.1145/3265689.3265705
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wannenburg J, 2017, IEEE T SYST MAN CY-S, V47, P3142, DOI 10.1109/TSMC.2016.2562509
   Wu DG, 2016, NEUROCOMPUTING, V190, P35, DOI 10.1016/j.neucom.2015.11.095
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Xu C, 2019, IEEE ACCESS, V7, P9893, DOI 10.1109/ACCESS.2018.2890675
   Xue HF, 2019, PROCEEDINGS OF THE 2019 THE TWENTIETH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '19), P151, DOI 10.1145/3323679.3326513
   Yang A, 2009, WARD: A Wearable Action Recognition Database
   Ye Z, 2018, P ACM INT MOB WEAR U, V2, DOI 10.1145/3214277
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Zdravevski E, 2017, IEEE ACCESS, V5, P5262, DOI 10.1109/ACCESS.2017.2684913
   Zhang M, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1036
   Zhang WT, 2019, IEEE ACCESS, V7, P80027, DOI 10.1109/ACCESS.2019.2922974
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.3978/j.issn.2305-5839.2015.12.38
   Zhu JD, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0097-2
   Zhu QC, 2019, IEEE T IND INFORM, V15, P3821, DOI 10.1109/TII.2018.2889315
   Zhuang ZD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225001
NR 136
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1077
EP 1108
DI 10.1007/s11042-021-11410-0
EA SEP 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698308700002
DA 2024-07-18
ER

PT J
AU Kumari, A
   Tanwar, S
AF Kumari, Aparna
   Tanwar, Sudeep
TI Multiagent-based secure energy management for multimedia grid
   communication using Q-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Demand response management; Residential energy management; Reinforcement
   learning; Artificial intelligence; Q-learning
ID DEMAND RESPONSE; OPTIMIZATION; SYSTEMS; MODEL
AB In smart grid infrastructure, multimedia communication plays an important role in various applications, for instance, load monitoring, automatic smart meter reading, and energy management. Energy management has gained widespread popularity with the increasing energy demand. The goal of this paper is to explore multiagent-based Reinforcement Learning (RL) for multicarrier (i.e., electricity and gas) Residential Energy Management (REM) systems with data security. It facilitates the possibility for a separate Demand Response Program (DRP) for every energy component accelerates with computational aspects of RL. This paper proposes Q-MSEM, a Q-learning-based Multiagent and Secure Energy Management scheme for the optimal solution of REM problems using RL and Ethereum Blockchain (EB) to reduce energy load and decrease energy costs. Then, Q-MSEM uses Ethereum Smart Contract (ESC) to covenants data security issues using off-chain storage, i.e., InterPlanetary File System (IPFS) to handle data storage costs issues. Experimental results disclose the effectiveness of the proposed Q-MSEM scheme in terms of reduction in load, energy cost (15.82%), and data storage cost.
C1 [Kumari, Aparna; Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
EM 17ftphde22@nirmauni.ac.in; sudeep.tanwar@nirmauni.ac.in
RI Tanwar, Sudeep/AAI-6709-2020
OI Tanwar, Sudeep/0000-0002-1776-4651
CR Ahrarinouri M, 2021, IEEE T IND INFORM, V17, P659, DOI 10.1109/TII.2020.2977104
   Al Kawasmi E, 2015, SYSTEMS ENG, V18, P115, DOI 10.1002/sys.21291
   ConsenSys, MYTHR SEC AN TOOL
   Eia, NAT GAS PRIC
   Gutierrez-Martinez VJ, 2019, ENERGIES, V12, DOI 10.3390/en12040671
   Hossein F, 2018, THESIS, P1
   Huang YT, 2018, IEEE T SMART GRID, V9, P252, DOI 10.1109/TSG.2016.2550031
   Jindal A, 2020, IEEE T SERV COMPUT, V13, P613, DOI 10.1109/TSC.2019.2962677
   Kumari A, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100427
   Kumari A, 2020, IEEE NETWORK, V34, P299, DOI 10.1109/MNET.001.1900660
   Kumari A, 2020, IEEE CONF COMPUT, P1051, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162989
   Li ZT, 2018, IEEE T IND INFORM, V14, P3690, DOI 10.1109/TII.2017.2786307
   Lu RZ, 2019, IEEE T SMART GRID, V10, P6629, DOI 10.1109/TSG.2019.2909266
   Lu RZ, 2019, APPL ENERG, V236, P937, DOI 10.1016/j.apenergy.2018.12.061
   Paterakis NG, 2015, IEEE T IND INFORM, V11, P1509, DOI 10.1109/TII.2015.2438534
   Patyn C, 2018, ADAPTIVE LEARNING AG, P1
   Paudyal P, 2019, INT J ELEC POWER, V109, P652, DOI 10.1016/j.ijepes.2019.02.016
   Pezeshki Z, 2019, ARTIF INTELL REV, V52, P495, DOI 10.1007/s10462-018-9630-6
   Rajalakshmi A., 2018, Int J Pure Appl Math, V119, P1437
   Rastegar M, 2015, ELECTR POW SYST RES, V119, P322, DOI 10.1016/j.epsr.2014.10.011
   Remani T, 2019, IEEE SYST J, V13, P3283, DOI 10.1109/JSYST.2018.2855689
   Reynolds J, 2018, ENERGY, V151, P729, DOI 10.1016/j.energy.2018.03.113
   Roustai M, 2018, SUSTAIN CITIES SOC, V39, P309, DOI 10.1016/j.scs.2018.01.045
   Sharifi AH, 2019, SUSTAIN CITIES SOC, V45, P579, DOI 10.1016/j.scs.2018.12.019
   Gazafroudi AS, 2019, INT J ELEC POWER, V112, P404, DOI 10.1016/j.ijepes.2019.05.016
   Wang JX, 2017, APPL ENERG, V202, P772, DOI 10.1016/j.apenergy.2017.05.150
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Xu X, 2020, IEEE T SMART GRID, V11, P3201, DOI 10.1109/TSG.2020.2971427
   Yu M, 2017, APPL ENERG, V203, P267, DOI 10.1016/j.apenergy.2017.06.010
NR 29
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36645
EP 36665
DI 10.1007/s11042-021-11491-x
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000696465800001
DA 2024-07-18
ER

PT J
AU Yamni, M
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Yamni, M.
   Karmouni, H.
   Sayyouri, M.
   Qjidaa, H.
TI Quaternion cartesian fractional hahn moments for color image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion cartesian fractional Hahn moments; Fractional Hahn
   polynomials; Color image descriptors; Image watermarking; Copyright
   protection
ID FOURIER-MELLIN MOMENTS; INVARIANT MOMENTS; FAST COMPUTATION;
   WATERMARKING; RECONSTRUCTION
AB Moment descriptors have been widely used for the analysis and representation of images. In this paper, we propose a new set of discrete orthogonal moments of fractional order, called Quaternion Cartesian Fractional Hahn Moments. The proposed QCFrHMs are based on new Fractional Hahn Polynomials and generalize the classical Quaternion Hahn Moments. First, FrHPs are proposed and defined using eigenvalue decomposition and the spectral representation of the classical Hahn polynomial matrix. Then, the proposed FrHPs are used as a kernel function to define the new Fractional Hahn Moments. Finally, based on quaternion algebra, the FrHMs for grayscale images are generalized to the QCFrHMs for color images. The proposed QCFrHMs depend on four parameters: two polynomial parameters and two fractional orders, which allow us to use them to propose a robust, blind and efficient watermarking scheme for the copyright protection of color images where the requirements of a watermarking scheme are successfully ensured thanks to the performance of the proposed QCFrHMs. Experimental results are provided to illustrate the effectiveness of the proposed color image descriptors.
C1 [Yamni, M.; Karmouni, H.; Qjidaa, H.] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST, Fes, Morocco.
   [Sayyouri, M.] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Syst & Applicat Lab, BP 72,My Abdallah Ave Km 5 Imouzzer Rd, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Sayyouri, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Syst & Applicat Lab, BP 72,My Abdallah Ave Km 5 Imouzzer Rd, Fes, Morocco.
EM mohamed.yamni@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Karmouni, Hicham/ACB-0232-2022; Sayyouri, Mhamed/AAB-5496-2020; Yamni,
   Mohamed/AAD-8740-2022
OI Karmouni, Hicham/0000-0001-9225-8380; Sayyouri,
   Mhamed/0000-0002-1615-419X; Yamni, Mohamed/0000-0002-9436-8361
CR Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Bin TJ, 2008, IMAGE VISION COMPUT, V26, P563, DOI 10.1016/j.imavis.2007.07.003
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   El Ogri O, 2019, PROCEDIA COMPUT SCI, V148, P428, DOI 10.1016/j.procs.2019.01.055
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   Karakasis EG, 2014, IEEE T IMAGE PROCESS, V23, P596, DOI 10.1109/TIP.2013.2289997
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Karmouni H, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov A.F., 1988, Special Functions of Mathematical Physics, DOI 10.1007/978-1-4757-1595-8
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Ping ZL, 2002, J OPT SOC AM A, V19, P1748, DOI 10.1364/JOSAA.19.001748
   Rahmalan Hidayah, 2010, Pattern Recognition and Image Analysis, V20, P505, DOI 10.1134/S1054661810040115
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2013, IEEE CONF IMAGING SY, P101, DOI 10.1109/IST.2013.6729671
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Xiao B, 2020, INFORM SCIENCES, V516, P545, DOI 10.1016/j.ins.2019.12.044
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Yamni M, 2021, CIRC SYST SIGNAL PR, V40, P6193, DOI 10.1007/s00034-021-01763-0
   Yamni M, 2021, J FRANKLIN I, V358, P2535, DOI 10.1016/j.jfranklin.2021.01.011
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yamni M., 2020, 2020 INT C INT SYST, P1, DOI [10.1109/ISCV49265.2020.9204169, DOI 10.1109/ISCV49265.2020.9204169]
   Yang B, 2012, PATTERN RECOGN, V45, P1602, DOI 10.1016/j.patcog.2011.10.025
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang HQ, 2016, COMM COM INF SC, V662, P766, DOI 10.1007/978-981-10-3002-4_62
   Zhang Li, 2007, Journal of Software, V18, P2283, DOI 10.1360/jos182283
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 47
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 737
EP 758
DI 10.1007/s11042-021-11432-8
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696465800005
DA 2024-07-18
ER

PT J
AU Wang, PY
   Zhang, JM
   Zhu, HQ
AF Wang, Pengyu
   Zhang, Jianmei
   Zhu, Hongqing
TI Fire detection in video surveillance using superpixel-based region
   proposal and ESE-ShuffleNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forest fire detection; Cauchy mixture model; Superpixel; Light-weight
   network; ShuffleNet
ID CONVOLUTIONAL NEURAL-NETWORKS; COLOR; MODEL
AB This paper proposes a forest fire detection framework using superpixel-based suspicious fire region proposal and light-weight convolutional neural network. The proposed methodology contains two main steps. In suspicious fire region proposal, we introduce a novel superpixel algorithm (SCMM) driven by Cauchy mixture model. Then, the negative Under-segmentation Error (UE) of each superpixel is applied to inter-frame comparison for predicting varying superpixels. After that, by computing the features of motion superpixels using Local Difference Binary (LDB) descriptor for two adjacent frames, the suspicious fire regions are localized. In following fire identification, to improve network performance while reducing computational complexity, this study presents a light-weight network architecture, called Expanded Squeeze-and-Excitation ShuffleNet (ESE-ShuffleNet). All suspicious fire regions are sent into this network to identify as either fire or non-fire included. Experiments show that our framework performs well on fire detection tasks. Code is available at http://www.imagetech-polynomials.com/ESE-Shuff.leNet.html.
C1 [Wang, Pengyu; Zhang, Jianmei; Zhu, Hongqing] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
C3 East China University of Science & Technology
RP Zhu, HQ (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
EM hqzhu@ecust.edu.cn
OI Zhu, Hongqing/0000-0002-2122-7066; WANG, Pengyu/0000-0003-0997-9887
FU National Nature Science Foundation of China [61872143]
FX This work was supported by the National Nature Science Foundation of
   China under Grant 61872143.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   Barmpoutis P, 2019, INT CONF ACOUST SPEE, P8301, DOI [10.1109/ICASSP.2019.8682647, 10.1109/icassp.2019.8682647]
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Dunnings Andrew J., 2018, 2018 25th IEEE International Conference on Image Processing (ICIP), P1558, DOI 10.1109/ICIP.2018.8451657
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Ganesh Samarth C. A., 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P653, DOI 10.1109/ICMLA.2019.00119
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hashemzadeh M, 2019, EXPERT SYST APPL, V130, P60, DOI 10.1016/j.eswa.2019.04.019
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HY, 2020, I COMP CONF WAVELET, P109, DOI 10.1109/ICCWAMTIP51612.2020.9317360
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuczma M., 2009, INTRO THEORY FUNCTIO
   Li P, 2020, CASE STUD THERM ENG, V19, DOI 10.1016/j.csite.2020.100625
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Machairas V, 2015, IEEE T IMAGE PROCESS, V24, P3707, DOI 10.1109/TIP.2015.2451011
   Matukhina O, 2020, P INT MULTICONF IND, P1
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P16201, DOI 10.1007/s11042-019-7548-x
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Saponara S, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P392, DOI 10.1109/SMARTCOMP50058.2020.00083
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Xiao XL, 2018, IEEE T IMAGE PROCESS, V27, P2883, DOI 10.1109/TIP.2018.2810541
   Xie XL, 2019, MULTIMED TOOLS APPL, V78, P12353, DOI 10.1007/s11042-018-6774-y
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang X, 2012, INT SYM MIX AUGMENT, P49, DOI 10.1109/ISMAR.2012.6402537
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XB, 2020, CHIN AUTOM CONGR, P3080, DOI 10.1109/CAC51589.2020.9327309
NR 45
TC 10
Z9 10
U1 5
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13045
EP 13072
DI 10.1007/s11042-021-11261-9
EA SEP 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000695537100004
DA 2024-07-18
ER

PT J
AU Wang, Y
   Ma, Y
   Huang, H
AF Wang, Yan
   Ma, Yan
   Huang, Hui
TI A neighborhood-based three-stage hierarchical clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity measure; 1-nearest neighbor; Shared nearest neighbors;
   Intercluster distance; Outlier detection; Hierarchical clustering
ID DENSITY; CONSTRUCTION; DISTANCE; SEARCH; NOISY; TREE
AB Many neighborhood-based clustering algorithms have been proposed to measure the similarity between data points or subclusters with their neighborhood information. However, most of them are vulnerable to the different cluster sizes, shapes and densities. In this paper, we propose a neighborhood-based three-stage hierarchical clustering algorithm (NTHC) which is robust to the difference. Three concepts, i.e., the stability of data point pair, the linked representatives, and the expanded representatives, are defined. Furthermore, a new measure of intercluster distance based on representatives is designed. In Stage 1, the outliers are detected and removed from the data set using reverse nearest neighbors. In Stage 2, small clusters are formed by merging the data points with stable connection on 1-nearest neighbor graph. In Stage 3, the final partitions are obtained by iteratively merging the closest pair of clusters based on the new measure of intercluster distance. Tests are carried out to compare the proposal with 15 other clustering algorithms. The experimental results on synthetic and real data sets demonstrate the proposed method is effective. In addition, we test the statistically significant differences among the sixteen clustering algorithms using the Friedman test. And the average rank value of the proposed algorithm is 4.19, which is superior to the other algorithms.
C1 [Wang, Yan; Ma, Yan; Huang, Hui] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Normal University
RP Ma, Y (corresponding author), Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
EM yian1585@163.com; ma-yan@shnu.edu.cn; Huanghui@shnu.edu.cn
RI wang, jiaqi/JSL-7112-2023
OI , Yan/0000-0003-4626-1401
FU National Natural Science Foundation of China [61373004, 61501297]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant no. 61373004, 61501297).
CR Abbas M, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107589
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Asuncion A., 2007, Uci machine learning repository
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   Blömer J, 2016, LECT NOTES COMPUT SC, V9220, P81, DOI 10.1007/978-3-319-49487-6_3
   Bouguettaya A, 2015, EXPERT SYST APPL, V42, P2785, DOI 10.1016/j.eswa.2014.09.054
   Bryant A, 2018, IEEE T KNOWL DATA EN, V30, P1109, DOI 10.1109/TKDE.2017.2787640
   Cassisi C, 2013, INFORM SYST, V38, P317, DOI 10.1016/j.is.2012.09.001
   Chang H, 2008, PATTERN RECOGN, V41, P191, DOI 10.1016/j.patcog.2007.04.010
   Chen YW, 2019, INFORM SCIENCES, V472, P145, DOI 10.1016/j.ins.2018.09.012
   Chowdhary C. L., 2017, NATURE INSPIRED COMP, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Dahal S., 2015, Effect of different distance measures in result of cluster analysis
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Ding SF, 2019, KNOWL-BASED SYST, V164, P371, DOI 10.1016/j.knosys.2018.11.007
   Ding SF, 2018, SOFT COMPUT, V22, P4573, DOI 10.1007/s00500-017-2640-5
   Dolatshah M, 2015, COMPUTER SCI
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Dong S, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114885
   Dong S, 2018, J INF PROCESS SYST, V14, P727, DOI 10.3745/JIPS.04.0076
   Dong S, 2013, IETE J RES, V59, P326, DOI 10.4103/0377-2063.118021
   Du MJ, 2016, KNOWL-BASED SYST, V99, P135, DOI 10.1016/j.knosys.2016.02.001
   Ertöz L, 2003, SIAM PROC S, P47
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan JC, 2020, INT J MACH LEARN CYB, V11, P1179, DOI 10.1007/s13042-019-01031-3
   Fränti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227
   GOWDA KC, 1978, PATTERN RECOGN, V10, P105
   Güngör E, 2017, EXPERT SYST APPL, V69, P10, DOI 10.1016/j.eswa.2016.10.022
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Inkaya T, 2015, EXPERT SYST APPL, V42, P9489, DOI 10.1016/j.eswa.2015.07.074
   Inkaya T, 2015, PATTERN RECOGN LETT, V52, P17, DOI 10.1016/j.patrec.2014.09.007
   JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640
   Jeon Y, 2017, IEEE ACCESS, V5, P5594, DOI 10.1109/ACCESS.2017.2690987
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Lai JZC, 2011, INFORM SCIENCES, V181, P1722, DOI 10.1016/j.ins.2011.01.011
   Li H, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107206
   Li J, 2020, J INF PROCESS SYST, V16, P718, DOI 10.3745/JIPS.04.0174
   Li XJ, 2020, IEEE T CYBERNETICS, V50, P2302, DOI 10.1109/TCYB.2018.2876615
   Liu R, 2018, INFORM SCIENCES, V450, P200, DOI 10.1016/j.ins.2018.03.031
   Liu YH, 2017, KNOWL-BASED SYST, V133, P208, DOI 10.1016/j.knosys.2017.07.010
   Lv XB, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/8451796
   Lv Y, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122014
   Lv YH, 2016, NEUROCOMPUTING, V171, P9, DOI 10.1016/j.neucom.2015.05.109
   Ma Y, 2021, INFORM SCIENCES, V557, P194, DOI 10.1016/j.ins.2020.12.016
   Maier M, 2009, THEOR COMPUT SCI, V410, P1749, DOI 10.1016/j.tcs.2009.01.009
   Murtagh F, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1219
   Qin YK, 2018, PATTERN RECOGN, V74, P1, DOI 10.1016/j.patcog.2017.09.008
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Ros F, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106220
   Ros F, 2019, INFORM SCIENCES, V486, P148, DOI 10.1016/j.ins.2019.02.051
   Sarfraz MS, 2019, PROC CVPR IEEE, P8926, DOI 10.1109/CVPR.2019.00914
   Vadapalli S, 2006, IEEE DATA MINING, P1108
   Xie WB, 2020, INFORM SCIENCES, V527, P279, DOI 10.1016/j.ins.2020.04.016
   Yang J, 2017, NEURAL COMPUT, V29, P3094, DOI [10.1162/neco_a_01014, 10.1162/NECO_a_01014]
   Ye HM, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P37, DOI 10.1109/ITNEC.2016.7560314
   Yu MC, 2015, CHAOS, V25, DOI 10.1063/1.4908014
   Zhong CM, 2011, INFORM SCIENCES, V181, P3397, DOI 10.1016/j.ins.2011.04.013
   Zhong CM, 2010, PATTERN RECOGN, V43, P752, DOI 10.1016/j.patcog.2009.07.010
   Zhou Q., 2018, Advances in Transportation Studies, V3, P101
NR 64
TC 5
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32379
EP 32407
DI 10.1007/s11042-021-11171-w
EA JUL 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678480200001
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
   Singh, A
AF Bhardwaj, Rupali
   Singh, Anjali
TI An efficient reversible and secure patient data hiding algorithm for
   E-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Privacy Protection; Homomorphic
   encryption; Electronic patient information (EPI)
ID HIGH-CAPACITY; ENCRYPTED IMAGES; DIFFERENCE; SIGNALS
AB E-healthcare requires communication of patient report to a specialized doctor in a real time scenario. Therefore, any harm to patient medical data can lead to a faulty diagnosis that can be lethal for the patient. To ensure safe and secure communication in E-healthcare framework, an efficient reversible data hiding algorithm in encrypted domain has been proposed in this paper. The proposed algorithm gives a higher embedding rate by embedding a single bit of patient data in base(2) numeral framework at every pixel of the cover image without any occurrence of underflow and overflow problem. The proposed method has been evaluated for content authentication by subjecting it to various image processing attacks. The experimental study reveals that for test images, proposed method has higher embedding rate than the compared methods, precisely recover patient information with an average value of Peak Signal Noise Ratio value of 48.13 dB between the cover image and stego image respectively. A comparison of the observed results with that of some state-of-art methods shows that proposed method performs better and as such is an ideal candidate for content authentication of Electronic patient information in a typical E-healthcare framework.
C1 [Bhardwaj, Rupali; Singh, Anjali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao B, 2010, IEEE ICC
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 26
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31687
EP 31703
DI 10.1007/s11042-021-10892-2
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000003
DA 2024-07-18
ER

PT J
AU Majidpourkhoei, R
   Alilou, M
   Majidzadeh, K
   Babazadehsangar, A
AF Majidpourkhoei, Reza
   Alilou, Mehdi
   Majidzadeh, Kambiz
   Babazadehsangar, Amin
TI A novel deep learning framework for lung nodule detection in 3d CT
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis system; Convolution neural network; Deep
   learning; Lung nodules
ID COMPUTER-AIDED DETECTION; CONVOLUTIONAL NEURAL-NETWORKS; FALSE-POSITIVE
   REDUCTION; PULMONARY NODULES; AUTOMATIC DETECTION; CLASSIFICATION;
   SYSTEM; SEGMENTATION; CNNS
AB Lung cancer is one of the deadliest cancers all over the world. One of the indications of lung cancers is the presence of the lung nodules which can appear individually or attached to the lung walls. The early detection of these nodules is crucial for saving the patient's lives. Machine learning and image processing techniques, generally embedded in computer-aided diagnosis (CAD) systems, might help radiologists locate and assess the risk of these nodules. Accordingly, in this paper, we present a framework for identifying pulmonary nodules in lung CT images and a convolutional neural network (CNN) approach to automatically extract the features from lung images, followed by classifying the suspicious regions as either nodule or non-nodule objects. The proposed model is based on Le-Net architectural stylization and the light model is obtained after going through the innovative steps. A subset of LIDC public dataset including N = 7072 CT slices of varying nodule sizes (1 mm to 5 mm) is used to train and validate this approach. The proposed framework carries out all stages of lung segmentation as well as diagnosis and categorization of the existing nodules automatically. Training and validation steps of this network with configurations 2.4GHz Core i5 processor, 8GB memory, and Intel Graphics 520 are performed approximately in six hours and this system yields the performance with accuracy = 90.1%, sensitivity = 84.1%, specificity =91.7%, for identifying the nodules. Compared to other famous CNN architectures, the proposed model is agile (light and fast) and has appropriate performance, thereby is suitable for real-time medical image analysis.
C1 [Majidpourkhoei, Reza; Alilou, Mehdi; Majidzadeh, Kambiz; Babazadehsangar, Amin] Islamic Azad Univ, Urmia Branch, Dept Comp Engn, Orumiyeh, Iran.
C3 Islamic Azad University
RP Alilou, M (corresponding author), Islamic Azad Univ, Urmia Branch, Dept Comp Engn, Orumiyeh, Iran.
EM rmajidpour@yahoo.com; me.alilou@gmail.com; K.Majidzadeh@iaurmia.ac.ir;
   bsamin2@liveutm.onmicrosoft.com
RI Babazadeh Sangar, Amin/JSL-7858-2023; Babazadeh Sangar,
   Amin/AGV-0118-2022; Babazadeh Sangar, Amin/F-7753-2017
OI Babazadeh Sangar, Amin/0000-0002-5190-8460; Babazadeh Sangar,
   Amin/0000-0002-5190-8460; majidpourkhoei, reza/0000-0002-4749-4146
CR Affonso C, 2015, EXPERT SYST APPL, V42, P9482, DOI 10.1016/j.eswa.2015.07.075
   Alakwaa W, 2017, INT J ADV COMPUT SC, V8, P409
   Alam M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P23, DOI [10.1109/CSCI.2016.0012, 10.1109/CSCI.2016.11]
   Alilou M, 2014, IMAGE ANAL STEREOL, V33, P13, DOI 10.5566/ias.v33.p13-27
   American Cancer Society, 2020, Key statistics for lung cancer
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   [Anonymous], 2018, LUNG NODULE DETECTIO
   [Anonymous], 2016, 22 AM C INF SYST SAN
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Bengio Yoshua, 2012, P ICML WORKSH UNS TR, P17
   Cao JL, 2019, PROC CVPR IEEE, P7384, DOI 10.1109/CVPR.2019.00757
   de Carvalho AO, 2018, PATTERN RECOGN, V81, P200, DOI 10.1016/j.patcog.2018.03.032
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   de Oliveira JEE, 2011, WORLD J RADIOL, V3, P24, DOI 10.4329/wjr.v3.i1.24
   Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035
   Froz BR, 2017, EXPERT SYST APPL, V69, P176, DOI 10.1016/j.eswa.2016.10.039
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Hassanpour H, 2011, IMAGE SEGMENTATION, DOI [10.5772/15941, DOI 10.5772/15941]
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hossain MS, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/858712
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jacobs C, 2016, EUR RADIOL, V26, P2139, DOI 10.1007/s00330-015-4030-7
   Khordehchi EA, 2017, IMAGE ANAL STEREOL, V36, P65, DOI 10.5566/ias.1679
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683
   Liang MZ, 2016, RADIOLOGY, V281, P279, DOI 10.1148/radiol.2016150063
   Monkam P, 2019, IEEE ACCESS, V7, P78075, DOI 10.1109/ACCESS.2019.2920980
   Nithila EE, 2017, ENG SCI TECHNOL, V20, P1192, DOI 10.1016/j.jestch.2016.12.006
   Orozco HM, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0003-y
   Oudkerk M, 2017, LANCET ONCOL, V18, pE754, DOI [10.1016/s1470-2045(17)30861-6, 10.1016/S1470-2045(17)30861-6]
   Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595
   Qian W, 2007, ACAD RADIOL, V14, P530, DOI 10.1016/j.acra.2007.01.012
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Severyn Aliaksei., 2015, P 9 INTERNATIONALWOR, P464, DOI DOI 10.18653/V1/S15
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Silveira M, 2007, P ANN INT IEEE EMBS, P4414, DOI 10.1109/IEMBS.2007.4353317
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Song QZ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8314740
   Sun WQ, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216329
   Sun WQ, 2016, COMPUT METH PROG BIO, V135, P77, DOI 10.1016/j.cmpb.2016.07.017
   Sun WQ, 2015, MED PHYS, V42, P2853, DOI 10.1118/1.4919772
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Wang B, 2018, LECT NOTES COMPUT SC, V11071, P759, DOI 10.1007/978-3-030-00934-2_84
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang YZ, 2017, COMPUT METH PROG BIO, V144, P97, DOI 10.1016/j.cmpb.2017.03.017
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Zhang JJ, 2018, NEUROCOMPUTING, V317, P159, DOI 10.1016/j.neucom.2018.08.022
NR 61
TC 14
Z9 15
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30539
EP 30555
DI 10.1007/s11042-021-11066-w
EA JUN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000660815700002
DA 2024-07-18
ER

PT J
AU Liu, CX
   Pang, MY
AF Liu, Caixia
   Pang, Mingyong
TI One-dimensional image surface blur algorithm based on wavelet transform
   and bilateral filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface blur; Wavelet transform; Bilateral filtering; Local variance
AB Image noises are usually generated in the processes of collection, transmission, and storage of images, while some noises, named internal noises, come from the image itself. The noises decrease image visual effect and quality. Thus, it is very important to remove the noises from the images. In this paper, we propose a one-dimensional surface blur algorithm based on wavelet transform and bilateral filtering for image internal noise elimination and detail preservation. In our algorithm, we first transform the two-dimensional image into one-dimensional signal vectors by merging the pixels in each row and column of the image. Then, we decompose each of the vectors into two parts: the low-frequency and high-frequency components with a discrete wavelet transform. We further perform the bilateral filtering and a local variance-based thresholding method on the two components to smooth and denoise signals, respectively. Finally, we evaluate our algorithm's performance in a group of face images. The experimental results show that our algorithm achieved better performance on image denoising and detail preservation than a set of traditional smoothing methods and the state-of-the-art. Our algorithm is a simple, effective, and easy-to-implement method, and it is suitable for image smoothing to improve the image's visual effect and quality.
C1 [Liu, Caixia; Pang, Mingyong] Nanjing Normal Univ, Inst EduInfo Sci & Engn, Nanjing, Peoples R China.
   [Liu, Caixia] Zaozhuang Univ, Dept Informat Sci & Engn, Zaozhuang, Shandong, Peoples R China.
C3 Nanjing Normal University; Zaozhuang University
RP Pang, MY (corresponding author), Nanjing Normal Univ, Inst EduInfo Sci & Engn, Nanjing, Peoples R China.
EM cxsqz@126.com; panion@netease.com
FU National Natural Science Foundation of China [62007028, 41631175,
   61702068]; Key Project of Ministry of Education for the 13th 5-years
   Plan of National Education Science of China [DCA170302]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   [1643320H111]
FX The work was supported by grants from the National Natural Science
   Foundation of China [No.62007028, 41631175, 61702068], the Key Project
   of Ministry of Education for the 13th 5-years Plan of National Education
   Science of China [No.DCA170302], and the Priority Academic Program
   Development of Jiangsu Higher Education Institutions [No.1643320H111].
CR Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chaudhury KN, 2016, IEEE T IMAGE PROCESS, V25, P2519, DOI 10.1109/TIP.2016.2548363
   Chaudhury KN, 2011, IEEE T IMAGE PROCESS, V20, P3376, DOI 10.1109/TIP.2011.2159234
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Hou YK, 2020, IEEE T IMAGE PROCESS, V29, P5121, DOI 10.1109/TIP.2020.2980116
   Ichikawa K, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103353
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu Jin, 2010, Electric Welding Machine, V40, P77
   Liu W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3388887
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pham TQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P454, DOI 10.1109/ICME.2005.1521458
   Singh K, 2020, MOB NETW APPL, V25, P1
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   Xia T, 2017, P 79 EAGE C EXH, V1, P1
   Xu J., 2018, ECCV, P20
   Yao S, 2006, CHINA SCI TECHNOLOGY, V16, P286
   Yu SY, 2019, PROCEEDINGS OF 6TH IEEE/ACM ANNUAL INTERNATIONAL WORKSHOP ON INNOVATING THE NETWORK FOR DATA-INTENSIVE SCIENCE (INDIS) 2019, P1, DOI 10.1109/INDIS49552.2019.00006
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhou F, 2013, THESIS BEIJING I GRA
NR 27
TC 2
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28697
EP 28711
DI 10.1007/s11042-021-10754-x
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659401100001
DA 2024-07-18
ER

PT J
AU Sudhamani, C
AF Sudhamani, Chilakala
TI Detection probability maximization through optimization of samples in
   cognitive radio networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio; Energy detection method; Cooperative spectrum sensing;
   Optimization; Number of samples
AB Cognitive radio technology is widely used to identify the underutilized spectrum bands through spectrum sensing. In this paper, energy detection method is used to detect the primary user's presence by increasing the number of samples. It increases the overall detection performance but effects the system overhead through long time estimation of total energy. Therefore optimization of samples is proposed to limit the number of samples and to reduce the system over head by maximizing the detection performance. This increases the detection performance for a given false alarm and reduces the number of samples compared to conventional method. Cooperative detection probability for AND, OR and MAJORITY fusion rules is estimated and the optimal number of samples for each method is identified. The simulation and numerical results show a notable improvement in the detection probability.
C1 [Sudhamani, Chilakala] Dept ECE, CMR Tech Campus, Hyderabad 501401, Telangana, India.
RP Sudhamani, C (corresponding author), Dept ECE, CMR Tech Campus, Hyderabad 501401, Telangana, India.
EM sudhamani.ece@cmrtc.ac.in
RI chilakala, sudhamani/AAE-3684-2020
CR Althunibat S, 2014, IEEE INT WORKSH COMP, P234, DOI 10.1109/CAMAD.2014.7033241
   Althunibat S, 2014, IEEE COMMUN LETT, V18, P1291, DOI 10.1109/LCOMM.2014.2329844
   [Anonymous], 2006, IEEE ICC
   Cabric D, 2004, CONF REC ASILOMAR C, P772, DOI 10.1109/acssc.2004.1399240
   Debnath S., 2020, ENG REP WILEY ONLINE, V2, P1
   Ganesan G, 2005, 2005 1st IEEE International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Conference Record, P137
   Lee CH, 2008, CONSUM COMM NETWORK, P968, DOI 10.1109/ccnc08.2007.223
   Liang YC, 2011, IEEE T VEH TECHNOL, V60, P3386, DOI 10.1109/TVT.2011.2158673
   Maleki S, 2011, IEEE SENS J, V11, P565, DOI 10.1109/JSEN.2010.2051327
   Mili MR, 2016, IEEE T COMMUN, V64, P1829, DOI 10.1109/TCOMM.2016.2535371
   Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210
   Peh ECY, 2011, GLOB TELECOMM CONF
   Salahdine F, 2017, IEEE ANN COMP COMM W, DOI 10.1109/CCWC.2017.7868352
   SUDHAMANI C, 2018, ENG SCI TECHNOL, V21, P815
   Sudhamani C, 2019, WIRELESS PERS COMMUN, V104, P907, DOI 10.1007/s11277-018-6059-9
   Tripathi P, 2013, IEEE INT C WIR COMM, P1
   Verma P, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P232, DOI 10.1109/SPIN.2015.7095276
   Wei J., 2010, INFOCOM IEEE C COMPU, P1
   Xiong C, 2011, IEEE T WIREL COMMUN, V10, P3874, DOI 10.1109/TWC.2011.091411.110249
   Zhang W, 2008, IEEE T WIREL COMMUN, V7, P4761, DOI 10.1109/T-WC.2008.060857
   Zhao N, 2012, IEEE GLOB COMM CONF, P3600, DOI 10.1109/GLOCOM.2012.6503674
NR 21
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12275
EP 12285
DI 10.1007/s11042-021-11089-3
EA JUN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000658077800005
DA 2024-07-18
ER

PT J
AU Doukianou, S
   Daylamani-Zad, D
   O'Loingsigh, K
AF Doukianou, Stella
   Daylamani-Zad, Damon
   O'Loingsigh, Kathy
TI Implementing an augmented reality and animated infographics application
   for presentations: effect on audience engagement and efficacy of
   communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed; augmented reality; Business presentation; Empirical studies in
   visualization; Usability testing; Human computer interaction (HCI)
ID VISUALIZATION; CLASSROOM; INFORMATION; BEHAVIOR; VIDEO; MAPS
AB Presentations are the most successful and popular form of communication in business. However, the formats of presentations in business have not changed much for past few decades. The emergent and disruptive technologies such as Augmented Reality and Animated Infographics have provided potential for enhancing communications in businesses to increase engagement and therefore increasing the effectiveness of such communications. This paper focuses on the impact and effectiveness of using interactive AR in business presentations. The paper presents the design and development of our AR presentation application. Followed by a presentation of an empirical study into the usability and effectiveness of using Augmented Reality and Animated Infographics in business presentation and compares the results against the traditional slideware slides presentation approach. The results of the experiment with 94 participants are presented and analysed. The results demonstrate that the AR approach out performs the traditional methods in terms of usability, audience engagement and effectiveness of communication.
C1 [Doukianou, Stella; O'Loingsigh, Kathy] Univ Greenwich, Sch Comp & Math Sci, London, England.
   [Daylamani-Zad, Damon] Brunel Univ London, Coll Engn Design & Phys Sci, London UB8 3PH, England.
C3 University of Greenwich; Brunel University
RP Daylamani-Zad, D (corresponding author), Brunel Univ London, Coll Engn Design & Phys Sci, London UB8 3PH, England.
EM S.Doukianou@greenwich.ac.uk; Damon.Daylamani-Zad@brunel.ac.uk
RI Daylamani-Zad, Damon/JXM-8824-2024; Askamp, Leonie/GYU-0316-2022
OI Daylamani-Zad, Damon/0000-0001-7849-458X; 
CR Aleokhina A, 2017, INT ED SOC SCI HUM R, P294
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Angelini M, 2019, COMPUT GRAPH FORUM, V38, P237, DOI 10.1111/cgf.13685
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Barreiros C, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P72, DOI [10.1109/ISMAR-Adjunct.2016.0043, 10.1109/ISMAR-Adjunct.2016.36]
   Bateman John A., 2017, Multimodality: Foundations, Research and Analysis: A Problem-Oriented Introduction
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Berliner D.C., 1990, The nature of time in schools: Theoretical concepts, practitioner perceptions, P3
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   BRESLOW N, 1970, BIOMETRIKA, V57, P579, DOI 10.1093/biomet/57.3.579
   Brill J.M., 2008, INT J TEACHING LEARN, V20, P70
   Brophy JE, 1982, J EDUC PSYCHOL
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   Chiu CC, 2016, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS FOR SCIENCE AND ENGINEERING (IEEE-ICAMSE 2016), P181, DOI 10.1109/ICAMSE.2016.7840274
   Cohen MF, 2008, US Patent, Patent No. [7,383,495, 7383495]
   Dewey J., 1913, INTEREST EFFORT ED
   Dey A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P49, DOI [10.1109/ISMAR-Adjunct.2016.0036, 10.1109/ISMAR-Adjunct.2016.29]
   Doukianou S, 2019, 41 ANN C COGN SCI SO, P1662
   Edmonds S, 2018, E LEARN WORLD C E LE, P807
   Eppler MartinJ., 2004, Knowledge visualization: towards a new discipline and its fields of application
   Fay MP, 2010, STAT SURV, V4, P1, DOI 10.1214/09-SS051
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Fulda, 2018, DIGITAL INVESTIGATIV, P123
   Gabbard JL, 2005, P IEEE VIRT REAL ANN, P11
   Gallardo C, 2018, LECT NOTES COMPUT SC, V10850, P351, DOI 10.1007/978-3-319-95270-3_29
   Gehman, 2003, COLUMBIA ACCIDENT IN, V6
   Good Lance., 2001, CounterPoint: Creating jazzy interactive presentations
   Good LE, 2010, US PATENT
   Gribok, 2015, VIDEO INFOGRAPHICS S
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Ivanov A, 2019, IEEE COMPUT GRAPH, V39, P19, DOI 10.1109/MCG.2019.2898941
   Ivson P, 2018, IEEE T VIS COMPUT GR, V24, P687, DOI 10.1109/TVCG.2017.2745105
   Kernbach S, 2010, IEEE INT CONF INF VI, P349, DOI 10.1109/IV.2010.55
   Khan M., 2011, INT J COMPUTER APPL, V34, P1, DOI DOI 10.5120/4061-5722
   Khan-Panni, 2012, FT ESSENTIAL GUIDE M
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kosslyn SM, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00230
   Lengler R, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P585, DOI 10.1109/IV.2009.102
   LENTZ FE, 1988, SCHOOL PSYCHOL REV, V17, P243
   Lewis C., 1993, TASK CENTERED USER I
   Lewis JR, 2002, INT J HUM-COMPUT INT, V14, P463, DOI 10.1080/10447318.2002.9669130
   Liarokapis F., 2010, P EUROGRAPHICS, P9, DOI [10.2312/eged.20101010, DOI 10.2312/EGED.20101010]
   Liarokapis F., 2004, World Transactions on Engineering and Technology Education, V3, P11
   Lievemaa J, 2017, THESIS TAMPERE U APP
   Lipkus I M, 1999, J Natl Cancer Inst Monogr, P149
   Locoro A, 2017, COMPUT HUM BEHAV, V71, P240, DOI 10.1016/j.chb.2017.01.032
   Lyra KT, 2016, IEEE INT CONF ADV LE, P366, DOI 10.1109/ICALT.2016.83
   Mackinlay J. D., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P173, DOI 10.1145/108844.108870
   McMahon B., 2004, LEADERSH POLICY SCH, V3, P59
   Mecham C., 2019, INDEPENDENCE, V44, P38
   MEECE JL, 1988, J EDUC PSYCHOL, V80, P514, DOI 10.1037/0022-0663.80.4.514
   Meeusah N, 2013, EFFECT DATA SET HUE
   Meiguins B., 2006, Proceedings of the 2006 ACM international conference on Virtual reality continuum and its applications, P391
   Meiguins BS, 2006, INFORMATION VISUALIZATION-BOOK, P529
   Milatz, 2013, THESIS AARHUS
   Modai O, 2018, US Patent, Patent No. [9,959,676, 9959676]
   Moon, 2007, MAKE IMPACT INFLUENC
   Neumeier M., 2009, The Designful Company: How to Build a Culture of Nonstop Innovation: A Whiteboard Overview
   Novotny M, 2013, PROCEDIA COMPUT SCI, V25, P231, DOI 10.1016/j.procs.2013.11.028
   Pagés R, 2018, J VIS COMMUN IMAGE R, V53, P192, DOI 10.1016/j.jvcir.2018.03.012
   Pantile D, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P463, DOI 10.1109/SITIS.2016.78
   Parry, 1991, SUCCESSFUL BUSINESS
   Pastizzo MJ, 2002, BEHAV RES METH INS C, V34, P158, DOI 10.3758/BF03195437
   PINTRICH PR, 1990, J EDUC PSYCHOL, V82, P33, DOI 10.1037/0022-0663.82.1.33
   Platts K., 2004, Management Decision, V42, P667, DOI 10.1108/00251740410538505
   Plowman L., 1999, P SIGCHI C HUMAN FAC, P310
   Puggioni MP, 2020, LECT NOTES COMPUT SC, V12243, P205, DOI 10.1007/978-3-030-58468-9_16
   Rahim NN, 2015, P 1 INT ISL HER C U, P38
   Raphaelson, 2000, WRITING AUDIENCE PRE, P90
   Resnikoff HL, 1989, US Patent, Patent No. [4,830,482, 4830482]
   Reynolds G, 2014, PRESENTATION ZEN DES
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   ROBERTSON GG, 1993, COMMUN ACM, V36, P57, DOI 10.1145/255950.153577
   Shaw G, 1998, HARVARD BUS REV, V76, P41
   SKINNER EA, 1993, J EDUC PSYCHOL, V85, P571, DOI 10.1037/0022-0663.85.4.571
   Stone Maureen., 2006, Choosing colors for data visualization
   Tavakol M, 2011, INT J MED EDUC, V2, P53, DOI 10.5116/ijme.4dfb.8dfd
   Thomas BH, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P45, DOI 10.1109/3DVis.2014.7160099
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Tufte E., 2003, COGNITIVE STYLE POWE
   Uyan Dur Banu, 2014, Online Journal of Art and Design, V2, P1
   Wagner DN., 2017, INT J INNOV ED, V4, P16, DOI [10.1504/IJIIE.2017.086470, DOI 10.1504/IJIIE.2017.086470]
   Wang YC, 2019, VISUAL COMPUT, V35, P1567, DOI 10.1007/s00371-018-1558-y
   Ware C., 2004, INFORM VISUAL
   Ware C., 2020, INFORM VISUALIZATION
   Wiebe EN, 2014, COMPUT HUM BEHAV, V32, P123, DOI 10.1016/j.chb.2013.12.001
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Williams R, 2017, NONDESIGNERS PRESENT
   Winn W, 1991, EDUC PSYCHOL REV, V3, P211, DOI 10.1007/BF01320077
   Yang KJ, 2015, 2015 IIAI 4TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI), P354, DOI 10.1109/IIAI-AAI.2015.222
   Yeon-Jae Oh, 2015, 2015 17th International Conference on Advanced Communication Technology (ICACT), P568, DOI 10.1109/ICACT.2015.7224925
   Zhang X, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P88, DOI 10.1109/ICME.2000.869552
   Zoellner M., 2009, P 10 INT S VIRTUAL R, P112
NR 95
TC 6
Z9 7
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30969
EP 30991
DI 10.1007/s11042-021-10963-4
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000655960200004
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Tewari, AS
   Parhi, I
   Al-Turjman, F
   Abhishek, K
   Ghalib, MR
   Shankar, A
AF Tewari, Anand Shanker
   Parhi, Ityendu
   Al-Turjman, Fadi
   Abhishek, Kumar
   Ghalib, Muhummad Rukunuddin
   Shankar, Achyut
TI User-centric hybrid semi-autoencoder recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Autoencoder; E-commerce; Dimensionality
   reduction; Collaborative filtering
AB Recommendation System is one of such solutions to overcome information overload issues and to identify products most relevant to users and provide suggestions to users for items they might be interested in consuming or elements matching their needs. The significant challenge of several recommendation approaches is that they suggested a huge number of things to the target user. But the exciting items, according to the target user, are seen at the bottom of the recommended list. The proposed approach has improved the quality of recommendations by implementing some of the unique features in the new framework of auto encoder called semi-autoencoder, which contains the rating information as well as some additional information of users. Autoencoder is widely used in the recommender system because it gives the best result for feature extraction, dimensionality reduction, regeneration of data, and a better understanding of the user's characteristics. The experimental results are compared with some established popular methods using precision, recall, and F-measure evaluation measures. Users generally don't want to see lots of suggestions. With its six building blocks, the proposed approach gives better performance for the top 10 recommendations compared to other well-known methods.
C1 [Tewari, Anand Shanker; Parhi, Ityendu; Abhishek, Kumar] NIT Patna, CSE Dept, Patna, Bihar, India.
   [Al-Turjman, Fadi] Near East Univ, Dept Artificial Intelligence Engn, Res Ctr AI & IoT, Mersin 10, Nicosia, Turkey.
   [Ghalib, Muhummad Rukunuddin] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Shankar, Achyut] Amity Univ, Amity Sch Engn & Technol, Dept CSE, Noida, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; Near East University; Vellore Institute of Technology
   (VIT); VIT Vellore; Amity University Noida
RP Shankar, A (corresponding author), Amity Univ, Amity Sch Engn & Technol, Dept CSE, Noida, India.
EM anand@nitp.ac.in; ityendup.pg18.it@nitp.ac.in;
   fadi.alturjman@neu.edu.tr; kumar.abhishek@nitp.ac.in;
   ruk.ghalib@vit.ac.in; ashankar2711@gmail.com
RI Shankar, Achyut/ABI-4052-2020; Ghalib, Muhammad Rukunuddin/C-4485-2019;
   Abhishek, Kumar/C-9914-2017; Al-Turjman, Fadi/L-2998-2019
OI Shankar, Achyut/0000-0003-3165-3293; Ghalib, Muhammad
   Rukunuddin/0000-0002-2786-3370; Abhishek, Kumar/0000-0001-6825-2392;
   Al-Turjman, Fadi/0000-0001-5418-873X
CR An SH, 2017, INT C INTEL HUM MACH, P43, DOI 10.1109/IHMSC.2017.17
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bokde D, 2015, PROCEDIA COMPUT SCI, V49, P136, DOI 10.1016/j.procs.2015.04.237
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   He M, 2019, IEEE ACCESS, V7, P30276, DOI 10.1109/ACCESS.2019.2902398
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Kawale J, 2015, P 24 ACM INT C INF K, P811, DOI DOI 10.1145/2806416.2806527
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Liang DW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P689, DOI 10.1145/3178876.3186150
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Murali MV, 2019, INT CONF ADVAN COMPU, P550, DOI [10.1109/icaccs.2019.8728409, 10.1109/ICACCS.2019.8728409]
   Oramas S, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2926718
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rivas A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12416
   Saini S, 2017, LECT NOTES COMPUT SC, V10244, P366, DOI 10.1007/978-3-319-59105-6_31
   Sammut C., 2011, Leave-One-Out Cross-Validation, DOI DOI 10.1007/978-0-387-30164-8469
   SEDHAIN S, 2015, P 24 INT C WORLD WID, P111, DOI DOI 10.1145/2740908.2742726
   Sharma RC, 2016, INT J DIGIT EARTH, V9, P1004, DOI 10.1080/17538947.2016.1168879
   Tewari AS, 2020, PROCEDIA COMPUT SCI, V167, P1934, DOI 10.1016/j.procs.2020.03.215
   Tewari AS, 2018, EXPERT SYST APPL, V97, P70, DOI 10.1016/j.eswa.2017.12.019
   Turcotte J, 2015, J COMPUT-MEDIAT COMM, V20, P520, DOI 10.1111/jcc4.12127
   Velammal BL, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12382
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Xu JL, 2019, IEEE IJCNN
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P957, DOI 10.1145/3077136.3080689
NR 29
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23091
EP 23104
DI 10.1007/s11042-021-11039-z
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000655825400003
DA 2024-07-18
ER

PT J
AU Wang, CP
   Wang, SM
   Xia, ZQ
   Li, Q
   Ma, B
   Li, J
   Yang, MH
   Shi, YQ
AF Wang, Chunpeng
   Wang, Simiao
   Xia, Zhiqiu
   Li, Qi
   Ma, Bin
   Li, Jian
   Yang, Meihong
   Shi, Yun-Qing
TI Medical image super-resolution via deep residual neural network in the
   shearlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep medical super-resolution network (DMSRN); Medical image;
   Super-resolution; Shearlet domain
ID ACCURATE
AB This paper proposes aconvolutional neural network (CNN)-based efficient medical image super-resolution (SR) method in the shearlet domain. Because of differences between imaging mechanisms optimized for natural images and medical images, the design begins with building a medical image dataset for medical image SR and extracting effective areas to remarkably enhance the training effects of the CNN-based method. Then, a new medical image SR network structure-deep medical super-resolution network (DMSRN)-has been designed in which local residual learning is implemented through a recursive network and combined with global residual learning to heighten the depth of the network on the ground with no parameter increase. This effectively fixes the long-term dependency problem, which causes the prior state layers to barely have any effect on the following state layers. Last, the design addresses the problem of too-smooth reconstruction effects in the CNN-based method in the image space domain; shearlet transform is introduced to DMSRN to restore global topology through low-frequency sub-bands and restore local edge detail information through high-frequency sub-bands. Experimental results show that the proposed method is better than other state-of-the-art methods for medical image SR, which significantly promotes the restoration ability of texture structure and edge details.
C1 [Wang, Chunpeng; Xia, Zhiqiu; Li, Qi; Ma, Bin; Li, Jian; Yang, Meihong] Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Jinan 250353, Peoples R China.
   [Wang, Chunpeng; Li, Qi; Li, Jian; Yang, Meihong] Qilu Univ Technol, Shandong Acad Sci, Shandong Prov Key Lab Comp Networks, Shandong Comp Sci Ctr,Natl Supercomp Ctr Jinan, Jinan 250014, Peoples R China.
   [Wang, Simiao] Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao 125105, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Qilu University of Technology; Qilu University of Technology; Liaoning
   Technical University; New Jersey Institute of Technology
RP Ma, B (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Jinan 250353, Peoples R China.
EM sddxmb@126.com
OI Wang, Chunpeng/0000-0002-3742-5614
FU National Natural Science Foundation of China [61802212, 61872203];
   Shandong Provincial Natural Science Foundation [ZR2019BF017]; Project of
   Shandong Province Higher Educational Science and Technology Program
   [J18KA331]; China Postdoctoral Science Foundation [2020M670728]; Major
   Scientific and Technological Innovation Projects of Shandong Province
   [2019JZZY010127, 2019JZZY010132, 2019JZZY010201]; Plan of Youth
   Innovation Team Development of Colleges and Universities in Shandong
   Province [SD2019-161]; Jinan City 20 universities Funding Projects
   Introducing Innovation Team Program [2019GXRC031]
FX This work was supported by the National Natural Science Foundation of
   China (Nos: 61802212 and 61872203), the Shandong Provincial Natural
   Science Foundation (No: ZR2019BF017), the Project of Shandong Province
   Higher Educational Science and Technology Program (No: J18KA331), China
   Postdoctoral Science Foundation (No: 2020M670728), Major Scientific and
   Technological Innovation Projects of Shandong Province (Nos:
   2019JZZY010127, 2019JZZY010132, and 2019JZZY010201), Plan of Youth
   Innovation Team Development of Colleges and Universities in Shandong
   Province (No: SD2019-161) and Jinan City 20 universities Funding
   Projects Introducing Innovation Team Program (No: 2019GXRC031).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Cao FL, 2019, NEUROCOMPUTING, V358, P424, DOI 10.1016/j.neucom.2019.05.066
   Chantas GK, 2007, IEEE T IMAGE PROCESS, V16, P1821, DOI 10.1109/TIP.2007.896664
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Deeba F, 2019, MULTIMED TOOLS APPL, V78, P27683, DOI 10.1007/s11042-019-07850-4
   Deng X, 2019, IEEE I CONF COMP VIS, P3076, DOI 10.1109/ICCV.2019.00317
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Gao M, 2020, MULTIMED TOOLS APPL, V79, P4831, DOI 10.1007/s11042-018-6751-5
   Gu YC, 2020, MULTIMED TOOLS APPL, V79, P21815, DOI 10.1007/s11042-020-08980-w
   Guo TT, 2019, IEEE T IMAGE PROCESS, V28, P4685, DOI 10.1109/TIP.2019.2913500
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   HARRIS JL, 1964, J OPT SOC AM, V54, P931, DOI 10.1364/JOSA.54.000931
   He JJ, 2020, NEUROCOMPUTING, V402, P359, DOI 10.1016/j.neucom.2020.03.107
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XG, 2009, J VIS COMMUN IMAGE R, V20, P312, DOI 10.1016/j.jvcir.2009.03.008
   Lin DY, 2020, NEUROCOMPUTING, V398, P399, DOI 10.1016/j.neucom.2019.02.067
   Liu YN, 2019, MULTIMED TOOLS APPL, V78, P2525, DOI 10.1007/s11042-018-6386-6
   Liu YN, 2021, IEEE T IMAGE PROCESS, V30, P2888, DOI 10.1109/TIP.2021.3055737
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Mao XJ, 2016, ADV NEUR IN, V29
   Monga V, 2017, P IEEE C COMP VIS PA, P624
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428
   Sánchez-Beato A, 2008, IEEE T IMAGE PROCESS, V17, P1817, DOI 10.1109/TIP.2008.2002833
   Sang Y, 2019, LECT NOTES COMPUT SC, V11954, P50, DOI 10.1007/978-3-030-36711-4_5
   Sang Y, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102831
   Sha F, 2019, EXPERT SYST APPL, V128, P157, DOI 10.1016/j.eswa.2019.03.032
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang YF, 2019, CHEM COMMUN, V55, P27, DOI 10.1039/c8cc08413k
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Umehara K, 2018, J DIGIT IMAGING, V31, P441, DOI 10.1007/s10278-017-0033-z
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INT CONF ACOUST SPEE, P2387, DOI [10.1109/icassp.2019.8682288, 10.1109/ICASSP.2019.8682288]
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang SS, 2020, HYBRID RESOLUTION NE, P1670
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhong ZS, 2018, ADV NEUR IN, V31
   Zhou F, 2012, IEEE T IMAGE PROCESS, V21, P3312, DOI 10.1109/TIP.2012.2189576
NR 54
TC 4
Z9 5
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26637
EP 26655
DI 10.1007/s11042-021-10894-0
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648016400001
DA 2024-07-18
ER

PT J
AU Chandriah, KK
   Naraganahalli, RV
AF Chandriah, Kiran Kumar
   Naraganahalli, Raghavendra V.
TI RNN / LSTM with modified Adam optimizer in deep learning approach for
   automobile spare parts demand forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Demand forecasting; Deep learning; Long-short term memory;
   Modified-Adam; Recurrent neural networks; Spare parts
AB The spare parts demand forecasting is very much essential for the organizations to minimize the cost and prevent the stock outs. The demand of spare parts/ car sales distribution is an important factor in inventory control. The valuation of the demand is challenging as the automobile spare parts/car sales demand are often recurrent. The renowned empirical method adopts historical demand data to create the distribution of lead time demand. Although it works reasonably well when service requirements are relatively low, it has difficulty reaching high target service levels. In this paper, we proposed Recurrent Neural Networks/ Long-Short Term Memory (RNN / LSTM) with modified Adam optimizer to predict the demand for spare parts. In this LSTM, weight vectors are generated respectively. These weights are optimized using the Modified-Adam algorithm. The accuracy of the forecast and the performance of the inventory are considered in the experimental result. Experimental results confirm that RNN / LSTM with a Modified-Adam works well with minimal error compared to other existing methods. We conclude that the proposed RNN/LSTM with Modified-Adam algorithm is well suited for the prediction of automobile spare parts.
C1 [Chandriah, Kiran Kumar] Visveswaraya Technol Univ, Dept Mech Engn, Belagavi, Karanataka, India.
   [Naraganahalli, Raghavendra V.] Natl Inst Engn NIE, Dept Mech Engn, Mysore, Karnataka, India.
C3 Visvesvaraya Technological University; National Institute of Engineering
   (NIE)
RP Chandriah, KK (corresponding author), Visveswaraya Technol Univ, Dept Mech Engn, Belagavi, Karanataka, India.
EM Kiran.chandriah@gmail.com
CR Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2016, SOFT COMPUT, V20, P3283, DOI 10.1007/s00500-015-1707-4
   Amirkolaii KN, 2017, IFAC PAPERSONLINE, V50, P15221, DOI 10.1016/j.ifacol.2017.08.2371
   [Anonymous], 2019, LOGISTICS SUPPLY CHA
   [Anonymous], 2014, INF SCI, DOI DOI 10.1016/j.ins.2014.03.128
   Babai MZ, 2019, INT J PROD ECON, V209, P30, DOI 10.1016/j.ijpe.2018.01.026
   Babai MZ, 2014, INT J PROD ECON, V157, P212, DOI 10.1016/j.ijpe.2014.08.019
   Costantino F, 2018, OMEGA-INT J MANAGE S, V81, P57, DOI 10.1016/j.omega.2017.09.009
   Diaz D. A. B., 2019, ADV INTELLIGENT SYST, V991, P1109, DOI [10.1007/978-3-030-21803-4_109, DOI 10.1007/978-3-030-21803-4_109]
   Dombi J, 2018, INT J PROD ECON, V201, P1, DOI 10.1016/j.ijpe.2018.04.015
   Fu WH, 2018, IFIP ADV INF COMM TE, V536, P65, DOI 10.1007/978-3-319-99707-0_9
   Jifri Mohd Hanif, 2017, 2017 7th IEEE International Conference on System Engineering and Technology (ICSET). Proceedings, P12, DOI 10.1109/ICSEngT.2017.8123412
   Kim N, 2019, TECHNOL FORECAST SOC, V139, P277, DOI 10.1016/j.techfore.2018.11.014
   Kim TY, 2017, COMPUT IND ENG, V103, P201, DOI 10.1016/j.cie.2016.11.014
   Komodakis N., 2016, PROC INT C LEARN REP
   Liu Y, 2019, IEEE T FUZZY SYST, V27, P943, DOI 10.1109/TFUZZ.2018.2831637
   Mehdizadeh M, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.01.047
   Pannakkong W, 2018, J SYST SCI SYST ENG, V27, P690, DOI 10.1007/s11518-018-5390-8
   Savastano M, 2016, L N INF SYST ORGAN, V18, P153, DOI 10.1007/978-3-319-40265-9_11
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Snyder RD, 2017, INT J FORECASTING, V33, P502, DOI 10.1016/j.ijforecast.2016.11.008
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Stormi K, 2018, J SERV MANAGE, V29, P277, DOI 10.1108/JOSM-09-2016-0250
   Widmer T, 2019, LECT NOTES BUS INF P, V354, P147, DOI 10.1007/978-3-030-20482-2_13
   Zhu S, 2017, EUR J OPER RES, V261, P169, DOI 10.1016/j.ejor.2017.01.053
NR 26
TC 54
Z9 59
U1 14
U2 101
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26145
EP 26159
DI 10.1007/s11042-021-10913-0
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645187800002
DA 2024-07-18
ER

PT J
AU Najafi, A
   Javadi, HHS
   Bayat, M
AF Najafi, Aniseh
   Javadi, Hamid Haj Seyyed
   Bayat, Majid
TI Efficient and dynamic verifiable multi-keyword searchable symmetric
   encryption with full security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Randomized symmetric searchable encryption; Multi-keyword search;
   Dynamics; Verifiability; Binary search; Plaintext privacy; Predicate
   privacy; Full security
ID RANKED SEARCH
AB Increasing the popularity of cloud computing raises the importance of efforts to improve the services of this paradigm. Searching over encrypted data is a requirement for cloud storage to provide, in addition to privacy-preserving, convenient and low-cost access to some of the outsourced data. Security and functionality along with efficiency are important characteristics of searchable encryption schemes that improve them make this schemes more applicable to the real world. There are proposed structures for symmetric searchable encryption (SSE) in this paper, by adding functionalities to randomized SSE schemes, to provide a optimal scheme. We design a rFSMSE scheme that allows searching by multiple keywords. This scheme is fully secure and its search time complexity is logarithmic. Then we upgrad this scheme to the verifiable rFSMSE scheme called rFSVMSE, without increasing the complexity of search time, storage, and communication. We demonstrate that the proposed schemes are upgradable to dynamic ones. Simulations show the time taken to search for multi-keywords in the rFSMSE and rFSVMSE schemes is less than that in the previous randomized SSE.
C1 [Najafi, Aniseh; Javadi, Hamid Haj Seyyed] Shahed Univ, Dept Math & Comp Sci, Tehran, Iran.
   [Bayat, Majid] Shahed Univ, Dept Comp Engn, Tehran, Iran.
C3 Shahed University; Shahed University
RP Javadi, HHS (corresponding author), Shahed Univ, Dept Math & Comp Sci, Tehran, Iran.
EM ensiyeh.najafi@shahed.ac.ir; h.s.javadi@shahed.ac.ir;
   mbayat@shahed.ac.ir
OI Haj Seyyed Javadi, Hamid/0000-0003-0082-036X
CR Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Byun JW, 2006, LECT NOTES COMPUT SC, V4165, P75
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Cash D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23264
   Cash D, 2013, LECT NOTES COMPUT SC, V8042, P353, DOI 10.1007/978-3-642-40041-4_20
   Chai Q, 2012, IEEE ICC
   Chang YC, 2005, LECT NOTES COMPUT SC, V3531, P442
   Chen RM, 2016, IEEE T INF FOREN SEC, V11, P2833, DOI 10.1109/TIFS.2016.2599293
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Curtmola R, 2011, J COMPUT SECUR, V19, P895, DOI 10.3233/JCS-2011-0426
   Fu ZJ, 2017, IEEE T INF FOREN SEC, V12, P2986, DOI 10.1109/TIFS.2017.2730365
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Goh EJ, 2003, Cryptology ePrint Archive, Report 2003/216
   Golle P, 2004, LECT NOTES COMPUT SC, V3089, P31, DOI 10.1007/978-3-540-24852-1_3
   ISHAI Y, 2016, CT RSA, P90
   Jiang XX, 2017, INFORM SCIENCES, V403, P22, DOI 10.1016/j.ins.2017.03.037
   Kamara S., 2012, P ACM C COMP COMM SE, P965, DOI DOI 10.1145/2382196.2382298
   Kurosawa K., 2012, Financial Cryptography and Data Security (FC '12), Lecture Notes in Computer Science, P285
   Li HW, 2016, IEEE T DEPEND SECURE, V13, P312, DOI 10.1109/TDSC.2015.2406704
   Li YX, 2020, IEEE ACCESS, V8, P86328, DOI 10.1109/ACCESS.2020.2992773
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu Q, 2022, IEEE T SERV COMPUT, V15, P69, DOI 10.1109/TSC.2019.2922177
   Lu CC, 2002, IEEE INT CONF ASAP, P277, DOI 10.1109/ASAP.2002.1030726
   Najafi A, 2019, FUTURE GENER COMP SY, V101, P410, DOI 10.1016/j.future.2019.06.018
   Pointcheval D., 2016, IACR CRYPTOLOGY EPRI, V2016, P62
   Ramasamy Rajkumar, 2017, 2017 IEEE 4th International Conference on Cyber-Security and Cloud Computing (CSCloud), P357, DOI 10.1109/CSCloud.2017.47
   Rizomiliotis Panagiotis., 2015, Proc. 2015 ACM Workshop Cloud Computing Security Workshop, P65
   Shen E, 2009, LECT NOTES COMPUT SC, V5444, P457
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   STEFANOV E, 2014, NDSS, DOI DOI 10.14722/NDSS.2014.23298
   Sun WH, 2015, IEEE INFOCOM SER, DOI 10.1109/INFOCOM.2015.7218596
   Sun WH, 2014, IEEE T PARALL DISTR, V25, P3025, DOI 10.1109/TPDS.2013.282
   Vivek SS, 2018, J SIGNAL PROCESS SYS, V90, P1151, DOI 10.1007/s11265-017-1299-6
   Wang PS, 2008, LECT NOTES COMPUT SC, V5339, P178, DOI 10.1007/978-3-540-89641-8_13
   Wang SL, 2016, IEEE T INF FOREN SEC, V11, P1265, DOI 10.1109/TIFS.2016.2523941
   Wong WK, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P139
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xu P, 2013, IEEE T COMPUT, V62, P2266, DOI 10.1109/TC.2012.215
   Yoshino Masayuki, 2012, Provable Security. Proceedings of the 6th International Conference (ProvSec 2012), P215, DOI 10.1007/978-3-642-33272-2_14
   Zhang R, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2940328
NR 41
TC 8
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26049
EP 26068
DI 10.1007/s11042-021-10844-w
EA APR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644761700001
DA 2024-07-18
ER

PT J
AU Zhang, QW
   Wang, YH
   Huang, LX
   Wei, T
   Su, RJ
AF Zhang, Qiuwen
   Wang, Yihan
   Huang, Lixun
   Wei, Tao
   Su, Rijian
TI Fast coding scheme for low complexity 3D-HEVC based on video content
   property
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Complexity; Content property; Video coding
ID CU SIZE DECISION; MODE DECISION; HEVC; MULTIVIEW; SELECTION
AB 3D-high efficiency video coding (3D-HEVC) is the latest new extension standard of high efficiency video coding (HEVC) for multi-view video plus depth (MVD). Several novel coding tools are employed in the 3D-HEVC for better representation of the dependent texture and depth video. However, employing these tools causes a significant increase in coding complexity. In this paper, we introduce a fast coding scheme for complexity reduction of 3D-HEVC. Since the multi-view video and depth are highly content dependent, testing all the prediction modes are not efficient. A statistically analysis is performed to study the features of 3D video contents from spatio, spatial and inter-view correlations. Based on this correlation, the proposed fast coding scheme determines to skip some treeblocks of texture and depth video at the early stage. Experimental results demonstrate that the proposed scheme can save 63.3% runtime of 3D-HEVC with only 0.41% bitrate increase.
C1 [Zhang, Qiuwen; Wang, Yihan; Huang, Lixun; Su, Rijian] Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, Zhengzhou 450002, Peoples R China.
   [Wei, Tao] Henan Univ Technol, Sch Elect Engn, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University of Light Industry; Henan University of Technology
RP Zhang, QW (corresponding author), Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, Zhengzhou 450002, Peoples R China.
EM zhangqwen@126.com
RI tao, wei/GXN-4445-2022; wang, yihan/HTN-8802-2023
FU National Natural Science Foundation of China [61771432, 61302118,
   61702464, 61773018, 61374014]; Basic Research Projects of Education
   Department of Henan [21zx003, 20A880004]; Scientific Project of Henan
   [202102210179]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61771432, 61302118, 61702464, 61773018
   and 61374014, the Basic Research Projects of Education Department of
   Henan No. 21zx003, and 20A880004, the Scientific Project of Henan under
   Grant 202102210179.
CR [Anonymous], 2001, ITU-T SG16/Q6
   [Anonymous], 2008, M16090 ISOIEC JTC1SC
   Chen Y, 2014, IEEE MULTIMEDIA, V21, P90, DOI 10.1109/MMUL.2014.31
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Hamout H, 2020, IEEE T CIRC SYST VID, V30, P1933, DOI 10.1109/TCSVT.2019.2918770
   Huang XP, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0226-x
   Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Saldanha M, 2020, IEEE T CIRC SYST VID, V30, P850, DOI 10.1109/TCSVT.2019.2898122
   Shen LQ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171018
   Shen LQ, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700298
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tohidypour HR, 2016, IEEE T CIRC SYST VID, V26, P1870, DOI 10.1109/TCSVT.2015.2477955
   Vetro A., 2014, 7 M SAN JOS CA US
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Zhang HB, 2018, IEEE T CIRC SYST VID, V28, P513, DOI 10.1109/TCSVT.2016.2612693
   Zhang N, 2014, SIGNAL PROCESS-IMAGE, V29, P951, DOI 10.1016/j.image.2014.06.003
   Zhang QW, 2019, J REAL-TIME IMAGE PR, V16, P1909, DOI 10.1007/s11554-017-0692-5
   Zhang QW, 2015, OPTIK, V126, P2793, DOI 10.1016/j.ijleo.2015.07.026
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
NR 27
TC 3
Z9 3
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25909
EP 25925
DI 10.1007/s11042-021-10961-6
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643186000003
DA 2024-07-18
ER

PT J
AU Djimasra, F
   Nkapkop, JD
   Tsafack, N
   Kengne, J
   Effa, JY
   Boukabou, A
   Bitjoka, L
AF Djimasra, Franklin
   Nkapkop, Jean De Dieu
   Tsafack, Nestor
   Kengne, Jacques
   Effa, Joseph Yves
   Boukabou, Abdelkrim
   Bitjoka, Laurent
TI Robust cryptosystem using a new hyperchaotic oscillator with stricking
   dynamic properties
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hidden attractor; Hyperchaos; Orthogonal moment; Chaotic encryption
AB This paper presents a digital image cryptosystem utilizing a novel dynamic system with very interesting features. The oscillator is designed by introducing a feedback control law to the third line of the Lorenz oscillator with exponential nonlinearity. This exponential nonlinearity is replaced with hyperbolic sine nonlinearity to induce more complexity in the oscillator. Using some well-known computation analysis tools like Lyapunov spectrum, bifurcation analysis, and phase portraits representations, the dynamic analysis indicates that the oscillator can show chaos or hyperchaos for the same parameter space. In addition, the oscillator is equilibrium free, consequently its attractors are classified as hidden. Finally, the sequences of the oscillator are utilized to design a robust encryption scheme. Our method relies on a discrete orthogonal moment, confusion and diffusion stages. The input image is represented in the transform domain using Hahn orthogonal moments. Chaotic sequences are used to confuse and diffuse the obtaind image. Various security techniques have been used with success to show that our encryption process is powerful to resist malicious attacks.
C1 [Djimasra, Franklin; Effa, Joseph Yves] Univ Ngaoundere, Dept Phys, POB 454, Ngaoundere, Cameroon.
   [Nkapkop, Jean De Dieu] Univ Inst Technol, Dept Elect Engn & Ind Comp, POB 8698, Douala, Cameroon.
   [Tsafack, Nestor] Univ Dschang, Fac Sci, Dept Phys, Res Unit Lab Condensed Matter Elect & Signal Proc, POB 67, Dschang, Cameroon.
   [Kengne, Jacques] Univ Dschang, Elect Engn Dept IUT FV, Res Unit Lab Automat & Appl Comp LAIA, POB 134, Bandjoun, Cameroon.
   [Boukabou, Abdelkrim] Univ MSB, Dept Elect, Jijel, Algeria.
   [Bitjoka, Laurent] Univ Ngaoundere, Dept Elect Engn Energet & Automat, Ngaoundere, Cameroon.
C3 Universite de Dschang; Universite de Dschang
RP Tsafack, N (corresponding author), Univ Dschang, Fac Sci, Dept Phys, Res Unit Lab Condensed Matter Elect & Signal Proc, POB 67, Dschang, Cameroon.
EM nestor.tsafack@yahoo.fr
RI Tsafack, Nestor/AAE-6386-2020
OI Tsafack, Nestor/0000-0002-6220-6931; Nkapkop, Jean de
   Dieu/0000-0001-7736-5145; EFFA, Joseph Yves/0000-0002-5812-778X;
   Nkapkop, Jean De Dieu/0000-0002-5397-6272
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Ahmed HEH, 2007, 2007 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, P67
   Alvarez G., 2003, ARXIVNLIN0311039
   Auyporn W., 2014, INT J SIGNAL PROCESS, DOI [10.12720/IJSPS.3.1.8-13, DOI 10.12720/IJSPS.3.1.8-13]
   Bao BC, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415500753
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Brucoli M, 1996, INT J BIFURCAT CHAOS, V6, P1673, DOI 10.1142/S0218127496001028
   El-Ashry I, 2010, THESIS MENOFIA U
   Elkamchouchi HM, 2005, RAD SCI C 2005 NRSC, P277, DOI DOI 10.1109/NRSC.2005.194011
   Fishawy NFE., 2007, INT J NETWORK SECUR, V5, P241
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   KAPITANIAK T, 1994, PHYS REV E, V50, P1642, DOI 10.1103/PhysRevE.50.1642
   Kengne J., 2018, INT J DYN CONTROL, V6, P1543, DOI [10.1007/s40435-018-0414-2, DOI 10.1007/S40435-018-0414-2]
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Leutcho GD, 2018, CHAOS SOLITON FRACT, V107, P67, DOI 10.1016/j.chaos.2017.12.008
   Li YX, 2005, INT J CIRC THEOR APP, V33, P235, DOI 10.1002/cta.318
   Li YX, 2005, IEEE T CIRCUITS-II, V52, P204, DOI 10.1109/TCSII.2004.842413
   Lian S., 2008, MULTIMEDIA CONTENT E, DOI [10.1201/9781420065282, DOI 10.1201/9781420065282]
   Liang JY, 2004, INT J UNCERTAIN FUZZ, V12, P37, DOI 10.1142/S0218488504002631
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu YJ, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106171
   LORENZ EN, 1969, TELLUS, V21, P289, DOI 10.1111/j.2153-3490.1969.tb00444.x
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Murali K, 2002, AIP CONF PROC, V622, P15, DOI 10.1063/1.1487516
   Negou AN, 2018, AEU-INT J ELECTRON C, V90, P1, DOI 10.1016/j.aeue.2018.04.003
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Nkapkop JDD, 2017, INT ARAB J INF TECHN, V14, P812
   Nkapkop JD, 2015, LECT NOTES COMPUT SC, V9522, P87, DOI 10.1007/978-3-319-27179-8_7
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   ]Signing VRF Kengne J, 2018, Int J Dyn Control, V6, P1421, DOI [10.1007/s40435-017-0392-9, DOI 10.1007/S40435-017-0392-9]
   Sivakumar T, 2019, OPT LASER TECHNOL, V111, P196, DOI 10.1016/j.optlastec.2018.09.048
   Tsafack N., 2019, WORLD J APPL PHYS, V4, P24, DOI DOI 10.11648/J.WJAP.20170203.11
   Tsafack N, 2018, SCI WORLD J
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wei ZC, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414501272
   Wei ZC, 2011, NONLINEAR ANAL-REAL, V12, P106, DOI 10.1016/j.nonrwa.2010.05.038
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu CX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090399
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 50
TC 15
Z9 15
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25121
EP 25137
DI 10.1007/s11042-021-10734-1
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640172500005
DA 2024-07-18
ER

PT J
AU Nguyen, TS
AF Nguyen, Thai-Son
TI Fragile watermarking for image authentication based on DWT-SVD-DCT
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High quality; Image authentication; Tamper detection; Fragile
   watermarking; DWT-SVD-DCT
ID TAMPER-DETECTION SCHEME; LOCALIZATION
AB Many fragile watermarking schemes for image authentication have been proposed to protect the integrity of digital images. However, these schemes still yielded unsatisfactory image quality of the watermarked images and low accuracy of tamper detection. In this paper, we propose a new, fragile watermarking scheme for image authentication based on the combination of discrete wavelets transform (DWT), singular value decomposition (SVD), and discrete cosines transform (DCT) algorithms. The feature coefficients are extracted and are used to embed the authentication code by using the quantization index modulation (QIM) process. To guarantee that the extracted authentication code is correct, the Gram-Schmidt process is used to adjust the feature coefficients. The experimental results demonstrated that the proposed scheme provides good quality watermarked images and achieves high accuracy of tamper detection under different attacks, i.e., direct cropping and object insertion attacks.
C1 [Nguyen, Thai-Son] Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Tra Vinh Provin, Vietnam.
C3 Tra Vinh University
RP Nguyen, TS (corresponding author), Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Tra Vinh Provin, Vietnam.
EM thaison@tvu.edu.vn
RI Nguyen, Thai-Son/AGD-3594-2022
OI Nguyen, Thai-Son/0000-0001-7008-0462
FU Tra Vinh University for Science and Technology Development [207/HD]
FX This research is funded by Tra Vinh University for Science and
   Technology Development under grant number 207/HD.HDKH-DHTV.
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Chan CS, 2011, PATTERN RECOGN LETT, V32, P1679, DOI 10.1016/j.patrec.2011.07.023
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Do, 2020, DIGIT MEDIA STEGANOG, P99
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mansouri A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102370
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Yin ZX, 2015, IET IMAGE PROCESS, V9, P300, DOI 10.1049/iet-ipr.2014.0159
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
   Zheng PJ, 2020, MULTIMED TOOLS APPL, V79, P18343, DOI 10.1007/s11042-019-08490-4
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 27
TC 10
Z9 11
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25107
EP 25119
DI 10.1007/s11042-021-10879-z
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639743500003
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Zhu, GF
   Lian, BB
   Chen, MX
   Chen, H
   Wu, CJ
AF Zhang, Chongyang
   Zhu, Guofeng
   Lian, Bobo
   Chen, Minxin
   Chen, Hong
   Wu, Chenjian
TI Image segmentation based on multiscale fast spectral clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multiscale; Quad-tree decomposition; Spectral
   clustering; Superpixel
AB Spectral clustering is a popular clustering algorithm, which has a large number of applications in image segmentation tasks. However, its applicability becomes difficult for high-resolution images due to high computational complexity. In this paper, we first propose a novel Fast Spectral Clustering algorithm based on quad-tree decomposition. The algorithm focuses on the spectral clustering at the superpixel level and its time complexity is O(n log n)+ O(m)+ O(m(3/2)), its space complexity is O(m), where n and m represent the number of pixels and superpixels in an image, respectively. Then we proposeMultiscale Fast Spectral Clustering by improving Fast Spectral Clustering, which is a bottom-up method based on the quad-tree and the related hierarchical structure. In this method, according to the hierarchical structure generated by the quad-tree, treating the child node's segmentation result as the superpixel of the parent node, the child nodes at the fine level can be merged into the parent nodes at the coarse level. The time complexity of Multiscale Fast Spectral Clustering is O(n log n) and its space complexity is O(m). Extensive experiments on both the Weizmann and BSDS500 segmentation datasets demonstrate that Multiscale Fast Spectral Clustering outperforms Normalized cut, a classical spectral clustering method, in terms of lower computational complexity and memory cost, with comparable clustering accuracy.
C1 [Zhang, Chongyang; Wu, Chenjian] Soochow Univ, Sch Elect & Informat Engn, Suzhou, Peoples R China.
   [Zhu, Guofeng; Lian, Bobo; Chen, Minxin; Chen, Hong] Soochow Univ, Sch Math Sci, Suzhou, Peoples R China.
C3 Soochow University - China; Soochow University - China
RP Chen, MX (corresponding author), Soochow Univ, Sch Math Sci, Suzhou, Peoples R China.
EM 20165228011@stu.suda.edu.cn; 20164207010@stu.suda.edu.cn;
   20174207019@stu.suda.edu.cn; chenminxin@suda.edu.cn;
   chenhong@suda.edu.cn; cjwu@suda.edu.cn
OI Wu, Chenjian/0000-0002-6645-1854
FU National Natural Science Foundation of China [61801321]
FX This work was funded by the National Natural Science Foundation of China
   under Grant 61801321.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   ALLEN LS, 1991, J NEUROSCI, V11, P933
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564
   Cao JZ, 2014, PATTERN RECOGN LETT, V38, P63, DOI 10.1016/j.patrec.2013.11.005
   Chew SE, 2015, IEEE I CONF COMP VIS, P1716, DOI 10.1109/ICCV.2015.200
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Cour T, 2005, PROC CVPR IEEE, P1124
   Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Elsayed A, 2010, RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XXVI, P333, DOI 10.1007/978-1-84882-983-1_27
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Filippone M, 2008, PATTERN RECOGN, V41, P176, DOI 10.1016/j.patcog.2007.05.018
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He L, 2019, IEEE T CYBERNETICS, V49, P1058, DOI 10.1109/TCYB.2018.2794998
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jia YH, 2018, IEEE SIGNAL PROC LET, V25, P403, DOI 10.1109/LSP.2018.2791606
   Langone R, 2017, NEUROCOMPUTING, V268, P27, DOI 10.1016/j.neucom.2016.12.085
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li P, 2013, IEEE T CYBERNETICS, V43, P1871, DOI 10.1109/TSMCB.2012.2234108
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lutkepohl H., 1997, COMPUT STAT DATA AN, V2, P243
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Rong H, 2018, SOFT COMPUT, V22, P2583, DOI 10.1007/s00500-017-2513-y
   Semertzidis T, 2015, INFORM PROCESS MANAG, V51, P616, DOI 10.1016/j.ipm.2015.05.007
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2
   Tung F, 2010, PATTERN RECOGN, V43, P4069, DOI 10.1016/j.patcog.2010.06.015
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang R, 2017, IEEE GEOSCI REMOTE S, V14, P2003, DOI 10.1109/LGRS.2017.2746625
   WEIS S, 1993, AM J NEURORADIOL, V14, P637
   Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907
   Yu ZW, 2015, IEEE ACM T COMPUT BI, V12, P887, DOI 10.1109/TCBB.2014.2359433
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhan Q, 2017, MULTIMED TOOLS APPL, V76, P20149, DOI 10.1007/s11042-017-4566-4
   Zhang CY, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1607, DOI [10.1109/itnec.2019.8729087, 10.1109/ITNEC.2019.8729087]
   Zhang H, 2013, IEEE IMAGE PROC, P4024, DOI 10.1109/ICIP.2013.6738829
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhou ZL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717694172
NR 48
TC 8
Z9 9
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24969
EP 24994
DI 10.1007/s11042-021-10831-1
EA APR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639743500005
DA 2024-07-18
ER

PT J
AU Zhan, J
   Zhang, DJ
   Tan, LF
   Zhang, GY
   Zupan, R
AF Zhan, Jie
   Zhang, Dianjun
   Tan, Lifeng
   Zhang, Guangyun
   Zupan, Robert
TI Performance analysis of inverting optical properties based on
   quasi-analytical algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocean color remote sensing; QAA (quasi-analytical algorithm); Absorption
   coefficient; MODIS data
AB The inherent optical parameters play a very important role in determining the concentration of seawater components. One such inherent parameter, the absorption coefficient (a), is greatly significant when calculating each component's content in water and simulating the water's biological, physical and chemical properties. Quasi-analytical algorithm (QAA) is one of current inherent optical parameters inversion algorithms. In this study, we compared three versions of QAA, including QAA_V4, QAA_V5 and more recently QAA_V6, using IOCCG data set. The results showed that QAA_V4 model performs best for the inversion of the absorption coefficient at 443 nm, with MRE, RMSE and R-2 values of 11.82%, 0.1995 and 0.9099, respectively, while QAA_V6 has the highest accuracy when inverting a at 555 nm and 670 nm wavelengths. Next, we tested the three models using MODIS product data, including data from case I and case II waters. The data is extracted from image, after position matching, then was imported into the three QAA models to calculate their RMSE, MRE and R-2 values. The QAA model showed a high accuracy and robust applicability for absorption coefficient inversion at shorter wavelengths, such as 443 nm. Future research should include verification with more complicated water bodies, solidifying the foundation for implementing QAA into ocean color remote sensing research.
C1 [Zhan, Jie; Zhang, Dianjun] Tianjin Univ, Sch Marine Sci & Technol, Tianjin 300072, Peoples R China.
   [Tan, Lifeng] Tianjin Univ, Sch Architecture, Dept Culture & Tourism Informat Technol Architect, Key Lab, Tianjin 300072, Peoples R China.
   [Zhang, Guangyun] Nanjing Tech Univ, Sch Geomat Sci & Technol, Nanjing 211816, Peoples R China.
   [Zupan, Robert] Univ Zagreb, Geodesy, Zagreb 10000, Croatia.
C3 Tianjin University; Tianjin University; Nanjing Tech University;
   University of Zagreb
RP Zhang, DJ (corresponding author), Tianjin Univ, Sch Marine Sci & Technol, Tianjin 300072, Peoples R China.; Tan, LF (corresponding author), Tianjin Univ, Sch Architecture, Dept Culture & Tourism Informat Technol Architect, Key Lab, Tianjin 300072, Peoples R China.
EM 176117@tju.edu.cn; tanlf_arch@163.com
RI Župan, Robert/AFI-9061-2022
OI Župan, Robert/0000-0001-7882-1173; Tan, Lifeng/0009-0000-7716-9777
FU National Key R&D Program of China [2018YFC1407400]; National Natural
   Science Foundation of China [52078324]; Major Research on Philosophy and
   Social Sciences of the Ministry of Education of China [19JZD056,
   2018JZD059]
FX This paper is financially supported by National Key R&D Program of China
   (2018YFC1407400) and the National Natural Science Foundation of China
   (No.52078324), Major Research on Philosophy and Social Sciences of the
   Ministry of Education of China (No.19JZD056 and No.2018JZD059) for their
   funding of this research. And the authors would like to sincerely thank
   the editor and the anonymous reviewers.
CR [Anonymous], 2006, Remote Sensing of Inherent Optical Properties: Fundamentals, Tests of Algorithms, and Applications
   Aurin DA, 2012, REMOTE SENS ENVIRON, V125, P181, DOI 10.1016/j.rse.2012.07.001
   Cao ZG, 2019, ISPRS J PHOTOGRAMM, V153, P110, DOI 10.1016/j.isprsjprs.2019.05.001
   Chen SG, 2015, OPT EXPRESS, V23, P13953, DOI 10.1364/OE.23.013953
   Dong Q, 2013, REMOTE SENS ENVIRON, V128, P259, DOI 10.1016/j.rse.2012.10.013
   Gordon H.R., 2012, Remote assessment of ocean color for interpretation of satellite visible imagery: a review, V4
   GORDON HR, 1988, J GEOPHYS RES-ATMOS, V93, P10909, DOI 10.1029/JD093iD09p10909
   Hall LO, 1998, NEURAL NETWORK APPRO
   Joshi ID, 2018, BIOGEOSCIENCES, V15, P4065, DOI 10.5194/bg-15-4065-2018
   Le CF, 2009, IEEE T GEOSCI REMOTE, V47, P2492, DOI 10.1109/TGRS.2009.2015658
   Lee Z., 2009, UPDATE QUASIANALYTIC
   Lee Z. P., 2014, Update of the Quasi-Analytical Algorithm (QAAv6)
   Lee ZP, 2011, APPL OPTICS, V50, P3155, DOI 10.1364/AO.50.003155
   Lee Z, 2007, J GEOPHYS RES-OCEANS, V112, DOI 10.1029/2006JC003802
   Lee Z, 2015, APPL OPTICS, V54, P546, DOI 10.1364/AO.54.000546
   Lee ZP, 2013, J GEOPHYS RES-OCEANS, V118, P4241, DOI 10.1002/jgrc.20308
   Lee ZP, 2010, APPL OPTICS, V49, P369, DOI 10.1364/AO.49.000369
   Lee ZP, 2005, J GEOPHYS RES-OCEANS, V110, DOI 10.1029/2004JC002573
   Lee ZP, 1999, APPL OPTICS, V38, P3831, DOI 10.1364/AO.38.003831
   Lee ZP, 2004, REMOTE SENS ENVIRON, V89, P361, DOI 10.1016/j.rse.2003.10.013
   Lee ZP, 2002, APPL OPTICS, V41, P5755, DOI 10.1364/AO.41.005755
   Liu XH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071028
   Mishra S, 2014, IEEE T GEOSCI REMOTE, V52, P375, DOI 10.1109/TGRS.2013.2240462
   Mishra S, 2013, REMOTE SENS ENVIRON, V133, P141, DOI 10.1016/j.rse.2013.02.004
   MOREL A, 1977, LIMNOL OCEANOGR, V22, P709, DOI 10.4319/lo.1977.22.4.0709
   Morel A., 1974, Optical Aspects of Oceanography
   Shi LL, 2018, PROC SPIE, V10784, DOI 10.1117/12.2325484
   Sun DY, 2011, INT J REMOTE SENS, V32, P4005, DOI 10.1080/01431161.2010.481297
   Wang YC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111192
   Watanabe F, 2016, ISPRS J PHOTOGRAMM, V121, P28, DOI 10.1016/j.isprsjprs.2016.08.009
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Yang W, 2014, IEEE GEOSCI REMOTE S, V11, P1046, DOI 10.1109/LGRS.2013.2284343
   Yang W, 2013, IEEE T GEOSCI REMOTE, V51, P3761, DOI 10.1109/TGRS.2012.2220147
   Zeng C, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030210
   Zheng GM, 2014, REMOTE SENS ENVIRON, V155, P194, DOI 10.1016/j.rse.2014.08.020
NR 35
TC 0
Z9 2
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4693
EP 4709
DI 10.1007/s11042-021-10748-9
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000634660600001
DA 2024-07-18
ER

PT J
AU Andreas, A
   Mavromoustakis, CX
   Mastorakis, G
   Doi, DT
   Batalla, JM
   Palliss, E
   Markakis, EK
AF Andreas, Andreou
   Mavromoustakis, Constandinos X.
   Mastorakis, George
   Dinh-Thuan Doi
   Batalla, Jordi Mongay
   Palliss, Evangelos
   Markakis, Evangelos K.
TI Towards an optimized security approach to IoT devices with confidential
   healthcare data exchange
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Confidentiality; Data exchange; Fragmentation;
   IoT internet of things; Encryption; Cloud computing
ID FRAGMENTATION; DESIGN
AB Reliable data exchange and efficient image transfer are currently significant research challenges in health care systems. To incentivize data exchange within the Internet of Things (IoT) framework, we need to ensure data sovereignty by facilitating secure data exchange between trusted parties. The security and reliability of data-sharing infrastructure require a community of trust. Therefore, this paper introduces an encryption frame based on data fragmentation. It also presents a novel, deterministic grey-scale optical encryption scheme based on fundamental mathematics. The objective is to use encryption as the underlying measure to make the data unintelligible while exploiting fragmentation to break down sensitive relationships between attributes. Thus, sensitive data distributed in separate data repositories for decryption and reconstruction using interpolation by knowing polynomial coefficients and personal values from the DBMS Database Management System. Aims also to ensure the secure acquisition of diagnostic images, micrography, and all types of medical imagery based on probabilistic approaches. Visual sharing of confidential medical imageries based on implementing a novel method, where transparencies <= k - 1 out of n cannot reveal the original image.
C1 [Andreas, Andreou; Mavromoustakis, Constandinos X.] Univ Nicosia, Dept Comp Sci, MoSys Lab, Mobile Syst Lab, Nicosia, Cyprus.
   [Andreas, Andreou; Mavromoustakis, Constandinos X.] Univ Nicosia, Res Fdn, Nicosia, Cyprus.
   [Mastorakis, George] Hellen Mediterranean Univ, Dept Management Sci & Technol, Agios Nikolaos 72100, Crete, Greece.
   [Dinh-Thuan Doi] Ind Univ Ho Chi Minh City IUH, Fac Elect Technol, Ho Chi Minh City, Vietnam.
   [Batalla, Jordi Mongay] Warsaw Univ Technol, Warsaw, Poland.
   [Palliss, Evangelos; Markakis, Evangelos K.] Hellen Mediterranean Univ, Dept Elect & Comp Engn, Iraklion, Crete, Greece.
C3 University of Nicosia; University of Nicosia; Hellenic Mediterranean
   University; Industrial University of Ho Chi Minh City; Warsaw University
   of Technology; Hellenic Mediterranean University
RP Andreas, A (corresponding author), Univ Nicosia, Dept Comp Sci, MoSys Lab, Mobile Syst Lab, Nicosia, Cyprus.; Andreas, A (corresponding author), Univ Nicosia, Res Fdn, Nicosia, Cyprus.
EM andreou.andreas@unic.ac.cy; mavromoustakis.c@unic.ae.cy;
   gmastorakis@hmu.gr; dodinhthuan@iuh.edu.vn;
   jordi.mongay.batalla@pw.edu.pl; pallis@hmu.gr; markakis@pasiphae.eu
RI Batalla, Jordi/AAL-9056-2021; Mavromoustakis, Constandinos/M-8305-2014;
   Andreou, Andreas/AAP-2513-2021
OI Batalla, Jordi/0000-0002-1489-5138; Mavromoustakis,
   Constandinos/0000-0003-0333-8034; Andreou, Andreas/0000-0002-9432-916X
FU project entitled 'Smart and Health Ageing through People Engaging in
   supporting Systems' - European Union's Horizon 2020 research and
   innovation programme [857159]; SPHINX project through the European
   Union's Horizon 2020 Research and Innovation Programme (Digital Society,
   Trust & Cyber Security E-Health, Well-Being and Ageing) [826183];
   Research & Innovation Foundation in Cyprus under the AAL framework
   [vINCI/P2P/AAL/0217/0016]
FX The research work presented in this article was partially supported by
   the project entitled 'Smart and Health Ageing through People Engaging in
   supporting Systems' with acronym SHAPES, which has received funding from
   the European Union's Horizon 2020 research and innovation programme
   under grant agreement No 857159. Undertaken by the SPHINX project
   through the European Union's Horizon 2020 Research and Innovation
   Programme (Digital Society, Trust & Cyber Security E-Health, Well-Being
   and Ageing) under grant agreement 826183. It is also part of the Ambient
   Assisted Living (AAL) project vINCI: "Clinically-validated INtegrated
   Support for Assistive Care and Lifestyle Improvement: The Human Link"
   funded by Research & Innovation Foundation in Cyprus under the AAL
   framework with Grant Nr. vINCI/P2P/AAL/0217/0016. We sincerely thank
   anonymous reviewers for critically reading the manuscript and suggesting
   substantial improvements, which helped us significantly improve our
   paper's presentation and research work quality.
CR Agrawal D, 2009, PROC INT CONF DATA, P1709, DOI 10.1109/ICDE.2009.151
   Al-Shayea TK, 2019, MEASUREMENT, V148, DOI 10.1016/j.measurement.2019.07.041
   Alshayea T, 2018, 2018 IEEE 23 INT WOR
   Alshayeh T., 2019, 2019 IEEE INT C COMM
   Anderson S, 2007, INT S ABSTR REF APPR
   Andreas A, 2020, IEEE INT WORKSH COMP, DOI 10.1109/camad50429.2020.9209264
   Bart┬u├k R, 2007, INT S ABSTR REF APPR
   Bisio I, 2018, IEEE NETWORK, V32, P108, DOI 10.1109/MNET.2018.1700355
   Bisio I, 2018, MULTIMED TOOLS APPL, V77, P9341, DOI 10.1007/s11042-017-4867-7
   Bisio I, 2014, IEEE GLOB COMM CONF, P2454, DOI 10.1109/GLOCOM.2014.7037176
   Blumenthal D, 2010, NEW ENGL J MED, V363, P501, DOI 10.1056/NEJMp1006114
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Chang CC, 2002, FIRST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, PROCEEDINGS, P230, DOI 10.1109/CW.2002.1180884
   Chang CC, 2000, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P21, DOI 10.1109/ICPADS.2000.857679
   Ciriani V., 2009, EUR S RES COMP SEC
   Ciriani V, 2007, 12 EUR S RES COMP SE
   Ciriani V., 2009, IFIP ANN C DAT APPL
   Ciriani V, 2010, ACM T INFORM SYST SE, V13, DOI 10.1145/1805974.1805978
   Emekci F, 2014, INFORM SCIENCES, V263, P198, DOI 10.1016/j.ins.2013.10.006
   Gagan A., 2005, P 2 BIENN C INN DAT
   Le D. -N., 2018, J. Cyber Secur. Mobil, V7, P379, DOI DOI 10.13052/JCSM2245-1439.742
   Leng C., 2013, Telkomnika Indonesian Journal of Electrical Engineering, V11, P2200
   Mavromoustakis CX, 2018, IEEE COMMUN MAG, V56, P139, DOI 10.1109/MCOM.2018.1700600
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Odisho AY, 2020, JAMIA OPEN, V3, P405, DOI 10.1093/jamiaopen/ooaa036
   Sareen S, 2016, INF SECUR J, V25, P39, DOI 10.1080/19393555.2015.1134732
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Snezana S, 2020, MACHINE LEARNING APP, V1316, P28
   Sridhar S, 2017, INT C INV SYST CONTR
   Stoldt J-P, 2020, IEEE INT C SOFTW ARC
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Yang CN, 2000, DESIGN CODE CRYPTOGR, V20, P325, DOI 10.1023/A:1008382327051
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 34
TC 10
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31435
EP 31449
DI 10.1007/s11042-021-10827-x
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000633324300004
PM 33814966
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Al-karawi, KA
   Mohammed, DY
AF Al-karawi, Khamis A.
   Mohammed, Duraid Y.
TI Improving short utterance speaker verification by combining MFCC and
   Entrocy in Noisy conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Short utterance; I-vector; GMM; Robustness; MFCC;
   Noisy environment; Entrocy
AB Short utterance and background noise represent great challenging for speaker verification due to the mismatch and limited training and/or retrieve data. A remarkable performance using matched training and testing conditions generally could be achieved in automatic speaker verification. However, mismatched noisy and short utterances conditions attend to drop the results significantly. Furthermore, the performance is significantly affected by the features extraction. The most common features in this field of the study are Mel-Frequency Cepstral Coefficients (MFCCs). With a noise presents in the background and short utterances, MFCC performance could not be reliable without a support feature. To address this, a new feature 'Entrocy' for accurate and robust speaker verification under limited data and noisy environments is proposed and employed to support MFCC coefficients. Entrocy feature represents the Fourier Transform of the Entropy that calculates the fluctuation of the information in the sound segments over time. The resulting Entrocy features are combined with MFCC functionality to generate a composite feature, which is tested using the Gaussian Mixture Model (GMM) recognition method. The suggested method was conducted out over a range of signal/noise ratios and utterances were truncating into shorts (2, 3, 4, 5, 6, 8, and 10s) for verification. The proposed method has shown strong robustness in the challenging of background noise and limited testing data and they consistently perform better than the well-known MFCC.
C1 [Al-karawi, Khamis A.] Diyala Univ, Baqubah, Diyala, Iraq.
   [Mohammed, Duraid Y.] Al Iraqia Univ, Sch Educ Women, Baghdad, Iraq.
C3 University of Diyala; Al-Iraqia University
RP Al-karawi, KA (corresponding author), Diyala Univ, Baqubah, Diyala, Iraq.
EM alkasi_68@yahoo.com; duraidyehya19@gmail.com
RI AL-KARAWI, Khamis A./AGB-6700-2022; Mohammed, duraid Y./I-7203-2019
OI AL-KARAWI, Khamis A./0000-0001-9275-6902; Mohammed, duraid
   Y./0000-0002-9586-1983
CR Al-Karawi Khamis A., 2015, International Journal of Information and Electronics Engineering, V5, P423, DOI 10.7763/IJIEE.2015.V5.571
   Al-Karawi KA, 2020, INT J SPEECH TECHNOL, P1
   Al-Karawi KA, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P52, DOI 10.1109/INTECH.2017.8102427
   [Anonymous], 2013, SPEECH LANGUAGE PROC
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   Duraid Y, 2020, APPL COMPUTING SUPPO, P95
   Fatima N, 2012, INT C SYST INF ICSAI
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Junqua J., 1991, EUROSPEECH
   Kanagasundaram A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2352
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Li FF, 2015, 2015 IEEE 13 INT C I
   Li FF, 2019, INT J ARTIFICIAL INT, V8
   Logan B., 2000, MEL FREQUENCY CEPSTR, P1
   Mak B, 2006, 2006 IEEE INT C AC S
   Mohammed DY, 2017, OVERLAPPED SPEECH MU
   Nosratighods M, 2010, SPEECH COMMUN, V52, P753, DOI 10.1016/j.specom.2010.04.007
   Poddar A, 2018, IET BIOMETRICS, V7, P91, DOI 10.1049/iet-bmt.2017.0065
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Stewart W. J., 2009, Probability, Markov Chains, Queues, and Simulation: the Mathematical Basis of Performance Modeling
   Vogt R, 2010, IEEE T AUDIO SPEECH, V18, P1182, DOI 10.1109/TASL.2009.2031505
   Wang ZS, 2021, IEEE T CYBERNETICS, V51, P1454, DOI [10.1007/s00170-020-06291-w, 10.1109/TCYB.2019.2960605]
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
   Zheng TF, 2016, IEEE-ACM T AUDIO SPE, V24
NR 30
TC 7
Z9 7
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22231
EP 22249
DI 10.1007/s11042-021-10767-6
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000632798100003
DA 2024-07-18
ER

PT J
AU Wadhwa, A
   Bhardwaj, A
AF Wadhwa, Anjali
   Bhardwaj, Anuj
TI Contrast enhancement of MRI images using morphological transforms and
   PSO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Morphological transforms; Particle swarm optimization; CIR; PSNR; PL;
   SSIM
AB Medical imaging plays a crucial role in correct extraction of the significant information for monitoring the patient's health and providing the quality treatment. A deluge of medical images requires initial interpretation for the presence of any abnormality, however, the correct diagnosis requires the images to be of good quality. To cope with the problem of poor contrast in medical images, this paper presents a method based on morphological transforms to improve the quality of the images. The proposed method incorporates Particle Swarm Optimization to find an optimum value of a parameter which controls the enhancement of the resulting image. The proposed algorithm is executed on a set of MRI images for testing its efficacy. The experimental results are compared in terms of both qualitative and quantitative parameters. The mean opinion score is obtained with the help of experts, which clearly shows the better performance of the proposed method. Furthermore, the parameters like Contrast Improvement Ratio, signal-to-noise ratio, peak signal-to-noise ratio, PL, and Structural Similarity Index are evident of better performance of proposed method when compared with the state-of-the-art methods and few recent methods. The comparison shows that the performance of the proposed method based on morphological transforms incorporating Particle Swarm Optimization is better not only visually but also in terms of other evaluation parameters.
C1 [Wadhwa, Anjali; Bhardwaj, Anuj] Jaypee Inst Informat Technol, Noida 201309, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Bhardwaj, A (corresponding author), Jaypee Inst Informat Technol, Noida 201309, India.
EM anujbhardwaj8@gmail.com
RI Bhardwaj, Anuj/KIE-2095-2024
OI Bhardwaj, Anuj/0000-0003-0866-2618
CR [Anonymous], 2017, DIGITAL IMAGE PROCES
   Bai XZ, 2010, INT CONF SIGN PROCES, P797, DOI 10.1109/ICOSP.2010.5655927
   Bai XZ, 2012, OPT LASER TECHNOL, V44, P328, DOI 10.1016/j.optlastec.2011.07.009
   Bhardwaj A, 2019, AIP CONF PROC, V2061, DOI 10.1063/1.5086649
   Bo Peng, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P1142, DOI 10.1109/ICCIS.2010.282
   Chen T, 2002, PATTERN RECOGN, V35, P199, DOI 10.1016/S0031-3203(01)00024-3
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Guan JL, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141857001X
   Hassanpour H, 2015, EGYPT J RADIOL NUC M, V46, P481, DOI 10.1016/j.ejrnm.2015.01.004
   Hemalatha S, 2018, AIN SHAMS ENG J, V9, P1689, DOI 10.1016/j.asej.2016.12.003
   Jordehi AR, 2013, J EXP THEOR ARTIF IN, V25, P527, DOI 10.1080/0952813X.2013.782348
   Kansal S, 2020, ARAB J SCI ENG, V45, P1655, DOI 10.1007/s13369-019-04151-8
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kimori Y, 2013, J SYNCHROTRON RADIAT, V20, P848, DOI 10.1107/S0909049513020761
   Kobatake H, 1996, IEEE T MED IMAGING, V15, P235, DOI 10.1109/42.500062
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Maragos P, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P135, DOI 10.1016/B978-012119792-6/50072-3
   Mukhopadhyay S, 2000, SIGNAL PROCESS, V80, P685, DOI 10.1016/S0165-1684(99)00161-9
   Oh J, 2010, INT J CONTROL AUTOM, V8, P857, DOI 10.1007/s12555-010-0418-y
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Reljin B, 2009, FOLIA HISTOCHEM CYTO, V47, P525, DOI 10.2478/v10042-009-0076-1
   Simsekli U, 2012, EURASIP J AUDIO SPEE, P1, DOI 10.1186/1687-4722-2012-8
   Subramani B, 2018, INT J IMAGING SYST T, V28
   Wadhwa A, 2020, MULTIMED TOOLS APPL, V79, P25379, DOI 10.1007/s11042-020-09177-x
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 28
TC 7
Z9 7
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21595
EP 21613
DI 10.1007/s11042-021-10743-0
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629886000002
DA 2024-07-18
ER

PT J
AU Brahimi, T
   Khelifi, F
   Kacha, A
AF Brahimi, Tahar
   Khelifi, Fouad
   Kacha, Abdellah
TI An efficient JPEG-2000 based multimodal compression scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal signal-image compression; JPEG-2000 codec; SPIHT codec;
   Wavelet compression; Biomedical data compression
ID IMAGE COMPRESSION; WAVELET TRANSFORMS; QUALITY ASSESSMENT; ECG SIGNALS;
   ALGORITHM; TREES
AB In this paper, a wavelet-based multimodal compression method is proposed. The method jointly compresses a medical image and an ECG signal within a single codec, i.e., JPEG-2000 in an effective and simple way. The multimodal scheme operates in two main stages: the first stage, consists of the encoder and involves a mixing function, aiming at inserting the samples of the signal in the image according to a predefined insertion pattern in the wavelet domain. The second stage represented by a separation function, consists of the extraction process of the ECG signal from the image after performing the decoding stage. Both the cubic spline and the median edge detection (MED) predictor have been adopted to conduct the interpolation process for estimating image pixels. Intensive experiments have been conducted to evaluate the performance of the multimodal scheme using objective distortion criteria. Results show clear superiority of the proposed scheme over the conventional separate compression approach involving two codecs: JPEG-2000 for images and ECG SPIHT-1D as well as other competing multimodal compression schemes in terms of both PRD and SNR at the signal decompression stage while maintaining good image quality and exhibiting a reduced computational complexity. Improvements in terms of average PRD and SNR values are as significant as 0.7 and 6 dB at low bit rates and 0.06 and 2 dB at higher bit rates on a number of test ECG signals and medical images.
C1 [Brahimi, Tahar] Univ Mohammed Seddik Benyahia Jijel, Dept Elect, L2EI Res Lab, BP 98, Jijel 18000, Algeria.
   [Khelifi, Fouad] Northumbria Univ, Fac Engn & Environm, Dept Comp & Informat Sci, Newcastle, England.
   [Kacha, Abdellah] Univ Mohammed Seddik Benyahia Jijel, Dept Elect, Lab Phys Rayonnement & Applicat, BP 98, Jijel 18000, Algeria.
C3 Northumbria University
RP Brahimi, T (corresponding author), Univ Mohammed Seddik Benyahia Jijel, Dept Elect, L2EI Res Lab, BP 98, Jijel 18000, Algeria.
EM t.brahimi@gmail.com; Fouad.khelifi@northumbria.ac.uk; akacha@ulb.ac.be
CR Adams MD, 2000, IEEE T IMAGE PROCESS, V9, P1010, DOI 10.1109/83.846244
   Al-Fahoum AS, 2006, IEEE T INF TECHNOL B, V10, P182, DOI 10.1109/TITB.2005.855554
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], 2012, JPEG XR IM COD SYST
   [Anonymous], 2008, 3 INT C INFORM COMMU, DOI DOI 10.1109/ICTTA.2008.4530091
   Boubchir L., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P97, DOI 10.1109/ISSPA.2012.6310698
   Bouridane A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P689
   Brahimi T., 2008, Mediterranean Journal of Electronics and Communications, V4, P148
   Brahimi T, 2017, MULTIMED TOOLS APPL, V76, P16783, DOI 10.1007/s11042-016-3952-7
   Brahimi T, 2017, AEU-INT J ELECTRON C, V73, P183, DOI 10.1016/j.aeue.2017.01.008
   Brahimi T, 2009, DIGIT SIGNAL PROCESS, V19, P220, DOI 10.1016/j.dsp.2008.07.012
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Fournier R, 2012, SIGNAL IMAGE MULTIRE, P225
   Gargour C, 2009, IEEE CIRC SYST MAG, V9, P57, DOI 10.1109/MCAS.2009.932556
   Ghanbari M, 2011, STANDARD CODECS IMAG, V3, DOI [10.1049/PBTE054E, DOI 10.1049/PBTE054E]
   Grossi G, 2015, DIGIT SIGNAL PROCESS, V45, P96, DOI 10.1016/j.dsp.2015.06.006
   Khelifi F, 2008, IEEE T MULTIMEDIA, V10, P316, DOI 10.1109/TMM.2008.917357
   Khelifi F, 2008, IEEE SIGNAL PROC LET, V15, P69, DOI 10.1109/LSP.2007.911156
   Kolisch G, 2011, WATER PRACT TECHNOL, V6, DOI 10.2166/wpt.2011.022
   Lu ZT, 2000, IEEE T BIO-MED ENG, V47, P849, DOI 10.1109/10.846678
   Ma J, 2015, IEEE J BIOMED INFORM, V19, P86
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Naït-Ali A, 2009, ADVANCED BIOSIGNAL PROCESSING, P353, DOI 10.1007/978-3-540-89506-0_17
   Padhy S, 2016, BIOMED SIGNAL PROCES, V23, P10, DOI 10.1016/j.bspc.2015.06.012
   Pearlman W.A., 2011, Digital Signal Compression: Principles and Practice, DOI [10.1017/CBO9780511984655, DOI 10.1017/CBO9780511984655]
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Pearlman William A, 2013, SYNTHESIS LECT IMAGE, V8, P1, DOI DOI 10.2200/S00464ED1V01Y201212IVM013
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sayood k, 2017, INTRO DATA COMPRESSI
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   Wang XX, 2016, ELECTRON LETT, V52, DOI 10.1049/el.2016.2174
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   WEINBERGER MJ, 1998, HPL98193
   Zeybek EH., 2012, J BIOMED SCI ENG, V5, P755, DOI [10.4236/jbise.2012.512094, DOI 10.4236/jbise.2012.512094]
   Zeybek EH, 2007, P ANN INT IEEE EMBS, P713, DOI 10.1109/IEMBS.2007.4352390
NR 41
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21241
EP 21260
DI 10.1007/s11042-021-10776-5
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629113400002
DA 2024-07-18
ER

PT J
AU Bedi, AK
   Sunkaria, RK
AF Bedi, Anterpreet Kaur
   Sunkaria, Ramesh Kumar
TI Mean distance local binary pattern: a novel technique for color and
   texture image retrieval for liver ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern; Mean distance local binary pattern; Content based
   image retrieval; Gray level co-occurrence matrix; Ultrasound database
ID FEATURE DESCRIPTOR; COOCCURRENCE PATTERN; CLASSIFICATION; FEATURES
AB A rapid growth in medical ultrasound database makes it difficult for medical practitioners to manage and search relevant data with good efficiency. Hence, a novel image retrieval technique using Mean Distance Local Binary Pattern (Mean Distance LBP) has been proposed for content-based image retrieval. The conventional local binary pattern (LBP) converts every pixel of image into a binary pattern based on their relationship with neighbourhood pixels. The proposed feature descriptor differs from local binary pattern as it transforms the mutual relationship of all neighbouring pixels in a binary pattern based on their standard deviation templates as well as Euclidean distance from the center pixel. Color feature and Gray Level Co-occurrence Matrix have also been used in this work. To prove the excellence of the proposed method, experiments have been conducted on two different databases of natural images and face images. Further, the method is applied on real time ultrasound database for retrieval of liver images from a set of ultrasound images of various organs. The performance has been observed using well-known evaluation measures, precision and recall, and compared with some state-of-art local patterns. Comparison shows a significant improvement in the proposed method over existing methods.
C1 [Bedi, Anterpreet Kaur; Sunkaria, Ramesh Kumar] Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Bedi, AK (corresponding author), Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar, India.
EM anterpreetbedi27@gmail.com
OI Bedi, Anterpreet Kaur/0000-0001-6064-5925
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   [Anonymous], 2002, AT T DATABASE FACES
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Beigi M., 1997, STORAGE RETRIEVAL IM
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng C, 2019, IEEE T IMAGE PROCESS, V28, P4032, DOI 10.1109/TIP.2019.2903661
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Farsi H, 2013, IET IMAGE PROCESS, V7, P212, DOI 10.1049/iet-ipr.2012.0203
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Hamouchene I, 2014, AASRI PROC, V9, P2, DOI 10.1016/j.aasri.2014.09.002
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He, 2008, 2008 10 IEEE INT C H
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain R., 1995, MACHINE VISION, P234
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   KATO T, 1992, P SOC PHOTO-OPT INS, V1662, P112, DOI 10.1117/12.58497
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mongiello M., 1998, STORAGE RETRIEVAL IM, VVII
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Rhawa, 2018, 2018 1 INT C SEC CYB
   Ruager S., 2010, ACM INT C IM VID
   Shi YF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4767
   Smith J., 1997, International Food Ingredients, P23
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vadivel A, 2007, PATTERN RECOGN LETT, V28, P974, DOI 10.1016/j.patrec.2007.01.004
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Visa A, 2002, P 5 NORD SIGN PROC
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 57
TC 13
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20773
EP 20802
DI 10.1007/s11042-021-10758-7
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000626425400001
DA 2024-07-18
ER

PT J
AU Jia, BQ
   Zhang, N
   Liang, N
   Wang, SQ
   Wu, B
AF Jia, Boqi
   Zhang, Nan
   Liang, Nan
   Wang, Shiqi
   Wu, Bo
TI Virtual view synthesis for the nonuniform illuminated between views in
   surgical video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual view synthesis; Interpolation; Hole filling; Surgical video;
   Nonuniform illuminated
ID DEPTH; DIBR
AB For high-quality surgical video virtual view synthesis, a Weighted Autoregressive Interpolation (WAI) algorithm and an Adaptively-enhanced Hole Filling (AHF) are proposed to reduce the artifacts caused by up-sampling and relieve the luma difference. First, high quality up-sampled reference views are acquired by the WAI algorithm. A Piecewise Autoregressive (PAR) model is introduced and the distance weight of pixels is also considered. The precision of the virtual view is improved by the WAI and the texture edges are well preserved. Next, for the AHF, the intermediate view with more structure details is selected as the template. The other intermediate view is calibrated to it. And the luma difference is relieved. Then, a Nearest background Holes Filling algorithm (NHF) is adopted to blend these two intermediate views, in which only background pixels are selected to fill the remaining holes. Combining the WAI with AHF, the visual quality of the surgical virtual video is improved. For the objective quality, the experimental results show that the PSNR of the proposed algorithm is 0.5841 dB higher than the VSRS 1D-Fast algorithm on average. For subjective quality, the proposed method can reduce the artifacts and gain higher subjective quality for the synthesized virtual view of the surgical video.
C1 [Jia, Boqi; Zhang, Nan; Liang, Nan; Wu, Bo] Capital Med Univ, Sch Biomed Engn, Beijing, Peoples R China.
   [Jia, Boqi; Zhang, Nan; Liang, Nan; Wu, Bo] Capital Med Univ, Beijing Key Lab Fundamental Res Biomech Clin Appl, Beijing, Peoples R China.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Capital Medical University; Capital Medical University; City University
   of Hong Kong
RP Wu, B (corresponding author), Capital Med Univ, Sch Biomed Engn, Beijing, Peoples R China.; Wu, B (corresponding author), Capital Med Univ, Beijing Key Lab Fundamental Res Biomech Clin Appl, Beijing, Peoples R China.
EM jiaboqi@mail.ccmu.edu.cn; zhangnan@ccmu.edu.cn; liangnan@ccmu.edu.cn;
   shiqwang@cityu.edu.hk; wubogo@ccmu.edu.cn
RI Wang, Shiqi/AAR-5013-2020
OI Wang, Shiqi/0000-0002-6338-1432
FU National Natural Science Foundation of China [61672362, 61272255];
   Beijing Natural Science Foundation [4172012]; Scientific Research Common
   Program of BeijingMunicipal Commission of Education [KM201710025011]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61672362, 61272255) and the Beijing Natural
   Science Foundation (No.4172012), the Scientific Research Common Program
   of BeijingMunicipal Commission of Education (No.KM201710025011). Also
   thanks Beijing Friendship Hospital, affiliated with Capital Medical
   University for the hernia surgical video.
CR Cai CT, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013010
   Cai JJ, 2017, IEEE INT SYM MULTIM, P1, DOI 10.1109/ISM.2017.11
   Campero A, 2019, WORLD NEUROSURG, V132, P188, DOI 10.1016/j.wneu.2019.08.139
   Chen CH, 2008, INT C PATT RECOG, P1814
   Chen XD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051562
   Cho JM, 2020, IEEE ACCESS, V8, P53901, DOI 10.1109/ACCESS.2020.2981378
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   Dziembowski A, 2017, INT CONF SYST SIGNAL
   Gautier J, 2011, 3DTV CONF
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Gwangju Institute of Science and Technology (GIST), 3DV SEQUENCES GIST
   Ham B, 2009, 16 IEEE INT C IM PRO, VIEEE, DOI [10.1109/ICIP.2009.5414509, DOI 10.1109/ICIP.2009.5414509]
   Hanxiong Y, 2015, INT C CONTR, DOI [10.1109/ICCAIS.2015.7338683, DOI 10.1109/ICCAIS.2015.7338683]
   JCT-VC, 2014, TEST MOD 10 3D HEVC
   Jiufei X, 2010, AS PAC C WEAR COMP S, VIEEE, DOI [10.1109/APWCS.2010.43, DOI 10.1109/APWCS.2010.43]
   Joachimiak M, 2014, 3DTV C TRUE VIS CAPT, VIEEE, P1, DOI [10.1109/3DTV.2014.6874740, DOI 10.1109/3DTV.2014.6874740]
   Kim HG, 2017, IEEE T CIRC SYST VID, V27, P1435, DOI 10.1109/TCSVT.2016.2515360
   Lai Y, 2012, INT CONF ACOUST SPEE, P1449, DOI 10.1109/ICASSP.2012.6288164
   Lai-Man Po, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2589, DOI 10.1109/ICIP.2011.6116194
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Luo GB, 2020, IEEE T PATTERN ANAL, V42, P1289, DOI 10.1109/TPAMI.2019.2899837
   Luo GB, 2018, IEEE ACCESS, V6, P32874, DOI 10.1109/ACCESS.2018.2847312
   Meng-Sung W., 2012, SID S, V41, P1252, DOI [10.1889/1.3499895, DOI 10.1889/1.3499895]
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Mousavinia A., 2018, MULTIDIM SYST SIGN P, V30, P1
   Muddala SM, 2014, 3DTV CONF
   Nagoya University,, 3DV SEQUENCES NAGOYA
   Poznan University,, 3DV SEQUENCES POZNAN
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ramírez R, 2015, I SYMP CONSUM ELECTR
   Schmeing M, 2012, PATT REC ICPR 21 INT
   Schmeing M, 2015, IEEE T MULTIMEDIA, V17, P2160, DOI 10.1109/TMM.2015.2476372
   Tezuka T, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P124, DOI 10.1109/PCS.2015.7170060
   Vosters LPJ, 2013, PROC SPIE, V8650, DOI 10.1117/12.2005094
   Wang LH, 2015, MULTIMED TOOLS APPL, V74, P9529, DOI 10.1007/s11042-014-2133-9
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xin Tong, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P490, DOI 10.1109/PCS.2010.5702544
   Yao L, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0485-9
   Yao L, 2019, MULTIMED TOOLS APPL, V78, P19325, DOI 10.1007/s11042-019-7236-x
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhu LW, 2013, SIGNAL PROCESS-IMAGE, V28, P1342, DOI 10.1016/j.image.2013.08.005
   Zhu SP, 2019, IEEE ACCESS, V7, P115171, DOI 10.1109/ACCESS.2019.2935021
NR 46
TC 1
Z9 1
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20619
EP 20639
DI 10.1007/s11042-021-10732-3
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000626425600003
DA 2024-07-18
ER

PT J
AU Ahmed, I
   Khan, A
   Khan, A
   Mujahid, K
   Khan, N
AF Ahmed, Irfan
   Khan, Aftab
   Khan, Asfandyar
   Mujahid, Kamran
   Khan, Naveed
TI Efficient measurement matrix for speech compressive sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Sensing matrix; Speech signal recovery; Gaussian
   random matrix; Deterministic matrix
AB Signal sampling is an important concern for compressive sensing framework. The use of efficient sampling may enhance the overall performance by collecting informative samples. The work done in this paper is aimed to propose the efficient sampling matrix for speech compressive sensing by reviewing the reconstruction results obtained via conventionally used measurement matrices. Recently used measurement matrices are either randomly structured or deterministic in nature. Therefore, the prime objective of this work is to analyse speed and reconstruction performance of l(1)-norm minimization algorithm when samples are provided by the concerned sampling matrix. The speed and accuracy analysis is intended to propose efficient sampling matrix which can facilitate faithful signal reconstruction process for speech compressive sensing. The sampling matrices chosen for this work are Bernoulli random matrix, Gaussian random matrix, Hadamard matrix and Toeplitz matrix. The observed matrices are carefully adjusted to provide different range of sampling ratios for signal recovery process. In this work, the number of input samples are changed (from 10% to 40%) to search for the efficient sampling matrix which can survive the least possible number of samples. The performances of the sampling matrices are compared on the basis of Root Mean Squared Error (RMSE) values and reconstruction time (in seconds) is obtained via l(1) minimization method.
C1 [Ahmed, Irfan; Khan, Aftab] Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
   [Khan, Asfandyar; Mujahid, Kamran; Khan, Naveed] Univ Engn & Technol, Dept Elect Engn, Peshawar, Pakistan.
C3 University of Engineering & Technology Peshawar; University of
   Engineering & Technology Peshawar
RP Ahmed, I (corresponding author), Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
EM irfanahmed@uetpeshawar.edu.pk; aftab.khan@uetpeshawar.edu.pk;
   asfand.k92@gmail.com; kamran.mujahid@ymail.com; naveed88375@gmail.com
RI Ahmed, Irfan/CAF-8126-2022; Khan, Naveed/KCK-0156-2024; Khan,
   Naveed/AAM-2892-2021
OI Khan, Naveed/0000-0001-7667-8553; Mujahid, Kamran/0000-0002-4036-9019;
   Ahmed, Irfan/0000-0002-3489-3519
CR Ahmed I, 2020, ARAB J SCI ENG, V45, P1567, DOI 10.1007/s13369-019-04080-6
   Ahmed I, 2012, INT CONF ROBOT ARTIF, P139, DOI 10.1109/ICRAI.2012.6413380
   Ahmed Irfan., 2012, AUTOMATION COMPUTING, P1
   [Anonymous], 2017, 2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)
   Arjoune Y, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3576
   Bala S, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P81, DOI 10.1109/ISPCC.2015.7375002
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Carrillo RE, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0404-5
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Deng CW, 2010, IEEE INT CON MULTI, P462, DOI 10.1109/ICME.2010.5583387
   Dias U, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P265, DOI 10.1109/iMac4s.2013.6526420
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Haider H, 2014, 2014 WORLD CONGRESS ON SUSTAINABLE TECHNOLOGIES (WCST), P72, DOI 10.1109/WCST.2014.7030100
   Nguyen Thu L N, 2013, ScientificWorldJournal, V2013, P192795, DOI 10.1155/2013/192795
   Pearlsy PV, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P162, DOI 10.1109/ISED.2018.8704026
   Qaisar S, 2013, J COMMUN NETW-S KOR, V15, P443, DOI 10.1109/JCN.2013.000083
   Rahnavard N, 2017, ARXIV170303340
   Salan S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P252, DOI 10.1109/ICICICT1.2017.8342569
   Tang X., 2018, PROC 2 INT FORUM MAN
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wei ZR, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7979606
   Yin M, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/9641608
   Zhang ZH, 2016, ACSR ADV COMPUT, V48, P11
NR 23
TC 5
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20327
EP 20343
DI 10.1007/s11042-021-10657-x
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700003
DA 2024-07-18
ER

PT J
AU Xiang, T
   Xiao, HF
   Qin, X
AF Xiang, Tao
   Xiao, Hongfei
   Qin, Xue
TI Quality-distinguishing and patch-comparing no-reference image quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference image quality assessment; Convolutional neural network;
   Quality-distinguishing; Patch-comparing; Visual importance
ID CONVOLUTIONAL NEURAL-NETWORK; NATURAL SCENE STATISTICS; REGRESSION;
   MAGNITUDE
AB No-reference image quality assessment (NR-IQA) based on deep learning attracts a great research attention recently. However, its performance in terms of accuracy and efficiency is still under exploring. To address these issues, in this paper, we propose a quality-distinguishing and patch-comparing NR-IQA approach based on convolutional neural network (QDPC-CNN). We improve the prediction accuracy by two proposed mechanisms: quality-distinguishing adaption and patch-comparing regression. The former trains multiple models from different subsets of a dataset and adaptively selects one for predicting quality score of a test image according to its quality level, and the latter generates patch pairs for regression under different combination strategies to make better use of reference images in network training and enlarge training data at the same time. We further improve the efficiency of network training by a new patch sampling way based on the visual importance of each patch. We conduct extensive experiments on several public databases and compare our proposed QDPC-CNN with existing state-of-the-art methods. The experimental results demonstrate that our proposed method outperforms the others both in terms of accuracy and efficiency.
C1 [Xiang, Tao; Xiao, Hongfei; Qin, Xue] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Xiang, T (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM txiang@cqu.edu.cn
RI Xiang, Tao/N-3706-2016; qin, xue/KQV-3701-2024
OI Xiang, Tao/0000-0002-9439-4623; Xiang, Tao/0000-0002-0022-3082
FU National Natural Science Foundation of China [U20A20176, 62072062];
   Natural Science Foundation of Chongqing, China [cstc2019jcyjjqX0026]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. U20A20176 and 62072062), and the Natural Science Foundation
   of Chongqing, China (No. cstc2019jcyjjqX0026).
CR [Anonymous], 2016, P 2016 IEEE INT C CO
   [Anonymous], 2016, IEEE CCECE 2016
   [Anonymous], 2015, Live in the wild image quality challenge database
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   Chen DQ, 2020, IEEE T IMAGE PROCESS, V29, P6496, DOI 10.1109/TIP.2020.2990342
   Cheng ZX, 2017, IEEE INT SYM MULTIM, P77, DOI 10.1109/ISM.2017.21
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu J, 2018, IEEE T MULTIMEDIA, V20, P1140, DOI 10.1109/TMM.2017.2761993
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Pan D, 2018, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2018.00667
   Po LM, 2019, IEEE T CIRC SYST VID, V29, P1223, DOI 10.1109/TCSVT.2019.2891159
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sheikh H.R., 2005, LIVE IMAGE QUALITY A, V2
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu LY, 2017, IEEE T CYBERNETICS, V47, P1336, DOI 10.1109/TCYB.2017.2671898
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Ye P, 2013, PROC CVPR IEEE, P987, DOI 10.1109/CVPR.2013.132
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang P, 2015, PROC CVPR IEEE, P2394, DOI 10.1109/CVPR.2015.7298853
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P2676, DOI 10.1109/TIP.2019.2952010
   Zuo LX, 2016, IEEE IMAGE PROC, P2082, DOI 10.1109/ICIP.2016.7532725
NR 49
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19601
EP 19624
DI 10.1007/s11042-021-10577-w
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500004
DA 2024-07-18
ER

PT J
AU Khanzadi, P
   Majidi, B
   Adabi, S
   Patra, JC
   Movaghar, A
AF Khanzadi, Pouria
   Majidi, Babak
   Adabi, Sepideh
   Patra, Jagdish C.
   Movaghar, Ali
TI Robust fuzzy rough set based dimensionality reduction for big multimedia
   data hashing and unsupervised generative learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy rough set; Multimedia big data; Image hashing; Neural networks;
   Generative learning; Pattern recognition
ID IMAGE QUALITY
AB The amount of high dimensional data produced by visual sensors in the smart environments and by autonomous vehicles is increasing exponentially. In order to search and model this data for real-time applications, the dimensionality of the data should be reduced. In this paper, a novel dimensionality reduction algorithm based on fuzzy rough set theory, called Centralized Binary Mapping (CBM), is proposed. The fuzzy CBM kernel is used for extracting the central elements and the memory cells from the blocks of high dimensional data. The proposed applications of CBM in this paper include hashing and generative modelling of multimedia big data. The robustness of the proposed CBM based hashing algorithm is 10% higher than comparable methods. Furthermore, based on the CBM, a novel architecture for neural networks called Deep Root Dimensional Mapping (DRDM) is proposed. The DRDM is used for generative modelling of multimedia big data using a new autonomous vehicle visual navigation dataset as well as the standard datasets. The simulation results show that the proposed DRDM converges rapidly and the perceptual quality of the outputs at the same epoch is higher than generative adversarial networks. The proposed CBM can be used as a new data structures in various pattern recognition and machine learning tasks.
C1 [Khanzadi, Pouria; Adabi, Sepideh] Islamic Azad Univ, Dept Comp Engn, North Tehran Branch, Tehran, Iran.
   [Majidi, Babak] Khatam Univ, Dept Comp Engn, Tehran, Iran.
   [Majidi, Babak] York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
   [Patra, Jagdish C.] Swinburne Univ Technol, Sch Software & Elect Engn, Melbourne, Vic, Australia.
   [Movaghar, Ali] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; York University - Canada; Swinburne University
   of Technology; Sharif University of Technology
RP Majidi, B (corresponding author), Khatam Univ, Dept Comp Engn, Tehran, Iran.; Majidi, B (corresponding author), York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
EM b.majidi@khatam.ac.ir
RI Adabi, Sepideh/AAO-3029-2021; Majidi, Babak/AAB-2365-2019; Movaghar,
   Ali/B-3980-2011; Patra, Jagdish C/J-4895-2016
OI Adabi, Sepideh/0000-0003-4379-4528; Majidi, Babak/0000-0001-6309-6407;
   Movaghar, Ali/0000-0002-6803-6750; 
CR Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y
   An JY, 2019, IEEE ACCESS, V7, P20708, DOI 10.1109/ACCESS.2019.2896913
   Chen XQ, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0479-7
   Dai JH, 2018, IEEE T FUZZY SYST, V26, P2174, DOI 10.1109/TFUZZ.2017.2768044
   Deng YJ, 2018, IEEE T GEOSCI REMOTE, V56, P7183, DOI 10.1109/TGRS.2018.2849085
   Duan Y., 2020, IEEE GEOSCI REMOTE S, P1, DOI DOI 10.1109/LGRS.2020.3009144
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Fadaeddini A, 2018, 2018 2ND NATIONAL AND 1ST INTERNATIONAL DIGITAL GAMES RESEARCH CONFERENCE: TRENDS, TECHNOLOGIES, AND APPLICATIONS (DGRC), P118, DOI 10.1109/DGRC.2018.8712070
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gahar RM, 2019, IEEE ACCESS, V7, P151006, DOI 10.1109/ACCESS.2019.2945889
   Gao ZQ, 2021, IEEE T GEOSCI REMOTE, V59, P1718, DOI 10.1109/TGRS.2020.2998035
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Jeba JA, 2019, INT J CLOUD APPL COM, V9, P59, DOI 10.4018/IJCAC.2019010105
   Khanzadi P, 2017, 2017 IEEE 4 INT C KN
   Khanzadi P, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P440, DOI 10.1109/KBEI.2017.8325017
   Long ZG, 2020, IEEE ACCESS, V8, P27308, DOI 10.1109/ACCESS.2020.2971562
   Loy CC, HIGH QUALITY VIDEO G
   Ma ZM, 2018, IEEE ACCESS, V6, P55537, DOI 10.1109/ACCESS.2018.2871825
   Majidi B, ENABLING APPL DATA S, P471
   Majidi B, 2018, 2018 25 NAT 3 INT IR, P1
   Mohammadkhani MA, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019)
   Pang YW, 2019, IEEE T NEUR NET LEAR, V30, P2779, DOI 10.1109/TNNLS.2018.2886317
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Radford A., 2015, COMPUTER SCI
   Ran RS, 2022, IEEE T CYBERNETICS, V52, P2137, DOI 10.1109/TCYB.2020.3003620
   Schizas ID, 2020, IEEE T SIGNAL PROCES, V68, P3871, DOI 10.1109/TSP.2020.3003423
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Sharafi S, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P322, DOI [10.1109/KBEI.2019.8734904, 10.1109/kbei.2019.8734904]
   Shi GY, 2020, IEEE GEOSCI REMOTE S, V17, P1425, DOI 10.1109/LGRS.2019.2944970
   Tan AH, 2019, IEEE T FUZZY SYST, V27, P527, DOI 10.1109/TFUZZ.2018.2862870
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tian DY, 2021, IEEE T CYBERNETICS, V51, P3802, DOI 10.1109/TCYB.2019.2906658
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Ullo SL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113113
   Vahdat-Nejad H, 2018, INT J CLOUD APPL COM, V8, P1, DOI 10.4018/IJCAC.2018010101
   Wan LT, 2021, IEEE T INTELL TRANSP, V22, P4301, DOI 10.1109/TITS.2020.3009223
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang YY, 2018, IEEE T FUZZY SYST, V26, P1257, DOI 10.1109/TFUZZ.2017.2718492
   Yang YY, 2017, IEEE T FUZZY SYST, V25, P825, DOI 10.1109/TFUZZ.2016.2581186
   Zhang TY, 2022, IEEE T NEUR NET LEAR, V33, P392, DOI 10.1109/TNNLS.2020.3027852
NR 41
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17745
EP 17772
DI 10.1007/s11042-021-10571-2
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000001
DA 2024-07-18
ER

PT J
AU Zear, A
   Singh, PK
AF Zear, Aditi
   Singh, Pradeep Kumar
TI Secure and robust color image dual watermarking based on LWT-DCT-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Cryptography; Compression; Lifting wavelet
   transform
ID SCHEME; PROTECTION; DWT
AB Now days advancements in multimedia technology and Information and Communication technologies (ICTs) has raised various security related concerns. Digital image watermarking is one of the new and popular techniques for the protection of multimedia content. This paper proposes an approach for digital image watermarking in which Lifting wavelet transform (LWT), Discrete Cosine Transform (DCT) and Singular Value Decomposition (SVD) have been used. The host color image is decomposed using LWT and LH3, LL3 sub bands of the third level LWT are transformed by DCT and then SVD. Security of logo (image watermark) is enhanced by using message-digest (MD5) hash algorithm and then DCT-SVD are applied to it before embedding it into LH3 sub band. The robustness of Info (Text watermark) is increased by encoding it using Hamming error correcting code. Error correcting code increases the length of watermark therefore arithmetic coding is applied that provides lossless compression. Experimental results are computed for different color image models (RGB, YIQ, YCbCr) at different gain factors, size of text watermark, different types of cover image and for attacks. The proposed method has good performance for the imperceptibility of watermarked image and robustness of watermarks. The performance of this algorithm can be improved by using various optimization techniques.
C1 [Zear, Aditi] NIT, Comp Sci & Engn Dept, Hamirpur, Himachal Prades, India.
   [Singh, Pradeep Kumar] ABES Engn Coll, Ghaziabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Singh, PK (corresponding author), ABES Engn Coll, Ghaziabad, Uttar Pradesh, India.
EM aditizear93@gmail.com; pradeep_84cs@yahoo.com
RI Singh, Pradeep Kumar/M-4363-2016
OI Singh, Pradeep Kumar/0000-0002-7676-9014
CR Abdurrman, 2013, P WORLD C ENG LOND U, V3, P1
   Ahmidi N, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P709, DOI 10.1109/ITCC.2004.1286738
   [Anonymous], 2009, INT J COMPUT THEORY
   [Anonymous], 2013, INT J COMPUT APPL
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Arya M. S., 2011, 2011 IEEE International Conference on Electro/Information Technology (EIT 2011), DOI 10.1109/EIT.2011.5978552
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Boonyapalanant A, 2019, ADV INTELL SYST COMP, P258
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheng Mingzhi, 2012, Journal of Multimedia, V8, P299, DOI 10.4304/jmm.8.3.299-305
   Dagadu JC, 2018, MULTIMED TOOLS APPL, V77, P24289, DOI 10.1007/s11042-018-5725-y
   Dai Q., 2019, INNOVATION MED HEALT, V145, P93, DOI [10.1007/978-981-13-8566-7_9, DOI 10.1007/978-981-13-8566-7_9/COVER]
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Gul E, 2020, MULTIMED TOOLS APPL, V79, P31239, DOI 10.1007/s11042-020-09548-4
   Gunjal B.L., 2011, INT J COMPUT THEORY, V3, P714, DOI [10.7763/IJCTE.2011.V3.397, DOI 10.7763/IJCTE.2011.V3.397]
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Inamdar, 2014, HLTH INFORM INT J HI, V1, P27
   Jing Liu, 2019, Innovation in Medicine and Healthcare Systems, and Multimedia. Proceedings of KES-InMed-19 and KES-IIMSS-19 Conferences. Smart Innovation, Systems and Technologies (SIST 145), P157, DOI 10.1007/978-981-13-8566-7_15
   Jinna S. Kurshid, 2009, International Journal of Recent Trends in Engineering, V2, P191
   Kashyap N., 2012, Int J Mod Educ Comput Sci, V4, P50, DOI DOI 10.5815/IJMECS.2012.03.07
   Kokare, 2012, INT J COMPUTER APPL, V39, P10, DOI [10.5120/5078-7193, DOI 10.5120/5078-7193]
   Kumar A, 2016, USNC-URSI RADIO SCI, P21, DOI 10.1109/USNC-URSI.2016.7588492
   Lefèvre P, 2019, SIGNAL PROCESS-IMAGE, V74, P119, DOI 10.1016/j.image.2018.12.015
   Li MJ, 2020, IEEE ACCESS, V8, P72308, DOI 10.1109/ACCESS.2020.2987914
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Loukhaoukha K, 2009, 2009 11TH CANADIAN WORKSHOP ON INFORMATION THEORY, P177, DOI 10.1109/CWIT.2009.5069549
   Mohananthini N., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P100
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Nagpal Sujata, 2016, International Journal of Modern Education and Computer Science, V8, P46, DOI 10.5815/ijmecs.2016.04.06
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Poonam P., 2012, 2012 International Conference on Computing Sciences (ICCS), P82, DOI 10.1109/ICCS.2012.32
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Roy SK, 2021, MIN PROC EXT MET REV, V42, P242, DOI 10.1080/08827508.2020.1743290
   Saini H, 2014, IEEE INT ADV COMPUT, P985, DOI 10.1109/IAdCC.2014.6779457
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sharma A, 2015, PROCEDIA COMPUT SCI, V70, P778, DOI 10.1016/j.procs.2015.10.117
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh Amit Kumar, 2020, IT Professional, V22, P45, DOI 10.1109/MITP.2019.2961898
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Su QT, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P70
   Vafaei M., 2013, World Appl. Sci. J, V22, P1572
   Venkatram N., 2014, IMAGE, V20, P23
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Xuelong Hu, 2008, 2008 International Conference on Neural Networks and Signal Processing, P430, DOI 10.1109/ICNNSP.2008.4590387
   Yadav AK, 2015, INT CONF CONTEMP, P19, DOI 10.1109/IC3.2015.7346646
   Zear A., 2017, INT J INF COMPUT SEC, V9
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
NR 56
TC 28
Z9 28
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26721
EP 26738
DI 10.1007/s11042-020-10472-w
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000616467500002
DA 2024-07-18
ER

PT J
AU Nia, ZM
   Khayyambashi, MR
AF Nia, Zahra Movahedi
   Khayyambashi, Mohammad Reza
TI Improving content popularity prediction with k-means clustering and
   deep-belief networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content popularity prediction; Deep-belief network (DBN); K-means
   clustering with Pearson distance; User generated content (UGC)
ID RESTRICTED BOLTZMANN MACHINES; ALGORITHM; MODEL
AB User-Generated Content (UGC) is turning into the predominant type of internet traffic. Content popularity prediction plays a pivotal role in managing this large-scale traffic. As a result, popularity prediction is increasingly becoming an important area of research in computer networking. Generally, popularity prediction methods are classified into two groups, namely, feature-driven and early-stage. While feature-driven methods predict content popularity before publication, early-stage methods monitor early content popularities to forecast the future. Many papers have shown that early-stage popularity prediction performs better than feature-driven methods. In this paper, we improve the performance of early-stage popularity prediction by first, classifying the data into several clusters using k-means clustering with Pearson correlation distance, and then, training a Deep-Belief Network (DBN) for each cluster. We evaluate our method using a dataset of YouTube videos and show that using a generative model such as DBN for time series prediction significantly improves the performance. Numerical results indicate that our proposed method outperforms other state-of-the-art methods by reducing Mean Absolute Percentage Error (MAPE) and mean Relative Square Error (mRSE) by up to 47.86% and 25.18%.
C1 [Nia, Zahra Movahedi; Khayyambashi, Mohammad Reza] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Khayyambashi, MR (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM z.movahedinia@eng.ui.ac.ir; m.r.khayambashi@comp.ui.ac.ir
RI Movahedi Nia, Zahra/JTV-3994-2023
CR Almeida, WSDM 13, P365, DOI 10.1145/2433396.2433443
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   Bao Z, 2017, IEEE BEHAV EC SOCIOC, DOI 10.1109/BESC.2017.8256373
   Ben Hassine N, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2083, DOI 10.1109/PIMRC.2015.7343641
   Borghol Y, 2011, PERFORM EVALUATION, V68, P1037, DOI 10.1016/j.peva.2011.07.008
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Gheisari M, 2019, IEEE ACCESS, V7, P85123, DOI 10.1109/ACCESS.2019.2920879
   Google Developers, ADD YOUTUBE FUNCT YO
   GURSUN G, 2011, IEEE INFOCOM SER
   Hassine, 2017, IEEE WIRELESS DAYS, DOI 10.1109/WD.2017.7918125
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hoiles W, 2017, IEEE T KNOWL DATA EN, V29, P1426, DOI 10.1109/TKDE.2017.2682858
   Hou TT, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3706
   Hraskoa R, 2015, PROCEDIA COMPUT SCI, V55, P990, DOI 10.1016/j.procs.2015.07.104
   Ibrahimi, 2017, IEEE WINCOM, DOI 10.1109/WINCOM.2017.8238196
   Li CY, 2016, IEEE ACCESS, V4, P1630, DOI 10.1109/ACCESS.2016.2552218
   Li YD, 2018, 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P767, DOI 10.1109/WCICA.2018.8630557
   Liu Y, 2019, IEEE ACCESS, V7, P27555, DOI 10.1109/ACCESS.2019.2901525
   MA C, 2017, ACM CIKM 17
   Martin T, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P683, DOI 10.1145/2872427.2883001
   Namous F, 2018, 2018 FIFTH HCT INFORMATION TECHNOLOGY TRENDS (ITT): EMERGING TECHNOLOGIES FOR ARTIFICIAL INTELLIGENCE, P180, DOI 10.1109/CTIT.2018.8649529
   Ouyang SX, 2016, IEEE ACCESS, V4, P3026, DOI 10.1109/ACCESS.2016.2580911
   Rahman S, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P797, DOI [10.1109/ICOIN48656.2020.9016437, 10.1109/icoin48656.2020.9016437]
   Ross KW, 2013, COMPUTER NETWORKING, P602
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   TAN J, 2020, WILEY T EMERGING TEL, V31
   Tan ZY, 2019, IEEE T MULTIMEDIA, V21, P147, DOI 10.1109/TMM.2018.2845688
   Tan ZY, 2016, IEEE T BROADCAST, V62, P436, DOI 10.1109/TBC.2016.2540522
   Wang XM, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P847, DOI [10.1109/ITNEC.2019.8729161, 10.1109/itnec.2019.8729161]
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yang MM, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P944, DOI 10.1109/ICDMW.2014.72
   Zhu CG, 2017, IEEE ACCESS, V5, P24593, DOI 10.1109/ACCESS.2017.2767104
NR 34
TC 2
Z9 3
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15745
EP 15764
DI 10.1007/s11042-020-10463-x
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900005
DA 2024-07-18
ER

PT J
AU Tabish, M
   Tanooli, ZUR
   Shaheen, M
AF Tabish, Malik
   Tanooli, Zahoor-ur-Rehman
   Shaheen, Muhammad
TI Activity recognition framework in sports videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VGG; Visual geometry group; ResNet; Residual networks; Neural network;
   Convolutional neural network; K-means clustering; Inception; GoogleNet
AB Recent advancements in activity recognition from sports videos have attracted wide scientific interest of the Computer Vision community. However, the activity recognition problem from cricket video sequences is largely under-represented in the literature. This paper aims to devise a convolutional neural network (CNN) based model for sports activity recognition. The model is trained on the pre-trained VGG16, VGG19, ResNet50, and Inception V3 Models and tested on the clustered cricket videos frames extracted from the data set especially prepared for this research. The clustering of the frames is done by using K-Mean clustering algorithm. K-Fold cross validation is done which gave an accuracy of 99% on clustered data and 91% on un-clustered data. The accuracy and time complexity of the proposed method is better as compared to the state of the art methods used for activity recognition from videos.
C1 [Tabish, Malik; Tanooli, Zahoor-ur-Rehman] COMSATS Univ Islamabad, Dept Comp Sci, Attock, Pakistan.
   [Shaheen, Muhammad] Fdn Univ Islamabad, Fac Engn & IT, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); Quaid I Azam University
RP Tanooli, ZUR (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Attock, Pakistan.
EM xahoor@gmail.com
RI Tabish, Mohammad/AAH-6504-2020; Shaheen, Prof. Dr.
   Muhammad/AGH-3143-2022
OI Tabish, Mohammad/0000-0001-8737-4088; Shaheen, Prof. Dr.
   Muhammad/0000-0003-3647-1261
CR [Anonymous], 2015, In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Badran, 2018, SPORTS VIDEO CLASSIF
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hari R, 2014, ANNU IEEE IND CONF
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong YX, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam MS, 2018, INT CONF INFRA MILLI
   Jayanth SB, 2014, ELECT LETT COMPUT VI, V13, P33
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Liu, 2010, 2010 IEEE INT C AC S
   Misra I, 2015, P IEEE C COMP VIS PA
   Mumtaz A, 2014, PROC CVPR IEEE, P368, DOI 10.1109/CVPR.2014.54
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shri SJ, 2019, COMPUT COMMUN, V147, P35, DOI 10.1016/j.comcom.2019.07.027
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tsunoda T, 2017, P IEEE C COMP VIS PA
   Venkatesh, VIDEO ABSTRACT SYSTE, V3, P3
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Yan X, 2014, PATTERN RECOGN, V47, P1626, DOI 10.1016/j.patcog.2013.10.019
   Ye, 2015, P 5 ACM INT C MULT R
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 37
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15101
EP 15123
DI 10.1007/s11042-021-10519-6
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000614681600005
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, BK
AF Kumar, Sanjay
   Singh, Binod Kumar
TI DWT based color image watermarking using maximum entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; DWT; YCbCr color space; Imperceptibility; Robustness
ID ALGORITHM; DCT; SVD
AB Digital watermarking techniques can be used to solve the authenticity and copyright protection issue of images. In this work, the authors have proposed an adaptive color image watermarking scheme based on DWT by combining alpha blending and entropy concept. Entropy is one of the important features of images and can be used for watermark insertion. There are two domains in which watermarking can be carried out i.e. spatial and transform domain. Here, watermark embedding is carried out in the of Y component of YCbCr color space. This paper also lays down the proper justification for the selection of the Y component to embed the watermark. The performance of the proposed scheme is tested over seven different standard color images. The average PSNR and SSIM of the proposed scheme are 51.6145 dB and 0.9992 respectively. Whereas, NCC of the proposed scheme under no attack condition is 1. Further, the performance of the proposed scheme is compared with other state-of-the-art techniques.
C1 [Kumar, Sanjay; Singh, Binod Kumar] NIT Jamshedpur, Dept Comp Sci & Engn, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), NIT Jamshedpur, Dept Comp Sci & Engn, Jharkhand, India.
EM 2017rscs001@nitjsr.ac.in; bksingh.cse@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Kumar, Dr. Sanjay/V-3889-2019
OI Singh, Binod/0000-0002-2697-8918; Kumar, Dr. Sanjay/0000-0002-4564-1085
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Abraham J, 2016, J KING SAUD U COMPUT
   Al-Otum HM, 2010, SIGNAL PROCESS, V90, P2498, DOI 10.1016/j.sigpro.2010.02.017
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Desai SD, 2017, STUD COMPUT INTELL, V660, P15, DOI 10.1007/978-3-319-44790-2_2
   Fragoso-Navarro E, 2018, IEEE ACCESS, V6, P75767, DOI 10.1109/ACCESS.2018.2883322
   Huang Y, 2019, IEEE T MULTIMEDIA, V21, P2447, DOI 10.1109/TMM.2019.2907475
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Khalili M, 2013, IET SIGNAL PROCESS, V7, P177, DOI 10.1049/iet-spr.2012.0380
   Koley S, 2019, J KING SAUD U COMPUT
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149
   Kumar S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1802, DOI 10.1109/RTEICT.2016.7808145
   Kumar S, 2017, IET BIOMETRICS, V6, P139, DOI 10.1049/iet-bmt.2016.0017
   Lakrissi Y, 2018, MULTIMED TOOLS APPL, V77, P13531, DOI 10.1007/s11042-017-4974-5
   Liu KC, 2010, AEU-INT J ELECTRON C, V64, P112, DOI 10.1016/j.aeue.2008.11.006
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Lu CS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P483, DOI 10.1109/ICIP.2001.958533
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Ntalianis KS, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P188, DOI 10.1109/ICCE.2002.1013985
   Pandey MK, 2019, MICROSYST TECHNOL, V25, P3071, DOI 10.1007/s00542-018-4162-1
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Pla OG, 2004, PROC SPIE, V5306, P571, DOI 10.1117/12.531459
   Prabha K, 2019, MULTIMEDIA TOOLS APP, P1
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Roy A, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500158
   Roy A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P537, DOI 10.1109/SPIN.2015.7095399
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Salimi L, 2020, MULTIMED TOOLS APPL, V79, P11357, DOI 10.1007/s11042-019-08455-7
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Sharma VK, 2018, IET IMAGE PROCESS, V12, P1065, DOI 10.1049/iet-ipr.2017.0965
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh RK, 2018, J INFORM OPTIM SCI, V39, DOI 10.1080/02522667.2017.1372153
   Singh R, 2020, IET IMAGE PROCESS, V14, P2052, DOI 10.1049/iet-ipr.2019.1059
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Swanson MD, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P369, DOI 10.1109/MMSP.1997.602663
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
NR 44
TC 27
Z9 28
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15487
EP 15510
DI 10.1007/s11042-020-10322-9
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400008
DA 2024-07-18
ER

PT J
AU Zhang, J
   He, XH
   Qing, LB
   Liu, LP
   Luo, XD
AF Zhang, Jin
   He, Xiaohai
   Qing, Linbo
   Liu, Luping
   Luo, Xiaodong
TI Cross-modal multi-relationship aware reasoning for image-text matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-text matching; Visual multi-relationship; Graph neural network;
   Cross-modal retrieval
ID LANGUAGE; NETWORK
AB Cross-modal image-text matching has attracted considerable interest in both computer vision and natural language processing communities. The main issue of image-text matching is to learn the compact cross-modal representations and the correlation between image and text representations. However, the image-text matching task has two major challenges. First, the current image representation methods focus on the semantic information and disregard the spatial position relations between image regions. Second, most existing methods pay little attention to improving textual representation which plays a significant role in image-text matching. To address these issues, we designed a decipherable cross-modal multi-relationship aware reasoning network (CMRN) for image-text matching. In particular, a new method is proposed to extract multi-relationship and to learn the correlations between image regions, including two kinds of visual relations: the geometric position relation and semantic interaction. In addition, images are processed as graphs, and a novel spatial relation encoder is introduced to perform reasoning on the graphs by employing a graph convolutional network (GCN) with attention mechanism. Thereafter, a contextual text encoder based on Bidirectional Encoder Representations from Transformers is adopted to learn distinctive textual representations. To verify the effectiveness of the proposed model, extensive experiments were conducted on two public datasets, namely MSCOCO and Flickr30K. The experimental results show that CMRN achieved superior performance when compared with state-of-the-art methods. On Flickr30K, the proposed method outperforms state-of-the-art methods more than 7.4% in text retrieval from image query, and 5.0% relatively in image retrieval with text query (based on Recall@1). On MSCOCO, the performance reaches 73.9% for text retrieval and 60.4% for image retrieval (based on Recall@1).
C1 [Zhang, Jin; He, Xiaohai; Qing, Linbo; Liu, Luping; Luo, Xiaodong] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
C3 Sichuan University
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM hxh@scu.edu.cn
RI Luo, Xiaodong/G-5953-2011; LIU, LUPING/T-7934-2019
FU National Natural Science Foundation of China [61871278]; Industrial
   Cluster Collaborative Innovation Project of Chengdu
   [2016-XT00-00015-GX]; Sichuan Science and Technology Program
   [2018HH0143]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61871278, the Industrial Cluster Collaborative
   Innovation Project of Chengdu (no. 2016-XT00-00015-GX), the Sichuan
   Science and Technology Program (no. 2018HH0143).
CR Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Amato G, 2020, ARXIV200409144
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen J, 2019, FUTURE GENER COMP SY, V91, P465, DOI 10.1016/j.future.2018.08.024
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Cornia M, 2020, MULTIMED TOOLS APPL, V1
   Devlin J., 2018, BERT PRE TRAINING DE
   Faghri F, 2018, P BRIT MACH VIS C, P1
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Y, 2018, Scene Graph Reasoning with Prior Visual Relationship for Visual Question Answering
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Jia Y, 2019, ARXIV190601290
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li S, 2017, IEEE I CONF COMP VIS, P1908, DOI 10.1109/ICCV.2017.209
   Li Y., 2016, P 4 INT C LEARNING R
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Liu C, 2020, ARXIV200400277
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu Y, 2019, PATTERN RECOGN, V93, P365, DOI 10.1016/j.patcog.2019.05.008
   Lu JS, 2019, ADV NEUR IN, V32
   Ma L, 2019, NEUROCOMPUTING, V345, P36, DOI 10.1016/j.neucom.2018.11.089
   Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Qi D, 2020, CoRR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Trott A, 2018, ARXIV171208697
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic Petar, 2018, INT C LEARN REPR
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Wang T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P12, DOI 10.1145/3343031.3350875
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3792
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang Y., 2018, 6 INT C LEARN REPR I
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 57
TC 2
Z9 3
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12005
EP 12027
DI 10.1007/s11042-020-10466-8
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000612271000004
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhang, MZ
AF Wang, Xingyuan
   Zhang, Maozhen
TI A new image encryption algorithm based on ladder transformation and DNA
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA plane; Chaotic system; Scrambling algorithm
AB In this paper, a new scrambling algorithm is proposed to reduce the correlation between the image pixels in three directions. In this paper, this algorithm is called ladder scrambling, and the image is scrambled multiple times in the form of diagonal lines. In terms of diffusion, DNA coding is used, and the secondary processing of the image is performed through DNA coding to change the pixel value of the image. The final encrypted image is affected by three conditions: the number of scrambling algorithms, the selection of DNA coding rules, and the key of the chaotic system. Theoretical analysis and experimental results show that the algorithm is safe and effective.
C1 [Wang, Xingyuan; Zhang, Maozhen] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116024, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn; zhang.maozhen@foxmail.com
RI Wang, Xing-yuan/I-6353-2015
OI Zhang, Maozhen/0000-0002-4750-0841
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program [XLYC1802013]; Key R&D Projects of Liaoning
   Province [2019020105-JH2/103]; Jinan City '20 universities' Funding
   Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Bouhous A, 2018, OPT LASER TECHNOL, V108, P162, DOI 10.1016/j.optlastec.2018.06.052
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Deng, 2015, INT C APPL TECHN INF, P36
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Lian SG, 2009, NEUROCOMPUTING, V72, P1296, DOI 10.1016/j.neucom.2008.11.005
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu Xiaolin, 2010, Proceedings of the 2010 IEEE International Conference on Granular Computing (GrC-2010), P556, DOI 10.1109/GrC.2010.11
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YP, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P347, DOI 10.1109/ISECS.2008.142
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 33
TC 11
Z9 12
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13339
EP 13365
DI 10.1007/s11042-020-10318-5
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300006
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Magdy, T
   Lashin, NA
AF Hosny, Khalid M.
   Magdy, Taher
   Lashin, Nabil A.
TI Improved color texture recognition using multi-channel orthogonal
   moments and local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color textures; Classification; Multi-Channel orthogonal descriptors;
   Local binary pattern
AB The texture is an essential characteristic of the image. So, recognition of texture is increasingly becoming a major topic in many image processing applications such as image retrieving, image classification, similarity, object recognition, and detection. The recognition of texture tries to allocate an unidentified image to one of the identified class of textures. This paper proposes a novel feature extraction technique for classification and recognition of color texture. The significant advantage of the introduced method is that it combines the extraction of local and global features of the color texture by using Local Binary Pattern (LBP) and multi-channel orthogonal radial substituted Chebyshev moments, respectively. Relevant features (local or global) provides discriminatory information that used to differentiate one object from another. Global features represent the image as a whole, while local features represent a specific part of the image. We performed experiments using challenging datasets: (Outex, ALOT) to test the efficacy of our image classification descriptors. The result of this approach has said that our descriptor is valid, competitive, discriminatory, and exceeds the current state-of-art methods.
C1 [Hosny, Khalid M.; Lashin, Nabil A.] Zagazig Univ, Informat Technol Dept, Zagazig 44519, Egypt.
   [Magdy, Taher] Sinai Univ, Comp Sci Dept, Arish, North Sinai, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Sinai University
RP Hosny, KM (corresponding author), Zagazig Univ, Informat Technol Dept, Zagazig 44519, Egypt.
EM k_hosny@yahoo.com
RI Hosny, Khalid M./B-1404-2008
OI Hosny, Khalid M./0000-0001-8065-8977
CR Abd Elaziz M, 2019, SOFT COMPUT, V23, P9573, DOI 10.1007/s00500-018-3521-2
   Bharathi VS, 2008, PATTERN RECOGN LETT, V29, P1868, DOI 10.1016/j.patrec.2008.06.003
   Padierna LC, 2018, PATTERN RECOGN, V84, P211, DOI 10.1016/j.patcog.2018.07.010
   Chen, 2014, EURASIP J ADV SIGNAL
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Di Ruberto C, 2018, PATTERN RECOGN, V83, P498, DOI 10.1016/j.patcog.2018.06.012
   Gao ZF, 2020, IEEE INTERNET THINGS, V7, P4092, DOI 10.1109/JIOT.2019.2963701
   Guo FX, 2017, DIGIT SIGNAL PROCESS, V62, P249, DOI 10.1016/j.dsp.2016.12.008
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hosny Khalid Mohamed, 2011, Journal of Computer Sciences, V7, P715, DOI 10.3844/jcssp.2011.715.722
   Hosny K.M., 2019, PATTERN RECOGN, V78, P376
   Hosny KM, 2007, PATTERN RECOGN, V40, P3597, DOI 10.1016/j.patcog.2007.04.014
   Hosny KM, 2019, PATTERN ANAL APPL, V22, P1105, DOI 10.1007/s10044-018-0740-1
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Hosny KM, 2018, J MATH IMAGING VIS, V60, P717, DOI 10.1007/s10851-018-0786-0
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Hosny KM, 2014, ARAB J SCI ENG, V39, P7097, DOI 10.1007/s13369-014-1336-8
   Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Karakasis EG, 2015, PATTERN RECOGN LETT, V55, P22, DOI 10.1016/j.patrec.2015.01.005
   Khan S, 2019, IEEE INTERNET THINGS, V6, P9237, DOI 10.1109/JIOT.2019.2896120
   Liu C, 2012, IET IMAGE PROCESS, V6, P996, DOI 10.1049/iet-ipr.2011.0348
   Mäenpää T, 2002, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2002.1044840
   Muhammad K, 2020, IEEE INTERNET THINGS, V7, P4455, DOI 10.1109/JIOT.2019.2950469
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainen J., 2002, WORKSH TEXT AN MACH
   Rizzini DL, 2018, PATTERN RECOGN, V84, P182, DOI 10.1016/j.patcog.2018.07.017
   Singh C, 2018, OPT LASER TECHNOL, V106, P234, DOI 10.1016/j.optlastec.2018.03.033
   Singh C, 2018, DIGIT SIGNAL PROCESS, V78, P376, DOI 10.1016/j.dsp.2018.04.001
   Singh C, 2013, INFORM SCIENCES, V233, P255, DOI 10.1016/j.ins.2013.01.012
   Singh C, 2012, OPT LASER ENG, V50, P655, DOI 10.1016/j.optlaseng.2011.11.012
   Suk T, 2009, LECT NOTES COMPUT SC, V5702, P334, DOI 10.1007/978-3-642-03767-2_41
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   TUCERYAN M, 1994, PATTERN RECOGN LETT, V15, P659, DOI 10.1016/0167-8655(94)90069-8
   Vijayalakshmi B, 2016, CURR SCI INDIA, V110, P687, DOI 10.18520/cs/v110/i4/687-691
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   Wang XY, 2015, OPT LASER TECHNOL, V66, P78, DOI 10.1016/j.optlastec.2014.07.020
   Yang JW, 2019, PATTERN RECOGN, V85, P37, DOI 10.1016/j.patcog.2018.07.036
NR 41
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13179
EP 13194
DI 10.1007/s11042-020-10444-0
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607369000002
DA 2024-07-18
ER

PT J
AU El-Khamy, SE
   Mohamed, AG
AF El-Khamy, Said E.
   Mohamed, Amira G.
TI An efficient DNA-inspired image encryption algorithm based on
   hyper-chaotic maps and wavelet fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Image encryption; DNA; Hyper map; Performance analysis
ID SEQUENCE OPERATION; PERMUTATION; SECURE; SYSTEM
AB This paper introduces an efficient image encryption method which is inspired by Deoxyribo Nucleic Acid (DNA) nitrogenous bases. Amongst its advantages is that it is highly sensitive to many types of attacks. A confused version of an image (using a simple chaotic map) is DNA coded using its four types of nitrogenous bases. The resultant image made of DNA sequences is transformed into four sub-images A, C, G, and T, DNA's bases. Chen's hyper-chaotic map is used to diffuse the resultant images, according to a control code. The four DNA images are then combined using a wavelet confusion algorithm to produce an encrypted image. Numerical simulation was used to examine the effectiveness of the encrypted image against different attacks. The results were compared to those of other encryption algorithms and proved that the proposed encryption method delivers better results than other conventional ones including DNA based with different chaotic maps and double random phase encoding.
C1 [El-Khamy, Said E.] Alexandria Univ, Fac Engn, Alexandria, Egypt.
   [Mohamed, Amira G.] Alexandria Higher Inst Engn & Technol AIET, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP El-Khamy, SE (corresponding author), Alexandria Univ, Fac Engn, Alexandria, Egypt.
EM elkhamy@ieee.org; eng_amira90@yahoo.com
RI Mohamed, Amira/HLV-8476-2023; Mohamed, Amira G./AAU-3050-2020
CR Ahmad J, 2015, WIRELESS PERS COMMUN, V84, P901, DOI 10.1007/s11277-015-2667-9
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Anwar T., 2014, Int. J. Bio-Sci. Bio-Technol., V6, P215, DOI DOI 10.14257/IJBSBT.2014.6.5.22
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Balaska N, 2020, IET IMAGE PROCESS, V14, P1120, DOI 10.1049/iet-ipr.2019.0671
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   Hashemi Y, 2013, International Journal of Research in Computer Science, V3, P27
   Hazra A., 2018, INT J NETW SECUR, V20, P1093
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Jia LX, 2010, CHINESE PHYS B, V19, DOI 10.1088/1674-1056/19/10/100501
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Liu XB, 2019, IEEE ACCESS, V7, P57188, DOI 10.1109/ACCESS.2019.2914184
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Sun SL, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.116117
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, IEEE ACCESS, V8, P68533, DOI 10.1109/ACCESS.2020.2986831
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xue W, 2012, PROCEDIA ENGINEER, V29, P1264, DOI 10.1016/j.proeng.2012.01.124
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhu ZL, 2009, 2009 INTERNATIONAL WORKSHOP ON CHAOS-FRACTALS THEORIES AND APPLICATIONS (IWCFTA 2009), P260, DOI 10.1109/IWCFTA.2009.61
NR 39
TC 23
Z9 23
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23319
EP 23335
DI 10.1007/s11042-021-10527-6
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000607038100005
DA 2024-07-18
ER

PT J
AU Huddar, MG
   Sannakki, SS
   Rajpurohit, VS
AF Huddar, Mahesh G.
   Sannakki, Sanjeev S.
   Rajpurohit, Vijay S.
TI Attention-based multimodal contextual fusion for sentiment and emotion
   classification using bidirectional LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal fusion; Contextual information; Attention model;
   Bidirectional LSTM
AB Due to the availability of an enormous amount of multimodal content on the social web and its applications, automatic sentiment analysis, and emotion detection has become an important and widely researched topic. Improving the quality of multimodal fusion is an important issue in this field of research. In this paper, we present a novel attention-based multimodal contextual fusion strategy, which extract the contextual information among the utterances before fusion. Initially, we fuse two-two modalities at a time and finally, we fuse all three modalities. We use a bidirectional LSTM with an attention model for extracting important contextual information among the utterances. The proposed model was tested on IEMOCAP dataset for emotion classification and CMU-MOSI dataset for sentiment classification. By incorporating the contextual information among utterances in the same video, our proposed method outperforms the existing methods by over 3% in emotion classification and over 2% in sentiment classification.
C1 [Huddar, Mahesh G.] Hirasugar Inst Technol, Dept Comp Sci & Engn, Nidasoshi, Belagavi, India.
   [Sannakki, Sanjeev S.; Rajpurohit, Vijay S.] Gogte Inst Technol, Dept Comp Sci & Engn, Belagavi, India.
RP Huddar, MG (corresponding author), Hirasugar Inst Technol, Dept Comp Sci & Engn, Nidasoshi, Belagavi, India.
EM mailtomgh1@gmail.com; sannakkisanjeev@gmail.com; vijaysr2k@yahoo.com
RI Rajpurohit/AGF-9902-2022; Huddar, Mahesh G./S-4686-2019; RAJPUROHIT,
   VIJAY/ADR-6899-2022; Sannakki, Sanjeev/AAX-4145-2021
OI Huddar, Mahesh G./0000-0002-4344-6024; RAJPUROHIT,
   VIJAY/0000-0003-0659-296X; 
CR [Anonymous], 2013, ACL
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Celli F, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1245, DOI 10.1145/2647868.2647870
   Chen LS, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P366, DOI 10.1109/AFGR.1998.670976
   de Kok S, 2018, PROG ARTIF INTELL, V7, P295, DOI 10.1007/s13748-018-0163-7
   Ellis JA, 2014, EXPERT REV MOL MED, V16, DOI 10.1017/erm.2014.5
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Gohil S, 2018, JMIR PUBLIC HLTH SUR, V4, P72, DOI 10.2196/publichealth.5789
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gupta P, 2016, INT CONF COMP COMMUN
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huddar Mahesh G., 2019, International Journal of Computer Sciences and Engineering, V7, P876
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   King DB, 2015, ACS SYM SER, V1214, P1
   Kirilenko AP, 2018, J TRAVEL RES, V57, P1012, DOI 10.1177/0047287517729757
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Korayem M, 2012, COMM COM INF SC, V322, P128
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Lyu K, 2016, WIRELESS PERS COMMUN, V89, P941, DOI 10.1007/s11277-016-3346-1
   Mariéthoz J, 2005, IEEE SIGNAL PROC LET, V12, P532, DOI 10.1109/LSP.2005.847860
   Mars A, 2017, PROCEDIA COMPUT SCI, V112, P906, DOI 10.1016/j.procs.2017.08.114
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Mohammad SM, 2013, ARXIV PREPRINT ARXIV
   Nagamma P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P933, DOI 10.1109/CCAA.2015.7148530
   Nalisnick ET, 2013, PROC INT CONF DOC, P758, DOI 10.1109/ICDAR.2013.155
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Peng BL, 2015, LECT NOTES COMPUT SC, V9042, P66, DOI 10.1007/978-3-319-18117-2_5
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Ramteke J, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P107
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Rozgic V, 2012, ASIAPAC SIGN INFO PR
   Teh YW, 2001, ADV NEUR IN, V13, P908
   Thakor P, 2015, PROCEDIA COMPUT SCI, V53, P199, DOI 10.1016/j.procs.2015.07.295
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
NR 48
TC 24
Z9 25
U1 3
U2 87
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13059
EP 13076
DI 10.1007/s11042-020-10285-x
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607038100006
DA 2024-07-18
ER

PT J
AU Hjouji, A
   El-Mekkaoui, J
   Qjidaa, H
AF Hjouji, Amal
   El-Mekkaoui, Jaouad
   Qjidaa, Hassan
TI New set of non-separable 2D and 3D invariant moments for image
   representation and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal invariant moments; Non-separable shifted Legendre polynomial;
   Non-separable shifted Jacobi polynomial image recognition; Image
   classification
ID ROTATION; FORMS
AB The extraction of feature vectors of the images is the most important step in image recognition, because it allows a good description of the forms to be recognized. This step is an operation that makes it possible to convert an image into a vector of real or complex values that can serve as a signature for this image. For an accurate recognition system, the used feature vector must be invariant to the three image transformations (translation, rotation and scale), which means that, the descriptor vectors of the image and the transformed image by translation, rotation or scale must be equal. Given the importance of moments and their invariants in pattern recognition and imaging, based on Newton's binomial and trinomial formulas and the normalized central moments, we construct in this paper four new series of moments for 2D and 3D image recognition, which are invariant to translation, scaling and rotation (TSR): the first is a set of non-orthogonal moment invariants for 2D images (2dMIs), the second is a set of orthogonal moment invariants for 2D images (2dOMIs), the third is a set of non-orthogonal moment invariants for 3D images (3dMIs) and the fourth is a set of orthogonal moment invariants for 3D images (3dOMIs). Using the proposed invariant moments (2dMIs), (2dOMIs), (3dMIs) and (3dOMIs), we construct two types of image descriptor vectors for 2D images and two types for 3D images, which are invariant to translation, rotation and scale. A series of experiments is performed to validate this new set of invariant moments and compare its performance with the existing invariants moments. The obtained results ensure the superiority of the proposed moments over all existing moments in image recognition. Experiments on processing time show that the proposed method is faster than the existing orthogonal invariant moments.
C1 [Hjouji, Amal] Sultan Moulay Slimane Univ, TIAD Lab, Beni Mellal, Morocco.
   [El-Mekkaoui, Jaouad; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
   [El-Mekkaoui, Jaouad] Sidi Mohamed Ben Abdellah Univ, TIN Lab, Fes, Morocco.
   [Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, LESSI Lab, Fes, Morocco.
C3 Sultan Moulay Slimane University of Beni Mellal; Sidi Mohamed Ben
   Abdellah University of Fez; Sidi Mohamed Ben Abdellah University of Fez;
   Sidi Mohamed Ben Abdellah University of Fez
RP El-Mekkaoui, J (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.; El-Mekkaoui, J (corresponding author), Sidi Mohamed Ben Abdellah Univ, TIN Lab, Fes, Morocco.
EM Jawad.mekkaou@gmail.com
OI Hassan, qjidaa/0000-0003-4505-5243; Hjouji, Amal/0000-0001-8932-9061;
   Jaouad, EL-MEKKAOUI/0000-0002-9209-7086
CR Batioua I, 2020, MULTIMED TOOLS APPL, V79, P13217, DOI 10.1007/s11042-019-08083-1
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   CYGANSKI D, 1985, IEEE T PATTERN ANAL, V7, P662, DOI 10.1109/TPAMI.1985.4767722
   Doha EH, 2013, APPL MATH COMPUT, V219, P8042, DOI 10.1016/j.amc.2013.01.051
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   Flusser J, 2003, IEEE T PATTERN ANAL, V25, P234, DOI 10.1109/TPAMI.2003.1177154
   Flusser J, 2016, 2D AND 3D IMAGE ANAL, DOI [10.1002/9781119039402, DOI 10.1002/9781119039402]
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Guo X, 1993, LECT NOTES COMPUTER, V719, DOI [10.1007/3-540-57233-3_67, DOI 10.1007/3-540-57233-3_67]
   Hjouji A, 2019, PROCEDIA COMPUT SCI, V148, P154, DOI 10.1016/j.procs.2019.01.019
   Hjouji A, 2020, MULTIMED TOOLS APPL, V79, P14225, DOI 10.1007/s11042-020-08648-5
   Hjouji A, 2020, J MATH IMAGING VIS, V62, P606, DOI 10.1007/s10851-020-00948-7
   Hjouji A, 2019, PATTERN RECOGN IMAGE, V29, P296, DOI 10.1134/S1054661819020020
   Hjouji A, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0187-6
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Suk T, 2015, PATTERN RECOGN, V48, P3516, DOI 10.1016/j.patcog.2015.05.007
   Suk T, 2014, SYMMETRY-BASEL, V6, P722, DOI 10.3390/sym6030722
   Suk T, 2011, LECT NOTES COMPUT SC, V6855, P212, DOI 10.1007/978-3-642-23678-5_24
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Xiao B, 2014, IMAGE VISION COMPUT, V32, P994, DOI 10.1016/j.imavis.2014.09.002
   Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001
   Xu D, 2006, INT C PATT RECOG, P544
   Yang JW, 2019, PATTERN RECOGN, V85, P37, DOI 10.1016/j.patcog.2018.07.036
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 30
TC 5
Z9 5
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12309
EP 12333
DI 10.1007/s11042-020-10356-z
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606409000002
DA 2024-07-18
ER

PT J
AU Thamizhvani, TR
   Ahmed, KFT
   Hemalatha, RJ
   Dhivya, AJA
   Chandrasekaran, R
AF Thamizhvani, T. R.
   Ahmed, K. F. Tanveer
   Hemalatha, R. J.
   Dhivya, A. Josephin Arockia
   Chandrasekaran, R.
TI Enhancement of MRI images of hamstring avulsion injury using histogram
   based techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Avulsion injuries; Contrast enhancement;
   Histogram clipping; Decision tree classifier
ID EQUALIZATION; BRIGHTNESS
AB A novel histogram based image enhancement technique is introduced to visualize the image more effectively. The proposed method uses hamstring avulsion injury Magnetic Resonance Imaging (MRI) images from the database. First, the image is clipped using the histogram. Second, the image is subdivided into eight sub-images and enhanced individually until a better enhancement rate is maintained to obtain the final output of the proposed method. The proposed method shows effective enhancement for clear visualization of the injury. The strength of the proposed method is compared with different histogram based enhancement techniques based on the parameters such as F-measure, Contrast improvement index (CII), Absolute Mean Brightness Error (AMBE) and Peak Signal to Noise Ratio (PSNR) to determine the efficient enhancement technique. The parameters are defined to be significant for different enhancement techniques based on the statistical analysis. Further classification of the enhancement techniques are performed with the help of decision tree classifier. Based on the results of the classifier, the proposed algorithm is stated to be more significant and efficient in enhancing the region of interest in the Hamstring Avulsion Injury MRI images. Thus the proposed method shows effective enhancement for improved visualization of the hamstring injury for the diagnosis of the state of injury. With these results, the region of injury can be analysed effectively for further processing.
C1 [Thamizhvani, T. R.; Ahmed, K. F. Tanveer; Hemalatha, R. J.; Dhivya, A. Josephin Arockia; Chandrasekaran, R.] Vels Inst Sci Technol & Adv Studies, Dept Biomed Engn, Chennai 600117, Tamil Nadu, India.
C3 Vels Institute of Science, Technology & Advanced Studies
RP Thamizhvani, TR (corresponding author), Vels Inst Sci Technol & Adv Studies, Dept Biomed Engn, Chennai 600117, Tamil Nadu, India.
EM thamizhvani.se@velsuniv.ac.in; tanveer2786.kf@gmail.com;
   hemalatharj@velsuniv.ac.in; a.dhivya.se@velsuniv.ac.in;
   chandrasekar.se@velsuniv.ac.in
RI TR, Thamizhvani/P-1994-2019; R.J, Hemalatha/N-3499-2018; Chandrasekaran,
   R/GWQ-4055-2022; AROCKIA DHIVYA A, JOSEPHIN/AAA-7744-2022
OI Chandrasekaran, R/0000-0003-3975-3010; AROCKIA DHIVYA A,
   JOSEPHIN/0000-0002-1603-0859; TR, Thamizhvani/0000-0002-7408-648X
CR Abbas AH, 2017, IRAQI J INFORM TECHN, V7, P67
   Benjamin-Laing H, 2012, ANN R COLL SURG ENGL, V94, P192
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Chen G, 2019, IEEE T MED IMAGING, V38, P2838, DOI 10.1109/TMI.2019.2915629
   Chen G, 2016, NEUROCOMPUTING, V177, P215, DOI 10.1016/j.neucom.2015.11.031
   Chen SD, 2004, DIGIT SIGNAL PROCESS, V14, P413, DOI 10.1016/j.dsp.2004.04.001
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Guanche CA, 2015, J HIP PRESERV SURG, V2, P116, DOI 10.1093/jhps/hnv026
   Hemalatha RJ, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/4976372
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Ibrahim H, 2009, IEEE T CONSUM ELECTR, V55, P891, DOI 10.1109/TCE.2009.5174471
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee CH, 2012, IEEE T CONSUM ELECTR, V58, P1253, DOI 10.1109/TCE.2012.6414993
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Meier J, 2007, LECT NOTES COMPUT SC, V4673, P165
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Shijin Kumar PS, 2016, ARPN J ENG APPL SCI, V11, P4305
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Slavotinek JP, 2002, AM J ROENTGENOL, V179, P1621, DOI 10.2214/ajr.179.6.1791621
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Thamizhvani TR, 2018, J CLIN DIAGN RES, V12, DOI 10.7860/JCDR/2018/36243.12362
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
NR 28
TC 3
Z9 3
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12117
EP 12134
DI 10.1007/s11042-020-10459-7
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296800001
DA 2024-07-18
ER

PT J
AU Kumar, M
   Bhandari, AK
   Singh, N
   Ghosh, A
AF Kumar, Mukteshwar
   Bhandari, Ashish Kumar
   Singh, Neha
   Ghosh, Arunangshu
TI A new multilevel histogram thresholding approach using variational mode
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational mode decomposition; Renyi entropy; Multi-level thresholding;
   Color image segmentation
ID SATELLITE IMAGE SEGMENTATION; SEARCH ALGORITHM; ENTROPY; OPTIMIZATION;
   TSALLIS; KAPURS; OTSU
AB Image segmentation is a technique of subdividing an image into numerous sections that converts an image into more expressive form that is easier to analyze. Histogram is one of the most widely used techniques for segmenting a digital image due to its simplicity. However, this method often leads to unsatisfactory segmentation performance because of abnormalities on gray level histogram. In this paper, we propose a technique for segmenting a digital image through multilevel iterative variational mode decomposition (VMD) using Renyi entropy. The VMD is employed first in order to decompose the gray-level histogram into corresponding sub-modes for analysis and attributes extraction. Splitting gray level histogram into various modes results in removal the unfavorable effects. Then, Renyi entropy is applied in order to find best threshold value for image segmentation. The feature set has been formulated by applying non-linear Renyi entropy on each of the modes extracted using VMD. The proposed technique has been tested on standard images and the experimental outcomes indicate that it can produce judicious segmentation outcomes compared to other techniques.
C1 [Kumar, Mukteshwar; Bhandari, Ashish Kumar; Singh, Neha; Ghosh, Arunangshu] Natl Inst Technol, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM mukteshwarkumar1993@gmail.com; bhandari.iiitj@gmail.com;
   nehasingh0910@gmail.com; arunangshu.ghosh@nitp.ac.in
RI Singh, Neha/JED-4558-2023; Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; Singh,
   Neha/0000-0001-7214-7392
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Afshar A, 2007, J FRANKLIN I, V344, P452, DOI 10.1016/j.jfranklin.2006.06.001
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Ben Chaabane S., 2008, MELECON 2008 - 2008 IEEE Mediterranean Electrotechnical Conference, P857, DOI 10.1109/MELCON.2008.4618543
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari A. K., 2018, IEEE J-STARS, DOI DOI 10.1109/JSTARS.2018.2870157
   BHANDARI AK, 2019, IEEE T SYST MAN CYBE
   Bhandari AK, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106243
   Bhandari AK, 2021, NEURAL COMPUT APPL, V33, P271, DOI 10.1007/s00521-020-05013-3
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P1871, DOI 10.1109/TIM.2019.2922516
   Bhandari AK, 2020, IEEE-CAA J AUTOMATIC, V7, P200, DOI 10.1109/JAS.2019.1911843
   Bhandari AK, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105570
   Bhandari AK, 2020, NEURAL COMPUT APPL, V32, P4583, DOI 10.1007/s00521-018-3771-z
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Chander A, 2011, EXPERT SYST APPL, V38, P4998, DOI 10.1016/j.eswa.2010.09.151
   Chang CI, 2006, IEE P-VIS IMAGE SIGN, V153, P837, DOI 10.1049/ip-vis:20050032
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Clausel M, 2015, APPL COMPUT HARMON A, V39, P450, DOI 10.1016/j.acha.2014.10.003
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Daubechies I, 2011, APPL COMPUT HARMON A, V30, P243, DOI 10.1016/j.acha.2010.08.002
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Do MN, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P158, DOI 10.1109/ICIP.2001.958075
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hao D, 2017, SIGNAL IMAGE VIDEO P, V11, P1411, DOI 10.1007/s11760-017-1101-z
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620
   Kandhway P, 2020, NEURAL COMPUT APPL, V32, P8901, DOI 10.1007/s00521-019-04381-9
   Kandhway P, 2019, MULTIMED TOOLS APPL, V78, P22613, DOI 10.1007/s11042-019-7506-7
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Labate D., 2005, P SPIE, V5914, P59140
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li JF, 2018, SIGNAL PROCESS, V147, P80, DOI 10.1016/j.sigpro.2018.01.022
   Liu D, 2006, PATTERN RECOGN LETT, V27, P1968, DOI 10.1016/j.patrec.2006.05.006
   Liu W, 2016, IEEE GEOSCI REMOTE S, V13, P28, DOI 10.1109/LGRS.2015.2493198
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2018, SIGNAL IMAGE VIDEO P, V12, P385, DOI 10.1007/s11760-017-1170-z
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sha CS, 2016, J VIS COMMUN IMAGE R, V41, P339, DOI 10.1016/j.jvcir.2016.10.013
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Singh N, 2020, CIRC SYST SIGNAL PR, V39, P3978, DOI 10.1007/s00034-020-01349-2
   Tao WB, 2007, PATTERN RECOGN LETT, V28, P788, DOI 10.1016/j.patrec.2006.11.007
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Wang XY, 2010, DIGIT SIGNAL PROCESS, V20, P1173, DOI 10.1016/j.dsp.2009.11.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 58
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11331
EP 11363
DI 10.1007/s11042-020-10189-w
EA JAN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605548700017
DA 2024-07-18
ER

PT J
AU Plaza, S
   Vilaplana, J
   Mateo, J
   Rius, J
   Solsona, F
AF Plaza, Sergi
   Vilaplana, Jordi
   Mateo, Jordi
   Rius, Josep
   Solsona, Francesc
TI CatDetect, a framework for detecting Catalan tweets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Catalan; Language detection; Twitter corpus; Machine learning
AB This work deals with language detection. It includes new proposals ranging from lexicon and morphological analysis to an increasing use of machine learning solutions. In this case, the language study is focused on Catalan, a minority language. In the context of the Twitter social network, this increases difficulty in detecting tweets (messages written on the Twitter social network). To achieve that, a Catalan-Twitter corpus was generated using lexical and morphological approaches, which then will be used to create supervised models based on machine learning techniques. They were also evaluated in order to see which obtains the best prediction score and thus, is the most suitable to be used. We demonstrate how our proposal is successful with Twitter in the case of minority languages. The best model is to be used on a website, where users can test the algorithm interactively in the front-end webpage and in background by means of a webservice across a RESTful API.
C1 [Plaza, Sergi] GFT, Parc Cient & Tecnol Lleida,Bldg H1, Lleida 25003, Spain.
   [Vilaplana, Jordi; Mateo, Jordi; Solsona, Francesc] Univ Lleida, Dept Comp Sci, Jaume II 69, Lleida 25001, Spain.
   [Rius, Josep] Univ Lleida, Dept AEGERN, Jaume II 73, Lleida 25001, Spain.
C3 Universitat de Lleida; Universitat de Lleida
RP Solsona, F (corresponding author), Univ Lleida, Dept Comp Sci, Jaume II 69, Lleida 25001, Spain.
EM plazacagigos@gmail.com; jordi.vilaplana@udl.cat; jordi.mateo@udl.cat;
   josep.riustorrento@udl.cat; francesc.solsona@udl.cat
RI Torrento, Josep Rius/U-3691-2019; Mayoral, Jordi Vilaplana/G-6766-2012;
   Mateo, Jordi/HZI-0461-2023; Mateo-Fornés, Jordi/AAH-4183-2020; Rius
   Torrento, Josep/HHR-9527-2022; Solsona, Francesc/D-6226-2014
OI Torrento, Josep Rius/0000-0003-2783-6230; Rius Torrento,
   Josep/0000-0003-2783-6230; Solsona, Francesc/0000-0002-4830-9184
FU Ministerio de Economia y Competitividad [TIN2017-84553-C2-2-R,
   2017-SGR363]; Generalitat de Catalunya; RecerCaixa
FX This work was supported by the Ministerio de Economia y Competitividad
   under contract TIN2017-84553-C2-2-R. IT, JV, JM, JR and FS are members
   of the research group 2017-SGR363, funded by the Generalitat de
   Catalunya. The research leading to these results has received funding
   from RecerCaixa.
CR [Anonymous], 2017, EMIGRANT 2 0 EMIGRAC
   [Anonymous], 2006, INT J
   [Anonymous], 2014, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   [Anonymous], 2014, DATA MINING EITH DEC, DOI [10.1142/9097, DOI 10.1142/9097]
   [Anonymous], 2005, J COMPUTING SCI COLL
   Baldwin M., 2010, P ANN C N AM CHAPT A, P229
   Bergsma Shane., 2012, Proceedings of the second workshop on language in social media, P65
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Brown RD, 2013, LECT NOTES COMPUT SC, V8082, P475, DOI 10.1007/978-3-642-40585-3_60
   Bruguera, 2008, INTRO ETIMOLOGIA
   Cardoso PMD, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P611, DOI 10.1145/2872518.2890560
   Carter S, 2013, LANG RESOUR EVAL, V47, P195, DOI 10.1007/s10579-012-9195-y
   Cruz YA, 2014, GECONTEC REV INT GES, V2, P35
   Herry S, 2006, 2006 IEEE OD SPEAK L, P1
   Jauhiainen T, 2019, J ARTIF INTELL RES, V65, P675
   Lee PM, 2012, BAYESIAN STAT INTRO, V4
   Lui M., 2014, Transactions of the Association for Computational Linguistics, V2, P27
   Lui M, 2015, WORKSH LANG AN SOC M, P17
   Padró L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2473
   Pavliy B, 2016, 8 B FACULTY CONT SOC, V8
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Ripley B. D., 2014, PATTERN RECOGNITION
   Shawe-Taylor NC, 2013, INTRO SUPPORT VECTOR
   Simons GaryF., 2020, ETHNOLOGUE LANGUAGES
   Tharwat A, 2020, APPL COMPUT INF, DOI DOI 10.1016/J.ACI.2018.08.003
   Varoquaux G., 2015, GetMobile: Mobile Computing and Communications, V19, P29, DOI [DOI 10.1145/2786984.2786995, 10.1145/2786984.2786995]
   Winkelmolen F, 2011, ICAART 2011: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P498
   Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983
NR 28
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10657
EP 10677
DI 10.1007/s11042-020-10182-3
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593002700003
DA 2024-07-18
ER

PT J
AU Parihar, AS
   Jain, G
   Chopra, S
   Chopra, S
AF Parihar, Anil Singh
   Jain, Gaurav
   Chopra, Shivang
   Chopra, Suransh
TI SketchFormer: transformer-based approach for sketch recognition using
   vector images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Transformers; Vector images; Deep learning
ID ALGORITHM
AB Sketches have been employed since the ancient era of cave paintings for simple illustrations to represent real-world entities and communication. The abstract nature and varied artistic styling make automatic recognition of these drawings more challenging than other areas of image classification. Moreover, the representation of sketches as a sequence of strokes instead of raster images introduces them at the correct abstract level. However, dealing with images as a sequence of small information makes it challenging. In this paper, we propose a Transformer-based network, dubbed as AttentiveNet, for sketch recognition. This architecture incorporates ordinal information to perform the classification task in real-time through vector images. We employ the proposed model to isolate the discriminating strokes of each doodle using the attention mechanism of Transformers and perform an in-depth qualitative analysis of the isolated strokes for classification of the sketch. Experimental evaluation validates that the proposed network performs favorably against state-of-the-art techniques.
C1 [Parihar, Anil Singh; Jain, Gaurav; Chopra, Shivang; Chopra, Suransh] Delhi Technol Univ, Machine Learning Res Lab, Dept Comp Sci & Engn, New Delhi 110042, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Machine Learning Res Lab, Dept Comp Sci & Engn, New Delhi 110042, India.
EM parihar.anil@gmail.com; gauravjain13298@gmail.com;
   shivangchopra11@gmail.com; suransh2008@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   [Anonymous], 2015, ARXIV150200254
   [Anonymous], 2017, arXiv preprint arXiv:1704.03477
   [Anonymous], 2011, P 16 INT C INT US IN
   Arandjelovic R, 2011, PATTERN RECOGN, V44, P1225, DOI 10.1016/j.patcog.2010.11.006
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Dehghani M., 2018, ARXIV180703819
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Graves A., 2013, GENERATING SEQUENCES
   Han B, 2018, ADV NEUR IN, V31
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laviola JJ, 2004, ACM T GRAPHIC, V23, P432, DOI 10.1145/1015706.1015741
   Li K., 2018, ECCV, P582
   Li L, 2019, IEEE COMPUT GRAPH, V39, P38, DOI 10.1109/MCG.2018.2884192
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu T, 2005, COMPUT AIDED DESIGN, V37, P1053, DOI 10.1016/j.cad.2004.11.004
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sarvadevabhatla RK, 2018, AAAI CONF ARTIF INTE, P7331
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Seddati O, 2017, MULTIMED TOOLS APPL, V76, P22333, DOI 10.1007/s11042-017-4799-2
   Seddati Omar, 2015, CONT BAS MULT IND CB, P1, DOI DOI 10.1109/CBMI.2015.7153606
   Sert M, 2019, MULTIMED TOOLS APPL, V78, P17095, DOI 10.1007/s11042-018-7067-1
   Sezgin TM, 2008, COMPUT GRAPH-UK, V32, P500, DOI 10.1016/j.cag.2008.05.008
   Song JF, 2018, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2018.00090
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun ZB, 2012, LECT NOTES COMPUT SC, V7572, P626, DOI 10.1007/978-3-642-33718-5_45
   Sutherland I. E., 1964, P SHAR DES AUT WORKS, DOI [DOI 10.1177/003754976400200514, 10.1177/003754976400200514]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang XX, 2018, IEEE IMAGE PROC, P2994, DOI 10.1109/ICIP.2018.8451288
   Xu P, 2018, PROC CVPR IEEE, P8090, DOI 10.1109/CVPR.2018.00844
   YANG Yongxin, 2015, ARXIV150107873
   Yanik E, 2015, COMPUT GRAPH-UK, V52, P93, DOI 10.1016/j.cag.2015.07.023
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang J, 2018, P JOINT S COMP AESTH, P3
   Zhang X., 2019, PATTERN RECOGNITION
   Zhao P, 2019, MULTIMED TOOLS APPL, V78, P35179, DOI 10.1007/s11042-019-08216-6
   Zou CQ, 2018, LECT NOTES COMPUT SC, V11219, P438, DOI 10.1007/978-3-030-01267-0_26
NR 50
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9075
EP 9091
DI 10.1007/s11042-020-09837-y
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587107900002
DA 2024-07-18
ER

PT J
AU Sisaudia, V
   Vishwakarma, VP
AF Sisaudia, Varsha
   Vishwakarma, Virendra P.
TI Copyright protection using KELM-PSO based multi-spectral image
   watermarking in DCT domain with local texture information based
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel extreme learning machine; Digital image watermarking; Entropy;
   Discrete cosine transform; Particle swarm optimization
ID EXTREME LEARNING-MACHINE; BLIND WATERMARKING; ROBUST; SCHEME; TRANSFORM;
   SVD; SECURE
AB Since many years, researchers have been developing techniques for copyright protection. This paper presents a novel approach for copyright protection of multi-spectral images using particle swarm optimization (PSO) and kernel extreme learning machine (KELM) based watermarking technique. It begins with the selection of non-overlapping blocks of host image based on local texture information. Next, discrete cosine transform (DCT) is performed on these selected blocks, after which coefficients scanned in zig-zag manner are used to form the dataset for training and testing of KELM. KELM is applied as a regression model and predicts the output for given input vector. The watermark bits are then embedded into the output vector. PSO is a nature- inspired meta- heuristic technique used for optimization of scaling factors that control the strength of copyright logo bits being inserted into the original image. The promising results obtained by using this technique have been compared with other state-of-art approaches.
C1 [Sisaudia, Varsha; Vishwakarma, Virendra P.] Univ Sch Informat Commun & Technol, Sect 16C, New Delhi 110078, India.
C3 GGS Indraprastha University
RP Sisaudia, V (corresponding author), Univ Sch Informat Commun & Technol, Sect 16C, New Delhi 110078, India.
EM sisaudia.varsha@gmail.com; virendravishwa@rediffmail.com
OI Vishwakarma, Virendra P./0000-0003-4276-8766
CR Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   [Anonymous], 2017, GLOBAL J RES ENG
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Hussein J. A., 2010, J COMPUTING, V2, P100
   Juneja S., 2018, Data Engineering and Intelligent Computing: Proceedings of IC3T 2016, Proceedings of the Third Springer International Conference on Computer Communication Technologies, Andhra Pradesh, India, 28-29 October 2016, V542, P595, DOI [10.1007/978-981-10-3223-3, DOI 10.1007/978-981-10-3223-3_57]
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149
   LEE HM, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P1583, DOI 10.1109/ICNN.1994.374392
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Mehta R, 2018, QUAL IT BUS OPER, P191, DOI [10.1007/978-981-10-5577-5, DOI 10.1007/978-981-10-5577-5]
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mehta R, 2016, J SIGNAL PROCESS SYS, V84, P265, DOI 10.1007/s11265-015-1055-8
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Moeinaddini E, 2019, SOFT COMPUT, V23, P9685, DOI 10.1007/s00500-018-3535-9
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Motwani Mukesh, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P321
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Qi M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013004
   Rajpal A., 2016, 2016 IEEE Int Conf Signal Process, Commun and Comput (ICSPCC), P1
   Roy SS, 2020, MULTIMED TOOLS APPL, V79, P13125, DOI 10.1007/s11042-020-08652-9
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tao H, 2012, INTEGR COMPUT-AID E, V19, P81, DOI 10.3233/ICA-2012-0392
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Vishwakarma VP, 2020, INT J EMBED SYST, V13, P74
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Yang YM, 2012, IEEE T NEUR NET LEAR, V23, P1498, DOI 10.1109/TNNLS.2012.2202289
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang LN, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102805
NR 46
TC 11
Z9 12
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8667
EP 8688
DI 10.1007/s11042-020-10028-y
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500003
DA 2024-07-18
ER

PT J
AU Yilmaz, GN
AF Nur Yilmaz, Gokce
TI Context and content based scalable video adaptation for ubiquitous
   multimedia communication services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient illumination; Key; non-key frames; MGS; Motion activity; NALU;
   Prioritization; R-D; Spatial structure; SVC; Video adaptation
ID SVC; OPTIMIZATION; EXTENSION; TRANSPORT; QUALITY; CONTOUR
AB A novel scalable video adaptation framework is developed to achieve the aim of ensuring enhanced Rate-Distortion (R-D) performances for the ubiquitous multimedia communication services in this study. This novel framework also integrates novel contributions in its development process. As the first contribution, novel models evaluating the motion information and spatial structure characteristics of the video contents are proposed. As the second novel contribution of the developed framework, adaptation experiments are conducted by exploiting a proposed adaptation approach relying on prioritizing the spatial, temporal, and quality layer based Network ion Layer Units (NALUs) of the scalability extension of the H.264/Advanced Video Coding (AVC) gradually in accordance with the video contents' motion and structural characteristics. The proposed adaptation approach also relies on the prioritization of the quality layer based NALUs from the key and non-key frames in both symmetric and asymmetric manners while attaining the target bit rate of a communication network. In accordance with these development steps, subjective experiments are carried to assess the quality of adapted video contents having different motion information and spatial structure characteristics under different ambient illumination conditions. Using the analysis results of the subjective experiments, another significant novelty of the framework relying on developing novel prioritization schemes, which assist an encoder to assign priority indices for each NALU of the encoded video contents based on their characteristics and the ambient illumination condition of the viewing environment, is performed. The adaptation experiments conducted in the light of the developed framework prove that highly efficient R-D performances can be attained for the video contents having any characteristic and viewed under any ambient illumination condition for assisting the multimedia communication services to ensure improved user viewing perception while easing the adverse effects of the network congestion.
C1 [Nur Yilmaz, Gokce] TED Univ, Comp Engn Dept, Ankara, Turkey.
C3 Ted University
RP Yilmaz, GN (corresponding author), TED Univ, Comp Engn Dept, Ankara, Turkey.
EM gokce.yilmaz@tedu.edu.tr
OI NUR YILMAZ, Gokce/0000-0002-0015-9519
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   [Anonymous], 2000, TECHNICAL REPORT
   [Anonymous], 2005, JTCSC29WG11N6 ISOIEC
   [Anonymous], TEXT ISO IEC 14496 4, pN9195
   Brandt J, 2010, IEEE 14 INT S CONS E, P1
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Chen X, 2017, IEEE T CIRC SYST VID, V27, P366, DOI 10.1109/TCSVT.2015.2511815
   Fleet DJ, 2006, HDB MATH MODELS COMP, P239
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Hu H, 2012, IEEE IMAGE PROC, P717, DOI 10.1109/ICIP.2012.6466960
   International Telecommunication Union/ITU Radio Communication Sector, 2012, METH SUBJ ASS QUAL T
   JSVM, 9 13 1 SOFTW
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Li MD, 2013, J VIS COMMUN IMAGE R, V24, P509, DOI 10.1016/j.jvcir.2013.03.006
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Mangasarian OL, 2004, WORKSH CLUST HIGH DI
   Nur G, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P218, DOI 10.1109/WIAMIS.2009.5031472
   Nur G, 2009, ICT MOB WIR COMM SUM
   Nur G, 2012, IEEE T CIRC SYST VID, V22, P225, DOI 10.1109/TCSVT.2011.2160600
   Peng WH, 2008, J VIS COMMUN IMAGE R, V19, P543, DOI 10.1016/j.jvcir.2008.08.002
   Ramakrishna M, 2017, PROCEDIA COMPUT SCI, V115, P715, DOI 10.1016/j.procs.2017.09.144
   Rempel AG, 2012, PERCEPTUAL CONSIDERA
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stockhammer T, 2002, INT C IM PROC ROCH N
   Thang TC, 2008, P 16 ACM INT C MULT, P689
   Thang TC, 2009, SIGNAL PROCESS-IMAGE, V24, P214, DOI 10.1016/j.image.2008.12.006
   Wang YK, 2007, IEEE T CIRC SYST VID, V17, P1149, DOI 10.1109/TCSVT.2007.906827
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
NR 30
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7987
EP 8013
DI 10.1007/s11042-020-10100-7
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583128600005
DA 2024-07-18
ER

PT J
AU Wang, ZJ
   Xing, YM
   Wang, JP
   Zeng, XY
   Yang, YL
   Xu, S
AF Wang, Zhujun
   Xing, Yingmei
   Wang, Jianping
   Zeng, Xianyi
   Yang, Yalan
   Xu, Shuo
TI A knowledge-supported approach for garment pattern design using fuzzy
   logic and artificial neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Garment pattern design; Knowledge modeling; Fuzzy logic; Artificial
   neural networks; Anthropometric measurements
ID SENSORY EVALUATION; ATYPICAL MORPHOLOGY; DISABLED PEOPLE; EASE
   ALLOWANCE; PREDICTION; BLOCK; MODEL
AB In the clothing industry, garment pattern design serves as a significant middle link between fashion design and manufacturing. With the advent of advanced multimedia techniques, like virtual reality, 3D modeling, and interactive design, this work has become more intuitive. However, it is still a tremendous knowledge-based work that relied on the experienced patternmakers' know-how. For enterprises, it will take a long time to cultivate a patternmaker from an abecedarian to an expert. Moreover, while facing fierce competition in the market, enterprises still have to endure the pressures and risks led by the turnover of experienced patternmakers. In this context, we put forward a knowledge-supported garment pattern design approach by learning the experienced patternmakers' knowledge based on fuzzy logic and artificial neural networks. Based on this approach, we created a knowledge-supported pattern design model, consisting of several sub-models following the garment styles, considering the properties of fabrics and fitting degree. The inputs of the model are the feature body dimensions, while the outputs, namely the pattern parameters, can be generated following the fabric and fitting degree selected. Through performance comparison with other models and the actual fitting test, the results revealed that the present approach was applicable. Our proposed approach can not only support the non-expert patternmakers or abecedarians to make decisions when developing the patterns by reducing the difficulties of patternmaking but help the enterprises to reduce the dependencies on the experts, hence promoting the efficiency and reducing risks.
C1 [Wang, Zhujun; Xing, Yingmei] Anhui Polytech Univ, Coll Text & Garments, Wuhu 241000, Anhui, Peoples R China.
   [Wang, Zhujun; Wang, Jianping; Yang, Yalan; Xu, Shuo] Donghua Univ, Coll Fash & Design, Shanghai 200051, Peoples R China.
   [Wang, Zhujun] Minist Culture & Tourism, Key Lab Silk Culture Heritage & Prod Design Digit, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zeng, Xianyi] Ecole Natl Super Arts & Ind Text, GEMTEX Lab, F-59056 Roubaix, France.
   [Wang, Zhujun; Wang, Jianping] Donghua Univ, Key Lab Clothing Design & Technol, Minist Educ, Shanghai 200051, Peoples R China.
C3 Anhui Polytechnic University; Donghua University; Universite de Lille;
   Ecole Nationale Superieure des Arts et Industries Textiles (ENSAIT);
   Donghua University
RP Wang, JP (corresponding author), Donghua Univ, Coll Fash & Design, Shanghai 200051, Peoples R China.; Wang, JP (corresponding author), Donghua Univ, Key Lab Clothing Design & Technol, Minist Educ, Shanghai 200051, Peoples R China.
EM wangjp@dhu.edu.cn
RI Xing, Yingmei/KPY-1792-2024; Wang, Zhujun/AAE-9321-2021; Zeng,
   Xianyi/AAQ-1183-2021
OI Xing, Yingmei/0000-0002-8453-5576; Wang, Zhujun/0000-0002-8583-6880;
   Zeng, Xianyi/0000-0002-3236-6766
FU Key Research Project of Humanities and Social Sciences in Anhui Province
   College [SK2016A0116, SK2017A0119]; Fundamental Research Funds for the
   Central Universities [CUSF-DH-D-2020091]; Graduate Student Innovation
   Fund of Donghua University [CUSF-DH-D-2020091]; Open Project Program of
   Key Laboratory of Silk Culture Heritage and Products Design Digital
   Technology of Ministry of Culture and Tourism of China [2020WLB07];
   European H2020 Research Program [761122]; Special Excellent Ph.D.
   International Visit Program of DHU; Open Project Program of Anhui
   Province College Key Laboratory of Textile Fabrics, Anhui Engineering
   and Technology Research Center of Textile [2018AKLTF15]; Social Science
   Planning Project in Anhui [AHSKQ2019D085]; National Key Research and
   Development Program of China [2019YFF0302100]; H2020 - Industrial
   Leadership [761122] Funding Source: H2020 - Industrial Leadership
FX The authors wish to acknowledge the financial support of the Key
   Research Project of Humanities and Social Sciences in Anhui Province
   College (No. SK2016A0116 and SK2017A0119), the Fundamental Research
   Funds for the Central Universities and Graduate Student Innovation Fund
   of Donghua University (No. CUSF-DH-D-2020091), the Open Project Program
   of Key Laboratory of Silk Culture Heritage and Products Design Digital
   Technology of Ministry of Culture and Tourism of China (No. 2020WLB07),
   the European H2020 Research Program (Project: FBD_BModel, No. 761122),
   the Special Excellent Ph.D. International Visit Program of DHU, the Open
   Project Program of Anhui Province College Key Laboratory of Textile
   Fabrics, Anhui Engineering and Technology Research Center of Textile
   (No. 2018AKLTF15), the Social Science Planning Project in Anhui (No.
   AHSKQ2019D085), and the National Key Research and Development Program of
   China (No. 2019YFF0302100).
CR Bin JC, 2019, MULTIMED TOOLS APPL, V78, P31163, DOI 10.1007/s11042-019-07895-5
   Bruniaux P, 2016, FIBRES TEXT EAST EUR, V24, P125, DOI 10.5604/12303666.1215537
   Chan AP, 2005, INT J CLOTH SCI TECH, V17, P100, DOI 10.1108/09556220510581245
   Chen Y, 2009, ENG APPL ARTIF INTEL, V22, P272, DOI 10.1016/j.engappai.2008.05.007
   Chen Y, 2008, INT J CLOTH SCI TECH, V20, P161, DOI 10.1108/09556220810865210
   Dong M, 2020, INFORM SCIENCES, V540, P469, DOI 10.1016/j.ins.2020.05.094
   Foundation E. M, 2017, NEW TEXT EC RED FASH
   Hong Y, 2018, TEXT RES J, V88, P1721, DOI 10.1177/0040517517708537
   Hong Y, 2018, IND TEXTILA, V69, P59
   Hong Y, 2017, TEXT RES J, V87, P1261, DOI 10.1177/0040517516651105
   Hong Y, 2017, INT J CLOTH SCI TECH, V29, P226, DOI 10.1108/IJCST-07-2016-0077
   Hu ZH, 2009, TEXT RES J, V79, P1319, DOI 10.1177/0040517508100726
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Ling X, 2021, INT J CLOTH SCI TECH, V33, P137, DOI 10.1108/IJCST-02-2020-0016
   Liu KX, 2019, INT J IND ERGONOM, V72, P212, DOI 10.1016/j.ergon.2019.05.012
   Liu KX, 2019, IEEE ACCESS, V7, P48830, DOI 10.1109/ACCESS.2019.2906261
   Liu KX, 2018, COMPUT AIDED DESIGN, V104, P113, DOI 10.1016/j.cad.2018.07.003
   Liu KX, 2017, J TEXT I, V108, P2107, DOI 10.1080/00405000.2017.1315794
   Liu KX, 2016, INT J CLOTH SCI TECH, V28, P736, DOI 10.1108/IJCST-02-2016-0016
   Liu KX, 2016, INT J IND ERGONOM, V55, P60, DOI 10.1016/j.ergon.2016.07.008
   Liu YJ, 2010, COMPUT IND, V61, P576, DOI 10.1016/j.compind.2010.03.007
   Lunscher N, 2018, IEEE COMPUT SOC CONF, P1208, DOI 10.1109/CVPRW.2018.00157
   Mas'ud AA, 2017, ENERGIES, V10, DOI 10.3390/en10071060
   Nasibov E, 2019, INT J CLOTH SCI TECH, V31, P299, DOI 10.1108/IJCST-06-2018-0077
   Song D, 2020, MULTIMED TOOLS APPL, V79, P33757, DOI 10.1007/s11042-019-08363-w
   Tao XY, 2018, COMPUT IND ENG, V115, P683, DOI 10.1016/j.cie.2017.10.023
   Tao X, 2013, INT J CLOTH SCI TECH, V25, P266, DOI 10.1108/09556221311326301
   Thomassey S, 2013, INT J IND ERGONOM, V43, P406, DOI 10.1016/j.ergon.2013.08.002
   Wang ZJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061140
   Xing YM, 2014, TEXT BIOENG INFORM S, P667
   Zeng XY, 2008, MATH COMPUT SIMULAT, V77, P443, DOI 10.1016/j.matcom.2007.11.013
   Zeng XY, 2003, INT J INTELL SYST, V18, P355, DOI 10.1002/int.10092
   Zhang JJ, 2020, J TEXT I, V111, P1324, DOI 10.1080/00405000.2019.1694351
   Zhang JJ, 2018, INT J CLOTH SCI TECH, V30, P101, DOI 10.1108/IJCST-03-2017-0036
   Zhu Xj, 2018, MULTIMED TOOLS APPL, V77, P27163, DOI 10.1007/s11042-018-5912-x
NR 36
TC 17
Z9 17
U1 5
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19013
EP 19033
DI 10.1007/s11042-020-10090-6
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000584947400005
DA 2024-07-18
ER

PT J
AU Alenazy, WM
   Alqahtani, AS
AF Alenazy, Wael Mohammad
   Alqahtani, Abdullah Saleh
TI Improved crossover firefly algorithm based deep Beleif network for
   low-resolution face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-resolution image; Face recognition; Facial features; DBN; CROFF
AB Face detection by low-resolution image (LR) is one of the key aspects of Human-Computer Interaction(HCI). Due to the LR image, which has changes in pose, lighting, and illumination, the performance of face recognition is reduced. In this work, we propose the Deep Belief Network-Crossover based Firefly (DBN-CROFF) method for face recognition from low-resolution images. The Histogram of Gradient (HOG) and 2-Dimensional Discrete Wavelet Transform (2D-DWT) to extract facial width, size of the cheeks, skin tone, nose, and lip shape features from facial data. The Kernel Principle Component Analysis (k-PCA) is used to successfully reduce the dimension of the feature. The experimental performance of the proposed method is evaluated using four datasets namely LFW, Multi-PIE, Extended Yale-B, and FERET with conventional techniques. Finally, the proposed DBN-CROFF solution surpasses the other conventional facial recognition approaches by giving a higher accuracy of recognization.
C1 [Alenazy, Wael Mohammad; Alqahtani, Abdullah Saleh] CFY Deanship King Saud Univ, Dept Self Dev Skills, Riyadh, Saudi Arabia.
RP Alenazy, WM (corresponding author), CFY Deanship King Saud Univ, Dept Self Dev Skills, Riyadh, Saudi Arabia.
EM walenazy@ksu.edu.sa
FU DSR [RG-1441-343]
FX The Authors extend their warm thanks to Deanship of Scientific Research
   (DSR), King Saud University, Riyadh, Saudi Arabia for permitting us to
   carry out the research and also for acknowledging the financial aid from
   DSR through the Project Group No. RG-1441-343.
CR Abebe HB, 2019, IET CYBER PHYS SYST, V4, P189, DOI 10.1049/iet-cps.2018.5045
   Abiantun R, 2019, PATTERN RECOGN, V90, P308, DOI 10.1016/j.patcog.2019.01.032
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Alenazy WM, 2021, J AMB INTEL HUM COMP, V12, P1631, DOI 10.1007/s12652-020-02235-0
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Gao GW, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106183
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Haghighat M, 2017, IEEE INT CONF AUTOMA, P912, DOI 10.1109/FG.2017.130
   Heinsohn D, 2019, IMAGE VISION COMPUT, V85, P46, DOI 10.1016/j.imavis.2019.02.012
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Jolliffe I., 2011, International Encyclopedia of Statistical Science, P1094, DOI [DOI 10.1007/978-3-642-04898-2_455, 10.1007/978-3-642-04898-2_455]
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li LC, 2019, KNOWL-BASED SYST, V172, P1, DOI 10.1016/j.knosys.2019.01.015
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Pan XQ, 2019, NEURAL COMPUT APPL, V31, P1445, DOI 10.1007/s00521-018-3449-6
   Phillips J, 2020, IEEE T PATTERN ANAL, V22, P1104
   Kurup AR, 2019, NEUROCOMPUTING, V367, P188, DOI 10.1016/j.neucom.2019.08.029
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Shakeel MS, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102590
   SUN J, 2020, SIGNAL PROCESS IMAGE, VPVOL
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Ullah Hidayat, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P86, DOI 10.1109/ICAEM.2019.8853753
   Wahid F, 2019, ARAB J SCI ENG, V44, P4027, DOI 10.1007/s13369-019-03759-0
   Wang ZY, 2015, NEURAL COMPUT APPL, V26, P1645, DOI 10.1007/s00521-015-1834-y
   Xu H, 2016, MYCORRHIZA, V26, P19, DOI 10.1007/s00572-015-0643-6
   Yi Dong, 2014, ARXIV14117923
   Yin BY, 2018, COMPUT ELECTR ENG, V66, P505, DOI 10.1016/j.compeleceng.2017.06.001
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 39
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7411
EP 7431
DI 10.1007/s11042-020-09976-2
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400008
DA 2024-07-18
ER

PT J
AU de la Rosa, JI
   Gutiérrez, O
   Villa-Hernández, J
   Moreno, G
   González, E
   Alaniz, D
AF de la Rosa, Jose I.
   Gutierrez, Osvaldo
   Villa-Hernandez, Jesus
   Moreno, Gamaliel
   Gonzalez, Efren
   Alaniz, Daniel
TI Entropy estimation for robust image segmentation in presence of non
   Gaussian noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayesian estimation; Markov random fields; Image segmentation; Non
   parametric estimators; Estimation
ID MEANS CLUSTERING-ALGORITHM; MINIMUM-ENTROPY; STATISTICAL-ANALYSIS;
   KERNEL SELECTION; FIELD MODELS
AB In this work we introduce a new approach for robust image segmentation. The idea is to combine two strategies within a Bayesian framework. The first one is to use a Markov Random Field (MRF), which allows to introduce prior information with the purpose of preserve the edges in the image. The second strategy comes from the fact that the probability density function (pdf) of the likelihood function is non Gaussian or unknown, so it should be approximated by an estimated version, and for this, it is used the classical non-parametric or kernel density estimation. This two strategies together lead us to the definition of a new maximum a posteriori (MAP) approach based on the minimization of the entropy of the estimated pdf of the likelihood function and the MRF at the same time, named MAP entropy estimator (MAPEE). Some experiments were conducted for different kind of images degraded with impulsive noise and other non-Gaussian distributions, where the segmentation results are very satisfactory comparing them with respect to recent robust approaches based on the fuzzy c-means (FCM) segmentation.
C1 [de la Rosa, Jose I.; Villa-Hernandez, Jesus; Moreno, Gamaliel; Gonzalez, Efren; Alaniz, Daniel] Ciudad Univ Siglo 21, Zacatecas 98160, Zac, Mexico.
   [Gutierrez, Osvaldo] Inst Tecnol Super Fresnillo, Fresnillo, Zacatecas, Mexico.
RP de la Rosa, JI (corresponding author), Ciudad Univ Siglo 21, Zacatecas 98160, Zac, Mexico.
EM ismaelrv@ieee.org
RI gutierrez, osvaldo/F-6031-2013; Moreno, Gamaliel/AAS-3273-2021
OI Moreno, Gamaliel/0000-0002-2498-138X; De la Rosa,
   Ismael/0000-0002-7337-8974; GONZALEZ-RAMIREZ, EFREN/0000-0002-8060-6170
CR [Anonymous], 2005, THESIS
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Banerjee A, 2020, IEEE T IMAGE PROCESS, V29, P4898, DOI 10.1109/TIP.2020.2975717
   Berlinet A, 1994, PUBLICATIONS LINSTIT, V38, P3
   Bertaux N, 2004, J OPT SOC AM A, V21, P2283, DOI 10.1364/JOSAA.21.002283
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536
   Bresson X, 2008, NONLOCAL UNSUPERVISE
   Chen KX, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-019-0407-4
   Clausi DA, 2004, IEEE T GEOSCI REMOTE, V42, P215, DOI 10.1109/TGRS.2003.817218
   Coupé P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018
   de la Rosa JI, 2013, J EUR OPT SOC-RAPID, V8, DOI 10.2971/jeos.2013.13047
   De la Rosa JI, 2003, IEEE T INSTRUM MEAS, V52, P1009, DOI 10.1109/TIM.2003.814816
   de la Rosa JI, 2002, IEEE IMTC P, P1205, DOI 10.1109/IMTC.2002.1007129
   De la Rosa JI, 2007, P 17 INT C EL COMM C
   DEVROYE L, 1992, ANN STAT, V20, P2037, DOI 10.1214/aos/1176348901
   Devroye L, 1999, STAT PROBABIL LETT, V44, P299, DOI 10.1016/S0167-7152(99)00021-8
   Devroye L, 1997, TEST-SPAIN, V6, P223
   DEVROYE L, 1989, ANN I H POINCARE-PR, V25, P533
   Gawish A, 2014, IEEE IMAGE PROC, P882, DOI 10.1109/ICIP.2014.7025177
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guo FF, 2016, IET IMAGE PROCESS, V10, P272, DOI 10.1049/iet-ipr.2015.0236
   Mata OG, 2014, INT CONF ELECTR COMM, P231, DOI 10.1109/CONIELECOMP.2014.6808596
   Gutierrez O, 2012, P 14 INT AUT M POW E, P387
   Gutiérrez O, 2012, OPT EXPRESS, V20, P6542, DOI 10.1364/OE.20.006542
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Iftikhar MA, 2014, INT J IMAG SYST TECH, V24, P52, DOI 10.1002/ima.22079
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lei XG, 2010, J SYST ENG ELECTRON, V21, P31, DOI 10.3969/j.issn.1004-4132.2010.01.006
   Li S. Z., 2009, Markov random field modeling in image analysis
   Li Y, 2005, INT J REMOTE SENS, V26, P5149, DOI 10.1080/01431160500176838
   Loader CR, 1999, ANN STAT, V27, P415, DOI 10.1214/aos/1018031201
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   MASRY E, 1983, IEEE T INFORM THEORY, V29, P696, DOI 10.1109/TIT.1983.1056736
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Pronzato L, 2004, CONTRIB STAT, P125
   Pronzato L, 2001, INT CONF ACOUST SPEE, P3993, DOI 10.1109/ICASSP.2001.940719
   Pronzato L, 2000, MAXENT 2000, P169
   Riaz F, 2020, IEEE ACCESS, V8, P16846, DOI 10.1109/ACCESS.2020.2967676
   Rivera M, 2007, IEEE T IMAGE PROCESS, V16, P3047, DOI 10.1109/TIP.2007.909384
   SAUER K, 1992, IEEE T NUCL SCI, V39, P1144, DOI 10.1109/23.159774
   SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   TERRELL GR, 1985, J AM STAT ASSOC, V80, P209, DOI 10.2307/2288074
   TERRELL GR, 1990, J AM STAT ASSOC, V85, P470, DOI 10.2307/2289786
   Vargas JIDLR, 2004, INT CONF ELECTR COMM, P98, DOI 10.1109/ICECC.2004.1269556
   Wachinger C, 2017, IEEE T BIO-MED ENG, V64, P1492, DOI 10.1109/TBME.2016.2603119
   Wachinger C, 2015, IEEE T MED IMAGING, V34, P2492, DOI 10.1109/TMI.2015.2442753
   Wang GT, 2019, IEEE T PATTERN ANAL, V41, P1559, DOI 10.1109/TPAMI.2018.2840695
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolsztynski E, 2005, SIGNAL PROCESS, V85, P937, DOI 10.1016/j.sigpro.2004.11.028
   Wolsztynski E, 2005, P 11 INT C APPL STOC, P882
   Wolsztynski K, 2004, INT CONF ACOUST SPEE, P1045
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhao ZX, 2014, IET IMAGE PROCESS, V8, P150, DOI 10.1049/iet-ipr.2011.0128
NR 60
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6991
EP 7021
DI 10.1007/s11042-020-09999-9
EA OCT 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582095600002
DA 2024-07-18
ER

PT J
AU Brajovic, M
   Stankovic, I
   Dakovic, M
   Stankovic, L
AF Brajovic, Milos
   Stankovic, Isidora
   Dakovic, Milos
   Stankovic, Ljubisa
TI The DCT domain sparsity-assisted detection and recovery of impulsively
   disturbed samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio signals; Concentration measure; DCT; Signal denoising; Sparse
   signal reconstruction
ID NOISE
AB A sparsity-assisted algorithm for the detection and removal of impulsive disturbances is presented. It is assumed that the uncorrupted signal is sparse or highly concentrated in the discrete cosine transform (DCT) domain or the windowed modified DCT (MDCT) domain. To detect whether a specific signal sample is corrupted by a disturbance, the gradient of the sparsity measure is estimated in the space of the signal samples by varying the values of signal samples. Samples whose variations caused the highest estimated gradient values are considered to be far (dislocated) from the sparsity measure minimum. They are labeled as disturbed and further classified as unavailable. Subsequently, these samples are reconstructed using a compressive sensing reconstruction approach. Numerical results support the presented theory and indicate potential applicability in audio signal processing, particularly in the removal of impulsive disturbances and concealment of unavailable, disturbed or lost data.
C1 [Brajovic, Milos; Stankovic, Isidora; Dakovic, Milos; Stankovic, Ljubisa] Univ Montenegro, Fac Elect Engn, Podgorica 81000, Montenegro.
   [Stankovic, Isidora] INP Grenoble, GIPSA Lab, F-38400 St Martin Dheres, France.
C3 University of Montenegro; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS)
RP Brajovic, M (corresponding author), Univ Montenegro, Fac Elect Engn, Podgorica 81000, Montenegro.
EM milosb@ucg.ac.me; isidoras@ucg.ac.me; milos@ucg.ac.me; ljubisa@ucg.ac.me
RI Stankovic, Ljubisa/J-8988-2013; Brajovic, Milos/AAH-4122-2019; Dakovic,
   Milos/C-1319-2010; Stankovic, Isidora/AAL-4037-2020
OI Brajovic, Milos/0000-0003-1106-3878; Dakovic, Milos/0000-0002-3317-3632;
   Stankovic, Isidora/0000-0003-3942-7194
CR Adler A, 2012, IEEE T AUDIO SPEECH, V20, P922, DOI 10.1109/TASL.2011.2168211
   [Anonymous], 2016, MATH PROBL ENG, DOI DOI 10.1007/s00034-016-0334-3
   [Anonymous], 2013, TIME FREQUENCY SIGNA
   Avila FR, 2012, IEEE T AUDIO SPEECH, V20, P2470, DOI 10.1109/TASL.2012.2203811
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Britanak V, 2001, IEEE SIGNAL PROC LET, V8, P48, DOI 10.1109/97.895372
   Buchner H, 2016, INT CONF ACOUST SPEE, P614, DOI 10.1109/ICASSP.2016.7471748
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Emiya V, 2011, IEEE T AUDIO SPEECH, V19, P2046, DOI 10.1109/TASL.2011.2109381
   Godsill S. J., 1998, Digital Audio Restora- tion
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259
   Jokanovic B, 2014, PROC SPIE, V9109, DOI 10.1117/12.2050894
   Lee BK, 2016, IEEE-ACM T AUDIO SPE, V24, P378, DOI 10.1109/TASLP.2015.2509780
   Stankovic I, 2018, MULTIMED TOOLS APPL, V77, P5885, DOI 10.1007/s11042-017-4502-7
   Stankovic L, 2018, IEEE-ACM T AUDIO SPE, V26, P1216, DOI 10.1109/TASLP.2018.2819819
   Stankovic L, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/6212674
   Volaric I, 2016, NOISE IMPACT L1 BASE
   Wang JC, 2016, IEEE-ACM T AUDIO SPE, V24, P2122, DOI 10.1109/TASLP.2016.2598306
   Wu DL, 2014, IEEE-ACM T AUDIO SPE, V22, P682, DOI 10.1109/TASLP.2014.2300336
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 21
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6221
EP 6234
DI 10.1007/s11042-020-09998-w
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578275300004
DA 2024-07-18
ER

PT J
AU Wang, XH
   Yan, WQ
AF Wang, Xiuhui
   Yan, Wei Qi
TI Non-local gait feature extraction and human identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human identification; Non-local features; Gait recognition;
   Self-attention
ID RECOGNITION; PERFORMANCE
AB As a new human identification technology, gait recognition is receiving more and more attention in recent years. However, traditional gait recognition techniques are limited by the challenges of feature representation and extraction algorithms. In this paper, by utilizing the self-attention mechanism, we propose a novel gait-based human identification solution. Firstly, we utilize non-local neural networks (NLNN) to extract non-local features from a pair of randomly selected gait energy maps (GEIs). Secondly, based on the relationship between GEIs and various parts of the human body, the output of NLNN is horizontally segmented into three sections, i.e., strong-dynamic region, weak-dynamic region and micro-dynamic region, respectively. Thirdly, the segmented gait features are weighted ensembled by three two-class classifiers. Finally, two experiments are carried out with the OU-ISIR large population dataset and the CASIA dataset B to evaluate the proposed approach.
C1 [Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Peoples R China.
   [Yan, Wei Qi] Auckland Univ Technol, 2-14 Wakefiled St, Auckland 1010, New Zealand.
C3 China Jiliang University; Auckland University of Technology
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn; wyan@aut.ac.nz
OI Wang, Xiuhui/0000-0003-1773-9760
FU National Natural Science Foundation of China [61602431]; Zhejiang
   Provincial Natural Science Foundation of China [Y20F020113]; China
   Scholarship Council
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No.61602431 and Zhejiang Provincial
   Natural Science Foundation of China under Grant No.Y20F020113, as well
   as a scholarship from the China Scholarship Council.
CR AlAsadi AH., 2014, J BASRAH RES, V40, P68
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chen Q, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P54, DOI 10.1109/BTAS.2017.8272682
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hagui M, 2016, INT IMAGE PROCESSING, P1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   [何逸炜 He Yiwei], 2018, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V31, P442
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Kanwar A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P719, DOI 10.1109/ICICICT.2014.6781369
   Kingma D. P., 2013, STAT-US
   Kozlow P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103329
   Krajuskina A, 2018, IEEE SYS MAN CYBERN, P3720, DOI 10.1109/SMC.2018.00630
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Manap H. H., 2012, 2012 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2012), P378, DOI 10.1109/ISIEA.2012.6496664
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Muramatsu D, 2015, IET BIOMETRICS, V4, P62, DOI 10.1049/iet-bmt.2014.0042
   National Institute of Standards and Technology (NIST), 2011, Commun. ACM
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   San-Segundo R, 2016, PATTERN RECOGN LETT, V73, P60, DOI 10.1016/j.patrec.2016.01.008
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shiraga K, 2016, INT CONF BIOMETR
   Sonderby CK, 2016, ADV NEUR IN, V29
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tong SB, 2018, IEEE ACCESS, V6, P57583, DOI 10.1109/ACCESS.2018.2874073
   Tsunashima H, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING AND BIG DATA (ICCBD 2018), P52, DOI 10.1145/3277104.3277110
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X, 2019, NEURAL COMPUT APPL, P532
   Wang X, 2019, NEURAL COMPUTING APP
   Wang XL, 2019, INT CONF MEASURE, P1, DOI [10.1109/TCYB.2019.2935141, 10.1109/ICMIC48233.2019.9068567]
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu SQ, 2006, INT C PATT RECOG, P441
NR 40
TC 7
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6065
EP 6078
DI 10.1007/s11042-020-09935-x
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700002
DA 2024-07-18
ER

PT J
AU Yu, S
   Li, XF
   Ma, MR
   Zhang, XL
   Chen, SP
AF Yu, Shuang
   Li, Xiongfei
   Ma, Mingrui
   Zhang, Xiaoli
   Chen, Shiping
TI Multi-focus image fusion based on L1 image transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Multi-focus; L1 image transform; Image quality
ID FILTER; MICROSCOPY; LAPLACIAN; SCHEME
AB In this paper, a new multi-focus image fusion algorithm based on L1 image transform is proposed. A distinctive advantage of the proposed algorithm is that an edge-preserving image decomposition (EPID) framework is constructed by introducing a L1-norm based image transform, which can not only effectively preserve and sharpen salient edges and ridges while eliminating insignificant details in the smoothing subband, but also maintain the detail information in the detail subbands. Another advantage is that the fusion rules for the smoothing subband and detail subbands are designed respectively according to their own characteristics so that both the structure and detail information can be fully retained. The fusion process mainly consists of the following three steps. Firstly, each source image is decomposed into a smoothing subband and several detail subbands by utilizing the EPID framework. Then, the subbands are fused by different fusion rules respectively to obtain a fused smoothing subband and a series of fused detail subands. Finally, the final fused image is reconstructed with less distortions by synthesizing the fused smoothing subband and a series of fused detail subands. Experimental results demonstrate the superiority of the proposed algorithm in terms of the visual perception and objective assessments.
C1 [Yu, Shuang; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Yu, Shuang; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Ma, Mingrui] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Chen, Shiping] CSIRO Data61, Sydney, NSW 2016, Australia.
C3 Jilin University; Jilin University; Jilin University; Commonwealth
   Scientific & Industrial Research Organisation (CSIRO)
RP Zhang, XL (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Ma, Mingrui/HDO-2199-2022; Zhang, Xiaoli/ABC-2210-2021; Chen,
   Shiping/B-7492-2011
OI Ma, Mingrui/0000-0002-0579-1505; Chen, Shiping/0000-0002-4603-0024
FU National Natural Science Foundation of China [61801190, 61272209];
   Nature Science Foundation of Jilin Province [20180101055JC]; Outstanding
   Young Talent Foundation of Jilin Province [20180520029JH]; China
   Postdoctoral Science Foundation [2017M611323]; Industrial Technology
   Research and Development Funds of Jilin Province [2019C054-3]; National
   Science & Technology Pillar Program of China [2012BAH48F02]
FX The work was supported in part by the National Natural Science
   Foundation of China under Grant 61801190 and 61272209, in part by the
   Nature Science Foundation of Jilin Province under Grant 20180101055JC,
   in part by the Outstanding Young Talent Foundation of Jilin Province
   under Grant 20180520029JH, in part by the China Postdoctoral Science
   Foundation under Grant 2017M611323, in part by the Industrial Technology
   Research and Development Funds of Jilin Province under Grant 2019C054-3,
   and in part by the National Science & Technology Pillar Program of China
   under Grant 2012BAH48F02.
CR Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Bai XZ, 2011, IMAGE VISION COMPUT, V29, P829, DOI 10.1016/j.imavis.2011.09.003
   Banharnsakun A, 2019, NEURAL COMPUT APPL, V31, P2025, DOI 10.1007/s00521-015-2061-2
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chai Y, 2011, OPT COMMUN, V284, P4376, DOI 10.1016/j.optcom.2011.05.046
   Costa MGF, 2019, BIOMED SIGNAL PROCES, V49, P289, DOI 10.1016/j.bspc.2018.12.018
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Garg R, 2014, 2014 RECENT ADVANCES IN ENGINEERING AND COMPUTATIONAL SCIENCES (RAECS)
   Gong YH, 2017, IEEE T IMAGE PROCESS, V26, P1786, DOI 10.1109/TIP.2017.2658954
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Haghighat M.B.A, 2010, 2010 6 IRANIAN C MAC, P1
   Hayat N, 2019, J VIS COMMUN IMAGE R, V62, P295, DOI 10.1016/j.jvcir.2019.06.002
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li HF, 2017, SIGNAL PROCESS, V138, P71, DOI 10.1016/j.sigpro.2017.03.008
   Li HF, 2016, SIGNAL PROCESS, V128, P474, DOI 10.1016/j.sigpro.2016.05.015
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li TJ, 2011, INFORM FUSION, V12, P85, DOI 10.1016/j.inffus.2010.03.007
   Liu SM, 2020, IEEE T CIRC SYST VID, V30, P1374, DOI 10.1109/TCSVT.2019.2901809
   Liu XB, 2016, BIOMED SIGNAL PROCES, V30, P140, DOI 10.1016/j.bspc.2016.06.013
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JL, 2017, CHIN CONTR CONF, P5464, DOI 10.23919/ChiCC.2017.8028223
   May KA, 2007, VISION RES, V47, P1705, DOI 10.1016/j.visres.2007.02.012
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Piccinini F, 2012, MICROSC RES TECHNIQ, V75, P1582, DOI 10.1002/jemt.22104
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Tan W, 2018, APPL OPTICS, V57, P10092, DOI 10.1364/AO.57.010092
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan T, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107065
   Zhan K., 2015, J INF HIDING MULTIME, V6, P600
   Zhan K, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033014
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao H, 2008, IMAGE VISION COMPUT, V26, P1285, DOI 10.1016/j.imavis.2008.03.007
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
NR 47
TC 7
Z9 7
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5673
EP 5700
DI 10.1007/s11042-020-09877-4
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600007
DA 2024-07-18
ER

PT J
AU El Hanouti, I
   El Fadili, H
   Zenkouar, K
AF El Hanouti, Imad
   El Fadili, Hakim
   Zenkouar, Khalid
TI Breaking an image encryption scheme based on Arnold map and Lucas series
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Image encryption; Equivalent keys; Chosen-plaintext
   attack; Arnold map; Lucas series
ID 2-DIMENSIONAL CHAOTIC MAP; DNA-SEQUENCE OPERATION; SECURITY ANALYSIS;
   CRYPTANALYSIS
AB Recently, a novel image encryption based on Arnold scrambling and Lucas series has been proposed in the literature. The scheme design is based on permutation-substitution operations, where Arnold map is used to permute pixels of the image forTrounds, and Lucas sequence is used to mask the image and substitute pixel's values. The authors of the cryptosystem have already tested their system against several statistical tests to show its robustness from a statistical view. This cryptanalytic paper scrutinizes the security of this cryptosystem in order to evaluate its immunity against conventional attacks. The results and methods adopted in this paper show that besides the statistical tests, we may need a deep cryptanalysis of every newly proposed cryptosystem before possible adoption in real applications. Those security results should be considered in further proposals.
C1 [El Hanouti, Imad; El Fadili, Hakim] SMBA Univ, Comp Sci & Interdisciplinary Phys Lab LIPI, Fes, Morocco.
   [Zenkouar, Khalid] SMBA Univ, Lab Intelligent Syst & Applicat LSIA, FST, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Hanouti, I (corresponding author), SMBA Univ, Comp Sci & Interdisciplinary Phys Lab LIPI, Fes, Morocco.
EM imad.elhanouti@usmba.ac.ma
RI fadili, hakim el/ABH-9598-2020; Hanouti, imad El/AAV-4597-2021
OI Hanouti, imad El/0000-0001-7228-2818
CR Ahmad J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030350
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arroyo D, 2009, IFAC P VOLUMES
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Bin Muhaya F, 2009, LECT NOTES COMPUTER
   Boussif M, 2019, MULTIMED TOOLS APPL, V78, P35493, DOI 10.1007/s11042-019-08108-9
   Broemeling LD, 2011, AM STAT, V65, P255, DOI 10.1198/tas.2011.10191
   Du M, 2018, IEEE COMMUN MAG, V56, P62, DOI 10.1109/MCOM.2018.1701148
   Dunlap RA, 2010, GOLDEN RATIO FIBONAC
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Farajallah M, 2018, MULTIMED TOOLS APPL, V77, P28225, DOI 10.1007/s11042-018-6015-4
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Hraoui S, 2013, 2013 ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS (AICCSA)
   Hraoui S, 2019, PROCEDIA COMPUTER SC
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Lamy-Bergot C, 2011, MULTIMED TOOLS APPL, V55, P261, DOI 10.1007/s11042-010-0571-6
   LAREW K, 1968, AM HIST REV, V74, P537, DOI 10.2307/1853680
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li HN, 2017, IEEE MULTIMEDIA, V24, P14
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Lian SG, 2008, MULTIMED TOOLS APPL, V38, P75, DOI 10.1007/s11042-007-0150-7
   Lin ZH, 2019, MULTIMED TOOLS APPL, V78, P20511, DOI 10.1007/s11042-018-6824-5
   Masood F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111893
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Nance J, 2011, ARXIV11112984
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Subramanyan B, 2011, P 2 INT C EM APPL EM
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wightman AS, 1968, MONOGRAPHIES INT MAT, V80, piv, DOI [10.1126/science.159.3821.1344, DOI 10.1126/SCIENCE.159.3821.1344]
   Wu Y., 2011, CYBERJOURNALS
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang Y, 2019, MULTIMED TOOLS APPL, V78, P31303, DOI 10.1007/s11042-019-07894-6
NR 39
TC 10
Z9 10
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4975
EP 4997
DI 10.1007/s11042-020-09815-4
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600005
DA 2024-07-18
ER

PT J
AU Sanches, SRR
   Sementille, AC
   Aguilar, IA
   Freire, V
AF Sanches, Silvio Ricardo Rodrigues
   Sementille, Antonio Carlos
   Aguilar, Ivan Abdo
   Freire, Valdinei
TI Recommendations for evaluating the performance of background subtraction
   algorithms for surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Performance assessment; Recommendations;
   Surveillance systems
ID MOVING OBJECT DETECTION; KERNEL DENSITY-ESTIMATION; GAUSSIAN
   MIXTURE-MODELS; LOW-RANK; FOREGROUND SEGMENTATION; SUBSPACE TRACKING;
   ILLUMINATION; PIXEL; RECONSTRUCTION; REPRESENTATION
AB Background subtraction is a prerequisite for a wide range of applications, including video surveillance systems. A significant number of algorithms are often developed and published in different publication mediums in the area, such as workshops, symposiums, conferences, and journals. An important task in presenting a new background subtraction algorithms is to clearly show that its performance outperforms the performance of the state-of-the-art algorithms. In this paper, we present recommendations on how to evaluate the performance of background subtraction algorithms for surveillance systems. We identified, through a systematic mapping, the key steps and components of this evaluation process - procedures, methods, and tools - most used by the authors in each of these steps. Considering this statistical analysis, we perform a theoretical analysis of the most used key components to identify their pros and cons. Then, we define a set of recommendations that aim to standardize and clarify the performance evaluation process of a new background subtraction algorithm.
C1 [Sanches, Silvio Ricardo Rodrigues] Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
   [Sementille, Antonio Carlos] Univ Estadual Paulista, Bauru, SP, Brazil.
   [Aguilar, Ivan Abdo] Simon Fraser Univ, Burnaby, BC, Canada.
   [Freire, Valdinei] Univ Sao Paulo, Elect Engn, Sao Paulo, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade Estadual
   Paulista; Simon Fraser University; Universidade de Sao Paulo
RP Sanches, SRR (corresponding author), Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
EM silviosanches@utfpr.edu.br; antonio.semente@unesp.br; iaguilar@sfu.ca;
   valdinei.freire@usp.br
RI Silva, Valdinei F/C-8663-2014; Sanches, Silvio RR/J-6357-2013
OI Sanches, Silvio/0000-0003-3635-7477; Aguilar, Ivan/0000-0002-8735-4041
CR Ahn JH, 2014, INT C PATT RECOG, P2555, DOI 10.1109/ICPR.2014.441
   Akilan T, 2020, IEEE T INTELL TRANSP, V21, P959, DOI 10.1109/TITS.2019.2900426
   Akilan T, 2018, MIDWEST SYMP CIRCUIT, P889, DOI 10.1109/MWSCAS.2018.8623825
   Ramirez-Quintana JA, 2015, PATTERN RECOGN, V48, P1137, DOI 10.1016/j.patcog.2014.09.009
   Alvar M, 2014, MACH VISION APPL, V25, P1133, DOI 10.1007/s00138-013-0550-9
   Alvarez-Meza AM, 2014, INT C PATT RECOG, P2590, DOI 10.1109/ICPR.2014.447
   [Anonymous], 2014, BACKGROUND SUBTRACTI
   [Anonymous], 2018, PROC INT C COMP APPL
   Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Balcilar M, 2016, SIGNAL IMAGE VIDEO P, V10, P85, DOI 10.1007/s11760-014-0705-9
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Berjón D, 2018, PATTERN RECOGN, V74, P156, DOI 10.1016/j.patcog.2017.09.009
   Biao Y, 2015, OPTIK, V126, P4586, DOI 10.1016/j.ijleo.2015.08.064
   Bispo J, 2015, P 2 ACM SIGPLAN INT, DOI [10.1145/2774959.2774961, DOI 10.1145/2774959.2774961]
   Bloisi DD, 2014, MACH VISION APPL, V25, P1257, DOI 10.1007/s00138-013-0554-5
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262
   Chan KL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0308-4
   Chan KL, 2015, MACH VISION APPL, V26, P723, DOI 10.1007/s00138-015-0696-8
   Chen A, 2018, J CLIN MED, V7, DOI 10.3390/jcm7010010
   Chen BH, 2018, NEUROCOMPUTING, V273, P481, DOI 10.1016/j.neucom.2017.08.002
   Chen XR, 2015, OPTIK, V126, P2256, DOI 10.1016/j.ijleo.2015.05.122
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Chiu WY, 2014, J REAL-TIME IMAGE PR, V9, P647, DOI 10.1007/s11554-011-0240-7
   Cocorullo Giuseppe, 2019, Journal of Real-Time Image Processing, V16, P1407, DOI 10.1007/s11554-016-0651-6
   De Gregorio M, 2014, IEEE COMPUT SOC CONF, P409, DOI 10.1109/CVPRW.2014.66
   Dou JF, 2017, SIGNAL IMAGE VIDEO P, V11, P407, DOI 10.1007/s11760-016-0975-5
   Dou JF, 2015, NEUROCOMPUTING, V168, P382, DOI 10.1016/j.neucom.2015.05.088
   Dou JF, 2014, OPTIK, V125, P435, DOI 10.1016/j.ijleo.2013.06.079
   Duan LH, 2020, IEEE GEOSCI REMOTE S, V17, P686, DOI 10.1109/LGRS.2019.2926412
   El Hamzaoui H, 2014, MATER RES EXPRESS, V1, DOI 10.1088/2053-1591/1/2/026203
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Elguebaly T, 2014, MACH VISION APPL, V25, P1145, DOI 10.1007/s00138-013-0568-z
   Elharrouss O, 2015, OPTIK, V126, P5992, DOI 10.1016/j.ijleo.2015.08.084
   Erichson NB, 2016, COMPUT VIS IMAGE UND, V146, P40, DOI 10.1016/j.cviu.2016.02.005
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Ge WF, 2016, PATTERN RECOGN, V59, P112, DOI 10.1016/j.patcog.2016.01.031
   Ge WF, 2014, INT C PATT RECOG, P2341, DOI 10.1109/ICPR.2014.406
   Gemignani G, 2016, IEEE T IMAGE PROCESS, V25, P5239, DOI 10.1109/TIP.2016.2605004
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo CS, 2014, MULTIMED TOOLS APPL, V72, P2633, DOI 10.1007/s11042-013-1566-x
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hernandez-Lopez FJ, 2014, MACH VISION APPL, V25, P1175, DOI 10.1007/s00138-013-0564-3
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Holtzhausen PJ, 2015, J REAL-TIME IMAGE PR, V10, P423, DOI 10.1007/s11554-012-0287-0
   López-Rubio FJ, 2015, COMPUT VIS IMAGE UND, V133, P30, DOI 10.1016/j.cviu.2014.12.007
   Jeeva S, 2019, CLUSTER COMPUT, V22, P11659, DOI 10.1007/s10586-017-1446-7
   Jeyabharathi D, 2018, J VIS COMMUN IMAGE R, V55, P434, DOI 10.1016/j.jvcir.2018.06.024
   Jeyabharathi D, 2016, MULTIMED TOOLS APPL, V75, P17617, DOI 10.1007/s11042-016-3772-9
   Ji ZJ, 2014, PATTERN RECOGN, V47, P2952, DOI 10.1016/j.patcog.2014.03.016
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kermani E, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-27
   Khraief C, 2020, MULTIMED TOOLS APPL, V79, P19537, DOI 10.1007/s11042-020-08812-x
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim W, 2018, MULTIMED TOOLS APPL, V77, P19439, DOI 10.1007/s11042-017-5410-6
   Kryjak T, 2014, J REAL-TIME IMAGE PR, V9, P61, DOI 10.1007/s11554-012-0290-5
   Kushwaha AKS, 2016, MULTIMED TOOLS APPL, V75, P16209, DOI 10.1007/s11042-015-2927-4
   Lee S, 2014, EVID-BASED COMPL ALT, V2014, DOI 10.1155/2014/967462
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li XY, 2018, OPTIK, V156, P659, DOI 10.1016/j.ijleo.2017.11.174
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Lim Kyungsun., 2017, Advanced Video and Signal Based Surveillance (AVSS), 2017 14th IEEE International Conference on, P1
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Ling Q, 2014, NEUROCOMPUTING, V133, P32, DOI 10.1016/j.neucom.2013.11.034
   Luo J, 2016, SIGNAL PROCESS, V124, P27, DOI 10.1016/j.sigpro.2015.10.036
   Ma MS, 2018, CHINA COMMUN, V15, P156, DOI 10.1109/CC.2018.8424611
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2014, COMPUT VIS IMAGE UND, V122, P65, DOI 10.1016/j.cviu.2013.11.006
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Microsoft Corporation, 2019, TEST IM WALLFL PAP
   Nakagawa E. Y., 2017, REVISAO SISTEMATICA
   Pal SankarK., 2012, Handbook on Soft Computing for Video Surveillance
   Panda DK, 2018, J VIS COMMUN IMAGE R, V56, P52, DOI 10.1016/j.jvcir.2018.07.014
   Parsa AB, 2020, ACCIDENT ANAL PREV, V136, DOI 10.1016/j.aap.2019.105405
   Petersen K, 2008, 12 INT C EV ASS SOFT, P1, DOI 10.5555/2227115.2227123
   Qin LX, 2015, J VIS COMMUN IMAGE R, V32, P1, DOI 10.1016/j.jvcir.2015.07.010
   Quach KG, 2017, COMPUT VIS IMAGE UND, V158, P126, DOI 10.1016/j.cviu.2017.03.002
   Raman R, 2018, MULTIMED TOOLS APPL, V77, P741, DOI 10.1007/s11042-016-4234-0
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Rashid ME, 2016, PROC TECH, V25, P536, DOI 10.1016/j.protcy.2016.08.142
   Roberto R, 2016, COMPUT GRAPH-UK, V56, P20, DOI 10.1016/j.cag.2016.02.002
   Sakkos D, 2018, MULTIMED TOOLS APPL, V77, P23023, DOI 10.1007/s11042-017-5460-9
   Salvadori C, 2017, J REAL-TIME IMAGE PR, V13, P273, DOI 10.1007/s11554-014-0402-5
   Sanches SRR, 2019, MULTIMED TOOLS APPL, V78, P32393, DOI 10.1007/s11042-019-07958-7
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Savas MF, 2018, OPTIK, V168, P605, DOI 10.1016/j.ijleo.2018.04.047
   Schick A., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P27, DOI DOI 10.1109/CVPRW.2012.6238923
   Seidel F, 2014, MACH VISION APPL, V25, P1227, DOI 10.1007/s00138-013-0555-4
   Seo JW, 2016, SIGNAL IMAGE VIDEO P, V10, P29, DOI 10.1007/s11760-014-0697-5
   Shah M, 2014, MACH VISION APPL, V25, P1105, DOI 10.1007/s00138-013-0552-7
   Shah N, 2017, IEEE INT SYMP SIGNAL, P13, DOI 10.1109/ISSPIT.2017.8388311
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Shi G, 2018, IEEE T IMAGE PROCESS, V27, P4810, DOI 10.1109/TIP.2018.2845123
   Shimada A, 2014, MACH VISION APPL, V25, P1121, DOI 10.1007/s00138-013-0563-4
   Silva C, 2017, P INT C PATT REC, P2216, DOI [10.1109/ICPR.2016.7899965, DOI 10.1109/ICPR.2016.7899965]
   Sobral A, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   St-Charles PL, 2014, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW.2014.67
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subudhi BN, 2017, MULTIMED TOOLS APPL, V76, P13511, DOI 10.1007/s11042-016-3698-2
   Sultana M, 2019, MACH VISION APPL, V30, P375, DOI 10.1007/s00138-018-0993-0
   Sun L, 2015, MULTIMED TOOLS APPL, V74, P3947, DOI 10.1007/s11042-013-1806-0
   Thien HT, 2017, IEEE T CIRC SYST VID, V27, P1478, DOI 10.1109/TCSVT.2016.2543118
   Nguyen TP, 2019, IEEE T CIRC SYST VID, V29, P433, DOI 10.1109/TCSVT.2018.2795657
   Tsung-Han Tsai, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P691, DOI 10.1109/ICGEC.2010.176
   Universite de Sherbrooke, 2018, CHANGEDETECTION NET
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Varadarajan S, 2015, COMPUT VIS IMAGE UND, V136, P45, DOI 10.1016/j.cviu.2014.12.004
   Varghese A., 2015, 2015 Global Conference on Communication Technologies (GCCT), P380, DOI DOI 10.1109/GCCT.2015.7342688
   Varghese A., 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI DOI 10.1186/S41074-017-0036-1
   Vijayan M, 2018, OPTIK, V168, P963, DOI 10.1016/j.ijleo.2018.05.012
   Wang B, 2014, OPTIK, V125, P1406, DOI 10.1016/j.ijleo.2013.08.034
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wen JJ, 2014, IEEE T CIRC SYST VID, V24, P2034, DOI 10.1109/TCSVT.2014.2333132
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu XH, 2019, MULTIMED TOOLS APPL, V78, P16507, DOI 10.1007/s11042-018-7037-7
   Xia HY, 2016, SIGNAL IMAGE VIDEO P, V10, P343, DOI 10.1007/s11760-014-0747-z
   Xiao HX, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0150-5
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yang MH, 2015, IEEE T CIRC SYST VID, V25, P595, DOI 10.1109/TCSVT.2014.2361418
   Yang SC, 2018, SIGNAL IMAGE VIDEO P, V12, P693, DOI 10.1007/s11760-017-1209-1
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Yoshinaga S, 2014, COMPUT VIS IMAGE UND, V122, P84, DOI 10.1016/j.cviu.2013.10.015
   Zeng Z, 2016, COMPUT VIS IMAGE UND, V152, P58, DOI 10.1016/j.cviu.2016.08.009
   Zhang C, 2017, MULTIMED TOOLS APPL, V76, P22077, DOI 10.1007/s11042-017-4802-y
   Zhang RG, 2017, SIGNAL IMAGE VIDEO P, V11, P841, DOI 10.1007/s11760-016-1030-2
   Zhang XG, 2015, MACH VISION APPL, V26, P871, DOI 10.1007/s00138-015-0703-0
   Zheng Z, 2018, P 32 INT C NEUR INF, P7913
   Zhou MN, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, P33
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu T, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P1379, DOI 10.1109/ICCSNT.2015.7490985
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 151
TC 3
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4421
EP 4454
DI 10.1007/s11042-020-09838-x
EA SEP 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573766700004
DA 2024-07-18
ER

PT J
AU Mehta, D
   Saxena, S
AF Mehta, Deepak
   Saxena, Sharad
TI Hierarchical WSN protocol with fuzzy multi-criteria clustering and
   bio-inspired energy-efficient routing (FMCB-ER)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical routing protocol; Grid cluster formation; Emperor penguin
   optimization; Multi criteria decision making
ID WIRELESS SENSOR NETWORKS; LEACH; ALGORITHM
AB Wireless Sensors Network (WSN) is used for monitoring and recording the physical environment and to transfer the sensed data to a central location by means of widely distributed sensor nodes. One of the major issues with WSNs is limited energy of sensor nodes and high energy consumption during data relay. An energy efficient routing protocol that consumes less energy in data transmission can enhance the network lifetime to a great extent. Considering it, this paper presents, a hierarchical routing protocol Fuzzy Multi-criteria Clustering and Bio-inspired Energy-efficient Routing (FMCB-ER) to enhance network lifetime thus improving upon the operational time of WSN based applications. Here in this approach a grid-based clustering technique is used to form the robust clusters. An adaptive Fuzzy Multi-Criteria Decision-Making (AF-MCDM) that combines Fuzzy-AHP and TOPSIS is then applied for optimum cluster head (CH) selection. For the purpose, the approach considersthreebroad parameters namely, energy, QoS and node position along with their six sub-criteria. After CH selection, the Emperor Penguin Optimization (EPO) is used to find optimal route for data transmission from CH to sink. The proposed method is evaluated and compared with other existing routing approaches on parameters of energy consumption, lifetime, throughput, end to end delay, jitter, packet delivery ratio, latency, number of dead, alive nodes. Simulation results confirm that the proposed approach outperforms the compared approaches on above discussed parameters. Especially, the proposed approach reduces the energy consumption up to 13% and increases the network lifetime up to 8% in comparison to compared approaches.
C1 [Mehta, Deepak; Saxena, Sharad] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Mehta, D (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM deepak.mehta@thapar.edu; sharad.saxena@thapar.edu
OI Mehta, Deepak/0000-0001-8502-1203
CR Arora VK, 2016, OPTIK, V127, P6590, DOI 10.1016/j.ijleo.2016.04.041
   Bear GS, 2016, IEEE ACCESS, V4, P3182, DOI 10.1109/ACCESS.2016.2576475
   Bulut E, 2018, INT SER OPER RES MAN, V260, P31, DOI 10.1007/978-3-319-62338-2_3
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dutt S, 2018, LECT NOTES NETWORKS, P117
   El-said SA, 2016, SOFT COMPUT, V20, P4549, DOI 10.1007/s00500-015-1762-x
   Gill RK, 2017, ADV INTELL SYST COMP, P377
   Gupta V., 2017, ADV INTELLIGENT SYST, P399
   Haque M, 2018, LECT NOTE NETW SYST, V19, P237, DOI 10.1007/978-981-10-5523-2_22
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Hidoussi F, 2017, WIRELESS PERS COMMUN, V96, P4929, DOI 10.1007/s11277-017-4963-z
   Huang HJ, 2017, COMPUT NETW, V129, P51, DOI 10.1016/j.comnet.2017.08.011
   Isabel RA, 2018, WIRELESS PERS COMMUN, V101, P201, DOI 10.1007/s11277-018-5683-8
   Jadidoleslamy H, 2017, WIRELESS PERS COMMUN, V96, P4217, DOI 10.1007/s11277-017-4382-1
   Khabiri M, 2018, WIRELESS PERS COMMUN, V98, P2473, DOI 10.1007/s11277-017-4983-8
   Khan BM, 2018, ADV WIRELESS TECHNOL, P312
   Liu X, 2018, INT CONF ASIAN LANG, P74, DOI 10.1109/IALP.2018.8629143
   Logambigai R, 2018, COMPUT ELECTR ENG, V68, P62, DOI 10.1016/j.compeleceng.2018.03.036
   Lotf J. J, 2010, COMP ENG TECHN ICCET, P3
   Marappan P, 2016, WIREL NETW, V22, P1415, DOI 10.1007/s11276-015-1063-4
   Mehta D, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100406
   Mondal S, 2017, LECT NOTES NETW SYST, P163
   Mostafaei H, 2019, IEEE T IND ELECTRON, V66, P5567, DOI 10.1109/TIE.2018.2869345
   Munuswamy S, 2018, TURK J ELECTR ENG CO, V26, P1444, DOI 10.3906/elk-1706-226
   Razaque A, 2016, APPL TECHNOL C LISAT, V2016, P1
   Singh R, 2017, AEU-INT J ELECTRON C, V72, P166, DOI 10.1016/j.aeue.2016.12.001
   Sivakumar P, 2018, PROCEDIA COMPUT SCI, V125, P248, DOI 10.1016/j.procs.2017.12.034
   Tanwar S, 2019, IEEE SYST J, V13, P313, DOI 10.1109/JSYST.2018.2818618
   Tanwar S, 2014, INT J COMMUN SYST, V27, P1289, DOI 10.1002/dac.2780
   Thangaramya K, 2019, COMPUT NETW, V151, P211, DOI 10.1016/j.comnet.2019.01.024
   Tunca C, 2015, IEEE T MOBILE COMPUT, V14, P1947, DOI 10.1109/TMC.2014.2366776
   Tyagi S, 2015, TELECOMMUN SYST, V59, P43, DOI 10.1007/s11235-014-9884-5
   Wang CZ, 2018, CHEMPHOTOCHEM, V2, P749, DOI 10.1002/cptc.201800053
   Wang Ke, 2016, Journal of China Universities of Posts and Telecommunications, V23, P46, DOI 10.1016/S1005-8885(16)60044-4
   Zhang Y., 2018, SOC INFO TELECOM ENG, V237, P3
NR 35
TC 25
Z9 26
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35083
EP 35116
DI 10.1007/s11042-020-09633-8
EA SEP 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000570032000001
DA 2024-07-18
ER

PT J
AU Fakhari, A
   Kiani, K
AF Fakhari, Ali
   Kiani, Kourosh
TI A new restricted boltzmann machine training algorithm for image
   restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Generative models; RBM; Contrastive divergence
ID SPARSE; REPRESENTATIONS
AB A variety of approaches have been proposed for addressing different image restoration challenges. Recently, deep generative models were one of the mostly used ones. In this paper, a new Restricted Boltzmann Machines (RBM) training algorithm for addressing corrupted data has been proposed. RBMs can be trained both supervised and unsupervised, however they are very sensitive to noise and occlusion. The proposed algorithm enables the RBM to be robust against corruptions. Using the new algorithm, we have given the RBM a posterior knowledge about desired or clean data. Despite other methods, the proposed algorithm works fine without changing the architecture of the model or adding any regularization term. Concretely, the RBM can be used as a robust feature extractor, even for unclean data. By creating different corrupted versions for each image instance, and using the original version in the reconstruction phase, the RBM can learn the desired probability distribution of data. Experimental results confirm the robustness of the model against different types of corruption.
C1 [Fakhari, Ali; Kiani, Kourosh] Semnan Univ, Elect & Comp Engn Fac, Semnan, Iran.
C3 Semnan University
RP Kiani, K (corresponding author), Semnan Univ, Elect & Comp Engn Fac, Semnan, Iran.
EM fakhari.ali@semnan.ac.ir; kourosh.kiani@semnan.ac.ir
RI Kiani, Kourosh/T-7468-2019
OI Kiani, Kourosh/0000-0001-6582-8691
CR [Anonymous], 2010, International Conference on Artificial Intelligence and Statistics
   Basu S, 2017, NEURAL PROCESS LETT, V45, P855, DOI 10.1007/s11063-016-9556-4
   Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647
   Chan T, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P17, DOI 10.1007/0-387-28831-7_2
   Choo S, 2018, NEUROCOMPUTING, V275, P1813, DOI 10.1016/j.neucom.2017.10.018
   Dabov K, 2008, PROC SPIE, V6812, DOI 10.1117/12.766355
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P30707, DOI 10.1007/s11042-018-6521-4
   Gao JB, 2013, IEEE IMAGE PROC, P499, DOI 10.1109/ICIP.2013.6738103
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Jansen C, 2015, IEEE INT SYM MULTIM, P323, DOI 10.1109/ISM.2015.68
   Le Roux N, 2011, NEURAL COMPUT, V23, P593, DOI 10.1162/NECO_a_00086
   Mao XJ, 2016, ADV NEUR IN, V29
   Melchior J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171015
   Mu YY, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P316, DOI 10.1109/MVA.2015.7153194
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Pires R, 2017, SIBGRAPI, P390, DOI 10.1109/SIBGRAPI.2017.58
   Selvi AS, 2019, MULTIMED TOOLS APPL, P4115
   Tang YC, 2012, PROC CVPR IEEE, P2264, DOI 10.1109/CVPR.2012.6247936
   Wang N., 2012, ESANN
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang Y, 2020, ARXIV200108878
   Zhang N, 2018, NEUROCOMPUTING, V275, P1186, DOI 10.1016/j.neucom.2017.09.065
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
NR 35
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2047
EP 2062
DI 10.1007/s11042-020-09685-w
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700006
DA 2024-07-18
ER

PT J
AU Yu, LJ
   Fan, GL
AF Yu, Liangjiang
   Fan, Guoliang
TI <i>DrsNet</i>: Dual-resolution semantic segmentation with rare
   class-oriented superpixel prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Rare class; Dual resolution; Super-pixels; Label
   transfer; CNN
ID NEURAL-NETWORKS; SCENE; CLASSIFICATION
AB Rare-class objects in natural scene images that are usually small and less frequent often convey more important information for scene understanding than the common ones. However, they are often overlooked in scene labeling studies due to two main reasons, low occurrence frequency and limited spatial coverage. Many methods have been proposed to enhance overall semantic labeling performance, but only a few consider rare-class objects. In this work, we present a deep semantic labeling framework with special consideration of rare classes via three techniques. First, a novel dual-resolution coarse-to-fine superpixel representation is developed, where fine and coarse superpixels are applied to rare classes and background areas respectively. This unique dual representation allows seamless incorporation of shape features into integrated global and local convolutional neural network (CNN) models. Second, shape information is directly involved during the CNN feature learning for both frequent and rare classes from the re-balanced training data, and also explicitly involved in data inference. Third, the proposed framework incorporates both shape information and the CNN architecture into semantic labeling through a fusion of probabilistic multi-class likelihood. Experimental results demonstrate competitive semantic labeling performance on two standard datasets both qualitatively and quantitatively, especially for rare-class objects.
C1 [Yu, Liangjiang; Fan, Guoliang] Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
C3 Oklahoma State University System; Oklahoma State University - Stillwater
RP Fan, GL (corresponding author), Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
EM liangjiang.yu@okstate.edu; guoliang.fan@okstate.edu
RI Fan, Guoliang/G-2893-2011
OI Fan, Guoliang/0000-0002-8584-9040
FU US National Institutes of Health (NIH) [R15 AG061833]; Oklahoma Center
   for the Advancement of Science and Technology (OCAST) Health Research
   Grant [HR18-069]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions that helped us improve this paper.
   This work is supported in part by the US National Institutes of Health
   (NIH) Grant R15 AG061833 and the Oklahoma Center for the Advancement of
   Science and Technology (OCAST) Health Research Grant HR18-069.
CR Abdulnabi AH, 2018, IEEE T MULTIMEDIA, V20, P1656, DOI 10.1109/TMM.2017.2774007
   Abdulnabi AH, 2017, PROC CVPR IEEE, P6278, DOI 10.1109/CVPR.2017.665
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2015, P BRIT MACH VIS C BM
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   [Anonymous], 2016, ARXIV160906694
   [Anonymous], 2019, MULTIMED TOOLS APPL
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BYEON W, 2015, PROC CVPR IEEE, P3547, DOI DOI 10.1109/CVPR.2015.7298977
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Das A, 2019, ADV INTELL SYST COMP, V740, P297, DOI 10.1007/978-981-13-1280-9_28
   Eigen D, 2012, PROC CVPR IEEE, P2799, DOI 10.1109/CVPR.2012.6248004
   Fan H, 2018, ARXIV181104778
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   George M, 2015, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2015.7298985
   Gould S, 2014, LECT NOTES COMPUT SC, V8689, P632, DOI 10.1007/978-3-319-10590-1_41
   Gould S, 2012, LECT NOTES COMPUT SC, V7576, P439, DOI 10.1007/978-3-642-33715-4_32
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   He XM, 2004, PROC CVPR IEEE, P695
   Hung WC, 2017, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2017.287
   Kang B, 2018, IEEE T MULTIMEDIA, V20, P2478, DOI 10.1109/TMM.2018.2798282
   Kosov S, 2019, MULTIMED TOOLS APPL, V78, P2551, DOI 10.1007/s11042-018-6298-5
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Larlus D, 2008, PROC CVPR IEEE, P864
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Liang M., 2015, Advances in Neural Information Processing Systems, P937
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liangjiang Yu, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P309, DOI 10.1007/978-3-319-50835-1_29
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Mottaghi R, 2013, PROC CVPR IEEE, P3143, DOI 10.1109/CVPR.2013.404
   Pinheiro Pedro., 2014, International conference on machine learning. PMLR, P82
   Ruiz-Sarmiento JR, 2017, INT J ROBOT RES, V36, P131, DOI 10.1177/0278364917695640
   Shi HC, 2018, IEEE T MULTIMEDIA, V20, P2670, DOI 10.1109/TMM.2018.2812600
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Shuai B, 2018, IEEE T PATTERN ANAL, V40, P1480, DOI 10.1109/TPAMI.2017.2712691
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Shuai B, 2016, IEEE T IMAGE PROCESS, V25, P2379, DOI 10.1109/TIP.2016.2533862
   Singh G, 2013, PROC CVPR IEEE, P3151, DOI 10.1109/CVPR.2013.405
   Stollenga MF, 2015, ADV NEUR IN, V28
   Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tung F, 2014, LECT NOTES COMPUT SC, V8694, P511, DOI 10.1007/978-3-319-10599-4_33
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Verbeek J., 2008, Advances in Neural Information Processing Systems, P1553
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wang SW, 2017, IEEE INT WORKSH MULT
   Wang Z, 2017, ARXIV170602493
   Wu Z., 2016, ARXIV160506885
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang JM, 2014, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2014.415
   Yang Y, 2020, ARXIV200108878
   Yu F., 2015, ARXIV
   Zhang H, 2018, IEEE ICC
   Zhang YM, 2012, PROC CVPR IEEE, P582, DOI 10.1109/CVPR.2012.6247724
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao J, 2017, MULTIMED TOOLS APPL, V76, P9169, DOI 10.1007/s11042-016-3513-0
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 71
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1687
EP 1706
DI 10.1007/s11042-020-09691-y
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765600003
PM 33776547
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Li, YZ
   Hu, YJ
AF Zhang, Qiu-yu
   Li, Yu-zhou
   Hu, Ying-jie
TI A retrieval algorithm for encrypted speech based on convolutional neural
   network and deep hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Convolutional neural network (CNN); Deep
   hashing; Speech feature extraction; Batch normalization algorithm
ID AUDIO
AB In this paper, we propose a retrieval algorithm for encrypted speech based on the convolution neural network (CNN) and deep hashing. It is used to overcome the feature extraction defects of the existing content-based encrypted speech retrieval methods, and solve the problem of low retrieval accuracy caused by high dimensional and temporality of audio data. Firstly, the study encrypts the original speech by the three-dimensional chaotic encryption algorithm and uploads it to the encryption speech library in the cloud. Since CNN can well capture the basic semantic structure features of speech data, we use CNN as a feature extractor to extract deep features from Log-Mel spectrogram/MFCC. The batch normalization algorithm is introduced in the training process, which improves the speed of network fitting, reduces the training time, and improves the retrieval efficiency of the system. Secondly, the deep features extracted from CNN are combined with the hash function to construct the system hashing index table. Finally, the retrieval is implemented by the normalized Hamming distance algorithm. The experimental results show that the proposed algorithm has better discrimination, robustness to amplitude change compared with the existing methods. Meanwhile, the proposed algorithm has a high recall, precision, and retrieval efficiency after various content preserving operations.
C1 [Zhang, Qiu-yu; Li, Yu-zhou; Hu, Ying-jie] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com; alexanderlyz@163.com; modaoshiyan@163.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078). The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the presentation.
CR Alamodi AOA, 2019, CHINESE PHYS B, V28, DOI 10.1088/1674-1056/28/2/020503
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P478, DOI 10.1145/3123266.3123371
   Dhiraj, 2019, MULTIMED TOOLS APPL, V78, P23949, DOI 10.1007/s11042-018-6706-x
   Elizalde B, 2019, INT CONF ACOUST SPEE, P4095, DOI 10.1109/ICASSP.2019.8682632
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Hertel L, 2015, IEEE IJCNN
   Hertel L, 2016, IEEE IJCNN, P3407, DOI 10.1109/IJCNN.2016.7727635
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Juvela L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5679, DOI 10.1109/ICASSP.2018.8461852
   Lei Z, 2015, LECT NOTES ENG COMP, P27
   Li Y, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2619063
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Nayyar RK, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P30, DOI 10.1109/BID.2017.8336569
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Santana LMQD, 2018, IEEE LAT AM T, V16, P918, DOI 10.1109/TLA.2018.8358674
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Spring R, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P445, DOI 10.1145/3097983.3098035
   Sun CW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072399
   Thangavel M, 2016, 2016 INT C REC TREND, P1, DOI DOI 10.1109/ICRTIT.2016.7569581
   Valenti M, 2017, IEEE IJCNN, P1547, DOI 10.1109/IJCNN.2017.7966035
   Wang D., 2015, THCHS-30: A Free Chinese Speech Corpus
   Wang H, 2015, BIOCHEM INSIGHTS, V8, P14, DOI 10.4137/BCI.S30377
   Wang K, 2013, SIXTH INTERNATIONAL CONFERENCE ON NONLINEAR MECHANICS (ICNM-VI), P423
   Wu JF, 2018, IEICE T INF SYST, VE101D, P556, DOI 10.1587/transinf.2017EDL8162
   Wu YZ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P331, DOI 10.1109/ICASSP.2018.8462168
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
   Zhao S, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/4318463
   Zheng W, 2018, APPL INTELL, V48, P3839, DOI 10.1007/s10489-018-1183-5
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
NR 34
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1201
EP 1221
DI 10.1007/s11042-020-09748-y
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700002
DA 2024-07-18
ER

PT J
AU Wang, XF
   Li, B
   Wang, Y
   Lei, JJ
   Xue, JR
AF Wang, Xiaofeng
   Li, Bin
   Wang, Yan
   Lei, Jinjin
   Xue, Jianru
TI An efficient batch images encryption method based on DNA encoding and
   PWLCM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Batch images encryption; Images stacking; PWLCM; DNA encoding
ID ALGORITHM; SCHEME; OPERATION; SEQUENCES; MAP
AB With the rapid development of the Internet, there is a pressing requirement for data security protection in Internet. However, in some applications, resource constrained devices in Internet requires that the algorithm for data encryption have high reliability and availability, as well as extremely low latency, and strong robustness in harsh environment. In this work, we propose an efficient batch images encryption/decryption scheme based on DNA encoding and piecewise linear chaotic mapping system (PWLCM). Different from all existing methods, the proposed method can encrypt/decrypt any number of images with different sizes via only single encryption computation, and the computing cost is equivalent to that of encrypting a single image. Experimental results demonstrate that the proposed method has strong robustness to resist the interference of harsh environment, such as noise contamination, JPEG compression, and image content loss. We also investigate the computing cost, encryption effect and the security. Comparing with the state-of-the-art methods, the proposed method has high encryption efficiency, stronger robustness and security.
C1 [Wang, Xiaofeng; Li, Bin; Wang, Yan; Lei, Jinjin] Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
   [Xue, Jianru] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an Jiaotong University
RP Wang, XF (corresponding author), Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
EM xfwang@xaut.edu.cn
OI Wang, Xiaofeng/0000-0002-0861-8193
FU National Natural Science Foundation of China [61772416]; National Major
   Research and Development Plan Program of China [2016YFB1001004]; Key
   Laboratory Project of the Education Department of Shaanxi Province
   [17JS098]; Shaanxi province technology innovation guiding fund project
   [2018XNCG-G-G-02]; foundation of the State Key Laboratory of Aerospace
   Dynamics
FX This work was supported by the National Natural Science Foundation of
   China under Grant No.61772416; the National Major Research and
   Development Plan Program of China under Grant No.2016YFB1001004; the Key
   Laboratory Project of the Education Department of Shaanxi Province under
   Grant No.17JS098; Shaanxi province technology innovation guiding fund
   project, No.2018XNCG-G-G-02; The foundation of the State Key Laboratory
   of Aerospace Dynamics.
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fu X, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2827059
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhou H, 1997, INT J BIFURCAT CHAOS, V7, P205, DOI 10.1142/S0218127497000145
   Zhou H, 1997, IEEE T CIRCUITS-I, V44, P268, DOI 10.1109/81.557386
   Zhou LH, 2000, IEEE T CIRCUITS-II, V47, P1107, DOI 10.1109/82.877154
NR 30
TC 14
Z9 15
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 943
EP 971
DI 10.1007/s11042-020-09533-x
EA SEP 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900011
DA 2024-07-18
ER

PT J
AU Wang, XY
   Xue, WH
   An, JB
AF Wang, Xingyuan
   Xue, Wenhua
   An, Jubai
TI Image encryption algorithm based on LDCML and DNA coding sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; C-shaped transformation; LDCML system; DNA sequence
ID CHAOS-BASED IMAGE; SEMI-TENSOR PRODUCT; MAP; PERMUTATION; OPERATION
AB This paper proposes a new C-shaped scrambling method and combines it with the Logistic-Dynamics Coupled Map Lattices (LDCML) and DNA coding, thus designing a new image encryption scheme. First, we use the chaotic sequence generated by the LDCML system to perform preliminary scrambling on the original image. Then convert it into a DNA matrix according to a coding rule. After that perform the second scrambling according to the "C" shape. Next, the scrambled DNA matrix is subjected to a diffusion operation using the corresponding DNA sequence of the chaotic sequence generated by the LDCML system and the addition, subtraction and XOR rules of the DNA. At last, the final encrypted image is obtained by performing a DNA decoding operation on the diffused DNA matrix. Simulation experiments and security analysis show that the algorithm is safe and can resist common attack methods.
C1 [Wang, Xingyuan; Xue, Wenhua; An, Jubai] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 1348640958@qq.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR Anand A, 2016, INT C INN CHALL CYB
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   El-Samie F.E. A., 2013, Image encryption: A communication perspective, DOI 10.1201/b1630
   Farwa S, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0135-x
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   KANEKO K, 1985, PROG THEOR PHYS, V74, P1033, DOI 10.1143/PTP.74.1033
   Khellat F, 2011, CHAOS SOLITON FRACT, V44, P934, DOI 10.1016/j.chaos.2011.07.015
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Ma J., 2015, J NETWORK NEW MEDIA, V4, P37
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Song CY, 2015, ENTROPY-SWITZ, V17, P6954, DOI 10.3390/e17106954
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, IEEE ACCESS, V6, P62272, DOI 10.1109/ACCESS.2018.2875676
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wu Min-Sheng, 1998, Chinese Journal of Computers, V21, P514
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 36
TC 23
Z9 23
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 591
EP 614
DI 10.1007/s11042-020-09688-7
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600008
DA 2024-07-18
ER

PT J
AU Li, X
   Hou, ZJ
   Liang, JZ
   Chen, C
AF Li, Xing
   Hou, Zhenjie
   Liang, Jiuzhen
   Chen, Chen
TI Human action recognition based on 3D body mask and depth
   spatial-temporal maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; 3D body mask; Depth spatial-temporal map
AB In this paper, a method based on depth spatial-temporal maps(DSTMs) is presented for human action recognition from depth video sequences, which provides compact global spatial and temporal information of human motion for action recognition. In our approach, the initial frame of depth sequences is dilated to generate 3D body mask. The new depth sequences of major part of the human body are then computed after using 3D body mask on each depth frame. We project each frame of the new depth sequences onto three orthogonal axes to get three binary lists. Under each projection axis, binary lists are stitching in order through an entire depth sequence forming a DSTM. We evaluate our method on two standard databases. Experimental results show that this method could effectively capture the spatial and temporal information of human motion and improve the accuracy of human action recognition.
C1 [Li, Xing; Hou, Zhenjie; Liang, Jiuzhen] Changzhou Univ, Coll Informat Sci & Engn, Changzhou, Jiangsu, Peoples R China.
   [Hou, Zhenjie] Jiangsu Prov Networking & Mobile Internet Technol, Huaian, Peoples R China.
   [Chen, Chen] Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
C3 Changzhou University; University of North Carolina; University of North
   Carolina Charlotte
RP Hou, ZJ (corresponding author), Changzhou Univ, Coll Informat Sci & Engn, Changzhou, Jiangsu, Peoples R China.; Hou, ZJ (corresponding author), Jiangsu Prov Networking & Mobile Internet Technol, Huaian, Peoples R China.
EM lixing03201012@163.com; houzj@cczu.edu.cn; jzliang@cczu.edu.cn;
   chenchen870712@gmail.com
RI Hou, Zhenjie/HKW-7644-2023; Liang, Jiuzhen/HJG-9384-2022
CR Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2014, IEEE ENG MED BIO, P4135, DOI 10.1109/EMBC.2014.6944534
   Chen C, 2014, IEEE ENG MED BIO, P4983, DOI 10.1109/EMBC.2014.6944743
   Davis JW, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P39, DOI 10.1109/EVENT.2001.938864
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang AY, 2009, J AMB INTEL SMART EN, V1, P103, DOI 10.3233/AIS-2009-0016
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang LF, 2015, SIGNAL PROCESS, V106, P245, DOI 10.1016/j.sigpro.2014.08.005
   Zhao NW, 2016, IEEE IJCNN, P4489, DOI 10.1109/IJCNN.2016.7727787
NR 19
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35761
EP 35778
DI 10.1007/s11042-020-09593-z
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000565480700002
DA 2024-07-18
ER

PT J
AU Pang, C
   Wang, WH
   Lan, RS
   Shi, Z
   Luo, XN
AF Pang, Cheng
   Wang, Wenhao
   Lan, Rushi
   Shi, Zhuo
   Luo, Xiaonan
TI Bilinear pyramid network for flower species categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained image classification; Fine-grained visual categorization
   (FGVC); Image classification; Convolutional neural network (CNN); Deep
   learning
AB It is a challenging task to distinguish between numerous species of flowers due to their visually similarities and variations of the pose and structure. Thanks to properly modeling of the local feature interactions, bilinear CNN has succeeded in classifying of many non-rigid fine-grained species including flowers. However, bilinear CNN only computes the feature in a straightforward way without exploring the interactions between features from multiple layers in the network. In this paper, we present a novel Bilinear Pyramid Network (BPN) for flower categorization. Instead of passing through the network and directly feeding the final classifier, features from a convolutional layer are resized and multiplied with that from the former layer, which alternates multiple times to generates prediction vectors using the features from distinct layers. These features encoded from the feature pyramid spontaneously carry multi-level semantic cues, which yields stronger discriminative powers than single-layer features. Experiments show that the proposed network obtains superior classification results on the challenging dataset of flowers.
C1 [Pang, Cheng; Wang, Wenhao; Lan, Rushi; Shi, Zhuo; Luo, Xiaonan] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology
RP Lan, RS (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
EM rslan2016@163.com
RI Wang, Wenhao/AAG-3120-2021
OI Wang, Wenhao/0000-0003-4198-6681; Pang, Cheng/0000-0001-7829-8992
FU National Natural Science Foundation of China [61962014, 61702129,
   61772149, U1701267]; China Postdoctoral Science Foundation
   [2018M633047]; Guangxi Science and Technology Project [AB17195057,
   AA18118039]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61962014, Grant 61702129, Grant
   61772149, and Grant U1701267, in part by the China Postdoctoral Science
   Foundation under Grant 2018M633047, and in part by the Guangxi Science
   and Technology Project under Grant AB17195057 and Grant AA18118039.
CR Angelova A., 2012, DEV DEPLOYMENT LARGE
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   [Anonymous], 2007, BMVC
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Huynh D, 2020, PROC CVPR IEEE, P4482, DOI 10.1109/CVPR42600.2020.00454
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fu SC, 2020, INFORM SCIENCES, V514, P484, DOI 10.1016/j.ins.2019.11.019
   Fu SC, 2019, IET IMAGE PROCESS, V13, P2763, DOI 10.1049/iet-ipr.2018.6224
   Fu SC, 2019, NEUROCOMPUTING, V362, P166, DOI 10.1016/j.neucom.2019.06.068
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   Gogul I, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Khan N, 2019, NEUROCOMPUTING, V357, P36, DOI 10.1016/j.neucom.2019.05.024
   Lam M, 2017, PROC CVPR IEEE, P6497, DOI 10.1109/CVPR.2017.688
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Mattos AB, 2014, IEEE IMAGE PROC, P5197, DOI 10.1109/ICIP.2014.7026052
   Munro J, 2020, PROC CVPR IEEE, P119, DOI 10.1109/CVPR42600.2020.00020
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pang C, 2018, MULTIMED TOOLS APPL, V77, P7851, DOI 10.1007/s11042-017-4679-9
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Varma M, 2007, IEEE I CONF COMP VIS, P369
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zou J, 2004, INT C PATT RECOG, P311, DOI 10.1109/ICPR.2004.1334185
NR 34
TC 4
Z9 4
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 215
EP 225
DI 10.1007/s11042-020-09679-8
EA SEP 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400001
DA 2024-07-18
ER

PT J
AU Dangol, R
   Alsadoon, A
   Prasad, PWC
   Seher, I
   Alsadoon, OH
AF Dangol, Ranjana
   Alsadoon, Abeer
   Prasad, P. W. C.
   Seher, Indra
   Alsadoon, Omar Hisham
TI Speech Emotion Recognition UsingConvolutional Neural Network and
   Long-Short TermMemory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Convolutional Neural Network (CNN); Long Short-term
   Memory (LSTM); Long short-term memory; Relation-aware self-attention
   mechanism; Hierarchical Spectral Clustering (HSC); Speech Emotion
   Recognition (SER)
AB Human-Robot interactions involve human intentions and human emotion. After the evolvement of positive psychology, the psychological research has a tremendous concentration to study the factors involved in the human emotion generation. Speech emotion recognition (SER) is a challenging job due to the complexity of emotions. Human emotion recognition is gaining importance as good emotional health can lead to good social and mental health. Although there are different approaches for speech emotion recognition, the most advanced model is Convolutional Neural Network (CNN) using Long Short-term Memory (LSTM) network. But they also suffer from the lack of parallelization of the sequences and computation times. Meanwhile, attention-mechanism has way better exhibitions in learning significant feature representations for specific tasks. Based on this technique, we propose an emotion recognition system with relation aware, self-attention mechanism to memorize the discriminative features for SER, where spectrograms are utilized as input. A CNN with a relation-aware self-attention is modelled to analyse 3D log-Mel spectrograms to extract the high-level features. Different layers such as 3D convolutional layers, 3D Max-pooling layers, and LSTM networks are used in the model. Here, the attention layer is exercised to support distinct parts of emotion and assemble discriminative utterance-level representations for SER. Finally, the fully connected layer is equipped with the utterance level representations with 64 output units to achieve higher-level representations. The approach of relation-aware attention-based 3D CNN and LSTM model provided a better outcome of 80.80% on average scale in speech emotion recognition. The proposed model in this paper focuses on enhancement of the attention mechanism to gain additional benefits of sequence to sequence parallelization by improving the recognition accuracy.
C1 [Dangol, Ranjana; Alsadoon, Abeer; Prasad, P. W. C.; Seher, Indra] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Dangol, Ranjana; Alsadoon, Abeer; Prasad, P. W. C.; Seher, Indra] Study Grp Australia, Dept Informat Technol, Sydney Campus, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Study Grp Australia, Dept Informat Technol, Sydney Campus, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Aldeneh Z, 2017, INT CONF ACOUST SPEE, P2741, DOI 10.1109/ICASSP.2017.7952655
   Hajarolasvadi N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050479
   Huang KY, 2019, INT CONF ACOUST SPEE, P5866, DOI 10.1109/ICASSP.2019.8682283
   Huang KY, 2019, PATTERN RECOGN, V88, P668, DOI 10.1016/j.patcog.2018.12.016
   Huang KY, 2020, IEEE T AFFECT COMPUT, V11, P393, DOI 10.1109/TAFFC.2018.2803178
   Pérez-Benito FJ, 2019, COMPUT METH PROG BIO, V168, P59, DOI 10.1016/j.cmpb.2017.11.004
   Jing SL, 2018, DIGIT SIGNAL PROCESS, V72, P216, DOI 10.1016/j.dsp.2017.10.016
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Lorenzo-Trueba J, 2018, SPEECH COMMUN, V99, P135, DOI 10.1016/j.specom.2018.03.002
   Lotfian R, 2021, IEEE T AFFECT COMPUT, V12, P870, DOI 10.1109/TAFFC.2019.2901465
   Motamed S, 2017, BIOL INSPIR COGN ARC, V19, P32, DOI 10.1016/j.bica.2016.12.002
   Poorna SS, 2019, INT J SPEECH TECHNOL, V22, P327, DOI 10.1007/s10772-019-09605-w
   Raffel C, 2015, ARXIV PREPRINT ARXIV
   Shaw P., 2018, P 2018 NAACL, V2, P464, DOI [DOI 10.18653/V1/N18-2074, 10.18653/v1/N18-2074]
   Sun LH, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0145-5
   Tokuno S, 2014, STRESS EVALUATION US
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 18
TC 24
Z9 27
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32917
EP 32934
DI 10.1007/s11042-020-09693-w
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000567296900002
DA 2024-07-18
ER

PT J
AU Gao, YL
   Xie, ZQ
   Yu, X
AF Gao, Yilong
   Xie, Zhiqiang
   Yu, Xu
TI A hybrid algorithm for integrated scheduling problem of complex products
   with tree structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Processing; Assembly; Tree-structured product; Integrated scheduling
   problem; Hybrid algorithm
AB Due to the poor design of encoding methods or evolutionary operators in previous genetic-algorithm-based integrated scheduling algorithms, this paper proposes an integrated scheduling algorithm based on a hybrid genetic algorithm and tabu search. Firstly, an encoding method based on a dynamic schedulable operation set is proposed. This method cannot only reflect the priority constraints among operations, but also avoid the problems of imposing constraints and missing solution space in previous division encoding method. Secondly, a decoding method based on machine idle time driving is presented to handle the scheduling order of operations on different machines. Then, two different discrete crossover and mutation operators are designed to ensure the legitimacy of the processing sequence of the same machine. Finally, a local search strategy based on tabu search is shown to enhance the search capability for superior solutions. The algorithm is tested by the randomly generated instances, and the experimental results indicate that the proposed algorithm is effective and can achieve satisfactory performance.
C1 [Gao, Yilong; Xie, Zhiqiang] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Yu, Xu] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.
C3 Harbin University of Science & Technology; Qingdao University of Science
   & Technology
RP Xie, ZQ (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM xzq1962hrbust@126.com
OI Xie, Zhiqiang/0000-0001-9828-3034
FU National Natural Science Foundation of China [61772160, 61370086];
   Heilongjiang Province Postdoctoral Science Foundation of China
   [LBHQ13092]; National University of Computer Education Research
   Association of china [ER2014018]; Heilongjiang Postdoctoral Science
   Foundation of china [LBH-Z15096]; Postdoctoral Science Foundation of
   China [2016M591541]
FX We acknowledge the support of the National Natural Science Foundation of
   China [grant numbers 61772160, 61370086]; Heilongjiang Province
   Postdoctoral Science Foundation of China [grant number LBHQ13092],
   National University of Computer Education Research Association of china
   [grant number ER2014018], the Heilongjiang Postdoctoral Science
   Foundation of china [grant number LBH-Z15096], Postdoctoral Science
   Foundation of China [grant number 2016M591541].
CR Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Rossit DA, 2018, OMEGA-INT J MANAGE S, V77, P143, DOI 10.1016/j.omega.2017.05.010
   Andrade CE, 2019, EXPERT SYST APPL, V128, P67, DOI 10.1016/j.eswa.2019.03.007
   Borisovsky P, 2020, INT J PROD RES, V58, P2677, DOI 10.1080/00207543.2019.1630764
   Dios M, 2018, COMPUT IND ENG, V115, P88, DOI 10.1016/j.cie.2017.10.034
   Gao KZ, 2019, IEEE T CYBERNETICS, V49, P1944, DOI 10.1109/TCYB.2018.2817240
   Komaki GM, 2019, INT J PROD RES, V57, P2926, DOI 10.1080/00207543.2018.1550269
   Lee DH, 2019, ROBOT CIM-INT MANUF, V56, P149, DOI 10.1016/j.rcim.2018.09.008
   Lei Q, 2018, INT J PROD RES, V56, P5437, DOI 10.1080/00207543.2018.1442942
   Liu H, 2018, APPL SOFT COMPUT, V68, P360, DOI 10.1016/j.asoc.2018.04.015
   Liu L, 2018, IEEE T IND ELECT
   Luo J, 2020, FUTURE GENER COMP SY, V108, P119, DOI 10.1016/j.future.2020.02.019
   Mahalingam T, 2019, MULTIMED TOOLS APPL, V78, P26633, DOI 10.1007/s11042-019-07768-x
   Mohammed AM, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.07.025
   Shi Fei, 2017, China Mechanical Engineering, V28, P2483, DOI 10.3969/j.issn.1004-132X.2017.20.014
   Sun L, 2019, IEEE T FUZZY SYST, V27, P1008, DOI 10.1109/TFUZZ.2019.2895562
   Wang Fu-ji, 2010, Computer Integrated Manufacturing Systems, V16, P115
   Xie Zhi-giang, 2017, Transactions of Beijing Institute of Technology, V37, P274, DOI 10.15918/j.tbit1001-0645.2017.03.010
   Xie Zhi-Qiang, 2017, Transactions of Beijing Institute of Technology, V37, P532, DOI 10.15918/j.tbit1001-0645.2017.05.018
   Xie Zhiqiang, 2018, Journal of Mechanical Engineering, V54, P191, DOI 10.3901/JME.2018.06.191
   [谢志强 Xie Zhiqiang], 2018, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V48, P578
   [谢志强 Xie Zhiqiang], 2018, [自动化学报, Acta Automatica Sinica], V44, P344
   Xie Zhiqiang, 2016, Journal of Shanghai Jiao Tong University, V50, P929, DOI 10.16183/j.cnki.jsjtu.2016.06.019
   Xie ZQ, 2009, COMPUT IND ENG, V57, P766, DOI 10.1016/j.cie.2009.02.004
   Yu KJ, 2016, J INTELL MANUF, V27, P831, DOI 10.1007/s10845-014-0918-3
   Zhang J., 2017, J INTELL MANUF, V30, P1809, DOI [10.1007/s10845-017-1350-2, DOI 10.1007/s10845-017-1350-2]
   Zhang SC, 2020, EUR J OPER RES, V283, P441, DOI 10.1016/j.ejor.2019.11.016
   Zhang XH, 2019, MULTIMED TOOLS APPL, V78, P29989, DOI 10.1007/s11042-018-6805-8
   Zhang XH, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12305
   Zhang Xiaohuan, 2017, Computer Integrated Manufacturing Systems, V23, P1938, DOI 10.13196/j.cims.2017.09.013
   [赵诗奎 Zhao Shikui], 2015, [计算机集成制造系统, Computer Integrated Manufacturing Systems], V21, P2435
NR 33
TC 7
Z9 7
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32285
EP 32304
DI 10.1007/s11042-020-09477-2
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300011
DA 2024-07-18
ER

PT J
AU Garg, B
   Arya, KV
AF Garg, Bharat
   Arya, K., V
TI Four stage median-average filter for healing high density salt and
   pepper noise corrupted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Salt-and-pepper noise; Median filter; Mean filter;
   Non-linear filter
ID IMPULSE NOISE; FUZZY FILTER; MEAN FILTER; REMOVAL; ALGORITHM
AB This paper introduces a novel four stage filter algorithm to ameliorate images corrupted by very high density salt-and-pepper noise. The proposed algorithm exhibits two parallel trimmed median filters (TMF) at the initial stage followed by a masking logic that selects denoised pixel based on the priority. To reduce the blurring effect, higher priority is given to TMF with small window size. In the absence of noise-free pixels, the current extreme pixel is left unchanged at the first stage. Further, the denoising of unprocessed extreme pixels is done with TMF of large size window at the second stage. The remaining noisy pixels are improved by the running average filter at the third stage. Finally, the last stage handles the noisy pixels at the boundary and rare scenario. Since the proposed filter utilized non-extreme pixels to estimate denoinsed pixels value, it effectively eliminates salt and pepper noise along with better edge preservation. The performance analysis of the proposed filter is carried out with various benchmark images for varying noise density. The experimental results demonstrate on an average improvement of 2.09 dB (0.018) and 1.06 dB (0.0478) of PSNR (SSIM) respectively for wide (10% - 90%) and very-high (90% - 98%) noise density ranges over state-of-the-art filters.
C1 [Garg, Bharat] Thapar Inst Engn & Technol, ECED, Patiala 147001, Punjab, India.
   [Arya, K., V] ABV Indian Inst Informat Technol & Management Gwa, Gwalior 474015, Madhya Pradesh, India.
C3 Thapar Institute of Engineering & Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Garg, B (corresponding author), Thapar Inst Engn & Technol, ECED, Patiala 147001, Punjab, India.
EM bharat.garg@thapar.edu; kvarya@iiitm.ac.in
RI Garg, Bharat/AAE-5728-2021; Garg, Bharat/GPP-5755-2022
OI Garg, Bharat/0000-0002-2904-3720
CR AHMED F, 2014, IEEE T FUZZY SYST, V0022, P01352, DOI DOI 10.1109/TFUZZ.2013.2286634
   Aiswarya K., 2010, P 2 INT C COMP MOD S, V4, P409
   [Anonymous], 2004, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2003.819861
   AZHAR M, 2019, J AMB INTEL HUM COMP, V0010, P03925, DOI DOI 10.1007/S12652-018-1153-0
   BALASUBRAMANIAN G, 2016, AEU INT J ELECTRON C, V0070, P00471, DOI DOI 10.1016/J.AEUE.2016.01.013
   BALASUBRAMANIAN G, 2016, IMAGING SCI J, V0064, P00241, DOI DOI 10.1080/13682199.2016.1168144
   BURGER HC, 2012, PROC CVPR IEEE, P02392
   Deivalakshmi S, 2010, 2010 5 INT C IND INF, P309
   DEIVALAKSHMI S, 2016, AEU INT J ELECTRON C, V0070, P00757, DOI DOI 10.1016/J.AEUE.2016.03.002
   ERKAN U, 2018, COMPUT ELECTR ENG, V0070, P00789, DOI DOI 10.1016/J.COMPELECENG.2018.01.019
   ERKAN U, 2018, TURK J ELECTR ENG CO, V0026, P00162, DOI DOI 10.3906/ELK-1705-256
   ESAKKIRAJAN S, 2011, IEEE SIGNAL PROC LET, V0018, P00287, DOI DOI 10.1109/LSP.2011.2122333
   FARAGALLAH OS, 2016, AEU INT J ELECTRON C, V0070, P01034, DOI DOI 10.1016/J.AEUE.2016.04.018
   GARG B, 2020, SIGNAL IMAGE VI 0516, DOI DOI 10.1007/S11760-020-01695-3
   Gonzalez RC, 2018, DIGITAL IMAGE PROCES, V4th
   KANDEMIR C, 2015, DIGIT SIGNAL PROCESS, V0046, P00164
   Karthik B, 2020, J AMBIENT INTELL HUM, P1
   LIANG SF, 2008, IEEE T FUZZY SYST, V0016, P00863, DOI DOI 10.1109/TFUZZ.2008.917297
   LIN TC, 2012, NEURAL COMPUT APPL, V0021, P00695, DOI DOI 10.1007/S00521-011-0648-9
   LU CT, 2016, PATTERN RECOGN LETT, V0080, P00188, DOI DOI 10.1016/J.PATREC.2016.06.026
   Mafi M, 2018, SIGNAL PROCESSING
   MAFI M, 2018, IEEE T IMAGE PROCESS, V0027, P05475
   MEHER SK, 2014, AEU INT J ELECTRON C, V0068, P01173, DOI DOI 10.1016/J.AEUE.2014.06.006
   NAIR MS, 2013, SIGNAL IMAGE VIDEO P, V0007, P01041, DOI DOI 10.1007/S11760-012-0310-8
   Pitas I, 2013, NONLINEAR DIGITAL FI, V84
   ROY A, 2017, AEU INT J ELECT COMM, V0072, P00114, DOI DOI 10.1016/J.AEUE.2016.12.006
   ROY A, 2016, SIGNAL PROCESS, V0128, P00262, DOI DOI 10.1016/J.SIGPRO.2016.04.007
   SANAEE P, 2019, SIGNAL IMAGE VIDEO P, V0013, P00895, DOI DOI 10.1007/S11760-019-01426-3
   SRINIVASAN KS, 2007, IEEE SIGNAL PROC LET, V0014, P00189, DOI DOI 10.1109/LSP.2006.884018
   TURKMEN I, 2016, J VIS COMMUN IMAGE R, V0034, P00028, DOI DOI 10.1016/J.JVCIR.2015.10.011
   VEERAKUMAR T, 2014, SIGNAL IMAGE VIDEO P, V0008, P00159, DOI DOI 10.1007/S11760-013-0517-3
   VIJAYKUMAR VR, 2014, AEU INT J ELECTRON C, V0068, P01145, DOI DOI 10.1016/J.AEUE.2014.06.002
   ZHANG K, 2017, IEEE T IMAGE PROCESS, V0026, P03142
   Zhang K, 2017, P IEEE C COMP VIS PA, P3929
NR 34
TC 15
Z9 15
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32305
EP 32329
DI 10.1007/s11042-020-09557-3
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300002
DA 2024-07-18
ER

PT J
AU Parajuli, N
   Alsadoon, A
   Prasad, PWC
   Ali, RS
   Alsadoon, OH
AF Parajuli, Nitesh
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Rasha S.
   Alsadoon, Omar Hisham
TI A recent review and a taxonomy for multimedia application in Mobile
   cloud computing based energy efficient transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Mobile cloud computing; Mobile devices; Offloading; Scheduling; Power
   consumption; Resource; Task
ID OFFLOADING FRAMEWORK; RESOURCE-ALLOCATION; SCHEDULING SCHEME; DYNAMIC
   RESOURCE; RATE ADAPTATION; EXECUTION; OPTIMIZATION; MANAGEMENT;
   ALGORITHM; NETWORKS
AB The mobile devices have entered the race of deploying high tech to the users but inherit a defect of limited battery storage. With the limitationof battery capacity, energy efficiency has been a major concern for Mobile Cloud Computing (MCC). The multimedia application comprises rich media that needs higher processing and computation, and the resource and computation are constrained. Energy-efficient transmission is a big concern because it equips the mobile device with high-end hardware components, but still, are far behind to the battery capacity and computation competence. This paper intends to introduce and investigate the different approaches/algorithms and tools that best fit to save resource utilization and energy consumption rationally. The algorithms like the Genetic Algorithm, Greedy scheduling algorithm, power-aware list-based scheduling, Offloading based task scheduling, media cloud distributed scheduling algorithm, etc. are discussed in this research. The data, Energy-efficient technique, and Cloud server response that defines each of the main components is introduced in this paper that concerns the implementation of the energy-efficient transmission in MCC. We propose these components that illustrate the workflow in the technology. A process when the data is perceived by the technique to adequately deliver a response to the mobile device. An energy-efficient transmission technique for MCC is a development towards the use of mobile cloud computing in this field working to counter the utilization of energy and resources that execute locally. This concept results in reducing the amount of data transmitted with the use of sharing the data externally between the tasks that will save energy. Through this paper, readers will understand the benefit of using the energy-efficient technique in the MCC. Also, the reader will understand the classification groups, validation criteria, future gaps of the 30 literature reviews about the technique, and how they intend to energy optimization in mobile devices.
C1 [Parajuli, Nitesh; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
   [Ali, Rasha S.] AL Nisour Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Al-Nisour University College; Al-Iraqia
   University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Ali, Rasha Subhi/X-9445-2018; ALI, Rasha/JBJ-4318-2023; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Ali, Rasha Subhi/0000-0002-9767-7151; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; Ali, Rasha/0000-0003-3427-423X; Subhi,
   Rasha/0000-0001-6718-5618; Alsadoon, Omar Hisham/0000-0001-7797-6392;
   withana, chandana/0000-0002-3007-687X
CR Ahmad H, 2018, MULTIMED TOOLS APPL, V77, P23877, DOI 10.1007/s11042-017-5603-z
   Ahmed E, 2015, J NETW COMPUT APPL, V52, P154, DOI 10.1016/j.jnca.2015.03.001
   Ahn S, 2018, IEEE ACCESS, V6, P899, DOI 10.1109/ACCESS.2017.2776323
   Alasaad A, 2015, IEEE T PARALL DISTR, P1
   Alsalih W., 2005, Proceedings. 19th IEEE International Parallel and Distributed Processing Symposium
   [Anonymous], 2010, PROC 8 INT C MOBILE, DOI [DOI 10.1145/1814433, 10.1145/1814433.1814441, DOI 10.1145/1814433.1814441]
   [Anonymous], 2018, WIREL NETW
   Badidi E, 2018, COMPUTING
   Bartolini C, 2015, INT C GRID EC BUS MO, P281
   Cao G, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P28, DOI 10.1145/3291842.3291857
   Cao YL, 2017, IEEE ACCESS, V5, P21862, DOI 10.1109/ACCESS.2017.2731899
   Cardellini V, 2016, MATH PROGRAM, V157, P421, DOI 10.1007/s10107-015-0881-6
   Chalack VA, 2017, INT J COMP APPL TECH, V6, P87, DOI DOI 10.7753/ijcatr0602.1003
   Chang Z, 2018, IEEE WIREL COMMUN, V25, P186, DOI 10.1109/MWC.2017.1600170
   Chang Z, 2016, IEEE T VEH TECHNOL, V65, P9834, DOI 10.1109/TVT.2016.2525821
   Chen HK, 2015, J SYST SOFTWARE, V99, P20, DOI 10.1016/j.jss.2014.08.065
   Chen K, 2015, IEEE T COMPUT, V64, P1029, DOI 10.1109/TC.2014.2308211
   Chen K, 2014, IEEE T MOBILE COMPUT, V13, P235, DOI 10.1109/TMC.2012.239
   Chen M, 2015, IEEE COMMUN MAG, V53, P18, DOI 10.1109/MCOM.2015.7120041
   Chen XF, 2015, IEEE J SEL AREA COMM, V33, P627, DOI 10.1109/JSAC.2015.2393496
   Chen X, 2015, IEEE T PARALL DISTR, V26, P974, DOI 10.1109/TPDS.2014.2316834
   Chunhui G, 2018, SHOCK VIBRATION, V2018
   Chunlin L, 2018, WIRE NETW, V25, P1
   Dong PP, 2016, IEEE T COMMUN, V64, P3456, DOI 10.1109/TCOMM.2016.2584615
   Durga S, 2018, CLUST COMPUT
   Durga S, 2013, P 4 INT C SIGN IM PR, P619, DOI DOI 10.1007/978-81-322-1000-9_57
   Ferdouse L, 2016, 2016 IEEE 21ST INTERNATIONAL WORKSHOP ON COMPUTER AIDED MODELLING AND DESIGN OF COMMUNICATION LINKS AND NETWORKS (CAMAD), P83, DOI 10.1109/CAMAD.2016.7790335
   Gamba M, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1111, DOI 10.1109/ICCNC.2015.7069505
   Gong X., 2016, P 13 INT C MOBILE UB, P160
   Gu D, 2015, GYNECOL ONCOL TRENDS, V1, P1
   Guo ST, 2019, IEEE T MOBILE COMPUT, V18, P319, DOI 10.1109/TMC.2018.2831230
   Guo XJ, 2018, WIREL NETW, V24, P79, DOI 10.1007/s11276-016-1322-z
   Hani QB, 2017, J CLOUD COMPUT-ADV S, V6, DOI 10.1186/s13677-017-0079-y
   He J, 2014, IEEE T MULTIMEDIA, V16, P242, DOI 10.1109/TMM.2013.2284894
   Hu CC, 2017, COMPUT NETW, V127, P56, DOI 10.1016/j.comnet.2017.08.001
   Huang D, 2012, IEEE T WIREL COMMUN, V11, P1991, DOI 10.1109/TWC.2012.041912.110912
   Jacobsson A, 2016, FUTURE GENER COMP SY, V56, P719, DOI 10.1016/j.future.2015.09.003
   Jo SW, 2018, IEEE COMMUN LETT, V22, P1260, DOI 10.1109/LCOMM.2018.2820685
   Kaewpuang R, 2013, IEEE J SEL AREA COMM, V31, P2685, DOI 10.1109/JSAC.2013.131209
   Kang X, 2014, WIT TRANS INFO COMM, P449, DOI 10.2495/ITIE20130581
   Kaur T, 2016, CLUSTER COMPUT, V19, P679, DOI 10.1007/s10586-016-0566-9
   Khorramnejad K, J CLOUD COMPUTING, V7, P13
   Kosta S, 2012, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2012.6195845
   Kumachev A, 2018, CJEM, V2, P1
   Kumari R, 2018, SOFT COMPUT, V22, P6751, DOI 10.1007/s00500-018-3264-0
   Kwak J, 2015, IEEE J SEL AREA COMM, V33, P2510, DOI 10.1109/JSAC.2015.2478718
   Lan L, 2018, MOBILE INFORM SYSTEM, V2018
   Li YB, 2017, IEEE SYST J, V11, P96, DOI 10.1109/JSYST.2015.2442994
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Lin CC, 2015, J PARALLEL DISTR COM, V86, P71, DOI 10.1016/j.jpdc.2015.08.004
   Liu J, 2015, ENERGY EFFICIENT SCH
   Liu TD, 2016, FUTURE GENER COMP SY, V61, P1, DOI 10.1016/j.future.2016.02.004
   Liu YC, 2016, IEEE T MOBILE COMPUT, V15, P2398, DOI 10.1109/TMC.2015.2504091
   Ma XQ, 2013, IEEE NETWORK, V27, P28, DOI 10.1109/MNET.2013.6616112
   Manasrah AM, 2018, WIRELESS COMMUNICATI, V2018
   Meng XF, 2015, J NETW COMPUT APPL, V49, P1, DOI 10.1016/j.jnca.2014.10.013
   Mollah MB, 2017, J NETW COMPUT APPL, V84, P38, DOI 10.1016/j.jnca.2017.02.001
   Neto JLD, 2018, IEEE T MOBILE COMPUT, V17, P2660, DOI 10.1109/TMC.2018.2815015
   Ou S, 2007, PERVASIVE MOB COMPUT, V3, P362, DOI 10.1016/j.pmcj.2007.04.004
   Pan S, 2018, AEU-INT J ELECTRON C, V95, P97, DOI 10.1016/j.aeue.2018.07.034
   Su P, 2016, KSII T INTERNET INF, V10, P4044, DOI 10.3837/tiis.2016.09.002
   Paris S, 2015, IEEE T MOBILE COMPUT, V14, P1573, DOI 10.1109/TMC.2014.2361127
   Qiu MK, 2015, IEEE T COMPUT, V64, P3528, DOI 10.1109/TC.2015.2409857
   Shi T, 2016, PERVASIVE MOB COMPUT, V27, P90, DOI 10.1016/j.pmcj.2015.07.005
   Sundararaj V., 2018, WIRELESS PERS COMMUN, P1
   Sundararaj V, 2017, PSO ALGORITHM WAVELE, P1
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Tang C, 2018, MOBILE CLOUD BASED S, P1
   Tang CG, 2018, DISTRIB PARALLEL DAT, V36, P529, DOI 10.1007/s10619-018-7231-7
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wang J, 2017, COMPUT NETW, V115, P100, DOI 10.1016/j.comnet.2016.11.020
   Wang Q, 2017, QUALITY DRIVEN MODUL
   Wang XM, 2017, IEEE SYST J, V11, P858, DOI 10.1109/JSYST.2015.2466617
   Wang Z, 2015, IEEE T COMPUT AID D, V34, P1600, DOI 10.1109/TCAD.2015.2422846
   Xiang L, 2013, IEEE T WIREL COMMUN, V12, P961, DOI 10.1109/TWC.2013.011713.112157
   Xue SJ, 2017, CLUSTER COMPUT, V20, P3199, DOI 10.1007/s10586-017-1047-5
   Yang C, 2017, ENERGY, V125, P11, DOI 10.1016/j.energy.2017.02.102
   Yang S, 2014, IEEE T MOBILE COMPUT, V13, P2648, DOI 10.1109/TMC.2014.2307293
   Zeng Z, 2016, CLUSTER COMPUT, V19, P601, DOI 10.1007/s10586-016-0543-3
   Zhang J, 2018, PERS UBIQUIT COMPUT, V22, P121, DOI 10.1007/s00779-017-1095-0
   Zhang J, 2018, MOBILE NETW APPL, V23, P1350, DOI 10.1007/s11036-018-1009-z
   Zhang JY, 2018, WIREL NETW, V24, P3083, DOI 10.1007/s11276-017-1519-9
   Zhang L, 2017, IEEE T CIRC SYST VID, V27, P170, DOI 10.1109/TCSVT.2016.2539690
   Zhang WW, 2013, IEEE T WIREL COMMUN, V12, P4569, DOI 10.1109/TWC.2013.072513.121842
   Zhong Jiandong, 2010, Robot, V32, P516, DOI 10.3724/SP.J.1218.2010.00516
   Zhou B, 2018, MOBILE CLOUDS ACM T, V18, P2
   Zhou BW, 2017, IEEE T SERV COMPUT, V10, P797, DOI 10.1109/TSC.2015.2511002
   Zhou B, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3122981
   Zhu W, 2017, FUTURE GENER COMP SY, V69, P66, DOI 10.1016/j.future.2016.10.034
NR 89
TC 8
Z9 8
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31567
EP 31594
DI 10.1007/s11042-020-09516-y
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100001
DA 2024-07-18
ER

PT J
AU Filali, Y
   EL Khoukhi, H
   Sabri, MA
   Aarab, A
AF Filali, Youssef
   EL Khoukhi, Hasnae
   Sabri, My Abdelouahed
   Aarab, Abdellah
TI Efficient fusion of handcrafted and pre-trained CNNs features to
   classify melanoma skin cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Melanoma; Handcrafted features; CNNs; Features fusion;
   Genetic algorithm
ID CLASSIFICATION; SEGMENTATION; LESIONS; DIAGNOSIS
AB Skin cancer is one of the most aggressive cancers in the world. Computer-Aided Diagnosis (CAD) system for cancer detection and classification is a top-rated solution that decreases human effort and time with very high classification accuracy. Machine learning (ML) and deep learning (DL) based approaches have been widely used to develop robust skin-lesion classification systems. Each of the techniques excels when the other fails. Their performances are closely related to the size of the learning dataset. Thus, approaches that are based on the ML are less potent than those found on the DL when working with large datasets and vice versa. In this article, we propose a powerful skin-lesion classification approach based on a fusion of handcrafted features (shape, skeleton, color, and texture) and features extracted from most powerful DL architectures. This combination will make it possible to remedy the limitations of both the ML and DL approaches for the case of large and small datasets. Features engineering is then applied to remove redundant features and to select only relevant features. The proposed approach is validated and tested on both small and large datasets. A comparative study is also conducted to compare the proposed approach with different and recent approaches applied to each dataset. The results obtained show that this features-fusion based approach is very promising and can effectively combine the power of ML and DL based approaches.
C1 [Filali, Youssef; EL Khoukhi, Hasnae; Sabri, My Abdelouahed] USMBA, Fac Sci Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
   [Aarab, Abdellah] USMBA, Fac Sci Dhar Mahraz, Dept Phys, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Filali, Y (corresponding author), USMBA, Fac Sci Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
EM filaliucf@gmail.com
RI sabri, abdelouahed/ABG-2698-2021
OI Filali, Youssef/0000-0001-8733-5257
FU laboratory: LIIAN; laboratory: LESSI; Faculty of Sciences, University
   Sidi Mohamed Ben abdellah, Fez, Morocco
FX This research work has been funded by the laboratories: LIIAN and LESSI
   and the Faculty of Sciences, University Sidi Mohamed Ben abdellah, Fez,
   Morocco.
CR Akram Tallha, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1083, DOI 10.1007/s12652-018-1051-5
   Almansour E, 2016, INT J COMPUT SCI NET, V16, P135
   Anirudha R. C., 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036522
   [Anonymous], 2011, INDIAN J SCI TECHNOL
   [Anonymous], 2017, arXiv preprint arXiv:1703.03108
   Arifin M. S., 2012, IEEE INT C MACHINE L, V5, P1675
   Barata C, 2019, IEEE J BIOMED HEALTH, V23, P1096, DOI 10.1109/JBHI.2018.2845939
   Berseth M., 2017, ISIC 2017 SKIN LESIO, P1, DOI 10.1111/j.1741-3737.2001.00491.
   Bhati P, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P181, DOI 10.1109/CCIntelS.2015.7437904
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Correa DN, 2015, LAT AM COMP C CLEI A, P1
   Dalila F, 2017, OPTIK, V140, P749, DOI 10.1016/j.ijleo.2017.04.084
   Dara Suresh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1795, DOI 10.1109/ICECA.2018.8474912
   Diaz I.G., 2017, INT SKIN IM COLL ISI
   Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Filali Youssef, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P379, DOI 10.1007/978-981-15-0947-6_36
   Filali Y, 2019, 2019 J COMPUTER SCI, V15, P1225
   Filali Y., 2017, 2017 INT C ADV TECHN, P1
   Filali Y, 2019, STAT OPTIMIZATION IN, V7, P456, DOI [DOI 10.19139/SOIC.V7I2.533, 10.19139/soic.v7i2.533]
   Filali Y, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723791
   Filali Y, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Gopal Krishna Patro S., 2015, IARJSET, V2, P20, DOI [10.17148/IARJSET.2015.2305, DOI 10.17148/IARJSET.2015.2305]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Immagulate I., 2015, INT J MED IMAGING, V3, P34, DOI [10.11648/j.ijmi.20150302.15, DOI 10.11648/J.IJMI.20150302.15]
   Jain S, 2015, PROCEDIA COMPUT SCI, V48, P735, DOI 10.1016/j.procs.2015.04.209
   Kannan V., 2018, FEATURE SELECTION US
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Marques JS, 2012, IEEE ENG MED BIO, P4402, DOI 10.1109/EMBC.2012.6346942
   Mendonc T, 2013, PH 2 DERMOSCOPIC IMA, P1
   Mohanaiah P., 2013, INT J SCI RES PUB, V3, P1, DOI 10.5772/58692
   Moura N, 2018, IEEE SYMP COMP COMMU, P513, DOI 10.1109/ISCC.2018.8538525
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nauman A, 2020, IEEE ACCESS, V8, P8202, DOI 10.1109/ACCESS.2020.2964280
   Oliveira RB, 2019, NEURAL COMPUT APPL, V31, P6091, DOI 10.1007/s00521-018-3439-8
   Oliveira RB, 2016, COMPUT METH PROG BIO, V131, P127, DOI 10.1016/j.cmpb.2016.03.032
   Ozkan I.A., 2017, Int. J. Intell. Syst. Appl. Eng., V5, P285, DOI DOI 10.18201/IJISAE.2017534420
   Pathan S, 2019, BIOMED SIGNAL PROCES, V51, P59, DOI 10.1016/j.bspc.2019.02.013
   Pathan S, 2018, MED BIOL ENG COMPUT, V56, P2051, DOI 10.1007/s11517-018-1837-9
   Qadri YA, 2020, IEEE COMMUN SURV TUT, V22, P1121, DOI 10.1109/COMST.2020.2973314
   Rubegni P, 2002, INT J CANCER, V101, P576, DOI 10.1002/ijc.10620
   Sabri MA, 2019, DE GR FRONT COMPU IN, V4, P31, DOI 10.1515/9783110621105-002
   Salido Julie Ann A., 2018, International Journal of Machine Learning and Computing, V8, P61, DOI 10.18178/ijmlc.2018.8.1.664
   Salido JANN, 2018, HAIR ARTIFACT REMOVA, V11, P2
   Sánchez-Monedero J, 2016, LECT NOTES ARTIF INT, V9648, P427, DOI 10.1007/978-3-319-32034-2_36
   Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8
   Shoieb D A., 2016, Journal of Image and Graphics, P122, DOI 10.18178/joig.4.2.122-129
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srividya TD, 2018, DETECTION SKIN CANC, V7, P131
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vasconcelos MJM, 2015, IEEE INT SYM MED MEA, P570, DOI 10.1109/MeMeA.2015.7145268
   Victor A., 2017, International Journal of Intelligent Engineering and Systems, V10, P444, DOI [DOI 10.22266/IJIES2017.0630.50, 10.22266/ijies2017.0630.50]
   Wu YR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082001
   Xu L, 1999, IMAGE VISION COMPUT, V17, P65, DOI 10.1016/S0262-8856(98)00091-2
   Zhang XQ, 2017, COMPUT ASSIST SURG, V22, P267, DOI 10.1080/24699322.2017.1389405
   Zhou HY, 2010, IEEE ENG MED BIO, P1974, DOI 10.1109/IEMBS.2010.5627556
NR 64
TC 18
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31219
EP 31238
DI 10.1007/s11042-020-09637-4
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645600002
DA 2024-07-18
ER

PT J
AU Mechkouri, SE
   El Joumani, S
   Zennouhi, R
   Masmoudi, L
AF Mechkouri, Salah Eddine
   El Joumani, Saleh
   Zennouhi, Rachid
   Masmoudi, Lhoussaine
TI Multi-objective optimization for worldview image segmentation funded on
   the entropies of Tsallis and Renyi
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization multi-objective; Segmentation; Tsallis and Renyi entropies;
   Worldview image
AB Image analysis usually refers to processing of images with the objective of finding objects presented in the image. The extraction and the analysis of image data is a fundamental step for image segmentation, in this work a new method allowing the evolution of the threshold satellite image defined and based on the optimization multi-objective for segmentation of Worldview images and funded on the Tsallis and the Renyi entropies. The Objective is the reclassification of all unclassified pixels by the previous method in 2017. The improved analysis and the optimized method multi-objective thresholding are proposed. First, respectively for each Worldview image selected, the optimal thresholds for all the criteria used in this study is find. Finally, by using the evaluation criteria corresponding to the Levine and Nazif criteria and the criteria of the mean square error, in order to challenge the performance of this method to that previously developed in 2017. The results obtained by this approach were very satisfactory and the efficacy of this method confirmed. This method overcomes the difficulties of the method previously developed in 2017 and obtained results that are more precise. Therefore, the new method based on multi-objective optimization contribute significantly to performance.
C1 [Mechkouri, Salah Eddine; El Joumani, Saleh; Zennouhi, Rachid; Masmoudi, Lhoussaine] Univ Mohammed V Rabat, Fac Sci, Dept Phys, Lab Concept & Syst Elect Signaux & Informat,LCS, BP 1014,Ave Ibn Battouta, Rabat 10000, Morocco.
C3 Mohammed V University in Rabat
RP Mechkouri, SE (corresponding author), Univ Mohammed V Rabat, Fac Sci, Dept Phys, Lab Concept & Syst Elect Signaux & Informat,LCS, BP 1014,Ave Ibn Battouta, Rabat 10000, Morocco.
EM salahmechkouri@gmail.com; jomanisalh@gmail.com; r.zennouhi@gmail.com;
   lhmasmoudi@fsr.ac.ma
OI SALAH EDDINE, MECHKOURI/0000-0002-0561-2861; MASMOUDI,
   Lhoussaine/0000-0002-8857-4249
FU COMSTECH TWAS 2015 Research Grant Award
FX A COMSTECH TWAS 2015 Research Grant Award supported the satellite image
   used for this work partially.
CR de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   El Joumani S, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0161-2
   El-Sayed MA, 2011, INT J INTELLIGENT CO, V11
   Gobindchandra K, 2015, J COMPUTER SCI, V2
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Mechkouri S., 2010, Geo Observateur, V18, P43
   Mechkouri Salah Eddine, 2014, Journal of Theoretical and Applied Information Technology, V62, P539
   Nakib A, 2007, SIGNAL PROCESS, V87, P2516, DOI 10.1016/j.sigpro.2007.04.001
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Rosenberger C, 1999, THESIS
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sparavigna A. C., 2015, International Journal of Sciences, V4, P40, DOI 10.18483/ijSci.613
   Sparavigna A.C., 2015, International Scientific Research Journal, V1, P16
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038
   Zennouhi R, 2009, IMAGING SCI J, V57, P260, DOI 10.1179/136821909X12490307952874
NR 16
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30637
EP 30652
DI 10.1007/s11042-020-09572-4
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560912200001
DA 2024-07-18
ER

PT J
AU Chen, JH
   Qi, XM
   Wang, WX
   Li, B
   Liu, YJ
AF Chen, Junhua
   Qi, Xingming
   Wang, Wenxin
   Li, Bao
   Liu, Youjun
TI Real-time location of surgical incisions in cataract phacoemulsification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cataract phacoemulsification; Surgical incision; Computer-aided
   location; Real-time
ID CORNEAL ASTIGMATISM; INTRAOCULAR-LENS; IRIS RECOGNITION; SEGMENTATION;
   ROTATION; PUPIL
AB Phacoemulsification is an important surgical treatment for cataracts. The location of the surgical incision affects the surgically induced astigmatism, and the typical surgical incision for phacoemulsification is located on the steepest meridian direction of the limbus. The real-time location of the surgical incision during the cataract phacoemulsification can reduce doctors' workloads and the potential for human error. A real-time surgical incision location algorithm in microscopic images is proposed in this paper. It is a two-part algorithm that consists of an iris external boundary detection algorithm and a rotation angle calculation algorithm. The steps in the iris external boundary detection algorithm include image space conversion, image segmentation, filtering, and least square based circle detection. The eye rotation angle calculation algorithm utilizes the SURF algorithm. Experiments on six phacoemulsification videos show that the algorithm can locate surgical incisions in microscopic videos accurately and quickly. The distance error of the iris external boundary algorithm is 2.45 +/- 0.136, and the area error is 2.69 +/- 0.184. The average running time of this algorithm for one image is 65.1 +/- 4.80 ms; a demonstration video, the S1 Video, is available. The algorithm proposed in this paper can determine the surgical incision location in cataract phacoemulsification in real-time based on a personal computer and can provide assistance for ophthalmology surgeons.
C1 [Chen, Junhua; Qi, Xingming; Wang, Wenxin; Li, Bao; Liu, Youjun] Beijing Univ Technol, Coll Life Sci & Bioengn, Beijing, Peoples R China.
   [Wang, Wenxin] Neusoft Beijing R&D Ctr, Bldg 22,Zhongguancun Software Pk 10, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Liu, YJ (corresponding author), Beijing Univ Technol, Coll Life Sci & Bioengn, Beijing, Peoples R China.
EM lyjlma@bjut.edu.cn
RI wang, wenxin/HGD-7043-2022
OI Chen, Junhua/0000-0002-0947-6879
FU National Natural Science Foundation of China [11832003, 11772016,
   11472022]; key project of science and technology of Beijing Municipal
   Commission of Education [KZ201810005007]; China Scholarship Council
   [201906540036]
FX The authors thanks for reviewers' comments. This research is supported
   by National Natural Science Foundation of China (11832003, 11772016,
   11472022) and the key project of science and technology of Beijing
   Municipal Commission of Education (KZ201810005007). Junhua Chen is
   partly supported by China Scholarship Council (201906540036).
CR Arvacheh EM, 2006, IEEE IMAGE PROC, P2453, DOI 10.1109/ICIP.2006.312773
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beltrame G, 2001, J CATARACT REFR SURG, V27, P720, DOI 10.1016/S0886-3350(00)00752-5
   Bora D. J., 2016, INT J COMPUTER SCI E, V4, P156
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Carvalho MJ, 2007, J REFRACT SURG, V23, P499
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Ganesan P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P101, DOI 10.1109/ICCICCT.2014.6992938
   Greenspan H, 2001, IEEE T MED IMAGING, V20, P928, DOI 10.1109/42.952730
   HARDING J., 1991, CATARACT BIOCH EPIDE
   He X, 2007, PATTERN RECOGN, V40, P1326, DOI 10.1016/j.patcog.2006.08.009
   Jiménez R, 2016, J CATARACT REFR SURG, V42, P1022, DOI 10.1016/j.jcrs.2016.03.039
   Jumb V, 2014, Int J Innovative Technol Exploring Eng, V3, P72
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Khan TM, 2011, OPT LASER ENG, V49, P177, DOI 10.1016/j.optlaseng.2010.08.020
   Kyung-Nam Kim, 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P324, DOI 10.1109/ICSMC.1999.825279
   Liang XH, 1998, J VIROL, V72, P8586, DOI 10.1128/JVI.72.11.8586-8596.1998
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   MAGUIRE LJ, 1989, AM J OPHTHALMOL, V108, P107, DOI 10.1016/0002-9394(89)90001-9
   MANFRED Ehlers, 1991, GEOSC REM SENS S 199, V4, P2231
   Moon Sung Chur, 2007, Korean J Ophthalmol, V21, P1, DOI 10.3341/kjo.2007.21.1.1
   Nichamin Louis D, 2006, Ophthalmol Clin North Am, V19, P485
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rho CR, 2012, J CATARACT REFR SURG, V38, P666, DOI 10.1016/j.jcrs.2011.11.031
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3, P101, DOI 10.1109/TPAMI.1981.4767056
   Ruhswurm I, 2000, J CATARACT REFR SURG, V26, P1022, DOI 10.1016/S0886-3350(00)00317-5
   Saika S, 1997, J CATARACT REFR SURG, V23, P139, DOI 10.1016/S0886-3350(97)80167-8
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Ullah F, 2004, PATTERN RECOGN, V37, P201, DOI 10.1016/S0031-3203(03)00184-5
   Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P121, DOI 10.1109/ACV.1994.341298
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Wildes RP, 1996, MACH VISION APPL, V9, P1, DOI 10.1007/BF01246633
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Xu Y, 2007, COMPUT METH PROG BIO, V88, P131, DOI 10.1016/j.cmpb.2007.08.004
   YUEN HK, 1990, IMAGE VISION COMPUT, V8, P71, DOI 10.1016/0262-8856(90)90059-E
NR 42
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30311
EP 30327
DI 10.1007/s11042-020-09560-8
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900008
DA 2024-07-18
ER

PT J
AU Zheng, JM
   Luo, Z
   Zeng, QX
AF Zheng, Jiming
   Luo, Zheng
   Zeng, Qingxia
TI An efficient image encryption algorithm based on multi chaotic system
   and random DAN coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Multi chaotic system; Random DAN coding;
   Multidirectional diffusion; SHA256
ID DNA
AB This paper presents a digital image encryption scheme based on multi chaotic system and random DNA coding. Firstly, the initial values and parameter values of 2D Logistic-adjusted-Sine mapping (2D-LASM) and Logistic-Sine system (LSS) are obtained from SHA256 hash values of the original image. In the scrambling stage, the chaotic sequences generated by 2D-LASM are used to get two column scrambling matrices and row scrambling matrix, respectively. The elements of the second column scrambling matrix and row scrambling matrix are used as row and column coordinates in the scrambling process. Then apply it to scrambling the DNA encoded image, which can complete the row and column scrambling at the same time. In the diffusion stage, we proposed a new diffusion method. Through the chaotic sequence generated by the LSS, a DNA coding sequence is obtained. DNA XOR operation is carried out on the central point and horizontal line of the image, and then spread from the central line to the upper and lower directions of the matrix to achieve the purpose of multi-directional diffusion and improve the encryption efficiency. Experimental results and security analysis show that the algorithm executes fast and has strong security. It can resist many attacks, such as statistical attacks, brute attacks, plaintext / select plaintext attacks, etc.
C1 [Zheng, Jiming; Luo, Zheng; Zeng, Qingxia] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing, Peoples R China.
   [Zheng, Jiming] Chongqing Univ Posts & Telecommun, Key Lab Intelligent Anal & Decis Complex Syst, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Zheng, JM (corresponding author), Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing, Peoples R China.; Zheng, JM (corresponding author), Chongqing Univ Posts & Telecommun, Key Lab Intelligent Anal & Decis Complex Syst, Chongqing 400065, Peoples R China.
EM Zhengjm@cqupt.edu.cn
OI Zheng, Jiming/0000-0002-6237-0168
FU National Natural Science Foundation of China [61876201]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61876201).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Dagadu JC, 2019, MULTIMED TOOLS APPL, V78, P24979, DOI 10.1007/s11042-019-7693-2
   Deng Xiao-Heng, 2014, Journal on Communications, V35, P216, DOI 10.3969/j.issn.1000-436x.2014.03.025
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Shen J, 2005, C ADV MULT INF PROC
   Souyah A, 2016, LECT NOTE NETW SYST, P3, DOI 10.1007/978-3-319-33410-3_1
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yang FF, 2020, CHINA COMMUN, V17, P21, DOI 10.23919/JCC.2020.05.003
   Yang Jiyun, 2018, Computer Engineering, V44, P151, DOI 10.3969/j.issn.1000-3428.2018.02.027
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 25
TC 13
Z9 13
U1 5
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29901
EP 29921
DI 10.1007/s11042-020-09454-9
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640300002
DA 2024-07-18
ER

PT J
AU Hosseinzadeh, M
   Koohpayehzadeh, J
   Bali, AO
   Asghari, P
   Souri, A
   Mazaherinezhad, A
   Bohlouli, M
   Rawassizadeh, R
AF Hosseinzadeh, Mehdi
   Koohpayehzadeh, Jalil
   Bali, Ahmed Omar
   Asghari, Parvaneh
   Souri, Alireza
   Mazaherinezhad, Ali
   Bohlouli, Mahdi
   Rawassizadeh, Reza
TI A diagnostic prediction model for chronic kidney disease in internet of
   things platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Multimedia medical systems; Healthcare data
   analytics; Chronic kidney disease (CKD); Feature selection techniques;
   Classification methods
ID FEATURE-SELECTION; HEALTH; CLASSIFICATION; PEOPLE
AB Chronic Kidney Disease (CKD) is being typically observed as a health threatening issue, especially in developing countries, where receiving proper treatments are very expensive. Therefore, early prediction of CKD that protects the kidney and breaks the gradual progress of CKD has become an important issue for physicians and scientists. Internet of Things (IoT) as a useful paradigm in which, low cost body sensor and smart multimedia medical devices are applied to provide remote monitoring of kidney function, plays an important role, especially where the medical care centers are hardly available for most of people. To gain this objective, in this paper, a diagnostic prediction model for CKD and its severity is proposed that applies IoT multimedia data. Since the influencing features on CKD are enormous and also the volume of the IoT multimedia data is usually very huge, selecting different features based on physicians' clinical observations and experiences and also previous studies for CKD in different groups of multimedia datasets is carried out to assess the performance measures of CKD prediction and its level determination via different classification techniques. The experimental results reveal that the applied dataset with the proposed selected features produces 97% accuracy, 99% sensitivity and 95% specificity via applying decision tree (J48) classifier in comparison to Support Vector Machine (SVM), Multi-Layer Perception (MLP) and Naive Bayes classifiers. Also, the proposed feature set can improve the execution time in comparison to other datasets with different features.
C1 [Hosseinzadeh, Mehdi] Duy Tan Univ, Inst Res & Dev, Da Nang 550000, Vietnam.
   [Hosseinzadeh, Mehdi; Souri, Alireza] Iran Univ Med Sci, Hlth Management & Econ Res Ctr, Tehran, Iran.
   [Koohpayehzadeh, Jalil] Iran Univ Med Sci, Dept Community Med, Prevent Med & Publ Hlth Res Ctr, Tehran, Iran.
   [Bali, Ahmed Omar] Univ Human Dev, Diplomacy & Publ Relat Dept, Sulaymaniyah, Iraq.
   [Asghari, Parvaneh] Islamic Azad Univ, Cent Tehran Branch, Dept Comp Engn, Tehran, Iran.
   [Mazaherinezhad, Ali] Iran Univ Med Sci, Sch Med, Hazrat Rasool Hosp, Dept Sports Med, Tehran, Iran.
   [Bohlouli, Mahdi] Inst Adv Studies Basic Sci, Dept Comp Sci & Informat Technol, Zanjan, Iran.
   [Bohlouli, Mahdi] Res & Innovat Dept Petanux GmbH, Bonn, Germany.
   [Rawassizadeh, Reza] Boston Univ, Dept Comp Sci, Metropolitan Coll, 111 Cummington St, Boston, MA 02215 USA.
C3 Duy Tan University; Iran University of Medical Sciences; Iran University
   of Medical Sciences; Islamic Azad University; Iran University of Medical
   Sciences; Institute for Advanced Studies in Basic Sciences (IASBS);
   Boston University
RP Souri, A (corresponding author), Iran Univ Med Sci, Hlth Management & Econ Res Ctr, Tehran, Iran.
EM hosseinzadeh.m@iums.ac.ir; koohpaye.j@iums.ac.ir; ahmed.bali@uhd.edu.iq;
   p_asghari@iauctb.ac.ir; souri.a@iums.ac.ir; mazaheri.a@iums.ac.ir;
   me@bohlouli.com; rrawassizadeh@acm.org
RI Mazaherinezhad@gmail.com, Ali/O-6317-2018; Bohlouli,
   Mahdi/AEI-1614-2022; Hosseinzadeh, Mehdi/GWV-3822-2022; Hosseinzadeh,
   Mehdi/ABE-7443-2020; Souri, Alireza/Y-4580-2018; Asghari,
   Parvaneh/AAO-3080-2021; Hosseinzadhe, Mehdi/AAU-4191-2021
OI Bohlouli, Mahdi/0000-0002-6659-5524; Souri, Alireza/0000-0001-8314-9051;
   Omar Bali, ahmed/0000-0002-4458-5683; Asghari,
   Parvaneh/0000-0002-5969-6896
FU  [98-1-37-14858];  [IR.IUMS.REC.1398.282]
FX This paper derives from the Research Project with code 98-1-37-14858 and
   Approval ID IR.IUMS.REC.1398.282.
CR Abdelaziz A., 2019, Security in Smart Cities: Models, Applications, and Challenges, P93, DOI [10.1007/978-3-030-01560-2_5, DOI 10.1007/97830300156025, DOI 10.1007/978-3-030-01560-25]
   Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   Al-Zinati M, 2020, SIMUL MODEL PRACT TH, V101, DOI 10.1016/j.simpat.2019.101957
   Asghari P., T EMERGING TELECOMMU
   Asghari P, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3637
   Belina S., 2018, INT J ENG TECHNOLOGY, V7, P190
   Bhatti MH, 2019, IEEE T IND INFORM, V15, P5747, DOI 10.1109/TII.2019.2925624
   Bragadottir G, 2013, CRIT CARE, V17, DOI 10.1186/cc12777
   Charleonnan A., 2016, 2016 MAN INN TECHN I, P80, DOI DOI 10.1109/MITICON.2016.8025242
   Chimwayi KB, 2017, RISK LEVEL PREDICTIO
   Deebak BD, 2019, IEEE ACCESS, V7, P135632, DOI 10.1109/ACCESS.2019.2941575
   Elhoseny M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46074-2
   Fried LP, 2001, J GERONTOL A-BIOL, V56, pM146, DOI 10.1093/gerona/56.3.M146
   Hamim M, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P533, DOI [10.1109/ICREST.2019.8644514, 10.1109/icrest.2019.8644514]
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Nguyen HH, 2017, INT C COMP SUPP COOP, P257, DOI 10.1109/CSCWD.2017.8066704
   Hussain A, 2015, J SYST SOFTWARE, V110, P253, DOI 10.1016/j.jss.2015.08.041
   Jain D, 2018, EGYPT INFORM J, V19, P179, DOI 10.1016/j.eij.2018.03.002
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kumar N, 2017, 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT)
   Lakshmanaprabu SK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105487
   Larsson A, 2004, SCAND J CLIN LAB INV, V64, P25, DOI 10.1080/00365510410003723
   Mainetti L, 2016, INT CONF SOFTW, P436
   Otunaiya Kehinde A, 2019, PERFORMANCE DATAMINI
   Oueida S, 2019, MULTIMED TOOLS APPL, V78, P24573, DOI 10.1007/s11042-018-6647-4
   Oueida S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124307
   Ravizza S, 2019, NAT MED, V25, P57, DOI 10.1038/s41591-018-0239-8
   Shrivas A.K., 2018, SOC SCI RES NETW ELE, V4, P26, DOI [10.2139/ssrn.3168581, DOI 10.2139/SSRN.3168581]
   Singh A, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS FOR COMPUTING RESEARCH (ICAICR '19), DOI 10.1145/3339311.3339329
   Tan ET, 2019, IETE J RES, V65, P653, DOI 10.1080/03772063.2018.1447402
   Tuli S, 2020, FUTURE GENER COMP SY, V104, P187, DOI 10.1016/j.future.2019.10.043
   Ware JE, 2000, SPINE, V25, P3130, DOI 10.1097/00007632-200012150-00008
   Xiong CZ, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1136-x
NR 33
TC 28
Z9 29
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16933
EP 16950
DI 10.1007/s11042-020-09049-4
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000553718200004
DA 2024-07-18
ER

PT J
AU Yao, QJ
   Shao, ZH
   Shang, YY
   Ding, H
   Liu, XL
   Zeng, R
   Tong, QB
AF Yao, Qijun
   Shao, Zhuhong
   Shang, Yuanyuan
   Ding, Hui
   Liu, Xilin
   Zeng, Rui
   Tong, Qingbin
TI Color image encryption based on discrete trinion Fourier transform and
   random-multiresolution singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Discrete trinion Fourier transform;
   Multiresolution singular value decomposition; Logistic map
ID GYRATOR TRANSFORM; INFORMATION
AB With more and more color images are spread and shared in the untrusted cloud server remotely over the open Internet, some private or confidential information may be contained, it is necessary to develop cryptosystem for these images to free from serious threats. This paper investigates a secure and robust cryptosystem for color image based on discrete trinion Fourier transform and random-multiresolution singular value decomposition. Firstly, a color image is represented into a trinion matrix by precoding and followed by block-wise discrete trinion Fourier transform. Then a mapping from trinion number domain to real number domain is implemented to facilitate random-multiresolution singular value decomposition. To further enhance the randomness of the transformed data, the scrambling based on chaotic sequence is applied to obtain the cipherimage. Experimental results have demonstrated that the proposed color image encryption algorithm is feasible. The adoption of logistic map ensures that the proposed cryptosystem attains high level security. Furthermore, the quality of the retrieved image is better than that of the algorithm based on single color channel processing separately and quaternion matrix based algorithms when it is decrypted correctly or under Gaussian noise and shear attacks. Moreover, employing a trinion matrix to represent a color image is more compact than using quaternion matrix. It would have potential applications in digital image protection.
C1 [Yao, Qijun] Capital Normal Univ, Beijing 100048, Peoples R China.
   [Shao, Zhuhong; Shang, Yuanyuan; Ding, Hui] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Liu, Xilin] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Peoples R China.
   [Zeng, Rui] Univ Sydney, Sydney, NSW, Australia.
   [Tong, Qingbin] Beijing Jiaotong Univ, Sch Elect Engn, Beijing 100044, Peoples R China.
C3 Capital Normal University; Capital Normal University; Taiyuan University
   of Technology; University of Sydney; Beijing Jiaotong University
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI Liu, Xilin/AAL-6947-2021; Shao, Zhuhong/AAD-4129-2022; Shang,
   Yuanyuan/ACH-0016-2022; Liu, Xilin/AFQ-1082-2022
OI Shang, Yuanyuan/0000-0003-4219-2541; Liu, Xilin/0000-0002-1136-6783
FU National Natural Science Foundation of China [61876112, 61601311];
   Project of Beijing Excellent Talents [2016000020124G088]; Beijing
   Municipal Education Research Plan Project [SQKM201810028018]; Natural
   Science Foundation of Shanxi Province [201801D221186]; School Foundation
   of Taiyuan University of Technology [2017QN12]
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311), Project of Beijing Excellent Talents
   (2016000020124G088), Beijing Municipal Education Research Plan Project
   (SQKM201810028018), Natural Science Foundation of Shanxi Province
   (201801D221186), School Foundation of Taiyuan University of Technology
   (2017QN12).
CR Abuturab MR, 2014, OPT LASER ENG, V57, P13, DOI 10.1016/j.optlaseng.2014.01.006
   Assefa D, 2011, SIGNAL PROCESS, V91, P1887, DOI 10.1016/j.sigpro.2011.02.011
   Bahri M, 2017, AIP CONF PROC, V1913, DOI 10.1063/1.5016638
   Bahria M, 2016, INF INT INTERDISC J, V19, P1657
   Bekkouche T, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023033
   Bhatnagar G, 2014, INFORM SCIENCES, V277, P247, DOI 10.1016/j.ins.2014.02.018
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Chen H, 2019, OPT LASER ENG, V112, P7, DOI 10.1016/j.optlaseng.2018.08.020
   Chen H, 2017, OPT LASER ENG, V93, P1, DOI 10.1016/j.optlaseng.2017.01.005
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Fan CL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060445
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Faragallah OS, 2019, IEEE ACCESS, V7, P4184, DOI 10.1109/ACCESS.2018.2879857
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Guo C, 2017, OPT LASER ENG, V89, P2, DOI 10.1016/j.optlaseng.2016.03.021
   Joshi M, 2010, OPT COMMUN, V283, P2496, DOI 10.1016/j.optcom.2010.02.024
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Lee IH, 2014, J OPT SOC KOREA, V18, P129, DOI 10.3807/JOSK.2014.18.2.129
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Liu XL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043046
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Luan GY, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2018.2886295
   Luo YL, 2018, IEEE ACCESS, V6, P77740, DOI 10.1109/ACCESS.2018.2884013
   Panna B, 2019, IETE TECH REV, V36, P600, DOI 10.1080/02564602.2018.1533892
   Praaveen K.P., 2018, ACM J NETW COMPUT AP, V108, P37
   Shao ZH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115662
   Shao ZH, 2013, IEEE IMAGE PROC, P4579, DOI 10.1109/ICIP.2013.6738943
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang X, 2012, CEREBROVASC DIS, V34, P7
   Wang XL, 2011, OPTIK, V122, P1856, DOI 10.1016/j.ijleo.2010.11.016
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao LL, 2017, OPT LASER ENG, V89, P80, DOI 10.1016/j.optlaseng.2016.06.007
   Yi FL, 2017, APPL OPTICS, V56, P4381, DOI 10.1364/AO.56.004381
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
NR 37
TC 6
Z9 6
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27555
EP 27581
DI 10.1007/s11042-020-09296-5
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552942300001
DA 2024-07-18
ER

PT J
AU Bellaaj, M
   Ouni, K
AF Bellaaj, Maha
   Ouni, Kais
TI Audio watermarking technique in frequency domain: comparative study MDCT
   Vs DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Digital; Audio; MDCT; DCT; Imperceptibility; Robustness;
   SNR; ODG; PEAQ
ID ALGORITHMS
AB Digital watermarking is the art of hiding information in a digital document in order to protect it. The inserted mark and the marked document can be an image, an audio or a video. In this article, we will present a comparative study between two variants of a digital audio watermarking technique operating in the frequency domain. In the first variant, the time-frequency mapping is performed by Modified Discrete Cosine Transform (MDCT). For the second variant, the time-frequency mapping is performed by the Discrete Cosine Transform (DCT). We will study the contribution of each transformation, point of view robustness against different types of attacks delivered by Stirmark audio, imperceptibility by using a statistical approach by calculating the SNR and an objective approach by calculating the ODG notes given by PEAQ and capacity of insertion. Finally, to highlight our results, we will compare the two variants of the proposed technique with some other existing techniques.
C1 [Bellaaj, Maha; Ouni, Kais] Univ Carthage, SEICT, Res Lab Smart Elect & ICT, Natl Engn Sch Carthage,ENICarthage,LR18ES44, Tunis, Tunisia.
C3 Universite de Carthage
RP Bellaaj, M; Ouni, K (corresponding author), Univ Carthage, SEICT, Res Lab Smart Elect & ICT, Natl Engn Sch Carthage,ENICarthage,LR18ES44, Tunis, Tunisia.
EM maha_bellaaj@yahoo.fr; kais.ouni@enicarthage.rnu.tn
RI Ouni, Kais/HNP-1767-2023
OI Ouni, Kais/0000-0003-1989-5177; bellaaj, maha/0000-0002-7619-8864
CR Ahmed N, 1974, IEEE T COMPUTERS C 2
   Anne M, 2001, TATOUAGE DIMAGES NUM
   [Anonymous], 1994, IS138183 ISOIEC
   [Anonymous], 1995, T3S7 AUD SPEC GROUP
   [Anonymous], IS111723 ISOIEC
   Baras C, 2005, TATOUAGE INFORME SIG
   Barnett R, 1999, ELECTRON COMMUN ENG, V11, P173, DOI 10.1049/ecej:19990401
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Cheng MH, 2003, IEEE T SIGNAL PROCES, V51, P221, DOI 10.1109/TSP.2002.806566
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   Cvejic N, 2003, P 3 INT S IM SIGN PR
   Dhar PK, 2017, RADIOENGINEERING, V26, P552, DOI 10.13164/re.2017.0552
   Drweesh ZT., 2014, INT J ENG TECHNOLOGY, V4, P45
   Eskicioglu AM, 2001, SIGNAL PROCESS-IMAGE, V16, P681, DOI 10.1016/S0923-5965(00)00050-3
   Fadwa D, 2003, TATOUAGE IMAGES TECH
   Gwenael D, 2005, TATOUAGE VIDEO, V22, P563
   Hembrooke E. F., 1961, US Patent, Patent No. [US3004104 A, 3004104]
   Hu HT, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-12
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Khalil M, 2014, THESIS
   Martin T, 2007, SCI DIGITAL MEDIA S
   Pinel J, 2010, 10 C FRANC AC LYON A, P12
   PRINCEN JP, 1986, IEEE T ACOUST SPEECH, V34, P1153, DOI 10.1109/TASSP.1986.1164954
   Princen JP, 1987, SUBBAND TRANSFORM C, P2161
   Shao XC, 2008, SIGNAL PROCESS, V88, P1313, DOI 10.1016/j.sigpro.2007.11.024
   Union Internationale des Telecommunications (UIT): Recommandation B.S, 2001, UN INT TEL UIT REC B
   Wu QL, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070284
   Wu QL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050723
NR 29
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27161
EP 27184
DI 10.1007/s11042-020-09338-y
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551736600005
DA 2024-07-18
ER

PT J
AU Zaman, MAU
   Islam, MR
   Rahman, MH
   Schultz, K
   McGonigle, E
   Wang, IG
AF Zaman, Md Assad Uz
   Islam, Md Rasedul
   Rahman, Mohammad Habib
   Schultz, Katie
   McGonigle, Erin
   Wang, Inga
TI Robot sensor system for supervised rehabilitation with real-time
   feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humanoid robot; Supervised rehabilitation; Telehealth; Kinect
ID EXOSKELETON; VISION; STROKE; TRACKING; DESIGN
AB Numerous assistive robot approaches have been proposed to rehabilitate individuals with impaired upper-limb function. However, to the best of our knowledge, none of these are fully supervised by the robotic system. In this research, we intend to use a robot as a tool to provide robot-guided supervised rehabilitation. A humanoid robot, NAO, was used for this purpose. To demonstrate rehabilitation exercises with NAO, a library of recommended rehabilitation exercises involving the shoulder (abduction/adduction, vertical flexion/extension, and internal/external rotation), and elbow (flexion/extension) joint movements were created. An Xbox Kinect sensor was used to analyze the subject upper arm movement during rehabilitation. For this purpose, a complete geometric solution was developed to find a unique inverse kinematic solution of human upper-arm from the Kinect data. A control algorithm was developed in MATLAB for the proposed robot guided supervised rehabilitation protocol. Experimental results show that the NAO and Kinect sensor can effectively be used to supervise and guide the subjects in performing active rehabilitation exercises for the shoulder and elbow joint movements.
C1 [Zaman, Md Assad Uz; Islam, Md Rasedul; Rahman, Mohammad Habib] Univ Wisconsin, Mech Engn Dept, BioRobot Lab, Room USR 281,115 E Reindl Way, Milwaukee, WI 53212 USA.
   [Schultz, Katie] Clement J Zablocki VA Med Ctr, Milwaukee, WI USA.
   [McGonigle, Erin] Med Coll Wisconsin MCW, Dept Phys Med & Rehabil, Milwaukee, WI USA.
   [Wang, Inga] Univ Wisconsin, Occupat Sci & Technol Dept, Milwaukee, WI 53201 USA.
C3 University of Wisconsin System; University of Wisconsin Milwaukee;
   University of Wisconsin System; University of Wisconsin Milwaukee
RP Zaman, MAU (corresponding author), Univ Wisconsin, Mech Engn Dept, BioRobot Lab, Room USR 281,115 E Reindl Way, Milwaukee, WI 53212 USA.
EM assaduz2@uwm.edu
RI Islam, Md Rasedul/C-4462-2019
OI Assad-Uz-Zaman, Md/0000-0001-5616-6497
CR Ali A, 2012, BOSNIAN J BASIC MED, V12, P193, DOI 10.17305/bjbms.2012.2484
   Back I., 2013, Annals of Long-Term Care: Clinical Care and Aging, V21, P38
   Bai J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081620
   Bakhti KKA, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0451-2
   Brainin M, 2007, LANCET NEUROL, V6, P553, DOI 10.1016/S1474-4422(07)70005-4
   Cai LS, 2019, APPL BIONICS BIOMECH, V2019, DOI 10.1155/2019/7175240
   Capecci M, 2015, IEEE ENG MED BIO, P8034, DOI 10.1109/EMBC.2015.7320257
   Carrillo FM, 2018, ACM T HUM-ROBOT INTE, V7, DOI 10.1145/3203304
   Ciabattoni L, 2016, IEEE IND ELEC, P400, DOI 10.1109/IECON.2016.7793305
   Craig J. J., 2005, Introduction to Robotics: Mechanics and Control
   Devanne M, 2018, 2018 SECOND IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P352, DOI 10.1109/IRC.2018.00074
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Sucar LE, 2008, COMM COM INF SC, V25, P531
   Fan J, 2016, IEEE ROMAN, P445, DOI 10.1109/ROMAN.2016.7745157
   Gorer Binnur, 2013, Ambient Intelligence. 4th International Joint Conference, AmI 2013. Proceedings: LNCS 8309, P124, DOI 10.1007/978-3-319-03647-2_9
   Görer B, 2017, AUTON ROBOT, V41, P657, DOI 10.1007/s10514-016-9598-5
   Gouaillier D, 2009, IEEE INT CONF ROBOT, P2124, DOI 10.1109/robot.2009.5152516
   Guidali M, 2011, MED BIOL ENG COMPUT, V49, P1213, DOI 10.1007/s11517-011-0809-0
   Hu XL, 2009, J ELECTROMYOGR KINES, V19, P639, DOI 10.1016/j.jelekin.2008.04.002
   Zannatha JMI, 2013, COMPUT METH PROG BIO, V112, P239, DOI 10.1016/j.cmpb.2013.04.021
   Islam MR, 2017, ADV ROBOT AUTOM, V6, P177, DOI DOI 10.4172/2168-9695.1000177
   Kiguchi K, 2008, ROBOT AUTON SYST, V56, P678, DOI 10.1016/j.robot.2007.11.007
   Krebs H I, 1998, IEEE Trans Rehabil Eng, V6, P75, DOI 10.1109/86.662623
   Lei Q, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194129
   Lotfi A, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010032
   Lum PS, 2004, IEEE T NEUR SYS REH, V12, P186, DOI 10.1109/TNSRE.2004.827225
   Mobini A, 2014, DISABIL REHABIL-ASSI, V9, P344, DOI 10.3109/17483107.2013.805825
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Otten A, 2015, IEEE-ASME T MECH, V20, P2285, DOI 10.1109/TMECH.2014.2375272
   Perry JC, 2007, IEEE-ASME T MECH, V12, P408, DOI 10.1109/TMECH.2007.901934
   Piron L, 2008, J TELEMED TELECARE, V14, P257, DOI 10.1258/jtt.2008.080304
   Rahman MH, 2015, ROBOTICA, V33, P19, DOI 10.1017/S0263574714000034
   Scherer M, 2016, PROCEDIA ENGINEER, V147, P466, DOI 10.1016/j.proeng.2016.06.342
   Semblantes Piedad A., 2018, Informatics in Medicine Unlocked, V13, P41, DOI 10.1016/j.imu.2018.10.002
   Terven JR, 2016, SCI COMPUT PROGRAM, V130, P97, DOI 10.1016/j.scico.2016.05.009
   Tho YQ, 2007, INT J ROBOT RES, V26, P607, DOI 10.1177/0278364907079278
   Thobbi A., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P92, DOI 10.1109/ICHR.2010.5686324
   Venugopalan J, 2013, IEEE ENG MED BIO, P4625, DOI 10.1109/EMBC.2013.6610578
   Wang F, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3692, DOI 10.1109/WCICA.2012.6359088
   Winter D.A.D.A. Winter., 1990, Biomechanics and motor control of human movement, V2nd, pxvi
   Xu JF, 2019, RACSAM REV R ACAD A, V113, P1343, DOI 10.1007/s13398-018-0551-7
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Yang C, 2016, IEEE ACCESS, V4, P650, DOI 10.1109/ACCESS.2016.2523803
   Yang NJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2191, DOI 10.1109/ROBIO.2013.6739794
   Zhao WB, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN HEALTHCARE AND E-HEALTH (CICARE), P133, DOI 10.1109/CICARE.2014.7007845
NR 45
TC 2
Z9 4
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26643
EP 26660
DI 10.1007/s11042-020-09266-x
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700001
DA 2024-07-18
ER

PT J
AU Zhao, L
   Wang, ZC
   Zhang, GX
   Gao, HB
AF Zhao, Lei
   Wang, Zengcai
   Zhang, Guoxin
   Gao, Huanbing
TI Driver drowsiness recognition via transferred deep 3D convolutional
   network and state probability vector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driver drowsiness detection; 3D convolution neural network; State
   probability vector; Transfer learning; Residual learning
ID FATIGUE
AB Driver drowsiness is a major cause of road accidents. In this study, a novel approach that detects human drowsiness is proposed and investigated. First, driver face and facial landmarks are detected to extract facial region from each frame in a video. Then, a residual-based deep 3D convolution neural network (CNN) that learned from an irrelevant dataset is constructed to classify driver facial image sequences with a certain number of frames for obtaining its drowsiness output probability value. After that, a certain number of output probability values is concatenated to obtain the state probability vector of a video. Finally, a recurrent neural network is adopted to classify constructed probability vector and obtain the recognition result of driver drowsiness. The proposed method is tested and investigated using a public drowsy driver dataset. Experimental results demonstrate that similar to 2D CNN, 3D CNN can learn spatiotemporal features from irrelevant dataset to improve its performance obviously in driver drowsiness classification. Furthermore, the proposed method performs stably and robustly, and it can achieve an average accuracy of 88.6%.
C1 [Zhao, Lei] Shandong Jianzhu Univ, Sch Mech & Elect Engn, 1000 Fengming Rd, Jinan, Peoples R China.
   [Wang, Zengcai] Shandong Univ, Sch Mech Engn, Vehicle Engn Res Inst, Jinan, Peoples R China.
   [Zhang, Guoxin] Hong Kong Polytech Univ, Dept Mech Engn, Hung HomKowloon, Hong Kong, Peoples R China.
   [Gao, Huanbing] Shandong Jianzhu Univ, Sch Informat & Elect Engn, 1000 Fengming Rd, Jinan, Peoples R China.
C3 Shandong Jianzhu University; Shandong University; Hong Kong Polytechnic
   University; Shandong Jianzhu University
RP Zhao, L (corresponding author), Shandong Jianzhu Univ, Sch Mech & Elect Engn, 1000 Fengming Rd, Jinan, Peoples R China.
EM leizhao1219@sdjzu.edu.cn; wangzc@sdu.edu.cn; zhanggx@polyu.edu.hk;
   gaohuanbing2004@sdjzu.edu.cn
FU Doctoral Foundation of Shandong Jianzhu University (China) [X18039Z];
   Natural Science Foundation of Shandong Province (China) [ZR2018MEE015];
   Open Foundation of State Key Laboratory of Automotive Simulation and
   Control (China) [20161105]
FX This work was supported by the Doctoral Foundation of Shandong Jianzhu
   University (China, Grant no. X18039Z), the Natural Science Foundation of
   Shandong Province (China, Grant no. ZR2018MEE015) and the Open
   Foundation of State Key Laboratory of Automotive Simulation and Control
   (China, Grant no. 20161105).
CR Akrout Belhassen, 2016, P INT IMAGE PROCESSI, P1, DOI DOI 10.1109/IPAS.2016.7880127
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   Deo N., 2018, ARXIV181106047
   Donahue J, 2014, PR MACH LEARN RES, V32
   Gou C, 2017, PATTERN RECOGN, V67, P23, DOI 10.1016/j.patcog.2017.01.023
   Guo JH, 2019, MECH ADV MATER STRUC, V26, P1390, DOI 10.1080/15376494.2018.1432810
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kay W., 2017, ARXIV170506950
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mandal B, 2017, IEEE T INTELL TRANSP, V18, P545, DOI 10.1109/TITS.2016.2582900
   Mårtensson H, 2019, IEEE T INTELL TRANSP, V20, P421, DOI 10.1109/TITS.2018.2814207
   McDonald AD, 2018, ACCIDENT ANAL PREV, V113, P25, DOI 10.1016/j.aap.2018.01.005
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Ou CJ, 2018, IEEE INT CONF FUZZY
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   Sikander G, 2019, IEEE T INTELL TRANSP, V20, P2339, DOI 10.1109/TITS.2018.2868499
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Tong M, 2019, NEURAL COMPUT APPL, V31, P7447, DOI 10.1007/s00521-018-3554-6
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yen IL, 2017, 2017 11TH IEEE SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE), P1, DOI 10.1109/SOSE.2017.26
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   You F, 2017, MULTIMED TOOLS APPL, V76, P14869, DOI 10.1007/s11042-016-4103-x
   Yu JT, 2016, IEEE INT SYMP NANO, P165, DOI 10.1145/2950067.2950071
   Zhang W, 2015, EVID-BASED COMPL ALT, V2015, P1
   Zhao L, 2018, MULTIMED TOOLS APPL, V77, P19415, DOI 10.1007/s11042-017-5380-8
   Zhao L, 2018, IET INTELL TRANSP SY, V12, P127, DOI 10.1049/iet-its.2017.0183
   Zhao L, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053024
NR 34
TC 12
Z9 12
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26683
EP 26701
DI 10.1007/s11042-020-09259-w
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700004
DA 2024-07-18
ER

PT J
AU Cheng, EJ
   Prasad, M
   Yang, J
   Zheng, DR
   Tao, X
   Mery, D
   Young, KY
   Lin, CT
AF Cheng, Eric Juwei
   Prasad, Mukesh
   Yang, Jie
   Zheng, Ding Rong
   Tao, Xian
   Mery, Domingo
   Young, Ku Young
   Lin, Chin Teng
TI A novel online self-learning system with automatic object detection
   model for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Online learning; Real-time learning; Feature pool;
   Classifier
AB This paper proposes a novel online self-learning detection system for different types of objects. It allows users to random select detection target, generating an initial detection model by selecting a small piece of image sample and continue training the detection model automatically. The proposed framework is divided into two parts: First, the initial detection model and the online reinforcement learning. The detection model is based on the proportion of users of the Haar-like features to generate feature pool, which is used to train classifiers and get positive-negative (PN) classifier model. Second, as the videos plays, the detecting model detects the new sample by Nearest Neighbor (NN) Classifier to get the PN similarity for new model. Online reinforcement learning is used to continuously update classifier, PN model and new classifier. The experiment shows the result of less detection sample with automatic online reinforcement learning is satisfactory.
C1 [Cheng, Eric Juwei; Zheng, Ding Rong; Young, Ku Young] Natl Chiao Tung Univ, Dept Elect Engn, Comp Sci, Hsinchu, Taiwan.
   [Prasad, Mukesh; Yang, Jie; Lin, Chin Teng] Univ Technol, Felt, Sch Comp Sci, Ctr Artificial Intelligence, Sydney, Ultimo, Australia.
   [Tao, Xian] Chinese Acad Sci, Res Ctr Precis Sensing & Control, Inst Automat, Beijing, Peoples R China.
   [Mery, Domingo] Pontificia Univ Catolica Chile, Dept Comp Sci, Santiago, Chile.
C3 National Yang Ming Chiao Tung University; University of Technology
   Sydney; Chinese Academy of Sciences; Institute of Automation, CAS;
   Pontificia Universidad Catolica de Chile
RP Prasad, M (corresponding author), Univ Technol, Felt, Sch Comp Sci, Ctr Artificial Intelligence, Sydney, Ultimo, Australia.
EM mukesh.prasad@uts.edu.au
RI Mery, Domingo/D-1385-2014; Lin, Chin-Teng (CT)/G-8129-2017
OI Mery, Domingo/0000-0003-4748-3882; Lin, Chin-Teng
   (CT)/0000-0001-8371-8197; Prasad, Mukesh/0000-0002-7745-9667
FU Australian Research Council (ARC) [DP180100670, DP180100656]; U.S. Army
   Research Laboratory [W911NF-10-2-0022]; Taiwan Ministry of Science and
   Technology [MOST 1062218-E-009-027-MY3]
FX This work was supported in part by the Australian Research Council (ARC)
   under Grant DP180100670 and Grant DP180100656, in part by the U.S. Army
   Research Laboratory under Agreement W911NF-10-2-0022, and in part by the
   Taiwan Ministry of Science and Technology under Grant MOST
   1062218-E-009-027-MY3.
CR [Anonymous], 2007, CS CMU ED
   [Anonymous], 2005, INT TRANSP SYST 2005
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2005, VIS SURV PERF EV TRA
   [Anonymous], 2015, TRAINING VERY DEEP N
   Blocki J, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1820, DOI 10.1145/3243734.3243773
   Cheng YY, 2014, ADAPTIVE ON LINE BOO
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dong EZ, 2019, IET COMPUT VIS, V13, P730, DOI 10.1049/iet-cvi.2018.5787
   Farfade S, 2015, INT C MULT RETR 2015
   Geronimo D, 2007, HAAR WAVELETS EDGE O, P418
   Gopale R, 2014, INT J INFINITE INNOV
   Grabner H., 2006, BMVC, P47
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo CH, 2009, RECONFIGURABLE MECHANISMS AND ROBOTS, P1
   Lee JF, 2010, NOVEL VEHICLE DETECT
   Lienhart R., 2002, INT C IM PROC, V1
   Oza NC, 2005, MAN CYB 2005 IEEE IN, V3
   Peng Suo, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1436, DOI 10.1109/ICOSP.2008.4697402
   Riberio M, 2017, IEEE INT C AUT ROB S
   Roth PM, 2008, COGN TECHNOL, P139, DOI 10.1007/978-3-540-75171-7_6
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Scharcanski J, 2011, IEEE T VEH TECH, V6
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Su J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183774
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Tome D, 2016, IEEE ICCE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walk S., 2010, CVPR 2010, DOI DOI 10.1109/CVPR.2010.5540102
   Wang L, 2017, IEEE INT CON MULTI, P1135, DOI 10.1109/ICME.2017.8019461
   Wu BS, 2013, DETECTION TRACKING M
   Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252
   Zhang Song, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P387, DOI 10.1109/ICEMI.2017.8265827
NR 35
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16659
EP 16681
DI 10.1007/s11042-020-09055-6
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000548128400006
DA 2024-07-18
ER

PT J
AU Poux, D
   Allaert, B
   Mennesson, J
   Ihaddadene, N
   Bilasco, IM
   Djeraba, C
AF Poux, Delphine
   Allaert, Benjamin
   Mennesson, Jose
   Ihaddadene, Nacim
   Bilasco, Ioan Marius
   Djeraba, Chaabane
TI Facial expressions analysis under occlusions based on specificities of
   facial motion propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial occlusions; Motion propagation; Facial framework; Facial
   expressions
ID RECOGNITION; ASYMMETRY
AB Although much progress has been made in the facial expression analysis field, facial occlusions are still challenging. The main innovation brought by this contribution consists in exploiting the specificities of facial movement propagation for recognizing expressions in presence of important occlusions. The movement induced by an expression extends beyond the movement epicenter. Thus, the movement occurring in an occluded region propagates towards neighboring visible regions. In presence of occlusions, per expression, we compute the importance of each unoccluded facial region and we construct adapted facial frameworks that boost the performance of per expression binary classifier. The output of each expression-dependant binary classifier is then aggregated and fed into a fusion process that aims constructing, per occlusion, a unique model that recognizes all the facial expressions considered. The evaluations highlight the robustness of this approach in presence of significant facial occlusions.
C1 [Poux, Delphine; Allaert, Benjamin; Bilasco, Ioan Marius; Djeraba, Chaabane] Univ Lille, Ctr Rech Informat Signal & Automat Lille, CNRS, Cent Lille,UMR 9189,CRIStAL, F-59000 Lille, France.
   [Mennesson, Jose] Univ Lille, Ctr Rech Informat Signal & Automat Lille, CNRS, Cent Lille,UMR 9189,CRIStAL,IMT Lille Douai, F-59000 Lille, France.
   [Ihaddadene, Nacim] ISEN Lille, Lille, France.
C3 Universite de Lille; Centrale Lille; Centre National de la Recherche
   Scientifique (CNRS); IMT - Institut Mines-Telecom; Universite de Lille;
   IMT Nord Europe; Centre National de la Recherche Scientifique (CNRS);
   Centrale Lille
RP Poux, D (corresponding author), Univ Lille, Ctr Rech Informat Signal & Automat Lille, CNRS, Cent Lille,UMR 9189,CRIStAL, F-59000 Lille, France.
EM delphine.poux@univ-lille.fr; benjamin.allaert@univ-lille.fr;
   jose.mennesson@univ-lille.fr; nacim.ihaddadene@yncrea.fr;
   marius.bilasco@univ-lille.fr; chabane.djeraba@univ-lille.fr
RI Allaert, Benjamin/AAW-3144-2021; Mennesson, José/GQQ-1007-2022
OI Allaert, Benjamin/0000-0002-4291-9803; Nacim,
   Ihaddadene/0000-0003-0044-8385
FU IRCICA (Univ. Lille, CNRS, USR 3380 -IRCICA, Lille, France); PAPUD
   project [ITEA3 - 16037]
FX This work was partly supported by IRCICA (Univ. Lille, CNRS, USR 3380
   -IRCICA, F-59000 Lille, France) and PAPUD project (ITEA3 - 16037).
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Allaert B, 2020, IEEE T AFFECTIVE COM
   [Anonymous], 2012, ADV SCI LETT
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Buciu I, 2005, INT CONF ACOUST SPEE, P453
   Chen YA, 2017, IEEE IMAGE PROC, P1202, DOI 10.1109/ICIP.2017.8296472
   Cornejo Jair., 2018, 2018 IEEE ANDESCON, P1
   Dapogny A, 2018, INT J COMPUT VISION, V126, P255, DOI 10.1007/s11263-017-1010-1
   DOPSON WG, 1984, CORTEX, V20, P243, DOI 10.1016/S0010-9452(84)80041-6
   EKMAN P, 1980, SCIENCE, V209, P833, DOI 10.1126/science.7403851
   Huang XH, 2012, PATTERN RECOGN LETT, V33, P2181, DOI 10.1016/j.patrec.2012.07.015
   Huang Y, 1189, SYMMETRY, V11, P2019
   Jampour M, 2017, COMPUT VIS IMAGE UND, V161, P29, DOI 10.1016/j.cviu.2017.05.008
   Kacem A, 2017, IEEE I CONF COMP VIS, P3199, DOI 10.1109/ICCV.2017.345
   Kotsia I, 2008, IMAGE VISION COMPUT, V26, P1052, DOI 10.1016/j.imavis.2007.11.004
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P1092, DOI 10.1109/TIP.2018.2872876
   Liu SS, 2014, IEEE IJCNN, P1285, DOI 10.1109/IJCNN.2014.6889744
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Poux D, 2018, 2018 INT C CONT BAS, P1
   Ranzato M, 2011, HINTON G DEEP GENERA
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tie Y, 2013, IEEE T CIRC SYST VID, V23, P142, DOI 10.1109/TCSVT.2012.2203210
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhuang BH, 2017, PROC CVPR IEEE, P2915, DOI 10.1109/CVPR.2017.311
NR 28
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22405
EP 22427
DI 10.1007/s11042-020-08993-5
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000545195700002
DA 2024-07-18
ER

PT J
AU Pan, YQ
   Zhai, WP
   Gao, W
   Shen, XJ
AF Pan, Yuqing
   Zhai, Wenpeng
   Gao, Wei
   Shen, Xiangjun
TI If-SVM: Iterative factoring support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support vector machine (SVM); Factoring; Iterative; Noisy samples
AB Support Vector Machine (SVM) is widely applied in classification and regression tasks where support vectors are pursued through convex quadratic programming technique due to its effectiveness and efficiency. However, existing studies ignore the importance of training samples when they are fed into the model. In this paper, we propose a novel Iterative Factoring Support Vector Machine (If-SVM) method. Sample factoring is introduced in our proposed model to measure the significance of each data point, where it can effectively reduce the negative impact of trivial or noisy data points. In this way, our proposed model is concentrates on the critical data points falling around the hyperplane. By introducing this iterative factoring of data points into SVM, the classification accuracy of our proposed method is above that of 1.45% than other comparative methods in image recognition datasets. Experimental results on a variety of UCI demonstrate that, our proposed method has superior performances in decreasing the total number of support vectors than the other state-of-the-art SVM methods. More importantly, our further experiments also illustrate that, the classification performance of the state-of-the-art SVM methods can be improved 1.29% by incorporating our sample factoring idea into their models, which demonstrate our idea is a useful tool to improve the state-of-art SVM models.
C1 [Pan, Yuqing; Zhai, Wenpeng; Gao, Wei; Shen, Xiangjun] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xjshen@ujs.edu.cn
FU National Natural Science Foundation of China [61572240, 61701200]
FX This work was funded in part by the National Natural Science Foundation
   of China (No.61572240, 61701200).
CR Abeo TA, 2019, PATTERN RECOGN, V90, P1, DOI 10.1016/j.patcog.2019.01.012
   Phan AV, 2017, APPL INTELL, V46, P455, DOI 10.1007/s10489-016-0843-6
   Cang S, 2004, NEURAL COMPUT APPL, V13, P175, DOI 10.1007/S00521-004-0400-9
   Chaki J., 2019, IEEE T IMAGE PROCESS, VPP, P1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui C, 2013, IMAGING MULTIMEDIA A
   Cui WT, 2009, CHEMOMETR INTELL LAB, V98, P130, DOI 10.1016/j.chemolab.2009.05.008
   de Amorim RC, 2012, PATTERN RECOGN, V45, P1061, DOI 10.1016/j.patcog.2011.08.012
   Fan Y., 2017, Learning what data to learn
   Han X, 2018, NEUROCOMPUTING
   Hu WJ, 2003, CIRCUITS SYST 2, V51, P234
   Huang Gao, 2017, CVPR
   Kalousis A, 2009, EUR C MACH LEARN KNO
   Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861
   Lin CF, 2004, PATTERN RECOGN LETT, V25, P1647, DOI 10.1016/j.patrec.2004.06.009
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Liu Y, 2018, PATTERN RECOGN, V78, P307, DOI 10.1016/j.patcog.2018.01.022
   Meng D, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.121
   Min H, 2015, J ELECT MEASUREMENT
   Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2
   Ren MY, 2018, PR MACH LEARN RES, V80
   Shen XJ, 2018, LEAST SQUARES KERNEL
   Shivaswamy PK, 2010, J MACH LEARN RES, V11, P747
   Song Q, 2002, IEEE T SYST MAN CY C, V32, P440, DOI 10.1109/TSMCC.2002.807277
   Torkkola K., 2003, Journal of Machine Learning Research, V3, P1415, DOI 10.1162/153244303322753742
   Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061
   Wu JX, 2015, IEEE T NEUR NET LEAR, V26, P2357, DOI 10.1109/TNNLS.2014.2382123
   Xing HJ, 2008, IEEE INT JOINT C NEU
   Xinyu Wu, 2020, ISH Journal of Hydraulic Engineering, V26, P343, DOI 10.1080/09715010.2018.1481772
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu J, 2018, IEEE T IND ELECTRON, V65, P5060, DOI 10.1109/TIE.2017.2739691
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang Q, 2011, FEATURE SAMPLE WEIGH
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang X., 1999, IEEE SIGN PROC SOC W
NR 35
TC 5
Z9 6
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25441
EP 25461
DI 10.1007/s11042-020-09179-9
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545796700001
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Tang, JT
   Xiang, Q
   Zhao, P
AF Liu, Zhengyi
   Tang, Jiting
   Xiang, Qian
   Zhao, Peng
TI Salient object detection for RGB-D images by generative adversarial
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Salient object detection; RGB-D image;
   Self-attention; Double stream network
AB Salient object detection for RGB-D image aims to automatically detect the objects of human interest by color and depth information. In the paper generative adversarial network is adopted to improve its performance by adversarial learning. Generator network takes RGB-D images as inputs and outputs synthetic saliency maps. It adopts double stream network to extract color and depth feature individually and then fuses them from deep to shallow progressively. Discriminator network takes RGB image and synthetic saliency maps (RGBS), RGB image and ground truth saliency map (RGBY) as inputs, and outputs their labels indicating whether input is synthetics or ground truth. It consists of three convolution blocks and three fully connected layers. In order to pursuit long-range dependency of feature, self-attention layer is inserted in both generator and discriminator network. Supervised by real labels and ground truth saliency map, discriminator network and generator network are adversarial trained to make generator network cheat discriminator network successfully and discriminator network distinguish synthetics or ground truth correctly. Experiments demonstrate adversarial learning enhances the ability of generator network, RGBS and RGBY input in discriminator network and self-attention layer play an important role in improving the performance. Meanwhile our method outperforms state-of-the-art methods.
C1 [Liu, Zhengyi; Tang, Jiting; Xiang, Qian; Zhao, Peng] Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei, Peoples R China.
C3 Anhui University
RP Liu, ZY (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei, Peoples R China.
EM liuzywen@ahu.edu.cn; 1796340141@qq.com; xiangqianforward@foxmail.com;
   18868519@qq.com
RI xiang, q/KUD-1041-2024; Liu, Zhengyi/AAB-6589-2022
OI Liu, Zhengyi/0000-0003-3265-823X
FU National Natural Science Foundation of China [61602004]; Natural Science
   Foundation of Anhui Province [1908085MF182]; Key Program of Natural
   Science Project of Educational Commission of Anhui Province
   [KJ2019A0034]
FX We thank Dr. Hao Chen from City University of Hong Kong for providing
   their result saliency maps. We also thank Prof. Ming-ming Cheng and Dr.
   Deng-ping Fan from Nankai University for providing the codes of all
   evaluation metrics. We further thank all anonymous reviewers for their
   valuable comments. This research is supported by National Natural
   Science Foundation of China (61602004), Natural Science Foundation of
   Anhui Province (1908085MF182) and Key Program of Natural Science Project
   of Educational Commission of Anhui Province (KJ2019A0034).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], CVPR
   [Anonymous], 2016, Empirical Methods in Natural Language Processing
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], ARXIV160505396
   [Anonymous], 2018, ICML
   [Anonymous], 2018, ARXIV180205751
   [Anonymous], 2017, ARXIV170101081
   [Anonymous], 2018, GENERATIVE IMAGE INP
   [Anonymous], 2016, EMNLP 2016 C EMP MET, DOI DOI 10.18653/V1/D16-1053
   [Anonymous], 2019, 33 AAAI C ART INT
   Arjovsky M., 2017, ARXIV170107875
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Bao JT, 2015, SENSORS-BASEL, V15, P21054, DOI 10.3390/s150921054
   Brock A., 2018, PREPRINT
   Cai X, 2018, 9 INT C GRAPH IM PRO, V10615, P1061541
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen H, 2017, IEEE INT C INT ROBOT, P4911, DOI 10.1109/IROS.2017.8206370
   Chen H, 2017, LECT NOTES COMPUT SC, V10528, P459, DOI 10.1007/978-3-319-68345-4_41
   Chen LC, 2017, RETHINKING ATROUS CO
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng Y, 2014, P INT C INT MULT COM, P23
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Fan D.P., 2018, IJCAI
   Fan D-P, 2020, IEEE T NEURAL NETWOR, P1
   Fan D-P, 2019, PROC CVPR IEEE, P8554, DOI DOI 10.1109/CVPR.2019.00875
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Feng D, 2017, PROC INT C DIGIT IMA, P1
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han J, 2018, INT J CONTROL AUTOM, V16, P522, DOI 10.1007/s12555-016-0338-6
   Hsu KJ, 2019, PROC CVPR IEEE, P8838, DOI 10.1109/CVPR.2019.00905
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ji YZ, 2018, NEUROCOMPUTING, V316, P357, DOI 10.1016/j.neucom.2018.08.013
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ledig C., 2017, P IEEE C COMP VIS PA, P4681
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li C, 2019, ARXIV190608462
   Li M, 2018, BMVC, P291
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Mao XF, 2018, NEUROCOMPUTING, V293, P55, DOI 10.1016/j.neucom.2018.02.092
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan HY, 2020, PROC SPIE, V11373, DOI 10.1117/12.2557190
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pathak HN, 2018, IEEE INT CONF BIG DA, P1777, DOI 10.1109/BigData.2018.8622477
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao Y, 2019, IJCAI, P904
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Radford A., 2015, ARXIV151106434
   Ren JK, 2015, EUROMICRO, P25, DOI 10.1109/ECRTS.2015.10
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Song H., 2018, ECCV, P715
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Vaswani A., 2017, P ADV NEUR INF PROC, V2017, P5998
   Wang L, 2018, IEEE T AUTOM SCI ENG, V15, P1521, DOI 10.1109/TASE.2018.2868471
   Wang N, 2019, ARXIV190101369
   Wang SH, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12272
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wang W, 2019, IEEE PAMI
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei L, 2019, IEEE TIP
   Yan B, 2017, IEEE IMAGE PROC, P2339, DOI 10.1109/ICIP.2017.8296700
   Yoon YJ, 2017, IEICE T INF SYST, VE100D, P2245, DOI 10.1587/transinf.2016EDL8246
   Zeng YH, 2019, 2019 IEEE VTS ASIA PACIFIC WIRELESS COMMUNICATIONS SYMPOSIUM (APWCS 2019), DOI [10.1080/08820139.2018.1509870, 10.1109/vts-apwcs.2019.8851608]
   Zhang Kai, 2019, CVPR
   Zhang P., 2018, ARXIV180206960
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao J, 2019, IEEE CVPR, P3927
   Zhao J-X, 2019, ARXIV190808297
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao J, 2020, NEURAL COMPUT APPL, V32, P9777, DOI 10.1007/s00521-019-04510-4
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zheng JB, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (IEEE ICBK 2017), P320, DOI 10.1109/ICBK.2017.58
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P2860, DOI 10.1109/ICCVW.2017.337
   Zhu DD, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100457
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2015, IEEE T PATTERN ANAL, V37, P862, DOI 10.1109/TPAMI.2014.2353617
NR 87
TC 10
Z9 13
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25403
EP 25425
DI 10.1007/s11042-020-09188-8
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544844100001
DA 2024-07-18
ER

PT J
AU Fu, XW
   Yang, XF
   Guo, CZ
   Li, X
AF Fu, Xiaowei
   Yang, Xuefei
   Guo, Chengzhen
   Li, Xi
TI Noise suppressed and bias field corrected image segmentation method for
   porous Ni-YSZ anode microstructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Solid oxide fuel cell (SOFC); Microstructure; Image segmentation; Fuzzy
   clustering; Bias field correction; Kernel metric
ID FUEL-CELL ELECTRODES; SOFC ANODE; CHARACTERIZE; SYSTEM
AB Accurate three-phase identification from Solid Oxide Fuel Cell (SOFC) anode micrograph is challenged by both noise and intensity inhomogeneity. In this paper, a novel framework is proposed for porous Ni-YSZ cermet anode Optical Microscopy (OM) image segmentation. The proposed framework takes advantage of a statistical model in which an observed image is decomposed into two multiplicative components (bias field and true image) and one additive component (noise). A two-stage Principal Component Analysis with Local Pixel Grouping (LPG-PCA) denoising algorithm is firstly performed to suppress additive noise, it can preserve more image local structural features by modeling a pixel and its nearest neighbors as a vector variable and selecting training samples with similar contents to this variable in a local window for PCA transformation. In order to enhance the robustness to noise, uneven illumination and other outliers, a kernel metric is introduced into fuzzy clustering method embedded with bias field correction for image segmentation. The proposed method has been compared to other state-of-the-art segmentation algorithms on both simulated images and real SOFC anode OM images. Extensive experiments results have demonstrated that the proposed framework can successfully eliminate the influence of both uneven illumination and noise on real Ni/YSZ anode OM images to obtain a better three-phase identification accuracy. The high-quality segmentation results lay firm foundation for accurate microstructural parameter extraction.
C1 [Fu, Xiaowei; Yang, Xuefei; Guo, Chengzhen] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan, Peoples R China.
   [Fu, Xiaowei; Yang, Xuefei; Guo, Chengzhen] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
   [Fu, Xiaowei] Huazhong Univ Sci & Technol, State Key Lab Mat Proc & & Mould Technol, Wuhan, Peoples R China.
   [Li, Xi] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Huazhong University of Science
   & Technology; Huazhong University of Science & Technology
RP Li, X (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan, Hubei, Peoples R China.
EM lixi_wh@126.com
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 1981, PATTERN RECOGN
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Fu X, 2016, FUEL CELLS, V16, P810, DOI 10.1002/fuce.201600065
   Fu XW, 2015, J POWER SOURCES, V300, P57, DOI 10.1016/j.jpowsour.2015.09.052
   Fu XW, 2015, BIOMED SIGNAL PROCES, V18, P30, DOI 10.1016/j.bspc.2014.11.005
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guan Y, 2011, J POWER SOURCES, V196, P1915, DOI 10.1016/j.jpowsour.2010.09.059
   Holzer L, 2011, J POWER SOURCES, V196, P7076, DOI 10.1016/j.jpowsour.2010.08.006
   Iwai H, 2010, J POWER SOURCES, V195, P955, DOI 10.1016/j.jpowsour.2009.09.005
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lanzini A, 2009, J POWER SOURCES, V194, P408, DOI 10.1016/j.jpowsour.2009.04.062
   Lee DS, 2004, SOLID STATE IONICS, V166, P13, DOI 10.1016/j.ssi.2003.10.003
   Lee JH, 2003, SOLID STATE IONICS, V158, P225, DOI 10.1016/S0167-2738(02)00915-3
   Lee JH, 2002, SOLID STATE IONICS, V148, P15, DOI 10.1016/S0167-2738(02)00050-4
   Lee KR, 2005, J POWER SOURCES, V140, P226, DOI 10.1016/j.jpowsour.2004.06.031
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Luo J, 2013, J POWER SOURCES, V224, P37, DOI 10.1016/j.jpowsour.2012.09.087
   McLachlan GJ, 2000, ANN REV STAT APPL
   Mogensen M, 1996, SOLID STATE IONICS, V86-8, P1151, DOI 10.1016/0167-2738(96)00280-9
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Resini C, 2008, INT J HYDROGEN ENERG, V33, P3728, DOI 10.1016/j.ijhydene.2008.04.044
   Rouhparvar H, 2015, APPL SOFT COMPUT, V30, P577, DOI 10.1016/j.asoc.2015.01.053
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shearing PR, 2011, ELECTROCHEM SOLID ST, V14, pB117, DOI 10.1149/1.3615824
   Nguyen TM, 2013, EVOL SYST-GER, V4, P171, DOI 10.1007/s12530-012-9066-1
   Wu XL, 2019, APPL ENERG, V248, P126, DOI 10.1016/j.apenergy.2019.04.053
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang L, 2015, INT J HYDROGEN ENERG, V40, P456, DOI 10.1016/j.ijhydene.2014.10.149
NR 30
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 18859
EP 18881
DI 10.1007/s11042-020-08753-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500001
DA 2024-07-18
ER

PT J
AU Chatterjee, I
   Kumar, V
   Rana, B
   Agarwal, M
   Kumar, N
AF Chatterjee, Indranath
   Kumar, Virendra
   Rana, Bharti
   Agarwal, Manoj
   Kumar, Naveen
TI Impact of ageing on the brain regions of the schizophrenia patients: an
   fMRI study using evolutionary approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schizophrenia; Functional magnetic resonance imaging (fMRI); Ageing;
   Feature selection; Classification; Evolutionary algorithm
ID AGE-RELATED-CHANGES; TEMPORAL-LOBE; ONSET; MATTER; ABNORMALITIES;
   DIAGNOSIS; DISORDER; GRAY
AB Schizophrenia is a mental disorder that results in adverse functional and biochemical changes in the brain. Although normal ageing significantly affects the brain of a person structurally as well as functionally, the functional activation pattern in the brain of a schizophrenia patient may change differentially with age. To the best of our knowledge, this is the first of its kind fMRI-based study to find the functional changes in the brain of schizophrenia patients associated with ageing. In this study, we aim to compare the age-related variations in the functional activation pattern in the brain of schizophrenia patients vis a vis the healthy controls. For this study, we have used 1.5T fMRI data of 60 subjects and 3T fMRI data of 50 subjects, having an equal number of schizophrenia and healthy subjects. We have split this dataset into multiple age-groups. We applied a three-stage methodology comprising the application of the general linear model, followed by statistical hypothesis testing, and a finally bi-objective NSGA-II algorithm for selection of relevant voxels. The proposed methodology yielded a set of relevant voxels in the brain that demonstrate the age related variations in activation patterns. Specifically, it revealed increased functional activations in elderly patients suffering from schizophrenia in multiple brain regions, mostly located in areas like frontal lobe, temporal lobe and parietal lobe as compared to the young schizophrenic patients. These findings may help in making decisions for differential clinical management of younger patients as compared to the elderly ones.
C1 [Chatterjee, Indranath] Tongmyong Univ, Dept Comp Engn, Busan 48520, South Korea.
   [Kumar, Virendra] All India Inst Med Sci, Dept NMR & MRI Facil, New Delhi 110029, India.
   [Rana, Bharti; Agarwal, Manoj] Univ Delhi, Hans Raj Coll, Dept Comp Sci, Delhi 110007, India.
   [Kumar, Naveen] Univ Delhi, Dept Comp Sci, Delhi 110007, India.
C3 Tongmyong University; All India Institute of Medical Sciences (AIIMS)
   New Delhi; University of Delhi; University of Delhi
RP Chatterjee, I (corresponding author), Tongmyong Univ, Dept Comp Engn, Busan 48520, South Korea.
EM indranath.cs.du@gmail.com; vrndra@gmail.com; bhartirana.it@gmail.com;
   agar.manoj@gmail.com; nk.cs.du@gmail.com
RI Kumar, Virendra/H-4874-2016; Agarwal, Manoj/AAU-8614-2021; KUMAR,
   NAVEEN/N-9993-2018; -, BHARTI/IQR-9133-2023; Chatterjee,
   Indranath/GRO-4311-2022; kumar, vivek/JEO-7153-2023; kumar,
   virendra/KCZ-3518-2024
OI Kumar, Virendra/0000-0002-1569-1989; Chatterjee,
   Indranath/0000-0001-9242-8888; 
FU Council of Science and Industrial Research (CSIR), India
   [09/045(1323)/2014-EMR-I]; Functional Biomedical Informatics Research
   Networks (FBIRN) [U24-RR021992, U24 GM104203]; Function BIRN Data
   Repository [2007-BDR-6UHZ1]
FX This work was supported by the research fellowship of Indranath
   Chatterjee from Council of Science and Industrial Research (CSIR), India
   having grant number 09/045(1323)/2014-EMR-I. Data used in this work are
   taken from the Functional Biomedical Informatics Research Networks
   (FBIRN) data repository, under the following support: for function data,
   U24-RR021992, Function BIRN and U24 GM104203, Bio-Informatics Research
   Network Coordinating Centre (BIRN-CC). The data were obtained from the
   Function BIRN Data Repository, Project Accession Number 2007-BDR-6UHZ1.
CR Åberg M, 2008, BIOSIGNALS 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, VOL II, P302
   Afonso RF, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00201
   [Anonymous], 2003, Paediatr Child Health, V8, P577
   [Anonymous], 2002, BIOMEDICAL IMAGING 2
   [Anonymous], 2011, STAT PARAMETRIC MAPP
   Batouli A.H., 2009, Iranian Journal of Radiology, V6
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Brandt AS, 2016, SCHIZOPHR RES, V172, P101, DOI 10.1016/j.schres.2016.02.017
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatterjee, 2018, F1000RESEARCH, V7, DOI [10.12688/f1000research.16405.2, DOI 10.12688/F1000RESEARCH.16405.2]
   Chatterjee I, 2019, QEIOS, V414, DOI [10.32388/599711, DOI 10.32388/599711]
   Chatterjee I, 2020, MULTIMEDIA SYST, V26, P383, DOI 10.1007/s00530-020-00649-6
   Chatterjee Indranath, 2019, F1000Res, V8, P124, DOI 10.12688/f1000research.17731.1
   Chatterjee I, 2018, MULTIMED TOOLS APPL, V77, P26991, DOI 10.1007/s11042-018-5901-0
   Chen L, 2018, COMPR PSYCHIAT, V80, P155, DOI 10.1016/j.comppsych.2017.09.009
   Cobia DJ, 2012, SCHIZOPHR RES, V139, P1, DOI 10.1016/j.schres.2012.05.002
   Cropley VL, 2017, AM J PSYCHIAT, V174, P286, DOI 10.1176/appi.ajp.2016.16050610
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   DeLisi LE, 2004, PSYCHIAT RES-NEUROIM, V130, P57, DOI 10.1016/j.pscychresns.2003.08.004
   DELISI LE, 1992, SCHIZOPHRENIA BULL, V18, P209, DOI 10.1093/schbul/18.2.209
   Demirci O, 2008, BRAIN IMAGING BEHAV, V2, P207, DOI 10.1007/s11682-008-9028-1
   DUPONT RM, 1994, PSYCHIAT RES-NEUROIM, V55, P121, DOI 10.1016/0925-4927(94)90020-5
   Esiri MM, 2007, J PATHOL, V211, P181, DOI 10.1002/path.2089
   Eyler LT, 2009, AM J GERIAT PSYCHIAT, V17, P43, DOI 10.1097/JGP.0b013e31817e8a7b
   Folsom David P, 2006, Dialogues Clin Neurosci, V8, P45
   Ford J, 2002, P 2002 IEEE ENG MED
   Ge YL, 2002, AM J NEURORADIOL, V23, P1327
   Harvey PD, 2018, SCHIZOPHR RES, V196, P14, DOI 10.1016/j.schres.2017.05.009
   HOLLIS C, 1995, BRIT J PSYCHIAT, V166, P489, DOI 10.1192/bjp.166.4.489
   Jones DK, 2006, HUM BRAIN MAPP, V27, P230, DOI 10.1002/hbm.20179
   Juneja A, 2018, MULTIMED TOOLS APPL, V77, P3963, DOI 10.1007/s11042-017-4404-8
   Juneja A, 2016, BIOMED SIGNAL PROCES, V27, P122, DOI 10.1016/j.bspc.2016.02.009
   Kim DI, 2009, SCHIZOPHRENIA BULL, V35, P67, DOI 10.1093/schbul/sbn133
   Kirkpatrick B, 2018, SCHIZOPHR RES, V196, P4, DOI 10.1016/j.schres.2017.06.034
   Lancaster JL, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00023
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Ma X, 2016, BRAIN INFORM, P1
   Mathalon DH, 2001, ARCH GEN PSYCHIAT, V58, P148, DOI 10.1001/archpsyc.58.2.148
   Mosiolek A, 2016, BMC PSYCHIATRY, V16, DOI 10.1186/s12888-016-0749-1
   Nguyen TT, 2018, SCHIZOPHRENIA BULL, V44, P398, DOI 10.1093/schbul/sbx069
   Niiniskorpi T, 2009, BIOSIGNALS 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P279
   Okusaga OO, 2014, AGING DIS, V5, P256, DOI 10.14336/AD.2014.0500256
   Potkin SG, 2009, SCHIZOPHRENIA BULL, V35, P19, DOI 10.1093/schbul/sbn162
   Powell F, 2017, BRAIN CONNECT, V7, P574, DOI 10.1089/brain.2017.0519
   Rana M, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00239
   Raz N, 2005, CEREB CORTEX, V15, P1676, DOI 10.1093/cercor/bhi044
   Rubia K, 2000, NEUROSCI BIOBEHAV R, V24, P13, DOI 10.1016/S0149-7634(99)00055-X
   Schnack HG, 2016, AM J PSYCHIAT, V173, P607, DOI 10.1176/appi.ajp.2015.15070922
   SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905
   Smart O, 2015, ENG APPL ARTIF INTEL, V39, P198, DOI 10.1016/j.engappai.2014.12.008
   Takahashi T, 2010, SCHIZOPHR RES, V119, P65, DOI 10.1016/j.schres.2009.12.006
   Zhang C, 2017, SCI REP-UK, V7, DOI 10.1038/srep41398
NR 52
TC 8
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24757
EP 24779
DI 10.1007/s11042-020-09183-z
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543064800001
DA 2024-07-18
ER

PT J
AU Sleem, L
   Couturier, R
AF Sleem, Lama
   Couturier, Raphael
TI TestU01 and Practrand: Tools for a randomness evaluation for famous
   multimedia ciphers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things; Cryptography; Randomness tests; Unpredictability
AB New dangerous attacks have arisen as we witness the current evolution of digital data. Connecting devices, vehicles, even our own bodies to the Internet have generated enormous amounts of data that need to be secured. New security solutions and ciphers are being proposed taking into consideration all the limitations in the devices used in today's technologies. However, different factors have to be taken into consideration to prove the reliability of any cipher. One of these criteria is the randomness of the ciphered output. Usually, randomness tests are used to prove the efficiency of Pseudo Random Number Generators- PRNGs, and they are not considered in the test suite for cryptographic algorithms. This paper proposes using the well known tools Practrand (Doty-Humphrey2010) and TestU01 (L'Ecuyer and Simard, ACM Trans Math Soft (TOMS) 33(4):22,2007) to test the randomness criteria for any new/old symmetric cipher. To show our cryptographic point of view, several well known ciphers were tested by these tools. Some of them failed these tests and did not meet the desired security requirements and the sufficient statistical immunity. In fact, this paper shows that these ciphers do not generate enough randomness making them vulnerable to different kinds of attacks which reinforces our proposal.
C1 [Sleem, Lama; Couturier, Raphael] Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, Belfort, France.
C3 Universite de Franche-Comte; Centre National de la Recherche
   Scientifique (CNRS); Universite de Technologie de Belfort-Montbeliard
   (UTBM)
RP Sleem, L (corresponding author), Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, Belfort, France.
EM lama.sleem@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013
OI Couturier, Raphaël/0000-0003-1490-9592
FU EIPHI Graduate School [ANR-17-EURE-0002]
FX This paper was partially supported by funds by the EIPHI Graduate School
   (contract "ANR-17-EURE-0002"). Simulations were conducted on the servers
   of the "Mesocentre de calcul de Franche-Comte". We would like to thank
   them for accepting our request and for giving us access to their
   machines.
CR [Anonymous], 1990, WORKSH THEOR APPL CR
   [Anonymous], 1992, BREAKTHROUGHS STAT M, DOI DOI 10.1007/978-1-4612-4380-9_6
   [Anonymous], 2003, THESIS
   Aoki K., 2001, Selected Areas in Cryptography. 7th Annual International Workshop, SAC 2000. Proceedings (Lecture Notes in Computer Science Vol.2012), P39
   Bernstein DJ, 2008, WORKSH REC SASC, V8, P3
   Biryukov A., 2017, IACR CRYPTOLOGY EPRI
   Boesgaard M, 2003, LECT NOTES COMPUT SC, V2887, P307
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Doty-Humphrey C, 2010, Practically random: C++ library of statistical tests for RNGs
   Hatzivasilis G, 2018, J CRYPTOGR ENG, V8, P141, DOI 10.1007/s13389-017-0160-y
   Hong D, 2006, LECT NOTES COMPUT SC, V4249, P46, DOI 10.1007/11894063_4
   Karn P, 1995, TECH REP
   Kaukonen K, 1999, THAYER R STREAM CIPH
   Kendall MG, 1938, J R STAT SOC, V101, P147, DOI 10.2307/2980655
   Koch W., 2005, LIBGCRYPT REFERENCE, P1
   Kwasnicki M, 2018, STRONG ENCRYPTION SM
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Lemire D, 2018, TESTINGRNG 2018
   Manogaran G., 2017, Big Data Analytics in Healthcare Internet of Things. Innovative Healthcare Systems for the 21st Century, P263, DOI DOI 10.1007/978-3-319-55774-8_10
   Marsaglia G, 1998, DIEHARD TEST SUITE 8, V8
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Rogaway P, 2004, LECT NOTES COMPUT SC, V3017, P348
   Schneier B., 1994, FAST SOFTW ENCR CAMB
   Schneier B., 1998, Current, V21, P1, DOI 10.1.1.35.1273
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Steele GL, 2014, ACM SIGPLAN NOTICES, V49, P453, DOI [10.1145/2714064.2660195, 10.1145/2660193.2660195]
   Walker J., 2008, ENTA Pseudorandom Number Sequence Test Program
   Wheeler DJ, 1998, CORRECTION XTE UNPUB
   WHEELER PW, 1994, IEE CONF PUBL, P363
   WILLE C., 2004, Storing Passwords - Done Right! ASPheute, 1 Maio
   wolfSSL, 2016, WOLFSSL USER MANUAL
   Wu HJ, 2008, LECT NOTES COMPUT SC, V4986, P39
   Wu WL, 2011, LECT NOTES COMPUT SC, V6715, P327, DOI 10.1007/978-3-642-21554-4_19
   Yu Y., 2006, CISC VIS NETW IND GL
NR 35
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24075
EP 24088
DI 10.1007/s11042-020-09108-w
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, MR
   Peng, JG
   Qin, ZY
   Chen, PH
   Jin, DQ
AF Yang, Murong
   Peng, Jigen
   Qin, Ziyan
   Chen, Penghe
   Jin, Dequan
TI Dimension reduction based on small sample entropy learning for
   hand-writing image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimension reduction; Small sample learning; Entropy; Hand-writing image
AB Since deep learning requires a large number of training samples, which is not conducive to its application in reality, small sample learning began to get a lot of attention recently. However, under the condition of small samples for training, high dimensional data still impede the efficiency of the general machine learning model. To solve this problem, we propose a dimension reduction method based on small sample entropy learning and apply it on hand-writing image. An index based on entropy is introduced to measure the importance of different features. Group entropy and labeled entropies are defined according to the distribution of the whole and labeled data on it respectively. And their estimating calculation forms are discussed separately in the case that feature is discrete and continuous. Finally, the index is approximated and prepared for dimension reduction. Numerical results on hand-writing image data sets are presented to verify that much irrelevant dimensions of hand-writing image are found and reduced. Average computational time of image classification computing is shortened. And classification accuracy is retained and even enhanced slightly on some labeled proportions. The case for one shot learning is validated as well. As a result, the proposed method is meaningful and has practical application value.
C1 [Yang, Murong; Qin, Ziyan; Chen, Penghe; Jin, Dequan] Guangxi Univ, Sch Math & Informat Sci, Nanning 530004, Peoples R China.
   [Peng, Jigen] Guangzhou Univ, Sch Math & Informat Sci, 230 Guangzhou Univ City Outer Ring Rd, Guangzhou 510006, Peoples R China.
C3 Guangxi University; Guangzhou University
RP Jin, DQ (corresponding author), Guangxi Univ, Sch Math & Informat Sci, Nanning 530004, Peoples R China.
EM dqjin@foxmail.com
RI Peng, Jigen/HCI-1333-2022
FU National Natural Science Foundation of China [11661010, 11771347,
   11861011, 11861012]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.11661010, No.11771347, No.11861011 and
   No.11861012).
CR Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   Boonchuay K, 2017, PATTERN ANAL APPL, V20, P769, DOI 10.1007/s10044-016-0533-3
   CAMILLERI D, 2017, ANAL LIMITATIONS DEE
   Cox T.F., 2001, Multidimensional Scalin, V46, P1050
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Feng W, 2016, 2016 IEEE MTT-S INTERNATIONAL MICROWAVE WORKSHOP SERIES ON ADVANCED MATERIALS AND PROCESSES FOR RF AND THZ APPLICATIONS (IMWS-AMP)
   Granziol D, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060551
   Kang M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010192
   Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861
   Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014
   Molina C, 2010, IEEE T AUDIO SPEECH, V18, P1041, DOI 10.1109/TASL.2009.2032618
   NEZHAD MZ, P 2016 IEEE INT C BI
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Qiu ZC, 2017, IEEE T NEUR NET LEAR, V28, P917, DOI 10.1109/TNNLS.2016.2514401
   RICHARDS LE, 1988, J MARKETING RES, V25, P410, DOI 10.2307/3172953
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Santoro A, 2016, PR MACH LEARN RES, V48
   SERRURIER M, 2015, ENTROPY EVALUATION B
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Snell J, 2017, ADV NEUR IN, V30
   Spurek P, 2017, EXPERT SYST APPL, V72, P49, DOI 10.1016/j.eswa.2016.12.011
   Suh J, 2017, IEEE T ROBOT, V33, P1313, DOI 10.1109/TRO.2017.2738664
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Xiong DY, 2011, IEEE T AUDIO SPEECH, V19, P2494, DOI 10.1109/TASL.2011.2144971
NR 25
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17365
EP 17376
DI 10.1007/s11042-020-09019-w
EA JUN 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000539939100003
DA 2024-07-18
ER

PT J
AU Abikoye, OC
   Ojo, UA
   Awotunde, JB
   Ogundokun, RO
AF Abikoye, Oluwakemi Christiana
   Ojo, Umar Abdulraheem
   Awotunde, Joseph Bamidele
   Ogundokun, Roseline Oluwaseun
TI A safe and secured iris template using steganography and cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Cryptography; Steganography; Algorithm
AB This study combines Cryptography (Twofish and Triple data decryption (3DES)) algorithms and Steganography (Least Significant Bits) to solve the problem of attacking or hacking biometric template for a malicious act, which has become a huge problem in the iris recognition system. Twofish and Triple data encryption are good and secured cryptography algorithms which are used to change readable secret data (plain image) into an unreadable format (cipher image) while least significant bits (LSB) is a steganography algorithm which embeds ciphertext/image directly into a cover image to produce an image known as stego image. In this work, Hough transform, Daugman rubber-sheet model and Log Gabor filter were used for iris image segmentation, normalization and feature extraction and the iris template generated was encrypted using 3DES and Twofish algorithms. The cipher image was then embedded into a cover image to produce stego image using LSB. The result of this work slightly changes the master file after embedding the secret image (stego file) that cannot be identified by the physical eyes and only a JPEG image was used as the master or cover file. The two levels of security technique provide high embedded capacity and eminence stego images that will able to withstand attackers.
C1 [Abikoye, Oluwakemi Christiana; Awotunde, Joseph Bamidele] Univ Ilorin, Ilorin, Nigeria.
   [Ojo, Umar Abdulraheem] FCT Coll Educ, Abuja, Nigeria.
   [Ogundokun, Roseline Oluwaseun] Landmark Univ, Omu Aran, Kwara State, Nigeria.
C3 University of Ilorin; Landmark University
RP Ogundokun, RO (corresponding author), Landmark Univ, Omu Aran, Kwara State, Nigeria.
EM abikoye.o@unilorin.edu.ng; Ojo_raheem@yahoo.com;
   Awotunde.jb@unilorin.edu.ng; ogundokun.roseline@lmu.edu.ng
RI Abikoye, Oluwakemi/HNQ-6855-2023; AWOTUNDE, Joseph
   Bamidele/AAC-7971-2021; OGUNDOKUN, ROSELINE/B-2783-2019
OI AWOTUNDE, Joseph Bamidele/0000-0002-1020-4432; OGUNDOKUN,
   ROSELINE/0000-0002-2592-2824; Abikoye, Oluwakemi
   Christiana/0000-0002-8912-6333
CR Anuja JS, 2019, INT J PURE APPL MATH, V119, P1471
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Chai TY, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020164
   Dwivedi R, 2019, APPL INTELL, V49, P1016, DOI 10.1007/s10489-018-1311-2
   Grover D, 2016, INT J PHARM TECHNOLO, V8, P19094
   Kayode SY, 2018, COMPUT INF SYST, V22
   Kelkboom E.J. C., 2009, IEEE 3rd international conference on biometrics: theory, applications, and systems, 2009 (BTAS '09), P1, DOI 10.1109/BTAS.2009.5339045
   Kumar MM, 2018, P 2018 2 INT C BIOM, P43, DOI DOI 10.1145/3230820.3230828
   Li S.Z., 2009, Encyclopedia of Biometrics, V1
   Li S, 2018, IETE TECH REV, V35, P34, DOI 10.1080/02564602.2018.1520153
   Maek N, 2019, ACTA POLYTECHNICA HU, V16
   Maiorana Emanuele, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3759, DOI 10.1109/ICASSP.2014.6854304
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Ouda O., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P882, DOI 10.1109/ICPR.2010.222
   Radman A, 2013, IET IMAGE PROCESS, V7, P42, DOI 10.1049/iet-ipr.2012.0452
   Rathgeb Christian, 2011, State of the Art in Biometrics, P179
   Rathgeb C, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0049-9
   Revenkar P.S., 2010, INT J COMPUTER SCI I, V7, P217
   Sadhya D, 2018, IET BIOMETRICS, V7, P251, DOI 10.1049/iet-bmt.2017.0049
   Taha MS, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052003
   Thanki Rohit, 2015, WSEAS Transactions on Information Science and Applications, V12, P1
   Tomasone JR, 2015, SYST REV-LONDON, V4, DOI 10.1186/s13643-015-0100-9
   Yang WC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132985
   Zaheera ZA, 2011, CCIS, V179, P547
   Zhao DD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4519548
NR 25
TC 22
Z9 22
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23483
EP 23506
DI 10.1007/s11042-020-08971-x
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539519000007
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Coppens, I
   Martens, L
AF De Pessemier, Toon
   Coppens, Ine
   Martens, Luc
TI Evaluating facial recognition services as interaction technique for
   recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Facial analysis; Emotion recognition; Human-computer
   interaction
ID EMOTION RECOGNITION
AB Recommender systems are tools and techniques to assist users in the content selection process thereby coping with the problem of information overload. For recommender systems, user authentication and feedback gathering are of crucial importance. However, the typical user authentication with username / password and feedback method with a star rating system are not user friendly and often bypassed. This article proposes an alternative method for user authentication based on facial recognition and an automatic feedback gathering method by detecting various face characteristics such as emotions. We studied the use case of video watching. Photos made with the front-facing camera of a tablet, smartphone, or smart TV are used as input of a facial recognition service. The persons in front of the screen can be identified. During video watching, implicit feedback for the video content is automatically gathered through emotion recognition, attention measurements, and behavior analysis. An evaluation with a test panel showed that the recognized emotions are correlated with the user's star ratings and that happiness can be most accurately detected. So as the main contribution, this article indicates that emotion recognition might be used as an alternative feedback mechanism for recommender systems.
C1 [De Pessemier, Toon; Coppens, Ine; Martens, Luc] Univ Ghent, WAVES, IMEC, IGent, Technol Pk 126, B-9052 Ghent, Belgium.
C3 IMEC; Ghent University
RP De Pessemier, T (corresponding author), Univ Ghent, WAVES, IMEC, IGent, Technol Pk 126, B-9052 Ghent, Belgium.
EM toon.depessemier@ugent.be; ine.coppens@ugent.be; luc1.martens@ugent.be
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   [Anonymous], 2019, IMDb Ratings and Reviews for New Movies and TV Shows
   [Anonymous], 2006, BIOMETRICS PERSONAL
   [Anonymous], 2019, MICROSOFT AZURE FACE
   [Anonymous], 2014, WORKSH MOB COMP SYST
   Arapakis I., 2009, P ACM INT C IM VID R, P29, DOI [10.1145/1646396.1646433, DOI 10.1145/1646396.1646433]
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024
   Buthpitiya S, 2011, LECT NOTES COMPUT SC, V6696, P97, DOI 10.1007/978-3-642-21726-5_7
   Chauhan M., 2014, Int. J. Comput. Sci. Inf. Technol., V5, P1615
   Cho M., 2020, ARXIV200300697, V3, P7
   CommonSenseMedia, 2019, COMMONSENSEMEDIA YOU
   De Pessemier T, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, VOL 2 (WEBIST), P243, DOI 10.5220/0005861302430250
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2497, DOI 10.1007/s11042-013-1563-0
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekstrand MD, 2018, COMPUTER SCI FACULTY, DOI [10.18122/cs_facpubs/147/boisestate, DOI 10.18122/CS_FACPUBS]
   Face++, 2019, FACE COGNITIVE SERVI
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Huang Y, 2020, ARXIV200400288
   Joho H, 2009, P ACM INT C IM VID R, V31
   Kairos, 2019, KAIROS SERVING BUSIN
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Masthoff J, 2011, RECOMMENDER SYSTEMS HANDBOOK, P677, DOI 10.1007/978-0-387-85820-3_21
   Miao Qi, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1040, DOI 10.1109/CSSE.2008.1060
   Nickel C., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P16, DOI 10.1109/IIH-MSP.2012.11
   Noldus, 2019, NOLDUS FACEREADER FA
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Shabrina N, 2016, 7TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION TECHNOLOGY FOR EMBEDDED SYSTEMS 2016 (IC-ICTES 2016), P85, DOI 10.1109/ICTEmSys.2016.7467127
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Tkalcic M., 2011, PROC RECSYS 2011 WOR, P9
   Wang Jie, 2017, [Computational Visual Media, 计算可视媒体], V3, P229
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
NR 39
TC 3
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23547
EP 23570
DI 10.1007/s11042-020-09061-8
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539519000001
DA 2024-07-18
ER

PT J
AU Kim, J
   Lee, D
   Park, N
AF Kim, Jinsu
   Lee, Donghyeok
   Park, Namje
TI CCTV-RFID enabled multifactor authentication model for secure
   differential level video access control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CCTV; Smart surveillance; RFID; Authentication; Access control;
   Differential level
ID SERVICE; PLATFORM; SYSTEM
AB In the intelligent CCTV surveillance environment, personal identity is confirmed based on face recognition. However, the recognition rate of the current face recognition technology is still faulty. In particular, face recognition may not work correctly due to various causes such as CCTV shot quality, weather, personal pose and facial expression, hairstyle, lighting condition, and so on. In this case, there is a great risk of exposing object's privacy information in the video surveillance environment due to erroneous object judgment. This paper proposes a video surveillance-based access control technique that combines a facial recognition system using CCTV machine learning with radio-frequency identification (RFID). The proposed method is implemented when accurate facial recognition is difficult to achieve due to poor video quality or low levels of similarity against feature vectors, in which cases multi-channel authentication is performed with the use of RFID features available on a mobile device in possession of the individual. The dual-channel authentication approach can still help identify the entity and protect his or her privacy with greater security even if the RFID tags for authentication are breached or accurate facial detection becomes challenging due to various factors such as CCTV video quality deterioration.
C1 [Kim, Jinsu; Park, Namje] Jeju Natl Univ, Grad Sch, Fac Sci Educ, 61 Iljudong Ro, Jeju Si 63294, Jeju Special Se, South Korea.
   [Lee, Donghyeok; Park, Namje] Jeju Natl Univ, Teachers Coll, Dept Comp Educ, 61 Iljudong Ro, Jeju Si 63294, Jeju Special Se, South Korea.
C3 Jeju National University; Jeju National University
RP Park, N (corresponding author), Jeju Natl Univ, Grad Sch, Fac Sci Educ, 61 Iljudong Ro, Jeju Si 63294, Jeju Special Se, South Korea.; Park, N (corresponding author), Jeju Natl Univ, Teachers Coll, Dept Comp Educ, 61 Iljudong Ro, Jeju Si 63294, Jeju Special Se, South Korea.
EM kimjinsu@jejunu.ac.kr; bonfarc@jejunu.ac.kr; namjepark@jejunu.ac.kr
OI Kim, Jinsu/0000-0003-1009-3928
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIT) [2019-0-00203]; Ministry of Education of the
   Republic of Korea; National Research Foundation of Korea
   [NRF-2019S1A5C2A04083374]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIT)
   [2019-0-00203, The Development of Predictive Visual Security Technology
   for Preemptive Threat Response]. And, this work was supported by the
   Ministry of Education of the Republic of Korea and the National Research
   Foundation of Korea (NRF-2019S1A5C2A04083374).
CR [Anonymous], 2015, P USENIX ATC 15 C US
   Bellare M., 2013, ANN INT C THEOR APPL
   Byung-Kwan Kim, 2014, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V12, P129, DOI 10.14801/kiitr.2014.12.4.129
   Cheolhee Park, 2016, Journal of KIISE, V43, P1165, DOI 10.5626/JOK.2016.43.10.1165
   Choudhary A, 2017, P 2017 INT C BIOM EN
   Donghyeok Lee, 2017, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V15, P79, DOI 10.14801/jkiit.2017.15.2.79
   Donghyeok Lee, 2016, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V26, P787, DOI 10.13089/JKIISC.2016.26.3.787
   Hossain MA, 2014, INT J DISTRIBUTED SE, V10
   Hyun Jung La, 2014, Journal of KIISE: Software and Applications, V41, P545
   Kaaniche N, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY (SECRYPT), P5
   Kim J, 2017, PRIV AW COMP PAC 201
   유영준, 2014, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V12, P103
   Lee D, 2018, PEER PEER NETW APPL, V11, P1299, DOI 10.1007/s12083-018-0637-1
   Lee D, 2017, J SUPERCOMPUT, V73, P1119, DOI 10.1007/s11227-017-1967-0
   Leng L, 2010, 2010 25 INT C IM VIS
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin Chia-Feng, 2012, 2012 9 INT C UB INT
   Ma JW, 2016, IEEE TRUST BIG, P1069, DOI [10.1109/TrustCom.2016.175, 10.1109/TrustCom.2016.0177]
   Park N, 2006, LECT NOTES COMPUT SC, V3842, P741
   Park N., 2018, INT J PURE APPL MATH, V118, P819
   Park N., 2015, Information, V18, P261
   Park N., 2018, International Journal of Pure and Applied Mathematics, V118, P837
   Park N, 2018, PERS UBIQUIT COMPUT, V22, P3, DOI 10.1007/s00779-017-1017-1
   Park Namje, 2013, [The Journal of Korean Institute of Communications and Information Sciences C, 한국통신학회논문지C], V38, P841
   Park N, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/2965438
   Park Namje, 2014, [The Journal of Korean Institute of Communications and Information Sciences C, 한국통신학회논문지C], V39, P466
   Park N, 2016, SECUR COMMUN NETW, V9, P500, DOI 10.1002/sec.1108
   Park N, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010020
   Park N, 2014, CLUSTER COMPUT, V17, P653, DOI 10.1007/s10586-014-0367-y
   Penhaker Marek, 2012, Intelligent Data Engineering and Automated Learning - IDEAL 2012. Proceedings 13th International Conference, P336, DOI 10.1007/978-3-642-32639-4_41
   Puzio P, 2013, INT CONF CLOUD COMP, P363, DOI 10.1109/CloudCom.2013.54
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Riad K, 2019, IEEE ACCESS, V7, P86384, DOI 10.1109/ACCESS.2019.2926354
   Robertson D. J., 2018, J US HOMELAND DEFENC, V5, P6
   Rodriguez-Silva DA, 2012, CLOUD COMP CLOUD 201
   Wei XN, 2017, ACS OMEGA, V2, P2017, DOI 10.1021/acsomega.6b00437
   Wu YL, 2017, J INFORM OPTIM SCI, V38, P173, DOI 10.1080/02522667.2016.1220076
   Yang M, 2017, PATTERN RECOGN, V66, P117, DOI 10.1016/j.patcog.2016.12.028
NR 39
TC 8
Z9 8
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23461
EP 23481
DI 10.1007/s11042-020-09016-z
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539166300001
DA 2024-07-18
ER

PT J
AU Cheng, J
   Wang, XM
   Song, RC
   Liu, Y
   Li, C
   Chen, X
AF Cheng, Juan
   Wang, Xingmao
   Song, Rencheng
   Liu, Yu
   Li, Chang
   Chen, Xun
TI Exploring the feasibility of seamless remote heart rate measurement
   using multiple synchronized cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote photoplethysmography (rPPG); Multi-cameras; Non-contact; Target
   region of interest (ROI); Heart rate
ID EMPIRICAL MODE DECOMPOSITION; NONCONTACT; PHOTOPLETHYSMOGRAPHY
AB Heart rate (HR) measurement and monitoring is of great importance to determine the physiological and mental status of individuals. Recently, it has been demonstrated that HR can be remotely retrieved from facial video-based photoplethysmographic signals captured using consumer-grade cameras. However, in existing studies, subjects are mostly required to keep their facial regions of interest (ROIs) within one single camera. To make this technique usable in a daily life situation where subjects move around freely, we launch a preliminary simulated study of seamless remote HR measurement using multiple synchronized cameras by combining ensemble empirical mode decomposition (EEMD) with time-delay canonical correlation analysis (TDCCA), termed as EEMD-TDCCA. At each time point, a target ROI with the largest area is first determined from all the ROIs provided by all the cameras. Then, the RGB time sequence is formed by taking average of all pixels within each target ROI. Afterwards, the green channel time sequence is decomposed into several intrinsic mode functions (IMFs) and only the IMF candidates, whose frequency corresponding to the maximum amplitude falling into the interested HR range will be further processed by TDCCA. Finally, the first pair of the canonical variables having the largest correlation coefficient is the HR source and the corresponding HR is derived by peak detection or frequency analysis. Thirty subjects were recruited and four state-of-the-art methods were employed for comparison. The best performance was achieved by using the proposed EEMD-TDCCA followed by frequency analysis, with the mean absolute error 4.11 bpm, mean percentage error 5.26%, root mean square error 5.37 bpm, the Pearson's correlation coefficient 0.90 and the intra-class correlation coefficient 0.89, demonstrating the feasibility of our proposed seamless remote HR measurement framework. This study will provide a promising solution for practical and robust non-contact HR measurement applications.
C1 [Cheng, Juan; Wang, Xingmao; Song, Rencheng; Liu, Yu; Li, Chang] Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China.
   [Chen, Xun] Univ Sci & Technol China, Dept Elect Engn, Informat Sci, Hefei 230026, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; University
   of Science & Technology of China, CAS
RP Song, RC (corresponding author), Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China.
EM chengjuan@hfut.edu.cn; rcsong@hfut.edu.cn
RI Yang, Jing/JFK-4046-2023; Liu, Yu/HKF-4917-2023; Song,
   Rencheng/JRW-5597-2023
OI Yang, Jing/0009-0004-8274-9863; Liu, Yu/0000-0003-2211-3535; Song,
   Rencheng/0000-0001-7760-7562; Cheng, Juan/0000-0003-1206-1698
FU National Key R&D Program of China [2017YFB1002802]; National Natural
   Science Foundation of China [61922075, 81571760, 61701160, 41901350];
   Fundamental Research Funds for the Central Universities [JZ2019HGBZ0151,
   JZ2020HGPA0111]
FX This work was supported by the National Key R&D Program of China (Grant
   2017YFB1002802), National Natural Science Foundation of China (Grants:
   61922075, 81571760, 61701160 and 41901350) and the Fundamental Research
   Funds for the Central Universities (Grants: JZ2019HGBZ0151 and
   JZ2020HGPA0111).
CR Aarts LAM, 2013, EARLY HUM DEV, V89, P943, DOI 10.1016/j.earlhumdev.2013.09.016
   Al-Naji A, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0395-y
   Amelard R, 2015, SCI REP-UK, V5, DOI 10.1038/srep14637
   Blackford EB, 2017, PROC SPIE, V10072, DOI 10.1117/12.2253409
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Chen DY, 2015, IEEE SENS J, V15, P618, DOI 10.1109/JSEN.2014.2347397
   Chen X, 2018, IEEE T INSTRUMENTATI
   Chen X, 2015, INT J MOL SCI, V16, P10986, DOI 10.3390/ijms160510986
   Chen X, 2018, IEEE T INSTRUM MEAS, V67, P359, DOI 10.1109/TIM.2017.2759398
   Chen X, 2016, IEEE SIGNAL PROC MAG, V33, P86, DOI 10.1109/MSP.2016.2521870
   Chen X, 2014, SENSORS-BASEL, V14, P18370, DOI 10.3390/s141018370
   Chen X, 2014, IEEE J BIOMED HEALTH, V18, P1232, DOI 10.1109/JBHI.2013.2284480
   Cheng J, 2017, IEEE J BIOMED HEALTH, V21, P1422, DOI 10.1109/JBHI.2016.2615472
   Correa NM, 2010, IEEE SIGNAL PROC MAG, V27, P39, DOI 10.1109/MSP.2010.936725
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Estepp JR, 2014, IEEE SYS MAN CYBERN, P1462, DOI 10.1109/SMC.2014.6974121
   Feng LT, 2015, IEEE T CIRC SYST VID, V25, P879, DOI 10.1109/TCSVT.2014.2364415
   Fleiss J.L., 1986, J R STAT SOC, DOI DOI 10.2307/2982050
   Haque MA, 2016, IEEE INTELL SYST, V31, P40, DOI 10.1109/MIS.2016.20
   Hassan MA, 2017, BIOMED OPT EXPRESS, V8, P4838, DOI 10.1364/BOE.8.004838
   Holton BD, 2013, PHYSIOL MEAS, V34, P1499, DOI 10.1088/0967-3334/34/11/1499
   Hotelling H, 1935, BIOMETRIKA, V28, P312
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lee D, 2015, IEEE ENG MED BIO, P2758, DOI 10.1109/EMBC.2015.7318963
   Leonhardt S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093080
   Lewandowska M., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P405
   Li XB, 2014, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2014.543
   Liu H, 2016, IEEE IMAGE PROC, P3249, DOI 10.1109/ICIP.2016.7532960
   McDuff DJ, 2018, IEEE T BIO-MED ENG, V65, P1725, DOI 10.1109/TBME.2017.2771518
   Monkaresi H, 2014, IEEE J BIOMED HEALTH, V18, P1153, DOI 10.1109/JBHI.2013.2291900
   Po LM, 2018, MULTIMED TOOLS APPL, V77, P6503, DOI 10.1007/s11042-017-4563-7
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Qi H, 2017, BIOMED SIGNAL PROCES, V31, P309, DOI 10.1016/j.bspc.2016.08.020
   Rasche S, 2016, CLIN HEMORHEOL MICRO, V64, P77, DOI 10.3233/CH-162048
   Rouast PV, 2018, FRONT COMPUT SCI-CHI, V12, P858, DOI 10.1007/s11704-016-6243-6
   Soneson C, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-191
   Sun Y, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.3.037005
   Sun Y, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3602852
   Tang J, 2018, COMPOS STRUCT, V198, P19, DOI 10.1016/j.compstruct.2018.05.042
   Tarassenko L, 2014, PHYSIOL MEAS, V35, P807, DOI 10.1088/0967-3334/35/5/807
   Tarvainen MP, 2002, IEEE T BIO-MED ENG, V49, P172, DOI 10.1109/10.979357
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Wang WJ, 2017, IEEE T BIO-MED ENG, V64, P1479, DOI 10.1109/TBME.2016.2609282
   Wang WJ, 2016, IEEE T BIO-MED ENG, V63, P1974, DOI 10.1109/TBME.2015.2508602
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Xu L, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.3611
   Yang Z, 2019, MULTIMED TOOLS APPL, V78, P26747, DOI 10.1007/s11042-019-07849-x
   Yu YP, 2015, BIOMED OPT EXPRESS, V6, P4610, DOI 10.1364/BOE.6.004610
   Yujing Sun, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286350
   Zhao F, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00236
   Zheng SY, 2013, INT CONF CLOUD SERV, P1, DOI 10.1109/CSC.2013.9
   Zhenyu Guo, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4374, DOI 10.1109/ICASSP.2014.6854428
NR 54
TC 3
Z9 4
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23023
EP 23043
DI 10.1007/s11042-020-09075-2
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538196200001
DA 2024-07-18
ER

PT J
AU Buvanesvari, VK
   Suganthi, M
AF Buvanesvari, V. K.
   Suganthi, M.
TI Three dimensional modelling of MRI knee images using improved edge
   detection and finite element modelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finite element modeling; Magnetic resource imaging; Knee cartilage; Edge
   detection
AB The knee is one of the complex joints in the human body. Manual Material Handling (MMH), especially lifting, poses a risk to humans and this is considered as the preliminary reason for back pain and other impairments in a knee. Hence, it is very necessary to find the positions of knee cartilage of a person. This is usually done by modelling a three dimensional (3D) model of a patient from a Magnetic Resonant Images (MRIs). This modelling is used for determining the patterns of stress and strain distribution from various body postures. However, the modelling accuracy is not favorable in executing the required 3D patterns for finding the actual patterns of knee position. In this paper, an improved 3D model is developed for evaluating the positions of knee cartilages. The source images are captured from MRI by scanning the knee portions of a human to render a 3D knee pattern. This method works on two different stages, initially, the method uses edge-based detection and the second stage gets the edges as its input to acquire to 3D models. The second stage uses a finite element model to analyze the stresses associated with the Knee-joint and careful design is made using the proposed model to analyze the knee cartilage. The proposed model attains a good temporal agreement between the rendered 3D results and the predicted muscle force based on the magnitude of the obtained models. The proposed 3D modelling is evaluated in terms of contact mechanics factors like contact pressure, contact area and contact stress are simulated synchronously. It is found that the maximum contact pressure exists on the medial tibial insert. Finally, it is concluded from the results that the automated segmentation method to render the 3D patterns from MR images is accurate and quick in determining the geometries of knee cartilages.
C1 [Buvanesvari, V. K.] Anna Univ, Chennai, Tamil Nadu, India.
   [Suganthi, M.] Mahendra Coll Engn, Dept Elect & Commun Engn, Salem, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Buvanesvari, VK (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.
EM v.k.buvanesvari@gmail.com
CR [Anonymous], PERSONAL UBIQUITOUS
   [Anonymous], 2018, J AMBIENT INTELL HUM
   [Anonymous], 2009012261 SAE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2018, DES AUTOM EMBED SYST
   Farrokhi S, 2011, OSTEOARTHR CARTILAGE, V19, P287, DOI 10.1016/j.joca.2010.12.001
   Guess TM, 2014, J BIOMECH ENG-T ASME, V136, DOI 10.1115/1.4026359
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Lokesh S., 2018, NEURAL COMPUT APPL, V2018, P1
   Lundberg HJ, 2012, J BIOMECH, V45, P990, DOI 10.1016/j.jbiomech.2012.01.015
   Madeti BK, 2015, FRONT MECH ENG, V10, P176, DOI 10.1007/s11465-014-0306-x
   Parthasarathy P, 2018, INFORM MED UNLOCKED, V12, P1, DOI [10.1016/j.imu.2018.04.004, DOI 10.1016/J.IMU.2018.04.004]
   Shu LM, 2018, J BIOMECH, V77, P146, DOI 10.1016/j.jbiomech.2018.07.008
   Stluka P, 2018, ADV IND CONTROL, P11, DOI 10.1007/978-3-319-68462-8_2
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Zeller IM, 2017, J ARTHROPLASTY, V32, P1344, DOI 10.1016/j.arth.2016.09.034
NR 16
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17045
EP 17056
DI 10.1007/s11042-019-7565-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600069
DA 2024-07-18
ER

PT J
AU Lee, YS
   Kim, SH
AF Lee, Yang Sun
   Kim, Se-Hoon
TI A proposal of novel design on the WAVE MAC algorithm with low-latency
   for seamless video surveillance in V2X environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE V2X; Vehicle communication; WAVE; IEEE Std; 1609x; IEEE 802; 11p; Low
   latency MAC operation
ID COMMUNICATION
AB This paper proposed an MAC (Media Access Control) operation method based on the CCH (Control Channel) and SCH (Service Channel) control mode of the WAVE (Wireless Access for Vehicle Environment) network in order to secure service performance sensitive to certain delays with no restriction to services pursued in the present WAVE network. The proposed method configures a new superframe for CCH and SCH frames in the WAVE network defined by IEEE Std. 1609.4 and applies TDM (Time Division Multiplexing) to the CCH frame in order to secure traffic stability and latency minimization in each terminal. CSMA/CA (Carrier Sense Multiple Access/Collision Avoidance) is applied to the SCH frame in order to secure autonomy in service perspectives. Additionally, delay control is secured despite congestion among multiple terminals in V2V communication without a station RSU (Road Side Unit) since the proposed MAC operation method adopts a new CCH/SCH coordination mode for the WAVE network. The proposed method's applicability is verified as the simulation analysis results showed satisfactory low latency performance.
C1 [Lee, Yang Sun] Mokwon Univ, Div Convergence Comp & Media, Daejeon, South Korea.
   [Kim, Se-Hoon] allRadio TNIE Co Ltd, R&D Lab, Seoul, South Korea.
C3 Mokwon University
RP Lee, YS (corresponding author), Mokwon Univ, Div Convergence Comp & Media, Daejeon, South Korea.
EM yslee48@gmail.com; shkim001@tnie.co.kr
OI Lee, Yang Sun/0000-0002-1268-2016
CR 3GPP,, 2015, Tech. Rep. 22.885
   [Anonymous], 2013, 160902013 IEEE
   [Anonymous], 2017, 2017 IEEE INT C COMM
   [Anonymous], 2016, 160942016 IEEE
   [Anonymous], 2010, 1609 IEEE
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Bilstrup K., 2008, Vehicular Technology Conference, P1
   Felice M.D., 2012, IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM), P1
   Hobert L, 2015, IEEE COMMUN MAG, V53, P64, DOI 10.1109/MCOM.2015.7355568
   Hwang TW, 2013, J COMMUNICATIONS RAD, V54, P4
   IEEE, 2012, P16092D17 IEEE
   IEEE, 2010, P16091D13 IEEE
   Luoto P, 2016, EUROPEAN WIRELESS 20
   Mir Z.H. F. Filali., 2014, 2014 IEEE 79 VEHICUL, P1, DOI DOI 10.1109/VTCSPRING.2014.7023017
   Stibor L, 2007, IEEE WCNC, P254, DOI 10.1109/WCNC.2007.53
   Vukadinovic V, 2018, AD HOC NETW, V74, P17, DOI 10.1016/j.adhoc.2018.03.004
   Wang Q, 2012, IEEE T INTELL TRANSP, V13, P449, DOI 10.1109/TITS.2011.2171951
   Zhang L, 2014, WIRELESS PERS COMMUN, V74, P1197, DOI 10.1007/s11277-013-1572-3
NR 18
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16035
EP 16049
DI 10.1007/s11042-019-7151-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600013
DA 2024-07-18
ER

PT J
AU Renita, DB
   Christopher, CS
AF Renita, D. Benyl
   Christopher, C. Seldev
TI Novel real time content based medical image retrieval scheme with
   GWO-SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image retrieval; Grey wolf; SVM; Query; Neutroscopic
AB Feature-Based Medical Image Retrieval (FBMIR) systems are exploited to retrieve useful contents from a massive number of medical images. A novel technique for image retrieval in medical field with Grey Wolf Optimization-Support Vector Machine (GWO-SVM) is proposed. CT scan images are used as input images. Firstly, the images are considered for extraction, where the scaling & rotation invariant features are taken out using corresponding colour moments. Secondly, texture features are taken out using dominant GLCM features that comprise of correlation, contrast, energy, etc. Feature mapping is performed with the help of Bag of Words (BoW). In the existing system, the images are first retrieved and then classified. In the proposed method, the time of image retrieval is more since it has to search the whole database for performing the retrieval. Moreover, the retrieval rates obtained by the existing methods are not satisfactory. The novelty of proposed paper gives GWO-SVM technique that initially classifies the class to which the query image belongs. Further the retrieval task are organized only from the Database of query images. The GWO algorithm gives the solved and optimized parameters are given a clear optimized value for the SVM classifier. Thus, by finding the retrieval rate after performing the classification, it is evident that output retrieval rate is large when compared to existing methods. The fundamental performance metrics like accuracy, sensitivity and specificity are taken into comparison. The proposed techniques provides higher accuracy 97.3% than the performance of BoW and Grey Wolf Optimization (GWO).
C1 [Renita, D. Benyl] CSI Inst Technol, CSE Dept, Thovalai, Nagercoil, India.
   [Christopher, C. Seldev] St Xaviers Catholic Coll Engn, CSE Dept, Chunkankadai, Kanniyakumari, India.
RP Renita, DB (corresponding author), CSI Inst Technol, CSE Dept, Thovalai, Nagercoil, India.
EM benilrenita@gmail.com; seldev@sxcce.edu.in
RI CHRISTOPHER, C SELDEV/AAD-4851-2021
OI CHRISTOPHER, C SELDEV/0000-0002-5228-029X
CR [Anonymous], 1999, P DARPA BROADC NEWS
   Antani S., 2002, P 3 IND C COMP VIS G, P242
   Berman P, 1999, IEEE WORKSH CONT BAS
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chaudhari R., 2012, International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, V1, P386
   Chen X, 2009, LECT NOTES ARTIF INT, V5476, P867, DOI 10.1007/978-3-642-01307-2_90
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3
   El-Kwae EA, 2000, J DIGIT IMAGING, V13, P70, DOI 10.1007/BF03168371
   Faloutsos, 1994, J INTELL INF SYST, V3, P231, DOI DOI 10.1007/BF00962238
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gali R, 2012, 4 INT C COMP INT COM
   Güld MO, 2002, PROC SPIE, V4685, P280, DOI 10.1117/12.467017
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hiremath P. S., 2007, 15 INT C ADV COMP CO
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Hwang KH, 2012, HEALTHC INFORM RES, V18, P3, DOI 10.4258/hir.2012.18.1.3
   I El-Naqa, 2009, IEEE T MED IMAGING
   Je<prime>gou H., 2012, P ECCV, P5
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lehmann TM, 2003, P SOC PHOTO-OPT INS, V5033, P109, DOI 10.1117/12.481942
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   MOJSILOVIS A, 2000, IEEE INT C IM PROC R, V3, P145
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Natsev A, 2004, IEEE T KNOWL DATA EN, V16, P301, DOI 10.1109/TKDE.2003.1262183
   Rafiee G., 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P775
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sim DG, 2001, ELECTRON LETT, V37, P18, DOI 10.1049/el:20010035
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   Tai XY, 2008, ICBBE 2008 2 INT C, P2574
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
NR 38
TC 20
Z9 22
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17227
EP 17243
DI 10.1007/s11042-019-07777-w
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600079
DA 2024-07-18
ER

PT J
AU Veeramsetty, V
   Singal, G
   Badal, T
AF Veeramsetty, Venkataramana
   Singal, Gaurav
   Badal, Tapas
TI Coinnet: platform independent application to recognize Indian currency
   notes using deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Indian currency note; Web
   application; Mobile application
AB In India, nearly 12 million visually impaired people had difficulty in identifying the currency notes. There is a need to develop an application that can recognize the currency note and provide a vocal message. In this paper, a novel lightweight Convolutional Neural Network (CNN) model is developed for efficient web and mobile applications to recognize the Indian currency notes. A new dataset for Indian currency notes has been created to train, validate, and test the CNN model. This CNN based web and mobile applications will provide a text and audio output based on the recognized currency note. The proposed model is developed using TensorFlow and improved by selection of optimal hyperparameter value, and compared with existing well known CNN architectures using transfer learning. Based on the results it has been observed that proposed model perform well over six widely used existing architectures in terms of training and testing accuracy.
C1 [Veeramsetty, Venkataramana] SR Engn Coll, Ctr Artif Intelligence & Deep Learning, Dept Elect & Elect Engn, Warangal, Andhra Pradesh, India.
   [Singal, Gaurav; Badal, Tapas] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
RP Veeramsetty, V (corresponding author), SR Engn Coll, Ctr Artif Intelligence & Deep Learning, Dept Elect & Elect Engn, Warangal, Andhra Pradesh, India.
EM venkataramana_v@srecwarangal.ac.in; gauraysinga1789@gmail.com;
   tapas.badal@bennett.edu.in
RI Singal, Gaurav/AAH-9527-2019; veeramsetty, venkataramana/GSN-4160-2022;
   Singal, Gaurav/O-3764-2017; veeramsetty, venkataramana/AAK-1158-2020
OI Singal, Gaurav/0000-0001-7570-6292; veeramsetty,
   venkataramana/0000-0002-2512-5761; Singal, Gaurav/0000-0001-7570-6292;
   veeramsetty, venkataramana/0000-0002-2512-5761
FU S.R. Engineering College
FX We thanks Leadingindia.ai and Bennett University for providing
   supercomputer NVIDIA DGX V100 access to do this work. We also
   acknowledge Dr Deepak Garg (Director, LeadingIndia.ai) and Dr Suneet K.
   Gupta (Assistant Professor, Bennett University) for giving us the
   environment to work on this specific domain. I would also like to show
   our gratitude to S.R. Engineering College for giving permission with
   financial support to do this work at Bennett University. If anyone needs
   complete code and Indian currency notes dataset, please mail to the
   corresponding authors.
CR Abu Doush I, 2017, J KING SAUD UNIV-COM, V29, P484, DOI 10.1016/j.jksuci.2016.06.003
   Ahmadi A., 2004, Artificial Life and Robotics, V8, P133, DOI 10.1007/s10015-004-0300-1
   [Anonymous], 2003, IPSJ Trans Math Model Appl
   Awoyera PO, 2020, ADV INTELL SYST COMP, V1048, P197, DOI 10.1007/978-981-15-0035-0_15
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Debnath Kalyan Kumar, 2010, Journal of Multimedia, V5, P560, DOI 10.4304/jmm.5.6.560-567
   Dhandapani K, 2019, INT J PLAST TECHNOL, P1
   Feng BY, 2014, PATTERN RECOGN, V47, P2621, DOI 10.1016/j.patcog.2014.02.011
   Frosini A, 1996, IEEE T NEURAL NETWOR, V7, P1482, DOI 10.1109/72.548175
   García-Lamont F, 2012, EXPERT SYST APPL, V39, P9651, DOI 10.1016/j.eswa.2012.02.132
   Gogoi M, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P553, DOI 10.1109/SPIN.2015.7095416
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hlaing KNN, 2016, 2016 SECOND ASIAN CONFERENCE ON DEFENCE TECHNOLOGY (ACDT), P67, DOI 10.1109/ACDT.2016.7437645
   Kagehiro T, 2006, IEICE T INF SYST, VE89D, P2061, DOI 10.1093/ietisy/e89-d.7.2061
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar BA, 2020, ADV INTELL SYST COMP, V1057, P677, DOI 10.1007/978-981-15-0184-5_58
   Kumar SN, 2018, INT J PUBLIC HLTH RE, V9, P747, DOI [10.5958/0976-5506.2018.01550.4, DOI 10.5958/0976-5506.2018.01550.4]
   Liu X., 2008, Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility, P305
   Liu Y., 2014, J INFORM COMPUT SCI, V11, P4031, DOI DOI 10.12733/JICS20104321
   Neil L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P7, DOI 10.1109/ISI.2018.8587375
   Paisios N., 2011, Proceedings of the 24th annual ACM symposium adjunct on User interface software and technology, P19, DOI DOI 10.1145/2046396.2046407
   Papastavrou S., 2010, ACM SIGGRAPH 2010 Posters, P68
   Parlouar R, 2009, ASSETS'09: PROCEEDINGS OF THE 11TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P227
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2014, INT C PATT RECOG, P2661, DOI 10.1109/ICPR.2014.460
   Stein C., 2012, P INT C BIOM SPEC IN, P1
   Sturman MC, 2011, CORNELL SCHOOL OF HOTEL ADMINISTRATION ON HOSPITALITY: CUTTING EDGE THINKING AND PRACTICE, P1
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Yan WQ, 2015, MULTIMED TOOLS APPL, V74, P4723, DOI 10.1007/s11042-013-1833-x
   Zeggeye JF, 2016, INT J IMAGE GRAPH SI, V8
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22569
EP 22594
DI 10.1007/s11042-020-09031-0
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000559642600003
DA 2024-07-18
ER

PT J
AU Zheng, X
   Zhao, JL
   Lv, ZH
   Duan, FQ
   Pan, ZK
AF Zheng, Xin
   Zhao, Junli
   Lv, Zhihan
   Duan, Fuqing
   Pan, Zhenkuan
TI Skull similarity comparison based on SPCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Craniofacial reconstruction; Skull similarity comparison; SPCA; PCA
AB As an important biological feature of the human, the skull plays an active role in assisting criminal investigation, victim identification, etc. This paper proposes a method based on Sparse Principal Component Analysis (SPCA) for comparison of skull similarity. Compared with Principal Component Analysis (PCA), SPCA can not only effectively reduce the data dimension,but also produce sparse principal components which are easy to explain. Each principal component of PCA is a linear combination of all original variables. It's difficulty in explaining the corresponding relationship between principal components and features. SPCA makes the loadings sparse, and thus highlights the main part of the principal component, which can solve the problem of PCA that has difficulty in explaining the result. The experimental results show that the dimensionality reduction data by SPCA is superior to PCA in the aspects of complexity, discrimination, stability, interpretability, and similarity evaluation. These indicate that the comparison of skull similarity based on SPCA is accurate and stable, which can provide an effective direction for improving the accuracy of craniofacial reconstruction and obtaining accurate reconstruction results.
C1 [Zheng, Xin; Zhao, Junli; Lv, Zhihan] Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Peoples R China.
   [Duan, Fuqing] Beijing Normal Univ, Coll Artificial Intelligence, Beijing 100875, Peoples R China.
   [Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
C3 Qingdao University; Beijing Normal University; Qingdao University
RP Zhao, JL (corresponding author), Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Peoples R China.
EM jancyzheng@163.com; zhaojl@yeah.net; lvzhihan@gmail.com;
   fqduan@bnu.edu.cn; zkpan@126.com
RI Lv, Zhihan/AHD-0875-2022; Lv, Zhihan/GLU-4458-2022; Lyu,
   Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074; Zhao,
   Junli/0000-0002-2034-6426
FU National Natural Science Foundation of China [61702293, 61772294,
   61572078, 61902203, 11572066, 11602047]; China Postdoctoral Science
   Foundation [2017M622137]; Key Research and Development Plan -Major
   Scientific and Technological Innovation Projects of ShanDong Province
   [2019JZZY020101]; Open Research Fund of theMinistry of Education
   Engineering Research Center of Virtual Reality Application of China
   [MEOBNUEVRA201601]
FX The authors gratefully appreciate the anonymous reviewers for all of
   their helpful comments. We also acknowledge the support of Xianyang
   Hospital for providing CT images.This work was supported by the National
   Natural Science Foundation of China under Grant Nos. 61702293, 61772294,
   61572078, 61902203, 11572066 and 11602047, China Postdoctoral Science
   Foundation No.2017M622137, Key Research and Development Plan -Major
   Scientific and Technological Innovation Projects of ShanDong Province
   No.2019JZZY020101, the Open Research Fund of theMinistry of Education
   Engineering Research Center of Virtual Reality Application of China
   under Grant No.MEOBNUEVRA201601.
CR [Anonymous], 1993, TECHNICAL REPORT
   [Anonymous], PRACTICAL MULTIVARIA
   [Anonymous], 1996, REGRESSION SHRINKAGE
   CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614
   Claes P, 2006, FORENSIC SCI INT, V159, pS147, DOI 10.1016/j.forsciint.2006.02.035
   Deng QQ, 2011, FORENSIC SCI INT, V208, P95, DOI 10.1016/j.forsciint.2010.11.011
   Duan FQ, 2014, IEEE T INF FOREN SEC, V9, P1322, DOI 10.1109/TIFS.2014.2332981
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Faisan S, 2012, PATTERN RECOGN LETT, V33, P1309, DOI 10.1016/j.patrec.2012.03.009
   Feng J, 2008, IMAGE VISION COMPUT, V26, P761, DOI 10.1016/j.imavis.2007.08.018
   Frank J, 1993, TECHNOMETRICS, V109, P148
   Helmer RP, 1993, ASSESSMENT RELIABILI, P229
   Hu YL, 2013, MULTIMED TOOLS APPL, V64, P345, DOI 10.1007/s11042-012-1005-4
   Huang RK, 2019, COMPUT GRAPH-UK, V82, P264, DOI 10.1016/j.cag.2019.05.026
   Ip HHS, 2002, P 15 INT C VIS INT, P314
   Jin W, 2013, COMPUTER APPL RES, P3124
   JOLLIFFE IT, 1995, J APPL STAT, V22, P29, DOI 10.1080/757584395
   Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148
   Kong S, 2006, RES SKULL RECOGNITIO
   Li H, 2012, 9 CHIN COMP GRAPH C, P35
   Li HY, 2011, SECUR COMMUN NETW, V4, P3, DOI 10.1002/sec.176
   Li N, 2011, RES IMPLEMENTATION 3
   Liang X, 2013, INT C DIGIT MANUF, P322, DOI 10.1109/ICDMA.2013.78
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Papatheodorou T, 2005, LECT NOTES COMPUT SC, V3546, P997
   Ricci A, 2006, AM J FOREN MED PATH, P246
   Shui W, 2011, RES APPL CRANIOFACIA
   SNOW CC, 1970, AM J PHYS ANTHROPOL, V33, P221, DOI 10.1002/ajpa.1330330207
   Stephan CN, 2001, J FORENSIC SCI, V46, P432
   VaneZis M., 2008, FORENSIC FACIAL RECO
   Vines SK, 2000, J ROY STAT SOC C-APP, V49, P441, DOI 10.1111/1467-9876.00204
   Wong HS, 2004, PATTERN RECOGN, V37, P2307, DOI 10.1016/j.patcog.2004.05.004
   Xiru C, 1984, PRACTICAL REGRESSION
   Yuan X, 2005, IEEE INT SYMP CIRC S, P3211
   Zhai G, 2013, ANATOMY J, P377
   Zhao J, 2014, CRANIOFACIAL RECONST
   Zhao JL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179671
   Zhao W, 2008, J BIOMEDICAL ENG, P1034
   Zhao W, 2007, BEIJING BIOMEDICAL E, P454
   Zhao W, 2008, J BIOMEDICAL ENG, P280
   Zhao W, 2007, COMPUTER APPL RES, P374
   Zhao W, 2007, PROCEEDINGS OF THE 26TH CHINESE CONTROL CONFERENCE, VOL 3, P241
   Zhu X, 2012, CHINESE J IMAGE GRAP, P568
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2003, J ROYAL STAT SOC
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 46
TC 3
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22423
EP 22446
DI 10.1007/s11042-020-08937-z
EA MAY 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534982800002
DA 2024-07-18
ER

PT J
AU Nian, TK
   Chondro, P
   Ruan, SJ
AF Nian, Ting-Kai
   Chondro, Peter
   Ruan, Shanq-Jang
TI A low complexity detection method for video data discontinuity
   implemented on SoC-FPGA by using pixel location prediction scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SoC-FPGA; Video quality; Freezing detection; Video streaming; Embedded
   system
AB Image/video processing in real-time is always in high demand for the quality of video. There are several factors which cause the loss of the video content, such as the type of transmission, missing data and especially data switch. Data switch generally occurs in the alternation of the video signal, which can cause the discontinuity of data during the video data stored in buffer or memory. The current method which adopts frame difference for detecting this issue may consume many resources and memory footprint. This paper presents a method which uses the video pixel prediction to detect the freezing event. The method is implemented with a video system which employs the System-on-chip (SoC) architecture with Field Programmable Gate Array (FPGA) and other components including DDR3 ram, flash, and exchange interfaces as the main processing platform that prevents this problem through freezing detection. The result of evaluation shows that the accuracy of the proposed method is above 99%, in terms of saving more logic usage and reducing the footprint of the memory on the video system.
C1 [Nian, Ting-Kai; Chondro, Peter; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Ruan, SJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 10607, Taiwan.
EM m10402157@mail.ntust.edu.tw; peterchondro.ee@gmail.com;
   sjruan@mail.ntust.edu.tw
RI Chondro, Peter/AAY-3814-2020
OI Chondro, Peter/0000-0002-9770-026X
CR Alavi M, 2001, MIS QUART, V25, P107, DOI 10.2307/3250961
   Apperson RW, 2007, IEEE T VLSI SYST, V15, P1125, DOI 10.1109/TVLSI.2007.903938
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Huynh-Thu Q, 2009, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP.2009.5413894
   ITU, 2007, ITU R REC BT 656
   Karam LJ, 2009, IEEE J-STSP, V3, P189, DOI 10.1109/JSTSP.2009.2015485
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kumbhare P, 2014, DESIGNING HIGH PERFO, pv13
   Laplante P.A., 1997, REAL TIME SYSTEMS DE, V2nd
   Li JN, 2017, IEEE T CIRC SYST VID, V27, P907, DOI 10.1109/TCSVT.2016.2515238
   Li P, 2011, APPL SPECIFIC SYSTEM, DOI [10.1109/ASAP.2011.6043264, DOI 10.1109/ASAP.2011.6043264]
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Marwedel P., 2006, EMBEDDED SYSTEM DESI
   Nagai Y, 2016, IEEE WCNC
   Pedre S, 2016, J REAL-TIME IMAGE PR, V11, P349, DOI 10.1007/s11554-013-0353-2
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Skobi V., 2016, 24 TEL FOR TELFOR, P1, DOI 10.1109/TELFOR.2016.7818805
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yammine G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P341, DOI 10.1109/PCS.2012.6213315
   Yan HY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061814
   Yang S, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P612, DOI 10.1109/CISP.2014.7003852
NR 24
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22261
EP 22276
DI 10.1007/s11042-020-09021-2
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533837800001
DA 2024-07-18
ER

PT J
AU Wang, XL
   Zheng, YL
   Zeng, M
   Cheng, X
   Lu, W
AF Wang, Xiaoli
   Zheng, Yinglin
   Zeng, Ming
   Cheng, Xuan
   Lu, Wei
TI Joint learning for face alignment and face transfer with depth image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face alignment; Cross-modal face transfer; Deep learning; Multi-task
   learning; Transfer learning
AB Face alignment and cross-modal face transfer are two important tasks for automatic face analysis in computer vision. Over the years, they have been extensively studied. Recently, deep neural networks have attracted much research attention for both face alignment and face transfer. With the prevalence of the consumer depth sensor, depth-based face alignment and cross-modal (image and depth) are increasingly important. Different from existing RGB- image based tasks, the main challenge of depth-based tasks is the lack of annotated data. To address the challenge, we observe that these two tasks are closely related and their learning processes may benefit each other. This paper develops a joint multi-task learning algorithm for both depth-based face alignment and face transfer using the deep convolutional neural network (CNN). The proposed approach allows the CNN model to simultaneously share visual knowledge and information between two tasks. We use a dataset of 10,000 face depth images for validation. Our experiments show that the proposed approach outperforms state-of-the-art algorithms. The results also show that learning these two related tasks simultaneously improves the performance of each individual task.
C1 [Wang, Xiaoli; Zheng, Yinglin; Zeng, Ming; Cheng, Xuan] Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
   [Lu, Wei] Renmin Univ, Sch Informat, Beijing, Peoples R China.
C3 Xiamen University; Renmin University of China
RP Zeng, M (corresponding author), Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
EM zengming@xmu.edu.cn
RI Zeng, Ming/GXF-3628-2022
OI Zeng, Ming/0000-0003-2836-9240
FU National Natural Science Foundation of China [61402387, 61702432];
   Fundamental Research Funds for Central Universities of China
   [20720180070, 20720190003]; Guiding Project of Fujian Province in China
   [2018I0016, 2018H0037]; International Cooperation Project
FX This work was supported by the National Natural Science Foundation of
   China (No. 61402387, 61702432), the Fundamental Research Funds for
   Central Universities of China (No. 20720180070, 20720190003), and the
   International Cooperation Project and the Guiding Project of Fujian
   Province in China (No. 2018I0016, 2018H0037).
CR Almahairi Amjad, 2018, ARXIV180210151
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273592
   [Anonymous], 2014, ARXIV14065212
   [Anonymous], 2017, P ASM 36 INT C OC
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Benaim S, 2018, LECT NOTES COMPUT SC, V11209, P222, DOI 10.1007/978-3-030-01228-1_14
   BETTADAPURA V, 2012, COMPUTER SCI
   Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Chen C, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508042
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dong H., 2017, UNSUPERVISED IMAGE T
   Dong XW, 2018, IEEE CONF COMPUT
   Fabbri M, 2018, INT C PATT RECOG, P1355, DOI 10.1109/ICPR.2018.8545652
   Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238
   Fourure D, 2017, NEUROCOMPUTING, V251, P68, DOI 10.1016/j.neucom.2017.04.014
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman Judy, 1989, ARXIV171103213
   Honari S, 2018, PROC CVPR IEEE, P1546, DOI 10.1109/CVPR.2018.00167
   Huang X., 2018, EUR C COMP VIS
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jin X, 2017, COMPUT VIS IMAGE UND, V162, P1, DOI 10.1016/j.cviu.2017.08.008
   Kai W, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318400076
   Kim K, 2018, 2018 EUROPEAN CONFERENCE ON OPTICAL COMMUNICATION (ECOC)
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   KRIAJ J, 2018, 2018 IEEE INT WORK C, P1
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Li MJ, 2018, LECT NOTES COMPUT SC, V11213, P186, DOI 10.1007/978-3-030-01240-3_12
   Lin JX, 2018, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2018.00579
   Liu Z, 2015, 20TH INTERNATIONAL CONFERENCE ON COMPOSITE MATERIALS
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Merget D, 2018, PROC CVPR IEEE, P781, DOI 10.1109/CVPR.2018.00088
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ranjan R., 2016, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Sun JW, 2018, IEEE ICC
   Sun YH, 2017, IEEE ICC
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu Y, 2017, IEEE ICC
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   XU R, 2017, ARXIV171006090
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702
NR 60
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33993
EP 34010
DI 10.1007/s11042-020-08873-y
EA MAY 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000533058700003
DA 2024-07-18
ER

PT J
AU Dash, PP
   Patra, D
AF Dash, Prajna Parimita
   Patra, Dipti
TI An efficient hybrid framework for visual tracking using Exponential
   Quantum Particle Filter and Mean Shift optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Particle Filter; Quantum Particle Filter; Abrupt motion
ID KALMAN FILTER; MODEL
AB Visual object tracking is a key component in many computer vision applications. In real time visual tracking, abrupt changes in speed and direction of the object are demanding challenges. In this paper, we present an efficient visual tracking framework which can efficiently handle the above challenge, i.e., abrupt motion of the object. The framework is formulated by hybridizing the proposed Exponential Quantum Particle Filter (EQPF) with the traditional Mean-Shift (MS) optimization for efficient computation in object tracking task. The efficacy of EQPF in estimating the abrupt changes in functions, is tested on the standard Quail function, and then it has been successfully applied in object tracking algorithm. The effective multi-modal propagation strategies of Quantum Particle Filter (QPF) enables the tracker to handle the abrupt changes in speed and direction, whereas, the hybridization with MS enhances the computational efficiency by reducing the number of particles. Performance of the proposed method is assessed by experimenting on different publicly available challenging sequences. Both the subjective and objective evaluations are carried out to validate the superiority of the proposed tracking method over other state-of-the-art methods.
C1 [Dash, Prajna Parimita] Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, Bihar, India.
   [Patra, Dipti] Natl Inst Technol, Dept Elect Engn, Rourkela, India.
C3 Birla Institute of Technology Mesra; National Institute of Technology
   (NIT System); National Institute of Technology Rourkela
RP Dash, PP (corresponding author), Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, Bihar, India.
EM pdash6@gmail.com; dpatra@nitrkl.ac.in
RI Dash, Prajna Parimita/AAE-9282-2021
OI Dash, Prajna Parimita/0000-0002-9767-8234
CR [Anonymous], BMVC
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Baxter RH, 2015, IEEE SIGNAL PROC LET, V22, P578, DOI 10.1109/LSP.2014.2364458
   Bishop C. M., 2006, PATTERN RECOGN, p©2006
   Bouten L, 2007, SIAM J CONTROL OPTIM, V46, P2199, DOI 10.1137/060651239
   BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755
   Cham TJ, 1999, IEEE COMP SOC C COMP
   CHAN YT, 1979, IEEE T AERO ELEC SYS, V15, P237, DOI 10.1109/TAES.1979.308710
   Chase BA, 2009, PHYS REV A, V79, DOI 10.1103/PhysRevA.79.022314
   Chen JG, 2019, MULTIMED TOOLS APPL, V78, P22463, DOI 10.1007/s11042-019-7514-7
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Concha D, 2018, J REAL-TIME IMAGE PR, V15, P309, DOI 10.1007/s11554-014-0483-1
   DAVIES EB, 1969, COMMUN MATH PHYS, V15, P277, DOI 10.1007/BF01645529
   Dhassi Y, 2019, MULTIMED TOOLS APPL, V78, P21349, DOI 10.1007/s11042-019-7386-x
   Fei MJ, 2017, MULTIMED TOOLS APPL, V76, P4617, DOI 10.1007/s11042-016-3723-5
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Khalili A, 2015, ELECTRON LETT, V51, P1251, DOI 10.1049/el.2015.1013
   KITAGAWA G, 1987, J AM STAT ASSOC, V82, P1032, DOI 10.2307/2289375
   Kristan M, 2010, IEEE T SYST MAN CY B, V40, P1505, DOI 10.1109/TSMCB.2010.2041662
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li PH, 2004, IMAGE VISION COMPUT, V22, P157, DOI 10.1016/j.imavis.2003.07.004
   Liu J, 2001, COMBINED PARAMETER S
   Madrigal F, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P31, DOI 10.1109/AVSS.2013.6636612
   Meng CX, 2019, MULTIMED TOOLS APPL, V78, P8799, DOI 10.1007/s11042-018-6382-x
   MINTY GJ, 1962, DUKE MATH J, V29, P341, DOI 10.1215/S0012-7094-62-02933-2
   Nguyen QT, 2006, TENCON IEEE REGION, P28
   Pourmomtaz N, 2020, MULTIMED TOOLS APPL, P1
   Rohilla R, 2017, IET COMPUT VIS, V11, P207, DOI 10.1049/iet-cvi.2016.0201
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   van Handel R, 2005, J OPT B-QUANTUM S O, V7, pS179, DOI 10.1088/1464-4266/7/10/001
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Verstraete F, 2001, PHYS REV A, V64, DOI 10.1103/PhysRevA.64.032111
   Wang Q, 2014, NEUROCOMPUTING, V131, P227, DOI 10.1016/j.neucom.2013.10.021
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wang Y, 2011, NONPARAMETRIC TECHNI
   YAO YS, 1994, INT C PATT RECOG, P654
   Yuan Y, 2014, IEEE T CIRC SYST VID, V24, P15, DOI 10.1109/TCSVT.2013.2273631
   Zhang S, 2018, VIRTUAL REAL-LONDON, V22, P37, DOI 10.1007/s10055-017-0311-6
NR 40
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21513
EP 21537
DI 10.1007/s11042-020-08999-z
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530987700003
DA 2024-07-18
ER

PT J
AU Yan, XH
   Liu, F
   Yan, WQ
   Yang, GZ
   Lu, YL
AF Yan, Xuehu
   Liu, Feng
   Yan, Wei Qi
   Yang, Guozheng
   Lu, Yuliang
TI Weighted visual cryptographic scheme with improved image quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptographic scheme; Random grids; Weighted; Improved image
   quality
ID CONSTRUCTION
AB The weighted visual cryptographic scheme (WVCS) allows the dealer to assign a weight to every shadow (participant) according to the participant's importance so that the ability of each shadow to reveal a secret image can be varied. However, the previous weighted random grid-based VCS (WRGVCS) has the shortcoming of low visual quality. The contribution of this paper is that a new WRGVCS for a (k, n) threshold is designed to improve the image quality of the revealed secret image and to realize more features. RG is utilized to achieve the features of no pixel expansion and no codebook design. The probability of covering the valid bits is improved to improve the image quality. Experimental results and security analyses indicate the effectiveness of the designed scheme. Contrast and feature comparisons with previous weighted VCS approaches exhibit improvements in the designed scheme over other relative weighted VCSs. The limitations of our work are that the weighted effect decreases for some thresholds, and the theoretical contrast of the designed scheme is not derived directly by the parameters.
C1 [Yan, Xuehu; Liu, Feng; Yang, Guozheng; Lu, Yuliang] Natl Univ Def Technol, Hefei 230037, Peoples R China.
   [Yan, Wei Qi] Auckland Univ Technol, Auckland, New Zealand.
C3 National University of Defense Technology - China; Auckland University
   of Technology
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]; Key Program of
   the National University of Defense Technology [ZK-17-02-07]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work is supported by the National Natural
   Science Foundation of China (Grant Number: 61602491) and the Key Program
   of the National University of Defense Technology (Grant Number:
   ZK-17-02-07).
CR Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Cheng Y., 2017, MULTIMEDIA TOOLS APP
   Ghoniem, 2018, IEEE ACCESS
   Gurunathan K, 2019, MULTIMEDIA TOOLS APP
   Hou Y.C, 2015, PRIVILEGE BASED VISU
   Jia XX, 2019, MULTIMED TOOLS APPL, V78, P8207, DOI 10.1007/s11042-018-6779-6
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li YN, 2018, IEEE SIGNAL PROC LET, V25, P140, DOI 10.1109/LSP.2017.2777881
   Liu F, 2019, MATH BIOSCI ENG, V16, P5750, DOI 10.3934/mbe.2019287
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P20673, DOI 10.1007/s11042-017-5482-3
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P16461, DOI 10.1007/s11042-017-5215-7
   Liu Y, 2018, INF SCI, V45, P321
   Miao FY, 2015, IEEE T INF FOREN SEC, V10, P889, DOI 10.1109/TIFS.2014.2384393
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Praveen K, 2018, ADV INTELL SYST, V563, P257, DOI 10.1007/978-981-10-6872-0_24
   Sharma A, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P1, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.18
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Tan LD, 2019, IEEE ACCESS, V7, P59278, DOI 10.1109/ACCESS.2019.2914515
   Wang GY, 2016, INT J DIGIT CRIME FO, V8, P85, DOI 10.4018/IJDCF.2016070106
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yan X.H., 2016, P SOC COMP 2 INT C Y, V1, P249, DOI DOI 10.1007/978-981-10-2053-7_23
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2018, MULTIMED TOOLS APPL, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2017, J VIS COMMUN IMAGE R, V42, P121, DOI 10.1016/j.jvcir.2016.10.014
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
NR 29
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21345
EP 21360
DI 10.1007/s11042-020-08970-y
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531339200004
DA 2024-07-18
ER

PT J
AU Wen, Y
   Yang, XM
   Celik, T
   Sushkova, O
   Albertini, MK
AF Wen, Yu
   Yang, Xiaomin
   Celik, Turgay
   Sushkova, Olga
   Albertini, Marcelo Keese
TI Multifocus image fusion using convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Multi-focus; Convolutional neural network; Morphological
   filtering
ID PERFORMANCE
AB Acquiring all-in-focus images is significant in the multi-media era. Limited by the depth-of-field of the optical lens, it is hard to acquire an image with all targets are clear. One possible solution is to merge the information of a few complementary images in the same scene. In this article, we employ a two-channel convolutional network to derive the clarity map of source images. Then, the clarity map is smoothed by using morphological filtering. Finally, the fusion image is constructed via merging the clear parts of source images. Experimental results prove that our approach has a better performance on both visual quality and quantitative evaluations than many previous fusion approaches.
C1 [Wen, Yu; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Celik, Turgay] Univ Witwatersrand, Sch Comp Sci & Appl Math, Johannesburg, South Africa.
   [Sushkova, Olga] Kotelnikov Inst Radio Engn & Elect, Moscow, Russia.
   [Albertini, Marcelo Keese] Univ Fed Uberlandia, Dept Comp Sci, Uberlandia, MG, Brazil.
C3 Sichuan University; University of Witwatersrand; Kotelnikov Institute of
   Radioengineering & Electronics; Universidade Federal de Uberlandia
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM arielyang@scu.edu.cn
RI Sushkova, Olga S/N-3819-2017; yang, xiao/HJI-7815-2023; Albertini,
   Marcelo K/J-7495-2012; Celik, Turgay/Q-9713-2018
OI Sushkova, Olga S/0000-0002-1960-7289; Celik, Turgay/0000-0001-6925-6010;
   Albertini, Marcelo/0000-0002-1846-946X
FU National Natural Science Foundation of China [61711540303, 61701327];
   Science Foundation of Sichuan Science and Technology Department
   [2018GZ0178]; State Key Laboratory [614250304010517]
FX The research in our paper is sponsored by National Natural Science
   Foundation of China (No. 61711540303, No. 61701327), Science Foundation
   of Sichuan Science and Technology Department (No. 2018GZ0178). Open
   research fund of State Key Laboratory (No. 614250304010517).
CR Ben Hamza A, 2005, INTEGR COMPUT-AID E, V12, P135
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   DE I, 2013, MULTIFOCUS IMAGE FUS
   ELTOUKHY HA, 2003, ELECT IMAGING
   Ghassemian H, 2016, INFORM FUSION, V27, P150
   Guo JL, 2020, SOFT COMPUT, V24, P9307, DOI 10.1007/s00500-019-04455-9
   HAGHIGHAT MBA, 2011, NONREFERENCE IMAGE F
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P5088, DOI 10.1109/TGRS.2013.2286827
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S, 2001, Information Fusion, V2, P169, DOI DOI 10.1016/S1566-2535(01)00038-0
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Min LinQiang Chen Shuicheng Yan., 2013, NETWORK IN NETWORK
   Morabito FC, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P367, DOI 10.1016/B978-0-12-372529-5.00013-5
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   PRABHAKAR KR, 2017, DEEPFUSE DEEP UNSUPE
   QIANG W, 2004, IEEE INSTR MEAS TECH
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Xydeas C, 2000, P SOC PHOTO-OPT INS, V4051, P89, DOI 10.1117/12.381668
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   YUAN C, 2011, 6 INT C IM GRAPH
   ZAGORUYKO S, 2015, LEARNING COMP IMAGE
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
NR 33
TC 11
Z9 12
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34531
EP 34543
DI 10.1007/s11042-020-08945-z
EA MAY 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000530603300002
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Lu, W
   Xue, YJ
   Yeung, YLO
AF Liu, Xianjin
   Lu, Wei
   Xue, Yingjie
   Yeung, Yuileong
TI Upscaling factor estimation on double JPEG compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Image resampling detection; Scaling factor estimation
ID FORENSICS; STEP
AB Resampling detection is one of the most important topics in image forensics. Some methods can even estimate the resampling factors. However, it remains a challenge on the post-compressed images because the JPEG compression destroys the statistical characteristics of the resampled images which greatly affect the detection ability. In this paper, we propose a method to estimate the upscaling factors of double JPEG compressed images in the presence of image upscaling between the two compressions. Both of the pre-compression and the post-compression have a great impact on the estimation. We first analyze the pre-compressed image upscaling and find that the peaks produced by the pre-compression will be suppressed by the post-compression. Therefore, the post-compression has a greater impact than the pre-compression. Through analyzing the influence of post-compression and the causes of the periodic JPEG peaks, we find that the image block estimation can effectively reduce the influence of JPEG block artifacts. To further improve the detection ability, a Gaussian filtering model is developed to deal with JPEG block artifacts and a detector which can more effective extract resampling characteristic is proposed to estimate the upscaling factor. The experimental results demonstrate that the proposed detection method outperforms some state-of-the-art methods.
C1 [Liu, Xianjin; Lu, Wei; Xue, Yingjie; Yeung, Yuileong] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci, Key Lab Machine Intelligence & Adv Comp,Minist Ed, Guangzhou 510006, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Lu, W (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci, Key Lab Machine Intelligence & Adv Comp,Minist Ed, Guangzhou 510006, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM liuxj48@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn
RI li, tong/JYO-7530-2024; Liu, Yixuan/JFJ-2820-2023
OI Lu, Wei/0000-0002-4068-1766
CR [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bianchi T, 2012, IEEE INT WORKS INFOR, P127, DOI 10.1109/WIFS.2012.6412637
   Birajdar GH, 2014, AEUE INT J ELECT COM, V68
   BLACHMAN NM, 1990, IEEE T COMMUN, V38, P13, DOI 10.1109/26.46523
   Bremner S, 2009, IEEE PHOT SPEC CONF, P2147
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chen CL, 2017, IEEE T IMAGE PROCESS, V26, P2811, DOI 10.1109/TIP.2017.2682963
   Chen CL, 2014, IEEE SIGNAL PROC LET, V21, P890, DOI 10.1109/LSP.2014.2320503
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen X, 2018, IEEE T NEUR NET LEAR, V29, P3938, DOI 10.1109/TNNLS.2017.2740318
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Dalgaard N, 2010, IEEE IMAGE PROC, P1753, DOI 10.1109/ICIP.2010.5652358
   David V., 2011, Workshop on Information Forensics and Security, P1
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Gardner AW, 1994, CYCLOSTATIONARITY CO
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Huang XC, 2019, INT J DIGIT CRIME FO, V11, P47, DOI 10.4018/IJDCF.2019040104
   Kao YT, 2012, IEEE T IMAGE PROCESS, V21, P3443, DOI 10.1109/TIP.2012.2191562
   Kirchner M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P13
   Kirchner M, 2009, IEEE INT WORKS INFOR, P21, DOI 10.1109/WIFS.2009.5386489
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin C, 2019, MULTIMEDIA TOOLS APP
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu BH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON MATERIAL SCIENCE AND ENVIRONMENTAL ENGINEERING (MSEE 2013), P556
   Liu X, 2018, MULTIMEDIA TOOLS APP
   Liu XJ, 2019, IEEE ACCESS, V7, P24632, DOI 10.1109/ACCESS.2019.2901020
   Liu X, 2019, IEEE HI ASS SYS ENGR, P1, DOI 10.1109/HASE.2019.00011
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Nguyen HC, 2013, LECT NOTES COMPUT SC, V8099, P113
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qian RH, 2012, IEEE INT CONF MULTI, P61, DOI 10.1109/ICMEW.2012.18
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Vázquez-Padín D, 2017, IEEE T INF FOREN SEC, V12, P2115, DOI 10.1109/TIFS.2017.2699638
   Vázquez-Padín D, 2015, EUR SIGNAL PR CONF, P2067, DOI 10.1109/EUSIPCO.2015.7362748
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P205, DOI 10.1109/WIFS.2012.6412650
   Vázquez-Padín D, 2010, IEEE IMAGE PROC, P1745, DOI 10.1109/ICIP.2010.5652513
   Wang R, 2017, INT J DIGITAL CRIME, V10
   Wei WM, 2010, IEEE T INF FOREN SEC, V5, P507, DOI 10.1109/TIFS.2010.2051254
   Wolberg G, 1994, Digital image warping
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Xiang XQ, 2018, J COASTAL RES, P1, DOI 10.2112/SI84-001.1
   Xiao H, 2019, J VIS COMMUN IMAGE R, V59
   Xue F, 2018, MULTIMEDIA TOOLS APP
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhang Q, 2018, MULTIMED TOOLS APPL, V77
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhou QX, 2019, J PHYS D APPL PHYS, V52, DOI 10.1088/1361-6463/ab37de
   Zhu N, 2016, NEUROCOMPUTING, V204, P33, DOI 10.1016/j.neucom.2015.06.113
NR 66
TC 3
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12891
EP 12914
DI 10.1007/s11042-019-08519-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700007
DA 2024-07-18
ER

PT J
AU Wang, X
   Dong, YY
   Zhang, Q
   Wang, Q
AF Wang, Xue
   Dong, Yingying
   Zhang, Qi
   Wang, Qing
TI Region-based depth feature descriptor for saliency detection on light
   field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field; Saliency detection; Multiple cue integration; Dark
   channels; Depth feature descriptor
ID OBJECT DETECTION; MODEL; RETRIEVAL; ATTENTION
AB This paper addresses the light field saliency detection problem via a multiple cue integration framework. By reinterpreting the usage of dark channels in estimating the amount of defocus, a novel region-based depth feature descriptor (RDFD) defined over the focal stack is proposed. Compared to the methods which utilize the depth map as another image channel, the RDFD can produce more informative saliency cues and make less restrictive assumptions on accurate depth map or focused clear images containing dark pixels. The proposed RDFD facilitates saliency detection in the following two respects: (1) the region-based depth contrast map can be computed by measuring a pair-wise distance between super-pixels with the proposed RDFD, (2) a spatial distribution prior in the 3D space (3D-SDP) can be obtained from such depth measurements to provide high-level semantic guidances, including the gradient-like distribution in depth and the object-biased prior in image plane. Both of them contribute to generating a contrast-based depth saliency map and refining a background-based color saliency map. Finally, these saliency maps are merged into a single map using a multi-layer cellular antomata (MCA) optimizer. Experimental results demonstrate that our method outperforms state-of-the-art techniques on the challenging light field saliency detection benchmark LFSD.
C1 [Wang, Xue; Dong, Yingying; Zhang, Qi; Wang, Qing] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, X (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM xwang@nwpu.edu.cn
RI 郑, 琦/KQA-9998-2024
OI Wang, Xue/0009-0003-5224-906X
FU NSFC [61801396, 61531014]; Fundamental Research Funds for the Central
   Universities [3102018zy030]
FX This work is supported by NSFC under Grant 61801396 and 61531014, and by
   the Fundamental Research Funds for the Central Universities under Grant
   3102018zy030.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Ciptadi A., 2013, BMVC
   Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   JIANG HZ, 2011, P BMVC
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   MAI L, 2013, PROC CVPR IEEE, P1131, DOI DOI 10.1109/CVPR.2013.150
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Ren JK, 2015, EUROMICRO, P25, DOI 10.1109/ECRTS.2015.10
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Sheng H, 2016, LECT NOTES ARTIF INT, V9983, P28, DOI 10.1007/978-3-319-47650-6_3
   Sheng H, 2016, INT CONF ACOUST SPEE, P1631, DOI 10.1109/ICASSP.2016.7471953
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   XUE T, 2019, IMAGE VISION COMPUT, P91
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 44
TC 14
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16329
EP 16346
DI 10.1007/s11042-020-08890-x
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000529468100002
DA 2024-07-18
ER

PT J
AU Uhm, KH
   Kang, MC
   Kim, JY
   Ko, SJ
AF Uhm, Kwang-Hyun
   Kang, Mun-Cheon
   Kim, Joon-Yeon
   Ko, Sung-Jea
TI Improving the robustness of gaze tracking under unconstrained
   illumination conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze tracking; Human computer interaction
ID SYSTEM; PUPIL
AB In human-computer interaction (HCI) applications, the performance degradation of gaze trackers in real-world environments is a critical issue. Typically, gaze trackers utilize the pupil center and corneal reflection (CR) obtained from an infrared (IR) light source to estimate the point of regard (POR). However, false CRs are often generated due to extraneous light sources such as sunlight or lamps. In this study, we propose a method of improving the robustness of gaze tracking under unconstrained illumination conditions. First, the proposed method generates a coded CR pattern by utilizing time-multiplexed IR light sources. Next, the CR candidates are detected in eye images, and their coordinates are compensated based on the head and eye movements of the user. Finally, true CRs are selected from the motion-compensated CR candidates by utilizing a novel cost function. Experimental results indicate that the gaze-tracking performance of the proposed method under various light conditions is considerably better than those of the conventional methods.
C1 [Uhm, Kwang-Hyun; Kang, Mun-Cheon; Kim, Joon-Yeon; Ko, Sung-Jea] Korea Univ, Dept Elect & Comp Engn, Seoul, South Korea.
C3 Korea University
RP Ko, SJ (corresponding author), Korea Univ, Dept Elect & Comp Engn, Seoul, South Korea.
EM khuhm@dali.korea.ac.kr; mckang@dali.korea.ac.kr; jykim@dali.korea.ac.kr;
   sjko@korea.ac.kr
RI Uhm, Kwang Hyun/JMC-4058-2023
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2014-3-00077]
FX This work was supported by the Institute of Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2014-3-00077, Development of global multi-target
   tracking and event prediction techniques based on real-time large-scale
   video analysis).
CR Arar NM, 2017, IEEE T CIRC SYST VID, V27, P2623, DOI 10.1109/TCSVT.2016.2595322
   Cho DC, 2012, IEEE T CONSUM ELECTR, V58, P1119, DOI 10.1109/TCE.2012.6414976
   Drewes H., 2007, Proceedings of the 4th international Conference on Mobile Technology Mobility '07, P364
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flores MJ, 2011, IET INTELL TRANSP SY, V5, P241, DOI 10.1049/iet-its.2009.0090
   Fukumoto K, 2015, COMM COM INF SC, V528, P475, DOI 10.1007/978-3-319-21380-4_80
   Gneo M, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-82
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen D.W., 2014, P S EYE TRACK RES AP, P91, DOI DOI 10.1145/2578153.2578165
   Heo H, 2010, IEEE T CONSUM ELECTR, V56, P1364, DOI 10.1109/TCE.2010.5606271
   Huang J.B., 2014, P S EYE TRACK RES AP, P75, DOI [10.1145/2578153.2578162, DOI 10.1145/2578153.2578162]
   Iqbal N, 2013, IEEE T CONSUM ELECTR, V59, P161, DOI 10.1109/TCE.2013.6490255
   Ji Q, 2004, IEEE T VEH TECHNOL, V53, P1052, DOI 10.1109/TVT.2004.830974
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Lee HC, 2013, SENSORS-BASEL, V13, P13439, DOI 10.3390/s131013439
   Lee HC, 2010, IEEE T CONSUM ELECTR, V56, P2577, DOI 10.1109/TCE.2010.5681143
   Lee SJ, 2011, IEEE T INTELL TRANSP, V12, P254, DOI 10.1109/TITS.2010.2091503
   Li FG, 2007, LECT NOTES COMPUT SC, V4521, P373
   Li F, 2008, J MOD OPTIC, V55, P503, DOI 10.1080/09500340701467827
   Ma Yi., 2010, INVITATION 3 D VISIO
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Nagamatsu Takashi, 2010, CHI 10 EXTENDED ABST, P3349, DOI DOI 10.1145/1753846.1753983
   San Agustin J, 2009, PSYCHNOLOGY J, V7, P213
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
NR 26
TC 4
Z9 4
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20603
EP 20616
DI 10.1007/s11042-020-08679-y
EA APR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000527911600002
DA 2024-07-18
ER

PT J
AU Paturkar, A
   Gupta, GS
   Bailey, D
AF Paturkar, Abhipray
   Gupta, Gourab Sen
   Bailey, Donald
TI Non-destructive and cost-effective 3D plant growth monitoring system in
   outdoor conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant growth parameters; 3D modeling; Leaf area; Plant height; Number of
   leaves; Structure from motion; Plant phenotyping
ID IMAGE; LIDAR
AB There is a high demand for non-destructive systems in plant phenotyping which should precisely calculate plant growth and structure parameters. In this study, the growth of chilli plants (Capsicum annum L) was monitored in outdoor conditions. We also proposed a cost-effective and non-destructive solution for reconstruction of plants in 3D using a single mobile phone camera based on a structure from motion algorithm. Various plant growth and structure parameters such as number of leaves, plant height, and leaf area were measured from the reconstructed 3D models at different plant growth periods. The accuracy of our proposed system is measured by comparing the values derived from the 3D plant model with manual measurements. The results demonstrate that the proposed system has potential to monitor plant growth precisely and non-destructively in outdoor conditions when compared with state-of-the-art systems.
C1 [Paturkar, Abhipray; Gupta, Gourab Sen; Bailey, Donald] Massey Univ, Dept Mech & Elect Engn, Sch Food & Adv Technol, Palmerston North, New Zealand.
C3 Massey University
RP Paturkar, A (corresponding author), Massey Univ, Dept Mech & Elect Engn, Sch Food & Adv Technol, Palmerston North, New Zealand.
EM A.Paturkar@massey.ac.nz
RI Sen Gupta, Gourab/GXH-4852-2022; Bailey, Donald/ABE-2026-2020
OI Sen Gupta, Gourab/0000-0003-2758-0335; Bailey,
   Donald/0000-0002-1025-3680
CR [Anonymous], DIGITAL IMAGE PROCES
   Carrivick J.L., 2016, STRUCTURE MOTION GEO, DOI DOI 10.1002/9781118895818
   Cignoni P., 2008, EUR IT CHAPT C SAL I
   Clevers JGPW, 1996, REMOTE SENS ENVIRON, V56, P42, DOI 10.1016/0034-4257(95)00227-8
   Hosoi F, 2011, SENSORS-BASEL, V11, P2166, DOI 10.3390/s110202166
   Hu Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030806
   Jay S, 2015, COMPUT ELECTRON AGR, V110, P70, DOI 10.1016/j.compag.2014.09.021
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazmi W, 2014, ISPRS J PHOTOGRAMM, V88, P128, DOI 10.1016/j.isprsjprs.2013.11.012
   Lati RN, 2013, INT J REMOTE SENS, V34, P6135, DOI 10.1080/01431161.2013.793870
   Leberl F, 2010, PHOTOGRAMM ENG REM S, V76, P1123, DOI 10.14358/PERS.76.10.1123
   Li L, 2014, SENSORS-BASEL, V14, P20078, DOI 10.3390/s141120078
   Lou L., 2014, ADV AUTONOMOUS ROBOT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mathews AJ, 2013, REMOTE SENS-BASEL, V5, P2164, DOI 10.3390/rs5052164
   Müller-Linow M, 2015, PLANT METHODS, V11, DOI 10.1186/s13007-015-0052-z
   Nguyen T., 2016, COMP STRUCTURE FROM
   Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869
   Omasa K, 2003, ENVIRON SCI TECHNOL, V37, P1198, DOI 10.1021/es0259887
   Omasa K, 1990, IMAGE INSTRUMENTATIO
   Omasa Kenji, 1998, Environment Control in Biology, V36, P217
   Paproki A, 2012, BMC PLANT BIOL, V12, DOI 10.1186/1471-2229-12-63
   Paturkar A., 2018, INT C REC TRENDS IM
   Paturkar A, 2017, INT CONF IMAG VIS
   Paulus S, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0490-0
   Pears N., 2012, 3D Imaging, Analysis and Application
   Rose JC, 2015, SENSORS-BASEL, V15, P9651, DOI 10.3390/s150509651
   Rovira-Más F, 2005, BIOSYST ENG, V90, P251, DOI 10.1016/j.biosystemseng.2004.11.013
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Teng P., 2016, ECOENGINEERING, V28, P107
   Tippetts B, 2016, J REAL-TIME IMAGE PR, V11, P5, DOI 10.1007/s11554-012-0313-2
   Turner D, 2012, REMOTE SENS-BASEL, V4, P1392, DOI 10.3390/rs4051392
   Wijesingha J, 2019, INT J APPL EARTH OBS, V78, P352, DOI 10.1016/j.jag.2018.10.006
   Zhang Y, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0324-2
   Zhang Y, 2018, J AGRIC METEOROL, V74, P129, DOI 10.2480/agrmet.D-18-00013
NR 37
TC 10
Z9 11
U1 6
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34955
EP 34971
DI 10.1007/s11042-020-08854-1
EA APR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000558430400001
DA 2024-07-18
ER

PT J
AU Gupta, R
   Gupta, V
   Kumar, B
   Singh, PK
   Singh, AK
AF Gupta, Rajeev
   Gupta, Vishal
   Kumar, Basant
   Singh, Pramod Kumar
   Singh, Amit Kumar
TI A novel method for automatic retinal detachment detection and estimation
   using ocular ultrasound image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocular ultrasound (USG) image; Retinal detachment (RD); Retinal globe
ID ULTRASONOGRAPHY; DIAGNOSIS
AB This paper presents a novel method for automated detection of retinal detachment from ocular ultrasound image using digital image processing and computational techniques. Retinal detachment (RD) is an ocular emergency in which retina gets detached from the tissues lying underneath it and often requires immediate intervention to prevent rapid, irreversible vision loss. Direct fundoscopy and visual field testing are most common methods for the detection of RD. These methods are difficult to perform and they do not completely rule out retinal detachment. Generally, Ophthalmologists use ocular ultrasound to enhance their clinical acumen in detecting RD. Sometimes it is difficult to extract diagnostic features from ultrasound (USG) images due to its poor quality. Also, noise present in the image would cause misinterpretation during visual inspection;this demands development of intelligent and automated techniques for detection of retinal detachment. Further, the paper proposes a novel frame work for accurate and automatic retinal detachment using image processing techniques and mathematical analysis of detached area contour detected within the ocular globe. Furthermore, the estimation of diagnostic parameters, indicative of retinal detachment is also computed. Based on the mathematical analysis, three such parameters, percentage area of detached retina (PADR) compared to the ocular globe, angular width of detachment (alpha) and maximum radial distance of detachment to choroid layer beneath it (beta), are calculated. These estimated parameters are very useful in determining the exact location and extent of retinal detachment. Results obtained through the proposed retinal detachment detection scheme are validated by the radiologist.
C1 [Gupta, Rajeev; Kumar, Basant] MNNIT Allahabad, Dept Elect & Commun Engn, Allahabad, Uttar Pradesh, India.
   [Gupta, Vishal] Ctr Dev Telemat, New Delhi, India.
   [Singh, Pramod Kumar] Banaras Hindu Univ, Dept Radio Diag & Imaging Med, Inst Med Sci, Varanasi, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol, Dept Comp Sc & Engn, Solan, Himachal Prades, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Banaras Hindu University (BHU); Jaypee
   University of Information Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sc & Engn, Solan, Himachal Prades, India.
EM rajeevg@mnnit.ac.in; vishalgupta584@gmail.com; singhbasant@mnnit.ac.in;
   pksimsbhu@gmail.com; amit_245singh@yahoo.com
RI Gupta, Rajeev/AAD-8694-2021; KUMAR, BASANT/AAD-8650-2021
CR BLUMENKRANZ MS, 1982, OPHTHALMOLOGY, V89, P821
   Chang Huan J, 2012, JAMA, V307, P1447, DOI 10.1001/jama.2012.320
   Chee Y.A., 2012, ADV ENV BIOTECHNOLOG, P355
   COLEMAN DJ, 1973, ARCH OPHTHALMOL-CHIC, V90, P29
   Damianidis CH, 2010, NEURORADIOL J, V23, P329, DOI 10.1177/197140091002300313
   Jaffe GJ, 2004, AM J OPHTHALMOL, V137, P156, DOI 10.1016/S0002-9394(03)00792-X
   Jalali Subhadra, 2003, Community Eye Health, V16, P25
   Jorgensen E., 1996, JDMS, V12, P287
   Kahn Andy, 2005, Cal J Emerg Med, V6, P47
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Michels R.G., 1990, Retinal detachment, P17
   Morajab S., 2015, INT RES J ENG TECHNO, V2, P731
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shinar Z, 2011, J EMERG MED, V40, P53, DOI 10.1016/j.jemermed.2009.06.001
   Vrablik ME, 2015, ANN EMERG MED, V65, P199, DOI 10.1016/j.annemergmed.2014.02.020
NR 17
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11143
EP 11161
DI 10.1007/s11042-018-6032-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600076
DA 2024-07-18
ER

PT J
AU Han, Y
   Chu, ZN
   Zhao, K
AF Han, Yi
   Chu, Zenan
   Zhao, Kai
TI Target positioning method in binocular vision manipulator control based
   on improved canny operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binocular vision; Robotic arm; Target positioning; Improved Canny
   operator; Edge detection
AB In order to improve the accuracy of binocular vision manipulator control, a target positioning method based on improved Canny operator is proposed. First, the image acquired by the left and right cameras is converted into an HSI color model, and the range of the target in the image is located by the image color feature as a region of interest (ROI). Then, the improved Canny edge detection algorithm is used to detect the target in the ROI image, extract the target contour, and determine the center position of the target. These processes are performed on the left and right images, respectively, to obtain the center of the target on the left and right images, and then the three-dimensional coordinates of the target with respect to the camera are determined by triangulation. The experimental results show that the method can accurately detect and locate the target position, and the positioning error is 2.4%. Therefore, it can provide accurate coordinates for the manipulator to perform related tasks.
C1 [Han, Yi] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
   [Han, Yi; Chu, Zenan; Zhao, Kai] Anyang Inst Technol, Dept Comp Sci & Informat Engn, Anyang 455000, Peoples R China.
   [Zhao, Kai] China Univ Petr East China, Coll Informat & Control Engn, Dongying 257000, Peoples R China.
C3 Huazhong University of Science & Technology; Anyang Institute of
   Technology; China University of Petroleum
RP Han, Y (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.; Han, Y (corresponding author), Anyang Inst Technol, Dept Comp Sci & Informat Engn, Anyang 455000, Peoples R China.
EM vincenthanyi@hotmail.com
CR Chen K.Y., 2013, APPL MECH MAT, V284-287, P1862, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.284-287.1862
   Chen WY, 2014, MATH STRUCT COMP SCI, V24, DOI 10.1017/S0960129513000820
   Congping Chen, 2015, Applied Mechanics and Materials, V733, P718, DOI 10.4028/www.scientific.net/AMM.733.718
   Cui EK, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.10.103106
   FengShan Huang, 2014, Applied Mechanics and Materials, V568-570, P320, DOI 10.4028/www.scientific.net/AMM.568-570.320
   Huang GS, 2014, AUT CONTR C, P213
   Hui J., 2016, J COMPUTATIONAL THEO, V13, P2006, DOI [10.1166/jctn.2016.5147, DOI 10.1166/jctn.2016.5147]
   Lei C, 2011, P INT C ART INT COMP, P321
   Li WM, 2017, APPL OPTICS, V56, P2368, DOI 10.1364/AO.56.002368
   Lin CY, 2014, J CHIN INST ENG, V37, P210, DOI 10.1080/02533839.2012.757048
   Liu H, 2013, 9 INT C ADV COMP INT, P34
   Ma QDY, 2018, INT C IM SIGN PROC, P152
   Mahesh SMV, 2013, INT C MACH VIS IM PR, P261
   Ruf B, 2016, INT WORKSH AD MULT R, P25
   Tang YT, 2016, INT EL DEVICES MEET
   Verma R, 2015, 2015 IEEE POWER, COMMUNICATION AND INFORMATION TECHNOLOGY CONFERENCE (PCITC-2015), P312, DOI 10.1109/PCITC.2015.7438182
   Yan, 2014, LECT NOTES ELECT ENG, V271, P761, DOI DOI 10.1007/978-3-642-40630-0_97
   Yao G, 2017, IEEE T GEOSCI REMOTE, V99, P1
   Yu QX, 2013, RES MOBILE LOCALIZAT
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 20
TC 8
Z9 9
U1 3
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9599
EP 9614
DI 10.1007/s11042-019-08140-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600070
DA 2024-07-18
ER

PT J
AU Panarello, A
   Celesti, A
   Fazio, M
   Puliafito, A
   Villari, M
AF Panarello, Alfonso
   Celesti, Antonio
   Fazio, Maria
   Puliafito, Antonio
   Villari, Massimo
TI A big video data transcoding service for social media over federated
   clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transcoding; Social media; Cloud computing; Federation
AB Nowadays, the advent of social networks have revolutionised the traditional communication media. In recent years, the number of social media providers has rapidly grown. In this context, one of the major problems is the on-demand video streaming provisioning. In fact, more and more users require to post and access in real-time videos from anywhere in a short time. Therefore, a denial of service condition can cause for social media providers a loss of users and a consequent lose of money. Commonly, videos, before to be delivered, must be transcoded in order to fits both users' hardware/software device and network capabilities, raising a big video data processing issue. In order to address such a concern, in this paper, we propose a Cloud federation system that enables social media providers to work together so as to take the advantages of a scalable video processing service. Experimental results demonstrate how the overhead due to setup and maintenance tasks of the federated environment is negligible compared to the benefits in terms of video transcoding performance. Moreover, we also demonstrate how Cloud federation can lighten and speed up the whole video processing service, by introducing an additional parallelization level.
C1 [Panarello, Alfonso; Celesti, Antonio; Fazio, Maria; Puliafito, Antonio; Villari, Massimo] Univ Messina, Dept Engn, Messina, Italy.
C3 University of Messina
RP Celesti, A (corresponding author), Univ Messina, Dept Engn, Messina, Italy.
EM acelesti@unime.it
RI Puliafito, Antonio/H-7823-2016
OI Puliafito, Antonio/0000-0003-0385-2711
CR Adobe Systems Software, HTTP DYN STREAM
   Aishwarya K, 2013, INT CONF ADV COMPU, P523, DOI 10.1109/ICoAC.2013.6922006
   [Anonymous], 3920 RFC
   [Anonymous], SMOOTH STREAM
   [Anonymous], STAT FACTS SOC MED U
   Apple Inc, HTTP LIVE STREAM OV
   Bernstein D, 2013, INT CONF CLOUD COMP, P45, DOI 10.1109/CloudCom.2013.102
   Bisignano M, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P814
   Bonacquisto P, 2015, IEEE T CLOUD COMPUT, V3, P345, DOI 10.1109/TCC.2014.2369435
   Celesti Antonio, 2013, 2013 IEEE Symposium on Computers and Communications (ISCC), P000035, DOI 10.1109/ISCC.2013.6754919
   Celesti Antonio, 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P337, DOI 10.1109/CLOUD.2010.46
   Celesti A., 2017, SENSORS SWITZERLAND, V17, P1
   Celesti A, 2016, J NETW COMPUT APPL, V59, P208, DOI 10.1016/j.jnca.2014.09.021
   Chang ZH, 2016, 2016 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P444, DOI 10.1109/APCCAS.2016.7803998
   Di Modica G, 2011, INT J AP MAT COM-POL, V21, P285, DOI 10.2478/v10006-011-0021-2
   Díaz-Sánchez D, 2016, TELECOMMUN SYST, V61, P59, DOI 10.1007/s11235-014-9952-x
   Dong B, 2012, J NETW COMPUT APPL, V35, P1847, DOI 10.1016/j.jnca.2012.07.009
   Dong Bo., 2010, SERVICES COMPUTING S, P65, DOI DOI 10.1109/SCC.2010.72
   Druppel J, DUBSMASH VIDEO TOOL
   Farhad SM, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P380, DOI [10.1109/HPCC-SmartCity-DSS.2016.94, 10.1109/HPCC-SmartCity-DSS.2016.0061]
   Gao G, 2016, RESOURCE PROVISIONIN, P97
   Guo J, 2016, IEEE T MULTIMEDIA, V18, P1297, DOI 10.1109/TMM.2016.2564100
   He QY, 2016, IEEE INT CONF CLOUD, P116, DOI [10.1109/CLOUD.2016.0025, 10.1109/CLOUD.2016.23]
   He QY, 2016, IEEE T MULTIMEDIA, V18, P916, DOI 10.1109/TMM.2016.2544698
   Huang CC, 2016, J DIABETES RES, V2016, DOI 10.1155/2016/6090749
   Huang JC, 2015, I S INTELL SIG PROC, P170, DOI 10.1109/ISPACS.2015.7432759
   Huh E.-N., 2017, T EMERGING TELECOMMU, V28, P1
   Kim Myoungjin., 2013, INT J MULTIMEDIA UBI, V8, P213
   Li XB, 2016, IEEE ACM INT SYMP, P600, DOI 10.1109/CCGrid.2016.50
   Life On Air Inc, MEERK
   MPEG-DASH, 2019, 23009 MPEGDASH ISOIE
   Panarello A, 2015, 2015 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P258, DOI 10.1109/ISCC.2015.7405525
   Qian YM, 2010, INT CONF ACOUST SPEE, P4918, DOI 10.1109/ICASSP.2010.5495112
   Son S, 2017, COMMUN COMPUT SCI, VE100A, P1248
   Twitter Inc, PERISCOPE
   Wang C, 2017, 2016 IEEE 18 INT WOR
   Wei L, 2017, IEEE T CIRC SYST VID, V27, P49, DOI 10.1109/TCSVT.2016.2589621
   Zakerinasab MR, 2015, 2015 IEEE 23RD INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), P69, DOI 10.1109/IWQoS.2015.7404710
   Zakerinasab MR, 2015, C LOCAL COMPUT NETW, P245, DOI 10.1109/LCN.2015.7366317
   Zheng YH, 2017, IEEE T CIRC SYST VID, V27, P1777, DOI 10.1109/TCSVT.2016.2556584
NR 40
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9037
EP 9061
DI 10.1007/s11042-019-07786-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600035
DA 2024-07-18
ER

PT J
AU Peng, YH
AF Peng, Yuhua
TI Super-resolution Reconstruction Using Multiconnection Deep Residual
   Network Combined an Improved Loss Function for Single-frame Image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SR reconstruction; Infrared image; Deep learning; Feature cascade; Loss
   function; Identity mapping
AB Super-resolution reconstruction plays an important role in reconstructing image detail and improving image visual effects, which is achieved mostly by linear interpolation algorithm in the existing display equipment, and there are no obvious details and blurred edges. In this paper, a multi-connection convolution network is proposed to solve the problems of the super-resolution reconstruction (SR) algorithm. The network constructs a multi-connection network structure, where a long skip strategy is used to obtain the identity mapping. It can concatenate the low-level features and high-level features, and can simultaneously represent various complex reconstruction scenes. In addition, a strong and flexible two parameter loss function is used to optimize and train the deep network and improve the generalization ability of the network model. The simulation results show that the proposed SR algorithm in this paper can generate high resolution images with rich details and clearness, and the objective quantitative evaluation is greatly improved.
C1 [Peng, Yuhua] Wuchang Univ Technol, Sch Informat & Engn, Wuhan 430223, Hubei, Peoples R China.
C3 Wuchang University of Technology
RP Peng, YH (corresponding author), Wuchang Univ Technol, Sch Informat & Engn, Wuhan 430223, Hubei, Peoples R China.
EM wxyxiaoying258@sina.com
RI peng, yu/GXW-2071-2022
CR [Anonymous], INFRARED LASER ENG
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977
   He Y, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281590
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Kim J, 2016, IEEE CONF COMPUT
   Lai RJ, 2018, J SCI COMPUT, V74, P1241, DOI 10.1007/s10915-017-0492-x
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   PARK S, 2018, MOL BRAIN, V11
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang MN, 2019, J MED BIOL ENG, V39, P1, DOI 10.1007/s40846-018-0390-1
   [徐冉 Xu Ran], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P556
   [薛峰 Xue Feng], 2017, [红外技术, Infrared Technology], V39, P1032
   Yan YQ, 2018, LECT NOTES COMPUT SC, V11257, P206, DOI 10.1007/978-3-030-03335-4_18
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Ye Y, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281578
   Yoon J, 2018, NEUROIMAGE, V179, P199, DOI 10.1016/j.neuroimage.2018.06.030
NR 20
TC 4
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9351
EP 9362
DI 10.1007/s11042-019-7544-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600056
DA 2024-07-18
ER

PT J
AU Qin, CY
   Li, CH
   Wei, J
AF Qin, Chaoyong
   Li, Chunhong
   Wei, Jie
TI Study on the evaluation of multimedia advertising performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia advertising; conversion; cost per click
ID SEARCH; ADS
AB With the development of multimedia information technology, all walks of life use multimedia technology to publish business information and advertising information to enhance users' awareness and satisfaction with the industry. Among the applications of using multimedia to enhance management, keyword advertising is undoubtedly one of the successful models. Keyword advertising, a typical kind of multimedia advertising, is an important way for advertiser to match customer needs precisely. Evaluating the effectiveness of this novel advertising approach comes to be the focus of attentions in this field. In addition, user experiences in advertisers' page are hardly taken into account in existing researches. Using a unique dataset of keywords on a commercial search engine provider in China, we model click, cost per click and conversion simultaneously. We introduce factors of three categories: bidding factor, keyword semantics factors and user cognition factors. Page view and bounce rate, which have not been reported in existing researches as far as we know, are employed to discover user cognition on website. We find that cost per click has a significant relationship with clicks and conversions. Brand information can increase both clicks and conversions while decrease cost per click. Although long tail keyword advertisement may bring website more traffic, it does not increase conversions. Specifically, we find that page view is positive relate to clicks and conversions while bounce rate is negative to conversions. Our research results can be easily applied in practice by advertiser to improve multimedia advertising performance.
C1 [Qin, Chaoyong] Guangxi Univ, Business Sch, Nanning, Peoples R China.
   [Li, Chunhong] Guangxi Univ, Math & Informat Sci Sch, Nanning, Peoples R China.
   [Wei, Jie] Guangxi Univ, Agr Coll Sch, Nanning, Peoples R China.
C3 Guangxi University; Guangxi University; Guangxi University
RP Qin, CY (corresponding author), Guangxi Univ, Business Sch, Nanning, Peoples R China.
EM qcy@gxu.edu.cn
RI L, Chun/HKW-1738-2023
CR Agarwal A, 2016, INFORM SYST RES, V27, P538, DOI 10.1287/isre.2016.0637
   Agarwal A, 2011, J MARKETING RES, V48, P1057, DOI 10.1509/jmr.08.0468
   Bucklin RE, 2009, J INTERACT MARK, V23, P35, DOI 10.1016/j.intmar.2008.10.004
   Edelman B, 2007, AM ECON REV, V97, P242, DOI 10.1257/aer.97.1.242
   Ghose A, 2009, MANAGE SCI, V55, P1605, DOI 10.1287/mnsc.1090.1054
   Gupta A, 2017, COMPUT ECON, V50, P687, DOI 10.1007/s10614-016-9637-5
   Haans H, 2013, MARKET LETT, V24, P151, DOI 10.1007/s11002-013-9226-5
   Jansen BJ, 2013, J AM SOC INF SCI TEC, V64, P2115, DOI 10.1002/asi.22910
   Kim S, 2014, INFORM SCIENCES, V276, P242, DOI 10.1016/j.ins.2014.02.058
   Qiao DD, 2017, INFORM MANAGE-AMSTER, V54, P531, DOI 10.1016/j.im.2016.11.003
   Rutz OJ, 2012, J MARKETING RES, V49, P306, DOI 10.1509/jmr.10.0354
   Rutz OJ, 2011, MARKET SCI, V30, P789, DOI 10.1287/mksc.1110.0647
   Yang S, 2010, MARKET SCI, V29, P602, DOI 10.1287/mksc.1090.0552
NR 13
TC 0
Z9 1
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9921
EP 9934
DI 10.1007/s11042-019-07780-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600011
DA 2024-07-18
ER

PT J
AU Ram, RS
   Prakash, SA
   Balaanand, M
   Sivaparthipan, CB
AF Ram, R. Saravana
   Prakash, S. Arun
   Balaanand, M.
   Sivaparthipan, C. B.
TI Colour and orientation of pixel based video retrieval using IHBM
   similarity measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video; Content based video retrieval; IHBM; Similarity measure;
   Histograms of oriented gradients (HOG); Descriptors
ID SYSTEM
AB Content-based video retrieval (CBVR) is the most energetic and stimulating research area since the early twentieth century in the domain of multimedia technology and immense quantity of retrieval techniques are introduced frequently. However, majority of the existent CBVR systems do not always give accurate results for all kinds of video databases with different colour, shape and texture feature descriptors. Sometimes, the images or videos that look similar are not semantically similar. Consequently, the retrieval outcomes that are solely centred on low level feature extraction are chiefly unsatisfactory and also unpredictable. This unlocks a new era for the research community to deviate the existent methodologies to new paradigm or direction that there is something at the back of the visual features which require to be regarded for precise searching and also retrieval. A novel CBVR methodology is suggested here centred on the selection of edge gradient feature descriptors known as HOG (Histograms of Oriented Gradients). HOG computes the edge gradient of the whole image, determines the orientation of every pixel and generates the histograms. Formerly, these extracted relevant histograms are utilized to retrieve the pertinent video frame as of the video sequence database through Integrated Histogram Bin Matching (IHBM) similarity measure. The Experimental Result of the proposed approach showed that the number of relevant retrieved video data samples is higher when compared to the existing HI Based CBVR system. The F1-score value is also high which in turn infers that the proposed approach's performance is better when matched other existing approaches.
C1 [Ram, R. Saravana] Anna Univ, Univ Coll Engn Dindigul, Dept Elect & Commun Engn, Dindigul, Tamil Nadu, India.
   [Prakash, S. Arun] Anna Univ, Univ Coll Engn Ramanathapuram, Dept Elect & Elect Engn, Ramanathapuram, Tamil Nadu, India.
   [Balaanand, M.] VRS Coll Engn & Technol, Dept Comp Sci & Engn, Arasur, India.
   [Sivaparthipan, C. B.] SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Anna University; Anna University; SNS College of Technology
RP Ram, RS (corresponding author), Anna Univ, Univ Coll Engn Dindigul, Dept Elect & Commun Engn, Dindigul, Tamil Nadu, India.
EM saravanaramkrishnan@gmail.com; arunprakashmadurai@gmail.com;
   balavdy@gmail.com; sivaparthipanece@gmail.com
RI CB, Sivaparthipan/AAC-9406-2020; Anand, Bala/AFO-6912-2022
OI CB, Sivaparthipan/0000-0002-5389-4330; Anand, Bala/0000-0002-9509-6943;
   ARUN PRAKASH, SEKAR/0000-0002-2959-5488
CR [Anonymous], 2018, 2018 9 IFIP INT C NE, DOI DOI 10.1109/NTMS.2018.8328728
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], INT J TECHNOLOGY ENG
   [Anonymous], 2018, CAAI T INTELL TECHNO, DOI DOI 10.1049/trit.2018.1012
   [Anonymous], 2018, INT C SOFT COMP NETW
   Asha S, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P212, DOI 10.1109/ICACC.2013.49
   Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   BalaAnand M, 2017, ADV NATURAL APPL SCI
   Barhoumi W, 2013, AASRI PROC, V4, P78, DOI 10.1016/j.aasri.2013.10.013
   Brindha N, 2017, SADHANA-ACAD P ENG S, V42, P1, DOI 10.1007/s12046-016-0574-8
   Burkard RE, 1996, DISCRETE APPL MATH, V70, P95, DOI 10.1016/0166-218X(95)00103-X
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng QL, 2018, CAAI T INTELL TECHNO, V3, P33, DOI 10.1049/trit.2018.0003
   Erol B, 2005, IEEE T MULTIMEDIA, V7, P179, DOI 10.1109/TMM.2004.840607
   Hu W, 2014, IEEE T SYST MAN CYB, V41, P797
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Liang B, 2012, PROCEDIA ENGINEER, V29, P2578, DOI 10.1016/j.proeng.2012.01.354
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Patel B. V., 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P272, DOI 10.1109/ICCET.2010.5486262
   Qi GQ, 2018, CAAI T INTELL TECHNO, V3, P83, DOI 10.1049/trit.2018.0011
   Rangarajan P., 2017, COMPUT ECON, P1
   Rossetto Luca, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P255, DOI 10.1007/978-3-319-14442-9_24
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sivic J., 2006, VIDEO GOOGLE EFFICIE, P127
   Solomon Z, 2018, 2018 INT C SOFT COMP, DOI [10.1109/ICSNS.2018.8573688, DOI 10.1109/ICSNS.2018.8573688]
   Suard F, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P207
   Thota C., 2018, Exploring the convergence of big data and the internet of things, P141
   Yarmohammadi H, 2013, IRAN CONF MACH, P214, DOI 10.1109/IranianMVIP.2013.6779981
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang L, 2013, IEEE INT CONF AUTOM, P4, DOI 10.1109/ASE.2013.6693061
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 33
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10199
EP 10214
DI 10.1007/s11042-019-07805-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600025
DA 2024-07-18
ER

PT J
AU Veerashetty, S
   Patil, NB
AF Veerashetty, Sachinkumar
   Patil, Nagaraj B.
TI Novel LBP based texture descriptor for rotation, illumination and scale
   invariance for image texture analysis and classification using
   multi-kernel SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP descriptor; IRSLBP descriptor; Rotation; Illumination; Multi kernel
   SVM approach and Texture analysis
AB In case of illumination change, the local binary pattern (LBP) descriptor have found to be used in analysis of texture of the image because of the ease of computation and robustness to such changes. However, the LBP technique also comes with limitations such as its inability to capture the discriminative information completely. For enhancing the LBP's performance, we proposed a new texture descriptor for rotation, illumination and scale invariance (IRSLBP) for texture classification. The proposed approach extracts the color features through quantification of the RGB space into single channel, which is marked by a smaller number of shades to reduce computation and to improve the efficiency. The IRSLBP descriptor provides the scale invariance by considering the circular neighbor set of every central pixel other than the normal neighboring pixels. Moreover, the proposed IRSLBP decomposed the difference vector into sign part and magnitude part by local difference sign magnitude transform. In addition, these mitigated the influence of rotation, illumination or noise and demonstrated effective robustness. Using the proposed IRSLBP descriptor, we have classified the different textures using Multi kernel support vector machine (SVM) approach.
C1 [Veerashetty, Sachinkumar] APPA Inst Engn & Technol, Dept Comp Sci & Engn, Kalaburagi, Karnataka, India.
   [Patil, Nagaraj B.] Govt Engn Coll, Dept Comp Sci & Engn, Raichur, Karnataka, India.
RP Veerashetty, S (corresponding author), APPA Inst Engn & Technol, Dept Comp Sci & Engn, Kalaburagi, Karnataka, India.
EM sveerashetty@gmail.com; nagarajbpatil1974@gmail.com
RI Veerashetty, Dr. Sachinkumar/HJG-5912-2022
OI Veerashetty, Dr. Sachinkumar/0000-0001-8217-1388
CR Ambika, 2019, HLTH TECHNOL, DOI [10.1007/s12553-018-00289-x, DOI 10.1007/S12553-018-00289-X]
   Antic A, 2018, MECH SYST SIGNAL PR, V98, P1, DOI 10.1016/j.ymssp.2017.04.030
   Calzada-Ledesma V, 2018, STUD COMPUT INTELL, V749, P515, DOI 10.1007/978-3-319-71008-2_37
   Candemir S, 2015, IMAGE VISION COMPUT, V42, P1, DOI 10.1016/j.imavis.2015.06.010
   Citraro L, 2017, IMAGE VISION COMPUT, V62, P8, DOI 10.1016/j.imavis.2017.03.004
   Di Ruberto C, 2017, IET IMAGE PROCESS, V11, P760, DOI 10.1049/iet-ipr.2016.1077
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Hao Y, 2018, MECH SYST SIGNAL PR, V98, P1
   Kaddar B, 2017, COMPUT ELECT ENG
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Mehta R, 2016, IEEE SIGNAL PROC LET, V23, P833, DOI 10.1109/LSP.2016.2561311
   Pan ZB, 2017, EXPERT SYST APPL, V88, P238, DOI 10.1016/j.eswa.2017.07.007
   Salwa L, 2017, PATTERN RECOGN LETT, V100, P1, DOI 10.1016/j.patrec.2017.09.027
   Sandid F, 2016, PATTERN RECOGN LETT, V80, P15, DOI 10.1016/j.patrec.2016.05.010
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Susan S, 2013, IET IMAGE PROCESS, V7, P725, DOI 10.1049/iet-ipr.2012.0527
   Tao G, 2017, PATTERN RECOGN, V69, P124, DOI 10.1016/j.patcog.2017.04.010
   Veerashetty S, 2018, INT J PURE APPL MATH, V118, P711
   Veerashetty S, 2018, J ADV RES DYNAMICAL, V10
   Veerashetty S, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P1173, DOI 10.1109/CTCEEC.2017.8455138
   Virupakshappa, 2019, HEALTH TECHNOL-GER, V9, P701, DOI 10.1007/s12553-018-00288-y
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Virupakshappa, 2018, COGN TECHNOL WORK, DOI [10.1007/s10111-018-0472-4, DOI 10.1007/S10111-018-0472-4]
   Virupakshappa D.B.A., 2018, Int J Pure Appl Math, V118, P33
   Yang Y, 2018, SIGNAL PROCESS-IMAGE, V60, P224, DOI 10.1016/j.image.2017.10.010
NR 26
TC 19
Z9 19
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9935
EP 9955
DI 10.1007/s11042-019-7345-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600012
DA 2024-07-18
ER

PT J
AU Vignesh, CC
   Karthik, S
AF Vignesh, C. Chandru
   Karthik, S.
TI Predicting the position of adjacent nodes with QoS in mobile ad hoc
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ANLC; Self-regulatory; QoS; Adjacent nodes; Throughput and Delays NV
ID LOCATION VERIFICATION; WIRELESS
AB The Mobile Ad Hoc Networks are a self-regulatory set of autonomous nodes which perform communication to all the other nodes within their communication ranges. The nodes which are not in straightforward range make use of in between nodes to perform communication with one another. In mobile ad hoc network, each and every autonomous node holds displacements and shifts based on the precise positions within the network. Hence the verification of node position is crucial in mobile ad hoc networks and it is mainly a great dispute during the existence of opponents focusing on damaging the system. The intention is to design a standard termed as Adjacent Node Location Confirmation (ANLC) for confirming the location of its transmitting adjacent nodes for interchanging the messages and confirms the location of the nodes in transmission within the network. Initially, the method focuses on finding the nodes based on which the transmission connection is set up or it is within the fixed distance. The distance is estimated based on message interchanges among the confirmer and its adjacent nodes in transmission. Soon after the estimation of distances the confirmer authenticates the location of nodes in transmission within the network based on straight balanced, traverse balanced and multi-lateration analysis. The analysis is performed based on QoS of the transmitting node choice for minimizing the delays and acquiring improved throughput. The performance of the designed scheme is estimated based on network throughput and delays.
C1 [Vignesh, C. Chandru; Karthik, S.] SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 SNS College of Technology
RP Vignesh, CC (corresponding author), SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM profchandruvignesh@gmail.com; profskarthik@gmail.com
RI SUBBURATHINAM, KARTHIK/H-4806-2012
OI SUBBURATHINAM, KARTHIK/0000-0002-1073-4847; Chinnappan, Dr Chandru
   Vignesh/0000-0001-5513-846X
CR [Anonymous], IEEE T POWER ELECT
   Calandriello G, 2011, IEEE T DEPEND SECURE, V8, P898, DOI 10.1109/TDSC.2010.58
   Capkun S, 2006, IEEE J SEL AREA COMM, V24, P221, DOI 10.1109/JSAC.2005.861380
   Capkun S, 2008, IEEE T MOBILE COMPUT, V7, P470, DOI 10.1109/TMC.2007.70782
   Ekici E, 2008, AD HOC NETW, V6, P195, DOI 10.1016/j.adhoc.2006.11.006
   Härri J, 2011, SIMUL-T SOC MOD SIM, V87, P275, DOI 10.1177/0037549709345997
   Hu YC, 2003, IEEE INFOCOM SER, P1976
   Hwang JM, 2007, IEEE INFOCOM SER, P2391, DOI 10.1109/INFCOM.2007.287
   Imaizumi N, 2016, J SUPERCOMPUT, V72, P1237, DOI 10.1007/s11227-016-1659-1
   Jiang T, 2009, IEEE INT SYMP CIRC S, P181, DOI 10.1109/ISCAS.2009.5117715
   Kandari S, 2016, WIRELESS PERS COMMUN, V86, P601, DOI 10.1007/s11277-015-2947-4
   Kumar Sunil, 2016, International Journal of Handheld Computing Research, V7, P26, DOI 10.4018/IJHCR.2016010103
   Lazos L, 2006, IEEE J SEL AREA COMM, V24, P233, DOI 10.1109/JSAC.2005.861381
   Maheshwari R, 2007, IEEE INFOCOM SER, P107, DOI 10.1109/INFCOM.2007.21
   Niu DM, 2017, MULTIMED TOOLS APPL, V76, P3255, DOI 10.1007/s11042-016-3963-4
   Papadimitratos P, 2008, IEEE COMMUN MAG, V46, P132, DOI 10.1109/MCOM.2008.4473095
   Poovendran R, 2007, WIREL NETW, V13, P27, DOI 10.1007/s11276-006-3723-x
   Poturalski M., 2008, ASIACCS, P189
   Rath M, 2018, SMART INNOV SYST TEC, V84, P579, DOI 10.1007/978-3-319-63645-0_64
   Song JH, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.160
   Vignesh CC, 2013, ENHANCING CLOCK SKEW
   Wang W, 2018, AD HOC NETW, V69, P38, DOI 10.1016/j.adhoc.2017.10.004
   Zhong S, 2008, THEORY ROBUST LOCALI
NR 23
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8445
EP 8457
DI 10.1007/s11042-018-5842-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600008
DA 2024-07-18
ER

PT J
AU Wang, YM
AF Wang, Yanmei
TI Iteration-based naive Bayes sentiment classification of microblog
   multimedia posts considering emoticon attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microblog; Social platform; Sentiment classification; Emoticon;
   Sentiment lexicon; Vectorization
AB Microblog (such as Weibo) is an integrated social platform of vital importance in the internet age. Because of its diversity, subjectivity and timeliness, microblog is popular among public. In order to perform sentiment classification on microblog posts and overcome the limitation of text information, a fine-grained sentiment analysis method is proposed, in which emoticon attributes are considered. Firstly, the microblog texts are pre-processed to remove some stop words and noise information such as links. Then the data is matched in the sentiment lexicon, and when the first matching succeeds, the second matching is performed in the emoticon dictionary. The emoticons in the emoticon dictionary are transformed into vector form. Through these matching, the emotional features are vectorized and other text features are considered. Finally, the iterative-based naive Bayesian classification method is used for sentiment classification. The experiment results show that emoticons have obvious effect on facilitating the sentiment classification of microblog posts, and the proposed sentiment classification method achieved better than average results in term of classification accuracy compared with state-of-art techniques.
C1 [Wang, Yanmei] Xiangnan Univ, Sch Art & Design, Chenzhou 423000, Hunan, Peoples R China.
C3 Xiangnan University
RP Wang, YM (corresponding author), Xiangnan Univ, Sch Art & Design, Chenzhou 423000, Hunan, Peoples R China.
EM czxnw11@126.com
RI wang, yanmei/HPH-0538-2023
CR Adams B, 2014, MULTIMED TOOLS APPL, V69, P951, DOI 10.1007/s11042-012-1138-5
   Boia M, 2014, LECT NOTES COMPUT SC, V8404, P32, DOI 10.1007/978-3-642-54903-8_3
   Di Fabbrizio G, 2013, IEEE INTELL SYST, V28, P28, DOI 10.1109/MIS.2013.36
   Feng S, 2015, WORLD WIDE WEB, V18, P949, DOI 10.1007/s11280-014-0289-x
   García-Pablos A, 2015, PROCES LENG NAT, P127
   Gui Bin, 2014, Transactions of Beijing Institute of Technology, V34, P537
   He Y., 2017, STAT INFORM FORUM, V32, P110
   Hu M., 2004, P 10 ACM SIGKDD INT, DOI DOI 10.1145/1014052.1014073
   홍삼열, 2012, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V13, P9, DOI 10.7472/jksii.2012.13.6.9
   Li FF, 2017, J CENT SOUTH UNIV, V24, P2322, DOI 10.1007/s11771-017-3644-0
   Li Y, 2016, IEEE INT C PROGR INF, P129
   [栗雨晴 Li Yuqing], 2016, [电子学报, Acta Electronica Sinica], V44, P2068
   Liu JNK, 2001, IEEE T SYST MAN CY C, V31, P249, DOI 10.1109/5326.941848
   [刘全超 Liu Quanchao], 2014, [中文信息学报, Journal of Chinese Information Processing], V28, P123
   [刘思叶 Liu Siye], 2018, [北京大学学报. 自然科学版, Acta Scientiarum Naturalium Universitatis Pekinensis], V54, P687
   Mao LJ, 2017, KNOWL-BASED SYST, V132, pS0950705117303118
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Quan C, 2010, INT J ADV INTELLIGEN, V2, P105
   [史绍亮 Shi Shaoliang], 2015, [计算机应用, Journal of Computer Applications], V35, P2721
   Sury U, 2009, INFORM SPEKTRUM, V32, P267, DOI [10.1007/s00287-009-0347-4, DOI 10.1007/S00287-009-0347-4]
   Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013
   Wang XM, 2013, COMM COM INF SC, V391, P385
   Yessenalina A, 2010, ACL 2010 P 48 ANN M
   Zhang H, 2018, MULTIMED TOOLS APPL, V53, P209
NR 24
TC 3
Z9 5
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19151
EP 19166
DI 10.1007/s11042-020-08797-7
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300004
DA 2024-07-18
ER

PT J
AU Biswas, R
   Bandyapadhay, SK
AF Biswas, Rajib
   Bandyapadhay, Samir Kumar
TI Random selection based GA optimization in 2D-DCT domain color image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; 2D-DCT; Embedding capacity; Data hiding;
   Genetic Algorithm (GA)
ID SUBSTITUTION
AB Steganography, the hiding technique used to secure sensitive data (i.e., images, audio ) while communication takes place. In this paper, the message is embedded in color image in frequency domain exploiting Genetic Algorithm (GA) which provides the robustness i.e., the algorithm can withstand against any rigorous testing and brutal attack except destruction of the stego image. The fragmentation of 8-bit binary stream of each color component to 4-bit and applying Genetic Algorithm (GA) to increase the robustness of the scheme. Random Multiple bits are chosen to embed secret message which increases security along with the payload. The use of transform domain, hash function based random pixel and bit selections for data hiding, secrete data encryption and more over use of Genetic Algorithm (GA) for optimization is the novelty of the proposed work. Perspective and meticulous statistical analysis has been done to immune the algorithm from any attack. The algorithm proposed here is tested with benchmark tools like StirMark 4.0, Confusion Matrix (Receiver Operating Curve Characteristic (ROC) curve) along with steganalysis and statistical tools. Visual disturbance and distortion in stego image is also very insignificant here.
C1 [Biswas, Rajib] Heritage Inst Technol, Dept Informat Technol, Kolkata 700107, India.
   [Bandyapadhay, Samir Kumar] Calcutta Univ, Comp Sci & Engn, Kolkata 700098, India.
C3 Heritage Institute of Technology (HITK); University of Calcutta
RP Biswas, R (corresponding author), Heritage Inst Technol, Dept Informat Technol, Kolkata 700107, India.
EM rajib.biswas.rd@gmail.com; 1954samir@gmail.com
RI Biswas, Rajib/H-3561-2013
CR [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2016, 4 ACMWORKSHOP INFORM
   [Anonymous], IEEE INT C RES ADV I
   [Anonymous], LIP BIOMETRIC TEMPLA
   [Anonymous], MULTIBIT ROBUST IMAG
   [Anonymous], 1996, INTRO GENETIC ALGORI
   [Anonymous], MEDIA WATERMARKING S
   [Anonymous], 2012, INT JOINT C ART INT
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], ATTACKS COPYRIGHT MA
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Fan Jerome, 2006, CJEM, V8, P19
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim C, 2011, COMM COM INF SC, V186, P130
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lin CC, 2011, COMPUT STAND INTER, V33, P477, DOI 10.1016/j.csi.2011.02.003
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Xu G, 2017, J PHYS D APPL PHYS, V50, DOI 10.1088/1361-6463/50/2/025102
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang XP, 2006, IEEE SIGNAL PROC LET, V13, P165, DOI 10.1109/LSP.2005.862602
NR 47
TC 14
Z9 14
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7101
EP 7120
DI 10.1007/s11042-019-08497-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100009
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Yang, YC
   Luo, D
   Qi, CD
AF Liu, Zhenghui
   Yang, Yancong
   Luo, Da
   Qi, Chuanda
TI Speech watermarking robust against recapturing and de-synchronization
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Robustness; Recapturing attacks;
   De-synchronization attacks
ID AUDIO WATERMARKING; ALGORITHM; AUTHENTICATION; SPECTRUM; SCHEME
AB Watermarking is a solution for forensics tracking for digital speech signal, while recapturing and de-synchronization attacks may remove the watermark effectively. It brings threat to watermarking technology used for forensics tracking. In this regards, we defined the discrete cosine transform coefficients logarithm mean (DCT-CLM) feature of speech signal and concluded that the interference caused by recapturing attack has similar impact on the DCT-CLM feature of two adjacent segments. Based on the feature, we proposed a speech watermarking method robust against recapturing and de-synchronization attacks. For the mute parts of speech signal have no meaning and are not the major component for forensics tracking, we focused on non-silence (NS) parts in this paper and embed watermark into DCT-CLM feature belonging to these parts. Compared with the state-of-the-art works, the BER value of the proposed method is decreased by 9% for recapturing attack. Besides, the method outperforms the recent robust watermarking methods notably for recapturing and post-processed with signal processing operations and de-synchronization attacks.
C1 [Liu, Zhenghui; Yang, Yancong; Qi, Chuanda] Xinyang Normal Univ, Coll Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Liu, Zhenghui] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Luo, Da] Dongguan Univ Technol, Sch Comp Sci & Network Secur, Dongguan 523000, Peoples R China.
C3 Xinyang Normal University; Dongguan University of Technology
RP Liu, ZH (corresponding author), Xinyang Normal Univ, Coll Comp & Informat Technol, Xinyang 464000, Peoples R China.; Liu, ZH (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
EM zhenghui.liu@163.com
RI Yang, Yancong/U-8083-2017; Luo, Da/ABW-0504-2022
OI Luo, Da/0000-0002-9128-6782
CR Burshtein D, 2002, IEEE T SPEECH AUDI P, V10, P341, DOI 10.1109/TSA.2002.803420
   Erfani Y, 2017, IEEE T INF FOREN SEC, V12, P840, DOI 10.1109/TIFS.2016.2636094
   Fan MQ, 2011, DIGIT SIGNAL PROCESS, V21, P110, DOI 10.1016/j.dsp.2010.09.003
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Kaur A, 2017, J INF SECUR APPL, V33, P1, DOI 10.1016/j.jisa.2016.12.003
   Li RK, 2016, IET SIGNAL PROCESS, V10, P266, DOI 10.1049/iet-spr.2014.0388
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Mai VK, 2015, IEEE-ACM T AUDIO SPE, V23, P670, DOI 10.1109/TASLP.2015.2401426
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Nadeau A, 2017, IEEE T INF FOREN SEC, V12, P1393, DOI 10.1109/TIFS.2017.2661724
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Natgunanathan I, 2012, IEEE T AUDIO SPEECH, V20, P2232, DOI 10.1109/TASL.2012.2199111
   Nishimura A, 2010, ACOUST SCI TECHNOL, V31, P328, DOI 10.1250/ast.31.328
   Peng H, 2013, DIGIT SIGNAL PROCESS, V23, P382, DOI 10.1016/j.dsp.2012.08.006
   Unoki M., 2011, J INF HIDING MULTIME, V2, P1
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Zhao H, 2013, IEEE T INF FOREN SEC, V8, P1746, DOI 10.1109/TIFS.2013.2278843
NR 20
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6009
EP 6024
DI 10.1007/s11042-019-08309-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900026
DA 2024-07-18
ER

PT J
AU Sun, X
   He, JJ
AF Sun, Xiao
   He, Jiajin
TI A novel approach to generate a large scale of supervised data for short
   text sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data-driven feature learning; Data augmentation; Short text sentiment
   analysis; Model architectural designs; Large-scale artificial data
AB As for the complexity of language structure, the semantic structure, and the relative scarcity of labeled data and context information, sentiment analysis has been regarded as a challenging task in Natural Language Processing especially in the field of short-text processing. Deep learning model need a large scale of training data to overcome data sparseness and the over-fitting problem, we propose multi-granularity text-oriented data augmentation technologies to generate large-scale artificial data for training model, which is compared with Generative adversarial network(GAN). In this paper, a novel hybrid neural network model architecture(LSCNN) was proposed with our data augmentation technology, which is can outperforms many single neural network models. The proposed data augmentation method enhances the generalization ability of the proposed model. Experiment results show that the proposed data augmentation method in combination with the neural networks model can achieve astonishing performance without any handcrafted features on sentiment analysis or short text classification. It was validated on a Chinese on-line comment dataset and Chinese news headline corpus, and outperforms many state-of-the-art models. Evidence shows that the proposed data argumentation technology can obtain more accurate distribution representation from data for deep learning, which improves the generalization characteristics of the extracted features. The combination of the data argumentation technology and LSCNN fusion model is well suited to short text sentiment analysis, especially on small scale corpus.
C1 [Sun, Xiao; He, Jiajin] Hefei Univ Technol, Sch Comp & Informat, 193 TunXi Rd, Hefei, Peoples R China.
C3 Hefei University of Technology
RP Sun, X (corresponding author), Hefei Univ Technol, Sch Comp & Informat, 193 TunXi Rd, Hefei, Peoples R China.
EM sunx@hfut.edu.cn
RI Sun, Xiao/JTV-1301-2023
OI Sun, Xiao/0000-0001-9750-7032
CR [Anonymous], COMPUTER MODERNIZATI
   [Anonymous], ARXIV160902748
   [Anonymous], CLASSIFICATION COMMO
   [Anonymous], STUDY CHINESE TEXT S
   [Anonymous], THESIS
   [Anonymous], 2014, A Convolutional Neural Network for Modelling Sentences
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Fawzi A, 2016, IEEE IMAGE PROC, P3688, DOI 10.1109/ICIP.2016.7533048
   Glover J., 2016, ARXIV161209122
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Kingma DP, 2013, ARXIV
   Kiritchenko S., 2014, P 8 INT WORKSH SEM E, P437, DOI DOI 10.3115/V1/S14-2076
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lipton Z. C., 2015, ARXIV
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Rosario B., 2004, P 42 ANN M ASS COMPU, P430
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun X, 2016, NEUROCOMPUTING, V210, P227, DOI 10.1016/j.neucom.2016.02.077
   [孙晓 Sun Xiao], 2016, [自动化学报, Acta Automatica Sinica], V42, P883
   Tang D, 2016, P C EMP METH NAT LAN, P214, DOI DOI 10.18653/V1/D16-1021
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang K.K., 2015, Image classification with pyramid representation and rotated data augmentation on torch 7
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang Xiang., 2015, Text Understanding From Scratch
   Zhang Ye, 2016, Proc Conf Empir Methods Nat Lang Process, V2016, P795
   Zhou Chunting, 2015, ARXIV
NR 42
TC 27
Z9 29
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5439
EP 5459
DI 10.1007/s11042-018-5748-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900001
DA 2024-07-18
ER

PT J
AU Gaj, S
   Sur, A
   Bora, PK
AF Gaj, Sibaji
   Sur, Arijit
   Bora, Prabin Kumar
TI Prediction mode based H.265/HEVC video watermarking resisting
   re-compression attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed doamin video watermarking; H.265/HEVC watermarking; Intra
   prediciton mode watermarking
ID PARALLEL FRAMEWORK; HEVC; INFORMATION; EFFICIENCY
AB This paper proposes a novel compressed domain robust watermarking scheme which embeds watermark by altering the intra prediction modes of 4 x 4 intra prediction blocks of the most recent high-definition video standards H.265/HEVC. Due to different compression architecture and higher number of intra prediction mode, the existing intra prediction mode based watermarking strategies for previous video standards such as H.264/AVC are not robust when those are directly applied for H.265/HEVC. This proposed work overcomes this shortcoming by reducing the synchronization error of watermark after re-compression attack in two stage. First, a spatial texture analysis is done based on number of non-zero transform coefficients of embedding blocks. Then, suitable candidate blocks for watermark embedding are selected based on 4 x 4 intra luma PB's sustainably and watermarked mode sustainability while maintaining visual quality and bit rate. In next stage, the robustness of the proposed method has been enhanced by grouping of intra prediction modes such a way that mode change due to re-compression can be closed within a group. Finally, each group is represented with two bits of watermark sequence and embedding have been done by altering prediction modes of selected 4 x 4 intra prediction block to the representative mode of the group denoted by the watermark bit pair. Experimental results on various test sequences show that the scheme is robust against re-compression with high QP values and robustness has been increased twice compared to existing intra prediction mode based watermarking schemes. Also, the proposed scheme has very low effect on the visual quality having least peak to signal ration of 28 dB for the watermarked test sequences and also has very similar bit increase rate compared to existing scheme.
C1 [Gaj, Sibaji; Sur, Arijit] IIT Guwahati, Multimedia Lab, Dept Comp Sci & Engn, Gauhati 781039, India.
   [Bora, Prabin Kumar] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Gaj, S (corresponding author), IIT Guwahati, Multimedia Lab, Dept Comp Sci & Engn, Gauhati 781039, India.
EM sibaji@iitg.ernet.in; arijit@iitg.ernet.in; prabin@iitg.ernet.in
RI Sur, Arijit/AAB-4216-2020; Gaj, Sibaji/AAE-8920-2022
OI Gaj, Sibaji/0000-0002-6997-5717
CR [Anonymous], 2016, PROC 8 IFIP INT C NE
   [Anonymous], 2013, VIDEO QUALITY MEASUR
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   Asim M, 2018, J SOFTW-EVOL PROC, V30, DOI 10.1002/smr.1944
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dutta T, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3002178
   El-Shafai W, 2019, MULTIMED TOOLS APPL, V78, P27211, DOI 10.1007/s11042-019-7448-0
   Gaj S, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3009910
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Joshi AM, 2018, 2018 IEEE 4TH INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2018), P58, DOI 10.1109/iSES.2018.00022
   Karam Y, 2012, UKSIM EURO SYMP COMP, P67, DOI 10.1109/EMS.2012.17
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Liu D, 2011, 2011 INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND NEURAL COMPUTING (FSNC 2011), VOL V, P71
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Song XG, 2014, MULTIMEDIA SYST, V20, P195, DOI 10.1007/s00530-012-0301-1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tariq N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081788
   Wang J, 2014, INT C COMP SCI SERV
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Zou DK, 2008, INT CONF ACOUST SPEE, P1749, DOI 10.1109/ICASSP.2008.4517968
NR 32
TC 12
Z9 12
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18089
EP 18119
DI 10.1007/s11042-019-08301-w
EA FEB 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000517016900001
DA 2024-07-18
ER

PT J
AU Huang, XF
   Li, D
   Yin, HB
AF Huang, Xiaofeng
   Li, Dong
   Yin, Haibing
TI HEVC quantization parameter selection algorithm based on inter-frame
   dependency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding; Rate-distortion optimization; Inter-frame
   dependency; Quantization parameter
ID RATE-DISTORTION OPTIMIZATION; BIT ALLOCATION; LAGRANGE MULTIPLIER;
   VIDEO; EFFICIENCY
AB Massive inter predictive modes are adopted in latest High Efficiency Video Coding (HEVC) standard to eliminate temporal redundancies, which results in stronger inter-frame dependency among neighboring frames than previous standards like H.264. The inter-frame dependency makes currently independent rate-distortion optimization (RDO) non-optimal any more. Quantization parameter (QP) selection algorithm taking inter-frame dependency into consideration is supposed to optimize RDO based rate control greatly. According to our research, the inter-frame dependency is reflected by the linear relationship between QP change (Delta QP) and the resulting change of distortion (Delta D). An adaptive QP selection algorithm for global RDO is proposed based on the modeling function between Delta D and Delta QP in this paper. Firstly, based on intensive statistic analysis, three parameters (initial QP (QP over bar \documentclass[12pt]{minimal} the length of pictures of group (GOP), and the average of SATD of one frame) are used to formulate the relationship between Delta D and Delta QP. Secondly, the resulting rate change Delta R relative to Delta QP is also formulated similarly. Thirdly, optimized Lagrangian multiplier (lambda) is calculated with these two mathematic models. Finally, we refine QP values based on the optimized lambda in terms of dependent RDO. The experimental results show that the proposed frame-level QP selection algorithm can decrease Bj circle divide tegaard Delta BitRate (BD-BR) by about 1.62% at the random-access (RA) configuration and 1.13% at the low-delay (LD) configuration, respectively. At the same time, it doesn't increase complexity significantly.
C1 [Huang, Xiaofeng; Li, Dong; Yin, Haibing] Hangzhou Dianzi Univ, 1158,2 St Hangzhou, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Yin, HB (corresponding author), Hangzhou Dianzi Univ, 1158,2 St Hangzhou, Hangzhou 310018, Peoples R China.
EM xfhuang@hdu.edu.cn; dongli_hdu@126.com; yhb@hdu.edu.cn
CR Bjotegaard G., 2001, VCEGM33
   BOSSEN F, 2013, 12 M
   Cho Y, 2013, IEEE T CIRC SYST VID, V23, P1003, DOI 10.1109/TCSVT.2013.2248215
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Gong YC, 2017, IEEE T CIRC SYST VID, V27, P1304, DOI 10.1109/TCSVT.2016.2539718
   Gong YC, 2016, SIGNAL PROCESS-IMAGE, V42, P1, DOI 10.1016/j.image.2016.01.006
   He J, 2018, IEEE T CIRC SYST VID, V28, P3424, DOI 10.1109/TCSVT.2017.2751519
   Hu SD, 2012, IEEE T IMAGE PROCESS, V21, P1911, DOI 10.1109/TIP.2011.2176347
   Hu SD, 2011, IEEE T CIRC SYST VID, V21, P1152, DOI 10.1109/TCSVT.2011.2138810
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li B, 2013, IEEE INT SYMP CIRC S, P477, DOI 10.1109/ISCAS.2013.6571884
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Li XA, 2009, IEEE IMAGE PROC, P3765, DOI 10.1109/ICIP.2009.5414354
   Liu JY, 2010, IEEE T CIRC SYST VID, V20, P967, DOI 10.1109/TCSVT.2010.2045924
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pang C, 2013, IEEE T CIRC SYST VID, V23, P990, DOI 10.1109/TCSVT.2013.2244795
   Seidel I, 2016, IEEE INT SYMP CIRC S, P802, DOI 10.1109/ISCAS.2016.7527362
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tianwu Yang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P85, DOI 10.1109/ICME.2012.171
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang Shumin, 2014, Biomed Res Int, V2014, P507353, DOI 10.1155/2014/507353
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiang Li, 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P4197, DOI 10.1109/ISCAS.2010.5537584
   Xu J., 2012, JCT-VC, document JCTVC-I0426
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zeng HQ, 2013, PICT COD SYMP, P69, DOI 10.1109/PCS.2013.6737685
   Zhao TS, 2016, IEEE T IMAGE PROCESS, V25, P2997, DOI 10.1109/TIP.2016.2556941
NR 29
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13951
EP 13966
DI 10.1007/s11042-020-08612-3
EA FEB 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515863700002
DA 2024-07-18
ER

PT J
AU Vaijayanthimala, J
   Padma, T
AF Vaijayanthimala, J.
   Padma, T.
TI RETRACTED: Multi-modal biometric authentication system based on face and
   signature using legion feature estimation technique (Retracted article.
   See MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE LFNN; Recognition; Significant pattern; Multi-modal biometric; Legion
   feature estimation technique
ID VERIFICATION
AB In biometrics, picking of the right methodology is a testing errand for recognition of a person. Due to the advantage of widely accepted identification, face, and signature-based biometric modality are selected as a significant pattern as compared with other modalities. Different Face and signature successions of a similar subject may contain varieties in determination, light, pose, facial appearances and sign position. These varieties add to the difficulties in planning a viable multimodal-based face and signature recognition algorithm. This paper proposed about the face and signature recognition method from a large dataset with the different pose and multiple features. Face recognition is the first stage of a system then the signature verification will be done. Here, data glove signaling means of signing process are taken into account to do signature verification system. Hence the proposed work have used Face, and the corresponding signature is detected from data glove signal patterns to features-level fusion for the verification system. The proposed Legion feature based verification method will be developed using four important steps like, i) Preprocessing, ii) feature extraction from face and data glove signals, iii) Legion feature based feature matching through Euclidean distance, iv) Legion feature Neural network (LFNN) fusion based on weighted summation formulae where two weights will be optimally found out using Legion optimization algorithm, vi) Recognition based on the final score. Finally, based on the feature library the face image and signature can be recognized. The comparability estimation is finished by utilizing least Euclidean separation fusion based LFNN to decide perceived and non-perceived images. Also, in a similar examination, a proposed strategy is compared with current technique by several performance metrics and the proposed LFNN technique efficiently recognize the face images and corresponding signature from the input databases than the existing technology.
C1 [Vaijayanthimala, J.] Dhirajlal Gandhi Coll Technol, Salem, India.
   [Padma, T.] Sona Coll Technol, Dept Comp Applicat, Salem, India.
C3 Sona College of Technology
RP Vaijayanthimala, J (corresponding author), Dhirajlal Gandhi Coll Technol, Salem, India.
EM vaijayanthimala87@rediffmail.com
OI Theagarajan, Padma/0000-0001-8213-5985
CR [Anonymous], IEEE P 17 INT C PATT
   [Anonymous], SIGNAL PROCESSING IN
   Biswas S, 2009, IEEE T PATTERN ANAL, V31, P884, DOI [10.1109/TPAMI.2008.135, 10.1109/TPAMI.2007.12.0830]
   Garcia-Salicetti S, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/964746
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gu YY, 2003, ENG MED BIOL SOC ANN, P13
   Kamel NS, 2008, INT J PATTERN RECOGN, V22, P431, DOI 10.1142/S0218001408006387
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   Lee LL, 1996, IEEE T PATTERN ANAL, V18, P643, DOI 10.1109/34.506415
   Nakanishi I, 2006, IEICE T FUND ELECTR, VE89A, P178, DOI 10.1093/ietfec/e89-a.1.178
   Ong TS, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND TECHNOLOGY, VOL II, PROCEEDINGS, P312, DOI 10.1109/ICCET.2009.128
   Rahmat Roushanak, 2009, IEEE S IND EL APPL I
   Samraj Andrews, 2010, Journal of Information Security, V1, P23, DOI 10.4236/jis.2010.11003
   Sayee BesarS., 2006, The 8th international Conference on Signal Processing, P3
   Sayeed Shohel, 2009, American Journal of Applied Sciences, V6, P233
   Sayeed Shohel, 2009, SIGNAL PROCESSING IN, V2, P1
   Sayeed Shohel, 2007, INT C INT ADV SYST
   SWAIN MJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390
   Tjahyadi R., 2007, P INT JOINT C ART IN
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yao JC, 2007, P ANN INT IEEE EMBS, P4576, DOI 10.1109/IEMBS.2007.4353358
NR 22
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4149
EP 4168
DI 10.1007/s11042-019-07871-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700059
DA 2024-07-18
ER

PT J
AU Wan, WB
   Wang, J
   Li, J
   Sun, JD
   Zhang, HX
   Liu, J
AF Wan, Wenbo
   Wang, Jun
   Li, Jing
   Sun, Jiande
   Zhang, Huaxiang
   Liu, Ju
TI Hybrid JND model-guided watermarking method for screen content images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Screen content images; Just noticeable distortion model; Watermarking
   robustness; STDM
ID QUALITY ASSESSMENT; PERCEPTUAL MODEL; COMPRESSION
AB With the prevalence of digital products like cellphone, tablet and personal computer, the screen content images (SCIs) consisting of text, graphic, and natural scene picture becomes a significant media in various communication scenarios. In this paper, we propose a novel Spread Transform Dither Modulation (STDM) watermarking scheme based on Hybrid just noticeable distortion model for screen content images. Firstly, the original image was transformed from RGB into YCrCb to ensure stability robustness and invisibility. Then, we proposed a novel automatic classification method based on AC coefficients feature. Different from pictorial block in screen content images, structural-based contrast masking effects was incorporated to adjust the just noticeable distortion value for textual blocks. Finally, the reference image from the SIQAD image database was used to evaluate the performance of our proposed scheme. Experiments showed that our method has a good performance in term of robustness with better visual quality.
C1 [Wan, Wenbo; Wang, Jun; Sun, Jiande; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Li, Jing] Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Peoples R China.
   [Liu, Ju] Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
C3 Shandong Normal University; Shandong Management University; Shandong
   University
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
EM wanwenbo@sdnu.edu.cn; jiandesun@sdnu.edu.cn; huaxzhang@l63.com;
   juliu@sdu.edu.cn
RI Zhang, Yuchen/GYI-8858-2022
CR Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Gu K, 2017, IEEE T VISUALIZATION
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Han L, 2017, IEEE INT CON MULTI, P139, DOI 10.1109/ICME.2017.8019479
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Li QO, 2007, INT CONF ACOUST SPEE, P185
   Li Q, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P98, DOI 10.1109/MMSP.2006.285276
   Li X, 2011, IET INFORM SECUR, V5, P170, DOI 10.1049/iet-ifs.2010.0218
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Lin T, 2013, IEEE T CIRC SYST VID, V23, P173, DOI 10.1109/TCSVT.2012.2223871
   Ma LH, 2010, IEICE T INF SYST, VE93D, P843, DOI 10.1587/transinf.E93.D.843
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Ni ZK, 2016, IEEE SIGNAL PROC LET, V23, P1394, DOI 10.1109/LSP.2016.2599294
   Pan ZT, 2013, IEEE T CIRC SYST VID, V23, P949, DOI 10.1109/TCSVT.2013.2243056
   Qi H, 2014, ELECTRON LETT, V50, P1435, DOI 10.1049/el.2014.1651
   Tong HHY, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P428, DOI 10.1109/ICIP.1998.999032
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Wan WB, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023002
   Wan WB, 2015, ELECTRON LETT, V51, P758, DOI 10.1049/el.2014.4329
   Wan WB, 2013, IEEE IMAGE PROC, P4522, DOI 10.1109/ICIP.2013.6738931
   Wang J, 2018, LECT NOTES COMPUT SC, V11066, P61, DOI 10.1007/978-3-030-00015-8_6
   Wang S, 2016, IEEE COMPUTER GRAPHI
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang H, 2012, IEEE INT WORKSH MULT, P77, DOI 10.1109/MMSP.2012.6343419
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
NR 38
TC 31
Z9 32
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4907
EP 4930
DI 10.1007/s11042-018-6860-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500037
DA 2024-07-18
ER

PT J
AU Zhe, S
   Peng, S
AF Zhe, Shen
   Peng, Sun
TI Authentication of splicing manipulation by exposing inconsistency in
   color shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image manipulation; Image authentication; Automated white balance; Color
   shift
ID CAMERA SYSTEM; ILLUMINATION
AB Splicing is one of the most common tampering techniques for image manipulation in many forensic cases. In this paper, a novel detection method which can expose splicing manipulation by discerning the inconsistencies of color shift in splicing images is presented. Color temperature varies dramatically in formation of different images due to photographic light sources, and always leads to color shift in an image, though it sometimes is imperceptible for human visualization. Therefore color shift can be taken as one kind of optical fingerprint of images for authentication. In this study, we proposed a color shift estimation based method to authenticate the presented images by localizing splicing manipulations automatically. These quantitative evidences contribute a lot to forensic investigators. This method comprises three steps: firstly it estimates the color shift of local partitions and the whole image; secondly exposes inconsistency in color shift by calculating distances between them as an indicator; and finally classifies these partitions into different classes by an optimized threshold. In our proposed method, color shift is estimated by using color constancy algorithm, which has been widely applied in cameras as AWB (automated white balance) to correct color shift in captured images. The following experiments exhibits the effectiveness of the proposed method with visual and quantitative evaluation.
C1 [Zhe, Shen] Shenyang Aerosp Univ, Civil Aviat Coll, Shenyang 110136, Liaoning, Peoples R China.
   [Zhe, Shen] Liaoning Shihua Univ, Sch Informat & Control Engn, Fushun 113001, Peoples R China.
   [Peng, Sun] Criminal Invest Police Univ China, Dept Criminal Sci & Tech, Shenyang 110035, Liaoning, Peoples R China.
C3 Shenyang Aerospace University; Liaoning Petrochemical University;
   Criminal Investigation Police University of China
RP Peng, S (corresponding author), Criminal Invest Police Univ China, Dept Criminal Sci & Tech, Shenyang 110035, Liaoning, Peoples R China.
EM angelzheshen@163.com; 6094079@qq.com
RI 沈, 沈喆/GSN-5587-2022
OI Sun, Peng/0000-0001-7543-9833
FU Natural National Science Foundation of China (NSFC) [61307016]; National
   Key RD Program [2017YFC0822204]; National Engineering Laboratory of
   Evidence Traceability Technology [2017NELKFKT09]
FX "This work was supported in part by Natural National Science Foundation
   of China (NSFC) (61307016). National Key R&D Program (2017YFC0822204).
   National Engineering Laboratory of Evidence Traceability Technology
   (2017NELKFKT09)."
CR Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Farid H, 2010, PROC SPIE, V7541, DOI 10.1117/12.837788
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gao SB, 2017, J OPT SOC AM A, V34, P1448, DOI 10.1364/JOSAA.34.001448
   Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219
   Huo JY, 2006, IEEE T CONSUM ELECTR, V52, P541, DOI 10.1109/TCE.2006.1649677
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Kee E., 2012, ACM T GRAPHIC, V32, P1, DOI [DOI 10.1145/2487228.2487236, 10.1145/2487228.2487236]
   Kee E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629646
   Lee JS, 2001, IEEE T CONSUM ELECTR, V47, P694, DOI 10.1109/30.964165
   Lee MH, 2009, OPT LETT, V34, P2664, DOI 10.1364/OL.34.002664
   Li CJ, 2016, OPT EXPRESS, V24, P14066, DOI 10.1364/OE.24.014066
   Nakano N, 1998, IEEE T CONSUM ELECTR, V44, P581, DOI 10.1109/30.713166
   Ng Tian-Tsong., Columbia Image Splicing Detection Evaluation Dataset
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sun P, 2018, FORENSIC SCI INT, V289, P1, DOI 10.1016/j.forsciint.2018.04.049
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xiao QK, 2014, MULTIMED TOOLS APPL, V72, P951, DOI 10.1007/s11042-013-1416-x
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1219, DOI 10.1109/TIP.2016.2516953
   [周荣政 Zhou Rongzheng], 2005, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V17, P529
NR 26
TC 1
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8235
EP 8248
DI 10.1007/s11042-019-08565-2
EA JAN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356500002
DA 2024-07-18
ER

PT J
AU Fourati, E
   Elloumi, W
   Chetouani, A
AF Fourati, Emna
   Elloumi, Wael
   Chetouani, Aladine
TI Anti-spoofing in face recognition-based biometric authentication using
   Image Quality Assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Anti-spoofing; Face recognition;
   Authentication
ID STATISTICS
AB Despite the rapid growth of face recognition-based biometrics for both authentication and identification, the security of face biometric systems against presentation attacks (also called spoofing attacks) remains a great concern. Indeed, Face recognition-based authentication techniques can be easily spoofed using various types of attacks such photographs, videos or forged 3D masks. This work proposes a fast and non-intrusive anti-spoofing solution based on Image Quality Assessment (IQA) and motion cues to distinguish between genuine and fake face-appearances. Quality measures are computed following a novel approach which enables us to highlight these liveness-related motion cues, thus outlining the distinction between real faces and spoofing attacks. Moreover, our method is well suited for real-time mobile applications as it takes into consideration both reliable robustness and low complexity of employed algorithms. Our approach is extensively evaluated on three public databases that include different types of presentation attacks. The obtained results proved to outperform state-of-the-art approaches.
C1 [Fourati, Emna; Elloumi, Wael] Worldline, 19 Rue Vallee Maillard, Blois, France.
   [Chetouani, Aladine] Univ Orleans, Lab PRISME, 12 Rue Blois, Orleans, France.
C3 Universite de Orleans
RP Elloumi, W (corresponding author), Worldline, 19 Rue Vallee Maillard, Blois, France.
EM emna.fourati@worldline.com; wael.elloumi@worldline.com;
   aladine.chetouani@univ-orleans.fr
RI Bueno, Regis Cortez/AAG-3852-2020; chetouani, aladine/AAB-3086-2020
OI Bueno, Regis Cortez/0000-0002-2923-4930; chetouani,
   aladine/0000-0002-2066-4707
CR Akhtar Z, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/4721849
   Anjos A, 2014, ADV COMPUT VIS PATT, P65, DOI 10.1007/978-1-4471-6524-8_4
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], 2016 IEEE 8 INT C BI
   [Anonymous], BRISQUE SOFTWARE REL
   [Anonymous], P INT C BIOM SPEC IN
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2015, PROC E HLTH BIOENG C
   [Anonymous], IMAGE VISION COMPUTI
   [Anonymous], J VIS
   [Anonymous], 2013, I W BIOMETRIC FORENS
   [Anonymous], 6 INT C BIOM THEOR A
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Cheng HT, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P542
   Chingovska Ivana, 2012, BIOSIG
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Fourati E., 2017, 2017 2 INT C BIOENGI, P1
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Hastie T., 2009, The Elements of Statistical Learning
   Jee H., 2008, Int. J. Comput. Inform. Eng., V2, P2142
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Kundu D, 2016, CONF REC ASILOMAR C, P1847, DOI 10.1109/ACSSC.2016.7869704
   Lee PH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P847
   Li LN, 2016, CELL BIOSCI, V6, DOI 10.1186/s13578-016-0090-x
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lucena Oeslle, 2017, Image Analysis and Recognition. 14th International Conference, ICIAR 2017. Proceedings: LNCS 10317, P27, DOI 10.1007/978-3-319-59876-5_4
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Melnikov A, 2015, LECT NOTES COMPUT SC, V9280, P643, DOI 10.1007/978-3-319-23234-8_59
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, CONF REC ASILOMAR C, P1718, DOI 10.1109/ACSSC.2012.6489326
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal Anish., 2012, Niqe software release
   Moorthy A., 2009, BIQI software release
   Moorthy A. K., 2009, IEEE Signal Process. Lett, V17, P7
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ng ES, 2012, INT C PATT RECOG, P1249
   Pan G., 2008, Recent advances in face recognition
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Rehman YAU, 2018, EXPERT SYST APPL, V108, P159, DOI 10.1016/j.eswa.2018.05.004
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Söllinger D, 2018, IET BIOMETRICS, V7, P314, DOI 10.1049/iet-bmt.2017.0146
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang T. M., 2013, ADV DIFFER EQU-NY, V2013, P1, DOI DOI 10.1371/J0URNAL.P0NE.0058952
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 49
TC 25
Z9 26
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 865
EP 889
DI 10.1007/s11042-019-08115-w
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600036
DA 2024-07-18
ER

PT J
AU Madhusudhan, R
   Shashidhara, R
AF Madhusudhan, R.
   Shashidhara, R.
TI A novel DNA based password authentication system for global roaming in
   resource-limited mobile environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; DNA cryptography; User anonymity; Global roaming;
   Security; Smart-card
ID SECURE AUTHENTICATION; USER ANONYMITY; SMART CARDS; SCHEME; SERVICE;
   EFFICIENT; ENCRYPTION; PROTOCOL
AB Mobile environments are highly vulnerable to security threats and pose a great challenge for the wireless and mobile networks being used today. Because the mode of a wireless channel is open, these networks do not carry any inherent security and hence are more prone to attacks. Therefore, designing a secure and robust protocol for authentication in a global mobile network is always a challenging. In these networks, it is crucial to provide authentication to establish a secure communication between the Mobile User (MU), Foreign Agent (FA) and Home Agent (HA). In order to secure communication among these entities, a number of authentication protocols have been proposed. The main security flaw of the existing authentication protocols is that attackers have the ability to impersonate a legal user at any time. Moreover, the existing authentication protocols in the literature are exposed to various kind of cryptographic attacks. Besides, the authentication protocols require larger key length and more computation overhead. To remedy these weaknesses in mobility networks, DNA (Deoxyribo Nucleic Acid) based authentication scheme using Hyper Elliptic Curve Cryptosystem (HECC) is introduced. It offers greater security and allows an MU, FA and HA to establish a secure communication channel, in order to exchange the sensitive information over the radio link. The proposed system derive benefit from HECC, which is smaller in terms of key size, more computational efficiency. In addition, the security strength of this authentication system is validated through widely accepted security verification tool called ProVerif. Further, the performance analysis shows that the DNA based authentication system using HECC is secure and practically implementable in the resource-constrained mobility nodes.
C1 [Madhusudhan, R.] Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal 575025, India.
   [Shashidhara, R.] Bennett Univ, Sch Engn & Appl Sci, Greater Noida 201310, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Madhusudhan, R (corresponding author), Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal 575025, India.
EM madhurk96@gmail.com; shashidhar@bennett.edu.in
CR Abadi M, 2009, LECT NOTES COMPUT SC, V5643, P35, DOI 10.1007/978-3-642-02658-4_5
   Adleman LM, 1998, SCI AM, V279, P54, DOI 10.1038/scientificamerican0898-54
   Ahmed Kareem, 2017, International Journal of Computers and Applications, V39, P91, DOI 10.1080/1206212X.2017.1289690
   Arshad H, 2017, INT J COMMUNICATION
   Chang CC, 2009, COMPUT COMMUN, V32, P611, DOI 10.1016/j.comcom.2008.11.032
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   EZZIANE Z, 2005, NANOTECHNOLOGY, V17, P27
   Fadell A, 2015, Google Patents. US Patent, Patent No. [9,134,896, 9134896]
   Gope P, 2016, IEEE SYST J, V10, P1370, DOI 10.1109/JSYST.2015.2416396
   Gupta A, 2010, INT J PHARM SCI RES, V1, P19, DOI 10.13040/IJPSR.0975-8232.1(6).19-26
   Ha J, 2015, INT J SECUR APPL, V9, P297
   He DJ, 2011, COMPUT COMMUN, V34, P367, DOI 10.1016/j.comcom.2010.02.031
   Huh JH, 2019, J SUPERCOMPUT, V75, P1831, DOI 10.1007/s11227-018-2342-5
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Jemimah J, 2018, 2018 4 INT C ADV EL, P1
   Jeon W, 2013, INT J SECUR APPL, V7, P1
   Jiang Q, 2013, WIRELESS PERS COMMUN, V68, P1477, DOI 10.1007/s11277-012-0535-4
   Karuppiah M, 2017, WIRELESS PERS COMMUN, V93, P383, DOI 10.1007/s11277-016-3672-3
   Karuppiah M, 2015, WIRELESS PERS COMMUN, V84, P2055, DOI 10.1007/s11277-015-2524-x
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   KOBLITZ N, 1990, LECT NOTES COMPUT SC, V403, P94
   Krishna BM, 2016, INT J ENG TECHNOLOGY
   Kumari S, 2014, SECUR COMMUN NETW, V7, P2039, DOI 10.1002/sec.916
   Kuo WC, 2014, J INF SECUR APPL, V19, P18, DOI 10.1016/j.jisa.2013.12.002
   Lai XJ, 2010, SCI CHINA INFORM SCI, V53, P506, DOI 10.1007/s11432-010-0063-3
   Lee CC, 2006, IEEE T IND ELECTRON, V53, P1683, DOI 10.1109/TIE.2006.881998
   Lee CC, 2017, WIRELESS PERS COMMUN, V94, P1281, DOI 10.1007/s11277-016-3682-1
   Madhusudhan R, 2018, J INF SECUR APPL, V38, P96, DOI 10.1016/j.jisa.2017.12.002
   Madhusudhan R., 2019, PEER PEER NETW APPL, V5, P1
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Misbahuddin M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P595, DOI 10.1145/2791405.2791503
   Mun H, 2012, MATH COMPUT MODEL, V55, P214, DOI 10.1016/j.mcm.2011.04.036
   Pelzl J, 2003, LECT NOTES COMPUT SC, V2779, P351, DOI 10.1007/978-3-540-45238-6_28
   Raju P.V.S.N., 2014, P 3 INT C FRONT INT, P29
   Rakesh T, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P118, DOI 10.1109/NGCT.2016.7877401
   UbaidurRahman NH, 2015, PROCEDIA COMPUT SCI, V46, P463, DOI 10.1016/j.procs.2015.02.045
   Vijayakumar P., 2013, International Journal on Network Security, V4, P1
   Wang X, 2009, PROTEOMICS, V9, P242, DOI 10.1002/pmic.200800155
   Wu CC, 2008, IEEE COMMUN LETT, V12, P722, DOI 10.1109/LCOMM.2008.080283
   Wu F, 2017, ANN TELECOMMUN, V72, P131, DOI 10.1007/s12243-016-0547-2
   Wu F, 2016, SECUR COMMUN NETW, V9, P3527, DOI 10.1002/sec.1558
   Xu GQ, 2018, J NETW COMPUT APPL, V107, P83, DOI 10.1016/j.jnca.2018.02.003
   Zhao DW, 2014, WIRELESS PERS COMMUN, V78, P247, DOI 10.1007/s11277-014-1750-y
   Zhu JM, 2004, IEEE T CONSUM ELECTR, V50, P231, DOI 10.1109/TCE.2004.1277867
NR 46
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2185
EP 2212
DI 10.1007/s11042-019-08349-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000022
DA 2024-07-18
ER

PT J
AU Elakkiya, E
   Selvakumar, S
AF Elakkiya, E.
   Selvakumar, S.
TI GAMEFEST: Genetic Algorithmic Multi Evaluation measure based FEature
   Selection Technique for social network spam detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Genetic algorithm; Spam detection; Multi evaluation
   measure
ID FEATURE SUBSET-SELECTION; INFORMATION GAIN; MUTUAL INFORMATION;
   CLASSIFICATION; OPTIMIZATION; RELEVANCE
AB Social Network sites have become incredibly important in the present day. This popularity attracts the attacker to easily approach a large population and to have access to massive information for performing intrusion activities in Online Social Networks (OSN) including spamming. Spammers not only spread unsolicited messages but also perform malicious activities that harm the user's financial or personal life and tarnish the reputation of social network platforms. Efficient spam detection requires the selection of relevant features to portray spammer behavior. Most of the existing feature selection techniques use any one of the evaluation measures such as, distance, dependence, consistency, information, and classifier error rate. The feature selection techniques select features from different perspectives based on the evaluation measures. Each evaluation measure produces different subset, and the detection rate differs accordingly. The majority of the existing works focus on the individual feature ranking, and discard the lowest weight feature. Lowest weight feature may produce more accurate prediction if, it is combined with other features. So, there is a need for the feature selection technique that considers the characteristics of all the evaluation measures to produce the appropriate subset, which increases the spam detection rate and assigns a weight for the combination of features. In regard to this, the paper proposes a new multi evaluation measure combined with feature subset selection based on the genetic algorithm, GAMEFEST. The performance of the proposed work has been evaluated using Twitter, Apontador, and YouTube datasets. Experimental results prove that our proposed GAMEFEST with Minimum Surplus Crossover (MSC) improves the efficiency of the learning process and increases the spam detection rate.
C1 [Elakkiya, E.; Selvakumar, S.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
   [Selvakumar, S.] Indian Inst Informat Technol, Una, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Elakkiya, E (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM 406115004@nitt.edu; ssk@nitt.edu
RI e, e/KBQ-8355-2024; E, Elakkiya/ABD-6973-2021; Subramanian,
   Selvakumar/ABB-3963-2021
OI E, Elakkiya/0000-0001-6175-762X; Subramanian,
   Selvakumar/0000-0002-4900-4745
CR Ahmed F, 2013, COMPUT COMMUN, V36, P1120, DOI 10.1016/j.comcom.2013.04.004
   Ahn CW, 2002, IEEE T EVOLUT COMPUT, V6, P566, DOI 10.1109/TEVC.2002.804323
   [Anonymous], P 28 ANN ACM S APPL
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Benevenuto F, 2012, IEEE T SYST MAN CY B, V42, P688, DOI 10.1109/TSMCB.2011.2173799
   Benevenuto Fabricio., 2010, CEAS
   Bermejo P, 2014, KNOWL-BASED SYST, V55, P140, DOI 10.1016/j.knosys.2013.10.016
   BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680
   Cadenas JM, 2013, EXPERT SYST APPL, V40, P6241, DOI 10.1016/j.eswa.2013.05.051
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chormunge S., 2018, J ELECT SYST INF TEC, V5, P542, DOI [DOI 10.1016/J.JESIT.2017.06.004, 10.1016/j.jesit.2017.06.004]
   Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005
   Costa H, 2014, INFORM SCIENCES, V279, P123, DOI 10.1016/j.ins.2014.03.108
   Covoes TF, 2011, INFORM SCIENCES, V181, P3766, DOI 10.1016/j.ins.2011.04.050
   Dai JH, 2013, APPL SOFT COMPUT, V13, P211, DOI 10.1016/j.asoc.2012.07.029
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   DASH M, 2000, P 4 PAC AS C KNOWL D, P98
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Fonseca C.M, 2011, MULTIOBJECTIVE GENET, P25, DOI [10.1007/978-3-642-16615-0_2, DOI 10.1007/978-3-642-16615-0_2]
   Ghosh S., 2012, P INT C WORLD WID WE, P61
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hall M., 2000, THESIS
   Hancer E, 2018, KNOWL-BASED SYST, V140, P103, DOI 10.1016/j.knosys.2017.10.028
   Jaganathan P, 2013, COMPUT BIOL MED, V43, P2222, DOI 10.1016/j.compbiomed.2013.10.016
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Liu MX, 2016, NEUROCOMPUTING, V215, P100, DOI 10.1016/j.neucom.2015.07.155
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Nogueira S., 2016, Joint European Conference on Machine Learning and Knowledge Discovery in Databases, P442, DOI [10.1007/978-3-319-46227-1_28, DOI 10.1007/978-3-319-46227-1_28]
   Padungweang P, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P196, DOI 10.1109/APCIP.2009.185
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rahnamayan S, 2007, COMPUT MATH APPL, V53, P1605, DOI 10.1016/j.camwa.2006.07.013
   Raileanu LE, 2004, ANN MATH ARTIF INTEL, V41, P77, DOI 10.1023/B:AMAI.0000018580.96245.c6
   Schwämmle V, 2010, BIOINFORMATICS, V26, P2841, DOI 10.1093/bioinformatics/btq534
   Selvakumar B, 2019, COMPUT SECUR, V81, P148, DOI 10.1016/j.cose.2018.11.005
   Shang XG, 1997, PATTERN RECOGN LETT, V18, P425, DOI 10.1016/S0167-8655(97)00028-7
   Song QB, 2013, IEEE T KNOWL DATA EN, V25, P1, DOI 10.1109/TKDE.2011.181
   Thaseen IS, 2016, PROCEEDINGS OF 2016 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang YT, 2017, PATTERN RECOGN, V61, P511, DOI 10.1016/j.patcog.2016.08.011
   Wang YW, 2018, EXPERT SYST APPL, V102, P83, DOI 10.1016/j.eswa.2018.01.041
   Witten IH, 2011, MOR KAUF D, P1
   Wu KL, 2012, PATTERN RECOGN, V45, P407, DOI 10.1016/j.patcog.2011.07.012
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091
   Zhang YS, 2013, NEUROCOMPUTING, V101, P32, DOI 10.1016/j.neucom.2012.06.036
   Zhang YS, 2012, EXPERT SYST APPL, V39, P6078, DOI 10.1016/j.eswa.2011.12.003
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
NR 52
TC 6
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7193
EP 7225
DI 10.1007/s11042-019-08334-1
EA DEC 2019
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664300006
DA 2024-07-18
ER

PT J
AU Ling, HF
   Wu, JY
   Huang, JR
   Chen, JZ
   Li, P
AF Ling, Hefei
   Wu, Jiyang
   Huang, Junrui
   Chen, Jiazhong
   Li, Ping
TI Attention-based convolutional neural network for deep face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminative feature embedding; Attention-based CNN; Channel attention
   block; Spatial attention block
ID REPRESENTATION
AB Discriminative feature embedding is of essential importance in the field of large scale face recognition. In this paper, we propose an attention-based convolutional neural network (ACNN) for discriminative face feature embedding, which aims to decrease the information redundancy among channels and focus on the most informative components of spatial feature maps. More specifically, the proposed attention module consists of a channel attention block and a spatial attention block which adaptively aggregate the feature maps in both channel and spatial domains to learn the inter-channel relationship matrix and the inter-spatial relationship matrix, then matrix multiplications are conducted for a refined and robust face feature. With the attention module we proposed, we can make standard convolutional neural networks (CNNs), such as ResNet-50, ResNet-101 have more discriminative power for deep face recognition. The experiments on Labelled Faces in the Wild (LFW), Age Database (AgeDB), Celebrities in Frontal Profile (CFP) and MegaFace Challenge 1 (MF1) show that our proposed ACNN architecture consistently outperforms naive CNNs and achieves the state-of-the-art performance.
C1 [Ling, Hefei; Wu, Jiyang; Huang, Junrui; Chen, Jiazhong; Li, Ping] Huazhong Univ Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Wuhan, Hubei, Peoples R China.
EM lhefei@163.com
OI Ling, Hefei/0000-0001-6797-7412
FU Natural Science Foundation of China [U1536203, 61972169]; National key
   research and development program of China [2016QY01W0200]; Major
   Scientific and Technological Project of Hubei Province [2018AAA068,
   2019AAA051]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203 and 61972169, in part by the National key
   research and development program of China (2016QY01W0200), in part by
   the Major Scientific and Technological Project of Hubei Province
   (2018AAA068 and 2019AAA051).
CR [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00482
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng EJ, 2019, PATTERN RECOGN LETT, V125, P71, DOI 10.1016/j.patrec.2019.03.006
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251
   Feng WJ, 2018, IEEE MTT S INT MICR, P12, DOI 10.1109/MWSYM.2018.8439265
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao Y, 2019, PROC CVPR IEEE, P3200, DOI 10.1109/CVPR.2019.00332
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G.B., 2014, LABELED FACES WILD U
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lei J, 2019, MULTIMED TOOLS APPL, V78, P27703, DOI 10.1007/s11042-019-07892-8
   Ling HF, 2019, IEEE ACCESS, V7, P55159, DOI 10.1109/ACCESS.2019.2913205
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu J., 2015, ARXIV150607310
   Liu W, 2018, P 32 INT C NEUR INF, P6225
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424
   Santurkar S, 2018, ADV NEUR IN, V31
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang L., 2019, IEEE Transactions on Cybernetics
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Xiaobo, 2018, ARXIV181211317
   Wei Zhou, 2019, IEEE T IMAGE PROCESS
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu L, 2019, IEEE ACCESS, V7, P36489, DOI 10.1109/ACCESS.2019.2900489
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   YANG JL, 2017, PROC CVPR IEEE, P5216, DOI DOI 10.1109/CVPR.2017.554
   Yi Dong, 2014, ARXIV14117923
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 56
TC 50
Z9 52
U1 2
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5595
EP 5616
DI 10.1007/s11042-019-08422-2
EA DEC 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000500863600002
DA 2024-07-18
ER

PT J
AU Yang, LR
   Men, M
   Xue, YM
   Zhong, P
AF Yang, Liran
   Men, Min
   Xue, Yiming
   Zhong, Ping
TI Low-rank representation-based regularized subspace learning method for
   unsupervised domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Subspace learning; Low-rank representation;
   Regularization; Robust
ID ALGORITHM; KERNEL
AB The conventional classification models implicitly assume that the distributions of data employed for training and test are identical. However, the assumption is rarely valid in many practical applications. In order to alleviate the difference between the distributions of the training and test sets, in this paper, we propose a regularized subspace learning framework based on the low-rank representation technique for unsupervised domain adaptation. Specifically, we introduce a regularization term of the subspace projection matrix to deal with the ill-conditioned problem and obtain a unique numerical solution. Meanwhile, we impose a structured sparsity-inducing regularizer on the error term so that the proposed method can filter out the outlier information, and therefore improve the performance. The extensive comparison experiments on benchmark data sets demonstrate the effectiveness of the proposed method.
C1 [Yang, Liran; Xue, Yiming] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Men, Min; Zhong, Ping] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
C3 China Agricultural University; China Agricultural University
RP Zhong, P (corresponding author), China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
EM zping@cau.edu.cn
FU National Natural Science Foundation of China [61872368]
FX The work is supported by the National Natural Science Foundation of
   China (Grant No. 61872368). The authors also gratefully acknowledge the
   helpful comments and suggestions of the reviewers, which have improved
   the presentation.
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2013, P ACM ICML FEB
   [Anonymous], 2014, ABS14123474 CORR
   [Anonymous], 2017, P IEEE C COMPUTER VI
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2014, P 31 INT C INT C MAC
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Cai D., 2007, PROC IEEE 11 INT C C
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen YM, 2019, IEEE T CYBERNETICS, V49, P1909, DOI 10.1109/TCYB.2018.2816981
   Ding ZM, 2018, IEEE T IMAGE PROCESS, V27, P5214, DOI 10.1109/TIP.2018.2851067
   Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92
   Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Finn C, 2017, PR MACH LEARN RES, V70
   Genç A, 2019, MULTIMED TOOLS APPL, V78, P5843, DOI 10.1007/s11042-018-6409-3
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hu JL, 2016, IEEE T IMAGE PROCESS, V25, P5576, DOI 10.1109/TIP.2016.2612827
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Kan MN, 2014, INT J COMPUT VISION, V109, P94, DOI 10.1007/s11263-013-0693-1
   Li JJ, 2017, IEEE T CIRC SYST VID, V27, P1700, DOI 10.1109/TCSVT.2016.2539541
   Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu L, 2018, KNOWL-BASED SYST, V156, P43, DOI 10.1016/j.knosys.2018.05.011
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Mozafari AS, 2016, PATTERN RECOGN, V56, P142, DOI 10.1016/j.patcog.2016.03.009
   Nuricumbo JR, 2016, MULTIMED TOOLS APPL, V75, P6829, DOI 10.1007/s11042-015-2612-7
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pereira LAM, 2018, PATTERN RECOGN, V75, P235, DOI 10.1016/j.patcog.2017.04.011
   Razzaghi P, 2019, KNOWL-BASED SYST, V163, P174, DOI 10.1016/j.knosys.2018.08.026
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Uzair M, 2017, IEEE T CYBERNETICS, V47, P651, DOI 10.1109/TCYB.2016.2523538
   Wang XG, 2018, KNOWL-BASED SYST, V156, P100, DOI 10.1016/j.knosys.2018.05.023
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yan K, 2018, IEEE T CYBERNETICS, V48, P288, DOI 10.1109/TCYB.2016.2633306
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Zhang L, 2019, IEEE T CIRC SYST VID, V29, P1339, DOI 10.1109/TCSVT.2018.2842206
NR 48
TC 7
Z9 7
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 3031
EP 3047
DI 10.1007/s11042-019-08474-4
EA DEC 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500863700003
DA 2024-07-18
ER

PT J
AU Khan, MH
   Farid, MS
   Grzegorzek, M
AF Khan, Muhammad Hassan
   Farid, Muhammad Shahid
   Grzegorzek, Marcin
TI A generic codebook based approach for gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Codebook; Spatiotemporal features; Fisher vector
   encoding; Feature evaluation
ID SHAPE; EXTRACTION; FEATURES; VIDEO; CLASSIFICATION; IDENTIFICATION;
   HISTOGRAMS; FLOW
AB Gait refers to the walking style of a person and it has emerged as an important biometric feature for person identification. The gait recognition algorithms proposed in literature exploit various types of information from the gait video sequence, such as, the skeletal data, human body shape, and silhouettes; and use these features to recognize the individuals. This paper presents the proposal of using a generic codebook in gait recognition. The idea is built upon a novel gait representation which exploits the spatiotemporal motion characteristics of the individual for identification. In particular, we propose to use a set of sample gait sequences to construct a generic codebook and use it to build a gait signature for person identification. To this end, we chose synthetic gait sequences of CMU MoCap gait database due to its diversity in walking styles. A set of spatiotemporal features are extracted from these sequences to build a generic codebook. The motion descriptors of real gait sequences are encoded using this generic codebook and Fisher vector encoding; the classification is performed using support vector machine. An extensive evaluation of this novel proposal is carried out using five benchmark gait databases: NLPR, CMU MoBo, TUM GAID, CASIA-B, and CASISA-C. In all experiments, the generic codebook is used in feature encoding. The performance of the proposed algorithm is also compared with the state-of-the-art gait recognition techniques and the results show that the idea of using a generic codebook in gait recognition is practical and effective.
C1 [Khan, Muhammad Hassan] Univ Siegen, Res Grp Pattern Recognit, Siegen, Germany.
   [Khan, Muhammad Hassan; Farid, Muhammad Shahid] Univ Punjab, Punjab Univ Coll Informat Technol, Punjab, Pakistan.
   [Grzegorzek, Marcin] Univ Lubeck, Inst Med Informat, Lubeck, Germany.
C3 Universitat Siegen; University of Punjab; University of Lubeck
RP Khan, MH (corresponding author), Univ Siegen, Res Grp Pattern Recognit, Siegen, Germany.; Khan, MH (corresponding author), Univ Punjab, Punjab Univ Coll Informat Technol, Punjab, Pakistan.
EM hassan.khan@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021; Farid, Muhammad Shahid/AAF-1825-2019;
   Khan, Muhammad Hassan/AAK-2021-2021
OI Farid, Muhammad Shahid/0000-0002-8384-2830; Khan, Muhammad
   Hassan/0000-0002-6145-5848; Grzegorzek, Marcin/0000-0003-4877-8287
CR [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], GAIT RECOGNITION USI
   [Anonymous], HUMAN ACTIVITY ANAL
   [Anonymous], P IM VIS COMP NZ CIT
   [Anonymous], IM VIS COMP C IM VIS
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], P INT C IM PROC ICIP
   [Anonymous], 2001, CMU MOTION BODY MOBO
   Anzai Y., 2012, Pattern recognition machine learning
   Bashir K., 2008, BMVC, P1
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Castro FM, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S021800141756002X
   Chai YM, 2006, INT C PATT RECOG, P425
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Chen S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1375
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   Dadashi F, 2009, 2 INT C IMAGE SIGNAL, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Goffredo M, 2008, IEEE INT C BIOMETRIC, P1
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P399, DOI 10.1109/BTAS.2012.6374606
   Hu MD, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413500171
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Khan MH, 2019, SIGNAL IMAGE VIDEO P, V13, P369, DOI 10.1007/s11760-018-1365-y
   Khan MH, 2018, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2018.8451629
   Khan MH, 2018, INT J MED INFORM, V113, P85, DOI 10.1016/j.ijmedinf.2018.02.010
   Khan MH, 2017, IEEE IMAGE PROC, P166, DOI 10.1109/ICIP.2017.8296264
   Khan MH, 2016, IEEE IMAGE PROC, P1235, DOI 10.1109/ICIP.2016.7532555
   Khan MSA, 2018, INT J INTELL SYST, V33, P1689, DOI 10.1002/int.21992
   Kusakunniran Worapan, 2014, Image and Vision Computing, V32, P1117, DOI 10.1016/j.imavis.2014.10.004
   Kusakunniran Worapan, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P17, DOI 10.1109/AVSS.2011.6027286
   Kusakunniran W, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P49, DOI 10.1109/AVSS.2009.44
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee H, 2008, INT J IMAG SYST TECH, V18, P237, DOI 10.1002/ima.20136
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liang JM, 2006, LECT NOTES COMPUT SC, V4221, P371
   Loula F, 2005, J EXP PSYCHOL HUMAN, V31, P210, DOI 10.1037/0096-1523.31.1.210
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu JW, 2006, LECT NOTES COMPUT SC, V3972, P232
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Castro FM, 2017, LECT NOTES COMPUT SC, V10306, P257, DOI 10.1007/978-3-319-59147-6_23
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rokanujjaman M, 2015, MULTIMED TOOLS APPL, V74, P3099, DOI 10.1007/s11042-013-1770-8
   Samangooei S, 2010, MULTIMED TOOLS APPL, V49, P195, DOI 10.1007/s11042-009-0391-8
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shaikh SH, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P101, DOI 10.1109/SPIN.2014.6776930
   Sivapalan S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P355, DOI 10.1109/AVSS.2011.6027350
   Su H, 2006, LECT NOTES COMPUT SC, V3972, P238
   Sun C, 2013, IEEE WORK APP COMP, P15, DOI 10.1109/WACV.2013.6474994
   Tan D, 2007, PROC IEEE COMPUT SOC, P1
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P673
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P222
   Tan DL, 2006, INT C PATT RECOG, P1000
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Veeraraghavan A, 2004, PROC CVPR IEEE, P730
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Whytock T, 2014, J MATH IMAGING VIS, V50, P314, DOI 10.1007/s10851-014-0501-8
   Yam C., 2009, Enclycopedia of Biometrics, P633, DOI DOI 10.1007/978-0-387-73003-5_37
   Yang YZ, 2014, INT C PATT RECOG, P444, DOI 10.1109/ICPR.2014.85
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zeng W, 2014, PATTERN RECOGN, V47, P3568, DOI 10.1016/j.patcog.2014.04.014
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
NR 82
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35689
EP 35712
DI 10.1007/s11042-019-08007-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800065
DA 2024-07-18
ER

PT J
AU Okada, K
   Yoshida, M
   Itoh, T
   Czauderna, T
   Stephens, K
AF Okada, Kaya
   Yoshida, Mitsuo
   Itoh, Takayuki
   Czauderna, Tobias
   Stephens, Kingsley
TI VR system for spatio-temporal visualization of tweet data and support of
   map exploration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal visualization; Virtual reality; Social media; Tweet data;
   Immersive visualization; Route recommendation
AB Social media analysis is helpful to understand the behavior of people. Human behavior in social media is related to time and location, which is often difficult to find the characteristics appropriately and quickly. We chose to apply virtual reality (VR) technologies to present the spatio-temporal social media data. This makes us easier to develop interactive and intuitive user interfaces and explore the data as we want. This paper proposes a VR system featuring two visualization techniques. One of the techniques is a three-dimensional temporal visualization of tweets of microblogs with location information. It consists of the two-dimensional map and a time axis. In particular, we aggregate the number of tweets of each coordinate and time step and depict them as piled cubes. We highlight only specific cubes so that users can understand the overall tendency of datasets. The other technique provides a route recommendation based on tweets of microblogs. Our technique supports users to explore attractive events and places by selecting effective tweets and suggesting routes. We also developed user interfaces for operating these objects in a VR space which indicate details of tweets.
C1 [Okada, Kaya] Ochanomizu Univ, Dept Adv Sci, Tokyo, Japan.
   [Itoh, Takayuki] Ochanomizu Univ, Dept Informat Sci, Tokyo, Japan.
   [Yoshida, Mitsuo] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.
   [Czauderna, Tobias] Monash Univ, Fac Informat Technol, Clayton, Vic, Australia.
   [Stephens, Kingsley] Monash Univ, Clayton, Vic, Australia.
C3 Ochanomizu University; Ochanomizu University; Toyohashi University of
   Technology; Monash University; Monash University
RP Okada, K (corresponding author), Ochanomizu Univ, Dept Adv Sci, Tokyo, Japan.
EM kaya@itolab.is.ocha.ac.jp; yoshida@cs.tut.ac.jp; itot@is.ocha.ac.jp;
   tobias.czauderna@monash.edu; kingsley.stephens@monash.edu
RI Yoshida, Mitsuo/Q-9156-2016
OI Yoshida, Mitsuo/0000-0002-0735-1116; Okada, Kaya/0000-0002-2552-0163;
   Czauderna, Tobias/0000-0002-1788-9593
FU Japan Society of the Promotion of Science
FX This work has been partially supported by Japan Society of the Promotion
   of Science under Grant-in-Aid for Scientific Research.
CR [Anonymous], 2014, EUR C VIS
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Chandler T, 2015, IEEE INT S BIG DAT V
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Febretti A., 2013, P IS T SPIE ELECT IM, V8649, P864
   Fu K., 2014, P 22 ACM SIGSPATIAL, P557, DOI [DOI 10.1145/2666310, 10.1145/2666310]
   Fukada Hidemi, 2013, SOC TOURISM INFORM, V8, P51
   Gil-Gómez JA, 2013, INT CONF PER COMP, P335, DOI 10.4108/icst.pervasivehealth.2013.252216
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Moravejosharieh A, 2016, INT J COMMUN SYST, V29, P1269, DOI 10.1002/dac.3098
   Okada K, 2018, 22 INT C INF VIS IV2
   Schneider T, 2016, 2016 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION, P116, DOI 10.1109/VISSOFT.2016.17
   Wakamiya S, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1136, DOI 10.1145/2971648.2971758
   Watanave Hidenori, 2014, Journal of the Institute of Image Information and Television Engineers, V68, P380
   Young M. K., 2014, P ACM S APPL PERCEPT, P83
NR 16
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32849
EP 32868
DI 10.1007/s11042-019-08016-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600012
DA 2024-07-18
ER

PT J
AU Toosi, R
   Sadeghi, M
   Akhaee, MA
AF Toosi, Ramin
   Sadeghi, Mohammadreza
   Akhaee, Mohammad Ali
TI Robust image watermarking using sample area quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Area quantization; Maximum likelihood
   detector; Quantization index modulation; Gradient descend
ID AMPLITUDE SCALE ESTIMATION
AB Digital watermarking is a way to protect the intellectual property of digital media. Among different algorithms, Quantization Index Modulation (QIM) is one of the popular methods in designing a watermark system. In this paper, a sample area quantization method is proposed for robust watermarking of digital images. First, the samples of the host signal form a polygon and low frequency wavelet coefficients of the carrier image is considered as the host sample. A watermark digit is embedded by quantizing the area of the polygon. Then, in order to minimize the distortion, the watermarked samples are obtained as close as possible to the host samples by solving an optimization problem while maintaining the quantized area at its fixed value. The optimization problem is solved using the gradient descend method. Finally, a maximum likelihood detector is designed to extract the watermark digits, assuming a Gaussian distribution for the host signal samples. The performance of the proposed method is theoretically obtained in terms of error probability in the presence of additive white Gaussian noise. Theoretical results are verified using simulation with artificial signals. The proposed method is compared to the state-of-the-art method under different attacks including: noise addition, JPEG compression, filtering, and geometrical attacks. The results confirm that the proposed method outperforms the other ones in terms of error probability against different attacks. The results also show that in the trade-off between robustness, distortion and capacity, by decreasing capacity the two other factors could be improved simultaneously.
C1 [Toosi, Ramin; Sadeghi, Mohammadreza; Akhaee, Mohammad Ali] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Tehran, Iran.
C3 University of Tehran
RP Akhaee, MA (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Tehran, Iran.
EM r.toosi@ut.ac.ir; mrsadeghi@ut.ac.ir; akhaee@ut.ac.ir
RI Toosi, Ramin/JCE-3460-2023; Toosi, Ramin/ABH-2457-2021
OI Toosi, Ramin/0000-0002-7099-9353
CR Abrardo A, 2004, PROC SPIE, V5306, P274, DOI 10.1117/12.524345
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Bradley B, 2004, PROC SPIE, V5306, P212, DOI 10.1117/12.527187
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ., 2007, DIGITAL WATERMARKING
   Eggers JJ, 2002, P SOC PHOTO-OPT INS, V4675, P387, DOI 10.1117/12.465297
   Fang H, 2018, MULTIMED TOOLS APPL, P1
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Gu Tianming, 2011, Proceedings of the 2011 IEEE 10th International Conference on Electronic Measurement & Instruments (ICEMI 2011), P163, DOI 10.1109/ICEMI.2011.6037879
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   Jiancheng Zou, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P438, DOI 10.1109/IIHMSP.2010.112
   Kuribayashi M, 2012, IEEE T INF FOREN SEC, V7, P403, DOI 10.1109/TIFS.2011.2170421
   Liu JH, 2018, CIRC SYST SIGNAL PR, V37, P1268, DOI 10.1007/s00034-017-0607-5
   Miller ML, 2004, IEEE T IMAGE PROCESS, V13, P792, DOI 10.1109/TIP.2003.821551
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Ourique F, 2005, ISSPA 2005: THE 8TH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P111
   Ourique F, 2005, AC SPEECH SIGN PROC, V2, pii
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Parekh M, 2018, ADV INTELL SYST, V710, P519, DOI 10.1007/978-981-10-7871-2_50
   Sadeghi M, 2019, SIGNAL PROCESS, V163, P213, DOI 10.1016/j.sigpro.2019.05.026
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sahraeian SME, 2008, IEEE IMAGE PROC, P429, DOI 10.1109/ICIP.2008.4711783
   Shterev ID, 2005, PROC SPIE, V5681, P516, DOI 10.1117/12.587865
   Shterev ID, 2006, IEEE T SIGNAL PROCES, V54, P4146, DOI 10.1109/TSP.2006.881216
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Thien HT, 2014, PROC INT CONF ADV, P280, DOI 10.1109/ATC.2014.7043398
   Wang Huai-bin, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P2614, DOI 10.1109/iCECE.2010.640
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Zaid AO, 2009, SIGNAL IMAGE VIDEO P, V3, P197, DOI 10.1007/s11760-008-0094-z
   Zebbiche K, 2018, MULTIMED TOOLS APPL, P1
   Zolotavkin Y, 2015, INT CONF ADV COMMUN, P155, DOI 10.1109/ICACT.2015.7224776
NR 38
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34963
EP 34980
DI 10.1007/s11042-019-08128-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800032
DA 2024-07-18
ER

PT J
AU Wu, C
   Song, YH
   Zhang, YL
AF Wu, Chen
   Song, Yonghong
   Zhang, Yuanlin
TI Multi-view gait recognition using NMF and 2DLDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; NMF; 2DLDA; 2D-EGEI; 2DPCA
ID VIEW TRANSFORMATION MODEL; FACE; REPRESENTATION; ALGORITHMS
AB View Transformation Model(VTM) is extensively employed in multi-view gait recognition. However, there still exists decline of matching accuracy among view transformation procedures. Particularly, the loss grows rapidly with the increase of the disparity of views. In the face of this difficulty, firstly, Non-negative Matrix Factorization(NMF) is introduced to obtain local structured features of human body to compensate accuracy loss. Moreover, 2D Linear Discriminant Analysis(2DLDA) is applied to improve classification ability by projecting features into a discriminant space. In the end, gait features, the Gait Energy Images(GEIs), is strengthened as 2D Enhanced GEI(2D-EGEI) by using the reconstruction of 2D Principal Component Analysis(2DPCA). Compared with the state-of-the-art, proposed method significantly outperforms the others. Furthermore, the comparisons of two deep learning methods is evaluated as well. Experimental outcomes show that the proposed method provides an alternative way to obtain the approximative outcomes compared with the deep learning methods.
C1 [Wu, Chen] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Song, Yonghong; Zhang, Yuanlin] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Song, YH (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
EM wuchen12345@stu.xjtu.edu.cn; songyh@mail.xjtu.edu.cn;
   ylzhangxian@stu.xjtu.edu.cn
FU National Key Research and Development Project of China [2017YFB1301101];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2018JM6104]
FX An earlier version of this paper was presented at the 2018 IEEE 4th
   International Conference on Identity, Security, and Behavior Analysis
   (ISBA) [29]. This work is partially supported by the National Key
   Research and Development Project of China (2017YFB1301101), and the
   Natural Science Basic Research Plan in Shaanxi Province of China
   (Program No.2018JM6104).
CR [Anonymous], 2 DIMENSIONAL NONNEG
   [Anonymous], 2016, IEEE T AUTOM SCI ENG
   [Anonymous], 2016, IEEE INFOCOM 2016
   Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117582
   Ben XY, 2019, PATTERN RECOGN, V90, P87, DOI 10.1016/j.patcog.2019.01.017
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jean F, 2009, IMAGE VISION COMPUT, V27, P1272, DOI 10.1016/j.imavis.2008.11.009
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu XZ, 2015, J AMB INTEL HUM COMP, V6, P557, DOI 10.1007/s12652-014-0230-2
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Nixon M., 2006, Human Identification Based on Gait
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tong SB, 2019, PATTERN RECOGN LETT, V125, P212, DOI 10.1016/j.patrec.2019.04.010
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu Cathy, 2018, 2018 IEEE International Conference on Robotics and Automation (ICRA), P6012, DOI 10.1109/ICRA.2018.8460567
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 33
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35789
EP 35811
DI 10.1007/s11042-019-08153-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800068
DA 2024-07-18
ER

PT J
AU Djaziri-Larbi, S
   Alouane, MH
AF Djaziri-Larbi, Sonia
   Turki-Haj Alouane, Monia
TI Spread spectrum data embedding in audio with UISA based cooperative
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Spread spectrum; Auditory model; Under-determined ISA;
   EMD; Cooperative detection
ID SOURCE SEPARATION; WATERMARKING; ROBUST; MODULATION
AB In the context of data embedding in audio for communications, Spread Spectrum (SS)-based techniques, combined with auditory models, are efficient in terms of robustness and perceptual quality of the modified host audio. However, their main drawback is the limited embedding capacity due to the strong interference caused by the host audio. In this work, we combine under-determined Blind Source Separation with a generic SS receiver -made of a Wiener equalizer and a correlation-based demodulator- to efficiently reduce the effect of the host interference. Two blocks are added to the generic receiver: an Under-determined Independent Subspace Analysis (UISA) block is placed after the Wiener equalizer in order to separate the components of the equalized output, and a cooperative detection block is applied to the UISA outputs in order to extract the relevant information from all available components. The UISA block uses Empirical Mode Decomposition to obtain multiple observations of the modified host signal. The performance of the proposed system in terms of bit error rate vs. bit-rate is significantly improved: average error rate is null for bit-rates below 500 bps and smaller than 0.1% for bit-rates reaching 1 kbps. The objective evaluation of the perceptual quality of the modified audio confirms the imperceptibility of the embedded data. The proposed system also exhibits robustness against common signal processing operations such as gain modification, noise, MPEG compression and re-quantization.
C1 [Djaziri-Larbi, Sonia; Turki-Haj Alouane, Monia] Univ Tunis El Manar, Signals & Syst Lab, Ecole Natl Ingenieurs Tunis, BP37, Belvedere 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Djaziri-Larbi, S (corresponding author), Univ Tunis El Manar, Signals & Syst Lab, Ecole Natl Ingenieurs Tunis, BP37, Belvedere 1002, Tunisia.
EM sonia.djaziri-larbi@enit.utm.tn; monia.turki@enit.utm.tn
CR Abrardo A, 2014, IEEE T INF FOREN SEC, V9, P1380, DOI 10.1109/TIFS.2014.2333592
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2000, Digital Watermarking
   ARNOLD M, 2000, IEEE INT C MULT EXP
   Arnold M, 2014, IEEE T INF FOREN SEC, V9, P411, DOI 10.1109/TIFS.2013.2293952
   Baras C, 2006, IEEE T AUDIO SPEECH, V14, P1772, DOI 10.1109/TASL.2006.879808
   Bassia P, 1998, EUR SIGN PROC C
   Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   BONEY L, 1996, IEEE INT C MULT COMP
   Casey MA, 2000, INT COMP MUS C
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   Cox IJ, 1996, INT WORKSH INF HID
   Cvejic Nedeljko, 2002, IEEE WORKSH MULT SIG, P2
   Djaziri-Larbi S, 2018, IEEE-ACM T AUDIO SPE, V26, P367, DOI 10.1109/TASLP.2017.2778150
   Djaziri-Larbi S, 2016, MULTIMED TOOLS APPL, V75, P4559, DOI 10.1007/s11042-015-2491-y
   El Hamdouni N, 2010, INT S SIGN IM VID CO
   El Hamdouni N, 2012, MULTIMED TOOLS APPL
   FitzGerald D, 2003, 114 CONV AUD ENG SOC
   GARCIA RA, 1999, 107 CONV AUD ENG SOC
   Geiser B, 2008, SPRACHK C
   Halalchi H, 2009, IEEE INT C AUD SPEEC
   Hayes MH., 1996, STAT DIGITAL SIGNAL
   Hu H, 2018, INT C TEL SIGN PROC
   Huang NE, 1998, P ROYAL SOC LONDON A, V454
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259
   International Organization for Standardization, 1993, 111723 ISOIEC
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Khaldi K, 2008, IEEE ISCCSP
   Khaldi K, 2009, EUR SIGN PROC C
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Lang A, 2005, 7 WORKSH MULT SEC
   Larbi S, 2005, IEEE T SIGNAL PROCES, V53
   Larbi S, 2004, IEEE INT C AUD SPEEC
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Liu Y, 2007, IEEE INT C MULT EXP
   Mahé G, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-27
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Matsuoka H, 2006, INT C INT INF HID MU
   Mezghani-Marrakchi I, 2014, IEEE ACM T AUDIO SPE, V22
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Parvaix M, 2010, IEEE T AUDIO SPEECH, V18, P1464, DOI 10.1109/TASL.2009.2035216
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Sagi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/64921
   Samaali I, 2012, J AUDIO ENG SOC, V60, P431
   Sequeira A, 2001, COMMUNICATION INFORM
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Swanson MD, 1999, IEEE INT C MULT COMP
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Xiang Y, 2015, CHINESE PHYS B, V23
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Xue Y, 2018, INT WORKSH DIG WAT
   Zhang Y, 2015, IEEE SIGNAL PROC LET, V22, P519, DOI 10.1109/LSP.2014.2363655
NR 58
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32307
EP 32331
DI 10.1007/s11042-019-07845-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000055
DA 2024-07-18
ER

PT J
AU Jiang, D
   Kim, J
AF Jiang, DaYou
   Kim, Jongweon
TI Artwork painting identification method for panorama based on adaptive
   rectilinear projection and optimized ASIFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artwork painting identification; Panorama; Object detection; Rectilinear
   projection; Feature extraction
AB In the paper, the authors present an artwork painting identification method for panorama based on adaptive rectilinear projection and optimized ASIFT (Affine Scale-Invariant Feature Transform). Firstly, the authors use the panorama dataset to train the artwork painting detection network to obtain the location information of artwork paintings. Secondly, the authors use the adaptive rectilinear projection to map the artwork painting into a square image with a fixed size. Then the authors use the image enhancement method to improve the image quality. Finally, the authors use the optimized ASIFT for features extraction and image matching. Several contrast experiments were conducted on the artwork paintings panorama dataset for artwork paintings identification. The results show that the proposed method can achieve 96% identification accuracy on average for the whole test artwork paintings panorama dataset. The proposed adaptive rectilinear based-method can improve at least 20% of the recognition accuracy. The proposed optimized ASIFT can improve at least 30% of the identification accuracy than SIFT. The authors also study other factors such as the size of the original artwork image, the image matching threshold, whether using image enhancement or not. The results show the size of the original artwork has little influence on the artwork identification in the panorama. The image matching threshold with 2.0 is better than 3.0. Furthermore, using the image enhancement method can improve about 2% of the identification accuracy.
C1 [Jiang, DaYou] Sangmyung Univ, Dept Copyright Protect, Seoul 03016, South Korea.
   [Kim, Jongweon] Sangmyung Univ, Dept Elect Engn, Seoul 03016, South Korea.
C3 Sangmyung University; Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Dept Elect Engn, Seoul 03016, South Korea.
EM dyjiang@cclabs.kr; jwkim@smu.ac.kr
RI jiang, dayou/AAQ-8986-2020; Kim, Jongweon/AAO-2221-2020
OI jiang, dayou/0000-0001-5054-6958; Kim, Jongweon/0000-0002-8916-6431
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2016, International Journal for Digital Art History
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Becattini F., 2016, Euro-Mediterranean Conference, P781
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Crowley E.J., 2016, VISUAL RECOGNITION A
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalens T., 2014, HAL01062126 INRIA
   Deng FC, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P375, DOI 10.1109/ICCAR.2017.7942721
   Fernando R., 2003, CG TUTORIAL
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Florea C, 2016, EUR SIGNAL PR CONF, P918, DOI 10.1109/EUSIPCO.2016.7760382
   Fu H, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281615
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jiang DY, 2018, INT J MACHINE LEARNI, V8, P54, DOI [10.18178/ijmlc.2018.8.1.663, DOI 10.18178/IJMLC.2018.8.1.663]
   Jin X, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050528
   Johnson CR, 2008, IEEE SIGNAL PROC MAG, V25, P37, DOI 10.1109/MSP.2008.923513
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Levi G, 2016, IEEE WINT CONF APPL
   Liu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P781, DOI 10.1109/ICInfA.2015.7279390
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Su H., 2018, ARXIV180311417
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viswanathan N, 2017, TECHNICAL REPORT
   Wang KH, 2019, INT CONF ACOUST SPEE, P3642, DOI [10.1109/icassp.2019.8683093, 10.1109/ICASSP.2019.8683093]
   Yang WY, 2018, INT C PATT RECOG, P2190, DOI 10.1109/ICPR.2018.8546070
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 36
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31893
EP 31924
DI 10.1007/s11042-019-07985-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000041
DA 2024-07-18
ER

PT J
AU Lin, C
   Lu, W
   Huang, XC
   Liu, K
   Sun, W
   Lin, HH
   Tan, ZY
AF Lin, Cong
   Lu, Wei
   Huang, Xinchao
   Liu, Ke
   Sun, Wei
   Lin, Hanhui
   Tan, Zhiyuan
TI Copy-move forgery detection using combined features and transitive
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Internet of things; Multimedia forensics; Region
   duplication detection; Copy-move forgery; Image segmentation; LIOP
ID IMAGE SPLICING DETECTION; STEGANALYSIS; CLOUD; EFFICIENT; SCHEME; MODEL;
   TRANSFORM; DCT
AB Recently, the research of Internet of Things (IoT) and Multimedia Big Data (MBD) has been growing tremendously. Both IoT and MBD have a lot of multimedia data, which can be tampered easily. Therefore, the research of multimedia forensics is necessary. Copy-move is an important branch of multimedia forensics. In this paper, a novel copy-move forgery detection scheme using combined features and transitive matching is proposed. First, SIFT and LIOP are extracted as combined features from the input image. Second, transitive matching is used to improve the matching relationship. Third, a filtering approach using image segmentation is proposed to filter out false matches. Fourth, affine transformations are estimated between these image patches. Finally, duplicated regions are located based on those affine transformations. The experimental results demonstrate that the proposed scheme can achieve much better detection results on the public database under various attacks.
C1 [Lin, Cong; Lu, Wei; Huang, Xinchao] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Cong; Lin, Hanhui] Guangdong Univ Finance & Econ, Ctr Fac Dev & Educ Technol, Guangzhou 510320, Guangdong, Peoples R China.
   [Liu, Ke; Sun, Wei] Sun Yat Sen Univ, Sch Elect & Informat Technol, Key Lab Informat Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Tan, Zhiyuan] Edinburgh Napier Univ, Sch Comp, Edinburgh EH10 5DT, Midlothian, Scotland.
C3 Sun Yat Sen University; Guangdong University of Finance & Economics; Sun
   Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Edinburgh Napier University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM lincong0310@gmail.com; luwei3@mail.sysu.edu.cn; z.tan@napier.ac.uk
RI Tan, Zhiyuan/K-3120-2019; Nasarian, Elham/ISB-6863-2023
OI Tan, Zhiyuan/0000-0001-5420-2554; Lu, Wei/0000-0002-4068-1766; lin,
   cong/0000-0002-5667-5037
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Fundamental
   Research Funds for the Central Universities [16lgjc83, 17lgjc45];
   Science and Technology Planning Project of Guangdong Province
   [2017A040405051]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45), the Science and Technology Planning Project of
   Guangdong Province (Grant No.2017A040405051).
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2014, IEEE T INFORM FORENS
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], IEEE INTERNET THINGS
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen X, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2790424
   Cheng XD, 2017, IEEE T AUTOMAT CONTR, V62, P5026, DOI 10.1109/TAC.2017.2679479
   Christlein V., 2010, IEEE International Workshop on Information Forensics and Security, P1
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Fang WW, 2014, INFORM SCIENCES, V283, P79, DOI 10.1016/j.ins.2014.06.022
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Feng BW, 2017, LECT NOTES COMPUT SC, V10082, P312, DOI 10.1007/978-3-319-53465-7_23
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Feng BW, 2016, SIGNAL PROCESS-IMAGE, V41, P1, DOI 10.1016/j.image.2015.10.007
   Feng BW, 2015, MULTIMED TOOLS APPL, V74, P9623, DOI 10.1007/s11042-014-2140-x
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gao LP, 2016, CLUSTER COMPUT, V19, P255, DOI 10.1007/s10586-015-0499-8
   Ghorbani M.A., 2011, 19 IR C EL ENG, P1
   Gui JS, 2017, IEEE ACCESS, V5, P2396, DOI 10.1109/ACCESS.2017.2672561
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li JH, 2016, ADV SOC SCI EDUC HUM, V76, P1
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JF, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 1, P883
   Lu X, 2017, J SUPERCOMPUT, V73, P3562, DOI 10.1007/s11227-016-1821-9
   Lu Z, 2017, MULTIMED TOOLS APPL, V76, P10855, DOI 10.1007/s11042-016-3877-1
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Melro L. S., 2017, COMPUTERS MAT CONTIN, V53, P111
   Nelson Bill., 2015, Guide to computer forensics and investigations
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang YH, 2017, INFORM SCIENCES, V408, P70, DOI 10.1016/j.ins.2017.04.035
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Wu PF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061303
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiong N., 2017, SENSORS, V17, P1
   Xiong N, 2009, INF SCI, V180, P2249
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Yang B, 2013, RADIOENGINEERING, V22, P1098
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang Y, 2014, SENSORS-BASEL, V14, P22408, DOI 10.3390/s141222408
   Yang ZH, 2017, CMC-COMPUT MATER CON, V53, P219
   Zhang CY, 2015, J INTERNET TECHNOL, V16, P1301, DOI 10.6138/JIT.2015.16.7.20151103a
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang H, 2016, J INTERNET TECHNOL, V17, P1391, DOI 10.6138/JIT.2016.17.7.20161108
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Y, 2018, SIG PROCESS, V146, P1
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
   Zhou P, 2016, IEEE T MULTIMEDIA, V18, P1217, DOI 10.1109/TMM.2016.2537216
   Zhou YZ, 2017, TSINGHUA SCI TECHNOL, V22, P714, DOI 10.23919/TST.2017.8195353
NR 85
TC 45
Z9 46
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30081
EP 30096
DI 10.1007/s11042-018-6922-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200025
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Sun, JM
   Yang, W
   Jiang, MQ
   Yang, FL
AF Liu, Xuejiao
   Sun, Junmei
   Yang, Wei
   Jiang, Mengqing
   Yang, Fengli
TI Ensuring efficient multimedia message sharing in mobile social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile social network; Message sharing; Attribute based encryption
ID ATTRIBUTE-BASED ENCRYPTION; DISCOVERY; SYSTEM
AB Mobile Social Networks (MSN) are attractive applications which enable users to share data with a group of friends and stay connected. WeChat, QQ are among the most popular applications of MSNs where personal multimedia files are shared among group contacts. However, the security risks accompanying such developments have raised concerns in people. The providers typically store users' data, and offer few options for the users to custom and manage the dissipation of their data over the network. In this paper, we design a data sharing framework in which individuals retain ownership of their data. The scheme gives users flexible and granular access control over their data, and more importantly it provides protection from the untrusted data provider server. Experiments show the efficiency of our scheme.
C1 [Liu, Xuejiao; Sun, Junmei; Yang, Fengli] Hangzhou Normal Univ, Inst Serv Engn, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Wei] Wuhan Univ, Wuhan, Hubei, Peoples R China.
   [Yang, Wei] Inst 145 Erqi Rd, Wuhan, Hubei, Peoples R China.
   [Jiang, Mengqing] Hangzhou Yuantiao Technol Corp, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Normal University; Wuhan University
RP Liu, XJ (corresponding author), Hangzhou Normal Univ, Inst Serv Engn, Hangzhou, Zhejiang, Peoples R China.
EM liuxuejiao0406@163.com
FU National Natural Science Foundation of China [61502134, 61472113,
   61304188]; Zhejiang Provincial Natural Science Foundation of China
   [LZ13F020004, LR14F020003]; Zhejiang Provincial Science and Technology
   Innovation Program [2013TD03]; Hangzhou Science and Technology
   Development Plan [20170533B04]
FX This research is supported in part by the following funds: National
   Natural Science Foundation of China under grant number 61502134,
   61472113, and 61304188, Zhejiang Provincial Natural Science Foundation
   of China under grant number LZ13F020004 and LR14F020003, Zhejiang
   Provincial Science and Technology Innovation Program under grant number
   2013TD03, and Hangzhou Science and Technology Development Plan under
   grant number 20170533B04.
CR [Anonymous], STANFORD PAIRINGS BA
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 1996, SECURE SCHEMES SECRE
   [Anonymous], LIBFENC FUNCTIONAL E
   Baden R, 2009, ACM SIGCOMM COMP COM, V39, P135, DOI 10.1145/1594977.1592585
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boneh D., 2001, Advances in Cryptology - CRTPTO 2001. 21st Annual International Cryptology Conference, Proceedings (Lecture Notes in Computer Science Vol.2139), P213
   Boyen X, 2007, LECT NOTES COMPUT SC, V4450, P1
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Cheung L, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P456
   Dong W, 2011, IEEE INFOCOM SER, P1647, DOI 10.1109/INFCOM.2011.5934958
   Gao HY, 2011, IEEE INTERNET COMPUT, V15, P56, DOI 10.1109/MIC.2011.50
   Green M., 2011, P 20 USENIX C SEC
   Hohenberger S, 2013, LECT NOTES COMPUT SC, V7778, P162, DOI 10.1007/978-3-642-36362-7_11
   Kate A, 2007, LECT NOTES COMPUT SC, V4776, P95
   Lewko A, 2010, LECT NOTES COMPUT SC, V6110, P62, DOI 10.1007/978-3-642-13190-5_4
   Li J, 2009, LECT NOTES COMPUT SC, V5735, P347
   Li M, 2011, IEEE INFOCOM SER, P2435, DOI 10.1109/INFCOM.2011.5935065
   Liang X, 2007, SHORT GROUP SIGNATUR
   Liang XH, 2013, IEEE J SEL AREA COMM, V31, P641, DOI 10.1109/JSAC.2013.SUP.0513056
   Liu XJ, 2016, J COMPUT SYST SCI, V82, P1316, DOI 10.1016/j.jcss.2016.05.006
   Liu XJ, 2013, IEEE INT CONF TRUST, P477, DOI 10.1109/TrustCom.2013.60
   Ostrovsky R, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P195, DOI 10.1145/1315245.1315270
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sahai A, 2012, LECT NOTES COMPUT SC, V7417, P199
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Song Y, 2017, DESTECH TRANS COMP, P213
   Tootoonchian Amin., 2009, P 5 INT C EMERGING N, P169, DOI DOI 10.1145/1658939.1658959
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Waters B, 2011, LECT NOTES COMPUT SC, V6571, P53, DOI 10.1007/978-3-642-19379-8_4
   Waters B, 2009, LECT NOTES COMPUT SC, V5677, P619, DOI 10.1007/978-3-642-03356-8_36
   Xia Y., 2014, MULTIMED TOOLS APPL, P1
   Xia YJ, 2016, THEOR COMPUT SCI, V618, P1, DOI 10.1016/j.tcs.2015.12.025
   Zhang L, IEEE T IMAGE PROCESS, P2235
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang R, 2012, IEEE INFOCOM SER, P1969, DOI 10.1109/INFCOM.2012.6195574
   Zhu W, 2016, IEEE INT C BIOINFORM, P1415, DOI 10.1109/BIBM.2016.7822730
NR 46
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31003
EP 31017
DI 10.1007/s11042-017-4543-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000001
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Chen, RP
   Zhu, L
   Liu, AF
   Lin, YW
   Huang, F
AF Zhang, Chengyuan
   Chen, Ruipeng
   Zhu, Lei
   Liu, Anfeng
   Lin, Yunwu
   Huang, Fang
TI Hierarchical information quadtree: efficient spatial temporal image
   search for multimedia stream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical information quadtree; Spatial temporal image search;
   Multimedia stream
ID NEURAL-NETWORKS
AB Massive amount of multimedia data that contain times- tamps and geographical information are being generated at an unprecedented scale in many emerging applications such as photo sharing web site and social networks applications. Due to their importance, a large body of work has focused on efficiently computing various spatial image queries. In this paper,we study the spatial temporal image query which considers three important constraints during the search including time recency, spatial proximity and visual relevance. A novel index structure, namely Hierarchical Information Quadtree(HI-Quadtree), to efficiently insert/delete spatial temporal images with high arrive rates. Base on HI-Quadtree an efficient algorithm is developed to support spatial temporal image query. We show via extensive experimentation with real spatial databases clearly demonstrate the efficiency of our methods.
C1 [Zhang, Chengyuan; Chen, Ruipeng; Zhu, Lei; Liu, Anfeng; Lin, Yunwu; Huang, Fang] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Zhang, Chengyuan; Chen, Ruipeng; Zhu, Lei; Lin, Yunwu; Huang, Fang] Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Liu, AF (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM cyzhang@csu.edu.cn; rpchen@csu.edu.cn; leizhu@csu.edu.cn;
   anfengliu@csu.edu.cn; lywcsu@csu.edu.cn; hfang@csu.edu.cn
RI HUANG, FANG/JBS-3517-2023; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-5348-7532; Liu, Yuxin/0000-0002-8632-2910
FU National Natural Science Foundation of China [61379110, 61472450,
   61702560]; Key Research Program of Hunan Province [2016JC2018]; Science
   and Technology Plan of Hunan Province [2018JJ3691]; Fundamental Research
   Funds for Central Universities of Central South University [2018zzts588]
FX This work was supported in part by the National Natural Science
   Foundation of China (61379110, 61472450, 61702560), the Key Research
   Program of Hunan Province (2016JC2018), project 2018JJ3691 of Science
   and Technology Plan of Hunan Province, and Fundamental Research Funds
   for Central Universities of Central South University (2018zzts588).
CR Alfarrarjeh A, 2017, CORR
   Amati G., 2012, CIKM, P2483
   [Anonymous], 2014, Metallogenic regularity and prospecting direction of Mo-Pb-Zn polymetallic mineralization in Dongwuqi area, Inner Mongolia
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   [Anonymous], 2013, P 16 INT C EXT DAT T
   AREF WG, 1990, PROCEEDINGS OF THE NINTH ACM SIGACT-SIGMOD-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P265, DOI 10.1145/298514.298579
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Cao S, 2012, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2012/03/016
   Cong G., 2009, PROC VLDB ENDOW, V2, P337, DOI DOI 10.14778/1687627.1687666
   Efron M, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P495
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Guo L, 2015, GEOINFORMATICA, V19, P29, DOI 10.1007/s10707-014-0204-8
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Huang MF, 2019, IEEE T SYST MAN CY-S, V49, P317, DOI 10.1109/TSMC.2018.2833204
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jin HY, 2015, J TRANSL MED, V13, DOI 10.1186/s12967-015-0616-8
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Liu X, 2018, IEEE T IND INFORM, V14, P3801, DOI 10.1109/TII.2018.2836150
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J., 2011, SIGMOD, P349
   Mehta P, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), DOI 10.1145/2996913.2996941
   Nepomnyachiy S., 2014, PROC 8 WORKSHOP GEOG, P1
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Rocha-Junior J.B., 2012, EDBT, P168
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Theodoridis Y, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P441, DOI 10.1109/MMCS.1996.535011
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.2013.6738166
   Wu L, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (9TH), VOL II, P598
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Yang Wang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P234, DOI 10.1007/978-3-319-06605-9_20
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zhang CY, 2013, PROC INT CONF DATA, P901, DOI 10.1109/ICDE.2013.6544884
   Zhang DX, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/2600428.2609562
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zheng K, 2015, PROC INT CONF DATA, P423, DOI 10.1109/ICDE.2015.7113303
   Zhu GQ, 2016, ONCOTARGETS THER, V9, P2153, DOI 10.2147/OTT.S97864
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 55
TC 23
Z9 23
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30561
EP 30583
DI 10.1007/s11042-018-6284-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200052
DA 2024-07-18
ER

PT J
AU Barzegar, S
   Sharifi, A
   Manthouri, M
AF Barzegar, Somayeh
   Sharifi, Arash
   Manthouri, Mohammad
TI Super-resolution using lightweight detailnet network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Convolutional neural networks; Residual blocks;
   Natural images
AB Image Super-Resolution is a complex method capable of converting a low-resolution image to a high-resolution image. Regarding many challenges of the Super-Resolution problem and a wide variety of its applications in image processing and man's interpretations, it is very crucial to find an operational method. Development of deep learning methods, especially Convolutional Neural Networks has increased the power of image enhancement methods including image Super-Resolution. The goal of this research is to propose a fast speed image Super-Resolution method using Convolutional Neural Networks. The proposed DetailNet network has a small structure to prevent the problems of training very deep networks. Super-Resolution is fast by this method due to its small simple network structure. The DetailNet network is designed to add details to an input image. According to the results, DetailNet has a significant ability to produce image details. This network has a general function. Therefore, the low-resolution image size can be increased first using any method, then DetailNet can enhance the image quality and add more details to the input image. The Proposed method is applied to natural color images which achieved acceptable results on benchmark datasets.
C1 [Barzegar, Somayeh; Sharifi, Arash] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Manthouri, Mohammad] Shahed Univ, Dept Elect & Elect Engn, Tehran, Iran.
C3 Islamic Azad University; Shahed University
RP Sharifi, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
EM a.sharifi@srbiau.ac.ir
RI Sharifi, Arash/AAU-2023-2021
OI Sharifi, Arash/0000-0002-2441-9477
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gregor K, 2010, P 27 INT C INT C MAC, P399
   Gupta P., 2011, P INT C COMM IND APP, P1, DOI 10.1109/ICCIndA.2011.6146669
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang D., 2015, Journal of Computer Science Technology Updates, V2, P19, DOI DOI 10.15379/2410-2938.2015.02.02.03
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SUN L, 2017, ABS170107604 CORR
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang LF, 2017, PATTERN RECOGN, V68, P191, DOI 10.1016/j.patcog.2017.02.027
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 27
TC 7
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1119
EP 1136
DI 10.1007/s11042-019-08218-4
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000491551600003
DA 2024-07-18
ER

PT J
AU Fotopoulou, F
   Oikonomou, S
   Economou, G
AF Fotopoulou, F.
   Oikonomou, S.
   Economou, G.
TI 3D shape classification with NNLS coding and optimal projections
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Nonnegative least squares; 3D shape
   classification; Laplace-Beltrami; Support vector machines
ID FACE
AB Using graph-based encoding techniques and well-known shape descriptors a framework is presented here which is checked for 3D shape classification performance. A data-driven feature extraction procedure, taking the form of a simple projection operator, is in the core of our framework. Provided a shape database, a graph encapsulating the structural relationships among all the available shapes is first constructed and then is employed to define low-dimensional sparse projections. The weights in the graph, reflecting the database structure, are calculated so as to approximate each shape as a sparse linear combination of the remaining dataset objects. NNLS (nonnegative least squares) coding method is employed and fully exploited in this stage. Sparse coding with L2graph is also included in the framework. By way of solving a generalized eigenanalysis problem, a linear matrix operator is designed by means of optimal projections that will act as the feature extractor. A trained SVM (support vector machine) in the final stage of our framework makes the class prediction. Two popular, inherently high dimensional descriptors, namely ShapeDNA and Global Point Signature (GPS), with a modification emphasizing the smaller eigenvalues are employed in our experimentations with SHREC10, SHREC11 and SCHREC15 datasets. Classification results are very promising and outperform state of the art methods, providing evidence about the highly discriminative nature of the 3D shape representation produced in the proposed multistage framework.
C1 [Fotopoulou, F.] Univ Patras, Dept Comp Engn & Informat, Patras 26500, Greece.
   [Oikonomou, S.; Economou, G.] Univ Patras, Dept Phys, Elect Lab, Patras 26500, Greece.
C3 University of Patras; University of Patras
RP Fotopoulou, F (corresponding author), Univ Patras, Dept Comp Engn & Informat, Patras 26500, Greece.
EM fotopoulou@ceid.upatras.gr
OI Fotopoulou, Foteini/0000-0002-0916-3047; Economou,
   George/0000-0001-9938-0768
CR Boyer E., 2011, P EUR WORKSH 3 D OBJ
   Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Cecilio A, 2003, J NEUROONCOL, V55, P57, DOI DOI 10.1016/S0925-2312(03)00435-1
   Chaudhari AJ, 2014, PHYS MED BIOL, V59, P961, DOI 10.1088/0031-9155/59/4/961
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Croissant JG, 2016, FRONT MOL BIOSCI, V3, DOI 10.3389/fmolb.2016.00001
   Danielle E, 2017, COMPUTER GRAPHICS FO, V36
   Furuya Takahiko, 2014, P BMVC 2014, DOI [10.5244/C.28.16, DOI 10.5244/C.28.16]
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao ZH, 2014, COMPUT AIDED DESIGN, V53, P62, DOI 10.1016/j.cad.2014.03.008
   Godil A, 2011, 3DOR, P79
   Hamza AB, 2016, NEUROCOMPUTING
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu H, 2014, MULTIMED TOOLS APPL
   Hu H, 2016, NEUROCOMPUTING
   Huang K, 2006, ADV NEURAL INF PROCE, V19, DOI /10.7551/mitpress/7503.003.0081
   Kazmi IK, 2013, 10 INT C COMP GRAPH
   Li CY, 2014, MULTIMEDIA SYST, V20, P253, DOI 10.1007/s00530-013-0318-0
   Li Y, 2013, NEUROCOMPUTING
   Lian Z., 2010, Eurographics Workshop on 3D Object Retrieval, V10, P101, DOI [10.2312/3DOR/3DOR10/101-108, 10.1109/CVPR.2014.491, DOI 10.2312/3DOR/3DOR10/101-108]
   Lian ZH, 2015, 2015 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING, MSE 2015, P1
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   LIPMAN Y, 2010, ACM T GRAPHIC, V29, DOI DOI 10.1145/1805964.1805971
   Liu M, 2017, MULTIMED TOOLS APPL
   Liu WF, 2016, IEEE T IND ELECTRON, V63, P5120, DOI 10.1109/TIE.2016.2552147
   Lopez GL, 2017, MULTIMED TOOLS APPL
   Luciano L, PATTERN RECOGN LETT
   Masoumi M, 2015, SHAPE CLASSIFICATION
   Masoumi M, 2017, J VIS COMMUN IMAGE R, V43, P198, DOI 10.1016/j.jvcir.2017.01.001
   Moyou M, 2014, IEEE INT C PATT REC
   Peng X, 2017, IEEE T CYBERNETICS, V47, P1053, DOI 10.1109/TCYB.2016.2536752
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rosenberg S., 1997, The Laplacian on a Riemannian Manifold: An Introduction to Analysis on Manifolds
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Shu Z, 2016, 3D MODEL CLASSIFICAT
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Vapnik V., 1999, NATURE STAT LEARNING
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang W., 2015, COLLABORATIVE REPRES
   Ye JB, 2016, VISUAL COMPUT, V32, P553, DOI 10.1007/s00371-015-1071-5
   Yu J, 2018, IEEE T IND ELECT, V65
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
NR 49
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34689
EP 34706
DI 10.1007/s11042-019-08152-5
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000489940100001
DA 2024-07-18
ER

PT J
AU Lee, S
   Sohn, BS
AF Lee, Seungchan
   Sohn, Bong-Soo
TI Generation of cartoon-style bas-reliefs from photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia computing; 3D computer graphics; Image processing; 3D
   printing
AB This paper describes a new algorithm that generates a cartoon-style bas-relief surface from photographs of general scenes. Most previous methods for bas-relief generation have focused on accurate restoration of input 3D models on a background plane. The generation of bas-reliefs with artistic effects has rarely been studied. Considering that non-photorealistic rendering (NPR) techniques are currently very popular and 3D printing technology is developing rapidly, extending NPR techniques to the generation of a bas-relief surface with artistic effects is natural and valuable. Furthermore, cartoon is a basic non-realistic and artistic style familiar to general users. From this motivation, our method focuses on generating a cartoon-style bas-relief surface. We use the lens blur function of Google Camera, which is a smartphone application, to obtain a photograph and its depth map as inputs. Using coherent line drawing and histogram-based quantization methods, we construct a depth map that contains the salient features of given input scenes in abstract form. Displacement mapping from the depth map onto a thin plane generates a cartoon-style bas-relief. Experimental results show that our method generates bas-relief surfaces that contain the characteristics of cartoons, such as coherent border lines and quantized layers.
C1 [Lee, Seungchan; Sohn, Bong-Soo] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Sohn, BS (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM bongbong@cau.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2017R1D1A1B03036291]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2017R1D1A1B03036291).
CR Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Arpa S, 2015, COMPUT GRAPH FORUM, V34, P253, DOI 10.1111/cgf.12557
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   Decaudin P, 1996, 2919518 INRIA, V2919, P518
   To HT, 2017, MULTIMED TOOLS APPL, V76, P10407, DOI 10.1007/s11042-016-3924-y
   Herholz P, 2017, COMPUT GRAPH-UK, V66, P135, DOI 10.1016/j.cag.2017.05.018
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kerber J, 2007, P 23 SPRING C COMP G, P101
   Li ZW, 2012, IEEE T VIS COMPUT GR, V18, P177, DOI 10.1109/TVCG.2011.26
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Seitz SM, 2006, P 2006 I E COMP SOC, P748
   Sohn BS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030572
   Sun XF, 2009, IEEE T VIS COMPUT GR, V15, P642, DOI 10.1109/TVCG.2009.21
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Wang M, 2017, COMP GRAPH INT C
   Wang M, 2010, 11 IASTED INT C COMP, P679
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Zhang YW, 2016, COMPUT GRAPH FORUM, V35, P311, DOI 10.1111/cgf.13028
NR 21
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28391
EP 28407
DI 10.1007/s11042-017-5343-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700003
DA 2024-07-18
ER

PT J
AU Lei, BY
   Zhao, X
   Lei, HJ
   Ni, D
   Chen, SP
   Zhou, F
   Wang, TF
AF Lei, Baiying
   Zhao, Xin
   Lei, Haijun
   Ni, Dong
   Chen, Siping
   Zhou, Feng
   Wang, Tianfu
TI Multipurpose watermarking scheme via intelligent method and chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermark; Artificial bee algorithm; Multipurpose; Quantization
   index modulation
ID DIGITAL WATERMARKING; IMAGE; OPTIMIZATION; PERFORMANCE; ALGORITHM;
   ROBUST; BLIND; CUES
AB In this paper, we propose a novel multipurpose intelligent image watermarking scheme for both content authentication and copyright protection. To achieve this, we first utilize integer discrete wavelet transform (IDWT) for watermark insertion and detection. The low frequency component of IDWT is used to insert a robust watermark (e.g., the copyright information) for copyright protection, whereas the high frequency component of IDWT is used to embed a fragile watermark (e.g., the logo data) for content authentication. To achieve a good tradeoff among the watermark conflicting requirements (e.g., robustness, fidelity and capacity), we develop an artificial bee colony (ABC) algorithm for optimal parameter selection. Experimental results demonstrate that the proposed scheme achieves promising performance in both copyright protection and content authentication simultaneously, which confirm the superiority of our proposed algorithm as compared to existing methods.
C1 [Lei, Baiying; Zhao, Xin; Ni, Dong; Chen, Siping; Wang, Tianfu] Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen 518060, Peoples R China.
   [Lei, Haijun] Shenzhen Univ, Coll Comp Sci & Technol, Shenzhen, Peoples R China.
   [Zhou, Feng] Georgia Inst Technol, George W Woodruff Sch Mech Engn, 813 Ferst Dr NW, Atlanta, GA 30332 USA.
C3 Shenzhen University; Shenzhen University; University System of Georgia;
   Georgia Institute of Technology
RP Wang, TF (corresponding author), Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen 518060, Peoples R China.; Zhou, F (corresponding author), Georgia Inst Technol, George W Woodruff Sch Mech Engn, 813 Ferst Dr NW, Atlanta, GA 30332 USA.
EM fzhou35@gatech.edu; tfwang@szu.edu.cn
RI Chen, Siqi/IZE-8631-2023; Lei, Baiying/GRE-9741-2022; Lei,
   Baiying/GQO-8422-2022; Lei, Baiying/AAY-5515-2020
OI Lei, Baiying/0000-0002-3087-2550; Lei, Baiying/0000-0002-3087-2550; Lei,
   Baiying/0000-0002-3087-2550; Zhao, Xin/0000-0003-2697-5642
FU National Natural Science Foundation of China [61402296, 61571304,
   61427806]; National Key Research and Development Project
   [2016YFC0104703]; (Key) Project of Department of Education of Guangdong
   Province [2014GXM052]; Shenzhen Key Basic Research Project
   [JCYJ20150525092940986]; Guangdong Medical Grant [B2016094]; Open Fund
   Project of Fujian Provincial Key Laboratory of Information Processing
   and Intelligent Control (Minjiang University) [MJUKF201711]; National
   Natural Science Foundation of Shenzhen University [2016077]
FX This work was supported partly by National Natural Science Foundation of
   China (Nos. 61402296, 61571304, and 61427806), National Key Research and
   Development Project (No. 2016YFC0104703), the (Key) Project of
   Department of Education of Guangdong Province (No. 2014GXM052), Shenzhen
   Key Basic Research Project (Nos. JCYJ20150525092940986), Guangdong
   Medical Grant (No. B2016094), Open Fund Project of Fujian Provincial Key
   Laboratory of Information Processing and Intelligent Control (Minjiang
   University) (No. MJUKF201711) and the National Natural Science
   Foundation of Shenzhen University (No. 2016077).
CR Ansari IA, 2016, PATTERN RECOGNITION
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Baiying Lei, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P86, DOI 10.1007/978-3-642-32205-1_9
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cong K, 2013, INT CONF QUAL SOFTW, P1, DOI 10.1109/QSIC.2013.44
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Jamal SS, 2013, NONLINEAR DYNAM, V73, P1469, DOI 10.1007/s11071-013-0877-9
   Jin Y, 2014, NEUROIMAGE, V100, P75, DOI 10.1016/j.neuroimage.2014.04.048
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karaboga D., 2005, Technical report-tr06
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lee SH, 2011, J MED SYST, V35, P1573, DOI 10.1007/s10916-010-9434-y
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lei B., 2012, P INT JOINT C NEUR N, P1
   Lei B., 2011, 8 INT C INF COMM SIG, P1
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lei BY, 2015, AEU-INT J ELECTRON C, V69, P188, DOI 10.1016/j.aeue.2014.08.012
   Lei BY, 2014, NONLINEAR DYNAM, V78, P2897, DOI 10.1007/s11071-014-1634-4
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Liu NS, 2015, NONLINEAR DYNAM, V80, P1329, DOI 10.1007/s11071-015-1946-z
   Mooney A, 2009, CHAOS SOLITON FRACT, V42, P560, DOI 10.1016/j.chaos.2009.01.025
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Sang T, 2001, IEEE T COMMUN, V49, P620, DOI 10.1109/26.917768
   Tefas A, 2003, IEEE T SIGNAL PROCES, V51, P1979, DOI 10.1109/TSP.2003.811245
   Wang XY, 2009, IEEE MULTIMEDIA, V16, P60, DOI 10.1109/MMUL.2009.44
   Wu XY, 2007, PHYS LETT A, V365, P403, DOI 10.1016/j.physleta.2007.01.034
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 40
TC 19
Z9 20
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27085
EP 27107
DI 10.1007/s11042-017-4743-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000014
DA 2024-07-18
ER

PT J
AU Xia, SF
   Yang, S
   Liu, JY
AF Xia, Sifeng
   Yang, Shuai
   Liu, Jiaying
TI Selfie retoucher: subject-oriented self-portrait enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Field of view expansion; Illumination unification;
   Image registration
ID COLOR
AB Sharing self-portraits starts trending nowadays with the boom of social networks and the rise of smartphones. However, limited by the hardware capabilities, self-portraits taken by the front cameras of portable media devices usually face quality problems such as an incomplete field of view and poor lighting style. In our paper, we introduce a selfie retoucher which enhances a self-portrait with the help of N supporting photos that share the same scene and similar shooting time. With the extra information brought by the supporting photos, a lager field of view and a better lighting style can be achieved. To accomplish this, we propose a novel subject-oriented self-portrait enhancement method with a cascaded illumination unification and photos registration framework. Based on the correspondences extracted from the input 1+N photos, our method estimates and updates the illumination and registration coefficients in a cascaded manner. Moreover, a subject-oriented enhancement algorithm is proposed to enhance the face of the photographer in the self-portrait. We adopt a face-specific illumination correction process over the self-portrait to further improve the visual quality of the subject. After the enhancement, we globally fuse the aligned photos by a Markov Random Field based optimization method. During the fusion, a body map is additionally derived from the subject for guidance. Experimental results demonstrate that the proposed method achieves high-quality results in this novel application scenario.
C1 [Xia, Sifeng; Yang, Shuai; Liu, Jiaying] Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
C3 Peking University
RP Liu, JY (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
EM liujiaying@pku.edu.cn
RI Liu, JY/GYJ-0138-2022
OI Liu, Jiaying/0000-0002-0468-9576
FU National Natural Science Foundation of China [61772043]; Beijing Natural
   Science Foundation [L182002, 4192025]
FX This work was supported in part by National Natural Science Foundation
   of China under contract No. 61772043 and in part by Beijing Natural
   Science Foundation under contract No. L182002 and No. 4192025.
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen Y, 2016, P EUR C COMP VIS
   Ebner M, 2006, PATTERN RECOGN LETT, V27, P1220, DOI 10.1016/j.patrec.2005.07.020
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson GD, 2003, P INT C COMP VIS
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   HaCohen Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461997
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732
   Laffont PY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366221
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li MD, 2015, IEEE T CIRC SYST VID, V25, P200, DOI 10.1109/TCSVT.2014.2347531
   Lin K, 2016, P EUR C COMP VIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nomura Yoshikuni., 2007, P 18 EUROGRAPHICS C, P127
   Osadchy M., 2007, Journal of machine learning research: JMLR
   Park J, 2016, P IEEE INT C COMPUTE
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Shan Q, 2014, LECT NOTES COMPUT SC, V8694, P16, DOI 10.1007/978-3-319-10599-4_2
   Sivic J, 2008, PROC CVPR IEEE, P2182
   Song S, 2018, P IEEE INT C COMP VI
   Valle R., 2018, P EUR C COMP VIS
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661278
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xiong XD, 2013, IEEE C ELEC DEVICES
   Yang S, 2017, P IEEE INT C AC SPEE
   Zhang W, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zhang Y, 2013, P IEEE INT C COMP VI
   Zhou Q.-Y., 2016, P EUR C COMP VIS
   Zhu X, 2012, P IEEE INT C COMP VI
NR 33
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27591
EP 27609
DI 10.1007/s11042-019-07873-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000037
DA 2024-07-18
ER

PT J
AU Zhang, QH
   Wan, CX
   Han, WL
AF Zhang, Qinghui
   Wan, Chenxia
   Han, Weiliang
TI A modified faster region-based convolutional neural network approach for
   improved vehicle detection performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Faster R-CNN; Modified inception model;
   Vehicle detection
ID OBJECT DETECTION
AB Presently available algorithms employed for vehicle detection exhibit three main disadvantages: slow detection speed, poor small objects detection, and low detection precision. To solve above problems, the present work proposes a vehicle detection approach employing a modified faster region-based convolutional neural network (R-CNN). Firstly, this approach introduces a deep CNN-based on VGG-16 and inception architecture, and adds a set of convolutional kernels with a 1 x 1 size, called a deep convolutional network (DCN). Then, an accurate vehicle region network (AVRN) and a vehicle attribute learning network (VALN) are designed. The AVRN accurately generates vehicle-like regions in real time, and the VALN detects the corresponding classifications and locations of vehicle-like regions. To improve the detection precision, we introduce corresponding loss functions for the AVRN and VALN. The calculation speed is increased by alternately optimizing and jointly training the AVRN and VALN. Experimental results demonstrate that the modified faster R-CNN approach improves significantly vehicle detection performance relative to existing algorithms, where, compared to the standard state-of-the-art faster R-CNN vehicle detection approach, the mean average precision of the test results obtained by the modified approach is increased by 11% and the detection time is reduced by one-third.
C1 [Zhang, Qinghui; Wan, Chenxia; Han, Weiliang] Henan Univ Technol, Coll Informat Sci & Engn, Lianhua Ave 100, Zhengzhou 450001, Henan, Peoples R China.
C3 Henan University of Technology
RP Zhang, QH (corresponding author), Henan Univ Technol, Coll Informat Sci & Engn, Lianhua Ave 100, Zhengzhou 450001, Henan, Peoples R China.
EM zqh131@163.com; wancx917@163.com; hanweiliang1205@126.com
FU National Natural Science Foundation of China [U1404617]; Outstanding
   Youth Project of Science and Technology Innovation Talent Program of
   Henan Province [174100510011]; Program for Innovative Research Team (in
   Science and Technology) in Henan Province University [16IRTSTHN026]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1404617), Outstanding Youth Project of Science and
   Technology Innovation Talent Program of Henan Province (No.
   174100510011), and Program for Innovative Research Team (in Science and
   Technology) in Henan Province University (No. 16IRTSTHN026).
CR [Anonymous], CLUSTERING CLASSIFIC
   [Anonymous], 2002, Computer Science, DOI DOI 10.1007/978-3-642-27733-7299-3
   [Anonymous], 2017, IEEE Transactions on Information Theory
   Chen ZY, 2016, IEEE T GEOSCI REMOTE, V54, P103, DOI 10.1109/TGRS.2015.2451002
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cheng HY, 2012, IEEE T IMAGE PROCESS, V21, P2152, DOI 10.1109/TIP.2011.2172798
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leitloff J, 2014, REMOTE SENS-BASEL, V6, P11315, DOI 10.3390/rs61111315
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu Y, 2016, PROCEEDINGS OF THE SEVENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC 2016), P57, DOI 10.1145/2987550.2987564
   Noh S, 2016, IEEE T INTELL TRANSP, V17, P323, DOI 10.1109/TITS.2015.2466652
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Sun ZH, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1019, DOI 10.1109/ICDSP.2002.1028263
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
NR 31
TC 7
Z9 8
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29431
EP 29446
DI 10.1007/s11042-018-6769-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700056
DA 2024-07-18
ER

EF