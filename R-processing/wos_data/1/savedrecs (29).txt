FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Song, W
   Yun, S
   Jung, SW
   Won, CS
AF Song, Wanbin
   Yun, Seokmin
   Jung, Seung-Won
   Won, Chee Sun
TI Rotated top-bottom dual-kinect for improved field of view
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect sensor; FOV (Field Of View); RGB-D; Depth image panorama
ID REAL-TIME; IMAGE
AB Existing commodity depth sensors have limited the field of view (FOV) of depth scanning. Our solution for extending the FOV is to use multiple depth sensors and stitch the captured depth images to a depth panorama. In our case study, we use two Kinects to address the following two questions: what is the best layout of the two Kinects to maximize the FOV and, second, how to combine the depth images together to form the depth panorama. We answer these questions by proposing a rotated top-bottom (RTB) arrangement of the two Kinects to maximize the FOV. Since the two Kinects capture the depth images from their own views, the depth values are not necessarily identical for the same object. To solve this problem, the depth adjustments are made for a frontal reference coordinate. Moreover, the perspective distortions of the two Kinects with respect to the frontal reference coordinate are corrected by perspective transformations. Experimental results show that our RTB sensor can generate panorama depth images with an almost doubled FOV.
C1 [Song, Wanbin; Yun, Seokmin; Won, Chee Sun] Dongguk Univ Seoul, Dept Elect & Elect Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
   [Jung, Seung-Won] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
C3 Dongguk University; Dongguk University
RP Won, CS (corresponding author), Dongguk Univ Seoul, Dept Elect & Elect Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
EM wbsong@dongguk.edu; smyun@dongguk.edu; swjung83@dongguk.edu;
   cswon@dongguk.edu
RI Won, Chee Sun/AAI-1101-2020
OI Jung, Seung-Won/0000-0002-0319-4467; Won, Chee Sun/0000-0002-3400-0792
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [NRF-2013R1A1A2005024];
   MSIP(Ministry of Science, ICT and Future Planning), Korea under
   ITRC(Information Technology Research Center) [IITP-2015-H8501-15-1014]
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2013R1A1A2005024) and by the MSIP(Ministry of Science,
   ICT and Future Planning), Korea, under the ITRC(Information Technology
   Research Center) support program (IITP-2015-H8501-15-1014) supervised by
   the IITP(Institute for Information & communications Technology
   Promotion).
CR Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], ACQUISITION DUAL RGB
   [Anonymous], INT IND TRAIN SIM ED
   [Anonymous], 2011, P 2011 3DTV C TRUE V, DOI DOI 10.1109/3DTV.2011.5877181
   Asteriadis S., 2013, Proceedings of the 6th International Conference on Computer Vision / Computer Graphics Collaboration Techniques and Applications. MIRAGE '13, P3, DOI DOI 10.1145/2466715.2466727
   Benavidez P., 2011, Proceedings of the 2011 6th International Conference on System of Systems Engineering (SoSE), P299, DOI 10.1109/SYSOSE.2011.5966614
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Burgin W, 2011, ACMIEEE INT CONF HUM, P119, DOI 10.1145/1957656.1957690
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chun S, 2014, MULTIMED TOOLS APPL, V72, P253, DOI 10.1007/s11042-013-1359-2
   Gottfried Jens-Malte, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P758
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Kim S, 2012, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2012.6467526
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Riche Nicolas, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P143, DOI 10.1007/978-3-642-23968-7_15
   Satta Riccardo, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P407
   Sch~nauer C, 2011, P WORKSHOP WHOLE BOD, P1
   Stowers J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P358, DOI 10.1109/ICMECH.2011.5971311
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Zhang LC, 2012, IEEE INT C INT ROBOT, P2389, DOI 10.1109/IROS.2012.6385968
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zug S, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2012), P144, DOI 10.1109/ROSE.2012.6402619
NR 24
TC 6
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8569
EP 8593
DI 10.1007/s11042-015-2772-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300020
DA 2024-07-18
ER

PT J
AU Li, ZQ
   Gao, Y
AF Li, Zuoqiang
   Gao, Yong
TI Acoustic feature extraction method for robust speaker identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust speaker identification; Gammatone filter banks; Feature
   extraction; RASTA; CMVN
ID ADDITIVE NOISE; RECOGNITION
AB When there is a mismatch between the acoustic training environment and the testing environment, the performance of automatic speaker identification systems degrades significantly. A robust feature extraction method for speaker recognition based on the gammatone filter is therefore proposed in this paper. By employing the working mechanism of the human auditory model instead of the traditional triangular filter banks, gammatone filter banks are used to simulate the auditory model of the human ear cochlea. The cube root compression method, equal loudness technology, and relative spectral (RASTA) filtering technology are incorporated into the robust feature extraction process. A simulation experiment is conducted based on the Gaussian mixture model (GMM) recognition algorithm. The experimental results indicate that the proposed feature parameters could show superior robustness and represent the characteristics of the speaker better than the conventional mel-frequency cepstrum coefficient (MFCC), cochlear cepstrum coefficient (CFCC) and relative spectra-perceptual linear predictive (RASTA-PLP) parameters.
C1 [Li, Zuoqiang; Gao, Yong] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Li, ZQ (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Sichuan, Peoples R China.
EM 469574181@qq.com; gaoyong@scu.edu.cn
OI zuoqiang, li/0000-0003-3386-8394
CR Acero A., 1993, ACOUSTICAL ENV ROBUS, V201
   COHEN JR, 1989, J ACOUST SOC AM, V85, P2623, DOI 10.1121/1.397756
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H., 1992, ICASSP, V1992, P121, DOI DOI 10.1109/ICASSP.1992.225957
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Hunt M. J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P215, DOI 10.1109/ICASSP.1988.196552
   Johannesma P., 1972, The pre-response stimulus ensemble of neurons in the cochlear nucleusJ, P58
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Lyon R. F., 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P3809, DOI 10.1109/ISCAS.2010.5537724
   Nemer E, 2001, IEEE T SPEECH AUDI P, V9, P217, DOI 10.1109/89.905996
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Seneff S., 1990, READINGS SPEECH RECO, P101
   Shao Y, 2009, INT CONF ACOUST SPEE, P4625, DOI 10.1109/ICASSP.2009.4960661
   STEVENS SS, 1972, J ACOUST SOC AM, V51, P575, DOI 10.1121/1.1912880
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   von Bekesy Georg., 1961, Nobel Lecture
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
   Zheng R, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P289
   ZUE V, 1990, INT CONF ACOUST SPEE, P49, DOI 10.1109/ICASSP.1990.115534
NR 26
TC 15
Z9 16
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7391
EP 7406
DI 10.1007/s11042-015-2660-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400032
DA 2024-07-18
ER

PT J
AU Xie, SY
   Guan, YP
AF Xie, Shiyang
   Guan, Yepeng
TI Motion instability based unsupervised online abnormal behaviors
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Direction randomness; Motion intensity; Motion
   instability
ID MODEL
AB Automatically detecting anomaly in surveillance videos is a crucial issue for social security. Motion instability based online abnormal behaviors detection has been developed in an unsupervised way. The motion instability is composed of direction randomness and motion intensity of particles gotten by optical flow based consecutive motion feature extraction. The direction randomness is gotten based on weighted average of a circular variance of all particles. The motion intensity is determined according to average energy of all particles considering the camera perspective effect. A feature tracking based scheme has been employed to extract spatial-temporal motion features from videos to increase the processing speed. An adaptive dynamic thresholding strategy is developed to detect deviation of the track from the patterns observed both in direction randomness and motion intensity. Besides a double-threshold inference strategy is adopted to determine the range of the motion instability. A state transition model is used to reduce false alarm for confirming anomaly. The anomaly in the video is fast online detected in an ordinary hardware from a cluttered scene without any hypothesis for the scenario contents in advance. Comparative study with state-of-the-arts has indicated the superior performance of the developed approach.
C1 [Xie, Shiyang; Guan, Yepeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Guan, Yepeng] Minist Educ, Key Lab Adv Displays & Syst Applicat, Shanghai, Peoples R China.
C3 Shanghai University
RP Guan, YP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.; Guan, YP (corresponding author), Minist Educ, Key Lab Adv Displays & Syst Applicat, Shanghai, Peoples R China.
EM ypguan@shu.edu.cn
FU Natural Science Foundation of China [11176016, 60872117]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20123108110014]
FX This work is supported partly by the Natural Science Foundation of China
   (Grant no. 11176016, 60872117), and Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant no. 20123108110014).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Ali S, 2007, PROC CVPR IEEE, P65
   Alvar M, 2014, MACH VISION APPL, V25, P1351, DOI 10.1007/s00138-014-0615-4
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], J INFORM COMPUT SCI
   [Anonymous], 1999, TECHNICAL REPORT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P EUR C COMP VIS
   [Anonymous], J COMPUT INF SYST
   [Anonymous], P IEEE C COMP VIS PA
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Kuhn A, 2012, IEEE INT WORKSH MULT, P387, DOI 10.1109/MMSP.2012.6343474
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lu Haixian, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P96, DOI 10.1109/ICALIP.2012.6376593
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Sharif MH, 2012, PATTERN RECOGN, V45, P2543, DOI 10.1016/j.patcog.2011.11.023
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6
   Wei-Ya Ren, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P212, DOI 10.1109/ICWAPR.2012.6294781
   Wiliem A, 2012, COMPUT VIS IMAGE UND, V116, P194, DOI 10.1016/j.cviu.2011.10.001
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Xu JX, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P48, DOI 10.1109/AVSS.2012.80
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
NR 33
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7423
EP 7444
DI 10.1007/s11042-015-2664-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400034
DA 2024-07-18
ER

PT J
AU Fu, ZH
   Li, JW
AF Fu, Zhong-hua
   Li, Jian-wei
TI GPU-based image method for room impulse response calculation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Room impulse response; Graphics processing unit; Image; source model
ID SOUND-PROPAGATION; REVERBERATION; EFFICIENT
AB Room impulse response (RIR) simulation based on the image-source method is widely used in room acoustic research. The calculation of the RIR in computer has to digitalize sound propagation delay into discrete samples. To carefully consider the digitalization error greatly increases the massive computational load of the image-source method. Therefore many real-time audio applications simply round-off the propagation delay to its nearest sample. This approximation, however, especially when the sampling frequency is low, degrades the phase precision that is required by applications such as microphone array. In this paper, by involving a Hanning-windowed ideal low-pass filter to reduce the digitalization error, a more precise image-source model is studied. We analyze its parallel calculation procedure and propose to use Graphics Processing Unit (GPU) to accelerate the calculation speed. The calculation procedure is divided into many parallel threads and arranged according the GPU architecture and its optimization criteria. We evaluate the calculation speeds of different RIRs using a general 5-core CPU, an ordinary GPU (GTX750) and an advanced GPU (K20C). The results show that, with similar precise RIR results, the speedup ratios of GTX750 and K20C over the general CPU can achieve 20 and 120 respectively.
C1 [Fu, Zhong-hua; Li, Jian-wei] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Li, JW (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM 840318140@qq.com; ljjianweiyx@gmail.com
RI li, jian/GSE-0245-2022; LI, JIAN/JAX-3092-2023; LI, JIAN/GRY-2197-2022;
   l, j/HNC-5728-2023
CR ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   Antani L, 2013, IEEE T VIS COMPUT GR, V19, P567, DOI 10.1109/TVCG.2013.27
   Campbell D. R., 2005, COMPUT INF SYST, V9, P48
   corporation N, 2009, NVID CUD PROGR GUID
   Cowan B, 2011, P AES INT C BIN SON
   Gallo E, 2004, ACM WORKSH GEN PURP
   Habets E. A. P, 2010, Tech. Rep.
   He J, 2013, SMART SUST CIT 2013, P361, DOI [10.1049/cp.2013.1957, DOI 10.1049/CP.2013.1957]
   Huang Y., 2006, Acoustic MIMO signal processing
   Huang YT, 2011, IEEE SIGNAL PROC MAG, V28, P20, DOI 10.1109/MSP.2010.938754
   Jedrzejewski M, 2004, P INT C COMP VIS GRA, P587
   Kinsier LE, 2009, FUNDAMENTALS ACOUSTI
   KULOWSKI A, 1985, APPL ACOUST, V18, P449, DOI 10.1016/0003-682X(85)90024-6
   Kuttruff H., 2000, Room Acoustics
   Laine S, 2009, APPL ACOUST, V70, P172, DOI 10.1016/j.apacoust.2007.11.011
   Lehmann EA, 2010, IEEE T AUDIO SPEECH, V18, P1429, DOI 10.1109/TASL.2009.2035038
   McGovern SG, 2009, APPL ACOUST, V70, P182, DOI 10.1016/j.apacoust.2008.02.003
   PETERSON PM, 1986, J ACOUST SOC AM, V80, P1527, DOI 10.1121/1.394357
   Raghuvanshi N, 2009, EAA S AUR
   Raghuvanshi N, 2009, IEEE T VIS COMPUT GR, V15, P789, DOI [10.1109/TVCG.2009.27, 10.1109/TVCG.2009.28]
   Rober N., 2007, 10 INT C DIG AUD EFF, P10
   Rober N, 2006, INT COMP MUS C ICMC
   Ryoo S, 2008, PPOPP2008
   Savioja L., 2010, P INT C DIG AUD EFF, P1
   Savioja L., 1999, THESIS HELSINKI U TE
   Siltanen S, 2008, ACTA ACUST UNITED AC, V94, P410, DOI 10.3813/AAA.918049
   Siltanen S, 2009, ACTA ACUST UNITED AC, V95, P106, DOI 10.3813/AAA.918132
   Svensson UP, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P205, DOI 10.1109/ASPAA.2011.6082341
   Svensson UP, 2002, VIRTUAL, SYNTHETIC, AND ENTERTAINMENT AUDIO, P11
   Taylor M, 2010, TR10006 U N CAR
   Tsingos Nicolas, 2009, P EAA S AUR ESP FINL
   Verdoolaege S, 2013, ACM T ARCHIT CODE OP, V9
   Yang Y, 2015, J COMPUT SCI TECH-CH, V30, P3, DOI 10.1007/s11390-015-1500-y
   Zhang Q, 2005, LECT NOTES COMPUT SC, V3711, P328
NR 34
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5205
EP 5221
DI 10.1007/s11042-015-2943-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700022
OA hybrid
DA 2024-07-18
ER

PT J
AU Kordelas, A
   Politis, I
   Dagiuklas, T
AF Kordelas, Athanasios
   Politis, Ilias
   Dagiuklas, Tasos
TI Transport analysis and quality evaluation of MVC video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264 MVC; NAL; Fragmentation unit; SNU; MOS; PSNR; SSIM; VQM
ID H.264/AVC; EXTENSION
AB This paper explores the performance of the emerging H.264/MVC standard for stereo video under various packetization schemes, encoding parameters and network conditions. An experimentation test-bed platform has been developed to support the multi session transmission approach for various video packetization options under various number of NAL units per frame. The paper presents measurements in terms of overhead as well as 3D video quality for sequences with different characteristics in terms of spatial resolution and motion. Extensive test-bed experiments indicate that the fragmentation of frames in more than one NAL units improves the perceived video quality measured objectively in terms of PSNR, VQM, SSIM for both base and non-base view as well as, subjectively in terms of 3D MOS.
C1 [Kordelas, Athanasios] Univ Patras, Dept Elect & Comp Engn, Patras, Greece.
   [Politis, Ilias; Dagiuklas, Tasos] Hellen Open Univ, Sch Sci & Technol, Patras, Greece.
C3 University of Patras; Hellenic Open University
RP Politis, I (corresponding author), Hellen Open Univ, Sch Sci & Technol, Patras, Greece.
EM kordelas@ece.upatras.gr; ilpolitis@eap.gr; dagiuklas@eap.gr
RI Politis, Ilias/AAP-9520-2021
OI Politis, Ilias/0000-0002-1083-0345
FU SIEMENS "Excellence" Program by the State Scholarship Foundation (IKY),
   Greece
FX This work was supported by the SIEMENS "Excellence" Program by the State
   Scholarship Foundation (IKY), Greece.
CR Akar GB, 2007, IEEE T CIRCUITS SYST, V17
   Amon P, 2007, IEEE T CIRC SYST VID, V17, P1174, DOI 10.1109/TCSVT.2007.905521
   [Anonymous], 2002, BT.500-11,
   [Anonymous], 2007, JTC1SC29WG11 ISOIEC
   [Anonymous], P IEEE
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Dagiuklas T, 2012, IJCSI INT J COMPUTER
   De Silva V, 2012, ROM WORKSH ATH
   Gürler CG, 2011, P IEEE, V99, P694, DOI 10.1109/JPROC.2010.2100010
   Hallapuro A, 3D VIDEO MVC STANDAR
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   IETF Draft, 2011, RTP PAYLOAD IN PRESS
   IETF Draft, 2005, RFC3984
   IETF Draft, 2010, RTP PAYLOAD IN PRESS
   IETF Draft, 2005, RTP PAYLOAD IN PRESS
   ITU Radio Communication Sector, 2002, METH SUBJ QUAL TEL P
   Kordelas A, 2012, PERFORMANCE H 264 MV
   Kordelas A, 2012, 16 PANHELLENIC C INF
   Liu S, 2008, FRAME LOSS ERROR CON, DOI [10.1109/ISCAS.2008.4542206, DOI 10.1109/ISCAS.2008.4542206]
   Liu Z, 2011, EXPT EVALUATION H 26
   Merkle P., 2007, IEEE INT C IM PROC S
   Micallef B, 2010, MELECON 2010 2010 15
   Oelbaum T, 2008, IEEE IMAGE PROC, P2772, DOI 10.1109/ICIP.2008.4712369
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Schierl T, 2011, P IEEE, V99, P671, DOI 10.1109/JPROC.2010.2091370
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seo KD, 2010, ETRI J, V32, P281, DOI 10.4218/etrij.10.1409.0031
   Smolic A, 2007, IEEE T CIRCUITS SYST, V17
   Su GM, 2011, INT J COMMUN SYST, V24, P1261, DOI 10.1002/dac.1190
   Vetro A, 2011, OVERVIEW STEREO MULT, DOI [10.1109/JPROC.2010.2098830, DOI 10.1109/JPROC.2010.2098830]
   Vetro A, 2011, OVERVIEW STEREO MULT, V99
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Zhu T, 2012, P 6 INT WORKSH VID P
NR 33
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5619
EP 5644
DI 10.1007/s11042-015-2530-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600013
DA 2024-07-18
ER

PT J
AU Zlitni, T
   Bouaziz, B
   Mahdi, W
AF Zlitni, Tarek
   Bouaziz, Bassem
   Mahdi, Walid
TI Automatic topics segmentation for TV news video using prior knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV stream structuring; Video grammar; TV news segmentation;
   Content-based video indexing; Automatic topics detection
AB TV streams represent a principal source of multimedia information. The goal of the proposed approach is to enable a better exploitation of this source of video by multimedia services (i.e., TV-On-Demand, catch-up TV), social community, and video-sharing platforms (Vimeo, Youtube, Facebook.). In this work, we present an automatic structuring approach of TV news. The originality of the approach is the use of the contextual and operational characteristics as prior knowledge. This knowledge is modeled as video grammar which governs the structuring of TV stream content. This structuring is carried out on two levels. The first level identifies news programs in TV stream. The second level aims to identify the internal structure of the identified news programs. At this level, we opt to treat the case of TV news programs due to the large audience because of pertinent information within. Comparison experiments to similar works have been carried out on the TRECVID 2003 database. We show significant improvements to TV news structuring exceed 90 %.
C1 [Zlitni, Tarek; Bouaziz, Bassem] Univ Sfax, Higher Inst Informat Technol & Multimedia, Sfax, Tunisia.
   [Mahdi, Walid] Taif Univ, KSA, Coll Comp & Informat Technol, At Taif, Saudi Arabia.
   [Zlitni, Tarek; Bouaziz, Bassem; Mahdi, Walid] MIRACL Lab, Sfax, Tunisia.
C3 Universite de Sfax; Taif University; Multimedia, InfoRmation Systems &
   Advancing Computing Laboratory (MIRACL); Universite de Sfax
RP Zlitni, T (corresponding author), Univ Sfax, Higher Inst Informat Technol & Multimedia, Sfax, Tunisia.
EM tarek.zlitni@isimsf.rnu.tn; bassem.bouaziz@isimsf.rnu.tn;
   walid.mahdi@isimsf.rnu.tn
RI MAHDI, Walid/HOF-7688-2023; BOUAZIZ, Bassem/J-4608-2016; BOUAZIZ,
   Bassem/AAM-2832-2020
OI MAHDI, Walid/0000-0003-3465-0397; BOUAZIZ, Bassem/0000-0002-3692-9482; 
CR Abduraman AE, 2011, TECH APPL
   [Anonymous], 2000, PROC IMAGE VISION CO
   [Anonymous], 2008, INDIAN J SCI TECHNOL
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Athanasakos KC, 2007, 10 INT C COMP GRAPH, P181
   Colace F, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1351
   David C, 1991, PRACTICE VIDEO
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Dumont É, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/732514
   Dunker P, 2008, IEEE INT S CONS EL, P1
   Goyal A, 2009, LECT NOTES COMPUT SC, V5478, P766, DOI 10.1007/978-3-642-00958-7_82
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hua S., 2012, EURASIP J IMAGE VIDE
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Jacobs A., 2004, TRECVID, V2004, P197
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marquez GRC, 2011, CEUR WORKSHOP, V719, P24
   Misra H, 2010, LECT NOTES COMPUT SC, V5916, P347, DOI 10.1007/978-3-642-11301-7_36
   Montagnuolo M, 2009, MULTIMED TOOLS APPL, V41, P125, DOI 10.1007/s11042-008-0222-3
   Naturel X, 2008, MULTIMED TOOLS APPL, V38, P233, DOI 10.1007/s11042-007-0180-1
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   O'Hare N, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1028
   Poli JP, 2008, MULTIMEDIA SYST, V14, P255, DOI 10.1007/s00530-008-0140-2
   Poulisse GJ, 2010, MULTIMED TOOLS APPL, V48, P3, DOI 10.1007/s11042-009-0358-9
   Ravani R, 2010, INT C SYST SIGN IM, P518
   Smeaton AF, 2003, TRECVID 2003 TEXT RE
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang JQ, 2006, LECT NOTES COMPUT SC, V4261, P279
   Wu XM, 2010, LECT NOTES COMPUT SC, V5916, P533
   Xie L, 2011, INFORM SCIENCES, V181, P2873, DOI 10.1016/j.ins.2011.02.013
   Zlitni T., 2010, 2nd International Conference on Computer Technology and Development (ICCTD 2010), P517, DOI 10.1109/ICCTD.2010.5645953
   Zlitni T, 2009, 7 INT C ADV MOB COMP, P316
NR 34
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5645
EP 5672
DI 10.1007/s11042-015-2531-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600014
DA 2024-07-18
ER

PT J
AU Farash, MS
   Kumari, S
   Bakhtiari, M
AF Farash, Mohammad Sabzinejad
   Kumari, Saru
   Bakhtiari, Majid
TI Cryptanalysis and improvement of a robust smart card secured
   authentication scheme on SIP using elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography; Authentication scheme; Session initiation
   protocol; Random oracle model
ID KEY EXCHANGE PROTOCOL; MUTUAL AUTHENTICATION; AGREEMENT; EFFICIENT
AB The session initiation protocol (SIP) has been receiving a lot of attention to provide security in the Voice over IP (VoIP) in Internet and mobility management. Recently, Yeh et al. proposed a smart card-based authentication scheme for SIP using elliptic curve cryptography (ECC). They claimed that their scheme is secure against known security attacks. However, in this paper, we indicate that Yeh et al.'s scheme is vulnerable to off-line password guessing attack, user impersonation attack and server impersonation attack, in the case that the smart card is stolen and the information stored in the smart card is disclosed. As a remedy, we also propose an improved smart card-based authentication scheme which not only conquers the security weaknesses of the related schemes but also provides a reduction in computational cost. The proposed scheme also provides the user anonymity and untraceability, and allows a user to change his/her password without informing the remote server. To show the security of our protocol, we prove its security the random oracle model.
C1 [Farash, Mohammad Sabzinejad] Kharazmi Univ, Fac Math Sci & Comp, Tehran, Iran.
   [Kumari, Saru] Dr BRA Univ, Agra Coll, Dept Math, Agra, Uttar Pradesh, India.
   [Bakhtiari, Majid] UTM, Fac Comp, Johor Baharu, Malaysia.
C3 Kharazmi University; Agra College; Universiti Teknologi Malaysia
RP Farash, MS (corresponding author), Kharazmi Univ, Fac Math Sci & Comp, Tehran, Iran.
EM sabzinejad@khu.ac.ir; bakhtiari@utm.my
RI Farash, Mohammad sabzinejad/A-2667-2015; Kumari, Saru/K-2038-2019
OI Farash, Mohammad sabzinejad/0000-0001-5821-4237; Kumari,
   Saru/0000-0003-4929-5383
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3570, P341
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], ISC INT J INF SECUR
   [Anonymous], ADV CRYPTOLOGY CRYPT
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Bayat M., 2010, Proceedings 2010 IEEE/IFIP 8th International Conference on Embedded and Ubiquitous Computing (EUC 2010), P578, DOI 10.1109/EUC.2010.93
   Chen TH, 2010, COMM COM INF SC, V119, P46
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9948-1
   Farash M.S., 2014, INT J NETW SECUR, V16, P143
   Farash M.S., 2012, IACSIT INT J ENG TEC, V4, P321
   Farash MS, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2879
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2015, CONCURR COMP-PRACT E, V27, P4897, DOI 10.1002/cpe.3477
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P405, DOI 10.1007/s11042-014-2296-4
   Farash MS, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2912
   Farash MS, 2016, INT J COMMUN SYST, V29, P1956, DOI 10.1002/dac.2848
   Farash MS, 2015, INT J NETW MANAG, V25, P31, DOI 10.1002/nem.1883
   Farash MS, 2014, J SUPERCOMPUT, V70, P1002, DOI 10.1007/s11227-014-1273-z
   Farash MS, 2014, J SUPERCOMPUT, V70, P987, DOI 10.1007/s11227-014-1272-0
   Farash MS, 2014, J SUPERCOMPUT, V69, P395, DOI 10.1007/s11227-014-1170-5
   Farash MS, 2014, INF TECHNOL CONTROL, V43, P143, DOI 10.5755/j01.itc.43.2.3790
   Farash MS, 2014, NONLINEAR DYNAM, V77, P399, DOI 10.1007/s11071-014-1304-6
   Farash MS, 2014, NONLINEAR DYNAM, V76, P1203, DOI 10.1007/s11071-013-1204-1
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   Farash MS, 2013, COMPUT ELECTR ENG, V39, P530, DOI 10.1016/j.compeleceng.2012.09.004
   Farash MS, 2012, INT ISC CONF INFO SE, P32, DOI 10.1109/ISCISC.2012.6408187
   Farash MS, 2011, COMPUT ELECTR ENG, V37, P199, DOI 10.1016/j.compeleceng.2011.02.007
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Lee YC, 2013, J INF SCI ENG, V29, P1121
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Wang YG, 2012, IFIP ADV INF COMM TE, V376, P489
   Wu SH, 2012, SECUR COMMUN NETW, V5, P236, DOI 10.1002/sec.315
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Yoon EJ, 2009, CISIS: 2009 INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, VOLS 1 AND 2, P549, DOI 10.1109/CISIS.2009.93
   Zhang LP, 2014, SECUR COMMUN NETW, V7, P2405, DOI 10.1002/sec.951
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
NR 42
TC 25
Z9 25
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4485
EP 4504
DI 10.1007/s11042-015-2487-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700015
DA 2024-07-18
ER

PT J
AU Guesmi, R
   Ben Farah, MA
   Kachouri, A
   Samet, M
AF Guesmi, Ramzi
   Ben Farah, Mohamed Amine
   Kachouri, Abdennaceur
   Samet, Mounir
TI Hash key-based image encryption using crossover operator and chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Hash function; Crossover
ID SCHEME; CRYPTANALYSIS
AB This paper proposes a color image encryption scheme using one-time keys based on crossover operator, chaos and the Secure Hash Algorithm(SHA-2). The (SHA-2) is employed to generate a 256-bit hash value from both the plain-image and the secret hash keys to make the key stream change in each encryption process. The SHA-2 value is employed to generate three initial values of the chaotic system. The permutation-diffusion process is based on the crossover operator and XOR operator, respectively. Experimental results and security analysis show that the scheme can achieve good encryption result through only one round encryption process, the key space is large enough to resist against common attacks,so the scheme is reliable to be applied in image encryption and secure communication.
C1 [Guesmi, Ramzi; Ben Farah, Mohamed Amine; Kachouri, Abdennaceur; Samet, Mounir] Sfax Univ, Natl Engn Sch Sfax, Lab Elect & Informat Technol, BPW 3038 Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Guesmi, R (corresponding author), Sfax Univ, Natl Engn Sch Sfax, Lab Elect & Informat Technol, BPW 3038 Sfax, Sfax, Tunisia.
EM ramzi.guesmi@gmail.com; med.farah@yahoo.fr;
   abdennaceur.kachouri@enis.rnu.tn; mounir.samet@enis.rnu.tn
RI Guesmi, Ramzi/AAD-1216-2020; Farah, Mohamed Amine Ben/AAI-1932-2019;
   Kachouri, Abdennaceur/AAG-8406-2020
OI Guesmi, Ramzi/0000-0001-8759-0151; Farah, Mohamed Amine
   Ben/0000-0002-0135-9942; 
CR Algredo-Badillo I, 2013, MICROPROCESS MICROSY, V37, P750, DOI 10.1016/j.micpro.2012.06.007
   Alvarez G, 2003, PHYS LETT A, V311, P172, DOI 10.1016/S0375-9601(03)00469-9
   [Anonymous], 2002, FED INF PROC STAND P
   Arroyo D, 2011, COMMUN NONLINEAR SCI, V16, P805, DOI 10.1016/j.cnsns.2010.04.031
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Chang CC, 2002, PATTERN RECOGN LETT, V23, P1847, DOI 10.1016/S0167-8655(02)00157-5
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Holland J.H., 1975, Adaptation in Natural and Artificial Systems: An introductory Analysis with Applications to Biology, Control and Artificial Intelligence, DOI DOI 10.1137/1018105
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Li CQ, 2010, INT J BIFURCAT CHAOS, V20, P2561, DOI 10.1142/S0218127410027192
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Ramasubramanian K, 2000, PHYSICA D, V139, P72, DOI 10.1016/S0167-2789(99)00234-1
   Rhouma R, 2009, PHYS LETT A, V373, P3398, DOI 10.1016/j.physleta.2009.07.035
   Solak E, 2011, INFORM SCIENCES, V181, P227, DOI 10.1016/j.ins.2010.09.009
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
NR 24
TC 86
Z9 89
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4753
EP 4769
DI 10.1007/s11042-015-2501-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700028
DA 2024-07-18
ER

PT J
AU Yin, XH
   Zhou, SB
   Siddique, MA
AF Yin, Xuehui
   Zhou, Shangbo
   Siddique, Muhammad Abubakar
TI Fractional nonlinear anisotropic diffusion with <i>p</i>-Laplace
   variation method for image restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional-order differentiation; Nonlinear diffusion; p-Laplace; Image
   restoration
ID SPLINES
AB In this paper, a novel class of fractional-order nonlinear anisotropic diffusion equations based image restoration model is established, which employs the p-Laplace norm of fractional-order gradient of an image intensity function. The role of the fractional-order gradient is to better accommodate the texture details of an image, and the adaptive factor p can be used to diffuse adaptively according to local geometry features, which are fractional-order curvature and fractional-order gradient of an image. Besides removing noise and non-linearly keeping high-frequency edge of images efficiently, our proposed model can enhance the texture details of images and greatly eliminate the staircase effects and also the speckle effects. Fourier transform technique is also proposed to compute the fractional order derivative. Experimental results illustrate that our proposed model can deal with edge preserving and texture enhancing, more efficiently than the other four methods and outperform the other four methods by means of PSNR. Our average PSNR is closed to 1dB higher than the average PSNRs of the other four methods.
C1 [Yin, Xuehui; Zhou, Shangbo; Siddique, Muhammad Abubakar] Chongqing Univ, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400030, Peoples R China.
   [Yin, Xuehui; Zhou, Shangbo; Siddique, Muhammad Abubakar] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Siddique, Muhammad Abubakar/AAO-9279-2021
OI Siddique, Muhammad Abubakar/0000-0001-9721-3034
FU Fundamental Research Funds for the Central Universities
   [106112014CDJZR188801]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities No. 106112014CDJZR188801.
CR [Anonymous], 2001, ELECTRON J DIFFER EQ
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Bergounioux M, 2010, J FUNCT ANAL, V259, P2296, DOI 10.1016/j.jfa.2010.05.016
   Blomgren P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P384, DOI 10.1109/ICIP.1997.632128
   Blomgren PV, 2000, IEEE T IMAGE PROCESS, V9, P1723
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen JJ, 2010, P ICISP, P143
   Chen YM, 2006, SIAM J APPL MATH, V66, P1383, DOI 10.1137/050624522
   Cuesta E, 2012, SIGNAL PROCESS, V92, P553, DOI 10.1016/j.sigpro.2011.09.001
   Dobrosotskaya JA, 2008, IEEE T IMAGE PROCESS, V17, P657, DOI 10.1109/TIP.2008.919367
   Hua JY, 2014, MULTIMED TOOLS APPL, V69, P157, DOI 10.1007/s11042-012-1263-1
   Janev M, 2011, MATH COMPUT MODEL, V54, P729, DOI 10.1016/j.mcm.2011.03.017
   Jun Z, 2011, APPL MATH MODEL, V35, P2516, DOI 10.1016/j.apm.2010.11.049
   Jung MY, 2011, IEEE T IMAGE PROCESS, V20, P1583, DOI 10.1109/TIP.2010.2092433
   Keshari S, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033018
   Kristály A, 2008, NONLINEAR ANAL-THEOR, V68, P1375, DOI 10.1016/j.na.2006.12.031
   Li F, 2010, APPL MATH COMPUT, V216, P870, DOI 10.1016/j.amc.2010.01.094
   LINDQVIST P., 2006, NOTES P LAPLACE EQUA, V102
   Mathieu B, 2003, SIGNAL PROCESS, V83, P2421, DOI 10.1016/S0165-1684(03)00194-4
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Podlubny I., 1999, FRACTIONAL DIFFERENT
   Pu YF, 2008, SCI CHINA SER F, V51, P1319, DOI 10.1007/s11432-008-0098-x
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   Unser M, 2000, SIAM REV, V42, P43, DOI 10.1137/S0036144598349435
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   You YL, 1998, IEEE T IMAGE PROCESS, V7, P304
   [ZHANG HongYing 张红英], 2007, [自动化学报, Acta Automatica Sinica], V33, P546
   Zhang J, 2012, J MATH IMAGING VIS, V43, P39, DOI 10.1007/s10851-011-0285-z
   Zhang Y, 2012, APPL MATH INFORM SCI, V6, P299
NR 33
TC 19
Z9 19
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4505
EP 4526
DI 10.1007/s11042-015-2488-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700016
DA 2024-07-18
ER

PT J
AU Zhao, PH
   Liu, YW
   Liu, JX
   Yao, RX
   Ci, S
AF Zhao, Pinghua
   Liu, Yanwei
   Liu, Jinxia
   Yao, Ruixiao
   Ci, Song
TI Perceptual rate-distortion optimization for H.264/AVC video coding from
   both signal and vision perspectives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual quality; Rate-distortion optimization; Lagrange multiplier
   adjustment; H.264/AVC
ID SSIM
AB Recent researches have shown that the Structural SIMilariy (SSIM)-based Rate-Distortion Optimization (RDO) can obtain more structural information than the traditional SSE-based RDO for video coding. Correspondingly, the perceptual video quality is improved at certain degree for the video stream encoded by the SSIM-based RDO. However, for the MB with significant luminance change (due to the flashlight or sunshine change, etc.) but little structure change compared to the co-located MB in the referred frame, the SSIM-based RDO may select improper encoding mode (SKIP) which leads to uncomfortable visual experience. In this paper, involving the surrounding pixels of the current coding MB into the measurement of spacial texture quality degradation, the RDO which jointly considers the SSIM-based distortion and SSE-based distortion is proposed to improve H.264/AVC perceptual coding performance. The Lagrange multiplier in the proposed RDO is firstly derived at the frame level. Then, to make the Lagrange multiplier more adaptive to the specific video content, the Lagrange multiplier for each individual MB is refined based on the visual information theory. Experimental results show that the proposed perceptual RDO can select the optimal encoding mode which preserves as much structural infoarmation as possible with as little SSE-based distortion as possible, and tht the perceptual quality of the encoded video is improved.
C1 [Zhao, Pinghua; Ci, Song] Chinese Acad Sci, Inst Acoust, Beijing, Peoples R China.
   [Zhao, Pinghua; Liu, Yanwei; Yao, Ruixiao] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
   [Ci, Song] Univ Nebraska Lincoln, Omaha, NE USA.
   Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese
   Academy of Sciences; Institute of Information Engineering, CAS; Zhejiang
   Wanli University; University of Nebraska System; University of Nebraska
   Lincoln; Chinese Academy of Sciences
RP Liu, YW (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM zhaopinghua205@163.com; liuyanwei@iie.ac.cn
RI Ci, Song/R-8324-2019; liu, yanwei/L-2453-2019; Liu, Jinxia/H-1794-2011
FU NSFC [61102077, 61401109, 61472388]; National Key Technology RD Program
   [2012BAH01B03]; Zhejiang Provincial Natural Science Foundation of China
   [LY13F010012]; Public welfare projects of Zhejiang Province [2014C31072]
FX This work was supported in part by NSFC under Grant nos. 61102077,
   61401109 and 61472388, National Key Technology R&D Program 2012BAH01B03,
   Zhejiang Provincial Natural Science Foundation of China under Contract
   LY13F010012, Public welfare projects of Zhejiang Province under Contract
   2014C31072.
CR Bjontegaard G, 2001, ITU TQ 6 SG16 VCEG 1
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen ZZ, 2010, IEEE INT CON MULTI, P784, DOI 10.1109/ICME.2010.5582549
   Girod Bernd, 1993, P207
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1614, DOI 10.1109/TCSVT.2010.2087472
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang X, 2011, IEEE IMAGE PROC, P1653, DOI 10.1109/ICIP.2011.6115770
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wiegand T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958171
   Yang CL, 2007, LECT NOTES COMPUT SC, V4810, P168
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhao PH, 2013, IEEE INT SYMP CIRC S, P485, DOI 10.1109/ISCAS.2013.6571886
NR 15
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2781
EP 2800
DI 10.1007/s11042-015-2533-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000024
DA 2024-07-18
ER

PT J
AU Kuo, YH
   Gao, P
   Chen, J
AF Kuo, Yonghong
   Gao, Pan
   Chen, Jian
TI Distributed video coding with limited feedback requests
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Feedback control; Side information refinement;
   Correlation noise model refinement
ID SIDE INFORMATION; ALGORITHM
AB Traditional decoder rate control (DRC) distributed video coding (DVC) can dynamically adjust the amount of parity information through feedback channel, which guarantees that minimum parity information should be transmitted from the encoder to the decoder. However, frequent feedback requests increase system complexity and video transmission delay. To solve the problems caused by frequent requests, this paper proposes a new feedback control algorithm which purposefully requests for more parity information through the feedback channel. To achieve a good rate distortion (RD), the proposed DVC architecture also performs frame classification, side information refinement and correlation noise model refinement. Frame classification module makes the judgment whether the current frame worth coding according to the motion intensity, which reduces the complexity of DVC system. Side information and correlation noise model refinement are performed based on correctly decoded bit-planes, which contributes to decreasing the error rate of the decoded frame. Experimental results show that the new feedback control algorithm significantly decreases the number of feedback requests. A good rate RD performance is also achieved with only one request. The proposed architecture has a better RD performance than encoder rate control (ERC) systems, and it also achieves a similar performance to DRC systems without feedback constraints in literature.
C1 [Kuo, Yonghong; Gao, Pan; Chen, Jian] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Kuo, YH (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM yhkuo@mail.xidian.edu.cn
RI KUO, Yong-Hong/M-9078-2015
FU National Science Foundation China [61340033]; 111 Project of China
   [B08038]
FX This work was supported by the National Science Foundation China under
   grant 61340033 and the 111 Project of China (B08038).
CR [Anonymous], 2014, J CHONGQING U, DOI DOI 10.11835/J.ISSN.1000-582X.2014.05.014
   [Anonymous], J INFORM HIDING MULT
   [Anonymous], 2011, DISTRIBUTED MULTIPLE
   [Anonymous], 2009, IEEE P PCS
   Artigas X, 2005, Proceedings ELMAR-2005, P53
   Artigas X, 2007, P PCS, P6
   ASCENSO J, 2005, EURASIP C SPEECH IM
   Ascenso J, 2006, IEEE IMAGE PROC, P605, DOI 10.1109/ICIP.2006.312408
   Ascenso J, 2008, J VIS COMMUN IMAGE R, V19, P600, DOI 10.1016/j.jvcir.2008.06.001
   Brites C, 2011, IEEE T CIRC SYST VID, V21, P1278, DOI 10.1109/TCSVT.2011.2147210
   Deligiannis N, 2012, IEEE T IMAGE PROCESS, V21, P1934, DOI 10.1109/TIP.2011.2181400
   Esmaili GR, 2009, INT CONF ACOUST SPEE, P801, DOI 10.1109/ICASSP.2009.4959705
   Fan XP, 2009, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2009.5414618
   Kubasov D, 2006, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2006.313175
   Laurenson Dave, 2006, 2006 14 EUR SIGN PRO, P1
   Martinez JL, 2008, IEEE IMAGE PROC, P1140, DOI 10.1109/ICIP.2008.4711961
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Morbée M, 2007, INT CONF ACOUST SPEE, P521
   Sheng T, 2010, MULTIMEDIA SYST, V16, P127, DOI 10.1007/s00530-009-0179-8
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2012, IEEE T CIRC SYST VID, V22, P1014, DOI 10.1109/TCSVT.2012.2189669
   Weerakkody WARJ, 2009, IET IMAGE PROCESS, V3, P329, DOI 10.1049/iet-ipr.2008.0195
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Ye SM, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/683510
   Zhou L, 2014, IEEE T CIRC SYST VID, V24, P889, DOI 10.1109/TCSVT.2013.2291311
   Zhou L, 2011, IEEE T MULTIMEDIA, V13, P1040, DOI 10.1109/TMM.2011.2160716
NR 26
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2051
EP 2065
DI 10.1007/s11042-014-2392-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000015
DA 2024-07-18
ER

PT J
AU Liu, XL
   Huet, B
AF Liu, Xueliang
   Huet, Benoit
TI Event-based cross media question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Events; Social media; Illustration; Cross media; Question answering
AB User generated content, available in massive amounts on the Internet, is receiving increased attention due to its many potential applications. One of such applications is the representation of events using multimedia data. In this paper, an event-based cross media question answering system, which retrieves and summarizes events on a given topic is proposed. In other words, we present a framework for leveraging social media data to extract and illustrate social events automatically on any given query. The system is built in three steps. First, the input query is parsed semantically to identify the topic, location, and time information related to the News of interest. Then, we use the parsed information to mine the latest and hottest related News from social news web services. Third, to identify a unique event, we model the News content by latent Dirichlet Allocation and cluster the News using the DBSCAN algorithm. In the end, for each event, we retrieve both textual and visual content of News that refer the same event. The resulting documents are shown within a vivid interface featuring both event description, tag cloud and photo collage.
C1 [Liu, Xueliang] Hefei Univ Technol, Hefei, Peoples R China.
   [Huet, Benoit] EURECOM, Sophia Antipolis, France.
C3 Hefei University of Technology; IMT - Institut Mines-Telecom; EURECOM
RP Liu, XL (corresponding author), Hefei Univ Technol, Hefei, Peoples R China.
EM liuxueliang@hfut.edu.cn; benoit.huet@eurecom.fr
OI Huet, Benoit/0000-0002-0608-6939
FU 973 Program of China [2013CB329604]; European Commission [FP7-287911
   LinkedTV, FP7-318101 MediaMixer]
FX This work was supported by the 973 Program of China (No. 2013CB329604),
   and the European Commission under contracts FP7-287911 LinkedTV and
   FP7-318101 MediaMixer, as well as.
CR Allan J., 1998, P DARPA BROADC NEWS
   [Anonymous], MEDIAEVAL
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bao B.-K., 2012, P 20 ACM INT C MULT, P1357
   Becker H, 2012, ACM C WSDM
   Chen L., 2009, ACM C CIKM
   Delgado D., 2010, Proceedings of the 18th ACM International Conference on Multimedia, P1647, DOI DOI 10.1145/1873951.1874311
   Firan C.S., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P189
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Hong RC, 2012, IEEE MULTIMEDIA, V19, P72, DOI 10.1109/MMUL.2011.53
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Li Guangda., 2009, Proceedings of the 17th ACM international conference on Multimedia, P773
   Li HJ, 2012, NEUROCOMPUTING, V95, P72, DOI 10.1016/j.neucom.2011.06.040
   Liu X, 2011, ACM INT C ICMR TRENT
   Liu X, 2011, P MEDIAEVAL 2011 WOR
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Pan C.Mitra., 2011, Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries, JCDL '11, P349
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   Sakaki T, 2010, INT C WORLD WID WEB
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   [孙承杰 Sun Chengjie], 2004, [中文信息学报, Journal of Chinese Information Processing], V18, P17
   Wang M, 2013, ACM T INTERNET TECHN, V12, DOI 10.1145/2492690
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Weng J, 2011, AAAI C WEBL SOCIAL M
   Yahiaoui I, 2003, EURASIP J APPL SIG P, V2003, P01
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhu X., 2007, AAAI, V7, P1590, DOI 10.5555/1619797.1619900
NR 30
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1495
EP 1508
DI 10.1007/s11042-014-2085-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600009
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Yang, NC
   Liu, CS
   Tseng, PY
   Chang, CK
AF Kuo, Chung-Ming
   Yang, Nai-Chung
   Liu, Chih-Shan
   Tseng, Pi-Yun
   Chang, Chi-Kao
TI An effective and flexible image enhancement algorithm in compressed
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosines transform (DCT); Compressed domain; Multi-enhancement
   factors; Image enhancement
ID CONTRAST
AB Images with JPEG format using discrete cosine transform (DCT) is selected for most popular compression standards. Enhancement in the compressed domain offers two major advantages, including low computational complexity and storage space. However, the compression is achieved by block-based transform; therefore, it is hard to enhance image globally. In this paper, the main issue is to develop a global enhancement method that effectively reduces the introduced blocking artifacts and achieves excellent visual quality of enhancement. We propose a combined DCT matrix representation, which consists of 8n x 8n pixel arrays, to enhance the global information on images for removing block artifacts in compressed-domain. In addition, we propose the multi-enhancement factors based on spatial frequency for image enhancement in compressed domain. From the simulation results, the proposed method achieves not only excellent improvement for image enhancement but also reducing the blocking artifacts significantly.
C1 [Kuo, Chung-Ming; Yang, Nai-Chung; Liu, Chih-Shan; Tseng, Pi-Yun; Chang, Chi-Kao] I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
FU National Science Counsel [102-2221-E-214 - 034 -MY2]
FX This work was supported by the National Science Counsel Granted NSC
   102-2221-E-214 - 034 -MY2
CR Amore M., 2007, P INT S CIRC SYST, V2, P1
   Atta R, 2013, IET IMAGE PROCESS, V7, P472, DOI 10.1049/iet-ipr.2013.0083
   Ghimire D, 2011, IEEE T CONSUM ELECTR, V57, P858, DOI 10.1109/TCE.2011.5955233
   Jen TC, 2012, IEEE T CIRC SYST VID, V22, P831, DOI 10.1109/TCSVT.2011.2177184
   Jobson DJ, 2002, P SOC PHOTO-OPT INS, V4736, P25, DOI 10.1117/12.477589
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Kogan R, 1998, P SOC PHOTO-OPT INS, V3304, P153, DOI 10.1117/12.304595
   Konstantinides K, 1999, IEEE T IMAGE PROCESS, V8, P874, DOI 10.1109/83.766864
   Kumar A, 2012, IET SIGNAL PROCESS, V6, P617, DOI 10.1049/iet-spr.2011.0298
   Lee JH, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P120, DOI 10.1109/ICCE.2012.6161769
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Lee S, 2006, PATTERN RECOGN LETT, V27, P1054, DOI 10.1016/j.patrec.2005.12.004
   Mukherjee J, 2008, IEEE T IMAGE PROCESS, V17, P1783, DOI 10.1109/TIP.2008.2002826
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Pinoli JC, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.021101
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Sengar P. S., 2013, INT C MICR COMM REN, P1
   Singh TR, 2013, 2013 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P269, DOI 10.1109/ISCBI.2013.61
   Tang J, 2004, IEEE T BIO-MED ENG, V51, P2013, DOI 10.1109/TBME.2004.834264
   Tang JS, 2003, IEEE SIGNAL PROC LET, V10, P289, DOI 10.1109/LSP.2003.817178
   Tsai CY, 2012, IEEE T MULTIMEDIA, V14, P1140, DOI 10.1109/TMM.2012.2190390
   Vale EE, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1516, DOI 10.1109/ISCCSP.2008.4537467
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xia JJ, 2011, IEEE SYS MAN CYBERN, P1496, DOI 10.1109/ICSMC.2011.6083883
   Xie XD, 2005, PATTERN RECOGN, V38, P221, DOI 10.1016/j.patcog.2004.07.002
NR 27
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1177
EP 1200
DI 10.1007/s11042-014-2363-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700022
DA 2024-07-18
ER

PT J
AU Lin, CS
   Lin, JW
AF Lin, Chow-Sing
   Lin, Jhe-Wei
TI Service availability of a peer with dynamic buffering for multiple
   description coded videos on multi-source streaming networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic buffering; Service availability; Multiple description coding;
   Peer-to-peer; Streaming
ID SYSTEMS
AB In multi-source streaming systems, such as peer-to-peer (P2P), because the buffer space of each peer is limited, most systems employ the cache-and-relay schemes that require each peer to cache the most recent video blocks it receives. As long as a peer keeps the initial part of the video stream in the buffer, it can relay the cached blocks to new arriving peers in a pipelining fashion and then reduce the loading of a server. In our previous research work, we propose a novel caching scheme for peer-to-peer on-demand video streaming, called Dynamic Buffering, which relies on the feature of Multiple Description Coding to gradually reduce the number of cached descriptions in a peer once the buffer is full in order to prolong the service availability of a peer. In this paper we study the service availability of a peer with dynamic buffering for various numbers of different forwarded descriptions, and provide detailed analysis on how the number of different forwarded descriptions affects the average service availability of a peer. In addition, we derive the mathematical formulas of the reduction of the average service availability of a peer for various numbers of different forwarded descriptions, compared to the best case of the service availability of a peer, and the gain of the average service availability of a peer by releasing the overlapped buffer space with child peers. Our experimental results show that the reduction of the average service availability of a peer is only related to the number of different forwarded descriptions. Besides, regardless of arrival rates, most peers forwarding only one description would possess the highest average service availability for various numbers of different forwarding descriptions, which matches the criteria of the previous work Splitstream.
C1 [Lin, Chow-Sing; Lin, Jhe-Wei] Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Su Lin St, Tainan 70005, Taiwan.
C3 National University Tainan
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Su Lin St, Tainan 70005, Taiwan.
EM mikelin@mail.nutn.edu.tw; sh900010@yahoo.com.tw
RI Lin, Chow-Sing/JPX-6621-2023
FU National Science Council of Taiwan [NSC 100-2221-E-024-006]
FX This work was partially supported by National Science Council of Taiwan
   under contracts NSC 100-2221-E-024-006.
CR Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Bernardini R, 2004, IEEE IMAGE PROC, P3213
   Campana O, 2004, P INT C TEL COMP NET, P191
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chadagorn A, 2014, J NETW COMPUT APPL, V39, P167, DOI 10.1016/j.jnca.2013.06.001
   Chen YS, 2014, IEEE ACM T NETWORK, V22, P1106, DOI 10.1109/TNET.2013.2272056
   Correia P, 2012, IEEE T MULTIMEDIA, V14, P923, DOI 10.1109/TMM.2011.2182184
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Hu C, 2014, COMPUT COMMUN, V44, P14, DOI 10.1016/j.comcom.2014.02.018
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Liao YT, 2011, IEEE T MULTIMEDIA, V13, P132, DOI 10.1109/TMM.2010.2089504
   Lin CS, 2007, J PARALLEL DISTR COM, V67, P903, DOI 10.1016/j.jpdc.2007.04.002
   Lin CS, 2014, MULTIMED TOOLS APPL, V72, P1653, DOI 10.1007/s11042-013-1482-0
   Lin CS, 2014, PEER PEER NETW APPL, V7, P1, DOI 10.1007/s12083-012-0138-6
   Lin CS, 2013, MULTIMED TOOLS APPL, V62, P701, DOI 10.1007/s11042-011-0872-4
   Lin CS, 2010, KSII T INTERNET INF, V4, P491, DOI 10.3837/tiis.2010.08.003
   Lin CS, 2010, INT J COMMUN SYST, V23, P553, DOI 10.1002/dac.1087
   Liu FM, 2012, IEEE T PARALL DISTR, V23, P1227, DOI 10.1109/TPDS.2011.283
   Magharei N, 2007, IEEE INFOCOM SER, P1424
   Magharei N, 2014, IEEE ACM T NETWORK, V22, P244, DOI 10.1109/TNET.2013.2257840
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Schollmeier R., 2001, P 1 INT C PEER TO PE, P101
   Stoica I, 2003, IEEE ACM T NETWORK, V11, P17, DOI 10.1109/TNET.2002.808407
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Xia PY, 2011, IEEE T MULTIMEDIA, V13, P366, DOI 10.1109/TMM.2010.2098021
   Xu YY, 2012, SIGNAL PROCESS-IMAGE, V27, P412, DOI 10.1016/j.image.2012.02.005
   Yuan XQ, 2013, FUTURE GENER COMP SY, V29, P1573, DOI 10.1016/j.future.2012.09.002
   Zandon'a N, 2005, P IADAT INT C MULT I, P290
   Zhang JW, 2014, COMPUT COMMUN, V40, P22, DOI 10.1016/j.comcom.2013.12.002
NR 32
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1009
EP 1026
DI 10.1007/s11042-014-2341-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700015
DA 2024-07-18
ER

PT J
AU Sayyouri, M
   Hmimid, A
   Qjidaa, H
AF Sayyouri, Mhamed
   Hmimid, Abdeslam
   Qjidaa, Hassan
TI Image analysis using separable discrete moments of Charlier-Hahn
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bivariate polynomials; Charlier-Hahn invariant moments; Image
   reconstruction; Pattern recognition; Classification
ID ORTHOGONAL POLYNOMIALS; GEOMETRIC MOMENTS; FAST COMPUTATION;
   CLASSIFICATION; RECOGNITION; PERFORMANCE; EQUATIONS; BINARY
AB In this paper, we present a new set of bivariate discrete orthogonal polynomials defined from the product of Charlier and Hahn discrete orthogonal polynomials with one variable. This bivriate polynomial is used to define other set of separable two-dimensional discrete orthogonal moments called Charlier-Hahn's moments. We also propose the use of the image slice representation methodology for fast computation of Charlier-Hahn's moments. In this approach the image is decomposed into series of non-overlapped binary slices and each slice is described by a number of homogenous rectangular blocks. Thus, the moments of Charlier-Hahn can be computed fast and easily from the blocks of each slice. A novel set of Charlier-Hahn invariant moments is also presented. These invariant moments are derived algebraically from the geometric invariant moments and their computation is accelerated using an image representation scheme. The presented approaches are tested in several well known computer vision datasets including computational time, image reconstruction, the moment's invariability and the classification of objects. The performance of these invariant moments used as pattern features for a pattern classification is compared with Charlier, Hahn, Tchebichef-Krawtchouk, Tchebichef-Hahn and Krawtchouk-Hahn invariant moments.
C1 [Sayyouri, Mhamed; Hmimid, Abdeslam; Qjidaa, Hassan] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mehraz, LESSI, CED ST, Fes 30003, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Sayyouri, M (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mehraz, LESSI, CED ST, BP 1796Fez Atlas, Fes 30003, Morocco.
EM mhamed.sayyouri@usmba.ac.ma; abdeslam_ph@yahoo.fr; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020
OI Sayyouri, Mhamed/0000-0002-1615-419X; QJIDAA,
   Hassan/0000-0003-3067-878X; Hassan, qjidaa/0000-0003-4505-5243
CR Dunkl C.F., 2001, ENCYCL MATH, V81
   Fernández L, 2007, J COMPUT APPL MATH, V199, P113, DOI 10.1016/j.cam.2005.09.029
   Fernández L, 2011, J APPROX THEORY, V163, P84, DOI 10.1016/j.jat.2009.08.007
   Flusser J, 2000, IEEE T IMAGE PROCESS, V9, P1977, DOI 10.1109/83.877219
   Hmimid Abdeslam, 2014, WSEAS Transactions on Signal Processing, V10, P156
   Hosny KM, 2007, APPL MATH COMPUT, V189, P1214, DOI 10.1016/j.amc.2006.12.025
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   Koornwinder T., 1975, THEORY APPL SPECIAL, P435
   Lewanowicz S, 2010, J COMPUT APPL MATH, V233, P1554, DOI 10.1016/j.cam.2009.02.070
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Nikiforov AF, 1991, CLASSICAL ORTHOGONAL
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Papakostas GA, 2010, IMAGE VISION COMPUT, V28, P414, DOI 10.1016/j.imavis.2009.06.011
   Papakostas GA, 2010, PATTERN RECOGN, V43, P58, DOI 10.1016/j.patcog.2009.05.008
   Sayyouri M., 2012, IEEE INT C COMPL SYS, P1
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Sayyouri M, 2012, COLLOQ INF SCI TECH, P101, DOI 10.1109/CIST.2012.6388071
   Shu HZ, 2010, IEEE T IMAGE PROCESS, V19, P3171, DOI 10.1109/TIP.2010.2052276
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Tsougenis E.D., 2013, DYNAMICS VIBRATION A, P1, DOI DOI 10.1115/IMECE2013-64102
   Tsougenis ED, 2014, MULTIMEDIA TOOLS APP
   Xu Y, 2005, INT MATH RES NOTICES, V2005, P449
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Yuan X, 2004, ADV APPL MATH, V33, P615, DOI 10.1016/j.aam.2004.03.002
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
NR 37
TC 28
Z9 28
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 547
EP 571
DI 10.1007/s11042-014-2307-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500025
DA 2024-07-18
ER

PT J
AU Trabelsi, RB
   Masmoudi, AD
   Masmoudi, DS
AF Trabelsi, Randa Boukhris
   Masmoudi, Alima Damak
   Masmoudi, Dorra Sellami
TI Hand vein recognition system with circular difference and statistical
   directional patterns based on an artificial neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand vein; Circular difference and statistical directional patterns;
   Voronoi diagram; Anisotropic diffusion; Artificial neural network
ID SHAPE
AB In this article, a novel hand vein pattern recognition process for human identification is presented. Hand vein characteristics can be considered as more reliable in biometric domain compared with other biometric characteristics, such as palmprint and fingerprint, because veins are located in volume, making features more robust to test conditions. In this paper, a rotation invariant texture descriptor called Circular Difference and Statistical Directional Patterns (CDSDP) is proposed to extract hand vein patterns. Its histogram is considered as attribute vector. The CDSDP is a surrounding circular difference with weights incorporating the statistical directional information of vessels. Experimental results show that the proposed descriptor based on CDSDP has better performance than the previous descriptors used in local binary patterns (LBP). The proposed method gives an Identification Rate (IR) of 99.8 % and an Error Equal Rate (EER) of 0.01 %. Furthermore, the average processing time of the proposed method is 5.2ms for one hand vein posture, which satisfies the criterion of a real time hand vein recognition system.
C1 [Trabelsi, Randa Boukhris; Masmoudi, Alima Damak; Masmoudi, Dorra Sellami] Univ Sfax, Sfax Engn Sch, Adv Control & Energy Management Lab CEM Lab, Comp Imaging Elect & Syst Grp CIELS, BP W, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Trabelsi, RB (corresponding author), Univ Sfax, Sfax Engn Sch, Adv Control & Energy Management Lab CEM Lab, Comp Imaging Elect & Syst Grp CIELS, BP W, Sfax 3038, Tunisia.
EM trabelsiboukhrisranda@live.fr; damak_alima@yahoo.fr;
   dorra.masmoudi@enis.rnu.tn
CR [Anonymous], 2007, HUMAN FINGER VEIN IM
   Beining Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1269, DOI 10.1109/ICPR.2010.316
   Chen G, 2013, IMAGE PROCESSING SEC
   Cheng-Bo Yu, 2009, Journal of Biomedical Science & Engineering, V2, P261, DOI 10.4236/jbise.2009.24040
   Francois A, 2007, 4 INT S VOR DIAGR SC
   GiTae P, 2013, SENSORS, P2895
   Hastie T., 2009, The Elements of Statistical Learning
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Hsu YY, 1995, IEE P GENERATION TRA
   KUMAR A, 2009, IEEE S COMP INT SEC
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Ladoux P, 2009, IEEE INT C BIOM
   Lee EC, 2011, OPT LASER ENG, V49, P816, DOI 10.1016/j.optlaseng.2011.03.004
   Lipmann RP, 1987, IEEE ACOUST SPEECH S, P688
   Liu J., 2012, J COMPUT INF SYST, V8, P1545
   Maglianesi M, 2012, IEEE LATIN AM T
   Meng F, 2011, INT C SYST SCI ENG D
   Mirmohamadsadeghi L, 2011, IEE INT JOINT C BIOM
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perona P, 1994, GEOMETRY DRIVEN DIFF, P71
   PIZER SM, 1984, J COMPUT ASSIST TOMO, V8, P300
   Qichuan T, 2010, INT C INT COMP TECHN
   Randa B. T., 2011, 8 INT MULT SYST SIGN
   Song W, 2011, PATTERN RECOGN LETT, V32, P1541, DOI 10.1016/j.patrec.2011.04.021
   Trabelsi R. Boukhris, 2012, Transactions on Systems, Signals & Devices, V7, P273
   Vapanick V, 1995, NATURE STAT LEARNING
   Wang Y, 2007, IEEE INT C INT COMP
   Wang YD, 2010, INT CONF SIGN PROCES, P1671, DOI 10.1109/ICOSP.2010.5656717
   Wang ZL, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P659
   Xiangrong Zhu, 2012, Biometric Recognition. 7th Chinese Conference, CCBR 2012. Proceedings, P157, DOI 10.1007/978-3-642-35136-5_20
   Yadav VH, 2012, INT J COMPUTER SCI E
   Yiding W, 2010, IEEE 10 INT C IGN PR
   Yörük E, 2006, IEEE T IMAGE PROCESS, V15, P1803, DOI 10.1109/TIP.2006.873439
   Zhao S, 2008, IEEE INT C MACH LEAR
NR 36
TC 16
Z9 19
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 687
EP 707
DI 10.1007/s11042-014-2315-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700001
DA 2024-07-18
ER

PT J
AU Alhamid, MF
   Rawashdeh, M
   Al Osman, H
   Hossain, MS
   El Saddik, A
AF Alhamid, Mohammed F.
   Rawashdeh, Majdi
   Al Osman, Hussein
   Hossain, M. Shamim
   El Saddik, Abdulmotaleb
TI Towards context-sensitive collaborative media recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized search; Context media search; Context-aware recommendation;
   Collaborative context; Retrieval model; Information filtering
ID HEART-RATE-VARIABILITY; MENTAL STRESS
AB With the rapid increase of social media resources and services, Internet users are overwhelmed by the vast quantity of social media available. Most recommender systems personalize multimedia content to the users by analyzing two main dimensions of input: content (item), and user (consumer). In this study, we address the issue of how to improve the recommendation and the quality of the user experience by analyzing the contextual aspect of the users, at the time when they wish to consume multimedia content. Mainly, we highlight the potential of including a user's biological signal and leveraging it within an adapted collaborative filtering algorithm. First, the proposed model utilizes existing online social networks by incorporating social tags and rating information in ways that personalize the search for content in a particular detected context. Second, we propose a recommendation algorithm to improve the user experience and satisfaction with the use of a biosignal in the recommendation process. Our experimental results show the feasibility of personalizing the recommendation according to the user's context, and demonstrate some improvement on cold start situations where relatively little information is known about a user or an item.
C1 [Alhamid, Mohammed F.; Al Osman, Hussein; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Commun Res Lab MCRlab, Ottawa, ON, Canada.
   [Alhamid, Mohammed F.; Hossain, M. Shamim; El Saddik, Abdulmotaleb] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Rawashdeh, Majdi] New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates.
C3 University of Ottawa; King Saud University; New York University Abu
   Dhabi
RP Alhamid, MF (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM malha016@uottawa.ca; majdi@nyu.edu; halos072@uottawa.ca;
   mshossain@ksu.edu.sa; elsaddik@uottawa.ca
RI Hossain, M. Shamim/K-1362-2014; Guizani, Mohsen/AAX-4534-2021;
   /D-4159-2009
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094; /0000-0002-7690-8547
CR Al Osman H., 2013, Multimedia Tools and Applications, P1
   Alhamid M F, 2013, P 1 ACM INT WORKSH M
   [Anonymous], 2010, MB
   [Anonymous], 2010, P 2 INT WORKSH CONT
   Bernardi L, 2000, J AM COLL CARDIOL, V35, P1462, DOI 10.1016/S0735-1097(00)00595-7
   Breese J., 1998, P 14 C UNC ART INT, P43
   Cai R., 2007, P 15 ACM INT C MULTI, P553, DOI DOI 10.1145/1291233.1291369
   Camm AJ, 1996, EUR HEART J, V17, P354
   Colombo R., 1989, IEEE COMPUT CARDIOL, V1990, P475
   de Campos LM, 2010, INT J APPROX REASON, V51, P785, DOI 10.1016/j.ijar.2010.04.001
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Dongmin Shin, 2009, 2009 IEEE Conference on Commerce and Enterprise Computing, P423, DOI 10.1109/CEC.2009.38
   EGELUND N, 1982, ERGONOMICS, V25, P663, DOI 10.1080/00140138208925026
   Gori M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2766
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hjortskov N, 2004, EUR J APPL PHYSIOL, V92, P84, DOI 10.1007/s00421-004-1055-z
   Hyung Z, 2013, EXPERT SYST APPL
   Jäschke R, 2008, AI COMMUN, V21, P231, DOI 10.3233/AIC-2008-0438
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kuifei Yu, 2012, Advances in Knowledge Discovery and Data Mining. Proceedings 16th Pacific-Asia Conference (PAKDD 2012), P431, DOI 10.1007/978-3-642-30217-6_36
   Lattimore PJ, 2001, APPETITE, V36, P187, DOI 10.1006/appe.2000.0387
   Lekakos G, 2008, MULTIMED TOOLS APPL, V36, P55, DOI 10.1007/s11042-006-0082-7
   Lops P, 2013, J INTELL INF SYST, V40, P41, DOI 10.1007/s10844-012-0215-6
   NARDUCCI F, 1985, DIGEST DIS SCI, V30, P40, DOI 10.1007/BF01318369
   Nasoz F, 2010, INFORM SCIENCES, V180, P3817, DOI 10.1016/j.ins.2010.06.034
   Nirjon S, 2012, MUSICALHEART HEARTY
   OLIVER N, 2006, P 8 C HUM COMP INT M
   Pessemier T, 2013, MULTIMED TOOLS APPL
   Salahuddin L, 2007, P ANN INT IEEE EMBS, P4656, DOI 10.1109/IEMBS.2007.4353378
   Siska E., 2002, GYMNICA, V32, P45
   Su JH, 2010, IEEE INTELL SYST, V25, P16, DOI 10.1109/MIS.2010.23
   TULEN JHM, 1989, PHARMACOL BIOCHEM BE, V32, P9, DOI 10.1016/0091-3057(89)90204-9
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   WOERNDL W, 2007, DAT ENG WORK 2007 IE, P871
   Yeung KF., 2011, A context-aware framework for personalized recommendation in mobile environments, September
   Yoon K, 2012, IEEE T CONSUM ELECTR, V58, P612, DOI 10.1109/TCE.2012.6227467
   Zanardi V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P51
   ZANGERLE E, 2012, P 2 WORKSH MAK SENS, P14
   Zhang Yujie, 2010, 2010 5th International Conference on Computer Science & Education (ICCSE 2010), P362, DOI 10.1109/ICCSE.2010.5593612
NR 42
TC 51
Z9 54
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11399
EP 11428
DI 10.1007/s11042-014-2236-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600019
DA 2024-07-18
ER

PT J
AU Cao, XZ
   Sun, L
   Niu, JW
   Wu, RQ
   Liu, YM
   Cai, HJ
AF Cao, Xizheng
   Sun, Lin
   Niu, Jingwen
   Wu, Ruiqi
   Liu, Yanmei
   Cai, Huijuan
TI Automatic composition of happy melodies based on relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic music composition; Happy melody; Hierarchical structure;
   Relation
ID CELLULAR-AUTOMATA; MUSIC; EMOTION; SYSTEM; RULES
AB To compose some happy melodies which have hierarchical structures, this paper proposes an automatic melody composition algorithm based on relations. First, various types of melody structure are formalized and saved into a database, so the melody structure form preferred by a user can be elected by human-computer interaction. Second, some sequences of trunk-note and several algorithms of splitting note are constructed by means of the pitch interval features of happy melody, and the theme phrase of happy melody is generated by splitting some trunk notes of the trunk-note-sequence. Third, several types of operators for developing the theme phrase, which include pitch offsetting, phrase inversing and repeating-developing, are constructed using relationship methods. Finally, under the guidance of the elected melody structure, some happy melodies of songs are produced automatically by the interreaction of the theme phrase and these operators. Experimental results demonstrate that this algorithm can make the obtained melodies have musically meaningful structures, and it is not easy to distinguish these machine-generated melodies from human-generated melodies.
C1 [Cao, Xizheng; Sun, Lin; Niu, Jingwen; Wu, Ruiqi; Liu, Yanmei; Cai, Huijuan] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
C3 Henan Normal University
RP Cao, XZ (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, 46 Jianshe Rd, Xinxiang 453007, Henan, Peoples R China.
EM caoxizheng@126.com
RI Niu, Jingwen/JSL-7380-2023; c, xz/H-3240-2011; c, x/HMD-7636-2023; Wu,
   Ruiqi/ADO-4836-2022
OI Wu, Ruiqi/0000-0003-2384-2414
FU Key Scientific and Technological Project of Henan Province, China
   [122102210054]; Young Core Instructor Project from Higher Education
   Institutions of Henan Province, China [2011GGJS-061]
FX This research was funded by the Key Scientific and Technological Project
   of Henan Province, China (No. 122102210054), and the Young Core
   Instructor Project from the Higher Education Institutions of Henan
   Province, China (No. 2011GGJS-061).
CR Aguilera G, 2010, MATH COMPUT SIMULAT, V80, P1200, DOI 10.1016/j.matcom.2009.04.012
   [Anonymous], 2001, Virtual music: Computer synthesis of musical style
   Ariza C, 2007, COMPUT MUSIC J, V31, P29, DOI 10.1162/comj.2007.31.1.29
   AYESH A, 2005, ARTIF INTELL, P318
   BARONI M, 1984, GRAMMAR MELODY RELAT, P201
   Basharin GP, 2004, LINEAR ALGEBRA APPL, V386, P3, DOI 10.1016/j.laa.2003.12.041
   Boenn G, 2011, THEOR PRACT LOG PROG, V11, P397, DOI 10.1017/S1471068410000530
   Boenn G, 2008, LECT NOTES COMPUT SC, V5366, P160, DOI 10.1007/978-3-540-89982-2_21
   Burraston D, 2005, DIGIT CREAT, V16, P165, DOI 10.1080/14626260500370882
   COPE D, 1987, COMPUT MUSIC J, V11, P30, DOI 10.2307/3680238
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   Gartland-Jones A., 2003, CONTEMP MUSIC REV, V22, P43, DOI [DOI 10.1080/0749446032000150870, 10.1080/0749446032000150870]
   Gillick J, 2010, COMPUT MUSIC J, V34, P56, DOI 10.1162/COMJ_a_00006
   Huq A, 2010, J NEW MUSIC RES, V39, P227, DOI 10.1080/09298215.2010.513733
   Liu XF, 2010, PHYSICA A, V389, P126, DOI 10.1016/j.physa.2009.08.035
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Lo M.Y., 2012, Evolving cellular automata for music composition with trainable fitness functions
   Nierhaus G, 2009, ALGORITHMIC COMPOSIT, P121
   Oliwa T, 2008, LECT NOTES COMPUT SC, V4974, P503
   Pearce M., 2001, Proceedings of the AISB'01 Symposium on Artificial Intelligence and Creativity in the Arts and Sciences, P22
   Reis C, 2011, NONLINEAR SCIENCE AND COMPLEXITY, P329, DOI 10.1007/978-90-481-9884-9_38
   Ruiqing Y, 2006, DESIGN UTILIZATION S, P147
   Ruiqing Y, 2006, 1 EXPLORATION PRACTI, P129
   Sandred Ö, 2009, CONTEMP MUSIC REV, V28, P149, DOI 10.1080/07494460903322430
   Senaratna NI, 2006, AUTOMATIC MUSIC COMP
   Shan MK, 2010, MULTIMED TOOLS APPL, V46, P1, DOI 10.1007/s11042-009-0303-y
   Steedman M, 2003, FORMAL GRAMMAR COMPU
   Stein L, 1995, ANTHOLOGY MUSICAL FO
   Unehara Muneyuki., 2003, Journal of the Asian Design International Conference
   Verbeurgt K, 2004, LECT NOTES COMPUT SC, V3029, P1123
   Wiggins GA, 1998, 1 S MUS COMP
   Xin H, 2007, MIND COMPUT, V1, P269
   Yibo L, 2007, ART ED, P66
   Yin F, 2006, J SOFTW, V17, P209
NR 34
TC 4
Z9 5
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9097
EP 9115
DI 10.1007/s11042-014-2057-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200001
DA 2024-07-18
ER

PT J
AU Ding, C
   Xie, L
   Zhu, PC
AF Ding, Chuang
   Xie, Lei
   Zhu, Pengcheng
TI Head motion synthesis from speech using deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head motion synthesis; Deep neural network; Talking avatar; Computer
   animation
ID DRIVEN; PROSODY
AB This paper presents a deep neural network (DNN) approach for head motion synthesis, which can automatically predict head movement of a speaker from his/her speech. Specifically, we realize speech-to-head-motion mapping by learning a DNN from audio-visual broadcast news data. We first show that a generatively pre-trained neural network significantly outperforms a conventional randomly initialized network. We then demonstrate that filter bank (FBank) features outperform mel frequency cepstral coefficients (MFCC) and linear prediction coefficients (LPC) in head motion prediction. Finally, we discover that extra training data from other speakers used in the pre-training stage can improve the head motion prediction performance of a target speaker. Our promising results in speech-to-head-motion prediction can be used in talking avatar animation.
C1 [Ding, Chuang; Xie, Lei] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Zhu, Pengcheng] Northwestern Polytech Univ, Sch Software & Microelect, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Xie, L (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM dingchuangnwpu@gmail.com; lxie@nwpu.edu.cn; nwpuzpc@gmail.com
RI Xie, Lei/JWO-8567-2024
FU National Natural Science Foundation of China [61175018]; Fok Ying Tung
   Education Foundation [131059]
FX This work was supported by the National Natural Science Foundation of
   China (61175018) and the Fok Ying Tung Education Foundation (131059).
CR ALLEN DM, 1971, TECHNOMETRICS, V13, P469, DOI 10.2307/1267161
   [Anonymous], 1988, LEARNING REPRESENTAT
   [Anonymous], 1997, The HTK book
   [Anonymous], INTERSPEECH
   [Anonymous], 2010, MOMENTUM
   [Anonymous], 1985, PARALLEL DISTRIBUTED
   [Anonymous], 1961, PRINCIPLES NEURODYNA
   Busso C, 2005, COMPUT ANIMAT VIRT W, V16, P283, DOI 10.1002/cav.80
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P2331, DOI 10.1109/TASL.2007.905145
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dahl GE, 2011, INT CONF ACOUST SPEE, P4688
   Dehon C, 2000, STUD CLASS DATA ANAL, P321
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Glorot X., 2010, P INT C ART INT STAT, P249
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kuratate T., 1999, EUROSPEECH
   Lattin J.M., 2003, Analyzing multivariate data
   Li Bingfeng, 2013, Journal of Tsinghua University (Science and Technology), V53, P898
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Reynolds D.A., 2008, HDB SPEECH PROCESSIN, P763, DOI DOI 10.1007/978-3-540-49127-9_38
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Salakhutdinov R., 2009, AISTATS
   Sargin ME, 2008, IEEE T PATTERN ANAL, V30, P1330, DOI 10.1109/TPAMI.2007.70797
   Thompson B., 2005, Canonical correlation analysis. Encyclopedia of statistics in behavioral science
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   Xie L, 2008, MULTIMEDIA SYST, V14, P237, DOI 10.1007/s00530-008-0141-1
   Xie L, 2007, PATTERN RECOGN, V40, P2325, DOI 10.1016/j.patcog.2006.12.001
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Xie L, 2014, MULTIMED TOOLS APPL, V73, P377, DOI 10.1007/s11042-013-1633-3
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Zhang S, 2007, LECT NOTES COMPUT SC, V4738, P24
   Zhang S, 2007, INT CONF ACOUST SPEE, P837
   Zhao K., 2013, SIGN INF PROC ASS AN, P1
NR 42
TC 33
Z9 35
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9871
EP 9888
DI 10.1007/s11042-014-2156-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400003
DA 2024-07-18
ER

PT J
AU Sadr, A
   Okhovat, RS
AF Sadr, Ali
   Okhovat, Raziyeh Sadat
TI Security in the speech cryptosystem based on blind sources separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind sources separation (BSS); Cryptography; Cryptanalysis; Quantized
   levels; Sparsity; Time-frequency domain
ID WATERMARKING ALGORITHM; ENCRYPTION; MIXTURES; IMAGES
AB In this paper, an appropriate selection for the key is investigated to enhance the security level of the speech cryptosystem based on blind sources separation. In fact, if an appropriate key is not selected, the cryptosystem may be attacked and therefore each confidential signal can be recovered only from the encrypted ones. Two important conditions which are studied in this paper are the number of quantized levels for a digital key and also non-sparsity in time-frequency domain. In the case of the first condition, simulation results show that with smaller coefficient for the confidential signal in comparison with the key, the number of quantized levels for the key should be more to guarantee the security. In the case of the second condition, an algorithm is proposed to recover the confidential signal only from the encrypted signal when the key is sparse in time-frequency domain.
C1 [Sadr, Ali; Okhovat, Raziyeh Sadat] Iran Univ Sci & Technol, Tehran, Iran.
C3 Iran University Science & Technology
RP Sadr, A (corresponding author), Iran Univ Sci & Technol, Tehran, Iran.
EM sadr@iust.ac.ir; Rokhovat@iust.ac.ir
RI Sadr, Ali/S-9892-2018
OI Sadr, Ali/0000-0002-0533-5606
CR Alvarez G, 2005, PHYS LETT A, V345, P245, DOI 10.1016/j.physleta.2005.07.083
   Ayllón D, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P785, DOI 10.1109/SSP.2011.5967822
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Cheong KY, 2007, IEEE T CIRCUITS-II, V54, P795, DOI 10.1109/TCSII.2007.900875
   Da-Peng Guo, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P1428, DOI 10.1109/ICNC.2010.5582616
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   Jourjine A, 2000, INT CONF ACOUST SPEE, P2985, DOI 10.1109/ICASSP.2000.861162
   Khan LA, 2011, COMPUT ELECTR ENG, V37, P559, DOI 10.1016/j.compeleceng.2011.04.008
   Kumar A, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P1352, DOI 10.1109/ICCCE.2008.4580826
   Kumar A, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P358, DOI 10.1109/ISM.2009.77
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P1675, DOI 10.1016/j.cnsns.2010.06.009
   Kumar A, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P201, DOI 10.1109/IADCC.2010.5423009
   Li SJ, 2008, IEEE T CIRCUITS-I, V55, P1055, DOI 10.1109/TCSI.2008.916540
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li YQ, 2006, IEEE T SIGNAL PROCES, V54, P423, DOI 10.1109/TSP.2005.861743
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Lin QH, 2005, LECT NOTES COMPUT SC, V3497, P544
   Lin QH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1366
   Lin QH, 2008, IMAGE VISION COMPUT, V26, P788, DOI 10.1016/j.imavis.2007.08.017
   Lin QH, 2006, LECT NOTES COMPUT SC, V3973, P318
   Lin QH, 2006, IEEE T CIRCUITS-I, V53, P1320, DOI 10.1109/TCSI.2006.875164
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Melia T., 2007, 9th International Symposium on Signal Processing and Its Applications, P1
   Mermoul A., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P538, DOI 10.1109/ISSPA.2010.5605593
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Shi ZW, 2005, PATTERN RECOGN LETT, V26, P2491, DOI 10.1016/j.patrec.2005.05.006
   Thomas J, 2007, IEEE T SIGNAL PROCES, V55, P3717, DOI 10.1109/TSP.2007.894243
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yang T, 1998, PHYS LETT A, V245, P495, DOI 10.1016/S0375-9601(98)00425-3
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 32
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9715
EP 9728
DI 10.1007/s11042-014-2147-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200030
DA 2024-07-18
ER

PT J
AU Kim, JT
   Lee, WH
AF Kim, Jung Tae
   Lee, Won-Hyung
TI Dynamical model for gamification of learning (DMGL)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game; Gamification; Game based learning; GBL; Learning game
AB The purpose of this paper is to hypothesize 'Dynamical model of educational effectiveness for the gamification of learning, and to widely announce a pure and right function of game through our model. For the theoretical contribution of gamification, we propose a dynamical model of game based learning that aims to maximize educational effectiveness that correlates with the four main primary factors (curiosity, challenge, fantasy and control). The main idea of this model is based on the correlations of four factors which originating from learning games which are built on the foundations of separate theories: 1) Game Design Features 2) Key Characteristics of a Learning Game 3) a theory of educational environment design known as the ARCS (attention, relevance, confidence, and satisfaction) and 4) the theoretical background of gamification labeled the MDA(mechanics, dynamics and aesthetics) framework. We created a sigmoidal equation for the educational effectiveness of Gamification by analyzing and correlating these factors. Through this dynamical model we will show that the effectiveness of the gamification of learning is educationally superior to traditional ways of learning in specific setting, after an elapsed adaptive time period with reasonable relationship of the four primary factors.
C1 [Kim, Jung Tae; Lee, Won-Hyung] Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Dept Image Engn Game, Seoul 156756, South Korea.
C3 Chung Ang University
RP Kim, JT (corresponding author), Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Dept Image Engn Game, 503 Chung Ang Cultural Arts Ctr,84 Heukseokro, Seoul 156756, South Korea.
EM game3651@gmail.com; whlee@cau.ac.kr
CR Abt CC, 1970, SERIOUS GAMES, Vxvi, P176
   [Anonymous], 2004, P CHALLENGES GAME WO
   [Anonymous], 2001, On the Horizon
   [Anonymous], COMPUTERS ENTERTAINM
   Brown V, 2011, 081448 EMAESA
   Carron T, 2008, SIMULATION GAMING
   ChanLin LJ, 2009, INNOV EDUC TEACH INT, V46, P91, DOI 10.1080/14703290802646123
   De Vries G, 2003, SHORT COURSE MATH CO
   Deb S, 2012, INT J ED LEARN, V1
   Deterding S., 2011, P CHI 2011 GAMIFICAT
   Deterding Sebastian., 2011, Proceedings of MindTrek
   Ebnera M, 2007, COMPUT ED
   Fields T., 2011, SOCIAL GAME DESIGN M
   Francis DJ, 1996, J EDUC PSYCHOL, V88, P3, DOI 10.1037/0022-0663.88.1.3
   Gause GF., 1969, The Struggle for Existence
   Hillen T., 2003, Math Biol., V6, P19
   Kapp K., 2012, GAMIFICATION LEARNIN, P75
   Kiili K, 2005, INTERNET HIGH ED
   Lepper MR, 1992, MOTIV EMOT
   Malone T.W., 1987, APTITUDE LEARNING
   Malone T. W, 1980, TECHNICAL REPORT
   Nagarajan P, 2010, INT J U E SERV SCI T, V3
   Park H, 2012, INT J GRID DISTRIB C, V5
   Qwaider WQ, 2011, INT J HYBRID INF TEC, V4
   Radoff J., 2011, Game on: Energize your business with social media games s, P24
   Rollings A, 2004, GAME ARCHITECT DESIG, p[35, 59]
   Strogatz S. H., 2000, Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering
   Takahashi D., 2008, Funware's threat to the traditional video game industry
   Verhulst P. F., 1838, CORR MATH PHYS, V10
   Zichermann G., 2011, GAMIFICATION DESIGN, P35
   Zichermann G, 2010, GAME BASED MARKETING, p[19, 43]
NR 31
TC 70
Z9 74
U1 1
U2 116
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8483
EP 8493
DI 10.1007/s11042-013-1612-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600015
OA hybrid
DA 2024-07-18
ER

PT J
AU Besbes, G
   Baazaoui-Zghal, H
AF Besbes, Ghada
   Baazaoui-Zghal, Hajer
TI Modular ontologies and CBR-based hybrid system for web information
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology; Case-based reasoning (CBR); Modular ontologies; Composition
AB Increasing amounts of data volume used on the Web and their heterogeneous character make the search for information a challenging task. Several advanced computing methods and technologies propose to incorporate a degree of semantic analysis during the search based on ontologies. Ontology engineering is based on the methods and methodologies for building ontologies combined with engineering process. This paper proposes a hybrid system based on ontology engineering and aiming to enhance web information retrieval results, by combining automatic Modular Ontology building with CBR (CBRModOnto). The system integrates a novel dynamic composition approach of modular ontologies, performed to reorganize the overlapping concepts between the different ontology modules and updates their hierarchy using semantic similarity measure. The search in our system occurs in two main phases. The first one composes modular ontologies and manages the knowledge base, while the second phase manages the CBR process. A demonstration case study presents a scenario to illustrate the proposed system. Our system has been implemented, the obtained experimental results show that hybridization that we propose enables an improvement of query reformulation, predicted ranking score and user's satistaction.
C1 [Besbes, Ghada; Baazaoui-Zghal, Hajer] Manouba Univ, Riadi GDL Lab, Tunis, Tunisia.
C3 Universite de la Manouba
RP Baazaoui-Zghal, H (corresponding author), Manouba Univ, Riadi GDL Lab, Tunis, Tunisia.
EM ghada.besbes@gmail.com; hajer.baazaouizghal@riadi.rnu.tn
RI Besbes, Ghada/JFK-5326-2023
OI Besbes, Ghada/0000-0001-7065-5262; Baazaoui, Hajer/0000-0002-2151-7397
CR AAMODT A, 1994, AI COMMUN, V7, P39
   Bargiela A., 2008, INT J COMMUNICATIONS, P76
   Bechhofer S., 2004, W3C recommendation
   Ben Mustapha Nesrine, 2012, Model and Data Engineering. Proceedings of the 2nd International Conference, MEDI 2012, P79, DOI 10.1007/978-3-642-33609-6_9
   Ben Mustapha N, 2011, 15 INT C KNOWL BAS I
   Chklovski T, C EMP METH NAT LANG
   Christopher D.Manning., 1999, FDN STAT NATURAL LAN
   d'Aquin M, 2009, LECT NOTES COMPUT SC, V5445, P67
   DIAZAGUDO B, 2001, P 6 UK CBR WORKSH
   Elloumi-Chaabene M, 2011, ICSOFT 2011: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SOFTWARE AND DATABASE TECHNOLOGIES, VOL 1, P305
   Fragos K, 2003, 1 BALK C INF
   Frieder O, 2002, CIKM
   Guan-yu L, 2008, 4 INT C WIR COMM NET
   Guarino N, 1998, FR ART INT, V46, P3
   Henriksson J., 2007, P TECHN OBJ OR LANG
   Jarrar M, 2005, LECT NOTES COMPUT SC, V3762, P613
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Lassila Ora, 1998, W3C Recommendation
   LESK Michael, 1986, P 5 ANN INT C SYST D, V5, P24, DOI 10.1145/318723.318728
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Minor M, 2002, LNI, V10, P81
   Mitra P, 2003, IN HAND I S, P93
   Navigli Roberto., 2011, P 20 ACM INT C INF K, P2317, DOI DOI 10.1145/2063576.2063955
   Rissland EL, 1995, INT JOINT CONF ARTIF, P400
   Sabou M, 2006, P ISWC 2006 WORKSH M
   Salton G., 1997, READINGS INFORM RETR, P323
   Sánchez D, 2008, DATA KNOWL ENG, V64, P600, DOI 10.1016/j.datak.2007.10.001
   Stuckenschmidt H, 2009, LECT NOTES COMPUT SC, V5445, P187
   Tan P. N., 2016, INTRO DATA MINING
   Turney P. D., 2001, P 12 EUR C MACH LEAR, P491, DOI DOI 10.1007/3-540-44795-4_42
   Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9
   Zghal HB, 2007, J WEB ENG, V6, P309
   Zimmermann A, 2006, LECT NOTES COMPUT SC, V4273, P16
NR 33
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8053
EP 8077
DI 10.1007/s11042-014-2041-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200029
DA 2024-07-18
ER

PT J
AU Liu, B
   Li, HJ
   Jia, XY
   Zhang, H
   Huang, R
   Liu, ZL
   Zhao, X
AF Liu, Bin
   Li, Haojie
   Jia, Xianyong
   Zhang, Hui
   Huang, Rui
   Liu, Zhaoliang
   Zhao, Xu
TI An object segmentation method for the color slow-motion videos based on
   adjacent frames gradual change
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Slow-motion video; Color image segmentation; Color similarity; Parallel
   computing
ID IMAGE SEGMENTATION; FUZZY CONNECTEDNESS; MEAN SHIFT; ALGORITHMS;
   SURVEILLANCE; TRACKING
AB Along with the high-speed cameras are more and more widely applied, how to automatically segment the region of interest in the slow-motion video is a new issue. In this paper, a color slow-motion video segmentation method is proposed. The main strategy is based on region growing and pixel color difference. A rapid color similarity computing method is improved and applied for classifying different pixels. An algorithm based on four directions corrosion is proposed to automatically extract the seed points for the serialized video frames. Utilizing this method, the color frames of the slow-motion videos can be segmented in series automatically. Also, the multithreading mode of parallel computing is introduced in the entire segmentation process. This method is not complicated but automatic. The regions of interest in the slow-motion video frames can be segmented clearly. This novel method can provide support to the video related applications.
C1 [Liu, Bin; Li, Haojie; Jia, Xianyong; Zhang, Hui; Huang, Rui; Liu, Zhaoliang; Zhao, Xu] Dalian Univ Technol, Natl Demonstrat Sch Software, Dalian 116620, Peoples R China.
C3 Dalian University of Technology
RP Liu, B (corresponding author), Dalian Univ Technol, Natl Demonstrat Sch Software, Dalian 116620, Peoples R China.
EM laohubinbin@163.com
FU National Natural Science Foundation of China [61300085, 61033012];
   Liaoning Provincial Education Department of China [L2013012]
FX Our thanks are due to the Youku (http://www.youku.com/), YouTube
   (http://www.youtube.com) and Tudou (http://www.tudou.com) for freely
   providing the color slow-motion video data sets. This study is supported
   by the National Natural Science Foundation of China (No. 61300085,
   61033012), the Scientific Research Fund of Liaoning Provincial Education
   Department of China (No. L2013012).
CR Babaguchi Noboru, 2000, ACM WORKSHOPS MULTIM, P205
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen SC, 2003, IEEE T INTELL TRANSP, V4, P154, DOI 10.1109/TITS.2003.821290
   Collins L, 2000, CMURITR0012 VSAM
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Cyganek B, 2008, INT J NEURAL SYST, V18, P339, DOI 10.1142/S0129065708001646
   Haifeng Xu, 2004, IEEE Transactions on Circuits and Systems for Video Technology, V14, P796, DOI 10.1109/TCSVT.2004.828338
   Han XW, 2004, IEEE ROBIO 2004: Proceedings of the IEEE International Conference on Robotics and Biomimetics, P535
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Ikonomakis N, 2000, J INTELL ROBOT SYST, V28, P5, DOI 10.1023/A:1008163913937
   KaewTrakulPong P, 2003, IMAGE VISION COMPUT, V21, P913, DOI 10.1016/S0262-8856(03)00076-3
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li HT, 2010, INT J REMOTE SENS, V31, P1453, DOI 10.1080/01431160903475266
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Minetto R, 2012, COMPUT VIS IMAGE UND, V116, P274, DOI 10.1016/j.cviu.2011.10.003
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pan H, 2002, INT CONF ACOUST SPEE, P3385
   Priese L., 2003, Introduction to the color structure code and its implementation
   Priese L., 1993, P IEEE INT VEH S 93, P95
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813
   Shapiro L. G., 2001, COMPUTER VISION
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   Udupa JK, 2003, P IEEE, V91, P1649, DOI 10.1109/JPROC.2003.817883
   VONWANGENHEIM A, 2008, J BRAZ COMPUT SOC, V14, P29
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yasuda G, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT SYSTEMS AND SIGNAL PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P576
   Yu ZY, 2002, LECT NOTES COMPUT SC, V2352, P517
   Zhong F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366194
NR 34
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7285
EP 7329
DI 10.1007/s11042-014-1981-7
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800032
DA 2024-07-18
ER

PT J
AU Danelakis, A
   Theoharis, T
   Pratikakis, I
AF Danelakis, Antonios
   Theoharis, Theoharis
   Pratikakis, Ioannis
TI A survey on facial expression recognition in 3D video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh video; 3D dynamic facial meshes; 3D video facial expression
   recognition
AB Facial expression recognition constitutes an active research area due to its various applications. This survey addresses methodologies for 3D mesh video facial expression recognition. Recognition is, actually, a special case of intra-class retrieval. The approaches are analyzed and compared in detail. They are primarily categorized according to the 3D dynamic face analysis technique used. In addition, currently available datasets, used for 3D video facial expression analysis, are presented. Finally, future challenges that can be addressed in order for 3D video facial expression recognition field to be further improved, are extensively discussed.
C1 [Danelakis, Antonios; Theoharis, Theoharis] Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 11528, Greece.
   [Theoharis, Theoharis] Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway.
   [Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, Thrace, Greece.
C3 National & Kapodistrian University of Athens; Norwegian University of
   Science & Technology (NTNU); Democritus University of Thrace
RP Danelakis, A (corresponding author), Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 11528, Greece.
EM a.danelakis@gmail.com; theotheo@idi.ntnu.no; ipratika@ee.duth.gr
RI PRATIKAKIS, IOANNIS/AAD-3387-2019; Theoharis, Theoharis/AAN-2555-2020
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688; 
FU European Union (European Social Fund - ESF); Greek national funds
   through the Operational Program "Education and Lifelong Learning" of the
   National Strategic Reference Framework (NSRF) - Research Funding
   Program: THALES-3DOR [MIS 379516]
FX This research has been co-financed by the European Union (European
   Social Fund - ESF) and Greek national funds through the Operational
   Program "Education and Lifelong Learning" of the National Strategic
   Reference Framework (NSRF) - Research Funding Program: THALES-3DOR (MIS
   379516).
CR [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops CVPRW
   [Anonymous], 3DOR 10 EUR ASS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], EU WORKSH 3D OBJ RET
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], P 3DTV C 12
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 1997, THESIS CARNEGIE MELL
   [Anonymous], IEEE FG 13
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Berretti S, 2012, LECT NOTES COMPUT SC, V7583, P73, DOI 10.1007/978-3-642-33863-2_8
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Drira H, 2012, INT C PATT RECOG, P1104
   Ekman P, 1978, FACIAL ACTION CODING
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Jeni LA, 2012, IMAGE VISION COMPUT, V30, P785, DOI 10.1016/j.imavis.2012.02.003
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kharevych L, 2006, ACM T GRAPHIC, V25, P412, DOI 10.1145/1138450.1138461
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Matuszewski BJ, 2012, IMAGE VISION COMPUT, V30, P713, DOI 10.1016/j.imavis.2012.02.002
   Rosato M, 2008, IEEE INT C BIOMETRIC, P1
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Tsalakanidou Filareti, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P4, DOI 10.1109/CVPR.2009.5204281
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Yin L, 2008, IEEE P FG 08, P1
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yin LJ, 2001, COMPUT VIS IMAGE UND, V84, P201, DOI 10.1006/cviu.2001.0949
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 47
TC 19
Z9 21
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5577
EP 5615
DI 10.1007/s11042-014-1869-6
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100010
DA 2024-07-18
ER

PT J
AU Irtaza, A
   Jaffar, MA
   Muhammad, MS
AF Irtaza, Aun
   Jaffar, M. Arfan
   Muhammad, Mannan Saeed
TI Content based image retrieval in a web 3.0 environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-Based Image Retrieval (CBIR); Genetic algorithms; Relevance
   feedback; Support vector machines; Social media
ID RELEVANCE FEEDBACK; GENETIC ALGORITHM
AB With the dramatic growth of Internet and multimedia applications, a virtually free worldwide digital distribution infrastructure has emerged. The concept of intelligent web or web 3.0 gives an opportunity to its users to share information in a way that could reach a broader audience and provide that audience with much deeper accessibility and interpretation of the information. Legacy image search systems which rely on the text annotations like keywords, and captions to retrieve images are not appropriate in web 3.0 architecture. Because these systems are unable to retrieve images which do not have this associated information. Also these systems suffers from the high cost of manual text annotations and linguistic problems as well while sharing and retrieving images. Therefore to handle these issues an image retrieval and management technique is presented in this paper which considers the actual image contents and do not rely on the associated metadata. Our content based image retrieval technique incorporates Genetic algorithms with support vector machines and user feedbacks for image retrieval purposes, and assures the effective retrieval and sharing of images by taking the users considerations into an account.
C1 [Irtaza, Aun; Jaffar, M. Arfan] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
   [Jaffar, M. Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Muhammad, Mannan Saeed] Hanyang Univ, Hanyang, South Korea.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); Hanyang University
RP Muhammad, MS (corresponding author), Hanyang Univ, Hanyang, South Korea.
EM aun.irtaza@gmail.com; arfan.jaffar@ccis.imamu.edu.sa;
   mannan@hanyang.ac.kr
RI Jaffar, Arfan/GQB-2768-2022; Irtaza, Aun/HTP-2773-2023; Muhammad, Mannan
   Saeed/G-5115-2015
OI Irtaza, Aun/0000-0001-7757-5839; Muhammad, Mannan
   Saeed/0000-0002-3036-4660
FU research fund of Hanyang University [HY-2012-N]
FX This work was supported by the research fund of Hanyang University
   (HY-2012-N).
CR Andrysiak T, 2005, INT J AP MAT COM-POL, V15, P471
   Azimi-Sadjadi MR, 2009, IEEE T IMAGE PROCESS, V18, P1645, DOI 10.1109/TIP.2009.2017825
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Bulò SR, 2011, PATTERN RECOGN, V44, P2109, DOI 10.1016/j.patcog.2011.03.016
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Chorianopoulos K, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-10
   da Silva AT, 2011, PATTERN RECOGN, V44, P2971, DOI 10.1016/j.patcog.2011.04.026
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Goh K., 2004, PROC ACM INT C MULTI, P564
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lama M., 2007, SPIE MED IM C SAN DI
   Lei Z, 2002, TENCON 99
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Mirzaei O, 2013, J CONV, V203, P231
   Park S, 2013, J INF PROCESS SYST, V9, P205, DOI 10.3745/JIPS.2013.9.2.205
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Rao NG, 2009, INT J COMPUT SCI NET, V9, P206
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Seo KK, 2007, LECT NOTES COMPUT SC, V4669, P537
   Silva JM, 2008, COMM MS 08 VANC BC C
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Stejic Z, 2003, INFORM PROCESS MANAG, V39, P1, DOI 10.1016/S0306-4573(02)00024-9
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Tao DC, 2007, IEEE T KNOWL DATA EN, V19, P568, DOI 10.1109/TKDE.2007.1003
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Torres RdS, 2005, NEW FRAMEWORK COMBIN, P335
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang SF, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P2996
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Ye J P, 2007, P 24 INT C MACH LEAR, P1087, DOI [DOI 10.1145/1273496.1273633, 10.1145/1273496.1273633]
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026
   Zhang D., 2004, IEEE C IM GRAPH
   Zhou XS, 2001, PATTERN RECOGN LETT, V22, P457, DOI 10.1016/S0167-8655(00)00124-0
NR 39
TC 9
Z9 9
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5055
EP 5072
DI 10.1007/s11042-013-1679-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900005
DA 2024-07-18
ER

PT J
AU Grega, M
   Lach, S
AF Grega, Michal
   Lach, Seweryn
TI Urban photograph localization using the INSTREET application-accuracy
   and performance analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Street view; Geotagging; Geolocalization; Urban environment; Safety
AB The paper proposes a solution to the problem of geolocation of photographs by using an algorithm to compare their content against a geolocated database of street view images, and analyzing the performance of the algorithm. The algorithm makes it possible to pinpoint the location where a photograph was taken. In order to solve this problem, we propose an algorithm based on MPEG-7 features. The paper also describes the results of optimizing the performance of the algorithm and its accuracy. We show that the algorithm scales with the size of the reference database at least up to 130 km(2), which was the largest urban area we tested the algorithm on.
C1 [Grega, Michal; Lach, Seweryn] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Grega, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM grega@kt.agh.edu.pl; sewlac@gmail.com
RI Grega, Michal/C-3704-2011
OI Grega, Michal/0000-0001-7633-8663
FU European Commission [218086]
FX The presented work was supported by the European Commission, in an
   integrated project INDECT (Grant number 218086).
CR [Anonymous], ITRODUCTION MPEG 7
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2008.4587784
   [Anonymous], 2006, INT S 3D DAT PROC VI
   [Anonymous], P IEEE INT C COMP VI
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Gallagher Andrew, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P55, DOI 10.1109/CVPR.2009.5204168
   Grega M, 2012, COMM COM INF SC, V287, P130
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Schindler G., 2008, IEEE C COMPUTER VISI
NR 10
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4369
EP 4380
DI 10.1007/s11042-013-1538-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600011
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, SF
   Liu, ZL
   Zhu, YC
   He, MH
   Chen, XP
   Ji, Q
AF Wang, Shangfei
   Liu, Zhilei
   Zhu, Yachen
   He, Menghua
   Chen, Xiaoping
   Ji, Qiang
TI Implicit video emotion tagging from audiences' facial expression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Implicit emotion tagging; Expression recognition; Emotion inference
AB In this paper, we propose a novel implicit video emotion tagging approach by exploring the relationships between videos' common emotions, subjects' individualized emotions and subjects' outer facial expressions. First, head motion and face appearance features are extracted. Then, the spontaneous facial expressions of subjects are recognized by Bayesian networks. After that, the relationships between the outer facial expressions, the inner individualized emotions and the video's common emotions are captured by another Bayesian network, which can be used to infer the emotional tags of videos. To validate the effectiveness of our approach, an emotion tagging experiment is conducted on the NVIE database. The experimental results show that head motion features improve the performance of both facial expression recognition and emotion tagging, and that the captured relations between the outer facial expressions, the inner individualized emotions and the common emotions improve the performance of common and individualized emotion tagging.
C1 [Wang, Shangfei; Liu, Zhilei; Zhu, Yachen; He, Menghua; Chen, Xiaoping] Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Rensselaer Polytechnic Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; leivo@mail.ustc.edu.cn; zhuyc@mail.ustc.edu.cn;
   hemh@mail.ustc.edu.cn; xpchen@ustc.edu.cn; qji@ecse.rpi.edu
RI Liu, Zhilei/B-3733-2015
OI Liu, Zhilei/0000-0003-1447-6256
FU NSFC [61175037, 61228304]; Special Innovation Project on Speech of Anhui
   Province [11010202192]; Project from Anhui Science and Technology Agency
   [1106c0805008]; fundamental research funds for the central universities
FX This paper is supported by the NSFC (61175037, 61228304), Special
   Innovation Project on Speech of Anhui Province (11010202192), Project
   from Anhui Science and Technology Agency (1106c0805008) and the
   fundamental research funds for the central universities.
CR [Anonymous], CONT BAS MULT IND CB
   [Anonymous], KANSEI ENG SOFT COMP
   [Anonymous], 2010, TECHNICAL REPORT
   [Anonymous], P AFF BRAIN COMP INT
   Arapakis I., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P461, DOI DOI 10.1145/1631272.1631336
   Arapakis I., 2009, P ACM INT C IM VID R, P29, DOI [10.1145/1646396.1646433, DOI 10.1145/1646396.1646433]
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Gray E.K., 2007, HDB EMOTION ELICITAT
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Joho Hideo, 2009, P ACM INT C IM VID R
   Kierkels JJM, 2009, IEEE INT CON MULTI, P1436, DOI 10.1109/ICME.2009.5202772
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Kok-Meng Ong, 2009, Information and Media Technologies, V4, P903
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Krzywicki AT, 2009, SPIE
   LIU Z, 2013, IEEE PULSE, V4, P10
   Lv Yanpeng., 2011, Proceedings of the Third International Conference on Internet Multimedia Computing and Service - ICIMCS'11, page, P170, DOI DOI 10.1145/2043674.2043723
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Money AG, 2008, LECT NOTES COMPUT SC, V4868, P194, DOI 10.1007/978-3-540-85099-1_17
   Money AG, 2009, DISPLAYS, V30, P59, DOI 10.1016/j.displa.2008.12.003
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Peng W-T, 2008, P 15 INT MULT MOD C, P484
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Peng WT, 2010, IEEE INT CON MULTI, P849, DOI 10.1109/ICME.2010.5582606
   Rainville P, 2006, INT J PSYCHOPHYSIOL, V61, P5, DOI 10.1016/j.ijpsycho.2005.10.024
   Scott I, AAM MODELLING SEARCH
   Smeaton AF, 2009, INT WORK CONTENT MUL, P162, DOI 10.1109/CBMI.2009.21
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Soleymani M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P803, DOI 10.1109/FG.2011.5771352
   Soleymani M., 2008, P 2 ACM WORKSHOP MUL, P32, DOI DOI 10.1145/1460676.1460684
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Soleymani M, 2008, IEEE INT SYM MULTIM, P228, DOI 10.1109/ISM.2008.14
   Toyosawa S, 2010, LECT NOTES COMPUT SC, V6297, P260, DOI 10.1007/978-3-642-15702-8_24
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Yazdani J.-S. Lee., 2009, Proc. SIGMM Workshop on Social media, P81
NR 37
TC 10
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4679
EP 4706
DI 10.1007/s11042-013-1830-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400011
DA 2024-07-18
ER

PT J
AU Son, SY
   Lee, SH
   Chung, K
   Lim, JS
AF Son, Sung-Yong
   Lee, Sang-Hong
   Chung, Kyungyong
   Lim, Joon S.
TI Feature selection for daily peak load forecasting using a neuro-fuzzy
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Daily peak load forecasting; Feature selection; Weighted fuzzy
   membership function
ID NETWORK APPROACH; IDENTIFICATION
AB Accurate electrical daily peak load forecasting (DPLF) is essential for power system management in order to prevent overloading and grid failure. Fuzzy neural networks have been successfully applied to load forecasting due to their nonlinear mapping and generalized behavior. In this paper, a neuro-fuzzy based DPLF (N-DPLF) model with a feature selection method is proposed for DPLF. The load data is clustered into seven subsets according to the season and day type. For each subset, the four features with the highest salience ranks are selected. After training N-DPLF model, the formed BSWs (bounded sum of weighted fuzzy membership functions) in accordance with the selected features denote characteristics of these features. The N-DPLF model provides explicit BSWs in hyperboxes, instead of the uncertain black box nature of neural network models, so that the selected features can be interpreted by the visually constructed BSWs. The N-DPLF model with a feature selection method shows a mean absolute percentage error (MAPE) of 1.86 % using Korea Power Exchange data over 1-year period.
C1 [Son, Sung-Yong; Lim, Joon S.] Gachon Univ, IT Coll, Songnam, South Korea.
   [Lee, Sang-Hong] Anyang Univ, Dept Comp Sci & Engn, Anyang, South Korea.
   [Chung, Kyungyong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Gachon University; Anyang University; Sangji University
RP Lim, JS (corresponding author), Gachon Univ, IT Coll, Songnam, South Korea.
EM xtra@gachon.ac.kr; shleedosa@gmail.com; kyjung@sangji.ac.kr;
   jslim@gachon.ac.kr
RI Chung, Kyungyong/JAC-2276-2023; Lim, Joon Seok/R-7753-2019
FU Power Generation & Electricity DeliveryCore Technology Program of the
   Korea Institute of Energy Technology Evaluation and Planning (KETEP) -
   Ministry of Trade, Industry & Energy, Republic of Korea [2013T100200068]
FX This work was supported by the Power Generation & Electricity
   DeliveryCore Technology Program of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP), granted financial resource
   from the Ministry of Trade, Industry & Energy, Republic of Korea. (No.
   2013T100200068).
CR Abdel-Aal RE, 2006, INT J ELEC POWER, V28, P133, DOI 10.1016/j.ijepes.2005.11.006
   Amin-Naseri MR, 2008, ENERG CONVERS MANAGE, V49, P1302, DOI 10.1016/j.enconman.2008.01.016
   Amjady N, 2001, IEEE T POWER SYST, V16, P798, DOI 10.1109/59.962429
   CHAI SH, 2007, KOREAN EC ASS, V23, P111
   Chai SH, 2007, J INTELL INF SYST, V17, P160
   Charytoniuk W, 1998, IEEE T POWER SYST, V13, P725, DOI 10.1109/59.708572
   Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679
   Chen Y, 2010, IEEE T POWER SYST, V25, P322, DOI 10.1109/TPWRS.2009.2030426
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P1291, DOI 10.1007/s00779-013-0743-2
   Chung KY, 2013, WIRELESS PERS COMMUN, V73, P243, DOI 10.1007/s11277-013-1234-5
   da Silva APA, 2008, INT J FORECASTING, V24, P616, DOI 10.1016/j.ijforecast.2008.07.006
   Drezga I, 1998, IEEE T POWER SYST, V13, P1238, DOI 10.1109/59.736244
   Fan S, 2006, IEEE T POWER SYST, V21, P392, DOI 10.1109/TPWRS.2005.860944
   Hanmandlu M, 2011, IEEE T POWER SYST, V26, P20, DOI 10.1109/TPWRS.2010.2048585
   Hippert HS, 2010, NEURAL NETWORKS, V23, P386, DOI 10.1016/j.neunet.2009.11.016
   Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780
   Huang HC, 2002, INT J ELEC POWER, V24, P245, DOI 10.1016/S0142-0615(01)00026-6
   Huang SJ, 2003, IEEE T POWER SYST, V18, P673, DOI 10.1109/TPWRS.2003.811010
   Jo NH, 2006, T KIEE A, V55A, P306
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Kim CI, 2002, ELECTR POW SYST RES, V63, P169, DOI 10.1016/S0378-7796(02)00097-4
   Kim JY, 2014, MULTIMED TOOLS APPL, V68, P465, DOI 10.1007/s11042-013-1357-4
   Ko JW, 2015, MULTIMED TOOLS APPL, V74, P8907, DOI 10.1007/s11042-013-1581-y
   Lauret P, 2008, ENERG CONVERS MANAGE, V49, P1156, DOI 10.1016/j.enconman.2007.09.009
   Lee SH, 2011, EXPERT SYST APPL, V38, P4259, DOI 10.1016/j.eswa.2010.09.093
   Liao GC, 2006, IEEE T EVOLUT COMPUT, V10, P330, DOI 10.1109/TEVC.2005.857075
   Lim JS, 2009, IEEE T NEURAL NETWOR, V20, P522, DOI 10.1109/TNN.2008.2012031
   Lim JS, 2006, NEUROCOMPUTING, V69, P969, DOI 10.1016/j.neucom.2005.06.009
   Mao HI, 2009, IEEE T POWER SYST, V24, P1080, DOI 10.1109/TPWRS.2009.2016609
   Pandian SC, 2006, ELECTR POW SYST RES, V76, P541, DOI 10.1016/j.epsr.2005.09.018
   Reis AJR, 2005, IEEE T POWER SYST, V20, P189, DOI 10.1109/TPWRS.2004.840380
   Rho MJ, 2015, MULTIMED TOOLS APPL, V74, P2391, DOI 10.1007/s11042-013-1772-6
   Saini LM, 2002, IEEE T POWER SYST, V17, P907, DOI 10.1109/TPWRS.2002.800992
   Senjyu T, 2005, IEEE T POWER SYST, V20, P102, DOI 10.1109/TPWRS.2004.831256
   Sheikhan N, 2011, NEURAL COMPUT APPL, DOI [10. 1007/s00521-011-0599-1, DOI 10.1007/S00521-011-0599-1]
   Siwek K, 2009, INT J AP MAT COM-POL, V19, P303, DOI 10.2478/v10006-009-0026-2
   Song GY, 2014, PERS UBIQUIT COMPUT, V18, P1387, DOI 10.1007/s00779-013-0740-5
   Subbaraj P, 2008, WORLD ACAD SCI ENG T, V45, P680
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Taylor JW, 2007, IEEE T POWER SYST, V22, P2213, DOI 10.1109/TPWRS.2007.907583
   Taylor JW, 2002, IEEE T POWER SYST, V17, P626, DOI 10.1109/TPWRS.2002.800906
   Xiao Z, 2009, EXPERT SYST APPL, V36, P273, DOI 10.1016/j.eswa.2007.09.031
   Yun Z, 2008, IEEE T POWER SYST, V23, P853, DOI 10.1109/TPWRS.2008.922249
NR 43
TC 12
Z9 14
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2321
EP 2336
DI 10.1007/s11042-014-1943-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200009
DA 2024-07-18
ER

PT J
AU Norouzi, B
   Seyedzadeh, SM
   Mirzakuchaki, S
   Mosavi, MR
AF Norouzi, Benyamin
   Seyedzadeh, Seyed Mohammad
   Mirzakuchaki, Sattar
   Mosavi, Mohammad Reza
TI A novel image encryption based on row-column, masking and main diffusion
   processes with hyper chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Hyper-chaotic system; Row-column process; Masking
   process; Significant bit planes
ID SCHEME; ALGORITHM; CRYPTANALYSIS; BREAKING; STANDARD; SECURITY
AB In this paper, a novel algorithm for image encryption based on the hyper-chaotic system is proposed. In order to generate the initial conditions of the hyper-chaotic system, 256-bit long external secret key is used. The algorithm consists of three main sections. In the first section, instead of encrypting each pixel, the rows and columns of the image are encrypted using a row-column algorithm. In order to reach higher sensitivity, higher complexity and higher security, the second section employs masking process which is applied to each quarter of the image (i.e. sub-images) that is to be encrypted, using that sub-image data itself and one of the other sub-images and the average data of other quarters of image. Finally in the last diffusion section, the four most significant bit planes will be encrypted. Experimental results and performance analysis prove the viability of this cryptography based on privacy, integrity and authenticity. It is demonstrated that 2D Correlation Coefficients (CC), Mean Absolute Error (MAE), Encryption Quality (EQ), Mean Square Error (MSE), Peak Signal-to-Noise Ratio (PSNR), the Number of Pixel Change Rate (NPCR), the Unified Average Changing Intensity (UACI), entropy and decryption quality can satisfy security and performance requirements (CC<0.0032, MAE>80, EQ>210.90, MSE>9555, PSNR<8.3875, NPCR>99.61243%, UACI>33.47573% and Entropy>7.99734). It can be seen that this algorithm yields better security performance in comparison to the results obtained from other algorithms.
C1 [Norouzi, Benyamin; Seyedzadeh, Seyed Mohammad; Mirzakuchaki, Sattar; Mosavi, Mohammad Reza] Iran Univ Sci & Technol, Sch Elect Engn, Elect Res Ctr, Tehran, Iran.
C3 Iran University Science & Technology
RP Norouzi, B (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Elect Res Ctr, POB 16846-13114, Tehran, Iran.
EM benyamin.norouzi@gmail.com; sm_seyedzade@elec.iust.ac.ir;
   m_kuchaki@iust.ac.ir; M_Mosavi@iust.ac.ir
RI Mirzakuchaki, Sattar/JCO-4452-2023; Mirzakuchaki, Sattar/I-8764-2016;
   Mosavi, Mohammad Reza/P-3505-2018
OI Mirzakuchaki, Sattar/0000-0003-0232-9267; Mosavi, Mohammad
   Reza/0000-0002-2389-644X
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Akhavan A, 2011, J FRANKLIN I, V348, P1797, DOI 10.1016/j.jfranklin.2011.05.001
   Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Belkhouche F., 2003, P IEEE ANN TECHN C, P39
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Ge X, 2010, PHYS LETT A, V374, P1362, DOI 10.1016/j.physleta.2010.01.024
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Khanzadi H, 2010, INT CONF SIGN PROCES, P2608, DOI 10.1109/ICOSP.2010.5656132
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu FW, 2014, MULTIMED TOOLS APPL, V73, P715, DOI 10.1007/s11042-012-1185-y
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Nian-Sheng L, 2011, COMMUN NONLINEAR SCI, V16, P761, DOI 10.1016/j.cnsns.2010.04.021
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   ROSSLER OE, 1976, PHYS LETT A, V57, P397, DOI 10.1016/0375-9601(76)90101-8
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2013, NONLINEAR DYNAM, V73, P795, DOI 10.1007/s11071-013-0832-9
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhong Z, 2012, OPT COMMUN, V285, P584, DOI 10.1016/j.optcom.2011.11.025
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 56
TC 80
Z9 85
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 781
EP 811
DI 10.1007/s11042-013-1699-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400007
DA 2024-07-18
ER

PT J
AU Castro, H
   Andrade, MT
   Almeida, F
   Tropea, G
   Melazzi, NB
   Mousas, AS
   Kaklamani, DI
   Chiariglione, L
   Difino, A
AF Castro, H.
   Andrade, M. T.
   Almeida, F.
   Tropea, G.
   Melazzi, N. Blefari
   Mousas, A. S.
   Kaklamani, D. I.
   Chiariglione, L.
   Difino, A.
TI Semantically connected web resources with MPEG-21
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SemanticWeb; Relationships; MPEG-21; DID; DII; Cloud; QoE;
   ContentSearch; Metadata; RDF/OWL
AB The Web is rapidly becoming the prime medium for human socialization. The resources that enable that process (social web sites, blogs, media objects, etc.) present growing complexity and, collectively, weave an ever more intricate web of relationships. Current technology for declaring those relationships is predominantly implicit, ambiguous and semantically poor. As a consequence, their automatic assessment is complex and error prone, preventing the satisfaction of users' needs such as effective semantic searches. To address these limitations, whilst enabling the explicit declaration of semantically unambiguous relationships between digital resources, a solution employing structured semantic descriptors and ontologies was conceived, based on MPEG-21. This paper explains the functioning of the devised mechanism, and goes beyond that, into the definition of two novel employment venues for it, at the service of two real-world usage scenarios. These demonstrate the mechanism's added value as a powerful alternative for the semantically aware interconnection of web resources, and highlight the increased QoE that said mechanism enables.
C1 [Castro, H.; Andrade, M. T.; Almeida, F.] Univ Porto, Fac Engn, INESC TEC, Oporto, Portugal.
   [Tropea, G.; Melazzi, N. Blefari] UdR Roma Tor Vergata, CNIT, Rome, Italy.
   [Mousas, A. S.; Kaklamani, D. I.] NTUA, Sch Elect & Comp Engn, Athens, Greece.
   [Chiariglione, L.; Difino, A.] CEDEO Net, I-10040 Turin, Italy.
C3 INESC TEC; Universidade do Porto; University of Rome Tor Vergata;
   National Technical University of Athens
RP Castro, H (corresponding author), Univ Porto, Fac Engn, INESC TEC, Oporto, Portugal.
EM hcastro@inescporto.pt
RI Almeida, Fernando L. F./H-4751-2018; ANDRADE, MARIA/JGM-7159-2023; da
   Costa Andrade, Maria Eduarda/IXN-1199-2023; Andrade, Maria/HKN-0074-2023
OI Almeida, Fernando L. F./0000-0002-6758-4843; Castro,
   Helder/0000-0003-3858-1616; Andrade, Maria Teresa/0000-0002-1363-5027
FU Portuguese Foundation for Science and Technology
   [FCT/UTA-Est/MAI/0010/2009]; North Portugal Regional Operational Program
   (ON.2 - O Novo Norte), under the National Strategic Reference Framework
   (NSRF), through the European Regional, Development Fund (ERDF)
FX The work presented in this paper was partially supported by: Portuguese
   Foundation for Science and Technology within project
   FCT/UTA-Est/MAI/0010/2009; the North Portugal Regional Operational
   Program (ON.2 - O Novo Norte), under the National Strategic Reference
   Framework (NSRF), through the European Regional, Development Fund
   (ERDF).
CR Aitenbichler E, 2010, UBIQUITOUS COMPUTING
   Aleman-Meza B, 2010, P 2010 IE 4 INT C SE
   [Anonymous], 2011, 2100032003PDAM2 IS 3
   [Anonymous], 2002, 210003MPEG21 ISOIE 3
   [Anonymous], 2006, 2100032003FDAM1200 3
   [Anonymous], 2005, 2100022005EMPEG21 2
   [Anonymous], 2010, ACM Sigkdd Explorations Newsletter
   Burnett IS, 2005, IEEE T MULTIMEDIA, V7, P400, DOI 10.1109/TMM.2005.846789
   Chang CH, 2006, IEEE T KNOWL DATA EN, V18, P1411, DOI 10.1109/TKDE.2006.152
   Clocksin WF, 2003, PHIL T R SOC LONDO A, V2003, P361
   Kahng M, 2011, P 4 WORKSH WORKSH PH
   Khare R, 2006, IEEE INTERNET COMPUT, V10, P68, DOI 10.1109/MIC.2006.13
   Marsh J., 2006, XML INCLUSIONS XINCL
   Page L., 1999, PAGERANK CITATION RA
   Paulheim H, 2010, INT J SEMANT WEB INF, V6, P36, DOI 10.4018/jswis.2010040103
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   W3C's HTML Working Group, 1997, W3C HTML 4 01 SPEC S
   Zahariadis T, 2010, FUTURE INTERNET EURO
NR 18
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 439
EP 462
DI 10.1007/s11042-014-1918-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300007
DA 2024-07-18
ER

PT J
AU Su, ZY
   Zhou, L
   Liu, GJ
   Kong, JS
   Dai, YW
AF Su, Zhiyong
   Zhou, Lang
   Liu, Guangjie
   Kong, Jianshou
   Dai, Yuewei
TI Authenticating topological integrity of process plant models through
   digital watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Semi-fragile watermarking; Topology authentication;
   Topological integrity; Process plant model; Connection points
ID CAPD MODELS; CAD; SCHEME
AB Process plant models, which feature their intrinsical complex topological relation, are important industrial art works in the field of Computer-Aided Design (CAD). This paper investigates the topology authentication problem for process plant models. Compared with the widely studied watermarking based geometrical information protection and authentication techniques for traditional mechanical CAD drawings, topology authentication is still in its infancy and offers very interesting potentials for improvements. A semi-fragile watermarking based algorithm is proposed to address this interesting issue in this paper. We encode the topological relation among joint plant components into the watermark bits based on the hamming code. A subset of the model's connection points are selected as mark points for watermark embedding. Then those topology sensitive watermark bits are embedded into selected mark points via bit substitution. Theoretical analysis and experimental results demonstrate that our approach yields a strong ability in detecting and locating malicious topology attacks while achieves robustness against various non-malicious attacks.
C1 [Su, Zhiyong; Liu, Guangjie; Kong, Jianshou; Dai, Yuewei] Nanjing Univ Sci & Technol, Sch Automat, Nanjing 210094, Jiangsu, Peoples R China.
   [Zhou, Lang] Nanjing Univ Finance & Econ, Sch Informat Engn, Nanjing 210046, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Finance & Economics
RP Kong, JS (corresponding author), Nanjing Univ Sci & Technol, Sch Automat, Nanjing 210094, Jiangsu, Peoples R China.
EM suzhiyong@njust.edu.cn; yzzhoulang@126.com; gjieliu@njust.edu.cn;
   kongjs77@163.com; daiywei@163.com
OI su, zhiyong/0000-0001-9483-5268
FU National Natural Science Foundation of China [61170250, 61103201]
FX This work is supported in part by the National Natural Science
   Foundation of China (NO.61170250, NO.61103201). The models used in this
   paper are the courtesy of Beijing Zhongke Fulong Computer Technology
   Co., Ltd. The authors also gratefully acknowledge the helpful comments
   and suggestions of the reviewers, which have improved the presentation.
CR Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   DOW MR, 1987, COMPUT AIDED DESIGN, V19, P226, DOI 10.1016/0010-4485(87)90259-4
   Feng XQ, 2014, MULTIMED TOOLS APPL, V68, P497, DOI 10.1007/s11042-012-1039-7
   Gao XF, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344440
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Kwon KR, 2006, IEEE IMAGE PROC, P1385, DOI 10.1109/ICIP.2006.312593
   Kwon KR, 2006, LECT NOTES COMPUT SC, V4109, P217
   Kwon SH, 2011, COMPUT AIDED DESIGN, V43, P629, DOI 10.1016/j.cad.2011.02.006
   Lavoué G, 2007, COMPUT GRAPH-UK, V31, P480, DOI 10.1016/j.cag.2007.01.022
   Lee JJ, 2004, EURASIP J APPL SIG P, V2004, P2142, DOI 10.1155/S1110865704407148
   Lee SH, 2012, DIGIT SIGNAL PROCESS, V22, P744, DOI 10.1016/j.dsp.2012.04.015
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Li J, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344439
   Mooney A, 2006, CHAOS SOLITON FRACT, V30, P1088, DOI 10.1016/j.chaos.2005.09.029
   Ohbuchi R, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P180, DOI 10.1109/CGI.1999.777952
   Ohbuchi R., 2000, P 4 IFIP WG 5 2 WORK, P103
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Singh J, 2012, MULTIMED TOOLS APPL, V61, P1
   Su ZY, 2013, COMPUT GRAPH-UK, V37, P269, DOI 10.1016/j.cag.2013.02.009
   Su ZY, 2013, COMPUT AIDED DESIGN, V45, P1042, DOI 10.1016/j.cad.2013.04.001
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
NR 24
TC 2
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1687
EP 1707
DI 10.1007/s11042-013-1677-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200026
DA 2024-07-18
ER

PT J
AU Jun, EA
   Rhee, HS
   Kim, JG
   Jung, SW
   Lee, DH
AF Jun, Eun-A
   Rhee, Hyun Sook
   Kim, Jeom Goo
   Jung, Seok Won
   Lee, Dong Hoon
TI Fingerprint-based access control using smart cards in IPTV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint-based access control; IPTV environments; Multimedia content
   protection; Smart cards
ID SET-TOP BOX; KEY EXCHANGE; SYSTEM; SCHEME
AB In internet protocol television (IPTV) environments, authentication should be implemented to provide the IPTV contents to those legitimate subscribers. After successful authentication, a legitimate subscriber is unconditionally granted access to the contents. However, each content might have its own policy that restricts access according to subscriber's attribute such as age. Authentication only is not sufficient to realize access control embracing diverse policies depending on contents. In this paper, we propose a novel fingerprint-based scheme that enables finegrained access control according to the policies of contents providers and subscriber's attribute. The proposed scheme is robust against man-in-the-middle attacks, replay attacks, and impersonation attacks which are considered as common threats in IPTV environments. The scheme also prevents cloning and McCormac Hack problems, that are critical attacks specific to authentication using smart cards.
C1 [Jun, Eun-A; Rhee, Hyun Sook; Lee, Dong Hoon] Korea Univ, Grad Sch Informat Secur, Seoul, South Korea.
   [Kim, Jeom Goo] Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
   [Jung, Seok Won] Mokpo Natl Univ, Dept Informat Secur Engn, Jeonnam, South Korea.
C3 Korea University; Namseoul University; Mokpo National University
RP Lee, DH (corresponding author), Korea Univ, Grad Sch Informat Secur, Seoul, South Korea.
EM eajun@korea.ac.kr; hyunsook.rhee@gmail.com; jgoo@nsu.ac.kr;
   jsw@mokpo.ac.kr; donghlee@korea.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [2010-0029121]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2010-0029121).
CR [Anonymous], P IEEE INT INF COMM
   [Anonymous], IEEE MIL COMM C
   Clodfelter R, 2010, J RETAIL CONSUM SERV, V17, P181, DOI 10.1016/j.jretconser.2010.03.007
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dimitriou T, 2005, First International Conference on Security and Privacy for Emerging Areas in Communications Networks, Proceedings, P59, DOI 10.1109/SECURECOMM.2005.4
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   ITU Rec, 1992, COND ACC BROADC SYST
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P882, DOI 10.1109/TCE.2004.1341695
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P225, DOI 10.1109/TCE.2004.1277866
   Kamperman F, 2001, IEEE T CONSUM ELECTR, V47, P47, DOI 10.1109/30.920419
   Kanjanarin W, 2001, NINTH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, PROCEEDINGS, P140, DOI 10.1109/ICON.2001.962331
   Kiyomoto S, 2008, ISI 2008: 2008 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P215, DOI 10.1109/ISI.2008.4565060
   Kogan N, 2003, P IEEE S SECUR PRIV, P225, DOI 10.1109/SECPRI.2003.1199339
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Piramuthu S, 2007, DECIS SUPPORT SYST, V43, P897, DOI 10.1016/j.dss.2007.01.003
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sakakibara H., 1994, Proceedings. 1994 International Conference on Network Protocols (Cat. No.94TH8002), P91, DOI 10.1109/ICNP.1994.344372
   Schnorr C. P., 1991, Journal of Cryptology, V4, P161, DOI 10.1007/BF00196725
   Shim K, 2003, IEEE COMMUN LETT, V7, P248, DOI 10.1109/LCOMM.2003.812175
   Yoon EJ, 2009, INFORMATICA-LITHUAN, V20, P139
NR 20
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 647
EP 661
DI 10.1007/s11042-011-0765-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700003
DA 2024-07-18
ER

PT J
AU Khan, NU
   Arya, KV
   Pattanaik, M
AF Khan, Nafis Uddin
   Arya, K. V.
   Pattanaik, Manisha
TI Edge preservation of impulse noise filtered images by improved
   anisotropic diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic diffusion; Second order difference; Impulsive noise
   reduction; Edge preservation
ID REMOVAL; ENHANCEMENT; REDUCTION
AB This paper provides a robust scheme for random valued impulsive noise reduction along with edge preservation by anisotropic diffusion with improved diffusivity. The defective impulse noisy pixels are detected by Laplacian based second order pixel difference operation where these defective pixels are replaced by appropriate values with regard of the gray level of their four directional neighbors. This de-noised image undergoes the diffusion operation where diffusion coefficient function is modified to make it adaptive by incorporating local gray level variance information. The proposed modified diffusion scheme effectively restore the edges and fine details destroyed during impulse noise reduction process. The effect of proposed diffusion scheme has been studied on various images and the results are compared with some existing diffusion methods which are independently used for impulse noise reduction and edge preservation. The results shows that the prior removal of impulsive noise before the application of diffusion process is advantageous over the direct application of diffusion for removing the impulsive noise. In addition, the results of the proposed diffusion scheme are compared with some of the median filter based methods which are effectively used for impulse noise reduction without caring of edge preservation. The proposed diffusion scheme sufficiently preserves the edges without boosting of impulsive noise components on images corrupted up to 50 % of the impulsive noise density.
C1 [Khan, Nafis Uddin; Arya, K. V.; Pattanaik, Manisha] ABV Indian Inst Informat Technol & Management, Dept Informat & Commun Technol, Gwalior 474015, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Khan, NU (corresponding author), ABV Indian Inst Informat Technol & Management, Dept Informat & Commun Technol, Gwalior 474015, India.
EM nafisuk97@gmail.com; kvarya@iiitm.ac.in; manishapattanaik@iiitm.ac.in
RI Khan, Nafis uddin/IAR-4272-2023
OI Khan, nafis uddin/0000-0002-4681-5278; Arya, Karm
   Veer/0000-0001-7117-1745
CR [Anonymous], DIGITAL IMAGE PROCES
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chao LT, 2007, INF SCI, V177, P1073
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Chen QA, 2010, SIGNAL PROCESS, V90, P2778, DOI 10.1016/j.sigpro.2010.03.016
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen Y, 2001, COMPUT VIS IMAGE UND, V82, P85, DOI 10.1006/cviu.2001.0903
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dai F, 2008, SIGNAL PROCESS, V88, P2850, DOI 10.1016/j.sigpro.2008.05.008
   Delon J, 2012, INT CONF ACOUST SPEE, P1093, DOI 10.1109/ICASSP.2012.6288077
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Ji ZX, 2009, INFORM PROCESS LETT, V109, P1238, DOI 10.1016/j.ipl.2009.09.007
   Kelong Zheng, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P621, DOI 10.1109/CISP.2010.5647244
   Khan NU, 2010, IEEE SYS MAN CYBERN, P3735, DOI 10.1109/ICSMC.2010.5641838
   Khan NU, 2012, P 8 IND C VIS GRAPH, P3735
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pinho AJ, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P591, DOI 10.1109/ICIP.1996.560564
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2010, PATTERN RECOGN LETT, V31, P484, DOI 10.1016/j.patrec.2009.09.012
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Wang SS, 2013, SIGNAL PROCESS, V93, P2696, DOI 10.1016/j.sigpro.2013.03.005
   Wang Y, 2007, IEEE T IMAGE PROCESS, V16, P1854, DOI 10.1109/TIP.2007.899002
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P2428, DOI 10.1109/TIP.2011.2131664
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yu JH, 2008, PATTERN RECOGN LETT, V29, P1496, DOI 10.1016/j.patrec.2008.03.002
NR 29
TC 26
Z9 26
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 573
EP 597
DI 10.1007/s11042-013-1620-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700027
DA 2024-07-18
ER

PT J
AU Yang, H
   Cao, YH
   Su, H
   Fan, YW
   Zheng, SB
AF Yang, Hua
   Cao, Yihua
   Su, Hang
   Fan, Yawen
   Zheng, Shibao
TI The large-scale crowd analysis based on sparse spatial-temporal local
   binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Crowd density; Local binary pattern; Sparse point;
   Density distribution
ID DENSITY; PEOPLE
AB As a particular class of public security issues, the large-scale crowd analysis plays a very important role in video surveillance application. This paper proposes a sparse spatial-temporal local binary pattern (SST-LBP) descriptor to extract dynamic texture of the walking crowd which can be applied to the crowd density estimation and distribution analysis. The proposed approach consists of four steps. First of all, sparse selected locations are extracted, which vary notably in both spatial domain and temporal domain. Afterwards, we propose a SST-LBP algorithm to extract the local dynamic feature and utilize the local feature's statistical property to describe the crowd feature. Thirdly, the overall crowd density level can be determined by classifying the crowd feature with support vector machine. Finally, the local feature is used to represent the local density and then the overall density distribution can be described. To improve the accuracy, we introduce the perspective correction into the detection of sparse selected locations and the spectrum analysis of SST-LBP code. The experiments on different datasets not only show that the proposed SST-LBP method is effective and robust on the large-scale crowd density estimation and distribution, but also indicate that the deformity correction is useful. Compared with other methods, the proposed method has the advantage of low computation complexity and high efficiency. In addition, it performs well on all density levels and can present local crowd distribution.
C1 [Yang, Hua; Cao, Yihua; Su, Hang; Fan, Yawen; Zheng, Shibao] Shanghai Jiao Tong Univ, Dept EE, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
   [Yang, Hua] Shanghai Key Lab Digital Media Proc & Transmiss, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, H (corresponding author), Shanghai Key Lab Digital Media Proc & Transmiss, Shanghai, Peoples R China.
EM hyang@sjtu.edu.cn
FU NSFC [61102099, 61171172]; Scientific and Technological Committee of
   Shanghai [11231203102, 10231204002]; National Basic Research Program
   (973 Program) [2010CB731406]
FX This research is partly supported by NSFC (No. 61102099, No. 61171172),
   Scientific and Technological Committee of Shanghai (No. 11231203102, No.
   10231204002) and National Basic Research Program (973 Program, No.
   2010CB731406). We sincerely thank for the testing video datasets from
   University of Reading and permission (PETS2009) and University of
   Minnesota.
CR [Anonymous], MACHINE VISION LEARN
   [Anonymous], IASTED INT S APPL IN
   Beran V., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P31
   Chan A. B., 2008, IEEE C COMPUTER VISI, P1
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Ge WN, 2010, IEEE SIGNAL PROC MAG, V27, P107, DOI 10.1109/MSP.2010.937495
   Guo S, 2009, ICIA: 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-3, P217
   Huang D, 2003, NEURAL PROCESS LETT, V18, P97, DOI 10.1023/A:1026226617974
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Ma RH, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P170
   Marana AN, 1999, INT CONF ACOUST SPEE, P3521, DOI 10.1109/ICASSP.1999.757602
   Marana AN, 1998, SAFETY SCI, V28, P165, DOI 10.1016/S0925-7535(97)00081-7
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   POLUS A, 1983, J TRANSP ENG-ASCE, V109, P46, DOI 10.1061/(ASCE)0733-947X(1983)109:1(46)
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Roqueiro D, 2007, INT J PARALLEL EMERG, V22, P193, DOI 10.1080/17445760601139096
   Su H, 2011, LECT NOTES COMPUT SC, V6494, P302, DOI 10.1007/978-3-642-19318-7_24
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   Yang H., 2011, IEEE INT CON MULTI, P1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 26
TC 4
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 41
EP 60
DI 10.1007/s11042-012-1264-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700003
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Dooms, S
   Martens, L
AF De Pessemier, Toon
   Dooms, Simon
   Martens, Luc
TI Comparison of group recommendation algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group recommender; Evaluation; User modeling; Algorithms
AB In recent years recommender systems have become the common tool to handle the information overload problem of educational and informative web sites, content delivery systems, and online shops. Although most recommender systems make suggestions for individual users, in many circumstances the selected items (e.g., movies) are not intended for personal usage but rather for consumption in groups. This paper investigates how effective group recommendations for movies can be generated by combining the group members' preferences (as expressed by ratings) or by combining the group members' recommendations. These two grouping strategies, which convert traditional recommendation algorithms into group recommendation algorithms, are combined with five commonly used recommendation algorithms to calculate group recommendations for different group compositions. The group recommendations are not only assessed in terms of accuracy, but also in terms of other qualitative aspects that are important for users such as diversity, coverage, and serendipity. In addition, the paper discusses the influence of the size and composition of the group on the quality of the recommendations. The results show that the grouping strategy which produces the most accurate results depends on the algorithm that is used for generating individual recommendations. Therefore, the paper proposes a combination of grouping strategies which outperforms each individual strategy in terms of accuracy. Besides, the results show that the accuracy of the group recommendations increases as the similarity between members of the group increases. Also the diversity, coverage, and serendipity of the group recommendations are to a large extent dependent on the used grouping strategy and recommendation algorithm. Consequently for (commercial) group recommender systems, the grouping strategy and algorithm have to be chosen carefully in order to optimize the desired quality metrics of the group recommendations. The conclusions of this paper can be used as guidelines for this selection process.
C1 [De Pessemier, Toon; Dooms, Simon; Martens, Luc] IMinds Ghent Univ, Wica, B-9050 Ghent, Belgium.
C3 IMEC; Ghent University
RP De Pessemier, T (corresponding author), IMinds Ghent Univ, Wica, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; simon.dooms@ugent.be; luc1.martens@ugent.be
CR Ardissono L, 2002, LECT NOTES COMPUTER, V2266, P228, DOI DOI 10.1007/3-540-45844-1
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Berkovsky J., 2010, P 4 ACM C REC SYST, P111
   Breese J., 1998, P 14 C UNC ART INT, P43
   CHAO DL, 2005, P 2005 INT ACM SIGGR, P120, DOI DOI 10.1145/1099203.1099224
   Chen YL, 2008, EXPERT SYST APPL, V34, P2082, DOI 10.1016/j.eswa.2007.02.008
   Crossen A., 2002, P IUI, P184
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Dooms S., 2011, P WORKSHOP HUMAN DEC, P67
   Goren-Bar D., 2002, P 2 WORKSH PERS FUT
   *GROUPL RES, 2011, MOVIELENS DAT SETS
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI [10.1145/358916.358995, DOI 10.1145/358916.358995]
   Jameson A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P596
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Kay J, 2006, P WORKSH NEW TECHN P
   Lieberman H, 1999, KNOWL-BASED SYST, V12, P427, DOI 10.1016/S0950-7051(99)00036-2
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   MCCARTHY J, 2002, P WORKSH MOB ADHOC C
   McCarthy J. F., 1998, P 1998 ACM C COMP SU, P363, DOI DOI 10.1145/289444.289511
   McCarthy K., 2006, FLAIRS Conference, P86
   McNee SM, 2006, CHI 06 HUM FACT COMP, P1097, DOI DOI 10.1145/1125451.1125659
   Mouzhi Ge, 2010, P 4 ACM C REC SYST B, P257, DOI [10.1145/1864708.1864761, DOI 10.1145/1864708.1864761]
   Murakami T, 2008, LECT NOTES ARTIF INT, V4914, P40
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Quijano-Sánchez L, 2010, PROC INT C TOOLS ART, P121, DOI 10.1109/ICTAI.2010.92
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Smyth B, 2004, USER MODEL USER-ADAP, V14, P383, DOI 10.1007/s11257-004-5270-4
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
   Yu ZW, 2005, IEEE VTS VEH TECHNOL, P2800
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 32
TC 70
Z9 79
U1 1
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2497
EP 2541
DI 10.1007/s11042-013-1563-0
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300020
OA Green Published
DA 2024-07-18
ER

PT J
AU Chen, F
   He, HJ
   Tai, HM
   Wang, HX
AF Chen, Fan
   He, Hongjie
   Tai, Heng-Ming
   Wang, Hongxia
TI Chaos-based self-embedding fragile watermarking with flexible watermark
   payload
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Self-embedding; Flexible watermark payload; Chaos
ID IMAGE TAMPER DETECTION; RESTORATION CAPABILITY; RECOVERY; MECHANISM
AB This paper proposes a self-embedding watermarking scheme that reduces the watermark payload significantly while maintaining good recovery quality and security. The embedded watermark contributes to the tamper detection and content recovery and is composed of only the compression codes of the image content. The compression codes with variable length are generated according to the roughness of the image. To improve the security, a chaos-based pseudorandom sequence generator is adopted to generate block-mapping sequence and encrypt compression codes. The proposed method takes into account the invisibility, recovery quality, and security using the flexible watermark payload, which preserves sufficient information of the image block with as few bits as possible. Experimental results demonstrate that the proposed scheme not only outperforms conventional self-embedding fragile watermarking algorithms in tamper detection and recovery, but also improve the security against the various counterfeiting attacks.
C1 [Chen, Fan; He, Hongjie; Wang, Hongxia] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Tai, Heng-Ming] Univ Tulsa, Dept Elect Engn, Tulsa, OK 74104 USA.
C3 Southwest Jiaotong University; University of Tulsa
RP He, HJ (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM hehojie@126.com
RI fan, chen/GWC-9330-2022; Tai, Heng-Ming/A-9267-2009; Wang,
   Hongxia/AAE-2135-2022
OI Tai, Heng-Ming/0000-0002-0162-7492
FU National Natural Science Foundation of China [60970122, 61170226];
   Research Fund for the Doctoral Program of Higher Education
   [20090184120021]; Fundamental Research Funds for the Central
   Universities [SWJTU09CX039, SWJTU10CX09]
FX This work is supported in part by the National Natural Science
   Foundation of China (60970122, 61170226), the Research Fund for the
   Doctoral Program of Higher Education (20090184120021), and the
   Fundamental Research Funds for the Central Universities (SWJTU09CX039,
   SWJTU10CX09)
CR Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chen F, 2011, LNCS, V7128, P142
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J, 1999, P INT C CONT SEC DAT
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lian SG, 2007, CHAOS SOLITON FRACT, V34, P851, DOI 10.1016/j.chaos.2006.03.120
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Zhang JS, 2007, PHYS LETT A, V362, P439, DOI 10.1016/j.physleta.2006.10.052
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 13
TC 20
Z9 23
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 41
EP 56
DI 10.1007/s11042-012-1332-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800003
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Wang, LM
AF Fu, Zhaoxia
   Wang, Liming
TI Optimized design of automatic image mosaic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image mosaic; Projection transformation; Image morphing; Inverse mapping
AB Virtual reality technology has been widely used in the fields of aerospace, robotics remote operation and biology medicine and so on. Panoramic image mosaic is one of the very important parts. Since photographs taken by the ordinary camera may appear distorted, overlapping and tilting, we propose a wide mosaic algorithm used in the projection transformation in this paper. The algorithm first uses the Harris operator to extract corners, adopting the improved corner response function for avoiding the randomness of k value. Then fast RANSAC method is used to match the images approximately, and the cross-correlation method of gray window as the center of feature points is used to the redundant feature points for further exact match. And then it need solve the model transformation parameters between two images according to these corners information and obtain the projection transformation matrix. Finally, the application of image morphing technique is for reconstructing the image having spatial transform, the result of which are carried on stitching seamlessly with another source image. Experimental results show that the algorithm is effective to achieve a good mosaic.
C1 [Fu, Zhaoxia; Wang, Liming] North Univ China, Informat & Commun Engn Inst, Sci & Technol Elect Test & Measurement Lab, Taiyuan 030051, Peoples R China.
   [Fu, Zhaoxia; Wang, Liming] North Univ China, Informat & Commun Engn Inst, Key Lab Instrumentat Sci & Dynam Measurement, Minist Educ, Taiyuan 030051, Peoples R China.
   [Fu, Zhaoxia] CPC, Shanxi Prov Comm, Party Sch, Taiyuan 030006, Peoples R China.
C3 North University of China; North University of China
RP Fu, ZX (corresponding author), North Univ China, Informat & Commun Engn Inst, Sci & Technol Elect Test & Measurement Lab, Taiyuan 030051, Peoples R China.
EM fzx2005@163.com
RI zhang, yueqi/JXM-4287-2024
FU Natural Science Foundation of China (NSFC) [61071193]
FX Authors like to express their thanks to anonymous reviewers for their
   help in revising the manuscript. This work is supported in part by the
   Natural Science Foundation of China (NSFC) under Grant No. 61071193.
CR Bao P, 2000, IEEE INFOR VIS, P309, DOI 10.1109/IV.2000.859773
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Fontanelli D, 2007, IEEE INT CON AUTO SC, P963
   GAO G, 2007, 2 INT C INN COMP INF, P471
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hsu CT, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P887, DOI 10.1109/ICIP.2000.899856
   Mattson P, 1998, INT J IMAG SYST TECH, V9, P475, DOI 10.1002/(SICI)1098-1098(1998)9:6<475::AID-IMA9>3.0.CO;2-N
   Matungka R, 2009, IEEE T IMAGE PROCESS, V18, P2340, DOI 10.1109/TIP.2009.2025010
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 13
TC 8
Z9 12
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 503
EP 514
DI 10.1007/s11042-013-1387-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800023
DA 2024-07-18
ER

PT J
AU Lei, JJ
   Feng, K
   Wu, MM
   Li, S
   Hou, CP
AF Lei, Jianjun
   Feng, Kun
   Wu, Meimin
   Li, Shuai
   Hou, Chunping
TI Rate control of hierarchical B prediction structure for multi-view video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MVC; Rate control; Mean Absolute Distortion (MAD); Header bits;
   Hierarchical B prediction
ID LAYER RATE CONTROL; BIT ALLOCATION; H.264/AVC
AB Rate control plays an important role in regulating bit streams in video coding. In order to obtain good coding performance, the hierarchical B prediction structure has been adopted in Multi-view Video Coding (MVC). However, the conventional rate control scheme is not efficient in the hierarchical B prediction structure. In this paper, we propose a rate control algorithm to address this problem. First, the accurate estimation of Mean Absolute Distortion (MAD) of the current frame is desired for both quantization parameter (QP) selection and Rate Distortion Optimization (RDO). Considering the hierarchical B structure, a bi-directional MAD prediction model is proposed to predict the MAD of the current frame by using the actual MADs of the encoded frames in the lower Temporal Layers (TLs). Second, the number of header bits has a close relationship with the TLs in the hierarchical B prediction structure. Therefore, we propose an enhanced prediction method in which a proportional relationship of the header bits is introduced if the frames are located in different TLs. Experimental results show that our proposed algorithm can achieve both accurate target bit rate and good coding performance.
C1 [Lei, Jianjun; Feng, Kun; Wu, Meimin; Li, Shuai; Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Lei, Jianjun] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
C3 Tianjin University; University of Washington; University of Washington
   Seattle
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM jjleitg@gmail.com
RI Li, Shuai/AAE-6907-2019; Lei, Jianjun/P-2539-2018
OI Li, Shuai/0000-0002-9938-0917; 
FU Natural Science Foundation of China [61271324, 60932007, 61002029,
   61001178, 61202266]; Natural Science Foundation of Tianjin
   [12JCYBJC10400, 12JCQNJC00500, 12JCQNJC00300]; Research Fund for the
   Doctoral Program of Higher Education of China [20110032120029]
FX The authors would like to thank the reviewers for their constructive and
   valuable comments on this paper. We would also like to thank Prof.
   Zhenhua Ling, Dr. Haoming Chen and Dr. Chen Zhao for comments and
   suggestions. This research was partially supported by the Natural
   Science Foundation of China (No.61271324, 60932007, 61002029, 61001178,
   61202266), Natural Science Foundation of Tianjin (No.12JCYBJC10400,
   12JCQNJC00500, 12JCQNJC00300), and Research Fund for the Doctoral
   Program of Higher Education of China (No.20110032120029).
CR [Anonymous], 2005, JTC1SC29WG11 ISOIEC
   Chen Y., 2009, JTC1SC29WG11 ISO IEC
   Chi MC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P93
   Cho YJ, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P387
   Cho YJ, 2009, INT CONF ACOUST SPEE, P641, DOI 10.1109/ICASSP.2009.4959665
   Hu SD, 2011, IEEE T CIRC SYST VID, V21, P1152, DOI 10.1109/TCSVT.2011.2138810
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Li M, 2009, SIGNAL PROCESS-IMAGE, V24, P177, DOI 10.1016/j.image.2008.12.009
   Li Zhen-gang, 2009, Journal of Applied Sciences, V27, P502
   Lim JE, 2003, IEEE T CONSUM ELECTR, V49, P1498, DOI 10.1109/TCE.2003.1261259
   Liu F, 2011, CHINA COMMUN, V8, P83
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Muller K, 2006, PICT COD S, P24
   Naito S, 1999, VCIP SPIE US, P1082
   Park S, 2009, ACM SIGPLAN NOTICES, V44, P25, DOI 10.1145/1508284.1508249
   Seo CW, 2010, IEEE T CIRC SYST VID, V20, P1210, DOI 10.1109/TCSVT.2010.2057011
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Son NR, 2006, LECT NOTES COMPUT SC, V4319, P822
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Woo W, 1999, IEEE T CIRC SYST VID, V9, P861, DOI 10.1109/76.785724
   Xu L, 2011, IEEE VIS COMM IM PRO, P6
   Xu L, 2007, IEEE INT SYMP CIRC S, P49, DOI 10.1109/ISCAS.2007.378179
   Yan T, 2009, IEEE S PHOT OP EL SO, P14
   Yi XQ, 2006, J VIS COMMUN IMAGE R, V17, P407, DOI 10.1016/j.jvcir.2005.04.005
   Zeng HQ, 2011, IEEE T CIRC SYST VID, V21, P1659, DOI 10.1109/TCSVT.2011.2133350
   ZG Li, 2003, JTC1SC29WG11 ISO IEC
   Zhu C, 2009, IEEE T CIRC SYST VID, V19, P511, DOI 10.1109/TCSVT.2009.2013521
   Zhu ZJ, 2007, 3DTV C, P7
NR 31
TC 9
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 825
EP 842
DI 10.1007/s11042-013-1386-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800037
DA 2024-07-18
ER

PT J
AU Pandey, P
   Kumar, S
   Singh, SK
AF Pandey, Punit
   Kumar, Shishir
   Singh, Satish K.
TI Rightful ownership through image adaptive DWT-SVD watermarking algorithm
   and perceptual tweaking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; False positive problem; Principal
   component; Tuning matrix; Adaptive and blended watermarking
ID COPYRIGHT PROTECTION; DIGITAL WATERMARKING; SCHEME; TRANSFORM; VECTOR;
   SYSTEM
AB In this paper, a tailored blended image adaptive watermarking scheme has been presented, which is based on DWT and SVD. Through this paper an attempt has been made to solve the problem of false positive while maintaining the robustness and imperceptibility with the help of principal component and perceptual tuning of the image. Perceptual tuning is a non-blind technique and based on the objective quality of image. The embedding strength is made dependent on watermark features as well as of host in wavelet domain by using tuning parameter which is user specific. The idea of embedding the principal component of intermediate frequency sub-bands of watermark image into singular values of perceptually tuned intermediate frequency sub-bands of host image have been exploited. The proposed algorithm is providing the adaptive behavior towards the image content for perceptual transparency and at the same time avoiding the possibility of false watermark extraction well supported by a private key, which is necessary at the time of extraction. Thus the proposed watermarking algorithm is a kind of non-blind, image adaptive and suitable for rightful ownership. Various comparative results make the algorithm superior in terms of intentional and non-intentional attacks. Also the algorithm is strong against the print and scan attack.
C1 [Pandey, Punit; Kumar, Shishir] Jaypee Univ Engn & Technol, Guna 473226, India.
   [Singh, Satish K.] Indian Inst Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Kumar, S (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, India.
EM pandey02_bit@rediffmail.com; dr.shishir@yahoo.com;
   satish432002@rediffmail.com
RI Kumar, Shishir/AAE-9164-2020; singh, satish/U-7158-2018; Singh, Dr
   Satish Kumar/JMP-6186-2023
OI singh, satish/0000-0002-8536-4991; Singh, Dr Satish
   Kumar/0000-0003-1991-7727
CR ABDELAZIZ B, 2003, P DIG WAT 2 INT WORK, P277
   Agarwal R, 2008, INT J IMAGE GRAPH, V8, P351, DOI 10.1142/S0219467808003131
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2002, IMAGING SCI J, V50, P133, DOI 10.1080/13682199.2002.11784400
   Chang CC, 2002, INFORMATICA, V26, P359
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox I., 2001, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Gaurav B, 2011, MULTIMED TOOLS APPL, DOI [10.1007/s11042-011-0788-z, DOI 10.1007/S11042-011-0788-Z]
   Jain C, 2008, RELIABLE SVD BASED W
   Kim WS, 1999, ELECTRON LETT, V35, P466
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li Q, 2007, ADAPTIVE DWT SVD DOM, P1947
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Maity SP, 2011, INFORM SCIENCES, V181, P450, DOI 10.1016/j.ins.2010.09.029
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Singh SK, 2011, SIGNAL PROCESS-IMAGE, V26, P662, DOI 10.1016/j.image.2011.08.001
   Wu YD, 2005, IEEE T MULTIMEDIA, V7, P624, DOI 10.1109/TMM.2005.846774
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 39
TC 18
Z9 19
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 723
EP 748
DI 10.1007/s11042-013-1375-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800033
DA 2024-07-18
ER

PT J
AU Sun, YC
   Tsai, WJ
AF Sun, Yu-Chen
   Tsai, Wen-Jiin
TI Rate-distortion optimized mode selection method for multiple description
   video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description video coding; Rate-distortion optimization; Unequal
   error protection; Multimedia transmission
AB Multiple description coding (MDC) is a potential solution for video transmission over error-prone networks because it shows promising enhancement of error resilient capability. The MDC systems encode a single video stream into two or more equally important independent sub-streams, called descriptions. Therefore, if some of the descriptors get lost, remaining descriptors can be used to recover the video. Much research has proposed different information distribution methods. Since each method has different characteristic, we proposed a general rate-distortion optimization framework for MDC systems in this paper. By sophisticated rate-distortion analysis and optimization, the framework enables MDC systems to adaptively encode video considering contents and channel variation. Experimental results showed that, by comparing with the work in Tsai and You (IEEE Trans Circ Syst Video Technol 22(2):309-320, 2012), the proposed technique improves the R-D performance significantly. The improvement can be up to 2.4 dB for the channels with 0 % similar to 20 % packet loss rates, and it can be even more if the loss rate increases. The proposed framework is not restricted to specific MDC tools. Ones can easily integrate their proposed coding tools into the framework and achieve better performance as long as the macroblock's bitrate and distortion information can be measured.
C1 [Sun, Yu-Chen; Tsai, Wen-Jiin] Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu 30050, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, WJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu 30050, Taiwan.
EM wjtsai@cs.nctu.edu.tw
RI Sun, Yuchen/JZD-1692-2024
CR APOSTOLOPOULOS JG, 2000, P IEEE INT C IM PROC
   Bemardini R, 2004, P IEEE INT C IM PROC
   Bjontegaard G., 2008, VCEGM33
   Campana O, 2006, P IEEE AS C SIGN SYS
   Comas D, 2003, EURASIP J APPL SIG P, V2003, P81, DOI 10.1155/S1110865703211215
   Comas D, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P581, DOI 10.1109/MMSP.2001.962795
   Correia P, IEEE T MULT IN PRESS
   Durigon M, 2005, P IEEE WORK MULTIMED
   FARBER N, 1999, P IEEE INT C IM PROC
   Gao S, 2006, P INT C DIG COMM PRO
   Hsiao CW, 2010, IEEE T CIRC SYST VID, V20, P76, DOI 10.1109/TCSVT.2009.2026973
   Jia J, 2006, IEICE T FUND ELECTR, VE89A, P1601, DOI 10.1093/ictfec/c89-a.6.1601
   Lin CS, 2010, MULTIMED TOOLS APPL, V46, P71, DOI 10.1007/s11042-009-0308-6
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Reichel J, 2007, JVTX202 JSVM
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Tsai WJ, 2012, IEEE T CIRC SYST VID, V22, P309, DOI 10.1109/TCSVT.2011.2179450
   Tsai WJ, 2010, IEEE T CIRC SYST VID, V20, P1822, DOI 10.1109/TCSVT.2010.2087816
   Vaishampayan VA, 1993, IEEE T INF THEORY, V39
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2006, IEEE T CIRC SYST VID, V16, P716, DOI 10.1109/TCSVT.2006.875203
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhu C, 2009, IEEE T CIRC SYST VID, V19, P511, DOI 10.1109/TCSVT.2009.2013521
NR 25
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1411
EP 1439
DI 10.1007/s11042-013-1434-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300018
DA 2024-07-18
ER

PT J
AU Vankeirsbilck, B
   Verslype, D
   Staelens, N
   Simoens, P
   Develder, C
   Demeester, P
   De Turck, F
   Dhoedt, B
AF Vankeirsbilck, Bert
   Verslype, Dieter
   Staelens, Nicolas
   Simoens, Pieter
   Develder, Chris
   Demeester, Piet
   De Turck, Filip
   Dhoedt, Bart
TI Platform for real-time subjective assessment of interactive multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive media quality assessment; Quality of experience;
   Interactivity; Subjective quality; Thin client computing
ID PERFORMANCE; QUALITY; FRAMEWORK
AB With the advent of cloud computing and remote execution of interactive applications, there is a need for evaluating the Quality of Experience (QoE) and the influence on this QoE of network condition variations, media encoding parameter settings and related optimization algorithms. However, current QoE assessment focuses mainly on audiovisual quality in non-interactive applications, such as video-on-demand services. On the other hand, where experiments aim to quantify interactive quality, the focus is typically targeted at games, using an ad-hoc test setup to assess the impact of network variations on the playing experience. In this paper, we present a novel platform enabling the assessment of a broad range of interactive applications (e.g., thin client remote desktop systems, remotely rendered engineering applications, games). Dynamic reconfiguration of media encoding and decoding is built into the system, to allow dynamic adaptation of the media encoding to the network conditions and the application characteristics. Evaluating the influence of these automatic adaptations is a key asset of our approach. A range of possible use cases is discussed, as well as a performance study of our implementation, showing that the platform we built is capable of highly controllable subjective user assessment. Furthermore, we present results obtained by applying the platform for a subjective evaluation of an interactive multimedia application. Specifically, the influence of visual quality and frame rate on interactive QoE has been assessed for a remotely executed race game.
C1 [Vankeirsbilck, Bert; Verslype, Dieter; Staelens, Nicolas; Simoens, Pieter; Develder, Chris; Demeester, Piet; De Turck, Filip; Dhoedt, Bart] Univ Ghent, Dept Informat Technol INTEC, Internet Based Commun Networks & Serv IBCN iMinds, B-9050 Ghent, Belgium.
   [Simoens, Pieter] Ghent Univ Coll, Dept INWE, B-9000 Ghent, Belgium.
C3 IMEC; Ghent University; Ghent University; HOGENT University College of
   Applied Sciences & Arts
RP Vankeirsbilck, B (corresponding author), Univ Ghent, Dept Informat Technol INTEC, Internet Based Commun Networks & Serv IBCN iMinds, Gaston Crommenlaan 8,Bus 201, B-9050 Ghent, Belgium.
EM bert.vankeirsbilck@intec.ugent.be
RI Develder, Chris/S-6359-2019; Dhoedt, Bart AGMH/K-5851-2015
OI Develder, Chris/0000-0003-2707-4176; Dhoedt, Bart
   AGMH/0000-0002-7271-7479; Vankeirsbilck, Bert/0000-0001-9489-8306; De
   Turck, Filip/0000-0003-4824-1199; Simoens, Pieter/0000-0002-9569-9373
FU IWT - Vlaanderen; Research Foundation - Flanders (FWO-Vl.)
FX Bert Vankeirsbilck is funded by a Ph.D. grant of the IWT - Vlaanderen.
   Chris Develder is supported in part by a post-doctoral fellowship of the
   Research Foundation - Flanders (FWO-Vl.).
CR [Anonymous], VDRIFT OP SOURC RAC
   [Anonymous], REP VAL VID QUAL MOD
   Chang Yu-Chun., 2011, IEEE INT WORKSHOP TE, P1, DOI [10.1109/CQR.2011.5996092, DOI 10.1109/ICME.2011.6012177]
   Chen KT, 2006, COMMUN ACM, V49, P34, DOI 10.1145/1167838.1167859
   Chen KT, 2009, IEEE INFOCOM SER, P702, DOI 10.1109/INFCOM.2009.5061978
   Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339
   Chun Y, 2008, CHINESE J ELECTRON, V17, P242
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Claypool Mark., 2009, Proceedings of the 4th International Conference on Foundations of Digital Games, P34, DOI DOI 10.1145/1536513.1536529
   Dick M., 2005, NetGames'05, P1
   Engel K, 2000, SPRING COMP SCI, P167
   Jarschel M, 2013, MATH COMPUT MODEL, V57, P2883, DOI 10.1016/j.mcm.2011.12.014
   Jovic M., 2008, PPPJ 08, P137, DOI DOI 10.1145/1411732.1411751
   Jumisko-Pyykkö S, 2011, MULTIMED TOOLS APPL, V55, P185, DOI 10.1007/s11042-010-0573-4
   Kohler E, 2000, ACM T COMPUT SYST, V18, P263, DOI 10.1145/354871.354874
   Kuipers F, 2010, LECT NOTES COMPUT SC, V6074, P216
   Lai AM, 2006, ACM T COMPUT SYST, V24, P175, DOI 10.1145/1132026.1132029
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Nieh J, 2003, ACM T COMPUT SYST, V21, P87, DOI 10.1145/592637.592640
   Quax Peter., 2004, NETGAMES 04, P152
   Ries M, 2008, INT CONF SYST SIGNAL, P181, DOI 10.1109/IWSSIP.2008.4604397
   Santiago P, 2008, P 2 INT WORKSH EMOTI
   Stegmaier S., 2002, PROC JOINT EUROGRAPH, P87, DOI [10.5555/509740.509754, DOI 10.5555/509740.509754]
   Tolia N, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.101
   Wattimena A. F., 2006, NETGAMES 06, DOI [DOI 10.1145/1230040.1230052, 10. 1145/1230040. 1230052]
   Yoo SH, 2006, INTERACT COMPUT, V18, P1084, DOI 10.1016/j.intcom.2006.01.003
   ZELDOVICH N, 2005, P ANN C USENIX ANN T, P54
NR 27
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 749
EP 775
DI 10.1007/s11042-013-1395-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800034
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, FS
   Lu, MY
AF Wang, Fasheng
   Lu, Mingyu
TI Robust particle tracker via Markov Chain Monte Carlo posterior sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Particle filter; Markov Chain Monte Carlo
AB Particle Filter has grown to be a standard framework for visual tracking. This paper proposes a robust particle tracker based on Markov Chain Monte Carlo method, aiming at solving the thorny problems in visual tracking induced by object appearance changes, occlusions, background clutter, and abrupt motions. In this algorithm, we derive the posterior probability density function based on second order Markov assumption. The posterior probability density is the joint density of the previous two states. Additionally, a Markov Chain with certain length is used to approximate the posterior density to avoid the drawbacks of traditional importance sampling based algorithm, which consequently improves the searching ability of the proposed tracker. We compare our approach with several alternative tracking algorithms, and the experimental results demonstrate that our tracker is superior to others in dealing with various types of challenging scenarios.
C1 [Wang, Fasheng; Lu, Mingyu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Liaoning Provin, Peoples R China.
C3 Dalian Maritime University
RP Lu, MY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Informat Bldg B-106,1 Linghai Rd, Dalian 116026, Liaoning Provin, Peoples R China.
EM fswang@dlmu.edu.cn; lumingyu@dlmu.edu.cn
RI Wang, Fasheng/AAD-9930-2020
OI Wang, Fasheng/0000-0002-0946-0789
FU National Natural Science Foundation of China [60772063, 61073133,
   61175053, 60973067, 61175096, 61272369]; Innovation Group Project of
   China Education Ministry [2011ZD010]; Fundamental research fund of DMU
   [2012QN030]; Foundation of Scientific Planning Project of Dalian City
   [2011E15SF100]; Natural Science Foundation of Liaoning Education
   Ministry [L2011241, L2010043]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60772063, 61073133, 61175053, 60973067, 61175096, 61272369),
   the Innovation Group Project of China Education Ministry (No. 2011ZD010,
   Fundamental research fund of DMU (NO. 2012QN030), Foundation of
   Scientific Planning Project of Dalian City (No. 2011E15SF100), the
   Natural Science Foundation of Liaoning Education Ministry (No. L2011241,
   L2010043).
CR [Anonymous], P IEEE AER C BIG SKY
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643
   Cong TD, 2012, P IEEE INT C AC SPEE
   Geyer CJ, 2011, CH CRC HANDB MOD STA, P3
   Gilks WR, 2001, J ROY STAT SOC B, V63, P127, DOI 10.1111/1467-9868.00280
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kwon J, 2008, LECT NOTES COMPUT SC, V5302, P387, DOI 10.1007/978-3-540-88682-2_30
   Liang FM, 2007, J AM STAT ASSOC, V102, P305, DOI 10.1198/016214506000001202
   Martínez-del-Rincón J, 2011, PATTERN RECOGN LETT, V32, P210, DOI 10.1016/j.patrec.2010.08.006
   Roberts GO, 2009, J COMPUT GRAPH STAT, V18, P349, DOI 10.1198/jcgs.2009.06134
   Wang FS, 2012, INT C PATT RECOG, P3066
   Yang M, 2009, IEEE T IMAGE PROCESS, V18, P1633, DOI 10.1109/TIP.2009.2019807
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhou XZ, 2012, IEEE T IMAGE PROCESS, V21, P789, DOI 10.1109/TIP.2011.2168414
NR 16
TC 10
Z9 10
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 573
EP 589
DI 10.1007/s11042-013-1379-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800026
DA 2024-07-18
ER

PT J
AU Farid, MS
   Mahmood, A
AF Farid, M. Shahid
   Mahmood, Arif
TI An image composition algorithm for handling global visual effects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image composition; Image fusion; Superimposed images
ID FUSION
AB Image composition is widely used in television and film industry to create synthetic visual effects. It requires seamless integration of different parts of two or more images into a single image. Existing image composition techniques only change the local contents of the resulting image while in many cases local changes may also require some global effects as well. For example, if the image of sun from one image is transferred to another image, the global brightness pattern should also be transferred. Unfortunately existing techniques cannot handle global effects of local content manipulations. This paper describes a novel image composition technique which captures global effects associated with a specific local content from one image and incorporates in the second image. In our proposed technique, all images are transformed to the frequency domain. The composite image is created in frequency domain by mixing different frequencies from multiple images and then transformed back to the spatial domain. We have experimented the proposed technique to shift the image of sun along with its global brightness pattern, the global effects of rain and also for transferring global texture pattern from one image to the other. In most of the cases the results produced by our algorithm appear far close to real images than state of the art existing image composition techniques.
C1 [Farid, M. Shahid] Univ Punjab, Coll Informat Technol, Lahore, Pakistan.
   [Mahmood, Arif] Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia.
C3 University of Punjab; University of Western Australia
RP Farid, MS (corresponding author), Univ Punjab, Coll Informat Technol, Lahore, Pakistan.
EM shahid.fareed@pucit.edu.pk; arif.mahmood@uwa.edu.au
RI Mahmood, Arif/R-7949-2019; Farid, Muhammad Shahid/AAF-1825-2019
OI Mahmood, Arif/0000-0001-5986-9876; Farid, Muhammad
   Shahid/0000-0002-8384-2830; Mahmood, Arif/0000-0001-8555-0383
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Arivazhagan S, 2009, SIGNAL IMAGE VIDEO P, V3, P137, DOI 10.1007/s11760-008-0065-4
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Farid MS, 2012, J MATH IMAGING VIS, V42, P50, DOI 10.1007/s10851-011-0273-3
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Flitti F, 2009, SIGNAL IMAGE VIDEO P, V3, P275, DOI 10.1007/s11760-008-0080-5
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   GRAPHICS IC, 1994, IEEE COMPUT GRAPH, V14, P83, DOI DOI 10.1109/38.310740
   Haenselmann T, 2009, IMAGE VISION COMPUT, V27, P391, DOI 10.1016/j.imavis.2008.06.008
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Porter T., 1984, Computers & Graphics, V18, P253
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Suo JL, 2011, IEEE T SYST MAN CY A, V41, P226, DOI 10.1109/TSMCA.2010.2064304
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   Toet A., 1990, Machine Vision and Applications, V3, P1, DOI 10.1007/BF01211447
   WALLACE BA, 1981, SIGGRAPH 81 C P, V15, P253, DOI DOI 10.1145/800224.806813
   Yang WX, 2009, IEEE T IMAGE PROCESS, V18, P2584, DOI 10.1109/TIP.2009.2027365
   Zhang Q, 2011, PATTERN RECOGN LETT, V32, P1544, DOI 10.1016/j.patrec.2011.06.002
NR 24
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1699
EP 1716
DI 10.1007/s11042-012-1303-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000033
DA 2024-07-18
ER

PT J
AU Shi, YH
   Wen, B
   Ding, WP
   Qi, N
   Yin, BC
AF Shi, Yunhui
   Wen, Bo
   Ding, Wenpeng
   Qi, Na
   Yin, Baocai
TI Prediction-based realistic 3D model compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometry image; Normal-map image; Geometric correlation; Prediction
ID PARAMETRIZATION
AB The benefit of using the geometry image to represent an arbitrary 3D mesh is that the 3D mesh can be re-sampled as a completely regular structure and coded efficiently by common image compression methods. For geometry image-based 3D mesh compression, we need to code the normal-map images while coding geometry images to improve the subjective quality and realistic effects of the reconstructed model. In traditional methods, a geometry image and a normal-map image are coded independently. However a strong correlation exists between these two kinds of images, because both of them are generated from the same 3D mesh and share the same parameterization. In this paper we propose a predictive coding framework, in which the normal-map image is predicted based on the geometric correlation between them. Additionally we utilize the strong geometric correlation among three components of normal-map image to improve the predicting accuracy. The experimental results show the proposed coding framework improves the coding efficiency of normal-map image, meanwhile the realistic effect of a 3D mesh is significantly enhanced.
C1 [Shi, Yunhui; Wen, Bo; Ding, Wenpeng; Qi, Na; Yin, Baocai] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wen, B (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM syhzm@bjut.edu.cn; wenbo@emails.bjut.edu.cn; wpding@bjut.edu.cn;
   q1987n@emails.bjut.edu.cn; ybc@bjut.edu.cn
FU 973 Program [2011CB302703]; National Natural Science Foundation of China
   [60825203, 61033004, 60973056, 61170103, 61003182, U0935004]; Beijing
   Natural Science Foundation [4102009, 4112007]
FX This paper is supported by 973 Program (2011CB302703), the National
   Natural Science Foundation of China (No. 60825203, 61033004, 60973056,
   61170103, 61003182, U0935004), Beijing Natural Science Foundation
   (4102009, 4112007).
CR Alliez P., 2003, In Advances in Multiresolution for Geometric Modelling, P3
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Ding WP, 2007, IEEE T IMAGE PROCESS, V16, P416, DOI 10.1109/TIP.2006.888341
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hoppe H, 2005, MATH VIS, P27, DOI 10.1007/3-540-26808-1_2
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Lin NH, 2007, IEEE T CONSUM ELECTR, V53, P182, DOI 10.1109/TCE.2007.339523
   Peercy M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P303, DOI 10.1145/258734.258873
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Sander P. V., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P87
   Shi YH, 2009, LECT NOTES COMPUT SC, V5820, P281
   Wen W, 2009, LECT NOTES COMPUT SC, V5879, P1230, DOI 10.1007/978-3-642-10467-1_124
NR 14
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2125
EP 2137
DI 10.1007/s11042-012-1231-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500033
DA 2024-07-18
ER

PT J
AU Damasceno, JR
   dos Santos, JAF
   Muchaluat-Saade, DC
AF Damasceno, Jean Ribeiro
   Ferreira dos Santos, Joel Andre
   Muchaluat-Saade, Debora Christina
TI EDITEC - a graphical editor for hypermedia composite templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NCL; XTemplate; Graphical editor; Hypermedia composite templates;
   Authoring tool
AB Hypermedia composite templates define generic structures of nodes and links to be added to a document composition, providing spatio-temporal synchronization semantics. This paper presents EDITEC, a graphical editor for hypermedia composite templates. EDITEC templates are based on the XTemplate 3.0 language. The editor was designed for offering a user-friendly visual approach. It presents a new method that provides several options for representing iteration structures graphically, in order to specify a certain behavior to be applied to a set of generic document components. The editor provides a multi-view environment, giving the user a complete control of the composite template during the authoring process. Composite templates can be used in NCL documents for embedding spatio-temporal semantics into NCL contexts. NCL is the standard declarative language used for the production of interactive applications in the Brazilian digital TV system and ITU H. 761 IPTV services. Hypermedia composite templates could also be used in other hypermedia authoring languages offering new types of compositions with predefined semantics.
C1 [Damasceno, Jean Ribeiro] Univ Fed Fluminense, MidiaCom Lab, Telecommun Engn Dept, Rio De Janeiro, Brazil.
   [Ferreira dos Santos, Joel Andre; Muchaluat-Saade, Debora Christina] Univ Fed Fluminense, Dept Comp Sci, MidiaCom Lab, Rio De Janeiro, Brazil.
C3 Universidade Federal Fluminense; Universidade Federal Fluminense
RP dos Santos, JAF (corresponding author), Univ Fed Fluminense, Dept Comp Sci, MidiaCom Lab, Rio De Janeiro, Brazil.
EM damascon@midiacom.uff.br; joel@midiacom.uff.br; debora@midiacom.uff.br
RI dos Santos, Joel A. F./O-6246-2016; Muchaluat-Saade, Débora
   Christina/E-7794-2014
OI dos Santos, Joel A. F./0000-0001-7234-613X; 
FU CNPq; FAPERJ; CAPES
FX This work was partially supported by CNPq, FAPERJ and CAPES. We would
   like to thank Glauco Amorim for helping with EDITEC usability tests.
CR ABNT NBR, 2007, DIG TERR TEL DAT C 2
   [Anonymous], 2008, Extensible Markup Language
   [Anonymous], P 2006 ACM S DOC ENG
   [Anonymous], 1998, ISO 9241-11
   Bouyakoub S, 2011, ACM T MULTIM COMPUT, V7, P30
   Bouyakoub S, 2008, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSIM.2008.54
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Consens MP, 2007, IEEE 23 INT C DAT EN
   Damasceno JR, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P77
   Deltour R, 2005, ERCIM NEWS, P41
   dos Santos JAF, 2012, P INT C SOFTW LANG E
   dos Santos JAF, 2012, MULTIMED TOOLS APPL, V61, P645, DOI 10.1007/s11042-011-0732-2
   Gaggi O, 2006, INT J SOFTW ENG KNOW, V4, P16
   Green TRG, 1996, J VISUAL LANG COMPUT, V7, P131, DOI 10.1006/jvlc.1996.0009
   Guimaraes RL, 2008, P 6 EITV
   Mattos DP, 2013, P 11 EUR INT TV C EU
   Muchaluat-Saade D. C., 2002, New Review of Hypermedia and Multimedia, V8, P139, DOI 10.1080/13614560208914739
   Rey-López M, 2008, MULTIMED TOOLS APPL, V40, P409, DOI 10.1007/s11042-008-0213-4
   W3C World Wide Web Consortium, 2008, SYNCHR MULT INT LANG
   W3C World-Wide Web Consortium, 1999, XML PATH LANGUAGE XP
   W3C World-Wide Web Consortium, 1999, XSL TRANSF XSLT VERS
NR 21
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1167
EP 1198
DI 10.1007/s11042-013-1734-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900026
DA 2024-07-18
ER

PT J
AU Demirkus, M
   Clark, JJ
   Arbel, T
AF Demirkus, Meltem
   Clark, James J.
   Arbel, Tal
TI Robust semi-automatic head pose labeling for real-world face video
   sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-automatic labeling; Real-world video sequence; Head pose; Automatic
   face tracking; Bag-of-words; Manifold
ID ANNOTATION; WEB
AB Automatic head pose estimation from real-world video sequences is of great interest to the computer vision community since pose provides prior knowledge for tasks, such as face detection and classification. However, developing pose estimation algorithms requires large, labeled real-world video databases on which computer vision systems can be trained and tested. Manual labeling of each frame is tedious, time consuming, and often difficult due to the high uncertainty in head pose angle estimate, particularly in unconstrained environments that include arbitrary facial expression, occlusion, illumination etc. To overcome these difficulties, a semi-automatic framework is proposed for labeling temporal head pose in real-world video sequences. The proposed multi-stage labeling framework first detects a subset of frames with distinct head poses over a video sequence, which is then manually labeled by the expert to obtain the ground truth for those frames. The proposed framework provides a continuous head pose label and corresponding confidence value over the pose angles. Next, the interpolation scheme over a video sequence estimates i) labels for the frames without manual labels and ii) corresponding confidence values for interpolated labels. This confidence value permits an automatic head pose estimation framework to determine the subset of frames to be used for further processing, depending on the labeling accuracy required. The experiments performed on an in-house, labeled, large, real-world face video database (which will be made publicly available) show that the proposed framework achieves 96.98 % labeling accuracy when manual labeling is only performed on 30 % of the video frames.
C1 [Demirkus, Meltem; Clark, James J.; Arbel, Tal] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 0E9, Canada.
C3 McGill University
RP Demirkus, M (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ H3A 0E9, Canada.
EM demirkus@cim.mcgill.ca; clark@cim.mcgill.ca; arbel@cim.mcgill.ca
OI Clark, James/0000-0002-4512-6171
CR Ambardekar A, 2009, P 2 INT C ADV COMP H, DOI [10.1109/ACHI.2009.17, DOI 10.1109/ACHI.2009.17]
   [Anonymous], 2005, UNCONSTRAINED FACE R
   [Anonymous], 2009, P BRIT MACH VIS C LO
   Ballerini L, 2003, LECT NOTES COMPUT SC, V2749, P275
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Blanz V, 2005, PROC CVPR IEEE, P454
   Blunsden S, 2010, ANN BMVA, P1
   Boom BJ, 2011, PATTERN RECOGN, V44, P1980, DOI 10.1016/j.patcog.2010.07.022
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Bruneau P, 2010, PATTERN RECOGN, V43, P485, DOI 10.1016/j.patcog.2009.03.024
   Chen YN, 2015, IEEE T PATTERN UNPUB, DOI [10.1109/TPAMI.2007.70798, DOI 10.1109/TPAMI.2007.70798]
   Delezoide B, 2011, P TREC VID RETR EV O
   Demirkus M, 2012, P IEEE COMP SOC WORK
   Demirkus M, 2011, IEEE IMAGE PROC, P573, DOI 10.1109/ICIP.2011.6116613
   Dhall Abhinav, 2012, IEEE Multimedia, V19, P01
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Furht B., 2003, Handbook of video databases: design and applications
   Gao Wen., 2004, The cas-peal large-scale chinese face database and evaluation protocols
   Giro-i-Nieto X., 2012, P 1 INT WORKSHOP VIS, P1, DOI DOI 10.1145/2304496.2304497
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hacid H., 2006, Advances in Multimedia Modeling. 13th International Multimedia Modeling Conference, MMM 2007. Proceedings (Lecture Notes in Computer Science Vol.4351), P586
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   He J, 2011, P 20 ACM INT C INF K, P1867, DOI [10.1145/2063576.2063845, DOI 10.1145/2063576.2063845]
   Hildebrand M, 2012, LECT NOTES COMPUT SC, V7131, P693
   Hildebrand M, 2009, INT J HUM-COMPUT ST, V67, P887, DOI 10.1016/j.ijhcs.2009.07.008
   Huang Gary B., 2007, 0749 U MASSCH 0749 U MASSCH
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Karaman S, 2012, LECT NOTES COMPUT SC, V7131, P29, DOI 10.1007/978-3-642-27355-1_6
   Kavasidis I, 2012, P 1 INT WORKSH VIS I, DOI [10.1145/2304496.2304502, DOI 10.1145/2304496.2304502]
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   LIN CY, 2003, P TRECVID WORKSH
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mezaris V, 2010, IEEE IMAGE PROC, P4697, DOI 10.1109/ICIP.2010.5653867
   Moehrmann J., 2012, Proceedings of the 1st International Workshop on Visual Interfaces for Ground Truth Collection in Computer Vision Applications. VIGTA '12, p2:1, DOI [DOI 10.1145/2304496.2304498, 10.1145/2304496.2304498]
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shneiderman B, 2000, IEEE INFOR VIS, P88, DOI 10.1109/IV.2000.859742
   Spampinato C, 2012, IEEE INT WORKS MACH
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Torki M, 2011, IEEE I CONF COMP VIS, P2603, DOI 10.1109/ICCV.2011.6126549
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Weston J., 2008, P 25 INT C MACH LEAR, P1168
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
NR 49
TC 17
Z9 17
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 495
EP 523
DI 10.1007/s11042-012-1352-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300023
DA 2024-07-18
ER

PT J
AU Doulamis, A
AF Doulamis, Anastasios
TI Event-driven video adaptation: A powerful tool for industrial video
   supervision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Objects' tracking; Computer vision tools; Adaptive scalable video
   adaptation
ID OBJECT TRACKING; SCALABILITY; SEGMENTATION
C1 Tech Univ Crete Decis Support Lab, Dept Prod & Management Engn, Khania 73100, Crete, Greece.
RP Doulamis, A (corresponding author), Tech Univ Crete Decis Support Lab, Dept Prod & Management Engn, Khania 73100, Crete, Greece.
EM doulamisanastasios@gmail.com
RI Doulamis, Anastasios/AAL-5972-2021
CR Abdel-Mottaleb M, 2004, IEEE T MULTIMEDIA, V6, P459, DOI 10.1109/TMM.2004.827500
   Akrivas G, IEEE 10 MED EL C MEL, P677
   Amonou I, 2000, P IEEE INT C ICIP SE, V1, P10
   Anagnostopoulos V., 2011, 2011 UkSim 13th International Conference on Computer Modelling and Simulation (UKSim 2011), P177, DOI 10.1109/UKSIM.2011.42
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Batra P, 2000, IEEE T IMAGE PROCESS, V9, P1677, DOI 10.1109/83.869179
   Bergman R, 2011, IEEE T IMAGE PROCESS, V20, P1668, DOI 10.1109/TIP.2010.2088970
   Castagno R, 1998, IEEE T CIRC SYST VID, V8, P562, DOI 10.1109/76.718503
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P685
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   De Keukelaere F, 2005, IEEE T MULTIMEDIA, V7, P427, DOI 10.1109/TMM.2005.846792
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Doulamis A., 2010, MULTIMED TOOLS APPL, P1380
   DOULAMIS A, 2000, J ARTIFICIAL INTELLI, V9, P277
   Doulamis A, FUTURE GENE IN PRESS
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Doulamis ND, 2010, MULTIMED TOOLS APPL, V50, P173, DOI 10.1007/s11042-009-0370-0
   Dugad R, 2003, IEEE T CIRC SYST VID, V13, P993, DOI 10.1109/TCSVT.2003.816519
   Emre M, 2011, IEEE T IMAGE PROCESS, V20, P1023, DOI 10.1109/TIP.2010.2081680
   Harada N, 2010, IEEE MULTIMEDIA, V17, P94, DOI 10.1109/MMUL.2010.73
   Haridasan R., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P289, DOI 10.1109/ISCAS.1998.698817
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   *ISO IEC JTC1 SC29, 1999, N3156 ISOIEC JTC1SC2
   Kao MP, 2008, IEEE T IMAGE PROCESS, V17, P908, DOI 10.1109/TIP.2008.921307
   Kim T, 2011, IET IMAGE PROCESS, V5, P87, DOI 10.1049/iet-ipr.2009.0276
   Kosmopoulos DI, COMPUTER VI IN PRESS
   Kreyszig E., 1991, Introductory functional analysis with applications, V17
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Li J, 2006, IEEE T MULTIMEDIA, V8, P431
   Luenberger DG, 1984, LINEAR NONLINEAR PRO
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Nater F, 2011, ICCV WORKSH VIS SURV
   Odobez JM, 2006, IEEE T IMAGE PROCESS, V15, P3514, DOI 10.1109/TIP.2006.877497
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Pereira F, 2005, IEEE T MULTIMEDIA, V7, P397, DOI 10.1109/TMM.2005.846773
   Perez-Pena Fernando, 2011, Proceedings of the International Conference on Signal Processing and Multimedia Applications. SIGMAP 2011, P131
   Sardis E., 2011, INT J MACHINE LEARNI, V1, P205
   Schoenemann T, 2011, IEEE T IMAGE PROCESS, V20, P2565, DOI 10.1109/TIP.2011.2118225
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   van der Schaar M, 2001, IEEE T CIRC SYST VID, V11, P318, DOI 10.1109/76.911158
   Voulodimos AS, APPL ARTIFI IN PRESS
   Voulodimos A, 2011, IEEE IMAGE PROC
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Yang Y, 2000, CONF REC ASILOMAR C, P1363, DOI 10.1109/ACSSC.2000.911214
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Young N, 2011, ELECTRON LETT, V47, P178, DOI 10.1049/el.2010.3294
   Zeng YH, 2001, IEEE T SIGNAL PROCES, V49, P2774, DOI 10.1109/78.960425
   Zhang GF, 2011, IEEE T PATTERN ANAL, V33, P603, DOI 10.1109/TPAMI.2010.115
   Zhang XQ, 2010, IEEE T CIRC SYST VID, V20, P1590, DOI 10.1109/TCSVT.2010.2087455
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
NR 52
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 339
EP 358
DI 10.1007/s11042-012-0992-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400006
DA 2024-07-18
ER

PT J
AU Hwang, G
   Park, S
   Kim, S
AF Hwang, Gyuhyun
   Park, Sanghun
   Kim, Seungchul
TI Components for bidirectional augmented broadcasting services on smart
   TVs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented broadcasting; Interactive broadcasting; Smart TVs; Multimedia
   content services; Real-time computer graphics; Photo-realistic rendering
ID INTERACTIVE CONTENTS PLAYER; VIDEO
AB We present the core components to support bidirectional augmented broadcasting services on smart TVs. These components are considered to be very significant for next-generation media services. The key modules used in our proposed system provide users with special functions, allowing them to insert graphic models into common broadcasting contents themselves. Efficiently encoding the tracking information of both the position and orientation of the cameras and the light sources used during an entire video production is the most critical task at the transmitting side. The information is stored in a predefined rendering profile format and is used to render inserted objects photo-realistically and combine them with the original broadcasting contents at the receiving side. We employ cutting-edge techniques developed in the field of computer graphics to display the composed contents seamlessly on smart TVs. This new broadcasting service paradigm will satisfy the needs of high-end users who expect to play the role of content producers.
C1 [Hwang, Gyuhyun; Park, Sanghun] Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.
   [Kim, Seungchul] ETRI, Smart Syst Res Team, Taejon 305700, South Korea.
C3 Dongguk University; Electronics & Telecommunications Research Institute
   - Korea (ETRI)
RP Park, S (corresponding author), Dongguk Univ, Dept Multimedia, Seoul 100715, South Korea.
EM spony@dongguk.edu; mshpark@dongguk.edu; skimc@etri.re.kr
RI Kim, Seung-Chul/D-9216-2018
OI Kim, Seungchul/0000-0002-6765-2471
FU ETRI R&D program of KCC (Korea Communications Commission), Korea
   [11921-03001]
FX This work was supported by the ETRI R&D program of KCC (Korea
   Communications Commission), Korea [11921-03001, "Development of Beyond
   Smart TV Technology"]. And the authors would like to thank Seoul
   Broadcasting System (SBS) & SBS Contents Hub for the rights to the
   broadcasting video clips used in these experiments.
CR Aittala M, 2010, VISUAL COMPUT, V26, P669, DOI 10.1007/s00371-010-0501-7
   [Anonymous], 2012, BBC
   Apodaca A, 1999, ADV RENDERMAN, P57
   Beraldin J.A., 2000, MODELLI METODI STUDI, P22
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Cavallaro R, 2011, IEEE MULTIMEDIA, V18, P38, DOI 10.1109/MMUL.2011.61
   Cheong WS, 2008, IEEE T CONSUM ELECTR, V54, P93, DOI 10.1109/TCE.2008.4470029
   Cho K.S., 2011, ELECT TELECOMMUNICAT, V26, P1
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Denia A., 2011, Proceedings of the 2011 International Conference on Computational Science and Its Applications (ICCSA), P10, DOI 10.1109/ICCSA.2011.36
   Hartley R, 2000, N VIEW GEOMETRY MULT, P409
   Hengel A, 2007, P ACM SIGGRAPH 2007
   Jeong JW, 2011, IEEE T CONSUM ELECTR, V57, P1830, DOI 10.1109/TCE.2011.6131160
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kim K, 2011, ELECT TELECOMMUNICAT, V26, P37
   Kim M, 2010, ELECT TELECOMMUN TRE, V25, P147
   Lee I, 2009, IEEE T CONSUM ELECTR, V55, P112, DOI 10.1109/TCE.2009.4814422
   Lee S, 2012, GREEN CHEM CHEM ENG, P17
   Madsen CB, 2008, GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P255
   MoonKoo Kim, 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P1475
   Morvan Y, 2008, IEEE T CONSUM ELECTR, V54, P925, DOI 10.1109/TCE.2008.4560180
   Oh J, 2010, P 9 ACM SIGGRAPH C V, P373
   황규현, 2012, [Journal of the Korea Computer Graphics Society, 한국컴퓨터그래픽스학회논문지], V18, P1
   Park SI, 2012, IEEE T BROADCAST, V58, P261, DOI 10.1109/TBC.2011.2182429
   Pollefeys M., 2001, PROC C OPTICAL 3D ME, P251
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   RT Software, TOG SPORTS
   Saito H., 2011, 2011 International Symposium on Ubiquitous Virtual Reality, P5, DOI 10.1109/ISUVR.2011.25
   Seo D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P201, DOI 10.1109/ICCE.2012.6161828
   Shesh A, 2009, P GRAPH INT 2009, P46
   Si Jung Jun Kim, 2012, 2012 International Symposium on Ubiquitous Virtual Reality (ISUVR), P1, DOI 10.1109/ISUVR.2012.17
   Yoon H, 2008, IEEE T CONSUM ELECTR, V54, P1722, DOI 10.1109/TCE.2008.4711226
   Zhang YF, 2001, IEEE T PATTERN ANAL, V23, P915, DOI 10.1109/34.946995
NR 34
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 687
EP 708
DI 10.1007/s11042-012-1307-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900009
DA 2024-07-18
ER

PT J
AU Bhattacharyya, D
   Pal, AJ
   Kim, TH
AF Bhattacharyya, Debnath
   Pal, Anindya J.
   Kim, Tai-hoon
TI Cell-graph coloring for cancerous tissue modelling and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cell graph; Genetic algorithm; Pattern Recognition; Cancer detection
ID BREAST CYTOLOGY; DIAGNOSIS; INTERNET; IDENTIFICATION; CARCINOMA;
   NETWORKS; TEXTURE; WEB
AB In traditional cancer diagnosis process, pathologists manually examine biopsies to make diagnostic assessments. The assessments are largely based on visual interpretation of cell morphology and tissue distribution, lacking of quantitative measures. Therefore, they are subject to considerable inter-observer variability. To circumvent this problem, numerous studies aim at quantifying the characteristics of cancerous cells and tissues that distinguish them from their counterparts. Such quantification facilitates to design automated systems that operate on quantitative measures, and in turn, to reduce the inter-observer variability. There is a computational model available that relies solely on the topological features of cancerous cells in a tumor. Despite their complex dynamic nature, the self-organizing clusters of cancerous cells exhibit distinctive graph properties that distinguish the cancerous tissue from non-cancerous tissues; e.g. from a healthy tissue or an inflamed tissue. It is difficult to distinguish a cancerous tissue sample visually from an inflamed one. It is possible to construct a graph of the cells (cell graph) based on the location of the cells in the low-magnification image of a tissue sample surgically removed from a human patient. Assuming the cells present in a sample as the vertices of the cell graphs and the edges connecting those vertices/cells we can construct the cell graphs. There is a possibility of implementing the technique of using cell graphs to detect cancerous sample biopsies using some simple or a little bit complex computational techniques. Here possibly a new way is going to be introduced in this field, which is an application of graph coloring using the cell graphs to classify the normal, cancerous and inflamed sample biopsies. This work intends to automate the solution to the problem of identifying cancerous sample biopsies applying customized graph Coloring method solving by Genetic Algorithm on the cell graphs.
C1 [Bhattacharyya, Debnath; Kim, Tai-hoon] Hannam Univ, Dept Multimedia, Taejon, South Korea.
   [Pal, Anindya J.] Heritage Inst Technol, Kolkata, India.
C3 Hannam University; Heritage Institute of Technology (HITK)
RP Kim, TH (corresponding author), Hannam Univ, Dept Multimedia, Taejon, South Korea.
EM debnathb@gmail.com; anindyajp@yahoo.com; taihoonn@empal.com
RI Bhattacharyya, Debnath/A-3144-2016
OI Bhattacharyya, Debnath/0000-0003-0140-9644
CR Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   Baase S., 1999, COMPUTER ALGORITHMS
   Barabasi A.L., 2002, The Formula: The Universal Laws Of Success
   Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943
   Choi HK, 1997, ANAL CELL PATHOL, V15, P1
   Davis L., 1991, Handbook of Genetic Algorithms
   Einstein AJ, 1998, J PATHOL, V185, P366
   Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Esgiar AN, 2002, IEEE T INF TECHNOL B, V6, P54, DOI 10.1109/4233.992163
   Esgiar AN, 1998, ANAL QUANT CYTOL, V20, P297
   Faloutsos M, 1999, COMP COMM R, V29, P251, DOI 10.1145/316194.316229
   Feldman R., 1990, COMPUTER J, V33
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Glotsos D., 2003, Proceedings of the International Conference of Computational Methods in Sciences and Engineering 2003 (ICCMSE 2003), P192
   Goldberg D. E., 1990, Complex Systems, V4, P445
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Goldberg M., 2003, 1 C N AM ASS COMP SO
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Gunduz C, 2003, TR0309 RENSS POL I D
   Gunduz C, 2004, BIOINFORMATICS, V20, P145, DOI 10.1093/bioinformatics/bth933
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HAMILTON PW, 1987, HISTOPATHOLOGY, V11, P901, DOI 10.1111/j.1365-2559.1987.tb01897.x
   Hamilton PW, 1997, J PATHOL, V182, P68
   Jain R., 2004, Australiasian Physical and Eng. Sciences in Medicine
   Jeong H, 2000, NATURE, V407, P651, DOI 10.1038/35036627
   Keenan SJ, 2000, J PATHOL, V192, P351, DOI 10.1002/1096-9896(2000)9999:9999<::AID-PATH708>3.0.CO;2-I
   Kumar R., 2000, P 9 INT WORLD WID WE, P247
   Liljeros F, 2001, NATURE, V411, P907, DOI 10.1038/35082140
   MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   MOSCATO P, 1992, TRANSPUT OCCAM ENG S, V28, P177
   MOSCATO P, 1989, 826 CALTECH CALT CON
   NEWMAN M, 2001, PHYS REV, pE64
   Pal AJ, 2008, ICFAI U J COMPUTER S, VII, P47
   Pal AJ, 2007, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P364, DOI 10.1109/COGINF.2007.4341911
   Pal AJ, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P640, DOI 10.1109/COGINF.2006.365560
   Peña-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6
   Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986
   SARMA SS, 1985, INT J ELECTRON, V77, P81
   Schnorrenberg F, 1996, Technol Health Care, V4, P147
   Sen Sarma S, 2003, C HOR TEL
   Shavitt Y, 2004, IEEE J SEL AREA COMM, V22, P67, DOI 10.1109/JSAC.2003.818796
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Tasoulis DK, 2003, LECT NOTES ARTIF INT, V2773, P199
   Todman AG, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1379, DOI 10.1109/CCECE.2001.933655
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Weyn B, 1999, CYTOMETRY, V35, P23, DOI 10.1002/(SICI)1097-0320(19990101)35:1<23::AID-CYTO4>3.0.CO;2-P
   WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5
   Wu B, 2003, BIOINFORMATICS, V19
   Wuchty S., 2003, COMPLEX SYSTEMS BIOM
   Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X
NR 53
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 229
EP 245
DI 10.1007/s11042-011-0797-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000006
DA 2024-07-18
ER

PT J
AU Ciobanu, L
   Côrte-Real, L
AF Ciobanu, Lucian
   Corte-Real, Luis
TI Multi-view codec with low-complexity encoding for Distributed Video
   Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed Video Coding (DVC); Distributed Source Coding (DSC);
   Wyner-Ziv (WZ); SSIM (Structural SIMilarity); Intra 4x4; Intra 16x16;
   Discrete Cosine Transform (DCT); CAVLC (Context-Adaptive Variable-Length
   Coding); Huffman Coding; Coset Coding
ID SIDE INFORMATION; BINARY
AB The low-complexity encoding, as fundamental requirement of Distributed Video Coding, relies on performing the bulk of computation at decoder, including tasks as the generation of side information and particularly, inter-camera registration in the case of multi-view systems with complete-overlapped views and free motion of the cameras (e.g., video surveillance). In Ciobanu and Corte-Real (Multimedia Tools Appl 48(3):411-436, 2010) we introduced a codec-independent solution for such tasks at decoder. In this paper, we present a multi-view Wyner-Ziv codec (IWZ) designed for the architecture and scenarios from Ciobanu and Corte-Real (2010) (e.g., free motion of the cameras, no a priori knowledge of the instant camera positions, no feedback channel), based on transform domain (DCT), block-based coset coding. We aimed to achieve a compromise between the low encoder complexity and the rate-distortion performance. A detailed evaluation is presented for comparison with conventional coding (Intra 4x4 and Intra 16x16). Practical results show a better overall performance of the proposed codec at low bitrates.
C1 [Ciobanu, Lucian; Corte-Real, Luis] Univ Porto, Fac Engn, INESC Porto, P-4100 Oporto, Portugal.
C3 Universidade do Porto; INESC TEC
RP Ciobanu, L (corresponding author), Univ Porto, Fac Engn, INESC Porto, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM lciobanu@inescporto.pt; lreal@inescporto.pt
RI Corte-Real, Luís/I-4852-2012
OI Ciobanu, Lucian/0000-0003-1102-8589; Corte-Real,
   Luis/0000-0003-2116-7056
FU Fundacao para a Ciencia e a Tecnologia, Portugal
FX The first author acknowledges the Fundacao para a Ciencia e a
   Tecnologia, Portugal, for the financial support.
CR Aaron A, 2004, P SPIE C VIS COMM IM
   Aaron A, 2002, 36 AS C SIGN SYST CO
   [Anonymous], 2009, RECOMMENDATION ITU T
   [Anonymous], 2009, H 264 AVC JM REFEREN
   Artigas X, 2007, PICT COD S PCS 2007
   Artigas X, 2006, IEEE INT C AC SPEECH
   Belkoura Z, 2006, P INT PICT COD S BEI
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Ciobanu L, 2010, MULTIMED TOOLS APPL, V48, P411, DOI 10.1007/s11042-009-0315-7
   Dalai M, 2006, IEEE INT C AC SPEECH
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guo X, 2006, P SPIE IS T EL IM SP, V6077
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   Lajnef K, 2006, SIGNAL PROCESS, V86, P3131, DOI 10.1016/j.sigpro.2006.03.013
   Lan C, 2004, P IEEE DAT COMPR C D
   Li YP, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P45
   Lv H, 2008, IEEE INT SYMP CIRC S, P3450, DOI 10.1109/ISCAS.2008.4542201
   Pedro J, 2007, PICT COD S PCS 2007
   Puri R, 2003, P INT C IM PROC ICIP
   Puri R., 2002, P ALL C COMM CONTR C
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tonoli C, 2007, PICT CODING SYMPOSIU
   Varodayan D, 2005, P AS C SIGN SYST COM
   Vatis Y, 2007, INT C IM PROC ICIP 2
   Westerlaken R, 2006, INT C IM PROC ICIP 2
   Westerlaken RP, 2007, INT C IM PROC ICIP 2
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yang Y, 2003, P AS C SIGN SYST COM
   Zhao Y, 2006, SIGNAL PROCESS, V86, P3115, DOI 10.1016/j.sigpro.2006.03.011
NR 29
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 731
EP 755
DI 10.1007/s11042-011-0970-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600011
DA 2024-07-18
ER

PT J
AU Costa, DG
   Guedes, LA
AF Costa, Daniel G.
   Guedes, Luiz Affonso
TI Exploiting the sensing relevancies of source nodes for optimizations in
   visual sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sensor networks; Sensing relevance; Network optimization;
   Energy-efficiency; Packet prioritization
ID WIRELESS; TRANSMISSION; COVERAGE
AB Wireless ad-hoc networks composed of resource-constrained camera-enabled sensors can provide visual information for a series of monitoring applications, enriching the understanding of the physical world. In many cases, source nodes may have different sensing relevancies for the monitoring functions of the applications, according to the importance of the visual information retrieved from the monitored field. As a direct result, high quality is only required for the most relevant information and, as it is expected that many visual monitoring applications can tolerate some quality loss in the data received from the least relevant source nodes, the network operation can be optimized exploiting this innovative concept. As a novel global QoS parameter, we envisage that the sensing relevancies of source nodes can be considered for a series of optimizations in different aspects of the wireless sensor network operation, achieving energy saving or assuring high quality transmission for the most relevant data. In this paper we discuss some approaches for the establishment of the sensing relevancies of the nodes and propose a protocol to support them. Moreover, we present two practical examples of optimizations based on the sensing relevancies of source nodes that transmit still images of the monitored field, addressing issues as energy-efficient data transmission and packet prioritization in intermediate nodes.
C1 [Costa, Daniel G.; Guedes, Luiz Affonso] Univ Fed Rio Grande do Norte, Dept Comp & Automat, BR-59072970 Natal, RN, Brazil.
   [Costa, Daniel G.] State Univ Feira de Santana, Dept Technol, BR-44036900 Feira De Santana, BA, Brazil.
C3 Universidade Federal do Rio Grande do Norte; Universidade Estadual de
   Feira de Santana
RP Costa, DG (corresponding author), Univ Fed Rio Grande do Norte, Dept Comp & Automat, Campus Univ, BR-59072970 Natal, RN, Brazil.
EM danielgcosta@uefs.br; affonso@dca.ufrn.br
RI Vasques, Francisco/ABD-7443-2021; Costa, Daniel G./I-4928-2013; Guedes,
   Luiz Affonso/G-7793-2012
OI Vasques, Francisco/0000-0003-3115-0901; Costa, Daniel
   G./0000-0003-3988-8476; Guedes, Luiz Affonso/0000-0003-2690-1563
CR Ai J, 2006, J COMB OPTIM, V11, P21, DOI 10.1007/s10878-006-5975-x
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   [Anonymous], P 4 IFIP INT C NEW T
   [Anonymous], P 2 INT C EMB NETW S
   Bai Yong., 2009, I SYMP CONSUM ELECTR, P1, DOI [DOI 10.1109/APPEEC.2009.4918349, 10.1109/APPEEC.2009.4918349.]
   Baronti P, 2007, COMPUT COMMUN, V30, P1655, DOI 10.1016/j.comcom.2006.12.020
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Chen BJ, 2002, WIREL NETW, V8, P481, DOI 10.1023/A:1016542229220
   Chi Feng W., 2005, ACM Transactions on Multimedia Computing, Communications and Applications, V1, P151, DOI DOI 10.1145/1062253.1062256
   Chow KY, 2007, IEEE WCNC, P4115
   Costa DG, 2011, SENSORS-BASEL, V11, P5439, DOI 10.3390/s110505439
   Costa DG, 2010, SENSORS-BASEL, V10, P8215, DOI 10.3390/s100908215
   Devarajan D, 2004, WORKSH BROADB ADV SE, P1
   Fuiorea D, 2007, SACI 2007: 4TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS, PROCEEDINGS, P209, DOI 10.1109/SACI.2007.375512
   Funiak S, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P34
   Han B., 2007, Testbeds and Research Infrastructure for the Development of Networks and 126 Communities, P1
   Korhonen J, 2005, IEEE WCNC, P1608
   Kulkarni P., 2005, 13th Annual ACM International Conference on Multimedia, P229, DOI 10.1145/1101149.1101191
   Lecuire Vincent, 2008, International Journal of Sensor Networks, V4, P37, DOI 10.1504/IJSNET.2008.019250
   Lecuire V, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/47345
   Lee H., 2006, C COGN SYST INT SENS, P1
   Lee JH, 2010, SENSORS-BASEL, V10, P2919, DOI 10.3390/s100402919
   Liang Y, 2010, ACM SIGCOMM COMP COM, V40, P13
   Mantzel E, 2005, WORKSH OM VIS CAM NE, P1
   Marengoni M., 1996, IMAGE VISION COMPUT, V75, P773
   Osais YE, 2010, MOBILE NETW APPL, V15, P216, DOI 10.1007/s11036-009-0179-0
   Pescaru D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS (AQTR 2008), THETA 16TH EDITION, VOL I, PROCEEDINGS, P289, DOI 10.1109/AQTR.2008.4588754
   Politis I, 2008, MOBILE NETW APPL, V13, P274, DOI 10.1007/s11036-008-0061-5
   Sayed AH, 2005, IEEE SIGNAL PROC MAG, V22, P24, DOI 10.1109/MSP.2005.1458275
   Shafique K., 2008, 2008 IEEE WORKSH APP, P1
   Shon T, 2008, LECT NOTES COMPUT SC, V5061, P363, DOI 10.1007/978-3-540-69293-5_29
   Soro S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P81, DOI 10.1109/AVSS.2007.4425290
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Soro S, 2005, 2ND INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS (BROADNETS 2005), P9, DOI 10.1109/ICBN.2005.1589704
   Wu HM, 2006, COMPUT NETW, V50, P2873, DOI 10.1016/j.comnet.2005.09.039
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
   Yu C, 2006, SPIE VISUAL COMMUNIC, P1
   Zhang L, 2008, LECT NOTES COMPUT SC, V5061, P439, DOI 10.1007/978-3-540-69293-5_35
   Zhao J, 2008, IEEE J-STSP, V2, P464, DOI 10.1109/JSTSP.2008.2001430
NR 41
TC 24
Z9 26
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 549
EP 579
DI 10.1007/s11042-011-0961-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600003
DA 2024-07-18
ER

PT J
AU Gao, GY
AF Gao, Guangyong
TI Composite chaos-based lossless image authentication and tamper
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Composite chaos; Lossless image authentication; Tamper localization
ID LYAPUNOV EXPONENTS; FEEDBACK-CONTROL; WATERMARKING
AB To improve the robustness to combined attack of signal processing plus tamper, a composite chaos-based lossless scheme for image authentication and tamper localization is proposed. A non-successive composite chaos (NSCC) is described, and its performance is analysed by some evaluation indicators. Then NSCC is employed to disturb original image and generate chaotic logo, which enhances the security and robustness of lossless image authentication scheme due to the good performance of NSCC in these aspects of randomness, complexity and ability of anti-forecast technology. Experimental results demonstrate that the proposed scheme is not only safe, but also realizes the correct extraction of logo and precise detection of tampered region position and shape under various attacks, especially signal processing plus tamper attack.
C1 [Gao, Guangyong] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
   [Gao, Guangyong] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.
C3 Jiujiang University; Nanjing University of Posts & Telecommunications
RP Gao, GY (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
EM gaoguangyong@163.com
FU Natural Science Foundation of Educational Commission of Jiangxi Province
   of China [GJJ12614]
FX This research is supported by the Natural Science Foundation of
   Educational Commission of Jiangxi Province of China under Grant
   GJJ12614.
CR Chen GR, 1996, INT J BIFURCAT CHAOS, V6, P1341, DOI 10.1142/S021812749600076X
   Chen GR, 1997, IEEE T CIRCUITS-I, V44, P250
   Chen SY, 2008, IEEE T CIRC SYST VID, V18, P704, DOI 10.1109/TCSVT.2008.918801
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Huang XY, 2011, IEEE T INF FOREN SEC, V6, P498, DOI 10.1109/TIFS.2011.2109952
   Mao L, 2011, MULTIMED TOOLS APPL, V52, P201, DOI 10.1007/s11042-010-0467-5
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Poljicak A, 2011, TEH VJESN, V18, P161
   Radu OP, 2011, J ELECTRON IMAGING, V20
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Rukhin A., STAT TEST SUITE RAND
   Sun FY, 2011, CHINESE PHYS B, V20, DOI 10.1088/1674-1056/20/4/040506
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   WALTON S, 1995, DR DOBBS J, V20, P18
   Yuen CH, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/1/010502
   Zhang JS, 2000, ACTA PHYS SIN-CH ED, V49, P403, DOI 10.7498/aps.49.403
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang S, 2005, ACTA PHYS SIN-CH ED, V54, P5062, DOI 10.7498/aps.54.5062
   佟晓筠, 2009, [中国科学. F辑, 信息科学, Science in China. Series F, Information Sciences], V39, P588
NR 19
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 947
EP 964
DI 10.1007/s11042-012-1329-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000016
DA 2024-07-18
ER

PT J
AU Zhang, XM
   Li, ZJ
   Chao, WH
AF Zhang, Xiaoming
   Li, Zhoujun
   Chao, Wenhan
TI Improving image tags by exploiting web search results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image tagging; Search based tagging; Tag expansion; Image retrieval
ID ANNOTATING IMAGES; RETRIEVAL
AB Automatic image tagging automatically assigns image with semantic keywords called tags, which significantly facilitates image search and organization. Most of present image tagging approaches are constrained by the training model learned from the training dataset, and moreover they have no exploitation on other type of web resource (e.g., web text documents). In this paper, we proposed a search based image tagging algorithm (CTSTag), in which the result tags are derived from web search result. Specifically, it assigns the query image with a more comprehensive tag set derived from both web images and web text documents. First, a content-based image search technology is used to retrieve a set of visually similar images which are ranked by the semantic consistency values. Then, a set of relevant tags are derived from these top ranked images as the initial tag set. Second, a text-based search is used to retrieve other relevant web resources by using the initial tag set as the query. After the denoising process, the initial tag set is expanded with other tags mined from the text-based search result. Then, an probability flow measure method is proposed to estimate the probabilities of the expanded tags. Finally, all the tags are refined using the Random Walk with Restart (RWR) method and the top ones are assigned to the query images. Experiments on NUS-WIDE dataset show not only the performance of the proposed algorithm but also the advantage of image retrieval and organization based on the result tags.
C1 [Zhang, Xiaoming; Li, Zhoujun; Chao, Wenhan] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Zhang, Xiaoming; Li, Zhoujun; Chao, Wenhan] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Zhang, Xiaoming; Li, Zhoujun; Chao, Wenhan] Beihang Univ, Beijing Key Lab Network Technol, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Zhang, XM (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
EM yolixs@163.com
OI Li, Zhoujun/0000-0002-9603-9713
FU National Natural Science Foundations of China [60973105, 61003111];
   State Key Laboratory of Software Development Environment
   [SKLSDE-2011ZX-03]
FX This work was supported by the National Natural Science Foundations of
   China (60973105 and 61003111), and the fund of the State Key Laboratory
   of Software Development Environment (SKLSDE-2011ZX-03). The authors
   would like to thank the Editors and the anonymous reviewers 739 for
   their valuable comments and remarks on the previous versions of this
   paper.
CR [Anonymous], P ACM MULT
   [Anonymous], 2006, Book Annosearch: Image auto-annotation by search, DOI DOI 10.1109/CVPR.2006.58
   [Anonymous], 2009, ICIVR
   [Anonymous], 2010, Proceedings of the Eighteenth ACM International Conference on Multimedia, DOI DOI 10.1145/1873951.1873959
   [Anonymous], KLUWER INT SERIES IN
   Bailloeul T., 2008, Proc. Multimedia Information Retrieval, P75, DOI DOI 10.1145/1460096.1460110
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bruza P. D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P260, DOI 10.1145/584792.584837
   Cao Guihong, 2008, P SIGIR 2008, P243, DOI DOI 10.1145/1390334.1390377
   Cao Liangliang, 2010, P 19 INT C WORLD WID
   CHANG SF, 2008, P TRECVID 2008
   Geng B., 2008, P 1 ACM INT C MULT I, P443
   Han J., 2012, Data Mining, P393, DOI [DOI 10.1016/B978-0-12-381479-1.00009-5, 10.1016/B978-0-12-381479-1.00009-5]
   Heesch D., 2006, P 14 ACM INT C MULT, P493
   Hong R., 2010, ACM INT C MULT ACM M
   Jing F., 2006, PROC MM 06, P377, DOI DOI 10.1145/1180639.1180720
   Jones K. S., 2000, Information Processing & Management, V36, P809, DOI 10.1016/S0306-4573(00)00016-9
   Lei W., 2009, P 18 ACM INT C WORLD, P20
   Lei W., 2009, P 17 ACM INT C MULT, P15
   Li J., 2006, P 14 ANN ACM INT C M, P911, DOI DOI 10.1145/1180639.1180841
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li XR, 2009, INT CONF ACOUST SPEE, P3717, DOI 10.1109/ICASSP.2009.4960434
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu Y., 2008, IEEE PES GEN M, P1
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Page L., 1998, P 7 INT WORLD WID WE, P161
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Setz AT, 2009, IEEE INT CON MULTI, P1460, DOI 10.1109/ICME.2009.5202778
   Shengli Yuan, 2010, Proceedings 2010 IEEE Global Communications Conference (GLOBECOM 2010), DOI 10.1109/GLOCOM.2010.5683786
   Siersdorfer S., 2009, P 32 ACM INT C RES D, P16
   Tong HH, 2006, IEEE DATA MINING, P613
   Tsikrika T, 2011, MULTIMED TOOLS APPL, V55, P27, DOI 10.1007/s11042-010-0584-1
   TURTLE HR, 1992, COMPUT J, V35, P279, DOI 10.1093/comjnl/35.3.279
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang CH, 2008, MULTIMEDIA SYST, V14, P205, DOI 10.1007/s00530-008-0128-y
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Yang KY, 2009, IEEE INT CON MULTI, P1620, DOI 10.1109/ICME.2009.5202829
   Zhou X., 2007, PROC 6 ACM INT C IMA, P25
NR 42
TC 7
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 601
EP 631
DI 10.1007/s11042-011-0863-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500004
DA 2024-07-18
ER

PT J
AU Montoliu, R
   Blom, J
   Gatica-Perez, D
AF Montoliu, Raul
   Blom, Jan
   Gatica-Perez, Daniel
TI Discovering places of interest in everyday life from smartphone data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile Phones; Multimodal data; Place discovering; Real-Life long-term
   experiments
AB In this paper, a new framework to discover places-of-interest from multimodal mobile phone data is presented. Mobile phones have been used as sensors to obtain location information from users' real lives. A place-of-interest is defined as a location where the user usually goes and stays for a while. Two levels of clustering are used to obtain places of interest. First, user location points are grouped using a time-based clustering technique which discovers stay points while dealing with missing location data. The second level performs clustering on the stay points to obtain stay regions. Agrid-based clustering algorithm has been used for this purpose. To obtain more user location points, a client-server system has been installed on the mobile phones, which is able to obtain location information by integrating GPS, Wifi, GSM and accelerometer sensors, among others. An extensive set of experiments has been performed to show the benefits of using the proposed framework, using data from the real life of a significant number of users over almost a year of natural phone usage.
C1 [Montoliu, Raul] Jaume I Univ, Inst New Imaging Technol iNIT, Castellon de La Plana, Spain.
   [Montoliu, Raul] Jaume I Univ, Dept Comp Sci & Engn, Castellon de La Plana, Spain.
   [Blom, Jan] Nokia Res Ctr, Lausanne, Switzerland.
   [Gatica-Perez, Daniel] Idiap Res Inst, Social Comp Grp, Martigny, Switzerland.
   [Gatica-Perez, Daniel] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Universitat Jaume I; Universitat Jaume I; Nokia Corporation; Swiss
   Federal Institutes of Technology Domain; Ecole Polytechnique Federale de
   Lausanne
RP Montoliu, R (corresponding author), Jaume I Univ, Inst New Imaging Technol iNIT, Castellon de La Plana, Spain.
EM montoliu@uji.es; jan.blom@nokia.com; gatica@idiap.ch
OI Montoliu Colas, Raul/0000-0002-8467-391X
FU Nokia Research Center Lausanne (NRC) through the LS-CONTEXT project;
   Spanish Ministerio de Ciencia e Innovacion under project Consolider
   Ingenio 2010 [CSD2007-00018]
FX This work was supported by Nokia Research Center Lausanne (NRC) through
   the LS-CONTEXT project. R. Montoliu was also supported by the Spanish
   Ministerio de Ciencia e Innovacion under project Consolider Ingenio 2010
   CSD2007-00018. Part of this work was done while R. Montoliu visited
   Idiap. We thank Niko Kiukkonen (NRC) and Olivier Bornet (Idiap) for
   their contribution to data collection, Trinh-Minh-Tri Do (Idiap) for
   help with data processing, and all the volunteers in the experiments for
   their participation.
CR [Anonymous], 2010, P ACM INT C PERV SER
   [Anonymous], 2008, P 16 ACM INT C MULT
   Apple-Inc, 2011, REM BETT WAY DO TO D
   Ashbrook D, 2003, PERS UBIQUIT COMPUT, V7, P275, DOI 10.1007/s00779-003-0240-0
   Bamis A., 2011, 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops 2011). PerCom-Workshops 2011: 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops 2011), P32, DOI 10.1109/PERCOMW.2011.5766898
   Brasche S, 2005, INT J HYG ENVIR HEAL, V208, P247, DOI 10.1016/j.ijheh.2005.03.003
   Choujaa D, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P105
   Eagle N, 2009, BEHAV ECOL SOCIOBIOL, V63, P1057, DOI 10.1007/s00265-009-0739-0
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   FARRAHI K., 2008, P IEEE INT S WEAR CO
   Gatica-Perez D, 2010, P ACM MULT 2010 INT, P1783
   González MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958
   Hightower J, 2005, LECT NOTES COMPUT SC, V3660, P159
   Jensen Bjorn Sand, 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), P196, DOI 10.1109/MLSP.2010.5588997
   Kang J.H., 2005, ACM SIGMOBILE Mobile Computing and Communications Review, V9, P58, DOI DOI 10.1145/1094549.1094558
   Kim DH, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P21
   LaMarca A, 2005, LECT NOTES COMPUT SC, V3468, P116
   Marmasse N, 2000, LECT NOTES COMPUT SC, V1927, P157
   Montoliu R, 2010, P 9 INT C MOB UB MUL
   Raento M, 2009, SOCIOL METHOD RES, V37, P426, DOI 10.1177/0049124108330005
   Reddy S, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P25, DOI 10.1109/ISWC.2008.4911579
   Schapsis Claudio., 2011, LOCATION BASED SOCIA
   Wang Y, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P179, DOI 10.1016/B978-044306732-7.50020-9
   Wikipedia, 2011, LIST COUNTR NUMB MOB
   Ye Y, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P1, DOI 10.1109/MDM.2009.11
   Zheng V.W., 2010, P 19 INT WORLD WID W
   Zheng Y., 2008, P 17 INT C WORLD WID, P247, DOI DOI 10.1145/1367497.1367532
   Zheng Y, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P312, DOI 10.1145/1409635.1409677
NR 28
TC 86
Z9 102
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 179
EP 207
DI 10.1007/s11042-011-0982-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800009
DA 2024-07-18
ER

PT J
AU Tejedor, J
   Echeverría, A
   Wang, D
   Vipperla, R
AF Tejedor, Javier
   Echeverria, Alejandro
   Wang, Dong
   Vipperla, Ravichander
TI Evolutionary discriminative confidence estimation for spoken term
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spoken term detection; Confidence measurement; Evolutionary discriminant
   analysis
ID NEURAL-NETWORKS; CLASSIFICATION; COMPUTATION; SYSTEM
AB Spoken term detection (STD) is the task of searching for occurrences of spoken terms in audio archives. It relies on robust confidence estimation to make a hit/false alarm (FA) decision. In order to optimize the decision in terms of the STD evaluation metric, the confidence has to be discriminative. Multi-layer perceptrons (MLPs) and support vector machines (SVMs) exhibit good performance in producing discriminative confidence; however they are severely limited by the continuous objective functions, and are therefore less capable of dealing with complex decision tasks. This leads to a substantial performance reduction when measuring detection of out-of-vocabulary (OOV) terms, where the high diversity in term properties usually leads to a complicated decision boundary. In this paper we present a new discriminative confidence estimation approach based on evolutionary discriminant analysis (EDA). Unlike MLPs and SVMs, EDA uses the classification error as its objective function, resulting in a model optimized towards the evaluation metric. In addition, EDA combines heterogeneous projection functions and classification strategies in decision making, leading to a highly flexible classifier that is capable of dealing with complex decision tasks. Finally, the evolutionary strategy of EDA reduces the risk of local minima. We tested the EDA-based confidence with a state-of-the-art phoneme-based STD system on an English meeting domain corpus, which employs a phoneme speech recognition system to produce lattices within which the phoneme sequences corresponding to the enquiry terms are searched. The test corpora comprise 11 h of speech data recorded with individual head-mounted microphones from 30 meetings carried out at several institutes including ICSI; NIST; ISL; LDC; the Virginia Polytechnic Institute and State University; and the University of Edinburgh. The experimental results demonstrate that EDA considerably outperforms MLPs and SVMs on both classification and confidence measurement in STD, and the advantage is found to be more significant on OOV terms than on in-vocabulary (INV) terms. In terms of classification performance, EDA achieved an equal error rate (EER) of 11% on OOV terms, compared to 34% and 31% with MLPs and SVMs respectively; for INV terms, an EER of 15% was obtained with EDA compared to 17% obtained with MLPs and SVMs. In terms of STD performance for OOV terms, EDA presented a significant relative improvement of 1.4% and 2.5% in terms of average term-weighted value (ATWV) over MLPs and SVMs respectively.
C1 [Tejedor, Javier] Univ Autonoma Madrid, Human Comp Technol Lab, Madrid, Spain.
   [Echeverria, Alejandro] Univ Autonoma Madrid, Machine Learning Grp, Spanish Natl Biotechnol Ctr, Madrid, Spain.
   [Wang, Dong; Vipperla, Ravichander] EURECOM, Multimedia Commun Dept, Sophia Antipolis, France.
C3 Autonomous University of Madrid; Autonomous University of Madrid; IMT -
   Institut Mines-Telecom; EURECOM
RP Tejedor, J (corresponding author), Univ Autonoma Madrid, Human Comp Technol Lab, Madrid, Spain.
EM javier.tejedor@uam.es; alejandro.e.rey@gmail.com; dong.wang@ed.ac.uk;
   ravichander.vipperla@eurecom.fr
RI Tejedor, Javier/B-5203-2012; Tejedor, Javier/L-2075-2015
OI Tejedor, Javier/0000-0002-8441-0036; Tejedor, Javier/0000-0001-7699-5620
FU French Ministry of Industry [09.2.93.0966]; 'Collaborative Annotation
   for Video Accessibility' (ACAV); 'The Adaptable Ambient Living
   Assistant' (ALIAS); joint national Ambient Assisted Living (AAL)
   programme
FX This work was partially supported by the French Ministry of Industry
   (Innovative Web call) under contract 09.2.93.0966, 'Collaborative
   Annotation for Video Accessibility' (ACAV) and by 'The Adaptable Ambient
   Living Assistant' (ALIAS) project funded through the joint national
   Ambient Assisted Living (AAL) programme.
CR Akbacak M, 2008, INT CONF ACOUST SPEE, P5240, DOI 10.1109/ICASSP.2008.4518841
   Alander JT, 1995, 941PHYS U VAAS DEP I
   Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI 10.1023/A:1015059928466
   Bisani M, 2008, SPEECH COMMUN, V50, P434, DOI 10.1016/j.specom.2008.01.002
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Black A.W., 1998, P 3 ESCA WORKSHOP SP, P77
   Burger Susanne., 2002, International Conference on Spoken Language Processing, V7, P301, DOI DOI 10.21437/ICSLP.2002-140
   Can D, 2009, INT CONF ACOUST SPEE, P3957, DOI 10.1109/ICASSP.2009.4960494
   Chan CA, 2010, P INT 10
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CP, 2010, P INT 10
   Chen S., 2002, Evolutionary Computation in Economics and Finance, NJ
   Cordón O, 2003, INT J APPROX REASON, V34, P241, DOI 10.1016/j.ijar.2003.07.010
   Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670
   Damper RI, 1997, LANG SPEECH, V40, P1
   Deligne S., 1995, EUROSPEECH, P2243
   Eiben A.E., 2015, NAT COMP SER, P223, DOI 10.1007/978-3-662-44874-8_15
   Filho EFM, 1997, IVTH BRAZILIAN SYMPOSIUM ON NEURAL NETWORKS, PROCEEDINGS, P58, DOI 10.1109/SBRN.1997.645849
   Fiscus JG, 2007, P WORKSH SEARCH SPON
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fogel G.B., 2002, Evolutionary Computation in Bioinformatics
   Hain T, 2006, LECT NOTES COMPUT SC, V4299, P419
   Janin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P364
   Jansen A, 2010, P INT 10
   Logan B., 2000, P ICSLP 00 BEIJ CHIN, V2, P676
   Mamou Jonathan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P615, DOI 10.1145/1277741.1277847
   Mamou J, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2106
   Mantere T, 2005, APPL SOFT COMPUT, V5, P315, DOI 10.1016/j.asoc.2004.08.004
   Martin A., 1997, Eurospeech
   Meng S, 2008, INT CONF ACOUST SPEE, P4345
   MICHALEWICZ Z., 1997, Evolutionary Algorithms, Chapter 2 in Fuzzy Evolutionary Computation
   Miller D. R., 2007, P INTERSPEECH, P314
   Mitchell M, 1999, ANNU REV ECOL SYST, V30, P593, DOI 10.1146/annurev.ecolsys.30.1.593
   Motlicek P, 2010, P INT 10
   *NIST, 2006, SPOK TERM DET STD 20
   Parada C, 2010, P ICASSP 10
   Parada C, 2010, P INT 10
   Rocha M, 2005, SPRING COMP SCI, P304, DOI 10.1007/3-211-27389-1_73
   Rocha M, 2007, NEUROCOMPUTING, V70, P2809, DOI 10.1016/j.neucom.2006.05.023
   Schneider D, 2010, P INT 10
   Sierra A, 2006, IEEE T EVOLUT COMPUT, V10, P81, DOI 10.1109/TEVC.2005.856069
   Sierra A., 2005, WSEAS Transactions on Information Science and Applications, V2, P1446
   Smith S., 2010, Genetic and evolutionary computation medical applications
   Szöke I, 2008, LECT NOTES COMPUT SC, V4892, P237
   Szoke I, 2008, P SPEECH SEARCH WORK
   Szoke I, 2006, P NIST SPOK TERM DET
   Szöke I, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P273, DOI 10.1109/SLT.2008.4777893
   Taylor P., 2005, 9th Annual Conference on Speech Communication and Technology Eurospeech, P1973
   Thambiratnam K, 2007, IEEE T AUDIO SPEECH, V15, P346, DOI 10.1109/TASL.2006.872615
   Vergyri D., 2007, PROC INTERSPEECH C, P2393
   Vergyri D, 2006, P NIST SPOK TERM DET
   Wallace R, 2010, P ICASSP 10
   Wang D, 2009, THESIS EDINBURGH U
   Wang D, 2011, ACM T INF S IN PRESS
   Wang D, 2010, IEEE T AUDIO SPEECH, V19, P688
   Wang D, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2091
   Wang D, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2103
   Watson D., 2003, Death sentence. The decay of public language
   Wessel F, 1998, INT CONF ACOUST SPEE, P225, DOI 10.1109/ICASSP.1998.674408
NR 59
TC 0
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 5
EP 34
DI 10.1007/s11042-011-0913-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Deigmoeller, J
   Itagaki, T
   Just, N
   Stoll, G
AF Deigmoeller, Joerg
   Itagaki, Takebumi
   Just, Norbert
   Stoll, Gerhard
TI Contextual cropping and scaling of TV productions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cropping and scaling; Computer vision; Regions of interest; Visual
   attention; Global motion estimation
ID VISUAL-ATTENTION; IMAGES; MODEL
AB In this paper, an application is presented which automatically adapts SDTV (Standard Definition Television) sports productions to smaller displays through intelligent cropping and scaling. It crops regions of interest of sports productions based on a smart combination of production metadata and systematic video analysis methods. This approach allows a context-based composition of cropped images. It provides a differentiation between the original SD version of the production and the processed one adapted to the requirements for mobile TV. The system has been comprehensively evaluated by comparing the outcome of the proposed method with manually and statically cropped versions, as well as with non-cropped versions. Envisaged is the integration of the tool in post-production and live workflows.
C1 [Deigmoeller, Joerg; Itagaki, Takebumi] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
   [Just, Norbert] Inst Rundfunktech, Inst German Publ Broadcasters Munich, Munich, Germany.
C3 Brunel University
RP Deigmoeller, J (corresponding author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
EM Joerg.Deigmoeller@honda-ri.de
CR [Anonymous], 2007, METH SUBJ ASS VID QU
   [Anonymous], 2007, C COMP VIS PATT REC
   Arthur C, 2007, GUARDIAN
   BMF Documentation, 2007, BMF BORADC MET EXCH
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng WH, 2005, IEICE T INF SYST, VE88D, P1578, DOI 10.1093/ietisy/e88-d.7.1578
   Dearden A., 2006, Proc. of 3rd Euro. Conf. on Visual Media Production CVMP-2006, P29, DOI DOI 10.1049/CP:20061968
   Deigmoeller J, 2010, P 2010 ACM S APPL CO
   Deselaers T, 2008, IEEE C COMP VIS PATT
   European Telecommunications Standards Institute, 2006, SPEC US VID AUD COD
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hou X, 2009, SPECTRAL RESIDUAL
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Knee M, 2008, INT BROADC C 2008 AM
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Lourakis M, 2009, HOMEST A C C LIB ROB
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Lum WY, 2003, IEEE T SOFTWARE ENG, V29, P1100, DOI 10.1109/TSE.2003.1265524
   Mason S, 2006, MOBILE TV RESULTS DV
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Sachs L., 1984, Applied Statistics a handbook of techniques
   TREISMAN A, 1986, SCI AM, V255, P106
   Walther DB, 2010, SALIENCY TOOLBOX
   Zaller J, 2007, SNELL WILCOXS HELIOS
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 28
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 623
EP 644
DI 10.1007/s11042-011-0804-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Huang, CF
   Lu, HP
   Ren, J
AF Huang, Chih-Fang
   Lu, Hsiang-Pin
   Ren, Jenny
TI Algorithmic approach to sonification of classical Chinese poetry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sonification; Markov chain; Classical Chinese poetry; Algorithmic
   composition
ID MUSIC
AB The classical Chinese poetry is a remarkable form of art in traditional Chinese character. However, it is difficult for people who are unfamiliar with ancient Chinese to experience the artistic content of the poetry. In this study, a sonification scheme, Tx2Ms (Text-to-Music), is proposed to extract the poetry features between lines in verses; moreover, dynamics and interval relations are modeled to map those features to the movement of multi-dimensional musical elements such as durations. This conversion is based on poetry intonation and acoustic analysis of the pronunciations of poems; and a stochastic compositional algorithm is created by applying a Markov chain. In addition, the best pentatonic mode for a specific poem is recommended according to the formants analysis. Therefore, the sonification of classical Chinese poetry not only provides a novel way for people to appreciate Chinese poetry but also enriches the state of mind and imagery in the delivery process, and the experiment results show that the proposed system is successfully accepted by most people.
C1 [Huang, Chih-Fang] Yuan Ze Univ, Dept Informat Commun, Chungli 32003, Taiwan.
   [Lu, Hsiang-Pin] Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan.
   [Ren, Jenny] Natl Chiao Tung Univ, Inst Mus, Hsinchu 300, Taiwan.
C3 Yuan Ze University; National Yang Ming Chiao Tung University; National
   Yang Ming Chiao Tung University
RP Huang, CF (corresponding author), Yuan Ze Univ, Dept Informat Commun, 135 Yuan Tung Rd, Chungli 32003, Taiwan.
EM jeffh@saturn.yzu.edu.tw
FU National Science Council projects of Taiwan [NSC99-2410-H-155-035-MY2]
FX The authors would like to appreciate the support from National Science
   Council projects of Taiwan: NSC99-2410-H-155-035-MY2.
CR [Anonymous], 1989, P INT COMP MUS C IC
   [Anonymous], 1959, EXPT MUSIC
   Bain R, 2006, INT COMP MUS C ICMC
   BALLAS JA, 1994, SFI S SCI C, V18, P79
   Barrass S, 1999, MULTIMEDIA SYSTEMS, V7
   BLATTNER MM, 1994, SFI S SCI C, V18, P447
   BREWSTER SA, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P222
   Chadabe J, 1997, ELECT SOUND PROMISE, P178
   Chen H-H, 2004, INTRO COMPOSITION CH
   Clement J, 1998, LEARNING HARMONIC PR
   COPE D, 1992, COMPUT MUSIC J, V16, P69, DOI 10.2307/3680717
   Cope D., 2004, Virtual Music: Computer Synthesis of Musical Style
   Doornbusch P, 2002, INT COMP MUS C GOT
   Durate J., 2006, 2 INT C WOCMAT WORKS, P96
   Fagerlonn J, 2009, P 15 INT C AUD DISPL
   Farbood M, 2001, INT COMP MUS C HAV C, P18
   Fowler AndrewJ., 1986, Indiana Theory Review, V7, P48
   Franz M, 1998, THESIS VIRGINIA POLY
   Garzonis S., 2009, P 27 INT C HUM FACT
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Goina M., 2008, P 2008 INT C NEW INT, P150
   Hsu C-Y, 1997, THEORY CLASSICAL CLI
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Hussein K, 2009, INT C PROGRAM COMPRE, P120, DOI 10.1109/ICPC.2009.5090035
   Jeon M., 2009, Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P91, DOI [10.1145/1620509.1620528, DOI 10.1145/1620509.1620528]
   Kaper G, 1999, COMPUTING SCI ENG, V1
   KRAMER G, 1994, SFI S SCI C, V18, P185
   Kramer G., 1999, SONIFICATION REPORT
   Lerdahl F, 2001, ANN NY ACAD SCI, V930, P337, DOI 10.1111/j.1749-6632.2001.tb05743.x
   McAlpine K, 1999, COMPUT MUSIC J, V23, P19, DOI 10.1162/014892699559733
   McCormack Jon., 1996, Complex Systems, V96, P320
   Mitchell Donald., 1985, Gustav Mahler: Songs and Symphonies of Life and Death
   Moore R. F., 1990, Elements of Computer Music
   Rahn John., 1980, BASIC ATONAL THEORY
   Rothstein J, 1995, COMPUTER MUSIC DIGIT, V7
   SAUE S, 2000, P INT C AUD DISPL IC
   Scaletti C., 1994, AUDITORY DISPLAY SON, V1, P223
   Shan MK, 2010, MULTIMED TOOLS APPL, V46, P1, DOI 10.1007/s11042-009-0303-y
   Spiliotopoulos D, 2009, LECT NOTES COMPUT SC, V5616, P587, DOI 10.1007/978-3-642-02713-0_62
   Sturm L, 2001, P 8 BIENN ARTS TECH
   Vazquez-Alvarez Y, 2010, P MULT LOC BAS TECHN, P37
   Verbeurgt K, 2004, LECT NOTES COMPUT SC, V3029, P1123
   Verron C, 2009, P 15 INT C AUD DISPL, P36
   Walker BN, 2009, LECT NOTES COMPUT SC, V5615, P445, DOI 10.1007/978-3-642-02710-9_49
   Walker N, 2003, P INT C AUD DISPL IC
   Winsor P, 1989, COMPUTER COMPOSERS T
   Winsor P, 1990, BLU RIDG SUMM PENN
   WINSOR P, 1992, AUTOMATED MUSIC COMP
   Wu XY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1345, DOI 10.1109/ICME.2008.4607692
   Yang C-C, 2004, THESIS NATL CHIAO TU
NR 50
TC 1
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 489
EP 518
DI 10.1007/s11042-011-0856-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600010
DA 2024-07-18
ER

PT J
AU Hussain, A
   Bhatti, SM
   Jaffar, MA
AF Hussain, Ayyaz
   Bhatti, Sohail Masood
   Jaffar, M. Arfan
TI Fuzzy based Impulse Noise Reduction Method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Impulse noise; Fuzzy filter; Fuzzy logic control;
   Structure similarity index; Fuzzy decision
ID FILTER
AB In this paper, we propose an image filtering technique based on fuzzy logic control to remove impulse noise for low as well as highly corrupted images. The proposed method is based on noise detection, noise removal and edge preservation modules. The main advantage of the proposed technique over the other filtering techniques is its superior noise removal as well as detail preserving capability. Based on the criteria of peak-signal-to-noise-ratio (PSNR), mean square error (MSE), structural similarity index measure (SSIM) and subjective evaluation measure we have found experimentally that the proposed method provides much better performance than the state-of-the-art filters. To analyze the detail preservation capability of the proposed filter sensitivity analysis is performed by changing the detail preservation module to see its effects on the details (texture and edge information) of resultant image. This sensitivity analysis proves experimentally that significant image details have been preserved by the proposed method.
C1 [Hussain, Ayyaz] Int Islamic Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Bhatti, Sohail Masood; Jaffar, M. Arfan] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.
   [Jaffar, M. Arfan] GIST, Signal & Image Proc Lab, Kwangju, South Korea.
C3 International Islamic University, Pakistan; Gwangju Institute of Science
   & Technology (GIST)
RP Hussain, A (corresponding author), Int Islamic Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
EM ayyaz.hussain@iiu.edu.pk; rsmbhatti@gmail.com; arfan.jaffar@nu.edu.pk
RI Bhatti, Sohail Masood/GPK-8682-2022; Jaffar, Arfan/GQB-2768-2022
OI Bhatti, Sohail Masood/0000-0002-8210-2785
FU Higher Education Commission (HEC), Pakistan [042-310165-Eg2-345]
FX The author, Mr. Sohail Masood Bhatti 042-310165-Eg2-345 would like to
   acknowledge the Higher Education Commission (HEC), Pakistan, for
   providing funding and required resources to complete this work.
CR Arakawa K, 1996, FUZZY SET SYST, V77, P3, DOI 10.1016/0165-0114(95)00122-0
   Arumugam MS, 2008, KNOWL INF SYST, V16, P331, DOI 10.1007/s10115-007-0109-z
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hussain A, DETAIL PRESERV UNPUB
   Hussain A, 2009, LECT NOTES COMPUT SC, V5496, P277, DOI 10.1007/978-3-642-01811-4_25
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Lee CS, 2005, IEEE T SYST MAN CY B, V35, P694, DOI 10.1109/TSMCB.2005.845397
   Lee CS, 2004, LECT NOTES COMPUT SC, V3174, P375
   Liu P., 2004, International Journal of Computational Cognition, V2, P131
   Mirza AM, 2007, J COMPUT SCI TECH-CH, V22, P580, DOI 10.1007/s11390-007-9061-3
   PITAS I, 1986, IEEE T ACOUST SPEECH, V34, P573, DOI 10.1109/TASSP.1986.1164857
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Resconi G, 2009, KNOWL INF SYST, V18, P213, DOI 10.1007/s10115-008-0164-0
   Saha S, 2010, KNOWL INF SYST, V23, P1, DOI 10.1007/s10115-009-0204-4
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Tukey J. M., 1971, EXPLORATORY DATA ANA
   Wang JH, 2002, IEEE T SYST MAN CY B, V32, P230, DOI 10.1109/3477.990880
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 22
TC 23
Z9 23
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 551
EP 571
DI 10.1007/s11042-011-0829-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, R
   Wang, LC
   Kong, DH
   Yin, BC
AF Wang, Ru
   Wang, Lichun
   Kong, Dehui
   Yin, Baocai
TI Making smooth transitions based on a multi-dimensional transition
   database for joining Chinese sign-language videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese sign synthesis; Video joining; Smooth transitions; Hand shape
AB This paper proposes a new method to generate smooth transition frames for serializing Chinese sign-language video clips. Each transition frame is composed of images of arms, hands, head and torso. Of them, the hand images are computed based on 3D hand models, and images of other parts are selected from a database. Experimental results show the method provided by this paper can improve the joined video's visual presentation.
C1 [Wang, Ru; Wang, Lichun; Kong, Dehui; Yin, Baocai] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, R (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM wangru@emails.bjut.edu.cn; wanglc@bjut.edu.cn; kdh@bjut.edu.cn;
   ybc@bjut.edu.cn
FU National Basic Research Program of China (973 Program) [2011CB302703];
   National Natural Science Foundation of China [60825203, U0935004,
   61033004]; Beijing Natural Science Foundation [4112008]; Guangdong
   Provincial Science and Technology project [2010A090100019]
FX This paper is supported by the National Basic Research Program of China
   (973 Program)(2011CB302703), the National Natural Science Foundation of
   China (No. 60825203, U0935004, 61033004), Beijing Natural Science
   Foundation(4112008), Guangdong Provincial Science and Technology project
   (2010A090100019). The authors thank Beijing 3rd School for the Deaf, who
   gives us a great help for Chinese sign's videotape.
CR ARAD N, 1995, COMPUT GRAPH FORUM, V14, P35, DOI 10.1111/1467-8659.1410035
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Cao Zheng, 2010, Information and Control, V39, P635, DOI 10.3724/SP.J.1219.2010.00635
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Chen WS, 2004, TAIWANESE SIGN LANGU
   Fitzgibbon A, 2005, INT J COMPUT VISION, V63, P141, DOI 10.1007/s11263-005-6643-9
   Krapez S., 1999, Elektrotehniski Vestnik, V66, P260
   Luo WW, 2006, RES CHINESE SIGN LAN
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Pan Jianjiang, 2002, Journal of Computer Aided Design & Computer Graphics, V14, P385
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   Solina F., 2001, MULTIMEDIA DICT SYNT, P268
   Wang Ruhai., 2009, GLOBAL TELECOMMUNICA, P1
   Wolberg G., 1990, Digital image warping
   Yang WW, 2009, COMPUT ANIMAT VIRT W, V20, P175, DOI 10.1002/cav.285
   Yang WW, 2005, J SOFTWARE, V16
   Zhao Zhi-xiang, 2008, Computer Engineering and Applications, V44, P74
NR 21
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 483
EP 493
DI 10.1007/s11042-011-0819-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300001
DA 2024-07-18
ER

PT J
AU Pammer, V
   Kump, B
   Lindstaedt, S
AF Pammer, Viktoria
   Kump, Barbara
   Lindstaedt, Stefanie
TI Tag-based algorithms can predict human ratings of which objects a
   picture shows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic annotation; Image tagging behaviour; Descriptive tags; Flickr;
   WordNet
AB Collaborative tagging platforms allow users to describe resources with freely chosen keywords, so called tags. The meaning of a tag as well as the precise relation between a tag and the tagged resource are left open for interpretation to the user. Although human users mostly have a fair chance at interpreting this relation, machines do not. In this paper we study the characteristics of the problem to identify descriptive tags, i.e. tags that relate to visible objects in a picture. We investigate the feasibility of using a tag-based algorithm, i.e. an algorithm that ignores actual picture content, to tackle the problem. Given the theoretical feasibility of a well-performing tag-based algorithm, which we show via an optimal algorithm, we describe the implementation and evaluation of a WordNet-based algorithm as proof-of-concept. These two investigations lead to the conclusion that even relatively simple and fast tag-based algorithms can yet predict human ratings of which objects a picture shows. Finally, we discuss the inherent difficulty both humans and machines have when deciding whether a tag is descriptive or not. Based on a qualitative analysis, we distinguish between definitional disagreement, difference in knowledge, disambiguation and difference in perception as reasons for disagreement between raters.
C1 [Pammer, Viktoria; Lindstaedt, Stefanie] Know Ctr, Inffeldgasse 21A, A-8010 Graz, Austria.
   [Kump, Barbara] Graz Univ Technol, Knowledge Management Inst, Tubingen, Germany.
C3 Graz University of Technology
RP Pammer, V (corresponding author), Know Ctr, Inffeldgasse 21A, A-8010 Graz, Austria.
EM vpammer@know-center.at; bkump@tugraz.at; slind@know-center.at
OI Pammer-Schindler, Viktoria/0000-0001-7061-8947
FU Austrian COMET Program-Competence Centers for Excellent Technologies;
   Austrian Federal Ministry of Transport, Innovation and Technology;
   Austrian Federal Ministry of Economy, Family and Youth; State of Styria
FX The Know-Center is funded within the Austrian COMET Program-Competence
   Centers for Excellent Technologies-under the auspices of the Austrian
   Federal Ministry of Transport, Innovation and Technology, the Austrian
   Federal Ministry of Economy, Family and Youth and by the State of
   Styria. COMET is managed by the Austrian Research Promotion Agency FFG.
CR Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   Bechhofer S, 2002, LECT NOTES COMPUT SC, V2519, P1152
   Cohen J., 2013, APPL MULTIPLE REGRES
   Gangemi A., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P285, DOI 10.1145/505168.505195
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Kurasaki Karen, 2000, FIELD METHOD, V12, P179, DOI [10.1177/1525822X0001200301, DOI 10.1177/1525822X0001200301]
   Mika P, 2005, LECT NOTES COMPUT SC, V3729, P522, DOI 10.1007/11574620_38
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nov O, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1097
   Pammer V, 2009, LECT NOTES COMPUT SC, V5887, P40, DOI 10.1007/978-3-642-10543-2_6
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Schmitz P, 2006, 15 WORLD WID WEB C W
   Sigurbjornsson B., 2008, Proceeding of the 17th International Conference on World Wide Web
   Sun A., 2009, Proc. SIGMM Workshop on Social Media, P19
   Terre BlancheM., 2006, RES IN PRACTICE, V2nd, P271
   Volkmer T, 2007, IEEE T MULTIMEDIA, V9, P967, DOI 10.1109/TMM.2007.900153
   Wimmer R.D., 2006, Mass media research: An introduction
NR 17
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 441
EP 462
DI 10.1007/s11042-011-0761-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000003
DA 2024-07-18
ER

PT J
AU Song, Y
   Tang, S
   Zheng, YT
   Chua, TS
   Zhang, YD
   Lin, SX
AF Song, Yan
   Tang, Sheng
   Zheng, Yan-Tao
   Chua, Tat-Seng
   Zhang, Yongdong
   Lin, Shouxun
TI Exploring probabilistic localized video representation for human action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Probabilistic video representation;
   Information-theoretic video matching
AB In recent years, the bag-of-words (BoW) video representations have achieved promising results in human action recognition in videos. By vector quantizing local spatial temporal (ST) features, the BoW video representation brings in simplicity and efficiency, but limitations too. First, the discretization of feature space in BoW inevitably results in ambiguity and information loss in video representation. Second, there exists no universal codebook for BoW representation. The codebook needs to be re-built when video corpus is changed. To tackle these issues, this paper explores a localized, continuous and probabilistic video representation. Specifically, the proposed representation encodes the visual and motion information of an ensemble of local ST features of a video into a distribution estimated by a generative probabilistic model. Furthermore, the probabilistic video representation naturally gives rise to an information-theoretic distance metric of videos. This makes the representation readily applicable to most discriminative classifiers, such as the nearest neighbor schemes and the kernel based classifiers. Experiments on two datasets, KTH and UCF sports, show that the proposed approach could deliver promising results.
C1 [Song, Yan] Chinese Acad Sci, Grad Univ, Beijing 10039, Peoples R China.
   [Song, Yan; Tang, Sheng; Zhang, Yongdong; Lin, Shouxun] Chinese Acad Sci, Inst Comp Technol, Lab Adv Comp Res, Beijing 10090, Peoples R China.
   [Zheng, Yan-Tao] ASTAR, Inst Infocomm Res, Singapore, Singapore.
   [Chua, Tat-Seng] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology,
   CAS; Agency for Science Technology & Research (A*STAR); A*STAR -
   Institute for Infocomm Research (I2R); National University of Singapore
RP Song, Y (corresponding author), Chinese Acad Sci, Grad Univ, Beijing 10039, Peoples R China.
EM songyan@ict.ac.cn; ts@ict.ac.cn; yzheng@i2r.a-star.edu.sg;
   chuats@comp.nus.edu.sg; zhyd@ict.ac.cn; sxlin@ict.ac.cn
FU National Basic Research Program of China (973 Program) [2007CB311105];
   National Nature Science Foundation of China [60873165]; Beijing
   Municipal Education Commission
FX This work was supported by National Basic Research Program of China (973
   Program, 2007CB311105); National Nature Science Foundation of China
   (60873165); Co-building Program of Beijing Municipal Education
   Commission.
CR [Anonymous], P IEEE INT C MULT EX
   Ballan Lamberto, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P506, DOI 10.1109/ICCVW.2009.5457658
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Chan A.B., 2004, A family of probabilistic kernels based on information divergence
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334
   Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946
   Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kullback S., 1968, INFORM THEORY STAT
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Liu JG, 2009, INT CONF ACOUST SPEE, P3549, DOI 10.1109/ICASSP.2009.4960392
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Rodriguez MD, 2008, PROCEEDING INT C COM, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Vasconcelos N, 2004, LECT NOTES COMPUT SC, V3023, P430
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Vergés-Llahí J, 2005, LECT NOTES COMPUT SC, V3523, P263
   Wang H., 2009, BMVC
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S F, 2007, P INT C COMPUTER VIS, P1
   Xiong ZY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1947
   Xu LM, 2007, AUTOM CONTROL COMPUT, V41, P224, DOI 10.3103/S0146411607040062
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 39
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 663
EP 685
DI 10.1007/s11042-011-0748-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900010
DA 2024-07-18
ER

PT J
AU Coppens, S
   Mannens, E
   De Pessemier, T
   Geebelen, K
   Dacquin, H
   Van Deursen, D
   Van de Walle, R
AF Coppens, Sam
   Mannens, Erik
   De Pessemier, Toon
   Geebelen, Kristof
   Dacquin, Hendrik
   Van Deursen, Davy
   Van de Walle, Rik
TI Unifying and targeting cultural activities via events modelling and
   profiling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event modelling; Profiling; Recommendation
AB Today, people have only limited, valuable spare time at their hands which they want to fill in as good as possible according to their interests. At the same time, cultural institutions are trying to attract interested communities to their carefully planned cultural programs. To distribute these cultural events to the right people, we developed a framework that will aggregate, enrich, recommend and distribute these events as targeted as possible. The aggregated events are published as Linked Open Data using an RDF/OWL representation of the EventsML-G2 standard. These event items are categorised and enriched via smart indexing and linked open datasets available on the Web of data. For recommending the events to the end-user, a global profile of the end-user is automatically constructed by aggregating his profile information from all user communities the user trusts and is registered to. This way, the recommendations take profile information into account from different communities, which has a detrimental effect on the recommendations. As such, the ultimate goal is to provide an open, user-friendly recommendation platform that harnesses the end-user with a tool to access useful event information that goes beyond basic information retrieval. At the same time, we provide the (inter)national cultural community with standardised mechanisms to describe/distribute event and profile information.
C1 [Coppens, Sam; Mannens, Erik; Van Deursen, Davy; Van de Walle, Rik] Ghent Univ IBBT, ELIS Multimedia Lab, B-9050 Ghent, Belgium.
   [De Pessemier, Toon] Ghent Univ IBBT, INTEC WiCa, B-9050 Ghent, Belgium.
   [Geebelen, Kristof] KU Leuven IBBT, Distrinet, B-3001 Louvain, Belgium.
   [Dacquin, Hendrik] VRT, VRT Medialab, B-1043 Brussels, Belgium.
C3 Ghent University; Ghent University; KU Leuven
RP Mannens, E (corresponding author), Ghent Univ IBBT, ELIS Multimedia Lab, B-9050 Ghent, Belgium.
EM sam.coppens@ugent.be; erik.mannens@ugent.be; tdpessem@intec.ugent.be;
   kristof.geebelen@cs.kuleuven.be; hendrik.dacquin@vrt.be;
   davy.vandeursen@ugent.be; rik.vandewalle@ugent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University, K.U. Leuven; VRT-medialab; Interdisciplinary Institute
   for Broadband Technology (IBBT); Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT); Fund for
   Scientific Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, K.U. Leuven, VRT-medialab, Interdisciplinary
   Institute for Broadband Technology (IBBT) through the CUPID-project (50%
   co-funded by industrial partners), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT), the Fund for
   Scientific Research-Flanders (FWO-Flanders), and the European Union.
CR [Anonymous], 2007, OASIS TECHN COMM WS
   [Anonymous], 2009, SPORTSML G2 SPEC VER
   [Anonymous], 2009, 5 INT C KNOWLEDGE CA, DOI DOI 10.1145/1597735.1597760
   [Anonymous], 2007, LINKINGOPENDATA W3C
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367760
   [Anonymous], 2004, W3C recommendation
   [Anonymous], 2007, CTR DIG MUS U LOND E
   [Anonymous], 2009, DEF CIDOC CONC REF M
   [Anonymous], 2009, EVENTSML G2 SPEC VER
   BERGLUND A, 2006, EXTENSIBLE STYLESHEE
   Bhupendra K, 2009, HYPER CONNECTIVITY A
   Bray T., 2006, Extensible Markup Language (XML) 1.1 Specification, V2nd
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Brickley D., 2004, RDF VOCABULARY DESCR
   CHINNICI R., 2004, WEB SERVICES DESCRIP
   Clark James, 1999, Xsl transformations (xslt)
   Foster D. P., 1998, AAAI WORKSH REC SYST, P114
   Hayes C, 2002, WORKSH PERS REC E CO
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Huang Z, 2004, AMCIS 2004
   International Press Telecommunications Council, 2009, NEWSML G2 SPEC VERS
   Internet Engineering Task Force, 2009, INT CAL SCHED COR OB
   Iskold A, 2004, ART SCI BUSINESS REC
   Kaneiwa K, 2007, LECT NOTES COMPUT SC, V4830, P394
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   McGuinness D.L., 2004, W3C RECOMMENDATION, V10
   Nack F., 2003, Proceedings of the 1st ACM MM WS on Experiential Telepresence (ETP'03), P53, DOI DOI 10.1145/982484.982492
   O'Reilly T., 2006, What Is Web 2.0: Design patterns and business models for the next generation of software
   Papagelis M, 2005, LECT NOTES COMPUT SC, V3477, P224
   S Corcoran, 2009, USING SOCIAL APPL AD
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Segaran T., 2007, PROGRAMMING COLLECTI
   Shaw R, 2009, P 4 INT AS SEM WEB C
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
NR 35
TC 2
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 199
EP 236
DI 10.1007/s11042-011-0757-6
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800012
OA Green Published
DA 2024-07-18
ER

PT J
AU Oh, JM
   Moon, N
AF Oh, Jung-Min
   Moon, NamMee
TI User-selectable interactive recommendation system in mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Collaborative filtering; Interactive
   recommendation; Smart phone; MAE
AB Mobile devices need to provide more accurate and personalized information in a computing environment with a small screen and limited information retrieval functions. This paper presents a user-selectable recommendation system that reflects a user interest group by employing collaborative filtering as technique to provide useful information in a mobile environment. We form similar groups by simultaneously considering a user's information preferences and demographics. Then we reconstruct lists of a final recommendation based on what search results the similar demographic group has chosen. This is an optional filter for the search results. This means that we provide an interactive flexible recommendation list that considers a user's intent more actively, rather than unilaterally. We show the Mean Absolute Error result to evaluate the recommendation and finally show the realization of a prototype that is based on both the iPhone and Android phone environments.
C1 [Oh, Jung-Min; Moon, NamMee] Hoseo Univ, Dept IT Applicat Technol GSV, Seoul, South Korea.
   [Moon, NamMee] Ewha Womans Univ, Seoul, South Korea.
   [Moon, NamMee] Seoul Univ Venture & Informat, Dept Digital Media, Seoul, South Korea.
C3 Hoseo University; Ewha Womans University
RP Moon, N (corresponding author), Hoseo Univ, Dept IT Applicat Technol GSV, Seoul, South Korea.
EM aliibaba@naver.com; mnm@hoseo.edu
FU Korea Science and Engineering Foundation (KOSEF); Korean government
   (MEST) [2010-0000487]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) grant funded by the Korean government (MEST) (No. 2010-0000487)
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], MOVIELENS
   [Anonymous], 2008, KOTRA GLOBAL WINDOW
   Ben Schafer J, 2001, DATA MIN KNOWL DISC, V5, P115, DOI 10.1023/A:1009804230409
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Kim K-R, 2010, MUE 2010
   Kjlee, 2007, KIISE, V34, P72
   Kyeong Kim Jae, 2005, Asia Pacific Journal of Information Systems, V15, P223
   Lee JaeSik, 2007, [Journal of Intelligence and Information Systems, 지능정보연구], V13, P65
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Miller FP, 2009, COLLABORATIVE FILTER, P13
   Oh J-M, 2010, J I ELECT ENG KOREA, V47, P18
   Park KC, 2008, THEIS HANYANG U
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Sarwar B., 2002, P 5 INT C COMP INF S, P27
   Ulucan S, 2005, RECOMMENDATION SYSTE, P20
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
NR 18
TC 9
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 295
EP 313
DI 10.1007/s11042-011-0737-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700004
DA 2024-07-18
ER

PT J
AU Laborie, S
   Euzenat, J
   Layaïda, N
AF Laborie, Sebastien
   Euzenat, Jerome
   Layaida, Nabil
TI Semantic adaptation of multimedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia document transformation; Qualitative representation and
   reasoning; SMIL
ID FRAMEWORK; KNOWLEDGE; MODEL
AB Multimedia documents have to be played on multiple device types. Hence, usage and platform diversity requires document adaptation according to execution contexts, not generally predictable at design time. In an earlier work, a semantic framework for multimedia document adaptation was proposed. In this framework, a multimedia document is interpreted as a set of potential executions corresponding to the author specification. To each target device corresponds a set of possible executions complying with the device constraints. In this context, adapting requires to select an execution that satisfies the target device constraints and which is as close as possible from the initial composition. This theoretical adaptation framework does not specifically consider the main multimedia document dimensions, i.e., temporal, spatial and hypermedia. In this paper, we propose a concrete application of this framework on standard multimedia documents. For that purpose, we first define an abstract structure that captures the spatio-temporal and hypermedia dimensions of multimedia documents, and we develop an adaptation algorithm which transforms in a minimal way such a structure according to device constraints. Then, we show how this can be used for adapting concrete multimedia documents in SMIL through converting the documents in the abstract structure, using the adaptation algorithm, and converting it back in SMIL. This can be used for other document formats without modifying the adaptation algorithm.
C1 [Laborie, Sebastien] Univ Toulouse 3, IRIT, F-31062 Toulouse 9, France.
   [Euzenat, Jerome; Layaida, Nabil] INRIA Grenoble Rhone Alpes & LIG, F-38334 Saint Ismier, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier
RP Laborie, S (corresponding author), Univ Toulouse 3, IRIT, 118 Route Narbonne, F-31062 Toulouse 9, France.
EM Sebastien.Laborie@irit.fr; Jerome.Euzenat@inrialpes.fr;
   Nabil.Layaida@inrialpes.fr
OI Laborie, Sebastien/0000-0002-9254-8027
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Amous I, 2005, MULTIMED TOOLS APPL, V25, P391, DOI 10.1007/s11042-005-6542-7
   [Anonymous], SYNCHRONIZED MULTIME
   ASADI MK, 2004, KNOWLEDGE BASED MEDI, P285
   Badros G. J., 2001, ACM Transactions on Computer-Human Interaction, V8, P267, DOI 10.1145/504704.504705
   Bilasco I, 2005, MULTIMED TOOLS APPL, V25, P361, DOI 10.1007/s11042-005-6540-9
   BORMANS J, 2002, MPEG 21 OVERVIEW V 5
   BRA PD, 2006, P 17 ACM C HYP HYP, P133
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   Condotta JF, 2007, LECT NOTES COMPUT SC, V4741, P806
   Euzenat J, 2003, P 18 INT JOINT C ART, P31
   FREKSA C, 1992, ARTIF INTELL, V54, P199, DOI 10.1016/0004-3702(92)90090-K
   Gerevini A, 2002, FRONT ARTIF INTEL AP, V77, P312
   GEURTS J, 2001, P INT C MULT MOD MMM, P247
   Grifoni Patrizia., 2009, Multimodal human computer interaction and pervasive services, P103, DOI [10.4018/978-1-60566-386-9.ch006, DOI 10.4018/978-1-60566-386-9.CH006]
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   He J, 2007, IEEE T KNOWL DATA EN, V19, P127, DOI 10.1109/TKDE.2007.250590
   Jannach D, 2006, APPL INTELL, V24, P109, DOI 10.1007/s10489-006-6933-0
   KIRDA E, 2005, LNCS, V3272, P96
   KLYNE G, 2001, COMPOSITE CAPABILITY
   LABORIE S, 2009, SCREENCAST OUR SMIL
   LABORIE S, 2006, POST P 1 INT C SEM D, P7
   Laborie S, 2008, STUD COMPUT INTELL, V93, P157
   Laborie S, 2006, LECT NOTES COMPUT SC, V4183, P128
   LAYAIDA N, 1997, THESIS U J FOURIER G
   Lei ZJ, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P913, DOI 10.1109/CCECE.2001.933563
   Lemlouma T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P106
   LEMLOUMA T, 2001, P 8 INT C MULT MOD M, P187
   NEBEL B, 1996, P ECAI 96, P38
   *OP MOB ALL, 2008, MULT MESS SERV CONF
   Rabin J., 2008, MOBILE WEB BEST PRAC
   Randell D. A., 1992, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), P165
   ROISIN C, 1998, P C CURR TRENDS THEO, P222
   ROUSSEAU F, 1999, P 8 INT C WORLD WID, P1273
   SCHERP A, 2005, MANAGING MULTIMEDIA, P246
   Shao BL, 2006, AXMEDIS 2006: SECOND INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P77
   vanBeek P, 1996, J ARTIF INTELL RES, V4, P1
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P16, DOI 10.1109/MSP.2003.1184335
   *W3C, 2010, UB WEB DOM
NR 39
TC 13
Z9 13
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 379
EP 398
DI 10.1007/s11042-010-0552-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600002
DA 2024-07-18
ER

PT J
AU Jumisko-Pyykkö, S
   Utriainen, T
AF Jumisko-Pyykko, Satu
   Utriainen, Timo
TI A Hybrid Method for Quality Evaluation in the Context of Use for Mobile
   (3D) Television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Experienced; Audiovisual quality; Context; Context of use;
   Evaluation
ID DISTRIBUTED MULTIMEDIA; PERCEPTION; PICTURE
AB Controlled psychoperceptual quality evaluation experiments are used to assess the excellence of produced audiovisual quality from fundamental signal processing algorithms to consumer services. When compromising produced quality for consumer services, used in dynamic and heterogeneous mobile contexts, the ecological validity of conventional quality evaluation methods can be questioned. The goal of this paper is to develop a method for evaluating the experienced multimedia quality in the context of use. We conducted three studies where the quality of mobile 2D and 3D television was assessed in three different field contexts, one simulated context and one controlled laboratory situation when audio-video compression and transmission parameters were varied. We propose a hybrid method for the design, data-collection and analysis of the experiments in the contexts of use. Its novelty is to complement conventional quantitative quality evaluation with concrete tools to identify factors that surround the assessment in the context. The methodological framework is part of our long-term aim to measure and understand the user-centered quality of experience.
C1 [Jumisko-Pyykko, Satu; Utriainen, Timo] Tampere Univ Technol, Human Ctr Technol, FIN-33101 Tampere, Finland.
C3 Tampere University
RP Jumisko-Pyykkö, S (corresponding author), Tampere Univ Technol, Human Ctr Technol, Korkeakoulunkatu 6,POB 589, FIN-33101 Tampere, Finland.
EM satu.jumisko-pyykko@iki.fi; timo.j.utriainen@tut.fi
FU European Commission [216503]; UCIT graduate school
FX This work is supported by the European Commission within the ICT program
   of FP7 under Grant 216503 with the acronym MOBILE3DTV
   (www.mobile3dtv.eu) and the UCIT graduate school. The authors wish to
   thank Dr. Miska Hannuksela and Dr. Atanas Gotchev for their comments and
   Cinovent, Red Star Studio, Stereoscape and the Centre of Computer
   Graphics and Visualization from the University of West Bohemia for
   providing content for the experiments.
CR [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], P 14 ANN ACM INT C M
   [Anonymous], VTT PUBLICATIONS
   [Anonymous], 2004, P 2004 C HUM FACT CO
   [Anonymous], 1999, 13407 ISO
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2005, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/1054972.1055101
   [Anonymous], P911 ITUT
   [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], 1994, E800 ITUT
   Barnard L, 2007, PERS UBIQUIT COMPUT, V11, P81, DOI 10.1007/s00779-006-0063-x
   Beresford K., 2006, AES 120th Convention, P6648
   BERNHAUPT R, 2008, HDB RES USER INTERFA, V44, P745
   BOEV A, 2009, P SPIE STEREOSCOPIC, V20, P7237
   Bradley NA, 2005, HUM-COMPUT INTERACT, V20, P403, DOI 10.1207/s15327051hci2004_2
   Brewster S, 2002, PERS UBIQUIT COMPUT, V6, P188, DOI 10.1007/s007790200019
   Buchinger S, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P179
   CHEN T, 2008, RIAM D2 6 DO PEOPLE
   Consolvo S, 2007, INT J HUM-COMPUT INT, V22, P103, DOI 10.1207/s15327590ijhc2201-02_6
   Cook T. D., 1979, QUASIEXPERIMENTATION
   Coolican H., 2009, RES METHODS STAT PSY
   *EUR BROADC UN, 2003, SUBJ LIST TESTS LOW
   *EUR TEL STAND I, 2005, 102377 ETSI TR
   Fiske S.T., 1991, SOCIAL COGNITION
   FLACK J, 2007, P SPIE, V6490
   Fredrickson BL, 2000, COGNITION EMOTION, V14, P577, DOI 10.1080/026999300402808
   Ghinea G, 2008, COMPUT HUM BEHAV, V24, P1317, DOI 10.1016/j.chb.2007.07.013
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   GOCHEV A, 2009, MULTIMEDIA MOBILE DE, P7256
   Goldsmith RE, 2001, INTERNET RES, V11, P149, DOI 10.1108/10662240110695098
   GOODMAN J, 2004, P HCI 2004
   Grill-Spector K, 2004, ANNU REV NEUROSCI, V27, P649, DOI 10.1146/annurev.neuro.27.070203.144220
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   HANDS DS, 2007, P SPIE, V6492
   Harrison GW, 2004, J ECON LIT, V42, P1009, DOI 10.1257/0022051043004577
   HART S G, 1988, P139
   *ITU T, 2008, P10 ITUT
   Jambon F, 2009, INT J MOB HUM COMPUT, V1, P56, DOI 10.4018/jmhci.2009040104
   Jumisko-Pyykk S., 2008, Proc 1st Int Conf Designing Interact User Experiences TVand video, V2008, P183, DOI DOI 10.1145/1453805.1453841
   Jumisko-Pyykkö S, 2008, INT J DIGIT MULTIMED, V2008, DOI 10.1155/2008/712380
   Jumisko-Pyykko Satu., 2008, P 10 INT C HUMAN COM, P63, DOI DOI 10.1145/1409240.1409248
   Jumisko-Pyykkö S, 2008, MULTIMED TOOLS APPL, V36, P167, DOI 10.1007/s11042-006-0080-9
   JUMISKOPYYKKO S, 2007, P SPIE MULTIMEDIA MO, P6507
   JUMISKOPYYKKO S, 2010, P 3DTV C 2010
   JUMISKOPYYKKO S, 2008, REPORT RES METHODOLO
   JUMISKOPYYKKO S, 2010, INT J MOBILE HUMAN C, V2
   Kaikkonen A., 2008, HDB RES USER INTERFA, P897
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   KIM H, 2002, P 35 ANN HAW INT C S, V5, P132
   Kjeldskov J, 2004, LECT NOTES COMPUT SC, V3160, P61
   Knoche H, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556137
   Knoche H, 2008, MULTIMED TOOLS APPL, V36, P145, DOI 10.1007/s11042-006-0076-5
   Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831
   Mizobuchi S., 2005, P 7 INT C HUMAN COMP, V111, P122, DOI [10.1145/1085777, DOI 10.1145/1085777]
   MUSTONEN T, 2004, HUM FACT COMP SYST C, P1243
   NAHRSTEDT K, 1995, COMPUTER, V28, P52, DOI 10.1109/2.384118
   Neisser U., 1976, COGNITION REALITY PR
   Oatley K., 2003, Understanding Emotions
   Oksman V, 2008, MULTIMEDIA SYST, V14, P105, DOI 10.1007/s00530-008-0118-0
   OULASVIRTA A, 2009, FUTURE INTERACTION D
   Oulasvirta A, 2009, J USABILITY STUD, V4, P93
   Pirhonen A., 2002, P SIGCHI C HUM FACT, P291
   Reiter U, 2007, LECT NOTES COMPUT SC, V4552, P943
   Roto V., 2006, Web browsing on mobile phones: Characteristics of user experience
   SASSE MA, 2006, P ISCA DEGA TUT RES
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shadish W. R., 2002, EXPT QUASI EXPT DESI
   Strauss E, 1998, CLIN ORTHOP RELAT R, P2
   STROHMEIER D, 2010, P VPQM 2010
   STROHMEIER D, 2010, P SPIE MULTIMEDIA MO
   Tamminen S, 2004, PERS UBIQUIT COMPUT, V8, P135, DOI 10.1007/s00779-004-0263-1
   TASHAKKORI A, 2008, ADV MIXED METHOD RES
   *VTT, 2007, CAST
   Winkler S, 2005, PROC SPIE, V5666, P139, DOI 10.1117/12.596852
NR 74
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 185
EP 225
DI 10.1007/s11042-010-0573-4
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500002
DA 2024-07-18
ER

PT J
AU Lamy-Bergot, C
   Fracchia, R
   Mazzotti, M
   Moretti, S
   Piri, E
   Sutinen, T
   Zuo, J
   Vehkaperä, J
   Feher, G
   Jeney, G
   Panza, G
   Amon, P
AF Lamy-Bergot, Catherine
   Fracchia, Roberta
   Mazzotti, Matteo
   Moretti, Simone
   Piri, Esa
   Sutinen, Tiia
   Zuo, Jing
   Vehkapera, Janne
   Feher, Gabor
   Jeney, Gabor
   Panza, Gianmarco
   Amon, Peter
TI Optimisation of multimedia over wireless IP links via X-layer design: an
   end-to-end transmission chain simulator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-to-end optimisation; High fidelity simulation; Quality of Service;
   Joint source channel (de) coding; Multimedia transmission; Point to
   multi-point video delivery; Cross-layer design; IPv6 mobility; Adaptive
   medium access control
AB End-to-end optimised Quality of Service (QoS) and its specific declination for multimedia applications with the end-user Perceived Quality of Service (PQoS) is nowadays a trendy topic in the literature. Many different techniques and approaches have been proposed, which are in general focusing on specific weak technical aspects of the transmission chain in the considered scenario. The end-to-end optimisation of a complete system system is however more complex and its practical realisation remains to be achieved, especially with the added constraint to be transparently integrated in existing legacy systems so as to not perturbate their current modes of operation. In this paper, we propose an architecture set-up within the ICT FP7 OPTIMIX project to study innovative solutions enabling enhanced multimedia streaming in a point to multi-point context for an IP (Internet Protocol) based wireless heterogeneous system, based on cross layer adaptation of the whole transmission chain. The corresponding simulation chain architecture is detailed with the description of the existing and/or future features of each module.
C1 [Lamy-Bergot, Catherine; Fracchia, Roberta] THALES Commun, Colombes, France.
   [Mazzotti, Matteo; Moretti, Simone] Univ Bologna, CNIT, Bologna, Italy.
   [Zuo, Jing] Univ Southampton, Commun Res Grp, Sch Elect & Comp Sci, Southampton, Hants, England.
   [Piri, Esa; Sutinen, Tiia; Vehkapera, Janne] VTT Tech Res Ctr Finland, Oulu, Finland.
   [Feher, Gabor; Jeney, Gabor] Budapest Univ Technol & Econ, H-1117 Budapest, Hungary.
   [Panza, Gianmarco] CEFRIEL Politecn Milano, Milan, Italy.
   [Amon, Peter] Siemens Corp Technol Informat & Commun, Munich, Germany.
   [Mazzotti, Matteo] Univ Bologna, CNIT DEIS, Bologna, Italy.
C3 Thales Group; University of Bologna; University of Southampton; VTT
   Technical Research Center Finland; Budapest University of Technology &
   Economics; Polytechnic University of Milan; Siemens AG; Siemens Germany;
   University of Bologna
RP Lamy-Bergot, C (corresponding author), THALES Commun, Colombes, France.
EM catherine.lamy-bergot@fr.thalesgroup.com
RI Feher, Gabor/AAE-2686-2021; Amon, Peter/KEI-3680-2024; Feher,
   Gabor/M-4472-2013
OI Feher, Gabor/0000-0003-2136-3356; Feher, Gabor/0000-0003-2136-3356;
   Lamy-Bergot, Catherine/0000-0001-7525-074X
FU European Commission within the EU [INFSO-ICT-214625]; Information
   Society Technologies
FX This work has been carried thanks to INFSO-ICT-214625 OPTIMIX project,
   which is partially funded by the European Commission within the EU 7th
   Framework Programme and Information Society Technologies.
CR [Anonymous], 26346 3GPP TS
   [Anonymous], 1980, 768 IETF RFC
   [Anonymous], 2006, DATAGRAM CONGESTION
   Bajic IV, 2007, IEEE T BROADCAST, V53, P276, DOI 10.1109/TBC.2006.889211
   Baugher M., 2004, 3711 IETF RFC
   Bernstein Daniel J, 2008, Tech. Rep.
   Bormann C., 2001, IETF RFC 3095
   CASNER S, 2003, 3550 IETF RFC
   Deering S., 1998, 2460 IETF RFC
   FU F, 2009, P IEEE PACK VID WORK, P1
   Hagenauer J, 1999, P IEEE, V87, P1764, DOI 10.1109/5.790636
   Hsu JL, 2009, IEEE SIGNAL PROC LET, V16, P268, DOI 10.1109/LSP.2008.2010821
   Kasch WT, 2009, IEEE COMMUN MAG, V47, P120, DOI 10.1109/MCOM.2009.4804397
   Kawadia V, 2005, IEEE WIREL COMMUN, V12, P3, DOI 10.1109/MWC.2005.1404568
   Kopke A., 2008, SIMUTOOLS
   Lacage M., 2006, YET ANOTHER NETWORK
   Liu ZY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1121, DOI 10.1109/ICME.2006.262732
   MAKELA J, 2007, S ISWPC 07 SAN JUAN, P378
   Martini MG, 2007, IEEE COMMUN MAG, V45, P84, DOI 10.1109/MCOM.2007.284542
   Moskowitz R, 2008, 5201 IETF RFC
   *OMNET, 2008, DISCR EV SIM SYST
   *OPTIMIX PROJ TEAM, 2010, OMNET BAS OPTIMIX SY
   SCHULZRINNE H, 1998, 2326 IETF RFC
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Srivastava V, 2005, IEEE COMMUN MAG, V43, P112, DOI 10.1109/MCOM.2005.1561928
   TIMMERER C, 2008, EUMOB 08
   UITTO M, 2009, MOBIMEDIA 09 LOND UK
   ZAHARIADIS T, 2008, IEEE ISCE 08 VIL POR
   MOBILITY FRAMEWORK M
   H 264 JOINT VERIFICA
NR 30
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 261
EP 288
DI 10.1007/s11042-010-0571-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mao, L
   Fan, YY
   Wang, HQ
   Lv, GY
AF Mao, Li
   Fan, Yang-Yu
   Wang, Hui-Qin
   Lv, Guo-Yun
TI Fractal and neural networks based watermark identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Watermarking; Discrete cosine transform; Fractal; Neural networks; Human
   visual system
ID ADAPTIVE WATERMARKING; IMAGE WATERMARKING; ROBUST
AB Transform techniques generally are more robust than spatial techniques for watermark embedding. In this paper, a color image watermarking algorithm based on fractal and neural networks in Discrete Cosine Transform (DCT) domain is proposed. We apply fractal image coding technique to obtain the characteristic data of a gray-level image watermark signal and encrypt the characteristic data by a symmetric encryption before they are embedded. We then use neural networks and Human Visual System (HVS) to embed the watermark in the DCT domain. A Just Noticeable Difference (JND) threshold controller is designed to ensure the strength of the embedded data adapting to the host image itself entirely. Aiming at misjudging problem of the extracting process, maximum membership principle criterion is selected for identifying the watermark. And the CIELab color space is chosen to guarantee the stability of the results. The simulation results show that the algorithm is robust for common digital image processing methods as attacks and that the quality of the image is retained.
C1 [Mao, Li; Fan, Yang-Yu; Lv, Guo-Yun] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
   [Mao, Li; Wang, Hui-Qin] XiAN Univ Architecture & Technol, Sch Informat & Control Engn, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Xi'an University of Architecture
   & Technology
RP Mao, L (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM morley220@qq.com
RI wang, hui/GRS-4730-2022
CR Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 2006, LECT NOTES COMPUT SC, V4283, P1
   FU X, 2005, INT J BUSINESS INTEL, V1, P65
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Khan A, 2008, PATTERN RECOGN, V41, P2594, DOI 10.1016/j.patcog.2008.01.007
   Lee CH, 1999, IEEE T CONSUM ELECTR, V45, P1005, DOI 10.1109/30.809176
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Tao B, 1997, INT CONF ACOUST SPEE, P2985, DOI 10.1109/ICASSP.1997.595419
   WANG LIPO., 2005, ADV INFO KNOW PROC
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
NR 16
TC 6
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 201
EP 219
DI 10.1007/s11042-010-0467-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500016
DA 2024-07-18
ER

PT J
AU Grgic, M
   Delac, K
   Grgic, S
AF Grgic, Mislav
   Delac, Kresimir
   Grgic, Sonja
TI SCface - surveillance cameras face database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance cameras; Face database; Face recognition
ID RECOGNITION
AB In this paper we describe a database of static images of human faces. Images were taken in uncontrolled indoor environment using five video surveillance cameras of various qualities. Database contains 4,160 static images (in visible and infrared spectrum) of 130 subjects. Images from different quality cameras should mimic real-world conditions and enable robust face recognition algorithms testing, emphasizing different law enforcement and surveillance use case scenarios. In addition to database description, this paper also elaborates on possible uses of the database and proposes a testing protocol. A baseline Principal Component Analysis (PCA) face recognition algorithm was tested following the proposed protocol. Other researchers can use these test results as a control algorithm performance score when testing their own algorithms on this dataset. Database is available to research community through the procedure described at www.scface.org.
C1 [Grgic, Mislav; Grgic, Sonja] Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Zagreb 41000, Croatia.
C3 University of Zagreb
RP Grgic, M (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Unska 3-12, Zagreb 41000, Croatia.
EM mislav.grgic@fer.hr
RI Grgic, Mislav/B-6128-2008
OI Grgic, Mislav/0000-0001-6230-3734
FU Ministry of Science, Education and Sports of the Republic of Croatia
   [036-0982560-1643]
FX The authors would like to thank Bozidar Klimpak for his technical
   support during database acquistion and indexing, Kresimir Marusic and
   Tehnozavod Marusic Ltd. for providing surveillance system equipment,
   Boris Krzic for providing professional photo equipment and his help with
   mug shots capturing, Darko Poljak for developing and providing JAVA
   software used for semiautomatic determination of eyes, nose and mouth
   coordinates, and to all participants in this project. Portions of the
   research in this paper use the FERET database of facial images collected
   under the FERET program. The authors would like to thank the FERET
   Technical Agent, the U. S. National Institute of Standards and
   Technology (NIST) for providing the FERET database. The work described
   in this paper was conducted under the research project "Intelligent
   Image Features Extraction in Knowledge Discovery Systems"
   (036-0982560-1643), supported by the Ministry of Science, Education and
   Sports of the Republic of Croatia.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   *ANSI INCITS, 2004, 3852004 ANSI INCITS
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Delac K, 2005, INT J IMAG SYST TECH, V15, P252, DOI 10.1002/ima.20059
   Gao W., 2004, JDLTR04FR001 CAS
   Gross Ralph., 2005, HDB FACE RECOGNITION
   Keval HU, 2008, PROC SPIE, V6982, DOI 10.1117/12.774212
   Klimpak B, 2006, PROCEEDINGS ELMAR-2006, P111, DOI 10.1109/ELMAR.2006.329527
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Turk M., 1991, J COGN NEUROSCI, V3
   Yambor W.S., 2002, Empirical Evaluation Methods in Computer Vision
   Yang XJ, 2008, PROCEEDINGS OF THE 2008 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, P319, DOI 10.1109/NAS.2008.23
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 21
TC 313
Z9 316
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 863
EP 879
DI 10.1007/s11042-009-0417-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100001
DA 2024-07-18
ER

PT J
AU Teixeira, CAC
   Melo, EL
   Cattelan, RG
   Pimentel, MDC
AF Teixeira, Cesar A. C.
   Melo, Erick Lazaro
   Cattelan, Renan G.
   Pimentel, Maria da Graca C.
TI Taking advantage of contextualized interactions while users watch TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital Interactive TV; Capture and access multimedia applications;
   User-media interaction
ID DIGITAL TV; PROGRAM; ARCHITECTURE; TELEVISION; SYSTEM
AB While watching TV, viewers use the remote control to turn the TV set on and off, change channel and volume, to adjust the image and audio settings, etc. Worldwide, research institutes collect information about audience measurement, which can also be used to provide personalization and recommendation services, among others. The interactive digital TV offers viewers the opportunity to interact with interactive applications associated with the broadcast program. Interactive TV infrastructure supports the capture of the user-TV interaction at fine-grained levels. In this paper we propose the capture of all the user interaction with a TV remote control-including short term and instant interactions: we argue that the corresponding captured information can be used to create content pervasively and automatically, and that this content can be used by a wide variety of services, such as audience measurement, personalization and recommendation services. The capture of fine grained data about instant and interval-based interactions also allows the underlying infrastructure to offer services at the same scale, such as annotation services and adaptative applications. We present the main modules of an infrastructure for TV-based services, along with a detailed example of a document used to record the user-remote control interaction. Our approach is evaluated by means of a proof-of-concept prototype which uses the Brazilian Digital TV System, the Ginga-NCL middleware.
C1 [Teixeira, Cesar A. C.; Melo, Erick Lazaro] Univ Fed Sao Carlos, Dept Computacao, BR-13565905 Sao Carlos, SP, Brazil.
   [Cattelan, Renan G.] Univ Fed Uberlandia, Fac Computacao, BR-38400902 Uberlandia, MG, Brazil.
   [Pimentel, Maria da Graca C.] Univ Sao Paulo, Inst Ciencias Matemat & Computacao, BR-13560970 Sao Carlos, SP, Brazil.
C3 Universidade Federal de Sao Carlos; Universidade Federal de Uberlandia;
   Universidade de Sao Paulo
RP Teixeira, CAC (corresponding author), Univ Fed Sao Carlos, Dept Computacao, Via Washington Luiz Km 235,Caixa Postal 676, BR-13565905 Sao Carlos, SP, Brazil.
EM cesar@dc.ufscar.br; erick_melo@dc.ufscar.br; renan@facom.ufu.br;
   mgp@icmc.usp.br
RI Pimentel, Maria G C/D-2875-2009; Akalugwu, Kenneth/F-4815-2014
OI Pimentel, Maria G C/0000-0001-8264-5811; Cattelan,
   Renan/0000-0001-9993-8469
FU CAPES; CNPq; FAPESP; FINEP; MCT/RNP/CTIC
FX This work was supported by CAPES, CNPq, FAPESP, FINEP and MCT/RNP/CTIC
   grants.
CR Abowd G. D., 2002, IEEE Pervasive Computing, V1, P48, DOI 10.1109/MPRV.2002.993144
   Adar E., 2007, WWW '07, P161, DOI DOI 10.1145/1242572.1242595
   Alvarez F, 2009, IEEE T BROADCAST, V55, P502, DOI 10.1109/TBC.2008.2012040
   [Anonymous], 2004, IEEE STAND LOC ME 16
   [Anonymous], 2007, J BRAZ COMPUT SOC
   Baluja S, 2008, WORLD WID WEB C, P895
   *BARBE, 2009, BROADC AUD RES BOARD
   Blanco-Fernández Y, 2008, SOFTWARE PRACT EXPER, V38, P925, DOI 10.1002/spe.855
   BULTERMAN DCA, 2003, P 2003 ACM S DOC ENG, P32
   Cattelan RG, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412201
   CESAR P, 2007, EURO ITV, P11, DOI DOI 10.1007/978-3-540-72559-6_2
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   Cesar P, 2009, MULTIMEDIA SYST, V15, P127, DOI 10.1007/s00530-009-0159-z
   Chen Wen-Yen., 2009, WWW 09, P681
   Das Abhinandan S, 2007, P 16 INT C WORLD WID, P271
   De Pessemier T, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P133
   *DIG, 2008, ORC INT RUW INTR FIN
   ENGEBRETSON J, 2006, FINGERPRINT BASED RE
   FAGA R, 2009, 27 ACM INT C DES COM, P1
   FERSCHA A, 2007, P 2 INT C INT TECHN, P1
   Fuxman Ariel, 2008, Proceedings of the 17th International Conference on World Wide Web (WWW'08), P61
   Hara Y, 2004, USER MODEL USER-ADAP, V14, P87, DOI 10.1023/B:USER.0000010139.95184.df
   HARADA T, 2001, Patent No. 2001091057
   Hauglid JO, 2008, MULTIMED TOOLS APPL, V40, P183, DOI 10.1007/s11042-008-0204-5
   Hofmann C, 2009, LECT NOTES COMPUT SC, V5621, P33, DOI 10.1007/978-3-642-02774-1_4
   Hsu SH, 2007, LECT NOTES COMPUT SC, V4471, P166
   Hwang MC, 2007, IEEE T CONSUM ELECTR, V53, P218, DOI 10.1109/TCE.2007.339528
   *IBOPE, 2004, METH TV AUD RES
   *IBOPE, 2007, METH TV
   *ITEG, 2009, INT COMP TEL TV RES
   Jansen J, 2009, MULTIMED TOOLS APPL, V43, P203, DOI 10.1007/s11042-009-0270-3
   Kientz JA, 2007, IEEE PERVAS COMPUT, V6, P28, DOI 10.1109/MPRV.2007.18
   Kim S., 2009, P FUELCELL2009, P1
   KIM SH, 2004, CHI 04 HUM FACT COMP, P1548
   Macedo AA, 2008, MULTIMED TOOLS APPL, V37, P93, DOI 10.1007/s11042-007-0131-x
   MANKOVITZ RJ, 1996, Patent No. 5541738
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   Maybury M, 2004, USER MODEL USER-ADAP, V14, P119, DOI 10.1023/B:USER.0000010142.18921.eb
   NIELSEN J, 2009, NIELSEN MEDIA RES OU
   NORES ML, 2009, MULTIMED TOOLS APPL, V41, P407
   O'Sullivan D, 2004, USER MODEL USER-ADAP, V14, P5, DOI 10.1023/B:USER.0000010131.72217.12
   PATEL M, 2008, UXTV 08, P95
   PHILOMIN V, 2001, Patent No. 2003050770
   Pimentel MDC, 2007, IEEE PERVAS COMPUT, V6, P93
   Pimentel MDC, 2010, HUM-COMPUT INT-SPRIN, P349, DOI 10.1007/978-1-84882-701-1_23
   PIMENTEL MGC, 2008, IEEE PERVAS COMPUT, V6, P60
   Richardson M, 2008, ACM T WEB, V2, DOI 10.1145/1409220.1409224
   *SBTVD, 2006, BRAZ DIG TV SYST REF
   SCHMITZ P, 2006, ACM MULTIMEDIA, P797
   SHAMMA DA, 2008, CHI EXTENDED ABSTRAC, P2931
   Spertus Ellen, 2005, Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, P678, DOI DOI 10.1145/1081870.1081956
   TEIXEIRA CAC, 2009, SAC 10
   TEIXEIRA CAC, 2009, SAC 09, P1829
   *TEL AUSTR, 2009, REM CONTR VIA FING
   Truong K.N., 2001, 3 INT C UBIQUITOUS C, P209, DOI DOI 10.1007/3-540-45427-6_17
   VILDJIOUNAITE E, 2008, P EUROLTV 2008 C, P82
   Vildjiounaite E, 2009, MULTIMEDIA SYST, V15, P143, DOI 10.1007/s00530-009-0157-1
   WITTENBURG K, 2006, AVI 06, P352
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
   Zhang HG, 2005, IEEE T CONSUM ELECTR, V51, P731, DOI 10.1109/TCE.2005.1468026
NR 60
TC 3
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 587
EP 607
DI 10.1007/s11042-010-0481-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100008
DA 2024-07-18
ER

PT J
AU Chu, WT
   Tsai, WH
AF Chu, Wei-Ta
   Tsai, Wen-Ho
TI Modeling spatiotemporal relationships between moving objects for event
   tactics analysis in tennis videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Tactics analysis; Spatiotemporal modeling; Tennis video
   analysis
ID FEATURES
AB Evolution of spatial relationships between objects often provides important clues for semantic video analysis. We present a symbolic representation that describes spatiotemporal characteristics and facilitates tactics detection based on string matching. To find typical spatiotemporal patterns of a targeted tactic, we organize training sequences as a tree, and effectively discover frequent patterns from the structure. Tactics detection is conducted by comparing a given test sequence with these frequent patterns. To realize the proposed idea, we develop elaborate audio/video processes to transform broadcasting tennis videos into symbolic sequences, and comprehensively tackle event detection and tactics analysis. We experiment on ten most important tennis championships in the year 2008, and report promising detection results on seven events/tactics. We demonstrate not only the effectiveness of the proposed methods, but also study the impacts brought by the results of tactics analysis.
C1 [Chu, Wei-Ta; Tsai, Wen-Ho] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wtchu@cs.ccu.edu.tw; tsaiwenho@gmail.com
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU National Science Council of ROC [NSC 96-2218-E-194-005,
   97-2221-E-194-050]
FX This work was partially supported by the National Science Council of ROC
   under NSC 96-2218-E-194-005 and 97-2221-E-194-050. The authors would
   like to thank anonymous reviewers for giving valuable comments, and
   thank Ming-Chun Tien, Yi-Tang Wang, Chen-Wei Chou, Kuei-Yi Hsieh, and
   Ja-Ling Wu for co-developing former version of the system.
CR [Anonymous], 2008, P 2008 INT C CONT IM
   [Anonymous], 2007, P 15 ACM INT C MULTI
   Cai R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P37
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Cheng W.-H., 2003, P 5 ACM SIGMM INT WO, P109, DOI DOI 10.1145/973264.973282
   Choi J., 2008, ACM ICMR, P291
   Chu W. T., 2007, P 20 COMP VIS GRAPH, P541
   Chu WT, 2008, MULTIMED TOOLS APPL, V38, P27, DOI 10.1007/s11042-007-0145-4
   Duan L.Y., 2003, Proc. ACM Int. Conf. Multimedia, P33
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Farin D, 2004, PROC SPIE, V5307, P80
   GALMAR E, 2008, P 1 ICIP WORKSH MULT
   HAN J, 2006, P SPIE C MULT CONT A
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Huang YP, 2009, EXPERT SYST APPL, V36, P9907, DOI 10.1016/j.eswa.2009.01.078
   Kijak E, 2006, MULTIMED TOOLS APPL, V30, P289, DOI 10.1007/s11042-006-0031-5
   Kolonias I, 2004, MACHINE LEARN SIGN P, P615
   LAN DJ, 2004, P PAC RIM C MULT, P306
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   LIU Y, 2005, P IEEE INT C AC SPEE, V2, P421
   Pallavi V, 2008, IEEE T MULTIMEDIA, V10, P794, DOI 10.1109/TMM.2008.922869
   PANTIC M, 2005, P INT C MEAS BEH
   REA N, 2005, P IEEE INT C IM PROC, V3, P1204
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Song XM, 2007, IEEE T IMAGE PROCESS, V16, P3035, DOI 10.1109/TIP.2007.908283
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   TAGAGI S, 2003, P IEEE INT C MULT EX, V2, P461
   *US TENN ASS, 1996, TENN TACT WINN PATT
   WANG HL, 2000, CHIN ANIM QUANRANTIN, V17, P36
   Wang JR, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P102, DOI 10.1109/MMMC.2005.20
   WANG P, 2004, P PAC RIM C MULT, P49
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Xu M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P189
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Zhang D., 2002, ACM Multimedia, P315
   Zhu GY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1629, DOI 10.1109/ICME.2006.262859
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 44
TC 6
Z9 6
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 149
EP 171
DI 10.1007/s11042-009-0363-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900008
DA 2024-07-18
ER

PT J
AU Li, Z
   Fan, JP
AF Li, Zhong
   Fan, Jianping
TI Exploit camera metadata for enhancing interesting region detection and
   photo retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interesting region; Metadata; Image segmentation; Image retrieval;
   Region restricted EM; Contour confidence map; Camera; Photo
ID IMAGE SEGMENTATION; COMPETITION; ALGORITHMS; ATTENTION; FEATURES
AB Photographs taken by human beings differ from the images that taken by a lifeless device, such as a surveillance camera or a visual sensor on a robot, in that human being intentionally shoot photographs to express his/her feeling or photo-realistically record a scene. This creation process is accomplished by adjusting two factors: the setting of parameters on a camera and the position between the camera and the object which he or she is interested in. In this paper, this procedure is learned using the machine learning technique so that what the interest of the photographer is and what the core content of a photo wants to display can be reversely calculated. A photo retrieval system was built upon the category of interesting regions and the metadata is used for help. The research also explore the argument how local or global feature affects the performance of image retrieval. A novel stochastic segmentation algorithm called region restricted EM algorithm was applied in order to construct the interesting regions. Experimental evaluation on over 7000+ photos taken by 200+ different models of cameras with variety of interests has shown the robustness of our technique.
C1 [Li, Zhong; Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Fan, JP (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM zhli@uncc.edu; jfan@uncc.edu
FU Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [0946400] Funding Source: National Science Foundation
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], 1989, Stochastic Complexity in Statistical Inquiry
   BOUTELL M, 2004, IEEE COMP SOC C COMP, V2, P623
   Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009
   Brox T, 2004, LECT NOTES COMPUT SC, V3175, P415
   BROX T, 2003, UNSUPERVISED SEGMENT, P353
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Fred ALN, 2003, IEEE T PATTERN ANAL, V25, P944, DOI 10.1109/TPAMI.2003.1217600
   FUSSENEGGER M, 2006, MULTIPHASE LEVEL SET, V2, P395
   KATO Z, 1999, BAYESIAN COLOR IMAGE, P33018
   Lee TCM, 2000, J AM STAT ASSOC, V95, P259, DOI 10.2307/2669543
   Luo JB, 2005, PATTERN RECOGN, V38, P919, DOI 10.1016/j.patcog.2004.11.001
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   Mansouri AR, 2006, COMPUT VIS IMAGE UND, V101, P137, DOI 10.1016/j.cviu.2005.07.008
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Shyu CR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P30, DOI 10.1109/IVL.1998.694482
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Yang S, 2007, IEEE T CIRC SYST VID, V17, P324, DOI 10.1109/TCSVT.2007.890829
   Zhang ZH, 2003, PATTERN RECOGN, V36, P1973, DOI 10.1016/S0031-3203(03)00059-1
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 32
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 207
EP 233
DI 10.1007/s11042-009-0346-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300004
DA 2024-07-18
ER

PT J
AU Szabó, G
   Veres, A
   Molnár, S
AF Szabo, Geza
   Veres, Andras
   Molnar, Sandor
TI On the impacts of human interactions in MMORPG traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMORPG; Effects of human behavior; Traffic characteristics; DPI
ID SELF-SIMILARITY
AB Game traffic depends on two main factors, the game protocol and the gamers' behavior. Based on a few popular real-time multiplayer games this paper investigates the latter factor showing how a set of typical game phases-e.g., player movement, changes in the environment-impacts traffic on different observation levels. The nature of human behavior has such a high impact on traffic characteristics that it influences the traffic both at a macroscopic-e.g., traffic rate-and at a microscopic-payload content-level. First, by understanding the nature of this impact a user behavior detection algorithm is introduced to grab specific events and states from passive traffic measurements. The algorithms focus on the characteristics of the traffic rate, showing what information can be gathered by observing only packet header information. Second, as an application of our method some results, including a detailed analysis of measurements taken from an operational broadband network, are presented. Third, a novel model and an algorithm are introduced to extend the Deep Packet Inspection traffic classification method with the analysis of non-fix byte signatures, which are not considered in current methods. The model captures the variation of the dynamic byte segments and provides parameters for the algorithm. The introduced algorithm exploits the spatial and temporal correlation by examining and extracting the correlation structure of the traffic and constructing signatures based on the observed correlation. The algorithm is evaluated by examining proprietary gaming traffic and also other known non-gaming protocols.
C1 [Szabo, Geza; Veres, Andras] Ericsson Hungary Ltd, Ericsson Res, Traff Lab, H-1037 Budapest, Hungary.
   [Molnar, Sandor] Budapest Univ Technol & Econ, Highs Speed Networks Lab, Dept Telecommun & Media Informat, H-1117 Budapest, Hungary.
C3 Ericsson; Budapest University of Technology & Economics
RP Szabó, G (corresponding author), Ericsson Hungary Ltd, Ericsson Res, Traff Lab, Laborc U 1, H-1037 Budapest, Hungary.
EM geza.szabo@ericsson.com; andras.veres@ericsson.com; molnar@tmit.bme.hu
RI Molnár, Sándor/G-4667-2015
OI Molnár, Sándor/0000-0002-1601-0815
CR Abry P, 1998, IEEE T INFORM THEORY, V44, P2, DOI 10.1109/18.650984
   [Anonymous], IMC 06
   [Anonymous], 2 LIF
   [Anonymous], 2004, BLIZZ ENT
   ARJONA A, 2008, AICT 08, P143
   Barabási AL, 2005, NATURE, V435, P207, DOI 10.1038/nature03459
   Beigbeder Tom., 2004, NETGAMES 04, P144
   Beran J., 1994, Statistics for Long-Memory Processes, P71
   CHEN K, 2006, ACM SIGCHI ACE 06
   CHEN K, 2005, NOSSDAV 05
   CLAYPOOL M, 2003, IEEE INT PERF COMP C
   *COSS, 2001, CDV SOFTW
   Cricenti AL, 2007, NETGAMES 07, p70 74, DOI [10.1145/1326257.1326270, DOI 10.1145/1326257.1326270]
   Crovella ME, 1997, IEEE ACM T NETWORK, V5, P835, DOI 10.1109/90.650143
   *CRYS, 1993, MMORPG AN COD
   DANIEL DP, 2007, NETGAMES 07, P25
   *EL ARTS, 2003, COMM CONQ GEN
   *EL ARTS, 2007, COMM CONQ 3
   *EV ONL, 2001, CCP
   FERNANDES S, 2007, NOSSDAV 07
   FRITSCH T, 2005, NETGAMES 05
   *GNUT, 2000, NULLS
   *GUILD WARS, 2005, NCSOFT
   Haffner P., 2005, MineNet'05
   *ID SOFTW, 2005, QUAKE4
   Iliofotou M., 2007, Network Traffic Analysis using Traffic Dispersion Graphs
   KARAGIANNIS T, 2005, P ACM SIGCOMM PHIL
   Kim H., 2004, SSYM 04
   KIM J, 2005, NETGAMES 05
   LAKHINA A, 2005, P ACM SIGCOMM PHIL
   LI Z, 2006, SP 2006
   LIANG H, 2008, AVATAR MOBILITY NETW
   *LUA, 1993, LUA PROGR LANG
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   *MATHW, 1983, MATL
   *MICR, 2002, AG MYTH
   *MICR, 1999, MSN MESS
   MOORE AW, 2005, P PAM BOST
   *NETL, 2005, MEAS ONL GAM APPL GP
   Park BC, 2008, IEEE IFIP NETW OPER, P160, DOI 10.1109/NOMS.2008.4575130
   *SILKR ONL, 2005, JOYMAX
   *STAR WARS GALAXIE, 2003, LUCASARTS
   Svoboda P., 2005, Internet And Multimedia Systems And Applications (IASTED)
   SZABO G, 2007, P IEEE WOWMOM HELS
   Szabo G., 2007, IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (Wo WMoM2007), P1
   TAN SA, 2005, NETGAMES 05, P1
   *UNR TOURN 2003, 2002, EP GAM
   VERES A, 2000, ACM SIGCOMM
   Willinger W, 1997, IEEE ACM T NETWORK, V5, P71, DOI 10.1109/90.554723
   Willinger W., 1996, A bibliographical guide to self-similar traffic and performance modeling for modern high-speed networks
   Xu K., 2005, P ACM SIGCOMM
   Yee N., 2003, DAEDALUS PROJECT
   Zander S., 2005, P IEEE LCN
   ZUEV D, 2005, P PAM
NR 54
TC 5
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 133
EP 161
DI 10.1007/s11042-009-0298-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900007
DA 2024-07-18
ER

PT J
AU Zhao, HL
   Jin, XG
   Lu, SF
   Mao, XY
   Shen, JB
AF Zhao, Hanli
   Jin, Xiaogang
   Lu, Shufang
   Mao, Xiaoyang
   Shen, Jianbing
TI AtelierM plus plus : a fast and accurate marbling system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual marbling; Interactive media; Fluid simulation; Graphics
   processing unit
ID GPU; VISUALIZATION
AB We present AtelierM++, a new interactive marbling image rendering system which allows artists to create marbling textures with real-time visual feedback on mega-pixel sized images. Marbling is a method of aqueous surface design, which can produce patterns similar to marble or other stone, hence the name. The system is based on the physical model of the traditional marbling process. We simulate real marbling by solving the Navier-Stokes equations on the graphics processing unit. We employ a third-order accurate but fast Unsplit semi-Lagragian Constrained Interpolation Profile method to reduce the numerical dissipation while retaining the stability. To simulate very sharp interface lines among different paints, a simple yet effective transformation function is applied to the paint concentrations. Several intuitive interfaces are implemented to provide flexible control for users. Extensive experimental results are shown to demonstrate both the effectiveness and efficiency of the proposed approach.
C1 [Zhao, Hanli; Jin, Xiaogang; Lu, Shufang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Mao, Xiaoyang] Univ Yamanashi, Kofu, Yamanashi, Japan.
   [Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Zhejiang University; University of Yamanashi; Beijing Institute of
   Technology
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM hanlizhao@gmail.com; jin@cad.zju.edu.cn; lushufang@cad.zju.edu.cn;
   mao@yamanashi.ac.jp; shenjianbing@bit.edu.cn
RI Shen, Jianbing/U-8796-2019
OI mao, xiaoyang/0000-0001-9531-3197; Shen, Jianbing/0000-0002-4109-8353
FU Science and Technology Plan of Zhejiang Province [2008C24008]; National
   Key Basic Research Foundation of China [2009CB320801]; National Natural
   Science Foundation of China [60833007]; Key Technology R D Program
   [2007BAH11B03]
FX The authors are especially grateful to our anonymous reviewers for their
   insightful and constructive comments. Many thanks also to Xiaoyan Luo
   and Yandan Zhao for their kind help in presenting the manuscript. The
   left pictures in Fig. 1 and the leftmost picture in Fig. 7 are
   downloaded from http://quilting.about.com/. This work was supported by
   the Science and Technology Plan of Zhejiang Province ( Grant No.
   2008C24008), the National Key Basic Research Foundation of China ( Grant
   No. 2009CB320801), the National Natural Science Foundation of China (
   Grant No. 60833007), and the Key Technology R& D Program ( Grant No.
   2007BAH11B03).
CR Acar R, 2006, IEEE T VIS COMPUT GR, V12, P600, DOI 10.1109/TVCG.2006.66
   Acar R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289606
   Akgun BT, 2004, LEONARDO, V37, P49, DOI 10.1162/002409404772828120
   [Anonymous], P ACM SIGGRAPH EUROG
   [Anonymous], 2008, NVIDIA CUDA COMP UN
   [Anonymous], ULTIMATE MARBLING HD
   BLYTHE D, 2006, P ACM SIGGRAPH, P724
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Cabral B., 1993, P 20 ANN C COMP GRAP, P263, DOI DOI 10.1145/166117.166151
   Fan Z, 2008, COMPUT GRAPH FORUM, V27, P341, DOI 10.1111/j.1467-8659.2008.01131.x
   Harris M., 2007, GPU GEMS, V3, P851
   HARRIS MJ, 2004, GPU GEMS, V38, P637
   Jin XG, 2007, IEEE COMPUT GRAPH, V27, P78, DOI 10.1109/MCG.2007.28
   Kim B, 2007, IEEE T VIS COMPUT GR, V13, P135, DOI 10.1109/TVCG.2007.3
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   MAO X, 2003, P 1 INT C COMP GRAPH, P79
   Morimoto Y, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P57, DOI 10.1109/PG.2007.51
   Orzan A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360691
   Packer R, 1999, IEEE MULTIMEDIA, V6, P11, DOI 10.1109/93.752965
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   SUZUKI T, 2001, P IASTED INT C VIS I, P208
   Weiskopf D, 2004, COMPUT GRAPH FORUM, V23, P479, DOI 10.1111/j.1467-8659.2004.00779.x
   *WIK FDN INC, 2008, SINC FILT
   Xu JY, 2008, IEEE COMPUT GRAPH, V28, P35, DOI 10.1109/MCG.2008.36
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
NR 28
TC 9
Z9 11
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 187
EP 203
DI 10.1007/s11042-009-0290-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100002
DA 2024-07-18
ER

PT J
AU de Mello, RF
   Goularte, R
   Dodonov, E
   Yang, L
   Park, J
   Kim, TH
AF de Mello, Rodrigo Fernandes
   Goularte, Rudinei
   Dodonov, Evgueni
   Yang, Laurence T.
   Park, Jong Hyuk
   Kim, Tai-hoon
TI On modeling and evaluating multicomputer transcoding architectures for
   live-video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live video; Transcoding; Multimedia
ID ADAPTATION
AB The pervasive and ubiquitous computing has motivated researches on multimedia adaptation which aims at matching the video quality to the user needs and device restrictions. This technique has a high computational cost which needs to be studied and estimated when designing architectures and applications. This paper presents an analytical model to quantify these video transcoding costs in a hardware independent way. The model was used to analyze the impact of transcoding delays in end-to-end live-video transmissions over LANs, MANs and WANs. Experiments confirm that the proposed model helps to define the best transcoding architecture for different scenarios.
C1 [de Mello, Rodrigo Fernandes; Goularte, Rudinei; Dodonov, Evgueni] Univ Sao Paulo, Dept Comp Sci, Inst Math & Comp Sci, Sao Paulo, Brazil.
   [Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 1C0, Canada.
   [Park, Jong Hyuk] Kyungnam Univ, Masan, South Korea.
   [Kim, Tai-hoon] Hannam Univ, Taejon, South Korea.
C3 Universidade de Sao Paulo; Saint Francis Xavier University - Canada;
   Kyungnam University; Hannam University
RP de Mello, RF (corresponding author), Univ Sao Paulo, Dept Comp Sci, Inst Math & Comp Sci, Sao Paulo, Brazil.
EM mello@icmc.usp.br; rudinei@icmc.usp.br; eugeni@icmc.usp.br;
   lyang@stfx.ca; jhpark1@kyungnam.ac.kr; taihoonn@ewha.ac.kr
RI Laurence T. Yang, FCAE/AAA-1898-2019; Mello, Rodrigo F/E-6397-2011;
   Goularte, Rudinei/E-2441-2011
OI Laurence T. Yang, FCAE/0000-0002-7986-4244; Fernandes de Mello,
   Rodrigo/0000-0002-0435-3992; Goularte, Rudinei/0000-0003-1531-1576
FU CAPES, Brazil [032506-6]; FAPESP, Brazil
FX This paper is based upon work supported by CAPES, Brazil under grant no.
   032506-6 and FAPESP, Brazil. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of the CAPES or FAPESP.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   Cheng X, 2007, P 7 ACM SIGCOMM C IN, P1
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   Culler David., 1993, P 4 ACM SIGPLAN S PR, P1
   DEMELLO RF, 2006, 7 INT M HIGH PERF CO, P1
   Dogan S, 2002, IEEE T CIRC SYST VID, V12, P453, DOI 10.1109/TCSVT.2002.800308
   DOGAN S, 2004, 5 WORKSH IM AN MULT
   HUANG J, 2003, P IEEE C ADV VID SIG
   Kim T, 2003, IEEE INFOCOM SER, P641
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Liu JC, 2004, IEEE T MULTIMEDIA, V6, P87, DOI 10.1109/TMM.2003.819753
   Rejaie R, 2000, IEEE J SEL AREA COMM, V18, P2530, DOI 10.1109/49.898735
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   SHEFLER WC, 1988, STAT CONCEPTS APPL
   SHEN B, 2002, INTERNET MULTIMEDIA, P360
   Wu DP, 2001, P IEEE, V89, P6, DOI 10.1109/5.904503
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2009
VL 43
IS 2
BP 109
EP 129
DI 10.1007/s11042-009-0259-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 430WI
UT WOS:000265021100001
DA 2024-07-18
ER

PT J
AU Barlas, G
   El-Fakih, K
AF Barlas, Gerassimos
   El-Fakih, Khaled
TI A GA-based movie-on-demand platform using multiple distributed servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple servers; Multiple clients; Genetic algorithms; Movie on demand;
   Divisible load
ID VIDEO SERVERS; DELIVERY
AB In this paper we present the design and explore the performance of a unicast-based distributed system for Movie-on-Demand applications. The operation of multiple servers is coordinated with the assistance of an analytical framework that provides closed-form solutions to the content partitioning and scheduling problem, even under the presence of packet losses. The problem of mapping clients to servers is solved with a genetic algorithm, that manages to provide adequate, near-optimum solutions with a minimum of overhead. While previous studies focused on the static behavior of such a system, i.e. fixed a-priori known number of N servers and K clients commencing operation at the same time instance, this paper focuses on the dynamic behavior of such a system over a period of time with clients coming and going at random intervals. The paper includes a rigorous simulation study that shows how the system behaves in terms of a variety of metrics, including the average access time over all the requested media, in response to differences in the client arrival rate or the consumed server bandwidth. As it is shown, the proposed platform exhibits excellent performance characteristics that surpass traditional approaches that treat clients individually. This has been verified to be true up to extreme system loads, proving the scalability of the proposed content delivery scheme. The significance of our findings also stems from the assumption of unreliable communications, a first for the study of complete systems in this domain.
C1 [Barlas, Gerassimos; El-Fakih, Khaled] Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
C3 American University of Sharjah
RP Barlas, G (corresponding author), Amer Univ Sharjah, Dept Comp Sci & Engn, POB 26666, Sharjah, U Arab Emirates.
EM gbarlas@aus.edu; kelfakih@aus.edu
RI Barlas, Gerassimos/AAI-5943-2021
OI Barlas, Gerassimos/0000-0002-9792-9638
CR Baker J.E., P INT C GEN ALG THEI, P101
   Barlas G, 2005, J PARALLEL DISTR COM, V65, P1057, DOI 10.1016/j.jpdc.2005.04.001
   Barlas G, 2005, IEEE T PARALL DISTR, V16, P982, DOI 10.1109/TPDS.2005.125
   Barlas G, 2004, LECT NOTES COMPUT SC, V3271, P282
   BARLAS G, 2002, ISCA PDCS 2002 P LOU, P13
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   Dong LG, 2003, MULTIMED TOOLS APPL, V20, P99, DOI 10.1023/A:1023654818590
   ERIKSSON H, 1994, COMMUN ACM, V37, P54, DOI 10.1145/179606.179627
   Furht B, 1998, IEEE MULTIMEDIA, V5, P78, DOI 10.1109/93.735871
   Gen M., 2000, Genetic Algorithms and Engineering Optimization
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288
   Lee JYB, 1998, IEEE MULTIMEDIA, V5, P20, DOI 10.1109/93.682522
   Lee KF, 2002, EURASIP J APPL SIG P, V2002, P507, DOI 10.1155/S111086570200080X
   Miettinen K., 1999, Evolutionary Algorithms in Engineering and Computer Science: Recent Advances in Genetic Algorithms, Evolution Strategies, Evolutionary Programming
   Milton J.S., 1995, INTRO PROBABILITY ST
   RODRIGUEZ P, 2000, P INF TEL AV MARCH 2
   STOCKINGER H, 2002, J CLUSTER COMPUTING, V5, P305
   Veeravalli B, 2000, MULTIMED TOOLS APPL, V12, P235, DOI 10.1023/A:1009623825393
   Veeravalli B., 2006, DISTRIBUTED MULTIMED
   Veeravalli B, 2007, MULTIMED TOOLS APPL, V32, P1, DOI 10.1007/s11042-006-0052-0
NR 21
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 361
EP 383
DI 10.1007/s11042-008-0211-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700003
DA 2024-07-18
ER

PT J
AU Boronat, F
   Guerri, JC
   Lloret, J
AF Boronat Segui, Fernando
   Guerri Cebollada, Juan Carlos
   Lloret Mauri, Jaime
TI An RTP/RTCP based approach for multimedia group and inter-stream
   synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; group synchronization; inter-stream synchronization;
   RTP/RTCP
ID MEDIA SYNCHRONIZATION; FEEDBACK TECHNIQUES; SYSTEMS; CONTINUITY
AB Most multimedia group and inter-stream synchronization techniques define or use proprietary protocols with new control messages. Many multimedia applications have been developed using RTP/RTCP as the standard for transmission of multimedia streams over IP networks. Instead of defining a new protocol, we propose the use of RTP/RTCP to provide synchronization. We take advantage of the feedback capabilities provided by RTCP and the ability to extend the protocol by extending and creating RTCP messages containing synchronization information. We have implemented our proposal and tested it in our University WAN. Our experiments have shown that network load resulting from synchronization is minimized and that asynchronies are within acceptable limits for multimedia applications.
C1 [Boronat Segui, Fernando; Lloret Mauri, Jaime] Univ Politecn Valencia, Escuela Politecn Super Gandia, Valencia 46730, Spain.
   [Guerri Cebollada, Juan Carlos] Univ Politecn Valencia, Escuela Tecn Super Ingn Telecomunicac, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Boronat, F (corresponding author), Univ Politecn Valencia, Escuela Politecn Super Gandia, Ctra Nazaret Oliva S-N, Valencia 46730, Spain.
EM fboronat@dcom.upv.es; jcguerri@dcom.upv.es; jlloret@dcom.upv.es
RI Lloret, Jaime/H-3994-2013; Boronat, Fernando/A-3234-2011
OI Lloret, Jaime/0000-0002-0862-0533; Boronat, Fernando/0000-0001-5525-3441
CR Akyildiz IF, 1996, IEEE J SEL AREA COMM, V14, P162, DOI 10.1109/49.481702
   BORONAT F, 2004, THESIS POLYTECHNIC U
   BORONAT F, 2005, IEEE LAT AM T, V3
   Boukerche A, 2005, MOBILE NETW APPL, V10, P233, DOI 10.1023/B:MONE.0000048557.95522.da
   BURMEISTER C, 2006, 4586 RFC
   Diot C, 1999, IEEE NETWORK, V13, P6, DOI 10.1109/65.777437
   GILI J, 1995, TELEF R D COMMUN, V6, P20
   Guerri JC, 2001, MULTIMED TOOLS APPL, V13, P307, DOI 10.1023/A:1009633314583
   GUERRI JC, 1997, THEIS U P V
   Ishibashi Y, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P106, DOI 10.1109/HAPTIC.2004.1287184
   Ishibashi Y, 2002, IEICE T COMMUN, VE85B, P812
   ITU-R Recommendation BT, 2002, METH SUBJ ASS QUAL T
   KANEOKA H, 2004, P 14 INT C ART REAL, P138
   Kouvelas I., 1997, Proceedings of the USENIX 1997 Annual Technical Conference, P235
   KOUVELAS Y, 1996, LIP SYNCHRONIZATION
   KUTSCHER D, 2000, MESSAGE BUS COMMUNIC
   Laoutaris N, 2002, IEEE NETWORK, V16, P30, DOI 10.1109/MNET.2002.1002997
   Manvi SS, 2006, J SYST SOFTWARE, V79, P701, DOI 10.1016/j.jss.2005.08.010
   MCCANNE S, 1995, VIC LEXIBLE FRAMEWOR, P511
   MILLS DL, 1991, IEEE T COMMUN, V39, P1482, DOI 10.1109/26.103043
   OTT J, 2006, 4585 RFC RTPAVPF NET
   RAMANATHAN S, 1993, COMPUT J, V36, P19, DOI 10.1093/comjnl/36.1.19
   RANGAN PV, 1995, ACM T INFORM SYST, V13, P145, DOI 10.1145/201040.201044
   RANGAN PV, 1995, COMPUT NETWORKS ISDN, V27, P549, DOI 10.1016/0169-7552(93)E0112-R
   RANGAN PV, 1992, IEEE COMMUN MAG, V30, P56, DOI 10.1109/35.144778
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   SCHULZRINNE H, 2003, 3550 RFC RTP
   *SPAN AC RES NETW, RED IRIS
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   YAVATKAR R, 1994, MULTIMEDIA SYSTEMS, V2, P74
NR 30
TC 18
Z9 27
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 285
EP 319
DI 10.1007/s11042-008-0208-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200006
DA 2024-07-18
ER

PT J
AU Jeong, J
AF Jeong, Jinguk
TI Play segmentation for the play-break based sports video using a local
   adaptive model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video structuring; video indexing; video segmentation; play
   segmentation; video summarization
ID HIGHLIGHTS
AB This paper proposes a new play segmentation algorithm using a local adaptive model for each sports game, in which the play start shots (PSS) that represent the start of each play segment are detected by comparing all of keyframes with the PSS model. The PSS model is calculated on the fly using generic clustering algorithm and a repetitive characteristic of the PSS. The end of each play segment (the play end shot (PES)) is determined by detecting close up shots using the field color extracted from the play start shots since the camera will focus on the players or the audience with close up view. Experimental results with 28 baseball videos show that good performance can be obtained with the proposed algorithm compared to other algorithms.
C1 Samsung Adv Inst Technol, Gyunggi Do, South Korea.
C3 Samsung
RP Jeong, J (corresponding author), Samsung Adv Inst Technol, Gyunggi Do, South Korea.
EM burinist@chol.com
CR [Anonymous], THESIS PACE U
   BAOXIN L, 2001, IEEE WORKSH CONT BAS, P132
   Chang P, 2002, IEEE IMAGE PROC, P609
   Ekin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P173
   GU L, 2004, P PAC RIM C MULT DEC, P57
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Hua W, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P821, DOI 10.1109/ICME.2002.1035908
   KONGWAH W, 2006, P INT C MULT EXP JUL, P1893
   REN R, 2005, P EUR C INF RETR MAR, P433
   Shen K, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB252
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Wang DH, 2004, IEEE IMAGE PROC, P2247
   YAMADA A, 2001, JTCISC29WG11N3914
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Zhang Lei, 1999, Proceedings of IEEE. IEEE Region 10 Conference. TENCON 99. `Multimedia Technology for Asia-Pacific Information Infrastructure' (Cat. No.99CH37030), P166, DOI 10.1109/TENCON.1999.818376
   ZHONG D, 2001, P IEEE INT C MULT EX, P713
NR 18
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 149
EP 167
DI 10.1007/s11042-008-0199-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400002
DA 2024-07-18
ER

PT J
AU Hui, SC
   Lee, JYB
AF Hui, S. C.
   Lee, Jack Y. B.
TI On aggregate available bandwidth in many-to-one data transfer-modeling
   and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE multi-sender transmission; bandwidth modeling; internet measurement;
   multi-source streaming
AB This work investigates the modeling of aggregate available bandwidth in multi-sender network applications. Unlike the well-established client-server model, where there is only one server sending the requested data, the available bandwidth of multiple senders when combined together does exhibit consistent properties and thus can be modeled and estimated. Through extensive experiments conducted in the Internet this work proposed to model the aggregate available bandwidth using a normal distribution and then illustrates its application through a hybrid download-streaming algorithm and a playback-adaptive streaming algorithm for video delivery under different bandwidth availability scenarios. This new multi-source bandwidth model opens a new way to provide probabilistic performance guarantee in best-effort networks such as the Internet, and is particularly suitable for the emerging peer-to-peer applications, where having multiple sources is the norm rather than the exception.
C1 Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Lee, JYB (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.
EM jacklee@computer.org
RI Lee, Yiu Bun/G-3743-2011; Lee, Jack/P-7331-2019
OI Lee, Yiu Bun/0000-0002-3583-6428; Lee, Jack/0000-0002-4584-929X
CR AGARWAL V, 2005, S C MULT COMP NETW S
   [Anonymous], 2003, 3448 RFC
   GOLUBCHIK L, 1995, ACM SIGMETRICS PERFO
   Hahn GeraldJ., 1994, STAT MODELS ENG
   Lam LS, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P346
   Liang YJ, 2001, INT CONF ACOUST SPEE, P1445, DOI 10.1109/ICASSP.2001.941202
   LIANG YQ, 2002, IEEE INT S CIRC SYST, V4, P719
   Morin PR, 1995, CITESEER
   MORRIS R, 2000, INFOCOM 2000 19 ANN, V1, P360
   NGUYEN T, 2002, SPIE C MULT COMP NET
   Park K, 1996, 1996 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P171, DOI 10.1109/ICNP.1996.564935
   PARK K, 1997, SPIE INT C PERF CONT, P296
   Paxson V., 1995, FAST APPROXIMATION S
   Reibman A. R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P837, DOI 10.1109/ICIP.1999.817248
   SETTON E, 2003, INT C MULT EXP BALT, V1, P509
   TUAN T, 1998, 98014 CSDTR PURD U
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
NR 17
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 139
EP 154
DI 10.1007/s11042-006-0088-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700002
DA 2024-07-18
ER

PT J
AU Zhang, WL
   Wu, XM
   Kamijo, S
   Sakauchi, M
AF Zhang, Wenli
   Wu, Xiaomeng
   Kamijo, Shunsuke
   Sakauchi, Masao
TI Semantic video database system with semi-automatic secondary-content
   generation capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video database; multimedia applications; semantic video content
   extraction; object-based annotation; object-based query; semantic video
   system; region-based model matching; ontological object model; object
   extraction and annotation; object-based interactive applications
ID RETRIEVAL; ANNOTATION
AB A semantic video database system, based on an interactive approach that maps low-level features to high-level concepts, is proposed. A database of ontological semantic object models allows the user to get information about specific semantic objects, such as certain actors or other features of a TV drama. The system searches the database for key frames within the video to detect similarities in detailed or "low-level" features, such as the color, area, and position of a specific part of the frame. Since image recognition techniques are limited in their ability to fully identify and compare images, we propose an additional function in which a coarse model is used to recover a greater number of similar key frames, thus providing more relevant results. From these results, the content provider can select relevant key frames interactively; the matched objects in them are then automatically annotated according to descriptions that are added into the model by content provider. Therefore, more complex content can be generated with greater accuracy by using a combination of application-oriented operations. The system has high potential for use in object-based interactive multimedia applications. We also present an object-based video content generation application called the Drama Characters' Popularity Voting System.
C1 Matsushita Elect Ind Co Ltd, Osaka 5718501, Japan.
   Univ Tokyo, Inst Ind Sci, Dept 3, Sakauchi Lab, Tokyo, Japan.
C3 Panasonic; University of Tokyo
RP Zhang, WL (corresponding author), Matsushita Elect Ind Co Ltd, 1006 Oaza Kadoma, Osaka 5718501, Japan.
EM zhang.wenli@jp.panasonic.com
CR Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   AGUIERRESMITH TG, 1992, P 3 INT WORKSH NETW
   [Anonymous], P IEEE COMP SOC C CO
   ARDIZZONE GD, 1997, BIOL MAR MEDIT, V4, P1
   Bargeron D, 1999, COMPUT NETW, V31, P1139, DOI 10.1016/S1389-1286(99)00058-4
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Hacid MS, 2000, IEEE T KNOWL DATA EN, V12, P729, DOI 10.1109/69.877505
   HAUPTMANN A, 2002, TEXT RETR C TREC 02
   HSIEH JW, 2000, REGION BASED IMAGE R
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Liu Y, 2002, MULTIMED TOOLS APPL, V17, P5, DOI 10.1023/A:1014614221234
   Mehtre BM, 1998, INFORM PROCESS MANAG, V34, P109, DOI 10.1016/S0306-4573(97)00049-6
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   OSAWA Y, 1990, P 6 INT C DAT ENG, P296
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SMITH JR, 1996, ACM MULTIMEDIA 96
   Trans D. A., 2000, Database and expert systems applications. 11th International Conference, DEXA 2000. Proceedings (Lecture Notes in Computer Science Vol.1873), P41
   TSUNETOSHI N, 2002, P 9 WORLD C ITS
   YOON J, 2001, RELEVANT FEEDBACK SE
   Zhang WL, 2002, LECT NOTES COMPUT SC, V2532, P261
   1998, ISOIECJTC1SC29WG11N2
NR 24
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2006
VL 30
IS 1
BP 27
EP 54
DI 10.1007/s11042-006-0007-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CF
UT WOS:000240363400002
DA 2024-07-18
ER

PT J
AU Dönderler, ME
   Saykol, E
   Arslan, U
   Ulusoy, Ö
   Güdükbay, U
AF Dönderler, ME
   Saykol, E
   Arslan, U
   Ulusoy, Ö
   Güdükbay, U
TI BilVideo:: Design and implementation of a video database management
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video databases; multimedia databases; information systems;
   content-based retrieval; spatiotemporal relations; spatio-temporal query
   processing; video query languages
ID RETRIEVAL
AB With the advances in information technology, the amount of multimedia data captured, produced, and stored is increasing rapidly. As a consequence, multimedia content is widely used for many applications in today's world, and hence, a need for organizing this data, and accessing it from repositories with vast amount of information has been a driving stimulus both commercially and academically. In compliance with this inevitable trend, first image and especially later video database management systems have attracted a great deal of attention, since traditional database systems are designed to deal with alphanumeric information only, thereby not being suitable for multimedia data.
   In this paper, a prototype video database management system, which we call BilVideo, is introduced. The system architecture of BilVideo is original in that it provides full support for spatio-temporal queries that contain any combination of spatial, temporal, object-appearance, external-predicate, trajectory-projection, and similarity-based object-trajectory conditions by a rule-based system built on a knowledge-base, while utilizing an object-relational database to respond to semantic (keyword, event/activity, and category-based), color, shape, and texture queries. The parts of BilVideo (Fact-Extractor, Video-Annotator, its Web-based visual query interface, and its SQL-like textual query language) are presented, as well. Moreover, our query processing strategy is also briefly explained.
C1 Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
EM mdonder@cs.bilkent.edu.tr; ediz@cs.bilkent.edu.tr;
   aumut@cs.bilkent.edu.tr; oulusoy@cs.bilkent.edu.tr;
   gudukbay@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011; Saykol, Ediz/AAF-6251-2020; Ulusoy,
   Ozgur/KVY-4530-2024
OI Gudukbay, Ugur/0000-0003-2462-6959; Saykol, Ediz/0000-0002-8950-5114;
   Ulusoy, Ozgur/0000-0002-6887-3778
CR Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], IEEE COMPUT
   [Anonymous], 1998, INT S ADV GEOGRAPHIC
   ARSLAN U, 2002, P WORKSH MULT SEM SO, P1
   ARSLAN U, 2002, THESIS BILKENT U ANK
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Catarci T, 2003, IEEE MULTIMEDIA, V10, P66, DOI 10.1109/MMUL.2003.1167924
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Chen SC, 2001, IEEE T KNOWL DATA EN, V13, P607, DOI 10.1109/69.940735
   Dönderler ME, 2004, VLDB J, V13, P86, DOI 10.1007/s00778-003-0114-0
   Dönderler ME, 2002, INFORM SCIENCES, V143, P13, DOI 10.1016/S0020-0255(02)00172-X
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   GAUCH S, 2000, ENCY LIB INFORMA S31, V68
   Hacid MS, 2000, IEEE T KNOWL DATA EN, V12, P729, DOI 10.1109/69.877505
   Hauptmann AlexanderG., 1997, Informedia: news-on-demand multimedia information acquisition and retrieval, P215
   Hjelsvold Rune., 1994, VLDB 94 P 20 INT C V, P686
   Hwang EJ, 1996, J VIS COMMUN IMAGE R, V7, P44, DOI 10.1006/jvci.1996.0005
   Kuo TCT, 2000, IEEE T MULTIMEDIA, V2, P1, DOI 10.1109/6046.825790
   Li Jinming, 1996, P 1996 MULT MOD INT, P119
   Li JZ, 1996, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS, PROCEEDINGS, P124, DOI 10.1109/MMDBMS.1996.541863
   LI JZ, 1997, P 4 INT C MULT MOD, P69
   LI JZ, 1997, TR9701 U ALB DEP COM
   LI JZ, 1997, P MULT COMP NETW MMC, P80
   LI JZ, 1998, TR9805 U ALB DEP COM
   Liu Y, 2002, MULTIMED TOOLS APPL, V17, P5, DOI 10.1023/A:1014614221234
   Marcus S, 1996, J ACM, V43, P474, DOI 10.1145/233551.233554
   MARKOVIC S B, 1996, THEORY MULTIMEDIA DA, P1
   MARTINEZ J, 2001, N4509 ISOIEC
   Nabil M, 2001, MULTIMED TOOLS APPL, V13, P35, DOI 10.1023/A:1009677223697
   Nascimento MarioA., 1998, Symposium on Applied Computing (SAC), P235, DOI [DOI 10.1145/330560.330692, 10.1145/330560.330692]
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   OZSU MT, 1997, P ACM MULT SEATTL 9, P233
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   SAYKOL E, 2001, 7 WORKSH MULT INF SY, P11
   SAYKOL E, 2001, THESIS BILKENT U ANK
   SAYKOL E, 2002, BUCE0201 BILK U DEP
   Sistla AP, 2000, J AUTOM REASONING, V25, P291, DOI 10.1023/A:1006322417869
   SISTLA AP, 1995, P 21 INT C VER LARG, P619
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   THEODORIDIS Y, 1996, P 3 IEEE C MULT COMP
   THEODORIDIS Y, 1999, LNCS SERIES
   Ünel G, 2004, J SYST SOFTWARE, V73, P113, DOI 10.1016/S0164-1212(03)00215-2
   Veltkamp Remco C., 2000, UUCS200034
   WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773
   Xu X., 1990, P 4 INT S SPATIAL DA, P1040
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
NR 47
TC 33
Z9 43
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 79
EP 104
DI 10.1007/s11042-005-2715-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nitta, N
   Babaguchi, N
   Kitahashi, T
AF Nitta, N
   Babaguchi, N
   Kitahashi, T
TI Generating semantic descriptions of broadcasted sports videos based on
   structures of sports games and TV programs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video content analysis; broadcasted sports video; closed-caption;
   intermodal collaboration; MPEG-7
AB This paper presents a model to represent a broadcasted sports video in a semantic way and proposes a method of automatically generating semantic descriptions of significant scenes. Representation of a video should clarify the semantic content of the video as accurately as possible. Our model structurizes the video and specifies suitable semantic descriptions for video segments paying attention to the structure of both a sports game and a sports TV program. As the elements of these semantic descriptions, the proposed method tries to obtain the information about the plays and their related players from the closed-caption stream by searching key phrases. Finding the corresponding segments of the video by means of template matching for the image stream attaches these textual descriptions to the proper portion of the video. In this paper, we discuss some experimental results of our method and the potentiality for integrating these results into the standardized MPEG-7 description tools.
C1 Osaka Univ, Dept Commun Engn, Suita, Osaka 5650871, Japan.
   Kwansei Gakuin Univ, Dept Informat, Sanda, Hyogo 6691337, Japan.
C3 Osaka University; Kwansei Gakuin University
RP Nitta, N (corresponding author), Osaka Univ, Dept Commun Engn, 2-1 Yamada Oka, Suita, Osaka 5650871, Japan.
EM naoko@comm.eng.osaka-u.ac.jp; babaguchi@comm.eng.osaka-u.ac.jp;
   kt@ksc.kwansei.ac.jp
CR Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   BENITEZ AB, LECT NOTES COMPUTER
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chang YL, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P306, DOI 10.1109/MMCS.1996.534992
   HUANG Q, 1999, P IEEE INT C AC SPEE, V6, P3025
   LAZARESCU M, 1999, P IEEE ICMCS 99, V1, P802
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   MANI I, 1997, INTELLIGENT MULTIMED, P241
   *MPEG MDS GROUP, 2001, JTC1SC29WG11MPEG01M7
   Nakamura Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P393, DOI 10.1145/266180.266391
   Nitta N, 2000, INT C PATT RECOG, P718
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   XU P, 2001, P IEEE INT C MULT EX, P928
   ZHONG D, 2001, P IEEE ICME 01, P920
NR 15
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 59
EP 83
DI 10.1023/B:MTAP.0000046382.62218.e1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700003
DA 2024-07-18
ER

PT J
AU Johnson, M
   Fotouhi, F
   Draghici, S
   Dong, M
   Xu, D
AF Johnson, M
   Fotouhi, F
   Draghici, S
   Dong, M
   Xu, D
TI Discovering document semantics QBYS: A system for querying the WWW by
   semantics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st Workshop on Multimedia Semantics
CY NOV 28-29, 2002
CL Milovy, CZECH REPUBLIC
DE query-by-semantics; document features; document type; neural network
AB This paper describes our research into a query-by-semantics approach to searching the World Wide Web. This research extends existing work, which had focused on a query-by-structure approach for the Web. We present a system that allows users to request documents containing not only specific content information, but also to specify that documents be of a certain type. The system captures and utilizes structure information as well as content during a distributed query of the Web. The system also allows the user the option of creating their own document types by providing the system with example documents. In addition, although the system still gives users the option of dynamically querying the web, the incorporation of a document database has improved the response time involved in the search process. Based on extensive testing and validation presented herein, it is clear that a system that incorporates structure and document semantic information into the query process can significantly improve search results over the standard keyword search.
C1 Madonna Univ, Coll Sci & Math, Livonia, MI 48150 USA.
   Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA.
C3 Wayne State University
RP Johnson, M (corresponding author), Madonna Univ, Coll Sci & Math, Livonia, MI 48150 USA.
EM mjohnson@madonna.edu; fotouhi@cs.wayne.edu; sod@cs.wayne.edu;
   mdong@cs.wayne.edu; xuduo18@cs.wayne.edu
RI Draghici, Sorin/B-3074-2013
OI Draghici, Sorin/0000-0002-0786-8377
CR [Anonymous], 1998, Computer Networks and ISDN Systems, DOI [DOI 10.1016/S0169-7552(98)00110-X, 10.1016/S0169-7552(98)00110-X]
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   BOYAN J, 1996, AAAI 96 WORKSH INT B, P334
   Chang SF, 1997, COMMUN ACM, V40, P63, DOI 10.1145/265563.265573
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   FOTOUHI F, 1999, P 14 INT S COMP INF, P214
   GLOVER E, 2001, IMPROVING CATEGORY S
   Hagan MT, 1997, NEURAL NETWORK DESIG
   HARMAN D, 1992, RELEVANCE FEEDBACK O, P241
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   JOHNSON M, 2003, QUERY BY STRUCTURE A, P301
   JOHNSON M, 2001, 12 INT C INF RES MAN, P108
   KONOPNICKI D, 1995, P 21 INT C VER LARG, P11
   Lakshmanan LVS, 1996, SIXTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING, PROCEEDINGS, P12, DOI 10.1109/RIDE.1996.492238
   LU S, 2002, INFORMATION RES, V7
   Madria S.K., 1999, P 1 INT DATA WAREHOU, P303
   MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296, DOI 10.1109/72.363467
   Mendelzon AO, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P80, DOI 10.1109/PDIS.1996.568671
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2004
VL 24
IS 2
BP 155
EP 188
DI 10.1023/B:MTAP.0000036841.99415.44
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 843OT
UT WOS:000223094200005
DA 2024-07-18
ER

PT J
AU Kantarci, A
   Tunali, T
AF Kantarci, A
   Tunali, T
TI Design and implementation of a streaming system for MPEG-1 videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video-on-demand; video streaming; frame interval; frame rate; MPEG-1;
   RTP; RTCP
AB A new streaming application has been developed for the Internet environment. The system has client-server structure together with multithreaded architecture and pipelining. RTP protocol is used to transmit packets belonging to MPEG videos. RTCP protocol collects transmission statistics. System is adaptive in the sense that it reacts to dynamic network conditions. A feedback mechanism controls both the frame interval and frame rate depending on the frame-loss statistics and buffered video level at the client. A flow control module at the client side controls buffer underflows and overflows. Performance results of the implementation are reported and discussed. The performance of the proposed buffering strategy is compared with other proposed methods from the literature. The comparisons showed that the proposed strategy is more robust than other methods.
C1 Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
   Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
C3 Ege University; Ege University
RP Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
EM kantarci@bornova.ege.edu.tr; tunali@ube.ege.edu.tr
CR ANKER T, 1999, P 19 INT C DISTR COM
   BUSSE I, 1995, P 1 INT WORKSH HIGH
   CEN S, 1995, P NOSSDAV 95 DURH NE, P18
   CHEN Z, 1995, P 4 INT WORLD WID WE
   Cramer CE, 2000, IEEE J SEL AREA COMM, V18, P150, DOI 10.1109/49.824788
   FLUCKINGER F, 1995, UNDERSTANDING NETWOR
   Gallmeister B.O., 1995, PROGRAMMING REAL WOR
   HESS CK, 1998, THESIS U ILLINOIS UR
   HOFFMAN D, 1998, RFC2250 RTP PAYLOAD
   KANTARCI A, 2000, P ICME 2000 MULT S N
   KANTARCI A, 2000, P 15 INT S COMP INF
   Lewis Bil., 1998, MULTITHREADED PROGRA
   MAYERPATEL K, 1997, SPIE P ACM SIGCOMM 9, P298
   NG JK, 1998, P 5 INT C REAL TIM C
   Schulzrinne H., 1996, Rtp: a transport protocol for real-time applications
   *SUN MICR, 1997, XIL PROGR GUID
   Zhang JB, 1997, REAL TIM SYST SYMP P, P253, DOI 10.1109/REAL.1997.641287
NR 17
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2003
VL 21
IS 3
BP 261
EP 280
DI 10.1023/A:1025774901363
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 721VY
UT WOS:000185340200004
DA 2024-07-18
ER

PT J
AU Mauve, M
AF Mauve, M
TI TeCo3D - Sharing interactive and dynamic 3D models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE distributed interactive media; interactive 3D models; VRML; RTP/I;
   consistency; late-join; recording
AB In this paper we present a method for sharing interactive and dynamic 3D models that are collaboration-unaware, i.e., models that have not been designed to be used by multiple users at the same time. This functionality is an essential requirement for the inclusion of arbitrary 3D models, as generated by standard CAD or animation software, into teleconferencing sessions. A key aim of this work is to show that a large part of the required functionality can be developed in a way so that it is reusable for other applications such as shared whiteboards or networked computer games. Our method therefore consists of both an application dependent part that handles the specific tasks required for sharing 3D models, and of a number of generic services such as synchronization, scalable support for latecomers, and the ability to record and replay sessions. The generic services are based on an abstract media model and the RTP/I application level protocol for distributed interactive media. Any other application for a medium that shares this model and that uses RTP/I may reuse these generic services. We have implemented a prototype called TeCo3D demonstrating the feasibility of our approach.
C1 Univ Mannheim, D-68131 Mannheim, Germany.
C3 University of Mannheim
RP Mauve, M (corresponding author), Univ Mannheim, L15,16, D-68131 Mannheim, Germany.
CR AMES AL, 1997, VRML 2 3 SOURCEBOOK
   [Anonymous], P ACM C COMP SUPP CO
   [Anonymous], P ACM C COMP SUPP CO
   Brutzman D, 1998, COMMUN ACM, V41, P57, DOI 10.1145/276609.276620
   Floyd S, 1997, IEEE ACM T NETWORK, V5, P784, DOI 10.1109/90.650139
   Hilt V, 1999, LECT NOTES COMPUT SC, V1718, P291
   HOLFELDER W, 1997, LECT NOTES COMPUTER, V1309, P450
   JACOBSON V, 1999, IN PRESS IEFT
   KUHMUNCH C, 1998, P ED MEDIA ED TELECO
   LAMPORT L, 1978, COMMUN ACM, V21, P558, DOI 10.1145/359545.359563
   MAUVE M, 1999, P SPIE MULT COMP NET, P240
   MAUVE M, 2000, THESIS U MANNHEIM
   Mauve M., 2000, RTP I APPL LEVEL REA
   MILLS DL, 1992, RFC1305 DARPA NETW W
   MINENKO W, 1996, THESIS U ULM
   ROBINSON J, 2000, P VRML2000 S VIRT RE
   SONSTEIN J, 1999, VNET WEB PAGE
   VOGEL J, 2000, P ACM MULT 2000 LOS
   VOGEL J, 2001, MULTIMEDIA LECT BOAR
   *VRML CONS, 1999, 147722 ISOIEC VRML
   *VRML CONS, 1997, 147721 ISOIEC VRML
NR 21
TC 3
Z9 3
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2003
VL 20
IS 3
BP 283
EP 304
DI 10.1023/A:1024076306065
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 686QF
UT WOS:000183331900005
DA 2024-07-18
ER

PT J
AU Mulhem, P
   Martin, H
AF Mulhem, P
   Martin, H
TI From database to web multimedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE database; multimedia presentation; SMIL
AB This paper deals with the integration of multimedia and database technologies in order to describe web multimedia documents. We present a middleware to seamlessly handle database accesses as well as compositional, spatial and temporal constraints related to data presentation. Our approach is based on the concept of Templates. A template is a logical presentation unit that merge database queries with layout specifications. We choose an XML and SMIL approach to implement template. Template definition and invocation are mapped into a XML DTD. Each template is then translated into a SMIL document. In this paper, we give an example to show the advantages of our approach.
C1 KRDL, CNRS, IPAL, Singapore, Singapore.
   IMAG, LSR, Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA)
RP Mulhem, P (corresponding author), KRDL, CNRS, IPAL, Singapore, Singapore.
CR ABITEBOUL S, 1999, S PRINC DAT SYST POD
   ABITEBOUL S, 1997, INT J DIGITAL LIBRAR, V1, P1
   ADAH S, 1999, ACM SIGMOD PHIL
   ALASQUR A, 1990, 15 VLDB C AMST NETH
   ALLEN JF, 1983, COMMUN ACM, V26, P11
   Arocena GO, 1998, PROC INT CONF DATA, P24, DOI 10.1109/ICDE.1998.655754
   BARAL C, P ACM MULT 98 C BRIS, P109
   BERTINO E, 1999, IEEE T MULTIMEDIA SY
   BLAIR DC, 1998, INFORMATION PROCESSI, V24
   Cattell RGG., 1994, ODMG93
   CHRISTOPHIDES V, 2000, SIGMOD C DALL TEX US
   Deutsch A., 1998, XML QL QUERY LANGUAG
   EGENHOFER MJ, 1991, INT J GEOGR INF SYST, V5, P161, DOI 10.1080/02693799108927841
   HIRZALLA N, 1995, REV IEEE MULTIMEDIA, V2
   KERAMANE C, 1996, P IEEE INT C MULT CO
   KIM W, 1989, ACTOODS33789
   LAHIRI T, 1997, INT J DIGITAL LIB, V1, P68
   Li Jinming, 1996, P 1996 MULT MOD INT, P119
   LIEFKE H, 2000, SIGMOD C DALL TEX US
   LINO M, 1994, INT C MULT COMP SYST
   MANNINO MV, 1990, IEEE T SOFTWARE ENG, V16
   MARTIN H, 1997, P INT S DIG MED INF
   MARTIN H, 1999, 9 INT DAT C HONG KON, P57
   MENDELSON A, J DIGITAL LIB, V1, P54
   Papadias D., 1994, International Journal on Very Large Data Bases, V3, P479, DOI [10.1007/BF01231605, DOI 10.1007/BF01231605]
   RUTLEDGE L, 1999, MOD MULT INF SYST C, P1
   SHIH T, 1997, IEEE INT C MULT COMP
   THOMAS DC, 1993, IEEE T KNOWL DATA EN, V5, P551
   WAHL T, 1994, INT C MULT COMP SYST
NR 29
TC 3
Z9 3
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2003
VL 20
IS 3
BP 263
EP 282
DI 10.1023/A:1024024321994
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 686QF
UT WOS:000183331900004
DA 2024-07-18
ER

PT J
AU Shibata, Y
   Miyakawa, A
AF Shibata, Y
   Miyakawa, A
TI Kansei information processing and virtual reality techniques for
   Japanese traditional crafting presentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB In this paper, we propose a user-friendly three-dimensional CG presentation system for a typical traditional Japanese crafting industry based on agent and virtual reality functions over Japan Gigabit Network (JGN) which is a testbed highspeed backbone network with 2.4 Gbps. A large number of traditional Japanese fittings in a local city are redesigned by three-dimensional computer graphics into CAD data and stored in the database servers distributed over JGN. Although each fitting data consists of more than several Mbytes size, user can interactively retrieve the desired fittings and put those into the traditional Japanese interior to design more creative and original houses, hotels and other buildings in realtime. We prototyped a presentation system using VRML and JAVA on networked CG workstations. User can walk through the desired virtual space as a Japanese interior organized by various Japanese traditional fittings and interactively change those fittings by selecting from the database and replacing by simple operations. As a result, we could verify the usefulness of our suggested system not only for Japanese crafting but also for worldwide design industries.
C1 Iwate Prefectural Univ, Software & Informat Sci, Morioka, Iwate, Japan.
   Educ Div, Tatsuruhama, Ishikawa, Japan.
RP Iwate Prefectural Univ, Software & Informat Sci, Morioka, Iwate, Japan.
EM shibata@iwate-pu.ac.jp; a-miyakawa@town.tatsuruhama.ishikawa.jp
RI Shibata, Yoshitaka/HZL-4519-2023
CR Fukuda M., 1998, Transactions of the Information Processing Society of Japan, V39, P158
   KATSUMOTO M, 1995, MMNET 95, P113
   Kohsaka Y., 1999, Proceedings of the 1999 ICPP Workshops on Collaboration and Mobile Computing (CMC'99). Group Communications (IWGC). Internet '99 (IWI'99). Industrial Applications on Network Computing (INDAP). Multimedia Network Systems (MMNS). Security (IWSEC). Parallel Computing '99 (IWPC'99). Parallel Execution on Reconfigurable Hardware (PERH), P614, DOI 10.1109/ICPPW.1999.800124
   Miyakawa A, 2001, 12TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P203, DOI 10.1109/DEXA.2001.953064
   MIYAKAWA A, 2001, IEEE P 21 ICDCS MNS2, P384
   SHIBATA Y, 1997, J MANAGE INFORM SYST, V13, P25
   Sugita K, 2001, 15TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING, PROCEEDINGS, P763, DOI 10.1109/ICOIN.2001.905566
NR 7
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2003
VL 20
IS 1
BP 83
EP 91
DI 10.1023/A:1023474501017
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 671JW
UT WOS:000182462500006
DA 2024-07-18
ER

PT J
AU Dong, XX
   Li, HS
   Wang, XC
   Wang, W
   Du, JP
AF Dong, Xiaoxiao
   Li, Haisheng
   Wang, Xiaochuan
   Wang, Wei
   Du, Junping
TI CANet: cross attention network for food image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Food image segmentation; Cross attention network; Cross spatial
   attention; Channel attention; Food safety
AB Food image segmentation which aims to distinguish various ingredients is crucial for food safety, as estimating calories and other nutrients is important for human health and sustainable development. However, the performances of current image segmentation methods are inferior on food image datasets due to the significant diversity of appearances and distinctive conditions between ingredients and daily props, while these methods have insufficient capabilities for feature extraction of food images. In addition, utilizing attention mechanisms to obtain contextual detail information and long-range dependencies leads to a quadratic computational complexity. In this paper, we propose a Cross Spatial Attention (CSA) module to extract richer spatial features from food images, with lower time and space complexity. Specifically, the CSA module aggregates the contextual information by cross-calculation of horizontal and vertical dimensions. And experiments demonstrate that, by taking a two-step cross-calculation, each pixel could eventually capture global long-range dependencies. Furthermore, our method integrates a Channel Attention (CA) module to selectively highlight interdependent channel information by integrating relevant features across all feature maps. Then the outputs of these two attention modules are aggregated to enhance the representation of the image feature. Convincing performance improvement is achieved on the FoodSeg103, UECFoodPix and ADE20K. Moreover, the proposed network achieved better trade-off between accuracy and efficiency.
C1 [Dong, Xiaoxiao; Li, Haisheng; Wang, Xiaochuan; Wang, Wei] Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.
   [Dong, Xiaoxiao; Li, Haisheng; Wang, Xiaochuan; Wang, Wei] Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
   [Dong, Xiaoxiao; Li, Haisheng; Wang, Xiaochuan; Wang, Wei] Natl Engn Lab Agriprod Qual Traceabil, Beijing 100048, Peoples R China.
   [Du, Junping] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
C3 Beijing Technology & Business University; Beijing University of Posts &
   Telecommunications
RP Li, HS (corresponding author), Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.; Li, HS (corresponding author), Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.; Li, HS (corresponding author), Natl Engn Lab Agriprod Qual Traceabil, Beijing 100048, Peoples R China.
EM 15210593108@163.com; lihsh@th.btbu.edu.cn; wangxc@btbu.edu.cn;
   wwei@st.btbu.edu.cn; junpingdu@126.com
OI LI, Haisheng/0000-0003-4861-0513
FU Beijing Municipal Education Commission [KZ202110011017]; National
   Natural Science Foundation of China; Beijing Natural Science Foundation;
    [62277001];  [L233026]
FX This work was supported by scientific research program of Beijing
   Municipal Education Commission KZ202110011017, National Natural Science
   Foundation of China (No. 62277001) and Beijing Natural Science
   Foundation (No. L233026).
CR Aguilar E, 2018, IEEE T MULTIMEDIA, V20, P3266, DOI 10.1109/TMM.2018.2831627
   [Anonymous], 2012, P ACM MULT 2012 WORK
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cao J, 2013, J ZHEJIANG U-SCI C, V14, P495, DOI 10.1631/jzus.CIDE1303
   Chang Y-W., 2006, Proc Algo, V2006, P331
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Contributors M, 2020, MMSegmentation: Open MMLab semantic segmentation toolbox and benchmark
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   De Silva LC, 2005, P ANN C IM VIS COMP, P28
   Fang YK, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107249
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ge M., 2015, P 5 INT C DIGITAL HL, P105, DOI DOI 10.1145/2750511.2750528
   Geng Z, 2020, INT C LEARN REPR
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YF, 2021, PROC CVPR IEEE, P5837, DOI 10.1109/CVPR46437.2021.00578
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kou FF, 2018, J COMPUT SCI-NETH, V28, P281, DOI 10.1016/j.jocs.2017.10.012
   Li FH, 2022, APPL INTELL, V52, P5185, DOI 10.1007/s10489-021-02703-w
   Li QP, 2013, CHIN CONT DECIS CONF, P3792
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Min WQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329168
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Misra D, 2021, IEEE WINT CONF APPL, P3138, DOI 10.1109/WACV48630.2021.00318
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Oh SW, 2022, IEEE T PATTERN ANAL, V44, P442, DOI 10.1109/TPAMI.2020.3008917
   Okamoto Kaimu, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12665), P647, DOI 10.1007/978-3-030-68821-9_51
   Park J., 2018, BRIT MACH VIS C BMVC
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Phanich M, 2010, 2010 INT C INF SCI A, P1
   Sadilek A, 2016, AAAI CONF ARTIF INTE, P3982
   Schiboni G., 2018, Seamless Healthcare Monitoring: Advancements in Wearable, Attachable, and Invisible Devices, P369, DOI DOI 10.1007/978-3-319-69362-0_13
   Shimoda W, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P13, DOI 10.1145/2986035.2986043
   Shimoda W, 2015, LECT NOTES COMPUT SC, V9281, P449, DOI 10.1007/978-3-319-23222-5_55
   Shroff G, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P119, DOI 10.1109/ISWC.2008.4911602
   Shu XB, 2022, IEEE T CIRC SYST VID, V32, P5281, DOI 10.1109/TCSVT.2022.3142771
   Shu XB, 2022, IEEE T PATTERN ANAL, V44, P3300, DOI 10.1109/TPAMI.2021.3050918
   Trattner C, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P489, DOI 10.1145/3038912.3052573
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang W, 2022, Trends Food Sci Technol
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei XL, 2019, PATTERN RECOGN LETT, V119, P12, DOI 10.1016/j.patrec.2017.12.002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Wu XW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P506, DOI 10.1145/3474085.3475201
   Wu ZH, 2023, IEEE T IMAGE PROCESS, V32, P682, DOI 10.1109/TIP.2022.3231744
   Xiaoxiao Dong, 2021, 2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS), P213, DOI 10.1109/CCIS53392.2021.9754670
   Xu L, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/135182
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Ye YZ, 2020, IEEE SYS MAN CYBERN, P648, DOI [10.1109/SMC42975.2020.9283099, 10.1109/smc42975.2020.9283099]
   Yu F., 2015, ARXIV
   Yuan YH, 2021, INT J COMPUT VISION, V129, P2375, DOI 10.1007/s11263-021-01465-9
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P489, DOI 10.1007/978-3-030-58610-2_29
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127
   Zhu FQ, 2011, INT SYMP IMAGE SIG, P337
NR 62
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17916-z
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500014
DA 2024-07-18
ER

PT J
AU Anitha, CL
   Sumathi, R
AF Anitha, C. L.
   Sumathi, R.
TI Anomaly detection in WSN IoT (Internet of Things) environment through a
   consensus-based anomaly detection approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomaly detection; WSN (Wireless Sensor Network); IoT (Internet of
   things); CSAD (consensus-based novel anomaly detection); Data packets
ID WIRELESS SENSOR NETWORKS; INTRUSION DETECTION; SECURITY
AB The most essential part of any IoT (Internet of Things) model is the wireless network sensors (WSN). The application of these networks combined with the latest technologies relating to IoT provides fast, economical as well as flexible applications. Wireless sensor networks have various applications for IoT where devices combined with the sensors are used for data collection from various environments as well as monitoring of these environments. These networks are highly prone to attacks considering their characteristic nature, which includes self-organization, a topology that is dynamic, large-scale, and constrained on resources. Various models have been proposed for the detection of attacks in these Wireless sensor networks. Although, the recent survey studies on the attacks in this network aims at the methodologies for detecting only one to two kinds of attacks as well as have the absence of performance analysis in detail. This research work proposes a CSAD (consensus-based novel anomaly detection) approach in three steps; first step; each step includes a novel algorithm. A novel distributed algorithm is proposed to classify the anomaly and normal data packets. In the second step level based approach is used for decision implementation to identify the anomaly; also it is responsible for efficient packet transmission. The third step includes discarding the anomaly Moreover, the proposed model is evaluated by inducing the different malicious nodes, and an anomaly detected is observed. Further comparison with the existing model is carried out based on the classified and misclassified packet; through the comparative analysis, it is observed that the Consensus-AD (Anomaly Detection) approach simply outperforms the existing model. A comparative analysis is carried out considering the throughput for model efficiency. Moreover, comparative analysis shows that the proposed model outperforms the existing anomaly detection protocol. The existing model observes a throughput of 80.99% whereas the CSAD model observes a throughput of 81.81%.
C1 [Anitha, C. L.; Sumathi, R.] SIT, Dept Comp Sci & Engn, Tumkur, India.
C3 Siddaganga Institute of Technology
RP Anitha, CL (corresponding author), SIT, Dept Comp Sci & Engn, Tumkur, India.
EM clanitha@gmail.com; rsusit@gmail.com
OI C L, Dr. Anitha/0000-0003-3090-6519
CR Abduvaliyev A, 2013, IEEE COMMUN SURV TUT, V15, P1223, DOI 10.1109/SURV.2012.121912.00006
   Abououf M, 2022, IEEE INTERNET THINGS, V9, P25285, DOI 10.1109/JIOT.2022.3196049
   Amaouche S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13137488
   Breitenbacher D, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P479, DOI 10.1145/3321705.3329847
   Dang TB, 2021, IEEE INTERNET THINGS, V8, P15468, DOI 10.1109/JIOT.2021.3073705
   Desai SS, 2021, IEEE T INF FOREN SEC, V16, P4092, DOI 10.1109/TIFS.2021.3101051
   Douiba M, 2023, J SUPERCOMPUT, V79, P3392, DOI 10.1007/s11227-022-04783-y
   Hazman C, 2023, CLUSTER COMPUT, V26, P4069, DOI 10.1007/s10586-022-03810-0
   Islam K, 2012, IEEE T SYST MAN CY C, V42, P1243, DOI 10.1109/TSMCC.2012.2205680
   Jiang S, 2020, IEEE ACCESS, V8, P169548, DOI 10.1109/ACCESS.2020.3024219
   Laouira ML, 2021, IEEE T SUST COMPUT, V6, P54, DOI 10.1109/TSUSC.2019.2904855
   Li WJ, 2019, FUTURE GENER COMP SY, V96, P481, DOI 10.1016/j.future.2019.02.064
   Miao XD, 2019, IEEE T CYBERNETICS, V49, P1475, DOI 10.1109/TCYB.2018.2804940
   Mohy-Eddine M, 2023, BIG DATA MIN ANAL, V6, P273, DOI 10.26599/BDMA.2022.9020032
   Mohy-eddine M, 2023, MULTIMED TOOLS APPL, V82, P23615, DOI 10.1007/s11042-023-14795-2
   Mohy-Eddine M, 2023, J COMPUT VIROL HACKI, V19, P469, DOI 10.1007/s11416-022-00456-9
   Mudgerikar A, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P493, DOI 10.1145/3321705.3329857
   Pajouh NH, 2019, IEEE T EMERG TOP COM, V7, P314, DOI 10.1109/TETC.2016.2633228
   Sharma M, 2021, IEEE CAN J ELECT COM, V44, P246, DOI 10.1109/ICJECE.2021.3053231
   Xie HM, 2019, IEEE INTERNET THINGS, V6, P2205, DOI 10.1109/JIOT.2018.2883403
   Yao S, 2020, IEEE INTERNET THINGS, V7, P3923, DOI 10.1109/JIOT.2019.2961839
   Yin CY, 2022, IEEE T SYST MAN CY-S, V52, P112, DOI 10.1109/TSMC.2020.2968516
NR 22
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17894-2
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200008
DA 2024-07-18
ER

PT J
AU Chang, RY
   Feng, XF
   Zhang, ZH
   Zhang, H
AF Chang, Rui-yun
   Feng, Xiu-fang
   Zhang, Ze-hua
   Zhang, Hao
TI An efficient and secure opto-cryptosystem for color medical images using
   2D-SICM based fractional fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Color medical image; S-box; FRFT-DRPE; 2D-SICM; HSI model
AB Medical images contain sensitive information and are prone to various attacks during network transmission. Therefore, it is essential to develop a robust algorithm to ensure the safety of transmitting medical images. In this paper, we propose an efficient and secure color medical image encryption system utilizing the FRFT-DRPE optical transformation and 2D-SICM hyperchaos system. The encryption process in our system considers the specific characteristics of each channel in the HSI color model. First, the image is converted from RGB space to HSI space. Subsequently, different encryption methods are applied to the hue and saturation components, including S-box replacement, scrambling, and diffusion operations. For the intensity component, scrambling and FRFT-DRPE optical encryption operations are performed. Additionally, the order of 2D-FRFT serves as an additional key to enhance the security of the encryption system. Finally, the three channels are merged to complete the overall encryption process. Simulations and performance analysis have confirmed the high-security level of our algorithm. It effectively protects the privacy of medical images during transmission.
C1 [Chang, Rui-yun; Feng, Xiu-fang] Taiyuan Univ Technol, Coll Software, Jinzhong 030600, Peoples R China.
   [Zhang, Ze-hua; Zhang, Hao] Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Zhang, H (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
EM zhanghao02@tyut.edu.cn
FU Key R & D plan in Shanxi Province
FX No Statement Available
CR Abd-El-Atty B, 2021, OPT LASER ENG, V138, DOI 10.1016/j.optlaseng.2020.106403
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen JX, 2017, OPTIK, V136, P1, DOI 10.1016/j.ijleo.2017.02.001
   Chen MM, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106026
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Elhosany HM., 2015, SIViP, V9, P223
   Faragallah OS, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106333
   Gong LH, 2018, INT J THEOR PHYS, V57, P59, DOI 10.1007/s10773-017-3541-1
   Huang HQ, 2019, IEEE ACCESS, V7, P177988, DOI 10.1109/ACCESS.2019.2958319
   Liang YR, 2016, MULTIMED TOOLS APPL, V75, P6605, DOI 10.1007/s11042-015-2592-7
   Liu HJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501632
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu LD, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102854
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Lone MA, 2022, OPTIK, V260, DOI 10.1016/j.ijleo.2022.168880
   Nan SX, 2022, NONLINEAR DYNAM, V108, P2705, DOI 10.1007/s11071-022-07335-4
   Qasim IM, 2023, OPT COMMUN, V533, DOI 10.1016/j.optcom.2023.129262
   Singh KN, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3498342
   Tian PR, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145325
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Xie HW, 2023, MULTIMED TOOLS APPL, V82, P27593, DOI 10.1007/s11042-023-14546-3
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang R, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10081242
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhou TQ, 2020, FUTURE GENER COMP SY, V108, P1307, DOI 10.1016/j.future.2018.04.008
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
NR 28
TC 0
Z9 0
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17821-5
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600006
DA 2024-07-18
ER

PT J
AU Chen, CL
   Huang, QY
   Zhou, M
   Huang, DC
   Liu, LC
   Deng, YY
AF Chen, Chin-Ling
   Huang, Qing-Yang
   Zhou, Ming
   Huang, Der-Chen
   Liu, Ling-Chun
   Deng, Yong-Yuan
TI Quantified emotion analysis based on design principles of color feature
   recognition in pictures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Picture recognition; Emotion analysis; Color psychology; Color
   classification
AB When people observe pictures, different pictures will generate different emotions, and the painters often convey emotional energy to the audience through the media. Through the effect of this emotional transfer, people get emotional satisfaction psychologically, and the author can better express the emotion he needs to express by using the principle. For those who do not know art appreciation, it is difficult to accurately describe the feelings brought by pictures and describe them accurately. It is also difficult to quickly and accurately find the picture of the corresponding feeling sought by oneself. This paper presents a quantitative picture emotion analysis method. Based on the analysis of the characteristics and colors of the pictures that arouse people's emotions, the classification planning is carried out in RGB space and HSV color space respectively. And the combination analysis of the color features with strong influence is carried out to select a more appropriate color space for the expression of human feelings. At the same time, the paper also discusses the effect of the black-and-white filling and the brightness saturation of the image. Finally, it makes use of the corresponding design principles to carry out a quantitative analysis of the emotion generated by it. The system performs a combined analysis of a picture from these directions and presents the results to the user.
C1 [Chen, Chin-Ling] Changchun Sci Tech Univ, Sch Informat Engn, Changchun 130600, Jilin, Peoples R China.
   [Chen, Chin-Ling; Deng, Yong-Yuan] Chaoyang Univ Technol, Dept Comp Sci & Informat Engn, Taichung 413310, Taiwan.
   [Huang, Qing-Yang] Fuzhou Univ, Xiamen Acad Arts & Design, Xiamen 361024, Fujian, Peoples R China.
   [Zhou, Ming] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen 361024, Fujian, Peoples R China.
   [Huang, Der-Chen; Liu, Ling-Chun] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 Chaoyang University of Technology; Fuzhou University; Xiamen University
   of Technology; National Chung Hsing University
RP Deng, YY (corresponding author), Chaoyang Univ Technol, Dept Comp Sci & Informat Engn, Taichung 413310, Taiwan.; Liu, LC (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
EM clc@mail.cyut.edu.tw; hqycleary@foxmail.com; mzhou@xmut.edu.cn;
   huangdc@nchu.edu.tw; d110056004@mail.nchu.edu.tw; allen.nubi@gmail.com
OI Chen, Chin-Ling/0000-0002-4958-2043
FU Ministry of Science and Technology, Taiwan
FX No Statement Available
CR AL-Ayash A, 2016, COLOR RES APPL, V41, P196, DOI 10.1002/col.21949
   Bai YY, 2021, INT J CLOTH SCI TECH, V33, P388, DOI 10.1108/IJCST-06-2019-0084
   Balouchian P, 2019, IEEE WINT CONF APPL, P1645, DOI 10.1109/WACV.2019.00180
   Buechner VL, 2015, CURR PSYCHOL, V34, P422, DOI 10.1007/s12144-014-9266-x
   Chemov V, 2015, COMPUT ELECTR ENG, V46, P328, DOI 10.1016/j.compeleceng.2015.08.005
   Chen Fen, 2019, Journal of the China Society for Scientific and Technical Information, V38, P420, DOI 10.3772/j.issn.1000-0135.2019.04.010
   Chen ZK., 2021, World Chin Paint Calligraphy, V233, P88, DOI [10.3969/j.issn.1673-6109.2021.07.020, DOI 10.3969/J.ISSN.1673-6109.2021.07.020]
   Cheng SH, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.730066
   Gao XP, 2007, COLOR RES APPL, V32, P223, DOI 10.1002/col.20321
   Gao Y, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Gong R, 2017, OPTIK, V136, P71, DOI 10.1016/j.ijleo.2017.02.026
   Huang GS, 2001, Color design
   Huang S., 2014, Shanxi Archit, V31, P48, DOI [10.3969/j.issn.1009-6825.2014.31.026, DOI 10.3969/J.ISSN.1009-6825.2014.31.026]
   Jonauskaite D, 2022, COLOR RES APPL, V47, P1224, DOI 10.1002/col.22815
   Jonauskaite D, 2020, PSYCHOL SCI, V31, P1245, DOI 10.1177/0956797620948810
   Kong W, 2021, Emotion and color in paintings: a novel temporal and spatial quantitative perspective
   Lang C, 2011, Van Gogh drawing artistic style evaluation Journal of Jilin Institute of Chemical Technology
   Lee J., 2020, Access, V99, P1
   Li Hai-fang, 2007, Journal of Computer Applications, V27, P453
   Ma Ling, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P1272
   Mäntylä MV, 2018, COMPUT SCI REV, V27, P16, DOI 10.1016/j.cosrev.2017.10.002
   Mittal N, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P684, DOI 10.1109/WI.2018.00-11
   Mohseni SA, 2017, 2017 INT C DIG IM CO, P1, DOI [10.1109/DICTA.2017.8227410, DOI 10.1109/DICTA.2017.8227410]
   Qi X., 2021, Rev Educ Theory, V3, P22, DOI [10.30564/ret.v4i3.3316, DOI 10.30564/RET.V4I3.3316]
   Ren ZM., 2019, Shanxi Electron Technol, V4, P51
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Tao F, 2018, Aesthetics
   Tian WF, 2022, J INTELL SYST, V31, P428, DOI 10.1515/jisys-2022-0026
   Wang R, 2020, Documentation, Information & Knowledge, V03, P119, DOI [10.13366/j.dik.2020.03.119, DOI 10.13366/J.DIK.2020.03.119]
   Wilms L, 2017, Psychol Res
   Ya-Li FU, 2008, Journal of Zhengzhou University of Light Industry(Natural Science), DOI [10.3969/j.issn.1004-1478.2008.06.031, DOI 10.3969/J.ISSN.1004-1478.2008.06.031]
   Yang SY., 2019, Comput Telecommun, V1, P79
   Zhao SJ., 2019, Masterpieces Rev, V35, P21
NR 33
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 18
PY 2023
DI 10.1007/s11042-023-17286-6
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CO5S9
UT WOS:001126208400002
DA 2024-07-18
ER

PT J
AU Kumari, P
   Bedi, AK
   Saini, M
AF Kumari, Pratibha
   Bedi, Anterpreet Kaur
   Saini, Mukesh
TI Multimedia datasets for anomaly detection: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Anomaly datasets survey; Concept drift; Multimodal anomaly detection;
   Long term surveillance
ID ABNORMAL EVENT DETECTION; COLLECTIVE CROWD BEHAVIORS; SURVEILLANCE;
   SCENES; AUDIO; RECOGNITION; ATTENTION; NETWORK; ONLINE; MODEL
AB Multimedia anomaly datasets play a crucial role in automated surveillance. They have a wide range of applications expanding from outlier objects/ situation detection to the detection of life-threatening events. For more than 1.5 decades, this field has attracted a lot of research attention, and as a result, more and more datasets dedicated to anomalous actions and object detection have been developed. Tapping these public anomaly datasets enable researchers to generate and compare various anomaly detection frameworks with the same input data. This paper presents a comprehensive survey on a variety of video, audio, as well as audio-visual datasets based on the application of anomaly detection. This survey aims to address the lack of a comprehensive comparison and analysis of multimedia public datasets based on anomaly detection. Also, it can assist researchers in selecting the best available dataset for bench-marking frameworks. Additionally, we discuss gaps in the existing dataset and insights for future direction towards developing multimodal anomaly detection datasets.
C1 [Kumari, Pratibha; Saini, Mukesh] IIT Ropar, Dept Comp Sci & Engn, Ropar 140001, Punjab, India.
   [Bedi, Anterpreet Kaur] Thapar Inst Engn & Technol, Elect & Instrumentat Engn Dept, Patiala 147004, Punjab, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Ropar; Thapar Institute of Engineering & Technology
RP Kumari, P (corresponding author), IIT Ropar, Dept Comp Sci & Engn, Ropar 140001, Punjab, India.
EM 2017csz0006@iitrpr.ac.in; anterpreet.bedi@thapar.edu;
   mukesh@iitrpr.ac.in
RI Kumari, Pratibha/JAX-1992-2023
OI Kumari, Pratibha/0000-0003-3681-3700
FU This work is supported by the grant received from DST, Govt. of India
   for the Technology Innovation Hub at the IIT Ropar in the framework of
   National Mission on Interdisciplinary Cyber-Physical Systems.
FX The authors sincerely thank Dr. Priyankar Choudhary for his valuable
   contributions to the revision of this manuscript. His expertise has
   helped strengthen the quality of the manuscript.
CR Abbasi A, 2022, IEEE ACCESS, V10, P38885, DOI 10.1109/ACCESS.2022.3166602
   Acharya J, 2020, IEEE T BIOMED CIRC S, V14, P535, DOI 10.1109/TBCAS.2020.2981172
   Acsintoae A, 2022, PROC CVPR IEEE, P20111, DOI 10.1109/CVPR52688.2022.01951
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Akhter I, 2022, 2022 19 INT BHURBAN, P629
   Akti S, 2022, IEEE WINT CONF APPL, P550, DOI 10.1109/WACVW54805.2022.00061
   Akti Seymanur, 2019, 2019 9 INT C IMAGE P, P1
   Aldayri A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166080
   Alías F, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7020146
   Allain P, 2012, ICPR, P1
   Almaadeed N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061858
   Ferreira JCA, 2009, IEEE INTL CONF IND I, P25, DOI 10.1109/INDIN.2009.5191765
   Ammar H, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01182-w
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   ARENA, 2014, Dataset
   Assari SM, 2016, LECT NOTES COMPUT SC, V9906, P119, DOI 10.1007/978-3-319-46475-6_8
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bala A, 2023, MULTIMED TOOLS APPL, V82, P34771, DOI 10.1007/s11042-023-14922-z
   Bansod SD, 2020, VISUAL COMPUT, V36, P609, DOI 10.1007/s00371-019-01647-0
   Barbalau A, 2023, COMPUT VIS IMAGE UND, V229, DOI 10.1016/j.cviu.2023.103656
   Basset A, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P282, DOI 10.1109/AVSS.2013.6636653
   Bastani V, 2015, AVSS, P1
   Belmonte R, 2021, CBMI
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Benezeth Y, 2011, PATTERN RECOGN LETT, V32, P423, DOI 10.1016/j.patrec.2010.10.008
   Bera A, 2016, IEEE COMPUT SOC CONF, P1289, DOI 10.1109/CVPRW.2016.163
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bogdoll D, 2022, IEEE COMPUT SOC CONF, P4487, DOI 10.1109/CVPRW56347.2022.00495
   Bolme DS, 2009, PETS, P1
   Brzezinski D, 2017, KNOWL INF SYST, V52, P531, DOI 10.1007/s10115-017-1022-8
   Burghouts GJ, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P375, DOI 10.1109/AVSS.2014.6918697
   Cao CQ, 2023, PROC CVPR IEEE, P20392, DOI 10.1109/CVPR52729.2023.01953
   Chan FH, 2017, LECT NOTES COMPUT SC, V10114, P136, DOI 10.1007/978-3-319-54190-7_9
   Chandrakala S, 2023, ARTIF INTELL REV, V56, P3319, DOI 10.1007/s10462-022-10258-6
   Chen H, 2019, IEEE ACCESS, V7, P32845, DOI 10.1109/ACCESS.2019.2903859
   Chen HW, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P361, DOI 10.1109/AVSS.2014.6918695
   Chen Z., 2016, SYNTH LECT ARTIF INT, V10, P1, DOI DOI 10.2200/S00737ED1V01Y201610AIM033
   Cheng M, 2021, INT C PATT RECOG, P4183, DOI 10.1109/ICPR48806.2021.9412502
   Cho M, 2023, PROC CVPR IEEE, P12137, DOI 10.1109/CVPR52729.2023.01168
   Chu CT, 2013, IEEE T MULTIMEDIA, V15, P1602, DOI 10.1109/TMM.2013.2266634
   Socoró JC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102323
   Conde C, 2013, NEUROCOMPUTING, V100, P19, DOI 10.1016/j.neucom.2011.12.037
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Cui XY, 2011, PROC CVPR IEEE
   Danesh Pazho Armin, 2023, Image Analysis: 23rd Scandinavian Conference, SCIA 2023, Proceedings. Lecture Notes in Computer Science (13885), P50, DOI 10.1007/978-3-031-31435-3_4
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Degardin B, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Demarty CH, 2015, MULTIMED TOOLS APPL, V74, P7379, DOI 10.1007/s11042-014-1984-4
   Demir F, 2019, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0091-3
   Derakhshani MM, 2022, LECT NOTES COMPUT SC, V13432, P314, DOI 10.1007/978-3-031-16434-7_31
   Dohi K, 2023, Arxiv, DOI arXiv:2305.07828
   Dohi K, 2022, Arxiv, DOI arXiv:2206.05876
   Dohi K, 2022, Arxiv, DOI arXiv:2205.13879
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Doshi K, 2020, IEEE COMPUT SOC CONF, P1025, DOI 10.1109/CVPRW50498.2020.00135
   Duong HT, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23115024
   eecs.qmul, 2007, i-Lids: dataset for AVSS
   Elharrouss O, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103116
   Fagette A, 2013, Particle video for crowd flow tracking
   Fan ZY, 2018, J SIGNAL PROCESS SYS, V90, P1651, DOI 10.1007/s11265-017-1309-8
   Fang JW, 2022, IEEE T INTELL TRANSP, V23, P9601, DOI 10.1109/TITS.2022.3157254
   Fayet C., 2018, LREC
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Foggia P, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P50, DOI 10.1109/AVSS.2014.6918643
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   George M, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P11, DOI 10.1109/ISED.2018.8704021
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Greco A, 2020, IEEE T INF FOREN SEC, V15, P3610, DOI 10.1109/TIFS.2020.2994740
   Guan J, 2023, ICASSP 2023 2023 IEE, P1
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Gupta V, 2022, INT CONF ACOUST SPEE, P6172, DOI 10.1109/ICASSP43922.2022.9746718
   Harada N, 2021, Arxiv, DOI arXiv:2106.02369
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Huszár VD, 2023, IEEE ACCESS, V11, P18772, DOI 10.1109/ACCESS.2023.3245521
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Jaafar N, 2019, 2019 INT C CONTROL A, P1
   Jebur SA, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010029
   Jha S, 2021, INFORM SCIENCES, V575, P1, DOI 10.1016/j.ins.2021.04.062
   Jodoin P-M, 2008, ICDSC, P1
   Jodoin PM, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P1, DOI 10.1109/AVSS.2013.6636607
   Jombo G, 2023, ENG BASEL, V4, P47, DOI 10.3390/eng4010004
   Joshi KV, 2021, INT J NEXT-GENER COM, V12, P1
   Jun Yang, 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P227, DOI 10.1109/CRV.2011.37
   Kaltsa V, 2018, COMPUT VIS IMAGE UND, V169, P28, DOI 10.1016/j.cviu.2018.01.011
   Kapoor S, 2020, IntelliSys, V1250, pNatur
   Katta SS, 2022, INT CONF ACOUST SPEE, P146, DOI 10.1109/ICASSP43922.2022.9747789
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Khan SU, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224963
   Kim S, 2015, IEEE INT SYM MULTIM, P21, DOI 10.1109/ISM.2015.89
   Koizumi Y., 2021, arXiv
   Koizumi Y, 2020, INT CONF ACOUST SPEE, P281, DOI [10.1109/icassp40776.2020.9053620, 10.1109/ICASSP40776.2020.9053620]
   Koizumi Y, 2019, IEEE WORK APPL SIG, P313, DOI [10.1109/WASPAA.2019.8937164, 10.1109/waspaa.2019.8937164]
   Kok VJ, 2017, IEEE T CYBERNETICS, V47, P1157, DOI 10.1109/TCYB.2016.2538765
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Kumari P, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2969, DOI 10.1145/3474085.3481033
   Kumari P, 2022, IEEE SENS J, V22, P17126, DOI 10.1109/JSEN.2022.3193969
   Kumari P, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P54, DOI 10.1109/BigMM50055.2020.00018
   Kuroyanagi I, 2021, TECH REP DCASE2021 C
   Pham L, 2020, IEEE ENG MED BIO, P164, DOI 10.1109/EMBC44109.2020.9175704
   Lamba S, 2020, VISUAL COMPUT, V36, P989, DOI 10.1007/s00371-019-01713-7
   Lazaridis L, 2018, EUR SIGNAL PR CONF, P2060, DOI 10.23919/EUSIPCO.2018.8553620
   Leal-Taixé L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130233
   Lefter I, 2016, IEEE T AFFECT COMPUT, V7, P162, DOI 10.1109/TAFFC.2015.2451622
   Lefter I, 2014, J MULTIMODAL USER IN, V8, P29, DOI 10.1007/s12193-014-0150-7
   Leyva R, 2017, I W BIOMETRIC FORENS
   Leyva R, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P621, DOI 10.1109/TSP.2017.8076061
   Li HL, 2021, IEEE T NEUR NET LEAR, V32, P4243, DOI 10.1109/TNNLS.2020.3017292
   Li JJ, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P102, DOI 10.1109/AVSS.2016.7738032
   Li K, 2022, IEEE Trans Med Imaging
   Li QJ, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P156, DOI 10.1109/ICIG.2009.166
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li XL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P54, DOI 10.1109/CISP-BMEI.2016.7852681
   Li XR, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P586, DOI 10.1145/2964284.2967289
   Li XL, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2854000
   Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873
   Li ZY, 2020, IEEE ACCESS, V8, P25531, DOI 10.1109/ACCESS.2020.2970497
   Lim MK, 2014, INT C PATT RECOG, P3957, DOI 10.1109/ICPR.2014.678
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu WR, 2023, PROC CVPR IEEE, P12147, DOI 10.1109/CVPR52729.2023.01169
   Liu ZH, 2023, PROC CVPR IEEE, P24500, DOI 10.1109/CVPR52729.2023.02347
   Lohani D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093601
   Lopez-Paz D, 2017, ADV NEUR IN, V30
   Loy CC, 2008, MLVMA
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo H, 2023, ICASSP 2023 2023 IEE, P1
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv H, 2023, PROC CVPR IEEE, P8022, DOI 10.1109/CVPR52729.2023.00775
   Lv H, 2021, IEEE T IMAGE PROCESS, V30, P4505, DOI 10.1109/TIP.2021.3072863
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Majhi S, 2020, ICCCNT, P1
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mesaros A, 2017, DCASE 2017 WORKSHOP
   Mnasri Z, 2022, MULTIMED TOOLS APPL, V81, P5537, DOI 10.1007/s11042-021-11817-9
   Morita K, 2021, TECH REP DCASE2021 C
   Mousavi H, 2015, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2015.27
   Mumtaz N, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239383
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   NVIDIA, 2021, AI CITY
   Oh DY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051308
   Oh SM, 2011, PROC CVPR IEEE
   Omarov B, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.920
   Pang WF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2260, DOI 10.1109/ICASSP39728.2021.9413686
   Patil N, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P43, DOI 10.1109/ISED.2016.7977052
   Patino L, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P88, DOI 10.1109/AVSS.2016.7738072
   Patino L, 2014, APPL SOFT COMPUT, V25, P485, DOI 10.1016/j.asoc.2014.08.039
   Patrikar DR, 2022, INT J MULTIMED INF R, V11, P85, DOI 10.1007/s13735-022-00227-8
   Peixoto BM, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103174
   Peng Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P322, DOI 10.1007/978-3-030-58577-8_20
   Pennisi A, 2016, COMPUT VIS IMAGE UND, V144, P166, DOI 10.1016/j.cviu.2015.09.010
   Perez M, 2019, INT CONF ACOUST SPEE, P2662, DOI [10.1109/icassp.2019.8683676, 10.1109/ICASSP.2019.8683676]
   Pham Lam, 2022, CBMI 2022: Proceedings of the 19th International Conference on Content-based Multimedia Indexing, P23, DOI 10.1145/3549555.3549568
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   PourReza M., 2021, arXiv
   Pranav M., 2020, P AS C COMP VIS, P1
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Primus P, 2020, Arxiv, DOI arXiv:2011.02949
   Provotar Oleksandr I., 2019, 2019 IEEE International Conference on Advanced Trends in Information Theory (ATIT), P513, DOI 10.1109/ATIT49449.2019.9030505
   Qiang Y, 2021, IEEE ACCESS, V9, P68108, DOI 10.1109/ACCESS.2021.3077577
   Rabiee H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P95, DOI 10.1109/AVSS.2016.7738074
   Ramachandra B, 2022, IEEE T PATTERN ANAL, V44, P2293, DOI 10.1109/TPAMI.2020.3040591
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Rehman AU, 2021, IEEE ACCESS, V9, P30587, DOI 10.1109/ACCESS.2021.3059519
   Ren J, 2021, INT CONF DAT MIN WOR, P959, DOI 10.1109/ICDMW53433.2021.00125
   Rendón-Segador FJ, 2023, NEURAL NETWORKS, V161, P318, DOI 10.1016/j.neunet.2023.01.048
   Rezaee Khosro, 2024, Personal and Ubiquitous Computing, V28, P135, DOI 10.1007/s00779-021-01586-5
   Ristea NC, 2022, PROC CVPR IEEE, P13566, DOI 10.1109/CVPR52688.2022.01321
   Rodrigues R, 2020, IEEE WINT CONF APPL, P2615, DOI [10.1109/WACV45572.2020.9093633, 10.1109/wacv45572.2020.9093633]
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Rota P, 2015, IEEE IMAGE PROC, P3456, DOI 10.1109/ICIP.2015.7351446
   Rushe E, 2019, INT CONF ACOUST SPEE, P3597, DOI 10.1109/ICASSP.2019.8683414
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sagun MAK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P277, DOI 10.1109/INISTA.2017.8001170
   Santhosh KK, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3417989
   Santhosh KK, 2022, IEEE T INTELL TRANSP, V23, P11891, DOI 10.1109/TITS.2021.3108504
   Santhosh KK, 2019, Trans Cybern
   Sarker MI, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21123993
   Sato Fumiaki, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P6471, DOI 10.1109/CVPR52729.2023.00626
   Saypadith S, 2021, IEEE ACCESS, V9, P150903, DOI 10.1109/ACCESS.2021.3126335
   Sengönül E, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13084956
   Sethi SS, 2020, P NATL ACAD SCI USA, V117, P17049, DOI 10.1073/pnas.2004702117
   Sharma N, 2020, INTERSPEECH, P4811, DOI 10.21437/Interspeech.2020-2768
   Sharma V, 2021, IEEE ACCESS, V9, P139489, DOI 10.1109/ACCESS.2021.3118541
   Shehab D, 2019, MACH VISION APPL, V30, P919, DOI 10.1007/s00138-018-0974-3
   Shobha B. S., 2018, 2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS), P183, DOI 10.1109/CSITSS.2018.8768743
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Singh D, 2019, IEEE T INTELL TRANSP, V20, P879, DOI 10.1109/TITS.2018.2835308
   Singh H, 2020, IEEE IMAGE PROC, P1901, DOI 10.1109/ICIP40778.2020.9190697
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Socoro JC, 2015, ICSV, P12
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Soliman Mohamed Mostafa, 2019, 2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS), P80, DOI 10.1109/ICICIS46948.2019.9014714
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Song W, 2019, IEEE ACCESS, V7, P39172, DOI 10.1109/ACCESS.2019.2906275
   Strisciuglio N, 2019, PATTERN RECOGN, V92, P25, DOI 10.1016/j.patcog.2019.03.016
   Su H, 2013, IEEE T INF FOREN SEC, V8, P1575, DOI 10.1109/TIFS.2013.2277773
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun C, 2021, IEEE T MULTIMEDIA, V23, P3292, DOI 10.1109/TMM.2020.3023303
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Sun SY, 2023, PROC CVPR IEEE, P22846, DOI 10.1109/CVPR52729.2023.02188
   Szymanowicz Stanislaw, 2021, P IEEECVF C COMPUTER, P3224
   Tan ZH, 2023, APPL INTELL, V53, P4218, DOI 10.1007/s10489-022-03708-9
   Tanabe R., 2021, arXiv
   Thakare KV, 2023, PATTERN RECOGN, V140, DOI 10.1016/j.patcog.2023.109567
   Thakare KV, 2023, P IEEE CVF WINT C AP, P5541
   Tian B, 2015, IEEE T INTELL TRANSP, V16, P557, DOI 10.1109/TITS.2014.2340701
   Tran TM, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3544014
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Tyagi Himanshu, 2022, 2022 International Conference on Fourth Industrial Revolution Based Technology and Practices (ICFIRTP), P171, DOI 10.1109/ICFIRTP56122.2022.10059434
   Ullah FUM, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3561971
   Ullah FUM, 2022, IEEE T IND INFORM, V18, P5359, DOI 10.1109/TII.2021.3116377
   Ullah W, 2023, EXPERT SYST APPL, V230, DOI 10.1016/j.eswa.2023.120599
   Ullah W, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106173
   Ullah W, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109456
   Ullah W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082811
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Varadarajan J, 2017, IEEE WINT CONF APPL, P615, DOI 10.1109/WACV.2017.74
   Varadarajan J, 2013, INT J COMPUT VISION, V103, P100, DOI 10.1007/s11263-012-0596-6
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Wall C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155566
   Wang Y, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P321, DOI 10.1109/ICASSP39728.2021.9413584
   Wilkinghoff K, 2021, TECH REP DCASE2021 C
   Wilkinghoff K, 2023, ICASSP 2023 2023 IEE, P1
   Wu P, 2021, IEEE T IMAGE PROCESS, V30, P3513, DOI 10.1109/TIP.2021.3062192
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu TC, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1877, DOI 10.1109/FSKD.2016.7603465
   Xu XY, 2018, INT SYM COMPUT INTEL, P319, DOI 10.1109/ISCID.2018.00079
   Xu YY, 2018, PROC CVPR IEEE, P5275, DOI 10.1109/CVPR.2018.00553
   Yadav Uma, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1462, DOI 10.1109/ICESC51422.2021.9532751
   Yang WY, 2023, IEEE T INF FOREN SEC, V18, P2015, DOI 10.1109/TIFS.2023.3262148
   Yang ZW, 2021, IEEE ACCESS, V9, P107842, DOI 10.1109/ACCESS.2021.3100678
   Yao Y, 2022, IEEE Trans Pattern Anal Mach Intell
   Yao Y, 2019, IEEE INT C INT ROBOT, P273, DOI [10.1109/IROS40897.2019.8967556, 10.1109/iros40897.2019.8967556]
   Yi S, 2016, IEEE T IMAGE PROCESS, V25, P4354, DOI 10.1109/TIP.2016.2590322
   Yi S, 2015, IEEE I CONF COMP VIS, P3137, DOI 10.1109/ICCV.2015.359
   Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971
   Yildiz AM, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.120031
   Yu G, 2022, PROC CVPR IEEE, P13967, DOI 10.1109/CVPR52688.2022.01360
   Yuan G, 2017, ARTIF INTELL REV, V47, P123, DOI 10.1007/s10462-016-9477-7
   Yukun Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P74, DOI 10.1007/978-3-030-58548-8_5
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zaheer MZ, 2022, PROC CVPR IEEE, P14724, DOI 10.1109/CVPR52688.2022.01433
   Zhang SJ, 2022, IEEE T CIRC SYST VID, V32, P5427, DOI 10.1109/TCSVT.2022.3148392
   Zhang WC, 2021, IEEE ACCESS, V9, P124847, DOI 10.1109/ACCESS.2021.3110798
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
   Zheng XT, 2022, CAAI T INTELL TECHNO, V7, P419, DOI 10.1049/cit2.12068
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhong JH, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P801
   Zhou BL, 2015, INT J COMPUT VISION, V111, P50, DOI 10.1007/s11263-014-0735-3
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhou ZL, 2022, IEEE T INTELL TRANSP, V23, P19772, DOI 10.1109/TITS.2022.3147826
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 268
TC 1
Z9 1
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17425-z
EA DEC 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yadav, GK
   Puig, D
   Nandi, GC
AF Yadav, Gaurav Kumar
   Puig, Domenec
   Nandi, G. C.
TI Designing an adaptive cost function for dynamic human pose predictions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep sequential networks; Encoder-decoder; Human 3.6M
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; IMAGES
AB In the modern-day scenario, machines and humans are expected to work together and collaborate in several social and manufacturing environments. The machines should predict humans' next move for effective collaborations by observing their present move. Human motion modelling and prediction are fundamental and challenging problems involving computer vision and graphics. To help solve some of the challenges, in the present investigation, we propose an innovative idea of developing a new cost function as the objective function based on adaptive sampling, which is subsequently used with an 'Adam' optimizer for training and validating a specially configured Deep Learning architecture. Our proposed development produced significantly improved results regarding future pose estimation/predictions. The adaptiveness of the proposed cost function is based on a bell-shaped locally weighted function. It has been observed that the area covered by the cost function plays a vital role during training, and the bell-shaped function's width helps decide the region of importance for the training samples. The proposed cost function has been used for training a gated recurrent unit (GRU) based encoder-decoder architecture. The encoder takes the observed input sequences, extracts the input sequence's significant variability, and passes it to the decoder. The decoder takes it as input, trains using the adaptive sampling-based method, and predicts future poses. We have experimented with this function in various sizes and shapes and compared the results obtained with some state-of-the-art research results. As elaborated in this paper, we obtained much-improved results in almost all the cases.
C1 [Yadav, Gaurav Kumar; Nandi, G. C.] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, Uttar Pradesh, India.
   [Yadav, Gaurav Kumar; Puig, Domenec] Univ Rovira I Virgili, Dept Comp Sci & Math Secur, Tarragona, Spain.
C3 Indian Institute of Information Technology Allahabad; Universitat Rovira
   i Virgili
RP Yadav, GK (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, Uttar Pradesh, India.; Yadav, GK (corresponding author), Univ Rovira I Virgili, Dept Comp Sci & Math Secur, Tarragona, Spain.
EM gauravkumaryadav51@gmail.com; domenec.puig@urv.cat; gcnandi@iiita.ac.in
RI , hasane/R-4445-2019
OI , hasane/0000-0002-2587-4164
CR Balasooriya NM, 2017, INT CONF IND INF SYS, P180
   Brodersen Kay H., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3121, DOI 10.1109/ICPR.2010.764
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Dawud AM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4629859
   Deepa A. R., 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1213, DOI 10.1109/ICOEI.2018.8553697
   Devi TM, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Islam A, 2017, INT CONF ADV ELECTR, P241, DOI 10.1109/ICAEE.2017.8255360
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Li HW, 2019, LECT NOTES COMPUT SC, V11383, P385, DOI 10.1007/978-3-030-11723-8_39
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Mehnatkesh H, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119087
   Mikolajczyk A, 2014, 2018 INT INT PHD WOR, P117
   Pereira S, 2018, IMIMIC WORKSH INT MA
   Polly FP, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P813, DOI 10.1109/ICOIN.2018.8343231
   Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226
   Rezaei M, 2017, LECT NOTES COMPUT SC, V10637, P798, DOI 10.1007/978-3-319-70093-9_85
   Sachdeva J., 2011, Proceedings of the 2011 4th International Conference on Developments in e-systems Engineering (DeSE 2011), P182, DOI 10.1109/DeSE.2011.31
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Su F, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14654
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Tandel GS, 2019, CANCERS, V11, DOI 10.3390/cancers11010111
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Vidyarthi A, 2016, P 2015 39 NATL SYSTE
   Xu Y, 2015, INT CONF ACOUST SPEE, P947, DOI 10.1109/ICASSP.2015.7178109
NR 29
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17736-1
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800009
DA 2024-07-18
ER

PT J
AU Parhad, SV
   Warhade, KK
   Shitole, SS
AF Parhad, Saurabh Vijay
   Warhade, Krishna K.
   Shitole, Sanjay S.
TI Speckle noise reduction in sar images using improved filtering and
   supervised classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Synthetic Aperture Radar; Remote Sensing; Speckle Noise; Improved
   Filters; Deblurring
AB Synthetic aperture radar (SAR) is a remote sensing device that extracts the earth's surface's geo and biophysical characteristics. Classification performance is a major phase in SAR processing. Speckle noise occurs in SAR due to the coherent combination of backscatter signals from different sources. One of the approaches for suppressing the noise from SAR is to utilize local statistics. The proposed architecture evaluates the robustness of several improved filters like Improved Lopez, Improved Boxcar, Improved Guided filter and improved Lee-sigma and verifies their effects on classification accuracy. These filters were designed to overcome the suppression of target points and the blurring of edges. The supervised Wishart classifier with an improved Sparrow Search Algorithm (WC-ISSA) is utilized in the classification. SSA is used to optimize WC parameters and improve classification performance. One of the essential parameters in speckle noise filtering is the size of the sliding window. The window size varies, and the improved filters' performance is evaluated. Further, a growing self-organizing map (GSOM) is used to improve blurring performance. The proposed model is used for deblurring and enhancing the performance of smoothing images. The overall evaluation is carried out on the Matlab platform. The performance of the improved filters is compared to the standard filters, and the performances are compared on the virtual SAR dataset. The implemented results proved that the Extended Lee-sigma performed better than other filters. The PSNR and SSIM obtained by the proposed model were found to be 65.72 and 99.92%, respectively, which is considered to be more effective than other models already in use.
C1 [Parhad, Saurabh Vijay; Warhade, Krishna K.] Dr Vishwanath Karad MIT World Peace Univ, Sch Elect & Commun Engn, Pune, Maharashtra, India.
   [Shitole, Sanjay S.] SNDT Womens Univ, Usha Mittal Inst Technol, Dept Informat Technol, Mumbai 400049, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University
RP Parhad, SV (corresponding author), Dr Vishwanath Karad MIT World Peace Univ, Sch Elect & Commun Engn, Pune, Maharashtra, India.
EM saurabhparhad@gmail.com
RI Parhad, Saurabh Vijay/ABU-6130-2022; Warhade, Krishna
   Keshavrao/E-5841-2018
OI Parhad, Saurabh Vijay/0000-0001-5721-1982; Warhade, Krishna
   Keshavrao/0000-0002-0282-9766
CR Ali EH., 2022, Bull Elect Eng Inform, V11, P1325, DOI [10.11591/eei.v11i3.3708, DOI 10.11591/EEI.V11I3.3708]
   Aranda-Bojorges G, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3108774
   Choi H., 2020, Int Soc Opt Photonics, V11515, p115152M
   Choi H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101184
   Choi H, 2019, PROC IEEE INT SYMP, P1441, DOI 10.1109/ISIE.2019.8781457
   Dabhi S, 2020, Arxiv, DOI arXiv:2004.11021
   Dalsasso E, 2021, IEEE J-STARS, V14, P4321, DOI 10.1109/JSTARS.2021.3071864
   Deny J, 2021, P 1 INT C ADV SCI IN
   Ko J, 2022, IEEE J-STARS, V15, P3, DOI 10.1109/JSTARS.2021.3132027
   Kumar B, 2021, INT J REMOTE SENS, V42, P5497, DOI 10.1080/01431161.2021.1921875
   Lattari F, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131532
   Li H, 2022, Wirel Commun Mobile Comput, V2022
   Li JY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242921
   Mohan E, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6239
   Murugesan K, 2020, ARAB J GEOSCI, V13, DOI 10.1007/s12517-019-4900-4
   Nadimi-Shahraki MH, 2021, COMPUTERS, V10, DOI 10.3390/computers10110136
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Painam RK, 2023, J INDIAN SOC REMOTE, V51, P1879, DOI 10.1007/s12524-022-01495-x
   Ponmani E, 2021, MULTIMED TOOLS APPL, V80, P26547, DOI 10.1007/s11042-021-10871-7
   Pourfard M, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3084411
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Saied SK, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172806
   Santhi V, 2021, INT CO SIG PROC COMM, P223, DOI 10.1109/ICSPC51351.2021.9451809
   Shi Y., 2021, IOP Publ, V2083, P032053
   Sivaranjani R, 2019, APPL SOFT COMPUT, V76, P671, DOI 10.1016/j.asoc.2018.12.030
   Sommervold O, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030850
   Song W, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14010168
   Su N, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030442
   Vijayakumar S., 2019, International Journal of Fuzzy System Applications, V8, P60, DOI 10.4018/IJFSA.2019100104
   Wang C, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040931
   Wang GT, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061465
   Wang RL, 2020, MULTIMED TOOLS APPL, V79, P7633, DOI 10.1007/s11042-019-08377-4
   Wen ZQ, 2023, INT J REMOTE SENS, V44, P902, DOI 10.1080/01431161.2023.2173029
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
NR 35
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17648-0
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800006
DA 2024-07-18
ER

PT J
AU Shirdel, S
   Teimoortashloo, M
   Mohammadiun, M
   Gharahbagh, AA
AF Shirdel, Shahryar
   Teimoortashloo, Mazdak
   Mohammadiun, Mohammad
   Gharahbagh, Abdorreza Alavi
TI A hybrid method based on deep learning and ensemble learning for
   induction motor fault detection using sound signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Induction motor; Fault detection; Convolutional neural network; Wavelet
   scattering; Sound signal
ID DIAGNOSIS; BEARING; SIGNATURE; STATOR
AB Fault detection in induction motors has an important role in saving costs in various industries. Due to the wide range of faults in induction motors, using different electrical and mechanical properties such as motor current, vibration, heat, and flux to detect faults in different conditions is necessary. In this research, A fault detection scheme using sound signals has been proposed. Sound signals are not sensitive to faults, or their signal-to-noise ratio is lower than other properties but acquiring sound signals does not need direct contact with the motor or to stop the motor in many cases, and sound sensors (microphones) have a lower cost than other types of sensors. The proposed method uses a hybrid combination of Mel-frequency cepstral coefficients (MFCCs), Wavelet scattering, ensemble learning, convolutional neural network (CNN) classification methods. The results of ensemble learning and CNN are combined in a novel FUSION step, and the final result is determined. The proposed method was implemented on a standard database, and its efficiency was proved compared to the state-of-the-art methods.
C1 [Shirdel, Shahryar] Islamic Azad Univ, Dept Elect Engn, Bojnourd Branch, Bojnourd, Iran.
   [Teimoortashloo, Mazdak] Islamic Azad Univ, Elect Ind Technol Dev Res Ctr, Bojnourd Branch, Bojnourd, Iran.
   [Mohammadiun, Mohammad] Islamic Azad Univ, Dept Mech Engn, Shahrood Branch, Shahrood, Iran.
   [Gharahbagh, Abdorreza Alavi] Islamic Azad Univ, Dept Elect Engn, Shahrood Branch, Shahrood, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University; Islamic Azad University
RP Teimoortashloo, M (corresponding author), Islamic Azad Univ, Elect Ind Technol Dev Res Ctr, Bojnourd Branch, Bojnourd, Iran.
EM mazdak1978@yahoo.com
OI Alavi Gharahbagh, Abdorreza/0000-0003-0863-1977; teimoortashloo,
   mazdak/0000-0002-8599-3253
FU No
FX No Statement Available
CR Akpudo U, 2020, LLE SVM 2020 INT C A, P404
   Al-Musawi AK, 2020, INFRARED PHYS TECHN, V104, DOI 10.1016/j.infrared.2019.103140
   Alamir MA, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107829
   AlBader M, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRICAL MACHINES (ICEM), VOL 1, P1452, DOI 10.1109/ICEM49940.2020.9270810
   Garcia-Calva TA, 2019, IEEE T ENERGY CONVER, V34, P1496, DOI 10.1109/TEC.2019.2917405
   [Anonymous], 2020, IEEE Sensors Journal
   Bacha K, 2012, INT J ELEC POWER, V43, P1006, DOI 10.1016/j.ijepes.2012.06.056
   Bazan GH, 2019, IEEE T IND ELECTRON, V66, P3237, DOI 10.1109/TIE.2018.2840983
   Choudhary A, 2021, IEEE SENS J, V21, P1727, DOI 10.1109/JSEN.2020.3015868
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Drakaki M, 2021, PROCEDIA COMPUT SCI, V180, P943, DOI 10.1016/j.procs.2021.01.345
   Endo T., 2019, Mimii dataset: Sound dataset for malfunctioning industrial machine investigation and inspection
   Ergin S, 2012, PROCEDIA ENGINEER, V30, P1103, DOI 10.1016/j.proeng.2012.01.969
   Fuyong Lyu, 2020, 2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD), P89, DOI 10.1109/ICSMD50554.2020.9261684
   Gandhi P, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103077
   Gangsar P, 2020, MECH SYST SIGNAL PR, V144, DOI 10.1016/j.ymssp.2020.106908
   Gülmezoglu MB, 2007, EUR T ELECTR POWER, V17, P628, DOI 10.1002/etep.161
   Gulmezoglu MB, 2007, COMPUT SPEECH LANG, V21, P266, DOI 10.1016/j.csl.2006.06.002
   Hajary A, 2019, IEEE T POWER ELECTR, V34, P11241, DOI 10.1109/TPEL.2019.2901598
   Hmida MA, 2020, IEEE T INSTRUM MEAS, V69, P8207, DOI 10.1109/TIM.2020.2993107
   Hosseinpoor Z, 2020, IEEE Sensors Journal
   Jeffali F, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.07.001
   Jiang YC, 2021, DIGIT SIGNAL PROCESS, V114, DOI 10.1016/j.dsp.2021.103055
   Juez-Gil M, 2020, ISA T, V106, P367, DOI 10.1016/j.isatra.2020.07.002
   Khanjani M, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108622
   Li JM, 2020, ISA T, V102, P335, DOI 10.1016/j.isatra.2020.02.031
   Luong P, 2020, IEEE-ASME T MECH, V25, P1067, DOI 10.1109/TMECH.2020.2970274
   Müller R, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P49, DOI 10.5220/0010185800490056
   Müller R, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P97, DOI 10.5220/0010226800970106
   Nguyen M, 2020, IEEE 8 INT C COMMUNI, P313
   Panagiotou PA, 2019, IEEE T IND APPL, V55, P3501, DOI 10.1109/TIA.2019.2905803
   Park Y, 2020, IEEE T IND APPL, V56, P4748, DOI 10.1109/TIA.2020.3000461
   Principi E, 2019, IEEE-CAA J AUTOMATIC, V6, P441, DOI 10.1109/JAS.2019.1911393
   Rocha EM, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106373
   Sadeghi R, 2019, IEEE T IND INFORM, V15, P4506, DOI 10.1109/TII.2018.2881921
   Sangeetha BP, 2019, IEEE T IND INFORM, V15, P3492, DOI 10.1109/TII.2018.2874463
   Singh A, 2020, ARTIF INTELL REV, V53, P3673, DOI 10.1007/s10462-019-09775-8
   Soleimani Y, 2019, IEEE T INSTRUM MEAS, V68, P2916, DOI 10.1109/TIM.2018.2870265
   Stief A, 2019, IEEE T IND ELECTRON, V66, P9510, DOI 10.1109/TIE.2019.2891453
   Suefusa K, 2020, INT CONF ACOUST SPEE, P271, DOI [10.1109/ICASSP40776.2020.9054344, 10.1109/icassp40776.2020.9054344]
   Tariq MF, 2019, IEEE T IND ELECTRON, V66, P4707, DOI 10.1109/TIE.2018.2866104
   Wang MH, 2021, IEEE Transactions on Power Delivery
   Xie Y, 2019, MECH SYST SIGNAL PR, V123, P554, DOI 10.1016/j.ymssp.2019.01.030
   Yaman O, 2021, MEASUREMENT, V168, DOI 10.1016/j.measurement.2020.108323
   Yassa N, 2019, ENRGY PROCED, V162, P251, DOI 10.1016/j.egypro.2019.04.027
   Zamudio-Ramirez Israel R, 2021, IEEE Transactions on Industrial Informatics
   Zarei J, 2019, IEEE T ENERGY CONVER, V34, P870, DOI 10.1109/TEC.2018.2877781
   Zhang S, 2020, IEEE T IND APPL, V56, P2158, DOI 10.1109/TIA.2020.2979383
NR 49
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 4
PY 2023
DI 10.1007/s11042-023-15996-5
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8Q2
UT WOS:001121582100003
DA 2024-07-18
ER

PT J
AU Tahir, M
   Halim, Z
   Waqas, M
   Sukhia, KN
   Tu, SS
AF Tahir, Madiha
   Halim, Zahid
   Waqas, Muhammad
   Sukhia, Komal Nain
   Tu, Shanshan
TI Emotion detection using convolutional neural network and long short-term
   memory: a deep multimodal framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data mining; Emotion recognition; Short text analysis; Sentiment
   classification; Learning system; Deep learning; Affective dataset
ID TEXT; RECOGNITION
AB Emotion detection systems play a crucial role in enhancing human-computer interaction. Existing systems predominantly rely on machine learning techniques. This study introduces a novel emotion detection method that employs deep learning techniques to identify five basic human emotions and the pleasure dimensions (valence) associated with these emotions, using text and keystroke dynamics. To facilitate this, we develop a non-acted dataset, DEKT-345 x 2, which includes text and keystroke features. The dataset is created by inducing emotions in participants under controlled conditions. Deep learning models are subsequently employed to predict a person's affective state using textual content. Semantic analysis of the text data is achieved by employing the global vector (Glove) representation of words. For both text and keystroke-based analysis, one-dimensional convolutional neural network (Conv1D), long short-term memory (LSTM), sandwich Conv1D, and sandwich LSTM models are employed. The robustness of our proposed method is assessed using the DEKT-345 x 2 dataset, which collects text and keystroke information from 69 participants. Through parameter tuning on training and validation data, we establish models that demonstrate superior performance compared to five related approaches and three machine learning classifiers. Our proposed framework achieves an accuracy of 88.57% using the LSTM model, 80% using the sandwich LSTM model, 71.42% using the Conv1D model, and 51.48% using the sandwich Conv1D model on text data across the five emotion classes.
C1 [Tahir, Madiha] Inst Space Technol, Islamabad 45730, Pakistan.
   [Halim, Zahid] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Machine Intelligence Res Grp MInG, Topi 23460, Pakistan.
   [Waqas, Muhammad; Tu, Shanshan] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   [Tahir, Madiha; Sukhia, Komal Nain] Inst Space Technol, Islamabad, Pakistan.
C3 GIK Institute Engineering Science & Technology; Beijing University of
   Technology
RP Halim, Z (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Machine Intelligence Res Grp MInG, Topi 23460, Pakistan.
EM madiha.tahir@ist.edu.pk; halimzahid@gmail.com; engr.waqas2079@gmail.com;
   komal.nain@ist.edu.pk; sstu@bjut.edu.cn
RI Waqas, Muhammad/ABB-4987-2021; Tahir, Madiha/KCJ-9981-2024
OI Waqas, Muhammad/0000-0003-0208-5784; Tahir, Madiha/0009-0001-2890-3661
FU GIK Institute graduate program research fund
FX The authors are indebted to the editor and anonymous reviewers for their
   helpful comments and suggestions. The authors would like to thank GIK
   Institute for providing research facilities. This work was supported by
   the GIK Institute graduate program research fund under the GA-4 scheme.
CR Aadam, 2022, SOFT COMPUT, V26, P10563, DOI 10.1007/s00500-021-06578-4
   Adolphs R, 2017, SOC COGN AFFECT NEUR, V12, P24, DOI 10.1093/scan/nsw153
   Ali N, 2023, ACM Transactions on Asian and Low-Resource Language Information Processing, DOI [10.1145/3592794, DOI 10.1145/3592794]
   Alm ECO., 2008, AFF TEXT SPEECH
   AVERILL JR, 1983, AM PSYCHOL, V38, P1145, DOI 10.1037/0003-066X.38.11.1145
   Binali H, 2010, 4 IEEE INT C DIG EC
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Calix RA, 2010, IEEE T MULTIMEDIA, V12, P544, DOI 10.1109/TMM.2010.2052026
   Epp C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P715
   Fortin MP, 2019, PROCEEDINGS OF THE ACM WORKSHOP ON CROSSMODAL LEARNING AND APPLICATION (WCRML'19), P3, DOI 10.1145/3326459.3329165
   Gaggioli Andrea, 2019, Cyberpsychol Behav Soc Netw, V22, P358, DOI 10.1089/cyber.2019.29150.csi
   Gao T, 2019, INT C INNOVATIVE MOB, P658
   Ghosh S, 2019, INT J HUM-COMPUT ST, V130, P47, DOI 10.1016/j.ijhcs.2019.04.005
   Ghosh S, 2017, INT CONF AFFECT, P146, DOI 10.1109/ACII.2017.8273592
   Grover S, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 2, P240
   Gu Y, 2018, IEEE INT C ACOUSTICS
   Halim Z, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106443
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolakowska A, 2016, ACSIS-ANN COMPUT SCI, V8, P1621, DOI 10.15439/2016F263
   Kolakowska A, 2015, C HUM SYST INTERACT, P291, DOI 10.1109/HSI.2015.7170682
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Kumar KMA, 2015, PROCEDIA COMPUT SCI, V70, P296, DOI 10.1016/j.procs.2015.10.096
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Li X, 2016, INT JOINT C NEURAL N
   Li YZ, 2017, ADV NEUR IN, V30
   Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   Marcus G., 2021, Commun. ACM, V64, P38, DOI [DOI 10.1145/3392663, 10.1145/3392663]
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Nahin AFMNH, 2014, BEHAV INFORM TECHNOL, V33, P987, DOI 10.1080/0144929X.2014.907343
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qin Y, 2020, J SIGNAL PROCESS SYS, V92, P819, DOI 10.1007/s11265-019-01511-3
   Rachman FH, 2016, 3 INT C INFORM TECHN
   Rahman AU, 2023, APPL INTELL, V53, P2798, DOI 10.1007/s10489-022-03552-x
   Roccetti M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0235-y
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Shikder R, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON NETWORKING, SYSTEMS AND SECURITY (NSYSS), P96, DOI 10.1109/NSysS.2017.7885808
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tahir M, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00234-5
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Xin Y, 2018, IEEE ACCESS, V6, P35365, DOI 10.1109/ACCESS.2018.2836950
   Yasmina D, 2016, PROCEDIA COMPUT SCI, V83, P292, DOI 10.1016/j.procs.2016.04.128
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
NR 47
TC 2
Z9 2
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 21
PY 2023
DI 10.1007/s11042-023-17653-3
EA NOV 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y6BH9
UT WOS:001106086000003
DA 2024-07-18
ER

PT J
AU Sidhu, S
   Khurana, SS
   Kumar, M
   Singh, P
   Bamber, SS
AF Sidhu, Simran
   Khurana, Surinder S.
   Kumar, Munish
   Singh, Parvinder
   Bamber, Sukhvinder S.
TI Sentiment analysis of Hindi language text: a critical review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Sentiment analysis; Opinion mining; Machine learning; Natural language
   processing; Stemming; Negation handling; Hindi language
AB Sentiment analysis involves extracting sentiments from various forms of text, including customer reviews, tweets, blogs, and news clips expressing opinions on diverse subjects, even populist events. The advent of tools supporting regional languages has resulted in a substantial surge of regional language texts. As Hindi ranks fourth in terms of native speakers, the development of sentiment analysis mechanisms for Hindi text becomes crucial. This paper provides a comprehensive review of specific approaches used in Hindi sentiment analysis, encompassing negation handling and the evolution of SentiWordNet for the Hindi Language. Moreover, it offers an overview of available Hindi lexicons and insights into diverse stemmers and morphological analyzers designed for the language. Additionally, the paper conducts an in-depth literature review of various sentiment analysis tasks carried out in Hindi, thereby opening avenues for future research in sentiment analysis and opinion mining in the Hindi language.
C1 [Sidhu, Simran; Khurana, Surinder S.; Singh, Parvinder] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Bamber, Sukhvinder S.] Panjab Univ, SSG Reg Ctr, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Hoshiarpur, Punjab, India.
C3 Central University of Punjab; Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Singh, Parvinder/AAM-5012-2021; Kumar, Munish/P-7756-2018
OI Singh, Parvinder/0000-0001-7258-7769; Kumar, Munish/0000-0003-0115-1620
CR Akhtar MS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2703
   Ankita S., 2020, Procedia Comput. Sci, V173, P325, DOI [10.1016/j.procs.2020.06.038, DOI 10.1016/J.PROCS.2020.06.038]
   [Anonymous], 2010, P NAACL HLT 2010 1 W
   [Anonymous], 2013, P 11 WORKSHOP ASIAN
   Arora P., 2013, Sentiment analysis for Hindi language. MS by Research in Computer Science
   Bahuguna A, 2014, P 11 INT C NATURAL L, P69
   Bakliwal A., 2011, P WORKSH SENT AN AI, P101
   Bakliwal A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1189
   Balamurali AR, 2012, P COLING 2012, P73
   Bansal N., 2013, Sentiment Analysis in Hindi, P1
   Basile V, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020029
   Bharati A, 2001, P NAT LANG PROC PAC, P685
   BhardwajKumar MKA., 2016, INT J INNOV RES TECH, V3, P43
   Bhatia Tej K., 1995, Negation in South Asian languages
   Bhattacharyya P, 2010, P 8 INT C NAT LANG P
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bose R, 2019, SMART INNOV SYST TEC, V107, P427, DOI 10.1007/978-981-13-1747-7_41
   Chen A, 2003, ACM Trans Asian Language Inform Process, V2
   Chu CT, 2005, Classifying the sentiment of movie review data, P1
   Das A, P 8 WORKSH AS LANG R, P56
   Das A., 2010, Knowledge Sharing Event-4: Task, V2, P1
   Das Dipankar, 2012, Natural Language Processing and Information Systems. Proceedings 17th International Conference on Applications of Natural Language to Information Systems, NLDB 2012, P320, DOI 10.1007/978-3-642-31178-9_41
   Desai Nikita, 2016, Int. J., V4, P8
   Devika MD, 2016, PROCEDIA COMPUT SCI, V87, P44, DOI 10.1016/j.procs.2016.05.124
   Dutta Kamlesh, 2011, Prague Bulletin of Mathematical Linguistics, P33, DOI 10.2478/v10108-011-0003-4
   Ganguly D, 2013, P 4 5 ANN M FORUM IN, P1
   Ghosh A, 2014, P 35 C LING SOC NEP, P1
   Goyal Vishal., 2008, 2008 First International Conference on Emerging Trends in Engineering and Technology, P1156, DOI DOI 10.1109/ICETET.2008.11
   Gupta H., 2015, Int J Innov Res Comput Commun Eng, V3, P3132
   Gupta V., 2014, Int J Adv Res Comput Sci Softw Eng, V4, P62
   Gupta V, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3450447
   Guru KP., 1952, Hindi vyakaran
   Huang CQ, 2021, AUSTRALAS J EDUC TEC, V37, P81, DOI 10.14742/ajet.6749
   Islam MZ, 2007, A light weight stemmer for bengali and its use in spelling checker
   Jain A, 2013, POSTPROCEEDINGS 4 5, P1
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Jha V., 2016, Int J Sci Eng Res, V7, P968
   Jha V, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P366, DOI 10.1109/ReTIS.2015.7232906
   Jhanwar MG, 2018, P 1 WORKSH HUM AI HA, P1
   Kachru Y., 1980, ASPECTS HINDI GRAMMA
   Karra AK, 2010, WordNet Linking
   Kumar Ayush, 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P684, DOI 10.1007/978-3-319-26832-3_65
   Kumar A, 2008, P 2 WORKSH AN NOIS U, P99
   Kumar Rakesh, 2020, Smart Trends in Computing and Communications. Proceedings of SmartCom 2019. Smart Innovation, Systems and Technologies (SIST 165), P115, DOI 10.1007/978-981-15-0077-0_13
   Lahiri Utpal., 1998, NAT LANG SEMANT, V6, P57, DOI DOI 10.1023/A:1008211808250
   Larkey Leah S., 2003, ACM Transactions on Asian Language Information Processing, V2, P130
   Li L, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101862
   Li L, 2024, IEEE T COMPUT SOC SY, V11, P1402, DOI 10.1109/TCSS.2023.3246181
   Li Y, 2023, Image and Vision Computing
   Liu S., 2023, ACM Transactions on Asian and Low-Resource Language Information Processing, V22, P1
   Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6
   Maheshwari S., 2017, Review of Business and Technology Research, V14, P70
   Majumder P, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1281485.1281489
   Malakar PK, 2015, International Journal of Research Studies in Computer Science and Engineering (IJRSCSE), P39
   Medagoda N, 2013, INT CONF ADV ICT, P144, DOI 10.1109/ICTer.2013.6761169
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Mishra D, 2016, PROCEDIA COMPUT SCI, V93, P554, DOI 10.1016/j.procs.2016.07.283
   Mishra Upendra, 2012, INT J COMPUT SCI ENG, V4, P711
   Morph, 2001, Hindi Morphological Analyser
   Mukherjee Subhabrata., 2012, COLING, P1847
   Mukhopadhyay S., 2012, SAGE Open, V2, P1, DOI [10.1177/2158244012451584, DOI 10.1177/2158244012451584]
   Mulatkar S., 2014, Int J Sci Technol Res, V3, P204
   Narayan D, 2002, P 1 INT C GLOB WORDN, P1
   Nie WZ, 2024, IEEE T MULTIMEDIA, V26, P514, DOI 10.1109/TMM.2023.3267295
   Pande BP., 2014, Int J Comput Linguist Res, V5, P119
   Pandey P, 2012, Cross-Lingual Word Sense Disambiguation using Wordnets and Context based Mapping
   Pandey P., 2015, INT J COMPUT APPL, V119, P23, DOI DOI 10.5120/21176-4185
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Patra Braja Gopal, 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P650, DOI 10.1007/978-3-319-26832-3_61
   Patra BG, 2015, P 12 INT C NAT LANG, P261
   Patra BrajaGopal., 2013, Proceedings of Sixth International Joint Conference on Natural Language Processing, P24
   Ramanathan A, 2003, P C EUR CHAPT ASS CO, P1
   Rudra Koustav, 2016, P 2016 C EMPIRICAL M, P1131
   Se Shriya, 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P703, DOI 10.1007/978-3-319-26832-3_67
   Sharma G, 2001, Annali di Ca'Foscari. Serieorientale, VXL, P131
   Sharma R., 2014, INT J COMPUTATIONAL, V4, P49, DOI https://doi.org/10.5121/ijcsa.2014.4405
   Shrestha H, 2020, INT J SPEECH TECHNOL, V23, P757, DOI 10.1007/s10772-020-09730-x
   Shrivastava K, 2020, INT ARAB J INF TECHN, V17, P954, DOI 10.34028/iajit/17/6/14
   Singh JP, 2015, LECT NOTES COMPUT SC, V9373, P416, DOI 10.1007/978-3-319-25013-7_33
   Sinha M, 2003, P INT S MACH TRANSL, P1
   Wang S, 2023, APPL SOFT COMPUT, V145, DOI 10.1016/j.asoc.2023.110570
   Yadav A, 2012, POSTPR FIRE 2012, P1
   Yadav M., 2015, Int J Innov Adv Comput Sci (IJIACS), V4, P14
   Zhang X, 2023, CAAI T INTELL TECHNO, V8, P1480, DOI [10.1049/cit2.12174, 10.7633/j.issn.1003-6202.2023.06.001]
NR 84
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17537-6
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900006
DA 2024-07-18
ER

PT J
AU Khan, MA
   AlGhamdi, MA
AF Khan, Murtaza Ali
   AlGhamdi, Mohammed A.
TI An intelligent and fast system for detection of grape diseases in RGB,
   grayscale, YCbCr, HSV and L*a*b* color spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Grape diseases; Classification; Multiclass support vector machine; Color
   spaces
ID IMAGE; SELECTION
AB To avoid loss and maintain the quality of the crop, identifying plant diseases is essential. However, it is challenging and time-consuming to identify a plant disease on-site. An intelligent method to identify and categorize diseases in grape plants is described in this work. In the proposed method, digital images of grape plants are used to find the features of healthy and disease-affected plants. Global features determine color and texture information, while patterns or structures (e.g., corners or edges) are detected using the speeded-up robust features (SURF) method. The number of features is reduced by quantifying feature space using the K-means clustering algorithm. The concise set of features serves as the training set of the support vector machine (SVM) classier. During testing, the system determined the class of unlabeled images using the trained SVM classifier. The original data set consists of 1600 images in RGB color space belonging to one healthy and three disease classes Black-measles, Black-rot, Leaf-blight, and Healthy-leaf. Simulations are performed in four color spaces: grayscale, YCbCr, HSV, and L*a*b*, to test the system and compute accuracy and confusion matrices. On-the-fly conversion transforms RGB images to other color spaces. The system achieved a maximum average accuracy of up to 90.63% at 70:30 training: testing data ratio in the L*a*b* color space. The suggested approach is compared with a deep learning-based convolutional neural network that utilizes ResNet-50 and transfers learning to categorize grape images
C1 [Khan, Murtaza Ali] Sohar Univ, Fac Comp & Informat Technol, Sohar, Oman.
   [AlGhamdi, Mohammed A.] Umm Al Qura Univ, Coll Comp & Informat Syst, Makkah Al Mukarramah, Saudi Arabia.
C3 Sohar University; Umm Al Qura University
RP Khan, MA (corresponding author), Sohar Univ, Fac Comp & Informat Technol, Sohar, Oman.
EM mukhan@su.edu.om; maeghamdi@uqu.edu.sa
RI Al-Ghamdi, Mohammed Saad/N-6668-2014; Al-Ghamdi, Mohammed.
   I./ISU-9198-2023; Khan, Murtaza Ali/AHA-3568-2022
OI Al-Ghamdi, Mohammed. I./0000-0002-9794-554X; Khan, Murtaza
   Ali/0000-0002-3442-8019
CR Akstinaite V, 2022, BRIT J MANAGE, V33, P1163, DOI 10.1111/1467-8551.12503
   AlGhamdi MA, 2020, ARAB J SCI ENG, V45, P6021, DOI 10.1007/s13369-020-04447-0
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benrais L, 2022, MULTIMED TOOLS APPL, V81, P3663, DOI 10.1007/s11042-021-11701-6
   Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Creasy T., 2018, Adapting and Adjusting Change Management in Agile
   Cristianini Nello., 2001, An Introduction to Support Vector Machines and Other Kernel-based Learning Methods, P22, DOI [DOI 10.1017/CBO9780511801389, 10.1017/CBO9780511801389]
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Gao F, 2016, MULTIDIM SYST SIGN P, V27, P969, DOI 10.1007/s11045-016-0396-1
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Healthy and disease affected leaves of grape plant, 2023, Healthy and disease affected leaves of grape plant
   Islam M, 2017, CAN CON EL COMP EN
   Khan MA, 2021, INT J IMAG SYST TECH, V31, P499, DOI 10.1002/ima.22564
   Kim TH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06562-4
   LEDWICH L, 2004, AUSTR C ROB AUT
   Li DH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540167
   Lin WC, 2016, INFORM SCIENCES, V329, P33, DOI 10.1016/j.ins.2015.08.021
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mullins M.G., 1992, Biology of the grapevine
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Plant village dataset at kaggle, 2021, Plant village dataset at kaggle
   Prasad S, 2016, SIGNAL IMAGE VIDEO P, V10, P379, DOI 10.1007/s11760-015-0751-y
   Salgadoe ASA, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020226
   Sha ZJ, 2020, INT J IMAG SYST TECH, V30, P495, DOI 10.1002/ima.22400
   Shrivastava S, 2015, MULTIMED TOOLS APPL, V74, P11467, DOI 10.1007/s11042-014-2239-0
   Singh A, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12526
   Stoean C., 2014, SUPPORT VECTOR MACHI, DOI DOI 10.1007/978-3-319-06941-8
   Umer M, 2021, COMPUT INTELL-US, V37, P409, DOI 10.1111/coin.12415
   V K, 2005, Support vector machines: theory and applications in support vector machines
NR 37
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17446-8
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500014
DA 2024-07-18
ER

PT J
AU Vanambathina, SD
   Burra, M
   Edupalli, B
   Vallem, ER
   Nellore, VS
AF Vanambathina, Sunny Dayal
   Burra, Manaswini
   Edupalli, Bhumika
   Vallem, Eswar Reddy
   Nellore, Venkata Sravani
TI Real time speech enhancement using densely connected neural networks and
   Squeezed temporal convolutional modules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech Enhancement; Convolutional neural networks; Squeezed temporal
   convolutional network; PESQ; STOI
ID NOISE; SEPARATION; END
AB In this paper, we present a fully convolutional neural network for enhancing real-time speech in the time domain. Skip connections are included in the architecture of the proposed encoder-decoder network. The layers in the decoder and encoder consists of densely connected blocks (DCB) with causal and dilated convolutions. These dilated convolutions facilitate the aggregation of contextual information across multiple resolutions. The network is ideal for real-time applications due to the causal convolutions' utilization of information inflow prevention from subsequent frames. Additionally, we propose employing up sampling in the decoder with sub-pixel convolutional layers. We also proposed a Squeezed temporal convolutional network (STCNs) after every dense block in encoder and decoder. According to experimental outcomes, the suggested model greatly surpasses previous state-of-the-art models in quality scores as well as objective intelligibility in real-time scenarios.
C1 [Vanambathina, Sunny Dayal; Edupalli, Bhumika] Vellore Inst Technol Andhra Pradesh VIT AP, Dept Elect & Commun Engn, Amaravathi 522237, India.
   [Burra, Manaswini] Potti Sriramulu Chalavadhi Mallikarjuna Rao Coll E, CSE DS Dept, Vijayawada, Andhra Pradesh, India.
   [Vallem, Eswar Reddy; Nellore, Venkata Sravani] Vellore Inst Technol Andhra Pradesh VIT AP, Dept Comp Sciene Engn, Amaravathi 522237, India.
C3 VIT-AP University; VIT-AP University
RP Vanambathina, SD (corresponding author), Vellore Inst Technol Andhra Pradesh VIT AP, Dept Elect & Commun Engn, Amaravathi 522237, India.
EM sunny.dayal@vitap.ac.in; manaswini.burra@gmail.com;
   bhoomika.19bec7146@vitap.ac.in; eswar.20bce7172@vitap.ac.in;
   sravani.20bcd7139@vitap.ac.in
CR Chen Z, 2017, INTERSPEECH, P3632, DOI 10.21437/Interspeech.2017-515
   Choi HS, 2019, Arxiv, DOI [arXiv:1903.03107, 10.48550/arXiv.1903.03107, DOI 10.48550/ARXIV.1903.03107]
   Défossez A, 2020, INTERSPEECH, P3291, DOI 10.21437/Interspeech.2020-2409
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Fu SW, 2017, IEEE INT WORKS MACH
   Fu SW, 2018, IEEE-ACM T AUDIO SPE, V26, P1570, DOI 10.1109/TASLP.2018.2821903
   Kingma DP, 2021, INT C LEARNING REPRE, P1
   Kishore V, 2020, INTERSPEECH, P4531, DOI 10.21437/Interspeech.2020-3122
   Koyama Y, 2020, Arxiv, DOI arXiv:2005.11611
   Li AD, 2020, INTERSPEECH, P2422, DOI 10.21437/Interspeech.2020-1513
   Li AD, 2021, IEEE-ACM T AUDIO SPE, V29, P1829, DOI 10.1109/TASLP.2021.3079813
   Liu CL, 2020, IEEE-ACM T AUDIO SPE, V28, P1888, DOI 10.1109/TASLP.2020.2976193
   Loizou P., 2017, SPEECH COMMUN, V49, P588
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Macartney C, 2018, Arxiv, DOI [arXiv:1811.11307, DOI 10.48550/ARXIV.1811.11307]
   Narayanan A, 2014, IEEE-ACM T AUDIO SPE, V22, P826, DOI 10.1109/TASLP.2014.2305833
   Oord A., 2016, ARXIV160903499
   Paliwal K, 2011, SPEECH COMMUN, V53, P465, DOI 10.1016/j.specom.2010.12.003
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Pandey A, 2021, IEEE-ACM T AUDIO SPE, V29, P1270, DOI [10.1109/TASLP.2021.3064421, 10.1109/taslp.2021.3064421]
   Pandey A, 2019, INT CONF ACOUST SPEE, P6875, DOI [10.1109/ICASSP.2019.8683634, 10.1109/icassp.2019.8683634]
   Pandey A, 2019, INT CONF ACOUST SPEE, P6885, DOI [10.1109/icassp.2019.8682169, 10.1109/ICASSP.2019.8682169]
   Pandey A, 2018, INTERSPEECH, P1136
   Pascual S, 2017, Arxiv, DOI [arXiv:1703.09452, DOI 10.48550/ARXIV.1703.09452]
   Reddy CKA, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6623, DOI 10.1109/ICASSP39728.2021.9415105
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tan K, 2019, INT CONF ACOUST SPEE, P6865, DOI 10.1109/ICASSP.2019.8682834
   Tan K, 2018, INTERSPEECH, P3229
   Thiemann J., 2013, J. Acoustical Soc. Amer., V133
   Ullah R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207782
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wan K, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7098, DOI 10.1109/ICASSP39728.2021.9413740
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   WANG DL, 1982, IEEE T ACOUST SPEECH, V30, P679, DOI 10.1109/TASSP.1982.1163920
   Wang Q, 2019, INTERSPEECH, P2728, DOI 10.21437/Interspeech.2019-1101
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Zhang QQ, 2020, Arxiv, DOI arXiv:1912.12023
NR 40
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17492-2
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500004
DA 2024-07-18
ER

PT J
AU Nnadozie, EC
   Casaseca-de-la-Higuera, P
   Iloanusi, O
   Ani, O
   Alberola-López, C
AF Nnadozie, Emmanuel C.
   Casaseca-de-la-Higuera, Pablo
   Iloanusi, Ogechukwu
   Ani, Ozoemena
   Alberola-Lopez, Carlos
TI Simplifying YOLOv5 for deployment in a real crop monitoring setting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Model simplification; Crop monitoring; YOLOv5; Deep
   learning
ID CONVOLUTIONAL NEURAL-NETWORK; ARCHITECTURE SEARCH; IDENTIFICATION;
   COMPRESSION
AB Deep learning-based object detection models have become a preferred choice for crop detection tasks in crop monitoring activities due to their high accuracy and generalization capabilities. However, their high computational demand and large memory footprint pose a challenge for use on mobile embedded devices deployed in crop monitoring settings. Various approaches have been taken to minimize the computational cost and reduce the size of object detection models such as channel and layer pruning, detection head searching, backbone optimization, etc. In this work, we approached computational lightening, model compression, and speed improvement by discarding one or more of the three detection scales of the YOLOv5 object detection model. Thus, we derived up to five separate fast and light models, each with only one or two detection scales. To evaluate the new models for a real crop monitoring use case, the models were deployed on NVIDIA Jetson nano and NVIDIA Jetson Orin devices. The new models achieved up to 21.4% reduction in giga floating-point operations per second (GFLOPS), 31.9% reduction in number of parameters, 30.8% reduction in model size, 28.1% increase in inference speed, with only a small average accuracy drop of 3.6%. These new models are suitable for crop detection tasks since the crops are usually of similar sizes due to the high likelihood of being in the same growth stage, thus, making it sufficient to detect the crops with just one or two detection scales.
C1 [Nnadozie, Emmanuel C.; Casaseca-de-la-Higuera, Pablo; Alberola-Lopez, Carlos] Univ Valladolid, Lab Proc Imagen, ETSI Telecomunicac, Valladolid, Spain.
   [Nnadozie, Emmanuel C.; Iloanusi, Ogechukwu] Univ Nigeria, Dept Elect Engn, Nsukka, Nigeria.
   [Nnadozie, Emmanuel C.; Ani, Ozoemena] Univ Nigeria, Dept Mechatron Engn, Enugu, Nigeria.
C3 Universidad de Valladolid; University of Nigeria; University of Nigeria
RP Nnadozie, EC (corresponding author), Univ Valladolid, Lab Proc Imagen, ETSI Telecomunicac, Valladolid, Spain.; Nnadozie, EC (corresponding author), Univ Nigeria, Dept Elect Engn, Nsukka, Nigeria.; Nnadozie, EC (corresponding author), Univ Nigeria, Dept Mechatron Engn, Enugu, Nigeria.
EM ennadozie@lpi.tel.uva.es; jcasasec@tel.uva.es;
   ogechukwu.iloanusi@unn.edu.ng; ozoemena.ani@unn.edu.ng;
   caralb@tel.uva.es
OI Iloanusi, Ogechukwu/0000-0002-6306-9713; Nnadozie, Emmanuel
   Chibuikem/0000-0002-0965-0937
FU Springer Nature; TETFUND NRF 2020
   [TETF/ES/DR&D-CE/NRF2020/SETI/88/VOL.1]; ERASMUS + KA107 (ICM) PhD
   Mobility Scholarship; DAAD In-country/In-region PhD scholarship; Agencia
   Estatal de Investigacion [PID2020-115339RB-I00, CPP2021-008880]; EU
   Horizon 2020 Research and Innovation Programme under the Marie
   Sklodowska-Curie [101008297]; Marie Curie Actions (MSCA) [101008297]
   Funding Source: Marie Curie Actions (MSCA)
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research was funded by TETFUND NRF 2020 with grant
   number TETF/ES/DR & D-CE/NRF2020/SETI/88/VOL.1, ERASMUS + KA107 (ICM)
   PhD Mobility Scholarship, and DAAD In-country/In-region PhD scholarship.
   Thanks are also given to Agencia Estatal de Investigacion for grant
   PID2020-115339RB-I00 and grant CPP2021-008880. The work was additionally
   supported in part by the EU Horizon 2020 Research and Innovation
   Programme under the Marie Sklodowska-Curie grant agreement No 101008297.
   This article reflects only the authors' view. The European Union
   Commission is not responsible for any use that may be made of the
   information it contains.
CR Boateng VA, 2023, IEEE ACCESS, V11, P62605, DOI 10.1109/ACCESS.2023.3287975
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Camci E, 2022, IEEE T CIRC SYST VID, V32, P6488, DOI 10.1109/TCSVT.2022.3167951
   Chitty-Venkata KT, 2023, IEEE ACCESS, V11, P25217, DOI 10.1109/ACCESS.2023.3253818
   Choi K, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073777
   Czymmek V, 2019, IEEE IMTC P, P585, DOI 10.1109/i2mtc.2019.8826921
   DECI AI, 2023, YOLO-NAS
   Ding ZX, 2022, IEEE T NEUR NET LEAR, V33, P5004, DOI 10.1109/TNNLS.2021.3067028
   Feng ZX, 2021, IEEE T IMAGE PROCESS, V30, P6985, DOI 10.1109/TIP.2021.3101158
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hoefler T, 2021, J MACH LEARN RES, V23
   Jeon ES, 2023, NEUROCOMPUTING, V518, P466, DOI 10.1016/j.neucom.2022.11.029
   Jocher G., 2023, YOLO ULTRALYTICS VER
   Jocher Glenn, 2020, Zenodo
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Khan S, 2023, COMPUT ELECTR ENG, V110, DOI 10.1016/j.compeleceng.2023.108867
   Kim T., 2021, P 30 INT JOINT C ART, P2628, DOI DOI 10.24963/IJCAI.2021/362
   Kirchhoffer H, 2022, IEEE T CIRC SYST VID, V32, P3203, DOI 10.1109/TCSVT.2021.3095970
   Knight Autumn, 2020, 2020 International Conference on Computational Science and Computational Intelligence (CSCI), P1684, DOI 10.1109/CSCI51800.2020.00310
   Li C., 2022, ARXIV, DOI [DOI 10.48550/ARXIV.2209.02976, 10.48550/arXiv.2209.02976]
   Li JR, 2023, IEEE ACCESS, V11, P46441, DOI 10.1109/ACCESS.2023.3273952
   Lin Y, 2020, IEEE T VEH TECHNOL, V69, P5703, DOI 10.1109/TVT.2020.2983143
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   López-Granados F, 2011, WEED RES, V51, P1, DOI 10.1111/j.1365-3180.2010.00829.x
   Martinez-Alpiste I, 2021, NEURAL COMPUT APPL, V33, P9961, DOI 10.1007/s00521-021-05764-7
   Mazumder AN, 2021, IEEE J EM SEL TOP C, V11, P532, DOI 10.1109/JETCAS.2021.3129415
   Moazzam SI, 2019, 2019 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION IN INDUSTRY (ICRAI), DOI 10.1109/icrai47710.2019.8967350
   Mustafa Mohd Marzuki, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P632, DOI 10.1109/ISSPIT.2007.4458197
   Neill JO, 2020, arXiv, DOI [10.48550/arXiv.2006.03669, DOI 10.48550/ARXIV.2006.03669]
   Nekooei A, 2022, NEURAL NETWORKS, V150, P350, DOI 10.1016/j.neunet.2022.02.024
   Oymak S, 2021, INF INFERENCE, V10, P1031, DOI 10.1093/imaiai/iaaa042
   Qi Q, 2022, IEEE T EMERG TOP COM, V10, P886, DOI 10.1109/TETC.2021.3050770
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Romeo J, 2013, EXPERT SYST APPL, V40, P2275, DOI 10.1016/j.eswa.2012.10.033
   Sepahvand M, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105560
   Sirisha U, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00302-w
   Sun WZ, 2021, IEEE J-STSP, V15, P603, DOI 10.1109/JSTSP.2020.3038227
   Tang JL, 2017, COMPUT ELECTRON AGR, V135, P63, DOI 10.1016/j.compag.2017.01.001
   Tao ZY, 2023, IEEE T CLOUD COMPUT, V11, P1733, DOI 10.1109/TCC.2022.3160129
   Thomas JB, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105890
   Thuan D., 2021, Bachelors Thesis
   Tzutalin, 2015, LAB GIT COD
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang Chien-Yao, 2021, YOU ONLY LEARN ONE R, DOI DOI 10.48550/ARXIV.2105.04206
   Wang DD, 2021, BIOSYST ENG, V210, P271, DOI 10.1016/j.biosystemseng.2021.08.015
   Wang ZP, 2022, POSTHARVEST BIOL TEC, V185, DOI 10.1016/j.postharvbio.2021.111808
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Wu GL, 2021, IEEE ACCESS, V9, P127917, DOI 10.1109/ACCESS.2021.3112695
   Xu S., 2022, arXiv preprint arXiv:2203.16250, P1, DOI [10.48550/arXiv.2203.16250, DOI 10.48550/ARXIV.2203.16250]
   Xu X, 2022, arXiv, DOI [10.48550/arXiv.2211.15444, DOI 10.48550/ARXIV.2211.15444]
   Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756
   Zaidi SSA, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103514
   Zoph B, 2017, arXiv, DOI [10.48550/arXiv.1611.01578, DOI 10.48550/ARXIV.1611.01578]
NR 61
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17435-x
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200016
OA hybrid
DA 2024-07-18
ER

PT J
AU Jana, M
   Jana, B
   Joardar, S
AF Jana, Manasi
   Jana, Biswapati
   Joardar, Subhankar
TI Reversible data hiding strategy exploiting circular distance
   interpolation utilizing optimal pixel adjustment with error substitution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding (RDH); Arnold transform (AT); Circular distance
   interpolation (CDI); Input value replacement (IVR); Optimal pixel
   adjustment process (OPAP)
ID PREDICTION-ERROR; IMAGE; SCHEME; PAYLOAD
AB Numerous reversible data hiding schemes have been proposed with the goal of ensuring both security and availability of the original image. However, in the case of medical images, there is a risk of information leakage and image distortion, which must be avoided. To address this issue, an innovative reversible data hiding scheme based on circular distance interpolation utilizing optimal pixel adjustment with error substitution has been proposed in this paper. This approach aims to conceal confidential information within an image while preserving its visual quality, enhancing capacity, improve security and achieve reversibility. Before embedding, the secret data has been scrambled using Arnold transform technique to enhance security of the proposed scheme. In circular distance interpolation, a circle has been drawn taking interpolated pixel as center with different radius. Data hiding capacity has been increased by extending the reference pixels of a circular area specially in complex regions. Then identify all reference pixels from the circular region and embed secret data bits into the interpolated pixels. Finally, substitution error, optimal pixel adjustment process and input value replacement strategies are applied on intermediate stego image to get a high imperceptible stego image. The proposed data hiding scheme has been measured using standard evaluation metrics such as PSNR(dB), payload (bpp) and SSIM using different circular areas with higher values than existing interpolation based reversible data hiding schemes. The proposed phenomenon highlighted the significant and valuable features of hidden data communication research, which includes the ability to ensure hidden communication, which are crucial in our modern high-tech lifestyle. This approach has many advantages and benefits for various sectors such as private organizations, government agencies, and the public.
C1 [Jana, Manasi] Haldia Inst Technol, Dept Comp Applicat, Purba Medinipur 721657, W Bengal, India.
   [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
   [Joardar, Subhankar] Haldia Inst Technol, Dept Comp Sci & Engn, Purba Medinipur 721657, W Bengal, India.
C3 Haldia Institute of Technology; Vidyasagar University; Haldia Institute
   of Technology
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM manasi.das30@gmail.com; biswapatijana@gmail.com;
   subhankarranchi@yahoo.co.in
OI Jana, Biswapati/0000-0003-4476-3459
FU The authors would like to thank the anonymous reviewers and associate
   editor for their valuable suggestions that greatly improved the
   manuscript.
FX The authors would like to thank the anonymous reviewers and associate
   editor for their valuable suggestions that greatly improved the
   manuscript.
CR Atta R, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165786
   Banerjee A, 2018, ADV INTELL SYST, V672, P356, DOI 10.1007/978-981-10-7512-4_36
   Biswapati J, 2016, ADV INTELL SYST, V411, P239, DOI 10.1007/978-81-322-2731-1_22
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Chowdhuri Partha, 2019, International Journal of Computers and Applications, V41, P218, DOI 10.1080/1206212X.2017.1422587
   Chowdhuri P., 2018, Int J Comput Appl, V43, P38
   Datta K, 2024, MULTIMED TOOLS APPL, V83, P8591, DOI 10.1007/s11042-023-15727-w
   Debasis G, 2016, ADV INTELL SYST, V434, P403, DOI 10.1007/978-81-322-2752-6_40
   Dey Ashis, 2022, Computational Intelligence in Communications and Business Analytics: 4th International Conference, CICBA 2022, Revised Selected Papers. Communications in Computer and Information Science (1579), P85, DOI 10.1007/978-3-031-10766-5_8
   Fan M, 2023, IEEE Access
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   George J, 2014, ANNU IEEE IND CONF
   Hassan FS, 2022, CAAI T INTELL TECHNO, V7, P56, DOI 10.1049/cit2.12053
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P8805, DOI 10.1007/s11042-017-4775-x
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P763, DOI 10.1007/s11042-016-4230-4
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Jana B, 2016, ADV INTELL SYST, V439, P495, DOI 10.1007/978-981-10-0755-2_53
   Jana B, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P360, DOI 10.1145/2818567.2818674
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jana Manasi, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P157, DOI 10.1007/978-981-13-9042-5_14
   Jana M, 2022, J King Saud Univ-Comput Inf
   Jana M, 2022, INF SECUR J, V31, P527, DOI 10.1080/19393555.2021.1956023
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kankana Datta, 2021, Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2020. Advances in Intelligent Systems and Computing (AISC 1255), P671, DOI 10.1007/978-981-15-7834-2_62
   Kaur M., 2023, IEEE Access
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim S, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090835
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li S, 2023, IEEE Trans Dependable Secure Comput
   Li S, 2020, IEEE ACCESS, V8, P214732, DOI 10.1109/ACCESS.2020.3040048
   Li YH, 2020, IEEE ACCESS, V8, P32226, DOI 10.1109/ACCESS.2020.2973179
   Liby JJ, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S021812662250044X
   Lin CC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060765
   Lu TC, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050577
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Mehbodniya A, 2022, PROCESSES, V10, DOI 10.3390/pr10050858
   Meikap S, 2021, MULTIMED TOOLS APPL, V80, P5617, DOI 10.1007/s11042-020-09823-4
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Mohammad AA, 2023, Multimed Tools Appl, P1
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nottingham trent University UK, 2023, ucid image database
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pal P, 2021, MULTIMED TOOLS APPL, V80, P21651, DOI 10.1007/s11042-021-10651-3
   Pal P, 2018, MULTIMED TOOLS APPL, V77, P23073, DOI 10.1007/s11042-017-5568-y
   Panchikkil S, 2022, OPTIK, V250, DOI 10.1016/j.ijleo.2021.168137
   Prasad S, 2023, IEEE T INTELL TRANSP, V24, P6865, DOI 10.1109/TITS.2023.3264467
   Ren F, 2023, Multimed Tools Appl, P1
   Samudra Y., 2023, J King Saud Univ-Comput Inf, V35, P101636
   Sharma VK, 2022, MULTIMED TOOLS APPL, V81, P17817, DOI 10.1007/s11042-022-12426-w
   Shastri S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15574-9
   Singh PK, 2020, P 6 INT C MATH COMP, P43
   Singh PK, 2022, P INT C FRONT COMP S, P445
   Singh PK, 2022, J KING SAUD UNIV-COM, V34, P4402, DOI 10.1016/j.jksuci.2020.09.014
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Thanh Nhan Vo, 2021, 2021 International Conference on Technologies and Applications of Artificial Intelligence (TAAI), P90, DOI 10.1109/TAAI54685.2021.00025
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   University of Southern California, 2022, The usc-sipi image database
   Wang CP, 2022, ISA T, V125, P665, DOI 10.1016/j.isatra.2021.06.019
   Xiong L, 2023, IEEE Trans Cloud Comput
NR 72
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17014-0
EA NOV 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500023
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Bhat, M
   Singh, N
   Kapoor, A
AF Kapoor, Rajiv
   Bhat, Manali
   Singh, Nikhil
   Kapoor, Aarchishya
TI Recent advances in the discipline of text based affect recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Affect recognition; Machine learning; Sentiment; Sentiment analysis;
   Review
ID SENTIMENT ANALYSIS; NEURAL-NETWORKS; SOCIAL MEDIA; TWITTER; CNN;
   CLASSIFICATION; EXTRACTION; TWEET; MODEL
AB Sentiment analysis is a part of natural language processing, along with text mining. Over the years, sentiment analysis has become a key study area for researchers and industries all over the world. The major goal of this review is to overview the papers that have found the sentiment of the data under study over the past few years. Also, the various techniques and methods that have enabled us to solve the problem of sentiment analysis are looked into and put forward briefly. The articles are looked into considering the area of sentiment analysis in which the contributions are made, be it sentiment detection, dataset creation, or transfer learning. This would help the researchers to curate advanced and accurate models and methods for analyzing sentiment. Additionally, they would be given a quick rundown of current developments in this area of research. With this in mind, the literature study is conducted taking into account various applications, various machine learning algorithms, the type of data utilized for analysis purposes, and various performance measurements. Challenges and gaps based on all the contributions studied are summarized.
C1 [Kapoor, Rajiv; Bhat, Manali; Singh, Nikhil] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
   [Kapoor, Aarchishya] IIT Indore, Dept Comp Sci & Engg, Indore, India.
C3 Delhi Technological University; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Indore
RP Kapoor, R (corresponding author), Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
EM rajivkapoor.dtu@gmail.com
RI Kapoor, Rajiv/AAA-2011-2022
OI Kapoor, Rajiv/0000-0003-3020-1455
FU We thank Mr Ruchirangad Kapoor , doing B.Tech from VIT-AP in Computer
   Sciences for helping in the script formatting and for making few very
   useful suggestions.
FX We thank Mr Ruchirangad Kapoor , doing B.Tech from VIT-AP in Computer
   Sciences for helping in the script formatting and for making few very
   useful suggestions.
CR Abas AR, 2020, IEEE ACCESS, V8, P128845, DOI 10.1109/ACCESS.2020.3008824
   Abawajy JH, 2016, IEEE COMMUN SURV TUT, V18, P1974, DOI 10.1109/COMST.2016.2533668
   Abulaish M, 2018, IEEE ACCESS, V6, P64847, DOI 10.1109/ACCESS.2018.2878494
   Acheampong FA, 2020, ENG REP, V2, DOI 10.1002/eng2.12189
   Al-Twairesh N, 2019, IEEE ACCESS, V7, P84122, DOI 10.1109/ACCESS.2019.2924314
   Al-Twairesh N, 2017, PROCEDIA COMPUT SCI, V117, P63, DOI 10.1016/j.procs.2017.10.094
   Aloufi S, 2018, IEEE ACCESS, V6, P78609, DOI 10.1109/ACCESS.2018.2885117
   Vo AD, 2018, IEEE ACCESS, V6, P5415, DOI 10.1109/ACCESS.2018.2797224
   [Anonymous], 2018, P 12 INT WORKSHOP SE
   [Anonymous], 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1299
   Athira U, 2018, IEEE ACCESS, V6, P4470, DOI 10.1109/ACCESS.2017.2789200
   Aydln CR, 2020, IEEE ACCESS, V8, P77820, DOI 10.1109/ACCESS.2020.2990306
   Aziz AA, 2020, IEEE ACCESS, V8, P17722, DOI 10.1109/ACCESS.2019.2958702
   Beladev M, 2016, KNOWL-BASED SYST, V111, P193, DOI 10.1016/j.knosys.2016.08.013
   Belcastro L, 2020, IEEE ACCESS, V8, P47177, DOI 10.1109/ACCESS.2020.2978950
   Benlahbib A, 2020, IEEE ACCESS, V8, P96550, DOI 10.1109/ACCESS.2020.2996805
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai R, 2020, IEEE ACCESS, V8, P171408, DOI 10.1109/ACCESS.2020.3024750
   Castillo SRM, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (IEEE CIC), P506, DOI [10.1109/CIC.2016.078, 10.1109/CIC.2016.76]
   Chan JYL, 2023, ARTIF INTELL REV, V56, P749, DOI 10.1007/s10462-022-10183-8
   Chang TT, 2009, J SYST ENG ELECTRON, V20, P1344
   Chen BF, 2019, IEEE ACCESS, V7, P14938, DOI 10.1109/ACCESS.2019.2892140
   Chen KT, 2021, Arxiv, DOI arXiv:2107.04191
   Chen ZK, 2018, IEEE ACCESS, V6, P24856, DOI 10.1109/ACCESS.2017.2782668
   Cheng Y, 2020, IEEE ACCESS, V8, P134964, DOI 10.1109/ACCESS.2020.3005823
   Cho K., 2014, ARXIV14061078
   Chung WY, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P191, DOI 10.1109/ISI.2017.8004908
   Dai JZ, 2019, IEEE ACCESS, V7, P138872, DOI 10.1109/ACCESS.2019.2941376
   Góes ASD, 2020, IEEE ACCESS, V8, P39403, DOI 10.1109/ACCESS.2020.2975485
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Diao YF, 2020, IEEE ACCESS, V8, P135152, DOI 10.1109/ACCESS.2020.2967095
   Ding X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4026
   Ding X, 2019, IEEE ACCESS, V7, P40323, DOI 10.1109/ACCESS.2019.2904858
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   Fang Y, 2018, IEEE ACCESS, V6, P20625, DOI 10.1109/ACCESS.2018.2820025
   Feizollah A, 2019, IEEE ACCESS, V7, P83354, DOI 10.1109/ACCESS.2019.2923275
   Fu XH, 2018, IEEE ACCESS, V6, P71884, DOI 10.1109/ACCESS.2018.2878425
   Gao Y, 2019, IEEE ACCESS, V7, P168548, DOI 10.1109/ACCESS.2019.2954590
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Garg I, 2020, IEEE ACCESS, V8, P1347, DOI 10.1109/ACCESS.2019.2961960
   Ghaddar B, 2018, EUR J OPER RES, V265, P993, DOI 10.1016/j.ejor.2017.08.040
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Gu T, 2020, IEEE ACCESS, V8, P121014, DOI 10.1109/ACCESS.2020.3006569
   Gunn S.R., 1998, Analyst, V14, P5, DOI DOI 10.1039/B918972F
   Han H, 2018, IEEE ACCESS, V6, P68302, DOI 10.1109/ACCESS.2018.2879481
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu T, 2020, IEEE ACCESS, V8, P8658, DOI 10.1109/ACCESS.2019.2961100
   Phan HT, 2020, IEEE ACCESS, V8, P14630, DOI 10.1109/ACCESS.2019.2963702
   Jain G, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P494, DOI [10.1109/CONFLUENCE.2019.8776967, 10.1109/confluence.2019.8776967]
   Jiahao Y, 2020, IEEE ACCESS, V8, P203712, DOI 10.1109/ACCESS.2020.3034939
   Jiang Long, 2011, P 49 ANN M ASS COMP, P151
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kastrati Z, 2020, IEEE ACCESS, V8, P106799, DOI 10.1109/ACCESS.2020.3000739
   Kleinbaum D.G., 2002, Logistic Regression
   Kumar A, 2020, MULTIMED TOOLS APPL, V79, P15349, DOI 10.1007/s11042-019-7346-5
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Kumar P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P450, DOI 10.1109/ICRCICN.2015.7434281
   Lan YY, 2020, IEEE ACCESS, V8, P70401, DOI 10.1109/ACCESS.2020.2987101
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Levordashka A., 2016, Proceedings of the Tenth International AAAI Conference on Web and Social Media (ICWSM 2016), (Icwsm), P623
   Li XD, 2018, IEEE ACCESS, V6, P73110, DOI 10.1109/ACCESS.2018.2881689
   Li XL, 2020, IEEE ACCESS, V8, P104026, DOI 10.1109/ACCESS.2020.2999673
   Li Z, 2020, IEEE ACCESS, V8, P75073, DOI 10.1109/ACCESS.2020.2986582
   Liang HZ, 2020, IEEE ACCESS, V8, P54164, DOI 10.1109/ACCESS.2020.2979012
   Liang L, 2020, J ENG-JOE, V2020, P595, DOI 10.1049/joe.2019.1212
   Ligthart A, 2021, ARTIF INTELL REV, V54, P4997, DOI 10.1007/s10462-021-09973-3
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.2200/S00416ED1V01Y201204HLT016, 10.2200/s00416ed1v01y201204hlt016]
   Long ZJ, 2020, IEEE ACCESS, V8, P136046, DOI 10.1109/ACCESS.2020.3011123
   Lu Q, 2020, IEEE ACCESS, V8, P52505, DOI 10.1109/ACCESS.2020.2981139
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Magdum D, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P336, DOI 10.1109/SPACES.2015.7058279
   Malviya Shrikant, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P188, DOI 10.1109/ICSDA.2016.7919009
   Mäntylä MV, 2018, COMPUT SCI REV, V27, P16, DOI 10.1016/j.cosrev.2017.10.002
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Moher D, 2011, EPIDEMIOLOGY, V22, P128, DOI 10.1097/EDE.0b013e3181fe7825
   Mukherjee P, 2021, PROCEDIA COMPUT SCI, V185, P370, DOI 10.1016/j.procs.2021.05.038
   Oliveira N, 2017, EXPERT SYST APPL, V73, P125, DOI 10.1016/j.eswa.2016.12.036
   Oriola O, 2020, IEEE ACCESS, V8, P21496, DOI 10.1109/ACCESS.2020.2968173
   Pai PF, 2018, IEEE ACCESS, V6, P57655, DOI 10.1109/ACCESS.2018.2873730
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Peng HY, 2017, COGN COMPUT, V9, P423, DOI 10.1007/s12559-017-9470-8
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rao GZ, 2020, IEEE ACCESS, V8, P32395, DOI 10.1109/ACCESS.2020.2973737
   Rasool A, 2020, IEEE ACCESS, V8, P191850, DOI 10.1109/ACCESS.2020.3030642
   Ren R, 2019, IEEE SYST J, V13, P760, DOI 10.1109/JSYST.2018.2794462
   Sedhai S, 2018, IEEE T COMPUT SOC SY, V5, P169, DOI 10.1109/TCSS.2017.2773581
   Short J., 1976, The social psychology of telecommunications
   Singh N, 2023, ENG APPL ARTIF INTEL, V125, DOI 10.1016/j.engappai.2023.106661
   Smetanin S, 2020, IEEE ACCESS, V8, P110693, DOI 10.1109/ACCESS.2020.3002215
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Tago K, 2018, TSINGHUA SCI TECHNOL, V23, P104, DOI 10.26599/TST.2018.9010012
   Velayutham T, 2017, 2017 3 INT C ADV COM, P1, DOI DOI 10.1109/ICACCAF.2017.8344722
   Verma S, 2022, GOV INFORM Q, V39, DOI 10.1016/j.giq.2022.101708
   Wang L, 2020, IEEE T KNOWL DATA EN, V32, P2026, DOI 10.1109/TKDE.2019.2913641
   Wang ZH, 2019, IEEE ACCESS, V7, P103000, DOI 10.1109/ACCESS.2019.2928044
   Wang ZG, 2020, BIG DATA MIN ANAL, V3, P208, DOI 10.26599/BDMA.2020.9020005
   Wu JS, 2019, IEEE ACCESS, V7, P183924, DOI 10.1109/ACCESS.2019.2960655
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
   Xu GX, 2019, IEEE ACCESS, V7, P43749, DOI 10.1109/ACCESS.2019.2907772
   Xu K, 2020, TSINGHUA SCI TECHNOL, V25, P20, DOI 10.26599/TST.2018.9010139
   Yang L, 2020, IEEE ACCESS, V8, P23522, DOI 10.1109/ACCESS.2020.2969854
   Yang Y., 2019, Multilingual universal sentence encoder for semantic retrieval, DOI DOI 10.48550/ARXIV.1907.04307
   Yin FL, 2020, IEEE ACCESS, V8, P63359, DOI 10.1109/ACCESS.2020.2984284
   Yu DJ, 2019, IEEE ACCESS, V7, P12373, DOI 10.1109/ACCESS.2019.2891902
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Zad S, 2021, 2021 IEEE WORLD AI IOT CONGRESS (AIIOT), P255, DOI [10.1109/AIIoT52608.2021.9454192, 10.1109/AIIOT52608.2021.9454192]
   Zhang DY, 2018, IEEE ACCESS, V6, P71241, DOI 10.1109/ACCESS.2018.2881270
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang X, 2018, IEEE ACCESS, V6, P50720, DOI 10.1109/ACCESS.2018.2869735
   Zhang XJ, 2019, IEEE ACCESS, V7, P347, DOI 10.1109/ACCESS.2018.2885362
   Zhao QC, 2019, IEEE ACCESS, V7, P175917, DOI 10.1109/ACCESS.2019.2953243
   Zhao ZJ, 2020, IEEE ACCESS, V8, P3920, DOI 10.1109/ACCESS.2019.2963047
   Zhong XF, 2018, IEEE ACCESS, V6, P35551, DOI 10.1109/ACCESS.2018.2843773
   Zhou J, 2020, IEEE ACCESS, V8, P132970, DOI 10.1109/ACCESS.2020.3010802
   Zhou JH, 2019, IEEE ACCESS, V7, P38856, DOI 10.1109/ACCESS.2019.2905048
NR 123
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17565-2
EA NOV 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500007
DA 2024-07-18
ER

PT J
AU Gupta, M
   Kishore, RR
AF Gupta, Megha
   Kishore, R. Rama
TI Robust digital image watermarking using cuckoo search optimization and
   probabilistic neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi- Blind Image Watermarking; Secure watermarking; Cuckoo search
   optimization; Probabilistic neural network
ID PRINCIPAL COMPONENT ANALYSIS; SCHEME; ALGORITHM; FRAMEWORK
AB In this new age, because of the exceptional achievement of the global computer network, the trading of digital media over the web has turned out to be unbelievably easy. However, securing the exclusive rights of the owner while trading digital media is an important issue. Digital image watermarking is a method to ensure copyright protection, security, and authenticity of data. In this paper, a novel technique is presented which is optimized, secure, and robust. The Watermark is set solidly in the discrete cosine transform domain. It is also encrypted based on the proposed block shuffling algorithm to increase security. The method was examined against various attacks, and it succeeded in maintaining statistical significance in terms of robustness and imperceptibility, as the average Peak Signal to Noise Ratio value is 65 dB, and the average Normalized Correlation value is close to one after apply all possible attacks. The results have been tested on MATLAB 2020a.
C1 [Gupta, Megha; Kishore, R. Rama] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi 110078, India.
   [Gupta, Megha] Noida Inst Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
C3 GGS Indraprastha University; Noida Institute of Engineering & Technology
RP Gupta, M (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi 110078, India.; Gupta, M (corresponding author), Noida Inst Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
EM megha.phd160.usict2019@ipu.ac.in
OI GUPTA, MEGHA/0000-0003-1481-4454
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   [Anonymous], 2015, Intelligent Computing, Communication and Devices, P231
   Baluja S, 2017, ADV NEUR IN, V30
   Byun SW, 2019, IEEE ACCESS, V7, P100706, DOI 10.1109/ACCESS.2019.2931039
   Chundong Wang, 2020, International Journal of Information and Computer Security, V12, P416
   Civicioglu P, 2013, ARTIF INTELL REV, V39, P315, DOI 10.1007/s10462-011-9276-0
   Dalal M, 2022, INF SECUR J, V31, P196, DOI 10.1080/19393555.2021.1896055
   Darwish SM, 2021, J EXP THEOR ARTIF IN, V33, P945, DOI 10.1080/0952813X.2020.1801853
   Deeba F, 2022, INF SECUR J, V31, P237, DOI 10.1080/19393555.2021.1919250
   Deeba F, 2020, INF SECUR J, V29, P30, DOI 10.1080/19393555.2020.1717684
   Dekhici L, 2019, CAN J ELECT COMPUT E, V42, P20, DOI 10.1109/CJECE.2018.2883030
   Dhawan S, 2021, INF SECUR J, V30, P63, DOI 10.1080/19393555.2020.1801911
   El Houby EMF, 2020, MULTIMED TOOLS APPL, V79, P28453, DOI 10.1007/s11042-020-09333-3
   Evsutin O, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116523
   Garg P, 2020, J INFORM OPTIM SCI, V41, P1499, DOI 10.1080/02522667.2020.1802124
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Garg P, 2020, J DISCRET MATH SCI C, V23, P73, DOI 10.1080/09720529.2020.1721875
   Ghosh A, 2019, ENG OPTIMIZ, V51, P2127, DOI 10.1080/0305215X.2019.1569645
   Golariya S, 2022, Int J Innov Res Growth., V11, DOI [10.26671/ijirg.2022.1.11.103, DOI 10.26671/IJIRG.2022.1.11.103]
   Gourrame K, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11020266
   Guo F, 2019, NAT COMPUT, V18, P747, DOI 10.1007/s11047-016-9601-2
   Gupta Manish, 2020, World Review of Entrepreneurship, Management and Sustainable Development, V16, P648, DOI 10.1504/WREMSD.2020.111396
   Hatoum MW, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116019
   Ikbal F, 2022, INF SECUR J, V31, P157, DOI 10.1080/19393555.2021.1873465
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Khan A, 2021, MULTIMED TOOLS APPL, V80, P2395, DOI 10.1007/s11042-020-09508-y
   Koley S, 2022, J KING SAUD UNIV-COM, V34, P636, DOI 10.1016/j.jksuci.2019.03.002
   Kusy M, 2018, INFORM SCIENCES, V430, P65, DOI 10.1016/j.ins.2017.11.036
   Lee YS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8357251
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li H, 2020, IEEE ACCESS, V8, P72620, DOI 10.1109/ACCESS.2020.2987689
   Liu JX, 2017, MULTIMED TOOLS APPL, V76, P24009, DOI 10.1007/s11042-016-4178-4
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Malik S, 2020, J INFORM OPTIM SCI, V41, P437, DOI 10.1080/02522667.2020.1723939
   Maloo S, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00291-6
   Mehta R, 2020, MULTIMED TOOLS APPL, V79, P18657, DOI 10.1007/s11042-020-08634-x
   Mohammed AA, 2020, MULTIMED TOOLS APPL, V79, P32095, DOI 10.1007/s11042-020-09694-9
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Prabha K, 2020, MULTIMED TOOLS APPL, V79, P6845, DOI 10.1007/s11042-019-08212-w
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Shankar T, 2017, INT J COMPUT SCI ENG, V15, P214, DOI 10.1504/IJCSE.2017.10008089
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Singh KN, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3498342
   Singh Neha, 2020, International Journal of Intelligent Information and Database Systems, V13, P319, DOI 10.1504/IJIIDS.2020.109460
   Sun YA, 2022, MULTIMED TOOLS APPL, V81, P6091, DOI 10.1007/s11042-021-11815-x
   Sundararajan M, 2018, MATER TODAY-PROC, V5, P1138, DOI 10.1016/j.matpr.2017.11.194
   Sunesh, 2020, J INFORM OPTIM SCI, V41, P1597, DOI 10.1080/02522667.2020.1802131
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Tanveer MSR, 2022, INF SECUR J, V31, P657, DOI 10.1080/19393555.2021.1934197
   Tuncer T, 2019, CRYPTOLOGIA, V43, P391, DOI 10.1080/01611194.2019.1582117
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang FX, 2008, INT CONF SIGN PROCES, P2194
   Wang XY, 2020, IEEE ACCESS, V8, P68533, DOI 10.1109/ACCESS.2020.2986831
   Wang XY, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105854
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Zhong X, 2021, IEEE T MULTIMEDIA, V23, P1951, DOI 10.1109/TMM.2020.3006415
NR 60
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17314-5
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900015
DA 2024-07-18
ER

PT J
AU Anjum
   Katarya, R
AF Anjum
   Katarya, Rahul
TI HateDetector: Multilingual technique for the analysis and detection of
   online hate speech in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE BERT; Multilingual encoder-decode (MBart); Online Hate speech (OHS);
   Log-likelihood test; Logistic Regression; ReLu
AB With the proliferation of social media platforms that provide anonymity, easy access, and the establishment of online communities and discussion, hate speech identification and monitoring has become a major concern for society, individuals and policymakers, which can be interpreted as hate speech. Many researchers attempted to detect hate speeches in multiple languages from social media, but the research was limited due to high complexity and minimum accuracy. A novel 'HateDetector: Multilingual Hate Speech Detection Technique' has been proposed to overcome these issues. In this technique, Bidirectional Encoder Representations from Transformers (BERT) with Multi-Layer Perceptron (MLP) is developed to identify the nature of the tweets by performing the process of code conversion and similarity check that results in good vector values representing the tweet nature. Additionally, the exact sentiment or nature of a tweet, whether hate or non-hate, is identified using the Profanity Check Technique (PCT), composed of ReLu activation function with a logistic regression classifier that classifies the resultant vectors and its respective emoji to neutral or hate speech. This technique performs all analyses of a tweet. It also auto-detects and easily finds hate speech, even from poorly written and complex text. According to the experiment's findings, the proposed technique performed exceptionally well, with a classification accuracy of 97.9%. Our proposed technique was able to compete with other state-of-the-art models.
C1 [Anjum; Katarya, Rahul] Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, New Delhi, India.
C3 Delhi Technological University
RP Anjum (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, New Delhi, India.
EM anjum_2792@yahoo.com; rahuldtu@gmail.com
OI Katarya, Prof. Rahul/0000-0001-7763-291X
CR Agarwal S, 2016, EUR INTELL SECUR INF, P124, DOI [10.1109/EISIC.2016.14, 10.1109/EISIC.2016.032]
   Ali R, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101365
   Alonso Pedro, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P13, DOI 10.1007/978-3-030-60276-5_2
   [Anonymous], P 13 INT WORKSH SEM, P464, DOI [10.18653/v1/s19-2082, DOI 10.18653/V1/S19-2082]
   Bisong E., 2019, BUILDING MACHINE LEA, P59, DOI DOI 10.1007/978-1-4842-4470-87
   Bloomberg M, Python programming language (version 3.6)
   Bohra A., 2018, P 2 WORKSH COMP MOD, P36, DOI DOI 10.18653/V1/W18-1105
   Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214654
   Chaudhari Ajinkya, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P940, DOI 10.1109/ICSSIT48917.2020.9214247
   Corazza M, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3377323
   Davidson T., 2017, 11 INT AAAI C WEB SO
   Davidson T, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P25
   Dinakar K., 2011, P INT AAAI C WEB SOC, P11, DOI DOI 10.1609/ICWSM.V5I3.14209
   Gamback B., 2017, P 1 WORKSH AB LANG O, P85, DOI [DOI 10.18653/V1/W17-3013, 10.18653/v1/W17-3013]
   Greevy E., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P468, DOI 10.1145/1008992.1009074
   Guiora A, 2017, PHILOSOPHIA, V45, P957, DOI 10.1007/s11406-017-9858-4
   Horev R, 2021, BERT Explained: State of the art language model for NLP Title
   Jain R, 2021, Profiling Hate Speech Spreaders on Twitter
   Kapil P, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106458
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Madhu H, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119342
   Mandl T, 2020, Overview of the HASOC Track at FIRE 2020: Hate Speech and Offensive Language Identification in Tamil, Malayalam, Hindi, English and German, P29, DOI [10.1145/3368567.3368584, DOI 10.1145/3368567.3368584]
   Mathur P., 2018, P 2 WORKSHOP ABUSIVE, P138
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), P18
   Maxime, 2019, What is a Transformer?No Title. Medium
   Mazari AC, 2024, CLUSTER COMPUT, V27, P325, DOI 10.1007/s10586-022-03956-x
   Miró-Llinares F, 2018, CRIME SCI, V7, DOI 10.1186/s40163-018-0089-1
   Modha S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113725
   Mozafari M, 2022, IEEE ACCESS, V10, P14880, DOI 10.1109/ACCESS.2022.3147588
   Mozafari M, 2020, STUD COMPUT INTELL, V881, P928, DOI 10.1007/978-3-030-36687-2_77
   Mridha MF, 2021, IEEE ACCESS, V9, P164681, DOI 10.1109/ACCESS.2021.3134154
   Mutanga RT, 2020, INT J ADV COMPUT SC, V11, P614
   Omar Ahmed, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P247, DOI 10.1007/978-3-030-44289-7_24
   Ousidhoum N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4675
   Paetzold GH, 2019, INT WORKSH SEM EV
   Park J. H., 2017, P 1 WORKSHOP ABUSIVE
   Paschalides D, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3371276
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3369869
   Qian J, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P31, DOI 10.1145/3195106.3195111
   Qureshi KA, 2021, IEEE ACCESS, V9, P109465, DOI 10.1109/ACCESS.2021.3101977
   Ridenhour Michael, 2020, Social, Cultural, and Behavioral Modeling. 13th International Conference, SBP-BRiMS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12268), P202, DOI 10.1007/978-3-030-61255-9_20
   Roy PK, 2020, IEEE ACCESS, V8, P204951, DOI 10.1109/ACCESS.2020.3037073
   Rui Cao, 2020, WebSci '20: 12th ACM Conference on Web Science, P11, DOI 10.1145/3394231.3397890
   Ryzhova Anastasia, 2022, Procedia Computer Science, P196, DOI 10.1016/j.procs.2022.11.056
   Sreelakshmi K., 2020, Procedia Computer Science, V171, P737, DOI 10.1016/j.procs.2020.04.080
   Wang G, 2014, PROCEEDINGS OF THE 2014 ACM INTERNET MEASUREMENT CONFERENCE (IMC'14), P137, DOI 10.1145/2663716.2663728
   Wang L, 2020, IEEE T KNOWL DATA EN, V32, P2026, DOI 10.1109/TKDE.2019.2913641
   Wang YB, 2021, IEEE ACCESS, V9, P37075, DOI 10.1109/ACCESS.2021.3062654
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
   Zhou YL, 2020, IEEE ACCESS, V8, P128923, DOI 10.1109/ACCESS.2020.3009244
NR 51
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 1
PY 2023
DI 10.1007/s11042-023-16598-x
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W5HD3
UT WOS:001091925800001
DA 2024-07-18
ER

PT J
AU Kaur, R
   Roul, RK
   Batra, S
AF Kaur, Ravneet
   Roul, Rajendra Kumar
   Batra, Shalini
TI Multilayer extreme learning machine: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Machine learning; Deep learning; ELM; ELM-autoencoder; Feature space;
   Multilayer ELM
ID SUPPORT-VECTOR-MACHINE; IMAGE CLASSIFICATION; PREDICTION MODEL;
   NETWORKS; BINARY; ELM; ALGORITHM
AB Majority of the learning algorithms used for the training of feedforward neural networks (FNNs), such as backpropagation (BP), conjugate gradient method, etc. rely on the traditional gradient method. Such algorithms have a few drawbacks, including slow convergence, sensitivity to noisy data, local minimum problem, etc. One of the alternatives to overcome such issues is Extreme Learning Machine (ELM), which requires less training time, ensures global optimum and enhanced generalization in neural networks. ELM has a single hidden layer, which poses memory constraints in some problem domains. An extension to ELM, Multilayer ELM (ML-ELM) performs unsupervised learning by utilizing ELM autoencoders and eliminates the need of parameter tuning, enabling better representation learning as it consists of multiple layers. This paper provides a thorough review of ML-ELM architecture development and its variants and applications. The state-of-the-art comparative analysis between ML-ELM and other machine and deep learning classifiers demonstrate the efficacy of ML-ELM in the niche domains of Computer Science which further justifies its competency and effectiveness.
C1 [Kaur, Ravneet; Roul, Rajendra Kumar; Batra, Shalini] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kaur, R (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
EM rkaur1_phd19@thapar.edu; raj.roul@thapar.edu; sbatra@thapar.edu
FU Department of Science and Technology (DST), Government of India under
   Innovation in Science Pursuit for Inspired Research (INSPIRE)
   Fellowship, INSPIRE [IF190242]
FX The authors acknowledge the financial support provided by the Department
   of Science and Technology (DST), Government of India under Innovation in
   Science Pursuit for Inspired Research (INSPIRE) Fellowship, INSPIRE
   Code- IF190242, for carrying out this research.
CR Allen EJ, 2022, NAT NEUROSCI, V25, P116, DOI 10.1038/s41593-021-00962-x
   An L, 2012, IEEE IMAGE PROC, P2209, DOI 10.1109/ICIP.2012.6467333
   Andrushia AD, 2020, PATTERN ANAL APPL, V23, P385, DOI 10.1007/s10044-019-00800-8
   Antal Balint, 2014, UCI Machine Learning Repository
   Bal PR, 2020, IEEE T RELIAB, V69, P1355, DOI 10.1109/TR.2020.2996261
   Baradarani A, 2013, PATTERN RECOGN, V46, P57, DOI 10.1016/j.patcog.2012.06.007
   Birkl C, 2017, Oxford battery degradation dataset 1, DOI [10.5287/bodleian:KO2kdmYGghttps://doi.org/10.5287/bodleian:KO2kdmYGg, DOI 10.5287/BODLEIAN:KO2KDMYGGHTTPS://DOI.ORG/10.5287/BODLEIAN:KO2KDMYGG]
   Cambria E, 2013, IEEE INTELL SYST, V28, P30, DOI 10.1109/MIS.2013.140
   Cao FX, 2019, IEEE T GEOSCI REMOTE, V57, P5580, DOI 10.1109/TGRS.2019.2900509
   Cao JW, 2016, J FRANKLIN I, V353, P4526, DOI 10.1016/j.jfranklin.2016.08.024
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Cao R, Multimed Tools Appl, V78, p28,953
   Chang NB, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3518096
   Chen BD, 2017, IEEE T SIGNAL PROCES, V65, P2888, DOI 10.1109/TSP.2017.2669903
   Chen FL, 2011, EXPERT SYST APPL, V38, P1336, DOI 10.1016/j.eswa.2010.07.014
   Chen LJ, 2018, PATTERN RECOGN, V84, P357, DOI 10.1016/j.patcog.2018.07.011
   Chen MJ, 2019, IEEE INTERNET THINGS, V6, P1410, DOI 10.1109/JIOT.2018.2856241
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Vong C, 2018, NEUROCOMPUTING, V310, P265, DOI 10.1016/j.neucom.2018.05.032
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cole Ron, 1994, UCI Machine Learning Repository
   Dai HZ, 2019, NEURAL NETWORKS, V115, P11, DOI 10.1016/j.neunet.2019.03.004
   Dailey M, 2001, CALIFORNIA FACIAL EX
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Deepa M, 2016, International Journal of Advanced Engineering Technology
   Deng CW, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5269-3
   Ding SF, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/129021
   Duan LJ, 2016, PROCEDIA COMPUT SCI, V88, P176, DOI 10.1016/j.procs.2016.07.422
   Fei XY, 2019, IEEE ENG MED BIO, P933, DOI [10.1109/EMBC.2019.8857280, 10.1109/embc.2019.8857280]
   Filannino M., 2011, Univ Manch, V86, P6
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Goebel K, 2010, DAWN MCINTOSH
   Good RP, 2010, IEEE T SEMICONDUCT M, V23, P201, DOI 10.1109/TSM.2010.2041263
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guangquan Zhao, 2020, 2020 11th International Conference on Prognostics and System Health Management (PHM-2020 Jinan), P315, DOI 10.1109/PHM-Jinan48558.2020.00063
   Güldener U, 2005, NUCLEIC ACIDS RES, V33, pD364, DOI 10.1093/nar/gki053
   Guo T, 2017, COGN COMPUT, V9, P581, DOI 10.1007/s12559-017-9474-4
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   Han F, 2019, NEUROCOMPUTING, V335, P261, DOI 10.1016/j.neucom.2018.07.080
   Hassanpour A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12494
   He DK, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103070
   He Q, 2013, NEUROCOMPUTING, V102, P52, DOI 10.1016/j.neucom.2012.01.040
   Hemanth JD, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12225
   Hernandez-Hernandez RA, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177797
   Huang G.B., 2012, Extreme learning machine: learning without iterative tuning. A Tutorial in IJCNN2012/WCCI2012
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2000, IEEE T NEURAL NETWOR, V11, P799, DOI 10.1109/72.846750
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2015, IEEE COMPUT INTELL M, V10, P18, DOI 10.1109/MCI.2015.2405316
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang ZT, 2019, ENG ANAL BOUND ELEM, V106, P505, DOI 10.1016/j.enganabound.2019.06.005
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Jahromi AN, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101655
   Jia XB, 2019, COGN COMPUT, V11, P101, DOI 10.1007/s12559-018-9596-3
   Jia XB, 2016, LECT NOTES COMPUT SC, V9950, P505, DOI 10.1007/978-3-319-46681-1_60
   Jiang XW, 2018, 2018 AUSTRALIAN & NEW ZEALAND CONTROL CONFERENCE (ANZCC), P81, DOI 10.1109/ANZCC.2018.8606551
   Johnson KA., 2001, The whole brain atlas
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Khan AW, 2021, IEEE ACCESS, V9, P107309, DOI 10.1109/ACCESS.2021.3100287
   Klahr D, 1978, Adv Child Dev Behav, V12, P61, DOI 10.1016/S0065-2407(08)60036-1
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Kurgan LA, 2001, ARTIF INTELL MED, V23, P149, DOI 10.1016/S0933-3657(01)00082-3
   Kushmerick N., 1999, Proceedings of the Third International Conference on Autonomous Agents, P175, DOI 10.1145/301136.301186
   Le BT, 2019, IEEE T GEOSCI REMOTE, V57, P4192, DOI 10.1109/TGRS.2018.2890040
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J., 2019, Int J Aerosp Eng, V2019, P13
   Lekamalage CKL, 2017, IEEE IMAGE PROC, P1297, DOI 10.1109/ICIP.2017.8296491
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li L, 2019, MULTIMED TOOLS APPL, V78, P33375, DOI 10.1007/s11042-019-7543-2
   Lillicrap TP, 2020, NAT REV NEUROSCI, V21, P335, DOI 10.1038/s41583-020-0277-3
   Lim TS, 1997, UCI machine learning repository
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu YX, 2019, IEEE T WIREL COMMUN, V18, P3424, DOI 10.1109/TWC.2019.2914040
   Lu HY, 2019, IEEE T COMP PACK MAN, V9, P2490, DOI 10.1109/TCPMT.2019.2934487
   Luo X, 2020, INT J MACH LEARN CYB, V11, P197, DOI 10.1007/s13042-019-00967-w
   Luong NC, 2019, IEEE COMMUN SURV TUT, V21, P3133, DOI 10.1109/COMST.2019.2916583
   Ma YY, 2019, INT J ELECTROCHEM SC, V14, P7737, DOI 10.20964/2019.08.44
   Madessa AH, 2020, A deep learning approach for specular highlight removal from transmissive materials
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   MANGASARIAN OL, 1990, SIAM PROC S, P22
   Mao Q, 2018, IEEE COMMUN SURV TUT, V20, P2595, DOI 10.1109/COMST.2018.2846401
   Mao YC, 2019, OPT LASER TECHNOL, V114, P10, DOI 10.1016/j.optlastec.2019.01.005
   Maulik U, 2017, IEEE GEOSC REM SEN M, V5, P33, DOI 10.1109/MGRS.2016.2641240
   Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182
   Mirza B, 2016, PROC ADAPT LEARN OPT, V6, P39, DOI 10.1007/978-3-319-28397-5_4
   Mitchell Tom, 1999, UCI Machine Learning Repository
   Moore A. W., 2005, Performance Evaluation Review, V33, P50, DOI 10.1145/1071690.1064220
   Mukherjee H, 2018, INT J SPEECH TECHNOL, V21, P753, DOI 10.1007/s10772-018-9525-6
   Nakai Kenta, 1996, UCI Machine Learning Repository
   Nash Warwick J, 1995, UCI Machine Learning Repository
   Nayak DR, 2020, MULTIMED TOOLS APPL, V79, P15381, DOI 10.1007/s11042-019-7233-0
   Noushahr HG, 2015, INT C INN TECHN APPL, P77
   Orimoloye LO, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112828
   Pace K, 1997, About us
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Parkavi RM., 2017, Adv Sci Technol Eng Syst J, V2, P69, DOI DOI 10.25046/AJ020108
   Poggio T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14663-9
   Raghuwanshi BS, 2018, NEURAL NETWORKS, V105, P206, DOI 10.1016/j.neunet.2018.05.011
   Ramana B, 2012, UCI Machine Learning Repository
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Ravari MR, 2020, SCI IRAN, V27, P3005, DOI 10.24200/sci.2020.53490.3263
   RIFKIN R., 2003, Nato Sci. Ser. Sub Ser. III Comput. Syst. Sci, V190, P131
   Roul RK, 2017, SOFT COMPUT, V21, P4239, DOI 10.1007/s00500-016-2189-8
   Roul RK., 2018, Int. J. Big Data Intell., V5, P49, DOI 10.1504/IJBDI.2018.088283
   Roy K., 2018, P REC TRENDS IM PROC, VVolume 1035, P572, DOI [10.1007/978-981-13-9181-150, DOI 10.1007/978-981-13-9181-150]
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   SANDBERG IW, 1994, IEEE T CIRCUITS-I, V41, P372, DOI 10.1109/81.296334
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Scholkopf B., 2002, Learning with Kernels
   She QS, 2019, MED BIOL ENG COMPUT, V57, P147, DOI 10.1007/s11517-018-1875-3
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Sindhwani V., 2006, SEMISUPERVISED LEARN, P217
   Slate David J, 1991, UCI Machine Learning Repository
   Smith L.I., 2002, TUTORIAL PRINCIPAL C
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Su Xiao-li, 2016, Control Theory & Applications, V33, P1674, DOI 10.7641/CTA.2016.60297
   Su XL, 2020, J FRANKLIN I, V357, P12588, DOI 10.1016/j.jfranklin.2020.05.031
   Su XL, 2019, INT J MACH LEARN CYB, V10, P2739, DOI 10.1007/s13042-018-0897-3
   Su XL, 2018, SOFT COMPUT, V22, P3575, DOI 10.1007/s00500-018-3153-6
   Su XL, 2018, J FRANKLIN I, V355, P1663, DOI 10.1016/j.jfranklin.2017.05.001
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tang JX, 2014, IEEE IMAGE PROC, P175, DOI 10.1109/ICIP.2014.7025034
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Tang LW, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123615
   Taskar B., 2003, Adv Neural Inf Process Syst, V16, P22
   Wang BX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030614
   Wang J, 2022, MULTIMED TOOLS APPL, V81, P41611, DOI 10.1007/s11042-021-11007-7
   Wang WR, 2017, MULTIDIM SYST SIGN P, V28, P851, DOI 10.1007/s11045-016-0408-1
   Wang XF, 2020, IEEE COMMUN SURV TUT, V22, P869, DOI 10.1109/COMST.2020.2970550
   Wang Y, 2017, PROG ARTIF INTELL, V6, P41, DOI 10.1007/s13748-016-0102-4
   Weisstein E.W, 2002, Moore-penrose matrix inverse
   Wen XH, 2018, SOFT COMPUT, V22, P3533, DOI 10.1007/s00500-018-3108-y
   Whittington JCR, 2019, TRENDS COGN SCI, V23, P235, DOI 10.1016/j.tics.2018.12.005
   Widodo A, 2007, MECH SYST SIGNAL PR, V21, P2560, DOI 10.1016/j.ymssp.2006.12.007
   Wong CM, 2018, IEEE T NEUR NET LEAR, V29, P757, DOI 10.1109/TNNLS.2016.2636834
   Wu D, 2019, IEEE ACCESS, V7, P118422, DOI 10.1109/ACCESS.2019.2936856
   Wu X, 2021, CHIN CONTR CONF, P1978, DOI 10.23919/CCC52363.2021.9550399
   Xia RF, 2020, J THERM SCI, V29, P623, DOI 10.1007/s11630-020-1213-6
   Xu XZ, 2019, NEUROCOMPUTING, V331, P213, DOI 10.1016/j.neucom.2018.11.018
   Xu Y, 2013, NEURAL COMPUT APPL, V22, P501, DOI 10.1007/s00521-011-0803-3
   Yaghoubi S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358239
   Yang J, 2020, NEURAL NETWORKS, V122, P117, DOI 10.1016/j.neunet.2019.09.030
   Yang JC, 2013, NEURAL COMPUT APPL, V22, P435, DOI 10.1007/s00521-011-0806-0
   Yang WC, 2019, IEEE T IND INFORM, V15, P4244, DOI 10.1109/TII.2019.2900665
   Yang YM, 2016, IEEE T CYBERNETICS, V46, P2570, DOI 10.1109/TCYB.2015.2481713
   Yang ZX, 2016, ENERGIES, V9, DOI 10.3390/en9060379
   Yu HY, 2019, SIGNAL IMAGE VIDEO P, V13, P1243, DOI 10.1007/s11760-019-01471-y
   Yu TJ, 2020, J CENT SOUTH UNIV, V27, P3744, DOI 10.1007/s11771-020-4574-9
   Yu W, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-16
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
   Zhang J, 2020, J FRANKLIN I, V357, P8925, DOI 10.1016/j.jfranklin.2020.04.033
   Zhang J, 2020, NEUROCOMPUTING, V396, P383, DOI 10.1016/j.neucom.2018.11.106
   Zhang LY, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0604-3
   Zhang N, 2016, APPL SOFT COMPUT, V43, P535, DOI 10.1016/j.asoc.2016.02.039
   Zhang N, 2016, NEUROCOMPUTING, V171, P1066, DOI 10.1016/j.neucom.2015.07.058
   Zhang WB, 2013, ELECTRON LETT, V49, P448, DOI 10.1049/el.2012.3642
   Zhang YS, 2017, PATTERN RECOGN, V68, P52, DOI 10.1016/j.patcog.2017.02.036
   Zhao GQ, 2021, IEEE SENS J, V21, P2324, DOI 10.1109/JSEN.2020.3019777
   Zheng LK, 2019, IEEE ACCESS, V7, P89845, DOI 10.1109/ACCESS.2019.2926348
   Zhou HM, 2015, IEEE T CYBERNETICS, V45, P2013, DOI 10.1109/TCYB.2014.2363492
   Zwitter Matjaz, 1988, UCI Machine Learning Repository
NR 172
TC 4
Z9 4
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40269
EP 40307
DI 10.1007/s11042-023-14634-4
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT5V8
UT WOS:001120729500001
DA 2024-07-18
ER

PT J
AU Sun, YM
   Li, JG
   Wang, LW
   Xv, J
   Liu, Y
AF Sun, Yumeng
   Li, Jinguang
   Wang, Linwei
   Xv, Junjie
   Liu, Yu
TI Deep Learning-based drone acoustic event detection system for microphone
   arrays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Microphone array; Sound detection; Beamforming
AB In recent years, drones have brought about numerous conveniences in our work and daily lives due to their advantages of low cost and ease of use. However, they have also introduced significant hidden threats to public safety and personal privacy. Effectively and promptly detecting drone is thus a crucial task to ensure public safety and protect individual privacy. This paper proposes a method that combines beamforming algorithm with Deep Learning neural network to achieve the detection of drone acoustic event using microphone array technology. The aim is to achieve maximum coverage and accuracy in drone detection. The proposed approach utilizes beamforming algorithm to perform directional audio capture of the drone sound signal acquired by the microphone array. It then extracts features such as Log-Mel spectrogram and Mel-Frequency Cepstral Coefficients from the audio signal, which are subsequently input to a Convolutional Neural Network for classification. The final detection result is obtained through this process. The study also incorporates experimental analysis to assess the impact of different frontend processing algorithms, dataset compositions and feature selections on the detection performance. To provide a more specific and pronounced indication of the accomplishment of the drone sound event detection task, a novel evaluation criterion is introduced, termed as the Machine- Human Ultimate Distance Ratio. This criterion is employed to assess the detection effectiveness of the drone sound event detection task. The results demonstrate that the detection range and accuracy of the drone sound event detection system based on Deep Learning and microphone array surpass those of single-microphone sound event detection method. The proposed detection approach achieves effective detection within a range of up to 135 m in the surrounding environment.
C1 [Sun, Yumeng; Li, Jinguang; Wang, Linwei; Xv, Junjie; Liu, Yu] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Liu, Y (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
EM yuliu@me.neu.edu.cn
RI Wang, zhenhua/KFA-8731-2024; wang, nan/KHW-4897-2024; Lin,
   Wei/KFQ-5381-2024; WANG, YANAN/KCL-4840-2024; wang, jin/KHD-7243-2024;
   li, qing/KHU-6871-2024; Yang, Ning/KHD-1133-2024; Wang,
   Xinyi/KHV-4909-2024; wang, shuo/KCL-3379-2024; zhang,
   yingying/KGM-8162-2024; Wang, Yibin/KEZ-9645-2024; wang,
   haoyu/KHY-6295-2024; Sun, Yang/KHY-5117-2024; Wang, Fei/KEH-6292-2024;
   Zhang, Yansong/KHW-4097-2024; li, fangyu/KCY-0521-2024; Chen,
   Yang/KHD-8849-2024
OI zhang, yingying/0000-0001-7479-3398; wang, haoyu/0009-0001-2467-5331;
   li, fangyu/0009-0009-8303-9157; 
FU This research was supported by the National Natural Science Foundation
   of China (Grant Nos. 51875094) and the Fundamental Research Funds for
   the Central Universities (Grant Nos.2020GFYD023). [51875094]; National
   Natural Science Foundation of China [2020GFYD023]; Fundamental Research
   Funds for the Central Universities
FX This research was supported by the National Natural Science Foundation
   of China (Grant Nos. 51875094) and the Fundamental Research Funds for
   the Central Universities (Grant Nos.2020GFYD023).
CR Akbal E, 2023, DIGIT SIGNAL PROCESS, V136, DOI 10.1016/j.dsp.2023.104012
   Busset J, 2015, PROC SPIE, V9647, DOI 10.1117/12.2194309
   Dong QS, 2023, MULTIMED TOOLS APPL, V82, P149, DOI 10.1007/s11042-022-12964-3
   Dong XF, 2020, IEEE ACCESS, V8, P125714, DOI 10.1109/ACCESS.2020.3007906
   Du L, 2009, DIGIT SIGNAL PROCESS, V19, P567, DOI 10.1016/j.dsp.2009.02.001
   Espinosa R, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107465
   Huang QH, 2018, SIGNAL PROCESS, V153, P153, DOI 10.1016/j.sigpro.2018.07.016
   Jiao QC, 2023, APPL ACOUST, V211, DOI 10.1016/j.apacoust.2023.109540
   Jintasuttisak T, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106560
   Katta SS, 2022, 5TH WORKSHOP ON BENCHMARKING CYBER-PHYSICAL SYSTEMS AND INTERNET OF THINGS (CPS-IOTBENCH 2022), P7, DOI 10.1109/CPS-IoTBench56135.2022.00008
   Khan M.A., 2022, P 2022 IEEE INT C IN, P1, DOI [10.1109/ICIT48603.2022.10002815, DOI 10.1109/ICIT48603.2022.10002815]
   Kiliç R, 2022, ENG SCI TECHNOL, V28, DOI 10.1016/j.jestch.2021.06.008
   Kim J, 2020, BUILD ENVIRON, V181, DOI 10.1016/j.buildenv.2020.107092
   Kumbasar N, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117654
   Li J, 2003, IEEE T SIGNAL PROCES, V51, P1702, DOI 10.1109/TSP.2003.812831
   Meng F, 2020, IEEE ACCESS, V8, P155710, DOI 10.1109/ACCESS.2020.3016748
   Meng Z, 2022, Research on robust adaptive beam forming algorithm for antenna arrays, DOI [10.27060/d.cnki.ghbcu.2020.001714, DOI 10.27060/D.CNKI.GHBCU.2020.001714]
   Milner B, 2008, 2008 16 EUR SIGN PRO, P1
   Mohammed KK, 2023, arXiv, DOI [10.48550/arXiv.2212.01436, DOI 10.48550/ARXIV.2212.01436]
   Mokayed H, 2021, PATTERN RECOGN LETT, V148, P45, DOI 10.1016/j.patrec.2021.05.002
   Padois T, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2021.107914
   Paredes JA, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115563
   Pinto L, 2021, MAR POLLUT BULL, V169, DOI 10.1016/j.marpolbul.2021.112594
   Ren JF, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107709
   Ren XD, 2022, SUSTAIN CITIES SOC, V77, DOI 10.1016/j.scs.2021.103505
   Sazdic-Jotic B, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115928
   Scholes S, 2022, IEEE ACCESS, V10, P38154, DOI 10.1109/ACCESS.2022.3162866
   Shandilya SK, 2023, DATA BRIEF, V50, DOI 10.1016/j.dib.2023.109355
   Siddagangaiah S, 2020, ECOL INDIC, V117, DOI 10.1016/j.ecolind.2020.106559
   Su Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071733
   Suman A, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107205
   Tong PF, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7040261
   Vafeiadis A, 2020, ENG APPL ARTIF INTEL, V89, DOI 10.1016/j.engappai.2019.08.020
   Zhou JG, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7030212
NR 34
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17477-1
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500006
DA 2024-07-18
ER

PT J
AU Kumar, R
   Panwar, R
   Chaurasiya, VK
AF Kumar, Ritesh
   Panwar, Rajesh
   Chaurasiya, Vijay Kumar
TI Urban traffic forecasting using attention based model with GCN and GRU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic forecasting; Intelligent traffic system; Graph convolution
   network (GRU); Gated recurrent unit (GRU); Attention based model
ID FLOW PREDICTION; NETWORK
AB Now-a-days since number of vehicles are growing day by day on the roads in urban and metropolitan area, hence traffic jam is becoming very common problem which everyone is facing time to time. So it becomes very crucial to forecast traffic to avoid the regular traffic congestion situation in daily life. In today's intelligent traffic system, reliable and precise traffic forecasting in metropolitan road networks is critical. Many models based on classical methods have been presented to address this; however, they lag in certain circumstances, failing to incorporate spatial and temporal dependency in the environment. As a result, this research aims to solve the geographical and temporal dependency problem that plagues most traffic forecasting models. Graph Convolution Network (GCN) and Gated Recurrent Unit (GRU) are employed in conjunction with an attention-based model for more accurate traffic forecasts in cities. A combined model called Spatio-Temporal Attention-based Model with GCN and GRU (ST AGG) is employed to anticipate traffic. ST-AGG model mainly focuses on extracting the relevant information from all the input given to the attention-based model. The spatial dependency is determined by using GCN and the temporal dependency is determined by using GRU, used in the ST-AGG model. It assists in short-term traffic forecasting as well as long-term traffic forecasting. The results demonstrate that the suggested ST AGG has properly predicted the volume of traffic on city roadways in real time with greater accuracy. The model depicts how traffic is influenced by geography and time. The Shen Zhen (SZ) car dataset from China and the Los Angeles (LAS) dataset from California are used to test the suggested model. And the result shows that Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) have reduced by up to 2.7% less, and accuracy has increased by 2.7% more compared to the previous model ST GCN for the SZ vehicle dataset. Similarly, although the accuracy has not changed significantly for the Loss Angeles data set, RMSE and MAE have reduced by 3.71% less as compared to the previous ST GCN model. The proposed model is more effective than the prior models like GCN, GRU, and ST GCN.
C1 [Kumar, Ritesh; Panwar, Rajesh; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol, Allahabad, India.
C3 Indian Institute of Information Technology Allahabad
RP Kumar, R (corresponding author), Indian Inst Informat Technol, Allahabad, India.
EM pwc2016002@iiita.ac.in; vijayk@iiita.ac.in
CR Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Barros J, 2015, 2015 INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P132, DOI 10.1109/MTITS.2015.7223248
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chan KY, 2012, IEEE T INTELL TRANSP, V13, P644, DOI 10.1109/TITS.2011.2174051
   Chandra SR, 2009, J INTELL TRANSPORT S, V13, P53, DOI 10.1080/15472450902858368
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Commons W, 2020, File: gated recurrent unit.svg-wikimedia commons, the free media repository
   Cong YL, 2016, PROCEDIA ENGINEER, V138, P59, DOI 10.1016/j.proeng.2016.01.234
   Culita J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247209
   de Medrano R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106615
   Defferrard M, 2016, ADV NEUR IN, V29
   Ding QY, 2011, ADV MATER RES-SWITZ, V156-157, P979, DOI 10.4028/www.scientific.net/AMR.156-157.979
   Do LNN, 2019, TRANSPORT RES C-EMER, V108, P12, DOI 10.1016/j.trc.2019.09.008
   Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316
   Fu R, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P324, DOI 10.1109/YAC.2016.7804912
   Gharaibeh A, 2017, IEEE COMMUN SURV TUT, V19, P2456, DOI 10.1109/COMST.2017.2736886
   Ghosh S, 2016, Arxiv, DOI arXiv:1602.06291
   Gu Y., 2012, LECT NOTES ELECT ENG, P59, DOI 10.1007/978-94-007-2169-2_7
   He Z., 2015, Int J Distrib Sensor Netw, V11, P530194
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huachun Tan, 2016, CICTP 2016. Green and Multimodal Transportation and Logistics. Proceedings of the 16th COTA International Conference of Transportation Professionals, P273
   Huang S., 2003, APPL NEURAL NETWORK
   Huang WH, 2014, IEEE T INTELL TRANSP, V15, P2191, DOI 10.1109/TITS.2014.2311123
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jian Y, 2012, Urban Transport China, V6
   Khotanzad A, 2003, IEEE IJCNN, P1071
   Laña I, 2018, IEEE INTEL TRANSP SY, V10, P93, DOI 10.1109/MITS.2018.2806634
   Leduc G, 2008, Road Traffic Data: Collection Methods and applications
   Li D, 2022, IEEE T INTELL TRANSP, V23, P8337, DOI 10.1109/TITS.2021.3078187
   Liang XY, 2019, IEEE T VEH TECHNOL, V68, P1243, DOI 10.1109/TVT.2018.2890726
   Liu DY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183836
   Liu J., 2004, J. Highw. Transp. Res. Dev., V3, P82, DOI DOI 10.3969/J.ISSN.1002-0268.2004.03.022
   Lu Y, 2021, arXiv, DOI DOI 10.48550/ARXIV.2110.01535
   Lu YZ, 2017, MIDWEST SYMP CIRCUIT, P1601, DOI 10.1109/MWSCAS.2017.8053244
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nagy AM, 2018, PERVASIVE MOB COMPUT, V50, P148, DOI 10.1016/j.pmcj.2018.07.004
   Nellore K, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020157
   OKUTANI I, 1984, TRANSPORT RES B-METH, V18, P1, DOI 10.1016/0191-2615(84)90002-X
   Oluwasanmi A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23083836
   Patre SS, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON MOBILE NETWORKS AND WIRELESS COMMUNICATIONS (ICMNWC), DOI 10.1109/ICMNWC52512.2021.9688532
   Pavlyuk D, 2017, PROCEDIA ENGINEER, V178, P57, DOI 10.1016/j.proeng.2017.01.062
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Srivastava P, 2023, Essentials of deep learning: introduction to long short term memory
   Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623
   Treboux J, 2015, IEEE WIREL COMMUNN, P64, DOI 10.1109/WCNCW.2015.7122530
   Vijayalakshmi B, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4609
   Wang J, 2013, TRANSPORT RES C-EMER, V27, P219, DOI 10.1016/j.trc.2012.08.004
   Wei P, 2013, TRANSPORT RES B-METH, V53, P1, DOI 10.1016/j.trb.2013.03.004
   Williams BM, 1998, TRANSPORT RES REC, P132, DOI 10.3141/1644-14
   WILLMOTT CJ, 1985, J GEOPHYS RES-OCEANS, V90, P8995, DOI 10.1029/JC090iC05p08995
   Wu YK, 2016, Arxiv, DOI arXiv:1612.01022
   [许菲菲 Xu Feifei], 2013, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V13, P185
   Xu XY, 2014, TRANSPORT RES C-EMER, V38, P28, DOI 10.1016/j.trc.2013.10.010
   Yang LK, 2021, IEEE INT C INTELL TR, P3710, DOI 10.1109/ITSC48978.2021.9564947
   Yang Z, 2014, Math Problems Eng, V2014
   [姚智胜 YAO Zhisheng], 2006, [北京交通大学学报. 自然科学版, Journal of Beijing Jiaotong university], V30, P19
   Yin HB, 2002, TRANSPORT RES C-EMER, V10, P85, DOI 10.1016/S0968-090X(01)00004-3
   Yu B, 2018, Arxiv, DOI arXiv:1709.04875
   Yu HY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071501
   Yulian Cao, 2011, Proceedings 2011 6th International Conference on Pervasive Computing and Applications (ICPCA 2011), P45, DOI 10.1109/ICPCA.2011.6106477
   Zaremba W, 2015, Arxiv, DOI arXiv:1409.2329
   Zhang MS, 2016, AAAI CONF ARTIF INTE, P3087
   Zhang Q, 2020, AAAI CONF ARTIF INTE, V34, P1177
   Zhang Xiao-li, 2009, Journal of Systems Engineering, V24, P178
   Zhang Z, 2021, 5 INT C COMP SCI APP, P1
   Zhang ZK, 2021, NEUROCOMPUTING, V461, P109, DOI 10.1016/j.neucom.2021.07.052
   Zhao L, 2020, IEEE T INTELL TRANSP, V21, P3848, DOI 10.1109/TITS.2019.2935152
NR 68
TC 0
Z9 0
U1 16
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17248-y
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700007
DA 2024-07-18
ER

PT J
AU Liu, W
   Gao, MQ
   Duan, SD
   Wei, LS
AF Liu, Wei
   Gao, Mingqiang
   Duan, Shuaidong
   Wei, Longsheng
TI Semi-supervised anomaly detection in video surveillance by inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video anomaly detection; Inpainting method; Semi-supervised learning;
   Generative adversarial network
AB Video anomaly detection (VAD) task can be addressed as a semi-supervised learning problem as datasets are highly biased towards normal samples. The popular reconstruction methods train the network based on only normal images. These methods detect anomaly events by comparing the input with the reconstructed image, assuming that the network can not accurately reconstruct anomalous regions. However, these methods suffer from the serious flaw that the anomaly regions are generalized sufficiently well. This problem reduces the ability of anomaly detection by narrowing the gap between reconstructed and anomaly input images. By converting the reconstruction process into an inpainting process, we introduce Inpainting-GAN, a distinctive anomaly detection model that utilizes generative adversarial networks (GANs) as the backbone network. Each input image is partially occluded in random way by a series of disjoint masks before being fed into our model, any abnormal areas in the frame will definitely be covered. Our network is trained to restore those masked regions to normal parts, which overcomes the drawback of reconstruction models. To address the temporal continuity in videos, we have incorporated optical flow as a motion constraint during the training of generator. Both qualitative and quantitative experimental results show that our proposed method shows competitive performance in VAD compared to some reconstruction methods. The experimental results on the UCSD Ped1, Ped2 and CUHK Avenue datasets have obtained AUC values of 78.6%, 94.7% and 81.4%.
C1 [Liu, Wei; Gao, Mingqiang; Duan, Shuaidong; Wei, Longsheng] China Univ Geosci, Sch Automat, Wuhan, Peoples R China.
C3 China University of Geosciences
RP Gao, MQ (corresponding author), China Univ Geosci, Sch Automat, Wuhan, Peoples R China.
EM liuwei@cug.edu.cn; mingqiang@cug.edu.cn; duanzdh@cug.edu.cn;
   weilongsheng@163.com
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Agarwal Shubham, 2018, P 11 INT C NAT LANG, P129
   Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Chen TY, 2018, MULTIMED TOOLS APPL, V77, P14137, DOI 10.1007/s11042-017-5020-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Di Mattia F, 2021, Arxiv, DOI [arXiv:1906.11632, 10.48550/ARXIV.1906.11632]
   Doersch C, 2021, Arxiv, DOI arXiv:1606.05908
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   FREUND Y, 1992, ADV NEUR IN, V4, P912
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Huang C, 2019, arXiv:1911.10676, V2
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Li S, 2021, IEEE T CIRC SYST VID, V31, P1283, DOI 10.1109/TCSVT.2020.2984783
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2022, IEEE T PATTERN ANAL, V44, P7505, DOI 10.1109/TPAMI.2021.3129349
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Malhotra P, 2016, Arxiv, DOI arXiv:1607.00148
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vu H, 2017, Arxiv, DOI arXiv:1708.05211
   Wang S, 2010, INT CONF SIGN PROCES, P1220, DOI 10.1109/ICOSP.2010.5655356
   Zavrtanik V, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107706
   Zenati H, 2019, Arxiv, DOI arXiv:1802.06222
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
NR 40
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17294-6
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300005
DA 2024-07-18
ER

PT J
AU Singh, MK
AF Singh, Mahesh K.
TI Feature extraction and classification efficiency analysis using machine
   learning approach for speech signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Feature extraction; Accuracy; SVM; Speech signal
ID VOICE
AB The problem of classification efficiency analysis in speech signals for speaker identification using a machine learning approach has been a challenge for several years. The classification using the machine learning approach maps the speaker's data of attention into several segments. For the speaker's classification system, segments represent a unique speaker. This manuscript used the principal component analysis (PCA) technique used in which speech signals are converted into a set of vectors by using feature extraction. Once this is done, a speaker model can be developed for use in further speaker classification. Here dual classifiers using machine learning approaches like support vector machine (SVM) and k- nearest neighbour (k-NN) are proposed and utilized to determine the relationship between the speaker voice in the model and the input test voice. It has been discussed about the SVM and k-NN, algorithms that have been shown the better classification efficiency in speaker identification. The k-NN classifier has considerably higher detection rates compared to the SVM classifier. The proposed result on k-NN may be inconsistent with some other assessments concerning to SVM. Here advantages of k-NN is presented over other machine learning algorithm as it has attained an outstanding classification efficiency of 94.45% using the k-NN classifier and a significantly lower identification rate of 92.90% using SVM. The proposed time-frequency changing averaging factor in conventional subtraction procedures improves voice quality metrics for diverse noise kinds and signal-to-noise ratio (SNR) levels. This manuscript also enhances voice classification efficiency in terms of Accuracy, sensitivity, specificity, precision, recall, and F-1 measure using machine learning. The authentication results for identified features such as accuracy, sensitivity, and specificity were calculated as 55.59%, 61.11%, and 52.55% respectively. Precision, recall, and F1-measure derived the result 57.14%, 61.11%, and 57.33% respectively. Existing approaches were thoroughly examined to build a better classification system.
C1 [Singh, Mahesh K.] Aditya Engn Coll, Dept ECE, Surampalem, India.
C3 Aditya Engineering College, Surampalem
RP Singh, MK (corresponding author), Aditya Engn Coll, Dept ECE, Surampalem, India.
EM mahesh.092002.ece@gmail.com
CR Abdusalomov AB, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218122
   Aggarwal A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062378
   Aouani Hadhami, 2020, Procedia Computer Science, V176, P251, DOI 10.1016/j.procs.2020.08.027
   Babaee E, 2017, APPL ARTIF INTELL, V31, P661, DOI 10.1080/08839514.2018.1430469
   Bhangale KB, 2021, INT J SPEECH TECHNOL, V24, P367, DOI 10.1007/s10772-021-09808-0
   Dara Suresh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1795, DOI 10.1109/ICECA.2018.8474912
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Hegde S, 2019, J VOICE, V33, DOI 10.1016/j.jvoice.2018.07.014
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Li F, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0651-3
   Nandan D, 2022, TRAIT SIGNAL, V39, P711, DOI 10.18280/ts.390235
   Oravec M, 2014, ELMAR PROC, P1, DOI 10.1109/ELMAR.2014.6923301
   Pandian A.P., 2021, Journal of Soft Computing Paradigm (JSCP), V3, P123, DOI DOI 10.36548/JSCP.2021.2.006
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Singh Mahesh K., 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P317
   Singh MK, 2020, MULTIMED TOOLS APPL, V79, P35537, DOI 10.1007/s11042-019-08329-y
   Singh MK, 2019, MULTIMED TOOLS APPL, V78, P29395, DOI 10.1007/s11042-018-6718-6
   Singh MK, 2019, TRAIT SIGNAL, V36, P455, DOI 10.18280/ts.360511
   Song ZJ, 2020, COMPUTING, V102, P663, DOI 10.1007/s00607-019-00753-0
   Wang DY, 2020, IEEE ACCESS, V8, P46335, DOI 10.1109/ACCESS.2020.2974101
   Zhang JW, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/1651560
NR 22
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17368-5
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100006
DA 2024-07-18
ER

PT J
AU Kogashi, K
   Nobuhara, S
   Nishino, K
AF Kogashi, Kaen
   Nobuhara, Shohei
   Nishino, Ko
TI SAN: Structure-aware attention network for dyadic human relation
   recognition in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dyadic human relation recognition (DHR); DHR dataset; Multi-task
   learning
AB We introduce a new dataset and method for Dyadic Human relation Recognition (DHR). DHR is a new task that concerns the recognition of the type (i.e., verb) and roles of a two-person interaction. Unlike past human action detection, our goal is to extract richer information regarding the roles of actors, i.e., which subjective person is acting on which objective person. For this, we introduce the DHR-WebImages dataset which consists of a total of 22,046 images of 51 verb classes of DHR with per-image annotation of the verb and role, and also a test set for evaluating generalization capabilities, which we refer to as DHR-Generalization. We tackle DHR by introducing a novel network inspired by the hierarchical nature of cognitive human perception. At the core of the network lies a "structure-aware attention" module that weights and integrates various hierarchical visual cues associated with the DHR instance in the image. The feature hierarchy consists of three levels, namely the union, human, and joint levels, each of which extracts visual features relevant to the participants while modeling their cross-talk. We refer to this network as Structure-aware Attention Network (SAN). Experimental results show that SAN achieves accurate DHR robust to lacking visibility of actors, and outperforms past methods by 3.04 mAP on DHR-WebImages verb task.
C1 [Kogashi, Kaen; Nobuhara, Shohei; Nishino, Ko] Kyoto Univ, Grad Sch Informat, Dept Intelligence Sci & Technol, Kyoto 6068501, Japan.
C3 Kyoto University
RP Kogashi, K (corresponding author), Kyoto Univ, Grad Sch Informat, Dept Intelligence Sci & Technol, Kyoto 6068501, Japan.
EM kaenkogashi.om@gmail.com; nob@i.kyoto-u.ac.jp; kon@i.kyoto-u.ac.jp
FU This work was in part supported by JSPS 20H05951, JSPS 21H04893, and JST
   JPMJCR20G7. [20H05951, JSPS 21H04893]; JSPS [JPMJCR20G7]; JST
FX This work was in part supported by JSPS 20H05951, JSPS 21H04893, and JST
   JPMJCR20G7.
CR 7-sl, 7ESL: 7 Steps to Learn English
   Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Birdwhistell R.L., 1952, Introduction to Kinesics: an Annotation System for Analysis of Body Motion and Gesture
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P713, DOI 10.1007/978-3-030-58610-2_42
   Chen SJ, 2020, IEEE SIGNAL PROC LET, V27, P1680, DOI 10.1109/LSP.2020.3025128
   Curto D, 2021, IEEE INT CONF COMP V, P2177, DOI 10.1109/ICCVW54120.2021.00247
   Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao C., 2018, ARXIV
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Gupta Abhay, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0915, DOI 10.1109/ICCSP48568.2020.9182416
   Gupta S, 2015, Arxiv, DOI arXiv:1505.04474
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Z, 2021, PROC CVPR IEEE, P14641, DOI 10.1109/CVPR46437.2021.01441
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Kim B., 2020, ECCV, P498, DOI DOI 10.1007/978-3-030
   Kim Bumsoo, 2021, CVPR
   Kogashi K, 2022, IEEE INT C MULT EXP
   Li K, 2021, PROC CVPR IEEE, P1944, DOI 10.1109/CVPR46437.2021.00198
   Li YL, 2020, Arxiv, DOI arXiv:2010.16219
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Li YK, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: INFRASTRUCTURE SYSTEMS AND SUSTAINABILITY, P166, DOI [10.1109/CVPR42600.2020.01018, 10.1061/9780784482858.019]
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4235, DOI 10.1145/3394171.3413600
   Liu Yunfei, 2020, EUR C COMP VIS ECCV
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Miech A, 2021, PROC CVPR IEEE, P9821, DOI 10.1109/CVPR46437.2021.00970
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Palmer Stephen E., 1975, EXPLORATIONS COGNITI, P279
   Patron A, 2010, BMVC, P50, DOI [10.5244/C.24.50, DOI 10.5244/C.24.50]
   Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207
   Poppe R, 2017, Automatic analysis of bodily social signals, P155
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Quan Y, 2021, NEURAL COMPUT APPL, V33, P4299, DOI 10.1007/s00521-020-05255-1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ricci E, 2015, IEEE I CONF COMP VIS, P4660, DOI 10.1109/ICCV.2015.529
   Ryoo M, 2010, UT INTERACTION DATAS
   Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453
   Smaira L., 2020, arXiv, DOI DOI 10.48550/ARXIV.2010.10864
   Stergiou A, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.102799
   Sun QR, 2017, PROC CVPR IEEE, P435, DOI 10.1109/CVPR.2017.54
   Tamura M, 2021, PROC CVPR IEEE, P10405, DOI 10.1109/CVPR46437.2021.01027
   Tianmin Shu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1669, DOI 10.1109/ICRA.2017.7989197
   Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363
   van Gemeren C, 2014, EUR C COMP VIS ECCV
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542
   Wang LM, 2021, Arxiv, DOI arXiv:2012.10071
   Wang S.-Y., 2020, CVPR, P8695
   Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020
   Wu Y., 2019, DETECTRON2
   Xu BJ, 2019, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2019.00212
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yun K, 2012, 2012 IEEE COMP VIS P
   Zhang ZM, 2017, CHIN AUTOM CONGR, P3780, DOI 10.1109/CAC.2017.8243438
   Zhao H., 2019, arXiv
   Zou C, 2021, PROC CVPR IEEE, P11820, DOI 10.1109/CVPR46437.2021.01165
NR 68
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17229-1
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700010
DA 2024-07-18
ER

PT J
AU Dewang, RK
   Yadav, MP
   Awasthi, S
   Raj, O
   Mewada, A
   Bawankule, KL
AF Dewang, Rupesh Kumar
   Yadav, Mahendra Pratap
   Awasthi, Surbhit
   Raj, Om
   Mewada, Arvind
   Bawankule, Kamlakant Laxman
TI Data secure application: an application that allows developers to store
   user data securely using blockchain and IPFS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Interplanetary file system; Cryptocurrency; Ethereum
ID CLOUD; CHALLENGES; PROTECTION
AB Due to the COVID-19 pandemic, the use of software applications has increased by end users, which is an issue regarding user data privacy. Numerous apps are collecting sensitive data like user location and phone number, which are becoming hotspots for cyber-attacks. A cyberattack breaches your data, attacking your information, thereby losing data integrity, confidentiality, and availability. Cyberattack refers to the unauthorized intrusion of external personnel into a user's private digital space. We have proposed a solution to provide secure data storage in third-party applications and leverage the power of Blockchain and Interplanetary File Systems. The proposed approach offers reliable role-based access to control data storage service that maintains data integrity, availability, and confidentiality. The proposed model uses the aforementioned technologies because they provide a distributed and decentralized nature of data storage and add-on support to data immutability. Traditionally the technologies used for such services are centralized and provide a single point of attack for the attacker. It puts confidential user data in jeopardy. The proposed solutions store encrypted data distributed to reduce reliance on big tech giants for data storage support and uproot the fear of collapsing systems due to a single point of failure.
C1 [Dewang, Rupesh Kumar; Awasthi, Surbhit; Raj, Om; Mewada, Arvind; Bawankule, Kamlakant Laxman] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
   [Yadav, Mahendra Pratap] Indian Inst Informat Technol Pune, Comp Sci & Engn Dept, Pune 411041, Maharshtra, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Yadav, MP (corresponding author), Indian Inst Informat Technol Pune, Comp Sci & Engn Dept, Pune 411041, Maharshtra, India.
EM rupeshdewang@mnnit.ac.in; mahendra@iiitp.ac.in;
   Surbhitaawasthi@gmail.com; omraj@gmail.com; mewadabpl@gmail.com;
   kamalakant.bawankule@gmail.com
RI Mewada, Arvind/AAX-2915-2021
OI Mewada, Arvind/0000-0002-4680-611X; Yadav, Mahendra
   Pratap/0000-0003-4224-3142
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Benet B J, 2018, Protoc. Labs, V2018, P1
   Benet Juan, 2014, arXiv
   Casino F, 2019, TELEMAT INFORM, V36, P55, DOI 10.1016/j.tele.2018.11.006
   cryps, Gwei to INR (Gwei to Indian Rupee)
   Decuyper X, 2020, How does a blockchain work-simply explained
   Es-Samaali H., 2017, INT J COMPUTER NETWO, V5, P137
   etherscan, Etherscan API
   Fromknecht C, 2014, A decentralized public [key infrastructure with identity retention
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Gray C, 2014, Storj vs. dropbox: Why decentralized storage is the future
   ibm, Blockchain for Financial Services
   IBM, Blockchain for the supply chain
   ipfs, IPFS powers the distributed Web
   Khan SN, 2021, PEER PEER NETW APPL, V14, P2901, DOI 10.1007/s12083-021-01127-0
   Labs P., 2017, Filecoin: A decentralized storage network
   Laurent A, 2022, BLOCKCHAIN-RES APPL, V3, DOI 10.1016/j.bcra.2022.100074
   Li NH, 2007, PROC INT CONF DATA, P81
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI [DOI 10.1145/1217299.1217302, 10.1109/icde.2006.1, DOI 10.1109/ICDE.2006.1]
   Nakamoto S., 2008, DECENTRAL BUS REV
   Narayanan Arvind, 2006, arXiv
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Prakash R., 2022, INT J INFORM MANAGE, V2
   Yadav MP, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6364
   Rafique A, 2021, INFORM SYST, V96, DOI 10.1016/j.is.2020.101671
   Rahulamathavan Y, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Rao RV, 2015, PROCEDIA COMPUT SCI, V48, P204, DOI 10.1016/j.procs.2015.04.171
   StorjLabs I, 2018, Storj: A decentralized cloud storage network framework
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Vorick D., 2014, Sia: Simple decentralized storage
   Wang SP, 2018, IEEE ACCESS, V6, P38437, DOI 10.1109/ACCESS.2018.2851611
   Yang P, 2020, IEEE ACCESS, V8, P131723, DOI 10.1109/ACCESS.2020.3009876
   Zarrin J, 2021, CLUSTER COMPUT, V24, P2841, DOI 10.1007/s10586-021-03301-8
   Zhang JD, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS IEEE INCOS 2015, P144, DOI 10.1109/INCoS.2015.42
   Zhang Q, 2010, J INTERNET SERV APPL, V1, P7, DOI 10.1007/s13174-010-0007-6
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 36
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17204-w
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000008
DA 2024-07-18
ER

PT J
AU Basu, D
   Mukherjee, H
   Marciano, M
   Sen, S
   Singh, SV
   Obaidullah, SM
   Roy, K
AF Basu, Debjyoti
   Mukherjee, Himadri
   Marciano, Matteo
   Sen, Shibaprasad
   Singh, Sajai Vir
   Obaidullah, Sk Md
   Roy, Kaushik
TI A bi-stage approach to North Indian raga distinction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sandhi Prakash raga; Music information retrieval; MFCC; Bi-stage
   classification
AB Music embraces an intricate assembly of auditory elements, carefully organized in diverse configurations to articulate a variety of human emotions, moods, thoughts, feelings, temporal contexts, and situations. One of the primary aspects of any music composition is the raga which governs its melodic framework. Thus, the delineation of ragas assumes an enormous significance as a preliminary step preceding a more deeper and intricate analysis. Each of these ragas is meant to be practiced during a particular time of the day to amplify the emotional content and physical involvement. In this current work, a machine learning-based approach has been proposed to classify the dawn and dusk time (Sandhi Prakash) ragas. Here, mel-frequency cepstral coefficients (MFCC) based feature extraction technique has been applied which was further processed to generate second-level statistical features. This brought down the original feature dimension by means of effective representation of the raw features. Several classification techniques were employed and a new bi-stage raga distinction technique has been proposed. The first stage classifies ragas as dawn/ dusk while the second stage performs deeper classification for these groups separately to identify the exact raga. Experiments were performed with over 57K clips from 11 ragas belonging to the 2 time periods and a performance improvement of 0.7% was obtained for the dusk ragas using the bi-stage approach over the single shot classification technique. The highest possible accuracy of 96.47% was obtained for distinguishing the dusk ragas with only 2-second clips in the experiments.
C1 [Basu, Debjyoti] Future Inst Engn & Management, Dept Informat Technol, Kolkata, India.
   [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, TISA Lab, Barasat, India.
   [Marciano, Matteo] New York Univ Abu Dhabi, Dept Arts & Humanities, Abu Dhabi, U Arab Emirates.
   [Sen, Shibaprasad] Techno Main Salt Lake, Dept Comp Sci & Engn AI ML, Kolkata 700091, W Bengal, India.
   [Singh, Sajai Vir] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida, UP, India.
   [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 West Bengal State University; New York University Abu Dhabi; Jaypee
   Institute of Information Technology (JIIT); Aliah University
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, TISA Lab, Barasat, India.
EM basu.debjyoti.nilachal@gmail.com; himadrim027@gmail.com;
   matteo.marciano@nyu.edu; shibubiet@gmail.com; sajaivir.singh@jiit.ac.in;
   sk.obaidullah@gmail.com; kaushik.mrg@gmail.com
RI Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576
CR Abirami S, 2020, ADV COMPUT, V117, P339, DOI 10.1016/bs.adcom.2019.09.007
   Acharya S, 2021, Advances in speech and music technology, P211
   Alim S. A., 2018, IntechOpen
   Anand A, 2019, 2019 2 INT C ADV COM, P1
   [Anonymous], 2021, Logistic regression - scikit-learn
   Basu D, 2021, 2 INT C ADV COMP ADV, P581
   Bayes Naive, 2021, scikit learn
   Belle S, 2009, J. ITC Sangeet Research Academy, V23
   Bhatkhande VN, 1956, Hindustani Sangeet Paddhati, Kramik Pustak Malika, V1
   Bidkar AA., 2021, Int J Electr Eng Technol (IJEET), V12, P251
   Bidkar AA, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P499, DOI 10.1109/ICACCT.2018.8529392
   Bora K, 2023, EMPIR STUD ARTS, V41, P623, DOI 10.1177/02762374231154179
   Cheng ZY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3654
   Chhetri AR, 2023, 2023 4 INT C EM TECH, P1
   Dandawate YH, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P725, DOI 10.1109/NGCT.2015.7375216
   Dasgupta P., 1988, Rager Kriyatmak Rupayan (Bengali)
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dighe P., 2013, ISMIR, P35
   Dutt S, 2019, Machine Learning, P199
   Dutta S., 2015, INT SOC MUS INF RETR, V1, P605
   Faris H, 2017, HANDBOOK OF NEURAL COMPUTATION, P537, DOI 10.1016/B978-0-12-811318-9.00028-4
   Farishta A, 2020, Artificial neural network to identify Indian classical music raga's
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gulati S., 2016, P 17 INT SOC MUS INF, P751
   Gulati S, 2016, INT CONF ACOUST SPEE, P66, DOI 10.1109/ICASSP.2016.7471638
   Joshi D., 2023, INDIAN J SCI TECHNOL, V16, P816, DOI [10.17485/IJST/v16i11.1809, DOI 10.17485/IJST/v16i11.1809]
   Joshi D, 2021, Indian classical raga identification using machine learning
   Katte T., 2013, Int J Electr Comput Eng, V4, P82
   Katte T, 2014, ANNU IEEE IND CONF
   Kirthika P, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING EDUCATION: INNOVATIVE PRACTICES AND FUTURE TRENDS (AICERA)
   Kumar MS, 2020, J S Technol Dev, V9
   Lele JA, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI 10.1109/punecon46936.2019.9105894
   Liu S., 2016, Computational and Statistical Methods for Analysing Big Data with Applications, P7
   Malek S, 2019, Ecosystem monitoring through predictive modeling
   Mel Frequency Cepstral Coefficient (MFCC) tutorial, 2021, Practical cryptography
   Misra S., 2020, Machine learning for subsurface characterization, V4, P243, DOI [DOI 10.1016/B978-0-12-817736-5.00009-0, 10.1016/b978-0-12-817736-5.00009-0]
   Mor B, 2021, MULTIMED TOOLS APPL, V80, P14853, DOI 10.1007/s11042-020-10303-y
   Muller M., 2015, Fundamentals of Music Processing. Audio, Analysis, Algorithms, Applications, DOI [10.1007/978-3-319-21945-5, DOI 10.1007/978-3-319-21945-5]
   Murthy YVS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177849
   Padmasundari G, 2017, NATL CONF COMMUN
   Paschalidou S., 2023, Sens Transducers, V260, P77
   Peri D, 2020, Doctoral dissertation
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Raga S, 2021, ITC Sangeet Research Academy
   Ranjani HG, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1112-2
   Rao P, 2014, J NEW MUSIC RES, V43, P115, DOI 10.1080/09298215.2013.873470
   Roy S, 2021, Journal of physics: conference series, V1896
   Sharifahmadian A., 2015, Numerical Models for Submerged Breakwaters: Coastal Hydrodynamics and Morphodynamics
   Sharma Ashish, 2023, Computer Assisted Music and Dramatics: Possibilities and Challenges. Advances in Intelligent Systems and Computing (1444), P93, DOI 10.1007/978-981-99-0887-5_7
   Sharma AK, 2014, INT CONF CONTEMP, P449, DOI 10.1109/IC3.2014.6897215
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Singha A, 2023, 2023 6 INT C INF SYS, P1
   Sridhar Rajeswari, 2009, International Journal of Recent Trends in Engineering, V1, P571
   Stober S, 2013, MULTIMED TOOLS APPL, V65, P467, DOI 10.1007/s11042-012-1042-z
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17322-5
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100002
DA 2024-07-18
ER

PT J
AU Szücs, G
   Borsodi, R
   Papp, D
AF Szucs, Gabor
   Borsodi, Rego
   Papp, David
TI Multi-camera trajectory matching based on hierarchical clustering and
   constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Constrained hierarchical clustering; Object re-identification;
   Multi-camera multi-target; Trajectory matching; Vehicle tracking
ID TRACKING; MULTITARGET; REIDENTIFICATION
AB The fast improvement of deep learning methods resulted in breakthroughs in image classification, object detection, and object tracking. Autonomous driving and traffic monitoring systems, especially the on-premise installed fixed position multi-camera configurations, benefit greatly from recent advances. In this paper, we propose a Multi-Camera Multi-Target (MCMT) vehicle tracking system using a constrained hierarchical clustering solution, which improves trajectory matching, and thus provides a more robust tracking of objects transitioning between cameras. YOLOv5, ByteTrack, and ResNet50-IBN ReID networks are used for vehicle detection and tracking. Static attributes such as vehicle type and vehicle color are determined from ReID features with SVM. The proposed ReID feature-based attribute categorization shows better performance, than its pure CNN counterpart. Single-camera trajectories (SCTs) are combined into multi-camera trajectories (MCTs) using hierarchical agglomerative clustering (HAC) with time and space constraints (our proposed algorithm is denoted by MCT#MAC). Similarities between SCTs are measured by comparing the mean ReID features cumulated on the trajectory. The system was evaluated on more datasets, and our experiments demonstrate that constraining HAC by manipulating the proximity matrix greatly improves the multi-camera IDF1 score.
C1 [Szucs, Gabor; Borsodi, Rego; Papp, David] Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Muegyetem Rkp 3, H-1111 Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Szücs, G (corresponding author), Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Muegyetem Rkp 3, H-1111 Budapest, Hungary.
EM szucs@tmit.bme.hu
OI Szucs, Gabor/0000-0002-5781-1088
CR Amosa TI, 2023, NEUROCOMPUTING, V552, DOI 10.1016/j.neucom.2023.126558
   Avsar E, 2022, MULTIMED TOOLS APPL, V81, P6653, DOI 10.1007/s11042-021-11804-0
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Chen WH, 2016, Arxiv, DOI arXiv:1502.03532
   Chen YB, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103432
   Dendorfer P, 2021, INT J COMPUT VISION, V129, P845, DOI 10.1007/s11263-020-01393-0
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong SG, 2011, VISUAL ANALYSIS OF BEHAVIOUR: FROM PIXELS TO SEMANTICS, P301, DOI 10.1007/978-0-85729-670-2_14
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Z., 2019, P CVPR WORKSH, P203
   Hou Yunzhong, 2019, P IEEE CVF C COMP VI, P167
   Hsu H.M., 2019, P CVPR WORKSH LONG B, P416
   Hsu HM, 2021, IEEE T IMAGE PROCESS, V30, P5198, DOI 10.1109/TIP.2021.3078124
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jia MX, 2023, IEEE T MULTIMEDIA, V25, P1294, DOI 10.1109/TMM.2022.3141267
   Jocher G., 2023, YOLOv5 by Ultralytics
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kanaci Aytac, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P377, DOI 10.1007/978-3-030-12939-2_26
   Khan SD, 2019, COMPUT VIS IMAGE UND, V182, P50, DOI 10.1016/j.cviu.2019.03.001
   Khorramshahi Pirazh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P369, DOI 10.1007/978-3-030-58568-6_22
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kumar R, 2020, J ARTIF INTELL SOFT, V10, P27, DOI 10.2478/jaiscr-2020-0003
   Kumar R, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852059
   Li F, 2022, IEEE COMPUT SOC CONF, P3264, DOI 10.1109/CVPRW56347.2022.00369
   Li P., 2019, P CVPR WORKSH, P222
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu C, 2021, IEEE COMPUT SOC CONF, P4124, DOI 10.1109/CVPRW53098.2021.00466
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Luna E, 2022, MULTIMED TOOLS APPL, V81, P7063, DOI 10.1007/s11042-022-11923-2
   Luo H, 2021, IEEE COMPUT SOC CONF, P4090, DOI 10.1109/CVPRW53098.2021.00462
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Othmani M, 2022, MULTIMED TOOLS APPL, V81, P28347, DOI 10.1007/s11042-022-12715-4
   Pan HY, 2023, TRANSP LETT, V15, P1366, DOI 10.1080/19427867.2022.2157075
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Papp D, 2017, CLEF
   Papp D., 2016, CLEF WORKING NOTES, P525
   Papp D, 2022, INFOCOMMUNICATIONS J, V14, P17, DOI 10.36244/ICJ.2022.1.3
   Qian YJ, 2020, IEEE COMPUT SOC CONF, P2511, DOI 10.1109/CVPRW50498.2020.00302
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen F, 2022, IEEE INTERNET THINGS, V9, P9049, DOI 10.1109/JIOT.2021.3119525
   Specker A, 2022, IEEE COMPUT SOC CONF, P3198, DOI 10.1109/CVPRW56347.2022.00361
   Specker A, 2021, IEEE COMPUT SOC CONF, P4168, DOI 10.1109/CVPRW53098.2021.00471
   Szucs G, 2015, WORKING NOTES CLEF 2
   Szucs G, 2021, INFOCOMMUNICATIONS J, V13, P26, DOI 10.36244/ICJ.2021.1.4
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   Tang Z, 2018, IEEE COMPUT SOC CONF, P108, DOI 10.1109/CVPRW.2018.00022
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang X, 2022, INT J INTELL SYST, V37, P6631, DOI 10.1002/int.22857
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu MH, 2021, IEEE COMPUT SOC CONF, P4072, DOI 10.1109/CVPRW53098.2021.00460
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Yang XP, 2022, IEEE COMPUT SOC CONF, P3095, DOI 10.1109/CVPRW56347.2022.00349
   Yao H, 2022, IEEE COMPUT SOC CONF, P3309, DOI 10.1109/CVPRW56347.2022.00374
   Ye J, 2021, IEEE COMPUT SOC CONF, P4039, DOI 10.1109/CVPRW53098.2021.00456
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou K, 2021, ICLR INT C LEARN REP, DOI [10.48550/arXiv.2104.02008, DOI 10.48550/ARXIV.2104.02008]
   Zhou KY, 2022, IEEE T PATTERN ANAL, V44, P5056, DOI 10.1109/TPAMI.2021.3069237
   Zhu XY, 2020, IEEE COMPUT SOC CONF, P2566, DOI 10.1109/CVPRW50498.2020.00309
NR 82
TC 0
Z9 0
U1 13
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17397-0
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000009
OA hybrid
DA 2024-07-18
ER

PT J
AU Abid, MH
   Ashraf, R
   Mahmood, T
   Faisal, CMN
AF Abid, Muhammad Haris
   Ashraf, Rehan
   Mahmood, Toqeer
   Faisal, C. M. Nadeem
TI Optimized transfer learning based multi-modal medical image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical treatment; Content-based medical image retrieval (CBMIR);
   Inceptionv3; Medical image classification; Optimal retrieval; Deep
   learning
AB Disease diagnosis using the medical image is a very technical and tedious process. Small abnormalities in multiple medical images could be noticed by medical specialists but deep analysis of a medical image is still a complicated task due to the restricted ability of the human visual system. The limitations of the human visual system might lead to medical treatment impairment. This issue, however, may be handled by searching for similar cases in the preceding medical database using an effective content-based medical image retrieval (CBMIR) method. The CBMIR's main problem is efficient classification but also required retrieval from multi-modal medical imagery information. Most prior attempts at medical image retrieving and classification employ handmade features, that perform poorly across a large collection across multimodal datasets. Even though there has been a few earlier research on using deep characteristics for classification, the total count is quite modest. To address this issue, we offer an upgraded Inceptionv3 network, which is a genetic algorithm-based optimum retrieval system incorporating multimodal medical images from multiple forms of imaging systems. The experimental findings from 5 classes are showing accuracy and optimization with F1. score using our technique is 97.22%, and 89.56% with 98.53%, respectively, each of which is higher than either the accuracy but also F1. score from the prior solution of CBMIR.
C1 [Abid, Muhammad Haris; Ashraf, Rehan; Mahmood, Toqeer; Faisal, C. M. Nadeem] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
C3 National Textile University - Pakistan
RP Ashraf, R (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM rehan_ashraf94@yahoo.com; toqeer.mahmood@ntu.edu.pk;
   nadeem.faisal@ntu.edu.pk
OI Faisal, Chaudhry Muhammad Nadeem/0000-0001-8781-4143
CR Ahmad J, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0875-4
   Alhijawi B, 2024, EVOL INTELL, V17, P1245, DOI 10.1007/s12065-023-00822-6
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Ashraf R, 2020, IEEE ACCESS, V8, P105659, DOI 10.1109/ACCESS.2020.2998808
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Ashraf R, 2016, J INF SCI ENG, V32, P245
   Baarab N, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7302
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Borkowski A.A., 2019, Lung and Colon Cancer Histopathological Image Dataset (LC25000), P1
   Çamlica Z, 2015, INT CONF IMAG PROC, P550, DOI 10.1109/IPTA.2015.7367208
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Dureja A, 2023, MULTIMED TOOLS APPL, V82, P17659, DOI 10.1007/s11042-022-13991-w
   Garbin C, 2020, MULTIMED TOOLS APPL, V79, P12777, DOI 10.1007/s11042-019-08453-9
   Ghrabat MJJ, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0191-8
   Hameed IM, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1927469
   Haripriya P, 2021, J AMB INTEL HUM COMP, V12, P781, DOI 10.1007/s12652-020-02077-w
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Khan UA, 2021, MULTIMED TOOLS APPL, V80, P26911, DOI 10.1007/s11042-021-10530-x
   Koga K, 2022, ALGORITHMS, V15, DOI 10.3390/a15050144
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Lepcha DC, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.015
   Majhi M, 2022, MULTIMED TOOLS APPL, V81, P41545, DOI 10.1007/s11042-020-10483-7
   Minagi A, 2022, J IMAGING, V8, DOI 10.3390/jimaging8020038
   Mittal U, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS FOR COMPUTING RESEARCH (ICAICR '19), DOI 10.1145/3339311.3339357
   National Institute of Health Clinical Center (NIHCC) and American's Research Hospital, 2020, CXR8 | Powered by Box
   Nawaz M, 2021, MULTIMED TOOLS APPL, V80, P28953, DOI 10.1007/s11042-021-11120-7
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Renita DB, 2020, MULTIMED TOOLS APPL, V79, P17227, DOI 10.1007/s11042-019-07777-w
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Salih O, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053248
   Samraj D, 2023, MULTIDIM SYST SIGN P, V34, P681, DOI 10.1007/s11045-023-00880-0
   Sangeetha V, 2006, INDIAN J CHEM B, V45, P1951
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Suharjito, 2017, ICIC Express Letters, V11, P1479
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tschandl P, 2019, BRIT J DERMATOL, V181, P155, DOI 10.1111/bjd.17189
   Tuyet VTH, 2021, MOBILE NETW APPL, V26, P1300, DOI 10.1007/s11036-021-01762-0
   Wang X, 2022, NEUROCOMPUTING, V486, P135, DOI 10.1016/j.neucom.2021.11.017
   Zafar B, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112242
   Zhang ZX, 2022, COMPUT SECUR, V116, DOI 10.1016/j.cose.2022.102682
NR 46
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17179-8
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000003
DA 2024-07-18
ER

PT J
AU Das, S
   Goswami, RS
AF Das, Surajit
   Goswami, Rajat Subhra
TI Review, Limitations, and future prospects of neural network approaches
   for brain tumor classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Brain tumor; Machine learning; Convolutional neural networks; Deep
   learning; Transfer learning
ID IMAGES; MACHINE; MRI; FEATURES; SYSTEM; CNN
AB Brain tumor classification (BTC) using magnetic resonance imaging (MRI) are very important for the early detection of brain tumors (BTs). It makes a substantial contribution to improving the accuracy of medical evaluations and treatment approaches, which eventually results in better patient outcomes. Neural networks (NNs) techniques, like deep learning (DL), machine learning (ML), and transfer learning (TL) have recently shown promise as tools for automating and enhancing procedures for BTC. This review critically evaluates the present research on NN-based techniques for BTC, emphasising its advantages, disadvantages, and potential for future development. The variability and variety of physical features of tumors make it difficult to classify BTs. Conventional diagnostic procedures often lack the accuracy necessary for correct classification, which may result in therapy delays and subpar patient care. The primary aim of this research is to assess the efficacy of current neural network approaches in addressing the challenges associated with identifying and classifying the various forms of brain tumors. Additionally, we want to compare these techniques in order to determine the most effective approach. We comprehensively examine several NN designs after conducting an extensive literature study. According to our study findings, neural network techniques consistently demonstrate superior performance in the classification of brain tumours when compared to conventional methodologies often used in the field. Future prospects lie in the development of novel architectures, the inclusion of data from multiple sources, and incorporation of explainable AI techniques. By addressing these challenges, NN can pave the way for more accurate, efficient, and personalized BTC, ultimately contributing to better clinical outcomes and advancing our understanding of brain pathology. The results of this research will perform as a benefit starting point for future studies.
C1 [Das, Surajit; Goswami, Rajat Subhra] Natl Inst Technol, Dept Comp Sci & Engn, Jote 791113, Arunachal Prade, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh
RP Goswami, RS (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jote 791113, Arunachal Prade, India.
EM surajit.phd21@nitap.ac.in; rajat@nitap.ac.in
RI Das, Surajit/JVN-5870-2024
OI Das, Surajit/0000-0003-2015-7251; Goswami, Rajat
   Subhra/0000-0002-1592-5765
CR Abd El Kader I, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11030352
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Agrawal Ritu, 2018, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V99, P173, DOI 10.1007/s40031-018-0314-z
   Ahmad S, 2022, IEEE ACCESS, V10, P59099, DOI 10.1109/ACCESS.2022.3179376
   Akinyelu AA, 2022, J IMAGING, V8, DOI 10.3390/jimaging8080205
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3236305
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Amran GA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11213457
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Ari A, 2018, TURK J ELECTR ENG CO, V26, P2275, DOI 10.3906/elk-1801-8
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Asif S, 2022, IEEE ACCESS, V10, P34716, DOI 10.1109/ACCESS.2022.3153306
   Assam M, 2021, IEEE ACCESS, V9, P33313, DOI 10.1109/ACCESS.2021.3061487
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Banerjee S, 2019, LECT NOTES COMPUT SC, V11383, P170, DOI 10.1007/978-3-030-11723-8_17
   Banzato T, 2018, BMC VET RES, V14, DOI 10.1186/s12917-018-1638-2
   Bhardwaj A., 2018, Deep Learning Essentials: Your Hands- on Guide to the Fundamentals of Deep Learning and Neural Network Modeling
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   braintumorsegmentation, Brain tumor dataset
   Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613
   Charan KS, 2022, 2022 14TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS), DOI 10.1109/MACS56771.2022.10022493
   Chen Q, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033819858363
   Cheng J, 2023, Brain Tumor Dataset
   Cheng JR, 2020, KSII T INTERNET INF, V14, P4625, DOI 10.3837/tiis.2020.12.001
   Cinarer G., 2019, 3 INT S MULTIDISCIP, P1, DOI DOI 10.1109/ISMSIT.2019.8932878
   Dalia M, 2021, A review on brain tumor classification in mri images
   Decuyper M, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101831
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Ding PP, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8850550
   El Kader IA., 2021, Current Med. Imag. Formerly Current Med. Imag. Rev., V17, P1248, DOI DOI 10.2174/1573405617666210224113315
   Esraa B, 2021, Brain tumor automatic detection from mri images using transfer learning model with deep convolutional neural network, DOI [10.21608/JAET.2020.42896.1051, DOI 10.21608/JAET.2020.42896.1051]
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fan JT, 2020, ENGINEERING-PRC, V6, P248, DOI 10.1016/j.eng.2019.11.012
   Fernando T, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3464423
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Gupta N, 2017, SIGNAL PROCESS-IMAGE, V59, P18, DOI 10.1016/j.image.2017.05.013
   Gurbina M, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P505, DOI [10.1109/TSP.2019.8769040, 10.1109/tsp.2019.8769040]
   Hashemi M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0263-7
   Hashemi M, 2020, MULTIMED TOOLS APPL, V79, P11921, DOI 10.1007/s11042-019-08373-8
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Hollon TC, 2020, NAT MED, V26, P52, DOI 10.1038/s41591-019-0715-9
   Hossain MF., 2021, Brain tumor classification from mri images using convolutional neural network, DOI [10.1109/IICAIET51634.2021.9573574, DOI 10.1109/IICAIET51634.2021.9573574]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Husham S., 2020, J. Inf. Technol. Manag, V12, P48, DOI 10.22059/JITM.2020.78889
   Hussain L, 2019, CURR MED IMAGING, V15, P595, DOI 10.2174/1573405614666180718123533
   imm, Brain tumor dataset
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Islami F, 2021, JNCI-J NATL CANCER I, V113, P1648, DOI 10.1093/jnci/djab131
   Johnson DR, 2012, J NEURO-ONCOL, V107, P359, DOI 10.1007/s11060-011-0749-4
   Kahn CE., 2018, Acad Radiol, V25, P1020, DOI [10.1016/j.acra.2017.12.013, DOI 10.1016/J.ACRA.2017.12.013]
   Kalaiselvi T, 2020, INT J IMAG SYST TECH, V30, P926, DOI 10.1002/ima.22433
   KAVI D, Brain tumor dataset
   Khalil HA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081256
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakshmi MJ, 2022, SOFT COMPUT, V26, P6245, DOI 10.1007/s00500-022-07163-z
   Latif G, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112888
   Latif G, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12041018
   Li YX, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2979-y
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Lo SCB, 2002, IEEE T MED IMAGING, V21, P150, DOI 10.1109/42.993133
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P97, DOI 10.1007/s00401-007-0243-4
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Maqsood S, 2022, MEDICINA-LITHUANIA, V58, DOI 10.3390/medicina58081090
   med, Brain tumor dataset
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Minarno AE., 2021, KINET GAME TECHNOL I, DOI [10.22219/kinetik.v6i2.1219, DOI 10.22219/KINETIK.V6I2.1219]
   Mishra A, 2023, IEEE ACCESS, V11, P6673, DOI 10.1109/ACCESS.2023.3237542
   Modiya P., 2022, International Journal of Intelligent Systems and Applications in Engineering, V10, P201
   Mohammed BA, 2020, MATH BIOSCI ENG, V18, P851, DOI 10.3934/mbe.2021045
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Mohsen H., 2020, IEEE Trans Med Imaging, V39, P1550
   Montaha S, 2022, IEEE ACCESS, V10, P60039, DOI 10.1109/ACCESS.2022.3179577
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Muneer KVA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1228-2
   Musa UI, 2022, Intracranial-tumor detection and classification system using convnet and transfer learning
   Musallam AS, 2022, IEEE ACCESS, V10, P2775, DOI 10.1109/ACCESS.2022.3140289
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   Narayana T. Lakshmi, 2018, 2018 International Conference on Smart Systems and Inventive Technology (ICSSIT), P168, DOI 10.1109/ICSSIT.2018.8748288
   Natarajan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1135-y
   NICKPARVAR M, Brain tumor dataset
   Nie D, 2019, IEEE T NEUR NET LEAR, V30, P1552, DOI 10.1109/TNNLS.2018.2870182
   Nwankpa C, 2018, Arxiv, DOI arXiv:1811.03378
   Ottom MA, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3176737
   Özcan H, 2021, MATH BIOSCI ENG, V18, P1550, DOI 10.3934/mbe.2021080
   Padmavathi K, 2022, 2022 INT C COMP COMM, P1, DOI [10.1109/ICCCI54379.2022.9740923, DOI 10.1109/ICCCI54379.2022.9740923]
   Pal R, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10040459
   paperswithcode, Brain tumor dataset
   Rahman AU, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10020147
   Rajinikanth Venkatesan, 2022, 2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT), P987, DOI 10.1109/ICICICT54557.2022.9917904
   Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1
   Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686
   Ramdlon Rafi Haidar, 2019, 2019 International Electronics Symposium (IES). Proceedings, P660, DOI 10.1109/ELECSYM.2019.8901560
   Ramtekkar PK, 2023, MULTIMED TOOLS APPL, V82, P44623, DOI 10.1007/s11042-023-15239-7
   Rasool M, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24060799
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Rehman SU, 2019, NEUROCOMPUTING, V365, P171, DOI 10.1016/j.neucom.2019.06.084
   Rizwan M, 2022, IEEE ACCESS, V10, P29731, DOI 10.1109/ACCESS.2022.3153108
   Rundo L, 2016, SMART INNOV SYST TEC, V54, P15, DOI 10.1007/978-3-319-33747-0_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Saeed MU, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161962
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saranya N., 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012206
   Sarkar A., 2020, 2020 International Conference for Emerging Technology (INCET), P1
   Sathi Khaleda Akhter, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P155, DOI 10.1109/ICCCA49541.2020.9250760
   Sekhar A, 2022, IEEE J BIOMED HEALTH, V26, P983, DOI 10.1109/JBHI.2021.3100758
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Shah HA, 2022, IEEE ACCESS, V10, P65426, DOI 10.1109/ACCESS.2022.3184113
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   smir, Brain tumor dataset
   Smith AB, 2012, AM J ROENTGENOL, V198, P34, DOI 10.2214/AJR.10.7311
   Somasundaram K, 2015, Int J Comput Intell & Inf, V5
   Srinivas C, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3264367
   Subramanian M, 2023, IEEE ACCESS, V11, P10336, DOI 10.1109/ACCESS.2023.3240443
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Tandel GS, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103804
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Ul Haq E, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/6446680
   Vidyarthi A, 2022, IEEE ACCESS, V10, P50624, DOI 10.1109/ACCESS.2022.3172303
   Virupakshappa D.B.A., 2018, Int J Pure Appl Math, V118, P33
   Wang LL, 2022, CANCERS, V14, DOI 10.3390/cancers14225569
   Wen J, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-022-00090-9
   Xie YT, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081850
   Yang Y, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00804
   Yuan YX, 2019, MED PHYS, V46, P756, DOI 10.1002/mp.13367
   ZAW H.T., 2019, P 5 INT C ENG APPL S, P1, DOI [DOI 10.1109/ICEAST.2019.8802562, 10.1109/ICEAST.2019.8802562]
   Zhang YH, 2021, IEEE ENG MED BIO, P3233, DOI 10.1109/EMBC46164.2021.9630571
   Zhou LL, 2019, TRANSL ONCOL, V12, P292, DOI 10.1016/j.tranon.2018.10.012
   Zhu ZT, 2018, INT CONF 3D VISION, P682, DOI 10.1109/3DV.2018.00083
   Zhuge Y, 2020, MED PHYS, V47, P3044, DOI 10.1002/mp.14168
NR 146
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17215-7
EA OCT 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000019
DA 2024-07-18
ER

PT J
AU Zhu, X
   Cao, XY
   Wang, L
   Liu, MQ
   Zhao, ZY
   Wei, XY
   Sun, YF
AF Zhu, Xuan
   Cao, Xingyu
   Wang, Lin
   Liu, Mengqi
   Zhao, Zhuoyue
   Wei, Xiuyu
   Sun, Yifei
TI DCCMF-GAN: double cycle consistently constrained multi-feature
   discrimination GAN for makeup transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Makeup transfer; Cycle consistency; Multi-feature Discriminators; Codec
   structure
AB Makeup transfer aims to transfer the makeup of the human face in the reference image to another face in the source image. Most mainstream makeup transfer methods directly learn the makeup, which often regard the interference information (posture, illumination, shadow and background) as part of makeup. We propose a novel Double Cycle Consistently constrained Multi-Feature Discrimination Generative Adversarial Networks (DCCMF-GAN) for makeup transfer, which is based on the separation of "makeup" and "content". DCCMF-GAN is nested by cycle reconstruction networks CycleI and CycleII, which are separately constrained by cycle consistency loss "cycle consistency1" and "cycle consistency2". Both cycle networks consist of two makeup-transfer generators G and two multi-feature discriminators, respectively. G first encodes to separate "makeup" and "content" of the source and the reference images. Then fuses the source content with reference makeup for makeup application, and merges the source makeup with reference content for makeup removal. Under the constraint of double cycle consistency loss and the adversarial learning of multi-feature discriminators in terms of identity, global makeup and focused local makeup ensure to generate pleasant makeup conversion results. Compared with several state-of-the-art makeup transfer methods, the proposed method is insensitive to pose, illumination, shadow, expression, aging and other interference, which achieves high-quality makeup transfer with strong robustness.
C1 [Zhu, Xuan; Cao, Xingyu; Wang, Lin; Liu, Mengqi; Zhao, Zhuoyue; Wei, Xiuyu] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
   [Sun, Yifei] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
C3 Northwest University Xi'an; Northwestern Polytechnical University
RP Wang, L (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
EM wanglin@nwu.edu.cn
RI Yan, Lu/KHW-7015-2024; Sun, Yifei/HGA-8706-2022
OI Sun, Yifei/0000-0002-1449-430X
FU key project of Natural Science Foundation of Shaanxi Province
   [2018JZ6007]; Key Research and Development Program of Shaanxi Province
   [2021ZDLGY15-03]
FX This work was supported by the key project of Natural Science Foundation
   of Shaanxi Province (Grant Nos. 2018JZ6007) and the Key Research and
   Development Program of Shaanxi Province (Program No.2021ZDLGY15-03).
CR Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012
   Chen HJ, 2019, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR.2019.01028
   Deng H, 2021, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR46437.2021.00648
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu Q, 2019, IEEE I CONF COMP VIS, P10480, DOI 10.1109/ICCV.2019.01058
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jamriska O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323006
   Jiahao Lu, 2022, APIT 2022: 2022 4th Asia Pacific Information Technology Conference, P88, DOI 10.1145/3512353.3512366
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Jin X, 2019, IEEE ACCESS, V7, P80928, DOI 10.1109/ACCESS.2019.2923116
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Li Y, 2018, AAAI CONF ARTIF INTE, P7057
   Liu LQ, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659234
   Liu MY, 2017, ADV NEUR IN, V30
   Liu S, 2016, Arxiv, DOI arXiv:1604.07102
   Liu S, 2022, IEEE T PATTERN ANAL, V44, P8538, DOI 10.1109/TPAMI.2021.3083484
   Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431
   Lyu YM, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3601, DOI 10.1145/3474085.3475531
   Sun YL, 2020, IEEE T INF FOREN SEC, V15, P2679, DOI 10.1109/TIFS.2020.2975921
   Sun ZY, 2022, AAAI CONF ARTIF INTE, P2325
   Nguyen T, 2021, PROC CVPR IEEE, P13300, DOI 10.1109/CVPR46437.2021.01310
   Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wan ZY, 2022, IEEE WINT CONF APPL, P3113, DOI 10.1109/WACV51458.2022.00317
   Wang SY, 2016, AAAI CONF ARTIF INTE, P58
   Xu L, 2013, IEEE IMAGE PROC, P3206, DOI 10.1109/ICIP.2013.6738660
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 42
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17240-6
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000009
DA 2024-07-18
ER

PT J
AU Mukherjee, N
   Sengupta, S
AF Mukherjee, N.
   Sengupta, S.
TI Application of deep learning approaches for classification of diabetic
   retinopathy stages from fundus retinal images: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic Retinopathy; DR Stage Classification; DR-related Lesions;
   Medical Image Analysis; Computer-assisted Diagnosis; Machine Learning;
   Deep Learning; Survey
ID CONVOLUTIONAL NEURAL-NETWORKS; TO-DISC RATIO; AUTOMATIC DETECTION;
   MACULAR EDEMA; OPTIC DISK; DIAGNOSIS; PREVALENCE; SYSTEM; EYE;
   MICROANEURYSMS
AB Diabetic retinopathy (DR) is an impediment of diabetes mellitus, which if not treated early may result in complete loss of vision, even without any preemptive symptoms. DR is caused by high level of glucose in the blood, causing alterations in the microvasculature of retina. However, early screening of diabetic patients through retinal fundus imaging, along with proper diagnosis and treatment can control the prevalence of DR complications. Manual inspection of pathological changes in retinal fundus images is an extremely challenging and tedious task. Therefore, computer-aided diagnosis (CAD) system is an efficient and effective method for early detection of DR and can greatly assist the ophthalmologists. CAD system encompasses DR detection and severity grading that includes detection, classification, localization and segmentation of lesions from the fundus images. Significant contributions have been made in DR severity grading using conventional image processing approaches using hand-engineered features and traditional machine-learning (ML) techniques. In the recent years, significant development of deep learning (DL) methods alleviated by the advancement of hardware computation power and efficient learning algorithms, has triumphed over the traditional ML methods in DR detection and grading tasks. Many researchers have employed the established as well as customized DL models in different DR image repositories and reported their findings. In this paper, we conduct a detailed review of the recent state-of-the-art contributions in the field of DL based DR classification by explaining their methodologies and highlighting their advantages and limitations. A detailed comparative study based on certain statistical parameters has also been conducted to quantitatively evaluate the methods, models and preprocessing techniques. In addition, the challenges in designing an efficient, accurate and robust deep-learning model for DR classification are explored in details to help the future research in this field.
C1 [Mukherjee, N.] Infosys Ltd, Mysore, India.
   [Sengupta, S.] Aliah Univ, Kolkata, India.
C3 Infosys Limited; Aliah University
RP Mukherjee, N (corresponding author), Infosys Ltd, Mysore, India.
EM nilarun.mukherjee@gmail.com
OI Mukherjee, Nilarun/0000-0002-1927-6424
CR Abràmoff MD, 2013, JAMA OPHTHALMOL, V131, P351, DOI 10.1001/jamaophthalmol.2013.1743
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Acharya UR, 2009, P I MECH ENG H, V223, P545, DOI 10.1243/09544119JEIM486
   Ahmad M, 2019, I S BIOMED IMAGING, P573, DOI [10.1109/ISBI.2019.8759417, 10.1109/isbi.2019.8759417]
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   [Anonymous], 2015, Community Eye Health, V28, P70
   [Anonymous], 1991, OPHTHALMOLOGY, V98, P786
   [Anonymous], Messidor and Messidor 2 dataset
   [Anonymous], DIABETIC RETINOPATHY
   [Anonymous], Kaggle diabetic retinopathy detection competition: Kaggle EyePACS dataset
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   ANTONY M, 2015, TEAM O O SOLUTION
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhutia KL., 2017, DJO 2017, V28, P19
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Brown BA, 2017, PROG MOL BIOL TRANSL, V147, P197, DOI 10.1016/bs.pmbts.2017.01.004
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen YW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1030, DOI 10.1109/ICASSP.2018.8461427
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Colas E, 2016, ACTA OPHTHALMOL, V94, DOI 10.1111/j.1755-3768.2016.0635
   Costa P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P165, DOI 10.23919/MVA.2017.7986827
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Zeiler MD, 2012, Arxiv, DOI [arXiv:1212.5701, DOI 10.48550/ARXIV.1212.5701]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deepa V, 2022, J KING SAUD UNIV-COM, V34, P6255, DOI 10.1016/j.jksuci.2021.05.009
   Dekhil O, 2019, IEEE CONF IMAGING SY, DOI 10.1109/ist48021.2019.9010333
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   Dozat T., 2016, INT C LEARN REPR SAN
   Dr. Rajendra Prasad Centre for Ophthalmic Sciences, 2019, AIIMS, New Delhi, National Diabetes and Diabetic Retinopathy Survey India 2015-2019-A Summary Report
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   FERRIS FL, 1987, OPHTHALMOLOGY, V94, P761
   Finlayson G. D., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P475, DOI 10.1007/BFb0055685
   Fleming AD, 2010, BRIT J OPHTHALMOL, V94, P706, DOI 10.1136/bjo.2008.149807
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gagnon L, 2001, PROC SPIE, V4322, P1218, DOI 10.1117/12.430999
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gondal WM, 2017, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2017.8296646
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graham B., 2015, Diabetic Retinopathy Detection
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Harangi B, 2019, IEEE ENG MED BIO, P2699, DOI [10.1109/embc.2019.8857073, 10.1109/EMBC.2019.8857073]
   Hatanaka Y, 2010, LECT NOTES COMPUT SC, V6165, P64, DOI 10.1007/978-3-642-13923-9_7
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hubbard LD, 1999, OPHTHALMOLOGY, V106, P2269, DOI 10.1016/S0161-6420(99)90525-0
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   JONAS JB, 1988, GRAEF ARCH CLIN EXP, V226, P587, DOI 10.1007/BF02169209
   Joshi GD, 2011, IEEE T MED IMAGING, V30, P1192, DOI 10.1109/TMI.2011.2106509
   Kaggle APTOS, 2019, Blindness Detection competition
   Kannan R, 2019, The Hindu
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Kanski J.J., 2009, Clinical ophthalmology: a synopsis
   Kanungo YS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P801, DOI 10.1109/RTEICT.2017.8256708
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Kauppi T, 2008, LECT NOTES COMPUT SC, V5259, P719, DOI 10.1007/978-3-540-88458-3_65
   Keenan TDL, 2013, EYE, V27, P1397, DOI 10.1038/eye.2013.196
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   KLEIN R, 1984, ARCH OPHTHALMOL-CHIC, V102, P527, DOI 10.1001/archopht.1984.01040030405011
   KLEIN R, 1984, ARCH OPHTHALMOL-CHIC, V102, P520, DOI 10.1001/archopht.1984.01040030398010
   Knudtson MD, 2003, CURR EYE RES, V27, P143, DOI 10.1076/ceyr.27.3.143.16049
   Kori A, 2018, Arxiv, DOI arXiv:1809.04228
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar SK, 2017, CoRR
   Lam Carson, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P147
   Lazar I, 2013, IEEE T MED IMAGING, V32, P400, DOI 10.1109/TMI.2012.2228665
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SC, 2001, ARCH OPHTHALMOL-CHIC, V119, P509
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Li XL, 2018, SPRINGERBRIEF MATH, P1, DOI 10.1007/978-3-319-89617-5_1
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin ZW, 2018, LECT NOTES COMPUT SC, V11071, P74, DOI 10.1007/978-3-030-00934-2_9
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu J, 2009, IFMBE PROC, V23, P559
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Looker HC, 2012, DIABETOLOGIA, V55, P2335, DOI 10.1007/s00125-012-2596-z
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   McMahan HB, 2014, ADV NEUR IN, V27
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Migiro G, 2018, Countries by Percentage of World Population
   Mishkin D, 2016, Arxiv, DOI [arXiv:1511.06422, DOI 10.48550/ARXIV.1511.06422, 10.48550/arXiv.1511.06422]
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan JJ, 2018, I C VIRTUAL REALITY, P46, DOI 10.1109/ICVRV.2018.00016
   PATZ A, 1980, INVEST OPHTH VIS SCI, V19, P1133
   Pires R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096814
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qureshi I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060749
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Raman R, 2009, OPHTHALMOLOGY, V116, P311, DOI 10.1016/j.ophtha.2008.09.010
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rema M, 2007, INDIAN J MED RES, V125, P297
   Rema M, 2005, INVEST OPHTH VIS SCI, V46, P2328, DOI 10.1167/iovs.05-0019
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena G., 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Schmidt D, 2007, EUR J MED RES, V12, P179
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SUSSMAN EJ, 1982, JAMA-J AM MED ASSOC, V247, P3231, DOI 10.1001/jama.247.23.3231
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tien-You Lee, 1994, Proceedings of the 1994 20th Annual Northeast Bioengineering Conference (Cat. No.94CH3439-7), P54, DOI 10.1109/NEBC.1994.305177
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Vo HH, 2016, IEEE INT SYM MULTIM, P209, DOI [10.1109/ISM.2016.99, 10.1109/ISM.2016.0049]
   Walter T, 2002, LECT NOTES COMPUT SC, V2526, P210
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Walter T, 2007, MED IMAGE ANAL, V11, P555, DOI 10.1016/j.media.2007.05.001
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang J, 2013, BMC PUBLIC HEALTH, V13, DOI 10.1186/1471-2458-13-633
   Wang ZG, 2019, Arxiv, DOI arXiv:1703.10757
   Welfer D, 2010, COMPUT MED IMAG GRAP, V34, P228, DOI 10.1016/j.compmedimag.2009.10.001
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whiting DR, 2011, DIABETES RES CLIN PR, V94, P311, DOI 10.1016/j.diabres.2011.10.029
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Youssif A.A. A., 2006, PROC CAIRO INT BIOME, P21
   Zachariah Sonia, 2015, Community Eye Health, V28, P72
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
   Zilin Zhang, 2020, ICIAI 2020: Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence, P70, DOI 10.1145/3390557.3394303
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 152
TC 2
Z9 2
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17254-0
EA OCT 2023
PG 61
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400020
DA 2024-07-18
ER

PT J
AU Remzan, N
   El Hachimi, Y
   Tahiry, K
   Farchi, A
AF Remzan, Nihal
   El Hachimi, Younes
   Tahiry, Karim
   Farchi, Abdelmajid
TI Ensemble learning based-features extraction for brain mr images
   classification with machine learning classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor; MRI; CNN; Transfer learning; Ensemble learning
ID CONVOLUTIONAL NEURAL-NETWORK; TUMOR CLASSIFICATION
AB In general, different neuroimaging methods including Computed Tomography (CT), Magnetic Resonance Imaging (MRI), and Positron Emission Tomography (PET) are employed to assess the tumor in the brain. For this study, MR images are utilized to diagnose brain tumors. To assist doctors and radiologists in automatic brain tumor diagnosis and to overcome the need for manual diagnosis, a brain MR image automated classification system is being developed. The latest advancement of deep learning has helped medicine and neuroimaging in the diagnosis of many diseases, and Convolutional Neural Networks (CNN) is an extremely frequently employed deep learning approach in the automatic image classification area. This paper presents a novel approach for classifying brain MR images utilizing a dataset consisting of 5712 MR images. The dataset was partitioned into training and validation sets using an 80-20 ratio to ensure unbiased evaluation. To extract informative features from brain MR images, we employ Transfer Learning, utilizing seven pre-trained CNNs, including ResNet-50, DenseNet-121, VGG-19, EfficientNetB1, EfficientNetV2B1, Inception V3, and MobileNet. Multiple machine learning classifiers are utilized to evaluate the extracted features, and the three best-performing features are chosen to form a robust Features Ensemble. This ensemble is then combined with the best-performing machine learning classifier, the Multilayer Perceptron (MLP), to classify brain MR images into four categories: Glioma tumor, Meningioma tumor, Pituitary tumor, and Normal brain. Our experimental findings indicate that the fusion of extracted features from ResNet-50, VGG-19, and EfficientNetV2B1, using the Features Ensemble approach with the MLP classifier, significantly enhances performance. We achieve an impressive accuracy of 96,67% (+/- 1,04) with a confidence level of 95%. Furthermore, our proposed technique surpasses existing state-of-the-art methods. These results underscore the effectiveness of our approach in accurately classifying brain MR images and its potential to improve diagnostic capabilities.
C1 [Remzan, Nihal; El Hachimi, Younes; Tahiry, Karim; Farchi, Abdelmajid] Hassan First Univ, Engn Ind Management & Innovat Lab, Settat, Morocco.
C3 Hassan First University of Settat
RP Remzan, N (corresponding author), Hassan First Univ, Engn Ind Management & Innovat Lab, Settat, Morocco.
EM n.remzan@uhp.ac.ma
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Adah T, 1999, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.1999.759924
   Amiri SA., 2012, International Journal of Computer Applications, V12, P38
   [Anonymous], 2010, Leonardo J Sci, DOI DOI 10.4018/JSSCI.2011040102
   [Anonymous], IEEE Conference Publication | IEEE Xplore'
   [Anonymous], Brain Tumor Dataset
   [Anonymous], Neural Network Models (supervised)
   Arunachalam M, 2017, INT J IMAG SYST TECH, V27, P216, DOI 10.1002/ima.22227
   Avsar E, 2019, TEH GLAS, V13, P337, DOI 10.31803/tg-20190712095507
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Banerjee S., Brain tumor detection and classification from multi-channel mris using deep learning and transfer learning', P9
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Byale H., 2018, International Journal of Applied Engineering Research, V13, P11686
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Ezhilarasi R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P388, DOI 10.1109/I-SMAC.2018.8653705
   Farchi A, 2022, 2022 5 INT C ADV COM, P1, DOI [10.1109/CommNet56067.2022.9993831, DOI 10.1109/COMMNET56067.2022.9993831]
   Fathabad YF., 2012, International Journal on Technical and Physical Problems of Engineering (IJTPE), V4, P133
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Huang G, 2018, Arxiv, DOI [arXiv:1608.06993, DOI 10.48550/ARXIV.1608.06993]
   Huang ZG, 2020, IEEE ACCESS, V8, P89281, DOI 10.1109/ACCESS.2020.2993618
   kaggle, Br35H:: Brain Tumor Detection 2020
   kaggle, Brain tumor mri dataset
   kaggle, Brain Tumor Classification (MRI)
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Khan HA, 2020, MATH BIOSCI ENG, V17, P6203, DOI 10.3934/mbe.2020328
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Kim D., 2020, PREPRINT, DOI [10.20944/preprints202008.0641.v1, DOI 10.20944/PREPRINTS202008.0641.V1]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J, 2018, BIG DATA MIN ANAL, V1, P1, DOI 10.26599/BDMA.2018.9020001
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Mehrotra R., 2020, MACH LEARN APPL, V2, P100003, DOI [10.1016/j.mlwa.2020.100003, DOI 10.1016/J.MLWA.2020.100003]
   Papageorgiou EI, 2008, APPL SOFT COMPUT, V8, P820, DOI 10.1016/j.asoc.2007.06.006
   Polat Ö, 2021, J SUPERCOMPUT, V77, P7236, DOI 10.1007/s11227-020-03572-9
   Popuri K, 2012, INT J COMPUT ASS RAD, V7, P493, DOI 10.1007/s11548-011-0649-2
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Remzan N., 2023, Int J Tech Phys Probl Eng (IJTPE), V15, P68
   Remzan N., 2022, IJECE, V12, P6664, DOI [10.11591/ijece.v12i6.pp6664-6674, DOI 10.11591/IJECE.V12I6.PP6664-6674]
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Saxena P, 2023, Arxiv, DOI [arXiv:1911.02265, 10.48550/arXiv.1911.02265]
   Senthilkumaran N, 2014, 2014 WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT 2014), P80, DOI 10.1109/WCCCT.2014.45
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh HP, 2021, PARTICUL SCI TECHNOL, V39, P74, DOI 10.1080/02726351.2019.1662528
   Soumik MFI, 2020, IEEE REGION 10 SYMP, P1018, DOI 10.1109/tensymp50017.2020.9230618
   Sugimoto K, 2015, IEEE T IMAGE PROCESS, V24, P3357, DOI 10.1109/TIP.2015.2442916
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tandel GS, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103804
   Tandel GS, 2019, CANCERS, V11, DOI 10.3390/cancers11010111
   Ullah Z, 2020, MED HYPOTHESES, V143, DOI 10.1016/j.mehy.2020.109922
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Wan SH, 2018, IEEE ACCESS, V6, P36825, DOI 10.1109/ACCESS.2018.2851382
   WASSERMAN PD, 1988, IEEE EXPERT, V3, P10, DOI 10.1109/64.2091
   Xu G, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS, P60, DOI 10.1109/ISCID.2009.22
   Zhou YF, 2019, LECT NOTES COMPUT SC, V11383, P208, DOI 10.1007/978-3-030-11723-8_21
NR 65
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17213-9
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400017
DA 2024-07-18
ER

PT J
AU Sharma, S
AF Sharma, Sanjeev
TI Low power high speed FPGA design of lossless medical image compression
   using optimal deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low power; High speed; Hardware design; FPGA; Lossless image
   compression; Medical image
ID VLSI DESIGN; IMPLEMENTATION
AB Medical image compression is vital for preserving image quality and optimizing storage and transmission in healthcare facilities. FPGA design faces challenges in balancing compression ratios, speed, and power consumption. This study proposes a novel approach using the Selfish Herd Optimization (SHO) algorithm to cluster medical image data based on anatomical features. A hybrid deep convolutional neural network generates optimal predictors for each cluster, extracting features from the image data and generating predictions for each pixel based on its neighbors. The proposed system achieves low power and high-speed FPGA design while ensuring reliability and accuracy. Experimental results on Virtex-7 VC709 and Virtex-5QV130FX FPGAs demonstrate impressive improvements, including a 244.08% increase in frequency, 210.04% increase in speed, 200.90% increase in throughput, 61.37% increase in efficiency, and significant reductions in resource utilization and power consumption. This design promises efficient lossless medical image compression with enhanced performance.
C1 [Sharma, Sanjeev] New Horizon Coll Engn, Bangalore, Karnataka, India.
RP Sharma, S (corresponding author), New Horizon Coll Engn, Bangalore, Karnataka, India.
EM sanjeevsharmaphd23@gmail.com
CR Alonso T, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232934
   Báscones D, 2020, IEEE T GEOSCI REMOTE, V58, P7435, DOI 10.1109/TGRS.2020.2982586
   Ben Atitallah R, 2018, IEEE T AERO ELEC SYS, V54, P1047, DOI 10.1109/TAES.2017.2733858
   Chen LQ, 2019, IEEE T CIRC SYST VID, V29, P3754, DOI 10.1109/TCSVT.2018.2881040
   Chen SL, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031573
   Chen YH, 2020, CIRC SYST SIGNAL PR, V39, P1665, DOI 10.1007/s00034-019-01198-8
   Chen ZY, 2016, IEEE T ULTRASON FERR, V63, P1525, DOI 10.1109/TUFFC.2016.2593795
   Dang F., 2023, Front Comput Intell Syst, V3, P51, DOI [10.54097/fcis.v3i2.7194, DOI 10.54097/FCIS.V3I2.7194]
   Dargar S, 2017, IEEE T BIO-MED ENG, V64, P2595, DOI 10.1109/TBME.2016.2644651
   Deepu CJ, 2015, IEEE T BIO-MED ENG, V62, P165, DOI 10.1109/TBME.2014.2342879
   Descampe A, 2021, P IEEE, V109, P1559, DOI 10.1109/JPROC.2021.3080916
   Dutta T, 2015, IEEE SENS J, V15, P778, DOI 10.1109/JSEN.2014.2354394
   Fang LY, 2015, IEEE T MED IMAGING, V34, P1306, DOI 10.1109/TMI.2014.2387336
   Farghaly SH, 2020, AEU-INT J ELECTRON C, V124, DOI 10.1016/j.aeue.2020.153363
   Fjeldtvedt J, 2018, IEEE J-STARS, V11, P3841, DOI 10.1109/JSTARS.2018.2869697
   García A, 2014, PROC SPIE, V9247, DOI 10.1117/12.2069493
   García A, 2013, WORK HYPERSP IMAG
   Ghodhbani R, 2023, Neural Comput Appl, V33, P1
   Heindel A, 2017, IEEE T CIRC SYST VID, V27, P1749, DOI 10.1109/TCSVT.2016.2556338
   Hwang YT, 2011, IEEE EMBED SYST LETT, V3, P20, DOI 10.1109/LES.2010.2092413
   Jayavathi SD, 2019, J REAL-TIME IMAGE PR, V16, P1765, DOI 10.1007/s11554-017-0683-6
   Jiang WW, 2018, IEEE T COMPUT AID D, V37, P2542, DOI 10.1109/TCAD.2018.2857098
   Kim SW, 2019, IEEE T CONSUM ELECTR, V65, P322, DOI 10.1109/TCE.2019.2923989
   Kim Y, 2019, J SYST ARCHITECT, V98, P41, DOI 10.1016/j.sysarc.2019.06.005
   Kiranmaye G, 2019, MULTIMED TOOLS APPL, V78, P17673, DOI 10.1007/s11042-018-7055-5
   Li TW, 2019, IEEE T VLSI SYST, V27, P1276, DOI 10.1109/TVLSI.2019.2892838
   Lopes A, 2017, MICROPROCESS MICROSY, V49, P54, DOI 10.1016/j.micpro.2017.01.008
   Lopes A, 2021, J REAL-TIME IMAGE PR, V18, P2037, DOI 10.1007/s11554-021-01078-y
   Lucas LFR, 2017, IEEE T MED IMAGING, V36, P2250, DOI 10.1109/TMI.2017.2714640
   Mahzoon A, 2017, IEEE T CIRCUITS-II, V64, P274, DOI 10.1109/TCSII.2016.2596800
   Mei KZ, 2007, IEEE T CIRC SYST VID, V17, P1065, DOI 10.1109/TCSVT.2007.903555
   Nagornov NN, 2022, IEEE ACCESS, V10, P19215, DOI 10.1109/ACCESS.2022.3151361
   Santos L, 2020, IEEE T AERO ELEC SYS, V56, P1120, DOI 10.1109/TAES.2019.2929971
   Santos L, 2013, 2013 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS (AHS), P107, DOI 10.1109/AHS.2013.6604233
   Tsigkanos A, 2020, IEEE T VLSI SYST, V28, P2397, DOI 10.1109/TVLSI.2020.3020164
   Yankelevsky Y, 2017, IEEE T SIGNAL PROCES, V65, P5743, DOI 10.1109/TSP.2017.2731303
NR 36
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-16958-7
EA OCT 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400007
DA 2024-07-18
ER

PT J
AU Tirupal, T
   Pandurangaiah, Y
   Roy, A
   Kishore, VV
   Nayyar, A
AF Tirupal, T.
   Pandurangaiah, Y.
   Roy, Ajay
   Kishore, V. Vijaya
   Nayyar, Anand
TI On the use of UDWT and fuzzy sets for medical image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal medical image; Image fusion; UDWT; Fuzzy sets; Fused image
ID WAVELET TRANSFORM; SEGMENTATION; RECOGNITION; FRAMEWORK; SCHEMES; IHS
AB Multimodal medical image fusion is the process of obtaining relevant information from medical images. In order to create a single image that is better suitable for diagnosis, multiple images from various sources are combined in image fusion for medical images. Since many of the structures in medical images are rarely discernible and the merged image typically shows blurring and lags behind the accompanying data, the complexity of medical images is higher. The purpose of this research is to present a novel hybrid approach based on fuzzy sets and Undecimated Discrete Wavelet Transform (UDWT) for improved visual analysis and to lessen blurring of medical images. There is no decimation stage in UDWT. It is a non-orthogonal multiresolution decomposition. In medical images, fuzzy sets are essential for reducing ambiguity. This research paper UDWT after fuzzifying the source photos. The maximum selection criterion is used to combine low-frequency subbands in the UDWT domain, whereas the Modified Spatial Frequency (MSF) technique is utilized to combine high-frequency subbands. The inverse UDWT creates the merged image. Several pairs of photos are used to demonstrate multimodal medical image fusion's efficacy. The suggested algorithm has higher entropy (6.99 bits/pixel for MR-MRA), spatial frequency (SF) (27.95 cycles/millimeter for CT-MRI), edge-based image fusion measure (QAB/F) (0.94 for MRI-PET), and standard deviation (SD) (40.24 for X-ray-VA) as compared to other existing algorithms. The experimental data enlightens that the proposed (UDWT + Fuzzy set) approach outperforms other approaches discussed in the literature.
C1 [Tirupal, T.; Pandurangaiah, Y.] G Pullaiah Coll Engn & Technol, Dept ECE, Kurnool 518002, Andhra Pradesh, India.
   [Roy, Ajay] Lovely Profess Univ, Dept ECE, Phagwara 144401, Punjab, India.
   [Kishore, V. Vijaya] Mohan Babu Univ, Dept ECE, Tirupati 517102, Andhra Pradesh, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 G. Pullaiah College of Engineering & Technology; Lovely Professional
   University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM tirutalari@gmail.com; y.pandurangaiah@gmail.com; ajoy.22652@lpu.co.in;
   kishiee@rediffmail.com; anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Rangaiah, Yagateela Pandu/KCL-2527-2024; Roy,
   Dr Ajay/ABQ-9826-2022
OI Nayyar, Anand/0000-0002-9821-6146; Rangaiah, Yagateela
   Pandu/0009-0000-9970-7521; Roy, Dr Ajay/0000-0002-6329-8241
CR Ali F. E., 2008, Progress In Electromagnetics Research C, V3, P215, DOI 10.2528/PIERC08041305
   Assareh A, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P193
   Azam MA, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105253
   Barra V, 2001, NEUROIMAGE, V13, P410, DOI 10.1006/nimg.2000.0707
   Baum KG, 2007, IEEE NUCL SCI CONF R, P3774, DOI 10.1109/NSSMIC.2007.4436944
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bloch I, 2005, PATTERN RECOGN LETT, V26, P449, DOI 10.1016/j.patrec.2004.08.009
   Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712
   Chavan S, 2016, ADV INTELLIGENT SYST, V137, P627
   Cheng S., 2008, 2008 2 INT C BIOINFO, P2523, DOI DOI 10.1109/ICBBE.2008.964
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Dou WB, 2007, IMAGE VISION COMPUT, V25, P164, DOI 10.1016/j.imavis.2006.01.025
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Gopi Krishna E., 2015, INT J TECH RES ENG, V2, P3184
   Haddadpour M, 2017, BIOMED J, V40, P219, DOI 10.1016/j.bj.2017.05.002
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Haribabu M, 2023, CURR MED IMAGING, V19, P673, DOI 10.2174/1573405618666220606161137
   Harvard, About us
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   Holupka EJ, 1996, INT J RADIAT ONCOL, V35, P975, DOI 10.1016/0360-3016(96)00231-3
   Hosseini HG, 2007, INT J BIOMED IMAGING, V2007, DOI 10.1155/2007/40980
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jionghua Teng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1552, DOI 10.1109/CISP.2010.5646958
   Kaplan I., 1998, Int J Rad Oncol Biol Phys, V42, P294, DOI DOI 10.1016/S0360-3016(98)80441-0
   Kavitha C. T., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P296, DOI 10.1109/ICSIP.2010.5697486
   Kor S, 2004, P ANN INT IEEE EMBS, V26, P1479
   Li B, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107793
   LI HY, 1995, IEEE T MED IMAGING, V14, P212, DOI 10.1109/42.387703
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li W, 2018, OPTIK, V172, P1, DOI 10.1016/j.ijleo.2018.06.123
   Li X, 2010, IET IMAGE PROCESS, V4, P283, DOI 10.1049/iet-ipr.2008.0259
   Lin KP., 1995, IEEE 17 ANN C ENG ME, V1, P377
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Manchanda M, 2016, J VIS COMMUN IMAGE R, V40, P197, DOI 10.1016/j.jvcir.2016.06.021
   Marshall S., 1995, Proc IEEE Vis Image Signal Process, V141, P1
   Megalooikonomou V, 2007, IEEE ENG MED BIOL, V26, P36, DOI 10.1109/EMB.2007.901790
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mikoajczyk K, 1993, Lecture Notes in Computer Science, V719, DOI [10.1007/3-540-57233-3_89, DOI 10.1007/3-540-57233-3_89]
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Mukhopadhyay S, 2001, PATTERN RECOGN, V34, P1939, DOI 10.1016/S0031-3203(00)00123-0
   Muzammil SR, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10110904
   Na Y, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P37, DOI 10.1109/FSKD.2008.608
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Naidu VPS., 2017, CONTROL DATA FUSION, V1, P13
   Prakash O, 2019, OPTIK, V182, P995, DOI 10.1016/j.ijleo.2018.12.028
   Qiu CH, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/9308745
   Qu GH, 2001, OPT EXPRESS, V9, P184, DOI 10.1364/OE.9.000184
   Raza M., 2001, Classifier fusion to predict breast cancer tumors based on microarray gene expression data. Knowledge-Based Intelligent Information and Engineering Systems, P866
   Rogova G. L., 2002, Information Fusion, V3, P91, DOI 10.1016/S1566-2535(02)00054-4
   Shandoosti HR, 2018, DIGIT SIGNAL PROCESS, V79, P9, DOI 10.1016/j.dsp.2018.04.002
   Shanker Mishra HO., 2014, INT J INFORM COMPUTA, V4, P47
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Singh R, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P232, DOI 10.1109/ICAPR.2009.97
   Srilatha K, 2015, RES J PHARM BIOL CHE, V6, P775
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Szu H, 2003, P ANN INT IEEE EMBS, V25, P1133, DOI 10.1109/IEMBS.2003.1279448
   Tang L, 2017, INT J IMAG SYST TECH, V27, P57, DOI 10.1002/ima.22210
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   Toet A., 1990, Machine Vision and Applications, V3, P1, DOI 10.1007/BF01211447
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Vakaimalar E, 2019, MULTIMED TOOLS APPL, V78, P17573, DOI 10.1007/s11042-018-7124-9
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Yang B, 2008, CONF CYBERN INTELL S, P55
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yang Y, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/835481
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 76
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16892-8
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500002
DA 2024-07-18
ER

PT J
AU Ernawan, F
AF Ernawan, Ferda
TI An improved hiding information by modifying selected DWT coefficients in
   video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hiding information; Video steganography; Discrete wavelet transform;
   Extracting data; Steganography
ID SCENE CHANGE DETECTION; WAVELET TRANSFORM; H.264/AVC; ROBUST;
   CRYPTOGRAPHY; ALGORITHM; SCHEME; IMAGE
AB The rapid expansion of information technology enables users to transfer data or files via the internet in a short time. Steganography is the art of embedding secret information or messages in multimedia data. Video is the most popular medium in steganography to transmit data from sender to receiver. Video has a larger hiding capacity and it provides large redundancy space in video frame sequences. The objective of this research is to embed into the selected video frames based on a new hiding technique with the discrete wavelet transform (DWT). The selected video frames based on scene change detection were chosen for hiding data to minimise the visibility effect on the stego-video. DWT was computed to decompose the selected video frame into sub-bands, the approximation coefficient matrix of two-level DWT was selected to embed the data. The proposed scheme was compared to the existing schemes in terms of imperceptibility. The experimental results showed that the proposed technique achieved high SSIM and PSNR values. The proposed scheme achieved an SSIM value of 0.990 and a PSNR value of 46.09 dB. In addition, the proposed steganography scheme produced good robustness against MPEG-4 compression whereby the message can be fully recognized.
C1 [Ernawan, Ferda] Univ Malaysia Pahang Al Sultan Abdullah, Fac Comp, Pekan 26600, Pahang, Malaysia.
   [Ernawan, Ferda] Univ Nusa Mandiri, Fac Informat Technol, Jakarta, Indonesia.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Ernawan, F (corresponding author), Univ Malaysia Pahang Al Sultan Abdullah, Fac Comp, Pekan 26600, Pahang, Malaysia.; Ernawan, F (corresponding author), Univ Nusa Mandiri, Fac Informat Technol, Jakarta, Indonesia.
EM ferda1902@gmail.com
RI Ernawan, Ferda/B-4214-2012
OI Ernawan, Ferda/0000-0002-6779-1594
FU This work was supported by the Ministry of Higher Education for
   providing financial support under the Fundamental Research Grant Scheme
   (FRGS), Ref: FRGS/1/2023/ICT04/UMP/02/1.; Ministry of Higher Education
   [FRGS/1/2023/ICT04/UMP/02/1]; Fundamental Research Grant Scheme (FRGS)
FX This work was supported by the Ministry of Higher Education for
   providing financial support under the Fundamental Research Grant Scheme
   (FRGS), Ref: FRGS/1/2023/ICT04/UMP/02/1.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Ashraf Z, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03771
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   BanuPriya R., 2019, Int J Mech Eng Technol, V10, P203
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Fatnassi A, 2019, PROCEDIA COMPUT SCI, V159, P953, DOI 10.1016/j.procs.2019.09.262
   Fuad M., 2019, Int J Sci Technol Res, V8, P761
   Gadde R, 2017, IEEE I CONF COMP VIS, P4463, DOI 10.1109/ICCV.2017.477
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Kar N, 2018, ICT EXPRESS, V4, P6, DOI 10.1016/j.icte.2018.01.003
   Laskar S. A., 2012, International Journal on Cryptography and Information Security, V2, P161
   Liu SY, 2020, COGN SYST RES, V59, P207, DOI 10.1016/j.cogsys.2019.09.008
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Muhammad F., 2020, Bull. Electr. Eng. Inf., V9, P1015
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Ramalingam M., 2011, WORLD ACAD SCI ENG T, V74, P502
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Ravichandran D., 2016, Image Coding, V5, P2319
   Reddy MIS, 2016, PROCEDIA COMPUT SCI, V85, P62, DOI 10.1016/j.procs.2016.05.177
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Swanberg D., 1908, Proc SPIE, V1993, P173
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Wu X, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113516
   Xiph.org, Video test media
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zhou WS, 2001, J VIS COMMUN IMAGE R, V12, P1, DOI 10.1006/jvci.2000.0459
NR 37
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-17113-y
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000010
DA 2024-07-18
ER

PT J
AU Agrawal, H
   Halder, A
   Chattopadhyay, P
AF Agrawal, Harshit
   Halder, Agrya
   Chattopadhyay, Pratik
TI A systematic survey on recent deep learning-based approaches to
   multi-object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning-based MOT; Literature review; MOT datasets; MOT evaluation
   metrics; MOT comparative study
ID MULTIPLE OBJECT TRACKING; CAMERA TRACKING; NETWORK FLOW; ONLINE; GRAPH;
   REIDENTIFICATION; ASSOCIATION
AB This survey covers an in-depth review of the state-of-the-art research on Multi-Object Tracking (MOT) from research articles published in 2019 or later in top-tier journals and conferences. We categorize existing MOT research into nine broad categories and discuss the workflow and limitations of each of these categories. Such a classification will enable readers to understand the research trend in different sub-domains of the MOT problem, as well as identify the research gaps. To the best of our knowledge, existing surveys on MOT do not put much emphasis on discussing the tracking step of MOT, which we have addressed here. Additionally, our survey highlights the progress made in MOT by employing recent Deep Learning models such as Transformers, Graph Neural Networks, etc., which also have not been covered in other surveys. It also discusses the challenges faced by the various trackers due to a variety of extrinsic and intrinsic factors. Additionally, we elaborate on the available public datasets, benchmarks, and metrics employed to evaluate the performance of an MOT model and make comparative studies to enlist the important results reported in previous research studies for some popular MOT datasets. This survey will provide the readers with an extensive overview of the state-of-the-art MOT algorithms and their shortcomings, which will help them in designing and developing newer and better MOT algorithms.
C1 [Agrawal, Harshit; Halder, Agrya; Chattopadhyay, Pratik] Indian Inst Technol BHU, Dept CSE, Pattern Recognit Lab, Varanasi 221005, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Chattopadhyay, P (corresponding author), Indian Inst Technol BHU, Dept CSE, Pattern Recognit Lab, Varanasi 221005, India.
EM harshitagrawal.cse18@iitbhu.ac.in; agryahalder.rs.cse21@iitbhu.ac.in;
   pratik.cse@iitbhu.ac.in
OI Halder, Agrya/0000-0001-9675-8104; Chattopadhyay,
   Pratik/0000-0002-5805-6563
FU The authors acknowledge SERB-DST, Government of India for supporting
   their work with a project grant (ref. no. CRG/2020/005465).
   [CRG/2020/005465]; SERB-DST, Government of India
FX The authors acknowledge SERB-DST, Government of India for supporting
   their work with a project grant (ref. no. CRG/2020/005465).
CR AL-Shakarji NM, 2020, IEEE APP IMG PAT, DOI 10.1109/AIPR50011.2020.9425339
   Bashar M., 2022, arXiv
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Beyer L, 2017, IEEE COMPUT SOC CONF, P1444, DOI 10.1109/CVPRW.2017.187
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Büchner M, 2022, IEEE ROBOT AUTOM LET, V7, P9707, DOI 10.1109/LRA.2022.3191558
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cai JR, 2022, PROC CVPR IEEE, P8080, DOI 10.1109/CVPR52688.2022.00792
   Cao Jinkun, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P9686, DOI 10.1109/CVPR52729.2023.00934
   Cao JK, 2023, Arxiv, DOI arXiv:2203.14360
   Chaabane M, 2021, Arxiv, DOI arXiv:2102.02267
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Chavez-Garcia RO, 2016, IEEE T INTELL TRANSP, V17, P525, DOI 10.1109/TITS.2015.2479925
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Chiu HK, 2020, Arxiv, DOI arXiv:2001.05673
   Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347
   Chu P, 2021, Arxiv, DOI arXiv:2104.00194
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Dai P, 2021, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR46437.2021.00247
   Dai Y, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102317
   Dave Achal, 2020, EUR C COMP VIS ECCV
   Dendorfer P., 2020, arXiv
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Emami P, 2020, Arxiv, DOI arXiv:1802.06897
   Fagot-Bouquet L, 2016, LECT NOTES COMPUT SC, V9912, P774, DOI 10.1007/978-3-319-46484-8_47
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan LT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1855, DOI 10.1109/ICInfA.2016.7832121
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gade R., 2017, IPSJ Trans Comput Vision Appl, V10, P1
   Galor A, 2022, arXiv
   Gani MHH, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATION (ICSIMA 2017)
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Gao XW, 2022, SIGNAL IMAGE VIDEO P, V16, P965, DOI 10.1007/s11760-021-02041-x
   Gebregziabher B, 2023, Arxiv, DOI arXiv:2307.02161
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Ghasemi A, 2015, Int J Sci Res Educ, V3
   He JW, 2021, PROC CVPR IEEE, P5295, DOI 10.1109/CVPR46437.2021.00526
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henschel R, 2019, IEEE COMPUT SOC CONF, P770, DOI 10.1109/CVPRW.2019.00105
   Hornakova A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6310, DOI 10.1109/ICCV48922.2021.00627
   Huang K., 2023, P IEEECVF C COMPUTER, P3162
   Jiang XL, 2019, Arxiv, DOI arXiv:1907.05315
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Khorramshahi P., 2022, Scalable and realtime multi-camera vehicle detection, re-identification, and tracking
   Kim C, 2021, PROC CVPR IEEE, P9548, DOI 10.1109/CVPR46437.2021.00943
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kim K., 2011, CVPR 2011 WORKSH, P37, DOI 10.1109/CVPRW.2011.5981808
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Lee J, 2021, IEEE ACCESS, V9, P114535, DOI 10.1109/ACCESS.2021.3105118
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li JH, 2020, IEEE WINT CONF APPL, P708, DOI 10.1109/WACV45572.2020.9093347
   Li M, 2016, Detecting, segmenting and tracking bio-medical objects
   Li YZ, 2022, INT CONF ACOUST SPEE, P2849, DOI 10.1109/ICASSP43922.2022.9747572
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Liu D, 2021, Multi-object tracking and segmentation for autonomous driving: A flow guided association approach
   Liu S, 2022, PROC CVPR IEEE, P8866, DOI 10.1109/CVPR52688.2022.00867
   Liu YT, 2022, NEUROCOMPUTING, V481, P91, DOI 10.1016/j.neucom.2022.01.073
   Luo CX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10468, DOI 10.1109/ICCV48922.2021.01032
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   Lusardi C, 2021, IEEE INT CONF COMP V, P3861, DOI 10.1109/ICCVW54120.2021.00433
    CM, 2016, Arxiv, DOI arXiv:1608.06148
   Ma C, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P253, DOI 10.1145/3323873.3325010
   Marinello N, 2022, IEEE COMPUT SOC CONF, P4499, DOI 10.1109/CVPRW56347.2022.00496
   McKee D., 2021, arXiv
   Meinhardt T, 2022, PROC CVPR IEEE, P8834, DOI 10.1109/CVPR52688.2022.00864
   Miah M, 2023, Arxiv, DOI arXiv:2110.11284
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Mostafa R, 2022, IEEE ACCESS, V10, P83085, DOI 10.1109/ACCESS.2022.3197157
   Musaev A, 2020, Arxiv, DOI arXiv:2005.08009
   Nalaie K, 2022, 7TH ACM/IEEE CONFERENCE ON INTERNET-OF-THINGS DESIGN AND IMPLEMENTATION (IOTDI 2022), P67, DOI 10.1109/IoTDI54339.2022.00010
   Ning GH, 2020, IEEE COMPUT SOC CONF, P4456, DOI 10.1109/CVPRW50498.2020.00525
   Ondrúska P, 2016, AAAI CONF ARTIF INTE, P3361
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pan GZ, 2019, NEUROCOMPUTING, V358, P33, DOI 10.1016/j.neucom.2019.05.033
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Pang Ziqi, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P17928, DOI 10.1109/CVPR52729.2023.01719
   Pang Z., arXiv
   Papakis I, 2020, arXiv
   Park Y, 2021, ELECTRONICS
   Patel AS, 2023, VISUAL COMPUT, V39, P2127, DOI 10.1007/s00371-022-02469-3
   Peng JL, 2020, Arxiv, DOI arXiv:2007.14557
   Peri N, 2020, IEEE COMPUT SOC CONF, P2648, DOI 10.1109/CVPRW50498.2020.00319
   Psalta A, 2022, Arxiv, DOI arXiv:2208.03571
   Qin Zheng, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P17939, DOI 10.1109/CVPR52729.2023.01720
   Rahul MV, 2017, P 9 INT C MACH LEARN
   Rangesh A, 2021, Arxiv, DOI arXiv:2101.04206
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E., 2016, Performance measures and a data set for multi-target, multi-camera tracking
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Rubin J, 2021, ML4H NEURIPS
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Saleh F, 2020, Arxiv, DOI arXiv:2004.07482
   Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292
   Seidenschwarz Jenny, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P13813, DOI 10.1109/CVPR52729.2023.01327
   Shuai B, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4625, DOI 10.1145/3394171.3416297
   Shuai B, 2021, PROC CVPR IEEE, P12367, DOI 10.1109/CVPR46437.2021.01219
   Smal I, 2008, MED IMAGE ANAL, V12, P764, DOI 10.1016/j.media.2008.03.004
   Song YY, 2021, IET IMAGE PROCESS, V15, P3661, DOI 10.1049/ipr2.12327
   Stadler D, 2021, 2021 17 IEEE INT C A, P1
   Stadler D, 2021, PROC CVPR IEEE, P10953, DOI 10.1109/CVPR46437.2021.01081
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Sun SJ, 2020, Arxiv, DOI arXiv:2008.08826
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tokmakov P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10840, DOI 10.1109/ICCV48922.2021.01068
   Tsai CY, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105770
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaquero L, 2022, Arxiv, DOI arXiv:2202.04966
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wan XY, 2018, IEEE COMPUT SOC CONF, P1311, DOI 10.1109/CVPRW.2018.00169
   Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245
   Wang C., 2020, IEEE T PATTERN ANAL
   Wang CC, 2019, ADV NEUR IN, V32
   Wang GA, 2024, Arxiv, DOI arXiv:2205.10766
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Wang L, 2017, IEEE IMAGE PROC, P3630, DOI 10.1109/ICIP.2017.8296959
   Wang Q, 2021, PROC CVPR IEEE, P3875, DOI 10.1109/CVPR46437.2021.00387
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13199, DOI 10.1109/ICCV48922.2021.01297
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang YX, 2021, Arxiv, DOI arXiv:2006.13164
   Wang YX, 2021, IEEE INT CONF ROBOT, P13708, DOI 10.1109/ICRA48506.2021.9561110
   Weng XS, 2020, Arxiv, DOI arXiv:2012.05894
   Weng XS, 2021, IEEE ROBOT AUTOM LET, V6, P4640, DOI 10.1109/LRA.2021.3068925
   Weng XS, 2020, IEEE INT C INT ROBOT, P10359, DOI 10.1109/IROS45743.2020.9341164
   Weng XS, 2020, PROC CVPR IEEE, P6498, DOI 10.1109/CVPR42600.2020.00653
   Willes J, 2023, Arxiv, DOI arXiv:2208.08041
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Dongming, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P14633, DOI 10.1109/CVPR52729.2023.01406
   Wu JL, 2021, PROC CVPR IEEE, P12347, DOI 10.1109/CVPR46437.2021.01217
   Wu MH, 2021, IEEE COMPUT SOC CONF, P4072, DOI 10.1109/CVPRW53098.2021.00460
   Xie D, 2004, INT C PATT RECOG, P767, DOI 10.1109/ICPR.2004.1333885
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu XK, 2022, IEEE J-STARS, V15, P8734, DOI 10.1109/JSTARS.2022.3213438
   Xu YH, 2023, IEEE T PATTERN ANAL, V45, P7820, DOI 10.1109/TPAMI.2022.3225078
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Xu Yihong, 2022, IEEE T PATTERN ANAL
   Xu YK, 2019, IET COMPUT VIS, V13, P355, DOI 10.1049/iet-cvi.2018.5598
   Yang F, 2023, IEEE WINT CONF APPL, P4788, DOI 10.1109/WACV56688.2023.00478
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang JM, 2022, APPL INTELL, V52, P9967, DOI 10.1007/s10489-021-03012-y
   Yin JB, 2020, PROC CVPR IEEE, P6767, DOI 10.1109/CVPR42600.2020.00680
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Zaech J-N, 2022, IEEE Robot Autom Lett, V1
   Zeng Fangao, 2022, ECCV
   Zhang JM, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107730
   Zhang WW, 2019, IEEE I CONF COMP VIS, P2365, DOI 10.1109/ICCV.2019.00245
   Zhang Y, 2021, EUR C COMP VIS
   Zhang Y, 2020, IEEE INTERNET THINGS, V7, P7892, DOI 10.1109/JIOT.2020.2996609
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhao DW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072004
   Zhenbo Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P264, DOI 10.1007/978-3-030-58452-8_16
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng LY, 2021, PROC CVPR IEEE, P2453, DOI 10.1109/CVPR46437.2021.00248
   Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14656, DOI 10.1109/CVPR42600.2020.01468
   Zhou XY, 2020, Arxiv, DOI arXiv:2004.01177
   Zhou XY, 2022, PROC CVPR IEEE, P8761, DOI 10.1109/CVPR52688.2022.00857
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu T, 2022, IEEE Trans Pattern Anal Mach Intell
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 179
TC 0
Z9 0
U1 10
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16910-9
EA SEP 2023
PG 57
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700011
DA 2024-07-18
ER

PT J
AU Alemu, AA
   Melese, MD
   Salau, AO
AF Alemu, Amlakie Aschale
   Melese, Malefia Demilie
   Salau, Ayodeji Olalekan
TI Ethio-Semitic language identification using convolutional neural
   networks with data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE LID; Ethio-Semitic Languages; CNN; MFCC; Mel-Spectrogram; Augmentation
AB In today's digital world, natural language is used to exchange information among humans, and it has now advanced to the point of being an evolution criteria for technology. The process of determining which language a speaker is speaking is known as spoken language identification, and it is used for front-end processing in human-computer interaction. In this study, we developed a Language Identification model for Ethio-Semitic languages because Language Identification is an intermediate task for other Natural Language Processing tasks such as speech to text translation, speech to speech translation, speech recognition, and speech information retrieval. We used Convolutional Neural Network with respect to different acoustic features such as Mel-frequency Cepstral Coefficients, mel-spectrogram and combined (Mel-frequency Cepstral Coefficients + mel-spectrogram) features to emphasize critical features for uncomplicated output identification. The study's primary goal was to identify specific languages such as Amharic, Geez, Guragigna, and Tigrigna. Based on this, the results show that Convolutional Neural Network with augmented data and hybrid features performed better than using Mel-frequency Cepstral Coefficients or Mel-spectrogram features. The proposed model achieved an average performance accuracy of 97%, 97.4% and 99.5% for testing, validation, and training respectively. We consequently reached the conclusion that the combined (Mel- Spectrogram + Mel-frequency Cepstral Coefficients) feature was the most crucial feature.
C1 [Alemu, Amlakie Aschale] Debre Tabor Univ, Dept Elect & Comp Engn, Debre Tabor, Ethiopia.
   [Melese, Malefia Demilie] Debre Tabor Univ, Gafat Inst Technol, Dept Informat Technol, Debre Tabor, Ethiopia.
   [Salau, Ayodeji Olalekan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Olalekan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
EM amlakieaschale19@gmail.com; nmalefia@gmail.com; ayodejisalau98@gmail.com
RI Alemu, Amlakie Aschale/KHD-8653-2024; salau, ayodeji
   Olalekan/C-1016-2018
OI salau, ayodeji Olalekan/0000-0002-6264-9783
CR Abate ST, 2020, INTERSPEECH, P1047, DOI 10.21437/Interspeech.2020-2856
   Abeje BT, 2022, MULTIMED TOOLS APPL, V81, P29027, DOI 10.1007/s11042-022-12768-5
   Afrillia Y, 2017, J PHYS CONF SER, V930, DOI 10.1088/1742-6596/930/1/012036
   Anjana JS, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   [Anonymous], 2015, INT C REC ADV NAT LA
   Bartz C, 2017, LECT NOTES COMPUT SC, V10639, P880, DOI 10.1007/978-3-319-70136-3_93
   Batanovic V, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242050
   Chauhan N, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P130, DOI [10.1109/ccoms.2019.8821751, 10.1109/CCOMS.2019.8821751]
   de Benito-Gorron D, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0152-1
   Demilie Wubetu Barud, 2022, 2022 9th International Conference on Computing for Sustainable Global Development (INDIACom), P569, DOI 10.23919/INDIACom54597.2022.9763213
   Demilie WB, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00299-1
   Deshwal D, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107289
   Dey S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3523179
   Discloser CR, 2012, discloser, V1, P1
   Feleke Tekabe Legesse., 2021, Ampersand, V8, P100074, DOI [10.1016/j.amper.2021.100074, DOI 10.1016/J.AMPER.2021.100074]
   Fesseha A, 2021, INFORMATION, V12, DOI 10.3390/info12020052
   Furlan B, 2013, DECIS SUPPORT SYST, V55, P710, DOI 10.1016/j.dss.2013.02.002
   Gris LR, 2020, AN 17 C LAT AM SOFTW, P16
   Gupta M., 2017, 4 INT C POW CONTR EM, P1, DOI [10.1109/ICPCES.2017.8117624, DOI 10.1109/ICPCES.2017.8117624]
   Gurmessa DK., 2022, J Electrical Electron Eng, V15, P37
   Hasan MR, 2021, J ENG-JOE, V2021, P817, DOI 10.1049/tje2.12082
   Hasan MR, 2020, IEEE REGION 10 SYMP, P1408
   Khamees A, 2021, CNN and RNN, DOI [10.1007/978-3-030-69717-4, DOI 10.1007/978-3-030-69717-4]
   Kim H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072225
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kshirsagar S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176445
   Kumar A, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P81, DOI 10.1109/ICSTM.2015.7225394
   Lei Y, 2014, OD 2014 SPEAK LANG R, P287
   Madhu C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, INFORMATICS, COMMUNICATION AND ENERGY SYSTEMS (SPICES)
   Maity S, 2012, 2012 NAT C COMM NCC, P1
   Mukherjee Shyamapada, 2019, 2019 International Conference on Information Technology (ICIT), P37, DOI 10.1109/ICIT48102.2019.00013
   Mushtaq Z, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107581
   Niu YF, 2017, Arxiv, DOI arXiv:1707.09917
   Petronas UT, 2013, Shikha Gupta 1, Jafreezal Jaafar 2, Wan Fatimah wan Ahmad 3 and Arpit Bansal 4 Universiti Tecknologi PETRONAS, V4, P101
   Ragab MG, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104660
   Rao KS., 2015, Language identification using spectral and prosodic features, DOI [10.1007/978-3-319-17725-0, DOI 10.1007/978-3-319-17725-0]
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Salau A. O., 2020, Accent classification of the three major nigerian indigenous languages using 1D CNN LSTM network model, P1, DOI [10.1007/978-981-15-2620-6_1, DOI 10.1007/978-981-15-2620-6_1]
   Singh G, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5123671
   Tamiru NK, 2022, VISUAL COMPUT, V38, P1703, DOI 10.1007/s00371-021-02099-1
   Wang Q., 2022, Attentive temporal pooling for conformer-based streaming language identification in long-form speech, P255, DOI [10.21437/odyssey.2022-36, DOI 10.21437/ODYSSEY.2022-36]
   Zhou G, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01942-2
NR 42
TC 2
Z9 2
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-17094-y
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S5NV5
UT WOS:001071641500002
DA 2024-07-18
ER

PT J
AU Chouhayebi, H
   Mahraz, MA
   Riffi, J
   Tairi, H
AF Chouhayebi, Hajar
   Mahraz, Mohamed Adnane
   Riffi, Jamal
   Tairi, Hamid
TI A dynamic fusion of features from deep learning and the HOG-TOP
   algorithm for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; MCB; SVM; LSTM; VGG19; ResNet; Facial expression
   recognition
ID EMOTION RECOGNITION; BINARY PATTERNS
AB Facial expression recognition plays an essential role in surveillance videos, anxiety treatment, expression analysis, gesture recognition, computer games, patient monitoring, operator fatigue detection, and robotics. Therefore, facial expression recognition has attracted more and more attention over the years and became a difficult task because emotion can be influenced by several factors. Some approaches based on Deep Convolutional Neural Networks (DCNN) and Transfer Learning have been successful to recognize emotion in video sequences. However, these approaches remain limited because it is difficult to model spatio-temporal interactions between video frames or identify salient features to improve accuracy. In this article, we propose a facial expression recognition system combining the representations of Deep Learning features and dynamic texture features. For the Deep Learning part, we used the VGG19 model to extract facial features, which will feed the LSTM (Long Short Term Memory) cells in order to extract spatio-temporal information between frames. While the HOG-TOP (Histogram of Oriented Gradients from Three Orthogonal Planes) descriptor aims to extract dynamic textures from video sequences to characterize facial appearance changes. Finally, we combine both models with a Multimodal Compact Bilinear (MCB) algorithm to produce a robust descriptor vector. Classification was performed using the SVM (Support Vector Machine) classifier to predict the emotion class. The experimental part was carried out based on the INTERFACE05 dataset that the accuracy of facial expression recognition was increased almost 1% by the fusion method (98.44%) than the baseline approach (97.75%). To summarize, the proposed method obtain a higher accuracy and robust detection meaning.
C1 [Chouhayebi, Hajar; Mahraz, Mohamed Adnane; Riffi, Jamal; Tairi, Hamid] Sidi Mohamed Ben Abdellah Univ, LISAC, Sci Fac Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Chouhayebi, H (corresponding author), Sidi Mohamed Ben Abdellah Univ, LISAC, Sci Fac Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
EM hajar.chouhayebi@usmba.ac.ma; adnane_1@yahoo.fr; riffi.jamal@gmail.com;
   htairi@yahoo.fr
OI Chouhayebi, Hajar/0000-0001-7080-1645
CR Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   [Anonymous], 2005, Int. J. Inf. Technol.
   [Anonymous], 2014, P 16 INT C MULT INT
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Charikar M, 2002, LECT NOTES COMPUT SC, V2380, P693
   Chen GCF, 2016, POL DEVEL CONTEMP CH, P1, DOI 10.1007/978-3-319-30969-9
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen S., 2015, AVEC 2015-Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015, P49, DOI DOI 10.1145/2808196.2811638
   Chew SW, 2011, LECT NOTES COMPUT SC, V7088, P311, DOI 10.1007/978-3-642-25346-1_28
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Delbrouck J-B, 2017, MULTIMODAL COMPACT B, V2014, P2014
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao JX, 2021, FRONT NEUROROBOTICS, V15, DOI 10.3389/fnbot.2021.763100
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Gudi A, 2015, IEEE INT CONF AUTOMA
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang XH, 2011, LECT NOTES COMPUT SC, V6688, P569, DOI 10.1007/978-3-642-21227-7_53
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Huang Y. Y., 2017, EMNLP, DOI [DOI 10.18653/V1/D17-1191, 10.18653/v1/d17-1191]
   Kim J, 2018, INTERFACE FOCUS, V8, DOI 10.1098/rsfs.2018.0011
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Krizhevsky A, 2012, IMAGENET LARGE SCALE, V27
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Dang LT, 2014, IEEE INT FUZZY SYST, P1297, DOI 10.1109/FUZZ-IEEE.2014.6891864
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long F, 2012, NEUROCOMPUTING, V93, P126, DOI 10.1016/j.neucom.2012.04.017
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Mellouk W., 2020, Procedia Computer Science, V175, P689, DOI [DOI 10.1016/J.PROCS.2020.07.101, 10.1016/j.procs.2020.07.101]
   Miyoshi R, 2021, NEURAL COMPUT APPL, V33, P7381, DOI 10.1007/s00521-020-05557-4
   Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Picard R.W., 1997, Studies, V136, DOI [DOI 10.1007/BF01238028, 10.1007/ BF01238028]
   Priyasad D, 2020, LEARNING SALIENT FEA, P21, DOI [10.21437/avsp.2019-5, DOI 10.21437/AVSP.2019-5]
   Priyasad D, 2020, INT CONF ACOUST SPEE, P3227, DOI [10.1109/icassp40776.2020.9054441, 10.1109/ICASSP40776.2020.9054441]
   Ranganathan H, 2016, IEEE WINT CONF APPL
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Saste ST, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P701, DOI 10.1109/ICECA.2017.8203631
   Satiyan M., 2010, INT J ELECT ELECT SY, V3, P89
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Staudemeyer Ralf C., 2019, Understanding LSTM - A tutorial into Long Short-Term Memory Recurrent Neural Networks, P1
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Wang ZM, 2020, INT J MACH LEARN CYB, V11, P923, DOI 10.1007/s13042-019-01056-8
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Yan JW, 2018, NEUROCOMPUTING, V309, P27, DOI 10.1016/j.neucom.2018.03.068
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 60
TC 1
Z9 1
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32993
EP 33017
DI 10.1007/s11042-023-16779-8
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070523100001
DA 2024-07-18
ER

PT J
AU Gezimati, M
   Singh, G
AF Gezimati, M.
   Singh, Ghanshyam
TI Terahertz imaging technology for localization of cancer tumours: a
   technical review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical; Cancer; Detection; Diagnosis; Terahertz imaging and
   spectroscopy; Computer aided diagnosis (CAD)
AB Currently, cancer is a large contributing factor in the increased mortality rates and at present the predictions are estimating an increased trend. The conventional medical cancer imaging modalities, for example X-Ray and Computed Tomography use ionizing radiation which is not tissue friendly for repeated assessments. The Terahertz (THz) cancer imaging offers novel opportunities for non-ionizing, non-invasive and early cancer detection, or diagnosis as well as improved cancer patient treatment follow-ups. In this review, a broad overview is given on the potential of THz radiation-based imaging and sensing as a technique for detection of various cancers cells. The THz radiation dynamics and interaction mechanisms with biological systems as well as parameter extraction and modelling for the observed THz image contrast are studied. The experimental studies on THz imaging and sensing are investigated with the goal approach to investigate the ex vivo, in vitro, and in vivo observations. The use of advanced analytic algorithms, specifically deep learning, is proposed for improved detection, discrimination of complex tissue with overlapping dielectric properties and development of clinical decision support systems. Research gaps in the THz imaging studies are identified based on recent trends, latest strategies suggested and the roadmap for future research direction provided.
C1 [Gezimati, M.; Singh, Ghanshyam] Univ Johannesburg, Dept Elect & Elect Engn Sci, Ctr Smart Informat & Commun Syst, Auckland Pk,Kingsway Campus,POB 524, ZA-2006 Johannesburg, South Africa.
C3 University of Johannesburg
RP Singh, G (corresponding author), Univ Johannesburg, Dept Elect & Elect Engn Sci, Ctr Smart Informat & Commun Syst, Auckland Pk,Kingsway Campus,POB 524, ZA-2006 Johannesburg, South Africa.
EM ghanshyams@uj.ac.za
RI Singh, Ghanshyam/G-8353-2012
OI Singh, Ghanshyam/0000-0002-5159-3286; GEZIMATI,
   MAVIS/0000-0003-0585-2838
FU University of Johannesburg
FX No Statement Available
CR Alfaro-Gomez M, 2019, INT CONF INFRA MILLI, DOI 10.1109/irmmw-thz.2019.8873832
   Amaechi BT, 2009, J APPL PHYS, V105, DOI 10.1063/1.3116632
   Apriono C, 2021, AIP CONF PROC, V2344, DOI 10.1063/5.0047176
   Azab MY, 2021, IEEE SENS J, V21, P7748, DOI 10.1109/JSEN.2021.3051075
   Bagraev NT, 2020, P INT C INFRARED MIL, P837
   Bagraev NT, 2016, P INT C INFRARED MIL, P944
   Banerjee S, 2022, IEEE SENSOR LETT, V6, DOI 10.1109/LSENS.2022.3178918
   Bennett DB, 2011, IEEE SENS J, V11, P1253, DOI 10.1109/JSEN.2010.2088387
   Bharadwaj AN, 2023, 2023 P INT C REC TRE, P1
   Bin Ji Y, 2016, SCI REP-UK, V6, DOI 10.1038/srep36040
   Bin Ji Y, 2015, BIOMED OPT EXPRESS, V6, P1398, DOI 10.1364/BOE.6.001398
   Boumali S, 2019, P ADV SCI ENG TECHN, P1
   Boutaayamou M, 2020, P INT C INFRARED MIL, P65
   Bowman TC, 2015, IEEE T ANTENN PROPAG, V63, P2088, DOI 10.1109/TAP.2015.2406893
   Brun MA, 2010, PHYS MED BIOL, V55, P4615, DOI 10.1088/0031-9155/55/16/001
   Cao YQ, 2021, SPECTROCHIM ACTA A, V256, DOI 10.1016/j.saa.2021.119713
   Cassar Q., 2021, 2021 46th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz50926.2021.9567087
   Castro-Camus E, 2022, APPL PHYS B-LASERS O, V128, DOI 10.1007/s00340-021-07732-4
   Chakraborty D, 2021, INT CONF INFRA MILLI, DOI 10.1109/IRMMW-THz50926.2021.9567049
   Chan KY, 2018, MED DEVICES-EVID RES, V11, P275, DOI 10.2147/MDER.S168338
   Chen H, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.3.036017
   Chen H, 2013, CHINESE PHYS LETT, V30, DOI 10.1088/0256-307X/30/3/030702
   Cheon H, 2017, IEEE J SEL TOP QUANT, V23, DOI 10.1109/JSTQE.2017.2704905
   Cheon H, 2016, SCI REP-UK, V6, DOI 10.1038/srep37103
   Cristian CR, 2018, INT CONF EXPO ELECTR, P634, DOI 10.1109/ICEPE.2018.8559831
   D'Arco A, 2020, CONDENS MATTER, V5, DOI 10.3390/condmat5020025
   Danciu M, 2019, MATERIALS, V12, DOI 10.3390/ma12091519
   Doradla P, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.8.080501
   Doradla P, 2014, PROC SPIE, V8985, DOI 10.1117/12.2038650
   Duka M, 2015, IEEE NW RUSS YOUNG, P327, DOI 10.1109/EIConRusNW.2015.7102290
   Eadie LH, 2013, EXPERT SYST APPL, V40, P2043, DOI 10.1016/j.eswa.2012.10.019
   Fan S, 2015, P 40 INT C INFR MILL, P1
   Fan ST, 2017, J BIOPHOTONICS, V10, P1143, DOI 10.1002/jbio.201600171
   Faruk A, 2019, OPTIK, V192, DOI 10.1016/j.ijleo.2019.162976
   Fedorov VI, 2016, 2016 INTERNATIONAL CONFERENCE LASER OPTICS (LO)
   Formanek F, 2011, BIOMED OPT EXPRESS, V2, P58, DOI 10.1364/BOE.2.000058
   Gezimati M, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-023-04991-7
   Gezimati M, 2023, IEEE ACCESS, V11, P18590, DOI 10.1109/ACCESS.2023.3247196
   Gezimati M, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-022-04340-0
   Globus T, 2019, CANCER BIOMARK, V24, P405, DOI 10.3233/CBM-182120
   Gong AP, 2020, APPL SPECTROSC REV, V55, P418, DOI 10.1080/05704928.2019.1670202
   Gong Y, 2009, P 34 INT C INFR MILL, P1
   Goryachuk A, 2017, IEEE INT SYM MED MEA, P134, DOI 10.1109/MeMeA.2017.7985863
   Grootendorst MR, 2017, BIOMED OPT EXPRESS, V8, P2932, DOI 10.1364/BOE.8.002932
   Gusev SI, 2017, 2017 PROGRESS IN ELECTROMAGNETICS RESEARCH SYMPOSIUM - SPRING (PIERS), P3229, DOI 10.1109/PIERS.2017.8262313
   Habib A, 2021, PLASMONICS, V16, P1297, DOI 10.1007/s11468-021-01409-6
   Hakeem Safa Isam, 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/3/032025
   Hernandez-Cardoso GG, 2018, J INFRARED MILLIM TE, V39, P879, DOI 10.1007/s10762-018-0485-3
   Hernandez-Cardoso GG, 2017, SCI REP-UK, V7, DOI 10.1038/srep42124
   Hernandez-Cardoso GG, 2017, P INT C INFR MILL TE, P1
   Hlali A, 2021, IEEE SENS J, V21, P19930, DOI 10.1109/JSEN.2021.3100469
   Hlali A, 2021, IEEE SENS J, V21, P9844, DOI 10.1109/JSEN.2021.3060326
   Horita K, 2020, P INT C INFRARED MIL, P61
   Hou DB, 2014, PHYS MED BIOL, V59, P5423, DOI 10.1088/0031-9155/59/18/5423
   Hua YF, 2010, IEEE T MICROW THEORY, V58, P2064, DOI 10.1109/TMTT.2010.2050184
   Huang HC, 2017, OPT LASER ENG, V94, P76, DOI 10.1016/j.optlaseng.2017.03.005
   Huang SY, 2009, PHYS MED BIOL, V54, P149, DOI 10.1088/0031-9155/54/1/010
   HURT WD, 1985, IEEE T BIO-MED ENG, V32, P60, DOI 10.1109/TBME.1985.325629
   Ji YB, 2014, BIOMED OPT EXPRESS, V5, P4162, DOI 10.1364/BOE.5.004162
   Kamburoglu K, 2014, DENTOMAXILLOFAC RAD, V43, DOI 10.1259/dmfr.20130404
   Kasalynas I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040432
   Kashanian H.A., 2015, Majlesi J. Multimed. Process, V4, P1
   Kaurav P, 2021, IEEE MTTS INT MICRO, DOI 10.1109/IMaRC49196.2021.9714693
   Kazemi F, 2021, SUPERLATTICE MICROST, V153, DOI 10.1016/j.spmi.2021.106865
   Ke L, 2021, SPECTROCHIM ACTA A, V255, DOI 10.1016/j.saa.2021.119667
   Konnikova M., 2020, Proc Int Conf Infr Millimet Terahertz Waves, IRMMW-THz, P846
   Konnikova MR, 2021, BIOMED OPT EXPRESS, V12, P1020, DOI 10.1364/BOE.412715
   Kucheryavenko AS, 2021, BIOMED OPT EXPRESS, V12, P5272, DOI 10.1364/BOE.432758
   Li DX, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2021.3058163
   Lin SJ, 2022, TALANTA, V248, DOI 10.1016/j.talanta.2022.123628
   Lin SJ, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2020.3038308
   Lindley-Hatcher H, 2021, APPL PHYS LETT, V118, DOI 10.1063/5.0055259
   Liu HY, 2022, J INFRARED MILLIM TE, V43, P48, DOI 10.1007/s10762-021-00839-x
   Liu K, 2021, BIOMED OPT EXPRESS, V12, P1559, DOI 10.1364/BOE.418859
   Liu Y., 2016, Proc Int Conf Infr, Millimeter, Terahertz Waves, IRMMW-THz, P1
   Locatelli M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13566
   Lopes DS, 2019, OPTICS INFOBASE C PA, P29
   Lykina A., 2020, 2020 International Conference Laser Optics (ICLO), DOI 10.1109/ICLO48556.2020.9285903
   Meng K, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.7.077001
   Musina Guzel R., 2020, [Journal of Biomedical Photonics & Engineering, Journal of Biomedical Photonics & Engineering], V6, P20201
   Nikitkina AI, 2021, J BIOMED OPT, V26, DOI 10.1117/1.JBO.26.4.043005
   Oh SJ, 2014, BIOMED OPT EXPRESS, V5, P2837, DOI 10.1364/BOE.5.002837
   Park JY, 2011, J APPL PHYS, V109, DOI 10.1063/1.3551575
   Peng Y, 2020, BME FRONT, V2020, DOI 10.34133/2020/2547609
   Pickwell E, 2004, APPL PHYS LETT, V84, P2190, DOI 10.1063/1.1688448
   Poorgholam-Khanjari S, 2021, OPT COMMUN, V480, DOI 10.1016/j.optcom.2020.126482
   Rao L, 2020, UK EU CHINA MILLIMET, DOI 10.1109/ucmmt49983.2020.9296085
   Reid CB, 2010, PHYS MED BIOL, V55, P4825, DOI 10.1088/0031-9155/55/16/013
   Rong L, 2015, SCI REP-UK, V5, DOI 10.1038/srep08445
   Sadeghi A, 2023, TRANSL ONCOL, V27, DOI 10.1016/j.tranon.2022.101565
   Saha Abhirupa, 2021, Advances in Smart Communication Technology and Information Processing. OPTRONIX 2020. Lecture Notes in Networks and Systems (LNNS 165), P111, DOI 10.1007/978-981-15-9433-5_12
   Salim A, 2018, BIOSENS BIOELECTRON, V117, P398, DOI 10.1016/j.bios.2018.06.031
   Samanta D., 2022, Trends in terahertz biomedical applications, P285
   Samanta D, 2021, NANOMEDICINE-UK, V16, DOI 10.2217/nnm-2020-0386
   Seki T, 2020, C ELECT INSUL DIEL P, P539, DOI 10.1109/CEIDP49254.2020.9437559
   Semenova AV, 2017, INT CONF INFRA MILLI
   Serita K, 2020, 2020 INTERNATIONAL TOPICAL MEETING ON MICROWAVE PHOTONICS (MWP 2020), P108
   Shi J, 2018, OPT EXPRESS, V26, P6371, DOI 10.1364/OE.26.006371
   Shi W, 2021, J BIOPHOTONICS, V14, DOI 10.1002/jbio.202000237
   Sim YC, 2013, BIOMED OPT EXPRESS, V4, P1413, DOI 10.1364/BOE.4.001413
   Sim YC, 2009, CURR APPL PHYS, V9, P946, DOI 10.1016/j.cap.2008.09.008
   Singh AK, 2020, INT CONF INFRA MILLI, DOI 10.1109/IRMMW-THz46771.2020.9370608
   Smolyanskaya O, 2020, PROC INT C INFRARED, P354
   Son J.-H., 2013, Terahertz Biomed Healthcare Technol
   Son JH, 2019, J APPL PHYS, V125, DOI 10.1063/1.5080205
   Son JH, 2018, INT CONF INFRA MILLI
   Suen JY, 2009, STUD HEALTH TECHNOL, V142, P364, DOI 10.3233/978-1-58603-964-6-364
   Taylor W, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195665
   Taylor ZD, 2008, OPT LETT, V33, P1258, DOI 10.1364/OL.33.001258
   Taylor ZD, 2011, IEEE T THZ SCI TECHN, V1, P201, DOI 10.1109/TTHZ.2011.2159551
   Truong BCQ, 2015, IEEE T BIO-MED ENG, V62, P699, DOI 10.1109/TBME.2014.2364025
   Vafapour Z, 2021, IEEE SENS J, V21, P19307, DOI 10.1109/JSEN.2021.3087953
   Vafapour Z, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05623
   Vaks VL., 2016, Proc Int Conf Infr, Millimeter, Terahertz Waves, IRMMW-THz, V2016, P1
   Vohra Nagma, 2021, 2021 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting (APS/URSI), P585, DOI 10.1109/APS/URSI47566.2021.9703938
   Vohra Nagma, 2021, 2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT), P368, DOI 10.1109/CAMA49227.2021.9703666
   Wahaia F, 2016, J MOL STRUCT, V1107, P214, DOI 10.1016/j.molstruc.2015.11.048
   Wahaia F, 2015, J MOL STRUCT, V1079, P448, DOI 10.1016/j.molstruc.2014.09.024
   Wahaia F, 2011, J MOL STRUCT, V1006, P77, DOI 10.1016/j.molstruc.2011.05.049
   Wang F, 2016, P 2015 ASIA PACIFIC, V2, P1
   Wang H, 2019, P INT C INFR MILL TE, P1
   Wang JR, 2019, BIOMED OPT EXPRESS, V10, P3584, DOI 10.1364/BOE.10.003584
   Wang L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196465
   Wang Y, 2021, NEURAL COMPUT APPL, V33, P9637, DOI 10.1007/s00521-021-05728-x
   Weisenstein C, 2019, INT CONF INFRA MILLI, DOI 10.1109/irmmw-thz.2019.8873759
   Wilmink GJ, 2011, J INFRARED MILLIM TE, V32, P1074, DOI 10.1007/s10762-011-9794-5
   Wu LM, 2022, BIOMED OPT EXPRESS, V13, P93, DOI 10.1364/BOE.445597
   Wu LM, 2019, BIOMED OPT EXPRESS, V10, P3953, DOI 10.1364/BOE.10.003953
   Wu XH, 2023, SPECTROCHIM ACTA A, V285, DOI 10.1016/j.saa.2022.121933
   Yadav R, 2021, SUPERLATTICE MICROST, V154, DOI 10.1016/j.spmi.2021.106881
   Yamaguchi S, 2016, SCI REP-UK, V6, DOI 10.1038/srep30124
   Yan SH, 2016, INT CONF MANIP MANU, P327, DOI 10.1109/3M-NANO.2016.7824992
   Yan ZY, 2022, TRENDS BIOTECHNOL, V40, P816, DOI 10.1016/j.tibtech.2021.12.002
   Yang K, 2021, BIOSENS BIOELECTRON, V175, DOI 10.1016/j.bios.2020.112874
   Yang S., 2021, P INT C INFR MILL TE, P1
   Yeo WG, 2019, INFRARED PHYS TECHN, V97, P411, DOI 10.1016/j.infrared.2019.02.001
   Yin XX, 2022, IEEE SENS J, V22, P9215, DOI 10.1109/JSEN.2022.3161013
   Yu C, 2012, QUANT IMAG MED SURG, V2, P33, DOI 10.3978/j.issn.2223-4292.2012.01.04
   Yum SM, 2019, INT CONF INFRA MILLI, DOI 10.1109/irmmw-thz.2019.8873980
   Zhan XY, 2023, TALANTA, V259, DOI 10.1016/j.talanta.2023.124483
   Zhan XY, 2021, BIOSENS BIOELECTRON, V188, DOI 10.1016/j.bios.2021.113314
   Zhang J, 2020, AOPC 2020: Advanced Laser Technology and Application, V11562, P36
   Zhang J, 2021, BIOSENS BIOELECTRON, V185, DOI 10.1016/j.bios.2021.113241
   Zhang J, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103548
   Zhang P, 2020, CURR OPT PHOTONICS, V4, P31, DOI 10.3807/COPP.2020.4.1.031
   Zhang TM, 2020, J BIOMED OPT, V25, DOI 10.1117/1.JBO.25.12.123002
   Zhang YY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010071
   Zhang Y, 2021, J INFRARED MILLIM TE, V42, P802, DOI 10.1007/s10762-021-00805-7
NR 148
TC 0
Z9 0
U1 13
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33675
EP 33711
DI 10.1007/s11042-023-16596-z
EA SEP 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Abualigah, L
   Oliva, D
   Jia, HM
   Gul, F
   Khodadadi, N
   Hussien, AG
   Al Shinwan, M
   Ezugwu, AE
   Abuhaija, B
   Abu Zitar, R
AF Abualigah, Laith
   Oliva, Diego
   Jia, Heming
   Gul, Faiza
   Khodadadi, Nima
   Hussien, Abdelazim G.
   Al Shinwan, Mohammad
   Ezugwu, Absalom E.
   Abuhaija, Belal
   Abu Zitar, Raed
TI Improved prairie dog optimization algorithm by dwarf mongoose
   optimization algorithm for optimization problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prairie dog optimization algorithm; Dwarf mongoose optimization
   algorithm; Meta-heuristics; Benchmark functions; Optimization problems
AB Recently, optimization problems have been revised in many domains, and they need powerful search methods to address them. In this paper, a novel hybrid optimization algorithm is proposed to solve various benchmark functions, which is called IPDOA. The proposed method is based on enhancing the search process of the Prairie Dog Optimization Algorithm (PDOA) by using the primary updating mechanism of the Dwarf Mongoose Optimization Algorithm (DMOA). The main aim of the proposed IPDOA is to avoid the main weaknesses of the original methods; these weaknesses are poor convergence ability, the imbalance between the search process, and premature convergence. Experiments are conducted on 23 standard benchmark functions, and the results are compared with similar methods from the literature. The results are recorded in terms of the best, worst, and average fitness function, showing that the proposed method is more vital to deal with various problems than other methods.
C1 [Abualigah, Laith] Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Dept Comp Sci, Mafraq 25113, Jordan.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
   [Oliva, Diego] Univ Guadalajara, Depto Innovac Basada Informac & El Conocimiento, CUCEI, Guadalajara, Jal, Mexico.
   [Jia, Heming] Sanming Univ, Sch Informat Engn, Sanming 365004, Peoples R China.
   [Gul, Faiza] Air Univ, Dept Elect Engn Aerosp & Avion, Campus Kamra, Kamra, Pakistan.
   [Khodadadi, Nima] Florida Int Univ, Dept Civil & Environm Engn, Miami, FL 33199 USA.
   [Hussien, Abdelazim G.] Linkoping Univ, Dept Comp & Informat Sci, Linkoping, Sweden.
   [Hussien, Abdelazim G.] Fayoum Univ, Fac Sci, Faiyum, Egypt.
   [Al Shinwan, Mohammad] Appl Sci Private Univ, Fac Informat Technol, Amman 11931, Jordan.
   [Ezugwu, Absalom E.] Northwest Univ, Unit Data Sci & Comp, 11 Hoffman St, ZA-2520 Potchefstroom, South Africa.
   [Abuhaija, Belal] Wenzhou Kean Univ, Dept Comp Sci, Wenzhou 325015, Peoples R China.
   [Abu Zitar, Raed] Sorbonne Univ Abu Dhabi, Sorbonne Ctr Artificial Intelligence, Abu Dhabi 38044, U Arab Emirates.
C3 Al al-Bayt University; Al-Ahliyya Amman University; Lebanese American
   University; Middle East University; Universiti Sains Malaysia; Sunway
   University; Universidad de Guadalajara; Sanming University; Air
   University Islamabad; State University System of Florida; Florida
   International University; Linkoping University; Egyptian Knowledge Bank
   (EKB); Fayoum University; North West University - South Africa;
   Wenzhou-Kean University
RP Abualigah, L (corresponding author), Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Dept Comp Sci, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.; Abuhaija, B (corresponding author), Wenzhou Kean Univ, Dept Comp Sci, Wenzhou 325015, Peoples R China.
EM aligah.2020@gmail.com; diego.oliva@cucei.udg.mx; jiaheming@fjsmu.edu.cn;
   faiza.gul@aack.au.edu.pk; nkhod002@fiu.edu; abdelazim.hussien@liu.se;
   moshanwan@yahoo.com; ezugwua@ukzn.ac.za; babuhaij@kean.edu;
   raed.zitar@sorbonne.ae
RI Oliva, Diego/A-3271-2016; Gul, Faiza/AAF-6524-2019; Abualigah,
   Laith/ABC-9695-2020; Hussien, Abdelazim/AAC-5121-2019; Khodadadi,
   Nima/AAU-8139-2021; Ezugwu, Absalom El-Shamir/AIE-3466-2022
OI Oliva, Diego/0000-0001-8781-7993; Gul, Faiza/0000-0002-3344-3188;
   Abualigah, Laith/0000-0002-2203-4549; Hussien,
   Abdelazim/0000-0001-5394-0678; Khodadadi, Nima/0000-0002-8348-6530;
   Ezugwu, Absalom El-Shamir/0000-0002-3721-3400
NR 0
TC 5
Z9 5
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32613
EP 32653
DI 10.1007/s11042-023-16890-w
EA SEP 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300003
DA 2024-07-18
ER

PT J
AU Yousaf, K
   Nawaz, T
AF Yousaf, Kanwal
   Nawaz, Tabassam
TI An attention mechanism-based CNN-BiLSTM classification model for
   detection of inappropriate content in cartoon videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YouTube; Video classification; Attention mechanism; Bidirectional LSTM;
   CNN
ID INDECENT VIDEOS; PORNOGRAPHY; NETWORKS
AB This paper proposes a novel method that combines an ImageNet pretrained convolutional neural network (CNN) with attention-based bidirectional long short-term memory (BiLSTM) network for accurate detection of inappropriate content in animated cartoon videos. The EfficientNet-B7 architecture is used as a pretrained CNN model for extracting features from videos, whilst the attention-based BiLSTM is implemented to dynamically focus on different parts of video feature sequences that are most relevant for classification. The whole architecture is trained end-to-end with input being the video frames and performed multiclass classification by classifying videos into three different categories namely safe, violent, and sexually explicit videos. This model is validated on a cartoon video dataset retrieved from YouTube by performing a search through YouTube Data API. The experimental results demonstrated that our model performs relatively better than other models by achieving an accuracy of 95.30%. Furthermore, the performance comparison with state-of-the-art algorithms showed that the proposed attention mechanism-based CNN-BiLSTM model achieved competitive results.
C1 [Yousaf, Kanwal; Nawaz, Tabassam] Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
C3 University of Engineering & Technology Taxila
RP Yousaf, K (corresponding author), Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
EM kanwal.yousaf@uettaxila.edu.pk
RI Yousaf, Kanwal/AAB-6350-2019
OI Yousaf, Kanwal/0000-0003-2198-6932
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abu-El-Haija S, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1609.08675
   Aldahoul N, 2021, IEEE ACCESS, V9, P39910, DOI 10.1109/ACCESS.2021.3064392
   Alghowinem S, 2019, ADV INTELL SYST COMP, V868, P294, DOI 10.1007/978-3-030-01054-6_21
   Ali A, 2018, ADV INTELL SYST, V700, P225, DOI 10.1007/978-3-319-72550-5_22
   Alshamrani S, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P508, DOI 10.1145/3442442.3452314
   Alshamrani S, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3213, DOI 10.1145/3340531.3418511
   [Anonymous], 2006, The 3rd European Conference on Visual Media Production (CVMP 2006)-Part of the 2nd Multimedia Conference 2006, IET, DOI DOI 10.1049/CP:20061978
   Bermingham A, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, P231, DOI 10.1109/ASONAM.2009.31
   Brandom R., 2017, The Verge
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Craig D, 2017, MEDIA INT AUST, V163, P77, DOI 10.1177/1329878X17693700
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elias N, 2017, CYBERPSYCHOLOGY, V11, DOI 10.5817/CP2017-3-2
   Endeshaw T, 2008, IEEE APP IMG PAT, P13
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Hou CC, 2018, LECT NOTES COMPUT SC, V11256, P501, DOI 10.1007/978-3-030-03398-9_43
   Ishikawa A, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739202
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Jung S, 2014, IEEE T CONSUM ELECTR, V60, P696, DOI 10.1109/TCE.2014.7027345
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kaushal Rishabh, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P157, DOI 10.1109/PST.2016.7906950
   Kay W., 2017, ARXIV170506950
   Ketkar N., 2017, Deep learning with python: a hands-on introduction, P97, DOI [DOI 10.1007/978-1-4842-2766-47, 10.1007/978-1-4842-2766-4_7, DOI 10.1007/978-1-4842-2766-4_7, 10.1007/978-1-4842-2766-47]
   Kim M, 2008, PROC CVPR IEEE, P1787
   Kingma D. P., 2014, arXiv
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lee HE, 2020, FORENS SCI INT-DIGIT, V34, DOI 10.1016/j.fsidi.2020.301022
   Liu YZ, 2011, IEEE INT CONF TRUST, P1488, DOI 10.1109/TrustCom.2011.205
   Lopes APB, 2009, SIBGRAPI, P224, DOI 10.1109/SIBGRAPI.2009.32
   Lozano-Blasco R, 2021, TECHNOL SOC, V66, DOI 10.1016/j.techsoc.2021.101648
   Maheshwari S, 2017, The New York Times
   Mariconti Enrico, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359309
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ochoa VMT, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P967, DOI 10.1109/SITIS.2012.143
   Papadamou K., 2020, P INT AAAI C WEB SOC, V14, P522, DOI [https://doi.org/10.1609/icwsm.v14i1.7320, DOI 10.1609/ICWSM.V14I1.7320]
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Reddit, 2017, WHAT IS ELSAGATE
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2104, DOI 10.1145/3297280.3297487
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Soomro K., 2012, ARXIV, DOI DOI 10.48550/ARXIV.1212.0402
   Tahir R, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P464, DOI 10.1145/3341161.3342913
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang S, 2009, P 17 ACM INT C MULT, P1003, DOI [10.1145/1631272.1631490, DOI 10.1145/1631272.1631490]
   Ulges A., 2012, P 2012 ACM INT WORKS, P21, DOI [10.1145/2390214.2390222, DOI 10.1145/2390214.2390222]
   Verma JP., 2016, ARTIF INTELL APPL IJ, V5, P41, DOI [10.5121/ijscai.2016.5105, DOI 10.5121/IJSCAI.2016.5105]
   Vitorino P, 2018, J VIS COMMUN IMAGE R, V50, P303, DOI 10.1016/j.jvcir.2017.12.005
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Wilson H., 2020, Seattle J Technol Environ Innov Law, V10, P8
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yenala H, 2018, INT J DATA SCI ANAL, V6, P273, DOI 10.1007/s41060-017-0088-4
   You JY, 2020, IEEE IMAGE PROC, P1761, DOI 10.1109/ICIP40778.2020.9190996
   Yu TZ, 2018, PATTERN RECOGN LETT, V112, P226, DOI 10.1016/j.patrec.2018.07.034
NR 58
TC 1
Z9 1
U1 9
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31317
EP 31340
DI 10.1007/s11042-023-16727-6
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500004
DA 2024-07-18
ER

PT J
AU Al Ghamdi, MA
   Bhatti, MS
   Saeed, A
   Gillani, Z
   Almotiri, SH
AF Al Ghamdi, Mohammed A.
   Bhatti, Muhammad Shahid
   Saeed, Atif
   Gillani, Zeeshan
   Almotiri, Sultan H.
TI A fusion of BERT, machine learning and manual approach for fake news
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; BERT; Machine Learning; NLP; Tweets; Articles; Manual
   Checking
AB A large number of users around the globe have preferred to read news and the latest information from the Internet, especially social media, leaving behind the traditional approach of print media. On the one hand, the Internet is a constructive medium to spread the latest news and information briefly. On the other hand, malicious users are very active on the Internet and spread fake news, which becomes viral within a few minutes. The spread of fake news has become a serious threat as many users now rely on Internet news without verification. In this digital world, it is easy to spread any toxic information over the Internet, like hate speech, extremism, propaganda, and political agendas. It is a big challenge in today's digital world to mitigate the spread of fake news; hence, there is a need for an automatic computational tool that can assist in measuring the credibility of news. This study aims to deliver a solution where fake news from Twitter and website-based articles can be detected using the Natural Language Processing (NLP) technique, Bidirectional Encoder Representations from Transformers (BERT), other machine learning classification algorithms, and manual program-based approaches. A dataset with fake and real labels for the textual content is used. Different classification algorithms are evaluated to find a suitable algorithm for delivering a fake news detector. The evaluations are based on machine learning and a program-based approach. The textual content that the user provides, such as an article or tweet, can confirm the legitimacy of fake news. This website offers fake news detection for both website-based news articles and tweets from Twitter in English, Arabic, and Urdu.
C1 [Al Ghamdi, Mohammed A.; Almotiri, Sultan H.] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Bhatti, Muhammad Shahid; Saeed, Atif; Gillani, Zeeshan] COMSATS Univ Islamabad Lahore, Dept CS, Lahore 54600, Pakistan.
C3 Umm Al Qura University; COMSATS University Islamabad (CUI)
RP Bhatti, MS (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.; Bhatti, MS (corresponding author), COMSATS Univ Islamabad Lahore, Dept CS, Lahore 54600, Pakistan.
EM maeghamdi@uqu.edu.sa; msbhatti@cuilahore.edu.pk;
   asaeed@cuilahore.edu.pk; zeeshangillani@cuilahore.edu.pk;
   shmotiri@uqu.edu.sa
RI Al-Ghamdi, Mohammed. I./ISU-9198-2023; Al Ghamdi, Mohammed
   A./GPS-4826-2022
OI Al-Ghamdi, Mohammed. I./0000-0002-9794-554X; Al Ghamdi, Mohammed
   A./0000-0002-5993-5236; Saeed, Atif/0000-0002-7889-8944
CR Acharya A, 2019, Fake news detection using machine learning
   Ahmed S., 2022, Development of fake news model using machine learning through natural language processing
   Aldwairi M, 2018, PROCEDIA COMPUT SCI, V141, P215, DOI 10.1016/j.procs.2018.10.171
   Bharadwaj P., 2019, INT J NAT LANG COMPU, V8
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Byers K, 2021, Growth Badger
   Gurav S., 2019, Int Res J Eng Technol (IRJET), V6, P308
   Ibrishimova MD, 2020, ADV INTELL SYST, V1035, P223, DOI 10.1007/978-3-030-29035-1_22
   Islam MU., 2021, Int. J. Comput. Appl, V975, P8887
   Khanam Z., 2021, IOP Conference Series: Materials Science and Engineering, V1099, DOI 10.1088/1757-899X/1099/1/012040
   Khurana U, 2017, The linguistic features of fake news headlines and statements
   Menon AHS, 2020, BBC
   News Fake, 2021, M LIbraray
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Poddar K, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960044
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Silk J, 2020, DW
   Soni VD., 2018, Int J Innov Res Sci Eng Technol, V7, P6349
   Swapna Y, 2019, Fake News Detection using Naive Bayes Classifier
   Thota A, 2018, SMU Data Sci Rev, V1
   UNIVERSITY B., 2021, Fake News: Develop Your Fact-Checking Skills: What Kinds of Fake News Exist?
   Yazdi KM, 2020, INT J ELECT COMMUN E, V14, P38, DOI 10.5281/zenodo.3669287
   Zhang XY, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3465, DOI 10.1145/3442381.3450004
NR 23
TC 1
Z9 1
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30095
EP 30112
DI 10.1007/s11042-023-16669-z
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066067700002
DA 2024-07-18
ER

PT J
AU Mactina, JN
   Neduncheliyan, S
AF Mactina, Josephine Nijofi
   Neduncheliyan, S.
TI An towards efficient optimal recurrent neural network-based brian tumour
   classification using cat and rat swarm (CARS) optimisation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain Tumor; Meta-heuristic Optimisation; Recurrent Neural Network;
   Feature Selection; Classification
ID FRAMEWORK
AB A brain tumour is a lump that forms in the brain as abnormal cells multiply and spread there. The intricacy of brain tissues makes it difficult and time-consuming to detect and characterise the location of brain tumours in MRI scans. However, patients are being helped by early prediction of brain tumour discovery and are being protected from more dire outcomes. This research employs the ideal swarm Cat & Rat Recurrent Learning (SCARRL) model as a meta-heuristic-based deep learning strategy for determining if a brain tumour is malignant or intermediate in severity using Magnetic resonance imaging (MRI)scans. To promote the efficiency of the Long Short-Term Memory learning classifier, a novel hybrid method called Cat and Rat Swarm (CARS) Optimisation has been designed for optimal feature selection. Cuckoo Search and Support Vector Machine (CS-SVM), Intelligent Integrated Model (IIM), and Recurrent- Long Short-Term Memory (LSTM) are only a few of the known approaches used to compare and contrast with the proposed strategy SCARRL on the Brain Tumor MRI Dataset. Accurate recognition is achieved thanks to the improved False Rejection Rate, Accuracy, False Acceptance Rate, and Correct Detection Rate achieved by the proposed methodology.
C1 [Mactina, Josephine Nijofi; Neduncheliyan, S.] Bharath Inst Higher Educ & Res, Chennai 600126, India.
C3 Bharath Institute of Higher Education & Research
RP Mactina, JN (corresponding author), Bharath Inst Higher Educ & Res, Chennai 600126, India.
EM nijojosephine5@gmail.com; sneduncheliyan8@gmail.com
OI SUBBU, Dr.NEDUNCHELIYAN/0009-0002-0904-8695
CR Benyelles FZ, 2021, 2020 2 INT WORKSH HU
   Fasihi MS, 2021, 2021 IEEE INT MIDW S
   Futrega M, 2022, LECT NOTES COMPUT SC, V12963, P15, DOI 10.1007/978-3-031-09002-8_2
   Gaba GS, 2022, SUSTAIN CITIES SOC, V80, DOI 10.1016/j.scs.2022.103766
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Ho TP, 2022, APPL INFORM PROCESSI
   Huang ZG, 2020, IEEE ACCESS, V8, P89281, DOI 10.1109/ACCESS.2020.2993618
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Kanumuri C, 2022, SMART SUSTAIN APPROA, P125, DOI DOI 10.1002/9781119682554.CH6
   Kapila D, 2022, MATER TODAY-PROC, V51, P12, DOI 10.1016/j.matpr.2021.04.089
   Kibriya H, 2021, 2021 M AL JINN U INT
   LillyMaheepa P., 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P708, DOI 10.1109/ICCCA49541.2020.9250923
   Lv C, 2018, IEEE T IND INFORM, V14, P3436, DOI 10.1109/TII.2017.2777460
   Mahesh DB, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102971
   Majib MS, 2021, IEEE ACCESS, V9, P116942, DOI 10.1109/ACCESS.2021.3105874
   Maqsood S, 2022, MEDICINA-LITHUANIA, V58, DOI 10.3390/medicina58081090
   Musallam AS, 2022, IEEE ACCESS, V10, P2775, DOI 10.1109/ACCESS.2022.3140289
   Nag K, 2016, IEEE T CYBERNETICS, V46, P499, DOI 10.1109/TCYB.2015.2404806
   Nick M, 2022, BRAIN TUMOR MRI DATA
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Pavuluri L, 2021, INT C COMP VIS IM PR
   Rajeev SK, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103949
   Rehman A, 2021, MICROSC RES TECHNIQ, V84, P133, DOI 10.1002/jemt.23597
   Sabar NR, 2015, IEEE T CYBERNETICS, V45, P217, DOI 10.1109/TCYB.2014.2323936
   Sethy PK, 2021, MULTIMED TOOLS APPL, V80, P28745, DOI 10.1007/s11042-021-11098-2
   Webber J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060932
   Yousefzadeh A, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351562
   Zhang LP, 2022, IEEE SENS J, V22, P785, DOI 10.1109/JSEN.2021.3130951
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30897
EP 30918
DI 10.1007/s11042-023-16870-0
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600001
DA 2024-07-18
ER

PT J
AU Lu, CT
   Liu, YC
   Pan, YC
AF Lu, Ching-Ta
   Liu, Yu-Chun
   Pan, Ying-Chen
TI An intelligent playback control system adapted by body movements and
   facial expressions recognized by OpenPose and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep-learning; Emotion recognition;
   Human-computer interaction; Pose recognition
AB Users watch videos for a long time when they are learning or entertaining. They may inevitably be tired, doze off or leave temporarily. However, the videos continue to play. When the users want to watch the video again, they must return to find the appropriate restarting position, causing inconvenience. The ultimate need of this study is to implement an effective video playback control system to automatically pause video playback when a user leaves the seat or falls asleep, while the system continues to play videos when the user sits in front of the computer and is in good condition. The proposed system recognizes human body movements and the opening/closing of the eyes (OCE). First, the user's image is captured through a web camera. Then the OpenPose deep-learning neural network recognizes the human pose. The recognized results are used to determine whether the user leaves or lies on her/his stomach. Therefore, the video can be paused if the user falls asleep while sitting with his eyes closed. The novelty of this study is that the proposed playback control system automatically pauses the video when the user is not in good condition. Accordingly, the user is free from wasting time searching for a proper playback position when the user wants to continue watching the video. The experimental results show that the accuracy rates of body motion recognition can reach 99.5%, and the accuracy rate of eyes closed recognition can reach 99.58%. Consequently, the proposed system can effectively control video playback in practice.
C1 [Lu, Ching-Ta] Feng Chia Univ, Dept Commun Engn, Taichung 407102, Taiwan.
   [Lu, Ching-Ta] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung 40402, Taiwan.
   [Liu, Yu-Chun] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Pan, Ying-Chen] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei 106, Taiwan.
C3 China Medical University Taiwan; China Medical University Hospital -
   Taiwan; National Taiwan Normal University; National Taiwan Normal
   University
RP Lu, CT (corresponding author), Feng Chia Univ, Dept Commun Engn, Taichung 407102, Taiwan.; Lu, CT (corresponding author), China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung 40402, Taiwan.
EM Lucas1@ms26.hinet.net
FU National Science and Technology Council, Taiwan
FX This work was supported by the National Science and Technology Council,
   Taiwan, grant number NSTC 111-2410-H-035-059-MY3. Our gratitude goes to
   the reviewers for their valuable comments which have significantly
   improved the quality of this paper.
CR Anderson K, 2006, IEEE T SYST MAN CY B, V36, P96, DOI 10.1109/TSMCB.2005.854502
   Badave Harshada, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P635, DOI 10.1109/ICICCS51141.2021.9432108
   Blom PM, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100307
   Buono P, 2023, MULTIMED TOOLS APPL, V82, P12859, DOI 10.1007/s11042-022-14048-8
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Catania F, 2023, MULTIMED TOOLS APPL, V82, P12797, DOI 10.1007/s11042-022-14135-w
   Francese R, 2023, MULTIMED TOOLS APPL, V82, P12771, DOI 10.1007/s11042-022-14290-0
   Fu JM, 2019, MULTIMEDIA SYST, V25, P451, DOI 10.1007/s00530-017-0547-8
   Garau N, 2023, CapsulePose: A variational CapsNet for real-time end-to-end 3D human pose estimation, V523, P81, DOI [10.1016/j.neucom.2022.11.097, DOI 10.1016/J.NEUCOM.2022.11.097]
   Hsu JL, 2018, MULTIMEDIA SYST, V24, P195, DOI 10.1007/s00530-017-0542-0
   Ilves M, 2014, ENTERTAIN COMPUT, V5, P147, DOI 10.1016/j.entcom.2014.04.005
   Jain AK, 2012, IEEE MULTIMEDIA, V19, P20, DOI 10.1109/MMUL.2012.4
   Joseph A, 2020, VISUAL COMPUT, V36, P529, DOI 10.1007/s00371-019-01628-3
   Kumar RJR, 2021, VISUAL COMPUT, V37, P2315, DOI 10.1007/s00371-020-01988-1
   Kyrollos DG, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244220
   Lin TY, 2015, Arxiv, DOI [arXiv:1405.0312, DOI 10.48550/ARXIV.1405.0312]
   Lu CT, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100452
   Mazhar O, 2019, ROBOT CIM-INT MANUF, V60, P34, DOI 10.1016/j.rcim.2019.05.008
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Noroozi F, 2016, INT C PATT RECOG, P61, DOI 10.1109/ICPR.2016.7899608
   Osokin D, 2018, Arxiv, DOI arXiv:1811.12004
   Pons G, 2022, IEEE T CYBERNETICS, V52, P4764, DOI 10.1109/TCYB.2020.3036935
   Su S., 2023, IEEE Trans Ind Inform, DOI [10.1109/TII.2022.3233675, DOI 10.1109/TII.2022.3233675]
   The MathWorks Inc, 2023, Estimate body pose using deep learning
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu CH, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031896
NR 26
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31139
EP 31160
DI 10.1007/s11042-023-16880-y
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900002
DA 2024-07-18
ER

PT J
AU Reddy, SK
   Kathirvelu, K
AF Reddy, Siva Kumar
   Kathirvelu, Kalaivani
TI Prostate cancer detection using Henry firefly gas solubility
   optimization-based deep residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Firefly algorithm; Deep residual network; Dice coefficient; Prostate
   cancer; SegNet
ID DIAGNOSIS
AB Accurate and appropriate prostate cancer detection can significantly reduce the death rate. In this research, the Henry Firefly Gas Solubility Optimization (HFGSO)-based Deep Residual Network (DRN) is established for the autonomous detection of prostate cancer. The pre-processing is done by Cuckoo Search-Based (T2FCS) filter and Type 2 Fuzzy. Subsequently, segmentation is exhibited by devised multi-objective SegNet scheme. The multi-objective SegNet method is newly designed by updating the objective function of SegNet with loss function. The multi-objective SegNet is trained by HFGSO. Then, data augmentation is done with cropping and rotation, which improves the performance of detection. At last, cancer identification is executed with DRN, and it is trained by HFGSO. The developed optimized multi-objective SegNet with DRN technique also achieved increased performance for the detection of cancer, with a sensitivity, specificity, and accuracy 0.9367, 0.9130, and 0.9263.
C1 [Reddy, Siva Kumar; Kathirvelu, Kalaivani] Vels Inst Sci Technol & Adv Studies VISTAS, Dept Comp Sci & Engn, Chennai, Tamilnadu, India.
C3 Vels Institute of Science, Technology & Advanced Studies
RP Reddy, SK (corresponding author), Vels Inst Sci Technol & Adv Studies VISTAS, Dept Comp Sci & Engn, Chennai, Tamilnadu, India.
EM sivakumarreddybojja@gmail.com
CR Ahmed HU, 2017, LANCET, V389, P815, DOI 10.1016/S0140-6736(16)32401-1
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cao RM, 2019, IEEE T MED IMAGING, V38, P2496, DOI 10.1109/TMI.2019.2901928
   Chen ZC, 2019, ENERG CONVERS MANAGE, V198, DOI 10.1016/j.enconman.2019.111793
   De Visschere P, 2017, CLIN RADIOL, V72, P23, DOI 10.1016/j.crad.2016.09.011
   Duran-Lopez L, 2020, IEEE ACCESS, V8, P128613, DOI 10.1109/ACCESS.2020.3008868
   Fernandis JR, 2021, MULTIMED RES, V4, P105
   Garber K, 2010, J NATL CANCER I, V102, P1528, DOI 10.1093/jnci/djq425
   Gokulkumari G., 2020, Multimed Res, V3, DOI [10.46253/j.mr.v3i4.a4, DOI 10.46253/J.MR.V3I4.A4]
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hao Zhang, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11857), P611, DOI 10.1007/978-3-030-31654-9_52
   Hashim FA, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108320
   Hashim FA, 2019, FUTURE GENER COMP SY, V101, P646, DOI 10.1016/j.future.2019.07.015
   Iqbal S, 2021, IEEE ACCESS, V9, P27085, DOI 10.1109/ACCESS.2021.3057654
   Ismail BM, 2020, INT CONF ELECTRO INF, P228, DOI [10.1109/eit48999.2020.9208240, 10.1109/EIT48999.2020.9208240]
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kuhl CK, 2017, RADIOLOGY, V285, P493, DOI 10.1148/radiol.2017170129
   Kumar SV, 2019, J VIS COMMUN IMAGE R, V58, P619, DOI 10.1016/j.jvcir.2018.12.020
   Lee W, 2020, J RAMAN SPECTROSC, V51, P293, DOI 10.1002/jrs.5770
   prostatemrimagedatabase, PROST MRI DAT
   Renukalatha S., 2017, ICTACT Journal on Image and Video Processing, V7, P1505, DOI 10.21917/ijivp.2017.0215
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Singh D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3155765
   Stanzione A, 2016, EUR J RADIOL, V85, P2269, DOI 10.1016/j.ejrad.2016.10.009
   Thestrup KCD, 2016, ACTA RADIOL OPEN, V5, DOI 10.1177/2058460116663046
   de Vente C, 2021, IEEE T BIO-MED ENG, V68, P374, DOI 10.1109/TBME.2020.2993528
   Wang YY, 2019, APPL SOFT COMPUT, V77, P188, DOI 10.1016/j.asoc.2019.01.015
   Xin Yu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P594, DOI 10.1007/978-3-030-59719-1_58
   Xu HL, 2019, INT J COMPUT ASS RAD, V14, P1647, DOI 10.1007/s11548-019-01967-5
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55972-4
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29331
EP 29352
DI 10.1007/s11042-023-16655-5
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400013
DA 2024-07-18
ER

PT J
AU Wang, MJ
   Ren, S
   Du, YL
   Li, YN
   Ma, XK
AF Wang, Mingjia
   Ren, Shuai
   Du, Yunliang
   Li, Yanan
   Ma, Xueke
TI Research on electric energy information acquisition system based on
   embedded platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electric energy data collection; Data compression technology; EMC
ID CT IMAGES; ALGORITHM
AB In response to the problems of large communication data volume, few communication methods and high communication costs in current electric energy information collection systems, the paper designs an electric energy information collection system based on uC/OS embedded real-time operating system. The system collects the data in the electricity meter downlink according to the parameters set by the host computer. After the data is compressed by the data collection terminal, it is transmitted to the main station through remote communication technology, which is convenient for the staff to monitor and manage the energy data. In this paper, LZO lossless compression technology and run-length coding technology are combined to improve the data compression scheme and use the RSA encryption algorithm to encrypt and calculate the data and use the touch-type fully intelligent combination interference generator PRM61245B to conduct EMC testing on the power information collection terminal. The experimental results show that the power system data acquisition system proposed in this paper can effectively improve the data transmission rate while ensuring data security, and can operate stably under the influence of external interference factors. Through a series of experimental tests, the practicability and effectiveness of the system are verified.
C1 [Wang, Mingjia; Ren, Shuai; Du, Yunliang; Li, Yanan; Ma, Xueke] Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
C3 Qingdao University of Science & Technology
RP Wang, MJ (corresponding author), Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
EM mingjiawang@126.com
RI Li, Ya-nan/ABD-2034-2021
FU Shandong Provincial Natural Science Foundation, China [ZR2014FL026]
FX This work was supported by Shandong Provincial Natural Science
   Foundation, China (Grant No.ZR2014FL026).
CR Ce Z, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 1, P502, DOI 10.1109/ICEMI.2015.7494273
   Flores ERC, 2012, ELECT ROBOT AUTO MEC, P153, DOI 10.1109/CERMA.2012.32
   Du H., 2021, J Phys Conf Ser, V1852, P022053, DOI [10.1088/1742-6596/1852/2/022053, DOI 10.1088/1742-6596/1852/2/022053]
   Fang X, 2020, Research of power metering intelligent concentrator based on GPRS communication
   Fu J, 2019, IOP Conf Ser Mater Sci Eng, V677
   Güngör VC, 2011, IEEE T IND INFORM, V7, P529, DOI 10.1109/TII.2011.2166794
   He T, 2019, IEEE ACCESS, V7, P114955, DOI 10.1109/ACCESS.2019.2935551
   Momoh JA, 2009, 2009 IEEE PES POW SY, P1, DOI DOI 10.1109/PSCE.2009.4840074
   Purba GE., 2022, J Comput Inf Res, V2, P30
   Qi BZ, 2022, Electron Measure Technol, V22, P1
   Singh KK, 2023, MULTIMED TOOLS APPL, V82, P15983, DOI 10.1007/s11042-022-13960-3
   Song TF, 2019, J ENG-JOE, V2019, P9101, DOI 10.1049/joe.2018.9194
   Wan Y, 2017, Electromechanical Control Technology and Transportation, P355
   Wang B, 2020, Power consumption information acquisition system based on converged communication technology
   Wenpeng Su, 2014, Advanced Materials Research, V918, P246, DOI 10.4028/www.scientific.net/AMR.918.246
   Wu ZF, 2007, 2007 8 INT C EL MEAS, P2
   Yang FL, 2021, IOP Confer Ser: Earth Environ Sci, V827
   You SC, 2016, Research and application of electricity information collection system
   Yu DC, 2018, Application and research of electric energy Dataacquire system
   Zhang QY, 2020, Electr Power Equip Manag, V1, P133
NR 20
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29377
EP 29397
DI 10.1007/s11042-023-16716-9
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400004
DA 2024-07-18
ER

PT J
AU Wan, YC
   Shao, MW
   Cheng, YS
   Ding, WP
AF Wan, Yecong
   Shao, Mingwen
   Cheng, Yuanshuo
   Ding, Weiping
TI Fuzzy-based cross-image pixel contrastive learning for compact medical
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Transformer; Contrastive learning
ID MODEL
AB Existing medical image segmentation ignore the exploration of inter-class similarity and intra-class variability in pixel semantics, and aim to develop deeper and more complex networks for strength enhancement, leading to insufficient pixel relationship modeling high computational cost. To overcome the aforementioned limitation, we propose a novel fuzzy-based cross-image pixel contrastive learning regime to exploit discriminative relationships between pixel representations across images globally. CPC ensures that the lesion pixel is pulled closer to other lesion pixels while pushed far away from the background pixels in the representation space, thus driving the network to discriminate pixel semantics more robustly. Instead of computing or storing all samples, we devise a fuzzy filtering strategy that selects Top-K samples based on fuzzy membership. Furthermore, considering the speed requirement of medical image segmentation, we propose a compact but efficient network for rapid and precise segmentation, which can model both local and long-range dependencies by microscopically fusing Transformer and convolution. Benefitted from our efficient design of the hybrid module, the proposed network enjoys the properties of being compact, lightweight, and powerful. We term our efficient hybrid network with cross-image pixel contrastive learning as CPCNet. Extensive qualitative and quantitative experiments on various image segmentation tasks demonstrate that our CPCNet surpasses the state-of-the-art approaches.
C1 [Wan, Yecong; Shao, Mingwen; Cheng, Yuanshuo] China Univ Petr, Coll Comp Sci & Technol, West Changjiang Rd, Qingdao 266580, Shandong, Peoples R China.
   [Ding, Weiping] Nantong Univ, Sch Informat Sci & Technol, Qiangyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
C3 China University of Petroleum; Nantong University
RP Shao, MW (corresponding author), China Univ Petr, Coll Comp Sci & Technol, West Changjiang Rd, Qingdao 266580, Shandong, Peoples R China.
EM yecongwan@gmail.com; smw278@126.com; cys1294414023@gmail.com;
   ding.wp@ntu.edu.cn
FU National Key Research and development Program of China [2021YFA1000102];
   National Natural Science Foundation of China [62376285, 62272375,
   61673396]; Natural Science Foundation of Shandong Province, China
   [ZR2022MF260]
FX This work was supported by National Key Research and development Program
   of China (2021YFA1000102), and in part by the grants from the National
   Natural Science Foundation of China (Nos. 62376285, 62272375, 61673396),
   Natural Science Foundation of Shandong Province, China (No.ZR2022MF260).
CR Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Aminian M, 2022, MULTIMED TOOLS APPL, V81, P17793, DOI 10.1007/s11042-022-12403-3
   [Anonymous], 2017, 2017 INT S BIOM IM I
   Arora T, 2019, MULTIMED TOOLS APPL, V78, P9383, DOI 10.1007/s11042-018-6550-z
   Asadi-Aghbolaghi M, 2020, ARXIV
   Bachman P, 2019, ADV NEUR IN, V32
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bucher M, 2016, LECT NOTES COMPUT SC, V9915, P524, DOI 10.1007/978-3-319-49409-8_45
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Chaitanya K., 2020, Advances in Neural Information Processing Systems, V33, P12546, DOI DOI 10.48550/ARXIV.2006.10511
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Codella Noel, 2019, arXiv
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Gidaris S., 2018, P 6 INT C LEARNING R
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hendrycks D., 2016, ARXIV
   Hjelm R. D., 2018, ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C-H, 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kalantidis Yannis, 2020, P INT C NEUR INF PRO, P21798
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Liu J, 2020, MULTIMED TOOLS APPL, V79, P11487, DOI 10.1007/s11042-019-08468-2
   Liu Y, 2022, IEEE T MED IMAGING
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lv TL, 2019, MULTIMED TOOLS APPL, V78, P17051, DOI 10.1007/s11042-018-7087-x
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Robinson J., 2020, arXiv
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sáez A, 2014, IEEE T MED IMAGING, V33, P1137, DOI 10.1109/TMI.2014.2305769
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Srinivasu PN, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P97, DOI 10.1016/B978-0-12-819061-6.00004-5
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Van den Oord A, 1807, REPRESENTATION LEARN
   Vaswani A, 2017, ADV NEUR IN, V30
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7283, DOI 10.1109/ICCV48922.2021.00721
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wang XL, 2021, PROC CVPR IEEE, P3023, DOI 10.1109/CVPR46437.2021.00304
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Xie ZD, 2021, PROC CVPR IEEE, P16679, DOI 10.1109/CVPR46437.2021.01641
   Yang ZY, 2023, PROC CVPR IEEE, P11525, DOI [10.1109/cvpr52729.2023.01109, 10.1109/CVPR52729.2023.01109]
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang K, 2022, ARXIV
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou M., 2022, arXiv
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 69
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30377
EP 30397
DI 10.1007/s11042-023-16611-3
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000009
DA 2024-07-18
ER

PT J
AU Chandra, TB
   Singh, BK
AF Chandra, Tej Bahadur
   Singh, Bikesh Kumar
TI Multicriteria decision support system for triage and ethical allocation
   of scarce resources to COVID-19 patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prioritization; Scarce resources; COVID-19; Multicriteria; Decision
   Support System; Ethics
ID STRATEGIES; SERVICES; DEMAND; IMPACT; LIFE
AB Mitigating the rapid surge of Coronavirus disease (COVID-19) is one of the challenging tasks for the healthcare industry. While offering adequate healthcare services to the best of their ability, scarce medical resources like medicines, ICU beds, ventilators, test kits, personal protective equipment (PPE), domain experts, etc., forks an additional ethics dispute. To help with difficult triage decisions, developing appropriate triage protocols and rationing resources is of vital importance. In this paper, we proposed a multicriteria decision support system (MDSS) that performs weighted aggregation of different associated symptoms, clinical and radiological findings. The model assists physicians to priorities patients based on disease severity. In this study, 20 commonly used symptomatological, clinical and radiological variables were considered in addition to computer-aided diagnosis (CAD) system's decision. Subsequently, the robustness of the proposed method is evaluated using a private dataset and compared with the results of subjective evaluation by domain experts. The obtained experimental results with positive correlation coefficient r=0.9554 (between MDSS rank and ground-truth rank) and r=0.8622 (between MDSS rank and computer-aided diagnosis (CAD) based rank) at 95% confidence interval confirm the strong agreement between proposed method and domain expert. The proposed system could be useful in low resource settings, specifically in pandemic situations and could also be updated to prioritize resources in completely new scenarios.
C1 [Chandra, Tej Bahadur] Bennett Univ, Sch Comp Sci Engn & Techol, Greator Noida, Uttar Pradesh, India.
   [Singh, Bikesh Kumar] Natl Inst Technol Raipur, Dept Biomed Engn, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Chandra, TB (corresponding author), Bennett Univ, Sch Comp Sci Engn & Techol, Greator Noida, Uttar Pradesh, India.
EM tejbahadur1990@gmail.com; bsingh.bme@nitrr.ac.in
OI Chandra, Tej Bahadur/0000-0002-3499-3296; Singh, Bikesh
   Kumar/0000-0002-5052-9768
CR Afroze S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15254-8
   Afzal HMR, 2020, IEEE ACCESS, V8, P180681, DOI 10.1109/ACCESS.2020.3028106
   Ahirwal Mitul Kumar, 2021, Evolution in Computational Intelligence. Frontiers in Intelligent Computing: Theory and Applications (FICTA 2020). Advances in Intelligent Systems and Computing (AISC 1176), P281, DOI 10.1007/978-981-15-5788-0_27
   Ahmad N, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107642
   Akoglu H, 2018, TURK J EMERG MED, V18, P91, DOI 10.1016/j.tjem.2018.08.001
   Albahri AS, 2020, INT J INF TECH DECIS, V19, P1247, DOI 10.1142/S0219622020500285
   Albahri OS, 2022, J ADV RES, V37, P147, DOI 10.1016/j.jare.2021.08.009
   Carli R, 2020, ANNU REV CONTROL, V50, P373, DOI 10.1016/j.arcontrol.2020.09.005
   Chandra TB, 2022, MED BIOL ENG COMPUT, V60, P2549, DOI 10.1007/s11517-022-02611-2
   Chandra TB, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113514
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Chatterjee Kaustuv, 2020, Med J Armed Forces India, V76, P147, DOI 10.1016/j.mjafi.2020.03.022
   Chen T, 2020, BMJ-BRIT MED J, V368, DOI [10.1136/bmj.m1091, 10.1136/bmj.m1295]
   Christian MD, 2014, CHEST, V146, pE61S, DOI 10.1378/chest.14-0736
   Clemente-Suárez VJ, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105208
   Cook T, 2021, J MED ETHICS, V47, P456, DOI 10.1136/medethics-2020-106771
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Nardo P, 2020, INT J INFECT DIS, V98, P494, DOI 10.1016/j.ijid.2020.06.082
   Department of Health, Swine flu clinical package for use when there are exceptional demands on healthcare services
   Department of Health, Pandemic Flu: Management of Demand and Capacity in healthcare organizations
   Egede LE, 2020, NEW ENGL J MED, V383, DOI 10.1056/NEJMp2023616
   Emanuel EJ, 2020, NEW ENGL J MED, V382, P2049, DOI 10.1056/NEJMsb2005114
   Ercole A, 2009, ANAESTHESIA, V64, P937, DOI 10.1111/j.1365-2044.2009.06070.x
   Fallucchi F, 2021, J MED ETHICS, V47, P3, DOI 10.1136/medethics-2020-106524
   Frej EA, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030659
   Godlee F, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1324
   Gómez W, 2012, IEEE T MED IMAGING, V31, P1889, DOI 10.1109/TMI.2012.2206398
   Gupta M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107039
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hossain MR, 2023, NEURAL COMPUT APPL, V35, P13503, DOI 10.1007/s00521-023-08442-y
   Huh K, 2020, INFECT CHEMOTHER, V52, P105, DOI 10.3947/ic.2020.52.1.105
   Jecker NS, 2021, J MED ETHICS, V47, P308, DOI 10.1136/medethics-2020-107036
   Jöbges S, 2020, BIOETHICS, V34, P948, DOI 10.1111/bioe.12805
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Krishnakumar B, 2020, J MICROBIOL IMMUNOL, V53, P389, DOI 10.1016/j.jmii.2020.03.024
   Kwee TC, 2020, RADIOGRAPHICS, V40, P1848, DOI 10.1148/rg.2020200159
   Menon DK, 2005, ANAESTHESIA, V60, P952, DOI 10.1111/j.1365-2044.2005.04372.x
   Namendys-Silva SA, 2020, LANCET RESP MED, V8, pE18, DOI 10.1016/S2213-2600(20)30110-7
   Ortiz-Barrios Miguel, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054591
   Pereira MA, 2022, EXPERT SYST APPL, V210, DOI 10.1016/j.eswa.2022.118362
   Rahimi I, 2023, NEURAL COMPUT APPL, V35, P23671, DOI 10.1007/s00521-020-05626-8
   Raj R, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103957
   Rajagopalan S, Assessing Healthcare Capacity in India
   Ramakrishna R, 2020, J NEURO-ONCOL, V147, P525, DOI 10.1007/s11060-020-03488-7
   Rana H., 2023, Decis. Mak. Appl. Manag. Eng., V6, P603
   Rawlings A, 2021, SURG ENDOSC, V35, P2217, DOI 10.1007/s00464-020-07629-x
   Santosh KC, 2018, IEEE T MED IMAGING, V37, P1168, DOI 10.1109/TMI.2017.2775636
   Savulescu J, 2020, BRIT J ANAESTH, V125, P253, DOI 10.1016/j.bja.2020.05.028
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Shang WF, 2020, J MED VIROL, V92, P2188, DOI 10.1002/jmv.26031
   Solnica A, 2020, J MED ETHICS, V46, P444, DOI 10.1136/medethics-2020-106242
   Spiegelhalter D, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m3259
   Srinivasan GN, 2008, Proceedings of World Academy of Science, Engineering and Technology, V36, P1264
   Sun LJ, 2020, J MED VIROL, V92, P2055, DOI 10.1002/jmv.25966
   Tanne JH, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m1090
   Tolchin B, 2021, J MED ETHICS, V47, P200, DOI 10.1136/medethics-2020-106457
   Topf MC, 2020, HEAD NECK-J SCI SPEC, V42, P1159, DOI 10.1002/hed.26184
   Valiani S, 2020, CAN MED ASSOC J, V192, pE1067, DOI 10.1503/cmaj.200756
   Wang M, 2020, AGING-US, V12, P7652, DOI 10.18632/aging.103170
   WHO, 2020, Ethics and COVID-19: resource allocation and priority-setting
   Zeneli A, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-043239
   Zhang XZ, 2006, MED DECIS MAKING, V26, P617, DOI 10.1177/0272989X06295359
NR 63
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27463
EP 27480
DI 10.1007/s11042-023-16617-x
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300004
DA 2024-07-18
ER

PT J
AU Chatterjee, R
   Chatterjee, A
AF Chatterjee, Rajdeep
   Chatterjee, Ankita
TI Pose4Gun: A pose-based machine learning approach to detect small
   firearms from visual media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Metric learning; Image classification; Firearms detection; Pose
   estimation
ID PARTICLE SWARM OPTIMIZATION
AB Violence due to firearms is a menace and is growing across the globe. Mostly small firearms such as pistols and revolvers are used in close proximity for violence in public places. Our moral duty is to contribute to solving this problem with our expertise as it is impossible to keep 24 x 7 eyes on everyone in the street and corners. An automatic lightweight artificial intelligence solution to detect such small firearms is a welcoming step towards a more secure society. Here, we have proposed a hand pose pattern analysis to identify whether a person is holding a pistol or revolver. Furthermore, different data prepossessing, machine learning and deep learning techniques have been implemented to classify guns and no-gun from visual media. Finally, we have introduced a metric learning approach instead of classification along with our novel Fuzzy Discernible Feature Selection (FDFS) technique to provide faster and more accurate discrimination between gun and non-gun instances from images and videos. The result from Deep Neural Network + FDFS has achieved 93% test accuracy and outperforms the other used machine learning and deep learning alternatives.
C1 [Chatterjee, Rajdeep] Kalinga Inst Ind Technol Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
   [Chatterjee, Rajdeep; Chatterjee, Ankita] Amygadala AI, Bhubaneswar, Odisha, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Chatterjee, R (corresponding author), Kalinga Inst Ind Technol Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.; Chatterjee, R (corresponding author), Amygadala AI, Bhubaneswar, Odisha, India.
EM cse.rajdeep@gmail.com; ankita.datta24@gmail.com
OI Chatterjee, Rajdeep/0000-0003-0125-4830
CR amnesty, 2018, GUN VIOL KEY FACTS
   [Anonymous], 2022, C PASSES 1 GUN CONTR
   [Anonymous], 2002, J. Telecommun. Inf. Technol, DOI DOI 10.26636/JTIT.2002.140
   [Anonymous], 2022, SIDHU MOOSE WALA WHA
   Asai M, 2006, ECONOMET REV, V25, P145, DOI 10.1080/07474930600713564
   Babatunde O.H., 2014, A genetic algorithm-based feature selection
   Bach Duy Khuat, 2021, ICSCA 2021: 2021 10th International Conference on Software and Computer Applications, P162, DOI 10.1145/3457784.3457810
   Chandra S, 2022, IEEE ACCESS, V10, P13715, DOI [10.1109/access.2022.3146334, 10.1109/ACCESS.2022.3146334]
   Chatterjee R, 2011, ROUGH SET ITS VARIAN, DOI [10.13140/2.1.1354.9447, DOI 10.13140/2.1.1354.9447]
   Chatterjee R., 2021, FUZZY DISCERNIBILITY, DOI [10.1101/2021.03.24.436722, DOI 10.1101/2021.03.24.436722]
   Chatterjee R, 2023, MULTIMEDIA SYST, V29, P2899, DOI 10.1007/s00530-021-00881-8
   Chatterjee R, 2019, FUTURE GENER COMP SY, V98, P419, DOI 10.1016/j.future.2019.01.048
   Chatterjee R, 2017, C HUM SYST INTERACT, P131, DOI 10.1109/HSI.2017.8005014
   Chatterjee R, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2703, DOI 10.1109/TENCON.2016.7848530
   Egiazarov Alexander, 2019, 2019 European Intelligence and Security Informatics Conference (EISIC). Proceedings, P70, DOI 10.1109/EISIC49498.2019.9108871
   ft, 2022, US PASS GUN CONTR BI
   Harshvardhan GM, 2022, IEEE ACCESS, V10, P30870, DOI 10.1109/ACCESS.2022.3159700
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   imfdb, 2008, INT MOV FIR DAT
   Jain P, 2021, 2021 IEEE 4 INT C CO, P1, DOI [10.1109/GUCON50781.2021.9573551, DOI 10.1109/GUCON50781.2021.9573551]
   Jensen Richard., 2008, COMPUTATIONAL INTELL, DOI 10.1002/9780470377888
   Jiang PY, 2022, PROCEDIA COMPUT SCI, V199, P1066, DOI 10.1016/j.procs.2022.01.135
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   keras, 2019, EFF
   Komorowski J., 1999, Rough Fuzzy Hybridization: A New Trend in Decision Making, P3
   Kruegle H., 2011, CCTV Surveillance: Video practices and technology
   Kumar Naveen, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P88, DOI 10.1109/PDGC50313.2020.9315851
   Lamas A, 2022, NEUROCOMPUTING, V489, P488, DOI 10.1016/j.neucom.2021.12.059
   Liu YN, 2011, J BIONIC ENG, V8, P191, DOI 10.1016/S1672-6529(11)60020-6
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, DOI 10.48550/ARXIV.1906.08172]
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Martin-Bautista M. J., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1314, DOI 10.1109/CEC.1999.782599
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Olmos R, 2018, NEUROCOMPUTING, V275, P66, DOI 10.1016/j.neucom.2017.05.012
   Papa JP, 2011, INT CONF ACOUST SPEE, P2052
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   pewresearch, 2022, WHAT DATA SAYS GUN D
   Rashedi E, 2010, NAT COMPUT, V9, P727, DOI 10.1007/s11047-009-9175-3
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruiz-Santaquiteria J, 2021, IEEE ACCESS, V9, P123815, DOI 10.1109/ACCESS.2021.3110335
   Sastry K., 2005, Genet. Algorithms, P97
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Taradeh M, 2019, INFORM SCIENCES, V497, P219, DOI 10.1016/j.ins.2019.05.038
   Targ S., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.08029
   Thangavel K., 2012, 2012 International Conference on Biomedical Engineering (ICoBE), P10, DOI 10.1109/ICoBE.2012.6178946
   Trottier D, 2014, INFORM COMMUN SOC, V17, P609, DOI 10.1080/1369118X.2013.808359
   Velasco-Mata A, 2021, NEURAL COMPUT APPL, V33, P17273, DOI 10.1007/s00521-021-06317-8
   washingtonpost, 2022, THERE HAVE BEEN 250
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Zhang F, 2020, Arxiv, DOI arXiv:2006.10214
NR 55
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 5
PY 2023
AR s11042-023-16441-3
DI 10.1007/s11042-023-16441-3
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q7BA0
UT WOS:001059026300001
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Sun, LB
   Qin, WH
   Tian, F
AF Zhu, Hangyu
   Sun, Libo
   Qin, Wenhu
   Tian, Feng
TI AG-YOLO: Attention-guided network for real-time object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Multi-scale; Object detection; Feature fusion;
   Global context; Real-time
ID NEURAL-NETWORK
AB Existing neural network models directly add attention mechanisms to the network as a plug-and-play component to capture long-range dependencies and reconstruct feature maps. However, most methods do not fully tap the potential of attention in dealing with multi-scale problems. In this paper, an attention-guided YOLOv4 network (AG-YOLO) is proposed to address the multi-scale issue in object detection. We propose and apply multi-scale feature extraction to later stages of the backbone, which can not only enrich the feature hierarchy with low computational overhead, but also model the intra-scale and inter-scale correlation simultaneously to avoid missing key information. To reduce the redundant use of information flow, we propose a lightweight attention-guided feature pyramid network, which provides an efficient multi-level aggregation strategy based on multi-scale channel attention. In addition, a global context pathway is designed to reduce the dilution of high-level semantic information caused by information transmission. Compared with the baseline, AG-YOLO increased the mAP_0.5 by 1.67%, while the number of parameters and GFLOPs merely increased by 0.33M and 0.18, respectively. Meanwhile, the detection accuracy of small object categories has been improved.
C1 [Zhu, Hangyu; Sun, Libo; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing, Peoples R China.
   [Tian, Feng] Duke Kunshan Univ, Div Nat & Appl Sci, Suzhou, Peoples R China.
C3 Southeast University - China; Duke Kunshan University
RP Sun, LB (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing, Peoples R China.
EM hangyuz@seu.edu.cn; sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn;
   feng.tian978@dukekunshan.edu.cn
FU This work was supported by National key research and development program
   under Grant 2020YFB160070301, the Key R amp;amp;D Program of Jiangsu
   Province under Grant BE2019311 and Jiangsu modern agricultural industry
   key technology innovation project under G [BE2019311]; National key
   research and development program [CX(20)2013]; Key R amp;amp;D Program
   of Jiangsu Province; Jiangsu modern agricultural industry key technology
   innovation project;  [2020YFB160070301]
FX This work was supported by National key research and development program
   under Grant 2020YFB160070301, the Key R &D Program of Jiangsu Province
   under Grant BE2019311 and Jiangsu modern agricultural industry key
   technology innovation project under Grant CX(20)2013.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao Y, 2019, IEEE ICC
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Dean J., 2015, NIPS DEEP LEARNING R
   Everingham M., 2012, PATTERN ANAL STAT MO, V2007, P1, DOI DOI 10.1007/S11263-014-0733-5
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huyan L, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040683
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Li AL, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10040469
   Li C., 2022, ARXIV
   Li Y, 2022, APPL INTELL, V52, P9861, DOI 10.1007/s10489-021-02912-3
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2022, INT J INTELL SYST
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239
   Ma Ningning, 2018, P EUR C COMP VIS ECC, DOI [10.1007/978-3-030-01264-9_8, DOI 10.1007/978-3-030-01264-9_8]
   Mao L, 2021, NEURAL PROCESS LETT, V53, P3545, DOI 10.1007/s11063-021-10560-4
   Ou ZH, 2023, IEEE INTERNET THINGS, V10, P4226, DOI 10.1109/JIOT.2022.3215469
   Park J., 2018, ARXIV
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M., 2019, arXiv
   Wang B, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2020.3018831, 10.1109/TIM.2021.3069844]
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang KF, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117682
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZM, 2021, IEEE T INTELL TRANSP, V22, P6561, DOI 10.1109/TITS.2020.2995546
   Wen GQ, 2023, APPL INTELL, V53, P1586, DOI 10.1007/s10489-022-03549-6
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Yang Y, 2022, IEEE T GEOSCI ELECT
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zeng NY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3153997
   Zhang MH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224706
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou KX, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030755
   Zhou SR, 2021, MULTIMED TOOLS APPL, V80, P11539, DOI 10.1007/s11042-020-10191-2
   Zhu XZ, 2019, IEEE I CONF COMP VIS, P6687, DOI 10.1109/ICCV.2019.00679
NR 66
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28197
EP 28213
DI 10.1007/s11042-023-16568-3
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600007
DA 2024-07-18
ER

PT J
AU Wei, X
   Qin, XB
   Zhao, C
   Qiao, XY
   Lu, Y
AF Wei, Xing
   Qin, Xiongbo
   Zhao, Chong
   Qiao, Xuanyuan
   Lu, Yang
TI Unsupervised domain adaptation for object detection through mixed-domain
   and co-training learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Object detection; Intermediate domain; Mixed domain;
   Co-training
AB As the data distribution difference between the target domain (test sample set) and the source domain (training sample set) increases, it may lead to a sharp decline in the performance of the object detection network. However, it is expensive or impossible to obtain massive labeled data directly in the target domain.Therefore, domain adaptation techniques are needed to solve this problem. Unsupervised domain adaptation can learn the domain invariant features of the source domain and the target domain, thereby ensuring the performance of object detection. In this paper, we propose a novel multi-step training approach to accomplish the task of domain-adaptive object detection, using a hybrid domain training and co-training solution. 1) Hybrid domain training uses the source domain and the target domain to generate an intermediate domain, and then mixes the source domain and the intermediate domain into a hybrid domain to participate in training, making full use of domain features. 2) Co-training combines the predictions of the two branches with the same structure, but uses a synergistic loss function to force the two branches to observe features from different perspectives, labeling the target domain with higher quality pseudo-labels. We evaluate the proposed method and perform ablation experiments on datasets Citycape, Foggy Cityscape and SIM10K et al. The results show that our method can obtain more efficient results, and it is robust.
C1 [Wei, Xing; Qin, Xiongbo; Zhao, Chong; Lu, Yang] Hefei Univ Technol, Sch Comp Sci & Infomat Engn, Hefei, Anhui, Peoples R China.
   [Wei, Xing; Zhao, Chong] Hefei Univ Technol, Intelligent Mfg Inst HFUT, Hefei, Anhui, Peoples R China.
   [Qiao, Xuanyuan] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.
C3 Hefei University of Technology; Hefei University of Technology;
   University of Edinburgh
RP Zhao, C (corresponding author), Hefei Univ Technol, Sch Comp Sci & Infomat Engn, Hefei, Anhui, Peoples R China.; Zhao, C (corresponding author), Hefei Univ Technol, Intelligent Mfg Inst HFUT, Hefei, Anhui, Peoples R China.
EM weixing@hfut.edu.cn; 2021171147@mail.hfut.edu.cn; zhaochong@hfut.edu.cn;
   s2220245@ed.ac.uk; Iuyang@hfut.edu.cn
FU Joint Fund of Natural Science Foundation of Anhui Province
   [2008085UD08]; Anhui Provincial Key RD Program [201904d08020008,
   202004a05020004]; Intelligent Networking and New Energy Vehicle Special
   Project of Intelligent Manufacturing Institute of HFUT [IMIWL2019003,
   IMIDC2019002]
FX This work was supported by Joint Fund of Natural Science Foundation of
   Anhui Province in 2020 (2008085UD08), Anhui Provincial Key R&D Program
   (201904d08020008, 202004a05020004) and Intelligent Networking and New
   Energy Vehicle Special Project of Intelligent Manufacturing Institute of
   HFUT (IMIWL2019003, IMIDC2019002).
CR Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bousmalis K, 2016, ADV NEUR IN, V29
   Chen M., 2011, ADV NEURAL INFORM PR, P2456
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding N, 2022, PROC CVPR IEEE, P7202, DOI 10.1109/CVPR52688.2022.00707
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gatys LA, 2015, PREPRINT
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   GONG Y, 2023, APPL INTELL, P1
   Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI [10.1109/WACV45572.2020.9093358, 10.1109/wacv45572.2020.9093358]
   Huang JX, 2021, ADV NEUR IN, V34
   Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson-Roberson M, 2016, PREPRINT
   Li GF, 2022, IEEE T INTELL TRANSP, V23, P17729, DOI 10.1109/TITS.2022.3164407
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long M, 2016, PREPRINT
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   McClosky David, 2006, P MAIN C HUM LANG TE, P152, DOI DOI 10.3115/1220835.1220855
   Mirza M, 2014, PREPRINT
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Saito K, 2017, PR MACH LEARN RES, V70
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Su P., 2020, EUR C COMP VIS, P403
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang J, 2018, PREPRINT
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3500, DOI 10.1109/ICCV48922.2021.00350
   Yu F, 2019, PREPRINT
   Zheng Y., 2020, P IEEE CVF C COMP VI, P13766
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Q, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182929
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25213
EP 25229
DI 10.1007/s11042-023-16147-6
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001086308500001
DA 2024-07-18
ER

PT J
AU Zhong, F
   Bai, ZY
AF Zhong, Fan
   Bai, Zhengyao
TI PSR-GAT: Arbitrary point cloud super-resolution using graph attention
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Upsampling; Graph attention network; Super-resolution
ID IMAGE SUPERRESOLUTION
AB Point cloud super-resolution plays a central role in the mesh's quality in 3D reconstruction, while the feature extractor is vital for the learning-based point cloud upsampling pipelines. In this paper, we propose an arbitrary 3D point cloud upsampling network (PSR-GAT), which comprises the feature extraction module, GAT module, and upsampling module. For the input point cloud, the feature extraction module locates k nearest points of each point in 3D space by k-NN algorithm, then converts the local geometry information into high dimensional feature space through a multi-layer point-wise convolution. The GAT module converts the local geometry feature of each point into the semantic feature through a multi-layer graph attention network. The module dynamically adjusts the neighbor space of the point in each layer to increase the receptive field range and effectively fuses the semantic information of different levels through residual connection. This makes the local geometric in- formation extraction efficient. The upsampling module adds the number of points and maps them from feature space to 3D space. Extensive experimental results show that PSR-GAT exhibits a better performance than the existing state-of-the-art approaches.
C1 [Zhong, Fan; Bai, Zhengyao] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Yunnan, Peoples R China.
C3 Yunnan University
RP Bai, ZY (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Yunnan, Peoples R China.
EM zffhost@mail.ynu.edu.cn; baizhy@ynu.edu.cn
OI Bai, Zhengyao/0000-0001-5350-629X
FU Yunnan Major Scientific and Technological Special Project
   [202002AD080001]
FX This work was supported by the Yunnan Major Scientific and Technological
   Special Project under Grant 202002AD080001.
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Boltz S, 2010, IEEE IMAGE PROC, P4597, DOI 10.1109/ICIP.2010.5651708
   Butt MA, 1998, IEEE T IMAGE PROCESS, V7, P1477, DOI 10.1109/83.718487
   Chen TY, 2023, IEEE T INTELL VEHICL, V8, P2875, DOI 10.1109/TIV.2022.3162672
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong YH, 2021, PR MACH LEARN RES, V139
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guennebaud G., 2004, Proceedings of Eurographics Symposium on Point-Based Graphics 2004, P41
   Guo F, 2022, MULTIMED TOOLS APPL, V81, P6069, DOI 10.1007/s11042-021-11825-9
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Han B, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104371
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang H., 2013, ACM Trans. Graph., V32, P1
   Kingma D. P., 2014, arXiv
   Kipf TN, 2016, ARXIV
   Li DS, 2022, APPL INTELL, V52, P9638, DOI 10.1007/s10489-021-03055-1
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo LQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16188, DOI 10.1109/ICCV48922.2021.01590
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P65, DOI 10.1109/CGIV.2011.23
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P59, DOI 10.1109/CGIV.2011.33
   Mao JG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3144, DOI 10.1109/ICCV48922.2021.00315
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Paszke A, 2019, ADV NEUR IN, V32
   Qi CR, 2017, ADV NEUR IN, V30
   Qian GC, 2021, PROC CVPR IEEE, P11678, DOI 10.1109/CVPR46437.2021.01151
   Qiao C, 2021, NAT METHODS, V18, P194, DOI 10.1038/s41592-020-01048-5
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Song WP, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P555, DOI 10.1145/3289600.3290989
   Tang Haotian, 2020, EUR C COMP VIS, P685, DOI DOI 10.1007/978-3-030-58604-1_41
   Te GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P746, DOI 10.1145/3240508.3240621
   van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500
   Velickovic P, 2017, ARXIV
   Wang GY, 2021, J SYST SCI COMPLEX, V34, P68, DOI 10.1007/s11424-020-9266-x
   Wang HY, 2022, NEURAL COMPUT APPL, V34, P1623, DOI 10.1007/s00521-021-06464-y
   Wu H., 2019, ARXIV
   Xu JW, 2023, NEURAL COMPUT APPL, V35, P9951, DOI 10.1007/s00521-022-06939-6
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Ye SQ, 2022, IEEE T VIS COMPUT GR, V28, P3206, DOI 10.1109/TVCG.2021.3058311
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Yue Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P752, DOI 10.1007/978-3-030-58529-7_44
   Zhang FY, 2020, PROC CVPR IEEE, P2795, DOI 10.1109/CVPR42600.2020.00287
   Zhang W, 2020, ADV INTELLIGENT SYST, V1244, P764
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao YF, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2214, DOI 10.1145/3474085.3475381
   Zolanvari S., 2019, P 30 BRIT MACHINE VI
NR 58
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26213
EP 26232
DI 10.1007/s11042-023-16525-0
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001063783300002
DA 2024-07-18
ER

PT J
AU Keshavarzian, R
   Aghagolzadeh, A
AF Keshavarzian, Razieh
   Aghagolzadeh, Ali
TI Low rank and sparse decomposition based on extended<i>
   LL<sub>p</sub></i> norm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alternating direction multiplier method; Low-rank and sparse
   decomposition; LLp norm; Robust principle component analysis
ID TRUNCATED NUCLEAR NORM; SCHATTEN-P-NORM; MATRIX COMPLETION; IMAGE
   CLASSIFICATION; FACE RECOGNITION; MINIMIZATION; REGULARIZATION;
   REPRESENTATION; MODEL
AB The problem of decomposing a given matrix into its low-rank and sparse components, known as robust principle component analysis (RPCA), has found many applications in variety of fields. In this problem, the goal is to recover the two components through constrained minimization of a combination of the rank function and l(0) norm. Oftentimes, exact recovery of the low-rank component is desired. Since the problem is NP-Hard, a convex relaxation where nuclear norm and l(1) norm are utilized to induce low-rank and sparsity is used. However, it may obtain suboptimal results since the nuclear norm cannot well approximate the rank function. This paper addresses the low-rank and sparse decomposition (LRSD) problem by utilizing a new nonconvex approximation function for the rank. In our LRSD approach, the nonconvex LLp norm is extended on singular values to obtain a new surrogate, called eLL(p), for the rank function. To solve the associated minimization problem, an efficient algorithm based on alternating direction multiplier method (ADMM) and Majorization-Minimization (MM) algorithm is developed. To verify the effectiveness of the proposed method, it is applied to the synthetic data and real applications including face image shadow removal and image denoising. Experimental results show the effectiveness of the proposed method compared with the other methods in terms of the recovery errors and objective evaluations. In real applications of the images, our proposed method achieves higher recovery accuracy in a less time.
C1 [Keshavarzian, Razieh] Islamic Azad Univ, Dept Elect Engn, Heris Branch, Heris, Iran.
   [Aghagolzadeh, Ali] Babol Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol, Iran.
C3 Islamic Azad University; Babol Noshirvani University of Technology
RP Aghagolzadeh, A (corresponding author), Babol Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol, Iran.
EM ra.keshavarzian@iau.ac.ir; aghagol@nit.ac.ir
RI Keshavarzian, Razieh/AAN-2135-2021
OI Keshavarzian, Razieh/0000-0002-7623-5282
FU Babol Noshirvani University of Technology [BNUT/389059/1401]
FX The authors would like to acknowledge the funding support of Babol
   Noshirvani University of Technology through grant program No.
   BNUT/389059/1401.
CR Abhadiomhen SE, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465056
   Abhadiomhen SE, 2022, APPL INTELL, V52, P530, DOI 10.1007/s10489-021-02409-z
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cao FL, 2017, NEURAL NETWORKS, V85, P10, DOI 10.1016/j.neunet.2016.09.005
   Carrillo RE, 2013, IEEE T SIGNAL PROCES, V61, P4822, DOI 10.1109/TSP.2013.2274275
   Carrillo RE, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/312989
   Carrillo RE, 2010, IEEE J-STSP, V4, P392, DOI 10.1109/JSTSP.2009.2039177
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen K, 2013, BIOMETRIKA, V100, P901, DOI 10.1093/biomet/ast036
   Chen TF, 2023, SIGNAL IMAGE VIDEO P, V17, P109, DOI 10.1007/s11760-022-02210-6
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Du JC, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P615, DOI 10.1109/ISCIT.2016.7751706
   Feng L, 2016, SIGNAL PROCESS-IMAGE, V47, P28, DOI 10.1016/j.image.2016.05.012
   Goldfarb D, 2013, MATH PROGRAM, V141, P349, DOI 10.1007/s10107-012-0530-2
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hong B, 2016, NEUROCOMPUTING, V175, P216, DOI 10.1016/j.neucom.2015.10.052
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hui KF, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108230
   Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836
   Jia XX, 2019, INFORM SCIENCES, V476, P83, DOI 10.1016/j.ins.2018.10.003
   Kang Z, 2015, IEEE DATA MINING, P211, DOI 10.1109/ICDM.2015.15
   Keshavarzian R, 2019, SIGNAL PROCESS-IMAGE, V78, P477, DOI 10.1016/j.image.2019.07.021
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li YN, 2016, INT CONF ACOUST SPEE, P2154, DOI 10.1109/ICASSP.2016.7472058
   Lin, 2010, ARXIV10095055
   Lin Z., 2009, Tech. Rep. UILU-ENG-09-2214
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   MILLER JH, 1972, IEEE T INFORM THEORY, V18, P241, DOI 10.1109/TIT.1972.1054787
   Min K., 2010, 19 ACM INT C INFORM, P269
   Murali S, 2022, VISUAL COMPUT, V38, P1527, DOI 10.1007/s00371-021-02086-6
   Nagarajaiah S, 2017, PROCEDIA ENGINEER, V199, P62, DOI 10.1016/j.proeng.2017.09.153
   Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160
   RIDER PR, 1958, ANN I STAT MATH, V9, P215
   Saeedi T, 2022, IEEE T KNOWL DATA EN, V34, P519, DOI 10.1109/TKDE.2020.2983708
   Shang F, 2014, ARXIV
   Shi CF, 2017, MED IMAGE ANAL, V38, P30, DOI 10.1016/j.media.2017.02.008
   Shi XS, 2018, NEUROCOMPUTING, V283, P205, DOI 10.1016/j.neucom.2017.12.034
   Song Y, 2018, NEUROCOMPUTING, V275, P2479, DOI 10.1016/j.neucom.2017.11.021
   Tang G., 2011, P ANN C INF SCI SYST, P1, DOI DOI 10.1109/CISS.2011.5766144
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Wen CL, 2021, INT J MACH LEARN CYB, V12, P1557, DOI 10.1007/s13042-020-01256-7
   Wen F, 2019, IEEE T SIGNAL PROCES, V67, P5402, DOI 10.1109/TSP.2019.2940121
   Wen F, 2020, IEEE T CIRC SYST VID, V30, P1497, DOI 10.1109/TCSVT.2019.2908833
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xie T, 2020, IEEE T IMAGE PROCESS, V29, P44, DOI 10.1109/TIP.2019.2926736
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Xue ZC, 2019, VISUAL COMPUT, V35, P1549, DOI 10.1007/s00371-018-1555-1
   Yang YP, 2023, DIGIT SIGNAL PROCESS, V133, DOI 10.1016/j.dsp.2022.103892
   Yang ZZ, 2022, MULTIMED TOOLS APPL, V81, P38279, DOI 10.1007/s11042-022-12509-8
   Yang ZZ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107527
   Yang ZZ, 2019, J FRANKLIN I, V356, P10138, DOI 10.1016/j.jfranklin.2019.09.017
   Yang ZZ, 2018, IEEE ACCESS, V6, P56945, DOI 10.1109/ACCESS.2018.2872688
   Yuan X., 2009, SPARSE LOW RANK MATR, V12
   Zhang CJ, 2014, COMPUT VIS IMAGE UND, V123, P14, DOI 10.1016/j.cviu.2014.02.013
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang DB, 2012, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR.2012.6247927
   Zhang QL, 2021, AUTOM CONTROL COMPUT, V55, P388, DOI 10.3103/S0146411621040064
   Zhao ZL, 2017, LECT NOTES COMPUT SC, V10638, P3, DOI 10.1007/978-3-319-70139-4_1
   Zheng QZ, 2022, J FRANKLIN I, V359, P9376, DOI 10.1016/j.jfranklin.2022.09.002
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
NR 70
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26107
EP 26130
DI 10.1007/s11042-023-16584-3
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001063782500003
DA 2024-07-18
ER

PT J
AU Babu, NR
   Balasubramaniam, P
   Joo, EM
AF Babu, N. Ramesh
   Balasubramaniam, P.
   Joo, Er. Meng
TI Video encryption via synchronization of a fractional order T-S fuzzy
   memristive hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Memristor; Hyperchaotic system; Fractional elements; T-S fuzzy model;
   Synchronization; Encryption; Decryption
ID CHAOTIC SYSTEMS; SCHEME
AB Memristors are frequently utilized as essential blocks in characterizing new nonlinear circuits consisting of fewer elements. In this paper, mathematical modeling of a fractional-order memristor circuit is developed by replacing classical circuit elements by fractional elements. The main contributions of this paper are: (1) A fractional order non-linear memristive hyper-chaotic system (MHCS) is remodeled into linear memristive hyperchaotic sub-models by using T-S fuzzy rules for the first time. (2) Synchronization of a sender and receiver system with applications in video cryptosystem is addressed. (3) A fuzzy feedback controller based on T-S fuzzy control laws which guarantee synchronization of the MHCS is designed. (4) Video encryption and decryption algorithms based on converting video samples into image frame are developed and a sequence of random masks is securely transacted with the help of a sequence of chaotic self-invertible masks for encryption and decryption process. (5) High-level security of the proposed work is entrusted by analyzing various metrics including entropy, Peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), number of changing pixel rate (NPCR), and edge difference ratio (EDR) along with numerical simulations. (6) The proposed encryption algorithms have several advantages such as high-level randomness, key sensitivity, and motion control of encrypted frames. Numerical simulation and experimental results demonstrate the effectiveness, efficiency and feasibility of real-world applications of the proposed algorithms.
C1 [Babu, N. Ramesh] Koneru Lakshmaiah Educ Fdn Deemed Univ, Dept Math, Vaddeswaram 522302, Andhra Prades, India.
   [Babu, N. Ramesh; Balasubramaniam, P.] Gandhigram Rural Inst Deemed Univ, Dept Math, Dindigul 624302, Tamil Nadu, India.
   [Joo, Er. Meng] Dalian Maritime Univ, Inst Artificial Intelligence & Marine Robot, Coll Marine Elect Engn, 1 Linghai Rd, Dalian 116026, Peoples R China.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Gandhigram Rural Institute; Dalian Maritime University
RP Balasubramaniam, P (corresponding author), Gandhigram Rural Inst Deemed Univ, Dept Math, Dindigul 624302, Tamil Nadu, India.
EM balugru@gmail.com
RI Babu, Dr. N. Ramesh/ABG-1382-2021; Balasubramaniam, P./O-3041-2013
OI Babu, Dr. N. Ramesh/0000-0002-1887-9514; Balasubramaniam,
   P./0000-0001-9673-5949
FU NFSC, UGC, New Delhi [82-1/2018 (SA-III)]; UGC [4071/(CSIR-UGC NET JUNE
   2018)]
FX This work is supported by NFSC, UGC, New Delhi, File No. 82-1/2018
   (SA-III), UGC-Ref. No.: 4071/(CSIR-UGC NET JUNE 2018).
CR Abomhara M., 2010, INT J COMP THEOR ENG, V2, P1793
   Acharya B., 2007, INT J SECURITY, V1, P14
   Bao BC, 2011, INT J BIFURCAT CHAOS, V21, P2629, DOI 10.1142/S0218127411029999
   BREWER JW, 1978, IEEE T CIRCUITS SYST, V25, P772, DOI 10.1109/TCS.1978.1084534
   Chen BJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500753
   Chen P, 2016, NONLINEAR DYNAM, V86, P725, DOI 10.1007/s11071-016-2933-8
   Ching SLP, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3020015
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Gómez-Aguilar José Francisco, 2014, Ing. invest. y tecnol., V15, P311
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Kalpana M, 2018, NONLINEAR DYNAM, V93, P543, DOI 10.1007/s11071-018-4208-z
   Khan A., 2016, J UNCERTAIN SYSTEMS, V10, P251
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Li SY, 2019, INFORM SCIENCES, V481, P604, DOI 10.1016/j.ins.2018.12.066
   Li Y, 2009, AUTOMATICA, V45, P1965, DOI 10.1016/j.automatica.2009.04.003
   Lin TC, 2015, INT J FUZZY SYST, V17, P206, DOI 10.1007/s40815-015-0024-5
   Luo HB, 2019, MULTIMED TOOLS APPL, V78, P34323, DOI 10.1007/s11042-019-08072-4
   Luo SH, 2021, IEEE T FUZZY SYST, V29, P1701, DOI 10.1109/TFUZZ.2020.2984998
   Ma DZ, 2010, CHINESE PHYS B, V19, DOI 10.1088/1674-1056/19/5/050506
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Muthukumar P, 2018, ISA T, V82, P51, DOI 10.1016/j.isatra.2017.07.007
   Muthukumar P, 2014, CHAOS, V24, DOI 10.1063/1.4886355
   Muthuswamy B, 2009, IETE TECH REV, V26, P417, DOI 10.4103/0256-4602.57827
   PECORA LM, 1990, PHYS REV LETT, V64, P821, DOI 10.1103/PhysRevLett.64.821
   Podlubny I, 1999, Fractional Differential Equations
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Wang B, 2018, COMPLEXITY, DOI 10.1155/2018/3079108
   Wang LM, 2019, APPL MATH COMPUT, V347, P293, DOI 10.1016/j.amc.2018.11.017
   [王小平 Wang Xiaoping], 2013, [自动化学报, Acta Automatica Sinica], V39, P1170
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Wen SP, 2013, PHYS LETT A, V377, P2016, DOI 10.1016/j.physleta.2013.05.046
   Xu H, 2020, MULTIMEDIA SYST, V26, P363, DOI 10.1007/s00530-020-00648-7
   Yang SG, 2008, PROG NAT SCI-MATER, V18, P1299, DOI 10.1016/j.pnsc.2008.05.009
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhu Z., 2019, COMPLEXITY, V2019, P1
NR 36
TC 1
Z9 1
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26055
EP 26088
DI 10.1007/s11042-023-16483-7
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500004
DA 2024-07-18
ER

PT J
AU Belhadj, F
   Moussaoui, A
AF Belhadj, Foudil
   Moussaoui, Adel
TI Attack via missed record synchronization on transformation-based
   fingerprint template protection algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Fingerprint template security; Attack via record
   multiplicity; Attack via missed redundancy synchronization; Fingerprint
   identification
ID CANCELABLE BIOMETRICS; ROBUST
AB Cancelable biometric template protection (BTP) schemes are proposed to overcome some security issues that traditional biometric templates know once compromised in particular the non-renewability and the user trackability. The main concern of the existing BTP algorithms is to ensure the non-invertibility of the transform function and maintain high separability statistics to assess the security of the transformed template so that the original biometric data can't be recovered back. We show in this paper that even if a BTP algorithm fulfills the above requirements, it is still vulnerable. We demonstrate this claim by launching an attack against a representative example of a transformation-based fingerprint template protection algorithm. The proposed attack, namely Attack via Missed Record Synchronization (AMRS), exploits the miss of shared redundant information between multiple correlated protected templates to deduce some additional hidden information that helps to reverse the transform function and spoof the authentication system. The proposed algorithm also allows to reconstruct the original template in terms of minutiae. The experiments conducted on the FVC database show that the proposed attack can break down the security of some cancelable algorithms knowing only reduced number of transformed templates.
C1 [Belhadj, Foudil] Mohamed Bachir El Ibrahimi Univ, LMSE Lab, Bordj Bou Arreridj, Algeria.
   [Moussaoui, Adel] Mohamed Boudiaf Univ, Msila, Algeria.
C3 University Bachir El Ibrahimi; Universite des Sciences et de la
   Technologie d'Oran Mohamed Boudiaf
RP Belhadj, F (corresponding author), Mohamed Bachir El Ibrahimi Univ, LMSE Lab, Bordj Bou Arreridj, Algeria.
EM foudil.belhadj@univ-bba.dz
RI BELHADJ, FOUDIL/AAD-4216-2019
OI belhadj, foudil/0000-0002-9144-0719
CR Abdullahi SM, 2023, IEEE T DEPEND SECURE, V20, P3828, DOI 10.1109/TDSC.2022.3213704
   Abdullahi SM, 2020, IEEE T INF FOREN SEC, V15, P2587, DOI 10.1109/TIFS.2020.2971142
   Abdullahi SM, 2022, ATTACK IRREVERSIBLE
   Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Medina-Pérez MA, 2014, LECT NOTES COMPUT SC, V8495, P132, DOI 10.1007/978-3-319-07491-7_14
   Belguechi R, 2013, COMPUT SECUR, V39, P325, DOI 10.1016/j.cose.2013.08.009
   Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Dong X, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.07770
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Feng YC, 2014, PATTERN RECOGN, V47, P3019, DOI 10.1016/j.patcog.2014.03.003
   Ghammam L, 2020, IEEE T INF FOREN SEC, V15, P2869, DOI 10.1109/TIFS.2020.2977533
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kholmatov A, 2008, PROC SPIE, V6819, DOI 10.1117/12.766861
   Lacharme P, 2013, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY (SECRYPT 2013), P363
   LAMAN G, 1970, J ENG MATH, V4, P331, DOI 10.1007/BF01534980
   Lee CH, 2007, IEEE T SYST MAN CY B, V37, P980, DOI 10.1109/TSMCB.2007.896999
   Lee Y, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P92
   Li C, 2014, CONCURR COMP-PRACT E, V26, P1593, DOI 10.1002/cpe.3042
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maltoni D., 2003, HDB FINGERPRINT RECO, P348, DOI [10.1007/978-1-84882-254-2., DOI 10.1007/978-1-84882-254-2, 10.1007/978-1-84882-254-2]
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Moujahdi C, 2014, PATTERN RECOGN LETT, V45, P189, DOI 10.1016/j.patrec.2014.04.001
   Nanwate Saloni, 2020, 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), P693, DOI 10.1109/GUCON48875.2020.9231257
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C, 2013, INT CONF BIOMETR
   Scheirer WJ, 2007, 2007 BIOMETRICS SYMPOSIUM, P30
   Sitharam M, 2018, HDB GEOMETRIC CONSTR
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Tran QN, 2021, IEEE T INF FOREN SEC, V16, P2926, DOI 10.1109/TIFS.2021.3069170
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
   Yang HJ, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 1, P645, DOI 10.1109/ICCSIT.2009.5234870
NR 34
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27543
EP 27563
DI 10.1007/s11042-023-16504-5
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600008
DA 2024-07-18
ER

PT J
AU Song, CM
   Liu, S
   Yan, XH
   Wang, XH
AF Song, Chuanming
   Liu, Shuang
   Yan, Xiaohong
   Wang, Xianghai
TI An image quality-aware approach with adaptive scattering coefficients
   for single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Atmospheric scattering model; Adaptive scattering
   coefficient
AB Most conventional dehazing methods obtain quality results by solving atmospheric scattering model (ASM) using acquired variables (i.e., global atmospheric light and transmission map). Prior-based strategies have made significant achievements in this task. Nonetheless, they usually obtain unrealistic dehazed images since strong assumptions can barely suit all circumstances. In this paper, we propose a novel image dehazing method with adaptive scattering coefficients to realize visual-friendly and quality-orientated restoration. Specifically, a regional rank-based technique is applied to find the most likely atmospheric light candidate. And then, different from previous image dehazing methods that rely on haze-relevant priors to estimate a transmission map, we develop an image quality-aware approach, together with a dynamic scattering coefficient. In this phase, an optimization function constrained by the image quality-aware indicators is designed to compute the scattering coefficient or transmission. The Fibonacci algorithm is further employed to solve this optimization problem. The proposed method produces high-quality results and exhibits favorable quantitative and qualitative performance compared to related methods.
C1 [Song, Chuanming; Liu, Shuang; Wang, Xianghai] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Song, Chuanming] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215031, Peoples R China.
   [Liu, Shuang] Dalian Univ Sci & Technol, Sch Informat Sci & Technol, Dalian 116052, Peoples R China.
   [Yan, Xiaohong] Dalian Jiaotong Univ, Sch Software, Dalian 116028, Peoples R China.
   [Yan, Xiaohong] Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.
C3 Liaoning Normal University; Soochow University - China; Dalian
   University of Technology; Dalian Jiaotong University; Dalian Maritime
   University
RP Song, CM (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.; Song, CM (corresponding author), Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215031, Peoples R China.; Yan, XH (corresponding author), Dalian Jiaotong Univ, Sch Software, Dalian 116028, Peoples R China.; Yan, XH (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.
EM chmsong@lnnu.edu.cn; lsliush@163.com; dl_yanxiaohong@163.com
RI feng, feng/KBR-1814-2024; yan, xiao/JVP-0766-2024; Wang,
   Xianghai/GRR-4512-2022; you, li/KHW-2201-2024; yi, zhang/KGL-4990-2024;
   yan, xu/KCY-8174-2024; YANG, DAN/KCL-5217-2024; luo, Jing/KFT-0288-2024
OI Wang, Xianghai/0000-0002-7600-9939; 
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Chen ZM, 2022, IEEE T IMAGE PROCESS, V31, P2570, DOI 10.1109/TIP.2022.3148867
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Cooper TJ, 2004, J ELECTRON IMAGING, V13, P85, DOI 10.1117/1.1636182
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Dong Z, 2022, COMPLEMENTARY FEATUR
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SY, 2020, MULTIDIM SYST SIGN P, V31, P1603, DOI 10.1007/s11045-020-00723-2
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Karimi D, 2022, IEEE ACCESS, V10, P29322, DOI [10.1109/access.2022.3156894, 10.1109/ACCESS.2022.3156894]
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   [李大鹏 Li Dapeng], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1753
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Peng YT, 2020, IEEE T CIRC SYST VID, V30, P1385, DOI 10.1109/TCSVT.2019.2902795
   Qi G, 2020, SENSORS-BASEL, V20
   Wang JZ, 2016, IEEE T MULTIMEDIA, V18, P1000, DOI 10.1109/TMM.2016.2544099
   Yan XH, 2022, SIGNAL PROCESS-IMAGE, V104, DOI 10.1016/j.image.2022.116670
   Yan XH, 2022, MULTIMED TOOLS APPL, V81, P30051, DOI 10.1007/s11042-022-12267-7
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zheng MY, 2020, IEEE SENS J, V20, P8062, DOI 10.1109/JSEN.2020.2981719
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 34
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25519
EP 25542
DI 10.1007/s11042-023-16288-8
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001054228300002
DA 2024-07-18
ER

PT J
AU Gupta, D
   Kumar, M
   Chaudhary, S
AF Gupta, Dipika
   Kumar, Manish
   Chaudhary, Sachin
TI A systematic review of deep learning frameworks for moving object
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Moving object segmentation; Deep learning; Convolutional neural
   network(CNN); Transformers
ID VIDEO; TRACKING; EXTRACTION; ACCURATE; NETWORK
AB Moving Object Segmentation (MOS) in machine learning and computer vision is gaining much interest among researchers in recent times. This field of dynamic scene understanding aims to understand every pixel of a video by segmenting objects in a frame sequence from beginning till end. The goal is to generate temporally consistent and accurate pixel masks for the target object in a video. Our paper follows a systematic way to represent the available state-of-the-art literature in the field of MOS. It includes a detailed analysis of semi-supervised, unsupervised, interactive, and referring MOS. Next, various deep learning-based approaches for MOS are elaborated. In Section 4, the basic architecture of MOS has been explained with a summary of the current benchmark data sets used. Further, a summary of evaluation metrics and qualitative and quantitative results forMOS are discussed. Finally, latest available results to date are provided as well as future research directions for MOS are detailed.
C1 [Gupta, Dipika; Kumar, Manish] Punjab Engn Coll, Comp Sci Engn, Sect 12, Chandigarh 160012, India.
   [Chaudhary, Sachin] Amity Univ, Mohali, India.
C3 Punjab Engineering College (Deemed University)
RP Gupta, D (corresponding author), Punjab Engn Coll, Comp Sci Engn, Sect 12, Chandigarh 160012, India.
EM dipikagupta.phdcse20@pec.edu.in; manishkumar@pec.edu.in;
   schaudhary@pb.amity.edu
OI Gupta, Dipika/0000-0003-4796-1071
CR Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ballas Nicolas, 2015, arXiv, DOI DOI 10.48550/ARXIV.1511.06432
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P777, DOI 10.1007/978-3-030-58536-5_46
   Botach A, 2022, PROC CVPR IEEE, P4975, DOI 10.1109/CVPR52688.2022.00493
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Caelles S, 2019, Arxiv, DOI arXiv:1905.00737
   Chen Y.W., 2022, P IEEECVF WINTER C A, P1320
   Cheng HK, 2021, ADV NEUR IN, V34
   Cheng HK, 2021, PROC CVPR IEEE, P5555, DOI 10.1109/CVPR46437.2021.00551
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Cho S, 2022, IEEE WINT CONF APPL, P1453, DOI 10.1109/WACV51458.2022.00152
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Duarte K, 2019, IEEE I CONF COMP VIS, P8479, DOI 10.1109/ICCV.2019.00857
   Duke B, 2021, PROC CVPR IEEE, P5908, DOI 10.1109/CVPR46437.2021.00585
   Fiaz M, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107401
   Gao MQ, 2023, ARTIF INTELL REV, V56, P457, DOI 10.1007/s10462-022-10176-7
   Ge WB, 2021, PROC CVPR IEEE, P16831, DOI 10.1109/CVPR46437.2021.01656
   Han JW, 2018, PROC CVPR IEEE, P9080, DOI 10.1109/CVPR.2018.00946
   Heo Y., 2021, P IEEECVF C COMPUTER, P7322
   Hu L, 2021, PROC CVPR IEEE, P4142, DOI 10.1109/CVPR46437.2021.00413
   Hu YT, 2017, ADV NEUR IN, V30
   Hu YT, 2019, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2019.00322
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Ji GP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4902, DOI 10.1109/ICCV48922.2021.00488
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Lamdouar Hala, 2020, P ASIAN C COMPUTER V
   Lan M, 2022, AAAI CONF ARTIF INTE, P1228
   Lee Y, 2021, ARXIV
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li Mingxing, 2022, CVPR, P1332
   Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683
   Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13
   Li XX, 2018, LECT NOTES COMPUT SC, V11207, P93, DOI 10.1007/978-3-030-01219-9_6
   Liang Y., 2020, Adv. Neural Inf. Proces. Syst., V33, P3430
   Lin HJ, 2019, IEEE I CONF COMP VIS, P3948, DOI 10.1109/ICCV.2019.00405
   Lin Z., 2022, P IEEE CVF C COMP VI, P1362
   Liu Y, 2022, Arxiv, DOI arXiv:2207.07922
   Liu Z., 2021, IEEE T INSTRUM MEAS, V71, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luiten J, 2020, IEEE WINT CONF APPL, P1989, DOI 10.1109/WACV45572.2020.9093285
   Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670
   Mao Yunyao, 2021, P IEEECVF INT C COMP, P9670
   Miao J., 2020, P IEEE CVF C COMP VI, P10366
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Park K, 2022, PROC CVPR IEEE, P1342, DOI 10.1109/CVPR52688.2022.00141
   Patil Prashant W., 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8146, DOI 10.1109/CVPR42600.2020.00817
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pont-Tuset J, 2018, Arxiv, DOI arXiv:1704.00675
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren SC, 2021, PROC CVPR IEEE, P15450, DOI 10.1109/CVPR46437.2021.01520
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Schmidt C., 2022, P IEEE CVF WINT C AP, P1200
   Seong H., 2020, EUR C COMP VIS, P629
   Seong H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12869, DOI 10.1109/ICCV48922.2021.01265
   Seonguk Seo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P208, DOI 10.1007/978-3-030-58555-6_13
   Seoung Wug Oh, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P9225, DOI 10.1109/ICCV.2019.00932
   Shi XJ, 2015, ADV NEUR IN, V28
   Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542
   Voigtlaender P, 2017, Arxiv, DOI arXiv:1706.09364
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Voigtlaender Paul, 2021, P IEEECVF WINTER C A, P3060
   Wang HC, 2021, PROC CVPR IEEE, P1296, DOI 10.1109/CVPR46437.2021.00135
   Wang W., 2019, PROC CVPR IEEE, P3064, DOI DOI 10.1109/CVPR.2019.00318
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   Wei LL, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3506716
   Wu D, 2022, P IEEE CVF C COMP VI, P4996
   Wu JN, 2022, PROC CVPR IEEE, P4964, DOI 10.1109/CVPR52688.2022.00492
   Xi Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9381, DOI 10.1109/CVPR42600.2020.00940
   Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39
   Xie HZ, 2021, PROC CVPR IEEE, P1286, DOI 10.1109/CVPR46437.2021.00134
   Xu K, 2021, ARXIV
   Xu K, 2022, PROC CVPR IEEE, P1332, DOI 10.1109/CVPR52688.2022.00140
   Xu N, 2018, Arxiv, DOI arXiv:1809.03327
   Xu X., 2021, ARXIV
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang LJ, 2019, IEEE I CONF COMP VIS, P5187, DOI 10.1109/ICCV.2019.00529
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yang ZX, 2021, ADV NEUR IN, V34
   Yin YJ, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107580
   Yin ZY, 2021, PROC CVPR IEEE, P15440, DOI 10.1109/CVPR46437.2021.01519
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhang L, 2019, IEEE I CONF COMP VIS, P5581, DOI 10.1109/ICCV.2019.00568
   Zhou TF, 2021, PROC CVPR IEEE, P6981, DOI 10.1109/CVPR46437.2021.00691
NR 94
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16417-3
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400007
DA 2024-07-18
ER

PT J
AU Elmeslimany, EM
   Kishk, SS
   Altantawy, DA
AF Elmeslimany, Eman M.
   Kishk, Sherif S.
   Altantawy, Doaa A.
TI ψnet: a parallel network with deeply coupled spatial and squeezed
   features for segmentation of medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image segmentation; U-Net; & psi;net; Polyp segmentation; DSB
   2018; ISIC 2017-2018
ID CONVOLUTIONAL NEURAL-NETWORK; POLYP SEGMENTATION; NET; ARCHITECTURE
AB The process of delineating a region of interest or an object in an image is called image segmentation. Efficient medical image segmentation can contribute to the early diagnosis of illnesses, and accordingly, patient survival possibilities can be enhanced. Recently, deep semantic segmentation methods demonstrate state-of-the-art (SOTA) performance. In this paper, we propose a generic novel deep medical segmentation framework, denoted as ?net. This model introduces a novel parallel encoder-decoder structure that draws up the power of triple U-Nets. In addition, a multi-stage squeezed-based encoder is employed to raise the network sensitivity to relevant features and suppress the unnecessary ones. Moreover, atrous spatial pyramid pooling (ASPP) is employed in the bottleneck of the network which helps in gathering more effective features during the training process, hence better performance can be achieved in segmentation tasks. We have evaluated the proposed ?net on a variety of challengeable segmentation tasks, including colonoscopy, microscopy, and dermoscopy images. The employed datasets include Data Science Bowl (DSB) 2018 challenge as a cell nuclei segmentation from microscopy images, International Skin Imaging Collaboration (ISIC) 2017 and 2018 as skin lesion segmentation from dermoscopy images, Kvasir-SEG, CVC-ClinicDB, ETIS-LaribDB, and CVC-ColonDB as polyp segmentation from colonoscopy images. Despite the variety in the employed datasets, the proposed model, with extensive experiments, demonstrates superior performance to advanced SOTA models, such as U-Net, ResUNet, Recurrent Residual U-Net, ResUNet++, UNet++, BCDU-Net, MultiResUNet, MCGU-Net, FRCU-Net, Attention Deeplabv3p, DDANet, ColonSegNet, and TMD-Unet.
C1 [Elmeslimany, Eman M.; Kishk, Sherif S.; Altantawy, Doaa A.] Mansoura Univ, Fac Engn, Elect & Commun Engn Dept, 60 El Gomhoria St, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University
RP Altantawy, DA (corresponding author), Mansoura Univ, Fac Engn, Elect & Commun Engn Dept, 60 El Gomhoria St, Mansoura, Egypt.
EM eman.mahmoud@std.mans.edu.eg; shkishk@mans.edu.eg; doaa1adel@mans.edu.eg
FU Science, Technology amp; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Alom MZ, 2018, arXiv
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Asadi-Aghbolaghi M, 2020, Arxiv, DOI [arXiv:2003.05056, 10.48550/arXiv.2003.05056]
   Azad Reza, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P251, DOI 10.1007/978-3-030-66415-2_16
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Azad Reza, 2021, P IEEECVF INT C COMP, P3274
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet Francois, 2018, Keras: the Python Deep Learning Library
   Codella N, 2019, Arxiv, DOI arXiv:1902.03368
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   El Jurdi R, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103248
   Erol T, 2022, Arxiv, DOI arXiv:2204.03652
   Eu CY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165630
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fu YB, 2021, PHYS MEDICA, V85, P107, DOI 10.1016/j.ejmp.2021.05.003
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jadon S, 2020, 2020 IEEE C COMPUTAT, P1
   Jha D, 2021, COMP MED SY, P37, DOI 10.1109/CBMS52027.2021.00014
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Karen Simonyan*., 2018, American Journal of Health-System Pharmacy, V75, P398
   Li XY, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103283
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Patel D., 2019, Augmented Hum. Res, V5, P6, DOI [10.1007/s41133-019-0024-3, DOI 10.1007/S41133-019-0024-3]
   Punn NS, 2022, ARTIF INTELL REV, V55, P5845, DOI 10.1007/s10462-022-10152-1
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Suganyadevi S, 2022, INT J MULTIMED INF R, V11, P19, DOI 10.1007/s13735-021-00218-1
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tran ST, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9010054
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wu Yuchao, 2020, Sheng Wu Yi Xue Gong Cheng Xue Za Zhi, V37, P533, DOI 10.7507/1001-5515.201906067
   Xing Y., 2020, WIREL COMMUN MOB COM, V2020, P1
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 69
TC 2
Z9 2
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16416-4
EA AUG 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Kushwaha, A
   Khare, A
   Prakash, O
AF Kushwaha, Arati
   Khare, Ashish
   Prakash, Om
TI Human activity recognition algorithm in video sequences based on the
   fusion of multiple features for realistic and multi-view environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human Activity Recognition; Zernike Moment; Optical Flow; Local Ternary
   Pattern; Histogram of Oriented Gradients; Support Vector Machine
ID FLOW; MECHANISM; STRATEGY
AB Video-based human activity recognition (HAR) is an active and challenging research area in the field of computer vision. The presence of camera motion, irregular motion of humans, varying illumination conditions, complex backgrounds, and variations in the shape and size of human objects in video clips of the same activity category makes human activity recognition more difficult. Therefore, to overcome these challenges, we introduce a novel feature representation technique for human activity recognition based on the fusion of multiple features. This paper presents a robust and view-invariant feature descriptor based on the combination of motion information and the local appearance of human objects for video-based human activity recognition in realistic and multi-view environments. Firstly, we used a combination of Optical Flow (OF) and Histogram of Oriented Gradients (HOG) to compute the dynamic pattern of motion information. Then, we computed shape information by combining Local Ternary Pattern (LTP) and Zernike Moment (ZM) feature descriptors. Finally, a feature fusion strategy is used to integrate the motion information and shape information to construct the final feature vector. The experiments are performed on three different publically available video datasets- IXMAS, CASIA, and TV human interaction (TV-HI) and achieved classification accuracy values are 98.25%, 92.21%, 98.66%, and 96.48% respectively on IXMAS, CASIA Single Person, CASIA Interaction and TV-HI datasets. The results are evaluated in terms of seven different performance measures- accuracy, precision, recall, specificity, F-measure, Matthew's correlation coefficient (MCC) and computation time. The effectiveness of the proposed method is proven by comparing its results with other existing state-of-the-art methods. The obtained results have demonstrated the usefulness of the proposed method.
C1 [Kushwaha, Arati] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, India.
   [Prakash, Om] HNB Garhwal Univ, Dept Comp Sci & Engn, Srinagar, Garhwal, India.
C3 GLA University; University of Allahabad; Hemwati Nandan Bahuguna Garhwal
   University
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, India.
EM aratikushwaha.jk@gmail.com; khare@allduniv.ac.in; au.omprakash@gmail.com
RI Kushwaha, Arati/ABG-4933-2020; Prakash, Om/AAL-4460-2021
OI Prakash, Om/0000-0001-6395-9989
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Celebi ME, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P788, DOI 10.1109/ITCC.2005.3
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen WJ, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P659, DOI 10.1109/CISP.2015.7407960
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duman E, 2019, IEEE ACCESS, V7, P183914, DOI 10.1109/ACCESS.2019.2960654
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Hung Huynh H., 2009, World Academy of Science, Engineering and Technology, V60, P280
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Khare M, 2014, LECT NOTES COMPUT SC, V8960, P87, DOI 10.1007/978-3-662-45947-8_7
   Kim SJ, 2014, PATTERN RECOGN LETT, V49, P40, DOI 10.1016/j.patrec.2014.05.018
   KM AD, 2017, 2017 IEEE INT C COMP, P1
   Kuo YM, 2010, IEEE T INF TECHNOL B, V14, P255, DOI 10.1109/TITB.2009.2036168
   Kushwaha A., 2021, MULTIMED TOOLS APPL, V31, P1
   Kushwaha A, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S0219467822500097
   Kushwaha A, 2020, IET IMAGE PROCESS, V14, P3393, DOI 10.1049/iet-ipr.2019.0960
   Ladjailia A, 2019, NEURAL COMPUT APPL, P1
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee SK, 1996, COMPUT IND ENG, V30, P511, DOI 10.1016/0360-8352(96)00020-4
   Liu S, 2023, IEEE INTERNET THINGS, V10, P3735, DOI 10.1109/JIOT.2022.3142115
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Nasrudin MW, 2014, P INT CONF INTELL, P7, DOI 10.1109/ISMS.2014.9
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Papadopoulos Georgios Th, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P473, DOI 10.1007/978-3-319-04114-8_40
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Prakash O, 2018, OPTIK, V157, P1267, DOI 10.1016/j.ijleo.2017.12.061
   Roitberg A, 2014, ASIAPAC SIGN INFO PR
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seemanthini K., 2018, Procedia Computer Science, V132, P1317, DOI 10.1016/j.procs.2018.05.048
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang Y., 2007, P IEEE INT C COMPUTE, P1, DOI [10.1109/CVPR.2007.383505, DOI 10.1109/CVPR.2007.383505, DOI 10.1016/J.EJ0R.2007.01.050]
   Won J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132992
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zhang H, 2010, INT CONF ACOUST SPEE, P930, DOI 10.1109/ICASSP.2010.5495286
   Zhu HY, 2017, IEEE I CONF COMP VIS, P5814, DOI 10.1109/ICCV.2017.619
NR 50
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16364-z
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600002
DA 2024-07-18
ER

PT J
AU Liang, JJ
   Pan, HJ
   Xiang, Z
   Qin, J
   Qiu, YL
   Guo, LB
   Wang, TF
   Jiang, W
   Lei, BY
AF Liang, Jiajun
   Pan, Huijuan
   Xiang, Zhuo
   Qin, Jing
   Qiu, Yali
   Guo, Libao
   Wang, Tianfu
   Jiang, Wei
   Lei, Baiying
TI Echocardiographic segmentation based on semi-supervised deep learning
   with attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image segmentation; 2D echocardiography; Semi-supervised
   learning; Attention mechanism
ID SEMANTIC SEGMENTATION; LEFT-VENTRICLE
AB Echocardiographic examination is one of the main methods for clinical diagnosis, management and follow-up of heart diseases. Echocardiographic segmentation is an essential step for obtaining precise measurements and accurate diagnosis. However, the current methods are mostly time-consuming, relatively subjective, and produce inconsistent results due to varying ultrasound image quality. To solve these problems, we propose an automatic 2D echocardiographic segmentation method, which is objective and robust for the change of image quality. Specifically, our method first constructs an echocardiographic motion estimation network to extract the heart motion features for the echocardiographic segmentation network. Then, based on semi-supervised learning, the echocardiographic segmentation network is trained by labeled images' ground truth and unlabeled images' pseudo labels, which are derived from the motion features. In addition, we introduce attention mechanism to observe its impact on segmentation performance. Experimental results show that the peak signal-to-noise ratio and the structural similarity index between the target images and the images reconstructed by the motion features are over 30dB and 92%, respectively. The echocardiographic segmentation network achieves 95.93% accuracy and 90.94% dice similarity coefficient in the segmentation of cardiac end-diastolic, and achieves 96.06% accuracy and 91.51% dice similarity coefficient in the segmentation of cardiac end-systolic. These results prove that the motion features and segmentation results obtained from our method are effective and accurate. Our code is publicly available at:
C1 [Liang, Jiajun; Xiang, Zhuo; Qiu, Yali; Guo, Libao; Wang, Tianfu; Lei, Baiying] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound,Guan, Shenzhen, Guangdong, Peoples R China.
   [Pan, Huijuan] Southern Univ & Technol Hosp, Dept Urol, Shenzhen, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Ctr Smart Hlth, Sch Nursing, Hong Kong, Peoples R China.
   [Jiang, Wei] Huazhong Univ Sci, Technol Union Shenzhen Hosp, Dept Ultrasound, Shenzhen, Peoples R China.
C3 Shenzhen University; Hong Kong Polytechnic University
RP Lei, BY (corresponding author), Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound,Guan, Shenzhen, Guangdong, Peoples R China.; Jiang, W (corresponding author), Huazhong Univ Sci, Technol Union Shenzhen Hosp, Dept Ultrasound, Shenzhen, Peoples R China.
EM liangjj2020@hotmail.com; sunnysn2006@hotmail.com; 1163248244@qq.com;
   harry.qin@polyu.edu.hk; qiuyali2019@email.szu.edu.cn;
   18270890216@qq.com; tfwang@szu.edu.cn; 2646748175@qq.com;
   leiby@szu.edu.cn
RI Lei, Baiying/GQO-8422-2022
OI Lei, Baiying/0000-0002-3087-2550
FU National Natural Science Foundation of China [62271328, U22A2024,
   62101338, 62201360, U1902209]; National Natural Science Foundation of
   Guangdong Province [2019B1515120029, 2020B121201001, 2021A1515110746];
   Shenzhen Key Basic Research Project [JCYJ20220818095809021, KCXFZ2020
   1221173213036, SGDX20201103095802007]
FX AcknowledgementsThis work was supported partly by National Natural
   Science Foundation of China (Nos. 62271328, U22A2024, 62101338, 62201360
   and U1902209), National Natural Science Foundation of Guangdong Province
   (Nos. 2019B1515120029, 2020B121201001 and 2021A1515110746), Shenzhen Key
   Basic Research Project (Nos. JCYJ20220818095809021, KCXFZ2020
   1221173213036, and SGDX20201103095802007).
CR Albishri AA, 2019, IEEE INT C BIOINFORM, P1416, DOI 10.1109/BIBM47256.2019.8983266
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Belaid A, 2018, SIGNAL IMAGE VIDEO P, V12, P1087, DOI 10.1007/s11760-018-1251-7
   Belaid A, 2011, IEEE T INF TECHNOL B, V15, P138, DOI 10.1109/TITB.2010.2090889
   Bernard O, 2016, IEEE T MED IMAGING, V35, P967, DOI 10.1109/TMI.2015.2503890
   Bonifazi G, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01448-2
   Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273
   Cikes M, 2014, JACC-CARDIOVASC IMAG, V7, P812, DOI 10.1016/j.jcmg.2014.06.004
   Dash S., 2020, Deep Learning Techniques for Biomedical and Health Informatics, DOI [10.1007/978-3-030-33966-1, DOI 10.1007/978-3-030-33966-1]
   Datar M, 2002, SIAM J COMPUT, V31, P1794, DOI 10.1137/S0097539701398363
   Guo W, 2022, MULTIMED TOOLS APPL, P1
   Hamarneh G, 2000, COMPUT CARDIOL, V27, P115, DOI 10.1109/CIC.2000.898469
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horimoto M, 2000, Rinsho Byori, V48, P128
   [胡盛寿 Hu Shengshou], 2019, [中国循环杂志, Chinese Circulation Journal], V34, P209
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang F, 2018, NEURAL COMPUT APPL, V29, P1257, DOI 10.1007/s00521-017-3158-6
   Kamranian Z, 2020, NEURAL COMPUT APPL, V32, P4073, DOI 10.1007/s00521-019-04448-7
   Keeney T, 2019, J AM GERIATR SOC, V67, P37, DOI 10.1111/jgs.15584
   Kingma D. P., 2014, arXiv
   Leclerc Sarah, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092632
   Leclerc S, 2019, IEEE T MED IMAGING, V38, P2198, DOI 10.1109/TMI.2019.2900516
   Lee D.-H., 2013, PSEUDOLABEL SIMPLE E, V3, P896
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Li H, 2019, IEEE J BIOMED HEALTH, V23, P527, DOI 10.1109/JBHI.2018.2859898
   Lin ZH, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101548
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Manson JE, 2019, NEW ENGL J MED, V380, P23, DOI 10.1056/NEJMoa1811403
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shengcong Chen, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P279, DOI 10.1007/978-3-030-59722-1_27
   Smistad Erik, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092812
   Swain D., 2022, J. Comput. Sci, V18, P993, DOI [10.3844/jcssp.2022.993.1004, DOI 10.3844/JCSSP.2022.993.1004]
   Ullah H, 2019, NEURAL COMPUT APPL, V31, P7317, DOI 10.1007/s00521-018-3527-9
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Ye M, 2020, PROC CVPR IEEE, P5456, DOI 10.1109/CVPR42600.2020.00550
   Yurtkulu SC, 2019, SIG PROCESS COMMUN, DOI 10.1109/siu.2019.8806244
   Zhang LG, 2020, NEURAL COMPUT APPL, V32, P1949, DOI 10.1007/s00521-019-04491-4
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 40
TC 0
Z9 0
U1 8
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16044-y
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700001
DA 2024-07-18
ER

PT J
AU Wang, HB
   Long, A
   Yu, LC
   Zhou, HM
AF Wang, Hongbin
   Long, An
   Yu, Luchuan
   Zhou, Hongming
TI An efficient approach of graph isomorphism identification using loop
   theory and hopfield neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Isomorphism identification; Adjacency list; Maximum-loop matrix; Neural
   networks; Kinematic chain
ID KINEMATIC CHAINS; ALGORITHM
AB Isomorphism identification of kinematic chains or topological graphs is a crucial issue in structural synthesis and innovative mechanism design. In this paper, a new method of isomorphism identification is proposed based on loop theory and hopfield neural networks. A program is written in Python to execute the method. First, the combination of maximum loops in a graph is generated by graph depth-first traversal algorithm. Then, the maximum loop is determined by its link degree sequence, and the maximum-loop matrix is also ensured by the selected maximum loop. Based on the iteration processes in hopfield neural networks, the maximum-loop matrix is changed from original low-ranking matrix to high-ranking matrix. Finally, some kinematic chains and topological graphs are introduced to justify the effectiveness of the proposed method. Results show that the proposed method applies to isomorphism identification of kinematic chains and topological graphs. And the proposed method is efficient and accurate. It enriches the application of loop theory and neural network for isomorphism identification.
C1 [Wang, Hongbin; Long, An; Yu, Luchuan; Zhou, Hongming] Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou 325035, Peoples R China.
C3 Wenzhou University
RP Yu, LC; Zhou, HM (corresponding author), Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou 325035, Peoples R China.
EM whb741@126.com; lajxutcm@163.com; lcyu@wzu.edu.cn; zhm69314@163.com
RI yu, xiao/KFT-1725-2024; Zhou, Honghao/JWO-4641-2024; chen,
   yue/JXW-9556-2024; chen, huan/KEC-2019-2024; li, jixiang/JXN-7599-2024;
   Chen, Liang/JXX-7887-2024; zhang, zheng/KBQ-7815-2024; Zhang,
   Wenbin/JXX-8070-2024; Zhou, Hong/JKJ-1067-2023; zheng, yi/JOZ-7204-2023;
   lei, xh/KFR-2496-2024; Wang, Ling/AGR-4917-2022; Yu, Yue/JWP-9103-2024;
   Wang, Ling/KBA-9814-2024
OI Wang, Ling/0000-0003-0272-2974; Wang, Ling/0000-0003-0272-2974
FU Innovation Ability Improvement Project of Science and Technology Small
   and Medium Enterprises in Shandong Province [2022TSGC2557]; Research
   Project of Education Department of Zhejiang Province [Y202248907]; Basic
   Scientific Research Project of Wenzhou City [G20220004]; Graduate
   Scientific Research Foundation of Wenzhou University [3162023003057]
FX & nbsp;This work was supported by the Innovation Ability Improvement
   Project of Science and Technology Small and Medium Enterprises in
   Shandong Province (Grant no. 2022TSGC2557); Research Project of
   Education Department of Zhejiang Province (Grant no. Y202248907); Basic
   Scientific Research Project of Wenzhou City (Grant no. G20220004) and
   Graduate Scientific Research Foundation of Wenzhou University (Grant no.
   3162023003057).
CR AMBEKAR AG, 1987, MECH MACH THEORY, V22, P453, DOI 10.1016/0094-114X(87)90062-0
   Bedi GS, 2011, P I MECH ENG C-J MEC, V225, P2700, DOI 10.1177/0954406211404102
   Cubillo JP, 2005, MECH MACH THEORY, V40, P131, DOI 10.1016/j.mechmachtheory.2004.07.004
   Cui RJ, 2021, P I MECH ENG C-J MEC, V235, P2715, DOI 10.1177/0954406220960789
   Ding HF, 2009, MECH MACH THEORY, V44, P122, DOI 10.1016/j.mechmachtheory.2008.02.008
   Galan-Marin G, 2007, NEURAL PROCESS LETT, V26, P133, DOI 10.1007/s11063-007-9047-8
   He LY, 2019, J MECH SCI TECHNOL, V33, P4899, DOI 10.1007/s12206-019-0930-9
   He P, 2001, DAC21067 DETC2001, P551
   Kamesh VV, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037628
   Liu H, 2018, J INTELL ROBOT SYST, V89, P343, DOI 10.1007/s10846-017-0564-z
   Lohumi MK, 2015, SADHANA-ACAD P ENG S, V40, P335, DOI 10.1007/s12046-015-0344-z
   RAO AC, 1988, INDIAN J TECHNOL, V26, P105
   Shukla A, 2020, AUST J MECH ENG, V18, P45, DOI 10.1080/14484846.2017.1374815
   Sun LB, 2022, ADV MECH ENG, V14, DOI 10.1177/16878132221131193
   Sun W, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018778404
   Sun W, 2017, J ADV MECH DES SYST, V11, DOI 10.1299/jamdsm.2017jamdsm0061
   Sunkari RP, 2006, J MECH DESIGN, V128, P1246, DOI 10.1115/1.2336253
   UICKER JJ, 1975, MECH MACH THEORY, V10, P375, DOI 10.1016/0094-114X(75)90037-3
   Wang YX, 2022, MECH SCI, V13, P585, DOI 10.5194/ms-13-585-2022
   Xiao RB, 2005, J COMPUT INF SCI ENG, V5, P18, DOI 10.1115/1.1846057
   Yang F, 2012, MECH MACH THEORY, V49, P298, DOI 10.1016/j.mechmachtheory.2011.09.008
   Yang P, 2015, SOFT COMPUT, V19, P217, DOI 10.1007/s00500-014-1244-6
   Yang P, 2009, ENG COMPUT-GERMANY, V25, P397, DOI 10.1007/s00366-009-0132-7
   Yi HJ, 2021, P I MECH ENG C-J MEC, V235, P5421, DOI 10.1177/0954406220977560
   Yu LCA, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01918-y
   Yu LC, 2022, MECH BASED DES STRUC, V50, P4348, DOI 10.1080/15397734.2020.1835486
   Zeng KH, 2014, MECH MACH THEORY, V72, P25, DOI 10.1016/j.mechmachtheory.2013.09.011
NR 27
TC 0
Z9 0
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16410-w
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700003
DA 2024-07-18
ER

PT J
AU Yang, M
   Zhang, JX
   Shi, Y
   Liu, B
   Guo, LX
   Yu, ZP
   Sheng, B
   Ma, LZ
AF Yang, Meng
   Zhang, Jia-Xiu
   Shi, Yi
   Liu, Bo
   Guo, Le-Xin
   Yu, Zhi-Peng
   Sheng, Bin
   Ma, Li-Zhuang
TI Framework of personalized layout for a museum exhibition hall
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital museum; Personalized recommendation; Layout design; System
   optimization; Module design
AB In order to generate a highly personalized, interactive and time-independent layout of artifacts in museums, to solve the limitations of real-world museums in terms of places, layouts and exhibition forms, to enrich the functions of existing digital museums, and to use the layout in digital museums to better guide the layout in real museums, a framework for personalized layout of museum exhibition halls is proposed. The framework consists of five modules: information preparation, personalized recommendation, random placement, optimization, and user interaction. The personalized recommendation module uses neural networks to train personalized recommendation models; the random placement module includes the layout of exhibit cases in the exhibition hall and the random filling of exhibit cases with artifacts, and proposes the Placement depends on Integrated path (PIP) algorithm. The optimization module includes efficiency optimization and rendering optimization; the user interaction module includes personal information collection, roaming, map navigation, and exhibit interaction functions. The experimental results show that the layout generated by this framework has a high degree of realism, scene loading speed and smoothness of online viewing, and the efficiency of artifact screening is improved to 7 times compared with that before optimization; the user tuning results show that more than 85% of people give realistic or very realistic evaluation to the layout, and the framework and algorithm in the paper can realize the personalized recommendation of artifacts and exhibition hall layout in a realistic, effective, real-time and interactive way.
C1 [Yang, Meng; Zhang, Jia-Xiu; Shi, Yi; Liu, Bo; Guo, Le-Xin; Yu, Zhi-Peng] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.
   [Yang, Meng] Natl Forestry & Grassland Adm, Engn Res Ctr Forestry Oriented Intelligent Informa, Beijing 100083, Peoples R China.
   [Sheng, Bin; Ma, Li-Zhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Beijing Forestry University; Shanghai Jiao Tong University
RP Yang, M (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.; Yang, M (corresponding author), Natl Forestry & Grassland Adm, Engn Res Ctr Forestry Oriented Intelligent Informa, Beijing 100083, Peoples R China.
EM yangmeng@bjfu.edu.cn
RI Wang, Zichao/KHX-4954-2024; li, qing/KHU-6871-2024; liu,
   miao/KGL-7043-2024; wang, yifang/KEI-3766-2024; zhang,
   xiaoyu/KEJ-0657-2024; Zhang, Yulin/KEI-1610-2024; Shen,
   Yan/KEJ-4617-2024; Zhu, Mengzhao/KFT-2345-2024; Lin, Wei/KFQ-5381-2024;
   liu, zhen/KFS-0275-2024; Liu, Zhen/KFS-2748-2024; Li,
   Yuanyuan/KEH-6935-2024; Liu, Xinru/KEH-2341-2024; yan, xu/KCY-8174-2024
OI Li, Yuanyuan/0000-0002-4955-1159; YANG, Meng/0000-0001-6439-2873
CR [Anonymous], About us
   Aoki H, 2008, ACTA ASTRONAUT, V63, P841, DOI 10.1016/j.actaastro.2007.11.001
   Artusi A, 2018, SIGNAL PROCESS-IMAGE, V63, P100, DOI 10.1016/j.image.2018.01.011
   BAKER BS, 1980, SIAM J COMPUT, V9, P846, DOI 10.1137/0209064
   Besoain F, 2021, INFORMATION, V12, DOI 10.3390/info12060244
   Carvajal DAL, 2020, J CULT HERIT
   Chao X., 2015, FORGING EQUIP MANUF, V50, P106
   Dede C, 1996, P IEEE VIRT REAL ANN, P246, DOI 10.1109/VRAIS.1996.490534
   Digital Collections, DIG COLL
   DQ Liu., 1998, MINI MICROSYSTEMS AN, V19, P20
   Gong W, 2015, CREATING PERSONAL 3D, P1193
   Gunn C, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P481
   Heath C, 2005, PUBLIC UNDERST SCI, V14, P91, DOI 10.1177/0963662505047343
   Hernández L, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P436, DOI 10.1109/CGI.2004.1309245
   Korzun D, 2019, FRONT ARTIF INTEL AP, V320, P237, DOI 10.3233/FAIA190186
   Leshchenko A., 2012, ICOFOM STUDY SER, V2012, P237
   Li B, 2022, MATH PROBL ENG
   Li X, 2022, ADV MULTIMED, V2022, DOI 10.1155/2022/3154353
   [刘海明 Liu Haiming], 2015, [图学学报, Journal of Graphics], V36, P526
   Louvre Museum Official Website, LOUVR
   Panteleris P, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.649784
   Shen Y., 2021, STUDY PROTECTION PRO, P515
   Takahashi J., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P244, DOI 10.1145/276675.276703
   Tao XH, 2011, IEEE T KNOWL DATA EN, V23, P496, DOI 10.1109/TKDE.2010.145
   THOMAS WA, 2005, ACTUAL VIRTUAL VISIT
   Wang Q. H., 2004, Virtual Reality, V7, P187, DOI 10.1007/s10055-004-0127-z
   Wojciechowski R., 2004, Proceedings of the ninth international conference on 3D Web technology, Monterey, CA, DOI [DOI 10.1145/985040.985060, https://doi.org/10.1145/985040.985060]
   Xu M., 2022, IEEE Geosci. Remote Sens. Lett., V19, P1
   Yang BX, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107804
   Yeung LHW, 2003, IEEE T IND ELECTRON, V50, P449, DOI 10.1109/TIE.2003.812285
   Younes Georges, 2017, Digital Applications in Archaeology and Cultural Heritage, V5, P1, DOI 10.1016/j.daach.2017.03.002
   Zherdev DA, 2020, VR ARCHAEOLOGICAL MU, V11310, DOI [10.1117/12.2545032, DOI 10.1117/12.2545032]
   Zhou XJ, 2012, ARTIF INTELL REV, V37, P119, DOI 10.1007/s10462-011-9222-1
NR 33
TC 0
Z9 0
U1 12
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16307-8
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000007
DA 2024-07-18
ER

PT J
AU Labbihi, I
   El Meslouhi, O
   Benaddy, M
   Kardouchi, M
   Akhloufi, M
AF Labbihi, Ismayl
   El Meslouhi, Othmane
   Benaddy, Mohamed
   Kardouchi, Mustapha
   Akhloufi, Moulay
TI Combining frequency transformer and CNNs for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Convolutional neural networks; Frequency
   transformers; Fourier transform
ID DIAGNOSIS
AB Image segmentation is one of the most challenging and difficult tasks in digital image processing. It has many medical applications such as cancerous tumors segmentation, organ segmentation, or abnormalities segmentation. Recent techniques combining convolution-based models and transformers are proposed for automatic medical segmentation tasks. These techniques achieve good results but require much time and resources. In this paper, we propose a new model to segment medical images which combines CNNs and frequency transformers in a parallel way to minimize the number of parameters and to reduce computation time. This work presents a powerful model, composed of two main branches, able to learn global-local feature interactions which are currently in a medical image. The first branch based on Frequency Transformer (FT) employs Fourier Transform instead of multi-head attention to capture global dependencies. While a no-deeper convolutional neural network (CNN) is employed to get rich local information. With a small number of parameters, the proposed model was tested on many public medical image databases and achieves state-of-the-art results for lesion/tumor segmentation tasks.
C1 [Labbihi, Ismayl; Benaddy, Mohamed] Ibn Zohr Univ, Fac Sci, LabSI Lab, Agadir 80000, Morocco.
   [El Meslouhi, Othmane] Cadi Ayyad Univ, Natl Sch Appl Sci, SARS Grp, Safi 46000, Morocco.
   [Kardouchi, Mustapha; Akhloufi, Moulay] Univ Moncton, Dept Comp Sci, PRIME Lab, 18 Antonine Maillet Ave, Moncton, NB E1A 3E9, Canada.
C3 Ibn Zohr University of Agadir; Cadi Ayyad University of Marrakech;
   University of Moncton
RP Labbihi, I (corresponding author), Ibn Zohr Univ, Fac Sci, LabSI Lab, Agadir 80000, Morocco.
EM ismayl.labbihi@edu.uiz.ac.ma; o.elmeslouhi@uca.ma; m.benaddy@uiz.ac.ma;
   mustapha.kardouchi@umoncton.ca; moulay.akhloufi@umoncton.ca
RI Benaddy, Mohamed/N-9093-2016
OI Benaddy, Mohamed/0000-0002-1007-0120
CR Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Alom MZ, 2018, arXiv
   An FP, 2019, CONTRAST MEDIA MOL I, V2019, DOI 10.1155/2019/6134942
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bi L, 2019, PATTERN RECOGN, V85, P78, DOI 10.1016/j.patcog.2018.08.001
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chu JL, 2014, LECT NOTES COMPUT SC, V8436, P59, DOI 10.1007/978-3-319-06483-3_6
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dai Y, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081384
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, P1748, DOI 10.1109/WACV51458.2022.00181
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heckbert P., 1995, COMPUT GRAPH-UK, V2, P15
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Huang C-H, 2021, ARXIV
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Huang XS, 2020, PR MACH LEARN RES, V119
   Isensee F, 2019, ARXIV
   Jena B, 2023, MULTIMED TOOLS APPL, V82, P10723, DOI 10.1007/s11042-022-13730-1
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Juneja P., 2016, International Journal of Computer Applications, V146, P22, DOI [DOI 10.5120/IJCA2016910808, 10.5120/ijca2016910808]
   Kayalibay B., 2017, arXiv
   Lee-Thorp J, 2021, ARXIV
   Li H, 2019, IEEE J BIOMED HEALTH, V23, P527, DOI 10.1109/JBHI.2018.2859898
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li Y, 2021, VISUAL COMPUT, ppp1
   Lin A, 2021, ARXIV
   Liu WT, 2022, LECT NOTES COMPUT SC, V13435, P235, DOI 10.1007/978-3-031-16443-9_23
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo H, 2022, P MACH LEARN RES PML, P808
   Masulli F, 1999, ARTIF INTELL MED, V16, P129, DOI 10.1016/S0933-3657(98)00069-4
   Nasreen G, 2023, MULTIMED TOOLS APPL, V82, P10921, DOI 10.1007/s11042-022-13756-5
   Paszke A, 2019, ADV NEUR IN, V32
   Patil DD., 2013, IJCSMC, V2, P22
   Rao YM, 2021, Advances in neural information processing systems, V34
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarker MMK, 2018, LECT NOTES COMPUT SC, V11071, P21, DOI 10.1007/978-3-030-00934-2_3
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shamir RR, 2019, ARXIV
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Srivastava Rupesh Kumar, 2015, arXiv
   Sun QX, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7467261
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Taud H., 2018, Geomatic approaches for modeling land change scenarios, DOI [DOI 10.1007/978-3-319-60801-3_27, DOI 10.1007/978-3-319-60801-327]
   Tomar NK, 2023, IEEE T NEUR NET LEAR, V34, P9375, DOI 10.1109/TNNLS.2022.3159394
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Valanarasu Jeya Maria Jose, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P363, DOI 10.1007/978-3-030-59719-1_36
   Vaswani A, 2017, ADV NEUR IN, V30
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang L., 2021, arXiv
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   WINOGRAD S, 1976, P NATL ACAD SCI USA, V73, P1005, DOI 10.1073/pnas.73.4.1005
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xu S., 2021, P IEEE INT C BIOINF, P1601, DOI [10.1109/BIBM52615.2021.9669734, DOI 10.1109/BIBM52615.2021.9669734]
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou H, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3050, DOI 10.1109/ICASSP39728.2021.9413680
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 70
TC 0
Z9 0
U1 18
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21197
EP 21212
DI 10.1007/s11042-023-16279-9
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900014
DA 2024-07-18
ER

PT J
AU Wang, Y
   Wang, HX
AF Wang, Yu
   Wang, Hongxia
TI A face template: Improving the face generation quality of multi-stage
   generative adversarial networks using coarse-grained facial priors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-face synthesis; Generative adversarial networks; Face template;
   Coarse-grained feature
AB The current text-to-face synthesis models only utilize text descriptions for image synthesis, neglecting the prior information of basic facial features. This leads to insufficient learning of both coarse-grained facial features, such as face shape and positions of the basic organs, and fine-grained facial features, such as facial wrinkles and hair textures, by the generators in each stage. As a result, the quality of the generated faces is low. To address this issue, we propose a generic face template. It includes only common facial information, such as face contour, shapes and relative positions of the basic organs. Moreover, to embed the face template into the first-stage generator of three stages for assisting face generation, we design a Facial Coarse-grained Feature Excitation Module (FCFEM). FCFEM extracts the coarse-grained feature channel weights of the face template. And it performs channel recalibration on the intermediate feature maps of the first-stage generator. This helps to generate more precise and complete initial face images. Therefore, it can enhance the ability of the generators in the latter two stages to learn fine-grained features. Experiments on the Multi-Modal CelebA-HQ dataset demonstrate that the multi-stage models using our method generate face images with higher quality and realism compared to the original models. They also achieve higher semantic consistency between generated images and text descriptions.
C1 [Wang, Yu; Wang, Hongxia] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430030, Peoples R China.
C3 Wuhan University of Technology
RP Wang, HX (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430030, Peoples R China.
EM whx_green@whut.edu.cn
CR Chen X, 2019, ARXIV
   Cheng J., 2020, IEEE C COMP VIS PATT, P10911
   Gatt A, 2018, ARXIV
   Goodfellow I. J., 2014, ARXIV
   Hensel M, 2017, ADV NEUR IN, V30
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Li BY, 2019, ADV NEUR IN, V32
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Luo XD, 2022, NEURAL NETWORKS, V155, P155, DOI 10.1016/j.neunet.2022.08.016
   Nasir OR, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P58, DOI [10.1109/BigMM.2019.00-42, 10.1109/BigMM.2019.00020]
   Odena A, 2017, PR MACH LEARN RES, V70
   Park H., 2018, ARXIV
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Qiao X, 2021, 2021 16 IEEE INT C A, P1
   Radford A., 2015, ARXIV
   Reed S, 2016, PR MACH LEARN RES, V48
   Ruan SL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13940, DOI 10.1109/ICCV48922.2021.01370
   Stap D, 2020, ARXIV
   Sun JX, 2022, PROC CVPR IEEE, P18666, DOI 10.1109/CVPR52688.2022.01813
   Sun JX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2290, DOI 10.1145/3474085.3475391
   Tao M, 2022, PROC CVPR IEEE, P16494, DOI 10.1109/CVPR52688.2022.01602
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Y., 2018, P EUROPEAN C COMPUTE
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Xing Di, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P55, DOI 10.1109/TBIOM.2019.2961926
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Yuan Z, 2021, INT C PATT RECOG, P1657, DOI 10.1109/ICPR48806.2021.9412022
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 36
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21677
EP 21693
DI 10.1007/s11042-023-16183-2
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500008
DA 2024-07-18
ER

PT J
AU Yin, FL
   Xing, TT
   Yao, ZB
   Fu, RL
   Li, ST
AF Yin, Fulian
   Xing, Tongtong
   Yao, Zebin
   Fu, Ruiling
   Li, Sitong
TI HGER: a heterogeneous information-based recommendation with graph
   enhanced representation for TV program
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV program recommendation; Heterogeneous information; Graph structure;
   Neural network
AB With the development of online programming, the broadcast TV industry has experienced some negative impacts. The program recommendation has become crucial to boost the industry's construction. While there have been many researches on program recommendation, there are still challenges to overcome such as alleviating the sparsity of user interaction data and improving the dynamics and generalizability of the recommendation model. In this paper, we propose a novel approach for TV program recommendation called heterogeneous information-based recommendation with graph enhanced representation (HGER). The HGER model mainly consists of two main modules. One is the program encoder which uses the program's heterogeneous information and attention mechanism to extract personalized content and considers high-order neighbor program representations through a graph structure. The other is the user encoder which utilizes the user's historical viewing behaviors and combines it with the graph structure to represent the high-order neighbor user. Thus, we implement an enhanced representation for both the program and user. Through extensive experiments on a real-world dataset, the results of AUC, NDCG and HR demonstrate that our approach can effectively enhance the dynamics and generalizability of the model for TV program recommendations.
C1 [Yin, Fulian] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
   [Yin, Fulian; Xing, Tongtong; Yao, Zebin; Fu, Ruiling; Li, Sitong] Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.
C3 Communication University of China; Communication University of China
RP Li, ST (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.
EM yinfulian@cuc.edu.cn; xtt@cuc.edu.cn; zebin.yao@cuc.edu.cn;
   fff_0523@cuc.edu.cn; sitongli@cuc.edu.cn
RI li, sitong/GXV-4288-2022
FU National Key Research and Development Program [2021YFF0901705,
   2021YFF0901700]; State Key Laboratory of Media Convergence and
   Communication, Communication University of China; Fundamental Research
   Funds for the Central Universities; High-quality and Cutting-edge
   Disciplines Construction Project for Universities in Beijing (Internet
   Information, Communication University of China)
FX The work was supported by the National Key Research and Development
   Program (No. 2021YFF0901705, 2021YFF0901700); the State Key Laboratory
   of Media Convergence and Communication, Communication University of
   China; the Fundamental Research Funds for the Central Universities; the
   High-quality and Cutting-edge Disciplines Construction Project for
   Universities in Beijing (Internet Information, Communication University
   of China).
CR Ahmed U, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3506701
   Ahmed U, 2022, FUTURE GENER COMP SY, V130, P106, DOI 10.1016/j.future.2021.12.008
   Ahmed U, 2022, FUTURE GENER COMP SY, V127, P70, DOI 10.1016/j.future.2021.08.028
   Ahmed U, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.642347
   Amiripalli SS., 2022, INT J SENS WIREL COM, V12, P230, DOI [10.2174/2210327911666210118143058, DOI 10.2174/2210327911666210118143058]
   Baichuan Liu, 2021, Journal of Physics: Conference Series, V1754, DOI 10.1088/1742-6596/1754/1/012148
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   Das D., 2017, International Journal of Computer Applications, V160, P6, DOI [10.5120/ijca2017913081, DOI 10.5120/IJCA2017913081]
   Defferrard Michael, 2016, arXiv
   Gan MX, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114695
   Gao JL, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3451397
   Gao L, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3378
   Gao M, 2018, ACM/SIGIR PROCEEDINGS 2018, P715, DOI 10.1145/3209978.3209987
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   Han XT, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P565, DOI 10.1145/3447548.3467450
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/3077136.3080777
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hu LM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102142
   Hui B, 2022, APPL INTELL, V52, P954, DOI 10.1007/s10489-021-02363-w
   Khoali M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060878
   Khoie MR, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7100966
   Kumar Pushpendra, 2018, International Journal of Information Technology, V10, P495, DOI 10.1007/s41870-018-0138-8
   Li L, 2022, CCF T PERVAS COMPUT, V4, P76, DOI 10.1007/s42486-021-00083-1
   Li SY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040638
   Li ZX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P408, DOI 10.1145/3404835.3462963
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Liu YW, 2021, INT J INTELL SYST, V36, P3174, DOI 10.1002/int.22412
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Lu Lingyun, 2023, WSDM '23: Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, P526, DOI 10.1145/3539597.3570482
   Ma MY, 2022, APPL INTELL, V52, P1913, DOI 10.1007/s10489-021-02497-x
   Mirhasani M., 2020, J ADV COMPUT ENG TEC, V6, P221
   Patel K, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105779
   Paul Dip, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P279, DOI 10.1007/978-981-13-7403-6_26
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Tran Q, 2022, NEUROCOMPUTING, V479, P89, DOI 10.1016/j.neucom.2022.01.023
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Reshma R, 2016, INT CONF RECENT
   Shao YN, 2021, PATTERN RECOGN LETT, V145, P157, DOI 10.1016/j.patrec.2021.02.008
   Shen R, 2022, ARAB J SCI ENG, V47, P9931, DOI 10.1007/s13369-021-05933-9
   Suyun Wei, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P2038, DOI 10.1109/CSSS.2012.507
   Thakker U, 2021, MULTIMED TOOLS APPL, V80, P28647, DOI 10.1007/s11042-021-10965-2
   Wang RX, 2017, ADKDD'17: 23RD ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2017), DOI 10.1145/3124749.3124754
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Widiyaningtyas T, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00425-x
   Wu CH, 2020, CCF T PERVAS COMPUT, V2, P178, DOI 10.1007/s42486-020-00044-0
   Xie LJ, 2021, COMPLEX INTELL SYST, V7, P1241, DOI 10.1007/s40747-021-00315-y
   Xie RB, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1168, DOI 10.1145/3488560.3498371
   Yadav V, 2021, J SCI IND RES INDIA, V80, P159
   Yi P, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P231, DOI 10.1109/ISCIT.2016.7751627
   Yin FL, 2022, KNOWL INF SYST, V64, P1759, DOI 10.1007/s10115-022-01695-4
   Yin FL, 2022, APPL INTELL, V52, P19, DOI 10.1007/s10489-021-02241-5
   Zhang S, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102453
   Zhao W, 2020, IEEE T CYBERNETICS, V50, P4680, DOI 10.1109/TCYB.2019.2896766
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
   Zhou YJ, 2021, WORLD WIDE WEB, V24, P1465, DOI 10.1007/s11280-021-00924-0
   Zhu QN, 2019, AAAI CONF ARTIF INTE, P5973
NR 59
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19391
EP 19414
DI 10.1007/s11042-023-16315-8
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900015
DA 2024-07-18
ER

PT J
AU Niu, YZ
   Zheng, YM
   Wang, ZL
   Zhong, MZ
   Zhao, TS
AF Niu, Yuzhen
   Zheng, Yuming
   Wang, Zhenlong
   Zhong, Mengzhen
   Zhao, Tiesong
TI Blind consumer video quality assessment with spatial-temporal perception
   and fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality assessment; Image quality assessment; Consumer video; User
   generated content
ID STATISTICS; ATTENTION
AB Blind quality assessment for user-generated content (UGC) or consumer videos is challenging in computer vision. Two open issues are yet to be addressed: how to effectively extract high-dimensional spatial-temporal features of consumer videos and how to appropriately model the relationship between these features and user perceptions within a unified blind video quality assessment (BVQA). To tackle these issues, we propose a novel BVQA model with spatial-temporal perception and fusion. Firstly, we develop two perception modules to extract the perceptual-distortion-related features separately from the spatial and temporal domains. In particular, the temporal-domain features are obtained with a combination of 3D ConvNet and residual frames for their high efficiencies in capturing the motion-specific temporal features. Secondly, we propose a feature fusion module that adaptively combines spatial-temporal features. Finally, we map the fused features onto perceptual quality. Experimental results demonstrate that our model outperforms other advanced methods in conducting subjective video quality prediction.
C1 [Niu, Yuzhen; Zheng, Yuming; Wang, Zhenlong; Zhong, Mengzhen] Fuzhou Univ, Coll Comp & Data Sci, Fuzhou 350116, Peoples R China.
   [Niu, Yuzhen; Zhao, Tiesong] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Niu, YZ (corresponding author), Fuzhou Univ, Coll Comp & Data Sci, Fuzhou 350116, Peoples R China.; Niu, YZ (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Peoples R China.
EM yuzhenniu@gmail.com; zyuming98@gmail.com; t.zhao@fzu.edu.cn
FU National Natural Science Foundation of China [62072110, 61972097,
   U21A20472]; Major Science and Technology project of Fujian Province
   (China) [2021HZ022007]; Industry-Academy Cooperation Project
   [2021H6022]; Natural Science Foundation of Fujian Province [2020J01494]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62072110, 61972097, and U21A20472, in
   part by the Major Science and Technology project of Fujian Province
   (China) under Granted 2021HZ022007, in part by the Industry-Academy
   Cooperation Project under Grant 2021H6022, in part by the Natural
   Science Foundation of Fujian Province under Grant 2020J01494.
CR Argyropoulos S, 2011, INT WORK QUAL MULTIM, P31, DOI 10.1109/QoMEX.2011.6065708
   Chen C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1277, DOI 10.1145/2964284.2964302
   Chen PF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P834, DOI 10.1145/3394171.3413717
   Chen ZF, 2012, IEEE T IMAGE PROCESS, V21, P1123, DOI 10.1109/TIP.2011.2168411
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Dendi SVR, 2020, IEEE T IMAGE PROCESS, V29, P5612, DOI 10.1109/TIP.2020.2984879
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   2000, VQEG M
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermens F, 2008, PSYCHOL REV, V115, P83, DOI 10.1037/0033-295X.115.1.83
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hosu V, 2017, INT WORK QUAL MULTIM
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Keimel C, 2011, INT WORK QUAL MULTIM, P49, DOI 10.1109/QoMEX.2011.6065711
   Kingma D. P., 2014, arXiv
   Korhonen J., 2018, 2018 10 INT C QUAL M, P1, DOI DOI 10.1109/QOMEX.2018.8463394
   Korhonen J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3311, DOI 10.1145/3394171.3413845
   Korhonen J, 2019, IEEE T IMAGE PROCESS, V28, P5923, DOI 10.1109/TIP.2019.2923051
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Li DQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2351, DOI 10.1145/3343031.3351028
   Li YM, 2016, IEEE T CIRC SYST VID, V26, P1044, DOI 10.1109/TCSVT.2015.2430711
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   MURDOCK BB, 1962, J EXP PSYCHOL, V64, P482, DOI 10.1037/h0045106
   Niu YZ, 2012, IEEE T CIRC SYST VID, V22, P1037, DOI 10.1109/TCSVT.2012.2189689
   Pandremmenou K, 2015, HUMAN VISION ELECT I, V9394, P486
   Park J, 2013, IEEE T IMAGE PROCESS, V22, P610, DOI 10.1109/TIP.2012.2219551
   Pinson MH, 2012, IEEE J-STSP, V6, P640, DOI 10.1109/JSTSP.2012.2215306
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Siahaan E, 2018, SIGNAL PROCESS-IMAGE, V60, P237, DOI 10.1016/j.image.2017.10.009
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinno Z, 2019, IEEE T IMAGE PROCESS, V28, P612, DOI 10.1109/TIP.2018.2869673
   Sogaard J, 2015, IEEE T CIRC SYST VID, V25, P1637, DOI 10.1109/TCSVT.2015.2397207
   Tao L, 2021, IEEE T IMAGE PROCESS, V30, P9231, DOI 10.1109/TIP.2021.3124156
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Valenzise G, 2012, IEEE T CIRC SYST VID, V22, P605, DOI 10.1109/TCSVT.2011.2171211
   Vega MT, 2017, SIGNAL PROCESS-IMAGE, V52, P20, DOI [10.1016/j.image.2016.12.001, 10.1016/jimage.2016.12.001]
   Wang YL, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901772
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JJ, 2019, J VIS COMMUN IMAGE R, V58, P353, DOI 10.1016/j.jvcir.2018.12.005
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu MN, 2020, INT CONF ACOUST SPEE, P4447, DOI [10.1109/ICASSP40776.2020.9053031, 10.1109/icassp40776.2020.9053031]
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Ying ZQ, 2021, PROC CVPR IEEE, P14014, DOI 10.1109/CVPR46437.2021.01380
   Ying ZQ, 2020, PROC CVPR IEEE, P3572, DOI 10.1109/CVPR42600.2020.00363
   You JY, 2019, IEEE IMAGE PROC, P2349, DOI [10.1109/icip.2019.8803395, 10.1109/ICIP.2019.8803395]
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
   Zhu KF, 2015, IEEE T CIRC SYST VID, V25, P533, DOI 10.1109/TCSVT.2014.2363737
NR 61
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18969
EP 18986
DI 10.1007/s11042-023-16242-8
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900001
DA 2024-07-18
ER

PT J
AU Abbas, Z
   Raina, P
AF Abbas, Zaheer
   Raina, Princess
TI A wavelet enhanced approach with ensemble based deep learning approach
   to detect air pollution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PM2; 5; Air pollution; Ensemble Empirical Mode Decomposition; Deep Long
   short-term memory neural network; Prediction; Weighted forecasting model
ID MODEL
AB Air pollution is one of the most serious environmental problems worldwide. Especially, PM2.5 cannot be blocked by filtration system of respiratory tract to cause serious threat to public health. Considering the serious impact of air pollution on human health and life, air pollutant concentration forecast has been drawn great attention because it can provide people with information of air quality. In order to improve the accuracy of air pollutant concentration forecast, this study proposes a new Ensemble Empirical Mode Decomposition (EEMD) multi-step forecasting model is proposed. Initially, input data are decomposed by enhanced empirical wavelet transform (EEWT) to increase the dimensionality of the data. Next, EEWT-NLSTM, EEWT-DLSTM and EEWT-Bi-LSTM models are constructed using wavelet decomposition results and Nested Long short-term memory neural network (NLSTM), Deep Long short-term memory neural network (DLSTM), and Bi-directional long-short term memory neural network (Bi-LSTM), respectively, followed by comparison and contrast of the prediction results. Three single prediction models are incorporated into combined weighted forecasting model by weight assignment, it improves the prediction accuracy. To accurately assess effectiveness of the experimental model, three evaluation metrics, Mean Absolute Percentage Error (MAPE), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE), are used in this paper to quantitatively evaluate prediction performance of proposed model. For the prediction of PM2.5, the proposed model achieved a Mean Absolute Error (MAE) of 0.047428.
C1 [Abbas, Zaheer; Raina, Princess] Baba Ghulam Shah Badshah Univ, Dept Math Sci, Rajouri, India.
RP Abbas, Z (corresponding author), Baba Ghulam Shah Badshah Univ, Dept Math Sci, Rajouri, India.
EM zamlectures@gmail.com
RI Abbas, Zaheer/JDX-0089-2023
CR Aladag E, 2021, URBAN CLIM, V39, DOI 10.1016/j.uclim.2021.100930
   Badyda AJ, 2017, ADV EXP MED BIOL, V944, P9, DOI 10.1007/5584_2016_55
   Chang YS, 2020, ENVIRON SCI POLLUT R, V27, P38155, DOI 10.1007/s11356-020-09855-1
   Dairi A, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3091511
   Du ZJ, 2021, ATMOS POLLUT RES, V12, DOI 10.1016/j.apr.2021.101153
   Fan SR, 2021, INFORMATION, V12, DOI 10.3390/info12050210
   Fang S, 2022, ENVIRON SCI POLLUT R, P1
   Fu ML, 2021, ENVIRON SCI POLLUT R, V28, P64818, DOI 10.1007/s11356-021-15574-y
   Heydari A, 2022, CLEAN TECHNOL ENVIR, V24, P607, DOI 10.1007/s10098-021-02080-5
   Janarthanan R, 2021, SUSTAIN CITIES SOC, V67, DOI 10.1016/j.scs.2021.102720
   Kalajdjieski J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244142
   Kim S, 2016, INT J FORECASTING, V32, P669, DOI 10.1016/j.ijforecast.2015.12.003
   Law EW, 2016, SOL ENERGY, V125, P267, DOI 10.1016/j.solener.2015.12.031
   Lin CY, 2021, ATMOS POLLUT RES, V12, DOI 10.1016/j.apr.2021.03.008
   Liu BC, 2021, ATMOS POLLUT RES, V12, DOI 10.1016/j.apr.2021.101144
   Sajjadi SA, 2017, METHODSX, V4, P372, DOI 10.1016/j.mex.2017.09.006
   Sun W, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103348
   Tao Q, 2019, IEEE ACCESS, V7, P76690, DOI 10.1109/ACCESS.2019.2921578
   Zhang ZD, 2021, ENVIRON SCI POLLUT R, V28, P39409, DOI 10.1007/s11356-021-12657-8
   Zhou QP, 2014, SCI TOTAL ENVIRON, V496, P264, DOI 10.1016/j.scitotenv.2014.07.051
NR 20
TC 2
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17531
EP 17555
DI 10.1007/s11042-023-16167-2
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700004
DA 2024-07-18
ER

PT J
AU Liu, LQ
   Wang, XH
   Bao, QF
   Li, XS
AF Liu, Linqi
   Wang, Xiuhui
   Bao, Qifu
   Li, Xuesheng
TI Behavior detection and evaluation based on multi-frame MobileNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Behavior detection; Multi-frame MobileNet; Depth-wise convolution;
   Point-wise convolution
ID RECOGNITION
AB Video-based behavior detection is an important research direction in computer vision, which has great application potential in intelligent video surveillance, sports behavior evaluation, gait recognition, and so on. However, due to the complexity of video content and background, video behavior detection and evaluation face many challenges and are still in their early stages. This paper proposes a novel multi-frame MobileNet model, which describes the internal differences of similar behaviors by introducing multiple continuous frames of behaviors to be detected, and realizes fine-grained behavior detection and evaluation. Firstly, using energy trend images (ETIs) of behaviors as features, multiple continuous frames of the target video are fed into the proposed network to explore the relationship between adjacent frames. Then,in the weighted point-wise convolution stage, by adding a fade-in factor to the timeline for providing different weights to each involved frame, which makes better use of the progressive relationship between behavior frames at different times. Finally, the effectiveness of the proposed method is verified by comparative experiments on multiple video data sets such as UCF101, HMDB51 and CASIA-B.
C1 [Liu, Linqi; Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
   [Bao, Qifu; Li, Xuesheng] Key Lab Safety Engn & Technol Res Zhejiang Prov, Hangzhou 310027, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn; qfbao@zjsafety.com
OI Wang, Xiuhui/0000-0003-1773-9760
FU Key R amp;D project of Zhejiang Province, China [2021C03151]; Natural
   Science Foundation of Zhejiang Province [Y20F020113]
FX This research was funded by the Key R & D project of Zhejiang Province,
   China, grant number No. 2021C03151 and the Natural Science Foundation of
   Zhejiang Province, grant number No.Y20F020113.
CR Akpinar KN, 2020, 2020 INT C ELECT COM, P1, DOI DOI 10.1109/ICECCE49384.2020.9179404
   An J, 2021, IEEE SENS J, P1
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   CHEN Y, 2023, IEEE T CIRC SYST VID, P1
   Nguyen C, 2022, IEEE COMPUT SOC CONF, P3248, DOI 10.1109/CVPRW56347.2022.00367
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Du B, 2021, IEEE INT CONF ELECTR, P40, DOI 10.1109/ICEIEC51955.2021.9463822
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Endah Sukmawati Nur, 2020, 2020 4 INT C INFORMA, P1
   Gomes R, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P244, DOI 10.1109/EIT51626.2021.9491910
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Howard A. G., 2017, arXiv
   Hu K, 2023, ARTIF INTELL REV, V56, P1833, DOI 10.1007/s10462-022-10210-8
   Juergen S., 2014, IDSIA0314, V61, P04
   Kacem A, 2018, IEEE T PATTERN ANAL, P09
   Karen S., 2014, ADV NEURAL INFORM PR, V1, P06
   Kong LT, 2020, IEEE T CIRC SYST VID, V30, P532, DOI 10.1109/TCSVT.2019.2893318
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li HF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3147513
   Limin W, 2016, TEMPORAL SEGMENT NET, V9912, P10
   Liu W, 2022, SUSTAINABILITY-BASEL, V14
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rabano SL, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666300
   Rahadian Raya, 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P21, DOI 10.1109/ISRITI48646.2019.9034664
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Kumar DS, 2020, INT J AMBIENT ENERGY, DOI 10.1080/01430750.2020.1730961
   Silva Mateus O., 2022, 2022 IEEE International Conference on Consumer Electronics - Taiwan, P321, DOI 10.1109/ICCE-Taiwan55306.2022.9869197
   Singh J., 2019, J VIS COMMUN IMAGE R, V66, P12
   Soomro K., 2012, CoRR, V2
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X, 2022, APPL INTELL
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   Xu BH, 2019, IEEE T IMAGE PROCESS, V28, P4941, DOI 10.1109/TIP.2019.2917283
   Yu SQ, 2006, INT C PATT RECOG, P441
NR 37
TC 1
Z9 1
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15733
EP 15750
DI 10.1007/s11042-023-16150-x
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300002
DA 2024-07-18
ER

PT J
AU Nawaz, M
   Javed, A
   Irtaza, A
AF Nawaz, Marriam
   Javed, Ali
   Irtaza, Aun
TI Convolutional long short-term memory-based approach for deepfakes
   detection from videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Deepfakes; Bi-LSTM; Deep learning; Multimedia forensic
ID SALIENCY DETECTION; IMAGES
AB The great development in the area of Artificial Intelligence (AI) has introduced tremendous advancements in information technology. Moreover, the introduction of lightweight machine learning (ML) techniques allows the applications to work with limited storage and processing power. Deepfakes is among the most famous type of such applications of this era which generates a large amount of fake and modified audiovisual data. The creation of such fake data has introduced a serious risk to the security and confidentiality of humans all around the globe. Accurate detection and classification of actual and deepfakes content is a challenging task due to the progression of Generative adversarial networks (GANs) which produce such convincing manipulated content that it's impossible for people to recognize it through their naked eyes. In this work, we have presented deep learning (DL)-based approach namely the convolutional long short-term memory (C-LSTM) method for deepfakes detection from videos. More specifically, the spatial information from the input sample is calculated by employing various pre-trained models like VGG16, VGG19, ResNet50, XceptionNet, and GoogleNet, DenseNet. Further, we have proposed a novel feature descriptor called the Dense-Swish-Net121. Whereas the Bi-LSTM model is utilized to compute the temporal information. Lastly, the results are predicted based on both the frame level and temporal level information to make the final decision. A detailed comparison of all CNN models with the Bi-LSTM approach is performed and has confirmed through the reported results that the proposed Dense-Swish-Net121 with Bi-LSTM approach performs well for deepfakes detection.
C1 [Nawaz, Marriam; Javed, Ali] UET Taxila, Dept Software Engn, Taxila 47050, Punjab, Pakistan.
   [Irtaza, Aun] UET Taxila, Dept Comp Sci, Taxila 47050, Punjab, Pakistan.
RP Nawaz, M (corresponding author), UET Taxila, Dept Software Engn, Taxila 47050, Punjab, Pakistan.
EM marriam.nawaz@uettaxila.edu.pk
RI Nawaz, Marriam/JVD-9229-2023; JAVED, ALI/X-3334-2019
FU Punjab HEC of Pakistan [PHEC/ARA/PIRCA/20527/21]; University of
   California Berkeley
FX This work was supported by grant of Punjab HEC of Pakistan via Award No.
   (PHEC/ARA/PIRCA/20527/21). We would like to thank Prof. Hany Farid from
   the University of California Berkeley to provide us with their World
   Leaders Dataset for performance evaluation
CR Agarwal S., 2019, P IEEE C COMP VIS PA, P38, DOI DOI 10.1109/ICCV.2015.425
   Agarwal S., 2019, CVPR WORKSHOPS, V1
   Albahli S, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.957961
   Albahli S, 2021, CMC-COMPUT MATER CON, V67, P1333, DOI 10.32604/cmc.2021.014691
   ALBAYAYDH WS, 2022, CHI C HUM FACT COMP, P1
   [Anonymous], 2020, arXiv
   Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Carvalho T, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P866, DOI 10.1109/ICMLA.2017.00-47
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen ZK, 2021, PROC CVPR IEEE, P9010, DOI 10.1109/CVPR46437.2021.00890
   Chindaudom A., 2020, Joint ICIEV icIVPR, P1
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Ganguly S, 2022, EXPERT SYST APPL, V210, DOI 10.1016/j.eswa.2022.118423
   Hernandez-Ortega J., 2020, arXiv
   Ilyas H, 2023, APPL SOFT COMPUT, V136, DOI 10.1016/j.asoc.2023.110124
   Khalid F, 2023, EXPERT SYST APPL, V222, DOI 10.1016/j.eswa.2023.119843
   Kohli A, 2021, MULTIMED TOOLS APPL, V80, P18461, DOI 10.1007/s11042-020-10420-8
   Kolagati S., 2022, INT J INF MANAG DATA, V2, P100054
   Korshunov P., 2018, arXiv
   Li YX, 2020, IEEE T MULTIMEDIA, V22, P1153, DOI 10.1109/TMM.2019.2940851
   Li YX, 2021, IEEE T CIRC SYST VID, V31, P2315, DOI 10.1109/TCSVT.2020.3023080
   Trinh L, 2021, IEEE WINT CONF APPL, P1972, DOI 10.1109/WACV48630.2021.00202
   Masood M, 2023, APPL INTELL, V53, P3974, DOI 10.1007/s10489-022-03766-z
   Masoodi M, 2021, INT SYMP TECHNOL SOC, DOI 10.1109/ISTAS52410.2021.9629182
   Mehta V, 2021, 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI '21 COMPANION), P61, DOI 10.1145/3397482.3450726
   Nawaz M, 2023, VISUAL COMPUT, V39, P6323, DOI 10.1007/s00371-022-02732-7
   Nawaz M, 2022, INT ARAB J INF TECHN, V19, P891, DOI 10.34028/iajit/19/6/6
   Nawaz M, 2021, CMC-COMPUT MATER CON, V69, P1927, DOI 10.32604/cmc.2021.018052
   Nawaz M, 2021, J INTELL FUZZY SYST, V40, P10351, DOI 10.3233/JIFS-191700
   Nawaz M, 2021, MULTIMED TOOLS APPL, V80, P28953, DOI 10.1007/s11042-021-11120-7
   Nazir Tahira, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P33, DOI 10.1109/ICAI52203.2021.9445228
   Nazir T, 2022, APPL SOFT COMPUT, V131, DOI 10.1016/j.asoc.2022.109778
   Nguyen T. T., 2019, arXiv
   Ranjan P, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2020), P86, DOI 10.1109/ICICT50521.2020.00021
   Roy R, 2022, 3D CNN ARCHITECTURES
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun ZK, 2021, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR46437.2021.00361
   Theckedath D., 2020, SN COMPUT SCI, V1, P1
   Uga B., 2019, Towards Trustworthy AI: A proposed set of design guidelines for understandable, trustworthy and actionable AI
   Wang GT, 2021, PROC CVPR IEEE, P15114, DOI 10.1109/CVPR46437.2021.01487
   Xu Y, 2022, IEEE WINT CONF APPL, P379, DOI 10.1109/WACVW54805.2022.00044
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang T, 2022, MECCANICA, V57, P2101, DOI 10.1007/s11012-022-01554-0
   Zhang WG, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020249
NR 49
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16977
EP 17000
DI 10.1007/s11042-023-16196-x
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500003
DA 2024-07-18
ER

PT J
AU Yu, Z
   Peng, JY
AF Yu, Zhe
   Peng, Jinye
TI Adaptive multi-information distillation network for image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Attention mechanism; Information distillation; Deep
   learning
ID VISIBILITY; QUALITY; WEATHER
AB Image dehazing is a challenging low-level vision task that estimates potentially haze-free images from hazy images. In recent years, convolutional neural network-based methods have achieved impressive results in image dehazing. However, most existing image dehazing methods tend to train networks on large paired artificial datasets and directly generate a visually plausible result. These methods obtain high performance in homogeneous haze images, but often fail in real haze images, especially for haze images with large inhomogeneous areas. We find that the main possible reason is that these methods did not distinguish between haze areas of different densities when extracting haze features. To this end, in this paper, we present a highly generalized dehazing network that utilizes dense combinations of information distillation to obtain more effective and diversified features. We devise a multi-information distillation module to compensate for the limitations caused by inhomogeneous haze, which can adaptively assign weights to different haze regions according to the importance of the features. After 3 times of channel segmentation operations at a fixed ratio, the important features are gradually extracted while relatively unimportant features will be retained. To further improve the low-level features that are easily lost during the training process, we design an enhanced spatial-channel attention module to guide the network to focus on the recovery of detailed information. Benefiting from the property of this network, we can more easily recover different types of haze images. Extensive experimental results demonstrate that our method surpasses most state-of-the-art dehazing methods in terms of visual quality, quantitative index, and various datasets.
C1 [Yu, Zhe; Peng, Jinye] Northwest Univ, Sch Informat Sci & Technol, 1 Xuefu Ave, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Peng, JY (corresponding author), Northwest Univ, Sch Informat Sci & Technol, 1 Xuefu Ave, Xian 710127, Shaanxi, Peoples R China.
EM 202210327@stumail.nwu.edu.cn; pjy@nwu.edu.cn
RI Lu, Yi/KEJ-2560-2024; xu, liu/KCL-1154-2024; Yuan, Ye/KBC-9835-2024;
   zhang, xiaoyu/KEJ-0657-2024; Yun, Wang/KHM-3009-2024; wang,
   wenjing/KEH-0575-2024; Qi, Ling/KHE-3068-2024; zhang,
   jiahao/KEE-9357-2024
OI Yuan, Ye/0009-0008-1640-7047; 
FU National Natural Science Foundation of China; Key Research and
   Development Program of Shaanxi; Program for Changjiang Scholars and
   Innovative Research Team in University
FX The research has been supported by the National Natural Science
   Foundation of China, the Key Research and Development Program of
   Shaanxi, and the Program for Changjiang Scholars and Innovative Research
   Team in University.
CR Adams J, 2021, INVERSE PROBL SCI EN, V29, P1789, DOI 10.1080/17415977.2021.1880398
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bharath Raj N, 2018, SINGLE IMAGE HAZE RE, V1810
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Caraffa Laurent, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P13, DOI 10.1007/978-3-642-37447-0_2
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen L, 2019, IEEE T IMAGE PROCESS, V28, P5897, DOI 10.1109/TIP.2019.2920510
   Chen S, 2019, P IEEE CVF C COMP VI, P0
   Cui T, 2019, LECT NOTES ARTIF INT, V11743, P594, DOI 10.1007/978-3-030-27538-9_51
   Das SD, 2020, IEEE COMPUT SOC CONF, P1994, DOI 10.1109/CVPRW50498.2020.00249
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fan ZW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1751, DOI 10.1145/3240508.3240694
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu XY, 2014, IEEE INT WORKSH MULT
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Kingma D. P., 2014, arXiv
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li C, 2016, IEEE INT SEMICONDUCT
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Liu B, 2018, PREPRINTS
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu X, 2019, PROC CVPR IEEE, P7000, DOI 10.1109/CVPR.2019.00717
   Metwaly K, 2020, IEEE COMPUT SOC CONF, P1842, DOI 10.1109/CVPRW50498.2020.00234
   Middleton W.E.K., 1957, Geophysik II/Geophysics II, P254, DOI DOI 10.1007/978-3-642-45881-13
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Ullah E., 2013, 2013 5th International Conference on Modelling, Identification and Control (ICMIC), P245
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HY, 2020, IEEE COMPUT SOC CONF, P1975, DOI 10.1109/CVPRW50498.2020.00247
   Yu MZ, 2020, IEEE COMPUT SOC CONF, P1832, DOI 10.1109/CVPRW50498.2020.00233
NR 54
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18407
EP 18426
DI 10.1007/s11042-023-15091-9
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100010
DA 2024-07-18
ER

PT J
AU El Maadi, A
   Loukhaoukha, K
   Benmami, M
   Mehallegue, N
   Zebbiche, K
AF El Maadi, Amar
   Loukhaoukha, Khaled
   Benmami, Mahmoud
   Mehallegue, Noureddine
   Zebbiche, Khalil
TI Comments on "efficient SVD speech watermarking with encrypted images"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech watermarking; Ambiguity attack; False positive detection;
   Singular value decomposition
ID SINGULAR-VALUE DECOMPOSITION; AUDIO WATERMARKING; WAVELET TRANSFORM;
   DWT-SVD; SCHEME; BLIND
AB In the paper entitled "Efficient SVD speech watermarking with encrypted images", El-Gazar et al. (2018) have proposed a new speech signal watermarking algorithm based on the SVD and encrypted watermarks. This algorithm is similar to one previously proposed by Liu and Tan in (2002) for digital image. However, some researchers have pointed out that Liu and Tan's algorithm suffers from the problem of false positive detection of the watermark, as reported in references (2007),(2005). In this paper, we demonstrate that El-Gazar et al. algorithm (2018) is vulnerable to two ambiguity attacks that allow the extraction of fake watermarks. Experimental results have shown that the extracted watermarks from different audio signals are visually and geometrically similar to the attacker's watermark, with normalized correlation values ranging from 0.9928 and 0.9994. Therefore, this algorithm cannot be used for security systems, data hiding, and copyright protection.
C1 [El Maadi, Amar] Ecole Mil Polytech, Algiers, Algeria.
   [Loukhaoukha, Khaled; Benmami, Mahmoud; Mehallegue, Noureddine; Zebbiche, Khalil] Dev Res Ctr, Algiers, Algeria.
   [Loukhaoukha, Khaled] Laval Univ, Dept Elect & Comp Engn, Quebec City, PQ, Canada.
   [Mehallegue, Noureddine; Zebbiche, Khalil] Queens Univ, Sch Elect Elect Engn & Comp Sci, Belfast, North Ireland.
C3 Ecole Military Polytechnic; Laval University; Queens University Belfast
RP Loukhaoukha, K (corresponding author), Dev Res Ctr, Algiers, Algeria.; Loukhaoukha, K (corresponding author), Laval Univ, Dept Elect & Comp Engn, Quebec City, PQ, Canada.
EM khaled.loukhaoukha.1@ulaval.ca
CR Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Chaharlang J, 2020, MULTIMED TOOLS APPL, V79, P17551, DOI 10.1007/s11042-020-08694-z
   Dhar PK, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030333
   Ding WP, 2022, IEEE TETCI, V6, P613, DOI 10.1109/TETCI.2021.3055520
   El-Gazar S, 2018, INT J SPEECH TECHNOL, V21, P953, DOI 10.1007/s10772-018-9531-8
   Ginanjar Rizki Rivai, 2019, IEIE Transactions on Smart Processing & Computing, V8, P49, DOI 10.5573/IEIESPC.2019.8.1.049
   Hu HT., 2017, J COMPUT, V28, P63
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Jiang SZ, 2020, J NETW COMPUT APPL, V165, DOI 10.1016/j.jnca.2020.102689
   Jie sang, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100052
   Joudaki AZ., 2022, J INF SYST TELECOMMU, V10, P151
   Kamaruddin NS, 2018, IEEE ACCESS, V6, P8011, DOI 10.1109/ACCESS.2018.2796585
   Karajeh H, 2019, MULTIMED TOOLS APPL, V78, P18395, DOI 10.1007/s11042-019-7214-3
   Kaur A, 2018, MULTIMEDIA SYST, V24, P341, DOI 10.1007/s00530-017-0545-x
   Keyvanpour MR, 2021, MULTIMED TOOLS APPL, V80, P20449, DOI 10.1007/s11042-021-10730-5
   Kumar KP, 2022, ARAB J SCI ENG, V47, P10003, DOI 10.1007/s13369-021-06431-8
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Li Z, 2019, IEEE ACCESS, V7, P84020, DOI 10.1109/ACCESS.2019.2899378
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   Loukhaoukha Khaled, 2009, 2009 Canadian Conference on Electrical and Computer Engineering (CCECE 2009), P229, DOI 10.1109/CCECE.2009.5090126
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Loukhaoukha K, 2016, INFORM PROCESS MANAG, V52, P644, DOI 10.1016/j.ipm.2015.12.009
   Loukhaoukha K, 2016, ADV ENG SOFTW, V93, P44, DOI 10.1016/j.advengsoft.2015.12.006
   Loukhaoukha K, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3327935
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mehallegue N, 2020, MULTIMED TOOLS APPL, V79, P2031, DOI 10.1007/s11042-019-08271-z
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mosleh M, 2021, MULTIMED TOOLS APPL, V80, P20423, DOI 10.1007/s11042-021-10686-6
   Nejad MY, 2019, INT J THEOR PHYS, V58, P3828, DOI 10.1007/s10773-019-04251-z
   Novamizanti L., 2019, TELKOMNIKA, V16, P2651, DOI [10.12928/telkomnika.v16i6.10111, DOI 10.12928/TELKOMNIKA.V16I6.10111]
   Quan YH, 2021, IEEE T NEUR NET LEAR, V32, P1852, DOI 10.1109/TNNLS.2020.2991378
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Saba T, 2020, MULTIMED TOOLS APPL, V79, P341, DOI 10.1007/s11042-019-08084-0
   Saini HS, 2019, INT J INNOVATIVE TEC, V8, P185
   Wu R, 2022, CHAOS SOLITON FRACT, V165, DOI 10.1016/j.chaos.2022.112770
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Yamni M, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117325
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhao M, 2015, J INTERNET TECHNOL, V16, P485, DOI 10.6138/JIT.2015.16.3.20150105
NR 46
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15617
EP 15628
DI 10.1007/s11042-023-16091-5
EA JUL 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000009
DA 2024-07-18
ER

PT J
AU Wang, XQ
   Zhang, SW
   Huang, L
AF Wang, Xuqi
   Zhang, Shanwen
   Huang, Lei
TI Aircraft segmentation in remote sensing images based on multi-scale
   residual U-Net with attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aircraft segmentation; Remote sensing images (RSIs); U-Net; Multi-scale
   residual U-Net with attention (MSRAU-Net)
ID RECOGNITION; MODEL
AB Aircraft segmentation in remote sensing images (RSIs) is an important but challenging problem for both civil and military applications. U-Net and its variants are widely used in RSI detection, but they are not suitable for multi-scale aircraft segmentation in RSIs, due to the aircrafts in RSIs are relatively small with various orientations, different sizes, fuzzy illumination and shadow, obscure boundary and irregular background. To overcome this problem, a multi-scale residual U-Net with attention (MSRAU-Net) model is constructed for multi-scale aircraft segmentation in RSIs. A multi-scale convolutional module, two modified Respaths and two kinds of attention modules are designed and introduced into MSRAU-Net to extract the multi-scale feature and make the feature fusion between the contraction path and the expansion path more efficient. Different from U-Net, MSRAU-Net replaces the convolutional block of U-Net with the Inception residual block to help the U-Net architecture coordinate the features learned from aircrafts with different scales, and the residual module and attention module are introduced into the modified Respath to deepen the network layers and solve the gradient disappearing problem while extracting the more effective feature from RSIs. The experiments on the RSI dataset validate that MSRAU-Net outperforms the other networks, in particular for detecting the small aircrafts. Compared with attention U-Net and MultiMixUNet, the precision of MSRAU-Net is improved by 9.25 and 3.36, respectively.
C1 [Wang, Xuqi; Zhang, Shanwen] XiJing Univ, Coll Informat Engn, Xian 710123, Peoples R China.
   [Huang, Lei] CNPC Tubular Goods Res Inst, Xian 710077, Peoples R China.
C3 Xijing University; China National Petroleum Corporation
RP Wang, XQ (corresponding author), XiJing Univ, Coll Informat Engn, Xian 710123, Peoples R China.
EM wangxuqi@xijing.edu.cn
FU National Natural Science Foundation of China [62172338, 62072378];
   Xijing University High-level Talent Special Fund Project [XJ21B14];
   Henan science and technology research project [212102210005]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 62172338 and 62072378),Xijing University High-level Talent
   Special Fund Project (No.XJ21B14). Henan science and technology research
   project (No. 212102210005).
CR Alruwaili M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6658058
   Cai BW, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111198
   Chen Z, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010139
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Deepan P, 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.02.831, DOI 10.1016/J.MATPR.2021.02.831]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Liu G, 2013, IEEE GEOSCI REMOTE S, V10, P573, DOI 10.1109/LGRS.2012.2214022
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meeboonmak N, 2020, 2ND INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCE AND ENGINEERING (MACISE 2020), P184, DOI 10.1109/MACISE49704.2020.00040
   Perone CS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24304-3
   Qi Z., 2017, J SENSORS, V16, P1
   Rong HJ, 2014, NEUROCOMPUTING, V128, P166, DOI 10.1016/j.neucom.2012.12.064
   Sanjar K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103658
   Wang GH, 2022, IET IMAGE PROCESS, V16, P1742, DOI 10.1049/ipr2.12444
   Wang XH, 2023, IEEE T PATTERN ANAL, V45, P6605, DOI 10.1109/TPAMI.2020.3015894
   Wang YT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235270
   Wu QC, 2015, IEEE GEOSCI REMOTE S, V12, P112, DOI 10.1109/LGRS.2014.2328358
   Wu QF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082618
   Xu TB, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P139, DOI 10.1109/ICDSP.2016.7868532
   Xu ZW, 2021, ENVIRON MODELL SOFTW, V140, DOI 10.1016/j.envsoft.2021.104992
   Yang JC, 2018, REMOTE SENS LETT, V9, P228, DOI 10.1080/2150704X.2017.1415474
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yao XW, 2015, NEUROCOMPUTING, V164, P162, DOI 10.1016/j.neucom.2015.02.073
   Zhang YH, 2018, REMOTE SENS LETT, V9, P11, DOI 10.1080/2150704X.2017.1378452
   Zhao A, 2017, IEEE GEOSCI REMOTE S, V14, P744, DOI 10.1109/LGRS.2017.2677954
   Zhao L, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P1362, DOI 10.1109/SSCI44817.2019.9002656
   Zhao P, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00670
   Zhuang ZM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221535
NR 28
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17855
EP 17872
DI 10.1007/s11042-023-16210-2
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000002
OA hybrid
DA 2024-07-18
ER

PT J
AU MunishKhanna
   Singh, LK
   Garg, H
AF MunishKhanna
   Singh, Law Kumar
   Garg, Hitendra
TI A novel approach for human diseases prediction using nature inspired
   computing & machine learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant-lion algorithm; Soft-computing; Machine learning; Feature selection;
   Human disease prediction
ID SALP SWARM ALGORITHM; SUPPORT VECTOR MACHINE; FEATURE-SELECTION;
   OPTIMIZATION ALGORITHM; DIFFERENTIAL EVOLUTION; CLASSIFICATION;
   IDENTIFICATION
AB Globally, patients with diabetes, diabetic retinopathy, cancer, and heart disease are growing rapidly in developed and developing countries. As a result of these ailments, the rate of human mortality and vision loss has risen dramatically. The design and development of computer-based prediction systems may facilitate the appropriate treatment of these four illnesses by medical professionals. For the design of an efficient and fast prediction (or classification) system, it is necessary to use efficient feature selection techniques to reduce the complexity of the feature space. If there are n features, then there is a possibility that 2(n) subsets of features can be created, and testing all of these subsets of selected features would require a significant amount of time. The suggested technique is to investigate the application of ant-lion based optimization to choose a subset of features. The chosen characteristics are used to train and evaluate four classifiers (and their ensemble) based on machine learning. The study used over three public benchmark datasets and one privately composed dataset, each one was disease-specific. The performance of the recommended strategy was evaluated using five performance assessment measures. This adjustment significantly improves the outcome. The strategy may decrease the initial feature set by up to 50% without impacting performance (in terms of accuracy). We can get maximum accuracies of 84.44% for the heart disease dataset, 79.99% for the diabetes dataset, 98.52% for the diabetic retinopathy dataset, and 97.18% for the skin cancer dataset. This empirical research will help doctors and all people make better decisions by giving them a second opinion.
C1 [MunishKhanna] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Singh, Law Kumar; Garg, Hitendra] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
C3 GLA University
RP MunishKhanna (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
EM munishkhanna.official@rocketmail.com; lawkumarcs1@gmail.com;
   hitendra.garg@gmail.com
RI Singh, Law Kumar/AAI-5450-2021; Garg, Hitendra/AAV-6756-2020
OI Singh, Law Kumar/0000-0002-7073-6852; 
CR Abbassi R, 2019, ENERG CONVERS MANAGE, V179, P362, DOI 10.1016/j.enconman.2018.10.069
   Acharya N, 2018, SOFT COMPUT, V22, P4407, DOI 10.1007/s00500-017-2635-2
   Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Aljarah I, 2020, Nature-Inspired Optimizers: Theories, Literature Reviews and Applications, P47, DOI [DOI 10.1007/978-3-030-12127-34, DOI 10.1007/978-3-030-12127-3_4]
   Aljarah I, 2018, COGN COMPUT, V10, P478, DOI 10.1007/s12559-017-9542-9
   Amin MS, 2019, TELEMAT INFORM, V36, P82, DOI 10.1016/j.tele.2018.11.007
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bharti R, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8387680
   Chen DB, 2016, SOFT COMPUT, V20, P1921, DOI 10.1007/s00500-015-1613-9
   Chen LH, 2008, EXPERT SYST APPL, V35, P1145, DOI 10.1016/j.eswa.2007.08.010
   da Silva SF, 2011, DECIS SUPPORT SYST, V51, P810, DOI 10.1016/j.dss.2011.01.015
   Das SP, 2018, INT J MACH LEARN CYB, V9, P97, DOI 10.1007/s13042-015-0359-0
   Dash M., 1997, Intelligent Data Analysis, V1
   Derrac J, 2009, LECT NOTES ARTIF INT, V5572, P557, DOI 10.1007/978-3-642-02319-4_67
   Desai NP., 2022, Turk J Comput Math Educ, V13, P85
   Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Eesa AS, 2015, EXPERT SYST APPL, V42, P2670, DOI 10.1016/j.eswa.2014.11.009
   Ekoe JM, 2018, CAN J DIABETES, V42, pS16, DOI 10.1016/j.jcjd.2017.10.004
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Faris H, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112898
   Faris H, 2018, KNOWL-BASED SYST, V154, P43, DOI 10.1016/j.knosys.2018.05.009
   Gonsalves AH, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P51, DOI 10.1145/3342999.3343015
   Grzybowski A, 2020, EYE, V34, P451, DOI 10.1038/s41433-019-0566-0
   Gu SK, 2018, SOFT COMPUT, V22, P811, DOI 10.1007/s00500-016-2385-6
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Hancer E, 2018, KNOWL-BASED SYST, V140, P103, DOI 10.1016/j.knosys.2017.10.028
   Hasan MK, 2020, IEEE ACCESS, V8, P76516, DOI 10.1109/ACCESS.2020.2989857
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Hegazy AE, 2019, ARAB J SCI ENG, V44, P3801, DOI 10.1007/s13369-018-3680-6
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Ibrahim A, 2018, ADV INTELL SYST COMP, V723, P42, DOI 10.1007/978-3-319-74690-6_5
   Islam M. M. Faniqul, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P113, DOI 10.1007/978-981-13-8798-2_12
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Katarya R, 2021, HEALTH TECHNOL-GER, V11, P87, DOI 10.1007/s12553-020-00505-7
   Kaveh A, 2010, ACTA MECH, V213, P267, DOI 10.1007/s00707-009-0270-4
   Kumari S, 2018, J AMB INTEL HUM COMP, V9, P643, DOI 10.1007/s12652-017-0460-1
   Kuo RJ, 2018, KNOWL INF SYST, V55, P253, DOI 10.1007/s10115-017-1083-8
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li Y, 2017, KNOWL INF SYST, V53, P551, DOI 10.1007/s10115-017-1059-8
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu H., 1998, FEATURE SELECTION KN, DOI [DOI 10.1007/978-1-4615-5689-3, 10.1007/978-1-4615-5689-3]
   Liu Y, 2015, IEEE T CYBERNETICS, V45, P1209, DOI 10.1109/TCYB.2014.2347372
   Mafarja M, 2020, COGN COMPUT, V12, P150, DOI 10.1007/s12559-019-09668-6
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Mahboob Alam Talha, 2019, Informatics in Medicine Unlocked, V16, P161, DOI 10.1016/j.imu.2019.100204
   Makrariya Akshara, 2021, Mathematical Modeling, Computational Intelligence Techniques and Renewable Energy. Proceedings of the First International Conference, MMCITRE 2020. Advances in Intelligent Systems and Computing (AISC 1287), P217, DOI 10.1007/978-981-15-9953-8_19
   Makrariya A, 2022, IEEE ACCESS, V10, P91346, DOI 10.1109/ACCESS.2022.3202630
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Misra A, 2019, J DIABETES, V11, P522, DOI 10.1111/1753-0407.12913
   Munir K, 2019, CANCERS, V11, DOI 10.3390/cancers11091235
   Murugan A, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103727
   Pandey AC., 2018, ADV COMPUTER COMPUTA, P353, DOI [10.1007/978-981-10-3773-3_35, DOI 10.1007/978-981-10-3773-3_35]
   Pandey AC, 2018, INT J SYST ASSUR ENG, V9, P821, DOI 10.1007/s13198-017-0660-2
   Pandey AC, 2017, INFORM PROCESS MANAG, V53, P764, DOI 10.1016/j.ipm.2017.02.004
   Patidar N., 2022, NONLINEAR DYNAMICS A, P797, DOI [10.1007/978-3-030-99792-2_67, DOI 10.1007/978-3-030-99792-2_67]
   Peña JM, 2010, IEEE T PATTERN ANAL, V32, P1517, DOI 10.1109/TPAMI.2010.84
   Prabhu S, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105209
   Qu XH, 2017, ENG APPL ARTIF INTEL, V57, P1, DOI 10.1016/j.engappai.2016.10.009
   Ramesh TR, 2022, MALAYS J COMPUT SCI, P132, DOI 10.22452/mjcs.sp2022no1.10
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rath A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102820
   Rodrigues D, 2014, EXPERT SYST APPL, V41, P2250, DOI 10.1016/j.eswa.2013.09.023
   Sajda P, 2006, ANNU REV BIOMED ENG, V8, P537, DOI 10.1146/annurev.bioeng.8.061505.095802
   Saraswat M, 2014, MED BIOL ENG COMPUT, V52, P1041, DOI 10.1007/s11517-014-1200-8
   Saudek CD, 2008, J CLIN ENDOCR METAB, V93, P2447, DOI 10.1210/jc.2007-2174
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Sayed GI, 2018, APPL INTELL, V48, P3462, DOI 10.1007/s10489-018-1158-6
   Shao WS, 2016, KNOWL-BASED SYST, V107, P219, DOI 10.1016/j.knosys.2016.06.011
   Shrestha M, 2023, MULTIMED TOOLS APPL, V82, P6221, DOI 10.1007/s11042-022-13582-9
   Stitt AW, 2016, PROG RETIN EYE RES, V51, P156, DOI 10.1016/j.preteyeres.2015.08.001
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Taradeh M, 2019, INFORM SCIENCES, V497, P219, DOI 10.1016/j.ins.2019.05.038
   Thomas RL, 2015, BRIT J OPHTHALMOL, V99, P64, DOI 10.1136/bjophthalmol-2013-304017
   Wang L, 2014, NEURAL COMPUT APPL, V25, P1407, DOI 10.1007/s00521-014-1627-8
   Wei JX, 2017, APPL SOFT COMPUT, V58, P176, DOI 10.1016/j.asoc.2017.04.061
   Winkler S.M., 2011, Proceedings of the 13th annual conference companion on Genetic and evolutionary computation, P503
   Wu YP, 2018, J AMB INTEL HUM COMP, V9, P1671, DOI 10.1007/s12652-018-0883-3
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yang B, 2019, J CLEAN PROD, V215, P1203, DOI 10.1016/j.jclepro.2019.01.150
   Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XXVI, P209, DOI 10.1007/978-1-84882-983-1_15
NR 89
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17773
EP 17809
DI 10.1007/s11042-023-16236-6
EA JUL 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600009
DA 2024-07-18
ER

PT J
AU Tripathi, A
   Dani, RR
   Mishra, A
   Chakraborty, A
AF Tripathi, Aditay
   Dani, Rajath R.
   Mishra, Anand
   Chakraborty, Anirban
TI Multimodal query-guided object localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch; Open-set object localization; Gloss; Cross-modal localization;
   Cross-modal attention
ID IMAGE RETRIEVAL; LANGUAGE; VISION
AB Recent studies have demonstrated the effectiveness of using hand-drawn sketches of objects as queries for one-shot object localization. However, hand-drawn crude sketches alone can be ambiguous for object localization, which could result in misidentification, e.g., a sketch of a laptop could be confused for a sofa. To overcome this, we propose a novel multimodal approach to object localization that combines sketch queries with linguistic category definitions, allowing for a better representation of visual and semantic cues. Our approach employs a cross-modal attention scheme that guides the region proposal network to obtain relevant proposals. Further, we propose an orthogonal projection-based proposal scoring technique that effectively ranks proposals with respect to the query. We evaluated our method using hand-drawn sketches from the 'Quick, Draw!' dataset and glosses from 'WordNet' as queries on the widely-used MS-COCO dataset, and achieve superior performance compared to related baselines in both open- and closed-set settings.
C1 [Tripathi, Aditay; Dani, Rajath R.; Chakraborty, Anirban] Indian Inst Sci, CDS, Bengaluru 560012, Karnataka, India.
   [Mishra, Anand] Indian Inst Technol, CSE, Jodhpur 342037, Rajasthan, India.
C3 Indian Institute of Science (IISC) - Bangalore; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Jodhpur
RP Chakraborty, A (corresponding author), Indian Inst Sci, CDS, Bengaluru 560012, Karnataka, India.
EM aditayt@iisc.ac.in; rajathrdani@gmail.com; mishra@iitj.ac.in;
   anirban@iisc.ac.in
FU Advanced Data Management Research Group, Corporate Technologies, Siemens
   Technology and Services Pvt. Ltd.; Pratiksha Trust, Bengaluru, India
FX This work is partly supported by research grants from the Advanced Data
   Management Research Group, Corporate Technologies, Siemens Technology
   and Services Pvt. Ltd., and Pratiksha Trust, Bengaluru, India.
CR Akbari H, 2021, ADV NEUR IN
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24
   Bhunia AK, 2022, arXiv
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Cao Y, 2014, CANCER INFORM, V13, P125, DOI 10.4137/CIN.S14053
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232
   Chowdhury PN., 2022, arXiv
   Dang-Nguyen D-T, 2012, P INT WORKSH CONT BA, P1
   Das Ayan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P632, DOI 10.1007/978-3-030-58574-7_38
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, BERT PRE TRAINING DE
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fellbaum C, 2012, Wordnet. The encyclopedia of applied linguistics
   Ge S., 2020, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Ha D., 2017, P INT C LEARN REPR
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hofmann T, 2013, P C UNC ART INT UAI
   Hsieh TI, 2019, ADV NEUR IN, V32
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jongejan Jonas, 2016, The Quick, Draw!-A.I. Experiment
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li K., 2018, ECCV, P582
   Li XY, 2018, IEEE T MULTIMEDIA, V20, P2749, DOI 10.1109/TMM.2018.2811621
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2017, PROC CVPR IEEE, P2298, DOI 10.1109/CVPR.2017.247
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YF, 2020, AAAI CONF ARTIF INTE, V34, P11645
   Luo RT, 2020, AAAI CONF ARTIF INTE, V34, P11709
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Nagarajan T, 2018, LECT NOTES COMPUT SC, V11205, P172, DOI 10.1007/978-3-030-01246-5_11
   Nagrani A, 2021, ADV NEUR IN, V34
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Osman A, 2019, COMPUT VIS IMAGE UND, V185, P24, DOI 10.1016/j.cviu.2019.05.001
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Plummer BA, 2018, LECT NOTES COMPUT SC, V11216, P258, DOI 10.1007/978-3-030-01258-8_16
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Qi YG, 2015, PROC CVPR IEEE, P1856, DOI 10.1109/CVPR.2015.7298795
   Rahman S, 2020, Arxiv, DOI arXiv:1811.08982
   Rahman S, 2019, LECT NOTES COMPUT SC, V11361, P547, DOI 10.1007/978-3-030-20887-5_34
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sermanet P, 2013, P INT C LEARNING REP
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592
   Tripathi Aditay, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P532, DOI 10.1007/978-3-030-58539-6_32
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Uppal S, 2022, INFORM FUSION, V77, P149, DOI 10.1016/j.inffus.2021.07.009
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang S, 2015, IEEE T MULTIMEDIA, V17, P1045, DOI 10.1109/TMM.2015.2431492
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu P, 2022, IEEE T NEUR NET LEAR, V33, P5150, DOI 10.1109/TNNLS.2021.3069230
   Xu P, 2018, PROC CVPR IEEE, P8090, DOI 10.1109/CVPR.2018.00844
   Yan XP, 2019, IEEE I CONF COMP VIS, P9576, DOI 10.1109/ICCV.2019.00967
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yi JR, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102827
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2016, Arxiv, DOI arXiv:1606.06259
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang YT, 2016, IEEE T MULTIMEDIA, V18, P1604, DOI 10.1109/TMM.2016.2568138
   Zimmermann RS, 2019, Computer Vision Image Understanding (CVIU), P188
NR 92
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14857
EP 14881
DI 10.1007/s11042-023-15779-y
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700007
DA 2024-07-18
ER

PT J
AU Abdellatef, E
   Naeem, EA
   Abd El-Samie, FE
AF Abdellatef, Essam
   Naeem, Ensherah A.
   Abd El-Samie, Fathi E.
TI DeepEnc: deep learning-based CT image encryption approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Deep learning; Feature extraction
ID SCHEME; EFFICIENT; SECURITY; SYSTEM
AB The rapid development of artificial intelligence gave motivations to researchers to apply it in information security, biometrics, and medical image encryption. This paper presents an encryption approach for CT images that are used in diagnosing COVID-19 disease. To add more privacy, the proposed encryption mechanism links the CT image and the facial image of a person. Firstly, a simple Convolutional Neural Network (CNN) is utilized to extract features from facial images. The architecture of the CNN model includes three convolutional groups, and each group consists of a convolutional layer, a batch normalization layer, a Rectified Linear Unit (ReLU), and a maximum pooling layer. Moreover, the extracted feature vector is utilized to adjust the initial states of a two-dimensional Sine Logistic Modulation Map (2D-SLMM), so as to generate chaotic matrices SLM1 and SLM2, and to adjust the initial states of a Tent Logistic Map (TLM) in order to get two other chaotic matrices, TLM1 and TLM2. Finally, the Chaotic Magic Transform (CMT) confusion operation and the bitwise XOR diffusion operation are used to randomly scramble the pixel locations and change the pixel values, respectively. Only after two rounds of CMT and two bitwise XOR operations with chaotic matrices SLM1, SLM2, TLM1 and TLM2, we get an unrecognizable encrypted CT image with a high security level. In adittion, we study and analyze the performance of the proposed approach in the presence of differential, entropy and key sensitivity attacks. In the experiments, when performing decryption, two cases are discussed; utilization of the correct key and utilization of the correct key with small variation. The robustness of the proposed encryption approach is measured using different metrics like Correlation Coefficient (CC), entropy, histogram analysis, and elapsed time. The maximum elapsed time is about 0.4361 seconds.
C1 [Abdellatef, Essam] Delta Higher Inst Engn & Technol DHIET, Dept Elect & Commun, Mansoura 35511, Egypt.
   [Naeem, Ensherah A.] Suez Univ, Fac Technol & Educ, Elect Dept, Suez 43527, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Elect & Elect Comm Dept, Fac Elect Engn, Shibin Al Kawm, Egypt.
C3 Delta Higher Institute for Engineering & Technology; Egyptian Knowledge
   Bank (EKB); Suez University; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Abdellatef, E (corresponding author), Delta Higher Inst Engn & Technol DHIET, Dept Elect & Commun, Mansoura 35511, Egypt.
EM essam_abdellatef@yahoo.com
CR Aminanto ME, 2017, LECT NOTES COMPUT SC, V10144, P136, DOI 10.1007/978-3-319-56549-1_12
   Aono Y, 2017, P INT C APPL TECHN I, P100, DOI 10.1007/978-981-10-5421-1_9
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bhilare S, 2018, MACH VISION APPL, P1
   Carcary M, 2016, IT PROF, V18, P22, DOI 10.1109/MITP.2016.27
   Cui GZ, 2007, 2007 INTERNATIONAL WORKSHOP ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION, P288, DOI 10.1109/IWASID.2007.373746
   De Cannière C, 2006, LECT NOTES COMPUT SC, V4176, P171
   Dieu J., 2014, COMPUT SCI APPL, V1, P232
   Ding Y., 2020, ARXIV
   Ding Y, 2021, IEEE T NEURAL NETW L
   Enayatifar R., 2011, INT J PHYS SCI, V6, P221
   Ferdowsi A, 2019, IEEE T COMMUN, V67, P1371, DOI 10.1109/TCOMM.2018.2878025
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Garcia-Bosque M, 2017, P IEEE INT INSTR MEA, P1
   Guangzhao Cui, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P148, DOI 10.1109/ICNC.2009.27
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiangli Shang, 2011, 2011 International Conference on Computer Science and Service System (CSSS), P1684
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Manifavas C, 2016, SECUR COMMUN NETW, V9, P1226, DOI 10.1002/sec.1399
   Mannai O, 2018, EUR SIGNAL PR CONF, P316, DOI 10.23919/EUSIPCO.2018.8553449
   Mizuchi Y, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P1014, DOI 10.1109/ICCAS.2013.6704065
   Mukhedkar M., 2015, P ANN IEEE IND C IND, P1, DOI DOI 10.1109/INDICON.2015.7443808
   Musleh M., 2012, INT J COMPUT SCI INF, V10, P1
   Natsheh QN, 2016, PROCEDIA COMPUT SCI, V90, P175, DOI 10.1016/j.procs.2016.07.018
   nist, FERET DAT
   Özkaynak F, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P621, DOI 10.1109/UBMK.2017.8093481
   Rao Y, 2016, IEEE INT WORKS INFOR
   Wanbo Yu, 2010, Proceedings of the 2010 International Conference on Intelligent Control and Information Processing (ICICIP 2010), P463, DOI 10.1109/ICICIP.2010.5564211
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yuan Zhongrui, 2017, 2017 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII). Proceedings, P1, DOI 10.1109/ICIICII.2017.55
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhou Shihai, 2010, Proceedings of the 2010 International Conference of Information Science and Management Engineering. ISME 2010, P97, DOI 10.1109/ISME.2010.186
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 39
TC 2
Z9 2
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11147
EP 11167
DI 10.1007/s11042-023-15818-8
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900006
DA 2024-07-18
ER

PT J
AU Wang, JX
   Zhang, Y
   Huang, L
   Wang, CT
   Ni, JQ
AF Wang, Junxiang
   Zhang, Ying
   Huang, Lin
   Wang, Chuntao
   Ni, Jiangqun
TI Reversible data hiding in enhanced images with anti-detection capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Undetectability; Multi-feature sorting; Enhanced
   image
AB Reversible data hiding (RDH) technique has been widely used for content authentication. However, most conventional RDH schemes generally concentrates on the rate-and-distortion performance (namely high capacity and low distortion), instead of their undetectability performance (namely security). In other words, the stego images with conventional RDH schemes could be easily detected by most steganalysis tools, e.g., SPAM, to reveal some suspicious secret data hidden in it, which increases the embedding risk. Therefore, their applications in some circumstances are restricted. In this paper, enhanced images generated by common image enhancement techniques are built as a desired carrier for RDH, to achieve both better rate-and-distortion and desired undetectability performance due to its special statistical histogram distribution, where many vacant interspaces are scattered in the histogram and suitable for histogram shifting based RDH process. In addition, considering that the enhanced images could provide much more candidate spaces for embedding, some strategies for security improvement, such as multi-feature sorting technique and so on, could be introduced. Experimental results verify the superiority of proposed scheme compared with other related algorithms.
C1 [Wang, Junxiang; Zhang, Ying; Huang, Lin] Jingdezhen Ceram Inst, Sch Mech & Elect Engn, Jingdezhen 333403, Jiangxi, Peoples R China.
   [Wang, Chuntao] South China Agr Univ, Coll Math & informat, Guangzhou 510642, Peoples R China.
   [Ni, Jiangqun] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
C3 Jingdezhen Ceramic Institute; South China Agricultural University; Sun
   Yat Sen University
RP Wang, JX (corresponding author), Jingdezhen Ceram Inst, Sch Mech & Elect Engn, Jingdezhen 333403, Jiangxi, Peoples R China.
EM wjx851113851113@163.com
FU National Natural Science Foundation of China [62062044, 61762054,
   61672242, U1736215, U1936212, 61772573]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China under Grant (62062044, 61762054, 61672242, U1736215,
   U1936212, 61772573). In addition, many thanks to the anonymous reviewers
   for their insightful comments and valuable suggestions, which helped a
   lot to improve the paper quality.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Benesty J., 2009, Noise Reduction in Speech Processing, P1, DOI DOI 10.1007/978-3-642-00296-05
   Boggs P.T., 1995, ACTA NUMER, V4, P1, DOI 10.1017/s0962492900002518
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dong L, 2020, IEEE T CIRCUITS-II, V67, P951, DOI 10.1109/TCSII.2020.2981550
   Dragoi IC, 2021, IEEE T INF FOREN SEC, V16, P187, DOI 10.1109/TIFS.2020.3006382
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Filler T., BOSS
   Fletcher R., 1987, Practical Methods of Optimization, DOI [DOI 10.1002/9781118723203, 10.1002/9781118723203]
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fu JC, 2000, COMPUT MED IMAG GRAP, V24, P59, DOI 10.1016/S0895-6111(00)00007-0
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hou DD, 2018, IEEE T IMAGE PROCESS, V27, P5087, DOI 10.1109/TIP.2018.2851074
   Khosravi MR, 2021, WIREL NETW, DOI 10.1007/s11276-021-02626-x
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li TF, 2020, IEEE ACCESS, V8, P12845, DOI 10.1109/ACCESS.2020.2964830
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin WS, 2005, IEEE T CIRC SYST VID, V15, P900, DOI 10.1109/TCSVT.2005.848345
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Myers L., 2004, Encyclopedia of statistical sciences, DOI [10.1002/0471667196.ess5050, DOI 10.1002/0471667196.ESS5050]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wang JX, 2019, IEEE ACCESS, V7, P35564, DOI 10.1109/ACCESS.2019.2903079
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang W, 2021, J SENSORS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZC, 2020, IEEE SIGNAL PROC LET, V27, P71, DOI 10.1109/LSP.2019.2956416
   Yadav AK, 2015, 2015 IEEE POWER, COMMUNICATION AND INFORMATION TECHNOLOGY CONFERENCE (PCITC-2015), P721, DOI 10.1109/PCITC.2015.7438091
   Zhang WM, 2015, IEEE T IMAGE PROCESS, V24, P294, DOI 10.1109/TIP.2014.2358881
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang Z, 2015, ASIAPAC SIGN INFO PR, P753, DOI 10.1109/APSIPA.2015.7415372
NR 49
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9853
EP 9872
DI 10.1007/s11042-023-15663-9
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900009
DA 2024-07-18
ER

PT J
AU Pan, TH
   Wang, Z
AF Pan, Tianhong
   Wang, Zheng
TI High-resolution network with an auxiliary channel for 2D hand pose
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE High-resolution network (HRnet); slice operation; auxiliary channel;
   multi-scale integration
AB High-resolution networks have been applied in various fields because of their advanced architecture. However, multiple multi-scale fusions of high and low-dimensional semantic information during hand pose estimation can blur the position information obtained in high resolution, causing overfitting. To address this problem, we added an auxiliary channel parallel to the original network in this study. The auxiliary channel slices images using a slicing operation instead of a convolutional downscaling operation to preserve the full information in the input. The input is then computed by following four convolution layers to obtain the initial position correction information, and the results are combined with the network for prediction. Adding the auxiliary channel increases the number of parameters in the original network by only 0.7%, but obtains a high accuracy gain, which is particularly noticeable on lightweight networks. We performed several experiments to verify the effectiveness of this method using multiple datasets.
C1 [Pan, Tianhong; Wang, Zheng] Anhui Univ, Sch Elect Engn & Automation, Hefei 230601, Anhui, Peoples R China.
C3 Anhui University
RP Pan, TH (corresponding author), Anhui Univ, Sch Elect Engn & Automation, Hefei 230601, Anhui, Peoples R China.
EM thpan@ahu.edu.cn; dncfjy2013@163.com
RI Pan, Tianhong/J-8591-2012
OI Pan, Tianhong/0000-0002-0993-3937
FU National Natural Science Foundation (NNSF) of China [62273002]
FX AcknowledgmentsThis work was supported by the National Natural Science
   Foundation (NNSF) of China under Grant 62273002.
CR Cai YJ, 2021, IEEE T PATTERN ANAL, V43, P3739, DOI 10.1109/TPAMI.2020.2993627
   Chen LJ, 2020, IEEE WINT CONF APPL, P400, DOI [10.1109/wacv45572.2020.9093380, 10.1109/WACV45572.2020.9093380]
   Chen YF, 2020, IEEE WINT CONF APPL, P370, DOI [10.1109/WACV45572.2020.9093271, 10.1109/wacv45572.2020.9093271]
   Elboushaki A, 2020, MULTIMED TOOLS APPL, V79, P28925, DOI 10.1007/s11042-020-09370-y
   Gao Q, 2017, LECT NOTES ARTIF INT, V10462, P462, DOI 10.1007/978-3-319-65289-4_44
   Gomez-Donoso F, 2019, IMAGE VISION COMPUT, V81, P25, DOI 10.1016/j.imavis.2018.12.001
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Kong D, 2020, IEEE WINTER C APPL C, P14
   Li Cong, 2021, 2021 IEEE 9th International Conference on Information, Communication and Networks (ICICN), P532, DOI 10.1109/ICICN52636.2021.9673812
   Li Y., 2022, BRIT MACHINE VISION
   Lin YS, 2018, IEEE INT CONF AUTOMA, P45, DOI 10.1109/FG.2018.00017
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Meng X., 2023, J. Eng. Appl. Sci, V70, P1, DOI [DOI 10.1186/S44147-023-00186-9, 10.1186/s44147-023-00186-9]
   Molchanov Pavlo, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163132
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pan TH, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103461
   Rasel A, 2019, INT J INFORM TECHNOL, V11, P50
   Rezaei M, 2022, IEEE C COMPUT VIS PA
   Santavas N, 2021, IEEE SENS J, V21, P11488, DOI 10.1109/JSEN.2020.3018172
   Seong S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163087
   Simonyan K, 2014, ADV NEUR IN, V27
   Spurr Adrian, 2020, P EUR C COMP VIS, P211
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Wang YG, 2020, IEEE T IMAGE PROCESS, V29, P2977, DOI 10.1109/TIP.2019.2955280
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu MY, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102802
   Yu CQ, 2021, PROC CVPR IEEE, P10435, DOI 10.1109/CVPR46437.2021.01030
   Yu J, 2020, J APPL SCI ENG, V23, P31, DOI 10.6180/jase.202003_23(1).0004
   Yu J, 2019, INT J COMPUT SCI ENG, V18, P12, DOI 10.1504/IJCSE.2019.10017870
   Zhang MY, 2022, MULTIMED TOOLS APPL, V81, P25745, DOI 10.1007/s11042-022-12780-9
NR 31
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 23
PY 2023
DI 10.1007/s11042-023-16045-x
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K2IG6
UT WOS:001014722500001
DA 2024-07-18
ER

PT J
AU Datta, K
   Jana, B
   Singh, PK
   Chakraborty, MD
AF Datta, Kankana
   Jana, Biswapati
   Singh, Prabhash Kumar
   Chakraborty, Mamata Dalui
TI Robust data hiding scheme for highly compressed image exploiting btc
   with hamming code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Hamming error correcting code; Even parity; Vertical
   redundancy checking; Block truncation coding; Image compression; Secret
   message
AB Compression techniques can be used on digital content to minimize duplication and maintain internet traffic, while ensuring the quality of the decoded object. Two functionalities such as data concealing and images compression can be combined into a single module, reducing the risk of responder attacks while improving execution efficacy. This study exploits Block Truncation Coding (BTC) with (7, 4) Hamming error correction and detection code to render a robust data hiding policy within highly compressed images. To compress the host image, BTC has been utilized which divides the image into (4 x 4) blocks. These blocks are categorized into two groups namely complex and smooth, based on threshold value where each smooth block accommodate two secret data bits encoded in it employing (7, 4) Hamming code whereas complex block remain unaltered. On the other hand, the Vertical Redundancy Check (V RC) approach greatly aids in determining the location of the hidden message bit. The cover or host image can be partially recovered due to the lossy property of BTC image compression scheme. To test its robustness and imperceptibility, several standard NIST approved steganalysis and statistical attacks are carried out. The developed technique is found to be secure and strong against a variety of geometrical attacks. The virtues of the proposed scheme are presented by comparing experimental results to the state-of-the-art schemes. The anticipated consequence highlighted certain outstanding magnificent aspects in the fields of verification of image, tamper recognition, and digital forgery sensing, all of which are essential to the contemporary technological life. This scheme benefits a wide range of government and business sectors, as well as health care, security, intellectual property rights, commercial and defense.
C1 [Datta, Kankana] Dept Comp Applicat, Haldia Inst Technol HIT Campus, Purba Medinipur, W Bengal, India.
   [Jana, Biswapati; Singh, Prabhash Kumar] Vidyasagar Univ, Dept Comp Sci, Midnapore, W Bengal, India.
   [Chakraborty, Mamata Dalui] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
C3 Haldia Institute of Technology; Vidyasagar University; National
   Institute of Technology (NIT System); National Institute of Technology
   Durgapur
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore, W Bengal, India.
EM dattakankana18@gmail.com; biswapatijana@gmail.com;
   prabhash.singh@mail.vidyasagar.ac.in; mamata.dalui@cse.nitdgp.ac.in
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR Abdelwahab AA, 2008, P IEEE SWARM INT S, P1
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bhardwaj R, 2021, MULTIMED TOOLS APPL, P1
   Biswapati J, 2017, ADV INTELL SYST, V458, P549, DOI 10.1007/978-981-10-2035-3_56
   Boneh D., 1999, Not. AMS, V46, P203
   Cao ZK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1818-0
   Chan CS, 2021, ASIAN HIST, P1, DOI 10.5117/9789463729253
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101314
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen SL, 2017, IEEE SENS J, V17, P4999, DOI 10.1109/JSEN.2017.2712908
   Chowdhuri Partha, 2021, International Journal of Computers and Applications, P38, DOI 10.1080/1206212X.2018.1505024
   Chowdhuri Partha, 2020, Intelligent Computing: Image Processing Based Applications. Advances in Intelligent Systems and Computing (AISC 1157), P103, DOI 10.1007/978-981-15-4288-6_7
   Chowdhuri P, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102420
   Chowdhury M. M. H., 2012, Int J Comput Sci Issues, V9, P327
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   Cox IJ., 2007, DIGITAL WATERMARKING
   Crandall R., 1998, Steganography Mailing List, V1998, P1
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fridrich J, 2007, LECT NOTES COMPUT SC, V4437, P282
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Junlan Bai, 2016, International Journal of Network Security, V18, P1122
   Kalaiyarasi M, 2021, MAT TODAY P
   Kan Wang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P317, DOI 10.1109/IIH-MSP.2012.83
   Kim C, 2011, LECT NOTES ARTIF INT, V6592, P372, DOI 10.1007/978-3-642-20042-7_38
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23070790
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lien BK, 2015, ADV INTELL SYST, V329, P179, DOI 10.1007/978-3-319-12286-1_18
   Lin CJ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/1577614
   Lin CC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030281
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin NH, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P66
   Liu LS, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107022
   Liu XL, 2019, IEEE ACCESS, V7, P116027, DOI 10.1109/ACCESS.2019.2935907
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu ZM, 2002, CHINESE J ELECTRON, V11, P152
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Meikap Sudipta, 2017, Communication, Devices, and Computing. ICCDC 2017. Proceedings: LNEE 470, P47, DOI 10.1007/978-981-10-8585-7_5
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Nguyen TD, 2021, MULTIMED TOOLS APPL, V80, P13099, DOI 10.1007/s11042-020-10347-0
   Nottingham trent university, 2017, UK UC IM DAT
   Pal P, 2021, WIRELESS PERS COMMUN, P1
   Pal P, 2017, INT C COMP INT COMM, P511
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Singh Prabhash Kumar, 2021, Proceedings of the Sixth International Conference on Mathematics and Computing. ICMC 2020. Advances in Intelligent Systems and Computing (AISC 1262), P43, DOI 10.1007/978-981-15-8061-1_4
   Singh PK, 2022, J KING SAUD UNIV-COM, V34, P4402, DOI 10.1016/j.jksuci.2020.09.014
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Standard D.E., 1999, Federal Information Processing Standards Publication, V112
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tsai YS, 2011, INFORM SCIENCES, V181, P3188, DOI 10.1016/j.ins.2011.03.017
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Tzong-Jer Chen, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P610, DOI 10.1109/CISP.2010.5647247
   University of california, 2017, SAN DIEG STAR IM DAT
   University of southern california, 2017, USC SIPI IMAGE DATAB
   Wang X, 2020, MULTIMED TOOLS APPL, V79, P6547, DOI 10.1007/s11042-019-08237-1
   Willems FMJ, 2005, IEEE T INFORM THEORY, V51, P1209, DOI 10.1109/TIT.2004.842707
   Xu SY, 2021, IEEE ACCESS, V9, P55191, DOI 10.1109/ACCESS.2021.3071819
   Xu SY, 2021, MULTIMED TOOLS APPL, V80, P20307, DOI 10.1007/s11042-021-10698-2
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI 10.1007/s11042-014-1958-6
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
NR 70
TC 3
Z9 3
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8591
EP 8628
AR s11042-023-15727-w
DI 10.1007/s11042-023-15727-w
EA JUN 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000001
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Tian, W
   Zhang, YC
   Wang, CZ
AF Zhou, Yi
   Tian, Wei
   Zhang, Yichi
   Wang, Chuzheng
TI DW-SCA Unet: medical image segmentation based on depth-wise separable
   convolutional attention U-shaped network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth-wise separable convolutional attention; Self-attention;
   Transformer; Channel-wise cross-attention
ID NET ARCHITECTURE
AB Medical image segmentation is an essential prerequisite for developing healthcare systems, especially for disease diagnosis and treatment planning. Recently, Transformer has achieved great success in various medical image segmentation tasks, which has long-range dependence compared to convolution neural network (CNN). However, self-attention in Transformer regards 2D images as 1D sequences, which destroys the crucial 2D structure of the image, which only considers the adaptability in spatial dimension but ignores the adaptability in channel dimension. Transformer can result in limited localization abilities due to insufficient low-level details. To solve these problems, this paper proposes Depth-wise Separable Convolutional Attention U-shape network (DW-SCA Unet), a U-shaped encoding-decoding network for medical image segmentation. The depth-wise separable convolutional attention block absorbs the advantages of depth-wise separable convolution and transformer, including long-range dependence, local structural information and adaptability. Specifically, we use a depth-wise separable convolutional attention block as the encoder to extract contextual features. And a symmetric depth-wise separable convolutional attention block with patch expanding layer is designed to perform up-sampling operation to restore the spatial resolution of the feature maps. On the skip connections of U-shaped networks, we use Channel-wise Cross-Attention (CCA) to guide the fused multi-scale channel-wise information to efficiently connect to decoder features for eliminating the ambiguity. Experimental results showed that DW-SCA Unet achieved better performance in the Synapse multi-organ segmentation task with segmentation accuracies of 80.54%% (DSC) and 20.02% (HD). The experiments on multi-organ and cardiac segmentation tasks also demonstrate the superiority, effectiveness and robustness of our DW-SCA Unet.
C1 [Zhou, Yi; Tian, Wei; Zhang, Yichi; Wang, Chuzheng] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Wang, CZ (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM wangchuzheng@csuft.edu.cn
RI Zhang, Yichi/IUN-3019-2023
OI Zhang, Yichi/0009-0006-7136-4997
FU National Natural Science Foundation of China [61602528]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant No. 61602528).
CR Alom MZ, 2018, arXiv
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo M.-H., 2022, arXiv
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   Han Qi, 2021, INT C LEARNING REPRE
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Huang X., 2021, ARXIV
   Huang Z., 2021, ARXIV
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Lee J., 2018, INT C LEARN REPR ICL
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tay Y., 2021, arXiv
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Valanarasu Jeya Maria Jose, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P363, DOI 10.1007/978-3-030-59719-1_36
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HN, 2022, AAAI CONF ARTIF INTE, P2441
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xie JS, 2022, IET SIGNAL PROCESS, V16, P501, DOI 10.1049/sil2.12114
   Yuan Y., 2021, Adv. Neural Inform. Process. Syst, V34, P7281
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 43
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8893
EP 8910
DI 10.1007/s11042-023-15960-3
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012974800003
DA 2024-07-18
ER

PT J
AU Amina, Y
   Bekkouche, T
   Daachi, ME
   Diffellah, N
AF Amina, Yahi
   Bekkouche, Tewfik
   Daachi, Mohamed El Hossine
   Diffellah, Nacira
TI A novel trigonometric 3D chaotic map and its application in a double
   permutation-diffusion image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-CSC chaotic system; Permutation; Diffusion; Image encryption;
   Security; Attacks
ID PRE-ENCRYPTION; ALGORITHM; COMBINATION
AB In this paper, we introduce a new three-dimensional cosines-sinus-cosines (3D-CSC) chaotic system. The performance evaluations of the proposed system exhibit a high chaotic behavior, an infinite chaotic range of its three control parameters, and a high sensitivity to initials conditions and control parameters. Especially, when compared with other existing 3D chaotic systems. Additionally, it is possible to extend the dimensions of 3D-CSC to 3 times N while maintaining the same high level of performance, and also incorporate additional control parameters of 3D-CSC. Furthermore, we present an innovative application of 3D-CSC in the development of a novel image encryption algorithm with enhanced security features. Our proposed algorithm utilizes a permutation-diffusion architecture applied in four distinct steps, including recursive XOR operation, arithmetic modular, and chaotic circular shift (both horizontal and vertical). This suggested method can be applied to various sorts of images (real-life images, medical images, biometric images). Obtained results demonstrate that the proposed algorithm combined with 3D-CSC is reliable and more powerful than other previous encryption algorithms, in terms of high-security level against statistical and differential attacks, a large keyspace, and its significant sensitivity. Moreover, despite the complexity of its architecture, it exhibits a high-speed level.
C1 [Amina, Yahi; Bekkouche, Tewfik; Daachi, Mohamed El Hossine; Diffellah, Nacira] Univ Mohamed El Bachir El Ibrahimi, Fac technol, Dept Elect, ETA Lab, Bordj Bouarreridj 34000, Algeria.
RP Amina, Y (corresponding author), Univ Mohamed El Bachir El Ibrahimi, Fac technol, Dept Elect, ETA Lab, Bordj Bouarreridj 34000, Algeria.
EM amina.yahi994@gmail.com
CR Ajmal H., 2020, JCR-J CLIN RHEUMATOL, V7, P1738, DOI [10.31838/jcr.07.05.296, DOI 10.31838/JCR.07.05.296]
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Azoug SE, 2016, OPT COMMUN, V359, P85, DOI 10.1016/j.optcom.2015.09.054
   Bekkouche T, 2019, OPT APPL, V49, P559, DOI 10.37190/oa190403
   Bekkouche T, 2018, OPTIK, V158, P940, DOI 10.1016/j.ijleo.2017.12.142
   Bigdeli N, 2012, COMPUT ELECTR ENG, V38, P356, DOI 10.1016/j.compeleceng.2011.11.019
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Florence ML, 2019, CLUSTER COMPUT, V22, P13119, DOI 10.1007/s10586-017-1276-7
   Girdhar A, 2021, APPL PHYS B-LASERS O, V127, DOI 10.1007/s00340-021-07585-x
   Hafsa A, 2021, MULTIMED TOOLS APPL, V80, P19769, DOI 10.1007/s11042-021-10700-x
   Herbadji D, 2020, IET IMAGE PROCESS, V14, P40, DOI 10.1049/iet-ipr.2019.0123
   Herbadji D, 2019, TRAIT SIGNAL, V36, P407, DOI 10.18280/ts.360505
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kelkar K., 2020, JCR-J CLIN RHEUMATOL, V7, P1433, DOI [10.31838/jcr.07.05.255, DOI 10.31838/JCR.07.05.255]
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Liu CY, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/3837209
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Luong M, 2011, J GLOBAL OPTIM, V49, P435, DOI 10.1007/s10898-010-9570-4
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Silva-García VM, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013012
   Marsaglia G., 2003, JMASM, V2, P2, DOI [DOI 10.22237/jmasm/1051747320, 10.22237/jmasm/1051747320, DOI 10.22237/JMASM/1051747320]
   Midoun MA, 2021, OPT LASER ENG, V139, DOI 10.1016/j.optlaseng.2020.106485
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Najm Hayder, 2021, International Journal of Interactive Mobile Technologies, V15, P184, DOI 10.3991/ijim.v15i02.19961
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Radhika KR, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P164, DOI 10.1109/ICRAECT.2017.56
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shariatzadeh M, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167779
   Stoyanov B, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010073
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Wadi SM, 2013, PROC TECH, V11, P51, DOI 10.1016/j.protcy.2013.12.161
   Yahi A, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168290
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yu MJ, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108227
   Zhou RG, 2018, INT J THEOR PHYS, V57, P1848, DOI 10.1007/s10773-018-3710-x
NR 44
TC 1
Z9 1
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7895
EP 7918
DI 10.1007/s11042-023-15858-0
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004891100003
DA 2024-07-18
ER

PT J
AU Zhang, JZ
   Zhang, G
   Kong, M
   Zhang, T
AF Zhang, Jinzhong
   Zhang, Gang
   Kong, Min
   Zhang, Tan
TI SCGJO: A hybrid golden jackal optimization with a sine cosine algorithm
   for tackling multilevel thresholding image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Golden jackal optimization; Sine cosine
   algorithm; Kapur's entropy; Image segmentation
ID MOTH-FLAME OPTIMIZATION
AB Multilevel thresholding is a fundamental, substantial and constructive technique that has been widely recognized and concerned in recent years. However, the computational complexity rises as the threshold level raises. The golden jackal optimization (GJO) imitates discovering prey, tracking and encircling prey, and trapping prey by employing a collaborative foraging mechanism. To eliminate the GJO's drawbacks, such as premature convergence, inferior computation accuracy and sluggish convergence rate, this paper proposes a hybrid golden jackal optimization with a sine cosine algorithm (SCGJO) based on Kapur's entropy to tackle the multilevel thresholding image segmentation, the intention is to actualize the accurate threshold values and the maximal fitness values. The SCGJO not only has fantastic adaptability and reliability to promote the complementary benefits and boost the convergence accuracy but also integrates exploration and exploitation to mitigate search stagnation and arrive at the ideal value. The experimental results demonstrate that the SCGJO is superior to the other algorithms and has a quicker convergence rate, higher computation accuracy, greater segmentation quality and stronger stability. In addition, the SCGJO is a steady and trustworthy approach for tackling image segmentation.
C1 [Zhang, Jinzhong; Zhang, Gang; Kong, Min; Zhang, Tan] West Anhui Univ, Sch Elect & Optoelect Engn, Luan 237012, Peoples R China.
C3 West Anhui University
RP Zhang, G (corresponding author), West Anhui Univ, Sch Elect & Optoelect Engn, Luan 237012, Peoples R China.
EM zhanggang@wxc.edu.cn
RI GAO, XIAO/JED-3257-2023
FU Start-up Fee for Scientific Research of High-level Talents in 2022
   [00701092336]; University Synergy Innovation Program of Anhui Province
   [GXXT-2021-026]; Smart Agriculture and Forestry and Smart Equipment
   Scientific Research and Innovation Team (Anhui Undergrowth Crop
   Intelligent Equipment Engineering Research Center) [2022AH010091];
   Scientific Research Project of University in Anhui Province
   [2022AH040241, 2022AH051674]
FX AcknowledgmentsThis work was partially funded by the Start-up Fee for
   Scientific Research of High-level Talents in 2022 under Grant No.
   00701092336, and partly supported by the University Synergy Innovation
   Program of Anhui Province under Grant No. GXXT-2021-026, Smart
   Agriculture and Forestry and Smart Equipment Scientific Research and
   Innovation Team (Anhui Undergrowth Crop Intelligent Equipment
   Engineering Research Center) under Grant No. 2022AH010091, Scientific
   Research Project of University in Anhui Province under Grant Nos.
   2022AH040241 and 2022AH051674.
CR Abdel-Basset M, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116145
   Abdel-Basset M, 2021, NEURAL COMPUT APPL, V33, P10685, DOI 10.1007/s00521-020-04820-y
   Agrawal S, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108172
   Al-Rahlawee ATH, 2021, MULTIMED TOOLS APPL, V80, P28217, DOI 10.1007/s11042-021-10860-w
   Aldahdooh A, 2018, DIGIT SIGNAL PROCESS, V77, P195, DOI 10.1016/j.dsp.2017.09.013
   Anitha J, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115003
   Bairwa AK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2571863
   Bridge PD, 1999, J CLIN EPIDEMIOL, V52, P229, DOI 10.1016/S0895-4356(98)00168-1
   Chen K, 2018, INFORM SCIENCES, V422, P218, DOI 10.1016/j.ins.2017.09.015
   Chopra N, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116924
   Chouksey M, 2020, MULTIMED TOOLS APPL, V79, P19075, DOI 10.1007/s11042-019-08138-3
   Das G, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500213
   Dinkar SK, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114766
   Duan LZ, 2021, J SUPERCOMPUT, V77, P6734, DOI 10.1007/s11227-020-03566-7
   Gill HS, 2022, MULTIMED TOOLS APPL, V81, P11005, DOI 10.1007/s11042-022-12093-x
   Hayyolalam V, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103249
   HOUSSEIN EH, 2021, EXPERT SYST APPL, V185
   Houssein EH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107348
   Jiang ZQ, 2021, ARAB J SCI ENG, V46, P8371, DOI 10.1007/s13369-021-05483-0
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kurmi Y, 2021, MULTIMED TOOLS APPL, V80, P3017, DOI 10.1007/s11042-020-09797-3
   Li XL, 2022, MULTIMEDIA SYST, DOI 10.1007/s00530-021-00882-7
   Liu QX, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10071014
   Liu X., 2022, J ELECTR ENG TECHNOL, P1
   Ma GY, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104960
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mookiah S, 2022, SOFT COMPUT, V26, P13193, DOI 10.1007/s00500-022-07133-5
   Naik MK, 2022, INT J IMAG SYST TECH, V32, P1397, DOI 10.1002/ima.22713
   Patra DK, 2022, PATTERN RECOGN IMAGE, V32, P174, DOI 10.1134/S1054661822010060
   Sharma A, 2022, MULTIMED TOOLS APPL, V81, P15521, DOI 10.1007/s11042-022-12303-6
   Shi CY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040773
   Si TP, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117481
   Singh S, 2020, NEURAL COMPUT APPL, V32, P16681, DOI 10.1007/s00521-020-04989-2
   Subasree S, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622501316
   Varga D, 2022, SIGNALS-BASEL, V3, P483, DOI 10.3390/signals3030028
   Vijh S, 2023, MULTIMED TOOLS APPL, V82, P4979, DOI 10.1007/s11042-022-12168-9
   Wang R, 2015, BIO-MED MATER ENG, V26, pS1345, DOI 10.3233/BME-151432
   Wang Y, 2022, J SUPERCOMPUT, V78, P11580, DOI 10.1007/s11227-021-04281-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu D, 2022, MACH INTELL RES, V19, P550, DOI 10.1007/s11633-022-1339-y
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Yan ZP, 2020, MULTIMED TOOLS APPL, V79, P32415, DOI 10.1007/s11042-020-09664-1
   Yang X-S, 2013, ARXIV
   Zhang YZ, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105542
NR 45
TC 3
Z9 3
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7681
EP 7719
DI 10.1007/s11042-023-15812-0
EA JUN 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900015
DA 2024-07-18
ER

PT J
AU Bouarroudj, K
   Kitouni, I
   Lechekhab, A
   Leghelimi, Z
   Kara, I
AF Bouarroudj, Kenza
   Kitouni, Ilham
   Lechekhab, Abdelmouhsen
   Leghelimi, Zinelabidine
   Kara, Issam
TI Quality evaluation of commercially available healthcare applications for
   prostate cancer management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate cancer; Artificial intelligence; MARS; HAs
ID RADIOTHERAPY
AB Many prostate cancer health applications are available on the software market. The main software solutions focus on helping patients cope with prostate cancer, helping urologists manage medical records and helping radiologists interpret multi-parametric magnetic resonance imaging. Some of these applications for prostate cancer make use of artificial intelligence. It is believed that artificial intelligence will play a key role in facilitating the clinical practice of health professionals and providing psychological support to patients. This study aims to assess the quality of commercially available applications for prostate cancer management.
C1 [Bouarroudj, Kenza] Abdelhamid Mehri Constantine 2 Univ, MISC Lab, Constantine, Algeria.
   [Kitouni, Ilham] Abdelhamid Mehri Constantine 2 Univ, LISIA Lab, Constantine, Algeria.
   [Lechekhab, Abdelmouhsen; Leghelimi, Zinelabidine] Abdelhamid Mehri Constantine 2 Univ, Constantine, Algeria.
RP Bouarroudj, K (corresponding author), Abdelhamid Mehri Constantine 2 Univ, MISC Lab, Constantine, Algeria.
EM kenza.bouarroudj@univ-constantine2.dz;
   ilham.kitouni@univ-constantine2.dz;
   abdelmouhsen.lechekhab@univ-constantine2.dz;
   zinelabidine.leghelimi@univ-constantine2.dz; karaissam.uro@gmail.com
RI Bouarroudj, kenza/JXN-6890-2024; kitouni, ilham/KHU-1804-2024
CR Aceto G, 2018, J NETW COMPUT APPL, V107, P125, DOI 10.1016/j.jnca.2018.02.008
   Algeria-Global Cancer Observatory, 2020, GLOBOCAN 2020 INT AG
   American Cancer Society, 2020, PROSTATECANCER RISK
   [Anonymous], 2022, GROWING PREVALENCE H
   [Anonymous], 2021, APP DOWNLOAD USAGE S
   Bohme C, 2018, J CANCER RES CLIN, V144, P173, DOI 10.1007/s00432-017-2533-0
   Brouard B, 2016, ANN MED, V48, P509, DOI 10.1080/07853890.2016.1195010
   Burton RJ, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0878-9
   Chen J, 2020, BJU INT, V126, P647, DOI 10.1111/bju.15226
   Chen J, 2019, BJU INT, V124, P567, DOI 10.1111/bju.14852
   Effiok Emmanuel Eyo, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P2303, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.340
   Gerke S, 2020, Artificial Intelligence in Healthcare, P295, DOI DOI 10.1016/B978-0-12-818438-7.00012-5
   Han S, 2019, ANN INTERN MED, V170, P784, DOI 10.7326/M18-1422
   iSalus Healthcare, 2021, 2021 EHR BUYERS GUID
   ISLAM Md, 2022, ARXIV
   Islam Md Milon, 2020, SN Comput Sci, V1, P185, DOI 10.1007/s42979-020-00195-y
   Jamnadass E, 2020, WORLD J UROL, V38, P2411, DOI 10.1007/s00345-020-03197-w
   Maurer T, 2019, NAT REV UROL, V16, P71, DOI 10.1038/s41585-018-0134-6
   Mesko Bertalan, 2017, Mhealth, V3, P38, DOI 10.21037/mhealth.2017.08.07
   Nabi J, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/20224
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Owens O.L., 2019, American Journal of Men's Health, V13
   Owens OL, 2018, AM J MENS HEALTH, V13, DOI 10.1177/1557988318816912
   Page MJ, 2021, INT J SURG, V88, DOI [10.1016/j.ijsu.2021.105906, 10.1016/j.jclinepi.2021.02.003, 10.1186/s13643-021-01626-4]
   Pereira-Azevedo N, 2017, JMIR CANCER, V3, P72, DOI 10.2196/cancer.6750
   Rodrigues R., 2020, Journal of Responsible Technology, V4, P100005, DOI [DOI 10.1016/J.JRT.2020.100005, 10.1016/j.jrt.2020.100005]
   Salonen A, 2014, PATIENT EDUC COUNS, V94, P10, DOI 10.1016/j.pec.2013.08.022
   Secinaro S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01488-9
   Spanakis EG, 2014, 2014 EAI 4TH INTERNATIONAL CONFERENCE ON WIRELESS MOBILE COMMUNICATION AND HEALTHCARE (MOBIHEALTH), P331, DOI 10.1109/MOBIHEALTH.2014.7015978
   Stacey Dawn, 2014, Cochrane Database Syst Rev, pCD001431, DOI [10.1002/14651858.CD001431.pub3, 10.1002/14651858.CD001431.pub5, 10.1002/14651858.CD001431.pub4]
   Stoyanov SR, 2015, JMIR MHEALTH UHEALTH, V3, DOI 10.2196/mhealth.3422
   Sundberg K, 2021, PATIENT EDUC COUNS, V104, P381, DOI 10.1016/j.pec.2020.08.003
   Sundberg K, 2017, SUPPORT CARE CANCER, V25, P2195, DOI 10.1007/s00520-017-3625-8
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI [DOI 10.3322/caac.21660, 10.3322/caac.21660]
   Terhorst Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241480
   Wang H, 2020, CANCER MANAG RES, V12, P12175, DOI 10.2147/CMAR.S269783
   Yang X, 2019, CHEM REV, V119, P10520, DOI 10.1021/acs.chemrev.8b00728
NR 37
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31793
EP 31819
DI 10.1007/s11042-023-15601-9
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:001003562600012
DA 2024-07-18
ER

PT J
AU Acharya, UK
   Kumar, S
AF Acharya, Upendra Kumar
   Kumar, Sandeep
TI Directed searching optimized texture based adaptive gamma correction
   (DSOTAGC) technique for medical image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Magnetic resonance imaging; Computed tomography;
   Directed searching optimization; Histogram equalization; Adaptive gamma
   correction
ID HISTOGRAM EQUALIZATION; ALGORITHM
AB Because of complexity and low contrast in medical images, few enhancement techniques result unwanted artifacts and information loss by affecting the structure similarity and peak signal to noise ratio. To meet these challenges, a Directed searching optimized texture-based adaptive gamma correction technique is proposed in this article. This proposed technique utilizes the textured regions of the image and suppresses the effect of non-textured regions for eliminating the artifacts. An adaptive clipping threshold is used in the textured image to control the enhancement rate. For improving the contrast, the transfer function of the enhanced image is evaluated using the modified weighted probability density function and adaptive gamma parameter. To make the algorithm more adaptive, parameters like clipped threshold, gamma parameter, and textural threshold are to be optimized using directed searching optimization algorithm. For improving the information contents and noise suppression capability, the proposed technique incorporated a fitness function which is a combination of entropy and peak signal to noise ratio. Equal weightage has been given to each parameter in the fitness function for obtaining a balanced optimal result. Then, the performance of the proposed technique is evaluated in terms of visual quality, information contents, average mean brightness error, noise suppression, and structural similarity. Experimental results show the proposed technique results in better visual effects without information loss. It effectively suppresses the effect of artifacts and significantly improves the contrast by making edges clearer and textures richer over other algorithms.
C1 [Acharya, Upendra Kumar] Galgotias Coll Engn & Technol, Dept Elect & Commun Engn, Greater Noida, Uttar Pradesh, India.
   [Acharya, Upendra Kumar; Kumar, Sandeep] Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
   [Acharya, Upendra Kumar] KIET Grp Inst, Dept Elect & Commun Engn, Ghaziabad, Uttar Pradesh, India.
C3 Galgotias College of Engineering & Technology (GCET); National Institute
   of Technology (NIT System); National Institute of Technology Delhi; KIET
   Group of Institutions
RP Kumar, S (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
EM sandeep@nitdelhi.ac.in
RI Kumar, Sandeep/V-7151-2019
OI Kumar, Sandeep/0000-0001-9922-2663; Acharya, Dr. Upendra
   Kumar/0000-0001-6271-2896
CR Acharya U.K., 2021, AISC, V1164, P607, DOI [10.1007/978-981- 15-4992-2 57, DOI 10.1007/978-981-15-4992-257]
   Acharya UK, 2023, MULTIDIM SYST SIGN P, V34, P25, DOI 10.1007/s11045-022-00853-9
   Acharya UK, 2021, OPTIK, V247, DOI 10.1016/j.ijleo.2021.167904
   Acharya UK, 2021, MULTIMED TOOLS APPL, V80, P24005, DOI 10.1007/s11042-021-10855-7
   Acharya UK, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166273
   Acharya UK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165760
   Agarwal M, 2020, INT J IMAG SYST TECH, V30, P687, DOI 10.1002/ima.22408
   [Anonymous], MRTIP DAT BAS
   [Anonymous], BIOM IM SEARCH ENG
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P6807, DOI 10.1109/TIM.2020.2976279
   Cascarano P, 2021, ARXIV
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P1725, DOI 10.1109/TCSS.2022.3178416
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   He KJ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3066467
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kallel F, 2017, IEEE T NANOBIOSCI, V16, P666, DOI 10.1109/TNB.2017.2771350
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kim HG, 2018, OPTIK, V166, P227, DOI 10.1016/j.ijleo.2018.03.139
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Li Z, 2020, INT J IMAG SYST TECH, V30, P939, DOI 10.1002/ima.22417
   Liu L, 2015, INT J IMAG SYST TECH, V25, P199, DOI 10.1002/ima.22137
   Magudeeswaran V, 2017, INT J IMAG SYST TECH, V27, P98, DOI 10.1002/ima.22214
   medpix, MED IM DAT
   Shoaib Mohammed, 2020, Journal of Physics: Conference Series, V1706, DOI 10.1088/1742-6596/1706/1/012091
   Singh K, 2016, J MOD OPTIC, V63, P1444, DOI 10.1080/09500340.2016.1154194
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Singh N, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3096266
   Subramani B, 2018, INT J IMAG SYST TECH, V28, P217, DOI 10.1002/ima.22272
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yang L, 2010, OPTIK, V121, P1752, DOI 10.1016/j.ijleo.2009.04.006
   Zarie M, 2019, IET IMAGE PROCESS, V13, P1081, DOI 10.1049/iet-ipr.2018.5395
   Zhao CY, 2019, BIOMED SIGNAL PROCES, V48, P189, DOI 10.1016/j.bspc.2018.10.008
   Zou DX, 2011, EXPERT SYST APPL, V38, P8716, DOI 10.1016/j.eswa.2011.01.079
NR 37
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6943
EP 6962
DI 10.1007/s11042-023-15953-2
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000166200002
PM 37362679
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Shelke, NA
   Kasana, SS
AF Shelke, Nitin Arvind
   Kasana, Singara Singh
TI Multiple forgery detection in digital video with VGG-16-based deep
   neural network and KPCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Forgery detection; Deep learning; VGG-16; KPCA; Inter-frame forgery;
   Intra-frame forgery
ID LOCALIZATION
AB The amount of video data is growing exponentially on a daily basis. Easily available software or mobile applications offer simple tools to perform the forgery in the video. So, before sending these videos from one place to another, it is important to verify them. In this paper, a forgery detection system is proposed to detect the multiple forgeries in the video using the VGG-16 deep neural model and KPCA (Kernel Principal Component Analysis). The proposed system works in four stages. The preprocessing approach is initially employed to extract and resize video frames. Then, a pre-trained VGG-16 model is tuned to extract the visual features from each input frame. A feature selection methodology, such as KPCA, is applied to minimize the dimensions of extracted features. Finally, correlations distribution among the selected features is analyzed to expose the forgeries. The performance of the proposed system is tested on a forged video dataset. The simulation result reveals that it gives better performance in identifying forgeries in the video, with accuracy and precision of 97.24% and 96.86%, respectively. In addition, the significance of the proposed system is that it yields superior results in post-processing operations like noise addition and adjustments to brightness, contrast, and hue.
C1 [Shelke, Nitin Arvind] Bennett Univ, Times India Grp, Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Kasana, Singara Singh] Thapar Inst Engn & Technol, Comp Sci & Engn, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Shelke, NA (corresponding author), Bennett Univ, Times India Grp, Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
EM nitinashelke@gmail.com
RI Shelke, Nitin Arvind/JCD-7173-2023
OI Shelke, Nitin Arvind/0000-0002-4801-1345
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Aloraini M, 2021, IEEE T CIRC SYST VID, V31, P917, DOI 10.1109/TCSVT.2020.2993004
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Clideo, 2020, US
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   FFmpeg, 2019, ABOUT US
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Kingra S, 2017, MULTIMED TOOLS APPL, V76, P25767, DOI 10.1007/s11042-017-4762-2
   Lee JM, 2004, CHEM ENG SCI, V59, P223, DOI 10.1016/j.ces.2003.09.012
   Li ZH, 2016, SECUR COMMUN NETW, V9, P4548, DOI 10.1002/sec.1648
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Long C., 2019, P IEEE C COMP VIS PA
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Qadir G., 2012, IET C IMAGE PROCESSI
   REWIND, 2013, DATS
   Shelke NA, 2022, MULTIMEDIA SYST, V28, P267, DOI 10.1007/s00530-021-00837-y
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   VTD, VIDEO TAMPERING DATA
   VTL, 2020, VIDEO TRACE LIB
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Zheng L, 2015, LECT NOTES COMPUT SC, V9023, P18, DOI 10.1007/978-3-319-19321-2_2
   Zheng Y., 2021, P IEEE CVF INT C COM
NR 27
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 2
PY 2023
DI 10.1007/s11042-023-15561-0
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KI8
UT WOS:000999746300002
DA 2024-07-18
ER

PT J
AU Mohammadi, A
   Akhaee, MA
AF Mohammadi, Ammar
   Akhaee, Mohammad Ali
TI Reversible data hiding in encrypted images using histogram modification
   and MSBs integration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Histogram modification; Prediction-errors; Reversible data hiding;
   Vacating room after encryption
ID ALGORITHM
AB Through cloud computing development, image encryption is employed to protect content-owner privacy. By the way, the need for embedding secret data in an encrypted image is the reason introducing reversible data hiding in an encrypted image. We may vacate the room before, by or after encryption to embed data. On the receiver side, data extraction can be done separately or jointly with the original image reconstruction. Meanwhile, presenting a separable scheme by vacating the room after encryption is more practical and more challenging than others which we do in this paper. In this way, we employ some notions of reversible data hiding (RDH) in a plain image, such as histogram modification and prediction-error computation. The most significant bits (MSBs) of the encrypted pixels are integrated to vacate the room for embedding data bits. The integrated MSBs would be more robust against failure of lossless reconstruction if modified for data embedding. Meanwhile, a data hider who embeds data is entirely blind to the original content. On the recipient side, data may be extracted error-freely and the original image may be reconstructed losslessly. We employ the chessboard predictor for the lossless reconstruction of the original image through prediction-error analysis. Integration of the encrypted pixels is an alternative method of compressing the encrypted pixels. Experimental results confirm that the proposed integration method outperforms the prior arts.
C1 [Mohammadi, Ammar] Res Ctr Developing Adv Technol, Tehran, Iran.
   [Akhaee, Mohammad Ali] Univ Tehran, Coll Engn, Dept Elect & Comp Engn, Tehran, Iran.
C3 University of Tehran
RP Mohammadi, A (corresponding author), Res Ctr Developing Adv Technol, Tehran, Iran.
EM mohammadi-a@rcdat.ac.ir; akhaee@ut.ac.ir
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen YC, 2019, IEEE T INF FOREN SEC, V14, P3332, DOI 10.1109/TIFS.2019.2914557
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Kaur G, 2022, ARTIF INTELL REV, VRev56, P1
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103478
   Mohammadi A, 2021, MULTIMED TOOLS APPL, V80, P3307, DOI 10.1007/s11042-020-09719-3
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Purohit Kaustubh, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2019. Advances in Intelligent Systems and Computing (AISC 1154), P135, DOI 10.1007/978-981-15-4032-5_14
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qiu YQ, 2022, IEEE T CIRC SYST VID, V32, P5874, DOI 10.1109/TCSVT.2022.3163905
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2022, IEEE T DEPEND SECURE, V19, P992, DOI 10.1109/TDSC.2020.3019490
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yin Zhaoxia, 2014, ScientificWorldJournal, V2014, P604876, DOI 10.1155/2014/604876
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 44
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15083-9
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H7JV7
UT WOS:000997691800001
DA 2024-07-18
ER

PT J
AU Feng, KL
   Huo, WX
   Xu, WH
   Li, M
   Li, TP
AF Feng, Kaili
   Huo, Wenxiao
   Xu, Wenhao
   Li, Meng
   Li, Tianping
TI CNA-DeepSORT algorithm for multi-target tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-target tracking; DeepSORT; Target detection; Attention mechanism;
   Multi-scale
ID RECOMMENDATION SYSTEM
AB In recent years, multi-target tracking algorithms have been developed rapidly. However, in multi-target tracking, mutual occlusion and cross between targets and sudden disappearance and reappearance of targets in videos can easily occur, which could only result in missed detection, false detection, and wrong ID switching. To address the above problems, the CenterNet attention DeepSORT algorithm (CNA-DeepSORT) proposed in this paper incorporates a CenterNet network with channel attention mechanism in the original detection part of the DeepSORT algorithm instead of Faster R-CNN, and designs a multi-scale feature extraction module with the DeepSORT algorithm in the multi-scale feature extraction module and designed a pedestrian recognition network combined with the DeepSORT algorithm. These improvements lead to a 3.7% improvement in MOTA metric, 1.6% improvement in MOTP metric, 238 fewer false ID switches, 2627 fewer FP metrics, 3943 fewer FN metrics, a decrease in run speed, and a 4 Hz reduction in frame rate compared to the original DeepSORT algorithm. improved by 3. 7, and there is some improvement in handling the occlusion problem of multi-target tracking, and the false and missed detection of targets during ID switching is reduced.
C1 [Feng, Kaili; Huo, Wenxiao; Li, Meng; Li, Tianping] Shandong Normal Univ, Sch Phys & Elect, Jinan 250014, Shandong, Peoples R China.
   [Xu, Wenhao] Dezhou Univ, Sch Phys & Elect Informat, Dezhou 253023, Shandong, Peoples R China.
C3 Shandong Normal University; Dezhou University
RP Li, TP (corresponding author), Shandong Normal Univ, Sch Phys & Elect, Jinan 250014, Shandong, Peoples R China.
EM fengkaili0210@163.com; huowx11@163.com; xwh_dream@163.com;
   limeng1110@163.com; sdsdltp@sdnu.edu.cn
RI luo, Jing/KFT-0288-2024
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Blackman SS, 2004, IEEE AERO EL SYS MAG, V19, P5, DOI 10.1109/MAES.2004.1263228
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Cavallaro A, 2016, ONLINE MULTITARGET T
   Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347
   Everingham M., 2011, Pattern Analysis, Statistical Modelling and Computational Learning, V8, P5
   Fan Q., 2019, PROC CVPR IEEE
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lan WK, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.4518
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Lee B, 2016, LECT NOTES COMPUT SC, V9914, P68, DOI 10.1007/978-3-319-48881-3_6
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo W, 2015, ARXIV
   Milan A., 2016, ARXIV160300831
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roccetti M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0235-y
   ROECKER JA, 1994, IEEE T AERO ELEC SYS, V30, P504, DOI 10.1109/7.272272
   Rui L A, 2022, PATTERN RECOGN
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smiatek J, 2021, TRENDS BIOTECHNOL, V39, P1117, DOI 10.1016/j.tibtech.2021.04.003
   Strippoli S, 2002, PERSONAL DIGITAL ASS
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yang B., 2014, PROC IEEE INT JOINT, P1
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng Z., 2017, IEEE Trans. on Circuits and Systems for Video Technology
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 42
TC 0
Z9 0
U1 54
U2 106
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15813-z
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OO5
UT WOS:000995776100002
DA 2024-07-18
ER

PT J
AU Li, YY
   Huang, Y
   Huang, WJ
   Wang, W
AF Li, Yuanyuan
   Huang, Yuan
   Huang, Weijian
   Wang, Wei
TI A global and local information extraction model incorporating selection
   mechanism for abstractive text summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abstractive text summarization; Dual encoding; Selection mechanism;
   Dilated convolution network
AB A global and local information extraction model incorporating selection mechanism is presented to address the concerns of insufficient semantic coding and redundant semantic information in the abstractive summary. The model, unlike single coding, encodes the source text twice. The global semantic information is extracted by the encoder based on Bidirectional Gated Recurrent Unit network, while the local feature vector is extracted by the encoder based on Dilated Convolution Network. The selection gate is in charge of filtering out redundant data. The output of the two encoders is fused as the input of the decoder to improve the feature representation at the source to generate diversified summaries. The model has good performance and effectively enhances the quality of summary, according on the experimental findings on two tough datasets, CNN/DailyMail and DUC 2004.
C1 [Li, Yuanyuan; Huang, Yuan; Huang, Weijian; Wang, Wei] Hebei Univ Engn, Sch Informat & Elect Engn, Handan 056038, Hebei, Peoples R China.
C3 Hebei University of Engineering
RP Li, YY (corresponding author), Hebei Univ Engn, Sch Informat & Elect Engn, Handan 056038, Hebei, Peoples R China.
EM lyuanyuanm@163.com
FU National Natural Science Foundation of China [61802107]; Handan science
   and technology R D plan project [21422093285]; Hebei Natural Science
   Foundation (Youth) project [D2021402043]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant Nos. 61802107); Handan science and technology
   R & D plan project(Grant Nos. 21422093285); Hebei Natural Science
   Foundation (Youth) project (Grant Nos. D2021402043).
CR [Anonymous], 2015, LCSTS LARGE SCALE CH
   [Anonymous], 2016, Abstractive text summarization using sequence-to-sequence rnns and beyond
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai S., 2018, EMPIRICAL EVALUATION
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P33701, DOI 10.1007/s11042-021-11345-6
   Chen L.Z, 2017, CORR ABS170605587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chopra Sumit, 2016, P 2016 C N AM CHAPT, P93, DOI DOI 10.18653/V1/N16-1012
   Ding J., 2019, COMPUT APPL, V39, P6
   Fudholi DH, 2022, J ENG SCI TECHNOL, V17, P730
   Gambhir M, MULTIMED TOOLS APPL
   Gao W., 2021, COMPUT ENG DES, V42, P9
   Gehring J, 2017, PR MACH LEARN RES, V70
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P24245, DOI 10.1007/s11042-022-12767-6
   He JZ, 2022, IEEE T PATTERN ANAL, V44, P100, DOI 10.1109/TPAMI.2020.3007074
   Hermann Karl Moritz, 2015, Advances in Neural Information Processing Systems, P1693
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang YX, 2022, APPL INTELL, V52, P9650, DOI 10.1007/s10489-021-02607-9
   Kalchbrenner Nal, 2016, ARXIV161010099
   Kedzie C, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1818
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Liang J, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/1270700
   Liang ZY, 2020, NEUROCOMPUTING, V410, P432, DOI 10.1016/j.neucom.2020.04.137
   Liao Kexin, 2018, Abstract Meaning Representation for Multi-Document summarization
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin H, 2019, AAAI CONF ARTIF INTE, P9815
   Lin JY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P163
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Ma TH, 2022, IEEE T COMPUT SOC SY, V9, P879, DOI 10.1109/TCSS.2021.3088506
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Napoles Courtney, 2012, P JOINT WORKSHOP AUT
   Niu GC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P496
   Oord A., 2016, ARXIV160903499
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Qiu D, 2022, COMPLEX INTELL SYST, V8, P555, DOI 10.1007/s40747-021-00527-2
   Rahman MM, 2021, ETRI J, V43, P288, DOI 10.4218/etrij.2019-0016
   Rani R, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115867
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Takase Sho, 2016, P 2016 C EMPIRICAL M, P1054, DOI [10.18653/v1/D16-1112, DOI 10.18653/V1/D16-1112]
   Wang BX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2311
   Wang K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2153
   Wang L, 2021, ABSTRACTIVE TEXT SUM, P2086
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang QL, 2021, NEUROCOMPUTING, V425, P290, DOI 10.1016/j.neucom.2020.04.136
   Wang WH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2306
   Xiao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3011
   Xu WR, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00674-7
   Yadav Vikas, 2019, P 27 INT C COMP LING
   Yao KC, 2020, IEEE T CYBERNETICS, V50, P985, DOI 10.1109/TCYB.2018.2876317
   Yu F., 2015, ARXIV
   Zhang ZD, 2019, IEEE T IMAGE PROCESS, V28, P1625, DOI 10.1109/TIP.2018.2877483
   Zhou QY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1095, DOI 10.18653/v1/P17-1101
NR 55
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15274-4
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300003
DA 2024-07-18
ER

PT J
AU Lu, GM
   Chen, HX
   Wei, JS
   Li, XN
   Zheng, XL
   Leng, HY
   Lou, YM
   Yan, JJ
AF Lu, Guanming
   Chen, Haoxia
   Wei, Jinsheng
   Li, Xiaonan
   Zheng, Xianlan
   Leng, Hongyao
   Lou, Yimo
   Yan, Jingjie
TI Video-based neonatal pain expression recognition with cross-stream
   attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Neonatal pain assessment; Neonatal pain expression recognition;
   Cross-stream attention; Deep learning; Convolutional neural networks
ID REPRESENTATION
AB Facial expression is considered as the most specific pain indicator, which has been effectively employed for neonatal pain assessment. Since neonates cannot verbalize their subjective pain experiences, recognizing neonatal pain expression automatically has great value and meaning. The Two-Stream Convolutional Network (TS-ConvNet) can effectively aggregate the spatial and temporal information in the neonatal pain expression videos by adopting the two-stream structure. However, traditional TS-ConvNet is unable to exploit the correlation across the spatial stream and temporal stream, due to the spatial and temporal streams being independent of each other. To overcome this drawback, this paper presents a Cross-Stream Attention (CSA) mechanism with non-local operations to model the correlation of the two streams and proposes a new model called TS-ConvNet with CSA units (TSCN-CSA) by introducing CSA mechanism into TS-ConvNet. TSCN-CSA enables spatial information and temporal information to interact with each other at different semantic levels, and employs ResNet-50 pre-trained on ImageNet as the backbone to extract neonatal pain expression features. In addition, to evaluate the performance of the proposed model, we collected a video dataset named Dynamic Facial Expression of Pain in Neonates (DFEPN), which is composed of 1897 video clips with four categories of expression labels: calmness, crying, moderate pain, and severe pain. The experimental results on the DFEPN dataset demonstrate that CSA units have a positive effect and improve the accuracy of TS-ConvNets for neonatal pain expression recognition. As a result, the proposed method achieves the promising recognition performance (66.20%) for the four categories based neonatal pain expression recognition.
C1 [Lu, Guanming; Chen, Haoxia; Wei, Jinsheng; Lou, Yimo; Yan, Jingjie] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Peoples R China.
   [Li, Xiaonan] Nanjing Med Univ, Childrens Hosp, Nanjing 210008, Peoples R China.
   [Zheng, Xianlan; Leng, Hongyao] Chongqing Med Univ, Natl Clin Res Ctr Child Hlth & Disorders, Key Lab Child Dev Dis Res, Minist Educ,Childrens Hosp, Chongqing 400014, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing Medical
   University; Chongqing Medical University
RP Lu, GM (corresponding author), Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Peoples R China.
EM lugm@njupt.edu.cn; 1219012734@njupt.edu.cn; 2018010217@njupt.edu.cn;
   xnli@njmu.edu.cn; zhengxianlan@cqmu.edu.cn; hongyaoleng@cqmu.edu.cn;
   2020010211@njupt.edu.cn; yanjingjie@njupt.edu.cn
RI li, xiaonan/U-7482-2019; Wei, Jinsheng/KBB-8618-2024
FU National Natural Science Foundation of China [72074038, 61971236]
FX This work was partly supported by National Natural Science Foundation of
   China (Grant Nos. 72074038 and 61971236). The authors would like to
   acknowledge the cooperation and generous assistance of all the nurses in
   the neonatal unit at Children's Hospital of Nanjing Medical University,
   the Second Affiliated Hospital of Nanjing Medical University, and
   Children's Hospital of Chongqing Medical University. We are especially
   grateful to the parents who had agreed to allow their children to take
   part in this study. Thanks to Jinsheng Wei (third author) who makes
   contributions to the technical guidance and theoretical analysis, the
   design and implementation of experiments, and the writing and technical
   editing, especially during the major revision, responsible for revision
   work, including supplementary experiments, rewriting most sections,
   rearranging structure, and clarification technical details.
CR Brahnam S, 2006, ARTIF INTELL MED, V36, P211, DOI 10.1016/j.artmed.2004.12.003
   Brahnam S, 2007, DECIS SUPPORT SYST, V43, P1242, DOI 10.1016/j.dss.2006.02.004
   Brahnam S, 2023, APPL COMPUT INFORM, V19, P122, DOI 10.1016/j.aci.2019.05.003
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gholami B, 2010, IEEE T BIO-MED ENG, V57, P1457, DOI 10.1109/TBME.2009.2039214
   Grunau RE, 1998, PAIN, V76, P277, DOI 10.1016/S0304-3959(98)00046-3
   GRUNAU RVE, 1987, PAIN, V28, P395, DOI 10.1016/0304-3959(87)90073-X
   Guanming Lu, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P251, DOI 10.1109/FSKD.2018.8687129
   Guanming Lu, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P756, DOI 10.1109/CSSE.2008.1321
   Hartley KA, 2015, ADV NEONAT CARE, V15, P201, DOI 10.1097/ANC.0000000000000193
   Hatfield L.A., 2013, Journal of Nursing Education and Practice, V3, P99, DOI [10.5430/jnep.v3n8p99, DOI 10.5430/JNEP.V3N8P99]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hummel P, 2006, SEMIN FETAL NEONAT M, V11, P237, DOI 10.1016/j.siny.2006.02.004
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Li C, 2019, PROC CVPR IEEE, P7864, DOI 10.1109/CVPR.2019.00806
   Lu GM, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1615, DOI 10.1109/FSKD.2016.7603418
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Prkachin K M, 2001, Pain Res Manag, V6, P105
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Ruicong Zhi, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P28, DOI 10.1007/978-3-030-68790-8_3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salekin MS, 2021, COMPUT BIOL MED, V129, DOI 10.1016/j.compbiomed.2020.104150
   Schwaller F, 2014, EUR J NEUROSCI, V39, P344, DOI 10.1111/ejn.12414
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Thiam P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030839
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Vaswani A., 2017, Adv. Neural Inf. Process. Syst, P6000
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J., 2022, ARXIV
   Wei JS, 2022, NEUROCOMPUTING, V479, P22, DOI 10.1016/j.neucom.2021.12.088
   Wei JS, 2021, NEUROCOMPUTING, V449, P159, DOI 10.1016/j.neucom.2021.03.063
   Yan J, 2020, PREPRINT, DOI [10.1109/TAFFC.2020.3030296, DOI 10.1109/TAFFC.2020.3030296]
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zamzmi Ghada, 2018, IEEE Reviews in Biomedical Engineering, V11, P77, DOI 10.1109/RBME.2017.2777907
   Zamzmi G, 2015, 11 IEEE INT C WORKSH
   Zhi RC, 2018, J CLIN MED, V7, DOI 10.3390/jcm7070173
NR 42
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15403-z
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YB1
UT WOS:000995344100001
DA 2024-07-18
ER

PT J
AU Tahbaz, M
   Shirgahi, H
   Yamaghani, MR
AF Tahbaz, Mahdi
   Shirgahi, Hossein
   Yamaghani, Mohammad Reza
TI Evolutionary-based image encryption using Magic Square Chaotic algorithm
   and RNA codons truth table
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; LS2 map; RNA codons; Magic square algorithm; Hash
   function; Genetic algorithm
ID HYBRID GENETIC ALGORITHM; PERMUTATION; MAP
AB Information security plays a key role in different areas such as Internet communications, medical imaging multimedia systems, and military communications. Image encryption is one of the techniques to ensure information security in communications. Therefore, this paper proposes a new hybrid model of a Magical Square Chaotic (MSC) algorithm and RNA codons for image encryption. The proposed model is composed of four steps. In the first phase, a secret key using the SHA-256 algorithm was considered for the initial value of the LS2 Map chaotic function. In the second phase, MSC algorithm was used for moving the image pixels. In the third phase, a combination of the RNA codons and chaotic function was employed for propagation of the image pixels. Finally, an optimization process was performed based on entropy criteria using genetic algorithm operators. The outputs of the simulation results confirm the superiority of the proposed model over other models. In addition, the analysis of the performance proves the high strength and security of the proposed model compared to the various types of attacks.
C1 [Tahbaz, Mahdi; Yamaghani, Mohammad Reza] Islamic Azad Univ, Dept Comp Engn, Lahijan Branch, Lahijan, Iran.
   [Shirgahi, Hossein] Islamic Azad Univ, Dept Comp Engn, Jouybar Branch, Jouybar, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Shirgahi, H (corresponding author), Islamic Azad Univ, Dept Comp Engn, Jouybar Branch, Jouybar, Iran.
EM hshirgahi.iau@gmail.com
CR Abbasi AA, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.106974
   Abbasi AA, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.164949
   Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Abdullah D, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012039
   Al-Mashhadi Haider M., 2017, 2017 International Conference on Current Research in Computer Science and Information Technology (ICCIT), P93, DOI 10.1109/CRCSIT.2017.7965540
   Alabaichi AM, 2016, INT J COMPUT SCI NET, V16, P105
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chenaghlu MA, FAST SECURE KEYED HA
   El-Zoghdy Said F., 2011, International Journal of Advanced Networking and Applications, V2, P796
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gulshan K., 2016, INDIAN J SCI TECHNOL, V9, P71871, DOI [10.17485/ijst/2016/v9i15/71871, DOI 10.17485/ijst/2016/v9i15/71871]
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Ibrahim Y, 2020, COMPLEXITY 2020
   Joshy A, 2017, 2017 INT C INV COMP
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Yin Q, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21062191
NR 30
TC 2
Z9 2
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15677-3
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600001
DA 2024-07-18
ER

PT J
AU Tejaswini, M
   Sumanth, TH
   Naik, KJ
AF Tejaswini, Mamidipaka
   Sumanth, T. Hari
   Naik, K. Jairam
TI Single image deraining using modified bilateral recurrent network
   (modified_BRN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image deraining; Recurrent network; Convolutional neural network; LSTM;
   Residual mapping; Direct mapping; Rain-streak layer; Backdrop
AB The process of reinstating a clean background to an image that has been destroyed by multiple rain streaks and rain built up is called Image Deraining. We propose a single recurrent network first that begins by iteratively unfolding one shallow-residual network and then uses a recurrent layer to transfer the in-depth properties across stages. The traditional SRN (Single Recurrent Network) was used to learn both residual mapping and direct mapping for the removal of unwanted rain-streaks and anticipating a clean backdrop. With the combining of the SRNs into modified Bilateral Recurrent Network (BRN), the rain-streak layer and the backdrop can be exploited. Hence, we put forward a model using bilateral LSTMs (Long Short-Term Memory) that can transmit deep-features of rain-streak layer and backdrop layer between stages, as well as introduce the inter-play between SRNs, resulting in a BRN. The proposed modified_BRN performs better over the sophisticated methods on real-world and synthetic datasets, such as the popular datasets: Rain100H, Rain 100 L and Rain 12. The comparative analysis of the experimental results has been analysed on the two standard parameters: PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index Measure).
C1 [Tejaswini, Mamidipaka; Sumanth, T. Hari; Naik, K. Jairam] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Naik, KJ (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
EM mamidipakatejaswini@gmail.com; harisumanth1637@gmail.com;
   Jnaik.cse@nitrr.ac.in
OI Naik, Dr K Jairam/0000-0002-6332-418X
CR [Anonymous], PYTORCH TUT
   Deng LJ, 2018, APPL MATH MODEL, V59, P662, DOI 10.1016/j.apm.2018.03.001
   Eigen D, 2018, RESTORING IMAGE TAKE
   Fan ZW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1751, DOI 10.1145/3240508.3240694
   Fu X, 2021, LIGHTWEIGHT PYRAMID
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Hu X, 2020, DEPTH ATTENTIONAL FE
   Jairam Naik K., 2020, ARTIFICIAL NEURAL NE, DOI [10.4018/978-1-7998-3238-6.ch005, DOI 10.4018/978-1-7998-3238-6.CH005]
   Jairam Naik K., 2020, ADV SECURITY PRIVACY, DOI [10.4018/978-1-7998-2795-5.ch001, DOI 10.4018/978-1-7998-2795-5.CH001]
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Li R, 2019, SINGLE IMAGE DERAINI
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liao Y, 2017, OVERVIEW SINGLE RECU
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Naik KJ, 2021, INT J COMPUT SCI ENG, V24, P653, DOI 10.1504/IJCSE.2021.119984
   Naik KJ, 2021, INT J COMMUN NETW DI, V27, P424, DOI 10.1504/IJCNDS.2021.119210
   Pan J, 2020, LEARNING DUAL CONVOL
   PSNR, US
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Removal R, MODEL DRIVEN DEEP NE
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   SivaSai JG, 2020, STUDIES COMPUTATIONA, P163, DOI [DOI 10.1007/978-981-15-5495-7_9, 10.1007/978-981-15-5495-7_9/COVER/]
   SSIM, US
   Sun L, 2017, RECOUPLED RECURRENT
   Sun L, 2017, COUPLED RECURRENT NE
   Syed F, 2019, BIDIRECTIONAL LONG S
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang C, SINGLE IMAGE RAIN RE
   Wang H, SURVEY RAIN REMOVAL
   Wang T, SPATIAL ATTENTIVE SI
   Wang T, 2020, SPATIAL ATTENTIVE SI
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Yang W, 2021, SCALE FREE SINGLE IM
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860
   Zhang H, 2019, Arxiv, DOI arXiv:1701.05957
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 39
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15276-2
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100003
DA 2024-07-18
ER

PT J
AU Liu, L
   Li, WW
   Liu, WB
   Li, Q
AF Liu, Lin
   Li, Wanwu
   Liu, Wenbao
   Li, Qiang
TI Real-scene 3D measurement algorithm and program implementation based on
   Mobile terminals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-scene 3D; Real-scene measurement; Measurement based on images;
   Photographs matching; Mobile terminals
ID VECTOR DATA; RECONSTRUCTION; MODEL
AB For real-scene three-dimensional (3D) Location Based Service (LBS), in order to overcome the defects of the poor spatial analysis and computing ability of 3D visualization based on images, the research deduces algorithms and designs schemes to realize the real-scene measurement on mobile terminals for homologous photographs with inner and outer directional elements according to the principle of close-range photogrammetry. The research proposes two methods of recognition and matching image feature points in different scenarios, and designs schemes including the preprocessing of image zooming, auxiliary selecting and prediction and display of feature points, so as to solve the problem of accurately recognizing the same ground point in the left and right photographs on mobile devices with a small screen. Then we program the above algorithm in Android system to realize real-scene images based 3D coordinate measurement and geometric measurement on smartphone terminals. At last, we carry out real-scene measurement experiment, data solving and error analysis using experimental calibration field data and measured data. The results show that the method proposed in the research can achieve real-scene measurement on mobile terminals, with certain guarantees for algorithm accuracy and execution efficiency.
C1 [Liu, Lin; Li, Wanwu; Liu, Wenbao; Li, Qiang] Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Li, WW (corresponding author), Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.
EM liwanwuqd@126.com
FU Natural Science Foundation of Shandong Province [ZR2019MD034]
FX The study was supported by the Natural Science Foundation of Shandong
   Province (NO. ZR2019MD034).
CR Andaru R, 2022, IEEE J-STARS, V15, P5924, DOI 10.1109/JSTARS.2022.3192264
   [毕卫华 Bi Weihua], 2021, [国土资源遥感, Remote Sensing for Land & Resources], V33, P248
   Cai ZW., 2019, SIMUL, V36, p88
   Caradonna G, 2018, LECT NOTES COMPUT SC, V10964, P305, DOI 10.1007/978-3-319-95174-4_25
   Cheng ML, 2022, AUTOMAT CONSTR, V135, DOI 10.1016/j.autcon.2021.104105
   Dang P, 2022, INT J DIGIT EARTH, V15, P1081, DOI 10.1080/17538947.2022.2080878
   Fadzli FE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084009
   Jasinska A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020728
   Lee J, 2022, INT J APPL EARTH OBS, V111, DOI 10.1016/j.jag.2022.102820
   Li D., 2008, INTRO PHOTOGRAMMETRY
   [李德仁 Li Deren], 2010, [测绘学报, Acta Geodetica et Cartographica Sinica], V39, P111
   Li DR., 2007, DIGITAL MEASURABLE I, p377
   Li ZL, 2002, PHOTOGRAMM ENG REM S, V68, P847
   Liu T, 2016, COMPUT GEOSCI-UK, V89, P12, DOI 10.1016/j.cageo.2016.01.008
   [刘小波 Liu Xiaobo], 2022, [测绘学报, Acta Geodetica et Cartographica Sinica], V51, P522
   Liu YP, 2022, FRONT PHYS-LAUSANNE, V9, DOI 10.3389/fphy.2021.828825
   Mehrabi M, 2016, SIGNAL PROCESS-IMAGE, V46, P54, DOI 10.1016/j.image.2016.05.005
   Ngeljaratan L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236844
   Pepe M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122412886
   Qiu YG, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15051211
   Supangkat SH, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15053942
   Wang CL, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11070383
   Wang GL, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11040234
   Wang HP, 2022, IEEE T IND ELECTRON, V69, P1694, DOI 10.1109/TIE.2021.3060643
   Wang SG., 2009, PHOTOGRAMMETRY
   Wang XG, 2023, ENG STRUCT, V279, DOI 10.1016/j.engstruct.2023.115589
   Wang Z., 2007, The Principle of Photogrammetry
   Wang ZX, 2023, J PLANT GROWTH REGUL, V42, P294, DOI [10.13700/j.bh.1001-5965.2022.0195, 10.1007/s00344-021-10547-4, 10.13254/j.jare.2022.0065]
   Xu Z, 2022, INT ARCH PHOTOGRAMME
   Yang BX, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107804
   Yang JQ, 2023, MICROMACHINES-BASEL, V14, DOI 10.3390/mi14020242
   [袁武彬 Yuan Wubin], 2020, [地理与地理信息科学, Geography and Geo-information Science], V36, P22
   Zhang Y, 2022, J SENSORS
   Zhang Z, 2023, OPT LETT, V48, P243, DOI 10.1364/OL.478758
   Zhang ZX., 2002, DIGITAL PHOTOGRAMMET
   Zhao L, 2023, INT J REMOTE SENS, V44, P713, DOI 10.1080/01431161.2023.2169844
   [朱庆 Zhu Qing], 2022, [测绘学报, Acta Geodetica et Cartographica Sinica], V51, P1040
   Zhu Xinyan, 2015, Geomatics and Information Science of Wuhan University, V40, P285, DOI 10.13203/j.whugis20140462
NR 38
TC 0
Z9 0
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47441
EP 47455
DI 10.1007/s11042-023-15595-4
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986153600001
DA 2024-07-18
ER

PT J
AU Otair, M
   Alrawi, AF
   Abualigah, L
   Jia, HM
   Altalhi, M
AF Otair, Mohammed
   Alrawi, Amer F.
   Abualigah, Laith
   Jia, Heming
   Altalhi, Maryam
TI Enhancing the quality of compressed images using rounding intensity
   followed by novel dividing technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compressed Images; Rounding Intensity Followed; Digital Image;
   Distortion
ID PARTICLE SWARM OPTIMIZATION; AVERAGING FUSION STRATEGY; ALGORITHM;
   WATERMARKING; DCT; CT
AB The most extensive data storage size is significantly increasing, and storing such data, including images to make them obtainable over the network, has become a significant problem. Thus, efficient compression techniques are necessary because the original images need much disk space. Generally, the primary purpose of image compression is to decrease the amount of data required for representing digital images. Image compression techniques can be categorized into lossless and lossy. Rounding Intensity followed by the Dividing Technique (FIRD) is a known lossy technique utilized in the proposed method that aims to reduce the range of the intensities and increase redundancy, achieving better compression performance. The main idea of this paper is to separate the (8*8 block of mage) into two parts: the matrix of hundreds and the single matrix. The elements in the hundreds matrix will be divided into 10, and the resulted matrix will be compressed using the Huffman technique. The elements in the single matrix will be rounded as follow: 0,1,2,3, and 4 to 2, and the elements 5, 6, 7, 8, and 9 are rounded to 7. Then, the Huffman technique will be applied to the resulting matrix. The previously generated values are combined, and the initial results indicate a reduction in distortion with better compression performance. This paper deals with whether the proposed technique enhancing the quality of Compressed Images using Rounding Intensity Followed by the Dividing Technique (E-RFID) can be used as a distinctive option in the distortion reduction process image a high compression ratio. In addition, image compression technology and quality enhancement with high compression explain each step's work, which will be presented in detail. The research factors have been positively impacted by improving the results and comparing them through MSE, PSNR, and MAE. The E-RIFD technique experiments showed an improved rate in MSE 66.82% and PSNR 18.31%, while the MAE improvement rate was 21.09% for grayscale images. However, when testing color images, the results show that the rate of improvement in MSE was 66.59% and PSNR 15.28, while the improvement rate in the MAE was 18.64%.
C1 [Otair, Mohammed; Alrawi, Amer F.] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Al al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Sch Comp Sci, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Yuan Ze Univ, Coll Engn, Taoyuan, Taiwan.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
   [Jia, Heming] Sanming Univ, Sch Informat Engn, Sanming 365004, Peoples R China.
   [Altalhi, Maryam] Taif Univ, Coll Business Adm, Dept Management Informat Syst, POB 11099, Taif 21944, Saudi Arabia.
C3 Al al-Bayt University; Yuan Ze University; Al-Ahliyya Amman University;
   Middle East University; Universiti Sains Malaysia; Sunway University;
   Sanming University; Taif University
RP Abualigah, L (corresponding author), Al al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Sch Comp Sci, Comp Sci Dept, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Yuan Ze Univ, Coll Engn, Taoyuan, Taiwan.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
EM Otair@aau.edu.jo; amerff89@gmail.com; aligah.2020@gmail.com;
   jiaheming@fjsmu.edu.cn; marem.m@tu.edu.sa
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Jassim FA, 2012, Arxiv, DOI arXiv:1211.4591
   Abualigah L, 2022, MULTIMED TOOLS APPL, V81, P16707, DOI 10.1007/s11042-022-12001-3
   Abualigah L, 2021, PROCESSES, V9, DOI 10.3390/pr9071155
   Alshami AL, 2018, INT J ADV COMPUT SC, V9, P397
   Cao QJ, 2020, MULTIMED TOOLS APPL, V79, P27091, DOI 10.1007/s11042-020-09265-y
   Chung KL, 2006, CHAOS SOLITON FRACT, V29, P215, DOI 10.1016/j.chaos.2005.08.023
   Cristobal G., 2013, Optical and digital image processing: fundamentals and applications
   Dorafshan S, 2018, CONSTR BUILD MATER, V186, P1031, DOI 10.1016/j.conbuildmat.2018.08.011
   Ewees AA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9192363
   Ezugwu AE, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104743
   Gandomi AH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030421
   Gharaibeh M, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6010002
   Gharaibeh M, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6010029
   Talukder KH, 2010, Arxiv, DOI arXiv:1010.4084
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Houssein EH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107348
   Impallaria A, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01091-x
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Li RY, 2002, IMAGE VISION COMPUT, V20, P37, DOI 10.1016/S0262-8856(01)00075-0
   Lin SY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121700
   Liu QX, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10071014
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P8825, DOI 10.1007/s11042-019-7545-0
   Lyon RF, 2006, P SOC PHOTO-OPT INS, V6069, P6901, DOI 10.1117/12.644941
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Meng Z, 2019, MULTIMED TOOLS APPL, V78, P33969, DOI 10.1007/s11042-019-08161-4
   Mohammad N, 2017, MULTIMED TOOLS APPL, V76, P13301, DOI 10.1007/s11042-016-3757-8
   Otair M, 2022, MULTIMED TOOLS APPL, V81, P28509, DOI 10.1007/s11042-022-12846-8
   Othman G., 2020, J. Soft Comput. Data Mining, V1, P31
   Philip Achimugu, 2011, Efficient Decision Support Systems - Practice and Challenges in Biomedical Related Domain, P311
   Poobal S., 2011, INT J ENG SCI TECHNO, V2, P239
   Rawat CS, 2013, INT ARAB J INF TECHN, V10, P553
   Robertson S, 2018, TRANSL RES, V194, P19, DOI 10.1016/j.trsl.2017.10.010
   Sharma M, 2010, INT J COMPUT SCI NET, V10, P133
   Shaukat S., 2020, Chaos Theory Appl., V30, P17
   Shehab M, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105458
   Shinde BS., 2012, IOSR J ENG, V1, P066, DOI [10.9790/3021-0116671, DOI 10.9790/3021-0116671]
   Si-Mohamed SA, 2022, EUR RADIOL, V32, P524, DOI 10.1007/s00330-021-08103-5
   Singh AP., 2016, INT RES J ENG TECHNO, V3, P2395
   Truong TK, 2000, IEEE T IMAGE PROCESS, V9, P529, DOI 10.1109/83.841930
   Vidal M, 2012, CHEMOMETR INTELL LAB, V117, P138, DOI 10.1016/j.chemolab.2012.05.009
   Vijendran AS, 2011, GLOBAL J COMP SCI TE, V11, P49
   Walia S, 2019, AUST J FORENSIC SCI, V51, P488, DOI 10.1080/00450618.2018.1424241
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu MS, 2007, ENG APPL ARTIF INTEL, V20, P531, DOI 10.1016/j.engappai.2006.08.005
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhao JL, 2019, ENG REP, V1, DOI 10.1002/eng2.12038
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 53
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15612-6
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600009
DA 2024-07-18
ER

PT J
AU Kulkarni, S
   Rabidas, R
AF Kulkarni, Sujata
   Rabidas, Rinku
TI Fully convolutional network for automated detection and diagnosis of
   mammographic masses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; U-Net; Mammogram; Mass detection; Classification
ID COMPUTER-AIDED DETECTION; DEEP; CLASSIFICATION
AB Breast cancer, though rare in male, is very frequent in female and has high mortality rate which can be reduced if detected and diagnosed at the early stage. Thus, in this paper, deep learning architecture based on U-Net is proposed for the detection of breast masses and its characterization as benign or malignant. The evaluation of the proposed architecture in detection is carried out on two benchmark datasets- INbreast and DDSM and achieved a true positive rate of 99.64% at 0.25 false positives per image for INbreast dataset while the same for DDSM are 97.36% and 0.38 FPs/I, respectively. For mass characterization, an accuracy of 97.39% with an AUC of 0.97 is obtained for INbreast while the same for DDSM are 96.81%, and 0.96, respectively. The measured results are further compared with the state-of-the-art techniques where the introduced scheme takes an edge over others.
C1 [Kulkarni, Sujata; Rabidas, Rinku] Assam Univ, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
C3 Assam University
RP Kulkarni, S (corresponding author), Assam Univ, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM sujata.kulkarni@aus.ac.in; rabidas.rinku@gmail.com
OI Kulkarni, Sujata/0000-0001-5419-2990
CR Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774
   Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409
   Akselrod-Ballin A, 2016, DEEP LEARNING DATA L
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Alanazi SA, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5528622
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Astley SM, 2004, CLIN RADIOL, V59, P390, DOI 10.1016/j.crad.2003.11.017
   Behera SK, 2021, MULTIMED TOOLS APPL, V80, P19043, DOI 10.1007/s11042-021-10704-7
   Casti P, 2014, IEEE ENG MED BIO, P4667, DOI 10.1109/EMBC.2014.6944665
   Chakraborty J, 2018, EXPERT SYST APPL, V99, P168, DOI 10.1016/j.eswa.2018.01.010
   Chicco D, 2021, IEEE ACCESS, V9, P78368, DOI 10.1109/ACCESS.2021.3084050
   Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Hamidinekoo A, 2018, MED IMAGE ANAL, V47, P45, DOI 10.1016/j.media.2018.03.006
   Hammad M, 2022, MULTIMEDIA SYST, V28, P1373, DOI 10.1007/s00530-020-00728-8
   Hammad M, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033072
   Hassan SA, 2020, MULTIMED TOOLS APPL, V79, P30735, DOI 10.1007/s11042-020-09518-w
   Heath M, 2000, P 4 INT WORKSH DIG M, DOI [10.1007/978-94-011-5318-875, DOI 10.1007/978-94-011-5318-875]
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Laishram R, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107620
   Laishram R, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P327, DOI 10.1109/CISP-BMEI51763.2020.9263644
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Mahmood T, 2021, P INT COMP SOFTW APP, P1918, DOI 10.1109/COMPSAC51774.2021.00291
   Metz Charles E, 2006, J Am Coll Radiol, V3, P413, DOI 10.1016/j.jacr.2006.02.021
   Mohammadi N, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Pisano ED, 2005, NEW ENGL J MED, V353, P1773, DOI 10.1056/NEJMoa052911
   Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226
   Ren S., 2016, ARXIV
   Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarkar PR, 2019, PR INT CONF DATA SC, P453, DOI 10.1109/DSAA.2019.00060
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Sethy PK, 2021, J INTELL FUZZY SYST, V41, P5253, DOI 10.3233/JIFS-189848
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Yang Wei T, 2006, AJR Am J Roentgenol, V187, pW576, DOI 10.2214/AJR.05.0126
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 44
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44819
EP 44840
DI 10.1007/s11042-023-14757-8
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000985452800014
PM 37362703
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, HR
   Wu, CH
   Li, T
AF Yang, Xin
   Li, Hengrui
   Wu, Chenhuan
   Li, Tao
TI SCCADC-SR: a real image super-resolution based on self-calibration
   convolution and adaptive dense connection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Real image degradation model; Self-calibration
   convolution; Adaptive dense connection; Attention mechanism
ID RECOMMENDATION SYSTEM
AB Because the real degradation model is more complex, and the different computing performance of devices leads to different degradation results. The super-resolution based on the real image degradation model has great challenges in practical applications. To solve these problems, we propose a novel SR network based on self-calibration convolution and adaptive dense connection (SCCADC-SR). Firstly, we introduce self-calibration convolution as the basic convolution module and use it as a supplement to the attention mechanism. Secondly, we use efficient channel attention (ECA) to construct an adaptive dense connection structure to deal with the features at the different levels. Then, we use the CutBlur method to enhance the data to improve the generalization ability of the model and use the long skip connection to improve the convergence of the depth model structure. Finally, SCCADC-SR combines self-ensemble and model ensemble to improve the model's robustness and reduce the noise. Experimental results show that for both real image data and Bicubic data, our SCCADC-SR improves SR reconstruction performance by 5% compared with the state-of-the-art methods.
C1 [Yang, Xin; Li, Hengrui; Wu, Chenhuan; Li, Tao] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yang, X (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
EM yangxin@nuaa.edu.cn
RI chen, zhuo/JXX-1337-2024; Li, Kunpeng/KFS-6306-2024; wang,
   liangyu/KHD-1769-2024; Yan, Xin/KGL-5903-2024; Li, Bo/KHX-7246-2024;
   zhang, zheng/KHY-8870-2024; zhong, jing/KBP-7800-2024; ZHANG,
   JING/KHY-1073-2024; WANG, YONGJIA/KFQ-4823-2024; YANG,
   DAN/KCL-5217-2024; Liu, Zhe/KEJ-5299-2024; Yin, Jing/KDO-6274-2024
OI Yang, Xin/0000-0003-0445-6497
FU National Natural Science Foundation of China [61573182, 62073164];
   Fundamental Research Funds for the Central Universities [NS2022041]
FX This research was supported by the National Natural Science Foundation
   of China (61573182, 62073164), and by the Fundamental Research Funds for
   the Central Universities (NS2022041).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   [Anonymous], 2020, AIM2020 WORKSH CHALL
   Anwar S, 2019, ARXIV
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Huang HY, 2021, PHYS REV X, V11, DOI 10.1103/PhysRevX.11.041038
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jaejun Yoo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8372, DOI 10.1109/CVPR42600.2020.00840
   Jang DW, 2019, IEEE COMPUT SOC CONF, P1795, DOI 10.1109/CVPRW.2019.00230
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, IEEE CONF COMPUT
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J., 2020, arXiv
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Muqeet A., 2020, ARXIV
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Shang TZ, 2020, IEEE COMPUT SOC CONF, P1778, DOI 10.1109/CVPRW50498.2020.00228
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wei P., 2020, P EUR C COMP VIS, P101
   Wu H., 2020, IEEE T CIRCUITS SYST
   Yan Q, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2414877
   Yang X, 2021, MULTIMED TOOLS APPL, V80, P7063, DOI 10.1007/s11042-020-09958-4
   Yang XY, 2024, CRIT REV BIOTECHNOL, V44, P302, DOI 10.1080/07388551.2022.2149386
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang Y., 2019, arXiv
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 44
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45699
EP 45716
DI 10.1007/s11042-023-15481-z
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983956900006
DA 2024-07-18
ER

PT J
AU Rao, BC
   Rani, SS
   Shashidhar, K
   Satyanarayana, G
   Raju, K
AF Rao, B. Chinna
   Rani, S. Saradha
   Shashidhar, K.
   Satyanarayana, Gandi
   Raju, K.
TI An effective image-denoising method with the integration of thresholding
   and optimized bilateral filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer tomography; Entropy difference; Thresholding; Denoising;
   Generative adversarial network
ID RECONSTRUCTION; SEGMENTATION
AB In medical image processing, noise reduction is a particularly difficult problem to solve. Denoising can aid doctors in making a diagnosis of sickness. Due to statistical uncertainty in all physical measurements used in computed tomography, noise is unavoidably injected into CT images. To improve the quality of CT images, edge-preserving denoising methods and noise reduction techniques are needed. If the noise in low-draught CT pictures can be reduced or eliminated, then it should be able to boost its effectiveness without raising the draught. As a result, the extraction method used in this research is known as the optimized bilateral filter, and wavelet-based packet thresholding. Levy based rat prey catching optimization (LRPSO) is proposed to optimize the weight function of bilateral filtering. The denoising technique is employed to safeguard the edges and get rid of the noise. The proposed methodology's results are analyzed and contrasted using certain established methods. According to the differentiated outcome analysis, the Proposed Methodology's execution is finer and more acceptable to the existing procedures in terms of optical standard PSNR, SSIM, and Entropy Difference (ED). The PSNR of the projected model for 25 images, under CT1, CT2, CT3 and CT4 database is 27.92, 26.02, 26.46 and 26.78, respectively.
C1 [Rao, B. Chinna] Raghu Engn Coll, Dept Elect & Commun Engn, Visakhapatnam 531162, Andhra Pradesh, India.
   [Rani, S. Saradha] GITAM Deemed Univ, Dept Elect & Commun Engn, Visakhapatnam 530045, India.
   [Shashidhar, K.] Guru Nanak Inst Tech Campus Autonomous, Dept Elect & Commun Engn, Hyderabad, India.
   [Satyanarayana, Gandi] Avanthi Inst Engn & Technol, Dept Comp Sci & Engn, Vizianagaram 531162, Andhrapradesh, India.
   [Raju, K.] Narasaraopeta Engn Coll Autonomous, Dept Elect & Commun Engn, Guntur, Andhra Pradesh, India.
C3 Gandhi Institute of Technology & Management (GITAM); Guru Nanak
   Institutions Technical Campus
RP Rao, BC (corresponding author), Raghu Engn Coll, Dept Elect & Commun Engn, Visakhapatnam 531162, Andhra Pradesh, India.
EM chinnaraob84@gmail.com
OI Satyanarayana, Gandi/0000-0003-0612-6424; Shashidhar,
   Dr.K./0009-0008-5345-1039
CR Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Chen HG, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165864
   Chen ZL, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101632
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gong CC, 2019, SIGNAL PROCESS, V165, P149, DOI 10.1016/j.sigpro.2019.06.031
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Irfan M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063056
   Kazantsev D, 2019, SOFTWAREX, V9, P317, DOI 10.1016/j.softx.2019.04.003
   Khaleghi Goli, 2021, Informatics in Medicine Unlocked, V24, DOI 10.1016/j.imu.2021.100573
   Li JG, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8738960
   Liu Y, 2022, COMPUT MATH METHOD M
   Mahanta B, 2020, J NAT GAS SCI ENG, V77, DOI 10.1016/j.jngse.2020.103227
   Martinez-Garcia J, 2021, DENDROCHRONOLOGIA, V69, DOI 10.1016/j.dendro.2021.125877
   Naik A, 2021, WIRELESS PERS COMMUN, V116, P655, DOI 10.1007/s11277-020-07732-1
   Ojha C, 2015, INT GEOSCI REMOTE SE, P2461, DOI 10.1109/IGARSS.2015.7326308
   Reimer RP, 2020, EUR J RADIOL, V132, DOI 10.1016/j.ejrad.2020.109267
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1211, DOI 10.1007/s11760-012-0389-y
   Sidorenko M, 2021, COMPUT GEOSCI-UK, V151, DOI 10.1016/j.cageo.2021.104716
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tan SW, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/4900803
   Usui K, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00087-9
   Yang FQ, 2020, NEUROCOMPUTING, V378, P65, DOI 10.1016/j.neucom.2019.09.087
   Yang H, 2021, COMPOS SCI TECHNOL, V213, DOI 10.1016/j.compscitech.2021.108875
NR 29
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43923
EP 43943
DI 10.1007/s11042-023-15266-4
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976628900005
DA 2024-07-18
ER

PT J
AU Saha, P
   Das, R
   Das, SK
AF Saha, Prottoy
   Das, Rudra
   Das, Shanta Kumar
TI BCM-VEMT: classification of brain cancer from MRI images using deep
   learning and ensemble of machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain cancer; Convolutional neural network; Transfer learning; Ensemble
   of classifiers; Machine learning; MRI images
ID TUMOR CLASSIFICATION
AB Brain cancer is quite possibly the most common cause of death in recent years. Appropriate diagnosis of the cancer type empowers the specialists to make the right choice of treatment, decision, and to save the patient's life. It goes without saying the importance of a computer-aided diagnosis system with image processing that can classify the tumor types correctly. In this paper, an enhanced approach has been proposed that can classify brain tumor types from magnetic resonance images (MRI) using deep learning and an ensemble of machine learning (ML) algorithms. The system named BCM-VEMT can classify among four different classes that consist of three categories of brain cancers (Glioma, Meningioma, and Pituitary) and a non-cancerous class, which means normal type. A convolutional neural network was developed to extract deep features from the MRI images. These extracted deep features are fed into ML classifiers to classify among these cancer types. Finally, a weighted average ensemble of classifiers is used to achieve better performance by combining the results of each ML classifier. The dataset of the system has a total of 3787 MRI images of four classes. BCM-VEMT has achieved better performance with 97.90% accuracy for the Glioma class, 98.94% accuracy for Meningioma, 98.92% accuracy for Pituitary and 98.00% accuracy for the Normal class. BCM-VEMT can have great significance for medical sectors in classifying brain cancer types.
C1 [Saha, Prottoy; Das, Rudra; Das, Shanta Kumar] Khulna Univ Engn & Technol, Dept Comp Sci & Engn, Khulna 9203, Bangladesh.
C3 Khulna University of Engineering & Technology (KUET)
RP Saha, P (corresponding author), Khulna Univ Engn & Technol, Dept Comp Sci & Engn, Khulna 9203, Bangladesh.
EM prottoy@cse.kuet.ac.bd; rudradas4074@gmail.com; aunkurdas7777@gmail.com
CR Bakas Spyridon, 2017, TCIA
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bhanothu Y, 2020, INT CONF ADVAN COMPU, P248, DOI [10.1109/ICACCS48705.2020.9074375, 10.1109/icaccs48705.2020.9074375]
   Cancer Treatment Centers of America, 2022, TYP BRAIN CANC COMM
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ezhilarasi R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P388, DOI 10.1109/I-SMAC.2018.8653705
   Figshare, 2022, BRAIN TUM DAT
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   ILSVRC, 2022, ILSVRC 2014 RES
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Kaggle.com, 2022, BRAIN MRI IM BRAIN T
   Kaggle.com, 2022, BRAIN TUM CLASS MRI
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Khan HA, 2020, MATH BIOSCI ENG, V17, P6203, DOI 10.3934/mbe.2020328
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Medicalnewstoday.com, 2022, MEDICALNEWSTODAY
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Montreal Children's Hospital, 2022, TRUE FALS NOT ALL TU
   National Brain Tumor Society, 2022, QUICK BRAIN TUM FACT
   Noreen N, 2021, CMC-COMPUT MATER CON, V67, P3967, DOI 10.32604/cmc.2021.014158
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Ramya P, 2021, J AMB INTEL HUM COMP, V12, P9939, DOI 10.1007/s12652-021-03390-8
   Rezaei K, 2022, IETE J RES, V68, P3829, DOI 10.1080/03772063.2020.1780487
   Sawant A, 2018, BRAIN, V5, P2089
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
NR 30
TC 4
Z9 4
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44479
EP 44506
DI 10.1007/s11042-023-15377-y
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000977223400004
DA 2024-07-18
ER

PT J
AU Yuan, Y
   Hongjie, H
   Chen, F
   Yuan, CQ
AF Yuan, Yuan
   Hongjie, He
   Chen, Fan
   Yuan, Changqi
TI Reversible data hiding in encrypted JPEG image with changing the number
   of AC codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; JPEG image; Adaptive encryption key; Histogram
   shift; 0-1 Conversion; AC codes
ID SCHEME
AB A reversible data hiding (RDH) in encrypted JPEG images (JPEG-RDH-EI) with an adaptive encryption key generated by minimum coded units histogram (MCUH) is proposed. However, the marked encrypted images are vulnerable to chosen-plaintext attack (CPA) since the MCUH is unchanged during the encryption and RDH process, which allows the encryption key can be reproduced by the marked encrypted image. To improve the security of marked encrypted images, this paper changes the MCUH in the RDH process by 0-1 conversion (refers to changing the value of coefficients from 0 to 1). To reduce the file growth, this paper explores the condition that the 0-1 conversion without file growth first. Then, a histogram shift scheme with embeddable zero coefficients is designed. The experimental results show that the proposed scheme can enhance the security of marked encrypted images by changing MCUH. In addition, the proposed algorithm has a smaller file growth and higher maximum embedding capacity than the existing histogram shift schemes since it embeds additional data in zero coefficients.
C1 [Yuan, Yuan; Hongjie, He] Southwest Jiaotong Univ, Sch Informat Sci & Technol, 999 Xian Rd, Chengdu 620010, Peoples R China.
   [Chen, Fan] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, 999 Xian Rd, Chengdu 620010, Peoples R China.
   [Yuan, Changqi] Beijing Inst Elect Technol & Applicat, 15 Xinjian Gongmen Rd, Beijing 100142, Peoples R China.
C3 Southwest Jiaotong University; Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, 999 Xian Rd, Chengdu 620010, Peoples R China.
EM ytuanyuan@my.swjtu.edu.cn; hjhe@home.swjtu.edu.cn; fchen@swjtu.edu.cn;
   13051231321@163.com
FU National Natural Science Foundation of China (NSFC) [U1936113, 61872303]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (NSFC) under Grant U1936113 and 61872303. In
   addition, many thanks to the editors and anonymous reviewers for their
   insightful comments and valuable suggestions, which helped a lot to
   improve the paper quality.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Du YC, 2021, INT J PAVEMENT ENG, V22, P1659, DOI 10.1080/10298436.2020.1714047
   Fridrich J, 2004, PROC SPIE, V5306, P354, DOI 10.1117/12.525418
   He JH, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107647
   He JH, 2020, IEEE T INF FOREN SEC, V15, P2121, DOI 10.1109/TIFS.2019.2958758
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   He JH, 2018, IEEE T MULTIMEDIA, V20, P2645, DOI 10.1109/TMM.2018.2817065
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Independent JPEG Group, About us
   Kerckhoffs A., 1883, J. des Sci. militaires, V1, P5
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Muchinguri, 1992, DIGITAL COMPRESSION
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2023, IEEE T MULTIMEDIA, V25, P2528, DOI 10.1109/TMM.2022.3148591
   Qiu YQ, 2021, IEEE T CIRC SYST VID, V31, P1380, DOI 10.1109/TCSVT.2020.3006494
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   [王洋洋 Wang Yangyang], 2020, [计算机研究与发展, Journal of Computer Research and Development], V57, P2271
   Wedaj FT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0206-1
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Yuan Y, 2022, LECT NOTES COMPUT SC, V13180, P58, DOI 10.1007/978-3-030-95398-0_5
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng M., 2018, J CYBER SECURITY, V3, P12
   Zhenxing Qian, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P1055, DOI 10.1109/TDSC.2016.2634161
NR 30
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43649
EP 43669
DI 10.1007/s11042-023-14614-8
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000973357400002
DA 2024-07-18
ER

PT J
AU Wang, JN
   Jia, ZH
   Lai, HC
   Shi, F
AF Wang, Junnan
   Jia, Zhenhong
   Lai, Huicheng
   Shi, Fei
TI A real time target face tracking algorithm based on saliency detection
   and Camshift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Kalman filter; Camshift algorithm; Face tracking
ID CORRELATION FILTER; MEAN-SHIFT; FUSION; FEATURES
AB To take advantage of the speed advantage of the Camshift and try to overcome the problem of its poor robustness in target tracking, in this paper, a real time target face tracking algorithm based on saliency detection and Camshift is proposed. Considering that the target to be tracked is more significant than the background in the frame, the saliency detection algorithm MBplus is first used to remove the background around the target as much as possible, so as to reduce the interference caused by the background to the Camshift tracking results. Then the Camshift is used to search and localize the targets in the processed video frames. At the same time, to compensate for the lack of tracking ability of Camshift for some characteristic targets, the Kalman filter is used to predict the position of the target in the current frame. Finally, the Kalman-predicted target position, the target position obtained by Camshift, are compared with the target tracked in the previous frame, and the position with high similarity is considered as the target tracking result of this paper. The experimental results show that the average tracking precision of the proposed target face tracking algorithm on the Birchfield database is 94.0%, its average tracking success rate on the NRC-IIT Facial Video Database is 100%, and even for the target faces with few attributes in ytcelebrity database, its tracking precision and tracking success rate are all 100%, which are superior to some state-of-the-art tracking algorithms.
C1 [Wang, Junnan; Jia, Zhenhong; Lai, Huicheng; Shi, Fei] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Wang, Junnan; Jia, Zhenhong; Lai, Huicheng; Shi, Fei] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Jia, ZH (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.; Jia, ZH (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM 1254982138@qq.com; jzhh9009@sohu.com; lai590@qq.com; sigofei@xju.edu.cn
FU National Science Foundation of China [61665012, U1803261]; International
   Science and Technology Cooperation Project of the Ministry of Education
   of the People's Republic of China [DICE 2016-2196]; Scientific research
   plan of universities in Xinjiang Uygur Autonomous Region [XJEDU2019Y006]
FX This work was supported by the National Science Foundation of China
   under Grant 61665012 and Grant U1803261, the International Science and
   Technology Cooperation Project of the Ministry of Education of the
   People's Republic of China under Grant DICE 2016-2196, and the
   Scientific research plan of universities in Xinjiang Uygur Autonomous
   Region under Grant XJEDU2019Y006. We would like to thank the referees
   for their efforts to review our manuscript, as well as for their
   valuable suggestions and questions.
CR [Anonymous], 1998, Intel Technology Journal, DOI DOI 10.1109/ACV.1998.732882
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gorodnichy DO, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P330, DOI 10.1109/CRV.2005.87
   Guan MY, 2021, IEEE T MULTIMEDIA, V23, P3841, DOI 10.1109/TMM.2020.3032043
   Guo F, 2020, IEEE T CIRC SYST VID, V30, P4887, DOI 10.1109/TCSVT.2019.2906226
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu RY, 2021, AAAI CONF ARTIF INTE, V35, P7789
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jiang X, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3149097
   Kim J, 2017, PATTERN RECOGN, V61, P139, DOI 10.1016/j.patcog.2016.07.039
   Kim M., 2008, Military Communications Conference, P1
   Laaroussi K, 2018, MULTIMED TOOLS APPL, V77, P13947, DOI 10.1007/s11042-017-5000-7
   Lee M, 2022, IEEE IMAGE PROC, P806, DOI 10.1109/ICIP46576.2022.9897408
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Libin Hu, 2019, International Symposium for Intelligent Transportation and Smart City (ITASC) 2019. Proceedings. Branch of ISADS (The International Symposium on Autonomous Decentralized Systems). Smart Innovation, Systems and Technologies (SIST 127), P84, DOI 10.1007/978-981-13-7542-2_8
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma F., 2023, IEEE T GEOSCI ELECT, V61, DOI DOI 10.1109/TGRS.2022.3231253
   Mondal A, 2021, APPL INTELL, V51, P5259, DOI 10.1007/s10489-020-02047-x
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Nawaz M, 2021, IEEE T MULTIMEDIA, V23, P2902, DOI 10.1109/TMM.2020.3019688
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Park C, 2022, IEEE IMAGE PROC, P811, DOI 10.1109/ICIP46576.2022.9897797
   Pei LL, 2022, MULTIMED TOOLS APPL, V81, P2145, DOI 10.1007/s11042-021-11673-7
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Putro MD, 2021, IEEE T IND INFORM, V17, P4449, DOI 10.1109/TII.2020.3022501
   Qi YK, 2020, IEEE T IMAGE PROCESS, V29, P9152, DOI 10.1109/TIP.2020.3023621
   Qian XL, 2023, IEEE T MULTIMEDIA, V25, P1810, DOI 10.1109/TMM.2022.3167805
   Ranganatha S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P772, DOI 10.1109/ICACCI.2017.8125935
   Saboo S, 2021, MULTIMED TOOLS APPL, V80, P20579, DOI 10.1007/s11042-021-10669-7
   Soetedjo A, 2016, INT CONF COMP SCI ED, P209, DOI 10.1109/ICCSE.2016.7581582
   Sun HP, 2021, MULTIMED TOOLS APPL, V80, P22719, DOI 10.1007/s11042-019-07761-4
   Tathe SV, 2013, P INT C ADV SIGN PRO
   Topkaya IS, 2019, SIGNAL IMAGE VIDEO P, V13, P61, DOI 10.1007/s11760-018-1328-3
   Wang JN, 2020, IEEE ACCESS, V8, P162022, DOI 10.1109/ACCESS.2020.3021235
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang SG, 2021, IEEE T CYBERNETICS, V51, P4212, DOI 10.1109/TCYB.2018.2881482
   Yan JR, 2021, MULTIMED TOOLS APPL, V80, P2355, DOI 10.1007/s11042-020-09644-5
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
   Zeng Y, 2018, IEEE T IMAGE PROCESS, V27, P4545, DOI 10.1109/TIP.2018.2838761
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang PP, 2019, IEEE T IMAGE PROCESS, V28, P3048, DOI 10.1109/TIP.2019.2893535
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
NR 57
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43599
EP 43624
DI 10.1007/s11042-023-14889-x
EA APR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000971514700001
DA 2024-07-18
ER

PT J
AU Prakash, A
   Bhandari, AK
AF Prakash, Anshuman
   Bhandari, Ashish Kumar
TI Cuckoo search constrained gamma masking for MRI image contrast
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Cuckoo search algorithm; Wavelet transforms;
   Masking; Gamma correction; MRI image enhancement
ID BAT ALGORITHM; HISTOGRAM; SEGMENTATION; OPTIMIZATION; SCHEME
AB Poor quality images in Magnetic Resonance Imaging (MRI) may not provide enough information for visual interpretation of the affected areas of the human body. Cuckoo Search Constrained Gamma Masking for MRI Image Contrast Enhancement is a novel adaptive image enhancement technique described in this paper to improve image views and give computational support. Nature-inspired algorithms are widely applied in the arena of image enhancement for various optimization purposes. Cuckoo search is one of the prominent nature-inspired performance algorithms that we employed in this work for the enhancement of magnetic resonance imaging (MRI). We proposed a wavelet-based masking technique employing a cuckoo search algorithm whose masking value is corrected by gamma function for the contrast enhancement of MRI images. The cuckoo search algorithm can inevitably fine-tune the relation of nest building using genetic operatives like adaptive cusp and alteration. The proposed contrast enhancement scheme is examined quantitatively for different types of MRI images. Extensive simulation results compared with quantitative values have revealed that the traditional nest building of cuckoo search optimization is improved by adaptive gamma correction. Comparative analysis with the existing works establishes the usefulness of the proposed methodology over the other standard approaches.
C1 [Prakash, Anshuman; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM anshuman.nitp@gmail.com; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
CR Abdel-Basset M, 2019, MULTIMED TOOLS APPL, V78, P3861, DOI 10.1007/s11042-017-4803-x
   Agrawal S, 2016, STUD COMPUT INTELL, P53
   Agrawal S, 2020, STUD COMPUT INTELL, V841, P85, DOI 10.1007/978-981-13-8930-6_5
   Ashour AmiraS., 2015, Journal of Signal and Information Processing, V6, P244, DOI DOI 10.4236/JSIP.2015.63023
   Bhandari AK, 2014, ISA T, V53, P1286, DOI 10.1016/j.isatra.2014.04.007
   Bhandari A K., 2018, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
   Bhandari AK, 2020, SOFT COMPUT, V24, P1619, DOI 10.1007/s00500-019-03992-7
   Bhandari Ashish Kumar, 2020, IEEE T INSTRUM MEAS
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chang YC, 2010, IEEE T CONSUM ELECTR, V56, P737, DOI 10.1109/TCE.2010.5505995
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen L, 2019, SOFT COMPUT, V23, P11297, DOI 10.1007/s00500-019-03844-4
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Daniel E, 2016, COMPUT BIOL MED, V71, P149, DOI 10.1016/j.compbiomed.2016.02.011
   Dhal Krishna Gopal, 2018, International Journal of Medical Engineering and Informatics, V10, P164
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, EVOL SYST-GER, V10, P129, DOI 10.1007/s12530-018-9216-1
   Dhal KG, 2015, ADV INTELL SYST, V339, P233, DOI 10.1007/978-81-322-2250-7_23
   Doury M, 2017, IRBM, V38, P179, DOI 10.1016/j.irbm.2017.07.001
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Hemanth J., 2019, INTEL SYST REF LIBR
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Iqbal MZ, 2014, SIGNAL PROCESS, V105, P430, DOI 10.1016/j.sigpro.2014.05.011
   Kallel F, 2018, SIGNAL IMAGE VIDEO P, V12, P905, DOI 10.1007/s11760-017-1232-2
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kumar M, 2020, IEEE T IMAGE PROCESS, V29, P7525, DOI 10.1109/TIP.2020.3004036
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P9033, DOI 10.1007/s11042-017-5277-6
   Manju VN, 2019, MULTIMED TOOLS APPL, V78, P14897, DOI 10.1007/s11042-018-6652-7
   Michahial S, 2019, EVOL INTELL, P1, DOI [DOI 10.1007/978-3-319-69892-2_62-1, 10.1007/978-3-319-69892-2_62-1, DOI 10.1007/978-1-4614-6439-6_1661-3]
   Prasath R, 2019, IMAGING SCI J, V67, P76, DOI 10.1080/13682199.2018.1552356
   Rundo L, 2019, EXPERT SYST APPL, V119, P387, DOI 10.1016/j.eswa.2018.11.013
   Sagayam K.M., 2018, Hybrid Metaheuristics Image Analysis, P87
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Sathish P, 2019, COMP M BIO BIO E-IV, V7, P273, DOI 10.1080/21681163.2017.1386593
   Shehab M., 2020, ARTIF INTELL, DOI [10.1007/978-3-030-36083-2, DOI 10.1007/978-3-030-36083-2]
   Shehab M, 2017, APPL SOFT COMPUT, V61, P1041, DOI 10.1016/j.asoc.2017.02.034
   Singh M, 2017, BIOCYBERN BIOMED ENG, V37, P124, DOI 10.1016/j.bbe.2016.10.006
   Singh N, 2020, IET IMAGE PROCESS, V14, P794, DOI 10.1049/iet-ipr.2019.0921
   Subramani B, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01568-9
   Sumathi R, 2018, BIOCYBERN BIOMED ENG, V38, P918, DOI 10.1016/j.bbe.2018.07.005
   Suresh S, 2017, IEEE J-STARS, V10, P3665, DOI 10.1109/JSTARS.2017.2699200
   Veluchamy M, 2020, MULTIMED TOOLS APPL, V79, P19945, DOI 10.1007/s11042-020-08870-1
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
NR 53
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40129
EP 40148
DI 10.1007/s11042-023-14545-4
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900017
DA 2024-07-18
ER

PT J
AU Ma, XJ
   Wang, CH
AF Ma, Xiaojuan
   Wang, Chunhua
TI Hyper-chaotic image encryption system based on N+2 ring Joseph algorithm
   and reversible cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; N+2 ring Joseph algorithm; Hyper-chaotic system;
   Reversible cellular automata
ID ATTRACTOR; MATRIX
AB Due to the complex characteristics of chaotic system, such as initial value sensitivity, periodicity and pseudo-randomness, chaotic sequences generated by chaotic system is very suitable for image data encryption after appropriate processing. This paper focuses on chaotic image encryption based on the improved Joseph algorithm, and proposes a hyperchaotic image encryption system based on N + 2 ring Joseph algorithm and reversible cellular automata. The initial value of the chaotic system is generated by the SHA-512 hash value of the original image, which makes the proposed encryption algorithm highly sensitive to the original image. In addition, the proposed N + 2 ring Joseph algorithm is formed by N chaotic sequences rolling forward like gears when scrambling each pixel position of the image. It greatly hides the pixel information of the original text, and increases the scrambling effect and the difficulty of being cracked. Furthermore, in the diffusion stage, we add the reversible cellular automata technology. On the basis of image shuffling, each pixel is further associated with other pixels, so that small changes of in pixel values can produce an avalanche effect. Finally, we conducted simulation experiments and safety analysis. The results illustrate that the encryption algorithm proposed in this paper has good encryption performance, and can effectively resist statistical attacks, differential attacks, known plaintext attacks, ciphertext only attacks, select plaintext attacks and select ciphertext attacks. In conclusion, it is a practical and secure image encryption algorithm.
C1 [Ma, Xiaojuan; Wang, Chunhua] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Wang, CH (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM wch1227164@hnu.edu.cn
RI Wang, Chunhua/HCH-5464-2022; Ma, Xiaojuan/GPP-6619-2022
OI Wang, Chunhua/0000-0001-6522-9795; 
FU National Natural Science Foundation of China [61971185]; Natural Science
   Foundation of Hunan Province [2020JJ4218]
FX AcknowledgmentsThis work is supported by the National Natural Science
   Foundation of China(No.61971185) and Natural Science Foundation of Hunan
   Province(2020JJ4218).
CR Abu Dalhoum AL, 2016, MULTIMED TOOLS APPL, V75, P17019, DOI 10.1007/s11042-015-2972-z
   Alvarez G, 2003, PHYS LETT A, V319, P334, DOI 10.1016/j.physleta.2003.10.044
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen RJ, 2010, SIGNAL PROCESS-IMAGE, V25, P413, DOI 10.1016/j.image.2010.03.002
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Habutsu T., 1991, SECRET KEY CRYPTOSYS, DOI DOI 10.1007/3-540-46416-6_11
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Kai F., 2022, RES IMAGE ENCRYPTION
   LI Chang, 2018, Research on key technologies of composited positioning forshearer
   Lin HR, 2021, IEEE T CIRCUITS-I, V68, P3397, DOI 10.1109/TCSI.2021.3081150
   Lin HR, 2021, IEEE T IND ELECTRON, V68, P12708, DOI 10.1109/TIE.2020.3047012
   Lin HA, 2021, CAN J PLANT PATHOL, V43, P62, DOI 10.1080/07060661.2020.1755366
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Wang CH, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S021812661850038X
   Wang X, 2021, INFORM SCIENCES, V574
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   WOLFRAM S, 1986, ADV APPL MATH, V7, P123, DOI 10.1016/0196-8858(86)90028-X
   WOLFRAM S, 1983, REV MOD PHYS, V55, P601, DOI 10.1103/RevModPhys.55.601
   Wu J., 2013, LECT NOTES ELECT ENG, V163, P1941, DOI [10.1007/978-1-4614-3872-4_248, DOI 10.1007/978-1-4614-3872-4_248]
   Xian YJ, 2022, INFORM SCIENCES, V596, P304, DOI 10.1016/j.ins.2022.03.025
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xie WL, 2021, NONLINEAR DYNAM, V104, P4523, DOI 10.1007/s11071-021-06476-2
   Xu B., 2017, NOVEL IMAGE ENCRYPTI, DOI [10.1007/978-3-319-69471-9_23, DOI 10.1007/978-3-319-69471-9_23]
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Xwa B, 2021, INFORM SCIENCES
   YANG GL, 2014, MATH PROBL ENG, V2014, P1
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang X, 2019, IEEE ACCESS, V7, P16336, DOI 10.1109/ACCESS.2019.2894853
   Zheng S, 2010, APPL MATH COMPUT, V215, P3192, DOI 10.1016/j.amc.2009.09.060
   Zhou L, 2018, INT J CIRC THEOR APP, V46, P84, DOI 10.1002/cta.2339
   Zhou L, 2016, NONLINEAR DYNAM, V85, P2653, DOI 10.1007/s11071-016-2852-8
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 47
TC 20
Z9 20
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38967
EP 38992
DI 10.1007/s11042-023-15119-0
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000010
DA 2024-07-18
ER

PT J
AU Singh, N
   Bhat, A
AF Singh, Nishant
   Bhat, Aruna
TI A systematic review of the methodologies for the processing and
   enhancement of the underwater images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Underwater image enhancement; Underwater image restoration; Deep
   learning; Image quality evaluation; Image dehazing; Image datasets
ID COLOR CORRECTION; RESTORATION
AB Underwater image processing has received tremendous attention in the past few years. The reason for increased research in this area is that the process of taking images underwater is very difficult. Images obtained underwater frequently suffer from quality deterioration issues such as poor contrast, blurring features, colour variations, non-uniform lighting, the presence of dust particles, noise at the bottom of the sea, different properties of the water medium, and so on. The improvement of underwater images is a critical problem in image processing and computer vision for a variety of practical applications. To address this problem, we need to find some other methods to increase the quality of the image while capturing it underwater. But capturing the image in normal circumstances as well as underwater is the same, so once we get an image, some mechanism to increase the quality of the captured image will also be required. A complete and in-depth study of relevant accomplishments and developments, particularly the survey of underwater image methods and datasets, which are a critical issue in underwater image processing and intelligent application, is still lacking. In this paper, we first provide a review of more than 85 articles on the most recent advancements in underwater image restoration methods, underwater image enhancement methods, and underwater image enhancement using deep learning and machine learning methods, along with the techniques, data sets, and evaluation criteria. To provide a thorough grasp of underwater image restoration, enhancement, and enhancement using deep learning and machine learning, we explore the strengths and limits of existing techniques. Additionally, we offer thorough, unbiased reviews and evaluations of the representative methodologies for five distinct types of underwater situations, which vary their usefulness in various underwater circumstances. Two main evaluations, subjective image quality evaluation and objective image quality evaluation; are used for evaluating the quality of images. These evaluations are useful to determine the efficiency of the predefined methods. With the help of these image quality evaluations, we come to the conclusion that the image enhancement methods and image enhancement methods using deep learning and machine learning are superior in comparison to the image restoration methods. As deep learning and machine learning based enhancement methods are newer and give far better results in comparison to the other two methods, lots of researchers are moving towards these methods. Finally, we also explore the potential difficulties and unresolved problems associated with underwater image enhancement and offer potential future research areas.
C1 [Singh, Nishant; Bhat, Aruna] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, India.
C3 Delhi Technological University
RP Bhat, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, India.
EM aruna.bhat@dtu.ac.in
RI Bhat, Aruna/GSI-4485-2022; Singh, Nishant/AAT-9718-2020
OI Bhat, Aruna/0000-0002-5475-8664; Singh, Nishant/0000-0003-2597-7726
CR Almabouada F, 2019, FRONT OPTOELECTRON, V12, P405, DOI 10.1007/s12200-019-0865-x
   Ancuti CO, 2017, IEEE IMAGE PROC, P695, DOI 10.1109/ICIP.2017.8296370
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti CO, 2017, IEEE COMPUT SOC CONF, P997, DOI 10.1109/CVPRW.2017.136
   Ancuti C, 2016, INT C PATT RECOG, P4202, DOI 10.1109/ICPR.2016.7900293
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Андреев А.В. Andreev A.V.], 2005, [Экологические системы и приборы, Ecological Systems and Devices, Ekologicheskie sistemy i pribory], P15
   [Anonymous], 2012, International Journal of Emerging Technology and Advanced Engineering
   [Anonymous], P CAR M MAR BREST FR
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Berman D, 2018, ARXIV
   Boom BJ, 2014, ECOL INFORM, V23, P83, DOI 10.1016/j.ecoinf.2013.10.006
   Bryson M, 2016, J FIELD ROBOT, V33, P853, DOI 10.1002/rob.21638
   Caimi Frank M., 2007, OCEANS 2007 - Europe, P1, DOI 10.1109/OCEANSE.2007.4302476
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chambah M, 2004, PROC SPIE, V5293, P157
   Chen CLP, 2012, IEEE T INTELL TRANSP, V13, P1657, DOI 10.1109/TITS.2012.2201478
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Chiang JY, 2011, LECT NOTES COMPUT SC, V6915, P372, DOI 10.1007/978-3-642-23687-7_34
   Cho Y., 2016, P IEEE OC, P1
   /csms.haifa.ac.il, RGBD UNDERWATER IMAG
   Cutter G, 2015, 2015 IEEE WINTER APPLICATIONS AND COMPUTER VISION WORKSHOPS (WACVW), P57, DOI 10.1109/WACVW.2015.11
   CVPR, 2018, WORKSHOP CHALLENGE A
   CVPR, 2019, WORKSHOP CHALLENGE A
   Dai Qin, 2013, Infrared and Laser Engineering, V42, P1706
   Del Grosso V. A., 1975, OCEAN 75 Conference, P331, DOI 10.1109/OCEANS.1975.1154053
   Ding XY, 2017, OCEANS-IEEE
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Emberton S., 2015, PROC BRIT MACH VIS C, V125, DOI 10.5244/C.29.125
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Fish4Knowledge, HOMEPAGES NF ACUK RB
   fishdb.co.uk, UNDERWATER PHOTOGRAP
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-757
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   github.com, RUIE DATASET
   github.com, PORT ROYAL UNDERWATE
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Grosso VAD, 1978, OPTICAL TRANSFER FUN, P74
   habcam.whoi.edu, HABCAM UNDERWATER IM
   [韩宏伟 Han Hongwei], 2011, [光子学报, Acta Photonica Sinica], V40, P136
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   HONJO S, 1984, DEEP-SEA RES, V31, P67, DOI 10.1016/0198-0149(84)90073-6
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Hou W., 2007, P SOC PHOTO-OPT INS, V6696, P707
   Hou WL, 2008, OPT EXPRESS, V16, P9958, DOI 10.1364/OE.16.009958
   Hou W, 2007, INT GEOSCI REMOTE SE, P1889, DOI 10.1109/IGARSS.2007.4423193
   HUFNAGEL RE, 1964, J OPT SOC AM, V54, P52, DOI 10.1364/JOSA.54.000052
   Iqbal K., 2007, INT J COMPUT SCI, V34, P1
   Jia Dong-xiao, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P76, DOI 10.1109/CSIP.2012.6308799
   Jian MW, 2017, IEEE INT CON MULTI, P1297, DOI 10.1109/ICME.2017.8019324
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li Y, 2019, WIREL NETW, P1, DOI DOI 10.1007/S11276-019-02092-6
   Liu R, 2019, ARXIV
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Mei Wang, 2010, Proceedings of the 12th Asia Pacific Web Conference (APWEB 2010), P253, DOI 10.1109/APWeb.2010.24
   Nery MS, 2005, SIBGRAPI 2005: XVIII Brazilian Symposium on Computer Graphics and Image Processing, Conference Proceedings, P173
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Peng YT, 2016, IEEE IMAGE PROC, P1953, DOI 10.1109/ICIP.2016.7532699
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Perez J, 2017, LECT NOTES COMPUT SC, V10338, P183, DOI 10.1007/978-3-319-59773-7_19
   Petit F, 2009, INT CONF ACOUST SPEE, P1177, DOI 10.1109/ICASSP.2009.4959799
   Sahoo A, 2019, OCEAN ENG, V181, P145, DOI 10.1016/j.oceaneng.2019.04.011
   Singh N., 2021, 2021 INT C ARTIFICIA, P1, DOI [10.1109/AIMV53313.2021.9670938, DOI 10.1109/AIMV53313.2021.9670938]
   Soni OK, 2020, INT CONF COMM SYST, P333, DOI [10.1109/CSNT.2020.61, 10.1109/CSNT48778.2020.9115732]
   Tan C. S., 2007, OCEANS 2006 - Asia Pacific, P1
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395
   Uemura T., 2020, 2 EAI INT C ROBOTIC, P53
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   VOSS KJ, 1990, APPL OPTICS, V29, P3638, DOI 10.1364/AO.29.003638
   Wang K, 2014, IEEE WINT CONF APPL, P800, DOI 10.1109/WACV.2014.6836021
   Wang Y, 2017, 2017 IEEE INT S CIRC, P1
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   www.mbari.org, MBARI UNDERWATER IMA
   Yang M, 2020, IEEE J OCEANIC ENG, V45, P521, DOI 10.1109/JOE.2018.2886093
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
   Yang M, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON UNCERTAINTY REASONING AND KNOWLEDGE ENGINEERING (URKE), P296, DOI 10.1109/URKE.2012.6319570
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 84
TC 1
Z9 1
U1 27
U2 95
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38371
EP 38396
DI 10.1007/s11042-023-15156-9
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000002
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Chang, KH
   Lin, IC
AF Wu, Jia-Jen
   Chang, Keng-Hao
   Lin, I-Chen
TI Generalizable person re-identification with part-based multi-scale
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification of persons; Domain generalization; Deep neural
   networks
ID GAN
AB Supervised person re-identification (Re-ID) has advanced significantly, but it suffers from the performance drop when the pretrained models are directly deployed to an unseen domain. Meanwhile, domain adaptation methods are widely investigated to decrease the performance degradation caused by domain gaps. However, it still requires training with unlabeled target-domain data and iteratively updating models. In this work, we proposed a generalizable person Re-ID framework named Part-based Multi-scale Network (PMN), which was trained on source domain(s) once and can be directly exploited to target domains with stable performance. To this end, we leveraged a part-based architecture which uniformly partitions feature maps into several horizontal stripes. The stripe features contain fine-grained information of human parts and therefore benefit learning discriminative features. The Scale Adjusting Module (SAM) is also designed to regulate the style differences appearing in lower-level feature maps and helps incorporation of features from different levels. When we integrated the style-adjusted features and fine-grained local features into our improved backbone, the proposed framework becomes generalized to variation of image styles and backgrounds from different datasets. Extensive experiments show the superiority of the proposed PMN over state-of-the-art generalizable methods on multiple popular Re-ID benchmarks with cross-domain setting. Furthermore, we also demonstrate the advantage of using our framework as a backbone for domain adaptation methods.
C1 [Wu, Jia-Jen; Chang, Keng-Hao; Lin, I-Chen] Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, 1001 Univ Rd, Hsinchu 30010, Taiwan.
   [Chang, Keng-Hao] Ind Technol Res Inst, Mech & Mechatron Syst Res Labs, 195,Sec 4,Chung Hsing Rd, Hsinchu 310401, Taiwan.
C3 National Yang Ming Chiao Tung University; Industrial Technology Research
   Institute - Taiwan
RP Lin, IC (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, 1001 Univ Rd, Hsinchu 30010, Taiwan.
EM jjwu.cs07g@nctu.edu.tw; justin.cs07@nycu.edu.tw; ichenlin@cs.nctu.edu.tw
OI Lin, I-Chen/0000-0001-9924-4723
FU Ministry of Science and Technology, Taiwan [MOST 109-2221-E-009-122-MY3]
FX This work was partially supported by the Ministry of Science and
   Technology, Taiwan under grant no. MOST 109-2221-E-009-122-MY3.
CR Cai HL, 2019, IEEE COMPUT SOC CONF, P1555, DOI 10.1109/CVPRW.2019.00197
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Choi S, 2021, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR46437.2021.00343
   Chuanchen Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P224, DOI 10.1007/978-3-030-58555-6_14
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Deng X, 2021, MULTIMED TOOLS APPL, V80, P23113, DOI 10.1007/s11042-020-10458-8
   Ding GD, 2019, IEEE T MULTIMEDIA, V21, P2891, DOI 10.1109/TMM.2019.2916456
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang WL, 2022, IEEE T MULTIMEDIA, V24, P3025, DOI 10.1109/TMM.2021.3092149
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang YW, 2021, IEEE T CIRC SYST VID, V31, P1790, DOI 10.1109/TCSVT.2020.3014167
   Isobe T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8506, DOI 10.1109/ICCV48922.2021.00841
   Jia J, 2019, 30 BRIT MACH VIS C 2, P117
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12
   Kingma D. P., 2014, arXiv
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee YH, 2018, COMPUT GRAPH FORUM, V37, P214, DOI 10.1111/cgf.13261
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XX, 2018, LECT NOTES COMPUT SC, V11207, P93, DOI 10.1007/978-3-030-01219-9_6
   Li Y, 2021, ACM T MULTIM COMPUT, V16
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Liu HJ, 2021, MULTIMED TOOLS APPL, V80, P29321, DOI 10.1007/s11042-021-11139-w
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu XB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P547, DOI 10.1145/3394171.3413904
   Liu XP, 2019, NEUROCOMPUTING, V364, P108, DOI 10.1016/j.neucom.2019.07.063
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Muandet Krikamol, 2013, INT C MACH LEARN, P10
   Muhammad N, 2020, MULTIMED TOOLS APPL, V79, P26327, DOI 10.1007/s11042-020-09158-0
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Ruan WJ, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3402666
   Shankar S, 2018, INT C LEARNING REPRE
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan HL, 2020, IEEE ACCESS, V8, P63632, DOI 10.1109/ACCESS.2020.2984915
   Tsai MH, 2014, MULTIMED TOOLS APPL, V72, P801, DOI 10.1007/s11042-013-1399-7
   Ulyanov D, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1607.08022
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Volpi R, 2018, ADV NEUR IN, V31
   Wang C, 2020, NEUROCOMPUTING, V382, P64, DOI 10.1016/j.neucom.2019.11.062
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JC, 2021, MULTIMED TOOLS APPL, V80, P17205, DOI 10.1007/s11042-020-09410-7
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu D, 2021, IEEE T EM TOP COMP I, V5, P70, DOI 10.1109/TETCI.2020.3034606
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P19769, DOI 10.1007/s11042-020-08723-x
   Xin Jin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P735, DOI 10.1007/978-3-030-58571-6_43
   Yang F, 2021, IEEE T MULTIMEDIA, V23, P1681, DOI 10.1109/TMM.2020.3001522
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2020, MULTIMED TOOLS APPL, V79, P22525, DOI 10.1007/s11042-019-08395-2
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zhou K, 2019, ARXIV
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XD, 2021, MULTIMED TOOLS APPL, V80, P15215, DOI 10.1007/s11042-021-10589-6
NR 92
TC 3
Z9 3
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38639
EP 38666
DI 10.1007/s11042-023-14718-1
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000955293100007
DA 2024-07-18
ER

PT J
AU Gavrovska, A
AF Gavrovska, Ana
TI Analysis of large-deviation multifractal spectral properties through
   successive compression for double JPEG detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forgery; Multifractal concept; Double compression;
   Rounding and truncating error; Quantization; Large-deviation
ID FORGERY DETECTION; IMAGES; RECOMPRESSION; ARTIFACTS; TRACES
AB Modern commercial software tools have the ability to deceive a viewer who is unable to determine whether the image content is authentic or not. Research on visual traces, image modifications as attacks, and possible misleading forensic analysis in practice, led to reexamining common used formats, like JPEG (Joint Photographic Experts Group) compressed images. This is one of the most popular image and media formats on the Internet that convey information that cannot be easily trusted. Recompression is one of the fundamental aspects to be investigated, where double JPEG (DJPEG) compression is analyzed through spectral and statistical properties. State-of-the-art methods use coefficients to employ characteristics, like periodicity in histogram spectra for various quality factors (QFs). Some of the studies consider only DJPEG estimations when primary QF is less than in a latter case or when the same quantization matrix is applied. In this paper DJPEG and SJPEG (single JPEG) images are considered through large-deviation spectrum method (LDSM) and rounding and truncating (RT) errors, where additional two successive compressions are employed. The proposed methodology gives promising way to address classification between SJPEG and DJPEG. The test results are obtained on publically available image sets and show the effectiveness of the proposed approach with low number of features compared to other available methods.
C1 [Gavrovska, Ana] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11120, Serbia.
C3 University of Belgrade
RP Gavrovska, A (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11120, Serbia.
EM anaga777@gmail.com
CR [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], Nrcs photo gallery
   [Anonymous], JPEG TOOLBOX
   Barral J, 2011, J STAT PHYS, V144, P1256, DOI 10.1007/s10955-011-0296-6
   Bhartiya G, 2017, MULTIMED TOOLS APPL, V76, P20799, DOI 10.1007/s11042-016-3964-3
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chouhan A, 2016, P IEEE INT C POW EL, P1, DOI [10.1109/ICPEICES.2016.7853478, DOI 10.1109/ICPEICES.2016.7853478]
   Dalmia N, 2018, SIGNAL PROCESS-IMAGE, V61, P9, DOI 10.1016/j.image.2017.10.011
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fatimah B, 2021, BIOCYBERN BIOMED ENG, V41, P690, DOI 10.1016/j.bbe.2021.03.004
   Feng XY, 2010, PROC SPIE, V7541, DOI 10.1117/12.838888
   Fraclab, US
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Galvan F, 2013, LECT NOTES COMPUT SC, V8156, P783
   Gavrovska A, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/376152
   Halim Z, 2018, CLUSTER COMPUT, V21, P377, DOI 10.1007/s10586-017-0868-6
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Ihlen EAF, 2013, HUM MOVEMENT SCI, V32, P633, DOI 10.1016/j.humov.2013.01.008
   Karaca BK, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102571
   Li B., 2017, ARXIV
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Mandelbrot B.B., 1982, The fractal geometry of nature
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Mitchell Joan L., 2017, Proceedings of the SPIE, V10259, DOI 10.1117/12.48892
   Nawayi Siti Habibah, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2071/1/012045
   Niu YK, 2020, IEEE SIGNAL PROC LET, V27, P191, DOI 10.1109/LSP.2019.2962997
   Niu YK, 2019, SIGNAL PROCESS-IMAGE, V76, P89, DOI 10.1016/j.image.2019.04.016
   Park J, 2018, LECT NOTES COMPUT SC, V11209, P656, DOI 10.1007/978-3-030-01228-1_39
   Pasquini C., 2016, P 4 ACM WORKSH INF H, P11, DOI DOI 10.1145/2909827.2930787
   Pavlovic A, 2019, MULTIMED TOOLS APPL, V78, P20655, DOI 10.1007/s11042-019-7277-1
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   PEYRIERE J, 1992, NATO ADV SCI I C-MAT, V372, P175
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shutaywi M, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060759
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Tondi B, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00119-0
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Véhel JL, 2013, IEEE ACM T NETWORK, V21, P1309, DOI 10.1109/TNET.2012.2229469
   Véhel JL, 2004, PROG PROBAB, V57, P23
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang XY, 2013, NONLINEAR DYNAM, V73, P347, DOI 10.1007/s11071-013-0790-2
   Wei Hou, 2013, International Journal of Information and Education Technology, V3, P512, DOI 10.7763/IJIET.2013.V3.327
   WEI W, 2012, ENERGY PROCEDIA, V17, P623, DOI DOI 10.1016/J.EGYPRO.2012.02.145
   Wiseman Y., 2015, ENCY INFORM SCI TECH, P295, DOI [10.4018/978-1-4666-5888-2.ch028, DOI 10.4018/978-1-4666-5888-2.CH028]
   Yang J, 2013, INT WORKSH DIG WAT, P169, DOI [10.1145/3464388, DOI 10.1145/3464388]
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107430
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Yuan HL, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033011
   Zach Fabian, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P185, DOI 10.1007/978-3-642-32717-9_19
   Zhang YJ, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2020.164196
   Zhu N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091119
NR 64
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36255
EP 36277
DI 10.1007/s11042-023-15130-5
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200002
DA 2024-07-18
ER

PT J
AU He, WT
   Wang, JA
   Wang, L
   Pan, RR
   Gao, WD
AF He, Wentao
   Wang, Jing'an
   Wang, Lei
   Pan, Ruru
   Gao, Weidong
TI A semantic segmentation algorithm for fashion images based on modified
   mask RCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clothes; Semantic segmentation; Mask RCNN; Feature pyramid network;
   Detection accuracy
AB The semantic segmentation of human body images has huge application potential in many fields, such as autonomous driving, artificial intelligence (AI) face changing, and virtual try-on. Nowadays, many researchers use additional human body posture information to generate multi-level human body analysis images. However, the existing method has limitations when faced with multiple poses and overlapping targets. In this paper, a novel algorithm based on Mask RCNN which has pixel-level accuracy is proposed. In the feature extraction process, a multi-scale feature fusion module applying dilated convolution is proposed to obtain richer semantic information from different perceptual fields. We added a small residual module to the original residual unit structure to increase the size of the receptive field of each layer to capture details and global characteristics. Three convolution kernels with different ratios are designed to obtain receptive fields of different scales. The experimental results show that our method has better performance while considering both object positioning and target classification.
C1 [He, Wentao; Wang, Jing'an; Wang, Lei; Pan, Ruru; Gao, Weidong] Jiangnan Univ, Key Lab Ecotext, Minist Educ, 1800 Lihu Ave, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Pan, RR (corresponding author), Jiangnan Univ, Key Lab Ecotext, Minist Educ, 1800 Lihu Ave, Wuxi 214122, Jiangsu, Peoples R China.
EM 13101978181@163.com; wja1124@163.com; wangl_jn@163.com; prrsw@163.com;
   gaowd3@163.com
RI zhou, you/KBC-3567-2024
OI He, Wentao/0000-0003-3928-4170
FU National Natural Science Foundation of China [61976105]; Postgraduate
   Research & Practice Innovation Program of Jiangsu Province [KYCX22_2342]
FX This work was supported by National Natural Science Foundation of China
   (No. 61976105) and Postgraduate Research & Practice Innovation Program
   of Jiangsu Province (No. KYCX22_2342).
CR Arsalan M, 2019, EXPERT SYST APPL, V122, P217, DOI 10.1016/j.eswa.2019.01.010
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen YZ, 2020, NEURAL PROCESS LETT, V51, P1081, DOI 10.1007/s11063-019-10129-2
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kwak J, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13081565
   Li SY, 2019, COMPUT-AIDED CIV INF, V34, P616, DOI 10.1111/mice.12433
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehmood S, 2023, NEURAL PROCESS LETT, V55, P881, DOI 10.1007/s11063-020-10368-8
   Paszke A., 2016, ARXIV160602147
   Pavoni G, 2021, APPL GEOMAT, V13, P131, DOI 10.1007/s12518-020-00331-6
   Qingrui Zhang, 2018, IAENG International Journal of Computer Science, V45, P435
   Razzaghi P, 2015, MULTIMED TOOLS APPL, V74, P11517, DOI 10.1007/s11042-014-2249-y
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Xia FT, 2017, PROC CVPR IEEE, P6080, DOI 10.1109/CVPR.2017.644
   Yu F., 2016, 4 INT C LEARN REPR I, DOI [10.48550/arXiv.1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang XX, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23040435
   Zhu BK, 2018, AAAI CONF ARTIF INTE, P7607
NR 25
TC 1
Z9 1
U1 10
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28427
EP 28444
DI 10.1007/s11042-023-14958-1
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000948950300005
DA 2024-07-18
ER

PT J
AU Alhijawi, B
   Fraihat, S
   Awajan, A
AF Alhijawi, Bushra
   Fraihat, Salam
   Awajan, Arafat
TI Adaptable inheritance-based prediction model for multi-criteria
   recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Multi-criteria rating; Collaborative filtering;
   Optimization; Predictive model
ID MATRIX-FACTORIZATION; ANT COLONY
AB A recommender system is an emerging personalization strategy in web applications to deal with information overload. Most recommender systems suggest items to users based on a single criterion, i.e., overall ratings. However, multi-criteria ratings are used for modeling more complex preferences of users. The incorporation of criteria ratings can lead to generating more reliable recommendations for users. Despite the success of multi-criteria methods, there is a need to be further optimized to handle popular issues, e.g., sparsity and cold-start. This research study presents a novel multi-criteria collaborative filtering recommender system based on optimization algorithms. The proposed method consists of an adaptable predictive model called multi-criteria inheritance-based prediction (MC-INH-BP). MC-INH-BP allows the customizing of the predictive model to suit the user context. Also, we propose a user profiling method called dynamic user interest print (D-UIP). The D-UIP stores the dynamic preferences of the users. The use of D-UIP reduces the impact of four challenges, critical users, tolerant users, dynamic opinion of the recurring users, and dynamic quality of the item. A set of experiments are conducted to compare MC-INH-BP with other single-criterion and multi-criteria collaborative filtering methods. The benchmark dataset, HotelExpedia, is used. The results prove the capability of MC-INH-BP to achieve better prediction accuracy regardless of the current context of the user. Besides, the results reveal that MC-INH-BP mitigates the cold start and sparsity issues.
C1 [Alhijawi, Bushra] Princess Sumaya Univ Technol, Data Sci Dept, Amman, Jordan.
   [Fraihat, Salam] Ajman Univ, AIRC, Ajman, U Arab Emirates.
   [Awajan, Arafat] Mutah Univ, Al Karak, Jordan.
C3 Princess Sumaya University for Technology; Ajman University; Mutah
   University
RP Alhijawi, B (corresponding author), Princess Sumaya Univ Technol, Data Sci Dept, Amman, Jordan.
EM b.alhijawi@psut.edu.jo; fraihat@ajman.ac.ae; awajan@psut.edu.jo
OI Fraihat, Salam/0000-0002-1025-7868
CR Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Alhijawi Bushra, 2020, International Journal of Advanced Intelligence Paradigms, V15, P229
   Alhijawi B., 2016, 2016 IEEE/ACIS 15th International Conference on Computer and Information Science, P1, DOI DOI 10.1109/ICIS.2016.7550751
   Alhijawi B, 2021, INFORM SYST, V96, DOI 10.1016/j.is.2020.101670
   Alhijawi B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102310
   Alhijawi B, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P136
   Alhijawi B, 2018, INT CONF INFORM COMM, P127, DOI 10.1109/IACS.2018.8355454
   Bai JZ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P60, DOI 10.1145/3308558.3313568
   Bedi P, 2012, EXPERT SYST APPL, V39, P1183, DOI 10.1016/j.eswa.2011.07.124
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Chen LM, 2018, ADV NEUR IN, V31
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Choudhary P., 2017, Proceedings of the 9th International Conference on Machine Learning and Computing - ICMLC 2017, P81, DOI DOI 10.1145/3055635.3056619
   Christensen G.S., 1979, Mathematics in Science and Engineering, P59, DOI [10.1016/s0076-5392, DOI 10.1016/S0076-5392]
   George T, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625, DOI 10.1109/icdm.2005.14
   Guo X, 2019, IEEE ACCESS, V7, P11349, DOI 10.1109/ACCESS.2019.2891544
   Gupta S, 2020, EVOL SYST-GER, V11, P29, DOI 10.1007/s12530-019-09296-3
   Hug Nicolas, 2020, J OPEN SOURCE SOFTW, V5, DOI [10.21105/joss.02174, DOI 10.21105/JOSS.02174]
   Kallrath J, 2009, ASTRON ASTROPHYS LIB, P3, DOI 10.1007/978-1-4419-0699-1_1
   Kant V, 2018, MULTIMED TOOLS APPL, V77, P12935, DOI 10.1007/s11042-017-4924-2
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kotkov D, 2020, COMPUTING, V102, P393, DOI 10.1007/s00607-018-0687-5
   Kuo RJ, 2007, EXPERT SYST APPL, V33, P794, DOI 10.1016/j.eswa.2006.08.035
   Kuo RJ, 2005, COMPUT MATH APPL, V50, P1709, DOI 10.1016/j.camwa.2005.05.009
   Lakiotaki K, 2011, IEEE INTELL SYST, V26, P64, DOI 10.1109/MIS.2011.33
   Leal Fatima, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 930), P262, DOI 10.1007/978-3-030-16181-1_25
   Leal F, 2017, ADV INTELL SYST, V570, P493, DOI 10.1007/978-3-319-56538-5_50
   Lemire D, 2005, SIAM PROC S, P471
   Li Ye, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P2553, DOI 10.1109/CompComm.2018.8780976
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   Nassar N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00309-6
   Nassar N, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.019
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Nilashi M, 2015, INFORM SCIENCES, V293, P235, DOI 10.1016/j.ins.2014.09.012
   Nilashi M, 2014, KNOWL-BASED SYST, V60, P82, DOI 10.1016/j.knosys.2014.01.006
   Nilashi M, 2014, EXPERT SYST APPL, V41, P3879, DOI 10.1016/j.eswa.2013.12.023
   Raghavan S., 2012, Proceedings of the sixth ACM conference on Recommender systems - RecSys '12, P123, DOI DOI 10.1145/2365952.2365978
   Raja K, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.3851
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Shen RP, 2019, EXPERT SYST APPL, V135, P249, DOI 10.1016/j.eswa.2019.06.001
   Veloso BM, 2019, ELECTRON COMMER R A, V34, DOI 10.1016/j.elerap.2019.100832
   Wang SF, 2020, INFORM SCIENCES, V513, P614, DOI 10.1016/j.ins.2019.11.028
   Wang SJ, 2018, AAAI CONF ARTIF INTE, P2532
   Yadav S, 2018, J COMPUT SCI-NETH, V28, P180, DOI 10.1016/j.jocs.2018.09.007
NR 48
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32421
EP 32442
DI 10.1007/s11042-023-14728-z
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000946890000002
DA 2024-07-18
ER

PT J
AU Taha, M
AF Taha, Miran
TI An efficient software defined network controller based routing
   adaptation for enhancing QoE of multimedia streaming service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart algorithm; Efficiency; SDN; Video streaming; QoE; QoS
AB SDN (Software-Defined Networks) is a new network communication prototype. SDN can control the wide range of network activities and its responsibilities to select an optimum route for end-users. Recent studies are focusing on issues regarding routing congestion and delay of packets within SDNs. In this research work, an efficient and smart-based algorithm is proposed to change the directions of packets in SDN networks. The proposed model estimates the cost of the given paths in networks depending on five criteria; adaptive network packet size, accurate packet numbers, the overall required time interval, QoS (Quality of Service) link capacity (bandwidth), and the number of hops (shortest path). In this way, the optimal paths from sender to receiver can be easily determined. This mechanism allows the SDN controller to minimize the decision time that is needed for selecting the flows. According to the aforementioned criteria, a dataset has been created which contains information about routing delay. From the proposed model, three criteria which are packet size, number, and time have been used to find the optimal packet delay to be used later in the model to find the cost of each path. A benchmark comparison between state-of-the-art and the suggested algorithm reveals that the time consumption of selecting an optimal recovery path has a significant delay reduction which is estimated to be a few milliseconds. Consequently, it can reduce bottleneck routes and resource utilization. Experimental results indicate that the proposed algorithm has increased the QoE (Quality of Experience) of both objective and subjective video streaming.The model reduced the delay time of route selection up to 96.3% and this leads to end-user satisfaction.
C1 [Taha, Miran] Univ Sulaimani, Coll Sci, Dept Comp Sci, Sulaymaniyah, Iraq.
C3 University of Sulimanyah
RP Taha, M (corresponding author), Univ Sulaimani, Coll Sci, Dept Comp Sci, Sulaymaniyah, Iraq.
EM miran.abdullah@univsul.edu.iq
RI Taha, Miran/L-6071-2019
OI Taha, Miran/0000-0002-3501-6999
FU university of Sulaimani
FX This research is a part of the research work of the University of
   Sulaimani in Kurdistan Region of Iraq. Special thanks to the College of
   Science at University of Sulaimani for providing a healthy environment
   to fulfill this project. We would also like to express our deep
   gratitude for the generous support and funds from the presidency of
   university of Sulaimani.
CR Aldwyan Y, 2019, FUTURE GENER COMP SY, V101, P1081, DOI 10.1016/j.future.2019.07.032
   Alghamdi SA, 2022, ARAB J SCI ENG, V47, P1321, DOI 10.1007/s13369-021-05841-y
   Ali J, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEM (ICISS 2018), P244, DOI 10.1145/3209914.3209931
   Alsaeedi M, 2019, IEEE ACCESS, V7, P107346, DOI 10.1109/ACCESS.2019.2932422
   [Anonymous], 2016, 4 INT C INFORM COMMU, DOI DOI 10.1109/ICOICT.2016.7571949
   [Anonymous], VIDEOLAN PROJECT NON
   [Anonymous], Big Buck Bunny
   Chahlaoui F., 2022, 2022 5 C CLOUD INTER, P180, DOI [10.1109/CIoT53061.2022.9766801, DOI 10.1109/CIOT53061.2022.9766801]
   Dorsch N, 2016, IEEE GLOB COMM CONF
   Fernandez C, 2016, SOFTWARE DEFINED NET, P183
   Hemalatha R, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7105
   Hsieh HH, 2019, TENCON IEEE REGION, P1483, DOI 10.1109/TENCON.2019.8929249
   Hwang RH, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P171, DOI [10.1109/ICS.2016.0042, 10.1109/ICS.2016.41]
   Jin H, 2019, 2019 INT C INFORM NE
   Jin H, 2019, 2019 IEEE 12 INT C C
   Jothish Kumar M., 2020, Intelligent Computing in Engineering. Select Proceedings of RICE 2019. Advances in Intelligent Systems and Computing (AISC 1125), P561, DOI 10.1007/978-981-15-2780-7_61
   Kamboj P, 2022, IEEE T NEURAL NETWOR
   Kannan A., 2018, INFORM SYSTEMS DESIG, P245, DOI [10.1007/978-981-13-3329-3_23, DOI 10.1007/978-981-13-3329-3_23]
   Keti F, 2015, P INT CONF INTELL, P205, DOI 10.1109/ISMS.2015.46
   Lee S, 2019, INT CONF COMPUT NETW, P197, DOI [10.1109/ICCNC.2019.8685572, 10.1109/iccnc.2019.8685572]
   Lin YD, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510886
   Liu YL, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P250, DOI 10.1109/ICNC.2015.7377999
   Lu LH, 2020, IMA J MATH CONTROL I, V37, P1237, DOI 10.1093/imamci/dnaa011
   Nisar K, 2020, INTERNET THINGS-NETH, V12, DOI 10.1016/j.iot.2020.100289
   Rego A, 2019, CLUSTER COMPUT, V22, P705, DOI 10.1007/s10586-018-2875-7
   Rezende P, 2019, IEEE ICC
   Rhamdani F, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), P222, DOI 10.1109/ICoICT.2018.8528730
   Sendra S, 2017, IEEE INT CONF COMM, P670, DOI 10.1109/ICCW.2017.7962735
   Sgambelluri A, 2013, J OPT COMMUN NETW, V5, P1066, DOI 10.1364/JOCN.5.001066
   Sharma S., 2011, 2011 8th International Workshop on the Design of Reliable Communication Networks (DRCN 2011), P164, DOI 10.1109/DRCN.2011.6076899
   Shi YP, 2019, IEEE NETWORK, V33, P29, DOI 10.1109/MNET.2018.1800191
   Singh SK, 2015, IEEE COMMUN SURV TUT, V17, P2157, DOI 10.1109/COMST.2015.2460222
   Taha M, 2017, INT WIREL COMMUN, P963, DOI 10.1109/IWCMC.2017.7986416
   Tan W, 2022, SPIE, V12256
   Venkatasubramanian S., 2022, 2022 3rd International Conference on Electronics and Sustainable Communication Systems (ICESC), P569, DOI 10.1109/ICESC54411.2022.9885318
   Wang RX, 2016, INT CONF NETW SER, P342, DOI 10.1109/CNSM.2016.7818444
   Wu JW, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718805689
   Xu XL, 2019, J SYST ENG ELECTRON, V30, P974, DOI 10.21629/JSEE.2019.05.14
   Yan JY, 2015, CHINA COMMUN, V12, P123, DOI 10.1109/CC.2015.7112035
   Yang Z, 2020, IEEE ACM T NETWORK, V28, P312, DOI 10.1109/TNET.2019.2959588
   Zhang ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3322479
NR 41
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33865
EP 33888
DI 10.1007/s11042-023-14938-5
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800007
DA 2024-07-18
ER

PT J
AU Song, X
   Zhijiang, Z
   Liang, X
   Huaidong, Z
AF Song, Xu
   Zhijiang, Zuo
   Liang, Xuan
   Huaidong, Zhou
TI Monocular camera and laser based semantic mapping system with
   temporal-spatial data association for indoor mobile robots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-robot interaction; Semantic mapping; Temporal-spatial correlation
ID MAPS; ENVIRONMENTS; NAVIGATION
AB In the future, the goal of service robots is to operate in human-centric indoor environments, requiring close cooperation with humans. In order to enable the robot to perform various interactive tasks, it is necessary for robots to perceive and understand environments from a human perspective. Semantic map is an augmented representation of the environment, containing both geometric information and high-level qualitative features. It can help the robot to comprehensively understand the environment and bridge the gap in human-robot interaction. In this paper, we propose a unified semantic mapping system for indoor mobile robots. This system utilizes the techniques of scene classification and object detection to construct semantic representations of indoor environments by fusing the data of a camera and a laser. In order to improve the accuracy of semantic mapping, the temporal-spatial correlation of semantics is leveraged to realize data association of semantic maps. Also, the proposed semantic mapping system is scalable and portable, which can be applied to different indoor scenarios. The proposed system was evaluated with collected datasets captured in indoor environments. Extensive experimental results indicate that the proposed semantic mapping system exhibits great performance in the robustness and accuracy of semantic mapping.
C1 [Song, Xu; Zhijiang, Zuo; Liang, Xuan] Jianghan Univ, Sch Smart Mfg, Wuhan 430056, Peoples R China.
   [Huaidong, Zhou] Beihang Univ, Sch Mech Engn & Automat, Beijing 100191, Peoples R China.
C3 Jianghan University; Beihang University
RP Song, X (corresponding author), Jianghan Univ, Sch Smart Mfg, Wuhan 430056, Peoples R China.
EM xusong1991@jhun.edu.cn
OI Xu, Song/0000-0002-4263-5632
FU School-level Scientific Research Project Funding Program ofJianghan
   University [2022XKZX33]; National Key R&D Program of China
   [2019YFB1310802]
FX This work was supported by the School-level Scientific Research Project
   Funding Program ofJianghan University (Grant No. 2022XKZX33) and the
   National Key R&D Program of China (Grant No.2019YFB1310802).
CR Authors U., 2012, IEEE INT C INTELLIGE
   Brucker M, 2018, IEEE INT CONF ROBOT, P1871
   Crespo J, 2018, IEEE INT C INT ROBOT, P5654, DOI 10.1109/IROS.2018.8594271
   De Gregorio D, 2017, IEEE INT CONF COMP V, P660, DOI 10.1109/ICCVW.2017.84
   de Oliveira FDB, 2021, J INTELL ROBOT SYST, V103, DOI 10.1007/s10846-021-01445-8
   Garg S, 2017, IEEE INT C INT ROBOT, P6863, DOI 10.1109/IROS.2017.8206608
   Huang GQ, 2019, IEEE INT CONF ROBOT, P9572, DOI [10.1109/ICRA.2019.8793604, 10.1109/icra.2019.8793604]
   Iqbal A, 2020, J INTELL ROBOT SYST, V100, P113, DOI 10.1007/s10846-020-01189-x
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kostavelis I, 2017, EXPERT SYST APPL, V68, P45, DOI 10.1016/j.eswa.2016.10.014
   Kostavelis I, 2016, ENG APPL ARTIF INTEL, V48, P173, DOI 10.1016/j.engappai.2015.11.004
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu S., 2021, INT J ADV MANUF TECH
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Luo RC, 2017, IEEE INT C INT ROBOT, P1519, DOI 10.1109/IROS.2017.8205956
   Martins R, 2020, J INTELL ROBOT SYST, V99, P555, DOI 10.1007/s10846-019-01136-5
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538
   Mertens A, 2011, LECT NOTES ARTIF INT, V7101, P542, DOI 10.1007/978-3-642-25486-4_54
   Niu L, 2019, IEEE T IMAGE PROCESS, V28, P965, DOI 10.1109/TIP.2018.2872916
   Nüchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001
   Pronobis A, 2010, INT J ROBOT RES, V29, P298, DOI 10.1177/0278364909356483
   Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637
   Qi XY, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881419900066
   Rangel JC, 2019, AUTON ROBOT, V43, P697, DOI 10.1007/s10514-018-9723-8
   Rozumnyi D, 2019, ARXIV
   Ruiz-Sarmiento JR, 2017, KNOWL-BASED SYST, V119, P257, DOI 10.1016/j.knosys.2016.12.016
   Sharma K, 2018, MULTIMED TOOLS APPL, V77, P7955, DOI 10.1007/s11042-017-4694-x
   Shi L, 2010, IEEE INT C INT ROBOT, P5941, DOI 10.1109/IROS.2010.5650387
   Singh D, 2017, LECT NOTES ARTIF INT, V10344, P194, DOI 10.1007/978-3-319-69775-8_12
   Song XH, 2022, IEEE T WIREL COMMUN, V21, P11164, DOI 10.1109/TWC.2022.3190243
   Sorkhi AG, 2020, MULTIMED TOOLS APPL, V79, P18033, DOI 10.1007/s11042-019-08264-y
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sunderhauf N, 2016, IEEE INT C ROBOTICS
   Tchuiev V, 2020, IEEE ROBOT AUTOM LET, V5, P4649, DOI 10.1109/LRA.2020.3003275
   Tchuiev V, 2019, IEEE INT C INT ROBOT, P7742, DOI [10.1109/IROS40897.2019.8967855, 10.1109/iros40897.2019.8967855]
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vasudevan S, 2007, ROBOT AUTON SYST, V55, P359, DOI 10.1016/j.robot.2006.12.008
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983
   Truong XT, 2017, IEEE T AUTOM SCI ENG, V14, P1743, DOI 10.1109/TASE.2017.2731371
   Zhang Q. L., 2004, 2004 IEEERSJ INT C I, P2301
   Zhou BJ, 2018, IEEE ICC
NR 43
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34459
EP 34484
DI 10.1007/s11042-023-14796-1
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000012
PM 37362690
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Elaskily, MA
   Dessouky, MM
   Faragallah, OS
   Sedik, A
AF Elaskily, Mohamed A.
   Dessouky, Mohamed M.
   Faragallah, Osama S.
   Sedik, Ahmed
TI A survey on traditional and deep learning copy move forgery detection
   (CMFD) techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy move forgery detection; SIFT; SURF; CNN; CovLSTM; Multi-domain CNN;
   Buster-net
ID REGION-DUPLICATION FORGERY; IMAGE FEATURES; FORENSICS; LOCALIZATION; DCT
AB Digital image forgeries become one of the most challenges faced by technology users today. A copy-move forgery is one of the most common types of these forgeries. This type is not only common, but it is also very simple to execute to create deceptive images. Many algorithms use various technologies to create a high-performance Copy Move Forgery Detection (CMFD) system. There are currently two major CMFD trends: traditional CMFD algorithms and deep-learning-based CMFD algorithms. The main concept behind CMFD algorithms is to extract image features using various techniques and then search for matching features. This main idea can be carried out by using different feature extraction techniques with various matching techniques. For traditional algorithms, there are many types of features extractors used such as invariant image moments, texture and intensity descriptors, Scale-Invariant Feature Transform (SIFT), Speed Up Roust Features (SURF), Discrete Cosine Transform (DCT), Singular Value Decomposition (SVD), Principal Component Analysis (PCA), and other extractors. The strength of these extractors varies according to the image properties and the forgery's performance perfection. Deep learning-based CMFD algorithms operate as a black box, by extracting image features using layers with complex training and validation processes to achieve the best scenario, such as Convolutional Neural Network (CNN), Convolutional Long Short-Term Memory (CovLSTM), Multi-domain CNN, and Buster-Net. This paper discusses different types of digital image forgery with focusing on copy-move forgery. A detailed survey of various types of CMFD algorithms, on the other hand, has been displayed. The paper provides a comprehensive comparison of various algorithms and evaluates them using various types of evaluation parameters. Finally, the paper focuses on the different datasets used by various algorithms to evaluate their performance accuracy and testing time. These datasets are detailed in terms of image numbers, the number of original images, the number of forged images, the resolution variety in each dataset, the size of the tampered region in each dataset, and the strength of each dataset compared with each other.
C1 [Elaskily, Mohamed A.] Elect Res Inst ERI, Dept Informat, Cairo, Egypt.
   [Dessouky, Mohamed M.] Univ Jeddah, Coll Comp Sci & Engn, Dept Comp Sci & Artificial Intelligence, Jeddah, Saudi Arabia.
   [Dessouky, Mohamed M.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Sedik, Ahmed] Prince Sultan Univ, Coll Engn, Smart Syst Engn Lab, Riyadh 11586, Saudi Arabia.
   [Sedik, Ahmed] Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Robot & Intelligent Machines, Kafrelsheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   University of Jeddah; Egyptian Knowledge Bank (EKB); Menofia University;
   Taif University; Prince Sultan University; Egyptian Knowledge Bank
   (EKB); Kafrelsheikh University
RP Elaskily, MA (corresponding author), Elect Res Inst ERI, Dept Informat, Cairo, Egypt.
EM mohamed_elaskily@eri.sci.eg; mmdessouky@uj.edu.sa; o.salah@tu.edu.sa;
   ahmed.seddiq@ai.kfs.edu.eg
RI Faragallah, Osama S./AHB-8031-2022; Sedik, Ahmed/GXV-6723-2022;
   Dessouky, Mohamed M./AAS-1043-2020
OI Faragallah, Osama S./0000-0003-1982-335X; Sedik,
   Ahmed/0000-0002-7651-8362; Dessouky, Mohamed M./0000-0003-2609-2225
FU Taif University, Taif, Saudi Arabia [TURSP-2020/08]
FX This study was funded by the Deanship of Scientific Research, Taif
   University Researchers Supporting Project number (TURSP-2020/08), Taif
   University, Taif, Saudi Arabia
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], COLUMBIA IMAGE SPLIC
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bi, 2019, PROC IEEE C COMPUT V, P0
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chauhan D, 2016, PROCEDIA COMPUT SCI, V85, P206, DOI 10.1016/j.procs.2016.05.213
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D., 2016, 2016 IEEE International workshop on information forensics and security (WIFS), P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dander A, 2013, SOURCE CODE BIOL MED, V8, DOI 10.1186/1751-0473-8-22
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Diane WNN, 2014, SCI WORLD J, DOI 10.1155/2014/975456
   Elaskily MA., 2019, MENOUFIA J ELECT ENG, V28, P159, DOI 10.21608/mjeer.2019.62749
   Elaskily MA., 2017, INT C ADV CONTROL CI
   Elaskily MA, 2021, J INTELL FUZZY SYST, V40, P4385, DOI 10.3233/JIFS-201192
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Fadl SM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P253, DOI 10.1109/VCIP.2014.7051552
   Hashmi Mohammad Farukh, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P147, DOI 10.1109/ICCCT.2014.7001483
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Jwaid MF, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P697, DOI 10.1109/I-SMAC.2017.8058268
   Kumar S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P649, DOI 10.1109/ICIIP.2013.6707675
   Liu B, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P865, DOI 10.1109/ICInfA.2013.6720415
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo WQ, 2006, INT C PATT RECOG, P746
   Maind Rohini A, 2014, INT J SOFT COMPUT EN, V4, P49
   Muhammad G., 2013, INT INFORM I, V16, P2957
   Mushtaq S., 2014, International Journal of Advanced Science and Technology, V73, P15, DOI DOI 10.14257/IJAST.2014.73.02
   Pandey Ramesh Chand, 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036519
   Prasad S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P706, DOI 10.1109/RTEICT.2016.7807915
   Qureshi MA, 2014, 2014 11TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD), DOI 10.1109/SSD.2014.6808907
   Rao Y, 2016, IEEE INT WORKS INFOR
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang XY, 2019, MATH BIOSCI ENG, V16, P4581, DOI 10.3934/mbe.2019229
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang J., 2013, J COMPUT INF SYST, V9, P6399
   Zhang J, 2014, INT CONF SIGN PROCES, P1859, DOI 10.1109/ICOSP.2014.7015314
   Zhang W, 2016, LECT NOTES COMPUT SC, P159
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zheng Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777
NR 53
TC 4
Z9 4
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34409
EP 34435
DI 10.1007/s11042-023-14424-y
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943970200013
DA 2024-07-18
ER

PT J
AU Prasanna, MSM
   Shaila, SG
   Vadivel, A
AF Prasanna, M. S. M.
   Shaila, S. G.
   Vadivel, A.
TI Polarity classification on twitter data for classifying sarcasm using
   clause pattern for sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sarcasm; Sentence; Clause; Classification; Tweets; Decision tree;
   Neuro-fuzzy; Linguistic grades; Weight; Polarity
ID IDENTIFICATION; NETWORK; IRONY
AB Nowadays, an enormous amount of data is available on the WWW and exponentially growing as well. A lot of users use social networking websites such as Twitter, Facebook, Instagram, and Google+ as common platforms for sharing and exchanging views and opinions on any topics/events. The researchers have considered the reviews and views of the users on these platforms for sentiment analysis, opinion mining, question answering, text summarization, etc. The paper proposes a novel approach for identifying reviews or opinion of users having sarcasm in the text patterns at the clause level. The sentences are classified into four categories such as Simple Sentences, Compound Sentences, Complex Sentences, and Compound-Complex Sentences based on the rules derived from a decision tree. The Simple Sentences and Complex Sentences alone are considered for analysing the sentence patterns where a positive sentiment contrasts with a negative polarity and vice-versa. The decision tree and neuro-fuzzy rules are used on sentence structures to classify the sentences into sarcastic and non-sarcastic sentence patterns. Membership functions are used to map the fuzzy rules and linguistic grading is used for grading the sarcastic patterns. The proposed approach is evaluated on Twitter Dataset and found that the results are promising with the recent and relevant work.
C1 [Prasanna, M. S. M.; Shaila, S. G.] Dayananda Sagar Univ, Dept CSE, Bangalore, India.
   [Vadivel, A.] GITAM Deemed be Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bangalore, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Vadivel, A (corresponding author), GITAM Deemed be Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bangalore, India.
EM prasana.msm@gmail.com; shaila-cse@dsu.edu.in; vayyasam@gitam.edu
RI A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676
CR Amir S, 2016, ARXIV
   Anisimovich A, 2014, P 1 ITALIAN C COMPUT, P108
   [Anonymous], 2010, Proceedings of the First Workshop on Social Media Analytics, SOMA '10, DOI DOI 10.1145/1964858.1964867
   [Anonymous], 2018, P 12 INT WORKSH SEM
   Barbieri F, 2014, P 1 ITALIAN C COMPUT, P104
   Barbieri F., 2014, P 5 WORKSHOP COMPUTA, P50
   Barnaghi P, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), P52, DOI 10.1109/BigDataService.2016.36
   Basile V., 2013, P 4 WORKSH COMP APPR, P100
   Basile Valerio, 2014, OVERVIEW EVALITA 201, P50
   Baziotis C., 2018, ARXIV
   Berry MichaelW., 2004, SURVEY TEXT MINING C
   Bharti SK, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1373, DOI 10.1145/2808797.2808910
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boia M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P345, DOI 10.1109/SocialCom.2013.54
   Bosco C, 2013, IEEE INTELL SYST, V28, P55, DOI 10.1109/MIS.2013.28
   Bouazizi M, 2016, IEEE ACCESS, V4, P5477, DOI 10.1109/ACCESS.2016.2594194
   Burfoot C., 2009, Proceedings of the acl-ijcnlp 2009 conference short papers, P161
   Buschmeier K., 2014, P 5 WORKSH COMP APPR, P42
   Campbell JD, 2012, DISCOURSE PROCESS, V49, P459, DOI 10.1080/0163853X.2012.687863
   Castellucci G, 2014, P 1 ITALIAN C COMPUT, P98
   Dave AD, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1985, DOI 10.1109/ICEEOT.2016.7755036
   Davidov D., 2010, Proceedings of the fourteenth conference on computational natural language learning, P107
   Delmonte R, 2014, P 1 ITALIAN C COMPUT, P64
   Diao YF, 2020, IEEE ACCESS, V8, P135152, DOI 10.1109/ACCESS.2020.2967095
   Ekbal A, 2008, PACLIC 22: PROCEEDINGS OF THE 22ND PACIFIC ASIA CONFERENCE ON LANGUAGE, INFORMATION AND COMPUTATION, P169
   Farias DIH, 2017, SENTIMENT ANALYSIS IN SOCIAL NETWORKS, P113, DOI 10.1016/B978-0-12-804412-4.00007-3
   Fersini E, 2014, P 1 ITALIAN C COMPUT, P70
   Fersini E, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (IEEE DSAA 2015), P981
   Ghosh D., 2015, P 2015 C EMP METH NA, P1003
   Ghosh D., 2016, 7 WORKSH COMP APPR S, P439, DOI DOI 10.18653/V1/W16-0425
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hazarika D, 2018, ARXIV
   Farías DIH, 2018, LECT NOTES COMPUT SC, V10762, P46, DOI 10.1007/978-3-319-77116-8_4
   Hernandez-Farias I, 2014, P 1 ITALIAN C COMPUT, P75
   Hiai S, 2019, INT J DATA WAREHOUS, V15, P66, DOI 10.4018/IJDWM.2019100104
   Hiai S, 2018, ADV INTELL SYST COMP, V700, P418, DOI 10.1007/978-3-319-72550-5_40
   Hiai S, 2016, PROCEEDINGS 2016 5TH IIAI INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS IIAI-AAI 2016, P31, DOI 10.1109/IIAI-AAI.2016.198
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Katz P, 2007, SWAT MPTHE SEMEVAL 2
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Li XD, 2008, FRONT BUS RES CHINA, V2, P277, DOI 10.1007/s11782-008-0016-5
   Li Y, 2021, P INT C NEUR INF PRO, V34, P15816
   Liang HZ, 2020, IEEE ACCESS, V8, P54164, DOI 10.1109/ACCESS.2020.2979012
   Liebrecht C, 2013, P 4 WORKSH COMP APPR, P29
   Liu W, 2020, IEEE ACCESS, V8, P98044, DOI 10.1109/ACCESS.2020.2995776
   Liu W, 2019, APPL INTELL, V49, P912, DOI 10.1007/s10489-018-1303-2
   Long W, 2018, NEURAL COMPUT APPL, V30, P661, DOI 10.1007/s00521-016-2684-y
   Manuel K., 2010, Proceedings 2010 Second Vaagdevi International Conference on Information Technology for Real World Problems (VCON 2010), P9, DOI 10.1109/VCON.2010.9
   Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238
   Mehndiratta P, 2019, J DATA INFO SCI, V4, P56, DOI 10.2478/jdis-2019-0021
   Mehndiratta P, 2019, J DISCRET MATH SCI C, V22, P465, DOI 10.1080/09720529.2019.1637152
   Mukherjee S, 2017, TECHNOL SOC, V48, P19, DOI 10.1016/j.techsoc.2016.10.003
   Muresan S, 2016, J ASSOC INF SCI TECH, V67, P2725, DOI 10.1002/asi.23624
   Naz F, 2019, J INTELL FUZZY SYST, V37, P6815, DOI 10.3233/JIFS-190596
   Poria S, 2016, P COLING
   Prasad A, 2017, 2017 25TH TELECOMMUNICATION FORUM (TELFOR), P1
   Prasanna MSM, 2021, MULTIMED TOOLS APPL, V80, P20151, DOI 10.1007/s11042-020-10422-6
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Ren FY, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113393
   Riloff E., 2013, P 2013 C EMP METH NA, P704
   Sonawane SS, 2020, PROCEDIA COMPUT SCI, V167, P830, DOI 10.1016/j.procs.2020.03.422
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Suhaimin Mohd Suhairi Md, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P703, DOI 10.1109/ICITECH.2017.8079931
   Sundararajan K, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/2860479
   Suzuki S, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P519, DOI 10.5220/0006192805190526
   Tang TT, 2021, LECT NOTES ARTIF INT, V12815, P491, DOI 10.1007/978-3-030-82136-4_40
   Thu PP, 2017, IEEE GLOB CONF CONSU
   Tungthamthiti P., 2016, J NAT LANG PROCESS, V23, P383, DOI [DOI 10.5715/JNLP.23.383, 10.5715/jnlp.23.383]
   Wallace BC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P512
   Wilson D, 2006, LINGUA, V116, P1722, DOI 10.1016/j.lingua.2006.05.001
   Zhang DW, 2022, IEEE T PATTERN ANAL, V44, P5866, DOI 10.1109/TPAMI.2021.3074313
   Zhang Meishan, 2016, P COLING 2016 26 INT, P2449
   Zhao YW, 2019, LECT NOTES ARTIF INT, V11888, P359, DOI 10.1007/978-3-030-35231-8_26
NR 74
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32789
EP 32825
DI 10.1007/s11042-023-14909-w
EA MAR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100001
DA 2024-07-18
ER

PT J
AU Iseed, SY
   Mahmoud, KW
AF Iseed, Saed Yacoub
   Mahmoud, Khaled Walid
TI Forensic approach for distinguishing between source and destination
   regions in copy-move forgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Joint probability matrix; Local binary pattern; DCT;
   Jensen Shannon divergence
ID LOCAL BINARY PATTERN; DETECTION ALGORITHM; MARKOV FEATURES; OBJECT
   REMOVAL; IMAGE FORGERY; CLASSIFICATION
AB The copy-move forgery involves copying a semantically part from an image and pasting it into a different location within the same image to change the context of the image and deceive people. The copy-move forensic detectors authenticate the image and localize similar regions without identifying which region is original or forged. Because the forged region is replicated from another region of the same image, its characteristics have been inherited, making it difficult to distinguish between the original and forged regions. This paper proposes two approaches as a second stage, after localizing duplicated regions, to distinguish between source and destination regions. The adjacent pixels in images are non-independent and have some correlations that would be destroyed due to modifying the image. The deviation of these correlations would expose traces left due to the image forgery and is evaluated by the Joint Probability Matrix (JPM) in the first approach and by the Local Binary Pattern (LBP) in the second approach. Both approaches employ Jensen Shannon Divergence (JSD) to measure the correlation between feature vectors and generate similarity scores to distinguish between the source and the destination regions. The proposed approaches were demonstrated by employing the GRIP dataset with six post-processing operations to conceal forgery. The experiments exhibit a high accuracy rate of 96.25%.
C1 [Iseed, Saed Yacoub; Mahmoud, Khaled Walid] Princess Sumaya Univ Technol, Cybersecur Dept, Amman, Jordan.
C3 Princess Sumaya University for Technology
RP Iseed, SY (corresponding author), Princess Sumaya Univ Technol, Cybersecur Dept, Amman, Jordan.
EM saed.iseed@gmail.com; k.mahmoud@psut.edu.jo
RI Mahmoud, Khaled/AAU-4144-2020
OI Mahmoud, Khaled/0000-0003-4407-7491
CR [Anonymous], 2008, DIGITAL WATERMARKING, DOI DOI 10.1016/B978-0-12-372585-1.X5001-3
   [Anonymous], IMAGE PROCESSING RES
   Beli ILK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030037
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Cozzolino D, 2013, NOVEL FRAMEWORK IMAG
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Dekking F. M., 2005, A modern introduction to probability and statistics: Understanding why and how, DOI 10.1007/1-84628-168-7
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   Ferreira WD, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2020.106685
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hu N, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163664
   Jaiswal A.K., 2019, SSRN Electron. J, DOI DOI 10.2139/SSRN.3351072
   Jin X, 2018, AAAI CONF ARTIF INTE, P77
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Kaur C., 2019, Stat. Optim. Inf. Comput, V7, P486, DOI DOI 10.19139/SOIC.V7I2.542
   Kee E, 2011, P NATL ACAD SCI USA, V108, P19907, DOI 10.1073/pnas.1110747108
   Khaleefah SH, 2021, J KING SAUD UNIV-COM, V33, P1219, DOI 10.1016/j.jksuci.2019.07.012
   Koshy Litty, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0041, DOI 10.1109/ICCSP48568.2020.9182066
   Li YB, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P653, DOI 10.1109/IAEAC.2018.8577881
   Li YY, 2020, J MARKETING RES, V57, P1, DOI 10.1177/0022243719881113
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liao X, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116438
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu QZ, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2560365
   Lu JH, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6740
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Malik MSA, 2020, J MED IMAG HEALTH IN, V10, P2481, DOI 10.1166/jmihi.2020.3180
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Moghaddasi Z, 2019, NEURAL COMPUT APPL, V31, P7867, DOI 10.1007/s00521-018-3586-y
   Pham NT, 2019, MULTIMED TOOLS APPL, V78, P12405, DOI 10.1007/s11042-018-6792-9
   Nguyen HV, 2015, LECT NOTES ARTIF INT, V9285, P173, DOI 10.1007/978-3-319-23525-7_11
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pavlichin DS, 2016, IEEE INT SYMP INFO, P580, DOI 10.1109/ISIT.2016.7541365
   Peyret R, 2018, NEUROCOMPUTING, V275, P83, DOI 10.1016/j.neucom.2017.05.010
   Pishro-Nik H, 2015, WIKIPEDIA
   Priya T.S. V., 2018, Int. J. Pure Appl. Math, V119, P1895
   Rahman T., 2021, 12 INT C ADV INFORM, DOI DOI 10.1145/3468784.3468789
   Rathgeb C, 2020, IET BIOMETRICS, V9, P154, DOI 10.1049/iet-bmt.2019.0196
   Rouder JN, 2019, AM STAT, V73, P186, DOI 10.1080/00031305.2017.1341334
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Shah AP, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P396, DOI 10.1109/ICOPS35962.2018.9575678
   Shah H., 2013, Int. J. Eng. Innov. Res, V2, P487
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang RX, 2018, INT J DIGIT CRIME FO, V10, P90, DOI 10.4018/IJDCF.2018100107
   Yohannan RP, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P629, DOI 10.1109/ICETECH.2016.7569326
   Zeebaree DQ, 2021, CMC-COMPUT MATER CON, V66, P3363, DOI 10.32604/cmc.2021.013314
   Zhang DY, 2018, MULTIMED TOOLS APPL, V77, P11823, DOI 10.1007/s11042-017-4829-0
   Zhang J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P390, DOI 10.1109/ICICISYS.2009.5357642
   Zhe S, 2020, MULTIMED TOOLS APPL, V79, P8235, DOI 10.1007/s11042-019-08565-2
NR 57
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31181
EP 31210
DI 10.1007/s11042-023-14824-0
EA FEB 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940065100007
DA 2024-07-18
ER

PT J
AU Garima
   Goel, N
   Rathee, N
AF Garima, Nidhi
   Goel, Nidhi
   Rathee, Neeru
TI Modified multidimensional scaling on EEG signals for emotion
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multidimensional scaling; Cosine similarity; DWT; MFCC; EEG; TQWT; FAWT
ID RECOGNITION; SELECTION; FEATURES; ENTROPY
AB Human emotional state is a physiological or physical process that is activated either intentionally or unintentionally by the perception of the stimulus. To fetch the information concerning the mental state of well-being, EEG signals can be utilized for storing the neuronal activities occurring in the brain. Therefore, emotion identification has now become a tedious task and requires more advanced signal processing techniques along with post-processing methods for efficiently recognizing emotions. Thus, in the proposed work authors have explored these techniques for emotion recognition using EEG signals by adopting the classical approach: signal processing (using Discrete Wavelet Transform, Mel-Frequency Cepstral Coefficients, Flexible Analytic Wavelet Transform, and Tunable Q Wavelet Transform), post-processing (for mapping the features to more discriminative space), and classification. The significant contribution of the authors is in devising an improved post-processing technique by learning a distance metric based on multidimensional scaling. The proposed Modified Multidimensional Scaling is a distance metric learning based on cosine similarity in contrast to the classical approach using Euclidian Distance. The main advantage of using cosine similarity is its ability to measure similarity based on the orientation and magnitude of the samples. Moreover, it establishes intra-class relationships rather than the inter-class relationship amongst the EEG features, which is being neglected in current state-of-the-art methods. The proposed algorithm is evaluated on a publically available DEAP dataset to prove its efficacy. Experimental results depict that the proposed post-processing technique using Flexible Analytic Wavelet Transform has achieved an accuracy of 80.93% which is best amongst all signal processing techniques incorporated in the proposed work. The comparative analysis of the proposed technique with the current state-of-the-art methods further confirms its efficacy.
C1 [Garima, Nidhi; Goel, Nidhi] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Garima, Nidhi; Rathee, Neeru] Maharaja Surajmal Inst Technol, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Maharaja
   Surajmal Institute of Technology
RP Garima (corresponding author), Indira Gandhi Delhi Tech Univ Women, Delhi, India.; Garima (corresponding author), Maharaja Surajmal Inst Technol, Delhi, India.
EM 1592garima@gmail.com; nidhi.iitr1@gmail.com; neeru1rathee@gmail.com
CR [Anonymous], 2015, 2015 7 C INFORM KNOW, DOI DOI 10.1109/IKT.2015.7288756
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Aydemir E, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109519
   Bayram I, 2013, IEEE T SIGNAL PROCES, V61, P1131, DOI 10.1109/TSP.2012.2232655
   Chen YM, 2015, NEUROCOMPUTING, V168, P871, DOI 10.1016/j.neucom.2015.05.037
   Chen Z, 2021, NEUROCOMPUTING, V462, P221, DOI 10.1016/j.neucom.2021.07.073
   Deng MQ, 2020, NEURAL NETWORKS, V130, P22, DOI 10.1016/j.neunet.2020.06.015
   France SL, 2011, IEEE T SYST MAN CY C, V41, P644, DOI 10.1109/TSMCC.2010.2078502
   Ganapathy N, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113571
   George ST, 2020, BIOCYBERN BIOMED ENG, V40, P709, DOI 10.1016/j.bbe.2020.02.001
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Handa P, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12929
   HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4
   Khateeb M, 2021, IEEE ACCESS, V9, P12134, DOI 10.1109/ACCESS.2021.3051281
   Kim BH, 2021, INT WINT WORKSH BR, P18, DOI 10.1109/BCI51272.2021.9385305
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Lan ZR, 2019, IEEE T COGN DEV SYST, V11, P85, DOI 10.1109/TCDS.2018.2826840
   Lan ZR, 2016, VISUAL COMPUT, V32, P347, DOI 10.1007/s00371-015-1183-y
   Lee G, 2014, NEUROCOMPUTING, V144, P560, DOI 10.1016/j.neucom.2014.04.008
   Li C, 2016, NEUROCOMPUTING, V178, P103, DOI 10.1016/j.neucom.2015.07.112
   Li X, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00162
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Lindquist KA, 2012, TRENDS COGN SCI, V16, P533, DOI 10.1016/j.tics.2012.09.005
   Liu Y., 2013, T COMPUTATIONAL SCI, P101
   Liu YH, 2013, IEEE ENG MED BIO, P4306, DOI 10.1109/EMBC.2013.6610498
   Lotfi E, 2014, NEURAL NETWORKS, V59, P61, DOI 10.1016/j.neunet.2014.06.012
   Menezes MLR, 2017, PERS UBIQUIT COMPUT, V21, P1003, DOI 10.1007/s00779-017-1072-7
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Omidvar M, 2021, J AMB INTEL HUM COMP, V12, P10395, DOI 10.1007/s12652-020-02837-8
   Pandey P, 2022, J KING SAUD UNIV-COM, V34, P1730, DOI 10.1016/j.jksuci.2019.11.003
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Prakash C, 2012, 2012 INT C SIGN PROC, P1, DOI [10.1109/SPCOM.2012.6290031, DOI 10.1109/SPCOM.2012.6290031]
   Rathee N, 2018, SIGNAL IMAGE VIDEO P, V12, P1141, DOI 10.1007/s11760-018-1255-3
   Raut S, 2021, P INT C ARTIFICIAL I, P185, DOI [10.1007/978-981-15-4992-2_18, DOI 10.1007/978-981-15-4992-2_18]
   Rayatdoost S., 2018, 2018 IEEE 28 INT WOR, P1
   Recio G, 2014, BIOL PSYCHOL, V96, P111, DOI 10.1016/j.biopsycho.2013.12.003
   Samadi E, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1052-x
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Shi LC, 2013, IEEE ENG MED BIO, P6627, DOI 10.1109/EMBC.2013.6611075
   Tang ZJ, 2017, SIGNAL PROCESS, V137, P240, DOI 10.1016/j.sigpro.2017.02.008
   Taran S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105367
   Teolis A., 1998, APPL NUM HARM ANAL, DOI 10.1007/978-1-4612-1664-3
   Torres E., 2020, EEG BASED BCI EMOTIO
   Vu N. N., 2022, Multimedia Technologies in the Internet of Things Environment, V2, P165
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   Yang YL, 2018, LECT NOTES COMPUT SC, V11307, P433, DOI 10.1007/978-3-030-04239-4_39
   Zhang JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101558
   Zhao MH, 2019, IEEE T IND ELECTRON, V66, P4696, DOI 10.1109/TIE.2018.2866050
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zhuang N, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/8317357
NR 54
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28547
EP 28568
DI 10.1007/s11042-023-14671-z
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937854600004
DA 2024-07-18
ER

PT J
AU Gupta, S
   Yadav, GK
   Nandi, GC
AF Gupta, Shekhar
   Yadav, Gaurav Kumar
   Nandi, G. C.
TI Development of human motion prediction strategy using inception residual
   block
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inception module; Human 3; 6M; Residual connection; Graph convolution
   network
AB Human Motion Prediction is a crucial task in computer vision and robotics. It has versatile application potentials, such as human-robot interactions, human action tracking for airport security systems, autonomous car navigation, and computer gaming, to name a few. However, predicting human motion based on past actions is extremely challenging due to the difficulties in correctly detecting spatial and temporal features. We propose an Inception Residual Block(IRB) to detect temporal features in human poses due to its inherent capability of processing multiple kernels to capture salient features. Here, we propose to use multiple 1-D Convolution Neural Networks (CNN) with different kernel sizes and input sequence lengths and concatenate them to get proper embedding. As kernels stride over different receptive fields, they detect smaller and bigger salient features at multiple temporal scales. Our main contribution is to propose a residual connection between input and the output of the inception block to have a continuity between the previously observed pose and the next predicted pose. With this proposed architecture, it learns prior knowledge much better about human poses, and we achieve much higher prediction accuracy as detailed in the paper. Subsequently, we further propose to feed the output of the IRB as an input to the Graph Convolution Neural Network (GCN) due to its better spatial feature learning capability. We perform a parametric analysis for a better design of our model. Subsequently, we evaluate our approach on the Human 3.6M dataset and CMU MoCap dataset and compare our short-term and long-term predictions with the state-of-the-art papers, where our model outperforms most of the pose results, the detailed reasons of which have been elaborated in the paper.
C1 [Gupta, Shekhar; Yadav, Gaurav Kumar; Nandi, G. C.] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj 211012, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Gupta, S (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj 211012, Uttar Pradesh, India.
EM guptashekhar54@gmail.com; gauravkumaryadav51@gmail.com;
   gcnandi@iiita.ac.in
FU Center of Intelligent Robotics, IIIT Allahabad
FX This work is supported by Center of Intelligent Robotics, IIIT
   Allahabad.
CR Aliakbarian S, 2020, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR42600.2020.00527
   Bütepage J, 2019, IEEE COMPUT SOC CONF, P2923, DOI 10.1109/CVPRW.2019.00352
   Bütepage J, 2018, IEEE INT CONF ROBOT, P4563, DOI 10.1109/ICRA.2018.8460651
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Cruttwell GSH, 2022, LECT NOTES COMPUT SC, V13240, P1, DOI 10.1007/978-3-030-99336-8_1
   Espinoza V., 2022, PMLR, P1006
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gong HF, 2011, IEEE I CONF COMP VIS, P619, DOI 10.1109/ICCV.2011.6126296
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Hamilton WL, 2017, ADV NEUR IN, V30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Kalatian A, 2022, TRANSPORT RES C-EMER, V134, DOI 10.1016/j.trc.2021.103453
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Koppula HS, 2013, IEEE INT C INT ROBOT, P2071, DOI 10.1109/IROS.2013.6696634
   Lebailly T., 2021, Lecture Notes in Computer Science, V12623, P651, DOI [DOI 10.1007/978-3-030-69532-3_39, 10.1007/978-3-030-69532-3_39]
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li C, 2019, IEEE T IMAGE PROCESS, V28, P4646, DOI 10.1109/TIP.2019.2912357
   Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Liu CC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P871, DOI 10.1145/3474085.3475264
   Liu RX, 2021, IEEE CONTR SYST LETT, V5, P1651, DOI 10.1109/LCSYS.2020.3042609
   Mao W, 2019, IEEE I CONF COMP VIS, P9488, DOI 10.1109/ICCV.2019.00958
   Marcheggiani D, 2018, P 2018 C N AM CHAPT, P1, DOI [DOI 10.18653/V1/N18-2078, 1804.08313]
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Paden B, 2016, IEEE T INTELL VEHICL, V1, P33, DOI 10.1109/TIV.2016.2578706
   Paszke A., 2017, NIPS W
   Sang HF, 2020, MULTIMED TOOLS APPL, V79, P5529, DOI 10.1007/s11042-019-08269-7
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Velickovic Petar, 2017, ARXIV171010903, DOI DOI 10.48550/ARXIV.1710.10903
   Yadav GK, 2020, 2020 IEEE INT C EL C, P1, DOI DOI 10.1109/CONECCT50063.2020.9198505
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yuan JL, 2022, NEUROCOMPUTING, V495, P194, DOI 10.1016/j.neucom.2022.01.064
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
NR 41
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21177
EP 21191
DI 10.1007/s11042-023-14440-y
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000937854600003
DA 2024-07-18
ER

PT J
AU Yang, ZY
   Leng, L
   Min, WD
AF Yang, Ziyuan
   Leng, Lu
   Min, Weidong
TI Downsampling in uniformly-spaced windows for coding-based Palmprint
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Downsampling in uniformly-spaced windows; Uniformly-spaced extreme
   downsampling method; Uniformly-spaced democratic voting downsampling
   method; Palmprint recognition; Coding-based palmprint recognition
   method; Downsampling
ID IDENTIFICATION
AB Palmprint is deemed as one of the most important biometric modalities. Many coding-based palmprint recognition methods have achieved satisfactory recognition performance, which can be free from training and require low storage cost and computational complexity. Downsampling is typically used to improve real-time ability, reduce the storage cost and improve the discriminative ability. Unfortunately, downsampling was not fully considered and studied. In this paper, we propose downsampling in uniformly-spaced windows (DUSW) and conduct it on two state-of-the-art downsampling methods as their reformative versions, dubbed uniformly-spaced extreme downsampling method (U-EDM) and uniformly-spaced democratic voting downsampling method (U-DVDM). In DUSW, the upper-left four pixels rather than all pixels in each block are selected to jointly decide the winner whose value is used as the representative feature of this block. DUSW overcomes the dictatorship of a single pixel and simultaneously ensures the sufficient spatial distance between the adjacent winners. Thus, DUSW reduces the correlation between the adjacent winners, and accordingly improves the discrimination and robustness. Meanwhile, the computational complexity is only 1/4 of the original downsampling methods for the representative reduction. The sufficient experiments demonstrate that DUSW can be easily embedded into the existing downsampling methods of coding-based palmprint recognition and improve their recognition performances.
C1 [Yang, Ziyuan; Min, Weidong] Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Peoples R China.
   [Leng, Lu] Nanchang Hangkong Univ, Sch Software, Nanchang 330036, Peoples R China.
   [Yang, Ziyuan] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Min, Weidong] Nanchang Univ, Inst Metaverse, Nanchang 330031, Peoples R China.
   [Min, Weidong] Nanchang Univ, Jiangxi Key Lab Smart City, Nanchang 330031, Peoples R China.
C3 Nanchang University; Nanchang Hangkong University; Sichuan University;
   Nanchang University; Nanchang University
RP Min, WD (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Nanchang 330031, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Inst Metaverse, Nanchang 330031, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Jiangxi Key Lab Smart City, Nanchang 330031, Peoples R China.
EM minweidong@ncu.edu.cn
RI Yang, Ziyuan/AAT-1866-2020; Min, Weidong/D-4585-2017
OI Yang, Ziyuan/0000-0002-0275-4098; Min, Weidong/0000-0003-2526-2181
CR Chaa M, 2021, MULTIMED TOOLS APPL, V80, P2263, DOI 10.1007/s11042-020-09689-6
   Chai TT, 2019, FUTURE GENER COMP SY, V99, P41, DOI 10.1016/j.future.2019.04.013
   Fei LK, 2019, IEEE T SYST MAN CY-S, V49, P346, DOI 10.1109/TSMC.2018.2795609
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Genovese A, 2019, IEEE T INF FOREN SEC, V14, P3160, DOI 10.1109/TIFS.2019.2911165
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kaibou R, 2021, J REAL-TIME IMAGE PR, V18, P2009, DOI 10.1007/s11554-021-01073-3
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Leng L, 2020, IET BIOMETRICS, V9, P290, DOI 10.1049/iet-bmt.2020.0106
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Liu H, 2020, J REAL-TIME IMAGE PR, V17, P1787, DOI 10.1007/s11554-020-00976-x
   Matkowski WM, 2020, ARXIV
   Palma D, 2019, IEEE T SYST MAN CY-S, V49, P2676, DOI 10.1109/TSMC.2017.2771232
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie ZH, 2018, IET COMPUT VIS, V12, P476, DOI 10.1049/iet-cvi.2017.0475
   Xu HH, 2023, NEURAL PROCESS LETT, V55, P2341, DOI 10.1007/s11063-022-10822-9
   Xu Y, 2018, IEEE T SYST MAN CY-S, V48, P232, DOI 10.1109/TSMC.2016.2597291
   Yang B, 2020, MULTIMED TOOLS APPL, V79, P21987, DOI 10.1007/s11042-020-09000-7
   Yang ZS, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3125108
   Yang ZY, 2023, ARTIF INTELL REV, V56, P995, DOI 10.1007/s10462-022-10194-5
   Yang ZY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204344
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zhang YK, 2021, IEEE T COMPUT IMAG, V7, P436, DOI 10.1109/TCI.2021.3070184
   Zhao SP, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107071
   Zhao SC, 2022, IEEE T NEUR NET LEAR, V33, P473, DOI 10.1109/TNNLS.2020.3028503
   Zhong DX, 2020, IEEE T CIRC SYST VID, V30, P1559, DOI 10.1109/TCSVT.2019.2904283
   Zhong DX, 2019, NEUROCOMPUTING, V328, P16, DOI 10.1016/j.neucom.2018.03.081
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 37
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22981
EP 22996
DI 10.1007/s11042-023-14574-z
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100012
DA 2024-07-18
ER

PT J
AU Ghosh, A
   Senthilrajan, A
AF Ghosh, Argha
   Senthilrajan, A.
TI Comparison of machine learning techniques for spam detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning algorithms; Classification; Spam email detection;
   Machine learning; Artificial intelligence
ID SEQUENTIAL MINIMAL OPTIMIZATION; CLASSIFICATION; SELECTION
AB Email is a useful communication medium for better reach. There are two types of emails, those are ham or legitimate email and spam email. Spam is a kind of bulk or unsolicited email that contains an advertisement, phishing website link, malware, Trojan, etc. This research aims to classify spam emails using machine learning classifiers and evaluate the performance of classifiers. In the pre-processing step, the dataset has been analyzed in terms of attributes and instances. In the next step, thirteen machine learning classifiers are implemented for performing classification. Those classifiers are Adaptive Booster, Artificial Neural Network, Bootstrap Aggregating, Decision Table, Decision Tree, J48, K-Nearest Neighbor, Linear Regression, Logistic Regression, Naive Bayes, Random Forest, Sequential Minimal Optimization and, Support Vector Machine. In terms of accuracy, the Random Forest classifier performs best and the performance of the Naive Bayes classifier is substandard compared to the rest of the classifiers. Random Forest classifier had the accuracy of 99.91% and 99.93% for the Spam Corpus and Spambase datasets respectively. The naive Bayes classifier had the accuracy of 87.63% and 79.53% for the Spam Corpus and Spambase datasets respectively.
C1 [Ghosh, Argha; Senthilrajan, A.] Alagappa Univ, Dept Computat Logist, Karaikkudi, India.
C3 Alagappa University
RP Ghosh, A (corresponding author), Alagappa Univ, Dept Computat Logist, Karaikkudi, India.
EM argha.ghosh16@gmail.com; agni_senthil@yahoo.com
OI Ghosh, Argha/0000-0001-7753-2425
FU Rashtriya Uchchatar Shiksha Abhiyan (RUSA-Phase 2.0) grant, Policy
   (TNMulti-Gen), Dept. of Edn. Govt. of India [F.24-51/2014-U]
FX This research work has been written with the financial support of
   Rashtriya Uchchatar Shiksha Abhiyan (RUSA-Phase 2.0) grant sanctioned
   vide Letter No. F.24-51/2014-U, Policy (TNMulti-Gen), Dept. of Edn.
   Govt. of India, Dt. 09.10.2018.
CR Abdulhamid Shafi'i Muhammad, 2018, International Journal of Computer Network and Information Security, V10, P60, DOI 10.5815/ijcnis.2018.01.07
   Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   Ali AS, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P972, DOI 10.1109/ICIS.2007.170
   Alzahrani A, 2019, IEEE SOUTHEASTCON, DOI [10.1109/southeastcon42311.2019.9020530, 10.1145/3290605.3300673]
   Aminikhanghahi S., 2014, OPTIMIZED SUPPORT VE, P111, DOI [10.1145/2663761.2664230, DOI 10.1145/2663761.2664230]
   Anamika, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P640, DOI 10.1145/2791405.2791552
   [Anonymous], 2003, KLUWER INT SER ENG C
   [Anonymous], POWER DECISION TABLE
   Aski A., 2016, NATURAL SCI ENG PACI, V18, P145
   Bassiouni M, 2018, J APPL SEC RES, V13, P315, DOI 10.1080/19361610.2018.1463136
   Becker BG, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P102, DOI 10.1109/INFVIS.1998.729565
   Bedmar IS, 2007, P 4 INT WORKSH SEM E, P382
   Bertsimas D, 2020, OPER RES LETT, V48, P203, DOI 10.1016/j.orl.2020.02.008
   Bienvenido-Huertas D, 2020, BUILD ENVIRON, V168, DOI 10.1016/j.buildenv.2019.106479
   bin Abd Razak S, 2013, INT CONF INTELL SYST, P347, DOI 10.1109/ISDA.2013.6920762
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Braun A.C., 2011, 2011 3rd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), P1, DOI DOI 10.1109/WHISPERS.2011.6080861
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bucurica M, 2015, INT C INTELL COMP CO, P471, DOI 10.1109/ICCP.2015.7312705
   Chen MZ, 2019, IEEE COMMUN SURV TUT, V21, P3039, DOI 10.1109/COMST.2019.2926625
   Chharia A, 2013, INT CONF CONTEMP, P130, DOI 10.1109/IC3.2013.6612176
   Chi-Yao Tseng, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P128, DOI 10.1109/CSE.2009.260
   Cho J, 2020, TELEMAT INFORM, V55, DOI 10.1016/j.tele.2019.101301
   Cristianni N., 2000, INTRO SUPPORT VECTOR
   Cui JA, 2011, MEASUREMENT, V44, P281, DOI 10.1016/j.measurement.2010.10.004
   Diale M, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH)
   Digamberrao Kale Sunil, 2018, Procedia Computer Science, V132, P1086, DOI 10.1016/j.procs.2018.05.024
   Dong YX, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106900
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   Edla Damodar Reddy, 2018, Procedia Computer Science, V132, P1523, DOI 10.1016/j.procs.2018.05.116
   Ernawati S, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM), P155
   Fujiwara Y, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2205, DOI 10.1145/3357384.3358092
   Garner SR, WEKA WAIKATO ENV KNO
   Gavankar SS, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P837, DOI 10.1109/I2CT.2017.8226246
   Gbenga DE., 2017, NOVA J ENG APPL SCI, V6, P1, DOI DOI 10.20286/NOVA-JEAS-060105
   Gomes SR, 2017, INT CONF ADV ELECTR, P482, DOI 10.1109/ICAEE.2017.8255404
   Gong CY, 2021, INT J APPROX REASON, V138, P123, DOI 10.1016/j.ijar.2021.08.006
   Guo Y., 2014, ADV MULTIMEDIA INFOR, V8879
   Gupta P, 2019, INT J SCI TECHNOL RE, V8
   Hansheng Lei, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P367, DOI 10.1109/ICNC.2011.6022107
   Hassan MA, 2018, INT CONF SOFT COMP, P93, DOI 10.1109/ISCMI.2018.8703222
   He LM, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3613
   Heredia B, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P127, DOI [10.1109/ICMLA.2016.38, 10.1109/ICMLA.2016.0029]
   Huang XL, 2015, NEUROCOMPUTING, V149, P1596, DOI 10.1016/j.neucom.2014.08.033
   Jain V, 2019, INT GEOSCI REMOTE SE, P3297, DOI 10.1109/igarss.2019.8897862
   Jiang LX, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS, P679, DOI 10.1109/FSKD.2007.552
   Joshi A.V., 2020, Machine Learning and Artificial Intelligence
   Kadlek F., 2013, P 10 FPGA WORLD C FP, V2, P1, DOI [10.1145/2513683.2513685, DOI 10.1145/2513683.2513685]
   Kalbhor M, 2013, 2013 4 INT C COMPUTI, P1, DOI [10.1109/ICCCNT.2013.6726691, DOI 10.1109/ICCCNT.2013.6726691]
   Kalmegh SR., 2018, INT J ENG SCI INVENT, V7, P01
   Kangil Kim, 2018, 2018 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/ICOPS35962.2018.9575485
   Kaur J., 2017, INT J COMPUT ENG TEC, V8, P83
   Kohavi R., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P249
   Kontsewaya Yu., 2021, Proc. Comput. Sci, V190, P479, DOI [10.1016/j.procs.2021.06.056, DOI 10.1016/J.PROCS.2021.06.056]
   Kramer O., 2013, Dimensionality Reduction with Unsupervised Nearest Neighbors, P13, DOI DOI 10.1007/978-3-642-38652-72
   Li JM, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, P68, DOI 10.1109/ISCID.2008.51
   Lin CJ, 2002, IEEE T NEURAL NETWOR, V13, P1045, DOI 10.1109/TNN.2002.1031937
   Lin L, 2020, CLIN NUTR, V39, P3182, DOI 10.1016/j.clnu.2020.02.013
   Liu YZ, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4360
   Lv C, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277962
   Ma CJ, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2020), P1567, DOI 10.1109/ICMCCE51767.2020.00343
   Mary JS, 2019, MEASUREMENT, V146, P24, DOI 10.1016/j.measurement.2019.05.102
   Matharasi B., 2017, INT J SCI RES PUBL, V7, P337
   Méndez JR, 2019, APPL SOFT COMPUT, V76, P89, DOI 10.1016/j.asoc.2018.12.008
   Moon SH, 2020, ATMOS RES, V240, DOI 10.1016/j.atmosres.2020.104928
   More AS, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P72, DOI 10.1109/ICISIM.2017.8122151
   Nasreen M, 2018, P 2 INT C EL COMM AE
   Noronha DH, 2019, MICROPROCESS MICROSY, V69, P138, DOI 10.1016/j.micpro.2019.06.007
   Okfalisa, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P294, DOI 10.1109/ICITISEE.2017.8285514
   Osegi EN, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100080
   Paing MP, 2018, BIOMED ENG INT CONF
   Panhalkar AR, 2022, J KING SAUD UNIV-COM, V34, P4763, DOI 10.1016/j.jksuci.2021.01.011
   Panigrahi P. K., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P506, DOI 10.1109/CICN.2012.14
   Panigrahi Ranjit, 2018, Procedia Computer Science, V132, P323, DOI 10.1016/j.procs.2018.05.186
   Patel DR, 2020, MATER TODAY-PROC, V26, P350, DOI 10.1016/j.matpr.2019.12.029
   Patel R, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P560, DOI 10.1109/CICN.2014.127
   Patil Siddalingeshwar, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1365, DOI 10.1109/ICOEI.2019.8862580
   Patil Tina R, 2013, INT J COMPUT SCI APP, V6
   Paul A, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010003
   Pelle R, 2018, WEBMEDIA'18: PROCEEDINGS OF THE 24TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB, P237, DOI 10.1145/3243082.3243111
   Peng XJ, 2013, INFORM SCIENCES, V221, P12, DOI 10.1016/j.ins.2012.09.009
   Pisner D.A., 2020, MACH LEARN, P101, DOI [DOI 10.1016/B978-0-12-815739-8.00006-7, 10.1016/B978-0-12-815739-8.00006-7]
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Platt JC, 1999, ADV NEUR IN, V11, P557
   Prakash JS, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P197, DOI 10.1109/MVIP.2012.6428794
   Provost J, 1999, NA IVE BAYES VS RULE
   Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346
   Rachida I, 2019, SCA2019
   Rathod SB, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1257, DOI 10.1109/ICCSP.2015.7322709
   Sahingoz OK, 2019, EXPERT SYST APPL, V117, P345, DOI 10.1016/j.eswa.2018.09.029
   Sahoo SR, 2020, ENTERP INF SYST-UK, V14, P710, DOI 10.1080/17517575.2020.1712742
   Saidani N, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101716
   Schapire Robert E, 2013, EMPIRICAL INFERENCE, P37, DOI [DOI 10.1007/978-3-642-41136-65, DOI 10.1007/978-3-642-41136-6_5]
   Shah N, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P473, DOI [10.1109/AICAI.2019.8701311, 10.1109/aicai.2019.8701311]
   Shahbudin S, 2008, IEEE SYS MAN CYBERN, P373, DOI 10.1109/ICSMC.2008.4811304
   Sharma A., 2016, International Journal of Computer Applications, V136, P28, DOI [DOI 10.5120/IJCA2016908471, 10.5120/ijca2016908471]
   Sharma AK, 2015, INT CONF COMM SYST, P1089, DOI 10.1109/CSNT.2015.11
   Shiliang Sun, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P91, DOI 10.1109/FSKD.2010.5569740
   Shubhangi DC., 2009, P INT C ADV COMP COM, P444, DOI [DOI 10.1145/1523103.1523191, 10.1145/1523103.1523191]
   Singels A., 2019, Proceedings of the Annual Congress - South African Sugar Technologists' Association, P1
   Subasi A, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON COMPUTER APPLICATIONS & INFORMATION SECURITY (ICCAIS' 2018)
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   Tran T., 2008, IEEE NetCod'08, P1
   Tretyakov K, MACHINE LEARNING TEC
   Turcanik M, 2015, INT C MIL TECHN ICMT, P1, DOI [10.1109/MILTECHS.2015.7153739, DOI 10.1109/MILTECHS.2015.7153739]
   Urmaliya A, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P481, DOI 10.1109/ICIIP.2013.6707638
   Vanhoenshoven F, 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), DOI 10.1109/SSCI.2016.7850079
   Vapnik V.N., 2000, The nature of statistical learning theory, P123, DOI [DOI 10.1007/978-1-4757-3264-1_6, DOI 10.1007/978-1-4757-3264-16]
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Vijayanand R, 2018, COMPUT SECUR, V77, P304, DOI 10.1016/j.cose.2018.04.010
   Wang F, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107521
   Wang LS, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P1676
   Wang SH, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3232230
   Wei R, 2020, J STAT PLAN INFER, V207, P215, DOI 10.1016/j.jspi.2019.12.004
   Witt G, 2012, WRITING EFFECTIVE BU, P25, DOI [10.1016/B978-0-12-385051-5.00003-3, DOI 10.1016/B978-0-12-385051-5.00003-3]
   Wu S., 2018, P INT C COMP DAT ENG, P62
   Yang FJ, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2019), P349, DOI 10.1109/CSCI49370.2019.00068
   Yasin W, INTELLIGENT COOPERAT
   Yuan PS, 2018, IEEE INT C BIOINFORM, P275, DOI 10.1109/BIBM.2018.8621234
   Zhang Z, 2020, MECH ADV MATER STRUC, V27, P3, DOI 10.1080/15376494.2018.1444216
   Zhu L, 2019, PROCEDIA COMPUT SCI, V162, P503, DOI 10.1016/j.procs.2019.12.017
NR 122
TC 5
Z9 5
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29227
EP 29254
DI 10.1007/s11042-023-14689-3
EA FEB 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936501100013
DA 2024-07-18
ER

PT J
AU Tiwary, T
   Mahapatra, RP
AF Tiwary, Tejal
   Mahapatra, Rajendra Prasad
TI Enhancement in web accessibility for visually impaired people using
   hybrid deep belief network -bald eagle search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visually impaired; Artificial intelligence; Alt text images; Bald eagle
   search; Deep belief network
AB In the modern era, accessing the web is the major task for Visually Impaired (VI) people that creates opportunities to connect with social media as part of professional, political, and social life. One of the difficulties faced by VI users is accessing and understanding images online. The advancements in assistive technologies based on computer-vision (CV) assist the VI people in diverse scenarios such as grocery shopping, generation of alternative text, object recognition, understanding text documents, identifying people etc. In this study, to make the digital platform user-friendly for VI people, an automated system is developed to generate alternative (alt) text for online images that are not captioned or the alt text is not specified for the image. The proposed Deep Belief Network - Bald Eagle Search (DBN-BES) method offers an effective way for VI that allows automatic captioning of web images. Our proposed work consists of two stages. The initial stage is the selection of images that are not captioned, and this selection process is obtained using the Bald Eagle Search (BES) Algorithm. After the selection stage, alt text for corresponding images is produced with the help of the Deep Belief Network (DBN) model. Thus, the proposed DBN-BES model automatically generates alt text which helps the VI people to understand the image content better. The presented model routinely increases web accessibility, addresses massive image data being created daily, and makes the web accessible to multiple users around the globe.
C1 [Tiwary, Tejal] SRMIST, Dept Comp Sci & Engn, NCR Campus, Ghaziabad, India.
   [Mahapatra, Rajendra Prasad] SRMIST, Dept CSE, NCR Campus, Ghaziabad, India.
C3 SRM Institute of Science & Technology Delhi NCR (Ghaziabad); SRM
   Institute of Science & Technology Delhi NCR (Ghaziabad)
RP Tiwary, T (corresponding author), SRMIST, Dept Comp Sci & Engn, NCR Campus, Ghaziabad, India.
EM tejal.tiwary@gmail.com
CR Akhil R, 2018, ADV INTELL SYST, ppp103
   Bhandari A, 2021, DISABIL REHABIL-ASSI, V16, P280, DOI 10.1080/17483107.2019.1673834
   Blachnik M, 2015, LECT NOTES ARTIF INT, V9119, P687, DOI 10.1007/978-3-319-19324-3_61
   Brzostek-Pawlowska J, 2019, NEW REV HYPERMEDIA M, V25, P31, DOI 10.1080/13614568.2019.1664645
   Cena F, 2019, WEB ACCESSIBILITY FD, ppp777
   Doush I., 2019, JORDAN J COMPUT INFO, V5, P1
   Elgendy IA, 2021, BIG DATA-US, V9, P265, DOI 10.1089/big.2020.0284
   Elgendy IA, 2021, WIREL NETW, V27, P2023, DOI 10.1007/s11276-021-02554-w
   Georgieva-Tsaneva GN, 2018, DIGIT PRESENT PRESER, V8, P143
   Giraud S, 2018, INT J HUM-COMPUT ST, V111, P23, DOI 10.1016/j.ijhcs.2017.10.011
   Guinness D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174092
   Hersh, 2008, DISABILITY ASSISTIVE, V1
   Ismail A, 2022, J KING SAUD UNIV-COM, V34, P901, DOI 10.1016/j.jksuci.2019.03.011
   Khayyat M, 2020, IEEE ACCESS, V8, P137052, DOI 10.1109/ACCESS.2020.3011705
   Kuber R, 2020, ASSISTIVE MULTIMODAL
   Lauer F, 2016, AUTOMATICA, V74, P80, DOI 10.1016/j.automatica.2016.07.027
   MacLeod H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5988, DOI 10.1145/3025453.3025814
   Makkar T, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P182
   Matousek J, 2020, J MULTIMODAL USER IN, V14, P219, DOI 10.1007/s12193-020-00323-1
   Nadi A, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.018
   Nir HL, 2018, UNIVERSAL ACCESS INF, V17, P663, DOI 10.1007/s10209-018-0615-7
   Oliveira R, 2021, HDB RES MULTIDISCIPL, P331
   Presley I., 2009, Assistive technology for students who are blind or visually impaired: A guide to assessment
   Rafiq M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061702
   Rayini J, 2017, LIB PHILOS PRACT E J, V1510
   Raymaker DM, 2019, AUTISM ADULTHOOD, V1, P146, DOI 10.1089/aut.2018.0020
   Salisbury E., 2017, P AAAI C HUMAN COMPU
   Shahira KC, 2021, IEEE ACCESS, V9, P52926, DOI 10.1109/ACCESS.2021.3069205
   Sridevi M, 2020, PROCEDIA COMPUT SCI, V167, P1839, DOI 10.1016/j.procs.2020.03.203
   Tapu R, 2020, PATTERN RECOGN LETT, V137, P37, DOI 10.1016/j.patrec.2018.10.031
   Vtyurina A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3590, DOI 10.1145/3308558.3314136
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Xie I, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102110
   Zhang XH, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01160-8
   Zhang XY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P609, DOI 10.1145/3242587.3242616
NR 35
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24347
EP 24368
DI 10.1007/s11042-023-14494-y
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000936501100002
DA 2024-07-18
ER

PT J
AU Wang, ZH
   Tang, ZJ
   Huang, JK
   Li, JD
AF Wang, Zhanhua
   Tang, Zhijie
   Huang, Jingke
   Li, Jianda
TI Fast calibration stitching algorithm for underwater camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fish-eye correction; Adaptive grayscale conversion method; FASTITCH
   stitch algorithm; Fish-eye stitching
AB Underwater environment is complex and changeable. In order to obtain more underwater environment information. The larger the field of view of underwater images collected by ROV, the more information is contained. Effective methods to obtain large field of view include fish-eye lens and image stitching. In order to obtain larger field information, we combine the two methods and propose a splicing algorithm that can be applied to fish-eye lenses. This algorithm includes two parts, the first part is correction the fish-eye images, on the basis of the traditional chessboard correction method to improve, this paper put forward a new adaptive gray level method, this method can keep more angular point features, can be more accurate extraction of checkerboard angular point, will be further accurate correction result. In order to achieve real-time underwater patchwork effect. For stitching the corrected images, this paper proposes a fast stitching algorithm (FASTITCH), in the process of image stitching, the algorithm can preserve image feature points and transposed matrix of image matching, so as to calculate the new coordinates, joining together the original feature points in the image. Using this coordinate to match the feature points of another image can save the time of finding feature points in the stitching image, and finally speed up the stitching and complete the task of real-time stitching. The experiment proves that: The error obtained by the new correction method is smaller. Compared with the traditional feature point stitching algorithm, the fast stitching algorithm (FASTITCN) proposed in this paper can shorten the stitching time by about 20%.
C1 [Wang, Zhanhua; Tang, Zhijie; Huang, Jingke; Li, Jianda] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
C3 Shanghai University
RP Tang, ZJ (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
EM tangzhijie@shu.edu.cn
RI wang, zhenyu/H-4365-2011
FU Natural Science Foundation of Shanghai [19ZR1419300]
FX AcknowledgementsThe author(s) disclosed receipt of the following
   financial support for the research, authorship, and publication of this
   article: This work was supported by the Natural Science Foundation of
   Shanghai (No.19ZR1419300) for providing financial support for this
   work.CRediT authorship contribution statementZhanhua Wang: Served as
   scientific advisors, Critically reviewed the study proposal, Software,
   Validation,Writing - original draft.Zhijie Tang: Served as scientific
   advisors, Funding acquisition.Jingke Huang: Writing - review & collected
   data.Jianda Li: Writing- review & collected data.
CR Bay H., 2006, P EUROPEAN C COMPUTE
   Cheng XM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040486
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hossein-Nejad Z, 2021, PATTERN ANAL APPL, V24, P669, DOI 10.1007/s10044-020-00938-w
   Jong-Eun Ha, 2013, 2013 INT S MECHATRON
   Lu L., 2019, INFRARED LASER ENG, V48, P926002, DOI [10.3788/IRLA201948.0926002, DOI 10.3788/IRLA201948.0926002]
   Martinez NT, 2021, OPTIC QUANT ELECT
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tang MH, 2019, IEEE T MULTIMEDIA, V21, P957, DOI 10.1109/TMM.2018.2867266
   Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011
   Wang J, 2008, PATTERN RECOGN, V41, P607, DOI 10.1016/j.patcog.2007.06.012
   Wang M, 2018, IEEE T MULTIMEDIA, V20, P620, DOI 10.1109/TMM.2017.2748459
   Wang Y., 2019, RAILWAY ENG
   Xiang X, 2020, CMC-COMPUT MATER CON, V62
   Xue W, 2021, IEEE T CIRC SYST VID, P1, DOI DOI 10.1109/TCSVT.2021.3058655
   Zhang X., 2018, IEEE T IMAGE PROCESS, V07, P16, DOI [10.12677/JISP.2018.71002, DOI 10.12677/JISP.2018.71002]
   Zhao Q, 2013, IEEE T MULTIMEDIA, V15, P1745, DOI 10.1109/TMM.2013.2280249
NR 17
TC 0
Z9 0
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27707
EP 27726
DI 10.1007/s11042-023-14533-8
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300004
DA 2024-07-18
ER

PT J
AU Xie, HW
   Zhang, YZ
   Zhang, H
   Li, ZY
AF Xie, Hong-wei
   Zhang, Yu-zhou
   Zhang, Hao
   Li, Zhen-yu
TI Novel medical image cryptogram technology based on segmentation and DNA
   encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4-D hyperchaotic system; Image segmentation; Regions of interest (ROI);
   Deoxyribonucleic acid (DNA) encoding; Medical image encryption
ID SEMI-TENSOR PRODUCT; ENCRYPTION ALGORITHM; CHAOS; MATRIX; COMBINATION;
   SEQUENCES; SYSTEM
AB This paper proposes a novel medical image cryptogram technology based on a fast and robust fuzzy C-means clustering image segmentation method and deoxyribonucleic acid encoding. In our method, first, the medical image is divided into background areas and regions of interest utilizing fuzzy C-means clustering image segmentation, which increases the encryption efficiency by about 60% when the background area is discarded. Second, some low-value pixels are also discarded in regions of interest to further reduce the encryption time. Third, a 4-dimensional hyperchaotic system has been improved. Furthermore, the hyperchaotic system and deoxyribonucleic acid encoding are utilized to encrypt the medical image. Finally, lossless encryption and fast encryption are done for different purposes. The experimental results demonstrate that the proposed algorithm has appealing encryption performance and the histogram and scatter graphs are governed by approximately uniform distribution. The NPCR and UACI of plaintext sensitivity and the key sensitivity are close to 99.6094% and 33.4635% respectively, which cause robustness against noise and clipping attacks.
C1 [Xie, Hong-wei; Zhang, Yu-zhou] Taiyuan Univ Technol, Coll Software, Jinzhong 030600, Peoples R China.
   [Zhang, Hao; Li, Zhen-yu] Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Zhang, H (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
EM zhangh545@126.com
RI li, zy/HZM-1892-2023
FU National Natural Science Foundation of China [61702356]; National
   Natural Science Foundation of Shanxi Province [201801D121143,
   20210302124050]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61702356), National Natural Science Foundation of Shanxi
   Province (Nos: 201801D121143 and 20210302124050).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   Deb S, 2021, MULTIMED TOOLS APPL, V80, P19803, DOI 10.1007/s11042-020-10308-7
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Gafsi M., 2020, SCI PROGRAMMING-NETH, V2020, P1
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hajjaji MA, 2019, MULTIMED TOOLS APPL, V78, P14379, DOI 10.1007/s11042-018-6795-6
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Jeevitha S, 2021, J AMB INTEL HUM COMP, V12, P3373, DOI 10.1007/s12652-020-02399-9
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li X, 2020, IEEE T NANOBIOSCI, V19, P299, DOI 10.1109/TNB.2020.2971644
   Liu HJ, 2016, OPTIK, V127, P5812, DOI 10.1016/j.ijleo.2016.04.014
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Signing VRF, 2021, CIRC SYST SIGNAL PR, V40, P4370, DOI 10.1007/s00034-021-01665-1
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   [鲜永菊 Xian Yongju], 2021, [振动与冲击, Journal of Vibration and Shock], V40, P15
   Xian YS, 2022, INT J COAL PREP UTIL, V42, P3249, DOI 10.1080/19392699.2021.1949712
   Xue XL, 2021, FRONT GENET, V12, DOI 10.3389/fgene.2021.654663
NR 32
TC 3
Z9 3
U1 8
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27593
EP 27613
DI 10.1007/s11042-023-14546-3
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934222700011
DA 2024-07-18
ER

PT J
AU Wang, LL
   Li, MY
   Chen, DY
   Yang, HL
   Lv, HX
AF Wang, Lili
   Li, Mingyu
   Chen, Deyun
   Yang, Hailu
   Lv, Hexiang
TI ECT for flow imaging: total least squares for image reconstruction
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrical capacitance tomography; Image reconstruction; Truncated
   singular value decomposition; Total least squares
AB For the problem that noise has a great impact on the measurement data during the electrical capacitance tomography data acquisition process, a denoising method based on the truncated singular value decomposition combined with the total least squares model is proposed. Soft threshold is performed on the effective value of the truncated singular value decomposition to remove the influence of external noise interference in the measurement data, and as far as possible to retain the original characteristics of the data. For the problem of different errors in the measurement data and the coefficient matrix, a mathematical model is introduced based on total least squares. It is used to improve the total least squares iterative method and reduce both the measurement error and the coefficient matrix error. To solve the problems of slow convergence speed and low efficiency caused by the ill-posedness of the equation during the iteration, adaptive correction parameters are introduced, which effectively avoids the occurrence of local convergence and improves the speed of convergence and imaging accuracy. To solve the ill-condition of the total least squares model, a regularization matrix is added so that the imaging results can achieve the goal of overall optimization. For 12-electrode electrical capacitance tomography system, the simulation experiments are carried out based on four typical flow patterns. The results show that the algorithm effectively increases the robustness of reconstruction and improves the accuracy of the reconstructed images.
C1 [Wang, Lili; Li, Mingyu; Chen, Deyun; Yang, Hailu; Lv, Hexiang] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Li, Mingyu] Heilongjiang Expt High Sch, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology
RP Wang, LL (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
EM wanglili@hrbust.edu.cn
RI zheng, yan/JKJ-3632-2023; wang, xiaoxuan/JMP-6531-2023; li,
   yifan/JHU-9272-2023; Wang, Xuechun/JRX-6509-2023; Zhang,
   Yunyi/JHS-3626-2023; Yu, Xiaohan/KCK-5462-2024; zhao, yan/JNT-6961-2023;
   yuanyuan, Li/JEZ-6497-2023; zhao, lin/JJF-0406-2023; zhang,
   xiao/JCN-8822-2023; song, yu/KCZ-2003-2024; su, hang/KEH-2976-2024;
   yang, yunfeng/KHT-9566-2024; yang, xiao/JLL-7721-2023
OI Wang, Lili/0000-0001-7633-6828
FU National Natural Science Foundation of China [61402126, 60572153,
   60972127]; Nature Science Foundation of Heilongjiang province of China
   [F2016024]; Heilongjiang Postdoctoral Science Foundation [LBH-Z15095];
   University Nursing Program for Young Scholars with Creative Talents in
   Heilongjiang Province [UNPYSCT-2017094]
FX AcknowledgementsWe thank the anonymous reviewers for valuable feedback.
   This work is sponsored by National Natural Science Foundation of China
   (61402126, 60572153, 60972127), Nature Science Foundation of
   Heilongjiang province of China (F2016024), Heilongjiang Postdoctoral
   Science Foundation (LBH-Z15095), University Nursing Program for Young
   Scholars with Creative Talents in Heilongjiang Province
   (UNPYSCT-2017094).
CR Almutairi Z, 2020, PROCESSES, V8, DOI 10.3390/pr8010051
   Cao BX., 2020, ANAL CHIM ACTA, V5, P1
   Chen T., 2019, CELL DISCOV, V6, P71
   Chen Yu, 2018, Computer Engineering, V44, P268, DOI 10.3969/j.issn.1000-3428.2018.01.045
   Lei J, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106126
   Li Yang, 2004, Chinese Journal of Scientific Instrument, V25, P665
   Lu L, 2019, T I MEAS CONTROL, V41, P2389, DOI 10.1177/0142331218799841
   [马敏 Ma Min], 2020, [传感器与微系统, Transducer and Microsystem Technology], V39, P136
   Naeimi Y, 2020, J STAT SOFTW, V55, P1
   Qian CJ., 2016, PHYS REV LETT, V39, P1
   Su YC, 2019, RSF-RUS SAGE J SOC S, V45, P42
   Sun TH., 2020, RSF-RUS SAGE J SOC S, V49, P398
   Tian, 2012, CONTROL INSTRUM CHEM, V39, P1387
   Wang HG, 2020, APPL THERM ENG, V176, DOI 10.1016/j.applthermaleng.2020.115311
   [王建国 Wang Jianguo], 2014, [振动与冲击, Journal of Vibration and Shock], V33, P176
   [王莉莉 Wang Lili], 2015, [仪器仪表学报, Chinese Journal of Scientific Instrument], V36, P515
   Wang YF., 2020, BMC GENOMICS, V42, P313
   [吴光明 Wu Guangming], 2019, [大地测量与地球动力学, Journal of Geodesy and Geodynamics], V39, P856
   Xing ZZ., 2016, MILITARY MED RES, V35, P1119
   Yang T., 2018, SCI REP-UK, V23, P12
   Zhang Lifeng, 2019, Electrical Measurement and Instrumentation, V56, P42, DOI 10.19753/j.issn1001-1390.2019.020.007
   Zhao Y., 2020, J NORTHEAST FOR UNIV, V48, P66
NR 22
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22741
EP 22758
DI 10.1007/s11042-023-14520-z
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000929853100003
DA 2024-07-18
ER

PT J
AU Liu, KX
   Zhu, C
   Tao, XY
   Bruniaux, P
   Zeng, XY
   Wang, JP
AF Liu, Kaixuan
   Zhu, Chun
   Tao, Xuyuan
   Bruniaux, Pascal
   Zeng, Xianyi
   Wang, Jianping
TI A novel evaluation technique for human body perception of clothing fit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fit evaluation; Decision tree C4; 5; Machine learning; Fashion design;
   Data learning
ID GARMENT PATTERN; DESIGN; SIZE; OPTIMIZATION; INTENTIONS
AB Fit evaluation plays an important role in garment products development and sales. Effective clothing fit evaluation methods can reduce the development cost of apparel products and the return rate of online apparel sales. In this research, we proposed an intelligent fit evaluation technology to predict clothing fit. The mathematical relationship model between clothing fit levels and indexes reflecting the clothing fit levels was constructed by using decision tree C4.5 algorithm. Then, two experiments were carried out to collect input and output training data. After learning from the collected data, the proposed model can predict clothing fit accurately. Next, we validated our proposed model's prediction accuracy using K-fold cross validation. Finally, we gave two applications of the proposed model for clothing products development and shopping online. Results show that our proposed method has high prediction accuracy and less requirement for the number of learning samples, and can predict clothing fit automatically and rapidly without real try-on.
C1 [Liu, Kaixuan; Zhu, Chun] Xian Polytech Univ, Apparel & Art Design Coll, Xian 710048, Peoples R China.
   [Liu, Kaixuan] Xian Polytech Univ, Shanxi Key Lab Intelligent Clothing Design, Xian 710048, Peoples R China.
   [Liu, Kaixuan; Tao, Xuyuan; Bruniaux, Pascal; Zeng, Xianyi] GEMTEX Lab, ENSAIT, F-59100 Roubaix, France.
   [Zhu, Chun; Wang, Jianping] Donghua Univ, Coll Fash & Design, Shanghai 200051, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University; Universite
   de Lille; Ecole Nationale Superieure des Arts et Industries Textiles
   (ENSAIT); Donghua University
RP Liu, KX (corresponding author), Xian Polytech Univ, Apparel & Art Design Coll, Xian 710048, Peoples R China.; Liu, KX (corresponding author), Xian Polytech Univ, Shanxi Key Lab Intelligent Clothing Design, Xian 710048, Peoples R China.; Liu, KX (corresponding author), GEMTEX Lab, ENSAIT, F-59100 Roubaix, France.
EM liukaixuan819@163.com
RI Zeng, Xianyi/AAQ-1183-2021
OI Zeng, Xianyi/0000-0002-3236-6766; liu, kaixuan/0000-0003-4105-8324
FU National Natural Science Foundation of China [61806161]; Natural Science
   Basic Research Program of Shaanxi Province, China [2019JQ-848];
   Innovation Ability Support Plan of Shaanxi Province-young Science and
   Technology Star Project, China [2020KJXX-083]; Youth Innovation Team of
   Shaanxi Universities, China
FX This paper was financially supported by the National Natural Science
   Foundation of China (No. 61806161), the Natural Science Basic Research
   Program of Shaanxi Province, China (No. 2019JQ-848), the Innovation
   Ability Support Plan of Shaanxi Province-young Science and Technology
   Star Project, China (No. 2020KJXX-083), China and the Youth Innovation
   Team of Shaanxi Universities, China.
CR Ashdown S.P., 2006, CLOTH TEXT RES J, V24, P121, DOI DOI 10.1177/0887302X0602400206
   Chattaraman V, 2013, CLOTH TEXT RES J, V31, P291, DOI 10.1177/0887302X13506111
   Chen CM, 2007, INT J CLOTH SCI TECH, V19, P131, DOI 10.1108/09556220710725720
   Chen X, 2015, KNOWL-BASED SYST, V87, P92, DOI 10.1016/j.knosys.2015.05.031
   Chiew KL, 2019, INFORM SCIENCES, V484, P153, DOI 10.1016/j.ins.2019.01.064
   Dutti A, 2017, IEEE ACCESS, V5, P15991, DOI 10.1109/ACCESS.2017.2654247
   Guo ZX, 2011, TEXT RES J, V81, P1871, DOI 10.1177/0040517511411968
   Han L, 2019, EXPERT SYST APPL, V122, P65, DOI 10.1016/j.eswa.2018.12.042
   Huck J., 1997, INT J CLOTH SCI TECH, V9, P45, DOI [10.1108/09556229710157876, DOI 10.1108/09556229710157876]
   Jiang Q, 2019, EXPERT SYST APPL, V116, P439, DOI 10.1016/j.eswa.2018.08.046
   Kausar S, 2018, IEEE ACCESS, V6, P72724, DOI 10.1109/ACCESS.2018.2882240
   Kim H, 2010, CLOTH TEXT RES J, V28, P79, DOI 10.1177/0887302X09332513
   Lin YL, 2016, MULTIMED TOOLS APPL, V75, P7575, DOI 10.1007/s11042-015-2681-7
   Liu KX, 2022, INT J ADV MANUF TECH, V120, P2685, DOI 10.1007/s00170-022-08965-z
   Liu KX, 2018, COMPUT AIDED DESIGN, V104, P113, DOI 10.1016/j.cad.2018.07.003
   Liu KX, 2018, INT J IND ERGONOM, V65, P46, DOI 10.1016/j.ergon.2018.01.013
   Liu KX, 2017, J TEXT I, V108, P2107, DOI 10.1080/00405000.2017.1315794
   Liu KX, 2017, KNOWL-BASED SYST, V133, P174, DOI 10.1016/j.knosys.2017.07.007
   Liu KX, 2017, INT J CLOTH SCI TECH, V29, P673, DOI 10.1108/IJCST-10-2016-0115
   Liu KX, 2017, INT J CLOTH SCI TECH, V29, P166, DOI 10.1108/IJCST-03-2016-0017
   Liu KX, 2016, INT J CLOTH SCI TECH, V28, P736, DOI 10.1108/IJCST-02-2016-0016
   Liu KX, 2016, INT J IND ERGONOM, V55, P60, DOI 10.1016/j.ergon.2016.07.008
   Liu KX, 2016, FIBER POLYM, V17, P1522, DOI 10.1007/s12221-016-6402-2
   Lu YH, 2014, APPL ERGON, V45, P1439, DOI 10.1016/j.apergo.2014.04.007
   Melin P, 2018, INFORM SCIENCES, V460, P594, DOI 10.1016/j.ins.2017.09.031
   Satam D, 2011, J TEXT I, V102, P353, DOI 10.1080/00405000.2010.482351
   Shin E, 2014, CLOTH TEXT RES J, V32, P20, DOI 10.1177/0887302X13515072
   Sun PY, 2019, INFORM SCIENCES, V479, P456, DOI 10.1016/j.ins.2018.04.065
   Tao XY, 2018, COMPUT IND ENG, V115, P683, DOI 10.1016/j.cie.2017.10.023
   Tao X, 2013, INT J CLOTH SCI TECH, V25, P266, DOI 10.1108/09556221311326301
   Thomassey S, 2013, INT J IND ERGONOM, V43, P406, DOI 10.1016/j.ergon.2013.08.002
   Zhang X, 2002, TEXT RES J, V72, P245, DOI 10.1177/004051750207200311
   Zhao XQ, 2021, TEXT RES J, V91, P2786, DOI 10.1177/00405175211020515
NR 33
TC 1
Z9 1
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21057
EP 21069
DI 10.1007/s11042-023-14530-x
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000933178200002
DA 2024-07-18
ER

PT J
AU Cai, ZF
   Fan, YL
AF Cai, Zhefei
   Fan, Yingle
TI A contour perception model that simulates the complex connection pattern
   of the visual cortex
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feedback connection; Horizontal connection; Hue perception; Surround
   suppression
ID COLOR; NETWORK; INHIBITION; BOUNDARIES
AB Contour detection is the basic content of image processing and plays an important role in image analysis and target recognition. This paper proposed a contour perception model that simulates the complex connection pattern of the visual cortex. The connection included the feedforward input from the lateral geniculate body (LGN), the horizontal input from the neurons in the same layer, and the feedback input from the advanced visual cortex. Using the sparse coding characteristics of the LGN, the windmill-like structure receptive field of the primary visual cortex, and the hue perception characteristics of the advanced visual cortex to improve the accuracy of the contour extracted by the proposed model. Choosing the BSDS500 natural scene dataset as the experimental object, the F-score is selected as the evaluation index. The average optimal F-score of the proposed method is 0.72, which is better than other mainstream biological vision-based methods. Concurrently, the NYUD dataset is used for further verification. To comprehensively verify the effectiveness of the model proposed in this paper, Performance-value rather than F-score is selected as the evaluation index. The average optimal Performance-value of the proposed method is 0.42, which shows better results, too. The complex connection pattern allows neural encoding and decoding to make full use of the characteristics of information exchange between the visual cortexes, which is more in line with the biological vision system.
C1 [Cai, Zhefei; Fan, Yingle] Hangzhou Dianzi Univ, Lab Pattern Recognit & Image Proc, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Fan, YL (corresponding author), Hangzhou Dianzi Univ, Lab Pattern Recognit & Image Proc, Hangzhou 310018, Peoples R China.
EM fan@hdu.edu.cn
RI Cai, Zhefei/ITT-4420-2023
OI Cai, Zhefei/0000-0001-6248-3026
FU Laboratory of Pattern Recognition and Image Processing in Hangzhou
   Dianzi University
FX This work has been supported by the Laboratory of Pattern Recognition
   and Image Processing in Hangzhou Dianzi University.
CR Akbarinia A, 2018, INT J COMPUT VISION, V126, P1367, DOI 10.1007/s11263-017-1035-5
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Azzopardi G, 2012, BIOL CYBERN, V106, P177, DOI 10.1007/s00422-012-0486-6
   BENJAMINI Y, 1988, AM STAT, V42, P257, DOI 10.2307/2685133
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   BUCHSBAUM G, 1983, PROC R SOC SER B-BIO, V220, P89, DOI 10.1098/rspb.1983.0090
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao YJ, 2019, MULTIMED TOOLS APPL, V78, P25121, DOI 10.1007/s11042-019-7722-1
   Capparelli F, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007370
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Fang T, 2020, SIGNAL IMAGE VIDEO P, V14, P1461, DOI 10.1007/s11760-020-01689-1
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jacob T, 2016, NEUROCOMPUTING, V199, P185, DOI 10.1016/j.neucom.2016.03.023
   Li M, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0807
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lin C, 2019, AUTOM CONTROL COMPUT, V53, P560, DOI 10.3103/S0146411619060075
   Liu LX, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115915
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Ma W, 2020, INFORM FUSION, V64, P238, DOI 10.1016/j.inffus.2020.08.014
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Melotti D, 2020, INFORM SCIENCES, V524, P229, DOI 10.1016/j.ins.2020.03.026
   Mingolla E, 1999, NEURAL NETWORKS, V12, P499, DOI 10.1016/S0893-6080(98)00144-0
   Mohan YS, 2019, CEREB CORTEX, V29, P5255, DOI 10.1093/cercor/bhz063
   Moratti S, 2014, NEUROIMAGE, V86, P470, DOI 10.1016/j.neuroimage.2013.10.037
   Murgas KA, 2020, J NEUROSCI, V40, P1862, DOI 10.1523/JNEUROSCI.1997-19.2020
   NATHANS J, 1986, SCIENCE, V232, P193, DOI 10.1126/science.2937147
   Palmerston JB, 2020, NEUROSCI LETT, V739, DOI 10.1016/j.neulet.2020.135407
   Wang YP, 2019, IEEE T IMAGE PROCESS, V28, P1285, DOI 10.1109/TIP.2018.2874279
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang HJ, 2019, KNOWL-BASED SYST, V164, P21, DOI 10.1016/j.knosys.2018.09.033
   Yang KF, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425538
   Yang KF, 2014, IEEE T IMAGE PROCESS, V23, P5020, DOI 10.1109/TIP.2014.2361210
   Yuan BH, 2021, NEUROCOMPUTING, V425, P219, DOI 10.1016/j.neucom.2020.04.089
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang Q, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107657
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
NR 40
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19347
EP 19368
DI 10.1007/s11042-022-14194-z
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886192700001
DA 2024-07-18
ER

PT J
AU Rahul
   Katarya, R
AF Rahul
   Katarya, Rahul
TI Deep auto encoder based on a transient search capsule network for
   student performance prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Student performance prediction; OULA dataset;
   Classification; Deep autoencoder; Capsule network
AB Prediction of Student performance through a machine predicts a student's future success. It can be considered an essential procedure to determine the students' academic excellence and identify them at high risk for academic performance. Prediction of student performance also provides universities with a high reputation and ranking. The evaluation of 'What students can do with their learning' is still a tedious task. There are many challenging factors to solve this problem, mainly owing to the enormous amount of data collected from students. Most of the research works have focused on developing new methodologies for student performance prediction. But all the existing work has some performance limitations. Here, a new model called transient search capsule network based on the deep Autoencoder (TSCNDE) is introduced to detect student performance. The TSCNDE method is implemented with the help of the PYTHON tool. The performance prediction process has been completed with the help of the OULA dataset. The obtained results are assessed on accuracy (99.2%), precision, (99.8%), specificity (98.7%), and sensitivity (98.9%) parameters. The results obtained showed that the TSCNDE method is about 99.2% more accurate than the other related method. Also, the obtained results are compared with some existing deep learning and machine learning methods.
C1 [Rahul; Katarya, Rahul] Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, New Delhi, India.
C3 Delhi Technological University
RP Rahul (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, New Delhi, India.
EM rahulzhere023@gmail.com
CR Abubakar Y., 2017, International Journal of Innovative Computing, V7
   Andolsek KM, 2016, ACAD MED, V91, P1475, DOI 10.1097/ACM.0000000000001386
   Asselman A, 2023, INTERACT LEARN ENVIR, V31, P3360, DOI 10.1080/10494820.2021.1928235
   Badugu S, 2020, ADV INTELL SYST COMP, V1079, P333, DOI 10.1007/978-981-15-1097-7_28
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Chakraborty Partha, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P683, DOI 10.1007/978-981-33-4673-4_56
   Cheung L.L. W., 2002, J EDUC BUS, V77, P257
   Giri A, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P1, DOI 10.1109/SAPIENCE.2016.7684163
   Guillén-Gámez FD, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041312
   Heuer H, 2018, DELFI 2018 DIE16 E L
   Hlosta M, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P6, DOI 10.1145/3027385.3027449
   Hussain M, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6347186
   Jaiswal AK, 2021, FUTURE GENER COMP SY, V117, P1, DOI 10.1016/j.future.2020.11.012
   Jaques N, 2017, INT CONF AFFECT, P202, DOI 10.1109/ACII.2017.8273601
   Kistner S, 2010, METACOGN LEARN, V5, P157, DOI 10.1007/s11409-010-9055-3
   Kuzilek J, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.171
   Ma YL, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-9062-8
   Minn S, 2020, ARXIV
   Namoun A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010237
   Okubo F, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P598, DOI 10.1145/3027385.3029479
   Pujianto Utomo, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P348, DOI 10.1109/ISRITI51436.2020.9315439
   Qais MH, 2020, APPL INTELL, V50, P3926, DOI 10.1007/s10489-020-01727-y
   Rahul, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P36, DOI 10.1109/I-SMAC47947.2019.9032493
   Rai Sachin, 2021, Evolution in Computational Intelligence. Frontiers in Intelligent Computing: Theory and Applications (FICTA 2020). Advances in Intelligent Systems and Computing (AISC 1176), P611, DOI 10.1007/978-981-15-5788-0_58
   Ramakrishna Sajja V., 2021, Machine Intelligence and Soft Computing. Proceedings of ICMISC 2020. Advances in Intelligent Systems and Computing (AISC 1280), P393, DOI 10.1007/978-981-15-9516-5_33
   Raut A.B., 2017, International Journal of Computational Intelligence Research, V13, P1735
   Rizvi S, 2019, COMPUT EDUC, V137, P32, DOI 10.1016/j.compedu.2019.04.001
   Saeed-Ul Hassan, 2019, INT J INTELL SYST, V34, P1935, DOI 10.1002/int.22129
   Shafi MM, 2021, INT J INSTR, V14, P65, DOI 10.29333/iji.2021.1415a
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Tripathi A., 2019, INSTRUM CONTROL TECH, V1, P1548
   Verma P, 2017, COMPUT APPL ENG EDUC, V25, P977, DOI 10.1002/cae.21849
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Zeineddine Hassan, 2021, Computers & Electrical Engineering, V89, DOI 10.1016/j.compeleceng.2020.106903
NR 37
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23427
EP 23451
DI 10.1007/s11042-022-14083-5
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000886739000001
DA 2024-07-18
ER

PT J
AU Garg, A
   Singh, AK
AF Garg, Ankit
   Singh, Anuj Kumar
TI Performance analysis of seam diversion based image retargeting technique
   based on edge detection operators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam carving; Edge detection; Saliency detection; Energy map; Edge map;
   Content-aware resizing
ID SIZE
AB Nowadays various resizing algorithms are being used to resize the images in a content-aware fashion. The seam diversion-based image retargeting (SDIR) algorithm improves the process of the existing seam carving technique. In this paper, the performance of the SDIR algorithm is analyzed based on a number of search and seam diversion operations. Further, the performance of the algorithm is analyzed based on the type of edge detection operators. To analyze the performance two experimentations are conducted. In experimentation-1, different edge detection operators are used to produce an importance map of the image. Further, the computational time of the SDIR algorithm is tested based on the identified line structures and other image objects. In experimentation-2, the performance of the algorithm is analyzed based on the visual quality of retargeted results and the quality of importance maps. To achieve this objective an objective image quality assessment (IQA) is carried out based on the structural similarity index measure (SSIM). The obtained results from phase-2 experimentation show that the distortions on the prominent regions can easily be noticeable to the human eyes when the algorithm performs many seam diversion operations. After experiment-2, a comparative analysis is conducted to justify its performance among the existing state of the arts. To meet this objective a total of 5 types of importance map is supplied to the algorithms to obtain the objective and subjective scores. After both analyses, the SDIR algorithm outperforms the other state of arts and minimize the structural deformations on the prominent objects of the image.
C1 [Garg, Ankit; Singh, Anuj Kumar] Univ Engn & Technol UETR, Sch Comp, Roorkee 247667, Uttarakhand, India.
RP Garg, A (corresponding author), Univ Engn & Technol UETR, Sch Comp, Roorkee 247667, Uttarakhand, India.
EM ankitgitm@gmail.com
RI Garg, Ankit/ABD-9886-2020; Singh, Dr. Anuj Kr./HGB-0160-2022
OI Garg, Dr. Ankit/0000-0002-6466-2738
CR Abhayadev M, 2019, J SCI IND RES INDIA, V78, P193
   Aggarwal N, 2006, IEEE T IMAGE PROCESS, V15, P582, DOI 10.1109/TIP.2005.863021
   Ahmadi M, 2021, MULTIMED TOOLS APPL, V80, P11917, DOI 10.1007/s11042-020-10185-0
   Arai K, 2019, INT J ADV COMPUT SC, V10, P143
   Asheghi B, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108496
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bakurov I, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116087
   Chai XL, 2020, IEEE T MULTIMEDIA, V22, P1208, DOI 10.1109/TMM.2019.2939707
   Chen YX, 2015, NEUROCOMPUTING, V151, P645, DOI 10.1016/j.neucom.2014.05.089
   Cui J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107242
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Garg A, 2023, VISUAL COMPUT, V39, P2683, DOI 10.1007/s00371-022-02486-2
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P12883, DOI 10.1007/s11042-022-12003-1
   Garg A, 2020, IET IMAGE PROCESS, V14, P2965, DOI 10.1049/iet-ipr.2019.1032
   Garg A, 2021, SIGNAL IMAGE VIDEO P, V15, P185, DOI 10.1007/s11760-020-01736-x
   Guo YC, 2018, J ELECTRON INF TECHN, V40, P331, DOI 10.11999/JEIT170501
   Guo Z, 2017, 2 INT C ART INT ENG, P651, DOI [10.12783/dtcse/aiea2017/14995, DOI 10.12783/DTCSE/AIEA2017/14995]
   Hashemzadeh M, 2019, SIGNAL PROCESS, V155, P233, DOI 10.1016/j.sigpro.2018.09.037
   Kajiura N, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1755, DOI 10.1145/3394171.3413857
   Kumar S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P675, DOI 10.1109/ICCCIS51004.2021.9397225
   Lin W., 2018, INT C SMART VEH TECH, V86, P282, DOI [10.1007/978-3-319-70730-3_34, DOI 10.1007/978-3-319-70730-3_34]
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Mei Y., 2021, P IEEE INT C MULTIME, P1
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Parsania Pankaj., 2015, International Journal of Innovative Research in Computer and Communication Engineering, 02, P7409, DOI DOI 10.15680/IJIRCCE.2014.0212024
   Patel D, 2019, PATTERN RECOGN LETT, V125, P179, DOI 10.1016/j.patrec.2019.04.013
   Patel D, 2019, NATL CONF COMMUN, DOI 10.1109/ncc.2019.8732245
   Patel D, 2019, IET IMAGE PROCESS, V13, P885, DOI 10.1049/iet-ipr.2018.5283
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Shilpa M, 2020, IET IMAGE PROCESS, V14, P2998, DOI 10.1049/iet-ipr.2020.0001
   Solanki P, 2017, ADV INTELL SYST, V459, P467, DOI 10.1007/978-981-10-2104-6_42
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Tang ZH, 2022, MULTIMED TOOLS APPL, V81, P1501, DOI 10.1007/s11042-021-11376-z
   Valdez-Balderas D, 2021, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP42928.2021.9506584
   Wan-Duo Ma, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P498, DOI 10.1109/ISPACS.2012.6473541
   Wang S, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1609, DOI 10.1109/ITOEC49072.2020.9141774
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wang Y., 2008, Nature Precedings, V3, P1, DOI [10.1038/npre.2008.1824.1, DOI 10.1038/NPRE.2008.1824.1]
   Wei D., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508216
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang DY, 2017, J VIS COMMUN IMAGE R, V48, P281, DOI 10.1016/j.jvcir.2017.07.006
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhang Q, 2018, LECT NOTES COMPUT SC, V10736, P306, DOI 10.1007/978-3-319-77383-4_30
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P8067, DOI 10.1007/s11042-016-3318-1
   Zhongyan Qiu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P428, DOI 10.1109/ICIG.2013.92
   Zhou B, 2016, J VIS COMMUN IMAGE R, V41, P21, DOI 10.1016/j.jvcir.2016.09.002
   Zhou Y, 2021, IEEE T CIRC SYST VID, V31, P126, DOI 10.1109/TCSVT.2020.2977943
NR 50
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23207
EP 23250
DI 10.1007/s11042-022-14157-4
EA NOV 2022
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884893500002
DA 2024-07-18
ER

PT J
AU Bathula, A
   Muhuri, S
   Gupta, SK
   Merugu, S
AF Bathula, Archana
   Muhuri, Samya
   Gupta, Suneet Kr.
   Merugu, Suresh
TI Secure certificate sharing based on Blockchain framework for online
   education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Security; Digital Signature; Education system
ID CHALLENGES
AB In recent times, technology development has greatly influenced the model of Blockchain for communication due to extensive digitalization worldwide. Moreover, blockchain technology plays an essential part in the role of an educational system for sharing important data between students and teachers. However, the security hazard is the main problem while transferring the data because the malicious attacker may be able to hack the essential data in communication. A novel Signature-based Rivest Shamir Framework (SbRSF) is proposed to overcome such issues for privacy limit maintenance and security action improvement. Also, the harmful attack in data transmission is estimated by this projected approach. The implementation of this research has been done on the python platform. Hence, the proposed model has gained 98.03% throughput, encryption, and decryption time of 5 ms and reduced the error rate to 0.2%. Moreover, the achieved results are compared with the conventional methods, such as the Elliptic curve model, sensitivity-based elliptic crypto scheme, and secure record sharing, to validate the significance of the projected approach in blockchain development.
C1 [Bathula, Archana] CMR Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad 501401, Telangana, India.
   [Bathula, Archana] Bennett Univ, Greater Noida 201310, Uttar Pradesh, India.
   [Muhuri, Samya] Bennett Univ, Dept Comp Sci Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Gupta, Suneet Kr.] Bennett Univ, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Merugu, Suresh] CMR Coll Engn & Technol, R&D, Hyderabad 501401, Telangana, India.
RP Bathula, A (corresponding author), CMR Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad 501401, Telangana, India.; Bathula, A (corresponding author), Bennett Univ, Greater Noida 201310, Uttar Pradesh, India.
EM archanabathulaab@gmail.com
RI Gupta, Dr. SUneet/ABG-7279-2022
OI Gupta, Dr. SUneet/0000-0002-0757-1290; Merugu,
   Suresh/0000-0002-0574-1065
CR Ali O, 2021, IEEE ACCESS, V9, P12730, DOI 10.1109/ACCESS.2021.3050241
   Berdik D, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102397
   Cao B, 2020, IEEE NETWORK, V34, P78, DOI 10.1109/MNET.011.1900536
   Chen G., 2018, SMART LEARN ENVIRON, V5, P1, DOI [10.1186/s40561-017-0050-x, DOI 10.1186/S40561-017-0050-X]
   Chi JC, 2020, J NETW COMPUT APPL, V167, DOI 10.1016/j.jnca.2020.102710
   de Lima FS, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/1574749
   Deepa N, 2022, FUTURE GENER COMP SY, V131, P209, DOI 10.1016/j.future.2022.01.017
   Gohwong, 2018, ASIAN ADM MANAGEMENT, V1, P1
   Guo JQ, 2020, MULTIMED TOOLS APPL, V79, P9735, DOI 10.1007/s11042-019-08059-1
   Harthy K.A., 2019, 2019 4 MEC INT C, P1
   Jackson NC, 2019, BUS HORIZONS, V62, P761, DOI 10.1016/j.bushor.2019.08.002
   Karthik MG., 2021, Int J Intell Eng Syst, V14, P113
   Khan RA, 2021, MULTIMED TOOLS APPL, V80, P7039, DOI 10.1007/s11042-020-10061-x
   Li HZ, 2019, IEEE ACCESS, V7, P179273, DOI 10.1109/ACCESS.2019.2956157
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Lizcano D, 2020, J COMPUT HIGH EDUC, V32, DOI 10.1007/s12528-019-09209-y
   Lu XH, 2021, MULTIMED TOOLS APPL, V80, P31887, DOI 10.1007/s11042-021-11183-6
   Mishra RA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102512
   Mustari N., 2021, ASIAN J POLIT SCI, V5, P1, DOI [10.2139/ssrn.4027326, DOI 10.2139/SSRN.4027326]
   Nanayakkara S, 2021, J IND INF INTEGR, V23, DOI 10.1016/j.jii.2021.100215
   Pourvahab M, 2019, IEEE ACCESS, V7, P153349, DOI 10.1109/ACCESS.2019.2946978
   Singh S, 2021, IEEE ACCESS, V9, P13938, DOI 10.1109/ACCESS.2021.3051602
   Sousa MJ, 2019, FUTURE GENER COMP SY, V91, P327, DOI 10.1016/j.future.2018.08.048
   Upadhyay A, 2021, J CLEAN PROD, V293, DOI 10.1016/j.jclepro.2021.126130
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Vidal FR, 2019, INT CONF CYBER DIST, P28, DOI 10.1109/CyberC.2019.00015
   Whaiduzzaman M, 2021, IEEE ACCESS, V9, P106655, DOI 10.1109/ACCESS.2021.3100072
   Yu KP, 2021, IEEE T IND INFORM, V17, P7669, DOI 10.1109/TII.2021.3049141
   Yun J, 2021, IEEE INTERNET THINGS, V8, P708, DOI 10.1109/JIOT.2020.3006896
NR 29
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16479
EP 16500
DI 10.1007/s11042-022-14126-x
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000882352400002
DA 2024-07-18
ER

PT J
AU Grewal, R
   Kasana, SS
   Kasana, G
AF Grewal, Reaya
   Kasana, Singara Singh
   Kasana, Geeta
TI Hyperspectral image segmentation: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images; Segmentation; Thresholding; Clustering;
   Superpixels; Edge detection; Region growing and merging; Watershed;
   Classification; Deep learning
ID MORPHOLOGICAL PROFILES; FEATURE-EXTRACTION; CLASSIFICATION; NETWORKS;
   REDUCTION; APPLE
AB Hyperspectral Images, which are high-dimensional in nature and capture bands over hundreds of wavelengths of the electromagnetic spectrum. These images have piqued researchers' curiosity in the last two decades. The purpose of this paper is to investigate how researchers segmented and classified Hyperspectral Images with unbalanced data and few labelled training examples. For the sake of comprehension, the background of Hyperspectral Images and segmentation techniques is briefly discussed at first. The study is organised around different Hyperspectral Image processing techniques such as thresholding, clustering, watershed, deep learning, and other methods. The recent trends and developments in HSI segmentation have been reviewed and compiled using benchmark datasets such as Indian Pines, Salinas Valley, Pavia University, and others. Finally, it is intended that the readers will gain a thorough understanding of existing segmentation techniques, their performance, and fresh research areas for HSI that need to be studied or explored.
C1 [Grewal, Reaya; Kasana, Singara Singh; Kasana, Geeta] Thapar Inst Engn & Technol Patiala, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kasana, SS (corresponding author), Thapar Inst Engn & Technol Patiala, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rgrewal_phd19@thapar.edu; singara@thapar.edu; gkasana@thapar.edu
CR Akbari D, 2020, CAN J REMOTE SENS, V46, P146, DOI 10.1080/07038992.2020.1760714
   Akbarimehr D, 2020, ARAB J GEOSCI, V13, DOI 10.1007/s12517-020-06228-3
   Angulo J, 2009, INT GEOSCI REMOTE SE, P1395, DOI 10.1109/IGARSS.2009.5418095
   Appice A, 2019, ISPRS J PHOTOGRAMM, V147, P215, DOI 10.1016/j.isprsjprs.2018.11.023
   Beirami BA, 2020, IEEE GEOSCI REMOTE S, V17, P1953, DOI 10.1109/LGRS.2019.2958833
   Azimpour P, 2020, INT J REMOTE SENS, V41, P6117, DOI 10.1080/01431161.2020.1736728
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Cao FL, 2020, NEUROCOMPUTING, V384, P170, DOI 10.1016/j.neucom.2019.11.092
   Cao XH, 2020, INT J REMOTE SENS, V41, P4528, DOI 10.1080/01431161.2020.1723172
   Cao XH, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105630
   Cariou C, 2020, INT CONF ACOUST SPEE, P4127, DOI [10.1109/ICASSP40776.2020.9053489, 10.1109/icassp40776.2020.9053489]
   Castaings T, 2010, INT J REMOTE SENS, V31, P5921, DOI 10.1080/01431161.2010.512313
   Challa A, 2021, Arxiv, DOI arXiv:2103.09384
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chauhan NS, 2019, INTRO IMAGE SEGMENTA
   Che WK, 2018, COMPUT ELECTRON AGR, V146, P12, DOI 10.1016/j.compag.2018.01.013
   Chen CW, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104543
   Chen CC, 2018, ENG APPL ARTIF INTEL, V68, P165, DOI 10.1016/j.engappai.2017.10.015
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Chen SY, 2018, COMPUT GEOSCI-UK, V112, P38, DOI 10.1016/j.cageo.2017.12.003
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Chu X, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103242
   Cui Binge, 2016, 2016 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P101, DOI 10.1109/ICITBS.2016.14
   Cui BG, 2017, INFRARED PHYS TECHN, V81, P79, DOI 10.1016/j.infrared.2016.12.010
   Das A, 2020, IEEE J-STARS, V13, P1374, DOI 10.1109/JSTARS.2020.2981164
   Dutta Tulika, 2020, Intelligence Enabled Research. DoSIER 2019. Advances in Intelligent Systems and Computing (AISC 1109), P21, DOI 10.1007/978-981-15-2021-1_4
   Fei BW, 2020, DATA HANDL SCI TECHN, V32, P523, DOI 10.1016/B978-0-444-63977-6.00021-3
   Gao YN, 2021, IEEE GEOSCI REMOTE S, V18, P1269, DOI 10.1109/LGRS.2020.2994629
   Gao ZM, 2020, ARTIF INTELL AGR, V4, P31, DOI 10.1016/j.aiia.2020.04.003
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2565, DOI 10.1109/TGRS.2013.2263282
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Glomb P, 2018, FORENSIC SCI INT, V290, P227, DOI 10.1016/j.forsciint.2018.06.040
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Gu YF, 2016, NEUROCOMPUTING, V173, P1630, DOI 10.1016/j.neucom.2015.09.035
   Guo YH, 2018, PROCEDIA COMPUT SCI, V129, P159, DOI 10.1016/j.procs.2018.03.066
   Hang RL, 2019, IEEE T GEOSCI REMOTE, V57, P5384, DOI 10.1109/TGRS.2019.2899129
   Hu LS, 2018, PROCEDIA COMPUT SCI, V129, P93, DOI 10.1016/j.procs.2018.03.054
   Ismail M, 2020, ALGORITHMS, V13, DOI 10.3390/a13120330
   Ji YM, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103054
   Ji YM, 2019, INFRARED PHYS TECHN, V99, P71, DOI 10.1016/j.infrared.2019.04.007
   Jiao L, 2020, Brain and nature-inspired learning, computation and recognition
   Kang XD, 2020, INFORM FUSION, V57, P130, DOI 10.1016/j.inffus.2019.12.003
   Kulkarni SA, 2014, MRI BRAIN IMAGE SEGM
   Kumar B, 2017, INT J REMOTE SENS, V38, P5830, DOI 10.1080/01431161.2017.1348636
   Li JB, 2019, POSTHARVEST BIOL TEC, V158, DOI 10.1016/j.postharvbio.2019.110986
   Li JB, 2019, POSTHARVEST BIOL TEC, V149, P235, DOI 10.1016/j.postharvbio.2018.12.007
   Li JB, 2018, POSTHARVEST BIOL TEC, V135, P104, DOI 10.1016/j.postharvbio.2017.09.007
   Li X., 2017, HYPERSPECTRAL IMAGIN, P27, DOI DOI 10.5772/INTECHOPEN.72250
   Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019
   Lima C, 2018, 2018 SBFOTON INTERNATIONAL OPTICS AND PHOTONICS CONFERENCE (SBFOTON IOPC)
   Lin LL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041261
   Liu YZ, 2015, INT J REMOTE SENS, V36, P3459, DOI 10.1080/01431161.2015.1055607
   Liu ZW, 2020, LWT-FOOD SCI TECHNOL, V132, DOI 10.1016/j.lwt.2020.109815
   Lu JR, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102890
   Lu QK, 2020, IEEE J-STARS, V13, P3291, DOI 10.1109/JSTARS.2020.3003053
   Lv ZY, 2014, IEEE J-STARS, V7, P4644, DOI 10.1109/JSTARS.2014.2328618
   Mehta A, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.015028
   Mehta A, 2016, REMOTE SENS LETT, V7, P721, DOI 10.1080/2150704X.2016.1182661
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Myasnikov EV, 2017, COMPUT OPT, V41, P564, DOI 10.18287/2412-6179-2017-41-4-564-572
   Nalepa J, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102994
   Noviyanto A, 2019, COMPUT ELECTRON AGR, V159, P129, DOI 10.1016/j.compag.2019.02.006
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Peter Protzel AL, 2015, SUPERPIXELS THEIR AP
   Pisani RJ, 2014, IEEE T GEOSCI REMOTE, V52, P6075, DOI 10.1109/TGRS.2013.2294762
   Qiao XJ, 2017, FOOD CHEM, V220, P393, DOI 10.1016/j.foodchem.2016.09.119
   Quesada-Barriuso P, 2021, J SUPERCOMPUT, V77, P10040, DOI 10.1007/s11227-021-03666-y
   Schonberger J.NI.FB.JD.WN.YE.GT.Y, 2014, IMAGE MANIPULATION P
   Song J, 2019, INFRARED PHYS TECHN, V96, P267, DOI 10.1016/j.infrared.2018.12.001
   Stefan van der W, 2014, IMAGE MANIPULATION P
   Sudakov I, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101072
   Tarabalka Y, 2010, PATTERN RECOGN, V43, P2367, DOI 10.1016/j.patcog.2010.01.016
   Tarabalka Y, 2012, INT GEOSCI REMOTE SE, P1409, DOI 10.1109/IGARSS.2012.6351272
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Tian X, 2020, POSTHARVEST BIOL TEC, V161, DOI 10.1016/j.postharvbio.2019.111071
   Tian X, 2019, BIOSYST ENG, V183, P110, DOI 10.1016/j.biosystemseng.2019.04.012
   Torres I, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105070
   Torti E, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110283
   Tu B, 2018, J VIS COMMUN IMAGE R, V56, P160, DOI 10.1016/j.jvcir.2018.09.010
   Vaddi R, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103296
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Wan XQ, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103055
   Wang H, 2020, MATH BIOSCI ENG, V17, P5099, DOI 10.3934/mbe.2020275
   Wang Y., 2018, Grain Oil, Sci. Technol., V1, P40, DOI [10.3724/sp.j.1447.gost.2018.18025, DOI 10.3724/SP.J.1447.GOST.2018.18025, 10.3724/SP.J.1447.GOST.2018.18025]
   Wang Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010120
   Wang YJ, 2020, INFRARED PHYS TECHN, V108, DOI 10.1016/j.infrared.2020.103365
   Wu YH, 2018, OPTIK, V172, P612, DOI 10.1016/j.ijleo.2018.07.058
   Xia JS, 2016, IEEE T GEOSCI REMOTE, V54, P4971, DOI 10.1109/TGRS.2016.2553842
   Ye DD, 2018, CHEMOMETR INTELL LAB, V177, P129, DOI 10.1016/j.chemolab.2018.04.002
   Youn S, 2013, INT C PAR DISTRIB SY, P716, DOI 10.1109/ICPADS.2013.127
   Yu HY, 2017, IEEE GEOSCI REMOTE S, V14, P2142, DOI 10.1109/LGRS.2017.2755061
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zeng S, 2019, NEUROCOMPUTING, V335, P59, DOI 10.1016/j.neucom.2019.01.042
   Zhang JX, 2021, TEXT RES J, V91, P729, DOI 10.1177/0040517520957401
   Zhang L, 2020, SPECTROCHIM ACTA A, V229, DOI 10.1016/j.saa.2019.117973
   Zhang QS, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P16, DOI 10.1109/GSIS.2013.6714730
   Zhang Y, 2019, REMOTE SENS LETT, V10, P244, DOI 10.1080/2150704X.2018.1524993
   Zhang YS, 2021, WATER RES, V204, DOI 10.1016/j.watres.2021.117618
   Zhang YX, 2020, IEEE GEOSCI REMOTE S, V17, P1440, DOI 10.1109/LGRS.2019.2945546
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
   Zhou S, 2020, INFRARED PHYS TECHN, V108, DOI 10.1016/j.infrared.2020.103363
NR 105
TC 7
Z9 7
U1 5
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20819
EP 20872
DI 10.1007/s11042-022-13959-w
EA OCT 2022
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000875800000001
DA 2024-07-18
ER

PT J
AU Badr, S
   El Mahalawy, A
   Attiya, G
   Nasr, AA
AF Badr, Shaimaa
   El Mahalawy, Ahmed
   Attiya, Gamal
   Nasr, Aida A.
TI Task consolidation based power consumption minimization in cloud
   computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Power consumption; Scheduling; Task consolidation; Data
   centers; And CloudSim
AB Cloud Computing is playing a huge role in future technology. Further, with the explosive growth of the Internet and cloud computing, several service providers, such as Amazon, Microsoft, IBM, and Google, have expanded their data centers and rapidly deployed data centers in different places around the world to deliver various cloud computing services. However, several challenges are raised with the wide spread use of cloud environment such as power consumption, load balance, reliability, scalability, and security. This paper tackles the power consumption problem and presents an efficient algorithm, called Task Consolidation based Power Minimization (TCPM), to efficiently schedule tasks onto available resources of the cloud environment so as to minimize power consumption. In proposed TCPM algorithm, several benefits of the existing algorithms are enhanced and incorporated into the TCPM algorithm, where the best-fit procedure is used to achieve the best possible resource utilization and avoid wasting energy. The results of the proposed TCPM algorithm are compared with other recent algorithms such as FCFS, WWO, and MCT algorithms using the CloudSim toolkit.
C1 [Badr, Shaimaa] Egyptian Elect Transmiss Co, Middle Egypt Reg Control Ctr, El Minia, Egypt.
   [El Mahalawy, Ahmed; Attiya, Gamal] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Shibin Al Kawm, Egypt.
   [Nasr, Aida A.] Tanta Univ, Fac Comp & Informat, Informat Technol Dept, Tanta, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Tanta University
RP Badr, S (corresponding author), Egyptian Elect Transmiss Co, Middle Egypt Reg Control Ctr, El Minia, Egypt.
EM Princess.basant@gmail.com; Ahmed.elinahalawy@el-eng.menofia.edu.eg;
   Gamal.mahrous@el-eng.menofm.edu.eg; Dr.aida_nasr@ics.tanta.edu.eg
RI Nasr, Aida A./AAU-2643-2020
OI Nasr, Aida A./0000-0003-4996-5439
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abdelhafiz Afaf Abdelkader, 2018, J COMPUT, V13, P1309
   Aishwarya Anusha K, INT J ENG RES TECHNO, V9, P2278
   Amer DA, 2021, INT J COMPUT, V183, P65
   Amer DA, 2022, J SUPERCOMPUT, V78, P2793, DOI 10.1007/s11227-021-03977-0
   Arulkumar V, 2019, ARTICLE CONCURRENCY
   Badr S, ICEEM2021 2021 IEEE
   Bharathi A., 2014, INT J ENG SCI INNOV, V3, P200
   Elzeki Omar, 2012, Int. J. Soft Comput. Eng. (IJSCE), V2
   Gaede S, 2009, CISC VIS NETW IND GL
   Hsu CH, 2014, INFORM SCIENCES, V258, P452, DOI 10.1016/j.ins.2012.10.041
   Hussain M, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2021.100517
   Kaur A, 2013, INT J COMPUT APPL, V75, P17
   Khurma RA, 2018, J THEOR APPL INF TEC, V96
   Koot M, 2021, APPL ENERG, V291, DOI 10.1016/j.apenergy.2021.116798
   Lee YC, 2012, J SUPERCOMPUT, V60, P268, DOI 10.1007/s11227-010-0421-3
   Madni SHH, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176321
   Medara R, 2020, IEEE
   Mehdi N.A., 2011, Minimum completion time for power-aware scheduling in cloud computing, 2011 Developments in E-systems Engineering
   Mekala MS, 2023, DISTRIB PARALLEL DAT, V41, P157, DOI 10.1007/s10619-021-07348-9
   Mishra SK, 2020, IEEE ACCESS, V8, P178825, DOI 10.1109/ACCESS.2020.3026875
   Panda SK, 2019, CLUSTER COMPUT, V22, P509, DOI 10.1007/s10586-018-2858-8
   Panda SK, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P262, DOI 10.1109/PDGC.2014.7030753
   Panigrahi P., 2015, J INF PROCESS, V94, P34
   Reda NM, 2015, J ADV RES
   Singh P, 2020, J CRIT REV, V7
   Singhn P, 2014, INT J ENG TECHNOL IN, V3, P2319
   Siva M., 2016, INT J INTELL ENG SYS, V9, P31
   Taherian Dehkordi S., 2019, J ARTIFICIAL INTELIG, V7, P617, DOI [https://doi.org/10.22044/JADM.2018.6446.1758, DOI 10.22044/JADM.2018.6446.1758]
   Wu XL, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3498363
   Yan ZP, 2020, MULTIMED TOOLS APPL, V79, P32415, DOI 10.1007/s11042-020-09664-1
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
NR 31
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21385
EP 21413
DI 10.1007/s11042-022-14009-1
EA OCT 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000873458400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sowmyayani, S
   Rani, PAJ
AF Sowmyayani, S.
   Rani, P. Arockia Jansi
TI STHARNet: spatio-temporal human action recognition network in content
   based video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Spatial features; Temporal features; Keyframes; Deep learning
AB Most of the needed information is easily accessible from our fingertips using the internet. The search procedure via the internet is a tough task behind the scenes. Content-Based Video Retrieval (CBVR) is one such search procedure on the internet. Human action recognition is one of them in CBVR. Even though there is research in these areas, the challenges are also partially solved. This paper also addresses the issues in human action recognition by designing an architecture named the Spatio-Temporal Human Action Recognition Network (STHARNet). The proposed STHARNet system is integrated into the CBVR system. The performance of the proposed architecture is evaluated by testing on three publicly available datasets: UCF Sports, KTH, and HMDB51. The results of the proposed architecture are encouraging and better than other recent methods.
C1 [Sowmyayani, S.] St Marys Coll Autonomous, Dept Comp Sci, Thoothukudi, Tamil Nadu, India.
   [Rani, P. Arockia Jansi] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tinmelveli, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Sowmyayani, S (corresponding author), St Marys Coll Autonomous, Dept Comp Sci, Thoothukudi, Tamil Nadu, India.
EM sowmyayani@gmail.com; jansimsuniv@gmail.com
RI s, Sowmyayani/AAM-5159-2021
CR Abdelbaky A, 2021, VISUAL COMPUT, V37, P1821, DOI 10.1007/s00371-020-01940-3
   Abdelbaky A, 2020, NEURAL COMPUT APPL, V32, P12561, DOI 10.1007/s00521-020-04712-1
   [Anonymous], UCF SPORTS
   Chen HQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093094
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Jalal A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12239814
   Jaouedi N, 2020, J KING SAUD UNIV-COM, V32, P447, DOI 10.1016/j.jksuci.2019.09.004
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P35827, DOI 10.1007/s11042-020-09408-1
   Kiziltepe RS, 2023, NEURAL COMPUT APPL, V35, P24513, DOI 10.1007/s00521-021-06322-x
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar B, 2022, J IRAN CHEM SOC, V19, P4093, DOI 10.1007/s13738-022-02605-9
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Nadeem A, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111766
   Pinge Anuja, 2021, Computational Vision and Bio-Inspired Computing. ICCVBIC 2020. Advances in Intelligent Systems and Computing (AISC 1318), P483, DOI 10.1007/978-981-33-6862-0_39
   Prathiba T, 2021, J AMB INTEL HUM COMP, V12, P6215, DOI 10.1007/s12652-020-02190-w
   Saoudi E, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00479-x
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sowmyayani S, 2014, ICTACT J IMAGE VIDEO, V5
   Torpey D, 2020, Arxiv, DOI arXiv:2002.09423
   Vishwakarma DK, 2020, COGN SYST RES, V61, P1, DOI 10.1016/j.cogsys.2019.12.004
   Wang JZ, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102898
   Yi Y, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115640
   Yudistira N, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115731
   Zhao GP, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102488
NR 24
TC 3
Z9 3
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 14
PY 2022
DI 10.1007/s11042-022-14056-8
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5Q8FM
UT WOS:000874060400002
DA 2024-07-18
ER

PT J
AU Wu, P
   Hua, Z
   Li, JJ
AF Wu, Pan
   Hua, Zhen
   Li, Jinjiang
TI Multi-scale siamese networks for multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Multi-scale convolution; Siamese network
ID SPARSE REPRESENTATION; FEATURE-EXTRACTION; ALGEBRA
AB In this paper, we propose a multi-scale Siamese network for multi-focus image fusion. Many current image fusion methods are based on classifier and discriminators to segment the original image, determine whether there is a focus on it, and generate the fused image by post-processing the decision map. We input two complementary source images as two branches into the network, introduce multi-scale convolution module and pyramid attention to extract image information, the whole process of fusing image edge information of different scales, reduce the information loss that occurs in the fusion process, and can better deal with the problems of artifacts and small-scale visual blurring of the images obtained by existing fusion methods, and the fused images are more adapted to the human visual. The proposed method is quantitatively and qualitatively compared with other existing more advanced methods on three publicly available datasets to demonstrate the effectiveness and superiority of the performance of our proposed method.
C1 [Wu, Pan; Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai, Peoples R China.
   [Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Hua, Z (corresponding author), Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
EM huazhen@sdtbu.edu.cn; lijinjiang@gmail.com
RI Hua, Zhen/AGN-6068-2022
FU National Natural Science Foundation of China [61772319, 62002200,
   62176140, 12001327]; Shandong Natural Science Foundation of China
   [ZR2021QF134, ZR2021MF068]; Yantai science and technology innovation
   development plan [2022JCYJ031]
FX The authors acknowledge the National Natural Science Foundation of China
   (61772319, 62002200, 62176140 and 12001327), Shandong Natural Science
   Foundation of China (ZR2021QF134 and ZR2021MF068), and Yantai science
   and technology innovation development plan (2022JCYJ031).
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Bastanfard A, 2022, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-022-12584-X
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chen ZY, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1688, DOI 10.1109/IAEAC.2017.8054302
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jing Z, 2018, NONCOOPERATIVE TARGE, P251
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   MirMashhouri A, 2022, MULTIMED TOOLS APPL, V81, P18935, DOI 10.1007/s11042-022-11966-5
   Mustafa HT, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115864
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Raghavendra R, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P346, DOI 10.1109/IIH-MSP.2013.93
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu S., 2020, arXiv
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   You C., 2014, J COMPUT INF SYST, V10, P1651
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang H., 2021, arXiv
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang XC, 2022, IEEE T PATTERN ANAL, V44, P4819, DOI 10.1109/TPAMI.2021.3078906
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFRARED PHYS TECHN, V83, P227, DOI 10.1016/j.infrared.2017.05.007
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 48
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15651
EP 15672
DI 10.1007/s11042-022-13949-y
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000874060400001
DA 2024-07-18
ER

PT J
AU Mohammedi, M
   Omar, M
   Bouabdallah, A
AF Mohammedi, Mohamed
   Omar, Mawloud
   Bouabdallah, Abdelmadjid
TI Methods for detecting and removing ocular artifacts from EEG signals in
   drowsy driving warning systems: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic accidents; Drowsiness detection; EEG signals; Ocular artifacts;
   Internet of things; Drowsy driving warning
ID EMPIRICAL MODE DECOMPOSITION; FATIGUE DETECTION; EOG ARTIFACTS;
   ELECTROENCEPHALOGRAM; DROWSINESS; ENTROPY; WAVELET; CLASSIFICATION;
   INTERNET; SPECTRUM
AB In the last decade, drowsiness while driving has been identified as a major factor behind a large number of fatal traffic accidents around the world. This highly prevalent problem has caused significant loss of life, injuries, property damage, and economic losses in many parts of the world. For that, great efforts have been made to introduce driver's drowsiness detection systems for reducing and preventing traffic accidents in many cities in the world. Among the existing driver assistance systems, the one based on the EEG signal measurement is the most popular and relevant system. Nevertheless, EEG signals can be easily altered by many kinds of artifacts arising from sources other than the brain, such as muscle (EMG), cardiac (ECG), and ocular (EOG) activities. In the midst of them, ocular artifacts are one of the most important noise sources among the others. In this paper, we give an in-depth review on techniques used to detect and eliminate ocular artifacts from EEG recordings for all potential EEG-based drowsiness warning applications. Initially, we present an overview of some significant artifact types that can be observed in EEG signals and we study their impact on drowsiness detection applications. Subsequently, we review many approaches to artifact rejection, categorize and compare them based on their ability to eliminate EOG artifacts. Finally, we provide an innovative idea based on the IoT Cloud, which might be the succeeding step for safe driving, for alerting the driver when is getting drowsy.
C1 [Mohammedi, Mohamed] Univ Bejaia, Fac Sci Exactes, Lab Informat Med, Bejaia 06000, Algeria.
   [Omar, Mawloud] Univ Bretagne Sud, IRISA, Vannes, France.
   [Bouabdallah, Abdelmadjid] Sorbonne Univ, Univ Technol Compiegne, CNRS, Heudiasyc UMR 7253, CS 60 319, F-60203 Compiegne, France.
C3 Universite de Bejaia; Sorbonne Universite; Centre National de la
   Recherche Scientifique (CNRS); Universite de Technologie de Compiegne
RP Mohammedi, M (corresponding author), Univ Bejaia, Fac Sci Exactes, Lab Informat Med, Bejaia 06000, Algeria.
EM mohamed.mohammedi@univ-bejaia.dz
OI Mohammedi, Mohamed/0000-0002-4732-6345
FU French Government, through the program "Investments for the future"
   [ANR-11-IDEX-0004-02]; General Directorate for Scientific Research and
   Technological Development, Ministry of Higher Education and Scientific
   Research (DGRSDT), Algeria
FX This work was carried out in the framework of the research activities of
   the LIMED (laboratory of Medical Computing) laboratory, which is
   affiliated to the faculty of exact sciences of the university of Bejaia
   and the IRISA laboratory, university of South Brittany, France. It was
   done in collaboration with the Labex MS2T, which was funded by the
   French Government, through the program "Investments for the future"
   managed by the National Agency for Research (Reference
   ANR-11-IDEX-0004-02). Finally, this work has been sponsored by the
   General Directorate for Scientific Research and Technological
   Development, Ministry of Higher Education and Scientific Research
   (DGRSDT), Algeria.
CR Akerstedt T, 2013, SOMNOLENCE VOLANT LI
   Amin J, 2013, IEEE ENG MED BIO, P4977, DOI 10.1109/EMBC.2013.6610665
   Aniket M, 2016, IFMBE PROC, V56, P62, DOI 10.1007/978-981-10-0266-3_13
   [Anonymous], STAT RELATED DROWSY
   Bansal D., 2019, EEG BASED BRAIN COMP
   Barrachina J, 2012, J NETW COMPUT APPL, V35, P1891, DOI 10.1016/j.jnca.2012.07.013
   Behera S, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P500, DOI 10.1109/ICDSBA.2018.00099
   Botta A, 2016, FUTURE GENER COMP SY, V56, P684, DOI 10.1016/j.future.2015.09.021
   Brion A, 2011, Medecine du sommeil, V8, P145
   Chacon-Murguia MI, 2015, IEEE CONSUM ELECTR M, V4, P107, DOI 10.1109/MCE.2015.2463373
   Chang TH, 2008, IEEE T INTELL TRANSP, V9, P501, DOI 10.1109/TITS.2008.928243
   Çinar S, 2017, EXPERT SYST APPL, V68, P36, DOI 10.1016/j.eswa.2016.10.009
   Colic A., 2014, Driver Drowsiness Detection: Systems and Solutions, DOI [10.1007/978-3-319-11535-1, DOI 10.1007/978-3-319-11535-1]
   Cuomo S, 2018, J NETW COMPUT APPL, V115, P48, DOI 10.1016/j.jnca.2018.04.016
   Deepthi AS., 2014, INT J COMPUT SCI TEC, V5, P124
   Dharmadhikari O., 2015, Int. J. Comput. Appl., V132, P16, DOI [10.5120/ijca2015907349, DOI 10.5120/IJCA2015907349]
   Di Flumeri G, 2016, IEEE ENG MED BIO, P3187, DOI 10.1109/EMBC.2016.7591406
   Electromyograms, 2003, MILLER KEANE ENCY DI
   Faber J., 2004, Neural Network World, V14, P285
   Fatourechi M, 2007, CLIN NEUROPHYSIOL, V118, P480, DOI 10.1016/j.clinph.2006.10.019
   Correa AG, 2014, MED ENG PHYS, V36, P244, DOI 10.1016/j.medengphy.2013.07.011
   GOTMAN J, 1973, ELECTROEN CLIN NEURO, V35, P225, DOI 10.1016/0013-4694(73)90233-2
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Guerrero-Mosquera C, 2012, IET SIGNAL PROCESS, V6, P99, DOI 10.1049/iet-spr.2010.0135
   He P, 2004, MED BIOL ENG COMPUT, V42, P407, DOI 10.1007/BF02344717
   Hu SY, 2013, IET INTELL TRANSP SY, V7, P105, DOI 10.1049/iet-its.2012.0045
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Inuso G, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P196, DOI 10.1109/icia.2007.4295725
   Islam MK, 2016, NEUROPHYSIOL CLIN, V46, P287, DOI 10.1016/j.neucli.2016.07.002
   Jafarifarmand A, 2013, NEUROCOMPUTING, V103, P222, DOI 10.1016/j.neucom.2012.09.024
   Jiang X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19050987
   Jirayucharoensak S, 2013, 2013 INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC), P136, DOI 10.1109/ICSEC.2013.6694767
   Kaplan S, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2462084
   Kavitha PT, 2007, 2007 6TH INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS & SIGNAL PROCESSING, VOLS 1-4, P1653
   Khatun S, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2544298
   Khatwani P., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1091
   Knipling RR, 1995, P ANN C ASS, P451
   Kozielski S, 2016, P 12 TH INT C
   Kumar Pradeep, 2008, International Journal of Food Safety, Nutrition and Public Health, V1, P189, DOI 10.1504/IJFSNPH.2008.023019
   Kumar P, 2017, J NETW COMPUT APPL, V89, P62, DOI 10.1016/j.jnca.2017.02.011
   Lakshmi M.R., 2014, Int. J. Adv. Res. Comput. Sci. Softw. Eng., V4, P84
   Lee KJ, 2015, IEEE SYS MAN CYBERN, P2384, DOI 10.1109/SMC.2015.417
   Lin CT, 2005, IEEE T CIRCUITS-I, V52, P2726, DOI 10.1109/TCSI.2005.857555
   Mahajan R, 2015, IEEE J BIOMED HEALTH, V19, P158, DOI 10.1109/JBHI.2014.2333010
   Majmudar CA, 2016, ACM T EMBED COMPUT S, V16, DOI 10.1145/2983629
   Mannan MMN, 2018, IEEE ACCESS, V6, P30630, DOI 10.1109/ACCESS.2018.2842082
   Mantri S., 2013, INT J ADV RES COMPUT, V1, P83
   Morales JM, 2015, LECT NOTES COMPUT SC, V9094, P89, DOI 10.1007/978-3-319-19258-1_8
   Minhas AA, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01554-1
   Mohammedi M, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMMUNICATIONS IN NETWORK TECHNOLOGIES (SACONET), P188, DOI 10.1109/SaCoNeT.2018.8585680
   NORTH ALVIN W., 1965, INVEST OPHTHALMOL, V4, P343
   Ocvirk T, 2020, THESIS U JYVASKYLA
   Picot Antoine, 2009, Biomedical Engineering, P145
   Qi GQ, 2021, ACCIDENT ANAL PREV, V159, DOI 10.1016/j.aap.2021.106223
   Rashed-Al-Mahfuz M, 2013, NEURAL REGEN RES, V8, P1500, DOI 10.3969/j.issn.1673-5374.2013.16.007
   Rau P. S., 2005, PROC 19 INT C ENHANC, P1
   Razzaque MA, 2016, IEEE INTERNET THINGS, V3, P70, DOI 10.1109/JIOT.2015.2498900
   Reaz MBI, 2006, BIOL PROCED ONLINE, V8, P11, DOI [10.1251/bpo124, 10.1251/bpo115]
   Roy V., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P425, DOI DOI 10.14257/IJMUE.2015.10.3.39
   Sandberg D, 2011, IEEE T INTELL TRANSP, V12, P97, DOI 10.1109/TITS.2010.2077281
   Sarhan A, 2019, CLOUD BASED IOT PLAT, P116
   Seal A, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8303465
   Sehgal T., 2016, INTERJ ADV RES COMPU, V5, P186
   Shwetha T., 2017, INT J ADV RES ELECT, V6, P1093
   Singh D, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P287, DOI 10.1109/WF-IoT.2014.6803174
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Sundararajan A, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P139, DOI 10.1109/ITNG.2015.27
   Sweeney KT, 2013, IEEE T BIO-MED ENG, V60, P97, DOI 10.1109/TBME.2012.2225427
   Teplan M., 2002, Measurement science review, V2, DOI DOI 10.1021/PR070350L
   The royal society for the prevention of accidents, ROYAL SOC PREVENTION, P1
   Tien Pham, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8227, P562, DOI 10.1007/978-3-642-42042-9_70
   Tiganj Z, 2010, IFMBE PROC, V28, P175
   Tijerina L, 1999, 808 DOT HS TBD NAT H
   Tuncer T, 2021, COGN NEURODYNAMICS, V15, P223, DOI 10.1007/s11571-020-09601-w
   Turan G., 2013, INTERJ ADV RES COMPU, V2, P2981
   UENO H, 1994, 1994 VEHICLE NAVIGATION & INFORMATION SYSTEMS CONFERENCE PROCEEDINGS, pA15
   Ullah A., 2015, INTERJ SCI ENG RES, V6, P125
   Upadhyay R, 2015, ANNU IEEE IND CONF
   Vanlaar W, 2007, FATIGUED DROWSY DRIV, P1
   VERLEGER R, 1982, PSYCHOPHYSIOLOGY, V19, P472, DOI 10.1111/j.1469-8986.1982.tb02509.x
   Vigon L, 2000, IEE P-SCI MEAS TECH, V147, P219, DOI 10.1049/ip-smt:20000475
   Wang HT, 2019, IEEE ACCESS, V7, P61975, DOI 10.1109/ACCESS.2019.2915533
   Wang HT, 2018, COGN NEURODYNAMICS, V12, P365, DOI 10.1007/s11571-018-9481-5
   Wang Q, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P8587
   WOESTENBURG JC, 1983, BIOL PSYCHOL, V16, P127, DOI 10.1016/0301-0511(83)90059-5
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Zikov T, 2002, P ANN INT IEEE EMBS, P98, DOI 10.1109/IEMBS.2002.1134407
   Zou SL, 2020, J NEUROSCI METH, V341, DOI 10.1016/j.jneumeth.2020.108691
NR 88
TC 0
Z9 0
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17687
EP 17714
DI 10.1007/s11042-022-13822-y
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000865154500004
DA 2024-07-18
ER

PT J
AU Ehsan, TZ
   Nahvi, M
   Mohtavipour, SM
AF Ehsan, Tahereh Zarrat
   Nahvi, Manoochehr
   Mohtavipour, Seyed Mehdi
TI Learning deep latent space for unsupervised violence detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Human behavior analysis; Human action recognition;
   Violence detection; Security and surveillance
ID ALGORITHM; FEATURES; MACHINE
AB Numerous violent actions occur in the world every day, affecting victims mentally and physically. To reduce violence rates in society, an automatic system may be required to analyze human activities quickly and detect violent actions accurately. Violence detection is a complex machine vision problem involving insufficient violent datasets and wide variation in activities and environments. In this paper, an unsupervised framework is presented to discriminate between normal and violent actions overcoming these challenges. This is accomplished by analyzing the latent space of a double-stream convolutional AutoEncoder (AE). In the proposed framework, the input samples are processed to extract discriminative spatial and temporal information. A human detection approach is applied in the spatial stream to remove background environment and other noisy information from video segments. Since motion patterns in violent actions are entirely different from normal actions, movement information is processed with a novel Jerk feature in the temporal stream. This feature describes the long-term motion acceleration and is composed of 7 consecutive frames. Moreover, the classification stage is carried out with a one-class classifier using the latent space of AEs to identify the outliers as violent samples. Extensive experiments on Hockey and Movies datasets showed that the proposed framework surpassed the previous works in terms of accuracy and generality.
C1 [Ehsan, Tahereh Zarrat; Nahvi, Manoochehr] Univ Guilan, Dept Elect Engn, Rasht, Iran.
   [Mohtavipour, Seyed Mehdi] Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
C3 University of Guilan; Iran University Science & Technology
RP Nahvi, M (corresponding author), Univ Guilan, Dept Elect Engn, Rasht, Iran.
EM tahere_zarrat@msc.guilan.ac.ir; nahvi@guilan.ac.ir;
   mehdi_mohtavipour@elec.iust.ac.ir
RI Mohtavipour, Seyed Mehdi/AAV-3668-2020
OI Mohtavipour, Seyed Mehdi/0000-0003-2749-8980
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Anusha R, 2020, MULTIMED TOOLS APPL, V79, P8213, DOI 10.1007/s11042-019-08469-1
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Blumstein A, 2020, CRIME INEQUALITY STA, P103
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ehsan Tahereh Zarrat, 2020, 2020 11th International Conference on Information and Knowledge Technology (IKT), P88, DOI 10.1109/IKT51791.2020.9345617
   Ehsan T.Z., 2022, P IEEE INT C MACHINE, P1
   Ehsan TZ, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P153, DOI 10.1109/ICCKE.2018.8566460
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kang MS, 2021, IEEE ACCESS, V9, P76270, DOI 10.1109/ACCESS.2021.3083273
   Khan Shehroz S., 2018, IEEE Transactions on Knowledge and Data Engineering, V30, P1796, DOI 10.1109/TKDE.2018.2806975
   Kingma D. P., 2014, arXiv
   Mao D., 2021, Human Activity Recognition Challenge, P15
   Materzynska J, 2020, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR42600.2020.00113
   Mohamed MA, 2012, LECT NOTES COMPUT SC, V7431, P482, DOI 10.1007/978-3-642-33179-4_46
   Mohtavipour SM, 2022, VISUAL COMPUT, V38, P2057, DOI 10.1007/s00371-021-02266-4
   Moon S, 2012, IEEE T NEUR NET LEAR, V23, P749, DOI 10.1109/TNNLS.2012.2189581
   Naik AJ, 2021, MULTIMED TOOLS APPL, V80, P18365, DOI 10.1007/s11042-021-10682-w
   Peixoto BM, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103174
   Pock T, 2007, LECT NOTES COMPUT SC, V4792, P511
   Saad Khaled, 2022, 2022 2nd International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P21, DOI 10.1109/MIUCC55081.2022.9781703
   Senst T, 2017, IEEE T INF FOREN SEC, V12, P2945, DOI 10.1109/TIFS.2017.2725820
   Gracia IS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120448
   Shafiee M. J., 2017, arXiv
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Soliman Mohamed Mostafa, 2019, 2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS), P80, DOI 10.1109/ICICIS46948.2019.9014714
   Ullah FUM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112472
   Wang P, 2021, PATTERN RECOGN LETT, V142, P20, DOI 10.1016/j.patrec.2020.11.018
   Wu P., 2020, COMPUTER VISION ECCV, P322
   Yu J, 2019, MULTIMED TOOLS APPL, V78, P8497, DOI 10.1007/s11042-018-6923-3
   Yukun Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P74, DOI 10.1007/978-3-030-58548-8_5
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhou TF, 2021, PROC CVPR IEEE, P1622, DOI 10.1109/CVPR46437.2021.00167
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 43
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12493
EP 12512
DI 10.1007/s11042-022-13827-7
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000007
DA 2024-07-18
ER

PT J
AU Chen, HY
   Zhang, HQ
   Zhen, XJ
AF Chen, Haiyan
   Zhang, Huaqing
   Zhen, Xiajun
TI A hybrid active contour image segmentation model with robust to initial
   contour position
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Intensity inhomogeneity; Local energy term; Global
   energy term; Active contour model
ID LEVEL SET METHOD; DRIVEN; ENERGY
AB In the present study, a hybrid active contour image segmentation model was proposed, which combines the local and global information of an image. Said model can be used to prevent the problem that the evolution curve is easy to fall into local optimum when the active contour model uses the local information of the image to segment the image with intensity inhomogeneity. In the model, firstly, the local energy term is constructed by using the image intensity mean of the local region inside and outside the evolution curve to capture the intensity inhomogeneity of the image. Secondly, the global energy term is constructed by using the intensity mean inside and outside the evolution curve to drive the evolution curve to the target edge. Finally, to adaptively adjust the relationship between the local energy term and the global energy term, the weight coefficient is constructed by the gray level of the local and global regions of the image. As such, the proposed model can adaptively adjust the evolution of the curve with the change of the target region. Experimental results on natural images and brain tumor images show that compared with the traditional and several of the latest active contour models, the proposed model has higher segmentation accuracy and robustness to the initial contour.
C1 [Chen, Haiyan; Zhang, Huaqing; Zhen, Xiajun] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Chen, HY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM chenhaiyan@sina.com
RI Chen, Haiyan/HGB-6216-2022; qin, cheng/KHC-3344-2024; guo,
   ppdop/KAL-9865-2024; fang, yu/KCK-2014-2024
FU National Natural Science Foundation of China [62161019, 62061024]
FX This work was supported by the National Natural Science Foundation of
   China (nos. 62161019 and 62061024).
CR Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Ding KY, 2018, PATTERN RECOGN LETT, V104, P29, DOI 10.1016/j.patrec.2018.01.019
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Dong FF, 2013, IMAGE VISION COMPUT, V31, P809, DOI 10.1016/j.imavis.2013.08.003
   Fang JX, 2019, IEEE ACCESS, V7, P184518, DOI 10.1109/ACCESS.2019.2909981
   Huang GP, 2018, MAGN RESON IMAGING, V52, P33, DOI 10.1016/j.mri.2018.05.011
   [黄鹏 Huang Peng], 2020, [武汉大学学报. 理学版, Journal of Wuhan University. Natural Science Edition], V66, P519
   Khan AW, 2021, IEEE ACCESS, V9, P107309, DOI 10.1109/ACCESS.2021.3100287
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Li H, 2018, ADV ENG SOFTW, V126, P75, DOI 10.1016/j.advengsoft.2018.10.001
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   [李智 Li Zhi], 2020, [华南理工大学学报. 自然科学版, Journal of South China University of Technology. Natural Science Edition], V48, P102
   Liu HX, 2020, IEEE ACCESS, V8, P59412, DOI 10.1109/ACCESS.2020.2981596
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   [鲁圆圆 Lu Yuanyuan], 2020, [计算机工程与应用, Computer Engineering and Application], V56, P228
   Mao L, 2019, ACTA OPT SIN, V39, DOI 10.3788/AOS201939.1217001
   Peng YL, 2019, J COMPUT SCI-NETH, V33, P11, DOI 10.1016/j.jocs.2019.03.003
   Shan XY, 2020, IEEE ACCESS, V8, P43200, DOI 10.1109/ACCESS.2020.2975854
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Wang Nan, 2020, Computer Engineering and Applications, V56, P211
   Weng GR, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105882
   Yang XJ, 2020, IEEE ACCESS, V8, P6460, DOI 10.1109/ACCESS.2019.2963435
   Zhang Aihua, 2018, Journal of Huazhong University of Science and Technology (Natural Science Edition), V46, P63, DOI 10.13245/j.hust.180113
   Zhang Aihua, 2016, Journal of Huazhong University of Science and Technology (Natural Science Edition), V44, P75, DOI 10.13245/j.hust.160216
   [张桂梅 Zhang Guimei], 2017, [计算机研究与发展, Journal of Computer Research and Development], V54, P1045
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
   [张开华 ZHANG Kaihua], 2008, [光电工程, Opto-Electronic Engineering], V35, P112
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang XY, 2018, OPTIK, V168, P517, DOI 10.1016/j.ijleo.2018.04.046
NR 33
TC 2
Z9 2
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10813
EP 10832
DI 10.1007/s11042-022-13782-3
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854429500002
DA 2024-07-18
ER

PT J
AU Kalra, U
   Kumar, A
   Hazra, T
AF Kalra, Umang
   Kumar, Ashish
   Hazra, Tanmoy
TI Intelligent mobile vending services: location optimisation for food
   trucks using coalitional game theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combinatorial optimisation; Game theory; Food trucks; Multi-agent
   system; Metaheuristic algorithm
AB The food truck industry has seen substantial expansion in the past few years. Mobile service flexibility, low capital expenditure and overhead costs are some of the reasons for making it a popular venture choice to enter the hospitality industry. It is important for these mobile vendors to discover locations with high demand and purchase capacity, while facing low competition from competing eateries. A novel spatio-temporal multi-objective optimization approach, developed using a metaheuristic algorithm based on the principles of coalitional game theory, has been presented in this paper for allocating optimal retail locations in a spatio-temporal competitive multi-agent environment. Multi-agent competition has been modeled using a number of socio-economic parameters to better emulate the dynamic spatio-temporal behavior of urban crowds and buying power. The proposed algorithm has shown to solve the problem more effectively than existing combinatorial optimization algorithms. Moreover, the proposed approach shows how coalitional game theory can produce a set of Pareto optimal solutions for multi-objective optimization problems involving competitive multi-agent.
C1 [Kalra, Umang; Kumar, Ashish; Hazra, Tanmoy] Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune 411048, Maharashtra, India.
RP Hazra, T (corresponding author), Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune 411048, Maharashtra, India.
EM umangkalra10@gmail.com; ashishkr0401@gmail.com; tanmoyhazra316@gmail.com
CR Akbar T, 2017, RES PAPERECONOMICS G
   Alfiero S, 2017, BRIT FOOD J, V119, P2462, DOI [10.1108/bfj-03-2017-0179, 10.1108/BFJ-03-2017-0179]
   Andreica A, 2015, APPL INTELL, V42, P751, DOI 10.1007/s10489-014-0623-0
   Anenberg E, 2015, J URBAN ECON, V90, P60, DOI 10.1016/j.jue.2015.09.006
   [Anonymous], 2011, NEXUS 35
   [Anonymous], ARXIV
   [Anonymous], 2020, MAPS PUNE MAHARASHTR
   Bhandawat R, LOCATION OPTIMIZATIO
   Burguillo, 2018, GAME THEORY, DOI 10.1007/978-3-319-69898-4_7
   Caliari, 2020, NOTE DETERMINISTIC S
   Cao K, 2019, T GIS, V23, P726, DOI 10.1111/tgis.12535
   Chang XH, 2019, EXPERT SYST APPL, V126, P112, DOI 10.1016/j.eswa.2019.01.086
   Cho S, 2022, GEOGR ANAL, V54, P294, DOI 10.1111/gean.12292
   Choi H, 2020, INT J HOSP MANAG, V90, DOI 10.1016/j.ijhm.2020.102647
   Chua BL, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176276
   Dammeyer F., 1993, Annals of Operations Research, V41, P31
   diva-portal, COMP AN TAB SEARCH G
   Ghazikhani A, 2010, P 2010 18 IR C EL EN, DOI 10.1109/IRANIANCEE.2010.5507017
   Giocoli Nicola., 2004, History of Political Economy, V36, P639, DOI [DOI 10.1215/00182702-36-4-639, 10.1215/00182702-36-4-639]
   Habet D, 2009, STUD COMPUT INTELL, V203, P129
   Hadzic S., 2013, Game Theory Relaunched, DOI [DOI 10.5772/53930, 10.5772/53930]
   Han M., 2017, COMBINATORIAL OPTIMI
   Han SH, 2015, INT J HOSP MANAG, V50, P84, DOI 10.1016/j.ijhm.2015.06.010
   Hegde S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2342, DOI 10.1109/ICACCI.2017.8126196
   Hines G, 2012, ECAI
   Liu Q, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103760
   Martin N, 2014, INT J URBAN REGIONAL, V38, P1867, DOI 10.1111/1468-2427.12169
   Maschler M, GAME THEORY, P659, DOI 10.1017/cbo9780511794216.017
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   McNeil P., 2019, Journal of Foodservice Business Research, V22, P326, DOI 10.1080/15378020.2019.1614400
   Meng R, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2220, DOI 10.1109/WCICA.2010.5554307
   Moon, 2011, SERV DEM CONS DET PE, DOI 10.1007/978-3-642-20189-9_2
   Norozpour Sajedeh, 2020, IOP Conference Series: Materials Science and Engineering, V993, DOI 10.1088/1757-899X/993/1/012114
   Nowe A., 2012, Game Theory and Multiagent Reinforcement Learning
   pmc, 2021, APPL FORM
   QGIS Development Team, 2019, QGIS GEOGR INF SYST
   Radulescu R, 2020, AUTON AGENT MULTI-AG, V34, DOI 10.1007/s10458-019-09433-x
   SARKAR S, 2022, CONCURR COMP-PRACT E, V34
   Shams F, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-201
   Shin YH, 2019, INT J HOSP MANAG, V79, P11, DOI 10.1016/j.ijhm.2018.12.008
   Si-Yu Huang, 2019, 2019 IEEE 8th Data Driven Control and Learning Systems Conference (DDCLS). Proceedings, P1382, DOI 10.1109/DDCLS.2019.8909048
   Sohrabi MK, 2020, ARCH COMPUT METHOD E, V27, P59, DOI 10.1007/s11831-018-9300-5
   Trunfio GA, 2006, LECT NOTES COMPUT SC, V4224, P81
   Uchigaito H, 2021, IEEE ELECTR POW ENER, P365, DOI 10.1109/EPEC52095.2021.9621698
   Wai B, SELECTING OPTIMAL LO
   Wang F, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2371, DOI 10.1145/2983323.2983696
   WOODERS MH, 1983, J MATH ECON, V11, P277, DOI 10.1016/0304-4068(83)90005-8
NR 47
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9477
EP 9490
DI 10.1007/s11042-022-13758-3
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854429700009
DA 2024-07-18
ER

PT J
AU Song, HJ
   Zhang, XH
   Song, J
   Zhao, JL
AF Song, Huajun
   Zhang, Xiuhui
   Song, Jie
   Zhao, Jianle
TI Detection and tracking of safety helmet based on DeepSort and YOLOv5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Helmet wearing detection; Multi-target tracking; YOLOv5; DeepSort
AB Safety helmets can effectively prevent accidental head injuries to construction personnel. Helmet wearing detection is of great significance to the safety management of the construction site. The existing detection algorithms are difficult to detect small targets and dense targets, and the target occlusion and complex and changeable construction environment will reduce the detection accuracy. To solve the above problems, an intelligent helmet recognition system is designed, which combines multi-target tracking algorithm DeepSort and YOLOv5 detector. Firstly, the target bounding box is extracted by YOLOv5 algorithm and input into DeepSort framework. Further, the target trajectory prediction and tracking are realized by Kalman filter and Hungarian Algorithm. The actual test results on the complex construction sites show that the helmet recognition system based on YOLOv5 and DeepSort improves the detection speed and accuracy compared with the single detection algorithm and partial tracking algorithm. The average accuracy of the system is 94.5%, and the detection speed can reach 40fps, basically realizing real-time detection and providing an effective guarantee for the helmet-wearing detection task.
C1 [Song, Huajun; Zhang, Xiuhui; Song, Jie; Zhao, Jianle] China Univ Petr East China, Sch Oceanog & Space Informat, Qingdao 266580, Peoples R China.
C3 China University of Petroleum
RP Song, HJ (corresponding author), China Univ Petr East China, Sch Oceanog & Space Informat, Qingdao 266580, Peoples R China.
EM hunjun.song@upc.edu.cn; 1605020207@s.upc.edu.cn
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bin Dai, 2020, AIAM2020: Proceedings of the 2nd International Conference on Artificial Intelligence and Advanced Manufacture, P95, DOI 10.1145/3421766.3421774
   Chen SB, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207574
   Chiverton J, 2012, IET INTELL TRANSP SY, V6, P259, DOI 10.1049/iet-its.2011.0138
   Deng BY, 2020, 2020 16TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2020), P155, DOI 10.1109/CIS52066.2020.00041
   Fang Ming, 2019, Optics and Precision Engineering, V27, P1196, DOI 10.3788/OPE.20192705.1196
   Fang Q, 2018, AUTOMAT CONSTR, V85, P1, DOI 10.1016/j.autcon.2017.09.018
   Fangbo Zhou, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P6, DOI 10.1109/ICPECA51329.2021.9362711
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo S, 2020, SAFETY HELMET DETECT, P423, DOI [10.1007/978-981-15-8086-4_40, DOI 10.1007/978-981-15-8086-4_40]
   Jamtsho Y, 2021, ICT EXPRESS, V7, P104, DOI 10.1016/j.icte.2020.07.008
   Li J, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P201, DOI 10.1109/ICACI.2017.7974509
   Li YG, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/9703560
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Prajwal M, 2019, INT J COMPUT APPL, V182, P52, DOI DOI 10.5120/IJCA2019918770
   Raj A. G. Vignesh, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1241, DOI 10.1109/ICESC51422.2021.9532985
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Silva R, 2013, PROC LAT AM COMPUT C
   Silva R, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P141, DOI 10.1109/SIBGRAPI.2014.28
   Wang W, 2021, SAFETY HELMET DETECT, P123, DOI [10.1007/978-981-15-9354-3_12, DOI 10.1007/978-981-15-9354-3_12]
   Wang XY, 2020, CHIN AUTOM CONGR, P5437, DOI 10.1109/CAC51589.2020.9327187
   Waranusast R, 2013, INT CONF IMAG VIS, P35, DOI 10.1109/IVCNZ.2013.6726989
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu F, 2019, IEEE INT C NETW SENS, P363, DOI [10.1109/ICNSC.2019.8743246, 10.1109/icnsc.2019.8743246]
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
NR 29
TC 6
Z9 8
U1 57
U2 310
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10781
EP 10794
DI 10.1007/s11042-022-13305-0
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854429700005
DA 2024-07-18
ER

PT J
AU Hsu, CC
   Kang, LW
   Chen, SY
   Wang, IS
   Hong, CH
   Chang, CY
AF Hsu, Chih-Chung
   Kang, Li-Wei
   Chen, Shih-Yu
   Wang, I-Shan
   Hong, Ching-Hao
   Chang, Chuan-Yu
TI Deep learning-based vehicle trajectory prediction based on generative
   adversarial network for autonomous driving applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous vehicles; Self-driving cars; Vehicle trajectory; Deep
   learning; Generative adversarial networks; Deep social learning networks
ID BEHAVIOR
AB Autonomous vehicles need to continuously navigate complex traffic environments by efficiently analyzing the surrounding scene, understanding the behavior of other traffic agents, and predicting their future trajectories. The primary objective is to draw up a safe motion and reduce the reaction time for possibly imminent hazards. The main problem addressed in this paper is to explore the movement patterns of surrounding traffic-agents and accurately predict their future trajectories for assisting the vehicle to make a reasonable decision. Traditional trajectory prediction modules require explicit coordinate information to model the interaction between the autonomous car and its surrounding vehicles. However, it is hard to know the real coordinate of surrounding vehicles in real-world scenarios without communications between vehicles. A GAN (generative adversarial network)-based deep learning framework is presented in this paper for predicting the trajectories of surrounding vehicles of an autonomous vehicle in an RGB image sequence without explicit coordinate annotation to solve this problem. To automatically predict the trajectory from RGB image sequences, a coordinate augmentation module and a coordinate stabilization module are proposed to extract the historical trajectory from an image sequence. Meanwhile, the self-attention mechanism is also proposed to improve the social pooling module for better capturing the context information of trajectories of surrounding vehicles. Experimental results are demonstrated that the proposed method is effective and efficient.
C1 [Hsu, Chih-Chung] Natl Cheng Kung Univ, Inst Data Sci, Tainan, Taiwan.
   [Kang, Li-Wei] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
   [Chen, Shih-Yu; Wang, I-Shan; Chang, Chuan-Yu] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
   [Hong, Ching-Hao] Natl Pingtung Univ Sci & Technol, Dept Management Informat Syst, Pingtung, Taiwan.
C3 National Cheng Kung University; National Taiwan Normal University;
   National Yunlin University Science & Technology; National Pingtung
   University Science & Technology
RP Kang, LW (corresponding author), Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
EM lwkang@ntnu.edu.tw
RI Chang, Chuan-Yu/X-9186-2019; Hsu, Chih-Chung/Y-4835-2019
OI Chang, Chuan-Yu/0000-0001-9476-8130; Hsu,
   Chih-Chung/0000-0002-2083-4438; Kang, Li-Wei/0000-0001-6529-3981
FU Technology National Science and Technology Council (NSTC), Taiwan [NSTC
   108-2221-E-003-027-MY3, 111-2221-E-003-019-MY3, 111-2221-E-006 -210,
   110-2634-F-007-015, 109-2218-E-006-032]; National Taiwan Normal
   University (NTNU) by the Ministry of Education (MOE) in Taiwan
FX This work were supported in part by TechnologyNational Science and
   Technology Council (NSTC), Taiwan, under the Grant NSTC
   108-2221-E-003-027-MY3, 111-2221-E-003-019-MY3, 111-2221-E-006 -210,
   110-2634-F-007-015, and 109-2218-E-006-032. This work was also
   financially supported by the National Taiwan Normal University (NTNU)
   within the framework of the Higher Education Sprout Project by the
   Ministry of Education (MOE) in Taiwan.
CR Abousaleh FS, 2021, IEEE T COGN DEV SYST, V13, P679, DOI 10.1109/TCDS.2020.3036690
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Chan FH, 2017, LECT NOTES COMPUT SC, V10114, P136, DOI 10.1007/978-3-319-54190-7_9
   Dai SZ, 2019, IEEE ACCESS, V7, P38287, DOI 10.1109/ACCESS.2019.2907000
   Deo N, 2018, IEEE COMPUT SOC CONF, P1549, DOI 10.1109/CVPRW.2018.00196
   Fernandes SL., 2020, MULTIMED TOOLS APPL, V79, P10953, DOI [10.1007/s11042-020-08785-x, DOI 10.1007/S11042-020-08785-X]
   Goli SA, 2018, IEEE INT VEH SYM, P550, DOI 10.1109/IVS.2018.8500614
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsieh D-Y., 2020, PROC AAAI C ARTIFICI
   Hsu CC, 2021, IEEE T GEOSCI REMOTE, V59, P7773, DOI 10.1109/TGRS.2020.3034414
   Jeon G, 2020, MULTIMED TOOLS APPL, V79, P34129, DOI 10.1007/s11042-020-09232-7
   Jeong Y, 2020, IEEE OPEN J INTEL TR, V1, P2, DOI 10.1109/OJITS.2020.2965969
   Jocher G., 2020, YOLOv5
   Kingma D. P., 2014, arXiv
   Kong FY, 2020, MULTIMED TOOLS APPL, V79, P35195, DOI 10.1007/s11042-019-7614-4
   Kong J, 2015, IEEE INT VEH SYM, P1094, DOI 10.1109/IVS.2015.7225830
   Kuefler A, 2017, IEEE INT VEH SYM, P204, DOI 10.1109/IVS.2017.7995721
   Li JC, 2019, IEEE INT CONF ROBOT, P6658, DOI [10.1109/icra.2019.8793661, 10.1109/ICRA.2019.8793661]
   Lin CY, 2020, IEEE T IMAGE PROCESS, V29, P9250, DOI 10.1109/TIP.2020.3025402
   Luo WJ, 2018, PROC CVPR IEEE, P3569, DOI 10.1109/CVPR.2018.00376
   Ma YX, 2019, AAAI CONF ARTIF INTE, P6120
   Messaoud K, 2021, IEEE T INTELL VEHICL, V6, P175, DOI 10.1109/TIV.2020.2991952
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Morris BT, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041113
   Mozaffari S, 2022, IEEE T INTELL TRANSP, V23, P33, DOI 10.1109/TITS.2020.3012034
   Pascanu R., 2013, ATLANTA PROC INT C M
   Paszke A, 2019, ADV NEUR IN, V32
   Rasouli A, 2020, IEEE T INTELL TRANSP, V21, P900, DOI 10.1109/TITS.2019.2901817
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy D, 2019, IEEE INT C INTELL TR, P2318, DOI 10.1109/ITSC.2019.8916927
   Rudenko A, 2020, INT J ROBOT RES, V39, P895, DOI 10.1177/0278364920917446
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Schreier M, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P334, DOI 10.1109/ITSC.2014.6957713
   Shirazi MS, 2017, IEEE T INTELL TRANSP, V18, P4, DOI 10.1109/TITS.2016.2568920
   Si WW, 2019, IEEE INT VEH SYM, P281, DOI [10.1109/ivs.2019.8814238, 10.1109/IVS.2019.8814238]
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Wang S, IEEE T INTELL TRANSP
   Wang Z., 2020, COMPUTER VISION ECCV, P107, DOI [10.1007/978-3-030-58621-8_7, DOI 10.1007/978-3-030-58621-8_7]
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yeh CH, 2021, INFORM FUSION, V67, P195, DOI 10.1016/j.inffus.2020.10.016
   Yeh CH, 2020, IEEE ACCESS, V8, P163447, DOI 10.1109/ACCESS.2020.3021729
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhao L, 2021, IEEE INTERNET THINGS, V8, P2066, DOI 10.1109/JIOT.2020.3021141
   Zyner A, 2020, IEEE T INTELL TRANSP, V21, P1584, DOI 10.1109/TITS.2019.2913166
NR 51
TC 2
Z9 2
U1 17
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10763
EP 10780
DI 10.1007/s11042-022-13742-x
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854682700006
DA 2024-07-18
ER

PT J
AU Hazarika, BB
   Gupta, D
AF Hazarika, Barenya Bikash
   Gupta, Deepak
TI Improved twin bounded large margin distribution machines for binary
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Margin distribution; Least squares; Iterative scheme; Large margin
   distribution machine; Twin support vector machine
ID SUPPORT VECTOR MACHINE; REGRESSION
AB Recently, a robust and effective classifier termed twin bounded large margin distribution machine (TBLDM) was suggested. TBLDM is based on the twin bounded support vector machine (TBSVM) and large margin distribution machine (LDM). TBLDM searches for two nonparallel hyperplanes by optimizing the negative and positive margin distributions. Based on TBLDM, this paper suggests a least-square variant of the TBLDM model termed as least squares TBLDM (LSTBLDM) and an iterative variant of TBLDM called iterative TBLDM (ITBLDM). In the first model, i.e., LSTBLDM, the optimization problem contains equality constraints rather than inequality constraints and it solves a system of linear equations, unlike the TBLDM model. In the second model, i.e., ITBLDM, the optimization problems are solved in primal using a simple, functional iterative scheme. The pseudo-codes are also specified for the proposed models to make them easily implementable. The experiments have been performed on one artificial and thirty-eight interesting real-world datasets. The proposed models are compared with the least squares support vector machine (LSSVM), twin support vector machine (TWSVM) and TBLDM. The results based on the classification accuracy reveal the usefulness and applicability of the proposed LSTBLDM and ITBLDM models.
C1 [Hazarika, Barenya Bikash] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
   [Gupta, Deepak] Natl Inst Technol Arunachal Pradesh, Dept Comp Sci & Engn, Jote, Arunachal Prade, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh
RP Gupta, D (corresponding author), Natl Inst Technol Arunachal Pradesh, Dept Comp Sci & Engn, Jote, Arunachal Prade, India.
EM barenya1431@gmail.com; deepakjnu85@gmail.com
RI Gupta, Deepak/H-4151-2019; Hazarika, Barenya Bikash/AAL-7514-2021
OI Gupta, Deepak/0000-0002-6375-8615; Hazarika, Barenya
   Bikash/0000-0001-8243-9153
CR Abe S, 2017, PATTERN RECOGN LETT, V98, P96, DOI 10.1016/j.patrec.2017.09.005
   Balasundaram S, 2017, APPL INTELL, V46, P124, DOI 10.1007/s10489-016-0809-8
   Balasundaram S, 2013, NEURAL COMPUT APPL, V22, P559, DOI 10.1007/s00521-011-0798-9
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Borah P, 2019, NEURAL COMPUT APPL, P1
   Borah P, 2021, APPL INTELL, V51, P5314, DOI 10.1007/s10489-020-01847-5
   Borah P, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P412, DOI 10.1109/SSCI.2018.8628818
   Cheng FY, 2016, PATTERN RECOGN LETT, V80, P107, DOI 10.1016/j.patrec.2016.06.009
   Cheng MY, 2019, NEURAL COMPUT APPL, V31, P6261, DOI 10.1007/s00521-018-3426-0
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Das Adhikary D, 2021, MULTIMED TOOLS APPL, V80, P35123, DOI 10.1007/s11042-020-09658-z
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Ganaie MA, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113072
   Gao W, 2013, ARTIF INTELL, V203, P1, DOI 10.1016/j.artint.2013.07.002
   Gong BM, 2018, NEUROCOMPUTING, V320, P141, DOI 10.1016/j.neucom.2018.09.025
   Gupta D, 2021, MULTIMED TOOLS APPL, V80, P30091, DOI 10.1007/s11042-020-10242-8
   Gupta D, 2019, NEURAL COMPUT APPL, V31, P7153, DOI 10.1007/s00521-018-3551-9
   Gupta D, 2017, APPL INTELL, V47, P962, DOI 10.1007/s10489-017-0913-4
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Hazarika BB, 2022, NEURAL PROCESS LETT, V54, P1091, DOI 10.1007/s11063-021-10671-y
   Hazarika BB, 2021, NEURAL COMPUT APPL, V33, P4243, DOI 10.1007/s00521-020-05240-8
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Kalteh AM, 2016, WATER RESOUR MANAG, V30, P747, DOI 10.1007/s11269-015-1188-3
   Kumar MA, 2009, EXPERT SYST APPL, V36, P7535, DOI 10.1016/j.eswa.2008.09.066
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2020, SOFT COMPUT, V24, P13197, DOI 10.1007/s00500-020-04733-x
   Liu LM, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107374
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Murphy P., 1996, UCI REPOSITORY MACHI
   Nasiri JA, 2020, NEURAL COMPUT APPL, V32, P12949, DOI 10.1007/s00521-020-04740-x
   Parray IR, 2020, SOFT COMPUT, V24, P16509, DOI 10.1007/s00500-020-04957-x
   Rastogi R, 2020, NEURAL COMPUT APPL, V32, P3633, DOI 10.1007/s00521-018-3921-3
   Reyzin L., 2006, P 23 INT C MACH LEAR, V148, P753, DOI [DOI 10.1145/1143844.1143939, 10.1145/1143844.1143939]
   Ripley BD, 1996, PATTERN RECOGNITION
   Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang HR, 2018, APPL INTELL, V48, P1041, DOI 10.1007/s10489-017-0984-2
   Wang LS, 2019, J APPL SPECTROSC+, V86, P465, DOI 10.1007/s10812-019-00842-0
   Xie XM, 2018, NEURAL COMPUT APPL, V30, P371, DOI 10.1007/s00521-017-3237-8
   Xu HT, 2018, LECT NOTES ARTIF INT, V11320, P718, DOI 10.1007/978-3-030-03991-2_64
   Zhang T, 2020, IEEE T KNOWL DATA EN, V32, P1143, DOI 10.1109/TKDE.2019.2897662
   Zhang T, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P313, DOI 10.1145/2623330.2623710
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zheng YL, 2020, ENERGIES, V13, DOI 10.3390/en13020426
NR 48
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13341
EP 13368
DI 10.1007/s11042-022-13738-7
EA SEP 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000852346600004
DA 2024-07-18
ER

PT J
AU Mao, NX
   Chen, F
   Zhang, SJ
   He, HJ
   Qu, LF
   Yang, YL
AF Mao NingXiong
   Fan, Chen
   Zhang Shanjun
   He Hongjie
   Qu Lingfeng
   Yang Yaolin
TI Reversible data hiding based on global adaptive pairing and optimal 2D
   mapping set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Prediction error expansion (PEE); Global
   adaptive pairing; Optimal 2D mapping set
ID WATERMARKING; EXPANSION; IMAGES; PVO
AB Two-dimensional prediction error expansion(2D-PEE) can effectively improve performance of reversible data hiding (RDH) because it can make full use of correlation of predicting errors. Most of the existing 2D-PEE is based on a fixed pairing pattern of adjacent positions. The fixed 2D mapping through experience obtained has the same mapping rules for different texture images, this will limit embedding performance. To address the problem, this paper proposes an RDH scheme based on global adaptive pairing and optimal 2D mapping set. The global adaptive pairing method is adopted to directly pair the ordered prediction error sequence. Since the prediction error pair is not constrained by position, the two-dimensional prediction error histogram (2D-PEH) is sharp. The single 2D-PEH is divided into multiple 2D-PEHs, and the 2D mapping of each sub-2D-PEH is adaptive determined by the dynamic programming method. Thereby, the optimal 2D mapping set is self-adaptive obtain according to the texture feature of the image. Experimental results show that the proposed scheme outperforms other state-of-the-art schemes. The PSNR of the image Lena is reaches 60.84 dB for an embedding capacity of 10,000 bits.
C1 [Mao NingXiong; He Hongjie; Qu Lingfeng; Yang Yaolin] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [Fan, Chen] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 610031, Sichuan, Peoples R China.
   [Zhang Shanjun] Kanagawa Univ, Fac Sci, Dept Informat Sci, Yokohama, Kanagawa, Japan.
C3 Southwest Jiaotong University; Southwest Jiaotong University; Kanagawa
   University
RP He, HJ (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
EM hjhe@home.swjtu.edu.cn
RI Lingfeng, Qu/GLT-0330-2022; fan, chen/GWC-9330-2022
OI Lingfeng, Qu/0000-0002-2544-4324; mao, ning xiong/0000-0001-8233-0991
FU National Natural Science Foundation of China [61872303, U1936113]
FX This work was supported by the National Natural Science Foundation of
   China under Grant (61872303, U1936113). In addition, many thanks to the
   anonymous reviewers for their insightful comments and valuable
   suggestions, which helped a lot to improve the paper quality.
CR Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J., 2009, Steganography in Digital Media: Principles, Algorithms, and Applications
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hiary S, 2017, MULTIMED TOOLS APPL, V76, P2131, DOI 10.1007/s11042-015-3161-9
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu R., 2021, IEEE T PATTERN ANAL, V30, P1
   Hu RW, 2021, IEEE SIGNAL PROC LET, V28, P464, DOI 10.1109/LSP.2021.3059202
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Ingemar J.C., 2008, DIGITAL WATERMARKING, V2nd
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kumar R, 2020, MULTIMED TOOLS APPL, V79, P22635, DOI 10.1007/s11042-020-09069-0
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mohammadi A, 2021, MULTIMED TOOLS APPL, V80, P3307, DOI 10.1007/s11042-020-09719-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sellahewa H, 2013, MOBILE MULTIMEDIA IM, P63
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Xuan GR, 2008, LECT NOTES COMPUT SC, V5041, P264
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhou K, 2021, MULTIMED TOOLS APPL, V80, P1123, DOI 10.1007/s11042-020-09374-8
NR 43
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10553
EP 10574
DI 10.1007/s11042-022-13705-2
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000850418800002
DA 2024-07-18
ER

PT J
AU Sun, GL
   Hu, HQ
   Su, YY
   Liu, Q
   Lu, XF
AF Sun, Guangling
   Hu, Haoqi
   Su, Yuying
   Liu, Qi
   Lu, Xiaofeng
TI ApaNet: adversarial perturbations alleviation network for face
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Face verification; Adversarial example; Adversarial
   perturbations alleviation network
AB Albeit Deep neural networks (DNNs) are widely used in computer vision, natural language processing and speech recognition, they have been discovered to be fragile to adversarial attacks. Specifically, in computer vision, an attacker can easily deceive DNNs by contaminating an input image with perturbations imperceptible to humans. As one of the important vision tasks, face verification is also subject to adversarial attack. Thus, in this paper, we focus on defending against the adversarial attack for face verification to mitigate the potential risk. We learn a network via an implementation of stacked residual blocks, namely adversarial perturbations alleviation network (ApaNet), to alleviate latent adversarial perturbations hidden in the input facial image. During the supervised learning of ApaNet, only the Labeled Faces in the Wild (LFW) is used as the training set, and the legitimate examples and corresponding adversarial examples produced by projected gradient descent algorithm compose supervision and inputs respectively. By leveraging the middle and high layer's activation of FaceNet, the discrepancy between an image output by ApaNet and the supervision is calculated as the loss function to optimize ApaNet. Empirical experiment results on the LFW, YouTube Faces DB and CASIA-FaceV5 confirm the effectiveness of the proposed defender against some representative white-box and black-box adversarial attacks. Also, experimental results show the superiority performance of the ApaNet as comparing with several currently available techniques.
C1 [Sun, Guangling; Hu, Haoqi; Su, Yuying; Liu, Qi; Lu, Xiaofeng] Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Lu, XF (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
EM luxiaofeng@shu.edu.cn
FU Natural Science Foundation of Shanghai [20ZR1419900]; Shanghai Committee
   of Science and Technology [21511102605]
FX This work was supported by Natural Science Foundation of Shanghai under
   Grant No. 20ZR1419900 and Shanghai Committee of Science and Technology
   under Grant (No.21511102605).
CR Becerra-Riera F, 2019, ARTIF INTELL REV, V52, P1155, DOI 10.1007/s10462-019-09689-5
   Boutros F, 2021, ARXIV
   Chhabra S, 2018, ARXIV
   Dabouei A, 2019, IEEE WINT CONF APPL, P1979, DOI 10.1109/WACV.2019.00215
   Deb D, 2020, ARXIV
   Duan RJ, 2020, PROC CVPR IEEE, P997, DOI 10.1109/CVPR42600.2020.00108
   Fan WQ, 2019, MULTIMED TOOLS APPL, V78, P20409, DOI 10.1007/s11042-019-7353-6
   Goel A, 2018, INT CONF BIOMETR THE
   Goodfellow I. J., 2014, ARXIV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goswami G, 2019, INT J COMPUT VISION, V127, P719, DOI 10.1007/s11263-019-01160-w
   Guo C., 2017, ARXIV
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Jia XJ, 2019, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2019.00624
   Kumar A, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Li YD, 2019, PR MACH LEARN RES, V97
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Madry A., 2018, ARXIV
   Massoli FV, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103103
   Mirjalili V, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P564, DOI 10.1109/BTAS.2017.8272743
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Papernot N., 2016, CORR
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Ren K, 2020, ENGINEERING-PRC, V6, P346, DOI 10.1016/j.eng.2019.12.012
   Rozsa A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P168, DOI 10.1109/BTAS.2017.8272695
   Rozsa A, 2016, INT C PATT RECOG, P3121, DOI 10.1109/ICPR.2016.7900114
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sriram S., 2019, INT S SEC COMP COMM, P111
   Stutz D, 2019, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2019.00714
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Xie C., 2020, arXiv
   Xie C., 2017, ARXIV
   Yi Dong, 2014, ARXIV14117923
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 49
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7443
EP 7461
DI 10.1007/s11042-022-13641-1
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843430100001
PM 36035322
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mandal, S
   Khan, DA
AF Mandal, Sudakshina
   Khan, Danish Ali
TI Enhanced-Longest Common Subsequence based novel steganography approach
   for cloud storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Cloud storage security; Data hiding; Longest common
   subsequence (LCS); Steganography realization
ID PROTOCOL; SYSTEM
AB Cloud storage is an essential and most demanding application for enterprise and private use in today's communication. However, the data security over the distributed cloud resources is threatened due to numerous security challenges. Analyzing and reviewing the existing security policies are necessary to prevent unauthorized infringement of sensitive information in cloud storage. Therefore, a convenient and adaptable security framework should be designed. However, traditional steganographic systems use the embedding technique substantially by transforming carriers which unavoidably leaves the evidence. Therefore the transforming bits can be easily detected through steganalysis. This paper proposes a novel steganography approach to ensure the security of sensitive information in cloud storage. The approach uses the realization over embedding technique, which stores only the cover-secret mapping instead of original information in the cloud by taking significantly less storage space. Enhanced Longest Common Subsequence (Enhanced- LCS) is used here to generate the secure reversible mapping, and data hiding methodology is used to mask the secret in this framework. This mapping is fully realized only by the dedicated recipient with keys. The Cantor pairing function is used for constructing keys. We significantly reduce the time and space complexity by using the Enhanced-LCS algorithm. Space and time complexities are calculated as O(n) and O(n*log(n)) here. Divergent file types such as image, word, and PDF files with different dimensions have been used to perform experimental analysis. This approach also ensures protection against some of the well-known security attacks. Different types of performance analysis make this framework more efficient and robust.
C1 [Mandal, Sudakshina; Khan, Danish Ali] Natl Inst Technol Jamshedpur, Dept Comp Applicat, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Khan, DA (corresponding author), Natl Inst Technol Jamshedpur, Dept Comp Applicat, Jharkhand, India.
EM sudakshina184@gmail.com; dakhan.ca@nitjsr.ac.in
RI Khan, Danish Ali/AAA-2936-2019
OI Khan, Danish Ali/0000-0002-6669-0900; Mandal,
   Sudakshina/0000-0001-9772-5339
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Amalarethinam DIG, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P181, DOI 10.1109/WCCCT.2016.52
   Anand S, 2019, DIGIT COMMUN NETW, V5, P276, DOI 10.1016/j.dcan.2019.10.007
   [Anonymous], 2011, CANTOR PAIRING FUNCT
   Asahiro Y, 2020, THEOR COMPUT SCI, V838, P238, DOI 10.1016/j.tcs.2020.07.042
   Bhowmick Ratul., 2019, 2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT), P1
   Bjelland E, 2018, SYSTEMS, V6, DOI 10.3390/systems6020022
   Blum C, 2021, COMPUT OPER RES, V125, DOI 10.1016/j.cor.2020.105089
   Callegati F, 2018, COMPUT SECUR, V74, P277, DOI 10.1016/j.cose.2017.10.006
   Cantor P., 2020, CORONAVIRUS KEEPING
   Caviglione L, 2017, IEEE T IND INFORM, V13, P1921, DOI 10.1109/TII.2016.2627503
   Cegielski P, 2001, THEOR COMPUT SCI, V257, P51, DOI 10.1016/S0304-3975(00)00109-2
   Gao F, 2008, CHINESE PHYS LETT, V25, P2766, DOI 10.1088/0256-307X/25/8/009
   Hamandi K, 2015, MOB INF SYST, V2015, DOI 10.1155/2015/746930
   Khan I, 2018, IEEE T CLOUD COMPUT, V6, P942, DOI 10.1109/TCC.2016.2560161
   Kholidy HA, 2021, FUTURE GENER COMP SY, V117, P299, DOI 10.1016/j.future.2020.12.009
   Khosravi B, 2019, J INF SECUR APPL, V45, P61, DOI 10.1016/j.jisa.2019.01.003
   Lisi M, 2007, MATEMATICHE, V62, P55
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Mandal S, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P91, DOI 10.1109/ICIIP47207.2019.8985974
   Muralidharan K., 2014, 2014 Proceedings of 3rd International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), DOI 10.1109/ICRITO.2014.7014660
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Pattanaik B, 2021, MATER TODAY-PROC
   Rahman MS, 2021, IEEE J BIOMED HEALTH, V25, P35, DOI 10.1109/JBHI.2020.2988449
   Raju KG, 2020, MATER TODAY-PROC
   Roy R, 2014, INT CONF CONTEMP, P218, DOI 10.1109/IC3.2014.6897176
   Saracevic M, 2019, FUTURE GENER COMP SY, V100, P186, DOI 10.1016/j.future.2019.05.010
   Sarkar M.K., 2014, ACEEE INT J NETW SEC, V5
   Shanthakumari R, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1106-0
   Shanthi S, 2018, MATER TODAY-PROC, V5, P1967, DOI 10.1016/j.matpr.2017.11.300
   Subramanian N, 2018, COMPUT ELECTR ENG, V71, P28, DOI 10.1016/j.compeleceng.2018.06.006
   Sumathi M, 2020, COMPUT COMMUN, V150, P569, DOI 10.1016/j.comcom.2019.11.029
   Szudzik, 2019, ARXIV
   Tan SQ, 2012, IEEE SIGNAL PROC LET, V19, P336, DOI 10.1109/LSP.2012.2194702
   Wazirali R, 2017, 2017 25TH INTERNATIONAL CONFERENCE ON SYSTEMS ENGINEERING (ICSENG), P451, DOI 10.1109/ICSEng.2017.61
   Wu JQ, 2020, IEEE T INF FOREN SEC, V15, P2282, DOI 10.1109/TIFS.2019.2963764
   Xiang T, 2015, DIGIT SIGNAL PROCESS, V43, P28, DOI 10.1016/j.dsp.2015.05.006
   Xu C, 2019, IEEE INTERNET THINGS, V6, P8345, DOI 10.1109/JIOT.2019.2917186
   Yogendra Naidu P, 2021, MATER TODAY-PROC
   Yue DD, 2020, J PARALLEL DISTR COM, V146, P1, DOI 10.1016/j.jpdc.2020.06.007
   Zhao SME, 2019, IEEE T NUCL SCI, V66, P1599, DOI 10.1109/TNS.2019.2890827
   Zhou ZL, 2019, IEEE ACCESS, V7, P179891, DOI 10.1109/ACCESS.2019.2955990
NR 44
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7779
EP 7801
DI 10.1007/s11042-022-13615-3
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000838552300009
DA 2024-07-18
ER

PT J
AU Devi, JS
   Sulthana, AR
AF Devi, J. Sarala
   Sulthana, A. Razia
TI Video object segmentation guided refinement on foreground-background
   objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Ensemble learning; Pixel level mapping;
   Instance level matching; ResNet; Activation function
AB Video Object Segmentation (VOS) for separating a foreground object from a video sequence is an intricate task and relies on fine-tuning. Many recent approaches focus on pixel-wise matching of foreground objects and gives importance to balancing the relation between the pixels for identifying the foreground objects and might lead to misclassification. This paper explores mapping between the foreground and background objects in semi-supervised VOS by balancing and mutually mapping the pixels between the foreground and background objects. The proposed model makes practical and effective use of enhanced pixel and instance level matching to improve the prediction. Moreover, the framework implements ensemble learning with a Leaky-ReLU activation function that improves the segmentation process. To evaluate the results of object segmentation process, J and F scores are measured. We carry experiments broadly on popular benchmark DAVIS, in the versions 2016 and 2017. Our Model achieves a promising performance of J & F score of 82%, surpassing all the other techniques.
C1 [Devi, J. Sarala; Sulthana, A. Razia] Birla Inst Technol & Sci, Dept Comp Sci & Engn, Pilani Dubai, U Arab Emirates.
RP Sulthana, AR (corresponding author), Birla Inst Technol & Sci, Dept Comp Sci & Engn, Pilani Dubai, U Arab Emirates.
EM saraladevi77@gmail.com; razia@dubai.bits-pilani.ac.in
RI devi, sri/GWQ-8417-2022
OI , J Sarala Devi/0000-0002-7938-6887; Sulthana, Razia/0000-0001-5331-1310
CR Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130
   Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154
   Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Favorskaya MN, 2019, STUDY ACTIVATION FUN
   Glorot X., 2010, 13 INT C ARTIFICIAL, V9, P249
   Griffin BA, 2019, PROC CVPR IEEE, P8906, DOI 10.1109/CVPR.2019.00912
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Hu YT, 2017, ADV NEUR IN, V30
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XX, 2018, LECT NOTES COMPUT SC, V11207, P93, DOI 10.1007/978-3-030-01219-9_6
   Liang YH, 2020, INT CONF ASIAN LANG, P1, DOI [10.1109/ialp51396.2020.9310512, 10.1109/IALP51396.2020.9310512]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luiten J, 2019, LECT NOTES COMPUT SC, V11364, P565, DOI 10.1007/978-3-030-20870-7_35
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/iccv.2019.00932
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pont-Tuset J., 2017, ARXIV
   Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Voigtlaender P., 2017, ARXIV
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318
   Wolf Christine T., 2016, First Monday, V21, DOI 10.5210/fm.v21i6.6787
   Wu Z., 2016, ARXIV160506885
   Xiao HX, 2018, PROC CVPR IEEE, P1140, DOI 10.1109/CVPR.2018.00125
   Xu B., 2015, ARXIV
   Xu N, 2018, LECT NOTES COMPUT SC, V11209, P603, DOI 10.1007/978-3-030-01228-1_36
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yang Z, 2019, IEEE I CONF COMP VIS, P931, DOI 10.1109/ICCV.2019.00102
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhu X., 2018, arXiv
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6769
EP 6785
DI 10.1007/s11042-022-12981-2
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590000001
DA 2024-07-18
ER

PT J
AU Diwan, T
   Anirudh, G
   Tembhurne, J
AF Diwan, Tausif
   Anirudh, G.
   Tembhurne, Jitendra, V
TI Object detection using YOLO: challenges, architectural successors,
   datasets and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Convolutional neural networks; YOLO; Deep learning;
   Computer vision
ID RECURRENT NEURAL-NETWORK; FASTER
AB Object detection is one of the predominant and challenging problems in computer vision. Over the decade, with the expeditious evolution of deep learning, researchers have extensively experimented and contributed in the performance enhancement of object detection and related tasks such as object classification, localization, and segmentation using underlying deep models. Broadly, object detectors are classified into two categories viz. two stage and single stage object detectors. Two stage detectors mainly focus on selective region proposals strategy via complex architecture; however, single stage detectors focus on all the spatial region proposals for the possible detection of objects via relatively simpler architecture in one shot. Performance of any object detector is evaluated through detection accuracy and inference time. Generally, the detection accuracy of two stage detectors outperforms single stage object detectors. However, the inference time of single stage detectors is better compared to its counterparts. Moreover, with the advent of YOLO (You Only Look Once) and its architectural successors, the detection accuracy is improving significantly and sometime it is better than two stage detectors. YOLOs are adopted in various applications majorly due to their faster inferences rather than considering detection accuracy. As an example, detection accuracies are 63.4 and 70 for YOLO and Fast-RCNN respectively, however, inference time is around 300 times faster in case of YOLO. In this paper, we present a comprehensive review of single stage object detectors specially YOLOs, regression formulation, their architecture advancements, and performance statistics. Moreover, we summarize the comparative illustration between two stage and single stage object detectors, among different versions of YOLOs, applications based on two stage detectors, and different versions of YOLOs along with the future research directions.
C1 [Diwan, Tausif; Tembhurne, Jitendra, V] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Anirudh, G.] Cent Univ Rajasthan, Dept Data Sci & Analyt, Jaipur, Rajasthan, India.
C3 Central University of Rajasthan (CURAJ)
RP Diwan, T (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM tdiwan@iiitn.ac.in; ganirudhani90@gmail.com
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Agarwal S, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1809.03193
   Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   [Anonymous], GOOGLE LENS WIKIPEDI
   [Anonymous], DETECTION LOCALIZATI
   [Anonymous], 2004, Computer vision and image processing
   Bengio Y., 2012, ABS12065538 CORR, V1, P5538
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Cao ZG, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113833
   Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9
   Chen BH, 2020, J ELECTR ENG TECHNOL, V15, P441, DOI 10.1007/s42835-019-00230-w
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Choi H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONTROL, AND COMPUTING TECHNOLOGIES FOR SMART GRIDS (SMARTGRIDCOMM)
   Cook A-p-f-o-l, 2017, Global average pooling layers for object localization
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gavali P, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P99, DOI 10.1016/B978-0-12-816718-2.00013-0
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153371
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Jiang JH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13101909
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kannadaguli Prashanth, 2020, 2020 International Conference on Decision Aid Sciences and Application (DASA), P1213, DOI 10.1109/DASA51403.2020.9317198
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim J., 2016, 2016 INT C PLATFORM, P1, DOI DOI 10.1109/PLATCON.2016.7456805
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lee HJ, 1995, IEEE REG 10 C TENCON, V2, P1355, DOI [10.1109/TENCON.1999.818681, DOI 10.1109/TENCON.1999.818681]
   Li J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183750
   Li X, 2018, J ADV TRANSPORT, DOI 10.1155/2018/7075814
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Mezaal MR, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7070730
   Nash W, 2018, NPJ MAT DEGRAD, V2, DOI 10.1038/s41529-018-0058-x
   Quang D, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw226
   Rastogi A, 2019, J MECH SCI TECHNOL, V33, P1869, DOI 10.1007/s12206-019-0339-5
   Rather AM, 2015, EXPERT SYST APPL, V42, P3234, DOI 10.1016/j.eswa.2014.12.003
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rey J, 2017, OBJECT DETECTION DEE
   Sak H., 2015, ARXIV
   Sakthi Raj, 2013, TALENTED MR 1X1 COMP
   Sermanet P., 2013, ARXIV
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P1687, DOI 10.1016/j.jksuci.2019.09.012
   Shi YZ, 2017, INT CONF ENTERP SYST, P173, DOI 10.1109/ES.2017.35
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thai LH., 2012, International Journal of Information Technology and Computer Science, V4, P32, DOI DOI 10.5815/IJITCS.2012.05.05
   Tsang S-H, 2018, REV INCEPTION V4 EVO
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Ujjwalkarn, 2016, INT EXPL CONV NEUR N
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang XG, 2018, 2018 INTERNATIONAL CONFERENCE ON SENSING, DIAGNOSTICS, PROGNOSTICS, AND CONTROL (SDPC), P676, DOI [10.1109/SDPC.2018.00130, 10.1109/SDPC.2018.8664773]
   Wei DQ, 2017, ENERGIES, V10, DOI 10.3390/en10030406
   Wei HR, 2019, MACH LEARN KNOW EXTR, V1, DOI 10.3390/make1030044
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Xiang J, 2020, IEEE ACCESS, V8, P48299, DOI 10.1109/ACCESS.2020.2979164
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Ye A., 2020, P 2020 3 INT C ALG C, P1, DOI DOI 10.26914/C.CNKIHY.2020.052215
   Zaytar M.A., 2016, Int. J. Comput. Appl., V143, P7, DOI DOI 10.5120/IJCA2016910497
   Zhang HP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091117
   Zhang SF, 2021, IEEE T CIRC SYST VID, V31, P674, DOI 10.1109/TCSVT.2020.2986402
   Zhang XW, 2018, INT CONF CYBER DIST, P138, DOI 10.1109/CyberC.2018.00036
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhang YS, 2016, CHINESE J ELECTRON, V25, P601, DOI 10.1049/cje.2016.07.002
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng YY, 2021, MATEC WEB CONF, V336, DOI 10.1051/matecconf/202133603002
NR 85
TC 185
Z9 191
U1 130
U2 261
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9243
EP 9275
DI 10.1007/s11042-022-13644-y
EA AUG 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000837590100001
PM 35968414
OA Bronze, Green Published
HC Y
HP Y
DA 2024-07-18
ER

PT J
AU Shrestha, M
   Alsadoon, OH
   Alsadoon, A
   Al-Dala'in, T
   Rashid, TA
   Prasad, PWC
   Alrubaie, A
AF Shrestha, Marmik
   Alsadoon, Omar Hisham
   Alsadoon, Abeer
   Al-Dala'in, Thair
   Rashid, Tarik A.
   Prasad, P. W. C.
   Alrubaie, Ahmad
TI A novel solution of deep learning for enhanced support vector machine
   for predicting the onset of type 2 diabetes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Type 2 diabetes; Support vector machine; Radial base
   function; Long short-term memory; Electronic health record
ID MELLITUS; CLASSIFICATION; DIAGNOSIS
AB Type 2 Diabetes is one of the most major and fatal diseases known to human beings, where thousands of people are subjected to the onset of Type 2 Diabetes every year. However, the diagnosis and prevention of Type 2 Diabetes are relatively costly in today's scenario; hence, the use of machine learning and deep learning techniques is gaining momentum for predicting the onset of Type 2 Diabetes. This research aims to increase the accuracy and Area Under the Curve (AUC) metric while improving the processing time for predicting the onset of Type 2 Diabetes. The proposed system consists of a deep learning technique that uses the Support Vector Machine (SVM) algorithm along with the Radial Base Function (RBF) along with the Long Short-term Memory Layer (LSTM) for prediction of onset of Type 2 Diabetes. The proposed solution provides an average accuracy of 86.31% and an average AUC value of 0.8270 or 82.70%, with an improvement of 3.8 milliseconds in the processing. Radial Base Function (RBF) kernel and the LSTM layer enhance the prediction accuracy and AUC metric from the current industry standard, making it more feasible for practical use without compromising the processing time.
C1 [Shrestha, Marmik; Alsadoon, Abeer; Al-Dala'in, Thair; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
   [Alsadoon, Abeer; Al-Dala'in, Thair; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn Dept, Erbil, KR, Iraq.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Al-Iraqia University; Western Sydney
   University; University of Kurdistan Hewler; University of New South
   Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./HLX-0184-2023;
   Rashid, Tarik A./P-3473-2019
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; Rashid, Tarik A./0000-0002-8661-258X; Alsadoon,
   Omar Hisham/0000-0001-7797-6392; withana, chandana/0000-0002-3007-687X
CR Bernardini M, 2020, IEEE J BIOMED HEALTH, V24, P235, DOI 10.1109/JBHI.2019.2899218
   Cahn A, 2020, DIABETES-METAB RES, V36, DOI 10.1002/dmrr.3252
   Caliskan A, 2018, ENG APPL ARTIF INTEL, V67, P14, DOI 10.1016/j.engappai.2017.09.002
   Choi BG, 2019, YONSEI MED J, V60, P191, DOI 10.3349/ymj.2019.60.2.191
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Gast R, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225900
   Habibi Shafi, 2015, Glob J Health Sci, V7, P304, DOI 10.5539/gjhs.v7n5p304
   Han Wu, 2018, Informatics in Medicine Unlocked, V10, P100, DOI 10.1016/j.imu.2017.12.006
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Kannadasan K, 2019, CLIN EPIDEMIOL GLOB, V7, P530, DOI 10.1016/j.cegh.2018.12.004
   Lee BJ, 2016, IEEE J BIOMED HEALTH, V20, P39, DOI 10.1109/JBHI.2015.2396520
   Mercaldo F, 2017, PROCEDIA COMPUT SCI, V112, P2519, DOI 10.1016/j.procs.2017.08.193
   Mohebbi A, 2017, IEEE ENG MED BIO, P2896, DOI 10.1109/EMBC.2017.8037462
   Nguyen BP, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105055
   Pimentel A, 2018, HEALTH INFORM J, V24, P194, DOI 10.1177/1460458216663023
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   Ryu KS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010421
   Samant P, 2018, COMPUT METH PROG BIO, V157, P121, DOI 10.1016/j.cmpb.2018.01.004
   Tigga NP, 2020, PROCEDIA COMPUT SCI, V167, P706, DOI 10.1016/j.procs.2020.03.336
   Xie ZD, 2019, PREV CHRONIC DIS, V16, DOI 10.5888/pcd16.190109
   Zheng T, 2017, INT J MED INFORM, V97, P120, DOI 10.1016/j.ijmedinf.2016.09.014
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 22
TC 2
Z9 2
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6221
EP 6241
DI 10.1007/s11042-022-13582-9
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836525000001
DA 2024-07-18
ER

PT J
AU Kulathilake, KASH
   Abdullah, NA
   Sabri, AQM
   Bandara, AMRR
   Lai, KW
AF Kulathilake, K. A. Saneera Hemantha
   Abdullah, Nor Aniza
   Sabri, Aznul Qalid Md
   Bandara, A. M. R. Ravimal
   Lai, Khin Wee
TI A review on self-adaptation approaches and techniques in medical image
   denoising algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Adaptive denoising; Radiography; Computed tomography; Magnetic resonance
   imaging; Ultrasonography; Lesion discrimination
ID LOW-DOSE CT; GENERATIVE ADVERSARIAL NETWORK; SPECKLE NOISE-REDUCTION;
   BILATERAL FILTER; NEURAL-NETWORK; ADAPTIVE REGULARIZATION; MAGNITUDE
   MRI; FUZZY-LOGIC; WAVELET; REMOVAL
AB Noise is a definite degeneration of medical images that interferes with the diagnostic process in clinical medicine. Although many denoising algorithms have been developed to improve the visual quality of medical images, failure to noise adaptation has been identified as a critical limitation of many existing denoising algorithms. Therefore, the objective of this study is to conduct an in-depth review to investigate and classify the various self-adaptive approaches and techniques implemented in recent medical image denoising applications. The articles published from the year 2015 have been retrieved from the web of science core collection database focusing on four medical imaging modalities, such as radiography, magnetic resonance imaging, computed tomography, and ultrasound. The analysis of the applications has emphasized the unique algorithmic components used to achieve the self-adaptability in detailed. Moreover, the strengths and weaknesses of those applications have been reviewed according to the various adaptive denoising approaches. Finally, this review highlights the limitations of existing adaptive denoising algorithms and open research directions for further studies of the domain.
C1 [Kulathilake, K. A. Saneera Hemantha; Abdullah, Nor Aniza] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
   [Kulathilake, K. A. Saneera Hemantha] Rajarata Univ Sri Lanka, Fac Sci Appl, Dept Comp, Mihintale, Sri Lanka.
   [Sabri, Aznul Qalid Md] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Artificial Intelligence, Kuala Lumpur 50603, Malaysia.
   [Bandara, A. M. R. Ravimal] Univ Sri Jayewardenepura, Fac Sci Appl, Dept Comp Sci, Nugegoda, Sri Lanka.
   [Lai, Khin Wee] Univ Malaya, Dept Biomed Engn, Fac Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Rajarata University of Sri Lanka; Universiti Malaya;
   University Sri Jayewardenepura; Universiti Malaya
RP Abdullah, NA (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
EM kule@as.rjt.ac.lk; noraniza@um.edu.my; aznulqalid@um.edu.my;
   ravimal@sjp.ac.lk; lai.khinwee@um.edu.my
RI Amarakoon Mudiyanselage, Randitha Ravimal Bandara/KJM-1197-2024; Lai,
   Khin Wee/A-2997-2011; MD SABRI, AZNUL QALID/AGY-6106-2022; Kulathilake,
   Saneera Hemantha/M-5299-2019; Abdullah, Nor Aniza/B-2768-2010
OI Amarakoon Mudiyanselage, Randitha Ravimal Bandara/0000-0001-8622-9049;
   Lai, Khin Wee/0000-0002-8602-0533; MD SABRI, AZNUL
   QALID/0000-0002-4758-5400; Kulathilake, Saneera
   Hemantha/0000-0003-2514-9285; Abdullah, Nor Aniza/0000-0001-6218-8772
FU Fundamental Research Grant Scheme [FRGS/1/2019/TK04/UM/01/2]; Ministry
   of Higher Education, Malaysia; University of Malaya [IIRG012C-2019];
   World Bank-funded Accelerating Higher Education Expansion and
   Development Operation, Sri Lanka [AHEAD/PhD/R1-PART-2/ENGTECH/105]
FX This work was supported by the Fundamental Research Grant Scheme
   [FRGS/1/2019/TK04/UM/01/2], Ministry of Higher Education, Malaysia, the
   research grant of University of Malaya [IIRG012C-2019], and the World
   Bank-funded Accelerating Higher Education Expansion and Development
   Operation, Sri Lanka [Grant number: AHEAD/PhD/R1-PART-2/ENG&TECH/105].
CR Ai DN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126914
   Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Aja-Fernández S, 2015, MED IMAGE ANAL, V20, P184, DOI 10.1016/j.media.2014.11.005
   Akar SA, 2016, APPL SOFT COMPUT, V43, P87, DOI 10.1016/j.asoc.2016.02.043
   Alkinani Monagi H, 2017, EURASIP J Image Video Process, V2017, P58, DOI 10.1186/s13640-017-0203-4
   [Anonymous], SIGN PROC C 2007 EUR
   Arora S, 2020, PATTERN RECOGN LETT, V139, P1, DOI 10.1016/j.patrec.2018.06.002
   Babu JJJ, 2016, BIOMED SIGNAL PROCES, V23, P93, DOI 10.1016/j.bspc.2015.08.001
   Baselice F, 2018, COMPUT METH PROG BIO, V153, P71, DOI 10.1016/j.cmpb.2017.10.006
   Baselice F, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0319-x
   Bhujle HV, 2019, BIOMED SIGNAL PROCES, V47, P252, DOI 10.1016/j.bspc.2018.08.031
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chang YN, 2015, BIO-MED MATER ENG, V26, pS1275, DOI 10.3233/BME-151425
   Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284
   Chen H, 2017, BIOMED OPT EXPRESS, V8, P679, DOI 10.1364/BOE.8.000679
   Chi JN, 2020, IEEE ACCESS, V8, P133470, DOI 10.1109/ACCESS.2020.3006512
   Chinnathambi V, 2019, IET IMAGE PROCESS, V13, P206, DOI 10.1049/iet-ipr.2018.5011
   Choi K, 2020, IEEE J-STSP, V14, P1137, DOI 10.1109/JSTSP.2020.2998413
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Das P, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101901
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Dorini LB, 2009, 2009 TUTORIALS OF THE XXII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING (SIBGRAPI 2009), P31, DOI 10.1109/SIBGRAPI-Tutorials.2009.11
   Du WC, 2019, IEEE SIGNAL PROC LET, V26, P1152, DOI 10.1109/LSP.2019.2922851
   Du WC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190069
   Elyasi I, 2016, OPTIK, V127, P11732, DOI 10.1016/j.ijleo.2016.09.054
   Fan FL, 2020, IEEE T MED IMAGING, V39, P2035, DOI 10.1109/TMI.2019.2963248
   Fu XW, 2015, ELECTRON LETT, V51, P321, DOI 10.1049/el.2014.3742
   Fu Y, 2016, NEUROCOMPUTING, V195, P30, DOI 10.1016/j.neucom.2015.09.125
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Golshan HM, 2015, IEEE ACM T COMPUT BI, V12, P861, DOI 10.1109/TCBB.2014.2344675
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu J, 2021, IEEE T COMPUT IMAG, V7, P73, DOI 10.1109/TCI.2021.3050266
   Gupta D, 2015, IET IMAGE PROCESS, V9, P107, DOI 10.1049/iet-ipr.2014.0330
   Hashemi S, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/638568
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heydari M, 2016, SIGNAL IMAGE VIDEO P, V10, P1211, DOI 10.1007/s11760-016-0878-5
   Hu K, 2018, BIOMED SIGNAL PROCES, V39, P336, DOI 10.1016/j.bspc.2017.08.014
   Hu K, 2016, MAGN RESON IMAGING, V34, P1128, DOI 10.1016/j.mri.2016.05.011
   Hu ZL, 2019, MED PHYS, V46, P1686, DOI 10.1002/mp.13415
   Huang S, 2019, IMAGING SCI J, V67, P224, DOI 10.1080/13682199.2019.1612589
   Huang ZH, 2018, BIOMED SIGNAL PROCES, V40, P131, DOI 10.1016/j.bspc.2017.09.019
   Irrera P, 2016, MED IMAGE ANAL, V28, P33, DOI 10.1016/j.media.2015.11.002
   Jia L, 2018, IEEE ACCESS, V6, P46179, DOI 10.1109/ACCESS.2018.2862403
   Jiang DS, 2018, JPN J RADIOL, V36, P566, DOI 10.1007/s11604-018-0758-8
   Joel T, 2018, APPL ACOUST, V138, P18, DOI 10.1016/j.apacoust.2018.03.023
   Joseph J, 2018, COMPUT ELECTR ENG, V69, P782, DOI 10.1016/j.compeleceng.2018.02.033
   Kala R, 2020, MULTIMED TOOLS APPL, V79, P15513, DOI 10.1007/s11042-019-7459-x
   Kang E, 2019, MED PHYS, V46, P550, DOI 10.1002/mp.13284
   Kang E, 2018, IEEE T MED IMAGING, V37, P1358, DOI 10.1109/TMI.2018.2823756
   Kang E, 2017, MED PHYS, V44, pe360, DOI 10.1002/mp.12344
   Kang M, 2015, J VIS COMMUN IMAGE R, V32, P180, DOI 10.1016/j.jvcir.2015.08.006
   Kaur P, 2018, CURR MED IMAGING REV, V14, P675, DOI 10.2174/1573405613666170428154156
   Kaur R, 2018, MULTIMED TOOLS APPL, V77, P22735, DOI 10.1007/s11042-017-5500-5
   Khaleel HS, 2018, BIOMED SIGNAL PROCES, V44, P82, DOI 10.1016/j.bspc.2018.04.004
   Kumar A, 2015, APPL OPTICS, V54, P8156, DOI 10.1364/AO.54.008156
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P24405, DOI 10.1007/s11042-017-5592-y
   Kumar M, 2017, BIO-MED MATER ENG, V28, P643, DOI 10.3233/BME-171702
   Kumar PK, 2015, INT J IMAG SYST TECH, V25, P256, DOI 10.1002/ima.22142
   Kwon K, 2016, COMPUT METH PROG BIO, V133, P25, DOI 10.1016/j.cmpb.2016.05.008
   Lee JSJ., 1988, ADAPTIVE IMAGE PROCE, DOI [10.1117/12.942745, DOI 10.1117/12.942745]
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Lee MS, 2017, BIOMED SIGNAL PROCES, V38, P74, DOI 10.1016/j.bspc.2017.05.001
   Lerallut R, 2007, IMAGE VISION COMPUT, V25, P395, DOI 10.1016/j.imavis.2006.04.018
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Li M, 2020, IEEE T MED IMAGING, V39, P2289, DOI 10.1109/TMI.2020.2968472
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu C, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/232389
   Liu Y, 2018, NEUROCOMPUTING, V284, P80, DOI 10.1016/j.neucom.2018.01.015
   Lu CT, 2018, COMPUT ELECTR ENG, V71, P862, DOI 10.1016/j.compeleceng.2017.08.012
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Lv HL, 2019, IEEE ACCESS, V7, P85995, DOI 10.1109/ACCESS.2019.2924907
   Ma YJ, 2020, IEEE ACCESS, V8, P67519, DOI 10.1109/ACCESS.2020.2986388
   Manjón JV, 2015, MED IMAGE ANAL, V22, P35, DOI 10.1016/j.media.2015.01.004
   Mao XJ, 2016, ADV NEUR IN, V29
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Martin-Fernandez M, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/182659
   Mishra D, 2018, IEEE SIGNAL PROC LET, V25, P1349, DOI 10.1109/LSP.2018.2858147
   Park HS, 2019, IEEE ACCESS, V7, P110414, DOI 10.1109/ACCESS.2019.2934178
   Periyasamy N, 2018, CURR MED IMAGING, V14, P521, DOI 10.2174/1573405613666170118102821
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Phophalia A, 2015, APPL SOFT COMPUT, V33, P1, DOI 10.1016/j.asoc.2015.04.005
   Prasath VBS, 2017, INFORMATICA-LITHUAN, V28, P505, DOI 10.15388/Informatica.2017.141
   Rajan J, 2010, PHYS MED BIOL, V55, pN441, DOI 10.1088/0031-9155/55/16/N02
   Ran MS, 2019, MED IMAGE ANAL, V55, P165, DOI 10.1016/j.media.2019.05.001
   Rawat N, 2019, WIRELESS PERS COMMUN, V106, P1547, DOI 10.1007/s11277-019-06229-w
   Renuka SV, 2019, BIOCYBERN BIOMED ENG, V39, P133, DOI 10.1016/j.bbe.2018.11.003
   Riji R, 2015, SIGNAL IMAGE VIDEO P, V9, P1543, DOI 10.1007/s11760-013-0611-6
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sa-ing V, 2018, IET IMAGE PROCESS, V12, P105, DOI 10.1049/iet-ipr.2017.0391
   Saadia A, 2016, COMPUT METH PROG BIO, V137, P65, DOI 10.1016/j.cmpb.2016.09.006
   Sagheer SVM, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102036
   Sagheer SVM, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101595
   Sagheer SVM, 2019, ARTIF INTELL MED, V94, P1, DOI 10.1016/j.artmed.2018.12.006
   Sagheer SVM, 2017, BIOMED SIGNAL PROCES, V38, P236, DOI 10.1016/j.bspc.2017.06.011
   Saladi S, 2017, INT J IMAG SYST TECH, V27, P201, DOI 10.1002/ima.22225
   Shan HM, 2018, IEEE T MED IMAGING, V37, P1522, DOI 10.1109/TMI.2018.2832217
   Sharif M, 2016, SIGNAL IMAGE VIDEO P, V10, P215, DOI 10.1007/s11760-014-0729-1
   Sharma A, 2019, ADV INTELL SYST COMP, V748, P707, DOI 10.1007/978-981-13-0923-6_60
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Sree SJ, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S0218126619501500
   Sudeep PV, 2015, BIOMED SIGNAL PROCES, V20, P125, DOI 10.1016/j.bspc.2015.04.015
   Tang C, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/8639825
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Veraart J, 2016, MAGN RESON MED, V76, P1582, DOI 10.1002/mrm.26059
   Wang H, 2019, J MAGN RESON IMAGING, V50, P1937, DOI 10.1002/jmri.26761
   Wang YB, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae511
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Wu D., 2017, ARXIV
   Xia Y, 2017, BIOMED SIGNAL PROCES, V34, P183, DOI 10.1016/j.bspc.2017.01.016
   Xiao LM, 2016, NEUROCOMPUTING, V195, P56, DOI 10.1016/j.neucom.2015.08.113
   Yang LL, 2020, IEEE ACCESS, V8, P930, DOI 10.1109/ACCESS.2019.2961983
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Yang S, 2015, INT J IMAG SYST TECH, V25, P15, DOI 10.1002/ima.22116
   Yang W, 2017, IEEE ACCESS, V5, P24698, DOI 10.1109/ACCESS.2017.2766438
   Yap KH, 2009, ADAPTIVE IMAGE PROCE
   Yi X, 2018, J DIGIT IMAGING, V31, P655, DOI 10.1007/s10278-018-0056-0
   Yin XR, 2019, IEEE T MED IMAGING, V38, P2903, DOI 10.1109/TMI.2019.2917258
   Yin ZX, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010126
   You CY, 2018, IEEE ACCESS, V6, P41839, DOI 10.1109/ACCESS.2018.2858196
   Yuan JJ, 2018, COMPUT MATH APPL, V76, P2212, DOI 10.1016/j.camwa.2018.05.044
   Yuan Y, 2018, J COMPUT ASSIST TOMO, V42, P972, DOI 10.1097/RCT.0000000000000805
   Yuan ZX, 2017, J MED IMAG HEALTH IN, V7, P288, DOI 10.1166/jmihi.2017.2021
   Zhang J, 2017, CIRC SYST SIGNAL PR, V36, P297, DOI 10.1007/s00034-016-0305-8
   Zhang J, 2015, BIOMED SIGNAL PROCES, V18, P1, DOI 10.1016/j.bspc.2014.11.010
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YB, 2019, J X-RAY SCI TECHNOL, V27, P397, DOI 10.3233/XST-180413
   Zhao TT, 2019, MED PHYS, V46, P190, DOI 10.1002/mp.13252
   Zhou ZX, 2020, IEEE T BIO-MED ENG, V67, P298, DOI 10.1109/TBME.2019.2912986
NR 130
TC 9
Z9 9
U1 8
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37591
EP 37626
DI 10.1007/s11042-022-13511-w
EA AUG 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000836084200004
DA 2024-07-18
ER

PT J
AU Jindal, B
   Garg, S
AF Jindal, Balkrishan
   Garg, Shelly
TI FIFE: fast and indented feature extractor for medical imaging based on
   shape features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Feature extraction; Shape descriptors; Skin lesions
AB The advancement in technology also upgraded the biomedical field and enhanced the diagnostic system performance, where medical imaging plays its inevitable role. Several image processing techniques created the medical systems automated and meticulous. These systems nowadays support physicians in identifying adverse diseases like cancer, tumor, and skin diseases. In this imaging, features have a significant role in visually performing the diagnostic and finding the suffered area. Moreover, it also improves the performance of the automatic recognition systems used in the medical field. The researchers proposed various feature extraction techniques that use color, texture, and shape-based features in image processing systems but not every feature is best suited for medical imaging. This paper covers the objective of providing a Fast and Indented Feature Extractor (FIFE) for the health care sector's future. This proposed extractor extracts only relevant shape features for processing to reduce processing time and improve the result's quality. The image samples are taken for a skin disease named skin lesions for this work. The dataset of ISIC and PH2 is used in this work for analysis. This FIFE works on multiple feature extraction approaches and blends them to form a distinct extraction level. The indentation level one, two, three, and four are used in this work using four different shape descriptors, namely SURF, FAST, BRISK, and ORB. The performance comparison of the proposed indentation levels is based on the number of features and time. The experimentation results are evaluated with qualitative and quantitative measures that reveal the proposed extractor's efficiency.
C1 [Jindal, Balkrishan] Punjabi Univ, Yadavindra Coll Engn, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
   [Garg, Shelly] Punjabi Univ, Dept Elect & Commun, Patiala 147002, Punjab, India.
C3 Punjabi University; Punjabi University
RP Garg, S (corresponding author), Punjabi Univ, Dept Elect & Commun, Patiala 147002, Punjab, India.
EM balkrishan_76@rediffmail.com; shellygarg96@gmail.com
OI , Shelly Garg/0000-0002-5139-472X
CR Abuzaghleh O, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Ali AR, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234352
   Almeida MAM, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060051
   Basavaiah J., 2020, Int. J. Intell. Eng. Syst, V13, P13, DOI [10.22266/ijies2020.0229.02, DOI 10.22266/IJIES2020.0229.02]
   Bhuiyan A, 2013, Int. J. Sci. Eng. Res, V4, P1
   Cao DY, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00219-9
   Chatterjee S., 2021, WHAT IS FEATURE EXTR
   Cheng YI, 2008, SKIN RES TECHNOL, V14, P53, DOI 10.1111/j.1600-0846.2007.00261.x
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Chuanping Geng, 2020, Journal of Physics: Conference Series, V1616, DOI 10.1088/1742-6596/1616/1/012026
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Erol R, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1892-5
   Garg S, 2021, MULTIMED TOOLS APPL, V80, P7397, DOI 10.1007/s11042-020-10064-8
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hidalgo F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154343
   Hwang SW, 2020, J WOOD SCI, V66, DOI 10.1186/s10086-020-01864-5
   ISIC archive, 2016, US
   Janney B., 2017, BIOMEDICINE INDIA, V37, P214
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Kumar A, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01826-x
   Li MH, 2020, IEEE ACCESS, V8, P130607, DOI 10.1109/ACCESS.2020.3000902
   librosa Development Team, 2021, FEATURE EXTRACTION A
   Mahmoud H, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE' 2018), P140, DOI 10.1109/ITCE.2018.8327948
   Mankowitz DJ, 2014, LECT NOTES ARTIF INT, V8371, P195, DOI 10.1007/978-3-662-44468-9_18
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Murumkar OS., 2015, INT J SCI ENG TECH R, V4, P1645
   Pathan S., 2019, BIOMED PHARMACOL J, V12, P107, DOI [10.13005/bpj/1619, DOI 10.13005/bpj/1619]
   Qu Xin, 2010, Acta Automatica Sinica, V36, P785, DOI 10.3724/SP.J.1004.2010.00785
   Sasikala N, 2020, EUR J ELECT ENG COMP, P4
   Vijayan Vineetha, 2020, Procedia Computer Science, V171, P436, DOI 10.1016/j.procs.2020.04.046
   Vinay A, 2015, PROCEDIA COMPUT SCI, V58, P614, DOI 10.1016/j.procs.2015.08.080
   Warsi Firoz, 2019, Informatics in Medicine Unlocked, V17, P257, DOI 10.1016/j.imu.2019.100176
   Wei LS, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/8145713
   Yang M., 2012, Advances in Reasoning-Based Image Processing Intelligent Systems, P255
   Yuvaraju M., 2015, International Journal of Research in Electrical & Electronics Engineering, V3, P1
   Zaqout I, 2019, PATTERN RECOGN
NR 36
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6053
EP 6069
DI 10.1007/s11042-022-13589-2
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400002
DA 2024-07-18
ER

PT J
AU Singh, R
   Rajpal, N
   Mehta, R
AF Singh, Ritu
   Rajpal, Navin
   Mehta, Rajesh
TI Non-invasive Single Channel integration model for fetal ECG extraction
   and sustainable fetal healthcare using wavelet framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fetal ECG extraction; Fetal ECG morphological analysis; Non-invasive
   single channel integration technique (NSCIT); Adaptive filtering;
   Wavelet transform
ID HEART-RATE; ABDOMINAL ECG; COMPONENTS; SEPARATION; SIGNAL
AB A retrospective aspect of prenatal complexities during pregnancy and advancements in technology shows the need for unscathed fetal ECG extraction from a single mother abdominal ECG (abdECG). The proposed work introduces a Non-invasive Single Channel Integration Technique (NSCIT) depicting a cumulative trapezoidal mathematical model with an LMS adaptive algorithm for mother and fetal ECG extraction with improved Signal-to-Noise Ratio (SNR). Besides separation, fetal ECG (fECG) features are extracted, simulated, analyzed, and compared with standards to generate fetus cardiac growth during later Gestation Period (GP) of 21st to 40th week of pregnancy. The variants of the wavelet transform, such as Dual-Tree Complex Wavelet Transform (DTCWT) for pre-processing and Maximal Overlap Discrete Wavelet Transform (MODWT) for post-processing, are exploited using a multi-resolution analysis. The NSCIT algorithm with LMS adaptive technique has shown 100% accuracy for detecting mother ECG and specific fetal ECG extraction channels. The improved accuracy using abdominal lead 4 is 96.36%, and overall abdominal mixed lead accuracy is 93.32% compared with recent existing literature. The maximum error in comparing Power Spectral Density (PSD) of actual and extracted fECG and mECG is significantly less. The calculated correlation coefficient between actual and extracted fetal QRS width, fetal R-peak intervals (R-R), and fetal heart rate (fHR) for Db1 are 0.70, 0.99, and 0.67, respectively. The research outcomes show that fECG SNR increases with GP, and it is maximum for the GP of 40th week. This fECG morphological analysis before childbirth will efficaciously contribute to sustainable fetal healthcare.
C1 [Singh, Ritu; Rajpal, Navin] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi, India.
   [Mehta, Rajesh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Bhadson Rd, Patiala 147001, Punjab, India.
C3 GGS Indraprastha University; Thapar Institute of Engineering &
   Technology
RP Singh, R (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi, India.
EM ritumtech@gmail.com; navin.rajpal@ipu.ac.in; rajesh.mehta@thapar.edu
CR Abbas R, 2018, LECT NOTES ARTIF INT, V10956, P767, DOI 10.1007/978-3-319-95957-3_81
   Almeida R, 2014, PHYSIOL MEAS, V35, P1723, DOI 10.1088/0967-3334/35/8/1723
   Azzerboni B., 2005, P EUR S ART NEUR NET, P193
   Behar J, 2013, COMPUT CARDIOL CONF, V40, P297, DOI 10.1049/iet-tv.41.18108
   Behar J, 2014, PHYSIOL MEAS, V35, P1569, DOI 10.1088/0967-3334/35/8/1569
   Behar J, 2014, ANN BIOMED ENG, V42, P1340, DOI 10.1007/s10439-014-0993-9
   Bin Queyam A, 2017, TECHNOLOGIES, V5, DOI 10.3390/technologies5040068
   Castillo E, 2013, DIGIT SIGNAL PROCESS, V23, P1897, DOI 10.1016/j.dsp.2013.07.010
   Clifford GD, 2014, PHYSIOL MEAS, V35, P1521, DOI 10.1088/0967-3334/35/8/1521
   Fergus P, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0378-z
   Georgieva A, 2013, NEURAL COMPUT APPL, V22, P85, DOI 10.1007/s00521-011-0743-y
   Ghorat M, 2018, IEEE T INSTRUM MEAS, V67, P2262, DOI 10.1109/TIM.2018.2816438
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gupta P, 2016, COMPUT BIOL MED, V68, P121, DOI 10.1016/j.compbiomed.2015.11.007
   Gustafsson F, 1996, IEEE T SIGNAL PROCES, V44, P988, DOI 10.1109/78.492552
   Hafez AG, 2013, IEEE T GEOSCI REMOTE, V51, P1547, DOI 10.1109/TGRS.2012.2207962
   Haykin Simon S., 2005, ADAPTIVE FILTER THEO
   Jezewski J, 2012, BIOMED ENG-BIOMED TE, V57, P383, DOI 10.1515/bmt-2011-0130
   John RG, 2019, COMPUT METH PROG BIO, V175, P193, DOI 10.1016/j.cmpb.2019.04.022
   Kahankova R, 2020, IEEE REV BIOMED ENG, V13, P51, DOI 10.1109/RBME.2019.2938061
   Kahankova R, 2017, ADV ELECTR ELECTRON, V15, P491, DOI 10.15598/aeee.v15i3.2207
   Kaleem AM, 2019, LECT NOTES ELECTR EN, V545, P187, DOI 10.1007/978-981-13-5802-9_17
   Khamene A, 2000, IEEE T BIO-MED ENG, V47, P507, DOI 10.1109/10.828150
   Khandoker A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31898-1
   Li S, 2017, FRONT APPL MATH STAT, V3, P2, DOI DOI 10.3389/FAMS.2017.00002
   Liu H, 2019, IEEE ACCESS, V7, P66633, DOI 10.1109/ACCESS.2019.2917826
   Martinek R, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2018), P23, DOI 10.1145/3177457.3177502
   O'Haver ThomasC., 2016, PRAGMATIC INTRO SIGN
   Paarmann L.D., 2001, DESIGN ANAL ANALOG F
   Panigrahy D, 2017, AUSTRALAS PHYS ENG S, V40, P191, DOI 10.1007/s13246-017-0527-5
   Percival DB, 1997, J AM STAT ASSOC, V92, P868, DOI 10.2307/2965551
   Rooijakkers MJ, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2452266
   Sana F, 2019, BIOMED SIGNAL PROCES, V48, P46, DOI 10.1016/j.bspc.2018.08.023
   Singh R, 2020, J INFORM OPTIM SCI, V41, P107, DOI 10.1080/02522667.2020.1715562
   Singh R, 2020, LECT NOTES ELECTR EN, V605, P490, DOI 10.1007/978-3-030-30577-2_43
   Spilka J, 2017, IEEE J BIOMED HEALTH, V21, P664, DOI 10.1109/JBHI.2016.2546312
   Stout MJ, 2011, CLIN PERINATOL, V38, P127, DOI 10.1016/j.clp.2010.12.002
   Trivedi N, 2012, J ULTRAS MED, V31, P389, DOI 10.7863/jum.2012.31.3.389
   Wang YX, 2010, MECH SYST SIGNAL PR, V24, P119, DOI 10.1016/j.ymssp.2009.06.015
   Yu FY, 2008, COMPUT BIOL MED, V38, P635, DOI 10.1016/j.compbiomed.2008.02.004
   Yu Q, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/11/118702
   Yujing Sun, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286350
   Zarzoso V, 1997, IMA J MATH APPL MED, V14, P207
   Zarzoso V, 2001, IEEE T BIO-MED ENG, V48, P12, DOI 10.1109/10.900244
   Zhang NN, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030457
   Zhang Y, 2020, MED BIOL ENG COMPUT, V58, P419, DOI 10.1007/s11517-019-02087-7
   Zheng W, 2010, MED ENG PHYS, V32, P708, DOI 10.1016/j.medengphy.2010.04.012
   Zhong W, 2019, AUSTRALAS PHYS ENG S, V42, P1081, DOI 10.1007/s13246-019-00805-x
   Zhong W, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aab297
   Zhu L, 2014, APPL MATH MODEL, V38, P1859, DOI 10.1016/j.apm.2013.10.002
NR 50
TC 3
Z9 3
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39669
EP 39695
DI 10.1007/s11042-022-13534-3
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000835601400003
DA 2024-07-18
ER

PT J
AU Ullah, I
   Khusro, S
AF Ullah, Irfan
   Khusro, Shah
TI On the analysis and evaluation of information retrieval models for
   social book search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Retrieval models; Book retrieval; Social book
   search; Social metadata
ID PROBABILISTIC MODEL; DIVERGENCE; EXPANSION
AB Social Book Search (SBS) studies how the Social Web impacts book retrieval. This impact is studied in two steps. In this first step, called the baseline run, the search index having bibliographic descriptions or professional metadata and user-generated content or social metadata is searched against the search queries and ranked using a retrieval model. In the second step, called re-ranking, the baseline search results are re-ordered using social metadata to see if the search relevance improves. However, this improvement in the search relevance can only be justified if the baseline run is made stronger by considering the contribution of the query, index, and retrieval model. Although the existing studies well-explored the role of query formulation and document representation, only a few considered the contribution of the retrieval models. Also, they experimented with a few retrieval models. This article fills this gap in the literature. It identifies the best retrieval model in the SBS context by experimenting with twenty-five retrieval models using the Terrier IR platform on the Amazon/LibraryThing dataset holding topic sets, relevance judgments, and a book corpus of 2.8 million records. The findings suggest that these retrieval models behave differently with changes in query and document representation. DirichletLM and InL2 are the best-performing retrieval models for a majority of the retrieval runs. The previous best-performing SBS studies would have produced better results if they had tested multiple retrieval models in selecting baseline runs. The findings confirm that the retrieval model plays a vital role in developing stronger baseline runs.
C1 [Ullah, Irfan] Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal 18050, Pakistan.
   [Khusro, Shah] Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
C3 University of Peshawar
RP Ullah, I (corresponding author), Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal 18050, Pakistan.
EM irfan@sbbu.edu.pk; khusro@uop.edu.pk
RI Khusro, Shah/C-1661-2014; Ullah, Irfan/C-9213-2014
OI Khusro, Shah/0000-0002-7734-7243; Ullah, Irfan/0000-0003-0693-5467
CR Ahmad A., 2019, P 2 WORKSH MACH READ, P137
   Amati G., 2002, ACM Transactions on Information Systems, V20, P357, DOI 10.1145/582415.582416
   Amati G., 2003, THESIS U GLASGOW GLA
   Amati G, 2007, NIST SPECIAL PUBLICA
   Amati G, 2006, LECT NOTES COMPUT SC, V3936, P13
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 2015, CEUR WORKSHOP PROC
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], LIB SCI INFORM SCI
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], 2001, UNPUB
   [Anonymous], 2013, CEUR WORKSHOP PROC
   Badache I, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P155, DOI 10.1145/3020165.3020177
   Bellot P., 2014, INFORM ACCESS EVALUA, V8685, P212, DOI DOI 10.1007/978-3-319-11382-1_19
   Bellot P, 2013, LECT NOTES COMPUT SC, V8138, P269, DOI 10.1007/978-3-642-40802-1_27
   Benkoussas C, 2015, WORKING NOTES CLEF 2, V1391, P1
   Benkoussas Chahinez, 2015, ScientificWorldJournal, V2015, P926418, DOI 10.1155/2015/926418
   Bogers T., 2012, INEX 2011, P45, DOI DOI 10.1007/978-3-642-35734-3_3
   Bogers T, 2012, WORKING NOTES CLEF 2, P1
   Cao B, 2019, WORLD WIDE WEB, V22, P637, DOI 10.1007/s11280-018-0554-5
   Chaa M, 2018, LECT NOTES COMPUT SC, V11018, P64, DOI 10.1007/978-3-319-98932-7_6
   Chaa M, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P799, DOI 10.1145/3106426.3106481
   Chaa Messaoud, 2016, CLEF CEUR WORKSHOP P, P1072
   Clinchant S, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P234
   Clinchant S, 2009, LECT NOTES COMPUT SC, V5766, P54, DOI 10.1007/978-3-642-04417-5_6
   Croft W. B., 2010, SEARCH ENGINES INFOR
   Dincer B. T., 2012, 21 TEXT RETRIEVAL C
   Ettaleb M, 2018, PROCEDIA COMPUT SCI, V126, P768, DOI 10.1016/j.procs.2018.08.011
   Feng S.-H, 2016, WORKING NOTES CLEF 2, V1609, P1089
   Hashemi H, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P55, DOI 10.1145/3341981.3344249
   Hiemstra D., 2001, THESIS
   Holur P, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210797
   Htait Amal, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P29, DOI 10.1145/3409256.3409847
   Imhof M, 2016, CLEF 2016 C LABS EV, P1123
   Imhof M, 2018, INFORM RETRIEVAL J, V21, P81, DOI 10.1007/s10791-017-9322-x
   Khalid S, 2020, ENG TECHNOL APPL SCI, V10, P6102
   Khalid S, 2021, J INF SCI, V47, P3, DOI 10.1177/0165551519863346
   Khalid S, 2019, ENG TECHNOL APPL SCI, V9, P3862
   Khusro S, 2016, 2016 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P106, DOI 10.1109/ICOSST.2016.7838586
   Kocabas I, 2014, INFORM RETRIEVAL, V17, P153, DOI 10.1007/s10791-013-9225-4
   Koolen M, 2016, LECT NOTES COMPUT SC, V9822, P351, DOI 10.1007/978-3-319-44564-9_29
   Koolen M, 2015, LECT NOTES COMPUT SC, V9283, P545, DOI 10.1007/978-3-319-24027-5_51
   Kumar R, 2016, CLEF 2016 C LABS EV, P1130
   Kumar R, 2020, ARTIF INTELL REV, V53, P95, DOI 10.1007/s10462-018-9647-x
   Macdonald C., 2005, P TREC 2005
   Macdonald C, 2020, DOCUMENTATION TERRIE
   Macdonald C, 2006, LECT NOTES COMPUT SC, V4022, P898
   Macdonald Craig, 2012, P OSIR SIGIR, P60
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472, DOI 10.1145/1076034.1076115
   Metzler D, 2004, INFORM PROCESS MANAG, V40, P735, DOI 10.1016/j.ipm.2004.05.001
   Ould-Amer N, 2016, WORKING NOTES CLEF 2, V1609, P1136
   Ould-Amer N, 2015, CEUR WORKSHOP PROC, P4
   Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517
   Ounis I., 2006, P 29 ACM C RES DEV I, P18
   Ounis I., 2007, Novatica/UPGRADE Special Issue on Web Information Access, V8, P49
   Pannu M., 2014, W CANADIAN C COMPUTI, P1, DOI DOI 10.1145/2597959.2597978
   Plachouras V, 2007, LECT NOTES COMPUT SC, V4425, P28
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Pradhan T, 2020, FUTURE GENER COMP SY, V110, P1139, DOI 10.1016/j.future.2019.11.017
   Ren J, 2021, IEEE T EM TOP COMP I, V5, P332, DOI 10.1109/TETCI.2021.3067655
   Robertson S., 2004, P 13 ACM INT C INF K, P42
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Robertson S. E., 1999, Seventh Text REtrieval Conference (TREC-7) (NIST SP 500-242), P253
   Rücklé A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3179, DOI 10.1145/3308558.3313502
   Singhal Amit, 2017, ACM SIGIR Forum, V51, P176, DOI 10.1145/3130348.3130365
   Singhal A., 1999, Seventh Text REtrieval Conference (TREC-7) (NIST SP 500-242), P239
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P809, DOI 10.1016/S0306-4573(00)00016-9
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P779, DOI 10.1016/S0306-4573(00)00015-7
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Ullah, 2020, THESIS U PESHAWAR PA
   Ullah I, 2021, MULTIMED TOOLS APPL, V80, P5131, DOI 10.1007/s11042-020-09811-8
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P8011, DOI 10.1007/s11042-019-08591-0
   Ullah I, 2016, ADV INTELL SYST, V464, P347, DOI 10.1007/978-3-319-33625-1_31
   Vishwakarma SK, 2015, PROCEDIA COMPUT SCI, V57, P815, DOI 10.1016/j.procs.2015.07.484
   Wu HZ, 2008, LECT NOTES COMPUT SC, V4956, P234
   Wu S-H, 2016, WORKING NOTES CLEF 2, V1609, P1155
   Yin XC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148479
   Zaragoza H, 2004, P 13 TEXT RETR C TRE, P7
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 81
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6431
EP 6478
DI 10.1007/s11042-022-13417-7
EA JUL 2022
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000830967300003
DA 2024-07-18
ER

PT J
AU Khattar, A
   Quadri, SMK
AF Khattar, Anuradha
   Quadri, S. M. K.
TI Multi-source domain adaptation of social media data for disaster
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Multi-source domain adaptation; Deep convolutional
   neural network (DCNN); Disaster management; Social media; Twitter
AB Labeled data scarcity at the time of an ongoing disaster has encouraged the researchers to use the labeled data from some previous disaster for training and transferring the knowledge to the current disaster task using Domain Adaptation (DA). However, often labeled data from more than one previous disaster may be available. As all deep learning models are data-hungry and perform better if fed with more annotated data, it is advisable to use data from multiple sources for training a Deep Convolutional Neural Network (DCNN). One of the easiest ways is to simply combine the data from multiple sources and use it for training. However, this arrangement is not that straightforward. The models trained on the combined data from various sources do not perform well on the target, mainly due to distribution discrepancies between multiple sources. This has motivated us to explore the challenging area of multi-source domain adaptation for disaster management. The aim is to learn the domain invariant features and representations across the domains and transfer more related knowledge to solve the target task with improved accuracy than single-source or combined-source domain adaptation. This study proposes a Multi-Source Domain Adaptation framework for Disaster Management (MSDA-DM) to classify disaster images posted on social media based on unsupervised DA with adversarial training. The empirical results obtained confirm that the proposed model MSDA-DM performs better than single-source DA by up to 10.83% and combined-source DA by up to 5.06% in terms of F1-score for different sets of source and target disaster domains. We also compare our model with current state-of-the-art models. The main challenge of multi-source DA is the choice of the relevant sources taken for training since, unlike single-source DA that handles only source-target distribution drift, the multi-source DA network has to address both source-target and source-source distribution drifts.
C1 [Khattar, Anuradha; Quadri, S. M. K.] Jamia Millia Islamia, Fac Nat Sci, Dept Comp Sci, New Delhi, India.
C3 Jamia Millia Islamia
RP Khattar, A (corresponding author), Jamia Millia Islamia, Fac Nat Sci, Dept Comp Sci, New Delhi, India.
EM anuradha.khattar@mirandahouse.ac.in; quadrismk@jmi.ac.in
RI Quadri, S M K/GVS-6474-2022; Khattar, Anuradha/JUV-1552-2023
OI Khattar, Anuradha/0000-0003-0089-7068
CR Alam F., 2018, P INT AAAI C WEB SOC, P556
   Alam F, 2018, 12 INT AAAI C WEB SO, P465, DOI DOI 10.1609/ICWSM.V12I1.14983
   Alam F, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1077
   Alam F, 2018, INT J HUM-COMPUT INT, V34, P311, DOI 10.1080/10447318.2018.1427831
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bengio Yoshua, 2012, P ICML WORKSH UNS TR, P17
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Chen ZL, 2021, INT J COMPUT VISION, V129, P2328, DOI 10.1007/s11263-021-01463-x
   Dai Y, 2020, AAAI CONF ARTIF INTE, V34, P7618
   Fan C, 2020, IEEE ACCESS, V8, P10478, DOI 10.1109/ACCESS.2020.2965550
   Ganin Y, 2017, ADV COMPUT VIS PATT, P189, DOI 10.1007/978-3-319-58347-1_10
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   GHIFARY M, 2016, LECT NOTES COMPUT SC, P1
   Ghosh S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1629, DOI 10.1145/3184558.3191621
   Ghosh S, 2018, INFORM SYST FRONT, V20, P901, DOI 10.1007/s10796-018-9878-z
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hiltz SR, 2020, INT J DISAST RISK RE, V42, DOI 10.1016/j.ijdrr.2019.101367
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Imran M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102261
   Imran M, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2771588
   Joseph JK, 2018, INTEGRATING DISASTER SCIENCE AND MANAGEMENT: GLOBAL CASE STUDIES IN MITIGATION AND RECOVERY, P287, DOI 10.1016/B978-0-12-812056-9.00016-6
   Karimpour M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01093-2
   Khattar Anuradha, 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P245, DOI 10.1007/978-981-15-9509-7_21
   KHATTAR A, 2022, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-022-12869-1
   Khattar A, 2020, INT C INN COMP COMM, DOI [10.2139/ssrn.3562973, DOI 10.2139/SSRN.3562973]
   Khattar A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1190, DOI [10.1109/ICICCS48265.2020.9120955, 10.1109/iciccs48265.2020.9120955]
   Laparra E, 2020, JAMIA OPEN, V3, P146, DOI 10.1093/jamiaopen/ooaa010
   Li H, 2015, PROCEEDINGS OF THE 22ND INTERNATIONAL CONGRESS ON SOUND AND VIBRATION
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Li X., 2019, P 16 INT C INF SYST, P633
   Li X, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-018-37508-4, 10.1038/s41598-019-42157-2]
   Liu HJ, 2021, MULTIMED TOOLS APPL, V80, P29321, DOI 10.1007/s11042-021-11139-w
   Madichetty S, 2021, MULTIMED TOOLS APPL, V80, P3927, DOI 10.1007/s11042-020-09873-8
   Madichetty S, 2020, MULTIMED TOOLS APPL, V79, P28901, DOI 10.1007/s11042-020-09343-1
   Madichetty S, 2019, INT CONF COMMUN SYST, P709, DOI [10.1109/COMSNETS.2019.8711095, 10.1109/comsnets.2019.8711095]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pandey N, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1352, DOI 10.1109/ICACCI.2016.7732236
   Paszke A, 2019, ADV NEUR IN, V32
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   Phengsuwan J, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020046
   Pizzati F, 2020, IEEE WINT CONF APPL, P2979, DOI 10.1109/WACV45572.2020.9093540
   Popel M, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18073-9
   Public Health England, 2021, SARS COV 2 VAR CONC
   Robertson BW, 2019, PROG DISASTER SCI, V2, DOI 10.1016/j.pdisas.2019.100030
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sebag A. S., 2019, PROC 12 INT S VIS IN, P1
   SHEN J, 2018, 32 AAAI C ART INT, DOI DOI 10.5555/3504035.350453
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Tang JT, 2021, INT J DISAST RISK RE, V55, DOI 10.1016/j.ijdrr.2021.102095
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Zhang NS, 2021, ANN MATH ARTIF INTEL, V89, P237, DOI 10.1007/s10472-020-09716-0
   Zhou Q, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106569
   Zhu YC, 2019, AAAI CONF ARTIF INTE, P5989
NR 57
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9083
EP 9111
DI 10.1007/s11042-022-13456-0
EA JUL 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000828262900002
PM 35874324
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Aziz, RM
   Desai, NP
   Baluch, MF
AF Aziz, Rabia Musheer
   Desai, Nishq Poorav
   Baluch, Mohammed Farhan
TI Computer vision model with novel cuckoo search based deep learning
   approach for classification of fish image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuckoo search (CS); Genetic algorithm (GA); Deep learning artificial
   neural network (DLANN); Fish image classification; Optimization
   technique
ID INDEPENDENT COMPONENT SUBSPACE; FEATURE-SELECTION
AB Fish is one of the most important cold-blooded animal groups. Fish is an important part of a healthy diet since it contains several minerals and micronutrients that are necessary for general body development. Because different kinds of fish have varied symptoms when it comes to sickness and decay, it's critical that we be able to identify and classify the most essential fish species. Traditional methods in this domain are now tedious and slow, however systems based on better deep learning techniques can overcome them. This study proposed a Deep Learning Artificial Neural Network (DLANN) model with a novel optimization technique for fish image classification. The success of DLANN is primarily attributed to its architecture, the optimization technique used, and the tuning of hyperparameters to identify different patterns in data. The Cuckoo Search (CS) algorithm is a popular nature-inspired optimization technique used to solve real-time science and engineering problems. In this paper, to overcome the shortcoming of CS by introducing a Genetic Algorithm (GA) in the exploration phase of the CS approach. A new optimization technique (GA-CS) has been proposed for DLANN to solve problems in fish image classification. An extensive experiment was conducted to compare the performance of the proposed techniques with several popular (EfficientNet, Inception V3, ResNet150 V2, VGG-19, DenseNet 121, LSTM Model, and a personalized Convolutional Neural Network (CNN) model) techniques of deep learning. Experimental results with different evaluation matrices (classification accuracy, recall, precision, standard deviation, and F1- Scores) show that the proposed optimization technique with deep learning gives the best result for fish image classification.
C1 [Aziz, Rabia Musheer; Desai, Nishq Poorav; Baluch, Mohammed Farhan] VIT Bhopal Univ, Bhopal Indore Highway, Sehore 466116, MP, India.
C3 VIT Bhopal University
RP Aziz, RM (corresponding author), VIT Bhopal Univ, Bhopal Indore Highway, Sehore 466116, MP, India.
EM rabia.aziz2010@gmail.com
RI Aziz, RABIA Musheer/AAN-4234-2020
OI Aziz, RABIA Musheer/0000-0003-2655-7272
CR Allken V, 2019, ICES J MAR SCI, V76, P342, DOI 10.1093/icesjms/fsy147
   Almero VJD, 2020, IEEE RIVF INT CONF, P166, DOI 10.1109/rivf48685.2020.9140795
   [Anonymous], 2018, Tech. Rep.
   [Anonymous], 2015, INT J BIOINFORM RES, DOI DOI 10.1007/S00607-021-01008-7
   Aziz R., 2018, Ann. Data Sci, V5, P615, DOI [10.1007/s40745-018-0155-2, DOI 10.1007/S40745-018-0155-2]
   Aziz Rabia Musheer, 2022, International Journal of Information Technology, P3321, DOI 10.1007/s41870-022-00864-6
   Aziz R, 2017, COMPUT BIOL CHEM, V71, P161, DOI 10.1016/j.compbiolchem.2017.10.009
   Aziz R, 2017, INT J DATA MIN BIOIN, V17, P42, DOI 10.1504/IJDMB.2017.10004926
   Aziz R, 2015, INT J ADV BIOTECHNOL, V6, P245
   Aziz R, 2016, GENOM DATA, V8, P4, DOI 10.1016/j.gdata.2016.02.012
   Aziz RM, 2022, SOFT COMPUT, V26, P12179, DOI 10.1007/s00500-022-07032-9
   Aziz RM, 2022, KARBALA INT J MOD SC, V8, P1, DOI [DOI 10.33640/2405-609X.3197, 10.33640/2405-609X.3197]
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Desai NP., 2022, Turk J Comput Math Educ, V13, P85
   Fink O, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103678
   Han Y, 2022, MULTIMED TOOLS APPL, V81, P19429, DOI 10.1007/s11042-021-11307-y
   Hridayami Praba, 2019, Journal of Computing Science and Engineering, V13, P124, DOI 10.5626/JCSE.2019.13.3.124
   Hulse SV, 2022, ECOL INFORM, V67, DOI 10.1016/j.ecoinf.2021.101486
   Iqbal MA, 2021, WIRELESS PERS COMMUN, V116, P1043, DOI 10.1007/s11277-019-06634-1
   Isçimen B, 2015, SIG PROCESS COMMUN, P1981, DOI 10.1109/SIU.2015.7130252
   Jalal A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101088
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kim YW, 2020, PATTERN RECOGN IMAGE, V30, P372, DOI 10.1134/S1054661820030116
   Li X, 2015, OCEANS 2015 MTS IEEE, P1
   Lopez-Vazquez V, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030726
   Malik S, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P55, DOI 10.1109/SIPROCESS.2017.8124505
   Martin JM, 2019, SCI TOTAL ENVIRON, V650, P1771, DOI 10.1016/j.scitotenv.2018.09.294
   Mathur M, 2020, MULTIMED TOOLS APPL, V79, P31625, DOI 10.1007/s11042-020-09371-x
   Musheer RA, 2019, SOFT COMPUT, V23, P13409, DOI 10.1007/s00500-019-03879-7
   Peng H, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106729
   Pornpanomchai Chomtip, 2013, Kasetsart Journal Natural Science, V47, P624
   Rachmatullah MN, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS, THEORY AND APPLICATIONS (ICAICTA 2018), P78, DOI 10.1109/ICAICTA.2018.8541313
   Saberioon M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041027
   Salman A, 2020, ICES J MAR SCI, V77, P1295, DOI 10.1093/icesjms/fsz025
   Salman A, 2019, ECOL INFORM, V51, P44, DOI 10.1016/j.ecoinf.2019.02.011
   Sawant S, 2021, MULTIMED TOOLS APPL, V80, P1725, DOI 10.1007/s11042-020-09705-9
   Sung M, 2017, OCEANS-IEEE
   Tharwat A, 2018, FISH RES, V204, P324, DOI 10.1016/j.fishres.2018.03.008
   Villon S, 2018, ECOL INFORM, V48, P238, DOI 10.1016/j.ecoinf.2018.09.007
   Xiao MH, 2022, MULTIMED TOOLS APPL, V81, P1567, DOI 10.1007/s11042-021-11556-x
   Yang XT, 2021, REV AQUACULT, V13, P66, DOI 10.1111/raq.12464
NR 41
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3677
EP 3696
DI 10.1007/s11042-022-13437-3
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825246000008
DA 2024-07-18
ER

PT J
AU Vellingiri, S
   McMahan, RP
   Johnson, V
   Prabhakaran, B
AF Vellingiri, Shanthi
   McMahan, Ryan P.
   Johnson, Vinu
   Prabhakaran, Balakrishnan
TI An augmented virtuality system facilitating learning through nature walk
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented virtuality; Photorealistic avatars; Educational tours; Sensor
   placements; User study; Field trips; Knowledge acquisition; Nature walk;
   Tree taxonomy
AB Augmented Virtuality (AV), the augmentation of a virtual environment with real-world objects or information, provides unique educational opportunities, such as photorealistic avatars (using content generation sensors) that convey natural gestures and body language, frames of reference for scale comparisons, and embodied cognition. In this research, we focus on the use of AV technologies for educational tours, such as nature walks, which are guided educational tours to teach students how to identify trees. Because additional content generation and tracking sensors require additional costs and logistics for educational deployment, we conducted a between-subjects experiment comparing AV systems with rear-only and front-and-rear Kinect sensor arrangements. While prior research indicates comparable tracking accuracies for such sensor conditions, we found significant differences between the two conditions. More importantly, we found evidence indicating that the rear-only sensor condition altered participant behavior and caused some participants to prioritize completing the educational tour quickly over correctly identifying trees and their features on the tour. However, we also found that both conditions afforded significant learning improvements, based on pre and post knowledge tests.
C1 [Vellingiri, Shanthi; Prabhakaran, Balakrishnan] Univ Texas Dallas, Richardson, TX 75083 USA.
   [McMahan, Ryan P.] Univ Cent Florida, Orlando, FL 32816 USA.
   [Johnson, Vinu] Dallas Coll, Mesquite, TX USA.
C3 University of Texas System; University of Texas Dallas; State University
   System of Florida; University of Central Florida
RP Vellingiri, S (corresponding author), Univ Texas Dallas, Richardson, TX 75083 USA.
EM shanthi16@gmail.com; rpm@ucf.edu; vinujohnson@dcccd.edu;
   bprabhakaran@utdallas.edu
FU US Army Research Office (ARO) [W911NF-17-1-0299]; National Science
   Foundation (NSF) [1626586]; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [1626586] Funding Source:
   National Science Foundation
FX This material is based upon work supported by the US Army Research
   Office (ARO) Grant W911NF-17-1-0299 and the National Science Foundation
   (NSF) under Grant No. 1626586. Any opinions, findings, and conclusions
   or recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the ARO and NSF.
CR Albert A, 2014, J CONSTR ENG M, V140, DOI 10.1061/(ASCE)CO.1943-7862.0000860
   Auvinet E, 2017, GAIT POSTURE, V51, P162, DOI 10.1016/j.gaitpost.2016.08.022
   Borst CW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P467, DOI 10.1109/VR.2018.8448286
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Elmqaddem N, 2019, INT J EMERG TECHNOL, V14, P234, DOI 10.3991/ijet.v14i03.9289
   Galloway C, 2017, PUBLIC RELAT REV, V43, P969, DOI 10.1016/j.pubrev.2017.06.010
   Jones A, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P267
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim J, 2015, IEICE T FUND ELECTR, VE98A, P2004, DOI 10.1587/transfun.E98.A.2004
   Koppelman H, 2008, ITICSE '08: PROCEEDINGS OF THE 13TH ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P194
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Kurillo G, 2013, VIRTUAL REAL-LONDON, V17, P29, DOI 10.1007/s10055-012-0217-2
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Morato C, 2014, J COMPUT INF SCI ENG, V14, DOI 10.1115/1.4025810
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Raghuraman S, 2017, THESIS
   Regenbrecht H, 2004, PRESENCE-TELEOP VIRT, V13, P338, DOI 10.1162/1054746041422334
   Shin DH, 2017, TELEMAT INFORM, V34, P1826, DOI 10.1016/j.tele.2017.05.013
   Vellingiri S, 2020, 2020 IEEE C VIRTUAL, DOI [10.1109/vrw50115.2020.00051, DOI 10.1109/VRW50115.2020.00051]
   Vellingiri S, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377353
   Vellingiri S, 2018, ALTMM'18: PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON MULTIMEDIA ALTERNATE REALITIES, P3, DOI 10.1145/3268998.3269002
   Wei T, 2015, 3DTV CONF
   Yükseltürk E, 2018, EDUC TECHNOL SOC, V21, P159
NR 25
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1553
EP 1564
DI 10.1007/s11042-022-13379-w
EA JUL 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000824839400002
DA 2024-07-18
ER

PT J
AU Chamishka, S
   Madhavi, I
   Nawaratne, R
   Alahakoon, D
   De Silva, D
   Chilamkurti, N
   Nanayakkara, V
AF Chamishka, Sadil
   Madhavi, Ishara
   Nawaratne, Rashmika
   Alahakoon, Damminda
   De Silva, Daswin
   Chilamkurti, Naveen
   Nanayakkara, Vishaka
TI A voice-based real-time emotion detection technique using recurrent
   neural network empowered feature modelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag-of-audio-words; Machine learning; Artificial intelligence; Big data;
   Emotion analysis
ID RECOGNITION
AB The advancements of the Internet of Things (IoT) and voice-based multimedia applications have resulted in the generation of big data consisting of patterns, trends and associations capturing and representing many features of human behaviour. The latent representations of many aspects and the basis of human behaviour is naturally embedded within the expression of emotions found in human speech. This signifies the importance of mining audio data collected from human conversations for extracting human emotion. Ability to capture and represent human emotions will be an important feature in next-generation artificial intelligence, with the expectation of closer interaction with humans. Although the textual representations of human conversations have shown promising results for the extraction of emotions, the acoustic feature-based emotion detection from audio still lags behind in terms of accuracy. This paper proposes a novel approach for feature extraction consisting of Bag-of-Audio-Words (BoAW) based feature embeddings for conversational audio data. A Recurrent Neural Network (RNN) based state-of-the-art emotion detection model is proposed that captures the conversation-context and individual party states when making real-time categorical emotion predictions. The performance of the proposed approach and the model is evaluated using two benchmark datasets along with an empirical evaluation on real-time prediction capability. The proposed approach reported 60.87% weighted accuracy and 60.97% unweighted accuracy for six basic emotions for IEMOCAP dataset, significantly outperforming current state-of-the-art models.
C1 [Chamishka, Sadil; Madhavi, Ishara; Alahakoon, Damminda; Nanayakkara, Vishaka] Univ Moratuwa, Comp Sci & Engn, Moratuwa, Sri Lanka.
   [Nawaratne, Rashmika; De Silva, Daswin] La Trobe Univ, Res Ctr Data Analyt & Cognit, Bundoora, Vic, Australia.
   [Chilamkurti, Naveen] La Trobe Univ, Comp Sci & Comp Engn, Bundoora, Vic, Australia.
C3 University Moratuwa; La Trobe University; La Trobe University
RP Chilamkurti, N (corresponding author), La Trobe Univ, Comp Sci & Comp Engn, Bundoora, Vic, Australia.
EM sadilchamishka.16@cse.mrt.ac.lk; madhavi.16@cse.mrt.ac.lk;
   B.Nawaratrie@latrobe.edu.au; D.Alahakoon@latrobe.edu.au;
   D.DeSilva@latrobe.edu.au; n.chilamkurti@latrobe.edu.au;
   vishaka@cse.mrt.ac.lk
RI Chilamkurti, Naveen/S-9636-2019; des, d/GVU-7765-2022; Nawaratne,
   Rashmika/N-8893-2018
OI Chilamkurti, Naveen/0000-0002-5396-8897; 
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abeysinghe S, 2018, INT CONF ADV ICT, P369, DOI 10.1109/ICTER.2018.8615462
   Adikari A, 2021, INT J INF MANAG DATA
   Adikari A, 2021, J MED INTERNET RES, V23, DOI 10.2196/27341
   Adikari A, 2021, IEEE T IND INFORM, V17, P2743, DOI 10.1109/TII.2020.3009277
   Adikari A, 2021, FUTURE GENER COMP SY, V116, P302, DOI 10.1016/j.future.2020.10.028
   Alahakoon D, 2023, INFORM SYST FRONT, V25, P221, DOI 10.1007/s10796-020-10056-x
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Baevski A, 2021, WAV2VEC 20 FRAMEWORK
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   De Barros PVA., 2016, MODELING AFFECTION M
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P154
   Han K, 2020, SPEECH EMOTION RECOG
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   Hazarika Devamanyu, 2018, Proc Conf, V2018, P2122, DOI 10.18653/v1/n18-1193
   Izard C., 2013, HUMAN EMOTIONS, P1
   Jiao WX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P397
   Keren G, 2016, IEEE IJCNN, P3412, DOI 10.1109/IJCNN.2016.7727636
   Lee CC, 2011, SPEECH COMMUN, V53, P1162, DOI 10.1016/j.specom.2011.06.004
   Lieskovská E, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101163
   Madhavi I, 2020, IEEE INT C EMERG, P929, DOI 10.1109/ETFA46521.2020.9212098
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Picard RW, 2010, IEEE T AFFECT COMPUT, V1, P11, DOI 10.1109/T-AFFC.2010.10
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Rathnayaka P, 2012, GATED RECURRENT NEUR, P2012
   Ruusuvuori J., 2012, The handbook of conversation analysis, P330, DOI [DOI 10.1002/9781118325001.CH16, DOI 10.1002/9781118325001]
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Schmitt M, 2017, J MACH LEARN RES, V18
   Schmitt M, 2016, INTERSPEECH, P495, DOI 10.21437/Interspeech.2016-1124
   Schuller B, 2014, INTERSPEECH, P427
   Tomar S., 2006, Linux Journal
   Tripathi S, 2019, ARXIV PREPRINT ARXIV
   Yoon S, 2019, INT CONF ACOUST SPEE, P2822, DOI 10.1109/ICASSP.2019.8683483
   Yoon S, 2018, IEEE W SP LANG TECH, P112, DOI 10.1109/SLT.2018.8639583
NR 41
TC 13
Z9 13
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35173
EP 35194
DI 10.1007/s11042-022-13363-4
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000814042800001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Karsh, RK
AF Karsh, Ram Kumar
TI LWT-DCT based image hashing for image authentication via blind geometric
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image hashing; LWT; DCT; Geometric transformation; Tamper detection
ID ROBUST HASH; PARTITION; TRANSFORM
AB Image authentication based on robust image hashing has been paid large attention by researchers. However, most of the existing methods are unable to authenticate, if the image is processed through geometric transformations and tampered. In this paper, we have proposed a blind geometric correction approach, which eliminates the effect of geometric transformation, including rotation-scaling-translation (RST). We have incorporated Lifting Wavelet Transform (LWT) and Discrete Cosine Transform (DCT) to construct a short hash. Furthermore, an algorithm to generate an image map from the hash is proposed to detect the tampered regions. The main objective is to keep the hash length short with better performance, i.e., perceptually robust to content-preserving operations and image tampering detection. Based on the difference of image maps obtained from "source image" and "query images", tampering regions have been localized. The proposed method can detect tampering, even if tampering and composite RST geometric transformations occur simultaneously, due to blind geometric correction. The experimental results show that the proposed image authentication method outperforms the state-of-the-art techniques.
C1 [Karsh, Ram Kumar] Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Karsh, RK (corresponding author), Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
EM ram@ece.nits.ac.in
OI Karsh, Ram/0000-0002-2341-341X
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], The USC-SIPI Image Database
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Du L, 2021, MULTIMED TOOLS APPL, V80, P22927, DOI 10.1007/s11042-020-08736-6
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hosny KM, 2018, CIRC SYST SIGNAL PR, V37, P5441, DOI 10.1007/s00034-018-0822-8
   idealtest, CASIA TAMP IM DET EV
   Karsh RK, 2018, MULTIMED TOOLS APPL, V77, P25409, DOI 10.1007/s11042-018-5799-6
   Karsh RK, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0179-0
   Karsh RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3639-6
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lu W, 2010, PROC SPIE, V7541, DOI 10.1117/12.838745
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Manish Mishra Manish Mishra, 2013, International Research Journal of Biological Sciences, V2, P1
   Ouyang JL, 2017, MULTIMED TOOLS APPL, V76, P2609, DOI 10.1007/s11042-015-3225-x
   Pun CM, 2017, IEEE T INF FOREN SEC, V12, P377, DOI 10.1109/TIFS.2016.2615272
   Reddy S., 2020, SMART COMPUTING PARA
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Saikia A, 2017, TENCON IEEE REGION, P2214, DOI 10.1109/TENCON.2017.8228229
   Sajjad M, 2019, IEEE T IND INFORM, V15, P6541, DOI 10.1109/TII.2019.2921652
   Su ZY, 2021, IEEE T CIRC SYST VID, V31, P1648, DOI 10.1109/TCSVT.2020.3002146
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   washington, GROUND TRUTH DAT
   Yan CP, 2017, IEEE T INF FOREN SEC, V12, P2144, DOI 10.1109/TIFS.2017.2699942
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 37
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22083
EP 22101
DI 10.1007/s11042-022-13349-2
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000810329100002
DA 2024-07-18
ER

PT J
AU Dixit, UD
   Shirdhonkar, MS
   Sinha, GR
AF Dixit, Umesh D.
   Shirdhonkar, M. S.
   Sinha, G. R.
TI Automatic logo detection from document image using HOG features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Connected components; Logo detection; Document image processing; HOG;
   SVM; Logo detection rate
AB Document image analysis and processing has drawn the attention of many researchers due to its real-time applications in day-to-day life. Document database comprising of logo provides a good opportunity for an easier way of indexing, searching and retrieval of the documents. Logo detection is an essential need for the implementation of any logo-based document indexing or retrieval techniques. This paper aims to develop an efficient logo detection method for document images. The major steps employed in the developed system include preprocessing of the input document, finding the connected components and classification of these components into the logo and non-logo candidates. The preprocessing step employs a median filter and a unique procedure for the removal of clutter noise to reduce the false detection rate. Histogram of Oriented Gradient (HOG) features and an SVM classifier are used to identify the logo and non-logo candidates of the document. The presented system is evaluated using Tobacco 800 dataset and the results are compared with existing techniques. The results show an improvement of 5% in average logo detection rate with the proposed work.
C1 [Dixit, Umesh D.] BLDEAs VP Dr PG Halakatti Coll Engn & Technol, Dept Elect & Commun Engn, Vijayapur 586103, Karnataka, India.
   [Shirdhonkar, M. S.] BLDEAs VP Dr PG Halakatti Coll Engn & Technol, Dept Comp Sci & Engn, Vijayapur 586103, Karnataka, India.
   [Sinha, G. R.] Myanmar Inst Informat Technol MIIT, Mandalay, Myanmar.
RP Dixit, UD (corresponding author), BLDEAs VP Dr PG Halakatti Coll Engn & Technol, Dept Elect & Commun Engn, Vijayapur 586103, Karnataka, India.
EM uddixit@rediffmail.com; ms_shirdhonkar@rediffmail.com;
   gr_sinha@mitt.edu.mm
RI Sinha, G R/T-2042-2019
OI Sinha, G R/0000-0003-2384-4591
CR [Anonymous], 1981, Two Dimensional Digital Signal Processing II
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bultheel A., 1995, B BELGIAN MATH SOC, V2, P1, DOI DOI 10.36045/BBMS/1103408773
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Dalal N., 2005, Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition, P886893
   Dixit Umesh D., 2020, International Journal of Information Technology, V12, P1217, DOI 10.1007/s41870-019-00394-8
   Dixit UD, 2021, PROC 2021 INT C COMP, P14
   Dixit UD, 2016, PROC IEEE INT C SIGN, P14
   Dixit UD., 2019, ADV BIOMETRICS
   Dixit UD, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500086
   Dixit UD, 2017, ADV INTELL SYST, V556, P481, DOI 10.1007/978-981-10-3874-7_45
   Dixit UD, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P787, DOI 10.1109/ICCSP.2016.7754252
   Guan BC, 2020, IEEE IMAGE PROC, P1396, DOI 10.1109/ICIP40778.2020.9191208
   Guangyu Zhu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P606, DOI 10.1109/ICDAR.2009.60
   Hassanzadeh S., 2011, AUSTR J BASIC APPL S, V5, P936
   Hoang TV, 2014, INT J DOC ANAL RECOG, V17, P161, DOI 10.1007/s10032-013-0213-4
   Hongye Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1335, DOI 10.1109/ICDAR.2009.129
   Jain R., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P135, DOI 10.1109/DAS.2012.54
   Kumar G, 2021, MULTIMED TOOLS APPL, V80, P4341, DOI 10.1007/s11042-020-09813-6
   Meethongjan K., 2020, TELKOMNIKA, V18, P3019, DOI [10.12928/telkomnika.v18i6.16133, DOI 10.12928/TELKOMNIKA.V18I6.16133]
   Nejad AA., 2012, INT J ELECTR COMPUT, V2, P577
   Pan J, 2016, PROC INT C SOFT COMP, P7288
   Patil Pushpa B., 2021, Advances in Artificial Intelligence and Data Engineering. Select Proceedings of AIDE 2019. Advances in Intelligent Systems and Computing (AISC 1133), P675, DOI 10.1007/978-981-15-3514-7_51
   Pham TD, 2003, PATTERN RECOGN, V36, P3023, DOI 10.1016/S0031-3203(03)00125-0
   Seiden S., 1997, Proceedings of the International Conference on Imaging Science, System and Technology, P446
   Shirdhonkar MS, 2010, P IEEE INT C COMP IN
   Vapnik V., 1999, NATURE STAT LEARNING
   Le VP, 2014, INT C PATT RECOG, P3056, DOI 10.1109/ICPR.2014.527
   Zhao JD, 2019, MULTIMED TOOLS APPL, V78, P75, DOI 10.1007/s11042-017-5254-0
   Zhu D, 2008, TOBACCO 800 COMPLEX
   Zhu G, 2007, PROC INT CONF DOC, P864
NR 31
TC 5
Z9 5
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 863
EP 878
DI 10.1007/s11042-022-13300-5
EA JUN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809315600001
DA 2024-07-18
ER

PT J
AU Quach, BM
   Dinh, VC
   Pham, N
   Huynh, D
   Nguyen, BT
AF Quach, Boi M.
   Dinh, V. Cuong
   Pham, Nhung
   Huynh, Dang
   Nguyen, Binh T.
TI Leaf recognition using convolutional neural networks based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf recognition; Deep learning; Support vector machines
ID PLANT; SHAPE; IDENTIFICATION; SYSTEM
AB There is a warning light for the loss of plant habitats worldwide that entails concerted efforts to conserve plant biodiversity. Thus, plant species classification is crucial to address this environmental challenge. In recent years, there has been a considerable increase in studies related to plant taxonomy. While some researchers try to improve their recognition performance using novel approaches, others concentrate on computational optimization for their framework. In addition, a few studies are diving into feature extraction to gain significantly in terms of accuracy. This paper proposes an effective method for the leaf recognition problem. In our proposed approach, a leaf goes through some pre-processing to extract its refined color image, vein image, xy-projection histogram, handcrafted shape, texture features, and Fourier descriptors. These attributes are then transformed into a better representation by neural network-based encoders before a support vector machine (SVM) model is utilized to classify different leaves. Overall, our approach performs a state-of-the-art result on the Flavia leaf dataset, achieving the accuracy of 99.69% on test sets under random 10-fold cross-validation and bypassing the previous methods. Another important contribution is the trade-offs in classification performance while minimizing the feature categories used. In order to tackle this challenge, we designed several empirical experiments to analyze the performance of different combinations of feature sources and choose the best combination for features for the main problem. We also release our codes (Scripts are available at https://github.com/Tayerquach/flavia_recognition) for contributing to the research community in the leaf classification problem.
C1 [Quach, Boi M.; Dinh, V. Cuong] Dublin City Univ, Dublin, Ireland.
   [Pham, Nhung; Nguyen, Binh T.] Univ Sci, Ho Chi Minh City, Vietnam.
   [Pham, Nhung; Nguyen, Binh T.] Vietnam Natl Univ Ho Chi Minh City, Ho Chi Minh City, Vietnam.
   [Huynh, Dang; Nguyen, Binh T.] AISIA Res Lab, Ho Chi Minh City, Vietnam.
   [Huynh, Dang] Hong Bang Int Univ, Ho Chi Minh City, Vietnam.
C3 Dublin City University; Vietnam National University Hochiminh City; Hong
   Bang International University
RP Nguyen, BT (corresponding author), Univ Sci, Ho Chi Minh City, Vietnam.; Nguyen, BT (corresponding author), Vietnam Natl Univ Ho Chi Minh City, Ho Chi Minh City, Vietnam.; Nguyen, BT (corresponding author), AISIA Res Lab, Ho Chi Minh City, Vietnam.
EM ngtbinh@hcmus.edu.vn
OI Nguyen, Thanh Binh/0000-0001-5249-9702
FU University of Science, Vietnam National University in Ho Chi Minh City;
   AISIA Research Lab in Vietnam
FX We want to thank the University of Science, Vietnam National University
   in Ho Chi Minh City, and AISIA Research Lab in Vietnam for supporting us
   throughout this paper.
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   Ahmed N, 2016, Science International, V28, DOI DOI 10.9790/0661-17134853
   [Anonymous], 2004, Forensic Sci. J.
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Beghin T, 2010, LECT NOTES COMPUT SC, V6475, P345, DOI 10.1007/978-3-642-17691-3_32
   Benco M, 2007, RADIOENGINEERING, V16, P64
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7_17
   Eid HF, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGY AND SENSOR APPLICATION (AITS), P76, DOI 10.1109/AITS.2015.28
   Ghasab MAJ, 2015, EXPERT SYST APPL, V42, P2361, DOI 10.1016/j.eswa.2014.11.011
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P26, DOI 10.5391/IJFIS.2017.17.1.26
   Khmag A, 2017, IEEE ST CONF RES DEV, P467, DOI 10.1109/SCORED.2017.8305438
   Kumar PSVVSR, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P548, DOI 10.1109/IC3I.2016.7918024
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Mittal P, 2018, 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT CIRCUITS AND SYSTEMS (ICICS 2018), P184, DOI 10.1109/ICICS.2018.00046
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095
   Salve P, 2022, J KING SAUD UNIV-COM, V34, P1361, DOI 10.1016/j.jksuci.2018.09.018
   Salve P, 2016, ADV INTELL SYST, V379, P85, DOI 10.1007/978-81-322-2517-1_10
   Schrader J, 2021, ANN BOT-LONDON, V128, P395, DOI 10.1093/aob/mcab078
   Shah MP, 2017, IEEE IMAGE PROC, P860, DOI 10.1109/ICIP.2017.8296403
   Su JY, 2020, IEEE ACCESS, V8, P208753, DOI 10.1109/ACCESS.2020.3037649
   Türkoglu M, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI 10.1109/idap.2019.8875911
   Türkoglu M, 2019, J FAC ENG ARCHIT GAZ, V34, P2097, DOI 10.17341/gazimmfd.423674
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054
   Wang ZB, 2014, IEEE IJCNN, P975, DOI 10.1109/IJCNN.2014.6889656
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang H, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P2025, DOI 10.1109/ICICEE.2012.538
   Zhiyu Liu, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9226, P115, DOI 10.1007/978-3-319-22186-1_11
NR 32
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 777
EP 801
DI 10.1007/s11042-022-13199-y
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809322800001
DA 2024-07-18
ER

PT J
AU Guo, SL
   Zhang, JG
   Zhang, WT
   Song, ZF
   Meng, CM
AF Guo, Shuangle
   Zhang, Jianguang
   Zhang, Wenting
   Song, Zhifei
   Meng, Chunmei
TI Feature selection via uncorrelated discriminant sparse regression for
   multimedia analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Uncorrelated discriminant; Sparse regression;
   Multimedia analysis
ID INFORMATION; FRAMEWORK
AB As an important part of multimedia analysis applications, feature selection has attracted much attention during the past decades. Lots of feature selection methods have been proposed, but most of them neglect to consider the correlation between the selected features, which leads to the feature redundancy problem. In this paper, we propose a novel supervised feature selection method, termed as Uncorrelated Discriminant Sparse Regression (UDSR). This method is an organic combination of discriminant sparse regression and uncorrelated constraint. In this method, the discriminant sparse regression ensures the discriminant power of the selected features, and the uncorrelated constraint avoids the redundancy of selected features. Thus the features selected by our method are not only discriminative but also uncorrelated with each other. The method can be applied to a wide range of multimedia applications. Experiments are conducted on two video datasets and four image datasets. The experimental results show that the proposed method has better performance for multimedia analysis, compared to the baseline and six state-of-the-art relative methods.
C1 [Guo, Shuangle] Binzhou Univ, Sch Informat Engn, Binzhou, Peoples R China.
   [Zhang, Jianguang] Hengshui Univ, Coll Math & Comp Sci, Hengshui, Peoples R China.
   [Zhang, Jianguang] Shenzhen Univ, Sch Comp Sci Software Engn, Shenzhen, Peoples R China.
   [Zhang, Wenting] Hengshui Univ, Coll Elect Informat Engn, Hengshui, Peoples R China.
   [Song, Zhifei] Hengshui Univ, Off Acad Res, Hengshui, Peoples R China.
   [Meng, Chunmei] Hengshui Univ, Coll Continuing Educ, Hengshui, Peoples R China.
C3 Shandong University of Aeronautics; Hengshui University; Shenzhen
   University; Hengshui University; Hengshui University; Hengshui
   University
RP Zhang, JG (corresponding author), Hengshui Univ, Coll Math & Comp Sci, Hengshui, Peoples R China.; Zhang, JG (corresponding author), Shenzhen Univ, Sch Comp Sci Software Engn, Shenzhen, Peoples R China.
EM lynxzjg@tju.edu.cn
RI Zhang, Wenting/S-2985-2017; Guo, Shuangle/ACG-0470-2022
OI Zhang, Wenting/0000-0002-6406-5220; 
FU Chinese Natural Science Foundation (CNSF) [61702165]; S&T Program of
   Hebei, China [F2020111001]; Scientific Research Project of Hengshui
   University [2021GC17, 2021yj18]; Humanities and Social Sciences project
   of the Ministry of Education [18YJCZH129]
FX This work was supported in part by the Chinese Natural Science
   Foundation (CNSF) (under Grant 61702165). This work was supported in
   part by the S&T Program of Hebei, China (under Grant F2020111001). This
   work was supported in part by the Scientific Research Project of
   Hengshui University (under Grant 2021GC17, Grant 2021yj18). This work
   was supported in part by the Humanities and Social Sciences project of
   the Ministry of Education(under Grant 18YJCZH129).
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], MATRIX COMPUTATIONS
   [Anonymous], 2013, 23 INT JOINT C ART I
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Chen XJ, 2020, IEEE T KNOWL DATA EN, V32, P165, DOI 10.1109/TKDE.2018.2879797
   Delaitre V., 2010, Proceedings of the British Machine Vision Conference, P1, DOI DOI 10.5244/C.24.97
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Fengxi Song, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P746, DOI 10.1109/ISDEA.2010.311
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T INSTRUM MEAS, V69, P660, DOI 10.1109/TIM.2019.2905904
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Han D, 2015, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR.2015.7299136
   Han Y, 2013, WORKSH 27 AAAI C ART
   HENRY ER, 1992, METHOD ENZYMOL, V210, P129
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Huang QH, 2011, IEEE T SYST MAN CY B, V41, P1471, DOI 10.1109/TSMCB.2011.2151256
   Ikizler N, 2008, INT C PATT RECOG, P1299
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Kwak S, 2016, PROC CVPR IEEE, P4938, DOI 10.1109/CVPR.2016.534
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P2139, DOI 10.1109/TIP.2019.2947776
   Li XL, 2019, IEEE T NEUR NET LEAR, V30, P1587, DOI 10.1109/TNNLS.2018.2868847
   Li YS, 2017, IEEE ACCESS, V5, P10323, DOI 10.1109/ACCESS.2017.2712789
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu HW, 2009, PATTERN RECOGN, V42, P1330, DOI 10.1016/j.patcog.2008.10.028
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Liu KY, 2019, KNOWL-BASED SYST, V165, P282, DOI 10.1016/j.knosys.2018.11.034
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohino-Herranz I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010309
   Nie F., 2008, AAAI
   Nie F., 2010, ADV NEURAL INFORM PR, P1
   Nie FP, 2019, IEEE T IMAGE PROCESS, V28, P2428, DOI 10.1109/TIP.2018.2886761
   Pang YW, 2019, IEEE T NEUR NET LEAR, V30, P2779, DOI 10.1109/TNNLS.2018.2886317
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Sáez JA, 2019, IEEE ACCESS, V7, P99754, DOI 10.1109/ACCESS.2019.2930355
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sharma A, 2014, MACH VISION APPL, V25, P775, DOI 10.1007/s00138-013-0577-y
   Shi CJ, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107332
   Shirzad MB, 2015, 2015 AI & ROBOTICS (IRANOPEN)
   Tang J., 2014, P SIAM INT C DAT MIN, P938
   Wang D, 2014, JOINT EUR C MACH LEA
   Wang D, 2015, IEEE T KNOWL DATA EN, V27, P2743, DOI 10.1109/TKDE.2015.2426703
   Wang H., 2009, BMVC
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang JZ, 2013, PATTERN RECOGN, V46, P1616, DOI 10.1016/j.patcog.2012.11.025
   Xiao Cai, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P91, DOI 10.1109/ICDM.2011.105
   Yang YL, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL V, P281, DOI 10.1109/PAAP.2010.52
   Yang ZW, 2018, MULTIMED TOOLS APPL, V77, P3431, DOI 10.1007/s11042-017-5165-0
   YAO BP, 2010, PROC CVPR IEEE, P9, DOI DOI 10.1109/CVPR.2010.5540234
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
NR 59
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 619
EP 647
DI 10.1007/s11042-022-13258-4
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527600005
DA 2024-07-18
ER

PT J
AU Li, XL
   Li, XX
   Yang, GT
AF Li, Xinli
   Li, Xiaoxiao
   Yang, Guotian
TI A novelty harmony search algorithm of image segmentation for multilevel
   thresholding using learning experience and search space constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Novelty harmony search;
   Evaluation index
ID OPTIMIZATION; ENTROPY
AB Image segmentation is an important part of image understanding and one of the most difficult problems in image processing. For image segmentation processing, this paper proposes an image segmentation algorithm for multilevel thresholding based on novelty harmony search algorithm. Firstly, the central harmony and central congestion distance are introduced to reduce local aggregation of initial points and expand the search range. Secondly, the new harmony generation strategy is constructed, which is based on dominant harmony learning experience. Then the search space constraints and parameters adaptive adjustment are adopted to improve the search efficiency. Finally, the harmony memory updating rules are designed to enhance the diversity of population. The image segmentation effect is evaluated by the between-class variance, peak signal-to-noise ratio and mean structural similarity. A series of experiments have been carried out to analyze the segmentation effect of the proposed NHS algorithm based on the Berkeley segmentation database. Compared with the basic harmony search algorithm, improved harmony search algorithm, global best harmony search algorithm, particle swarm optimization algorithm and artificial bee colony algorithm, the experimental results show the effectiveness of the proposed algorithm. In particular the proposed algorithm is superior to other methods when the threshold number increases. The influence of noise and artifact on image segmentation is also discussed and analyzed. It illustrates that the image can be segmented in the Gaussian noise, mixed noise and strip line artifact conditions based on the proposed algorithm.
C1 [Li, Xinli; Li, Xiaoxiao; Yang, Guotian] North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China.
C3 North China Electric Power University
RP Li, XL (corresponding author), North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China.
EM lixinli@ncepu.edu.cn
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd Elaziz M, 2020, IEEE ACCESS, V8, P125306, DOI 10.1109/ACCESS.2020.3007928
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2019, INFRARED PHYS TECHN, V98, P132, DOI 10.1016/j.infrared.2019.03.010
   Chen J, 2012, APPL MATH COMPUT, V219, P592, DOI 10.1016/j.amc.2012.06.048
   Drozdzal M, 2018, MED IMAGE ANAL, V44, P1, DOI 10.1016/j.media.2017.11.005
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Kattan A, 2013, APPL MATH COMPUT, V219, P8542, DOI 10.1016/j.amc.2013.02.074
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Li Xiaoyu, 2015, INT C INTELLIGENT SY
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   Mala C, 2016, SOFT COMPUT, V20, P1793, DOI 10.1007/s00500-015-1677-6
   Matic T, 2018, ISA T, V76, P246, DOI 10.1016/j.isatra.2018.03.015
   Moussa M, 2020, TRAIT SIGNAL, V37, P405, DOI 10.18280/ts.370307
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Oliva D, 2013, J APPL MATH, DOI 10.1155/2013/575414
   Omran MGH, 2008, APPL MATH COMPUT, V198, P643, DOI 10.1016/j.amc.2007.09.004
   Pan QK, 2010, APPL MATH COMPUT, V216, P830, DOI 10.1016/j.amc.2010.01.088
   Pare S, 2020, IJST-T ELECTR ENG, V44, P1, DOI 10.1007/s40998-019-00251-1
   Pare S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P730, DOI 10.1109/ICDSP.2015.7251972
   Rad AE, 2017, MULTIMED TOOLS APPL, V76, P2185, DOI 10.1007/s11042-015-3196-y
   Ramadas M, 2020, NEURAL COMPUT APPL, V32, P6139, DOI 10.1007/s00521-019-04104-0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salem M, 2015, PROCEEDINGS OF 2015 THIRD IEEE WORLD CONFERENCE ON COMPLEX SYSTEMS (WCCS)
   SINGHA A, 2020, IEEE ACCESS 11298511
   Smolka B, 2020, MULTIMED TOOLS APPL, V79, P32857, DOI 10.1007/s11042-020-09550-w
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Tuba V, 2017, LECT NOTES COMPUT SC, V10585, P571, DOI 10.1007/978-3-319-68935-7_62
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang ZC, 2020, IEEE ACCESS, V8, P16269, DOI 10.1109/ACCESS.2020.2966665
   Zou DX, 2010, NEUROCOMPUTING, V73, P3308, DOI 10.1016/j.neucom.2010.07.010
NR 37
TC 3
Z9 3
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 703
EP 723
DI 10.1007/s11042-022-13288-y
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527600001
DA 2024-07-18
ER

PT J
AU AlQudah, MM
   Otair, MA
   Alqudah, MAY
   AlAzzam, SI
   Alqudah, SA
AF AlQudah, Mohammad M.
   Otair, Mohammed A.
   Alqudah, Mohammad A. Y.
   AlAzzam, Sayer, I
   Alqudah, Safa'a Ali
TI Prediction of hidden patterns in rheumatoid arthritis patients records
   using data mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data mining; Rheumatoid arthritis; RJ48; DAS 28; Methotrexate; WEKA;
   Classification; Feature selection
ID DISEASE-ACTIVITY; CLASSIFICATION; ALGORITHMS
AB Rheumatoid Arthritis (RA) disease is an inflammatory disease, which is characterized by persistent synovitis and autoantibodies that eventually lead to joint damage and reduced quality of life. This paper implements two data mining methodologies to explore the most important attributes that correlated with RA disease activity: (1) Feature selection algorithms to be used by Association rules (Apriori and Predictive) or Classification algorithms (J48 and J48 Consolidated), (2) Predictive rules (Rule Induction), Feature weight (Information Gain) and Trees algorithms (CHAD). This study experiments a precollected dataset consists of 260 patient records with a confirmed diagnosis of RA. The experimented algorithms are measured in terms of F-Measure, Accuracy, and the output tree. The accuracy of the J48 classification algorithm result was 79.18%. Many new rules were found by using the Predictive- Apriori technique from the association rules algorithms. By using the Information Gain algorithm, the most important attributes that highly correlated with the disease discovered were identified. This study revealed a model that validates the previous RA studies and includes new parameters that include both non-pharmacologic measures (No smoking, physical exercise and patient compliance) and pharmacologic therapies (MTX dose above 20 mg /week, prednisone dose >5 mg/day as add-on therapy and biologic DMARDs (adalimumab, preferred in our study) and Hb > 10.8 g/dl). The model would help RA patients to have will controlled and low disease activity.
C1 [AlQudah, Mohammad M.; Otair, Mohammed A.] Amman Arab Univ, Sch Comp & Informat Technol, Amman, Jordan.
   [Alqudah, Mohammad A. Y.] Univ Sharjah, Coll Pharm, Dept Pharm Practice & Pharmacotherapeut, Sharjah 27272, U Arab Emirates.
   [Alqudah, Mohammad A. Y.; AlAzzam, Sayer, I] Jordan Univ Sci & Technol, Fac Pharm, Dept Clin Pharm, Irbid 22110, Jordan.
   [Alqudah, Safa'a Ali] Al Balqa Appl Univ, Allied Med Sci Dept, Al Salt, Jordan.
C3 University of Sharjah; Jordan University of Science & Technology;
   Al-Balqa Applied University
RP AlQudah, MM (corresponding author), Amman Arab Univ, Sch Comp & Informat Technol, Amman, Jordan.
EM mmaq78@gmail.com; otair@aau.edu.jo
RI Alqudah, Mohammad A/D-6917-2015
OI Alqudah, Mohammad A/0000-0002-2623-3115
FU Jordan University of Science and Technology
FX We are grateful to Jordan University of Science and Technology for
   support in providing patient data.
CR Ahmed A., 2014, World Journal of Computer Application and Technology, V2, P43
   Akin M, 2017, PLANT CELL TISS ORG, V128, P303, DOI 10.1007/s11240-016-1110-6
   Aletaha D, 2005, CLIN EXP RHEUMATOL, V23, pS100
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali M, 2015, PAK J ZOOL, V47, P1579
   Alqudah MAY, 2017, INFLAMMOPHARMACOLOGY, V25, P431, DOI 10.1007/s10787-017-0315-6
   [Anonymous], 2014, Data Mining with Decision Trees: Theory and Applications
   Bardhan S, 2019, AUSTRALAS PHYS ENG S, V42, P259, DOI 10.1007/s13246-019-00726-9
   Bascol K., 2019, P 22 INT C ART INT S, V89, P1245
   Beniwal S., 2012, International Journal of Engineering Research and Technology(IJERT), V1
   Chaurasia V., 2014, International Journal of Advanced Computer Science and Information Technology, V2, P56
   Chaurasia V., 2017, INT J INNOV RES COMP, V2, P2456
   Curtis JR, 2014, ARTHRIT CARE RES, V66, P990, DOI 10.1002/acr.22281
   Damberg E, 2014, BIOMED RES INT, DOI [10.1155/2017/3292849, DOI 10.1155/2017/3292849]
   Demisse GB., 2017, ARXIV PREPRINT ARXIV
   Durairaj M., 2013, International Journal of Scientific Technology Research, V2, P29
   Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4
   Gosselt HR, 2021, J PERS MED, V11, DOI 10.3390/jpm11010044
   Guo Y., 2022, SOFT COMPUT, V116
   Hajar T.L, 2015, J PALLIAT CARE MED, V5, P221, DOI [10.4172/2165-7386.1000221, DOI 10.4172/2165-7386.1000221]
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11
   Jiang P, 2015, CLIN EXP RHEUMATOL, V33, P115
   Koh Hian Chye, 2005, J Healthc Inf Manag, V19, P64
   Kumar A, 2020, Advances in Computing and Data Sciences, V4, P507
   Levi EH, 2016, AUTOIMMUN REV, V15, P393, DOI 10.1016/j.autrev.2016.01.006
   Myasoedova E, 2010, ARTHRITIS RHEUM-US, V62, P1576, DOI 10.1002/art.27425
   Nahar K, 2021, EDUC INF TECHNOL, V26, P6051, DOI 10.1007/s10639-021-10575-3
   Nakagawa C, 2021, THER ADV MUSCULOSKEL, V13, DOI 10.1177/1759720X211047057
   Nourisson C, 2017, RMD OPEN, V3, DOI 10.1136/rmdopen-2017-000515
   Pinjarkar V, 2022, ROLE IOT BLOCKCHAIN, P441
   Prajna B, 2016, INT J COMPUT SCI TEC, V7
   Ramotra Atul Kumar, 2020, Smart Trends in Computing and Communications. Proceedings of SmartCom 2019. Smart Innovation, Systems and Technologies (SIST 165), P89, DOI 10.1007/978-981-15-0077-0_10
   Rashidi S, 2014, TRANSPORT RES REC, P74, DOI 10.3141/2418-09
   Saad M.K., 2010, IMPACT TEXT PREPROCE
   Scott DL, 2010, LANCET, V376, P1094, DOI 10.1016/S0140-6736(10)60826-4
   Shanmugam S, 2019, J SUPERCOMPUT, V75, P5507, DOI 10.1007/s11227-019-02800-1
   Shanmugam S, 2017, INT J RES ENG APPL M, V03, DOI [10.18231/2454-9150.2017.0006, DOI 10.18231/2454-9150.2017.0006]
   Singh JA, 2016, ARTHRITIS RHEUMATOL, V68, P1, DOI 10.1002/art.39480
   Singh P., 2021, Int. J. Appl. Res. Bioinformatics, V11, P51
   Smyrnova G, 2014, REV BRAS REUMATOL, V54, P437, DOI 10.1016/j.rbr.2014.06.002
   Sornalakshmi M, 2022, NEURAL COMPUT APPL, V34, P10597, DOI 10.1007/s00521-020-04862-2
   Sundaramurthy S., 2020, P 2020 INT C DEC AID, P17, DOI [10.1109/DASA51403.2020.9317253, DOI 10.1109/DASA51403.2020.9317253]
   Taylor Andrew, 2011, ISRN Rheumatol, V2011, P437281, DOI 10.5402/2011/437281
   Traore BB, 2017, EXPERT SYST APPL, V72, P443, DOI 10.1016/j.eswa.2016.10.010
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Wu CT, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020085
   Zhang HN, 2022, MOB NETW APPL, P1
NR 49
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 7
PY 2022
DI 10.1007/s11047-022-13331-y
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1X2VT
UT WOS:000807318300005
DA 2024-07-18
ER

PT J
AU Pan, M
   Zhang, HR
   Wu, JH
   Jin, Z
AF Pan, Meng
   Zhang, Huanrong
   Wu, Jiahao
   Jin, Zhi
TI Self-distillation framework for indoor and outdoor monocular depth
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular depth estimation; Generalization ability; Self-distillation
AB As one of the most crucial tasks of scene perception, Monocular Depth Estimation (MDE) has made considerable development in recent years. Current MDE researchers are interested in the precision and speed of the estimation, but pay less attention to the generalization ability across scenes. For instance, the MDE networks trained on outdoor scenes achieve impressive performance on outdoor scenes but poor performance on indoor scenes, and vice versa. To tackle this problem, we propose a self-distillation MDE framework to improve the generalization ability across different scenes in this paper. Specifically, we design a student encoder that extracts features from two datasets of indoor and outdoor scenes, respectively. After that, we introduce a dissimilarity loss to pull apart encoded features of different scenes in the feature space. Finally, a decoder is adopted to estimate the final depth from encoded features. By doing so, our self-distillation MDE framework can learn the depth estimation of two different datasets. To the best of our knowledge, we are the first one to tackle the generalization problem across datasets of different scenes in the MDE field. Experiments demonstrate that our method reduces the degradation problem when a MDE network is in the face of datasets with complex data distribution. Note that evaluating on two datasets by a single network is more challenging than evaluating on two datasets by two different networks.
C1 [Pan, Meng; Zhang, Huanrong; Wu, Jiahao; Jin, Zhi] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Robot & Digital Intelligen, Guangzhou 510535, Peoples R China.
C3 Sun Yat Sen University
RP Jin, Z (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou 510006, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Robot & Digital Intelligen, Guangzhou 510535, Peoples R China.
EM panm9@mail2.sysu.edu.cn; zhanghr37@mail2.sysu.edu.cn;
   wujh79@mail2.sysu.edu.cn; jinzh26@mail.sysu.edu.cn
RI Jin, Zhi/AAB-2440-2022; Wu, Jiahao/HTP-0561-2023
OI Jin, Zhi/0000-0001-9670-7366; Wu, Jiahao/0000-0002-2417-8554; Zhang,
   Huanrong/0000-0003-3830-3480
FU National Natural Science Foundation of China [62071500, 61701313];
   Sino-Germen Mobility Programme [M-0421]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62071500, 61701313) and Sino-Germen Mobility Programme
   M-0421.
CR Bhoi Amlaan, 2019, ARXIV190109402
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Cao Z.-L., 2015, J. Chongqing Univ. Technol., V29, P70
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chen WF, 2016, ADV NEUR IN, V29
   Dai A., 2017, ACM Transactions on Graphics (ToG), V36, DOI DOI 10.1145/3054739
   Dean J., 2015, NIPS DEEP LEARNING R
   Droeschel D, 2017, ROBOCUP, P319
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Lee J, 2019, PR MACH LEARN RES, V97
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Li RB, 2019, LECT NOTES COMPUT SC, V11364, P663, DOI 10.1007/978-3-030-20870-7_41
   Ling Zou, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P185, DOI 10.1109/ICALIP.2010.5684978
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Mousavian A, 2016, INT CONF 3D VISION, P611, DOI 10.1109/3DV.2016.69
   Paszke A, 2019, ADV NEUR IN, V32
   Pereyra G, 2018, ARXIV180403235
   Poggi M, 2020, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR42600.2020.00329
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Romero A., 2014, ARXIV14126550
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Weder S, 2020, PROC CVPR IEEE, P4886, DOI 10.1109/CVPR42600.2020.00494
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Yoneda K, 2014, IEEE INT VEH SYM, P1345, DOI 10.1109/IVS.2014.6856596
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao CQ, 2020, SCI CHINA TECHNOL SC, V63, P1612, DOI 10.1007/s11431-020-1582-8
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 43
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35899
EP 35913
DI 10.1007/s11042-021-11500-z
EA JUN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000804560500004
DA 2024-07-18
ER

PT J
AU Sale, D
AF Sale, Deepali
TI An enhanced image fusion in the spatial domain based on modified
   independent component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram equalization (HE); Laplacian second-order derivatives (LSD);
   Modified independent component analysis (MICA)
AB Image Fusion (IF) couples the complementary information available in manifold images that are of the same scene into a sole image, which in turn encompasses a more precise illustration of the scene when compared with a solitary source image. The existent paper suggested IF utilizing disparate algorithms, but they suffer from too low RR, low informative as well as low-quality image. To trounce these issues, a MICA centered on an ameliorated IF in the Spatial Domain introduced. Steps i) Image Acquisition, ii) Image Enhancements, iii) image sharpening and iv) IF. Initially, the IA is performed, where the needed images are taken as of the Data Base. Next, the image sharpening is performed utilizing LSD. Finally, the IF is done utilizing the MICA is the sharpening image. Experimentation's outcomes on proposed IF exhibited that the method attains competitive or better RR performance when weighed with the top-notch methods.
C1 [Sale, Deepali] Dr DY Patil Inst Technol, Elect & Telecommun Engn, Pimpri, India.
   [Sale, Deepali] Savitribai Phule Pune Univ, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University
RP Sale, D (corresponding author), Dr DY Patil Inst Technol, Elect & Telecommun Engn, Pimpri, India.; Sale, D (corresponding author), Savitribai Phule Pune Univ, Pune, Maharashtra, India.
EM saleishwari@gmail.com
CR Abhyankar Maitreyi, 2016, 2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS), DOI 10.1109/ICIS.2016.7550766
   AL-Shatnawi A., 2021, INT J ADV SOFT COMPU, V13
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Castanedo F, 2013, SCI WORLD J, DOI 10.1155/2013/704504
   Dey A., 2015, IEEE 2 INT C RECENT
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Fernandes SL, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS)
   Gao Zhirong, 2014, Wuhan University Journal of Natural Sciences, V19, P323, DOI 10.1007/s11859-014-1020-6
   Ge QB, 2016, IEEE T SYST MAN CY-S, V46, P912, DOI 10.1109/TSMC.2016.2523911
   Guo Q, 2015, OPTIK, V126, P5241, DOI 10.1016/j.ijleo.2015.09.185
   Jiang Y, 2014, INFORM FUSION, V18, P107, DOI 10.1016/j.inffus.2013.06.001
   Kaur G, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1420, DOI 10.1109/ICEEOT.2016.7754918
   Li J, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103171
   Liu CP, 2020, MULTIMED TOOLS APPL, V79, P10475, DOI 10.1007/s11042-019-7563-y
   Liu ZW, 2016, INFRARED PHYS TECHN, V79, P183, DOI 10.1016/j.infrared.2016.10.015
   Lu Y, 2014, FRONT COMPUT SCI-CHI, V8, P243, DOI 10.1007/s11704-014-2328-2
   Lu Zongguang, 2017, [Computational Visual Media, 计算可视媒体], V3, P359
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma Y, 2016, NEUROCOMPUTING, V202, P12, DOI 10.1016/j.neucom.2016.03.009
   Manu CS, 2015, 2015 8 INT C ADV PAT, DOI [10.1109/icapr.2015.7050690, DOI 10.1109/ICAPR.2015.7050690]
   Nandal A, 2019, IJST-T ELECTR ENG, V43, P141, DOI 10.1007/s40998-018-0135-8
   Parisotto S, 2020, IEEE T IMAGE PROCESS, V29, P5507, DOI 10.1109/TIP.2020.2983537
   Seal A, 2019, MULTIMED TOOLS APPL, V78, P30373, DOI 10.1007/s11042-019-7701-6
   Singh S., 2021, ARCH COMPUT METHOD E, V28, P1, DOI [10.1007/s11831-019-09366-4, DOI 10.1007/S11831-019-09366-4]
   Tang WJ, 2017, MULTIMED TOOLS APPL, V76, P22725, DOI 10.1007/s11042-017-4343-4
   Wu SL, 2020, COMPUT COMMUN, V157, P444, DOI 10.1016/j.comcom.2020.04.010
   Xu M, 2016, IEEE ACCESS, V4, P10280, DOI 10.1109/ACCESS.2016.2635147
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
NR 30
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44123
EP 44140
DI 10.1007/s11042-022-13238-8
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000804560400001
DA 2024-07-18
ER

PT J
AU Tu, HY
   Wang, WL
   Chen, JC
   Wu, F
   Li, GQ
AF Tu, Hangyao
   Wang, Wanliang
   Chen, Jiachen
   Wu, Fei
   Li, Guoqing
TI Unpaired image-to-image translation with improved two-dimensional
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image translation; Generative adversarial network; Feature extraction;
   Feature fusion
ID CYCLEGAN; FUSION
AB With the feature-level constraints, unpaired image translation is challenging in generating poor realistic images, which focuses on convolutional feature extraction, ignoring the SVD feature extraction. To address this limitation, the Unpaired Image-to-image Translation with Improved Two-dimensional Feature (UNTF) is proposed. Specifically, in our method the novel feature extraction module consists two part: the SVD feature extraction and the convolutional feature extraction. The SVD feature maps were built by Two-Dimensional Feature which transform 1-D features into 2-D features to cascade with convolutional features. In up-sampling module sub-pixel convolution is used to replace transposed convolution. What's more, the proposed feature loss can stabilize the training process of generator. Finally, the proposed network was verified by ablation study and state-of-the-art methods. Experiments on image translation, image illustration, and image restoration show that both the image clarity index (EGF) and experts agree that the proposed method is superior to the existing methods.
C1 [Tu, Hangyao; Wang, Wanliang; Chen, Jiachen; Wu, Fei; Li, Guoqing] ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310015, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Wang, WL (corresponding author), ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310015, Zhejiang, Peoples R China.
EM zjutwwl@zjut.edu.cn
RI Wang, Wanliang/G-5024-2011
FU National Natural Science Foundation of China [61873240]
FX This work is supported by National Natural Science Foundation of China
   (No. 61873240). The data used to support the findings of this study are
   available from the corresponding author upon request.
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Buisine J, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010075
   Chai CL, 2018, MULTIMED TOOLS APPL, V77, P22339, DOI 10.1007/s11042-018-5968-7
   Chen GQ, 2020, APPL INTELL, V50, P3503, DOI 10.1007/s10489-020-01725-0
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Emami H, 2021, IEEE T MULTIMEDIA, V23, P391, DOI 10.1109/TMM.2020.2975961
   Fang YK, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107249
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Guo X, 2020, OPTIK, V206, DOI 10.1016/j.ijleo.2020.164214
   Hicsonmez S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103886
   Huang JC, 2020, MULTIMED TOOLS APPL, V79, P29639, DOI 10.1007/s11042-020-09524-y
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim T, 2017, PR MACH LEARN RES, V70
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Lim S, 2020, IEEE T COMPUT IMAG, V6, P1127, DOI 10.1109/TCI.2020.3006735
   Liu JP, 2021, IEEE T CYBERNETICS, V51, P839, DOI 10.1109/TCYB.2020.2977537
   Liu LL, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104097
   Liu MY, 2017, ADV NEUR IN, V30
   Liu RJ, 2020, MULTIMED TOOLS APPL, V79, P14375, DOI 10.1007/s11042-018-6761-3
   Lu GS, 2019, AAAI CONF ARTIF INTE, P4432
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Oh G, 2020, IEEE T COMPUT IMAG, V6, P1285, DOI 10.1109/TCI.2020.3018562
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosales R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P472
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P593, DOI 10.1109/TIM.2019.2902808
   Taigman Y., 2016, INT C LEARN REPR
   Tang H, 2023, IEEE T NEUR NET LEAR, V34, P1972, DOI 10.1109/TNNLS.2021.3105725
   Xu HH, 2022, IEEE T CIRC SYST VID, V32, P538, DOI 10.1109/TCSVT.2021.3067022
   Xu HH, 2021, IEEE J-STARS, V14, P8823, DOI 10.1109/JSTARS.2021.3108233
   Yang X, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108208
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zang ZL, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7172842
   Zhang SY, 2020, MULTIMED TOOLS APPL, V79, P14357, DOI 10.1007/s11042-018-6694-x
   Zhao B, 2018, LECT NOTES COMPUT SC, V11218, P157, DOI 10.1007/978-3-030-01264-9_10
   Zhao JM, 2019, ENG APPL ARTIF INTEL, V82, P263, DOI 10.1016/j.engappai.2019.04.003
   Zhao Y, 2021, PROC CVPR IEEE, P16413, DOI 10.1109/CVPR46437.2021.01615
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 45
TC 0
Z9 1
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43851
EP 43872
DI 10.1007/s11042-022-13115-4
EA MAY 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802892700002
DA 2024-07-18
ER

PT J
AU Marín-Lora, C
   Sotoca, JM
   Chover, M
AF Marin-Lora, Carlos
   Sotoca, Jose M.
   Chover, Miguel
TI Improved perception of ceramic molds through augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Product demonstration; Spatial presence; Decision
   comfort; Ceramic molds
ID E-COMMERCE; EDUCATION; SYSTEM
AB Augmented Reality techniques allow the user to visualize part of the real world through a display device by incorporating graphical information into the existing physical information. In this sense, it is important to know how the physical presence of the user in the augmented reality experience can affect the perception and evaluation of the product. To this end, this work presents a theoretical framework that explains how users perceive and evaluate the benefits and quality of augmentation with augmented reality through their physical presence, compared to visualizing the same experience through a video. The application was developed for the exhibition and sale of ceramic molds. Users viewed graphical information about the mold, placed between them and the screen while seeing themselves in the television as if it was a mirror. The experiments showed that the integration of the product into the environment and the spatial presence of the users had a positive effect on the perceived value in terms of usefulness and enjoyment, improved comfort in the purchase decision, and reinforced the overall opinion of the product.
C1 [Marin-Lora, Carlos; Sotoca, Jose M.; Chover, Miguel] Univ Jaume 1, Inst New Imaging Technol, Espaitec 2,Av Vicent Sos Baynat, Castellon de La Plana 12071, Spain.
C3 Universitat Jaume I
RP Chover, M (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Espaitec 2,Av Vicent Sos Baynat, Castellon de La Plana 12071, Spain.
EM cmarin@uji.es; sotoca@uji.es; chover@uji.es
FU Ministry of Science, Innovation and Universities
   [PID2019-106426RB-C32/AEI, RTI2018-098651-B-C54/AEI,
   PDC2021-120997C31/AEI]; Universitat Jaume I [UJI-B2018-56, UJI-B2018-44,
   UJI-FISABIO2020-04]; CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work was funded by the Ministry of Science,
   Innovation and Universities
   (PID2019-106426RB-C32/AEI/10.13039/501100011033,
   RTI2018-098651-B-C54/AEI/10.12039/501100011033,
   PDC2021-120997C31/AEI/10.13039/501100011033) and by research projects of
   the Universitat Jaume I (UJI-B2018-56, UJI-B2018-44,
   UJI-FISABIO2020-04).
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Aliprantis J., 2019, Int. J. Comput. Methods Herit. Sci, V3, P118, DOI DOI 10.4018/IJCMHS.2019070107
   [Anonymous], 2021, TECHNOLOGIES U UNITY
   [Anonymous], 2005, Journal of Services Marketing, DOI [DOI 10.1108/08876040510596803, 10.1108/08876040510596803]
   [Anonymous], 2021, GOOGLE ARCORE GOOGLE
   [Anonymous], 2021, VUFORIA VUFORIA ENGI
   [Anonymous], CEVISAMA INT FAIR CE
   García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bauer HH, 2006, J BUS RES, V59, P866, DOI 10.1016/j.jbusres.2006.01.021
   Beck M, 2018, J RETAIL CONSUM SERV, V40, P279, DOI 10.1016/j.jretconser.2016.08.006
   Berahmand K, 2019, COMPUTING, V101, P1711, DOI 10.1007/s00607-018-0684-8
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Bulearca M., 2010, Global Business Management Research, V2, P237
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Chi HL, 2013, AUTOMAT CONSTR, V33, P116, DOI 10.1016/j.autcon.2012.12.017
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   Connolly P, 2010, 65 MID C ENG DES GRA
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   Cardoso LFD, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106159
   Dorozhkin DV, 2012, VIRTUAL REAL-LONDON, V16, P15, DOI 10.1007/s10055-010-0165-7
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Frigo Mauricio A., 2016, Journal of Industrial and Intelligent Information, V4, P125, DOI 10.18178/jiii.4.2.125-130
   Galindo, 2008, PRESSES MOLDS COMPAC
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gottschalk Sebastian, 2020, Human-Centered Software Engineering. 8th IFIP WG 13.2 International Working Conference, HCSE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12481), P84, DOI 10.1007/978-3-030-64266-2_5
   Hartmann T, 2015, IMMERSED MEDIA TELEP
   Hilken T, 2017, J ACAD MARKET SCI, V45, P884, DOI 10.1007/s11747-017-0541-x
   Jetter J, 2018, COMPUT HUM BEHAV, V87, P18, DOI 10.1016/j.chb.2018.04.054
   Jreskog K. G., 2016, Multivariate analysis with LISREL
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Carmona PL, 2012, ENTROPY-SWITZ, V14, P323, DOI 10.3390/e14020323
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Li H, 2005, ADVERTISING PROMOTIO, P149
   Li Wenkai., 2017, Multimodal Technol Inter, V1, P17, DOI [DOI 10.3390/MTI1030017, 10.3390/mti1030017]
   Lu YZ, 2007, LECT NOTES COMPUT SC, V4551, P643
   Malhotra NK, 2014, REV BRASIL MARK, V13, P27, DOI 10.5585/remark.v13i2.2698
   Meegahapola L, 2017, INT CONF ADV ICT, P278
   Moloney J, 2006, INFORMATION VISUALIZATION-BOOK, P687
   Paelke V, 2014, 2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA)
   Parker JR, 2016, J CONSUM RES, V43, P113, DOI 10.1093/jcr/ucw010
   Poncin I, 2014, J RETAIL CONSUM SERV, V21, P851, DOI 10.1016/j.jretconser.2014.02.013
   Rauschnabel PA, 2019, J RETAIL CONSUM SERV, V49, P43, DOI 10.1016/j.jretconser.2019.03.004
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Spreer P., 2014, Transactions on Marketing Research, V1, P20, DOI [10.15764/MR.2014.01002, DOI 10.15764/MR.2014.01002]
   Sutherland IE, 1965, MULTIMEDIA WAGNER VI
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Vorderer P., 2004, Report to the European Community, Project Presence: MEC (IST-2001-37661), P3
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Zhu EG, 2014, PEERJ, V2, DOI 10.7717/peerj.469
NR 57
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43373
EP 43390
DI 10.1007/s11042-022-13168-5
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, BY
   Peng, YW
   Wang, C
AF Wu, Baiyan
   Peng, Yuwei
   Wang, Chao
TI A TTP watermarking protocol based on visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital copyright protection; TTP Watermarking protocol; Visual
   cryptography; Tripartite transaction model; Certification authority;
   Piracy tracing; Cryptosystem
ID PROTECTION; EFFICIENT; SCHEME
AB With the development of information technology, big data has had a positive impact on the development of various industries. All kinds of digital data trading platforms have been established accordingly. However, when the original data buyer illegally distributes the digital data that he has bought through the data trading platform, the copyright protection problem arises. Watermarking protocols designed for tracing illegal distributors when unauthorized copies are found provide good solutions for the above problem. Classic buyer-seller watermarking protocols are designed for two-party transaction models, not fit for the data trading platform-based tripartite transaction model. In this paper, the author proposes a TTP (Trusted Third Party) watermarking protocol based on visual cryptography for the tripartite transaction model. As far as we know, our proposed scheme is the first watermarking protocol for tripartite transaction models. Besides, by introducing computation-cheap visual cryptography, our scheme provides a good balance between some contradictory requirements, such as security versus efficiency. Through the security analysis, it can be found that the proposed scheme can solve the problems reported in the existing literatures and achieves several improvements over other schemes.
C1 [Wu, Baiyan] Hunan Univ Sci & Technol, Natl Local Joint Engn Lab Geospatial Informat Tec, Xiangtan 411201, Peoples R China.
   [Wu, Baiyan] Hunan Univ Sci & Technol, Hunan Prov Key Lab Geoinformat Engn Surveying Map, Xiangtan 411201, Peoples R China.
   [Peng, Yuwei] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Wang, Chao] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Hunan University of Science & Technology; Hunan University of Science &
   Technology; Wuhan University; Wuhan University
RP Wu, BY (corresponding author), Hunan Univ Sci & Technol, Natl Local Joint Engn Lab Geospatial Informat Tec, Xiangtan 411201, Peoples R China.; Wu, BY (corresponding author), Hunan Univ Sci & Technol, Hunan Prov Key Lab Geoinformat Engn Surveying Map, Xiangtan 411201, Peoples R China.
EM wby1029@sina.com
FU Foundation for Innovative Research Groups of the Natural Science
   Foundation of Hunan Province [2020JJ1003]; National Natural Science
   Foundation of China [41201389]
FX This work was partially supported by the project supported by the
   Foundation for Innovative Research Groups of the Natural Science
   Foundation of Hunan Province (Grant No. 2020JJ1003) and by the National
   Natural Science Foundation of China (Grant No.41201389).
CR Bianchi T, 2014, IEEE T INF FOREN SEC, V9, P1557, DOI 10.1109/TIFS.2014.2340581
   Chang CC, 2010, COMPUT SECUR, V29, P269, DOI 10.1016/j.cose.2009.08.008
   Chen TH, 2006, PATTERN RECOGN, V39, P1530, DOI 10.1016/j.patcog.2006.02.009
   Choi JG, 2003, LECT NOTES COMPUT SC, V2846, P265
   Cox I., 2001, Digital Watermarking
   Deng M., 2008, SECURE ANONYMOUS BUY, P524
   Deng M., P IEEE INT S ELECT C, V923, P929
   Eslami Z, 2014, MULTIMED TOOLS APPL, V72, P2723, DOI 10.1007/s11042-013-1555-0
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Frattolillo F, 2007, IEEE T INF FOREN SEC, V2, P350, DOI 10.1109/TIFS.2007.903849
   Frattolillo F, 2019, J INF SECUR APPL, V47, P246, DOI 10.1016/j.jisa.2019.05.011
   Frattolillo F, 2016, ACM T WEB, V10, DOI 10.1145/2856036
   Frattolillo F, 2015, COMPUT J, V58, P944, DOI 10.1093/comjnl/bxu015
   Huang J., 2016, MULTIMED TOOLS APPL, V76, P1
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Kumar A., 2011, INT J COMPUTER APPL, V21, P46, DOI [10.5120/2528-3441, DOI 10.5120/2528-3441]
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Paillier P., 1999, ADV CRYPTOLOGY EUROC, V1592
   Qiao LT, 1998, J VIS COMMUN IMAGE R, V9, P194, DOI 10.1006/jvci.1998.0391
   Rial A, 2011, IEEE T INF FOREN SEC, V6, P202, DOI 10.1109/TIFS.2010.2095844
   Rial A, 2010, IEEE T INF FOREN SEC, V5, P920, DOI 10.1109/TIFS.2010.2072830
   [王洪君 Wang Hongjun], 2018, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V54, P157
   Yang JC, 2020, IEEE NETWORK, V34, P62, DOI 10.1109/MNET.011.1900374
   Zhang J., 2006, IEE Proceedings-Information Security, V153, P15, DOI 10.1049/ip-ifs:20055069
   Zhongqiu Xu, 2012, International Journal of Information and Computer Security, V5, P1
NR 28
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41079
EP 41101
DI 10.1007/s11042-022-13002-y
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000796326500001
DA 2024-07-18
ER

PT J
AU Gupta, B
   Prakasam, P
   Velmurugan, T
AF Gupta, Bhart
   Prakasam, P.
   Velmurugan, T.
TI Integrated BERT embeddings, BiLSTM-BiGRU and 1-D CNN model for binary
   sentiment classification analysis of movie reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Binary sentiment classification; Movie review; Convolutional neural
   network; BiLSTM; Self-attention
ID OPINIONS; TEXT
AB Now a days, understanding the review of the articles, movies are the major issue due to different sentiment present on them. Reviews are short texts which expressing the opinion of the writer on certain texts and express the sentiment related to them. In the recent past, many researchers pay attention to sentiment analysis. In this research work, a novel binary sentiment classification is proposed to classify either positive or negative sentiment. First, the Bidirectional Encoder Representations from Transformers (BERT) embeddings are introduced to tokenize and preprocess the input text. The Bidirectional Long Short-Term Memory (BiLSTM) - Bidirectional Gated Recurrent Unit (BiGRU) and 1-D Convolutional Neural Network (CNN) model is integrated and proposed for sentiment classification. The proposed integrated BERT Embedding and BiLSTM-BiGRU is applied to extract the specified target and self-attention layer is added for better understanding of context, further 1-D CNN along with few other deep learning layers, the sentiment is classified for the selected IMDB movie review dataset. The proposed BERT Embedding + BiLSTM-BiGRU + self-attention and 1-D CNN model is trained and validated with the IMDB movie review dataset. From the simulation, it is found that the testing accuracy and AUC (Area Under the Curve) values are 93.89% and 0.9828 respectively. The performance of the proposed integrated BERT Embedding + BiLSTM-BiGRU+ self-attention and 1-D CNN model is compared with existing models and it is observed that it outperforms better in binary sentiment classification analysis.
C1 [Gupta, Bhart; Prakasam, P.; Velmurugan, T.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Prakasam, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM bhartgupta4747@gmail.com; prakasamp@gmail.com; tvelmurugan@vit.ac.in
RI p, p/JED-5004-2023; P, Prakasam/B-3075-2016
OI P, Prakasam/0000-0002-2471-6375
CR Alaparthi S, 2020, ARXIV200701127, P01
   Ali NM., 2019, INT J DATA MIN KNOWL, V9, P19, DOI 10.5121/ijdkp.2019.9302
   Amit M, 2016, ARXIV1610082229V1
   An HW, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01521-w
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367513
   [Anonymous], 2015, Sentiment analysis
   Appel O, 2016, KNOWL-BASED SYST, V108, P110, DOI 10.1016/j.knosys.2016.05.040
   Bodapati Jyostna Devi, 2019, Ingenierie des systemes d'information, V24, P125, DOI 10.18280/isi.240119
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Catal C, 2017, APPL SOFT COMPUT, V50, P135, DOI 10.1016/j.asoc.2016.11.022
   Chaturvedi I, 2016, KNOWL-BASED SYST, V108, P144, DOI 10.1016/j.knosys.2016.07.019
   Chen YL, 2018, C IND ELECT APPL, P2731, DOI 10.1109/ICIEA.2018.8398173
   Cheng Y, 2020, IEEE ACCESS, V8, P134964, DOI 10.1109/ACCESS.2020.3005823
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Fernández-Gavilanes M, 2016, EXPERT SYST APPL, V58, P57, DOI 10.1016/j.eswa.2016.03.031
   Ganapathibhotla M., 2008, COLING 2008 22 INT C, P241, DOI DOI 10.3115/1599081.1599112
   Garg K, 2021, MULTIMED TOOLS APPL, V80, P19885, DOI 10.1007/s11042-021-10559-y
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Jindal N., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P244, DOI 10.1145/1148170.1148215
   Khan FH, 2016, APPL SOFT COMPUT, V39, P140, DOI 10.1016/j.asoc.2015.11.016
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Lai HL, 2022, MULTIMED TOOLS APPL, V81, P19415, DOI 10.1007/s11042-021-11234-y
   Li D, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), P471, DOI 10.1109/CCI.2016.7778967
   Li WT, 2019, INT C PAR DISTRIB SY, P774, DOI 10.1109/ICPADS47876.2019.00114
   LIU W, 2019, IEEE ACCESS, V7, P13
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Minaee S, 2019, ARXIV190404206V1
   Mitchell M., 2013, P 2013 C EMPIRICAL M, P1643
   Munikar Manish, 2019, 2019 ARTIFICIAL INTE, V1, P1, DOI DOI 10.1109/AITB48515.2019.8947435
   Narayanan R., 2009, Proceedings of EMNLP '09, V1, P180, DOI 10.3115/1699510.1699534
   Naz H, 2021, MULTIMED TOOLS APPL, V80, P11443, DOI 10.1007/s11042-020-10190-3
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Rill S, 2014, KNOWL-BASED SYST, V69, P24, DOI 10.1016/j.knosys.2014.05.008
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shaukat Z, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1926-x
   Shen JH, 2019, PROC SPIE, V11321, DOI 10.1117/12.2550215
   Singh NK, 2020, J AMB INTEL HUM COMP, V11, P97, DOI 10.1007/s12652-018-0862-8
   Tang D, 2016, P C EMP METH NAT LAN, P214, DOI DOI 10.18653/V1/D16-1021
   Tang DY, 2015, WIRES DATA MIN KNOWL, V5, P292, DOI 10.1002/widm.1171
   Tang DY, 2015, IEEE-ACM T AUDIO SPE, V23, P1750, DOI 10.1109/TASLP.2015.2449071
   Verma P, 2019, INT J INNOV TECHNOL, V8, P337, DOI DOI 10.35940/IJITEE.K1343.0981119
   Victor M, 2016, ARXIV161003759
   WADAWADAGI RS, 2019, INT J KNOWL WEB INTE, V6, P51, DOI DOI 10.1504/IJKWI.2019.103616
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Xu KQ, 2011, DECIS SUPPORT SYST, V50, P743, DOI 10.1016/j.dss.2010.08.021
   Yang S., 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, P1636
   Yu Q, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P116, DOI 10.1145/3357254.3357262
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhou K., 2018, 2018 24 INT C AUT CO, P1, DOI DOI 10.23919/ICONAC.2018.8749069
NR 55
TC 8
Z9 8
U1 13
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33067
EP 33086
DI 10.1007/s11042-022-13155-w
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800006
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Wang, WY
   Yu, GH
   Wang, J
   Tang, L
AF Zhu, Yun
   Wang, Weiye
   Yu, Gaohang
   Wang, Jun
   Tang, Lei
TI A Bayesian robust CP decomposition approach for missing traffic data
   imputation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Missing data; CP tensor decomposition; Sparse tensor; Fully Bayesian
   treatment; Variational reasoning
ID TENSOR; FACTORIZATION; COMPLETION; DISCOVERY
AB The inevitable problem of missing data is ubiquitous in the real transportation system, which makes the data-driven intelligent transportation system suffer from incorrect response. We propose a Bayesian robust Candecomp/Parafac (CP) tensor decomposition (BRCP) approach to deal with missing data and outliers by integrating the general form of transportation system domain knowledge. Specifically, when the lower rank tensor captures the global information, the sparse tensor is added to capture the local information, which can robustly predict the distribution of missing items and under the fully Bayesian treatment, the effective variational reasoning can prevent the over fitting problem. Real and reliable traffic data sets are used to evaluate the performance of the model in two data missing scenarios, which the experimental results show that the proposed BRCP model achieves the best imputation accuracy and is better than the most advanced baseline (Bayesian Gaussian CP decomposition (BGCP), high accuracy low-rank tensor completion (HaLRTC) and SVD-combined tensor decomposition (STD)), even in the case of high missed detection rate, the model still has the best performance and robustness.
C1 [Zhu, Yun; Wang, Weiye; Wang, Jun; Tang, Lei] Gannan Normal Univ, Sch Phys & Elect Informat, Ganzhou 341000, Peoples R China.
   [Yu, Gaohang] Hangzhou Dianzi Univ, Sch Sci, Hangzhou 310018, Peoples R China.
C3 Gannan Normal University; Hangzhou Dianzi University
RP Yu, GH (corresponding author), Hangzhou Dianzi Univ, Sch Sci, Hangzhou 310018, Peoples R China.
EM yxwywang@163.com
RI wang, weiye/HII-8503-2022; tang, lei/JCO-4117-2023; Yu,
   Gaohang/F-2329-2011
FU National Natural Science Foundation of China [12071104]
FX This work was financially supported by the National Natural Science
   Foundation of China (No.12071104).
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Bhanu M, 2021, IEEE T INTELL TRANSP, V22, P3359, DOI 10.1109/TITS.2020.2984175
   Chen XY, 2022, IEEE T PATTERN ANAL, V44, P4659, DOI 10.1109/TPAMI.2021.3066551
   Chen XY, 2019, TRANSPORT RES C-EMER, V104, P66, DOI 10.1016/j.trc.2019.03.003
   Chen XY, 2019, TRANSPORT RES C-EMER, V98, P73, DOI 10.1016/j.trc.2018.11.003
   Chen XY, 2018, TRANSPORT RES C-EMER, V86, P59, DOI 10.1016/j.trc.2017.10.023
   Gong CF, 2020, IEEE ACCESS, V8, P11124, DOI 10.1109/ACCESS.2020.2964299
   Goulart JHD, 2017, TRANSPORT RES C-EMER, V85, P348, DOI 10.1016/j.trc.2017.09.011
   Jia T, 2021, IEEE T INTELL TRANSP, V22, P3101, DOI 10.1109/TITS.2020.2979634
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li YQ, 2021, IEEE ACCESS, V9, P11264, DOI 10.1109/ACCESS.2021.3050836
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Ran B, 2016, PHYSICA A, V446, P54, DOI 10.1016/j.physa.2015.09.105
   Rodrigues F, 2019, IEEE T INTELL TRANSP, V20, P594, DOI 10.1109/TITS.2018.2817879
   Tan HC, 2016, IEEE T INTELL TRANSP, V17, P2123, DOI 10.1109/TITS.2015.2513411
   Zhao QB, 2015, IEEE T PATTERN ANAL, V37, P1751, DOI 10.1109/TPAMI.2015.2392756
   Zhou G., 2015, IEEE T NEUR NET LEAR, V13, P736, DOI DOI 10.1109/TNNLS.2015.2423694
NR 17
TC 6
Z9 6
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33171
EP 33184
DI 10.1007/s11042-022-13069-7
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800012
DA 2024-07-18
ER

PT J
AU Khaire, P
   Kumar, P
AF Khaire, Pushpajit
   Kumar, Praveen
TI Online suspicious event detection in a constrained environment with RGB
   plus D camera using multi-stream CNNs and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Depth sensor; Surveillance; Action recognition; RGB-D;
   Convolutional neural networks
ID HUMAN ACTION RECOGNITION
AB Automated detection of human actions is very important for surveillance of government offices, Bank-ATMs, etc. to prevent crime and loss of property and lives of people. Currently, such environments are monitored by CCTV cameras which give only RGB frame of the scene. To detect unusual human actions, we propose to use a depth sensor, as it additionally provides depth and skeletal data of human being. This paper presents a 2-stage framework to detect a suspicious event and unsafe activity in an ATM as a use case of constrained environment. In the first stage, any suspicious event which arises due to unusual human actions is detected proactively in real-time. This is achieved by classifying motion representation images of RGB and Depth video segments using multi-stream CNNs (Convolutional Neural Networks). In the second stage, entire activity is analyzed as safe or unsafe by classifying spatiotemporal skeleton features through SVM (Support Vector Machine). Due to the unavailability of datasets for analyzing human actions in Bank-ATMs, we also contributed a unique RGB+D dataset by replicating activities in ATM-like environment. Experimental results show that our approach can detect suspicious event with 0.807 F-measure and classifies activities with 89.1% accuracy.
C1 [Khaire, Pushpajit; Kumar, Praveen] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Khaire, P (corresponding author), Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM pushpjitkhaire@gmail.com
RI Kumar, Praveen/AAA-8584-2022; KHAIRE, PUSHPAJIT/AFK-2217-2022
OI Kumar, Praveen/0000-0003-4820-3088; KHAIRE,
   PUSHPAJIT/0000-0002-4065-4338
FU Science and Engineering Research Board (SERB) [ECR/2016/000387];
   Department of Science & Technology (DST), Government of India
FX This research was supported by Science and Engineering Research Board
   (SERB) under project no. ECR/2016/000387, in cooperation with the
   Department of Science & Technology (DST), Government of India. The views
   and conclusions contained in this document are those of the authors and
   should not be interpreted as representing the official policies, either
   expressed or implied, of DST-SERB or the Government of India. The
   DST-SERB or Government of India is authorized to reproduce and
   distribute reprints for Government purposes notwithstanding any
   copyright notation thereon.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2015, PROC CVPR IEEE
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YS, 2020, MOBILE NETW APPL, V25, P426, DOI 10.1007/s11036-019-01245-3
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Greenwood, 2013, P 11 ACM C EMB NETW, P75
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Huynh-The T, 2020, IEEE T IND INFORM, V16, P3100, DOI 10.1109/TII.2019.2910876
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Imran J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P144, DOI 10.1109/ICACCI.2016.7732038
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Karg M, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1351
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khaire Pushpajit, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P409, DOI 10.1007/978-981-10-7895-8_32
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu F., 2012, P 20 ACM INT C MULTI, P1295
   Liu MY, 2019, AAAI CONF ARTIF INTE, P8762
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mansur A, 2013, IEEE T CYBERNETICS, V43, P1226, DOI 10.1109/TSMCB.2012.2226879
   McNally W, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P49, DOI 10.1109/CRV.2019.00015
   Nar R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2042, DOI 10.1109/ICACCI.2016.7732351
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Simonyan K, 2014, ADV NEUR IN, V27
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Theodorakopoulos I, 2014, J VIS COMMUN IMAGE R, V25, P12, DOI 10.1016/j.jvcir.2013.03.008
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121511
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
NR 40
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32857
EP 32881
DI 10.1007/s11042-022-12656-y
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782544500001
DA 2024-07-18
ER

PT J
AU Singh, B
   Sharma, MK
AF Singh, Balkar
   Sharma, M. K.
TI Efficient watermarking technique for protection and authentication of
   document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document watermarking; Zero width characters; MD5; Integrity rate
ID TEXT; STEGANOGRAPHY; ALGORITHM
AB In this paper, a hashing based watermarking technique for the protection and authentication of document image is proposed. Message Digest 5 (MD5) hashing is applied on the cover document image to produce its hash value. This hash value is further translated to Unicode Zero Width Characters (ZWC) by using a lookup table. Watermark is also translated to ZWC prior to embedding in the input image. At the end of each sentence, both of these ZWC are inserted in the cover image. At the receiver end, this watermark is regenerated from its embedded ZWCs and used for the security purposes. The hash value of the cover image is used to detect tampering. The embedded data does not degrade the cover image as invisible Unicode white spaces are used in place of original watermark and hash value. The proposed technique's effectiveness is demonstrated by comparison to existing state-of-the-art techniques.
C1 [Singh, Balkar] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Sharma, M. K.] Thapar Inst Engn & Technol, Sch Math, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Singh, B (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM balkar.singh@thapar.edu; mksharma@thapar.edu
CR Addison A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.1080/19409052.2016.1267657, DOI 10.17485/ijst/2016/v9i48/87787]
   Ahvanooey MT, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101702
   Ahvanooey MT, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5325040
   Ahvanooey MT, 2016, INF SECUR J, V25, P191, DOI 10.1080/19393555.2016.1202356
   Alotaibi RA, 2018, J KING SAUD UNIV-COM, V30, P236, DOI 10.1016/j.jksuci.2016.12.007
   Bharti, 2020, ADV INTELL SYST COMP, V999, P657
   Hakak SI, 2019, IEEE ACCESS, V7, P69614, DOI 10.1109/ACCESS.2019.2914071
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Khosravi B, 2019, J INF SECUR APPL, V45, P61, DOI 10.1016/j.jisa.2019.01.003
   Kumar, 2020, DIQA DATASET
   Laouamer L, 2015, ARAB J SCI ENG, V40, P1097, DOI 10.1007/s13369-015-1596-y
   Mohamed AA, 2014, EGYPT INFORM J, V15, P79, DOI 10.1016/j.eij.2014.04.002
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Naqvi N, 2018, WIRELESS PERS COMMUN, V103, P1563, DOI 10.1007/s11277-018-5868-1
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Patiburn S., 2017, International Journal of Education and Management Engineering, V7, P1, DOI DOI 10.5815/IJEME.2017.03
   Por LY, 2012, J SYST SOFTWARE, V85, P1075, DOI 10.1016/j.jss.2011.12.023
   Rivest R., 1992, Tech. Rep.
   Rizzo S.G., 2016, P INT DAT ENG APPL S, P97
   Rizzo S. G., 2017, P 2017 IEEE ACM INT, P208
   Rui X, 2013, PROCEDIA COMPUT SCI, V17, P844, DOI 10.1016/j.procs.2013.05.108
   Subramanyam AV, 2014, MULTIMED TOOLS APPL, V71, P1311, DOI 10.1007/s11042-012-1272-0
NR 22
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22985
EP 23005
DI 10.1007/s11042-022-12174-x
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000781336500003
DA 2024-07-18
ER

PT J
AU Ghulanavar, R
   Jagadeesh, A
   Dama, KK
AF Ghulanavar, Rohit
   Jagadeesh, A.
   Dama, Kiran Kumar
TI Faulty gear diagnosis using weighted PCA with swish activated BLSTM
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; BLSTM; WPCA; ANN; NN; Gear; Vibration signal
ID STOCHASTIC RESONANCE; EXTRACTION
AB The early faulty gear diagnosis is most necessary in the industry. In the current decade, with the tremendous growth of ANN (Artificial Neural Network), the researcher planned to use DL (Deep Learning) methods to sketch out faults in gear in an early stage. Traditional gear fault diagnosis method mostly utilizes deep NN (Neural Network) related to tine sequence of gathered signals. In this instance, feature extraction in the direction of inverse time domain signal is commonly ignored. To overcome this issue, here in this paper, proposed Weighted Principal Component Analysis (WPCA) and BLSTM (Bi-Directional Long Short Term Memory) along with Swish Activation function for faulty gear diagnosis from the vibration signals. WPCA is utilized to extract multi-scale features related to faulty gear from the vibration signal. Likewise, BLSTM is used to classify the extracted features to diagnose the fault in an earlier stage. Several experiments were conducted to evaluate the proposed work of categorizing the defects in gear from the vibrating signal. Experiments were conducted on three kinds of the dataset to classify the type of faulty gear accurately. The proposed work proves its superiority in organizing the gear faults in a most efficient way than existing methods.
C1 [Ghulanavar, Rohit; Jagadeesh, A.; Dama, Kiran Kumar] Koneru Lakshmaiah Educ Fdn, Dept Mech Engn, Vijayawada 522502, AP, India.
   [Ghulanavar, Rohit] KITs Coll Engn, Dept Mech Engn, Kolhapur 416234, MS, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Ghulanavar, R (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Mech Engn, Vijayawada 522502, AP, India.; Ghulanavar, R (corresponding author), KITs Coll Engn, Dept Mech Engn, Kolhapur 416234, MS, India.
EM grohit0801@gmail.com
RI Dama, Kiran Kumar/Q-7009-2019; GHULANAVAR, ROHIT/AGE-2596-2022
OI Dama, Kiran Kumar/0000-0001-6933-6838; GHULANAVAR,
   ROHIT/0000-0002-0906-1059; A, Jagadeesh/0000-0003-3012-1981
CR Abood OG, 2017, PROC INT MID EAST P, P644, DOI 10.1109/MEPCON.2017.8301249
   Akram MA, 2019, ADV SCI TECHNOL-RES, V13, P192, DOI 10.12913/22998624/111663
   Athiwaratkun B, 2017, INT CONF ACOUST SPEE, P2482, DOI 10.1109/ICASSP.2017.7952603
   Cerrada M, 2016, APPL INTELL, V44, P687, DOI 10.1007/s10489-015-0725-3
   Ding XX, 2017, IEEE T INSTRUM MEAS, V66, P1926, DOI 10.1109/TIM.2017.2674738
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Han T, 2018, MEASUREMENT, V118, P181, DOI 10.1016/j.measurement.2018.01.036
   He GL, 2016, J SOUND VIB, V366, P514, DOI 10.1016/j.jsv.2015.12.020
   Huang WG, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107273
   Jinsakul N, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7121170
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Lei YG, 2013, MECH SYST SIGNAL PR, V38, P113, DOI 10.1016/j.ymssp.2012.06.021
   Li B, 2017, MECH SYST SIGNAL PR, V85, P415, DOI 10.1016/j.ymssp.2016.08.036
   Li Y, 2018, MEASUREMENT, V130, P94, DOI 10.1016/j.measurement.2018.08.002
   Liu HY, 2014, SIGNAL PROCESS, V96, P118, DOI 10.1016/j.sigpro.2013.05.013
   López-Nicolás C, 2011, INT J INFORM MANAGE, V31, P502, DOI 10.1016/j.ijinfomgt.2011.02.003
   Lu SL, 2019, MECH SYST SIGNAL PR, V116, P230, DOI 10.1016/j.ymssp.2018.06.032
   Mishra S, 2019, STUD COMPUT INTELL, V776, P455, DOI 10.1007/978-3-662-57277-1_19
   Park S, 2018, MECH SYST SIGNAL PR, V108, P262, DOI 10.1016/j.ymssp.2018.02.028
   Qi LY, 2016, COMPUTING, V98, P195, DOI 10.1007/s00607-014-0413-x
   Qin Y, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/8/085003
   Shao SY, 2019, IEEE T IND INFORM, V15, P2446, DOI 10.1109/TII.2018.2864759
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Singh J, 2017, MECH SYST SIGNAL PR, V87, P307, DOI 10.1016/j.ymssp.2016.10.028
   Sun RB, 2018, MECH SYST SIGNAL PR, V102, P346, DOI 10.1016/j.ymssp.2017.09.028
   Tripathi GC, 2019, TENCON IEEE REGION, P1239, DOI [10.1109/tencon.2019.8929500, 10.1109/TENCON.2019.8929500]
   Wang D, 2019, MEASUREMENT, V133, P328, DOI 10.1016/j.measurement.2018.10.018
   Wang L, 2019, IEEE T INSTRUM MEAS, V68, P450, DOI 10.1109/TIM.2018.2851423
   Wang TY, 2017, J SOUND VIB, V392, P367, DOI 10.1016/j.jsv.2016.12.041
   Wang ZJ, 2019, MEASUREMENT, V140, P63, DOI 10.1016/j.measurement.2019.03.033
   Wen L, 2020, NEURAL COMPUT APPL, V32, P6111, DOI 10.1007/s00521-019-04097-w
   Xie JY, 2017, IEEE GEOSCI REMOTE S, V14, P1213, DOI 10.1109/LGRS.2017.2703611
   Yang Y, 2015, J SOUND VIB, V335, P350, DOI 10.1016/j.jsv.2014.09.025
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
NR 35
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30351
EP 30364
DI 10.1007/s11042-022-12823-1
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mahajan, S
   Abualigah, L
   Pandit, AK
AF Mahajan, Shubham
   Abualigah, Laith
   Pandit, Amit Kant
TI Hybrid arithmetic optimization algorithm with hunger games search for
   global optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hunger games search; Arithmetic optimization algorithm; Engineering
   design problems; Metaheuristic; Swarm intelligence; Optimization methods
ID EVOLUTIONARY ALGORITHMS; PREDICTION; EFFICIENT; STATES; MATTER
AB Recently, many population-dependent methods have been proposed. Despite their acceptance in many applications, we are still exploring suggested methods to solve actual problems. Consequently, researchers need to change and refine their procedures significantly based on the major evolutionary processes to achieve quicker convergence, more consistent equilibrium with high-quality performance and optimization. Therefore, a new hybrid method using Hunger Games Search (HGS) and Arithmetic Optimization Algorithm (AOA) is proposed in this paper. HGS is a recently proposed population-dependent optimization method that stabilizes the features and efficiently performs unconstrained and constrained problems. In contrast, AOA is a modern meta-heuristic optimization method. They can be applied to different problems, including image processing, machine learning, wireless networks, power systems, engineering design etc. The proposed method is analyzed in context with HGS and AOA. Each method is tested on the same parameters like population size and no. of iteration to evaluate the performance. The proposed method (AOA-HGS) is assessed by varying the dimensions on 23 functions (F1-F23). The impact of varying dimensions is a standard test utilized in previous studies for optimizing test functions that show the effect of varying dimensions on the efficiency of AOA-HGS. From this, it is noted that it works efficiently for both high and low dimensional problems. In high dimensional problem population, dependent methods give efficient search results. The AOA-HGS is very competitive and superior compared with others on test functions. No. of optimization methods obtained optimum results, but AOA-HGS has the best when compared with all. So, AOA-HGS is capable of getting optimum results.
C1 [Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Sch Elect & Commun, Katra 182320, J&k, India.
   [Abualigah, Laith] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
C3 Shri Mata Vaishno Devi University; Universiti Sains Malaysia
RP Mahajan, S (corresponding author), Shri Mata Vaishno Devi Univ, Sch Elect & Commun, Katra 182320, J&k, India.
EM mahajanshubham2232579@gmail.com; aligah.2020@gmail.com;
   amitkantpandit@gmail.com
RI Abualigah, Laith/ABC-9695-2020; MAHAJAN, SHUBHAM/AAY-6389-2020
OI Abualigah, Laith/0000-0002-2203-4549; MAHAJAN,
   SHUBHAM/0000-0003-0385-3933
CR Abd Elaziz M, 2021, FUTURE GENER COMP SY, V124, P142, DOI 10.1016/j.future.2021.05.026
   Abualigah L., 2021, CLUSTER COMPUT, V24, P2161, DOI DOI 10.1007/s10586-021-03254-y
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Alshaer HN, 2021, MULTIMED TOOLS APPL, V80, P10373, DOI 10.1007/s11042-020-10074-6
   Altabeeb AM, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107403
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Boussaïd I, 2013, INFORM SCIENCES, V237, P82, DOI 10.1016/j.ins.2013.02.041
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Coello CAC, 2002, COMPUT METHOD APPL M, V191, P1245, DOI 10.1016/S0045-7825(01)00323-1
   COLORNI A, 1992, FROM ANIM ANIMAT, P134
   Cuevas E, 2014, APPL INTELL, V40, P256, DOI 10.1007/s10489-013-0458-0
   Cuevas E, 2013, EXPERT SYST APPL, V40, P6359, DOI 10.1016/j.eswa.2013.05.055
   Davis L., 1991, PROC INT C GENETIC A, P18
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Eid A, 2021, NEURAL COMPUT APPL, V33, P14327, DOI 10.1007/s00521-021-06078-4
   Fogel D.B., 1998, Artificial intelligence through simulated evolution
   Ghosh KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114485
   Glover F., 1990, ORSA Journal on Computing, V2, P4, DOI [10.1287/ijoc.1.3.190, 10.1287/ijoc.2.1.4]
   Gogna A, 2013, J EXP THEOR ARTIF IN, V25, P503, DOI 10.1080/0952813X.2013.782347
   Hassan MH, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115205
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Kaur H., 2021, DATA DRIVEN APPROACH
   Kaveh A, 2016, COMPUT STRUCT, V165, P1, DOI 10.1016/j.compstruc.2015.11.012
   Kaveh A, 2013, ADV ENG SOFTW, V59, P53, DOI 10.1016/j.advengsoft.2013.03.004
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Li J, 2020, INFORM SCIENCES, V519, P289, DOI 10.1016/j.ins.2020.01.046
   Li J, 2017, KNOWL-BASED SYST, V127, P58, DOI 10.1016/j.knosys.2017.02.032
   Li J, 2014, INFORM SCIENCES, V269, P238, DOI 10.1016/j.ins.2013.12.015
   Liu EB, 2019, IEEE ACCESS, V7, P83251, DOI 10.1109/ACCESS.2019.2924515
   Lourenco H. R., 2003, Handbook of metaheuristics, P320, DOI DOI 10.1007/0-306-48056-5_11
   Mahajan S., 2021, MULTIMED TOOLS APPL
   Mahajan S, 2022, SOFT COMPUT, P1
   Mahajan S, 2021, MULTIMED TOOLS APPL, V80, P19335, DOI 10.1007/s11042-021-10641-5
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Michalewicz Z., 2013, Genetic algorithms+data structures=evolution programs
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mirjalili S, 2013, SWARM EVOL COMPUT, V9, P1, DOI 10.1016/j.swevo.2012.09.002
   Pang JH, 2018, COMPUT IND ENG, V123, P54, DOI 10.1016/j.cie.2018.06.017
   Sahin CB, 2021, NEURAL COMPUT APPL, V33, P14049, DOI 10.1007/s00521-021-06047-x
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sharaff Aakanksha, 2020, 2020 INT C SYST COMP
   Sharma D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P396, DOI [10.1109/iccs45141.2019.9065686, 10.1109/ICCS45141.2019.9065686]
   Spall, 2005, INTRO STOCHASTIC SEA, V65
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wen FH, 2017, INT J INF TECH DECIS, V16, P205, DOI 10.1142/S0219622016500504
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yan JK, 2020, INFORM FUSION, V55, P173, DOI 10.1016/j.inffus.2019.08.010
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang XS., 2010, RES DEV INTELLIGENT
   Yang YT, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114864
   Zhou AM, 2011, SWARM EVOL COMPUT, V1, P32, DOI 10.1016/j.swevo.2011.03.001
NR 57
TC 30
Z9 30
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28755
EP 28778
DI 10.1007/s11042-022-12922-z
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900012
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Paliwal, S
   Chandrakar, A
   Prabukumar, M
AF Agilandeeswari, L.
   Paliwal, Swapnil
   Chandrakar, Anvita
   Prabukumar, M.
TI A new lightweight conditional privacy preserving authentication and key
   - agreement protocol in social internet of things for vehicle to smart
   grid networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart Grid; Vehicle-to-grid (V2G); Social Internet of Things;
   Lightweight Authentication; Key Agreement; AVISPA; Real; or; Random
   oracle model
ID WIRELESS SENSOR NETWORKS; USER AUTHENTICATION; SCHEME; EXCHANGE
AB Smart grid systems play a vital role in resource management and distributions within a given supply chain. Vehicle-to-grid (V2G) technology is a perfect fit for real-world application as it provides a better and more efficient means for managing electric power. However, ensuring the security and privacy of this technology has become a significant concern, which is due to the difficulty in achieving security goals. In this paper, a lightweight Authentication and Key Agreement protocol named A2P that can ensure low energy consumption and rapid delivery from the source is proposed. Here, a lightweight XOR-based authentication scheme with an unpredictable pseudonym update phase is introduced. The pseudonym update phase is in such a fashion that no relationship amongst two updated pseudonyms can ever be derived even if sensitive information was compromised, thus enhancing privacy. The proposed A2P protocol can reduce the load on the grid and establish an expedited response system for future needs. To provide evidence for the real-time application of the proposal, we have presented a formal and informal analysis of our work. The formal analysis is achieved using Automated Validation Information Security Protocols and Applications (AVISPA), and simulation in the Real - or - Random Oracle (ROR) model, while an informal analysis via proving how our proposals can withstand malicious attacks namely DOS attack, replay attack, party corruption, etc. An extensive performance analysis proves that the proposed A2P system is 22.22% computationally efficient when compared to the related state-of-art methods.
C1 [Agilandeeswari, L.; Paliwal, Swapnil; Chandrakar, Anvita; Prabukumar, M.] Vellore Inst Technol, Sch Informat Technol & Engn SITE, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn SITE, Vellore 632014, Tamil Nadu, India.
EM agila.l@vit.ac.in
RI L, Agilandeeswari/P-8997-2016
OI L, Agilandeeswari/0000-0001-6147-9535
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Abdallah A, 2017, IEEE T VEH TECHNOL, V66, P2615, DOI 10.1109/TVT.2016.2577018
   Chang CC, 2016, IEEE T WIREL COMMUN, V15, P357, DOI 10.1109/TWC.2015.2473165
   Choi Y, 2014, SENSORS-BASEL, V14, P10081, DOI 10.3390/s140610081
   Cui J, 2018, VEH COMMUN, V14, P15, DOI 10.1016/j.vehcom.2018.09.003
   Dua A, 2018, IEEE T VEH TECHNOL, V67, P4359, DOI 10.1109/TVT.2017.2780183
   Faheem M, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.03.009
   Faheem M, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3503
   Faheem M, 2018, COMPUT SCI REV, V30, P1, DOI 10.1016/j.cosrev.2018.08.001
   Faheem M, 2019, INT J AD HOC UBIQ CO, V32, P236
   Gope P, 2016, IEEE T IND ELECTRON, V63, P7124, DOI 10.1109/TIE.2016.2585081
   Islam SKH, 2018, FUTURE GENER COMP SY, V84, P216, DOI 10.1016/j.future.2017.07.002
   Jiang Q, 2016, J NETW COMPUT APPL, V76, P37, DOI 10.1016/j.jnca.2016.10.001
   Khalid U, 2020, CLUSTER COMPUT, V23, P2067, DOI 10.1007/s10586-020-03058-6
   Lee JS, 2007, J NETW COMPUT APPL, V30, P1377, DOI 10.1016/j.jnca.2006.10.003
   Li X, 2018, IEEE T IND INFORM, V14, P3599, DOI 10.1109/TII.2017.2773666
   Liu YD, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/492819
   Muthumeenakshi R, 2017, COMPUT ELECTR ENG, V59, P27, DOI 10.1016/j.compeleceng.2017.03.011
   Otuoze Abdulrahaman Okino, 2018, Journal of Electrical Systems and Information Technology, V5, P468, DOI 10.1016/j.jesit.2018.01.001
   Ourahou M, 2020, MATH COMPUT SIMULAT, V167, P19, DOI 10.1016/j.matcom.2018.11.009
   Paliwal, 2021, US. Patent, Patent No. 17058828
   Paliwal S., 2018, ADV INTELLIGENT SYST, V736
   Paliwal S, 2019, IEEE ACCESS, V7, P136073, DOI 10.1109/ACCESS.2019.2941701
   Rottondi C, 2014, ENERGIES, V7, P2780, DOI 10.3390/en7052780
   Shen J, 2018, IEEE INTERNET THINGS, V5, P2526, DOI 10.1109/JIOT.2017.2775248
   Shen J, 2021, IEEE T BIG DATA, V7, P668, DOI 10.1109/TBDATA.2017.2705048
   Stegelmann M., 2011, European Public Key Infrastructure Workshop, P75
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wan ZG, 2016, COMPUT SECUR, V62, P246, DOI 10.1016/j.cose.2016.07.004
   Wang HQ, 2015, IEEE T INF FOREN SEC, V10, P2340, DOI 10.1109/TIFS.2015.2455513
   Wang Y, 2020, INT J HYDROGEN ENERG, V45, P18995, DOI 10.1016/j.ijhydene.2020.05.098
   Wu F, 2017, J AMB INTEL HUM COMP, V8, P101, DOI 10.1007/s12652-016-0345-8
   Xie Q, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/325734
   Yang X, 2019, VEH COMMUN, V15, P16, DOI 10.1016/j.vehcom.2018.11.001
   Zhang Y, 2013, IEEE WIREL COMMUN, V20, P66, DOI 10.1109/MWC.2013.6704476
   Zhao QY, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102355
NR 36
TC 2
Z9 2
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27683
EP 27710
DI 10.1007/s11042-022-12946-5
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800015
DA 2024-07-18
ER

PT J
AU Greco, A
   Strisciuglio, N
   Vento, M
   Vigilante, V
AF Greco, Antonio
   Strisciuglio, Nicola
   Vento, Mario
   Vigilante, Vincenzo
TI Benchmarking deep networks for facial emotion recognition in the wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Robustness; Emotion recognition; Expression
   recognition; Face analysis; Deep learning; Benchmarking
ID EXPRESSION RECOGNITION; CLASSIFICATION
AB Emotion recognition from face images is a challenging task that gained interest in recent years for its applications to business intelligence and social robotics. Researchers in computer vision and affective computing focused on optimizing the classification error on benchmark data sets, which do not extensively cover possible variations that face images may undergo in real environments. Following on investigations carried out in the field of object recognition, we evaluated the robustness of existing methods for emotion recognition when their input is subjected to corruptions caused by factors present in real-world scenarios. We constructed two data sets on top of the RAF-DB test set, named RAF-DB-C and RAF-DB-P, that contain images modified with 18 types of corruption and 10 of perturbation. We benchmarked existing networks (VGG, DenseNet, SENet and Xception) trained on the original images of RAF-DB and compared them with ARM, the current state-of-the-art method on the RAF-DB test set. We carried out an extensive study on the effects that modifications to the training data or network architecture have on the classification of corrupted and perturbed data. We observed a drop of recognition performance of ARM, with the classification error raising up to 200% of that achieved on the original RAF-DB test set. We demonstrate that the use of the AutoAugment data augmentation and an anti-aliasing filter within down-sampling layers provide existing networks with increased robustness to out-of-distribution variations, substantially reducing the error on corrupted inputs and outperforming ARM. We provide insights about the resilience of existing emotion recognition methods and an estimation of their performance in real scenarios. The processing time required by the modifications we investigated (35 ms in the worst case) supports their suitability for application in real-world scenarios. The RAF-DB-C and RAFDB-P test sets, trained models and evaluation framework are available at https://github.com/MiviaLab/emotion-robustness.
C1 [Greco, Antonio; Vento, Mario; Vigilante, Vincenzo] Univ Salerno, Dept Comp Engn Elect Engn & Appl Math DIEM, Fisciano, Italy.
   [Strisciuglio, Nicola] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands.
C3 University of Salerno; University of Twente
RP Greco, A (corresponding author), Univ Salerno, Dept Comp Engn Elect Engn & Appl Math DIEM, Fisciano, Italy.
EM agreco@unisa.it; n.strisciuglio@utwente.nl; mvento@unisa.it;
   info@vvigilante.com
FU Italian MIUR within PRIN [20172BH297 002CUP D44I17000200005]
FX This research was partially supported by the Italian MIUR within PRIN
   2017 grants, Projects Grant 20172BH297 002CUP D44I17000200005
CR Acharya D, 2018, IEEE COMPUT SOC CONF, P480, DOI 10.1109/CVPRW.2018.00077
   Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   [Anonymous], 2017, ARXIV170307140
   Antipov G, 2017, PATTERN RECOGN, V72, P15, DOI 10.1016/j.patcog.2017.06.031
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carletti V., 2019, IEEE T PATTERN ANAL
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   Geirhos Robert, 2018, Advances in Neural Information Processing Systems, P7549
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Greco A, 2019, IEEE SYS MAN CYBERN, P358, DOI 10.1109/SMC.2019.8914039
   Gunes H, 2016, IMAGE VISION COMPUT, V55, P6, DOI 10.1016/j.imavis.2016.03.013
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hendrycks Dan, 2019, ARXIV190312261
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kollias D, 2020, INT J COMPUT VISION, V128, P1455, DOI 10.1007/s11263-020-01304-3
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lim Sungbin, 2019, ARXIV190500397
   Ly ST, 2019, IEEE COMPUT SOC CONF, P2927, DOI 10.1109/CVPRW.2019.00353
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strisciuglio N, 2020, NEURAL COMPUT APPL, V32, P17957, DOI 10.1007/s00521-020-04751-8
   Vasiljevic Igor, 2016, arXiv
   Vo TH, 2020, IEEE ACCESS, V8, P131988, DOI 10.1109/ACCESS.2020.3010018
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang N, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P217, DOI 10.1109/ISBAST.2013.38
   Watanabe S., 2021, ARXIV210310189
   Wen Z., 2021, ARXIV210907270
   Yin Dong, 2019, ARXIV190608988
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485
   Zhou HS, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P562, DOI 10.1145/3340555.3355713
NR 49
TC 9
Z9 9
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11189
EP 11220
DI 10.1007/s11042-022-12790-7
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000780464900007
OA hybrid
DA 2024-07-18
ER

PT J
AU Kaur, N
   Singh, P
AF Kaur, Navdeep
   Singh, Parminder
TI Speech waveform reconstruction from speech parameters for an effective
   text to speech synthesis system using minimum phase harmonic sinusoidal
   model for Punjabi
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frame overlapping; Spectral subtraction; Speech parameters extraction;
   Speech synthesis; Minimum phase harmonic sinusoidal model
ID GENERATION
AB Speech processing plays a vital role in current speech communication applications. The major objective of digital speech is transmission of messages among human and computer systems. A Text-to-speech synthesizer is utilized for these transmission of speech. Many significant works are carried out in the previous speech synthesis framework but still having issues in quality speech generation. This work presents an effective text to speech synthesis system using minimum phase harmonic sinusoidal modeling in Punjabi language. To develop the presented system, initially input phoneme speech is converted into an overlapping frames. Then, spectral subtraction technique is utilized to eliminate the noise of overlapped frames for speech enhancement. Subsequently, spectral speech parameters such as Mel frequency cepstral coefficients (MFCC), excitation parmeters such as fundamental frequency, energy and their first order(delta) and second order (delta-delta) time derivatives are extracted. After extracting all the parameters, the speech signal is synthesized from the extracted speech parameters using minimum phase harmonic sinusoidal model. Here, this synthesis model is dependent on the extracted speech parameters and also the amplitudes, phases of sine waves for the production of synthetic speech.The presented speech waveform reconstruction method to speeh synthesis process is implemented in PYTHON platform. The experimental outcomes of the presented methodology proved that the presented work is significantly better in terms of various effective performance measures like execution time (0.125 s), SNR (16.4 dB), RMSE (0.074 dB), BSD (3.21%), accuracy (97.6%).
C1 [Kaur, Navdeep] Govt Polytech Coll Girls, Comp Sci & Engn, Amritsar, Punjab, India.
   [Kaur, Navdeep] IK Gujral Punjab Tech Univ, Kapurthala, India.
   [Singh, Parminder] Guru Nanak Dev Engn Coll, Comp Sci & Engn, Ludhiana, Punjab, India.
C3 I. K. Gujral Punjab Technical University; Guru Nanak Dev Engineering
   College Ludhiana
RP Kaur, N (corresponding author), Govt Polytech Coll Girls, Comp Sci & Engn, Amritsar, Punjab, India.; Kaur, N (corresponding author), IK Gujral Punjab Tech Univ, Kapurthala, India.
EM Nav_783@yahoo.com
OI Singh, Parminder/0000-0003-4715-4966
FU I.K Gujral Punjab Technical University, Kapurthala
FX This piece of research work is supported by I.K Gujral Punjab Technical
   University, Kapurthala.
CR Agiomyrgiannakis Y, 2015, INT CONF ACOUST SPEE, P4230, DOI 10.1109/ICASSP.2015.7178768
   Arik SÖ, 2017, ADV NEUR IN, V30
   Baby A, 2020, SPEECH COMMUN, V123, P10, DOI 10.1016/j.specom.2020.06.002
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P15875, DOI 10.1007/s11042-017-5160-5
   Choi H., 2018, P 2 INT C MECH SYST, P107
   Haq M.R., 2019, 2019 International Joint Conference on Neural Network (IJCNN'19), P1
   Jia Y, 2018, ADV NEUR IN, V31
   Juvela L, 2019, INT CONF ACOUST SPEE, P6915, DOI [10.1109/ICASSP.2019.8683271, 10.1109/icassp.2019.8683271]
   Kadyan V, 2017, INT J SPEECH TECHNOL, V20, P761, DOI 10.1007/s10772-017-9446-9
   Luong HT, 2017, INT CONF ACOUST SPEE, P4905, DOI 10.1109/ICASSP.2017.7953089
   Nuesse T, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519862982
   Pahwa Anjali, 2016, International Journal of Image, Graphics and Signal Processing, V8, P17, DOI 10.5815/ijigsp.2016.09.03
   Panda SP, 2015, ADV INTELL SYST, V309, P523, DOI 10.1007/978-81-322-2009-1_59
   Prafianto H, 2019, SPEECH COMMUN, V111, P14, DOI 10.1016/j.specom.2019.06.001
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI [10.1109/ICASSP.2019.8683143, 10.1109/icassp.2019.8683143]
   Rebai I, 2016, INT J SPEECH TECHNOL, V19, P485, DOI 10.1007/s10772-016-9342-8
   Reddy MK, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101029
   Ren Y, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1979, DOI 10.1145/3394486.3403249
   Sahu L., 2012, INT J SCI RES PUBL, V2, P1
   Saito Y, 2018, IEEE-ACM T AUDIO SPE, V26, P84, DOI 10.1109/TASLP.2017.2761547
   Sharma B., 2015, TENCON 2015 2015 IEE, P1
   Suryawanshi S., 2014, INT J ADVENCED RES E, V3, P133
   Tachibana H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4784, DOI 10.1109/ICASSP.2018.8461829
   Takamichi S, 2016, IEEE-ACM T AUDIO SPE, V24, P755, DOI 10.1109/TASLP.2016.2522655
   Tüske Z, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4859, DOI 10.1109/ICASSP.2018.8461871
   Valin JM, 2019, INT CONF ACOUST SPEE, P5891, DOI 10.1109/ICASSP.2019.8682804
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Wen TH, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2019.06.008
   Yang S, 2020, NEURAL NETWORKS, V125, P121, DOI 10.1016/j.neunet.2020.01.034
   Zen HG, 2019, INTERSPEECH, P1526, DOI 10.21437/Interspeech.2019-2441
NR 30
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26101
EP 26120
DI 10.1007/s11042-022-12850-y
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100010
DA 2024-07-18
ER

PT J
AU Sabharwal, T
   Gupta, R
AF Sabharwal, Tanupreet
   Gupta, Rashmi
TI Deep facial recognition after medical alterations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition after medical alterations; Deep feed forward neural
   network with back propagation; Weight update; Computational complexity;
   Recognition rate (RR); Mean Square Error (MSE); Regression Coefficient
   (R); F-score (F)
ID ALTERED FACE IMAGES; PLASTIC-SURGERY
AB Medical alterations on the facial region introduce skin consistency deviations amongst images of the same individual, thus making face recognition after medical alterations complicated than in regular circumstances. Cosmetic surgeries lead to medical identity thefts. Thus this makes one's security a serious concern and human identification after medical alterations a critical dare. As prevailing techniques for human identification after surgery are not favorable, so in the present picture cosmetic therapies score above facial recognition. Neural models are not used till date to recognize surgically altered faces. The proposed approach uses a Deep Feed Forward Neural Network to recognize surgically altered faces. The innovation lies in weight update during back propagation which results into optimization of computational complexity and thus less training. While calculating error gradient during weight update, trace of inversed Hessian matrix is evaluated instead of computing the entire matrix which results into cumbersome calculations. Trace reveals vital facial features essential for recognition. Training deep models is computationally expensive but our scheme reduces computation complexity. Rank 1 Recognition Rates (RR) are obtained empirically by bootstrap sampling with 95% confidence interval level for the plastic surgery facial dataset. RR values 97.89% and 98.24% obtained for global and local surgeries are best reported till date in literature. This dataset is unbalanced so with biased metrics (RR and MSE (Mean Square Error)) unbiased metrics (F-score and R (Regression Coefficient)) are also analyzed. The recognition results obtained are equivalent to existing deep models which are computationally expensive and require large processing power.
C1 [Sabharwal, Tanupreet] GGSIPU, USICT, Delhi, India.
   [Gupta, Rashmi] AIACT&R, Dept Elect & Commun Engn, NSUT East Campus, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology;
   Netaji Subhas University of Technology (East Campus)
RP Gupta, R (corresponding author), AIACT&R, Dept Elect & Commun Engn, NSUT East Campus, Delhi, India.
EM kaurtanpreet86@gmail.com
RI Gupta, Rashmi/KMY-3135-2024; Gupta, Rashmi/HLH-0461-2023
OI Gupta, Rashmi/0000-0003-3983-4638; 
CR Aggarwal G., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P113, DOI 10.1109/WACV.2012.6163008
   Ali ASO, 2016, IET COMPUT VIS, V10, P342, DOI 10.1049/iet-cvi.2014.0263
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2020, PLASTIC SURG FACE DA
   [Anonymous], 2018, IEEE PELS WORKSHOP E
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhatt H. S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P720, DOI 10.1109/FG.2011.5771337
   Bhatt HS, 2013, IEEE T INF FOREN SEC, V8, P89, DOI 10.1109/TIFS.2012.2223684
   De Marsico M, 2011, LECT NOTES COMPUT SC, V6754, P191, DOI 10.1007/978-3-642-21596-4_20
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   El-Said SA, 2014, INT J COMPUT APPL T, V49, P352, DOI 10.1504/IJCAT.2014.062371
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Gupta R, 2020, INFORM SCIENCES, V530, P201, DOI 10.1016/j.ins.2020.01.031
   Ibrahim RM, 2013, IJCSI, V10
   Jillela R., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P402, DOI 10.1109/BTAS.2012.6374607
   Kermani BG, 2005, SENSOR ACTUAT B-CHEM, V110, P13, DOI 10.1016/j.snb.2005.01.008
   Lakshmiprabha NS, 2011, IM INF PROC ICIIP 20, P1, DOI [10.1109/ICIIP.2011.6108945, DOI 10.1109/ICIIP.2011.6108945]
   Leyvand T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360637
   Li Y, 2018, IEEE T DEPEND SECURE, V15, P231, DOI 10.1109/TDSC.2016.2550459
   Liu X., 2013, COMPUTER VISION ACCV, DOI 10.1007/978-3-642-37444-9_44
   Liu X., 2012, COMPUTER VISION ACCV, P565
   Mun M., 2014, INT J COMPUT SCI INF, V5, P3711
   Nappi M, 2016, IMAGE VISION COMPUT, V54, P71, DOI 10.1016/j.imavis.2016.08.012
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Ricanek K, 2013, COMPUTER, V46, P94, DOI 10.1109/MC.2013.82
   Sabharwal Tanupreet, 2021, International Journal of Information Technology, V13, P391, DOI 10.1007/s41870-020-00566-x
   Sabharwal T, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102373
   Sabharwal T, 2019, ARTIF INTELL REV, V52, P1009, DOI 10.1007/s10462-018-9660-0
   Singh Richa, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P72, DOI 10.1109/CVPR.2009.5204287
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Verghis TJ., 2014, COMPUSOFT, V3, P529
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wilamowski BM, 2010, IEEE T NEURAL NETWOR, V21, P930, DOI 10.1109/TNN.2010.2045657
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
NR 35
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25675
EP 25706
DI 10.1007/s11042-022-12895-z
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288100002
DA 2024-07-18
ER

PT J
AU Brabin, D
   Ananth, C
   Bojjagani, S
AF Brabin, Denslin
   Ananth, Christo
   Bojjagani, Sriramulu
TI Blockchain based security framework for sharing digital images using
   reversible data hiding and encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Compression; Encryption; JPEG; Reversible data hiding
ID SCHEME
AB Security is an important issue in current and next-generation networks. Blockchain will be an appropriate technology for securely sharing information in next-generation networks. Digital images are the prime medium attacked by cyber attackers. In this paper, a blockchain based security framework is proposed for sharing digital images in a multi user environment. The proposed framework uses reversible data hiding and encryption as component techniques. A novel high capacity reversible data hiding scheme is also proposed to protect digital images. Reversible data hiding in combination with encryption protects the confidentiality, integrity and authentication of digital images. In the proposed technique, the digital image is compressed first to create room for data hiding, then the user signature is embedded; afterwards the whole image is encrypted. For compression, JPEG lossy compression is used to create high capacity. For encryption, any symmetric block cipher or stream cipher can be used. Experimental results show that the proposed blockchain based framework provides high security and the proposed reversible data hiding scheme provides high capacity and image quality.
C1 [Brabin, Denslin] DMI Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Ananth, Christo] Samarkand State Univ, Dept Nat & Exact Sci, Samarkand, Uzbekistan.
   [Bojjagani, Sriramulu] SRM Univ AP, Dept Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
C3 Samarkand State University; SRM University-AP
RP Brabin, D (corresponding author), DMI Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM denscse@gmail.com; dr.christoananth@gmail.com;
   sriramulubojjagani@gmail.com
RI Brabin, Denslin/AAL-1499-2020; Ananth, Christo/H-6799-2016; BOJJAGANI,
   SRIRAMULU/D-6092-2018
OI Brabin, Denslin/0000-0002-4377-0617; Ananth,
   Christo/0000-0001-6979-584X; BOJJAGANI, SRIRAMULU/0000-0002-8801-4292
CR Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Brabin DRD, 2020, WIRELESS PERS COMMUN, V115, P187, DOI 10.1007/s11277-020-07567-w
   Cai YF, 2016, FINANC INNOV, V2, DOI 10.1186/s40854-016-0039-4
   Dobre RA, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ARTIFICIAL INTELLIGENCE, ROBOTICS & OPTIMIZATION (ICCAIRO), P211, DOI 10.1109/ICCAIRO.2018.00042
   Dong ZY, 2018, J MOD POWER SYST CLE, V6, P958, DOI 10.1007/s40565-018-0418-0
   Elisa N, 2023, WIREL NETW, V29, P1005, DOI 10.1007/s11276-018-1883-0
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Li B, 2019, IEEE INTERNET THINGS, V6, P2241, DOI 10.1109/JIOT.2018.2887086
   Li H, 2019, PEER PEER NETW APPL, V12, P1178, DOI 10.1007/s12083-019-00786-4
   Mehedi SK, 2019, Iran J. Comput. Sci., V2, P189, DOI [10.1007/s42044-019-00044-z, DOI 10.1007/S42044-019-00044-Z]
   Meng ZX, 2018, P INT COMP SOFTW APP, P359, DOI 10.1109/COMPSAC.2018.10258
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Rakovic V, 2019, WIRELESS PERS COMMUN, V106, P219, DOI 10.1007/s11277-019-06270-9
   Ryu JH, 2019, J SUPERCOMPUT, V75, P4372, DOI 10.1007/s11227-019-02779-9
   Sarkar P, 2022, J KING SAUD UNIV-COM, V34, P5349, DOI 10.1016/j.jksuci.2020.11.034
   Shin SH, 2018, MULTIMED TOOLS APPL, V77, P14841, DOI 10.1007/s11042-017-5065-3
   Shukla AK, 2018, IEEE ACCESS, V6, P51130, DOI 10.1109/ACCESS.2018.2868192
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Xie XZ, 2019, MULTIMED TOOLS APPL, V78, P11443, DOI 10.1007/s11042-018-6651-8
   Yang XD, 2020, IEEE ACCESS, V8, P45468, DOI 10.1109/ACCESS.2020.2976894
   Yi HB, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1473-6
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zheng BK, 2018, J COMPUT SCI TECH-CH, V33, P557, DOI 10.1007/s11390-018-1840-5
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 32
TC 6
Z9 7
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24721
EP 24738
DI 10.1007/s11042-022-12617-5
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200009
DA 2024-07-18
ER

PT J
AU Lu, JB
   Huo, GQ
   Cheng, JX
AF Lu, Jinbo
   Huo, Guanqun
   Cheng, Jixiang
TI Research on image stitching method based on fuzzy inference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stitching; Fuzzy inference; ZNCC; Eliminate ghosting
ID MUTUAL INFORMATION; MOSAICS
AB This paper concern the problem of ghosting caused by parallax and moving objects in image stitching. Previous approaches have used local homography or optimal seam lines to avoid ghosting. In this work, we propose an image stitching method based on fuzzy inference. At first, our use of the contrast limited adaptive histogram equalization (CLAHE) increase the matching points of the object surface in the low-contrast images. Then, to reduce the number of mismatching points, we combine the orientation of feature points to improve the zero-mean normalized cross-correlation (ZNCC) for filter matching points. Furthermore, by viewing the distance weight and gray difference of pixels in overlapping region as the first input and the second input of fuzzy inference respectively, and regarding the output of the fuzzy inference as the weight of image fusion. We generate high-quality stitching images. The experimental results show that our approach can reduce the ghosting phenomenon and improve the quality of the stitching.
C1 [Lu, Jinbo; Huo, Guanqun; Cheng, Jixiang] Southwest Petr Univ, Sch Elect & Informat Engn, Chengdu 637001, CO, Peoples R China.
C3 Southwest Petroleum University
RP Lu, JB (corresponding author), Southwest Petr Univ, Sch Elect & Informat Engn, Chengdu 637001, CO, Peoples R China.
EM lujb@swpu.edu.cn
FU National Natural Science Foundation for Young Scientists of China
   [61,603,319, 61,601,385]
FX This work was supported in part by the National Natural Science
   Foundation for Young Scientists of China (61,603,319, 61,601,385).
CR Adwan S, 2016, MEASUREMENT, V84, P32, DOI 10.1016/j.measurement.2016.01.039
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Dame A, 2012, IEEE T IMAGE PROCESS, V21, P4190, DOI 10.1109/TIP.2012.2199124
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   Duplaquet ML, 1998, P SOC PHOTO-OPT INS, V3387, P369, DOI 10.1117/12.316427
   Fang FM, 2019, IEEE GEOSCI REMOTE S, V16, P1115, DOI 10.1109/LGRS.2019.2893210
   Fang Xianyong, 2003, Journal of Computer Aided Design & Computer Graphics, V15, P1362
   Gao JH, 2011, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2011.5995433
   Haixiang Su, 2014, 2014 7th International Symposium on Computational Intelligence and Design (ISCID), P104, DOI 10.1109/ISCID.2014.75
   Harris C., 1988, ALVEY VISION C, P147151
   Laraqui A, 2017, MULTIMED TOOLS APPL, V76, P8803, DOI 10.1007/s11042-016-3478-z
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Lin KM, 2016, COMPUT GRAPH FORUM, V35, P479, DOI 10.1111/cgf.12848
   Liu SD, 2020, SCI REP-UK, V10, DOI [10.1038/s41598-020-64588-y, 10.1177/2158244020924052]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo XY, 2020, PATTERN RECOGN LETT, V135, P431, DOI 10.1016/j.patrec.2020.05.003
   Pilchak AL, 2012, J MICROSC-OXFORD, V248, P172, DOI 10.1111/j.1365-2818.2012.03661.x
   Rivaz H, 2014, MED IMAGE ANAL, V18, P343, DOI 10.1016/j.media.2013.12.003
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Vaidya OS, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P431, DOI 10.1109/ICACCT.2018.8529642
   Vishwakarma A, 2020, MULTIMED TOOLS APPL, V79, P23599, DOI 10.1007/s11042-020-09124-w
   [汪丹 Wang Dan], 2017, [红外技术, Infrared Technology], V39, P53
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zheng J, 2019, IEEE T MULTIMEDIA, V21, P2561, DOI 10.1109/TMM.2019.2905692
NR 30
TC 4
Z9 4
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23991
EP 24002
DI 10.1007/s11042-022-12748-9
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000025
DA 2024-07-18
ER

PT J
AU Zhang, BH
   Zhu, SY
   Zhou, YF
   Lu, XQ
   Gu, Y
   Li, JJ
   Liu, X
AF Zhang Baohua
   Zhu Siyu
   Zhou Yufeng
   Lu Xiaoqi
   Gu Yu
   Li Jianjun
   Liu Xin
TI A novel unsupervised person re-identification algorithm based on soft
   multi-label and compound attention model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Soft multi-label; Compound attention model
ID ATTRIBUTE
AB To explore discriminative information fully and keep consistence of labels, an unsupervised person re-identification algorithm based on soft multi-label and compound attention model was proposed in this study. Based on learning of reference agent labels, soft multi-label was built by constructing a mapping model of targets and reference datasets. Later, soft multi-label was added into initial samples through deep convolutional network training to realize accurate labeling of targets and fine-grain classification of features under multi-camera scenes. In the training stage of the deep network, a compound attention mechanism is added between the convolution blocks to fuse the complementary information of the multiple channels features and the spaces domain features, therefore the potential discriminative information is explored. In addition, a weight fusion of distance loss function, label consistency loss function, and reference agent loss function was performed to distinguish hard negative pair set and realize matching of multi-camera labels. Since learning rate is the key influencing factor against the improvement of identification precision and training speed, a rectified adaptive moment estimation was adopted to achieve adaptive control of learning rate, accelerate training convergence of network and increase the robustness of the proposed algorithm. The proposed algorithm is proved by an experiment that it can increase identification precision significantly. The rank-1 of the proposed algorithm is at least 3.9% higher, and its mean average precision (mAP) is at least 4.7% higher compared to those of similar representative algorithms.
C1 [Zhang Baohua; Zhu Siyu; Zhou Yufeng; Gu Yu; Li Jianjun; Liu Xin] Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.
   [Zhang Baohua; Lu Xiaoqi; Gu Yu; Li Jianjun; Liu Xin] Inner Mongolia Key Lab Pattern Recognit & Intelli, Baotou 014010, Inner Mongolia, Peoples R China.
   [Lu Xiaoqi] Inner Mongolia Ind Univ, Sch Informat Engn, Hohhot 010051, Inner Mongolia, Peoples R China.
C3 Inner Mongolia University of Science & Technology
RP Zhang, BH (corresponding author), Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.; Zhang, BH (corresponding author), Inner Mongolia Key Lab Pattern Recognit & Intelli, Baotou 014010, Inner Mongolia, Peoples R China.
EM zbh_wj2004@imust.cn; zsyu94@gmail.com; joeyfex@sina.cn;
   13009546564@sina.cn; guyu2010023@imust.edu.cn; xidianjj@imust.cn;
   lx2001lx@imust.cn
RI ZHOU, yf/IAO-5497-2023; Zhou, Yujie/HZI-3990-2023; lu,
   xiaoqi/G-3472-2013; , 谷宇/ABW-8361-2022; Zhou, Yufeng/GQQ-5547-2022; sun,
   rong/JRX-7214-2023
OI , 谷宇/0000-0003-4345-6932; 
FU National Natural Science Foundation of China [61962046, 62001255,
   61841204]; Inner Mongolia Outstanding Youth Cultivation Fund [2018JQ02];
   Inner Mongolia Science and Technology Plan Project (Research and
   implementation of key technologies for intelligent analysis platform of
   traffic big data); Inner Mongolia Science and Technology Plan Project;
   Inner Mongolia Natural Science Foundation [2019MS06003]
FX The authors thank the anonymous reviewers and editors for the very
   constructive comments. This work was supported by the National Natural
   Science Foundation of China(61962046, 62001255, 61841204). Inner
   Mongolia Outstanding Youth Cultivation Fund(2018JQ02). Inner Mongolia
   Science and Technology Plan Project (Research and implementation of key
   technologies for intelligent analysis platform of traffic big data).
   Inner Mongolia Science and Technology Plan Project. Inner Mongolia
   Natural Science Foundation (2019MS06003).
CR Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Li YL, 2018, PROC CVPR IEEE, P5997, DOI 10.1109/CVPR.2018.00628
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu L, 2021, POSTGRAD MED, V133, P265, DOI 10.1080/00325481.2020.1803666
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Wu JL, 2019, IEEE I CONF COMP VIS, P8320, DOI 10.1109/ICCV.2019.00841
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xin XM, 2019, PATTERN RECOGN, V88, P285, DOI 10.1016/j.patcog.2018.11.025
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X., 2020, NEURAL COMPUT APPL, V32, P1
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
NR 42
TC 1
Z9 3
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24081
EP 24098
DI 10.1007/s11042-022-12728-z
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000021
DA 2024-07-18
ER

PT J
AU Latha, D
   Sheela, CJJ
AF Latha, D.
   Sheela, C. Jaspin Jeba
TI Enhanced hybrid CBIR based on multichannel LBP oriented color descriptor
   and HSV color statistical feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Color image descriptor; TBIR; LBP
ID SHAPE DESCRIPTORS; CLASSIFICATION
AB Internet applications stores vast quantity of images into databases of server and also several quantities of images are also retrieved from databases. This phenomenon projects the CBIR system as a vital need. The Content based Image Retrieval (CBIR) is an image retrieval system that is mostly demanded by the fields such as agriculture object recognition, biomedical, etc. The CBIR method that is imparted in this paper is Enhanced Hybrid CBIR based on Multichannel LBP oriented color descriptor and HSV color statistical feature(CBIR_MCLBP_HSV). This method employs the Hybrid feature sets which are generated by histogram oriented features and statistical features. The main contribution of this method is the new color-image-descriptor which is entitled as Multichannel LBP Oriented Color image descriptor (MCLBP). To strengthen this CBIR system, the HSV color space oriented statistical features such as Mean and Standard deviation are included in this new framework. The reduced feature sets from MCLP and the usage of HSV color space results in fast and higher retrieval rate. This excellent method is fit for large size online image retrieval. The proposed methodology is experimentally analyzed and compared with the existing recent CBIR algorithms with the help of three standard databases (DB_Corel1k, DB_USPTex and KTH-TIPS2a) and a user contributed database named DB_VEG.
C1 [Latha, D.; Sheela, C. Jaspin Jeba] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
RP Latha, D (corresponding author), Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
EM dlathasatheesh@gmail.com; jaspinjebashheela@gmail.com
CR Abbadeni N, 2011, IEEE T IMAGE PROCESS, V20, P236, DOI 10.1109/TIP.2010.2060345
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], COR DAT
   [Anonymous], USPTEX DATABASE
   [Anonymous], KTH TIPS TEXTURE IMA
   [Anonymous], HSV COL SPAC
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   González R, 2016, PROC IEEE-PES
   Gonzalez Rafael C., 2014, DIGITAL IMAGE PROCES
   Jain AK, 2017, FUNDAMENTALS DIGITAL
   Kong FH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2228, DOI 10.1109/ICMLC.2009.5212186
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Sajjanhar A, 2008, 2008 IEEE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P338, DOI 10.1109/CIT.2008.4594698
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Sujatha Vijayakumar H, 2012, J SCI ENG RES, V3, P1
   Yang JC, 2017, IEEE T IND INFORM, V13, P2350, DOI 10.1109/TII.2017.2657545
   Zhang C., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P51, DOI 10.1145/1076034.1076046
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
NR 26
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23801
EP 23818
DI 10.1007/s11042-022-12568-x
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800026
DA 2024-07-18
ER

PT J
AU Dev, K
   Ashraf, Z
   Muhuri, PK
   Kumar, S
AF Dev, Krishna
   Ashraf, Zubair
   Muhuri, Pranab K.
   Kumar, Sandeep
TI Deep autoencoder based domain adaptation for transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Transfer learning; Deep neural network; Marginal
   distribution; Domain adaptation; Classification
ID REGULARIZATION; NETWORK
AB The concept of transfer learning has received a great deal of concern and interest throughout the last decade. Selecting an ideal representational framework for instances of various domains to minimize the divergence among source and target domains is a fundamental research challenge in representative transfer learning. The domain adaptation approach is designed to learn more robust or higher-level features, required in transfer learning. This paper presents a novel transfer learning framework that employs a marginal probability-based domain adaptation methodology followed by a deep autoencoder. The proposed frame adapts the source and target domain by plummeting distribution deviation between the features of both domains. Further, we adopt the deep neural network process to transfer learning and suggest a supervised learning algorithm based on encoding and decoding layer architecture. Moreover, we have proposed two different variants of the transfer learning techniques for classification, which are termed as (i) Domain adapted transfer learning with deep autoencoder-1 (D-TLDA-1) using the linear regression and (ii) Domain adapted transfer learning with deep autoencoder-2 (D-TLDA-2) using softmax regression. Simulations have been conducted with two popular real-world datasets: ImageNet datasets for image classification problem and 20_Newsgroups datasets for text classification problem. Experimental findings have established and the resulting improvements in accuracy measure of classification shows the supremacy of the proposed D-TLDA framework over prominent state-of-the-art machine learning and transfer learning approaches.
C1 [Dev, Krishna] RPATech Spawn Ventures Serv Private Ltd, Gurugram 122011, Hariyana, India.
   [Ashraf, Zubair] Aligarh Muslim Univ, Dept Comp Sci, Aligarh 202002, Uttar Pradesh, India.
   [Muhuri, Pranab K.; Kumar, Sandeep] South Asian Univ, Dept Comp Sci, New Delhi 110021, India.
C3 Aligarh Muslim University; South Asian University (SAU)
RP Ashraf, Z (corresponding author), Aligarh Muslim Univ, Dept Comp Sci, Aligarh 202002, Uttar Pradesh, India.
EM ashrafzubair786@gmail.com
RI MUHURI, PRANAB K./F-4301-2015; Ashraf, Zubair/GYR-3594-2022
OI MUHURI, PRANAB K./0000-0001-7122-7622; Ashraf,
   Zubair/0000-0001-7122-2856
CR [Anonymous], 2008, PROC INT C MACHINE L
   Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658
   Banerjee T, 2022, MULTIMED TOOLS APPL, V81, P13237, DOI 10.1007/s11042-021-10946-5
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Blitzer J., 2008, ADV NEURAL INFORM PR, P129, DOI DOI 10.5555/2981562.2981579
   Cao XB, 2013, NEUROCOMPUTING, V100, P51, DOI 10.1016/j.neucom.2011.12.043
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P20547, DOI 10.1007/s11042-021-10753-y
   Chen JY, 2022, MULTIMED TOOLS APPL, V81, P12093, DOI 10.1007/s11042-021-10833-z
   Chen MM, 2015, J MACH LEARN RES, V16, P3849
   Clinchant S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P26
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P210
   Day Oscar, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0089-0
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Fung GPC, 2006, IEEE T KNOWL DATA EN, V18, P6
   Fuzhen Zhuang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P417, DOI 10.1007/978-3-662-44845-8_27
   Ganin Y., 2015, ICML
   Glorot X., 2011, P 28 INT C INT C MAC, P513
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Huang Z, 2016, NEUROCOMPUTING, V218, P448, DOI 10.1016/j.neucom.2016.09.018
   Kang J, 2022, MULTIMED TOOLS APPL, V81, P22355, DOI 10.1007/s11042-021-11282-4
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Liu F, 2016, IEEE T IMAGE PROCESS, V25, P949, DOI 10.1109/TIP.2015.2512107
   Liu HJ, 2021, MULTIMED TOOLS APPL, V80, P29321, DOI 10.1007/s11042-021-11139-w
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Pan JH, 2016, NEUROCOMPUTING, V190, P10, DOI 10.1016/j.neucom.2015.12.097
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan WK, 2016, NEUROCOMPUTING, V177, P447, DOI 10.1016/j.neucom.2015.11.059
   Pharmaceutics, 2000, J AM VET MED ASSOC, V224, P871, DOI [10.1097/gme.0b013e3181967b88, DOI 10.1097/GME.0B013E3181967B88]
   Rosenstein M.T., 2005, NIPS 2005 workshop on transfer learning, P1
   Roy AG, 2016, DASA DOMAIN ADAPTATI, P1
   Saha B, 2016, KNOWL INF SYST, V46, P315, DOI 10.1007/s10115-015-0821-z
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shao M, 2016, AAAI CONF ARTIF INTE, P2023
   Shuteng Niu, 2020, IEEE Transactions on Artificial Intelligence, V1, P151, DOI 10.1109/TAI.2021.3054609
   Silver DL, 2008, MACH LEARN, V73, P313, DOI 10.1007/s10994-008-5088-0
   Tahmoresnezhad J, 2017, KNOWL INF SYST, V50, P585, DOI 10.1007/s10115-016-0944-x
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tang J, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2746230
   Utkin LV, 2016, PROCEEDINGS OF THE XIX IEEE INTERNATIONAL CONFERENCE ON SOFT COMPUTING AND MEASUREMENTS (SCM 2016), P224, DOI 10.1109/SCM.2016.7519735
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Varshney N., 2021, Multimed. Tools Appl., P1
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhai JH, 2016, INT J UNCERTAIN FUZZ, V24, P327, DOI 10.1142/S0218488516500161
   Zhang WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI [10.1145/2783258.2783304, 10.1109/tbdata.2016.2573280]
   Zhao P, 2019, MULTIMED TOOLS APPL, V78, P35179, DOI 10.1007/s11042-019-08216-6
   Zhou JT, 2014, AAAI CONF ARTIF INTE, P2213
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zhuang FZ, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3108257
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
NR 57
TC 6
Z9 7
U1 13
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22379
EP 22405
DI 10.1007/s11042-022-12226-2
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000769836800003
PM 35310888
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lin, Y
   Lan, YF
   Wang, SB
AF Lin, Yi
   Lan, Yangfan
   Wang, Shunbo
TI A novel method for improving the perceptual learning effect in virtual
   reality interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality interaction; Perceptual learning; Task-technology fit;
   Reflective thinking; Individual participation factors
ID TASK-TECHNOLOGY FIT; ACCEPTANCE MODEL
AB The development of intellectualization trend in online education has been characterized by constructing a multi-terminal immersive learning environment. Virtual reality (VR) technology has been increasingly used in online education to create multisensory interactive learning. However, the technical features of this technology, including high immersion and strong interactions, have not been entirely played substantially. Consequently, improvements in the perceptual learning effect have been hindered. To address these issues, this study built a novel VR interaction model for perceptual learning by introducing reflective thinking variables and individual participation factors from the task-technology fit perspective. Furthermore, the deployment strategy of this model used to build a VR education system was proposed. The usability evaluation results of the proposed model show that the path hypothesis of the novel model is verified. Particularly, the path coefficients of reflective thinking, learner participation, and instructor participation factors on the perceptual learning effect were 0.238 (p < 0.01), 0.398 (p < 0.001), and 0.348 (p < 0.001), respectively. Compared to the traditional VR education system, the immersion and interaction of the VR education system using the proposed deployment strategy were enhanced by 4.9% and 10.7%, respectively. Further, learners' perceptual learning effect improved by 5.3%.
C1 [Lin, Yi; Lan, Yangfan; Wang, Shunbo] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350018, Peoples R China.
C3 Fuzhou University
RP Lan, YF (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350018, Peoples R China.
EM lanyangfan_123@163.com
OI Lin, Yi/0000-0003-3239-3446; lan, yang fan/0000-0001-9388-9264
FU Educational Research Project for Young Teachers of The Education
   Department of Fujian Province, China [JAT200029]
FX This work is funded by Educational Research Project for Young Teachers
   of The Education Department of Fujian Province, China (JAT200029).
CR Abdullah J, 2019, VIRTUAL REAL-LONDON, V23, P461, DOI 10.1007/s10055-019-00381-1
   Alavesa P, 2020, MULTIMED TOOLS APPL, V79, P3285, DOI 10.1007/s11042-018-7077-z
   Ang KLM, 2020, IEEE ACCESS, V8, P116392, DOI 10.1109/ACCESS.2020.2994561
   Arana-Llanes JY, 2018, J INTELL FUZZY SYST, V34, P3359, DOI 10.3233/JIFS-169517
   Astivia OLO, 2020, EDUC PSYCHOL MEAS, V80, P825, DOI 10.1177/0013164420903770
   Barrett AJ, 2021, COMPUT EDUC, V169, DOI 10.1016/j.compedu.2021.104214
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Dai HM, 2020, COMPUT EDUC, V150, DOI 10.1016/j.compedu.2020.103850
   Das N., 2018, J ED TRAIN, V16, P54, DOI [10.5296/jet.v6i1.13856, DOI 10.5296/JET.V6I1.13856]
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dishaw MT, 1999, INFORM MANAGE-AMSTER, V36, P9, DOI 10.1016/S0378-7206(98)00101-3
   Dunnagan CL, 2020, J CHEM EDUC, V97, P3060, DOI 10.1021/acs.jchemed.0c00548
   GOODHUE DL, 1995, MIS QUART, V19, P213, DOI 10.2307/249689
   Gromer D, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00372
   Guo X., 2018, International Journal of Performability Engineering, V14, P2877, DOI [https://doi.org/10.23940/ijpe.18.11.p33.28772885, DOI 10.23940/IJPE.18.11.P33.28772885]
   Ikbal MS, 2021, IEEE ACCESS, V9, P3798, DOI 10.1109/ACCESS.2020.3047698
   Kim J, 2018, ROU FOC BUS MANAG, P1, DOI [10.4324/9781351113717, 10.1109/NVMSA.2018.00008]
   Lee J, 2019, TELEMAT INFORM, V39, P37, DOI 10.1016/j.tele.2018.12.006
   Liu QT, 2018, IEEE T LEARN TECHNOL, V11, P243, DOI 10.1109/TLT.2017.2708115
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Manis KT, 2019, J BUS RES, V100, P503, DOI 10.1016/j.jbusres.2018.10.021
   Maraza-Quispe B, 2020, INT J ADV COMPUT SC, V11, P146
   McGill TJ, 2009, COMPUT EDUC, V52, P496, DOI 10.1016/j.compedu.2008.10.002
   Mulders M, 2020, INT J EMERG TECHNOL, V15, P208, DOI 10.3991/ijet.v15i24.16615
   Pan CT, 2020, INT J ADV MANUF TECH, V108, P91, DOI 10.1007/s00170-020-05360-4
   Rahmalan H., 2020, Int. J. Adv. Trends Comput. Sci. Eng., V9, P5906, DOI DOI 10.30534/IJATCSE/2020/253942020
   Ramos A, 2021, J EDUC PSYCHOL, V113, P370, DOI 10.1037/edu0000476
   Puig MS, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083298
   Shen CW, 2019, VIRTUAL REAL-LONDON, V23, P313, DOI 10.1007/s10055-018-0348-1
   Sun R, 2019, VIRTUAL REAL-LONDON, V23, P385, DOI 10.1007/s10055-018-0355-2
   Sutjarittham T, 2019, IEEE INTERNET THINGS, V6, P7595, DOI 10.1109/JIOT.2019.2902410
   Syawaludin A, 2019, INT J INSTR, V12, P331, DOI 10.29333/iji.2019.12421a
   Syed ZA, 2019, INT J ENG EDUC, V35, P842
   Tao GR, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-020-00801-3
   Wang DX, 2019, IEEE T HAPTICS, V12, P189, DOI 10.1109/TOH.2018.2879812
   Wang SF, 2018, COMPUT EDUC, V121, P131, DOI 10.1016/j.compedu.2018.03.006
   Wenger MJ, 2020, J EXP PSYCHOL LEARN, V46, P455, DOI 10.1037/xlm0000735
   Wu SL, 2018, J VIS COMMUN IMAGE R, V57, P107, DOI 10.1016/j.jvcir.2018.10.018
   Yang G, 2021, BRIT J EDUC TECHNOL, V52, P807, DOI 10.1111/bjet.13056
   Zanjani N, 2016, ASIA-PAC EDUC RES, V25, P519, DOI 10.1007/s40299-016-0277-2
   Zhang X, 2017, BEHAV INFORM TECHNOL, V36, P548, DOI 10.1080/0144929X.2016.1268647
   Zhou Y, 2018, PROCEDIA COMPUT SCI, V130, P239, DOI 10.1016/j.procs.2018.04.035
NR 43
TC 3
Z9 3
U1 5
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21385
EP 21416
DI 10.1007/s11042-022-12542-7
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700003
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kurmi, Y
AF Kumar, Satrughan
   Kurmi, Yashwant
TI CNN-based denoising system for the image quality enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Parametric rectified linear unit; Image
   enhancement; Object shape and edge preservation; Edge aware filter
ID BILATERAL FILTER
AB A biased convolutional neural network (CN2) model widely employed for the image denoising applications. The performance of the denoising convolutional neural network (DeCN2) has been improved through by slightly considering the negative part in activation function along with positive range termed as parametric rectified linear unit (PReLU) that helps to improve the noise removal performance with limited complexity. The system is further incorporating Gaussian bilateral filtering to enhance the edges for the CN2 outcomes. The system evaluation is performed on the four standard datasets as Set-12 datasets, McMaster, KODAK-24, and BSD-68. The performance measure shows that the proffered system provides better image visualization, PSNR, and SSIM than state-of-the-art systems.
C1 [Kumar, Satrughan] Madanapalle Inst Technol & Sci, Dept ECE, Madanapalle, India.
   [Kurmi, Yashwant] Madhyanchal Profess Univ Bhopal, Dept ECE, Ratibad, India.
C3 Madanapalle Institute of Technology & Science
RP Kumar, S (corresponding author), Madanapalle Inst Technol & Sci, Dept ECE, Madanapalle, India.
EM satrughankumar@gmail.com
RI Kurmi, Yashwant/AAK-1374-2021
OI Kurmi, Yashwant/0000-0003-4986-2106
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Astola J, 1997, FUNDAMENTALS NONLINE
   Aurich V., 1995, Informatik Aktuell, P538, DOI DOI 10.1007/978-3-642-79980-8_63
   Benesty J, 2010, INT CONF ACOUST SPEE, P205, DOI 10.1109/ICASSP.2010.5496033
   Bhattacharya S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020219
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen BH, 2020, IEEE SIGNAL PROC LET, V27, P1670, DOI 10.1109/LSP.2020.3024990
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Ciuparu A, 2020, NEUROCOMPUTING, V384, P376, DOI 10.1016/j.neucom.2019.12.014
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Ding B, 2018, CHIN CONT DECIS CONF, P1836, DOI 10.1109/CCDC.2018.8407425
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gai S, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.032
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   Gouravaraju S, 2020, ARXIV PREPRINT ARXIV
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Guo YC, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115690
   Hong Hui Tan, 2019, IOP Conference Series: Materials Science and Engineering, V495, DOI 10.1088/1757-899X/495/1/012003
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isogawa K, 2018, IEEE SIGNAL PROC LET, V25, P224, DOI 10.1109/LSP.2017.2782270
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kim S, 2020, IET IMAGE PROCESS, V14, P472, DOI 10.1049/iet-ipr.2018.6691
   Li XY, 2013, IEEE T IMAGE PROCESS, V22, P1915, DOI 10.1109/TIP.2013.2237922
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Maas A.L., 2013, P INT C MACH LEARN, P3
   Murphy J.., 2016, OVERVIEW CONVOLUTION, P1
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Peng L, 2014, LECT N MANAG SCI, V30, P3, DOI 10.1109/IHMSC.2014.104
   Shabalin AA, 2013, J MULTIVARIATE ANAL, V118, P67, DOI 10.1016/j.jmva.2013.03.005
   Shi WZ, 2019, SIGNAL PROCESS-IMAGE, V76, P243, DOI 10.1016/j.image.2019.05.007
   Sivadas S., 2015, 16 ANN C INT SPEECH
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang CS, 2020, IEEE ACCESS, V8, P9488, DOI 10.1109/ACCESS.2020.2964271
   Xu L, 2015, PR MACH LEARN RES, V37, P1669
   Yang H, 2019, IEEE ACCESS, V7, P97919, DOI 10.1109/ACCESS.2019.2929541
   Yaroslavsky LP, 1996, PROC SPIE, V2825, P2, DOI 10.1117/12.255218
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang F, 2018, IET IMAGE PROCESS, V12, P485, DOI 10.1049/iet-ipr.2017.0389
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3150, DOI 10.1109/TIP.2018.2812081
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
NR 48
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20147
EP 20174
DI 10.1007/s11042-022-12406-0
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600024
DA 2024-07-18
ER

PT J
AU Abd Warif, NB
   Idris, MYI
   Wahab, AWA
   Ismail, NSN
   Salleh, R
AF Abd Warif, Nor Bakiah
   Idris, Mohd Yamani Idna
   Wahab, Ainuddin Wahid Abdul
   Ismail, Nor-Syahidatul N.
   Salleh, Rosli
TI A comprehensive evaluation procedure for copy-move forgery detection
   methods: results from a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Copy-move; Region duplication; Evaluation performance; Image forensics
ID ROBUST-DETECTION; ALGORITHM; SYMMETRY; IMAGES; SIFT; DCT
AB In the current age, the wide use of digital images has led to the manipulations of content that misrepresent information with malicious goals. This issue demands the requirement of digital image investigation to authenticate the source and certify the trustworthiness of images. One image manipulation technique is called copy-move forgery (CMF), which duplicates one or more regions in an image before it is pasted to another location within the same image. In this paper, a systematic review is conducted to assess the performance evaluation techniques implemented by current CMF detection methods' approaches. Five research questions are generated to find and solve the related issues on the evaluation levels. At present, CMF detection performance is evaluated either through image-level, pixel-level, or both level evaluations. Image-level evaluation identifies an image either as forged or not while all images in pixel-level evaluation are treated as forged images to localise the CMF regions. The study shows that both image and pixel-level evaluations are dependent and must be incorporated together to ensure a fair evaluation is conducted. A comprehensive evaluation procedure that covers both evaluations is proposed as a guide to future research. The procedure is then examined with seven state-of-the-art CMF detection methods based on keypoint, block, and combination approaches using three available CMF datasets that consist of multiple CMF attacks. The results are measured using multiple F-score values: image scores, pixel scores, and a multiplication of both of these to get the overall percentages of the detection. The results show that the block-based approach is able to obtain the highest percentages of detection in almost all cases of attacks in CMF.
C1 [Abd Warif, Nor Bakiah] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Ctr Informat Secur Res, Batu Pahat, Johor, Malaysia.
   [Idris, Mohd Yamani Idna; Wahab, Ainuddin Wahid Abdul; Salleh, Rosli] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur, Malaysia.
   [Ismail, Nor-Syahidatul N.] Univ Malaysia Pahang, Coll Comp & Appl Sci, Fac Comp, Dept Comp Syst & Networking, Pekan, Pahang, Malaysia.
C3 University of Tun Hussein Onn Malaysia; Universiti Malaya; Universiti
   Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Abd Warif, NB (corresponding author), Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Ctr Informat Secur Res, Batu Pahat, Johor, Malaysia.
EM norbakiah@uthm.edu.my; yamani@um.edu.my; ainuddin@um.edu.my;
   nadiahismail@ump.edu.my; rosli_salleh@um.edu.my
RI Idris, Mohd. Yamani Idna/B-5232-2010; Idris, Mohd. Yamani
   Idna/GPP-2401-2022; Wahid, Abdul/JAO-5831-2023; WARIF, NOR BAKIAH
   ABD/X-5674-2019; SALLEH, ROSLI/B-9611-2010; Abdul Wahab, Ainuddin
   Wahid/A-9293-2013
OI Idris, Mohd. Yamani Idna/0000-0003-4894-0838; WARIF, NOR BAKIAH
   ABD/0000-0002-6226-2271; SALLEH, ROSLI/0000-0002-7379-8397; Abdul Wahab,
   Ainuddin Wahid/0000-0003-1062-0329
FU Ministry of Higher Education (MOHE) through Fundamental Research Grant
   Scheme [FRGS/1/2020/ICT04/UTHM/02/1]
FX This research was supported by Ministry of Higher Education (MOHE)
   through Fundamental Research Grant Scheme (FRGS/1/2020/ICT04/UTHM/02/1).
CR Abd Warif NB, 2019, FORENSIC SCI INT, V295, P83, DOI 10.1016/j.forsciint.2018.12.004
   Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Al-Qershi OM, 2018, MULTIMED TOOLS APPL, V77, P31807, DOI 10.1007/s11042-018-6201-4
   Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, CASIA TAMPERED IMAGE
   [Anonymous], 2010, P 25 INT S COMP INF
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Dixit R, 2017, IET IMAGE PROCESS, V11, P746, DOI 10.1049/iet-ipr.2016.0322
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Kim S., 2002, IAPR WORKSH MACH VIS, P11
   Langille A., 2006, CRV '06: Proceedings of the The 3rd Canadian Conference on Computer and Robot Vision, Washington, DC, USA, IEEE Computer Society, P64, DOI DOI 10.1109/CRV.2006.9
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Niyishaka P., 2020, MULTIMED TOOLS APPL
   Park JY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040492
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadeghi S, 2017, MALAYS J COMPUT SCI, V30, P117, DOI 10.22452/mjcs.vol30no2.4
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tahaoglu G, 2021, MULTIMED TOOLS APPL, V80, P23419, DOI 10.1007/s11042-020-10241-9
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Vaishnavi D, 2019, J INF SECUR APPL, V44, P23, DOI 10.1016/j.jisa.2018.11.001
   Wang XY, 2020, MULTIDIM SYST SIGN P, V31, P857, DOI 10.1007/s11045-019-00688-x
   Wang YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102536
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 62
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15171
EP 15203
DI 10.1007/s11042-022-12010-2
EA FEB 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600014
DA 2024-07-18
ER

PT J
AU Wei, C
   Huang, SB
   Li, RS
AF Wei, Chi
   Huang, Shaobin
   Li, Rongsheng
TI Enhance text-to-SQL model performance with information sharing and
   reweight loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-SQL; Multi-task learning; Re-weighted loss
AB The goal of Text-to-SQL task is to map natural language queries into equivalent structured query languages(NL2SQL). On the WikiSQL dataset, the method used by the state-of-the-art models is to decouple the NL2SQL task into subtasks and then build a dedicated decoder for each subtask. There are some problems in this method, such as the model is too complicated, and the ability to learn the dependency between different subtasks is limited. To solve these problems, this paper innovatively introduces the sharing mechanism of multi-task learning into the NL2SQL task and realizes sharing by letting different subtasks share the same decoder. Firstly, sharing decoders for different subtasks can effectively reduce the complexity of the model, and at the same time, allows different subtasks to share knowledge during the training process so that the model can better learn the dependencies between different subtasks. This paper also designed a re-weighted loss to balance the complexity of the SELECT clause and the WHERE clause. We have evaluated the method in this article on the WikiSQL dataset. The experimental results show that the accuracy of the proposed model is better than state-of-the-art on the WikiSQL without execution guided decoding.
C1 [Wei, Chi; Huang, Shaobin; Li, Rongsheng] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Li, RS (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM 2236058667@qq.com; huangshaobin@hrbeu.edu.cn; dasheng@hrbeu.edu.cn
CR Bogin B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3659
   Bogin B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4560
   Dong L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P33
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Guo T, 2019, PR MACH LEARN RES, V97
   He Pengcheng, 2019, ABS190808113 CORR
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hwang Wonseok, 2019, ARXIV190201069
   Krishnamurthy J, 2017, P 2017 C EMP METH NA
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Lyu Q, 2020, ARXIV PREPRINT ARXIV
   Ma JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6936
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Popescu A.-M., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P149, DOI 10.1145/604045.604070
   Qi K., 2020, ARXIV PREPRINT ARXIV
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I, 2014, ADV NEUR IN, V27
   Xu Xiaojun, 2018, SQLNET GENERATING ST
   Yu T., 2018, P 2018 C N AM CHAPT, V2, P588, DOI DOI 10.18653/V1/N18-2093
   Zhong V, 2018, Seq2SQL: Generating structured queries from natural language using reinforcement learning
NR 22
TC 2
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15205
EP 15217
DI 10.1007/s11042-022-12573-0
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600009
DA 2024-07-18
ER

PT J
AU Singal, G
   Singhal, H
   Kushwaha, R
   Veeramsetty, V
   Badal, T
   Lamba, S
AF Singal, Gaurav
   Singhal, Himanshu
   Kushwaha, Riti
   Veeramsetty, Venkataramana
   Badal, Tapas
   Lamba, Sonu
TI RoadWay lane detection for autonomous driving vehicles via deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection; Self-driving; Driver assistance systems
ID SYSTEM
AB Locomotion is basic to all human needs. Modern-day transport has come a long way but still far away from perfection and all-around safety. Lane Detection is a concept of demarcating lanes on the roads while the vehicle is moving. Lane detection algorithm is crucial aspect in making intelligent driving systems that can be used in autonomous self-driving vehicles, road safety, and accidents prevention systems, testing and analyzing driving skills, etc. Lane detection systems using hand crafted features fails in complex scenarios like adverse weather condition, low illumination, sharp turns and occlusion. Recently, deep learning models have been used remarkable in driving assistance systems and shows a significant improvement in their performance. Although, deep learning based methods has shown significant success in lane detection using hybrid techniques, that includes FCN, CNN and RNN. But, a safe driving assistance system can be used to save lives by avoiding accidents, it is crucial to have a real-time lane detection method. We have proposed a lightweight model that can detect lane with high accuracy and low execution time. The size of model has been kept short to make it hardware deployable and perform in real-time. We have designed and trained a deep Convolutional Neural Network (CNN) model for lane detection since a CNN based model is known to work best for image classification datasets. We have used multiple networks and optimization criteria as hyper-parameters and proposed the one with higher F1 score and execution time in comparison to other methods. The training part is done on Supercomputer NVIDIA DGX V100.
C1 [Singal, Gaurav] Netaji Subhas Univ Technol, Delhi, India.
   [Singhal, Himanshu] IIIT, Vadodara, India.
   [Kushwaha, Riti; Badal, Tapas] Bennett Univ, Greater Noida, India.
   [Veeramsetty, Venkataramana] SR Engn Coll, Ctr Artificial Intelligence & Deep Learning, Dept Elect & Elect Engn, Warangal, Andhra Pradesh, India.
   [Lamba, Sonu] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Netaji Subhas University of Technology; Thapar Institute of Engineering
   & Technology
RP Singal, G (corresponding author), Netaji Subhas Univ Technol, Delhi, India.
EM gauravsingal789@gmail.com; 201551014@iiitvadodara.ac.in;
   riti.kushwaha07@gmail.com; venkataramana_v@srecwarangal.ac.in;
   tapas.badal@bennett.edu.in; sonu.lamba@thapar.edu
RI Singal, Gaurav/O-3764-2017; veeramsetty, venkataramana/AAK-1158-2020;
   Kushwaha, Riti/AAR-1690-2021; veeramsetty, venkataramana/GSN-4160-2022
OI Singal, Gaurav/0000-0001-7570-6292; veeramsetty,
   venkataramana/0000-0002-2512-5761; Kushwaha, Riti/0000-0003-0738-437X;
   veeramsetty, venkataramana/0000-0002-2512-5761
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   [Anonymous], 2017, ROAD SAFETY INDIA PU
   Arce F, 2017, 2017 2 INT C SMART D
   Fan C, 2019, IEEE ACCESS, V7, P150833, DOI 10.1109/ACCESS.2019.2947574
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Heidarizadeh, 2021, ARXIV 210404755
   Huang YP, 2010, INT J ADV MANUF TECH, V51, P233, DOI 10.1007/s00170-010-2626-2
   Hur J, 2013, IEEE INT VEH SYM, P1297, DOI 10.1109/IVS.2013.6629645
   Huval B, 2015, CORR 150401716
   Kim J, 2017, IEEE COMPUT SOC CONF, P1194, DOI 10.1109/CVPRW.2017.158
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Mamidala RS, 2019, TENCON IEEE REGION, P2454, DOI [10.1109/tencon.2019.8929655, 10.1109/TENCON.2019.8929655]
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Miao XD, 2012, INT J SMART SENS INT, V5, P957, DOI 10.21307/ijssis-2017-517
   Ning J, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9180666
   Ning X, 2018, IEEE T IMAGE PROCESS, V27, P2575, DOI 10.1109/TIP.2018.2806229
   Pomerleau D, 1996, IEEE EXPERT, V11, P19, DOI 10.1109/64.491277
   Singal G, 2018, IEEE 8 INT ADV COMPU
   Ullah A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207595
   Wang W, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00172-z
   Wojek C, 2008, LECT NOTES COMPUT SC, V5305, P733, DOI 10.1007/978-3-540-88693-8_54
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou SY, 2010, IEEE INT VEH SYM, P59, DOI 10.1109/IVS.2010.5548087
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 25
TC 2
Z9 2
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4965
EP 4978
DI 10.1007/s11042-022-12171-0
EA FEB 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000761979300019
DA 2024-07-18
ER

PT J
AU Zhong, YJ
   Sun, ZX
   Luo, ST
   Sun, YH
   Wang, Y
AF Zhong, Yijie
   Sun, Zhengxing
   Luo, Shoutong
   Sun, Yunhan
   Wang, Yi
TI Video supervised for 3D reconstruction from single image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image reconstruction; 3D reconstruction; Video supervision;
   Knowledge distillation
AB As a long-standing ill-posed problem, 3D reconstruction from a single image is an important research topic in computer vision. The information in a single image can represent an infinite number of possible three-dimensional shapes. To recover reasonable object geometry from a single image requires a correct shape prior. Thus, using what kind of supervision and how to make better use of training data are key issues. In this paper, we propose a framework for 3D reconstruction from single image with video supervision. On the one hand, we build a temporal network to generate fine 3D structure from video input benefiting from its temporal correlation. On the other hand, we introduce the knowledge distillation to transfer the shape prior extracted from the video. Also the mechanism ensures that the student network which for single image reconstruction can make full use of the knowledge learned from the teacher network which receives video input. In the inference phase, we can use the student network independently. Extensive experiments on ShapeNet show the superiority of our method.
C1 [Zhong, Yijie; Sun, Zhengxing; Luo, Shoutong; Sun, Yunhan; Wang, Yi] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM zhongyj@smail.nju.edu.cn; szx@nju.edu.cn
RI Sun, Zhengxing/A-7411-2011
OI Zhong, Yijie/0000-0002-2351-8799
FU National Natural Science Foundation of China [42075139, 42077232,
   61272219]; National High Technology Research and Development Program of
   China [2007AA01Z334]; Science and technology program of Jiangsu Province
   [BE2020082, BE2010072, BE2011058, BY2012190]; China Postdoctoral Science
   Foundation [2017M621700]; Innovation Fund of State Key Laboratory for
   Novel Software Technology [ZZKT2018A09]
FX This work is supported by the National Natural Science Foundation of
   China No.42075139, 42077232, 61272219; the National High Technology
   Research and Development Program of China No. 2007AA01Z334; the Science
   and technology program of Jiangsu Province No. BE2020082, BE2010072,
   BE2011058, BY2012190; the China Postdoctoral Science Foundation No.
   2017M621700 and Innovation Fund of State Key Laboratory for Novel
   Software Technology No. ZZKT2018A09.
CR [Anonymous], 2011, P 4 INT C ART INT ST
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544
   Brown M, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P56, DOI 10.1109/3DIM.2005.81
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Chang A. X., 2015, ARXIV
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dibra E, 2017, PROC CVPR IEEE, P5504, DOI 10.1109/CVPR.2017.584
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Harltey Andrew, 2006, Multiple View Geometry in ComputerVision, V2
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Insafutdinov E, 2018, ADV NEUR IN, V31
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kar A., 2017, P ADV NEUR INF PROC
   Kato H, 2019, PROC CVPR IEEE, P9770, DOI 10.1109/CVPR.2019.01001
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Khodatars M, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104949
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, STAT-US
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin CH, 2019, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2019.00106
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Mandikal P., 2018, PROC BRIT MACH VIS C, P55
   Mandikal P, 2019, IEEE WINT CONF APPL, P1052, DOI 10.1109/WACV.2019.00117
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Paschalidou D, 2020, PROC CVPR IEEE, P1057, DOI 10.1109/CVPR42600.2020.00114
   Paschalidou D, 2018, PROC CVPR IEEE, P3897, DOI 10.1109/CVPR.2018.00410
   Qi SH, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102053
   Rezende DaniloJimenez., 2016, ADV NEUR IN, P4997
   Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207
   Richter SR, 2015, PROC CVPR IEEE, P1128, DOI 10.1109/CVPR.2015.7298716
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Shoeibi A, 2020, ARXIV2007107850
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Simonyan K., 2014, CORR
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Tulsiani S, 2018, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR.2018.00306
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Wang KQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3726
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113
   WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9
   Wu J., 2017, PROC ADVNEURAL INF P, V30, P153
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xu Q., 2019, Advances in Neural Information Processing Systems (NeurIPS)
   Yan XC, 2016, ADV NEUR IN, V29
   Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w
   Yang B, 2019, IEEE T PATTERN ANAL, V41, P2820, DOI 10.1109/TPAMI.2018.2868195
   Yao Y, 2020, PROC CVPR IEEE, P528, DOI 10.1109/CVPR42600.2020.00061
   Zhu CY, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275008
NR 68
TC 1
Z9 1
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15061
EP 15083
DI 10.1007/s11042-022-12459-1
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761886300010
DA 2024-07-18
ER

PT J
AU El Ouariachi, I
   Benouini, R
   Zenkouar, K
   Zarghili, A
   El Fadili, H
AF El Ouariachi, Ilham
   Benouini, Rachid
   Zenkouar, Khalid
   Zarghili, Arsalane
   El Fadili, Hakim
TI RGB-D feature extraction method for hand gesture recognition based on a
   new fast and accurate multi-channel cartesian Jacobi moment invariants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-channel orthogonal moments; Moments invariants; Cartesian Jacobi
   moments; Fast and accurate computation; Feature extraction; Hand gesture
   recognition
ID PSEUDO-ZERNIKE MOMENTS; IMAGE REPRESENTATION; FAST COMPUTATION; FOURIER
   MOMENTS; RETRIEVAL; LEGENDRE; SET
AB Due to the diversity of hand gestures uses in human computer interaction and the complexity involved by gestures, many features have been proposed, however each feature has its own drawbacks. Therefore, in this work, we propose a new set of Red, Green, Blue and Depth (RGB-D) feature extraction method based on Image Moment Invariants, named Fast and Accurate Multi-channel Cartesian Jacobi Moment Invariants for Depth (FA-MCJMI(D)), RGB (FA-MCJMI(RGB)) and RGB-D (FA-MCJMI(RGBD)) images. We first introduce the fundamental concepts and properties to present the Multi-channel Cartesian Jacobi Moments (MCJMs). Then, we express the MCJMIs using geometric moment invariants under Rotation, Scaling and Translation (RST) transforms. Moreover, we provide the theoretical approach to enhance their numerical accuracy and improve their computational speed. Then we explore the application of our new moment invariants in hand gesture representation and recognition. Accordingly, several experiments are conducted to validate this new set of FA-MCJMI in comparison with some deep learning approches and other existing methods, on several popular hand gesture datasets, with regard to image reconstruction, invariability, numerical stability, computational complexity and recognition. The experiments demonstrate the superiority of the new FA-MCJMI set over the methods commonly used in the literature under geometric distortions, illumination variations and image occlusions.
C1 [El Ouariachi, Ilham; Benouini, Rachid; Zenkouar, Khalid; Zarghili, Arsalane] Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
   [El Fadili, Hakim] Univ Sidi Mohamed Ben Abdellah, Natl Sch Appl Sci, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Ouariachi, I (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
EM ilham.elouariachi@usmba.ac.ma; rachid.benouini@usmba.ac.ma
RI El Ouariachi, Ilham/HLQ-7521-2023
OI El Ouariachi, Ilham/0000-0002-9386-3651
FU Moroccan National Center for Scientific and Technical Research (CNRST)
   under the Excellence Research Scholarships Program
FX This work is supported by the Moroccan National Center for Scientific
   and Technical Research (CNRST) under the Excellence Research
   Scholarships Program.
CR Aggarwal A, 2019, BIOMED SIGNAL PROCES, V50, P10, DOI 10.1016/j.bspc.2019.01.009
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Anagha PH, 2021, INT J SPEECH TECHNOL, V24, P77, DOI 10.1007/s10772-020-09756-1
   [Anonymous], ARXIVMATH9602214
   [Anonymous], 2018, ASIA COMMUN PHOTONIC, DOI DOI 10.1109/ACP.2018.8596293
   [Anonymous], 2011, INT J COMPUT THEORY
   Benouini R, 2021, IET IMAGE PROCESS, V15, P523, DOI 10.1049/ipr2.12044
   Benouini R, 2019, PROCEDIA COMPUT SCI, V148, P409, DOI 10.1016/j.procs.2019.01.049
   Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Camacho-Bello C, 2014, J OPT SOC AM A, V31, P124, DOI 10.1364/JOSAA.31.000124
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Cheng HN, 2016, PATTERN RECOGN, V52, P397, DOI 10.1016/j.patcog.2015.09.028
   Chiang Amy, 2015, Journal of Computer Science, V11, P127, DOI 10.3844/jcssp.2015.127.136
   Dai X, 2012, INT C INT SCI INT DA, P90
   Devulapalli S, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.016504
   DICKEY JM, 1983, J AM STAT ASSOC, V78, P628, DOI 10.2307/2288131
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Ouariachi I, 2022, NETWORKING INTELLIGE, P737
   Elouariachi I, 2021, EUR SIGNAL PR CONF, P620, DOI 10.23919/Eusipco47968.2020.9287845
   Elouariachi I, 2020, PATTERN ANAL APPL, V23, P1337, DOI 10.1007/s10044-020-00866-9
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Hao Y, 2018, IEEE SIGNAL PROC LET, V25, P1064, DOI 10.1109/LSP.2018.2843296
   Hosny KM, 2007, APPL MATH COMPUT, V189, P1214, DOI 10.1016/j.amc.2006.12.025
   Hosny KM, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107324
   Hosny KM, 2019, PATTERN RECOGN, V88, P153, DOI 10.1016/j.patcog.2018.11.014
   Hosny KM, 2014, ARAB J SCI ENG, V39, P7097, DOI 10.1007/s13369-014-1336-8
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Li D, IEEE T GEOSCI ELECT
   Lin J, 2013, OPTIK, V124, P6795, DOI 10.1016/j.ijleo.2013.05.097
   Monge-Alvarez J, 2018, APPL ACOUST, V135, P124, DOI 10.1016/j.apacoust.2018.02.001
   MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nwali M, 2019, PATTERN RECOGN, V89, P151, DOI 10.1016/j.patcog.2019.01.001
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Ozcan T, 2020, MULTIMED TOOLS APPL, V79, P26587, DOI 10.1007/s11042-020-09268-9
   Papakostas GA, 2006, IMAGE VISION COMPUT, V24, P960, DOI 10.1016/j.imavis.2006.02.015
   Patil Sandeep Baburao, 2017, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V98, P19, DOI 10.1007/s40031-016-0250-8
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Roitberg A, 2019, IEEE COMPUT SOC CONF, P198, DOI 10.1109/CVPRW.2019.00029
   Schoutens W., 2000, LECT NOTES STAT, V146, DOI 10.1007/978-1-4612-1170-9
   Shanmuganathan V, 2020, NEURAL COMPUT APPL, V32, P16723, DOI 10.1007/s00521-020-05349-w
   Singh C, 2018, OPT LASER TECHNOL, V106, P234, DOI 10.1016/j.optlastec.2018.03.033
   Singh C, 2018, DIGIT SIGNAL PROCESS, V78, P376, DOI 10.1016/j.dsp.2018.04.001
   Singh C, 2014, DIGIT SIGNAL PROCESS, V27, P95, DOI 10.1016/j.dsp.2013.12.004
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sykora P, 2014, AASRI PROC, V9, P19, DOI 10.1016/j.aasri.2014.09.005
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Yang TF, 2019, INFORM SCIENCES, V505, P388, DOI 10.1016/j.ins.2019.07.089
   Yap PT, 2004, TENCON IEEE REGION, pA594
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 55
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12725
EP 12757
DI 10.1007/s11042-022-12161-2
EA FEB 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600006
DA 2024-07-18
ER

PT J
AU Guo, XE
   Liu, F
   Tian, XT
AF Guo, Xue
   Liu, Feng
   Tian, Xuetao
TI Noise modeling and denoising of images collected by on-board track
   inspection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian noise; Image denoising; Weighted nuclear norm minimization; Low
   rank matrix approximation
ID SPARSE; FILTER
AB With the increase of railway mileage year by year, technologies such as vision and optical-fiber sensing are widely applied to automatic railway inspections. On-board track inspection system (OBTIS) is a vision-based system designed for automatic railway inspection. How to improve the defect detection accuracy of the images collected by the OBTIS is a practical problem. Images will inevitably be contaminated by noises in the process of acquisition. And noise will have a negative effect on the accuracy of defect detection. To reduce the influence of noise on defect detection, on the one hand, we model the noise in the images collected by OBTIS as region-adaptive (RA) Gaussian noise through the probability distribution characteristics of numerous images. On the other hand, based on weighted nuclear norm minimization (WNNM), we propose a denoising model named RA-WNNM to reduce the noise of images in OBTIS. RA-WNNM adopts the adaptation characteristic of noise into a weight matrix, which makes it have no analytical solution. The alternating direction method of multipliers framework is employed to decompose the RA-WNNM into several sub-problems with analytical solutions for iterative solution. Experimental results demonstrate the superiority of RA-WNNM both in denoising and image classification.
C1 [Guo, Xue; Liu, Feng; Tian, Xuetao] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Engn Res Ctr Network Management Technol High Spee, Minist Educ, 3 Shangyuan Village, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Guo, XE (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Engn Res Ctr Network Management Technol High Spee, Minist Educ, 3 Shangyuan Village, Beijing, Peoples R China.
EM guoxue@bjtu.edu.cn; fliu@bjtu.edu.cn; xttian@bjtu.edu.cn
FU China Railway Corporation; (Ministry of Railways) [K20D00010]
FX This work was supported by the China Railway Corporation (Originally
   known as the Ministry of Railways) [grant numbers K20D00010].
CR Alippi C, 2000, IEEE T INSTRUM MEAS, V49, P559, DOI 10.1109/19.850395
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H., 2012, CVPR
   Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong L, 2019, IEEE T IMAGE PROCESS, V28, P4161, DOI 10.1109/TIP.2019.2907039
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Feng H, 2014, IEEE T INSTRUM MEAS, V63, P877, DOI 10.1109/TIM.2013.2283741
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Lane DM, 2014, INTRO STAT, P273
   Leung B, 2011, IEEE T IMAGE PROCESS, V20, P1885, DOI 10.1109/TIP.2011.2107524
   Liu D., 2018, Advances in Neural Information Processing Systems, P1673
   Liu JB, 2019, IEEE SENS J, V19, P6844, DOI 10.1109/JSEN.2019.2911015
   Liu L, 2020, IEEE C COMP VIS PATT
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Mandriota C, 2004, MACH VISION APPL, V15, P179, DOI 10.1007/s00138-004-0148-3
   Mao XJ, 2016, ADV NEUR IN, V29
   Nam S, 2016, PROC CVPR IEEE, P1683, DOI 10.1109/CVPR.2016.186
   Ni XF, 2022, IEEE T INTELL TRANSP, V23, P5806, DOI 10.1109/TITS.2021.3058635
   Peng L, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3011782
   Rakhshanfar M, 2016, IEEE T IMAGE PROCESS, V25, P4172, DOI 10.1109/TIP.2016.2588320
   Sholl H, 2006, WORLD AUT C
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR HOMELAND SECURITY AND PERSONAL SAFETY, P56, DOI 10.1109/CIHSPS.2006.313313
   Singh P, 2018, ENG SCI TECHNOL, V21, P589, DOI 10.1016/j.jestch.2018.05.009
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Valsesia D, 2019, IEEE IMAGE PROC, P2399, DOI [10.1109/icip.2019.8803367, 10.1109/ICIP.2019.8803367]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xu G, 2013, CHINA RAILWAY SCI
   Xu J, 2018, LECT NOTES COMPUT SC, V11212, P21, DOI 10.1007/978-3-030-01237-3_2
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Ye JQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3042297
   Yue ZS, 2019, ADV NEUR IN, V32
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 42
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11695
EP 11715
DI 10.1007/s11042-022-12104-x
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400012
DA 2024-07-18
ER

PT J
AU Hosseini, S
   Varzaneh, ZA
AF Hosseini, Soodeh
   Varzaneh, Zahra Asghari
TI Deep text clustering using stacked AutoEncoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AutoEncoder; Clustering; BERT word embedding; Topic modelling
ID FEATURE-SELECTION
AB Text data is a type of unstructured information, which is easily processed by a human, but it is hard for the computer to understand. Text mining techniques effectively discover meaningful information from text, which has received a great deal of attention in recent years. The aim of this study is to evaluate and analyze the comments and suggestions presented by Barez Iran Company. Barez is an unlabeled dataset. Extracting useful information from unlabeled large textual data by human to manually be very difficult and time consuming. Therefore, in this paper we analyze suggestions presented in Persian using BERTopic modeling for cluster analysis of the dataset. In BERTopic, each document belongs to a topic with a probability distribution. As a result, seven latent topics are found, covering a broad range of issues such as Installation, manufacture, correction, and device. Then we propose a novel deep text clustering based on hybrid of a stacked autoencoder and k-means clustering to organize text documents into meaningful groups for mining information from Barez data in an unsupervised method. Our data clustering has three main steps: 1) Text representation with a new pre-trained BERT model for language understanding called ParsBERT, 2) Text feature extraction based on based on a new architecture of stacked autoencoder to reduce the dimension of data to provide robust features for clustering, 3) Cluster the data by k-means clustering. We employ the Barez dataset to verify our work's effectiveness; Silhouette Score is used to evaluate the resulting clusters with the best value of 0.60 with 3 clusters grouping. Experimental evaluations demonstrate that the proposed algorithm clearly outperforms other clustering methods.
C1 [Hosseini, Soodeh; Varzaneh, Zahra Asghari] Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
   [Hosseini, Soodeh; Varzaneh, Zahra Asghari] Shahid Bahonar Univ Kerman, Mahani Math Res Ctr, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK); Shahid Bahonar University of
   Kerman (SBUK)
RP Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.; Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Mahani Math Res Ctr, Kerman, Iran.
EM so_hosseini@uk.ac.ir; z.asghari@math.uk.ac.ir
RI Asghari Varzaneh, Zahra/JPY-2561-2023
OI Asghari Varzaneh, Zahra/0000-0003-3173-6849
CR Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Ali F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020234
   [Anonymous], 2014, DEEP LEARNING VIA ST
   Barde BV, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P745, DOI 10.1109/ICCONS.2017.8250563
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bharti KK, 2015, EXPERT SYST APPL, V42, P3105, DOI 10.1016/j.eswa.2014.11.038
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Chauhan GS, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113673
   Choudhary AK, 2009, COMPUT IND, V60, P728, DOI 10.1016/j.compind.2009.05.006
   Da'u A, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112871
   Dashtipour K, 2020, NEUROCOMPUTING, V380, P1, DOI 10.1016/j.neucom.2019.10.009
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dinh DT, 2019, COMM COM INF SC, V1103, P1, DOI 10.1007/978-981-15-1209-4_1
   Farahani Mehrdad, 2020, PARSBERT TRANSFORMER
   Fayyad U, 1996, AI MAG, V17, P37
   Feldman R., 1995, Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95), P112
   Gupta Vishal, 2009, Journal of Emerging Technologies in Web Intelligence, V1, P60, DOI 10.4304/jetwi.1.1.60-76
   Habibi M, 2017, BIOINFORMATICS, V33, pI37, DOI 10.1093/bioinformatics/btx228
   Hariri FR., 2021, JURNAL ONLINE INFORM, V6, P79
   Indah RNG, 2019, J. Phys. Conf. Ser., V1363
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Joulin A., 2016, ARXIV PREPRINT ARXIV, V2, P427
   Karaa WB, 2016, INTEL SYST REF LIBR, V96, P267, DOI 10.1007/978-3-319-21212-8_12
   Li T, 2018, IEEE INT CONF BIG DA, P5375, DOI 10.1109/BigData.2018.8622140
   Lima ACES, 2014, NEURAL NETWORKS, V58, P122, DOI 10.1016/j.neunet.2014.05.020
   Mikolov T, 2013, P WORKSHOP ICLR 2013
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nasa D, 2012, TEXT MINING TECHNIQU, V2, P50
   Niharika S, 2012, SURVEY TEXT CATEGORI, V3, P39
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ombabi AH, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00668-1
   Orkphol K, 2019, INT J COMPUT INTELL, V18, DOI 10.1142/S1469026819500172
   Patel FN, 2012, TEXT MINING BRIEF SU, V2, P243
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Rachman DAC., 2021, JURNAL EKSPONENSIAL, V11, P167
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saumya S., 2020, SPAM REV DETECTION U, P1
   Silva C, 2003, IEEE IJCNN, P1661
   Thirumoorthy K, 2021, HYBRID APPROACH TEXT, V178
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Tryon R.C., 1939, Cluster analysis: correlation profile and orthometric (factor) analysis for the isolation of unities in mind and personality
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Vayansky I, 2020, INFORM SYST, V94, DOI 10.1016/j.is.2020.101582
   Webster J.J., 1992, COLING 1992, V4, P1106, DOI [DOI 10.3115/992424.992434, 10.3115/992424.992434]
   Yousefi-Azar M, 2017, EXPERT SYST APPL, V68, P93, DOI 10.1016/j.eswa.2016.10.017
NR 49
TC 7
Z9 7
U1 11
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10861
EP 10881
DI 10.1007/s11042-022-12155-0
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700014
DA 2024-07-18
ER

PT J
AU Marwa, F
   Zahzah, EH
   Bouallegue, K
   Machhout, M
AF Marwa, Fradi
   Zahzah, El-hadi
   Bouallegue, Kais
   Machhout, Mohsen
TI Deep learning based neural network application for automatic ultrasonic
   computed tomographic bone image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VSMN-VGG-SegNet; USCT; Segmentation; Time process; GPU
AB Deep-learning techniques have led to technological progress in the area of medical imaging segmentation especially in the ultrasound domain. In this paper, the main goal of this study is to optimize a deep-learning-based neural network architecture for automatic segmentation in Ultrasonic Computed Tomography (USCT) bone images in a short time process. The proposed method is based on an end to end neural network architecture. First, the novelty is shown by the improvement of Variable Structure Model of Neuron (VSMN), which is trained for both USCT noise removal and dataset augmentation. Second, a VGG-SegNet neural network architecture is trained and tested on new USCT images not seen before for automatic bone segmentation. Therefore, we offer a free USCT dataset. In addition, the proposed model is implemented on both the CPU and the GPU, hence overcoming previous works by a value of 97.38% and 96% for training and validation and achieving high segmentation accuracy for testing with a small error of 0.006, in a short time process. The suggested method demonstrates its ability to augment USCT data and then to automatically segment USCT bone structures achieving excellent accuracy outperforming the state of the art.
C1 [Marwa, Fradi; Machhout, Mohsen] Monastir Univ, Phys Dept, Fac Sci Monastir, Monastir, Tunisia.
   [Marwa, Fradi; Zahzah, El-hadi] La Rochelle Univ, Lab Informat Image & Interact, L3i, La Rochelle, France.
   [Bouallegue, Kais] Sousse Univ, ISSAT Sousse, Sousse, Tunisia.
C3 Universite de Monastir; Universite de Sousse
RP Marwa, F (corresponding author), Monastir Univ, Phys Dept, Fac Sci Monastir, Monastir, Tunisia.
EM marwafradi32@gmai1.com
OI Mohsen, Machhout/0000-0002-5629-0508
FU ministry of high education and scientific research in Tunisia
FX This study has been funded by the ministry of high education and
   scientific research in Tunisia.
CR [Anonymous], 2019, IJCA
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Belal SL, 2019, EUR J RADIOL, V113, P89, DOI 10.1016/j.ejrad.2019.01.028
   Bouallegue K, 2017, NEUROCOMPUTING, V249, P28, DOI 10.1016/j.neucom.2017.03.006
   Bullock J., 2018, ARXIV PREPRINT ARXIV
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   Dahdouh S., 2011, THESIS U PARIS SUD
   Dong JB, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224426
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Fradi Marwa, 2018, International Journal of Image, Graphics and Signal Processing, V10, P1, DOI 10.5815/ijigsp.2018.09.01
   Fradi M, 2018, INT C SCI EL TECHN I, P372
   Guerroumi, 2019, THESIS ECOLE TECHNOL
   Hopp T, 2014, PROC SPIE, V9040, DOI 10.1117/12.2044376
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jue J, 2019, LECT NOTES COMPUT SC, V11769, P221, DOI 10.1007/978-3-030-32226-7_25
   Kayid A., 2018, PERFORMANCE CPUS GPU
   Khagi B, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/3640705
   Klein A, 2019, INT J COMPUT ASS RAD, V14, P21, DOI 10.1007/s11548-018-1883-7
   La Rosa F., 2017, A Deep Learning Approach to Bone Segmentation in CT scans
   Lasaygues P, 2018, P INT WORKSH MED ULT, P291
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Marwa F, 2019, PROC SPIE, V10955, DOI 10.1117/12.2506473
   Minnema J, 2018, COMPUT BIOL MED, V103, P130, DOI 10.1016/j.compbiomed.2018.10.012
   Oda M., 2016, INT C MED IM COMP CO, P556
   Ruiter NV, 2017, PROC SPIE, V10139, DOI 10.1117/12.2272593
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saood A, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00529-5
   Sedik A, 2020, VIRUSES-BASEL, V12, DOI 10.3390/v12070769
   Sudha S, 2019, TENCON IEEE REGION, P767, DOI [10.1109/TENCON.2019.8929648, 10.1109/tencon.2019.8929648]
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   TORRES JSM, 2019, SYMP IMAG SIG PROC A, pNIL58
   Tung DL, INVOLVING CPUS MULTI
   van Sloun RJG, 2020, P IEEE, V108, P11, DOI 10.1109/JPROC.2019.2932116
   WANG X, 2016, FOUND TRENDS SIGNAL, V8
   Yalman Y, 2013, TURK J ELECTR ENG CO, V21, P603, DOI 10.3906/elk-1111-11
NR 36
TC 9
Z9 9
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13537
EP 13562
DI 10.1007/s11042-022-12322-3
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000756208600002
PM 35194385
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Balochian, S
   Baloochian, H
AF Balochian, Saeed
   Baloochian, Hossein
TI Edge detection on noisy images using Prewitt operator and fractional
   order differentiation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Edge detection; Fractional order differentiation; Noisy images
ID ANT COLONY OPTIMIZATION; ALGORITHM
AB Edge detection is the most important step in finding discontinuities and exploring boundaries on digital images. This paper presents a novel method for edge detection using fractional order differentiation (FOD) coupled with Prewitt operator. FOD employs information of neighboring pixels to perform weighted averaging implicitly to not only calculate derivative of the image but also eliminate noise. Performing various experiments on sample images, visual evaluation of the results indicated superiority of the proposed method over five traditional and six recently proposed edge detection methods. Finally, performance evaluation of Prewitt fractional order edge detection (FOED) based on Pratt's figure of merit (FOM) showed its promising potentials for edge detection on medical images.
C1 [Balochian, Saeed] Islamic Azad Univ, Dept Elect Engn, Gonabad Branch, Gonabad 9691664791, Khorasan E Raza, Iran.
   [Baloochian, Hossein] Islamic Azad Univ, Ferdows Branch, Ferdows, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Balochian, S (corresponding author), Islamic Azad Univ, Dept Elect Engn, Gonabad Branch, Gonabad 9691664791, Khorasan E Raza, Iran.
EM saeed.balochian@gmail.com; hossein.baloochian@gmail.com
RI Balochian, Saeed/AAN-3639-2021
OI Balochian, Saeed/0000-0003-3137-9167
CR [Anonymous], 2013, SIGNAL IMAGE PROCESS
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chiwueze OI, 2013, LIFE SCI J, V10, P171
   Das S, 2011, FUNCTIONAL FRACTIONAL CALCULUS, SECOND EDITION, P51
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Gebäck T, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-75
   Gu M, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/6098021
   Jevtic A, 2009, IEEE IND ELEC, P3177, DOI 10.1109/IECON.2009.5415195
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Kumar P, 2016, OPTIK, V127, P8710, DOI 10.1016/j.ijleo.2016.05.118
   Larnier S, 2012, IEEE INT C AC SPEECH, P25
   Liu XC, 2015, OPT COMMUN, V353, P147, DOI 10.1016/j.optcom.2015.05.019
   Lu DS, 2008, PATTERN RECOGN LETT, V29, P416, DOI 10.1016/j.patrec.2007.10.021
   Mathieu B, 2003, SIGNAL PROCESS, V83, P2421, DOI 10.1016/S0165-1684(03)00194-4
   Mekideche M, 2014, INT CONF MULTIMED, P223, DOI 10.1109/ICMCS.2014.6911409
   Nadakuduru PV, 2010, WORLD C ENG COMPUTER, V1
   Neto CMS, 2013, BRAZIL POWER ELECTR, P699, DOI 10.1109/COBEP.2013.6785191
   Pu YF, 2008, SCI CHINA SER F, V51, P1319, DOI 10.1007/s11432-008-0098-x
   Reshmalakshmi C., 2017, Materials Today: Proceedings, V4, P4274, DOI 10.1016/j.matpr.2017.02.131
   Singh S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P393
   SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2
   Thirumavalavan S, 2016, J ADV RES, V7, P979, DOI 10.1016/j.jare.2016.04.002
   Tian J, 2011, LECT NOTES COMPUT SC, V6910, P27, DOI 10.1007/978-3-642-24016-4_2
   Tian J, 2008, IEEE C EVOL COMPUTAT, P751, DOI 10.1109/CEC.2008.4630880
   Zhang Y., 2010, J COMPUT INF SYST, V6, P3191
   Zhuang X, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P133, DOI 10.1109/CIMSA.2004.1397248
NR 26
TC 20
Z9 21
U1 16
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 14
PY 2022
DI 10.1007/s11042-022-12011-1
EA FEB 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZA9TO
UT WOS:000756497800015
DA 2024-07-18
ER

PT J
AU Madhu
   Kumar, R
AF Madhu
   Kumar, Raman
TI A hybrid feature extraction technique for content based medical image
   retrieval using segmentation and clustering techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; GLCM; DPG; Canny edge detection; OKE; Clustering; Medical image
ID SYSTEM
AB In this paper hybrid feature extraction algorithm for the medical images has been proposed. These medical images are a mixture of the ultrasound image, Brain MRI, and breast cancer images. Previous research did limited work in CBIR. Some research considered just PCA while some considered only DWT. There are limited researches that focused on the hybrid approach. However, the previous researches that considered the hybrid approach has limited scope. The research is considering three different hybrid approaches. The first approach is the hybridization of DWT, PCA, and GLCM. The approach is the hybridization of OKE, DWT, PCA, and GLCM. OKE hybrid algorithm converts the grayscale image into the binary image using the Otsu binarization algorithm. Here, the medical image has been processed to grayscale before clustering. The third hybrid approach is the integration of Canny Edge detection, DWT, PCA, and GLCM. Here is the edge detection mechanism getting the edges of an image before applying it to the cluster. The images are clustered using K-means clustering and calculated the distance using the Euclidean distance metric. Then hybrid feature extraction algorithm is proposed using Discrete Wavelet Transform (DWT), the principal component analysis (PCA), and gray-Level Co-Occurrence Matrix (GLCM). The simulation of proposed algorithms and comparative analysis is also done in this paper. The image dataset used in research is the composition of brain MRI to detect brain tumors, ultrasounds samples, and samples to detect breast cancer. The edge detection mechanism has been integrated into GLCM in order to improve the accuracy during the classification of medical images.
C1 [Madhu; Kumar, Raman] IK Gujral Punjab Tech Univ, Dept Comp Sci & Engn, Kapurthala, Punjab, India.
C3 I. K. Gujral Punjab Technical University
RP Madhu (corresponding author), IK Gujral Punjab Tech Univ, Dept Comp Sci & Engn, Kapurthala, Punjab, India.
EM madhu.dahiya2588@gmail.com; er.ramankumar@aol.in
RI Kumar, Raman/I-6869-2019
OI Kumar, Raman/0000-0003-2934-7609
CR Agarwal S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P368, DOI 10.1109/ICICICT.2014.6781310
   Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Alsmadi MK, 2020, ARAB J SCI ENG, V45, P3317, DOI 10.1007/s13369-020-04384-y
   Annrose J, 2018, OPTIK, V157, P1053, DOI 10.1016/j.ijleo.2017.11.179
   [Anonymous], 2016, 2016 INT C COMP TECH, DOI DOI 10.1109/ICCTIDE.2016.7725364
   Ansari MA, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1136, DOI 10.1109/CCAA.2017.8229967
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Banharnsakun A, 2020, COMPUT INTELL-US, V36, P351, DOI 10.1111/coin.12275
   Basha Cmak Zeelan, 2020, 2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC). Proceedings, P991, DOI 10.1109/ICCMC48092.2020.ICCMC-000184
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dorobantiu A, 2020, PATTERN ANAL APPL, V23, P883, DOI 10.1007/s10044-019-00808-0
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   ElAdel A, 2016, MACH VISION APPL, V27, P781, DOI 10.1007/s00138-016-0789-z
   Gupta Ekta, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359320
   Jain R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1970, DOI 10.1109/RTEICT.2016.7808181
   Jyothi N., 2020, Intelligent Communication, Control and Devices. Proceedings of ICICCD 2018. Advances in Intelligent Systems and Computing (AISC 989), P799, DOI 10.1007/978-981-13-8618-3_82
   Lee JS, 2020, TRANS ELECTR ELECTRO, V21, P150, DOI 10.1007/s42341-020-00188-x
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Manikandan LC, 2021, J AMB INTEL HUM COMP, V12, P4689, DOI 10.1007/s12652-020-01871-w
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Prathyakshini Akshaya, 2018, COMMUNICATIONS COMPU, V801
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Renita DB, 2020, MULTIMED TOOLS APPL, V79, P17227, DOI 10.1007/s11042-019-07777-w
   Sengur A, 2008, COMPUT BIOL MED, V38, P329, DOI 10.1016/j.compbiomed.2007.11.004
   Shashank J, 2008, PROC CVPR IEEE, P365
   Shirke SS, 2018, TECHNOSOCIETAL 2016, DOI [10.1007/978-3-319-53556-2_26, DOI 10.1007/978-3-319-53556-2_26]
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Zhang CY, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P135, DOI 10.1109/SERA.2017.7965719
   Zhang G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112521
NR 32
TC 3
Z9 3
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8871
EP 8904
DI 10.1007/s11042-022-11901-8
EA FEB 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000752200500001
DA 2024-07-18
ER

PT J
AU JinnAff, R
   Kim, J
AF JinnAff, Ruichen
   Kim, Jongweon
TI Coordinate quantization transformation CityGML watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CityGML watermarking; Quantization index modulation; Group quantization
AB As most of the contents are becoming digitized, robust and invisible copyright notation of visible digital contents is required. In this paper, we proposed a blind watermarking method for CityGML (City Geography Markup Language) model using a group coordinate quantization transformation (CQT) algorithm. Firstly, the Vertices of CityGML models were extracted from a text file. Secondly, the candidate coordinate of the vertex set was selected and it was quantized by a given space. Then, the quantized vertex set groups were sorted and selected. Finally, the watermark was inserted by altering their mean values. We embedded the watermark on buildings or objects on the map and the data load should be guaranteed and imperceptible should be maintained. The proposed method is blind and efficient for CityGML data copyright protection compared to the existing method.
C1 [JinnAff, Ruichen] HELIOSEN Co Ltd, Seongnam Si, Gyeonggi Do, South Korea.
   [Kim, Jongweon] Sangmyung Univ, Dept Artificial Intelligence Things, Seoul 03016, South Korea.
C3 Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Dept Artificial Intelligence Things, Seoul 03016, South Korea.
EM jwkim@smu.ac.kr
OI Kim, Jongweon/0000-0002-8916-6431
CR Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Chang HJ, 2009, IEEE INT CON MULTI, P1014, DOI 10.1109/ICME.2009.5202669
   Chen L, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115935
   Cheng Q, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P389, DOI 10.1109/ICME.2000.869622
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Hong DJ, 2019, INFORM COMMUNICATION
   Hou JU, 2017, IEEE T INF FOREN SEC, V12, P2712, DOI 10.1109/TIFS.2017.2718482
   Jiang DY., 2018, J THEOR APPL INF TEC, V96, P7455
   Jiang DY, 2018, P 12 INT C COMP GRAP, P229
   Jin R, 2019, INT CONF UBIQ FUTUR, P718, DOI [10.1109/icufn.2019.8806040, 10.1109/ICUFN.2019.8806040]
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Kim, 2017, J MACROTRENDS TECHNO, V5, P1
   Kim YW, 2003, PROC INT CONF DOC, P775
   Li S, 2017, J INFORM HIDING MULT, V8, P97
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Son J, 2017, LECT NOTES ELECTR EN, V424, P315, DOI 10.1007/978-981-10-4154-9_37
   Song HS, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P332
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
NR 20
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8561
EP 8573
DI 10.1007/s11042-022-11943-y
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751676900001
DA 2024-07-18
ER

PT J
AU Nie, L
   Chen, TS
   Wang, ZX
   Kang, WX
   Lin, L
AF Nie, Lin
   Chen, Tianshui
   Wang, Zhouxia
   Kang, Wenxiong
   Lin, Liang
TI Multi-label image recognition with attentive transformer-localizer
   module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label image recognition; Attention model; Recurrent memory
   network; Image context learning; Deep representation learning
ID SYSTEM
AB Recently, remarkable progress on multi-label image classification has been achieved by locating semantic-agnostic image regions and extracting their features with deep convolutional neural networks. However, existing pipelines depend on the hypothesis region generation step, which typically brings about extra computational costs, e.g., generating hundreds of meaningless proposals and extracting their features. Moreover, the contextual dependencies among these localized regions are usually ignored or oversimplified during the learning and inference stages. To resolve these issues, we develop a novel attentive transformer-localizer (ATL) module that contains differential transformations (e.g., translation, scale), which can automatically discover the discriminative semantic-aware regions from input images in terms of multi-label recognition. This module can be flexibly incorporated with recurrent neural networks such as the long short-term memory (LSTM) network for memorizing and updating the contextual dependencies of the localized regions. We thus build a unified multi-label image recognition framework. Specifically, the ATL module is applied to progressively localize the attentive regions from the convolutional feature maps in a proposal-free manner, and the LSTM network sequentially predicts label scores for the localized regions and updates the parameters of the ATL module while capturing the global dependencies among these regions. To associate the localized regions with semantic labels over diverse locations and scales, we further design three constraints together with the ATL module. Extensive experiments and evaluations on two large-scale benchmarks (i.e., PASCAL VOC and Microsoft COCO) show that the proposed approach achieves superior performance over existing state-of-the-art methods in terms of both performance and efficiency.
C1 [Nie, Lin; Kang, Wenxiong] South China Univ Technol, Wushan Campus 381 Wushan Rd, Guangzhou, Guangdong, Peoples R China.
   [Chen, Tianshui] Guangdong Univ Technol, Higher Educ Mega Ctr, 100 WaiHuan West Rd, Guangzhou, Peoples R China.
   [Wang, Zhouxia] Univ Hong Kong, Hong Kong, Peoples R China.
   [Lin, Liang] Sun Yat Sen Univ, Higher Educ Mega Ctr, 137 WaiHuan East Rd, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; Guangdong University of
   Technology; University of Hong Kong; Sun Yat Sen University
RP Chen, TS (corresponding author), Guangdong Univ Technol, Higher Educ Mega Ctr, 100 WaiHuan West Rd, Guangzhou, Peoples R China.
EM tianshuichen@gmail.com
RI Li, Li/IAQ-0885-2023; l, j/HNC-5728-2023; qin, cheng/KHC-3344-2024; L,
   J/JEF-9564-2023; zhang, cl/JDW-6549-2023; LU, LU/JEZ-4760-2023; Li,
   Jiaxi/HTS-3430-2023; l, j/JVZ-8480-2024; Lin, L/HKO-8213-2023
OI Li, Jiaxi/0000-0002-8197-8590; Chen, Tianshui/0000-0002-5848-5624
FU Deeply promote the innovation-driven booster project of Foshan City
   [2021020]; National Natural Science Foundation of China [61976095]
FX This work is supported by Deeply promote the innovation-driven booster
   project of Foshan City (NO.2021020) and National Natural Science
   Foundation of China (No. 61976095).
CR [Anonymous], 2005, Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM'05, DOI [DOI 10.1145/1099554.1099591, 10.1145/1099554.1099591]
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.37
   Bai Y, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500657
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen L, 2019, VISUAL COMPUT, V35, P1361, DOI 10.1007/s00371-018-01615-0
   Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083
   CHEN T, 2021, ARXIV211210941
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Guo Y, 2011, IN C IND ENG ENG MAN, P1300, DOI 10.1109/IEEM.2011.6118126
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Li Z, 2018, MULTIMED TOOLS APPL, V77, P6079, DOI 10.1007/s11042-017-4517-0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2017, IEEE INFOCOM SER
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LYU F, 2018, COARSE FINE MULTILAB, P1, DOI DOI 10.1109/ISC2.2018.8656664
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang S, 2017, IEEE T MULTIMEDIA, V19, P2105, DOI 10.1109/TMM.2017.2729786
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829
   WANG Z, IEEE T CIRCUITS SYST, P1
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300
   Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 60
TC 5
Z9 5
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7917
EP 7940
DI 10.1007/s11042-021-11818-8
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500005
DA 2024-07-18
ER

PT J
AU Ramsook, D
   Hosein, P
   Hosein, N
AF Ramsook, Darren
   Hosein, Patrick
   Hosein, Nicholas
TI Instant message summarization with Emoji unicode characterset support
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Textual summarization; Instant message; Emoji; Machine learning; Natural
   language processing
AB Summarization techniques have traditionally achieved good performance results when summarizing sentences and documents. However, their application to instant messaging notifications have not been thoroughly examined. This research outlines a model for summarizing instant messages, through the use of text and the Emoji Unicode Characterset, for applications where screen space is limited (e.g, in smartwatches and smart bracelets). The proposed model uses a Greedy N-gram token replacement method. This method produced high quality results and was evaluated using human participants. We found that there is a decrease in the time taken to read the summarized message when compared with the original message.
C1 [Ramsook, Darren] Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
   [Hosein, Patrick] Univ West Indies, Dept Comp Sci, St Augustine, Trinidad Tobago.
   [Hosein, Nicholas] Univ Calif Davis, Dept Elect & Comp Engn, Davis, CA 95616 USA.
C3 Trinity College Dublin; University West Indies Mona Jamaica; University
   West Indies Saint Augustine; University of California System; University
   of California Davis
RP Ramsook, D (corresponding author), Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
EM darrenramsook@outlook.com; patrick.hosein@sta.uwi.edu;
   nhosein@ucdavis.edu
OI Ramsook, Darren/0000-0001-8691-9402; Hosein,
   Nicholas/0000-0003-3103-5129
CR Altmami NI, 2022, J KING SAUD UNIV-COM, V34, P1011, DOI 10.1016/j.jksuci.2020.04.020
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Colmenares C.A, 2015, PROC C N AM CHAPTER, P133, DOI DOI 10.3115/V1/N15-1014
   CTIA, 2019, 2019 CTIA ANN SURV H
   Devlin J., 2018, BERT PRE TRAINING DE
   Google, 2013, WORD2VEC MOD
   Haridas AV, 2018, INT J KNOWL-BASED IN, V22, P39, DOI 10.3233/KES-180374
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jain A, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P51, DOI 10.1109/MLDS.2017.12
   Kelly R., 2015, Experiences of Technology Appropriation: Unanticipated Users, Usage, Circumstances, and Design, V2
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Madankar M, 2016, PROCEDIA COMPUT SCI, V78, P845, DOI 10.1016/j.procs.2016.02.071
   Moratanch N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P265
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Rekabdar B, 2019, IEEE INT C SEMANT CO, P204, DOI [10.1109/ICSC.2019.00047, 10.1109/ICOSC.2019.8665583]
   Sharaff A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P906, DOI [10.1109/ICCS45141.2019.9065722, 10.1109/iccs45141.2019.9065722]
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Tan JW, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4109
   Tatman R., 2017, EMOJINET
   Twilio, 2016, GLOB MOB MESS CONS R
   Twitter, 2016, NEW TWEETS 2 REC
   Widyassari AP, 2020, J KING SAUD UNIV-COM, V34, P1029, DOI 10.1016/j.jksuci.2020.05.006
   Zhang S., 2020, P 59 ANN M ASS COMP
NR 23
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7957
EP 7967
DI 10.1007/s11042-022-12006-y
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865500001
DA 2024-07-18
ER

PT J
AU Sowmyayani, S
   Rani, PAJ
AF Sowmyayani, S.
   Rani, P. Arockia Jansi
TI Salient object based visual sentiment analysis by combining deep
   features and handcrafted features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object; Convolutional neural network; Visual sentiment; Clutter
ID IMAGES; COMPLEXITY
AB With the rapid growth of social networks, the visual sentiment analysis has quickly emerged for opinion mining. Recent study reveals that the sentiments conveyed by some images are related to salient objects in them, we propose a scheme for visual sentiment analysis that combines deep and handcrafted features. First, the salient objects are identified from the entire images. Then a pre-trained model such as VGG16 is used to extract deep features from the salient objects. In addition, hand-crafted features such as Visual texture, Colourfulness, Complexity and Fourier Sigma are extracted from all the salient objects. Deep features are combined individually with all the handcrafted features and the performance is measured. The sentiment is predicted using Convolutional Neural Network Classifier. The proposed method is tested on ArtPhoto, Emotion6, Abstract, IAPS datasets, Flickr and Flickr & Instagram datasets. The experimental results substantially proved that the proposed method achieves higher accuracy than other methods.
C1 [Sowmyayani, S.] St Marys Coll Autonomous, Dept Comp Sci, Thoothukudi, Tamil Nadu, India.
   [Rani, P. Arockia Jansi] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Sowmyayani, S (corresponding author), St Marys Coll Autonomous, Dept Comp Sci, Thoothukudi, Tamil Nadu, India.
EM sowmyayani@gmail.com; jansimsuniv@gmail.com
CR Ali AR, 2017, IEEE WINT CONF APPL, P679, DOI 10.1109/WACV.2017.81
   Andrienko YA, 2000, EUR PHYS J B, V15, P539, DOI 10.1007/s100510051157
   [Anonymous], 2015, P 1 INT WORKSH AFF S, DOI 10.1145/2813524.2813530
   Barla A, 2002, LECT NOTES COMPUT SC, V2388, P83
   BIRKHOFF GEORGE DAVID, 1933, Aesthetic measure, DOI DOI 10.4159/HARVARD.9780674734470
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Braun J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00808
   Chen T, 2014, ARXIV PREPRINT ARXIV
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fu KR, 2018, NEUROCOMPUTING, V275, P788, DOI 10.1016/j.neucom.2017.09.028
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He XS, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON BIG DATA AND COMPUTATIONAL INTELLIGENCE (ICBDCI)
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Nicolaou M.A., 2011, Proceedings of the 19th ACM international conference on Multimedia, P933
   Peng K.-C., 2005, 2015 IEEE C COMPUTER, P860
   Proulx R, 2008, ECOL INDIC, V8, P270, DOI 10.1016/j.ecolind.2007.02.005
   Redies C, 2012, LECT NOTES COMPUT SC, V7583, P522, DOI 10.1007/978-3-642-33863-2_54
   Rosenholtz R, 2007, J VISION, V7, DOI 10.1167/7.2.17
   Solli M, 2009, LECT NOTES COMPUT SC, V5702, P573, DOI 10.1007/978-3-642-03767-2_70
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wu LF, 2020, NEURAL PROCESS LETT, V51, P2063, DOI 10.1007/s11063-019-10027-7
   Xiong HT, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0433-8
   Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266
   Yang JF, 2018, PROC CVPR IEEE, P7584, DOI 10.1109/CVPR.2018.00791
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   Zhan C, 2019, IEEE I CONF COMP VIS, P1151, DOI 10.1109/ICCV.2019.00124
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 36
TC 3
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7941
EP 7955
DI 10.1007/s11042-022-11982-5
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500001
DA 2024-07-18
ER

PT J
AU Khatter, H
   Ahlawat, AK
AF Khatter, Harsh
   Ahlawat, Anil Kumar
TI Content curation algorithm on blog posts using hybrid computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blog; Cosine similarity; Fuzzy logic self-attention; Bi-directional Long
   short term memory auto encoder
AB Content curation is a significant step to identify the relevant content for the searched topics. There are many methods introduced to generate summarized contents but those methods focussed only on generating precise contents that lacked the key essence of the input texts. Therefore, we propose a hybrid model with the integration of self-attention to the bi-directional long short-term memory auto-encoder (Bi-LSTM-AE) to generate information-rich abstracts. Initially, the dataset is pre-processed and then the major word-level and sentence-level features are extracted. Then, based on the similarities between the contents, the extractive summary is generated which is then given to the auto-encoder for final abstraction. The efficiency of the model has been proved through simulations with the CNN/Daily Mail dataset in terms of ROUGE metrics. The proposed model outperformed the other compared models with a score of 0.59 for ROUGE 1, 0.39 for ROUGE 2 and 0.71 for ROUGE L with high generalization.
C1 [Khatter, Harsh; Ahlawat, Anil Kumar] Dr APJ Abdul Kalam Tech Univ, KIET Grp Inst, Delhi NCR, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); KIET Group of
   Institutions
RP Khatter, H (corresponding author), Dr APJ Abdul Kalam Tech Univ, KIET Grp Inst, Delhi NCR, Lucknow, Uttar Pradesh, India.
EM hk9219275292@gmail.com
RI Khatter, Harsh/JOK-0349-2023; Ahlawat, Anil K/A-5396-2016
OI Khatter, Harsh/0000-0002-4758-2971; 
CR Belwal RC, 2021, J AMB INTEL HUM COMP, V12, P8975, DOI 10.1007/s12652-020-02591-x
   Bidoki M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102341
   Cong Y, 2017, IEEE T IMAGE PROCESS, V26, P185, DOI 10.1109/TIP.2016.2619260
   Gerani S, 2019, COMPUT SPEECH LANG, V53, P302, DOI 10.1016/j.csl.2016.06.005
   Joshi A, 2019, EXPERT SYST APPL, V129, P200, DOI 10.1016/j.eswa.2019.03.045
   Karthikeyan T., 2019, International Journal of Web Portals, V11, P41, DOI 10.4018/IJWP.2019070103
   Khattab H, 2012, POW EN SOC GEN M, P1
   Khatter H., 2015, INT J U AND E SERVIC, V8, P45, DOI [10.14257/ijunesst.2015.8.6.05, DOI 10.14257/IJUNESST.2015.8.6.05]
   Khatter H, 2020, SOFT COMPUT, P1
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2082-z
   Lamsiyah S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114152
   Malhotra D, 2019, J MANAG ANAL, V6, P365, DOI 10.1080/23270012.2019.1671241
   Manjari K. Usha, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P648, DOI 10.1109/ICOEI48184.2020.9142938
   Mao XK, 2019, EXPERT SYST APPL, V133, P173, DOI 10.1016/j.eswa.2019.05.011
   Nguyen MT, 2019, INFORM PROCESS MANAG, V56, P495, DOI 10.1016/j.ipm.2018.12.006
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Oliveira H, 2016, EXPERT SYST APPL, V65, P68, DOI 10.1016/j.eswa.2016.08.030
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Roul RK, 2021, SOFT COMPUT, V25, P1113, DOI 10.1007/s00500-020-05207-w
   Souza CM, 2021, SCIENTOMETRICS, V126, P135, DOI 10.1007/s11192-020-03732-x
   Trappey AJC, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101027
   Vázquez E, 2018, J INTELL FUZZY SYST, V35, P353, DOI 10.3233/JIFS-169594
   Verma P, 2019, EXPERT SYST APPL, V120, P43, DOI 10.1016/j.eswa.2018.11.022
   Wang RY, 2019, COMPUT SPEECH LANG, V57, P1, DOI 10.1016/j.csl.2019.01.006
   Wu LF, 2017, NEUROCOMPUTING, V236, P73, DOI 10.1016/j.neucom.2016.08.114
   You XD, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P154, DOI [10.1109/CCET48361.2019.8989315, 10.1109/ccet48361.2019.8989315]
   Zhao MJ, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101166
NR 30
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7589
EP 7609
DI 10.1007/s11042-022-12105-w
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749232600006
DA 2024-07-18
ER

PT J
AU Khanam, KZ
   Srivastava, G
   Mago, V
AF Khanam, Kazi Zainab
   Srivastava, Gautam
   Mago, Vijay
TI The homophily principle in social network analysis: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Homophily; Social network analysis; Natural language processing; Machine
   learning
ID LATENT DIRICHLET ALLOCATION; TWITTER; MEDIA; ONLINE; MODEL; US;
   IDENTIFICATION; CONSUMPTION; ENGAGEMENT; DISCOURSE
AB In recent years, social media has become a ubiquitous and integral part of social discourse. Homophily is a fundamental topic in network science and can provide insights into the flow of information and behaviours within society. Homophily mainly refers to the tendency of similar-minded people to interact with one another in social groups than with dissimilar-minded people. The study of homophily has been very useful in analyzing the formations of online communities. In this paper, we review and survey the effects of homophily in social networks and summarize the state-of-art methods that have been proposed in the past recent years to identify and measure those effects in multiple types of social networks. We conclude with a critical discussion of open challenges and directions for future research.
C1 [Khanam, Kazi Zainab; Srivastava, Gautam; Mago, Vijay] Lakehead Univ, Dept Comp Sci, Thunder Bay, ON, Canada.
   [Srivastava, Gautam] Brandon Univ, Dept Math & Comp Sci, Brandon, MB R7A 6A9, Canada.
   [Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, Taichung 40402, Taiwan.
C3 Lakehead University; Brandon University; China Medical University Taiwan
RP Srivastava, G (corresponding author), Lakehead Univ, Dept Comp Sci, Thunder Bay, ON, Canada.; Srivastava, G (corresponding author), Brandon Univ, Dept Math & Comp Sci, Brandon, MB R7A 6A9, Canada.; Srivastava, G (corresponding author), China Med Univ, Res Ctr Interneural Comp, Taichung 40402, Taiwan.
EM kkhanam@lakeheadu.ca; srivastavag@brandonu.ca; vmago@lakeheadu.ca
RI Srivastava, Gautam/N-5668-2019
OI Srivastava, Gautam/0000-0001-9851-4103; Mago, Vijay/0000-0002-9741-3463
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX We would like to thank the reviewers for their helpful comments on our
   work. This work is supported by the Natural Sciences and Engineering
   Research Council of Canada (NSERC).
CR Albalawi Y, 2019, J MED INTERNET RES, V21, DOI 10.2196/14731
   Arun R, 2010, LECT NOTES ARTIF INT, V6118, P391
   Bandura A, 2001, MEDIA PSYCHOL, V3, P265, DOI 10.1207/S1532785XMEP0303_03
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Barone MJ, 2000, J ACAD MARKET SCI, V28, P248, DOI 10.1177/0092070300282006
   Barreto JE, 2017, PM&R, V9, pS98, DOI 10.1016/j.pmrj.2017.02.012
   Basov, 2019, AMBIVALENCE CULTURAL
   BASS FM, 1994, MARKET SCI, V13, P203, DOI 10.1287/mksc.13.3.203
   Belford M, 2018, EXPERT SYST APPL, V91, P159, DOI 10.1016/j.eswa.2017.08.047
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blevins JL, 2019, NEW MEDIA SOC, V21, P1636, DOI 10.1177/1461444819827030
   Boutyline A, 2017, POLIT PSYCHOL, V38, P551, DOI 10.1111/pops.12337
   Bucur D, 2019, INFORM SCIENCES, V481, P229, DOI 10.1016/j.ins.2019.01.003
   Cao J, 2009, NEUROCOMPUTING, V72, P1775, DOI 10.1016/j.neucom.2008.06.011
   Cepic D, 2020, SOC NETWORKS, V62, P33, DOI 10.1016/j.socnet.2020.02.003
   Cero I, 2020, AM PSYCHOL, V75, P365, DOI 10.1037/amp0000477
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Chu KH, 2019, ADDICT BEHAV, V91, P222, DOI 10.1016/j.addbeh.2018.11.015
   Chu KH, 2018, J ADOLESCENT HEALTH, V63, P582, DOI 10.1016/j.jadohealth.2018.08.002
   Chung TL, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106623
   Colladon AF, 2019, INT J INFORM MANAGE, V48, P254, DOI 10.1016/j.ijinfomgt.2018.09.009
   Currarini S, 2016, EUR ECON REV, V90, P18, DOI 10.1016/j.euroecorev.2016.03.011
   Cvetojevic S, 2021, COMPUT ENVIRON URBAN, V87, DOI 10.1016/j.compenvurbsys.2021.101621
   Dehghani M, 2016, J EXP PSYCHOL GEN, V145, P366, DOI 10.1037/xge0000139
   Di Tommaso G, 2020, SOC NETWORKS, V62, P58, DOI 10.1016/j.socnet.2020.02.007
   Dincelli Ersin, 2016, Proceedings of the Association for Information Science and Technology, V53, DOI 10.1002/pra2.2016.14505301109
   Ejima H, 2017, NANO TODAY, V12, P136, DOI 10.1016/j.nantod.2016.12.012
   Escobar-Viera CG, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10496
   Eyal K, 2003, J BROADCAST ELECTRON, V47, P77, DOI 10.1207/s15506878jobem4701_5
   Fincham K, 2019, MEDIA COMMUN-LISBON, V7, P213, DOI 10.17645/mac.v7i1.1765
   Franz D, 2019, J MED INTERNET RES, V21, DOI 10.2196/13544
   Getchell MC, 2016, COMPUT HUM BEHAV, V54, P597, DOI 10.1016/j.chb.2015.06.044
   Ghaznavi J, 2015, BODY IMAGE, V14, P54, DOI 10.1016/j.bodyim.2015.03.006
   Gilbert E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P211
   Gonzalez-Bailon S, 2009, SOC NETWORKS, V31, P271, DOI 10.1016/j.socnet.2009.07.003
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Grace MK, 2018, SOC SCI MED, V212, P33, DOI 10.1016/j.socscimed.2018.07.008
   Halberstam Y, 2016, J PUBLIC ECON, V143, P73, DOI 10.1016/j.jpubeco.2016.08.011
   Han SS, 2018, IEEE WCNC
   Hanks L, 2017, INT J HOSP MANAG, V60, P123, DOI 10.1016/j.ijhm.2016.10.007
   Himelboim I, 2016, NEW MEDIA SOC, V18, P1382, DOI 10.1177/1461444814555096
   Horn R. A., 1990, P S APPL MATH, P87, DOI DOI 10.1090/PSAPM/040/1059485
   Huber GA, 2017, J POLIT, V79, P269, DOI 10.1086/687533
   Huberty M, 2015, INT J FORECASTING, V31, P992, DOI 10.1016/j.ijforecast.2014.08.005
   Jang SM, 2015, GLOBAL ENVIRON CHANG, V32, P11, DOI 10.1016/j.gloenvcha.2015.02.010
   Jia RX, 2020, PUBLIC RELAT REV, V46, DOI 10.1016/j.pubrev.2019.101818
   Jin YP, 2017, PROCEDIA ENGINEER, V174, P788, DOI 10.1016/j.proeng.2017.01.223
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karimi F, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29405-7
   Kassens-Noor E, 2019, CITIES, V90, P229, DOI 10.1016/j.cities.2019.02.009
   Kets W, 2019, GAME ECON BEHAV, V115, P410, DOI 10.1016/j.geb.2019.04.002
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Kim K, 2017, COMMUN NONLINEAR SCI, V44, P482, DOI 10.1016/j.cnsns.2016.08.011
   Kipf TN, 2016, ARXIV
   Koiranen I, 2019, TELEMAT INFORM, V36, P117, DOI 10.1016/j.tele.2018.11.009
   Kwon HE, 2017, J MANAGE INFORM SYST, V34, P768, DOI 10.1080/07421222.2017.1373008
   Ladhari R, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2019.102027
   Lai M, 2019, DATA KNOWL ENG, V124, DOI 10.1016/j.datak.2019.101738
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lazarsfeld P., 1954, Freedom and Control in Modern Society, DOI DOI 10.1111/J.1467-8705.2012.02056_3.X
   Li SC, 2018, J IND INF INTEGR, V10, P1, DOI 10.1016/j.jii.2018.01.005
   Liang H, 2018, COMPUT HUM BEHAV, V82, P167, DOI 10.1016/j.chb.2018.01.016
   Linvill DL, 2019, COMPUT HUM BEHAV, V99, P292, DOI 10.1016/j.chb.2019.05.027
   Lusher Dean, 2013, Exponential random graph models for social networks: Theory, methods, and applications
   Ma LY, 2015, MANAGE SCI, V61, P454, DOI 10.1287/mnsc.2014.1928
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mahmood A, 2017, J INTERACT MARK, V37, P117, DOI 10.1016/j.intmar.2016.10.003
   Mayer A, 2008, J PUBLIC ECON, V92, P329, DOI 10.1016/j.jpubeco.2007.09.001
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Mei WJ, 2019, AUTOMATICA, V110, DOI 10.1016/j.automatica.2019.108580
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mimno D., 2012, ARXIV12063278
   Mimno D, 2011, EMNLP, P262, DOI DOI 10.5555/2145432.2145462
   Moody J, 2001, AM J SOCIOL, V107, P679, DOI 10.1086/338954
   Moore S, 2020, RADIOGRAPHY, V26, pE297, DOI 10.1016/j.radi.2020.04.005
   Morris Martina, 2008, J Stat Softw, V24, P1548
   Mou Y, 2017, COMPUT HUM BEHAV, V72, P432, DOI 10.1016/j.chb.2017.02.067
   Murakami Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37793-z
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701
   Nguyen, 2019, ADV NEURAL INFORM PR, P1106
   O'Connor B., 2010, ICWSM, P384
   O'Neill S, 2015, NAT CLIM CHANGE, V5, P380, DOI 10.1038/nclimate2535
   Öztürk N, 2018, TELEMAT INFORM, V35, P136, DOI 10.1016/j.tele.2017.10.006
   Pan JQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2633
   Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505
   Peel L, 2018, P NATL ACAD SCI USA, V115, P4057, DOI 10.1073/pnas.1713019115
   Perra N, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.036107
   Phua J, 2017, TELEMAT INFORM, V34, P412, DOI 10.1016/j.tele.2016.06.004
   Pourebrahim N, 2019, COMPUT ENVIRON URBAN, V77, DOI 10.1016/j.compenvurbsys.2019.101354
   Preotiuc-Pietro D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1754
   Puranam D, 2017, MARKET SCI, V36, P726, DOI 10.1287/mksc.2017.1048
   Qudar Mohiuddin Md Abdul, 2020, ARXIV201011091
   Robins G, 2007, SOC NETWORKS, V29, P173, DOI 10.1016/j.socnet.2006.08.002
   Saffer AJ, 2018, MANAGE COMMUN Q, V32, P121, DOI 10.1177/0893318917700510
   Sandhu Mannila, 2019, Online Social Networks and Media, V14, P13, DOI 10.1016/j.osnem.2019.100054
   SAUNDERS DA, 1991, CONSERV BIOL, V5, P18, DOI 10.1111/j.1523-1739.1991.tb00384.x
   Scepanovic S., 2017, NETWORKS MEDIA, V2, P18
   Shaghaghi Abdolreza, 2011, Health Promot Perspect, V1, P86, DOI 10.5681/hpp.2011.009
   Singla P., 2008, Proceedings of the 17th international conference on World Wide Web, WWW '08, P655, DOI DOI 10.1145/1367497.1367586
   Snijders T. A., 2002, J. Soc. Struct, V3, P1
   Song YY, 2016, COMPUT HUM BEHAV, V60, P525, DOI 10.1016/j.chb.2016.02.086
   Steyvers M., 2015, Handbook of Latent Semantic Analysis, DOI [10.4324/9780203936399.ch21, DOI 10.4324/9780203936399.CH21, DOI 10.1371/JOURNAL.PONE.0073791]
   Stivala A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227804
   Tamburrini N, 2015, SOC NETWORKS, V40, P84, DOI 10.1016/j.socnet.2014.07.004
   Tang J., 2013, P 6 ACM INT C WEB SE, P53, DOI DOI 10.1145/2433396.2433405
   van den Beukel S, 2019, NEUROCOMPUTING, V338, P361, DOI 10.1016/j.neucom.2018.06.091
   VanderWeele, 2017, SOCIOLOGICAL METHODS, V54, P3058
   Warren K, 2020, DRUG ALCOHOL DEPEN, V207, DOI 10.1016/j.drugalcdep.2019.107773
   Wei HL, 2021, PROG MATER SCI, V116, DOI 10.1016/j.pmatsci.2020.100703
   Williams HTP, 2015, GLOBAL ENVIRON CHANG, V32, P126, DOI 10.1016/j.gloenvcha.2015.03.006
   Xiong J, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102229
   Xu SF, 2020, COMPUT HUM BEHAV, V102, P87, DOI 10.1016/j.chb.2019.08.006
   Xu Y, 2019, J R SOC INTERFACE, V16, DOI 10.1098/rsif.2019.0536
   Yang Weiwei, 2015, P 2015 C EMP METH NA, P261
   Yap J, 2015, SOC NETWORKS, V40, P103, DOI 10.1016/j.socnet.2014.08.002
   Yaqub U, 2017, GOV INFORM Q, V34, P613, DOI 10.1016/j.giq.2017.11.001
   Zhang AH, 2018, PHYSICA A, V493, P267, DOI 10.1016/j.physa.2017.09.075
   Zhang DK, 2016, IEEE DATA MINING, P609, DOI [10.1109/ICDM.2016.0072, 10.1109/ICDM.2016.139]
   Zhang JZ, 2018, ADV NEUR IN, V31
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhou ZK, 2018, SOC NETWORKS, V55, P160, DOI 10.1016/j.socnet.2018.07.001
   Zhu J, 2014, J MACH LEARN RES, V15, P1073
   Zhu J, 2012, J MACH LEARN RES, V13, P2237
   Zhu YQ, 2015, BUS HORIZONS, V58, P335, DOI 10.1016/j.bushor.2015.01.006
NR 125
TC 34
Z9 35
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8811
EP 8854
DI 10.1007/s11042-021-11857-1
EA JAN 2022
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000743891900001
DA 2024-07-18
ER

PT J
AU Rangra, A
   Sehgal, VK
AF Rangra, Abhilasha
   Sehgal, Vivek Kumar
TI Natural disasters management using social internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Internet of things; Network centralities; Community
   identifications; Interface of developer kits
ID BIG DATA ANALYTICS; SMART CITIES; TRUST; SECURITY; INFORMATION; IOT
AB Natural disasters are very unexpected in human life. The best prevention from such natural disasters is an early warning system which gives a good period to take some necessary measures during the occurrence of disasters. Social media is the best medium to broadcast ominous massages and this can be done by integrating the internet of things with Social Networks. This paper proposes pre-identification of communities that may expose to natural disasters and identification of the best node where the broadcasting system can be placed. A smart broadcasting device that includes a Programmable IoT board like Raspberry Pi or Jetson Nano can be placed at a node with high centrality. The proposed work is very useful to prevent human causality by issuing early warnings of natural disasters like rain flooding, the collapse of old buildings, old bridges, earthquakes, land sliding.
C1 [Rangra, Abhilasha; Sehgal, Vivek Kumar] Jaypee Univ Informat Technol, Waknaghat, India.
C3 Jaypee University of Information Technology
RP Sehgal, VK (corresponding author), Jaypee Univ Informat Technol, Waknaghat, India.
EM vivekseh@ieee.org
RI Sehgal, Vivek Kumar/S-1937-2017
OI Sehgal, Vivek Kumar/0000-0002-0026-2284
CR Albino V, 2015, J URBAN TECHNOL, V22, P3, DOI 10.1080/10630732.2014.942092
   Ali M, 2015, INFORM SCIENCES, V305, P357, DOI 10.1016/j.ins.2015.01.025
   [Anonymous], 2017, INTERNET THINGS CLOU
   Atzori L, 2014, IEEE COMMUN MAG, V52, P97, DOI 10.1109/MCOM.2014.6710070
   Baham C, 2017, J MANAGE INFORM SYST, V34, P633, DOI 10.1080/07421222.2017.1372996
   Birregah B, 2012, IEEE ENABL TECHNOL, P379, DOI 10.1109/WETICE.2012.47
   Braddock RD, 2003, RELIAB ENG SYST SAFE, V79, P225, DOI 10.1016/S0951-8320(02)00233-8
   Chiregi Matin, 2018, Journal of Electrical Systems and Information Technology, V5, P608, DOI 10.1016/j.jesit.2017.09.001
   Fan WJ, 2015, INT J AUTOM COMPUT, V12, P208, DOI 10.1007/s11633-014-0840-3
   González E, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY (IWAT), P5, DOI 10.1109/IWAT.2016.7434784
   Habib SM, 2011, IEEE INT CONF TRUST, P933, DOI 10.1109/TrustCom.2011.129
   Hanka W, 2010, NAT HAZARD EARTH SYS, V10, P2611, DOI 10.5194/nhess-10-2611-2010
   Haworth B, 2015, GEOGR COMPASS, V9, P237, DOI 10.1111/gec3.12213
   Huang JW, 2013, J CLOUD COMPUT-ADV S, V2, DOI 10.1186/2192-113X-2-9
   Jin D, 2011, OCEAN COAST MANAGE, V54, P189, DOI 10.1016/j.ocecoaman.2010.10.025
   Kapucu N, 2006, AM REV PUBLIC ADM, V36, P207, DOI 10.1177/0275074005280605
   Ko R. K. L., 2011, Proceedings of the 2011 IEEE World Congress on Services (SERVICES 2011), P584, DOI 10.1109/SERVICES.2011.91
   Lansing J, 2016, DATA BASE ADV INF SY, V47, P58, DOI 10.1145/2963175.2963179
   Majid TA, 2014, EXPLORING ISSUES INF
   Mijumbi R, 2016, IEEE COMMUN SURV TUT, V18, P236, DOI 10.1109/COMST.2015.2477041
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Mouradian C, 2018, IEEE INTERNET THINGS, V5, P4119, DOI 10.1109/JIOT.2018.2867255
   O'Callaghan, 2018, EXECUTIVE SUMMARY WO
   Pandey P, 2020, IBM J RES DEV, V64, DOI 10.1147/JRD.2019.2947018
   Poslad S, 2015, IEEE T EMERG TOP COM, V3, P246, DOI 10.1109/TETC.2015.2432742
   Randhawa S., 2017, International Journal of Wireless and Microwave Technologies, V7, P14, DOI DOI 10.5815/IJWMT.2017.04.02
   Shah SA, 2019, IEEE ACCESS, V7, P91885, DOI 10.1109/ACCESS.2019.2928233
   Shah SA, 2019, IEEE ACCESS, V7, P54595, DOI 10.1109/ACCESS.2019.2913340
   Shaikh R, 2015, PROCEDIA COMPUT SCI, V45, P380, DOI 10.1016/j.procs.2015.03.165
   Silva BN, 2018, SUSTAIN CITIES SOC, V38, P697, DOI 10.1016/j.scs.2018.01.053
   Sun DW, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.537
   Takabi H., 2010, IEEE 34th Annual Computer Software and Applications Conference Workshops (COMPSACW 2010), P393, DOI 10.1109/COMPSACW.2010.74
   Tang MD, 2017, FUTURE GENER COMP SY, V74, P302, DOI 10.1016/j.future.2016.01.009
   Tekeli-Yesil S, 2006, J PUBLIC HEALTH-HEID, V14, P317, DOI 10.1007/s10389-006-0043-7
   Wiltshire A., 2006, PROC 3 INT C EARLY W, P27
   Wisner B., 2016, OXFORD RES ENCY NATU, DOI DOI 10.1093/ACREFORE/9780199389407.013.25
   Wisner Ben., 2012, ROUTLEDGE HDB HAZARD, DOI 10.4324/9780203844236
   Xia WF, 2017, IEEE COMMUN SURV TUT, V19, P640, DOI 10.1109/COMST.2016.2626784
NR 38
TC 5
Z9 5
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34447
EP 34461
DI 10.1007/s11042-021-11486-8
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000737741900008
DA 2024-07-18
ER

PT J
AU Singh, S
   Kumar, R
AF Singh, Shiksha
   Kumar, Rajesh
TI Breast cancer detection from histopathology images with deep inception
   and residual blocks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical Image Analysis; Breast Cancer Detection; Histopathology Image;
   Convolutional Neural Network
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION
AB Research Highlights With an increase in the availability of huge pixel whole slide image (WSI) of tissues has given bloom to microscopic pathology application of deep learning and the possibility of loading the scanned images onto the machines, it has become easier for the researchers to develop an automated system for analyzing such images. The paper presents the deep learning-based approach for breast cancer for binary class classification. The proposed model has exploited the inception block of Inception V3 and residual block of Resnet. The proposed model is verified experimentally on both the dataset large (BHI) and small (BreakHis). The contribution of the paper can be summarized as- Remarkable classification accuracy is achieved while working on the recent dataset. The two-step feature map extraction model is trained by combining different magnification levels. The dataset is classified into benign and malignant class. The result is discussed on various performance measures for both the benchmark dataset. The experimental outcomes are compared with the result of the conventional model of Inception and Resnet along with the latest work reported in the literature of deep learning for breast cancer. It is concluded from the experimental result that the proposed model works competently with a large dataset as well as the small dataset. And magnification plays an important role.
   Abstract The rapid growth of the network in deep learning, a subset of artificial intelligence has motivated the researchers to develop the tools for medical imaging analysis. Here we have introduced computer aided diagnosis tools for binary class classification and detection for breast cancer on histopathological images. In this paper, we have proposed a hybrid deep neural network for image level cancer detection in cancerous and non-cancerous category of histopathology images. The hybrid deep neural network comprises of inception and residual block. The network incorporates the advance multilevel feature map for histopathological images and involve the advantages of inception and residual block. The model proposed combines the sturdiness of inception block and residual block and shows the stability in performance against the existing start-of the art algorithms. The proposed method is trained and validated on two publicly available dataset i.e., Breast Histopathology Images (BHI) and BreakHis. The image level classification has been performed at different magnification level in case of BreakHis dataset. The experimental outcome is evaluated on different performance measures and compared with the conventional Inception model and ResNet model as well as state-of-art breast cancer detection techniques. The proposed approach shows the training accuracy of 0.9642 for Breakhis and 0.8017 for BHI dataset. The model proposed outperforms the existing cancer detection algorithms as well as conventional deep neural networks with obtained accuracy of 0.8521 for BHI and 0.8080,0.8276,0.8655and 0.8580 for 40X,100X,200X and 400X respectively for BreakHis dataset.
C1 [Singh, Shiksha; Kumar, Rajesh] Univ Allahabad, JK Inst Appl Phys & Technol, Dept Elect & Commun, Prayagraj, India.
C3 University of Allahabad
RP Singh, S (corresponding author), Univ Allahabad, JK Inst Appl Phys & Technol, Dept Elect & Commun, Prayagraj, India.
EM shikshacse@allduniv.ac.in; rajeshkumariitbhu@gmail.com
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Alom MZ, 2019, J DIGIT IMAGING, V32, P605, DOI 10.1007/s10278-019-00182-7
   [Anonymous], 2017, High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   B. P&D Laboratory-Pathological anatomy and cytopathology Parana, BREAST CANC HISTOPAT
   Bidart, CNN FINE TUNING
   Chapala H., 2020, P 2020 INT C ELECT S, P60, DOI DOI 10.1109/ICESC48915.2020.9155805
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   Dara Suresh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1795, DOI 10.1109/ICECA.2018.8474912
   de Matos J, 2019, IEEE IJCNN
   Fonseca P, 2015, PROC SPIE, V9414, DOI 10.1117/12.2081576
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   Hargrave M, 2019, DEEP LEARNING INVEST
   Haugeland J., 1989, Artificial Intelligence: The Very Idea
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Jaiswal Ankit Kumar, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P289, DOI 10.1007/978-981-13-2685-1_28
   Jaiswal AK, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01107-z
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Kahya M.A., 2017, J. Appl. Math. Bioinf., V7, P49
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mooney Paul, 2017, Breast histopathology images
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Robert W, REDISCOVERING BIOL M
   Sahoo, 2018, DATASCIENCE
   Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345
   Sheikhpour R, 2016, APPL SOFT COMPUT, V40, P113, DOI 10.1016/j.asoc.2015.10.005
   Spanhol FA, 2017, IEEE SYS MAN CYBERN, P1868, DOI 10.1109/SMC.2017.8122889
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Truong TD, 2020, IFMBE PROC, V69, P531, DOI 10.1007/978-981-13-5859-3_92
   Vandenberghe ME, 2017, SCI REP-UK, V7, DOI 10.1038/srep45938
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Westberg S., 2018, arXiv preprint arXiv:1803.01164, DOI DOI 10.48550/ARXIV.1803.01164
   Zainudin Z., 2020, DEEP LAYER CNN ARCHI, DOI 10.1007/978-3-030-14118-9_5
   Zhang Q, 2016, ULTRASONICS, V72, P150, DOI 10.1016/j.ultras.2016.08.004
NR 42
TC 30
Z9 30
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5849
EP 5865
DI 10.1007/s11042-021-11775-2
EA DEC 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000736409100001
DA 2024-07-18
ER

PT J
AU Babu, G
   Khayum, PA
AF Babu, Gorla
   Khayum, Pinjari Abdul
TI Elephant herding with whale optimization enabled ORB features and CNN
   for Iris recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Iris segmentation; ORB point selection; Convolutional
   neural network; Elephant herding with whale optimization algorithm;
   Multi-objective function
ID NETWORK
AB Iris biometrics is one of the frequently used biometrics for security purposes, and it provides the appropriate tools for identifying humans. Deep learners when used along with iris recognition can improve accuracy, automatic learning, and generalization ability. Despite the advantages of deep learners, some problems like time complexity and computational efforts exist in deep learners. In order to solve these obstacles, this paper intends to develop the intelligent iris recognition model based on the concepts merged with multi-objective feature selection and deep learning. The main phases of the proposed model involve (a) Pre-processing, (b) Iris Segmentation, (c) optimal ORB point selection and feature vector generation, and (d) optimal recognition. Here, the pre-processing of the image is performed by filtering and contrast enhancement techniques. Further, the iris segmentation is done by few approaches such as reflection moving, iris localization, and Hough-transform-based segmentation. Once the segmentation of the iris is finished, feature extraction is carried out by optimized Oriented FAST and rotated BRIEF (ORB) features concerning on multi-objective function. Finally, the optimized Convolutional Neural Network (CNN) is used for iris recognition. Here, the hybrid algorithm with the integration of two meta-heuristic algorithms like Elephant Herding Optimization (EHO), and Whale Optimization Algorithm (WOA) called Elephant Herding with Whale Optimization Algorithm (EH-WOA) is utilized for performing the optimized ORB feature selection and optimized CNN. The experiments are conducted on a benchmark datasets like IIT Delhi (IITD) Iris database, and MMU iris dataset to analyze the performance of the proposed model over the different network structures for accurate iris recognition. Through the experimental analysis, the proposed optimized CNN + EH-WOA had better values in terms of accuracy, which is 0.98% higher than SVM, 0.92% higher than KNN, 0.88% higher NN, and 0.85% higher than CNN respectively for the learning % as 75 for MMU iris dataset. Similarly, several performance measures have considered for showing the efficiency of the designed model.
C1 [Babu, Gorla] JNTU, Elect & Commun Engn, Anantapur, Andhra Pradesh, India.
   [Khayum, Pinjari Abdul] G Pullareddy Engn Coll, Elect & Commun Engn, Kurnool, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Babu, G (corresponding author), JNTU, Elect & Commun Engn, Anantapur, Andhra Pradesh, India.
EM babu.gorla@gmail.com
CR Abiyev RH, 2008, INT J SECUR APPL, V2, P41
   Azam M. S., 2020, INT J COMPUTER APPL, V175, P24
   Chen CH, 2009, EXPERT SYST APPL, V36, P10351, DOI 10.1016/j.eswa.2009.01.033
   Chen YF, 2020, IEEE ACCESS, V8, P32365, DOI 10.1109/ACCESS.2020.2973433
   Chen Yuh-Min, 2014, ScientificWorldJournal, V2014, P329397, DOI 10.1155/2014/329397
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082601
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   De Marsico M, 2016, PATTERN RECOGN LETT, V82, P106, DOI 10.1016/j.patrec.2016.02.001
   Gupta G., 2011, Int. J. Soft Comput. Eng. (IJSCE), V1, P304
   Kaur B, 2018, ARAB J SCI ENG, V43, P7209, DOI 10.1007/s13369-017-3057-2
   Kulkarni SB, 2014, INT J IMAGE GRAPH, V14, DOI 10.1142/S0219467814500107
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Lee MB, 2019, IEEE ACCESS, V7, P122134, DOI 10.1109/ACCESS.2019.2937809
   Li YH, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/1281020
   Liu S, 2020, IEEE ACCESS, V8, P53321, DOI 10.1109/ACCESS.2020.2981555
   Liu S, 2019, IEEE ACCESS, V7, P132871, DOI 10.1109/ACCESS.2019.2941225
   [刘元宁 Liu Yuanning], 2019, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V49, P221
   Melin P, 2018, ADV INTELL SYST COMP, V734, P282, DOI 10.1007/978-3-319-76351-4_29
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Oktiana M, 2019, IEEE ACCESS, V7, P130484, DOI 10.1109/ACCESS.2019.2939326
   Pillai JK, 2014, IEEE T PATTERN ANAL, V36, P73, DOI 10.1109/TPAMI.2013.98
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Proença H, 2007, IEEE T PATTERN ANAL, V29, P607, DOI 10.1109/TPAMI.2007.1016
   Roy K, 2006, LECT NOTES COMPUT SC, V3832, P486
   Sahoo RM, 2020, ADV INTELL SYST COMP, V1120, P217, DOI 10.1007/978-981-15-2449-3_18
   Saini TK, 2021, INT J ADV COMPUT SCI, V12
   Shende DK, 2020, WIREL NETW, V26, P4011, DOI 10.1007/s11276-020-02299-y
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Tan TN, 2010, IMAGE VISION COMPUT, V28, P223, DOI 10.1016/j.imavis.2009.05.008
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wang K, 2019, PATTERN RECOGN, V86, P85, DOI 10.1016/j.patcog.2018.08.010
   Wang R, 2019, IEEE ACCESS, V7, P71235, DOI 10.1109/ACCESS.2019.2918813
   Wildes RP, 1996, MACH VISION APPL, V9, P1, DOI 10.1007/BF01246633
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 38
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5761
EP 5794
DI 10.1007/s11042-021-11746-7
EA DEC 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735722700001
DA 2024-07-18
ER

PT J
AU Ruchika
   Purwar, RK
   Verma, S
   Jain, A
AF Ruchika
   Purwar, Ravindra Kumar
   Verma, Shailesh
   Jain, Anchal
TI Crowd abnormality detection in video sequences using supervised
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormality detection; CNN; ROC; AUC; Supervised learning
ID ANOMALY DETECTION; EVENT DETECTION; FRAMEWORK
AB In this paper, a Convolutional Neural Network (CNN) based crowd abnormality detection model in video sequences is proposed. The model has two convolution layers, two Fully Connected (FC) layers in which 1st FC layer uses Rectified Linear Unit (ReLU) and the 2nd uses sigmoid function as activation functions. Both convolution layers consist of a convolution operator followed by ReLU and the max-pooling layer. Intermediate convolutional layers produce features that are used to detect the abnormality in the video frame. The performance of the proposed model has been evaluated based on three parameters - Receiver Operator Characteristic (ROC) curve, Area Under the Curve (AUC), and Equal Error Rate (EER). Three scientific datasets have been used, consisting of several video sequences with various normal and abnormal activities. Experimental results show that the proposed CNN model performs better for all datasets compared with other similar methods in literature and achieves a maximum of near 100% sensitivity through the ROC curve for one dataset. Further, the average AUC value for the UCSD dataset (Ped1 and Ped2) is close to 98% and 95% for the Avenue dataset. The average EER for the UCSD dataset (Ped1 and Ped2) is near 10% and 11.5% for the Avenue dataset. Moreover, the model has also been evaluated for a couple of random YouTube videos of abnormal behavior, and it gives satisfactory results.
C1 [Ruchika; Purwar, Ravindra Kumar; Verma, Shailesh] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Delhi 110078, India.
   [Jain, Anchal] Simon Fraser Univ, Burnaby, BC, Canada.
C3 GGS Indraprastha University; Simon Fraser University
RP Ruchika (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Delhi 110078, India.
EM ruchika.usict.077164@ipu.ac.in; ravindra@ipu.ac.in; skv210968@gmail.com;
   anchalresearch10@gmail.com
RI Lalit, Ruchika/GZK-1845-2022
OI LALIT, RUCHIKA/0000-0002-9171-5014
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Boiman O, 2005, IEEE I CONF COMP VIS, P462
   Cheng JM, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P285
   Chollet Francois, 2018, DEEP LEARNING PYTHON, V361
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hu X, 2019, IEEE T INF FOREN SEC, V14, P1007, DOI 10.1109/TIFS.2018.2868617
   Huang S, 2018, MATH PROBL ENG, DOI [10.1155/2018/6323942, DOI 10.1155/2018/6323942]
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jäger M, 2008, IEEE T IMAGE PROCESS, V17, P1700, DOI 10.1109/TIP.2008.2001043
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, V25, P1097
   Kumar M, 2017, INT J COMPUT INT SYS, V10, P234, DOI 10.2991/ijcis.2017.10.1.16
   Lalit R, 2019, International Journal of Innovative Technology and Exploring Engineering, V8, P629, DOI [10.35940/ijitee.I1100.0789S19, DOI 10.35940/IJITEE.I1100.0789S19]
   Li He-Ping, 2007, Journal of Software, V18, P527, DOI 10.1360/jos180527
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabzalian Behnam, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P173, DOI 10.1109/PRIA.2019.8786007
   Sikdar A, 2020, NEUROCOMPUTING, V415, P317, DOI 10.1016/j.neucom.2020.07.058
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Sun JY, 2019, MULTIMED TOOLS APPL, V78, P3633, DOI 10.1007/s11042-017-5244-2
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Wang YX, 2016, NEUROCOMPUTING, V201, P12, DOI 10.1016/j.neucom.2016.03.038
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Zhang XX, 2009, LECT NOTES ARTIF INT, V5476, P278, DOI 10.1007/978-3-642-01307-2_27
   Zhang XG, 2020, NEUROCOMPUTING, V414, P291, DOI 10.1016/j.neucom.2020.07.019
   Zou XT, 2008, IEEE IMAGE PROC, P781, DOI 10.1109/ICIP.2008.4711871
NR 46
TC 8
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5259
EP 5277
DI 10.1007/s11042-021-11781-4
EA DEC 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000730052100001
DA 2024-07-18
ER

PT J
AU Chandran, SN
   Gangodkar, D
AF Chandran, Nisha S.
   Gangodkar, Durgaprasad
TI A novel image retrieval technique based on semi supervised clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Clustering; Micro clusters; Kullback -Leibler distance; Gaussian
   mixture modeling; Decision trees
ID RELEVANCE FEEDBACK; SYSTEM
AB Traditionally Content-Based Image Retrieval (CBIR) problems investigate the occurrence of images matching to a user-submitted query image or a sketch drawn by the user within a large image collection. However, there is often limited support for retrieving semantically similar images from large databases, matching the user's perception. In this paper, we try to address this semantic gap problem in CBIR by performing a clustering-based retrieval. In the proposed approach we first perform a continuous probabilistic semi-supervised clustering to group similar images to form macro clusters. Macro clusters so formed, ensures class-wise similarity instead of semantic similarity. To retrieve the semantically matching images from these macro clusters formed, the CBIR method is adopted using a cluster within-cluster approach. The key idea is that the macro clusters formed during the initial phase of classification are further classified into micro clusters based on the decision tree approach. For retrieval, as the first step, the macro cluster matching to the user's query is found. In the next step, to ensure semantic similarity the image is classified to the matching micro cluster. The proposed method is experimentally evaluated first on Wang database which contains complex and diverse images with varying fine details. Further, the experiments are repeated on the Ponce group database and Corel 5K database. The experimental results obtained demonstrate the effectiveness of the proposed approach.
C1 [Chandran, Nisha S.] Graph Era Hill Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
   [Gangodkar, Durgaprasad] Graph Era Univ, Dept CSE, Dehra Dun, Uttarakhand, India.
C3 Graphic Era University
RP Chandran, SN (corresponding author), Graph Era Hill Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
EM nisha.unnikrishnan@gmail.com; dgangodkar@yahoo.com
OI Chandran, Nisha/0000-0002-0558-5496
CR Afifi AJ, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Ajorloo H, 2011, INT J INF TECH DECIS, V10, P933, DOI 10.1142/S0219622011004634
   Aslandogan YA, 1999, IEEE T KNOWL DATA EN, V11, P56, DOI 10.1109/69.755615
   Bing Liu, 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P20
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chandran SN, 2017, MULTIMED TOOLS APPL, V76, P21937, DOI 10.1007/s11042-017-4664-3
   Chen Yixin, 2003, P 5 ACM SIGMM INT WO, P193
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Goldberger J., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P158
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Jing F, 2003, LECT NOTES COMPUT SC, V2728, P206
   Karakos D, 2005, INT CONF ACOUST SPEE, P1081
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Park SS, 2007, INT J INF TECH DECIS, V6, P213, DOI 10.1142/S0219622007002496
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Ramchandran K, 1996, P 33 ANN CLIN LIBR A, P100
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Ru, 2020, IMAGE RETRIEVAL VIA
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, V14, P988, DOI 10.1109/TKDE.2002.1033769
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Town C., 2000, CONTENT BASED IMAGE
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P256, DOI 10.1016/j.jvcir.2016.03.008
   Xiao-Ying T, 2009, INT J INF TECH DECIS, V8, P239, DOI 10.1142/S0219622009003363
   Younus ZS, 2015, ARAB J GEOSCI, V8, P6211, DOI 10.1007/s12517-014-1584-7
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhu SH, 2014, J INTELL INF SYST, V42, P95, DOI 10.1007/s10844-013-0257-4
NR 42
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35741
EP 35769
DI 10.1007/s11042-021-11542-3
EA NOV 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000722157500003
DA 2024-07-18
ER

PT J
AU Silva, CM
   Rosa, KAI
   Bugatti, PH
   Saito, PTM
   Corrêa, CG
   Yokoyama, RS
   Sanches, SRR
AF Silva, Claudinei M.
   Rosa, Katharina A., I
   Bugatti, Pedro H.
   Saito, Priscila T. M.
   Correa, Cleber G.
   Yokoyama, Roberto S.
   Sanches, Silvio R. R.
TI Method for selecting representative videos for change detection datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Change detection; Dataset; Algorithm evaluation
ID GAUSSIAN MIXTURE MODEL; OBJECT DETECTION; SEGMENTATION; ALGORITHMS
AB In evaluating the change detection algorithms, the algorithm evaluated must show a superior performance than the state-of-the-art algorithms. The evaluation process steps comprise executing a new algorithm to segment a set of videos from a dataset and compare the results regarding a ground truth. In this paper, we propose using additional information in evaluating change detection algorithms: the level of difficulty in classifying a pixel. First, for each video frame used in the evaluation, we created a difficulty map structure, which stores values representing the level of difficulty required by an algorithm to classify each pixel of that frame. Second, we developed a metric to estimate each dataset video's difficulty based on our difficulty maps. Third, we applied the metric to selecting the more representative videos from the dataset based on their difficulty level. Finally, to demonstrate the method's contribution, we evaluated it using all videos from the CDNet 2014 dataset. The results showed that a subset of videos selected by our method has the same potential as the original CDNet 2014 dataset. Hence, a new change detection algorithm can be evaluated more quickly using our subset of videos selected.
C1 [Silva, Claudinei M.; Rosa, Katharina A., I; Bugatti, Pedro H.; Saito, Priscila T. M.; Correa, Cleber G.; Sanches, Silvio R. R.] Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
   [Yokoyama, Roberto S.] Univ Fed ABC, Santo Andre, SP, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade Federal do ABC
   (UFABC)
RP Sanches, SRR (corresponding author), Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
EM claudinei.2018@alunos.utfpr.edu.br; katharina@alunos.utfpr.edu.br;
   pbugatti@utfpr.edu.br; psaito@utfpr.edu.br; clebergimenez@utfpr.edu.br;
   r.sadao@ufabc.edu.br; silviosanches@utfpr.edu.br
RI Saito, Priscila/E-8159-2013; Bugatti, Pedro/T-5178-2017; Sanches, Silvio
   RR/J-6357-2013
OI Saito, Priscila/0000-0002-4870-4766; Bugatti, Pedro/0000-0001-9421-9254;
   Sanches, Silvio/0000-0003-3635-7477
CR Allebosch G, 2016, COMM COM INF SC, V598, P433, DOI 10.1007/978-3-319-29971-6_23
   Allebosch G, 2015, LECT NOTES COMPUT SC, V9386, P130, DOI 10.1007/978-3-319-25903-1_12
   [Anonymous], 2012, UCF101 DATASET 101 H
   [Anonymous], 2019, Opencv
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bianco S, 2017, LECT NOTES COMPUT SC, V10484, P96, DOI 10.1007/978-3-319-68560-1_9
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Braham M, 2017, IEEE IMAGE PROC, P4552, DOI 10.1109/ICIP.2017.8297144
   Chan YT, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013038
   Chen YY, 2015, IEEE INT CON MULTI
   De Gregorio M., 2017, P ESANN, P453
   De Gregorio M, 2014, IEEE COMPUT SOC CONF, P409, DOI 10.1109/CVPRW.2014.66
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Fisher R, 2019, CAVIAR TEST CASE SCE
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002
   Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659
   Kalsotra R, 2019, IEEE ACCESS, V7, P59143, DOI 10.1109/ACCESS.2019.2914961
   Krungkaew R., 2016, 2016 13 INT C ELECT, P1
   Lee SH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050621
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Lu XQ, 2014, IEEE IMAGE PROC, P3268, DOI 10.1109/ICIP.2014.7025661
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Martins I, 2017, LECT NOTES COMPUT SC, V10255, P50, DOI 10.1007/978-3-319-58838-4_6
   Microsoft Corporation, 2019, TEST IM WALLFL PAP
   Miron A, 2015, INT CONF SYST SIGNAL, P273, DOI 10.1109/IWSSIP.2015.7314229
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Russel J, 2013, INTERQUARTILE RANGE
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Sanches SRR, 2021, MULTIMED TOOLS APPL, V80, P4421, DOI 10.1007/s11042-020-09838-x
   Sedky M, 2014, IEEE COMPUT SOC CONF, P405, DOI 10.1109/CVPRW.2014.65
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Universite de Sherbrooke, 2019, CHANG DET NET A VID
   University of Naples Parthenope, 2019, SCEN BACKGR MOD NET
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Varadarajan S, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P63, DOI 10.1109/AVSS.2013.6636617
   Varghese A., 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI DOI 10.1186/S41074-017-0036-1
   Wang B, 2014, IEEE COMPUT SOC CONF, P401, DOI 10.1109/CVPRW.2014.64
   Wang KF, 2018, IEEE ACCESS, V6, P15505, DOI 10.1109/ACCESS.2018.2812880
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Yilmaz AA, 2020, IEEE ACCESS, V8, P100631, DOI 10.1109/ACCESS.2020.2997962
   Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317
   Zheng W., 2019, Neurocomputing
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 54
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3773
EP 3791
DI 10.1007/s11042-021-11640-2
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000721653400001
DA 2024-07-18
ER

PT J
AU Rezaie, V
   Parnianifard, A
AF Rezaie, Vahid
   Parnianifard, Amir
TI A new intelligent system for diagnosing tumors with MR images using
   type-2 fuzzy neural network (T2FNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MRI; Artificial intelligence; Type-2 fuzzy neural network (T2FNN);
   Self-organizing Map (SOM)
ID BRAIN-TUMORS; SEGMENTATION; ALGORITHM
AB Early diagnosis of tumors can reduce mortality rates. Hence, tumor position, tumor area, and tumor categories evaluation are also mandatory concerns for the proper medication. This paper presents a new intelligent system for diagnosing the human brain tumors using 60 magnetic resonance images (MRI) with contrast. The proposed methods have five distinct modules including pre-processing, performance elements, critic, learning element, and classification. In the pre-processing, the quality of MR images are enhanced and the noises are removed from it. In the performance elements, the images are segmented with K-mean algorithm and the feathers are extracted from the images with the help of gray level co-occurrence matrix. Next, the data is manipulated in critical part with roles and it is transfered to the learning element part. Then, the Self Organizing Map (SOM) is used to identify the exact location of tumors. Finally, the four types of tumors, astrocytoma, meningiomas, metastatic and glioblastoma will be classified by the K-mean type-2 fuzzy neural. The obtained results indidate that the proposed method has greater values of Sensitivity, Precision, F-measure, Accuracy, and Receiver Operating Characteristic (ROC) compare to other relevant methods.
C1 [Rezaie, Vahid] Yazd Univ, Dept Ind Engn, Yazd, Iran.
   [Parnianifard, Amir] Chulalongkorn Univ, Fac Engn, Dept Elect Engn, Bangkok, Thailand.
C3 University of Yazd; Chulalongkorn University
RP Rezaie, V (corresponding author), Yazd Univ, Dept Ind Engn, Yazd, Iran.
EM vahid.rezaie71@gmail.com
RI Parnianifard, Amir/F-7887-2017
OI Parnianifard, Amir/0000-0002-0760-2149
CR Adhikari SK, 2015, APPL SOFT COMPUT, V34, P758, DOI 10.1016/j.asoc.2015.05.038
   Ahmmed R., 2017, 2017 3rd International Conference on Electrical Information and Communication Technology (EICT), P1, DOI [10.1109/EICT.2017.8275232, DOI 10.1109/EICT.2017.8275232]
   Al-Badarneh A., 2015, P INT C ENG MIS 2015, P1, DOI [10.1145/2832987.2833063, DOI 10.1145/2832987.2833063]
   [Anonymous], 2018, TOXICITY UNCERTAINTY, V1711
   Behzadfar N., 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P329, DOI 10.1109/BHI.2012.6211580
   Benson CC, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1135, DOI 10.1109/ICACCI.2017.8125994
   Chatterjee S, 2020, SOFT COMPUT, V24, P11731, DOI 10.1007/s00500-019-04635-7
   Chauhan S, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P223, DOI 10.1109/RISE.2017.8378158
   de Oliveira JMP, 2011, DIAGNOSTIC TECHNIQUE
   DEAN BL, 1990, RADIOLOGY, V174, P411, DOI 10.1148/radiology.174.2.2153310
   Demirkaya O., 2008, Image Processing with MATLAB: Applications in Medicine and Biology
   Dogan B., 2016, ULUDAG U J FACULTY E, V21, P257, DOI [10.17482/uumfd.270102, DOI 10.17482/UUMFD.270102]
   Drevelegas A, 2011, IMAGING OF BRAIN TUMORS WITH HISTOLOGICAL CORRELATIONS, SECOND EDITION, P1, DOI 10.1007/978-3-540-87650-2
   Fridrich, 2014, DIGITAL IMAGE ACQUIS, P33
   Ghaemi S, 2019, SOFT COMPUT, V23, P1407, DOI 10.1007/s00500-018-3053-9
   Gurbina M, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P505, DOI [10.1109/TSP.2019.8769040, 10.1109/tsp.2019.8769040]
   Halder A, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105758
   Han HG, 2019, NEUROCOMPUTING, V365, P249, DOI 10.1016/j.neucom.2019.07.004
   Henson JW, 2005, LANCET ONCOL, V6, P167, DOI 10.1016/S1470-2045(05)01767-5
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Jellinger, 1986, THERAPY MALIGNANT BR, DOI [10.1007/978-3-7091-8876-7, DOI 10.1007/978-3-7091-8876-7]
   Jothi G, 2016, APPL SOFT COMPUT, V46, P639, DOI 10.1016/j.asoc.2016.03.014
   Kahali S, 2017, APPL SOFT COMPUT, V60, P312, DOI 10.1016/j.asoc.2017.07.001
   Kar S, 2017, INT J CLIN ONCOL, V22, P667, DOI 10.1007/s10147-017-1110-5
   Karthik R, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105685
   Kebria PM, 2019, IEEE INT CON AUTO SC, P1625, DOI [10.1109/coase.2019.8843018, 10.1109/COASE.2019.8843018]
   Keerthana TK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1265, DOI 10.1109/ICICCT.2018.8473297
   Laws, 2012, BRAIN TUMORS, P1
   LE TL, 2019, PROC 2018 IEEE INT C, P4150, DOI DOI 10.1109/SMC.2018.00703
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Lin, 2018, DEEP CLUSTERING ALGO
   Mahmud M. S., 2018, P 2018 IEEE INT C EN, P1, DOI DOI 10.1109/IC4ME2.2018.8465607
   metode penelitian Nursalam, 2016, J CHEM INF MODEL, V53, P1689, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Norvig, 2013, ARTIFICIAL INTELLIGE
   Nurhopipah Ade, 2018, 2018 3rd International Conference on Information Technology, Information System and Electrical Engineering (ICITISEE), P235, DOI 10.1109/ICITISEE.2018.8720977
   Praylin Selva Blessy S. A., 2014, Applied Mechanics and Materials, V626, P38, DOI 10.4028/www.scientific.net/AMM.626.38
   Qin BJ, 2008, PROC SPIE, V6833, DOI 10.1117/12.755417
   Saeed S. O. M., 2019, 201921ST INT C TRANS, P1
   Santos RS, 2013, COMPUT METH PROG BIO, V109, P269, DOI 10.1016/j.cmpb.2012.10.010
   Selvaganesan K., 2019, FUZZY SETS SYST, DOI [10.1007/s10278-012-9568-1, DOI 10.1007/S10278-012-9568-1]
   Siddiqui MF, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9030037
   Singh C, 2019, APPL SOFT COMPUT, V76, P156, DOI 10.1016/j.asoc.2018.12.005
   Siri FH, 2020, J GASTROINTEST CANC, V51, P418, DOI 10.1007/s12029-019-00279-w
   Sood D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12420-1
   Sun D, 2019, AUTOMATICA, V106, P358, DOI 10.1016/j.automatica.2019.04.033
   Taghavifar H, 2019, MECH SYST SIGNAL PR, V130, P41, DOI 10.1016/j.ymssp.2019.04.060
   Pham TX, 2018, APPL SOFT COMPUT, V65, P230, DOI 10.1016/j.asoc.2018.01.003
   Le TL, 2019, INT J FUZZY SYST, V21, P2258, DOI 10.1007/s40815-019-00730-x
   van der Burgh HK, 2017, NEUROIMAGE-CLIN, V13, P361, DOI 10.1016/j.nicl.2016.10.008
   Varlamis I, 2017, COMPUT METH PROG BIO, V145, P73, DOI 10.1016/j.cmpb.2017.04.011
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Wu Y, 2013, J DIGIT IMAGING, V26, P786, DOI 10.1007/s10278-012-9568-1
   Zarandi MHF, 2011, APPL SOFT COMPUT, V11, P285, DOI 10.1016/j.asoc.2009.11.019
   Zarinbal M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0311-6
   Zhu XH, 2019, ENG APPL ARTIF INTEL, V85, P740, DOI 10.1016/j.engappai.2019.07.019
NR 55
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2333
EP 2363
DI 10.1007/s11042-021-11221-3
EA OCT 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000711317800002
DA 2024-07-18
ER

PT J
AU Zhang, J
   Wen, XY
   Whang, M
AF Zhang, Jing
   Wen, Xingyu
   Whang, Mincheol
TI Empathy evaluation by the physical elements of the advertising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Empathy; Advertising elements; Gaze tracking
ID IMPACT; MUSIC; INVOLVEMENT; EYES
AB Watching videos is becoming a common trend in modern times. Advertising designers have concerned that physical attributes in the video affect the viewer's empathy and determine their purchase decisions. Therefore, the purpose of this study is to provide an advertisement guideline, that increasing viewer's empathy by controlling the physical elements and together considering the objective biological data of the viewer's gaze tracking. This article uses two methods for comparison accuracy. The first method is about using eye-tracking data to derive areas of interest in the video and to evaluate empathy with the image properties in the advertisement. The physical elements of the advertising pictures, such as characteristics of color, saturation, and value have been analyzed by comparing between advertising videos with and without consideration of gaze tracking for the region of interest of the video. Then the empathy in advertising has been determined by using the method of machine learning classification. The results showed that the accuracy rate was 1.8% higher than the other kinds of videos in feature value of considering the region of interest extraction by gaze tracking. Contribution: (1). The physical elements in the advertisement contribute to increase the viewer's empathy; (2). The paper also finds that the video making by the method of extracting physical elements of some region of interest has a stronger influence on the viewer's empathy; (3). The decision of physical elements in advertisements can increase the empathy of viewers during viewing processes, which can also improve the effectiveness of advertisements.
C1 [Zhang, Jing; Wen, Xingyu] Univ Sangmyung, Dept Emot Engn, Seoul 03016, South Korea.
   [Whang, Mincheol] Univ Sangmyung, Dept Human Ctr Artificial Intelligence, Seoul 03016, South Korea.
RP Whang, M (corresponding author), Univ Sangmyung, Dept Human Ctr Artificial Intelligence, Seoul 03016, South Korea.
EM whang@smu.ac.kr
RI ZHANG, JING/HQY-9841-2023
OI ZHANG, JING/0000-0002-5230-6285
FU National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF-2020R1A2B5B02002770]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT)
   (NRF-2020R1A2B5B02002770).
CR ALPERT AJ, 1990, J CHROMATOGR, V499, P177, DOI 10.1016/S0021-9673(00)96972-3
   Argyle M., 1976, Gaze and Mutual Gaze
   Baltes R.F., 2014, Psychomusicol. Music Mind Brain, V24, P58, DOI [DOI 10.1037/PMU0000030, 10.1037/pmu0000030]
   Barbee, DEP SPEECH COMMUNICA
   BARONCOHEN S, 1995, BRIT J DEV PSYCHOL, V13, P379, DOI 10.1111/j.2044-835X.1995.tb00687.x
   Bartsch A, 2019, INT J ADVERT, V38, P345, DOI 10.1080/02650487.2018.1482098
   Carter CS, 2009, SOCIAL NEUROSCIENCE OF EMPATHY, P169
   Dafonte-Gómez A, 2014, COMUNICAR, V22, P199, DOI 10.3916/C43-2014-20
   Davis MH., 2018, ROUTLEDGE, DOI 10.4324/9780429493898
   Decety J, 2006, THESCIENTIFICWORLDJO, V6, P1146, DOI 10.1100/tsw.2006.221
   Deighton John., 1993, ADVERTISING EXPOSURE, P261
   Eeroia T, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01176
   Elliott R, 2011, PSYCHOTHERAPY, V48, P43, DOI 10.1037/a0022187
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Escalas JE, 2003, J CONSUM RES, V29, P566, DOI 10.1086/346251
   FARNSWORTH EA, 1969, COLUMBIA LAW REV, V69, P576, DOI 10.2307/1121118
   Hoffman M.L., 2008, HDB EMOTIONS, P440
   Hood BM, 1998, PSYCHOL SCI, V9, P131, DOI 10.1111/1467-9280.00024
   Hua Wang, 2006, Proceedings. ETRA 2006. Symposium on Eye Tracking Research and Applications, P73, DOI 10.1145/1117309.1117346
   Huang L, 2016, J FOOD PROD MARK, V22, P191, DOI 10.1080/10454446.2014.1000434
   Hyeonjin Soh, 2019, [The journal of Convergence on Culture Technology, 문화기술의 융합], V5, P99, DOI 10.17703/JCCT.2019.5.1.99
   Keen Suzanne, 2007, Empathy and the Novel
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78
   Lee，Do-Hee, 2014, [Asia Marketing Journal, 아시아마케팅저널], V15, P103
   MACINNIS DJ, 1991, J CONSUM RES, V18, P161, DOI 10.1086/209249
   Miu AC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030618
   Morris JD, 1998, ADV CONSUM RES, V25, P518
   PARK CW, 1986, J MARKETING RES, V23, P11, DOI 10.2307/3151772
   Patterson M., 2002, Consumption Markets Culture, V5, P231
   Pelphrey KA, 2002, J AUTISM DEV DISORD, V32, P249, DOI 10.1023/A:1016374617369
   Polyorat K, 2007, PSYCHOL MARKET, V24, P539, DOI 10.1002/mar.20172
   Ritossa D.A., 2004, PSYCHOL MUSIC, V31, P5, DOI DOI 10.1177/0305735604039281
   Roncha A, 2016, J FASH MARK MANAG, V20, P300, DOI 10.1108/JFMM-10-2015-0082
   STERN BB, 1994, J CONSUM RES, V20, P601, DOI 10.1086/209373
   STOUT PA, 1993, J ADVERTISING, V22, P61, DOI 10.1080/00913367.1993.10673397
   Strayer J., 1990, EMPATHY ITS DEV, P218
   Tavassoli NT, 2003, J MARKETING RES, V40, P468, DOI 10.1509/jmkr.40.4.468.19391
   Yoo S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113136
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030649
   ZIMNY GH, 1963, AM J PSYCHOL, V76, P311, DOI 10.2307/1419170
NR 40
TC 3
Z9 3
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2241
EP 2257
DI 10.1007/s11042-021-11637-x
EA OCT 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710608700001
DA 2024-07-18
ER

PT J
AU Nayef, BH
   Abdullah, SNHS
   Sulaiman, R
   Alyasseri, ZAA
AF Nayef, Bahera H.
   Abdullah, Siti Norul Huda Sheikh
   Sulaiman, Rossilawati
   Alyasseri, Zaid Abdi Alkareem
TI Optimized leaky ReLU for handwritten Arabic character recognition using
   convolution neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic handwritten characters; Convolution neural network; Rectified
   linear unit; Optimized leaky ReLU
ID ARCHITECTURES
AB Object classification, such as handwritten Arabic character recognition, is a computer vision application. Deep learning techniques such as convolutional neural networks (CNNs) are employed in character recognition to overcome the processing complexity with traditional methods. Usually, a CNN is followed by an activation function such as a rectified linear unit (ReLU) or leaky ReLU to filter the extracted features. Most handwritten character recognition endures an imbalanced number of positive and negative vectors. This issue decreases CNN performance when adopting ReLU and leaky ReLU for the next deep layers in the architecture. Hence, this study proposed an optimized leaky ReLU to retain more negative vectors using a CNN architecture with a batch normalization layer to address this weakness. To evaluate the proposed method, four datasets are used: Arabic Handwritten Characters Dataset (AHCD), self-collected, Modified National Institute of Standards and Technology (MNIST), and AlexU Isolated Alphabet (AIA9K). The proposed method shows significant performance in terms of accuracy, precision, and recall measures compared to the state-of-art methods. The results showed outstanding improvement over the known leaky ReLU as follows: 99% for AHCD, 95.4% for self-collected data, 90% for HIJJA dataset and 99% for Digit MNIST. The proposed CNN architecture with the proposed optimized leaky ReLU showed a stable accuracy performance and error rates between the training, validation, and testing phases. This indicates that most samples are trained and classified correctly.
C1 [Nayef, Bahera H.; Abdullah, Siti Norul Huda Sheikh; Sulaiman, Rossilawati; Alyasseri, Zaid Abdi Alkareem] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Nayef, BH (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
EM p99947@siswa.ukm.edu.my; snhsabdullah@ukm.edu.my;
   rossilawati@ukm.edu.my; zaid.alyasseri@uokufa.edu.iq
RI Nayef, Bahera Hani/IVU-8995-2023; Alyasseri, Zaid Abdi
   Alkareem/H-5280-2013; Sheikh Abdullah, Siti Norul Huda/J-7949-2015
OI Alyasseri, Zaid Abdi Alkareem/0000-0003-4228-9298; Sheikh Abdullah, Siti
   Norul Huda/0000-0002-2602-7805
FU Ministry of Higher Education, Malaysia [FRGS/1/2019/ICT02/UKM/02/9]
FX We would like to convey our gratitude to research team members at the
   Digital Forensic Lab and Medical and Health Informatics Lab at the
   Faculty of Information Science and Technology, Universiti Kebangsaan
   Malaysia, who contributed to this project. Apart from that, we thank the
   Ministry of Higher Education, Malaysia, which supporteYYd this project
   under the Fundamental Research Grant Scheme (FRGS)
   FRGS/1/2019/ICT02/UKM/02/9 entitled "Convolution neural network
   enhancement based on adaptive convexity and regularization functions for
   fake video analytics."
CR Agarap A. F., 2018, ARXIV
   Ali AAA, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P187, DOI 10.1109/ICIIP47207.2019.8985839
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Arora R., 2016, ARXIV161101491, DOI 10.48550/arXiv.1611.01491
   Azmi M., 2013, NOVEL FEATURE COMBIN
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Chen Z, 2017, DEEP LEARNING APPROA, P92
   Clevert D., 2016, ARXIV151107289
   Dahou A, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2537689
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   GAO Z, 2019, 2019 IEEE INT C IM P
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Hasan A. H., 2018, International Journal on Advanced Science, Engineering and Information Technology, V8, P1528
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ibrahim MN., 2013, 2013 5 INT C COMP IN
   Jain V., 2019, COMP STUDY CONVOLUTI
   Jebril Noor A., 2018, Pattern Recognition and Image Analysis, V28, P321, DOI 10.1134/S1054661818020141
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Lee Joonho, 2019, ARXIV190510761
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Memon J, 2020, IEEE ACCESS, V8, P142642, DOI 10.1109/ACCESS.2020.3012542
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Najadat HM, 2019, INT CONF INFORM COMM, P147, DOI 10.1109/iacs.2019.8809122
   Nwankpa C., 2018, ARXIV181103378
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Ramdan J, 2013, PROC TECH, V11, P580, DOI 10.1016/j.protcy.2013.12.231
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1
   SAHU DK, 2015, 2015 13 INT C DOC AN
   Saleh Al -Sheikh I., 2020, Asia-Pacific J. Inf. Technol. Multimedia, V09, p69?81, DOI 10.17576/apjitm-2020-0901-06
   Sarkhel R, 2016, PATTERN RECOGN, V58, P172, DOI 10.1016/j.patcog.2016.04.010
   Shrikumar Avanti, 2016, ARXIV160501713
   Sulaiman A, 2021, MULTIMED TOOLS APPL, V80, P5473, DOI 10.1007/s11042-020-09923-1
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Torki M., 2014, ARXIV14113519
   Visin F., 2015, arXiv
   Wang Bao., 2018, Advances in Neural Information Processing Systems (NeurIPS)
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Younis KS., 2017, JORDAN J COMPUT INFO, V3, P7, DOI DOI 10.5455/JJCIT.71-1498142206
NR 45
TC 22
Z9 24
U1 7
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2065
EP 2094
DI 10.1007/s11042-021-11593-6
EA OCT 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000708822400001
DA 2024-07-18
ER

PT J
AU Badhe, SS
   Shirbahadurkar, SD
   Gulhane, SR
AF Badhe, Sanjay Srikrushna
   Shirbahadurkar, Suresh Damodar
   Gulhane, Sushen Rameshpant
TI Renyi entropy and deep learning-based approach for accent classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep belief network; Dragonfly optimization algorithm; Bird swarm
   optimization; Tanimoto; Renyi entropy
ID BELIEF NETWORKS; SPEECH
AB Accent classification has been gained more attention, due to improving demands for better speaker recognition with the accented speech. An accent is defined by the pronunciation of the language, particularly with the locality, social class, or particular nation. Thus, this paper proposes a model for accent classification using feature extraction and classifier. At first, the input signals are pre-processed. Here, the spectral skewness, spectral centroid, tonal power ratio, spectral kurtosis, spectral flux, and Renyi entropy-based Multi kernel Mel Frequency Cepstral Coefficient features (ReMKMFCC) features is adapted for the feature extraction, and the ReMKMFCC feature is derived by the combination of Renyi entropy, Multiple Kernel Weighted Mel Frequency Cepstral Coefficient (MKMFCC). After the extraction of the features, the features are fed as input to the feature selection module. The feature selection is carried out using Tanimoto, and then the selected features are forwarded to the classification module, where the features are classified using DBN, and the classifier is trained by the proposed Dragonfly-Bird swarm optimization (DBSO), which is the combination of Dragonfly Algorithm (DA) and Bird swarm optimization algorithm (BSO). Thus, the DBSO-based DBN aims at classifying the accent. The analysis proves that the proposed method acquired a maximal accuracy of 96.96% by considering dataset-1, maximum F-Measure of 96.97% by considering dataset-2, and minimal FAR of 3.04%, by considering the dataset -1.
C1 [Badhe, Sanjay Srikrushna; Gulhane, Sushen Rameshpant] Pune Savitribai Phule Pune Univ, DY Patil Inst Technol, Pune, Maharashtra, India.
   [Shirbahadurkar, Suresh Damodar] Pune Savitribai Phule Pune Univ, Zeal Coll Eng & Res, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University; Savitribai Phule Pune University
RP Badhe, SS (corresponding author), Pune Savitribai Phule Pune Univ, DY Patil Inst Technol, Pune, Maharashtra, India.
EM sanjaysrikrushnabadhe@gmail.com
CR Ahmadi S, 2001, SPEECH COMMUN, V34, P369, DOI 10.1016/S0167-6393(00)00057-1
   Anderson DV, 2017, NEUROCOMPUTING, P1
   Arslan LM, 1996, SPEECH COMMUN, V18, P353, DOI 10.1016/0167-6393(96)00024-6
   Bajceta M, 2015, 2015 4TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO), P311, DOI 10.1109/MECO.2015.7181931
   Chu A, 2012, ACCENT CLASSIFICATIO
   Djellab M, 2017, LANG RESOUR EVAL, V51, P613, DOI 10.1007/s10579-016-9347-6
   Dong W, 2018, DEEP FACTORIZATION S
   Fadi B, 2011, THESIS COLUMBIA U
   Faragallah OS, 2018, INT J SPEECH TECHNOL, V21, P185, DOI 10.1007/s10772-018-9494-9
   Gharsellaoui S, 2018, COMPUT SPEECH LANG, V48, P67, DOI 10.1016/j.csl.2017.10.006
   Jiao Y, 2016, INTERSPEECH, P2388, DOI 10.21437/Interspeech.2016-1148
   Kulkarni V., 2016, P INT AAAI C WEB SOC, P615
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Liu G, 2016, SPEECH COMMUN
   Liu MK, 2000, INT CONF ACOUST SPEE, P1025
   Luo S, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501402
   Manjunath G, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P553, DOI 10.1109/ICME.2002.1035841
   Mannepalli K, 2017, ALEX ENG J, V56, P485, DOI 10.1016/j.aej.2016.09.002
   MCAULAY RJ, 1986, IEEE T ACOUST SPEECH, V34, P744, DOI 10.1109/TASSP.1986.1164910
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Oropeza V, 2011, GEOPHYSICS, V76, pV25, DOI 10.1190/1.3552706
   Pradip S, 2019, CIRCUITS SYST SIGNAL
   Rizwan M, 2016, IEEE IJCNN, P2625, DOI 10.1109/IJCNN.2016.7727528
   Sastry PN, 2015, INT J SPEECH TECH
   Sengupta Saptarshi, 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P207, DOI 10.1007/978-981-10-8863-6_21
   Sergyán S, 2008, 2008 6TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS, P206
   Sheu LJ, 2011, NONLINEAR DYNAM, V65, P103, DOI 10.1007/s11071-010-9877-1
   Slimani D, 2018, PROCEDIA COMPUT SCI, V128, P79, DOI 10.1016/j.procs.2018.03.011
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Xu QY, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.69
   Youzhi Zheng, 2008, Information Technology Journal, V7, P930, DOI 10.3923/itj.2008.930.935
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhong J, 2018, MULTIMED TOOLS APPL, P1
NR 34
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1467
EP 1499
DI 10.1007/s11042-021-11371-4
EA OCT 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000704172500001
DA 2024-07-18
ER

PT J
AU Fradi, M
   Khriji, L
   Machhout, M
AF Fradi, Marwa
   Khriji, Lazhar
   Machhout, Mohsen
TI Real-time arrhythmia heart disease detection system using CNN
   architecture based various optimizers-networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arrhythmia; ECG-class; Signal augmentation; CNN; Processing time
ID ATRIAL-FIBRILLATION; NEURAL-NETWORK
AB The main objective of this paper is to develop an interactive classifier aided deep learning system to assist cardiologists for heart arrhythmia disease classification as it shows a health-threatening condition that can lead to heart-related complications. Therefore, automatic arrhythmia heart disease detection in an early stage is of high interest as it helps to reduce the mortality rate of cardiac disease patients. In this context, a deep learning architecture is propounded for automatic classification of the patient`s electrocardiogram (ECG) signal into a specific class according to the ANSI-AAMI standards. Our proposed methodology is a multistage technique. The first stage combines an R-R peak extraction with a low pass filter applied on the ECG raw data for noise removal. The proposed second stage is a convolutional neural network (CNN) based Fully Connected layers architecture, using different networks optimizer. Different ECG databases have been used for validation purposes. The whole system is implemented on CPU and GPU for complexity analysis. For the predicted improved PTB dataset, the classification accuracy results achieve 99.37%, 99.15%, and 99.31% for training, validation, and testing, respectively. Besides, for the MIT-BIH database, the training, validation, and testing accuracies are 99.5%, 99.06%, and 99.34%, respectively. A top F1-score of 0.99 is obtained. Experimental results show a high achievement compared to the state-of-the-art models. The implementation on GPU confirms the low computational complexity of the system and the possible use in detecting disease events in real-time, which makes it a good candidate for portable healthcare devices.
C1 [Fradi, Marwa; Machhout, Mohsen] Monastir Univ, Fac Sci Monastir, Elect & Microelect Lab, Monastir, Tunisia.
   [Khriji, Lazhar] Sultan Qaboos Univ, Dept Elect & Comp Engn, Coll Engn, Muscat, Oman.
C3 Universite de Monastir; Sultan Qaboos University
RP Khriji, L (corresponding author), Sultan Qaboos Univ, Dept Elect & Comp Engn, Coll Engn, Muscat, Oman.
EM marwa.fradi@gmail.com; lazhar@squ.edu.om; machhout@yahoo.fr
RI Khriji, Lazhar/AAJ-3563-2021
OI Khriji, Lazhar/0000-0002-1434-5689; Mohsen, Machhout/0000-0002-5629-0508
FU OMANTEL [EG/SQU-OT/18/01]; Sultan Qaboos University
FX This work was funded partially by OMANTEL under grant number
   "EG/SQU-OT/18/01" and Sultan Qaboos University. The necessary equipment
   have been procured, and infrastructure has been developed for the
   research using this.
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Afif M, 2020, CLUSTER COMPUT, V23, P3335, DOI 10.1007/s10586-020-03090-6
   Alarsan FI, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0244-x
   Alfaras M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00103
   Asgari S, 2015, COMPUT BIOL MED, V60, P132, DOI 10.1016/j.compbiomed.2015.03.005
   Bousseljot R., 1995, BIOMED TECH, V40, P317, DOI [10.1515/bmte.1995.40.s1.317, DOI 10.1515/BMTE.1995.40.S1.317, 10.1515/bmte.1995.40s1.317]
   Castells F, 2007, BIOMED TECH, V52, P18, DOI 10.1515/BMT.2007.005
   Celin S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1083-6
   Chiu, 2009, 13 INT C BIOMED ENG
   Dokur Z, 2020, NEURAL COMPUT APPL, V32, P12515, DOI 10.1007/s00521-020-04709-w
   Ebrahimi Z., 2020, Expert Syst. Appl.: X, V7, P100033, DOI [10.1016/j.eswax.2020.100033, DOI 10.1016/J.ESWAX.2020.100033]
   Erdenebayar U, 2019, J KOREAN MED SCI, V34, DOI 10.3346/jkms.2019.34.e64
   Fradi M, 2021, IJACSA
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guo L, 2019, BIOCYBERN BIOMED ENG, V39, P868, DOI 10.1016/j.bbe.2019.06.001
   He RN, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.01206
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Izci E, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P121, DOI 10.1109/tiptekno.2019.8895011
   Ji YS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112558
   Jiang W, 2007, IEEE T NEURAL NETWOR, V18, P1750, DOI 10.1109/TNN.2007.900239
   Jun T.J., 2018, ECG arrhythmia classification using a 2-D convolutional neural network
   Kanani Pratik, 2020, Procedia Computer Science, V171, P524, DOI 10.1016/j.procs.2020.04.056
   Kayid A., 2018, PERFORMANCE CPUSGPUS
   Khan AA, 2015, J MED BIOENG, V4
   Khriji Lazhar, 2020, Impact of Digital Technologies on Public Health in Developed and Developing Countries. 18th International Conference, ICOST 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12157), P100, DOI 10.1007/978-3-030-51517-1_9
   Kim JH, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/2826901
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kiranyaz S, 2019, IEEE T IND ELECTRON, V66, P8760, DOI 10.1109/TIE.2018.2833045
   Kiranyaz S, 2015, IEEE ENG MED BIO, P2608, DOI 10.1109/EMBC.2015.7318926
   Kumar G., 2019, 27 IRISH C ARTIFICIA, P353
   Kwon S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/12770
   Le TD, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P56, DOI 10.1145/3184407.3184424
   Li JC, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7416037
   Ma FY, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9159158
   Ma H, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6627939
   Mehta SS, 2010, IRBM, V31, P48, DOI 10.1016/j.irbm.2009.10.001
   Mouselinos S, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST), DOI 10.1109/mocast.2019.8741940
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Pyakillya B, 2017, J PHYS CONF SER, V913, DOI 10.1088/1742-6596/913/1/012004
   Song XJ, 2020, MULTIMED TOOLS APPL, V79, P22325, DOI 10.1007/s11042-020-09035-w
   Visa S., 2011, Maics, V710, P120
   Wu MZ, 2021, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.564015
   Xia Y, 2018, COMPUT BIOL MED, V93, P84, DOI 10.1016/j.compbiomed.2017.12.007
   Yuan C, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1159, DOI 10.1109/ICInfA.2016.7831994
NR 45
TC 9
Z9 9
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41711
EP 41732
DI 10.1007/s11042-021-11268-2
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000696143500001
DA 2024-07-18
ER

PT J
AU Halabi, O
   Saleh, M
AF Halabi, Osama
   Saleh, Mohammad
TI Augmented reality flavor: cross-modal mapping across gustation,
   olfaction, and vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Olfactory display; Gustation; Cross-modal mapping;
   Flavor
ID TASTE; ODORS
AB Gustatory display research is still in its infancy despite being one of the essential everyday senses that human practice while eating and drinking. Indeed, the most important and frequent tasks that our brain deals with every day are foraging and feeding. The recent studies by psychologists and cognitive neuroscientist revealed how complex multisensory rely on the integration of cues from all the human senses in any flavor experiences. The perception of flavor is multisensory and involves combinations of gustatory and olfactory stimuli. The cross-modal mapping between these modalities needs to be more explored in the virtual environment and simulation, especially in liquid food. In this paper, we present a customized wearable Augmented Reality (AR) system and olfaction display to study the effect of vision and olfaction on the gustatory sense. A user experiment and extensive analysis conducted to study the influence of each stimulus on the overall flavor, including other factors like age, previous experience in Virtual Reality (VR)/AR, and beverage consumption. The result showed that smell contributes strongly to the flavor with less contribution to the vision. However, the combination of these stimuli can deliver richer experience and a higher belief rate. Beverage consumption had a significant effect on the flavor belief rate. Experience is correlated with stimulus and age is correlated with belief rate, and both indirectly affected the belief rate.
C1 [Halabi, Osama; Saleh, Mohammad] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
C3 Qatar University
RP Halabi, O (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
EM ohalabi@qu.edu.qa
RI Halabi, Osama/C-6985-2014
OI Halabi, Osama/0000-0002-2052-0500
FU NPRP Grant from the Qatar National Research Fund (Qatar Foundation)
   [NPRP 11S-1219-170106]
FX This work was partly supported by NPRP Grant #NPRP 11S-1219-170106 from
   the Qatar National Research Fund (a member of Qatar Foundation). This
   work also was not possible without the effort of students Babkir
   Elnimah, Ali Hazi, and Ahmed Ibrahim as part of their senior project.
CR [Anonymous], 2014, P 20 ACM S VIRT REAL
   Aoyama K, 2020, GALVANIC TASTE STIMU, P341
   Avery JA, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2010932118
   Brunetti R, 2017, J EXP PSYCHOL HUMAN, V43, P819, DOI 10.1037/xhp0000348
   Chiou R, 2012, PERCEPTION, V41, P339, DOI 10.1068/p7161
   Demattè ML, 2006, CHEM SENSES, V31, P531, DOI 10.1093/chemse/bjj057
   Di Lorenzo PM, 2021, NUTRIENTS, V13, DOI 10.3390/nu13020398
   Djordjevic J, 2004, CHEM SENSES, V29, P199, DOI 10.1093/chemse/bjh022
   Do EYL, 2014, P 2 ACM INT WORKSH I
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Halabi O, 2014, IEICE T INF SYST, VE97D, P2048, DOI 10.1587/transinf.E97.D.2048
   Halabi O, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P52, DOI 10.1109/CW.2013.38
   Halabi O, 2006, J ROBOT MECHATRON, V18, P409, DOI 10.20965/jrm.2006.p0409
   Halabi O, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P500, DOI 10.1109/WHC.2009.4810826
   Halabi Osama, 2020, The Disruptive Fourth Industrial Revolution, P257, DOI [DOI 10.1007/978-3-030-48230-5_11, 10.1007/978-3-030-48230-5_11]
   Harrison M, 1997, J FOOD SCI, V62, P653, DOI 10.1111/j.1365-2621.1997.tb15429.x
   Huang FX, 2019, COMPUT HUM BEHAV, V95, P168, DOI 10.1016/j.chb.2019.01.027
   Iwata H, 2004, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2004.1310055
   Kerruish E, 2019, SENSES SOC, V14, P31, DOI 10.1080/17458927.2018.1556952
   Klapetek A, 2012, ATTEN PERCEPT PSYCHO, V74, P1154, DOI 10.3758/s13414-012-0317-9
   Liang P, 2021, FOOD QUAL PREFER, V89, DOI 10.1016/j.foodqual.2020.104151
   Makovac E, 2014, ACTA PSYCHOL, V152, P75, DOI 10.1016/j.actpsy.2014.07.008
   Mitchel AD, 2011, J EXP PSYCHOL LEARN, V37, P1081, DOI 10.1037/a0023700
   Nakano K, 2019, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR.2019.000-1
   Narumi Takuji, 2014, IEEE Trans Vis Comput Graph, V20, P504, DOI 10.1109/TVCG.2014.37
   Narumi T, 2011, P IEEE VIRT REAL ANN, P127, DOI 10.1109/VR.2011.5759450
   Petit O, 2019, J INTERACT MARK, V45, P42, DOI 10.1016/j.intmar.2018.07.004
   Prescott J, 2004, CHEM SENSES, V29, P331, DOI 10.1093/chemse/bjh036
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Ranasinghe N, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P139, DOI 10.1145/2818346.2820761
   Sammons JD, 2016, J NEUROPHYSIOL, V116, P171, DOI 10.1152/jn.01119.2015
   Simner J, 2010, PERCEPTION, V39, P553, DOI 10.1068/p6591
   Spence C, 2013, FLAVOUR
   Spence C., 2014, PERCEPTION ITS MODAL, P247, DOI DOI 10.1093/ACPROF:OSO/9780199832798.003.0011
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spence C, 2017, FLAVOUR: FROM FOOD TO PERCEPTION, P373
   Spence C, 2010, PSYCHOLOGIST, V23, P720
   Taylor AJ, 2010, FOOD FLAVOUR TECHNOL, VSecond, DOI [10.1002/9781444317770, DOI 10.1002/9781444317770]
   Walker L, 2016, J EXP PSYCHOL HUMAN, V42, P138, DOI 10.1037/xhp0000128
   Wang QJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.595788
   Yanai K, 2020, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2020), P185, DOI 10.1109/MIPR49039.2020.00045
NR 42
TC 5
Z9 5
U1 8
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36423
EP 36441
DI 10.1007/s11042-021-11321-0
EA SEP 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692967600003
PM 34512111
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Wei, XY
   Yu, L
   Tian, SW
   Feng, PC
   Ning, X
AF Wei, Xiangyu
   Yu, Long
   Tian, Shengwei
   Feng, Pengcheng
   Ning, Xin
TI Underwater target detection with an attention mechanism and improved
   scale
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLOv3; Underwater target; Detection; Attention
AB The light problem and the complicated environment of underwater images make target detection difficult. These images are usually blurry because tiny inorganic and organic particles in the water have a great impact on light. To solve this problem, we add squeeze and excitation modules after the deep convolution layers of the YOLOv3 model to learn the relationship between channels and enhance the semantic information of deep features. In addition, many small targets will lose too much information after five downsamples. This is not conducive to detection. By expanding the detection scale, we combine the deep semantic information with the location information of the shallower layer to improve the detection performance of small targets. The experimental results show that the YOLOv3-brackish model greatly improved the detection of small fish, crabs, shrimp and starfish. In addition, there were minor improvements in the detection of big fish and jellyfish. The mean average precision increased by 4.43%.
C1 [Wei, Xiangyu; Feng, Pengcheng] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Network Ctr, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Informat Sci & Engn, Signal & Signal Proc Lab, Urumqi 830000, Peoples R China.
   [Tian, Shengwei] Xinjiang Univ, Coll Software, Urumqi 830000, Peoples R China.
   [Tian, Shengwei] Xin Jiang Univ, Coll Software, Key Lab Software Engn Technol, Urumqi 830000, Peoples R China.
   [Ning, Xin] Chinese Acad Sci, Inst Semicond, Beijing 100000, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University; Xinjiang
   University; Xinjiang University; Chinese Academy of Sciences
RP Yu, L (corresponding author), Xinjiang Univ, Coll Network Ctr, Urumqi 830000, Peoples R China.; Yu, L (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Signal & Signal Proc Lab, Urumqi 830000, Peoples R China.
EM yul_xju@163.com
RI Ning, Xin/M-9479-2018; Wang, Zhi/GZB-2713-2022
OI Ning, Xin/0000-0001-7897-1673; Wang, Zhi/0000-0001-6952-8848; Yu,
   Long/0000-0001-9041-0801; Yu, Long/0000-0002-9038-4129
FU Key Program of National Natural Science Foundation of China [U2003208];
   Major science and technology projects in the autonomous region
   [2020A03004-4, 2019750001]
FX We thank the anonymous reviewers for their insightful comments. This
   work was supported by the Key Program of National Natural Science
   Foundation of China (U2003208), Major science and technology projects in
   the autonomous region (2020A03004-4) and the real-time underwater
   specific target autonomous recognition project (2019750001).
CR Almero VJD, 2020, IEEE RIVF INT CONF, P166, DOI 10.1109/rivf48685.2020.9140795
   Clausi DA, 2002, PATTERN RECOGN, V35, P1959, DOI 10.1016/S0031-3203(01)00138-8
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DaoLiang Li DaoLiang, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P1
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin WH, 2020, INT CONF ACOUST SPEE, P2588, DOI [10.1109/icassp40776.2020.9053829, 10.1109/ICASSP40776.2020.9053829]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Martin M, 2020, 2 INT C DAT ENG APPL, P1, DOI [10.1109/IDEA49133.2020.9170740, DOI 10.1109/IDEA49133.2020.9170740]
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pedersen M, 2019, DETECTION MARINE ANI
   Rathi D, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P344
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Xinhua Zhao, 2020, 2020 IEEE International Conference on Mechatronics and Automation (ICMA), P637, DOI 10.1109/ICMA49215.2020.9233693
   Xu T, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM 2020), P616, DOI [10.1109/ICARM49381.2020.9195292, 10.1109/icarm49381.2020.9195292]
NR 23
TC 31
Z9 32
U1 6
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33747
EP 33761
DI 10.1007/s11042-021-11230-2
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000688418200003
DA 2024-07-18
ER

PT J
AU Bansal, M
   Lobiyal, DK
AF Bansal, Mani
   Lobiyal, D. K.
TI Multilingual sequence to sequence convolutional machine translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution Neural Network; English-Punjabi; Punjabi-English;
   Hindi-Punjabi; Punjabi-Hindi; Neural Machine Translation
ID ENGLISH; SYSTEM
AB In this paper, to improve the translation quality of a sentence, Convolutional sequence to sequence architecture has been applied to English-Punjabi, Punjabi-English, Hindi-Punjabi, Punjabi-Hindi language pairs. The Convolution architecture consists of Gated Linear Unit (GLU) and a Multi-Hop attention mechanism. The GLU mechanism controls the information flow through hidden units to produce good translations. The Multi-Hop attention is an enhanced version of the attention mechanism that allows the model to make repeated gaze on the sentence than looking at the sentence only once. As compared to the Recurrent Neural Network (RNN), the Convolution based technique provides better accuracy, captures long-range dependencies between the words, capture local context, and allows parallelization over every element in a sequence without depending on the computations of the previous time steps. In this work, we have applied the architecture on four Indian language pairs and compared the performance of our model with conventional models using BLEU, METEOR and WER as evaluation metrics. Our model outperforms recurrent neural networks by 2 BLEU points on English-Punjabi, 2.5 BLEU points on Punjabi-English, 3.5 BLEU points on Hindi-Punjabi translations, and 1.5 BLEU points on Punjabi-Hindi.
C1 [Bansal, Mani; Lobiyal, D. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Bansal, M (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM mani57_scs@jnu.ac.in; lobiyal@gmail.com
FU Council of Scientific and Indian Research (CSIR)
   [09/263(1152)/2018-EMR-I]; Department of Science and Technology (DST),
   Govt. of India
FX This work was supported by Council of Scientific and Indian Research
   (CSIR) with file no. 09/263(1152)/2018-EMR-I. We are also thankful to
   Department of Science and Technology (DST), Govt. of India for support
   through PURSE Grant.
CR Agrawal R, 2017, THESIS INT I INFORM
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   Chen SF, 1998, DARPA BROADC NEWS TR
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Forcada ML, 2011, MACH TRANSL, V25, P127, DOI 10.1007/s10590-011-9090-0
   Gehring J, 2017, PR MACH LEARN RES, V70
   Goyal V, 2011, P 49 ANN M ASS COMP
   Goyal V., 2019, GEORGE RONCHI FDN J, V64, P2009
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jindal S, 2018, J STAT MANAG SYST, V21, P553, DOI 10.1080/09720510.2018.1471265
   Josan G.S., 2008, P 22 INT C ON COMP L, P157
   Josan GS., 2012, CSI J COMPUT, V1, P3
   Josan Gurpreet Singh, 2011, International Journal of Information Technology and Knowledge Management, V4, P459
   Kaur A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ENGINEERING & COMPUTATIONAL SCIENCES (RAECS)
   Kaur D, 2015, INT J SCI RES MANAGE, V3
   Kaur J., 2011, INT J COMPUT SCI ENG, V3.4, P1518
   Kaur K, 2011, PUNJABI ENGLISH MACH
   Koehn P., 2009, STAT MACHINE TRANSLA, DOI DOI 10.1017/CBO9780511815829
   Kumar A, 2018, J STAT MANAG SYST, V21, P547, DOI 10.1080/09720510.2018.1466963
   Kumar P., 2013, INT J APPL INNOVATIO, V2, P318
   Lavie A, 2007, PROC 2 WORKSH STAT M
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Mahata SK, 2019, J INTELL SYST, V28, P447, DOI 10.1515/jisys-2018-0016
   Nair LR., 2012, INT J COMP APPL, V39, P0975
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Premjith B, 2019, J INTELL SYST, V28, P387, DOI 10.1515/jisys-2019-2510
   Revanuru K, 2017, COMPUTE'17: PROCEEDINGS OF THE 10TH ANNUAL ACM INDIA COMPUTE CONFERENCE, P11, DOI 10.1145/3140107.3140111
   Shirai S, 1997, RECENT ADV EXAMPLE B, V211-224
   Sidhu BK., 2010, J COMPUTER SCI ENG, V2, P32
   Singh S, 2018, J INTELL FUZZY SYST, V34, P1551, DOI 10.3233/JIFS-169450
   Somers H., 1999, Machine Translation, V14, P113, DOI 10.1023/A:1008109312730
   Sutskever I, 2014, ADV NEUR IN, V27
   van der Wel E, 2017, ARXIV170704877
   Zhang Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081665
NR 34
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33701
EP 33726
DI 10.1007/s11042-021-11345-6
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687926200009
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Zhang, RX
   Qiu, Y
   Zhao, MY
   Sun, Z
AF Hu, Zheng-ping
   Zhang, Rui-xue
   Qiu, Yue
   Zhao, Meng-yao
   Sun, Zhe
TI 3D convolutional networks with multi-layer-pooling selection fusion for
   video classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video classification; Mid-level semantics; Pooling operator;
   Convolutional neural network; Multi-scale feature fusion
ID RECOGNITION; CNN
AB C3D has been widely used for video representation and understanding. However, it is performed on spatio-temporal contexts in a global view, which often weakens its capacity of learning local representation. To alleviate this problem, a concise and novel multi-layer feature fusion network with the cooperation of local and global views is introduced. For the current network, the global view branch is used to learn the core video semantics, while the local view branch is used to capture the contextual local semantics. Unlike traditional C3D model, the global view branch can only provide the big view branch with the most activated video features from a broader 3D receptive field. Via adding such shallow-view contexts, the local view branch can learn more robust and discriminative spatio-temporal representations for video classification. Thus we propose 3D convolutional networks with multi-layer-pooling selection fusion for video classification, the integrated deep global feature is combined with the information originated from shallow layer of local feature extraction networks, through the space-time pyramid pooling, adaptive pooling and attention pooling three different pooling units, different time-space feature information is obtained, and finally cascaded and used for classification. Experiments on the UCF-101 and HMDB-51 datasets achieve correct classification rate 95.0% and 72.2% respectively. The results show that the proposed 3D convolutional networks with multi-layer-pooling selection fusion has better classification performance.
C1 [Hu, Zheng-ping; Zhang, Rui-xue; Qiu, Yue; Zhao, Meng-yao; Sun, Zhe] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Hebei, Peoples R China.
   [Hu, Zheng-ping; Sun, Zhe] Hebei Key Lab Informat Transmiss & Signal Proc, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University
RP Hu, ZP (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Hebei, Peoples R China.
EM hzp_ysu@163.com
FU National Natural Science Foundation of China [61771420, 62001413];
   Natural Science Foundation of Hebei Province [F2020203064]; China
   Postdoctoral Science Foundation [2018M641674]; Doctoral Foundation of
   Yanshan University [BL18033]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771420 and and 62001413, the Natural Science
   Foundation of Hebei Province under Grants F2020203064, as well as the
   China Postdoctoral Science Foundation Grant 2018M641674 and the Doctoral
   Foundation of Yanshan University under Grants BL18033. In this paper, we
   utilize the public video database and thank the provider of the
   databases.
CR Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng C, 2018, IEEE IMAGE PROC, P3468, DOI 10.1109/ICIP.2018.8451625
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YF, 2021, IEEE T MULTIMEDIA, V23, P4285, DOI 10.1109/TMM.2020.3039329
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Jing LL, 2018, J VIS COMMUN IMAGE R, V52, P58, DOI 10.1016/j.jvcir.2018.01.016
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li C, 2019, IEEE T IMAGE PROCESS, V28, P4646, DOI 10.1109/TIP.2019.2912357
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Shi YM, 2017, IEEE I CONF COMP VIS, P716, DOI 10.1109/ICCV.2017.84
   Simonyan K, 2014, ADV NEUR IN, V27
   Sudhakaran S, 2020, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR42600.2020.00118
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang JZ, 2018, IEEE T MULTIMEDIA, V20, P2578, DOI 10.1109/TMM.2018.2855081
   Wang L, 2020, EURO C COMP VISION, P20
   Wu HB, 2020, IEEE T MULTIMEDIA, V22, P2293, DOI 10.1109/TMM.2019.2953814
   Zhang J, 2019, IEEE T MULTIMEDIA, V21, P2518, DOI 10.1109/TMM.2019.2907453
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zhu SG, 2019, J VIS COMMUN IMAGE R, V60, P38, DOI 10.1016/j.jvcir.2018.12.026
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 35
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33179
EP 33192
DI 10.1007/s11042-021-11403-z
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000684785000004
DA 2024-07-18
ER

PT J
AU Pérez, P
   Ruiz, J
   Benito, I
   López, R
AF Perez, Pablo
   Ruiz, Jaime
   Benito, Ignacio
   Lopez, Raul
TI A parametric quality model to evaluate the performance of tele-operated
   driving services over 5G networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tele-operated Driving; 5G; QoE planning model
ID QOE ASSESSMENT; VIDEO QUALITY; RESOLUTION
AB We have developed a parametric model to quantify the Key Quality Indicators which affect video-based Tele-operated Driving (ToD) over a mobile network, as well as their relationship with the network Key Performance Indicators. This model can be easily used to specify Quality of Service policies (e.g. through network slicing) that guarantee the required conditions for remote driving on specific areas. We have used our model to validate the feasibility of deploying remote-assisted driving in different real networks, both from current 4G deployments and from pre-commercial and commercial 5G pilots. Our results show that some ToD services (supervision and, up to some point, parking) may be feasible with high-end existing 5G networks. However, full remote driving requires some improvements in the system, particularly to reduce end-to-end latency, increase uplink performance, and minimize service losses. Both the model and its results will be used in the framework of European Union H2020 project 5G-MOBIX to deploy a ToD proof-of-concept in the cross-border corridor between Spain and Portugal.
C1 [Perez, Pablo; Ruiz, Jaime; Benito, Ignacio] Nokia Bell Labs, Madrid, Spain.
   [Lopez, Raul] Nokia, Madrid, Spain.
RP Pérez, P (corresponding author), Nokia Bell Labs, Madrid, Spain.
EM pablo.perez@nokia-bell-labs.com;
   jaime_jesus.ruiz_alonso@nokia-bell-labs.com;
   ignacio.benito_frontelo@nokia-bell-labs.com;
   raul.lopez_lopez.ext@nokia.com
OI Benito Frontelo, Ignacio/0000-0001-8775-0733; Perez,
   Pablo/0000-0002-3502-6791
FU European Union's Horizon 2020 research and innovation programme
   [825496]; H2020 - Industrial Leadership [825496] Funding Source: H2020 -
   Industrial Leadership
FX This work has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement no 825496
   (5G-MOBIX: 5G for cooperative & connected automated MOBIlity on X-border
   corridors).
CR 5G-MOBIX, 2019, D2 1 5G EN CCAM US C
   5G-MOBIX, 5G COOP CONN AUT MOB
   5GAA, 2020, STUD SPECTR NEEDS SA
   5GAA, 2020, C V2X US CAS
   Benito-Frontelo I, 2019, EUR C NETW COMM EUCN
   Bokani A, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P344, DOI 10.1145/2910017.2910618
   Cao HW, 2016, IEEE VEHIC NETW CONF
   Cermak G, 2011, IEEE T BROADCAST, V57, P258, DOI 10.1109/TBC.2011.2121650
   Chucholowski F. E., 2016, J UNMANNED SYST TECH, V3, P80, DOI DOI 10.21535/JUST.V3I3.38
   Diaz C, 2020, IP NETWORKS IEEE T N
   Gaber A, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P191, DOI [10.1109/ITCE48509.2020.9047764, 10.1109/itce48509.2020.9047764]
   Gnatzig Sebastian, 2013, ICINCO 2013. Proceedings of the 10th International Conference on Informatics in Control, Automation and Robotics, P231
   Hetzer Dirk, 2019, 2019 European Conference on Networks and Communications (EuCNC), P78, DOI 10.1109/EuCNC.2019.8801993
   Hosseini A, 2016, IEEE INT VEH SYM, P165, DOI 10.1109/IVS.2016.7535381
   Hossfeld T, 2007, LECT NOTES COMPUT SC, V4516, P361
   Hossfelt T., 2016, P 5 ISCA DEGA WORKSH
   Janowski L, 2012, MULTIMED TOOLS APPL, V61, P769, DOI 10.1007/s11042-011-0932-9
   Kang L, 2018, HOTMOBILE'18: PROCEEDINGS OF THE 19TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, P19, DOI 10.1145/3177102.3177104
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Kostopoulos A, 2019, IEEE INT CONF COMM, DOI 10.1109/iccw.2019.8756985
   Kousaridas A, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12010005
   Krogfoss B, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123090
   Liu RL, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P264, DOI 10.1145/3122986.3123008
   Moller S., 2018, 2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX), P1, DOI DOI 10.1109/QOMEX.2018.8463404
   Monroy I. T., 2018, 2018 20 INT C TRANSP, P1
   Muzaffar R, 2020, P ACM MOB WORKSH
   Narayanan A, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P894, DOI 10.1145/3366423.3380169
   Neumeier S, 2019, IEEE INT C INTELL TR, P4190, DOI 10.1109/ITSC.2019.8917244
   Neumeier S, 2019, PROCEEDINGS OF THE 3RD NETWORK TRAFFIC MEASUREMENT AND ANALYSIS CONFERENCE (TMA 2019), P113, DOI 10.23919/TMA.2019.8784466
   Pérez P, 2011, BELL LABS TECH J, V16, P91, DOI 10.1002/bltj.20488
   Raake A, 2011, IEEE SIGNAL PROC MAG, V28, P68, DOI 10.1109/MSP.2011.942472
   Raca D, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P303, DOI 10.1145/3339825.3394938
   Raca D, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P460, DOI 10.1145/3204949.3208123
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Robitza W, 2017, MULTIMED TOOLS APPL, V76, P22243, DOI 10.1007/s11042-017-4870-z
   Saeed U, 2019, INT SYM WIRELESS COM, P271, DOI [10.1109/iswcs.2019.8877213, 10.1109/ISWCS.2019.8877213]
   Velez G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226622
   Wang SQ, 2009, PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2, P1, DOI 10.1109/PLASMA.2009.5227540
NR 38
TC 6
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12287
EP 12303
DI 10.1007/s11042-021-11251-x
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000677229000006
DA 2024-07-18
ER

PT J
AU Ahmad, S
   Hayat, MF
   Qureshi, MA
   Asef, S
   Saleem, Y
AF Ahmad, Saleha
   Hayat, Muhammad Faisal
   Qureshi, Muhammad Ali
   Asef, Shahzad
   Saleem, Yasir
TI Enhanced halftone-based secure and improved visual cryptography scheme
   for colour/binary Images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decryption; Encryption; Halftoning; Visual cryptography
ID SECRET
AB Visual Cryptography (VC) is gaining attraction during the past few years to secure the visual information in the transmission network. It enables the visual data i.e. handwritten notes, photos, printed text, etc. to encrypt in such a way that their decryption can be done through the human visual framework. Hence, no computational assistance is required for the decryption of the secret images they can be seen through naked eye. In this paper, a novel enhanced halftoning-based VC scheme is proposed that works for both binary and color images. Fake share is generated by the combination of random black and white pixels. The proposed algorithm consists of 3 stages i.e., detection, encryption, and decryption. Halftoning, Encryption, (2, 2) visual cryptography and the novel idea of fake share, make it even more secure and improved. As a result, it facilitates the original restored image to the authentic user, however, the one who enters the wrong password gets the combination of fake share with any real share. Both colored and black images can be processed with minimal capacity using the proposed scheme.
C1 [Ahmad, Saleha; Hayat, Muhammad Faisal; Asef, Shahzad; Saleem, Yasir] Univ Engn & Technol, Dept Comp Sci, Lahore, Pakistan.
   [Qureshi, Muhammad Ali] Islamia Univ Bahawalpur, Dept Informat & Commun Engn, Bahawalpur, Punjab, Pakistan.
C3 University of Engineering & Technology Lahore; Islamia University of
   Bahawalpur
RP Qureshi, MA (corresponding author), Islamia Univ Bahawalpur, Dept Informat & Commun Engn, Bahawalpur, Punjab, Pakistan.
EM saleha.ahmad2k13@gmail.com; muhammad.faisal.hayat@uet.edu.pk;
   ali.qureshi@iub.edu.pk; shehzad@uet.edu.pk; yasir@uet.edu.pk
RI Hayat, Muhammad/HDN-8672-2022; Qureshi, Muhammad Ali/C-3857-2012;
   Saleem, Yasir/JDM-9428-2023
OI Qureshi, Muhammad Ali/0000-0003-4390-2461; 
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Almuhammadi S, 2017, CAN CON EL COMP EN
   [Anonymous], 2015, NUCLEUS
   AshaBhadran, 2015, INT RES J ENG TECHNO, V2
   Bhatnagar Rajat, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P78, DOI 10.1109/ICECA.2018.8474649
   Chandini M.S., 2020, INT J PROGR RES SCI, V1, P33
   Chattonadhvav Arup Kumar, 2018, 2018 Global Wireless Summit (GWS), P236, DOI 10.1109/GWS.2018.8686653
   Cimato S., 2017, VISUAL CRYPTOGRAPHY
   Dhiman K, 2018, COMPUT ELECTR ENG, V70, P647, DOI 10.1016/j.compeleceng.2017.09.017
   Ibrahim Dyala R., 2022, International Journal of Computers and Applications, V44, P623, DOI 10.1080/1206212X.2020.1859244
   Karwande, 2018, INT J RES ENG SCI MA, V1, P368
   Pahuja S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P281, DOI 10.1109/COMPTELIX.2017.8003979
   PAKNAHAD SM, 2016, 2016 10 INT S COMM S, P1
   Purushothaman V., 2016, 2016 ONL INT C GREEN, P1
   Qureshi MA., 2012, INT J COMPUT ELECT E, V4, P558, DOI [10.7763/IJCEE.2012.V4.557, DOI 10.7763/IJCEE.2012.V4.557]
   Rao J, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P855, DOI 10.1109/ICGCIoT.2015.7380582
   Ratheesh V, 2014, VISUAL CRYPTOGRAPHIC
   Ravella Y, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P344, DOI 10.1109/ICCONS.2017.8250740
   Saher M, 2018, MEHRAN UNIV RES J EN, V37, P645, DOI 10.22581/muet1982.1804.16
   Shankar K, 2017, CHINA COMMUN, V14, P118, DOI 10.1109/CC.2017.7868160
   Shankar K, 2015, PROCEDIA COMPUT SCI, V70, P462, DOI 10.1016/j.procs.2015.10.080
   Sharma BP, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN MECHANICAL, INDUSTRIAL, AUTOMATION AND MANAGEMENT SYSTEMS (AMIAMS) - PROCEEDINGS, P1, DOI 10.1109/CLEOE-EQEC.2017.8086726
   Siahaan, 2017, INT J ADV TRENDS COM, V3
   Surya, 2021, SOLID STATE TECHNOL, V64, P203
   Tan LD, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P961, DOI 10.1109/ICIVC.2018.8492724
   Thomas Sandhya Anne, 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1091, DOI 10.1109/ICOEI.2018.8553863
   Thomas SA, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P1164, DOI 10.1109/CTCEEC.2017.8455136
   Yan XH, 2020, MULTIMED TOOLS APPL, V79, P21345, DOI 10.1007/s11042-020-08970-y
NR 28
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32071
EP 32090
DI 10.1007/s11042-021-11152-z
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000676079100003
DA 2024-07-18
ER

PT J
AU Sreesudha, P
   Malleswari, BL
AF Sreesudha, P.
   Malleswari, B. L.
TI A hybridization approach of PSO and GSO algorithm for minimum-BER based
   multi-user detection in STBC-MIMO MC-CDMA systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gravitational search algorithm; Particle swarm optimization; STBC;
   Baseband receivers; CDMA system; Bit error rate
ID TIME BLOCK-CODES; SPACE; PERFORMANCE; RECEIVERS; DIVERSITY
AB The usage of productive baseband receivers are portrayed by reasonable computational load is an urgent point in the advancement of transmission frameworks misusing assorted qualities in various spaces.Several research works have been published in the literature ofspace-time block codes multi-carrier code-division multiple-access (STBC MC-CDMA)Systems based on minimum conditional bit error rate Criterion. As like, in our previous paper, an efficient STBC communication system was performed using oppositional krill herd algorithm (OKHA). To overcome the drawbacks in the previous work, in this work we proposed a hybrid Particle swarm optimization (PSO) and group search optimization (GSO), called PSGSO based Multi-User Detection in STBC MC-CDMA Systems. In this paper, we use the Alamouti's STBC encoder for transmitting sequence and the channel estimation matrix is optimally evaluated using PSGSO algorithm. The simulation results show that the proposed algorithm is properly reducing the bit error rate (BER), symbol error rate (SER) and properly increase the spectral efficiency value compare to other techniques.
C1 [Sreesudha, P.] GNITS, Dept Elect & Telemat Engn, Hyderabad, India.
   [Malleswari, B. L.] Sridevi Womens Engn Coll, Hyderabad, India.
RP Sreesudha, P (corresponding author), GNITS, Dept Elect & Telemat Engn, Hyderabad, India.
EM sreesudhap0581@gmail.com
RI Malleswari, Barooru Lakshmi/HPC-6101-2023; sreesudha, p/GLS-0250-2022
OI Malleswari, Barooru Lakshmi/0000-0003-0195-4300; 
CR Alamouti SM, 1998, IEEE J SEL AREA COMM, V16, P1451, DOI 10.1109/49.730453
   Bader F, 2002, 13TH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOL 1-5, PROCEEDINGS, P409, DOI 10.1109/PIMRC.2002.1046732
   Bäro S, 2000, GLOB TELECOMM CONF, P1067, DOI 10.1109/GLOCOM.2000.891301
   Barukang, 2007, BINARY GENETIC ALGOR, P1
   Caldwell R, 2005, IEEE POTENTIALS, V24, P27, DOI 10.1109/MP.2005.1594005
   Couzin ID, 2005, NATURE, V433, P513, DOI 10.1038/nature03236
   D'Orazio L, 2007, GLOB TELECOMM CONF, P3427
   Debbat F, 2013, IJCSI INT J COMPUT S, V10, P195
   Gesbert D, 2003, IEEE J SEL AREA COMM, V21, P281, DOI 10.1109/JSAC.2003.809458
   Hara S, 1999, IEEE T VEH TECHNOL, V48, P1584, DOI 10.1109/25.790535
   Hassibi B, 2002, IEEE T INFORM THEORY, V48, P1804, DOI 10.1109/TIT.2002.1013127
   He S, 2006, LECT NOTES COMPUT SC, V3982, P934, DOI 10.1007/11751595_98
   Ma WK, 2002, IEEE T SIGNAL PROCES, V50, P912, DOI 10.1109/78.992139
   Miller SL, 2000, IEEE J SEL AREA COMM, V18, P2356, DOI 10.1109/49.895040
   Nagaradjane P, 2012, COMPUT ELECTR ENG, V38, P105, DOI 10.1016/j.compeleceng.2011.10.017
   Namgoong J, 2000, IEEE T COMMUN, V48, P1897, DOI 10.1109/26.886487
   Paulraj AJ, 1997, IEEE SIGNAL PROC MAG, V14, P49, DOI 10.1109/79.637317
   Rong Y, 2005, IEEE T SIGNAL PROCES, V53, P3081, DOI 10.1109/TSP.2005.851199
   Saad NM, 2015, INT J ELECT COMMUN A
   Sethuraman BA, 2003, IEEE T INFORM THEORY, V49, P2596, DOI 10.1109/TIT.2003.817831
   Sun W, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P3452
   Vardhan KV, 2008, IEEE J SEL AREA COMM, V26, P473, DOI 10.1109/JSAC.2008.080406
   Wolniansky PW, 1998, 1998 URSI SYMPOSIUM ON SIGNALS, SYSTEMS, AND ELECTR ONICS, P295, DOI 10.1109/ISSSE.1998.738086
   Wong KK, 2002, IEEE T COMMUN, V50, P1960, DOI 10.1109/TCOMM.2002.806503
   Yang J, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P220
   Yang LL, 2006, IEEE T VEH TECHNOL, V55, P397, DOI 10.1109/TVT.2005.861177
   Yu JL, 2009, SIGNAL PROCESS, V89, P99, DOI 10.1016/j.sigpro.2008.07.010
   Yuen C, 2005, IEEE T WIREL COMMUN, V4, P2089, DOI 10.1109/TWC.2005.853890
NR 28
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31967
EP 31992
DI 10.1007/s11042-021-11091-9
EA JUL 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678031600001
DA 2024-07-18
ER

PT J
AU Das, B
   Majumder, M
   Phadikar, S
   Sekh, AA
AF Das, Bidyut
   Majumder, Mukta
   Phadikar, Santanu
   Sekh, Arif Ahmed
TI Multiple-choice question generation with auto-generated distractors for
   computer-assisted educational assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-assisted learning; Multiple-choice question; Distractor
   generation; Unsupervised clustering; Computer-aided assessment
ID AUTOMATIC-GENERATION
AB Multiple-choice questions (MCQs) are used as instrumental tool for assessment, not only in various competitive examinations but also in contemporary information and communications Technology (ICT)-based education, active learning, etc. Therefore, automatic generation of multiple-choice test items from text-based learning material is a truly demanding task in computer aided-assessment. A lot of systems were developed in the past two decades for this purpose, but the system generated questions have failed to satisfy the needs of computer-based automated assessment. As a consequence, this is still an open area of research in education technology and natural language processing. This article presents an automated system for generating multiple-choice test items with distractors. The system first selects informative sentences using the topic-words or keywords (one or more words). The best keyword from a selected sentence is chosen as an answer key. Next, the system eliminates the answer key from this sentence and transforms it into a question-sentence (stem). The wrong options or distractors are generated automatically using a feature-based clustering approach, without using any external information or knowledge-base. The result highlights the efficiency of the proposed system for generating MCQs with distractors.
C1 [Das, Bidyut] Haldia Inst Technol, Haldia, India.
   [Majumder, Mukta] Univ North Bengal, Siliguri, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Kolkata, W Bengal, India.
   [Sekh, Arif Ahmed] XIM Univ, Bhubaneswar, India.
C3 Haldia Institute of Technology; University of North Bengal; Maulana Abul
   Kalam Azad University of Technology
RP Das, B (corresponding author), Haldia Inst Technol, Haldia, India.
EM bidyut2002in@gmail.com; mukta_jgec_it_4@yahoo.co.in;
   sphadikar@yahoo.com; skarifahmed@gmail.com
RI Sk, Arif Ahmed/U-5120-2019; Majumder, Mukta/J-7447-2019; Das, Dr.
   Bidyut/AAE-5814-2020
OI Sk, Arif Ahmed/0000-0003-0706-2565; Majumder, Mukta/0000-0003-2608-5762;
   Das, Dr. Bidyut/0000-0002-8588-1913
CR Afzal N, 2014, SOFT COMPUT, V18, P1269, DOI 10.1007/s00500-013-1141-4
   Agarwal M., 2011, Proc. of the sixth workshop on innovative use of NLP for building educational applications, P56
   Agarwal M., 2011, P 6 WORKSH INN US NL, P1, DOI DOI 10.1109/CIMSA.2011.6059919
   Aldabe I, 2010, LECT NOTES ARTIF INT, V6233, P27, DOI 10.1007/978-3-642-14770-8_5
   Alsubait T, 2016, KUNSTL INTELL, V30, P183, DOI 10.1007/s13218-015-0405-9
   Andersen S, 2014, SENTENCE TYPES FUNCT
   [Anonymous], 2012, UNM ED
   Araki J., 2016, P COLING 2016 26 INT, P1125
   Becker L., 2012, P 2012 C N AM CHAPT, P742
   Ben Aouicha M, 2018, SOFT COMPUT, V22, P1855, DOI 10.1007/s00500-016-2438-x
   Bholowalia P., 2014, International Journal of Computer Application, V105
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Coniam D., 1997, CALICO Journal, V14, P15
   Das Bidyut, 2018, International Journal of Modern Education and Computer Science, V10, P57, DOI 10.5815/ijmecs.2018.01.06
   Das B, 2019, COMPUT APPL ENG EDUC, V27, P1485, DOI 10.1002/cae.22163
   Das B, 2017, INT J EDUC TECHNOL H, V14, DOI 10.1186/s41239-017-0060-3
   Divate M, 2017, CURR SCI INDIA, V113, P1683, DOI 10.18520/cs/v113/i09/1683-1691
   Dostal M, 2011, CEUR WORKSHOP PROCEE, V706, P140
   Du X., 2017, P 2017 C EMP METH NA, P2067, DOI 10.18653/v1/D17-1219
   Du XY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1342, DOI 10.18653/v1/P17-1123
   Effenberger T., 2015, THESIS MASARYKOVA U
   Gao LY, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P102
   Gates DM, 2011, 2011 AAAI FALL S SER, P19
   Goto T, 2010, KNOWL MANAG E-LEARN, V2, P210
   Karamanis N., 2006, P 4 INT NAT LANG GEN, P111
   Kim Y, 2019, AAAI CONF ARTIF INTE, P6602
   Knoop S., 2013, Proc. of the Second Workshop on NLP for Computer-assisted Language Learning at NODALIDA 2013, P39
   Kurdi G, 2020, INT J ARTIF INTELL E, V30, P121, DOI 10.1007/s40593-019-00186-y
   Leo J, 2019, INT J ARTIF INTELL E, V29, P145, DOI 10.1007/s40593-018-00172-w
   Levy R., 2006, P LREC GEN IT, P2231
   Li J, 2019, TURK J ELECTR ENG CO, V27, P1794, DOI 10.3906/elk-1806-38
   Liu M, 2018, IEEE T LEARN TECHNOL, V11, P193, DOI 10.1109/TLT.2017.2679009
   Ma L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2895, DOI 10.1109/BigData.2015.7364114
   Majumder M., 2015, P 2 WORKSH NAT LANG, P64, DOI DOI 10.18653/V1/W15-4410
   Majumder M, 2014, KNOWL MANAG E-LEARN, V6, P377
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marie-Catherine deMarneffe Christopher D. Manning., 2008, STANFORD TYPED DEPEN
   Maurya KK, 2020, LEARNING DISTRACT HI, P1115
   Mitkov R., 2006, Natural Language Engineering, V12, P177, DOI 10.1017/S1351324906004177
   Naqvi SR, 2019, INT J ELEC ENG EDUC, V56, P140, DOI 10.1177/0020720918790108
   Narendra A., 2013, P RECENT ADV NATURAL, P511
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Patra R, 2019, EDUC INF TECHNOL, V24, P973, DOI 10.1007/s10639-018-9814-3
   Pugh D, 2016, MED TEACH, V38, P838, DOI 10.3109/0142159X.2016.1150989
   Rao CHD, 2020, IEEE T LEARN TECHNOL, V13, P14, DOI 10.1109/TLT.2018.2889100
   Rose D., 2010, TEXT MINING APPL THE, V1, P1, DOI [DOI 10.1002/9780470689646.CH1, 10.1002/9780470689646.CH1]
   Santhanavijayan A, 2017, INT J SIGNAL IMAGING, V10, P54, DOI 10.1504/IJSISE.2017.084571
   Singh Bhatia Arjun, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P733, DOI 10.1007/978-3-642-45062-4_104
   Smith S., 2010, Practical tourism research, P1, DOI 10.1079/9781845936327.0001
   Subramanian S, 2018, MACHINE READING FOR QUESTION ANSWERING, P78
   Sun XW, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3930
   Susanti Yuni, 2018, Res Pract Technol Enhanc Learn, V13, P15, DOI 10.1186/s41039-018-0082-z
   Warrens M.J., 2020, Advanced Studies in Classification and Data Science, P301
   Wongso R., 2018, INT J ELECT COMPUT E, V8, P5311
   Yuan Xingdi, 2017, P 2 WORKSHOP REPRESE, P15
   Zhang SN, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P2247, DOI 10.1109/IAEAC.2017.8054419
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 57
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31907
EP 31925
DI 10.1007/s11042-021-11222-2
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675334700003
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, TD
   Bandyopadhyay, S
AF Singh, Alok
   Singh, Thoudam Doren
   Bandyopadhyay, Sivaji
TI An encoder-decoder based framework for hindi image caption generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; VGG16; VGG19; Stacked LSTM; Hindi image caption generation
AB In recent times, research activity on image caption generation has attracted several researchers. The present work attempt to address the problem of Hindi image caption generation using Hindi Visual genome dataset. Hindi is the official and most spoken language in India. In a linguistically diverse country like India, it is essential to provide a means that can help the people to understand the visual entities in their native languages. In this paper, an encoder-decoder based architecture is proposed where Convolutional Neural Network (CNN) is employed for encoding visual features of an image and stacked Long Short-Term Memory (sLSTM) in combination with both uni-directional LSTM and bi-directional LSTM for generating the captions in Hindi. For encoding the visual feature representation of an image, VGG19 based pre-trained model is used and sLSTM architecture is employed for caption generation at the decoder side. The model is tested over Hindi visual genome dataset to validate the proposed approach's performance and cross-verification is carried out for English captions with Flickr dataset. The experimental results of the proposed approach manifest that the model is qualitatively and quantitatively better than state-of-the-art approaches for Hindi caption generation.
C1 [Singh, Alok; Singh, Thoudam Doren; Bandyopadhyay, Sivaji] Natl Inst Technol, Ctr Nat Language Proc CNLP, Dept Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Singh, A (corresponding author), Natl Inst Technol, Ctr Nat Language Proc CNLP, Dept Comp Sci & Engn, Silchar, Assam, India.
EM alok.rawat478@gmail.com
RI SINGH, ALOK/AGM-6725-2022
OI SINGH, ALOK/0000-0002-2683-0542
FU Scheme for Promotion of Academic and Research Collaboration (SPARC) -
   Ministry of Education (erstwhile MHRD), Govt of India [P995,
   SPARC/2018-2019/119/SL]
FX This work is supported by Scheme for Promotion of Academic and Research
   Collaboration (SPARC) Project Code: P995 of No: SPARC/2018-2019/119/SL
   (IN) funded by Ministry of Education (erstwhile MHRD), Govt of India.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, P 2016 IEEE INT C MU, DOI DOI 10.1109/ICME.2016.7552883
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Dhir R, 2019, COMPUT SIST, V23, P693, DOI [10.13053/cys-23-3-3269, 10.13053/CyS-23-3-3269]
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   He XD, 2017, IEEE SIGNAL PROC MAG, V34, P109, DOI 10.1109/MSP.2017.2741510
   Hironobu Y.M., 1999, IMAGE TO WORD TRANSF
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Isozaki H., 2010, P 2010 C EMP METH NA, P944
   Jaffe A., 2017, P 2 C MACH TRANSL, P458
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Kiros R, 2014, P 31 INT C INT C MAC, V32
   Laskar SR, 2019, P 6 WORKSH AS TRANSL, P62, DOI [10.18653/v1/D19-5205, DOI 10.18653/V1/D19-5205]
   Liu Maofu, 2020, IEEE T CYBERNETICS
   Meetei LS, 2019, P 6 WORKSH AS TRANSL, P181, DOI DOI 10.18653/V1/D19-5224
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parida S, 2019, CICLING 2019 LA ROCH
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Alok, 2021, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2020, NEHU. Lecture Notes in Networks and Systems (LNNS 170), P65, DOI 10.1007/978-981-33-4084-8_7
   Sutskever I, 2014, ADV NEUR IN, V27
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang MS, 2016, IEEE IMAGE PROC, P4448
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
NR 33
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35721
EP 35740
DI 10.1007/s11042-021-11106-5
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000671519500001
DA 2024-07-18
ER

PT J
AU Bachiller, P
   Rodriguez-Criado, D
   Jorvekar, RR
   Bustos, P
   Faria, DR
   Manso, LJ
AF Bachiller, P.
   Rodriguez-Criado, D.
   Jorvekar, R. R.
   Bustos, P.
   Faria, D. R.
   Manso, L. J.
TI A graph neural network to model disruption in human-aware robot
   navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social navigation; Graph neural networks; Human-robot interaction
ID AGREEMENT
AB Autonomous navigation is a key skill for assistive and service robots. To be successful, robots have to minimise the disruption caused to humans while moving. This implies predicting how people will move and complying with social conventions. Avoiding disrupting personal spaces, people's paths and interactions are examples of these social conventions. This paper leverages Graph Neural Networks to model robot disruption considering the movement of the humans and the robot so that the model built can be used by path planning algorithms. Along with the model, this paper presents an evolution of the dataset SocNav1 (Manso et al 2020) which considers the movement of the robot and the humans, and an updated scenario-to-graph transformation which is tested using different Graph Neural Network blocks. The model trained achieves close-to-human performance in the dataset. In addition to its accuracy, the main advantage of the approach is its scalability in terms of the number of social factors that can be considered in comparison with handcrafted models.
C1 [Bachiller, P.; Bustos, P.] Univ Extremadura, Robot & Artificial Vis Lab, Extremadura, Spain.
   [Rodriguez-Criado, D.; Faria, D. R.; Manso, L. J.] Aston Univ, Coll Engn & Phys Sci, Birmingham B4 7ET, W Midlands, England.
   [Jorvekar, R. R.] Pune Inst Comp Technol, Dept Comp Engn, Pune, Maharashtra, India.
C3 Universidad de Extremadura; Aston University
RP Manso, LJ (corresponding author), Aston Univ, Coll Engn & Phys Sci, Birmingham B4 7ET, W Midlands, England.
EM pilarb@unex.es; 190229717@aston.ac.uk; ronitjorvekar007@gmail.com;
   pbustos@unex.es; d.faria@aston.ac.uk; l.manso@aston.ac.uk
RI Rodriguez-Criado, Daniel/KPB-8411-2024; Faria, Diego R/B-4056-2011;
   Manso, Luis J./JQJ-4127-2023; Bachiller, Pilar/H-2476-2015
OI Rodriguez-Criado, Daniel/0000-0003-0562-531X; Manso, Luis
   J./0000-0003-2616-1120; Bachiller, Pilar/0000-0003-0690-7749
FU Spanish Government [RTI2018099522-BC42]; Government of Extremadura
   [GR18133, IB18056]
FX This work has partly been supported by grant RTI2018099522-BC42, from
   the Spanish Government, and by grants GR18133 and IB18056, from the
   Government of Extremadura.
CR Baghel R., 2020, WORKSH PHYS AG, P180, DOI 10.1007/978-3-030-62579-5_13
   Battaglia, 2018, ARXIV180601261
   Bhatt M, 2009, INT J ROBOT AUTOM, V24, P235, DOI 10.2316/Journal.206.2009.3.206-3274
   Charalampous K, 2017, ROBOT AUTON SYST, V93, P85, DOI 10.1016/j.robot.2017.03.002
   Chen C., 2019, ARXIV190913165
   Chen CG, 2019, IEEE INT CONF ROBOT, P6015, DOI [10.1109/ICRA.2019.8794134, 10.1109/icra.2019.8794134]
   Chen YF, 2017, IEEE INT C INT ROBOT, P1343, DOI 10.1109/IROS.2017.8202312
   Chen YY, 2020, IEEE ROBOT AUTOM LET, V5, P2754, DOI 10.1109/LRA.2020.2972868
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   Cosley D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1953
   Cucurull G., 2018, PROC INT C LEARN REP
   Ferrer G, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P331, DOI 10.1109/ECMR.2013.6698863
   Gilmer Justin, 2017, P 34 INT C MACH LEAR, P1263, DOI DOI 10.48550/ARXIV.1704.01212
   Gori M, 2005, IEEE IJCNN, P729
   Haddad S, 2020, IEEE WINT CONF APPL, P1140, DOI 10.1109/WACV45572.2020.9093456
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang YF, 2019, IEEE I CONF COMP VIS, P6281, DOI 10.1109/ICCV.2019.00637
   James S, 2019, PYREP BRINGING V REP
   Kipf TN, 2017, INT C LEARN REPR
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li Q, 2019, GRAPH NEURAL NETWORK
   Li Y., 2016, P 4 INT C LEARNING R
   Manso L., 2020, WORKSH PHYS AG, P167
   Manso LJ, 2020, DATA, V5, DOI 10.3390/data5010007
   Martins GS, 2019, IEEE INT CONF ROBOT, P9624, DOI [10.1109/ICRA.2019.8794262, 10.1109/icra.2019.8794262]
   Neunert M, 2016, IEEE INT CONF ROBOT, P1398, DOI 10.1109/ICRA.2016.7487274
   Pacchierotti E, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P164
   Paszke A, 2019, ADV NEUR IN, V32
   Patompak P, 2020, INT J SOC ROBOT, V12, P267, DOI 10.1007/s12369-019-00560-9
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Ramón-Vigo R, 2014, IEEE ROMAN, P774, DOI 10.1109/ROMAN.2014.6926347
   Rios-Martinez J, 2015, INT J SOC ROBOT, V7, P137, DOI 10.1007/s12369-014-0251-1
   Rodriguez-Criado D, 2020, ARXIV201105180
   Rodriguez-Criado D, 2020, MULTICAMERA TORSO PO
   Rohmer E, 2013, IEEE INT C INT ROBOT, P1321, DOI 10.1109/IROS.2013.6696520
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108
   Tranberg Hansen Soren, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P927, DOI 10.1109/ROMAN.2009.5326212
   Vasquez D, 2014, IEEE INT C INT ROBOT, P1341, DOI 10.1109/IROS.2014.6942731
   Vaswani A, 2017, ADV NEUR IN, V30
   Vega A, 2019, PATTERN RECOGN LETT, V118, P72, DOI 10.1016/j.patrec.2018.07.015
   Vemula A, 2018, IEEE INT CONF ROBOT, P4601
   Wang MX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P803
   Ying R, 2018, ADV NEUR IN, V31
NR 46
TC 11
Z9 13
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3277
EP 3295
DI 10.1007/s11042-021-11113-6
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000663494600003
OA Green Submitted, Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Maksimovic, M
   Aichroth, P
   Cuccovillo, L
AF Maksimovic, Milica
   Aichroth, Patrick
   Cuccovillo, Luca
TI Detection and localization of partial audio matches in various
   application scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio matching; Partial audio matching; Duplicate detection; Provenance
   analysis; Metadata tracking; Copy-move-forgery
AB In this paper, we describe various application scenarios for archive management, broadcast/stream analysis, media search and media forensics which require the detection and accurate localization of unknown partial audio matches within items and datasets. We explain why they cannot be addressed with state-of-the-art matching approaches based on fingerprinting, and propose a new partial matching algorithm which can satisfy the relevant requirements. We propose two distinct requirement sets and hence two variants / settings for our proposed approach: One focusing on lower time granularity and hence lower computational complexity, to be able to deal with large datasets, and one focusing on fine-grain analysis for small datasets and individual items. Both variants are tested using distinct evaluation sets and methodologies and compared with a popular audio matching algorithm, thereby demonstrating that the proposed algorithm achieves convincing performance for the relevant application scenarios beyond the current state-of-the-art.
C1 [Maksimovic, Milica; Aichroth, Patrick; Cuccovillo, Luca] Fraunhofer IDMT, Ehrenbergstr 31, D-98693 Ilmenau, Germany.
RP Maksimovic, M (corresponding author), Fraunhofer IDMT, Ehrenbergstr 31, D-98693 Ilmenau, Germany.
EM milica.maksimovic@idmt.fraunhofer.de
RI Yeraliyeva, Bakhyt/ABJ-7322-2022
OI Yeraliyeva, Bakhyt/0000-0002-8680-7694; Cuccovillo,
   Luca/0000-0001-5559-6508; Gerhardt, Milica/0000-0003-0017-9656;
   Aichroth, Patrick/0000-0003-4777-6335
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Allamanche E., 2001, P INT S MUS INF RETR, P197
   Anguera X., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P455, DOI 10.1109/ICME.2012.137
   [Anonymous], 2018, Free Spoken Digit Dataset (FSDD)
   Bisio I, 2015, IEEE T MOBILE COMPUT, V14, P14, DOI 10.1109/TMC.2013.79
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Chandrasekhar Vijay., 2011, ISMIR, V20, P801
   Covell M, 2007, INT CONF ACOUST SPEE, P237
   Ellis d, 2014, AUDFPRINT LANDMARK B
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gomez E, 2002, P INT TEL S NAT BRAS
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Heritier m, 2009, NIST TREC VID RETR E
   Imran M, 2017, IEEE ACCESS, V5, P12843, DOI 10.1109/ACCESS.2017.2717842
   Jégou H, 2012, INT CONF ACOUST SPEE, P2369, DOI 10.1109/ICASSP.2012.6288391
   Ke Y, 2005, PROC CVPR IEEE, P597
   Liu ZH, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P625, DOI 10.1109/DSC.2017.11
   Maksimovic M, 2018, INT WORK CONTENT MUL
   Maksimovic M, 2017, IEEE INT CON MULTI, P1165, DOI 10.1109/ICME.2017.8019547
   Malekesmaeili M, 2012, IEEE INT WORKSH MULT, P136, DOI 10.1109/MMSP.2012.6343429
   Mihcak M., 2001, Information Hiding, V2137, P51
   NIST, 2020, TREC VID RETR EV TRE
   Nucci M, 2013, IEEE INT WORKSH MULT, P99, DOI 10.1109/MMSP.2013.6659271
   Ouali C, 2014, INT WORK CONTENT MUL
   Ouali C, 2016, IEEE-ACM T AUDIO SPE, V24, P1106, DOI 10.1109/TASLP.2016.2541303
   Sonnleitner R, 2016, IEEE-ACM T AUDIO SPE, V24, P409, DOI 10.1109/TASLP.2015.2509248
   Wang A.L., 2003, P ISMIR 2003 4 INT C, P7
   Yan Q, 2015, INT CONF ACOUST SPEE, P1782, DOI 10.1109/ICASSP.2015.7178277
NR 27
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22619
EP 22641
DI 10.1007/s11042-020-09912-4
EA JUN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000663494600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, J
   Yu, ZY
   Duan, ZZ
   Lu, GD
AF Wang, Jin
   Yu, Zhiyong
   Duan, Zhizhao
   Lu, Guodong
TI A sub-region one-to-one mapping (SOM) detection algorithm for glass
   passivation parts wafer surface low-contrast texture defects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPP wafer detection; Texture features; Image matching; Sub-region
   mapping; Feature extraction; Defect detection
ID IMAGE; FEATURES
AB Glass Passivation Parts (GPP) wafer texture defects are one of the most important factors affecting the accuracy of wafer defect detection. Template matching has local errors and low efficiency, and deep learning requires many training samples. In the early stage, defect training sample sets cannot be provided. This paper discusses the design of an effective GPP wafer grain region texture defect detection algorithm using a sub-region one-to-one mapping. A set of standard wafer datum is selected as the reference of grain region segmentation detection, and then the standard wafer images and test GPP wafer images are automatically calibrated and segmented, respectively. Then, a series of pre-processes were performed to equalize the sizes of the two grain-region images. Then the grain region was divided into an equal number of rectangular sub-regions of the same size according to the measurement precision requirement. The correlation degree of each test sub-region is judged by the designed three-channel RGB gray-scale similarity decision functions. Experiments show that the algorithm successfully achieved the necessary calibration and segmentation for the grain region. Compared with the template and histogram matching algorithms, the proposed method does not require a training set, the detection accuracy is significantly improved and the detection efficiency is up to 29.74 times better on average using the proposed algorithm.
C1 [Wang, Jin; Yu, Zhiyong; Duan, Zhizhao; Lu, Guodong] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wang, J (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
EM dwjcom@zju.edu.cn
FU National Key R&D Program of China [2017YFB1301203]; National Natural
   Science Foundation of China [51775492]; Key R&D Program of Zhejiang
   Province [2020C01026]; Robotics Institute of Zhejiang University
   [K11808, K11811]
FX this paper was supported by the National Key R&D Program of China
   (2017YFB1301203), National Natural Science Foundation of China
   (51775492), the Key R&D Program of Zhejiang Province (No. 2020C01026),
   and Robotics Institute of Zhejiang University (No. K11808 and K11811).
CR Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Cuche E, 2000, APPL OPTICS, V39, P4070, DOI 10.1364/AO.39.004070
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Jian CX, 2017, APPL SOFT COMPUT, V52, P348, DOI 10.1016/j.asoc.2016.10.030
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kim D, 2012, EXPERT SYST APPL, V39, P4075, DOI 10.1016/j.eswa.2011.09.088
   Kim JS, 2019, IEEE T SEMICONDUCT M, V32, P39, DOI 10.1109/TSM.2018.2870253
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin YH, 2008, PATTERN RECOGN, V41, P2413, DOI 10.1016/j.patcog.2008.01.017
   Loce R P, 2005, U.S. Patent, Patent No. [6,944,341[P], 6944341]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Meli L, 2017, INT SOC OPTICS PHOTO, V10143
   Meli L, 2017, IEEE T SEMICONDUCT M, V30, P402, DOI 10.1109/TSM.2017.2759759
   See Judi E., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P262, DOI 10.1177/1541931213601548
   Smit RJM, 1998, COMPUT METHOD APPL M, V155, P181, DOI 10.1016/S0045-7825(97)00139-4
   TANIMOTO SL, 1981, COMPUT VISION GRAPH, V16, P356, DOI 10.1016/0146-664X(81)90046-0
   Tello G, 2018, IEEE T SEMICONDUCT M, V31, P315, DOI 10.1109/TSM.2018.2825482
   Tsai DM, 2019, IEEE T COMP PACK MAN, V9, P163, DOI 10.1109/TCPMT.2018.2873744
   Wang MJJ, 2004, IEEE T SEMICONDUCT M, V17, P444, DOI 10.1109/TSM.2004.831943
   Yong P B, 2018, U.S. Patent Application, Patent No. [10/014,229[P], 10014229]
   Zhong FQ, 2017, INT J ADV MANUF TECH, V93, P55, DOI 10.1007/s00170-015-7638-5
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 23
TC 8
Z9 8
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28879
EP 28896
DI 10.1007/s11042-021-11084-8
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661366900003
DA 2024-07-18
ER

PT J
AU Lang, RN
   Zhu, SH
   Wang, DS
AF Lang, Runnan
   Zhu, Songhao
   Wang, Dongsheng
TI Pitch contours curve frequency domain fitting with vocabulary matching
   based music generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music Generation; Frequency domain characteristics; Long-term structure
ID ADVERSARIAL NETWORKS
AB In this paper, we present a whole new perspective on generating music. The method proposed in this paper is the first to be used which uses the frequency domain characteristics of pitch contour curve to generate music melody with long-term structure controllable. The music generated by this method has a good long-term structure that other basic music generation methods do not have. This method has great development potential and application ability, can be combined with other music generation methods, and improve the performance of long-term structure. This method firstly uses the neural network to fit the pitch contour curve in frequency domain, then combines the vocabulary matching method to perfect the detailed characteristics of melody generated in time domain and control the long-term trend of notes generated with respect to label information, finally generates music melody with real and controllable long-term structure. Through a large number of experiments, it can be seen that compared with the music generated based on the LSTM, the music generated by the proposed method has better long-term structure and has similar statistical characteristics.
C1 [Lang, Runnan; Zhu, Songhao; Wang, Dongsheng] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Peoples R China.
EM zhush@njupt.edu.cn
CR Ammari T, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3311956
   [Anonymous], 2003, Proceedings of the AISB Symposium on Artificial Intelligence and Creativity in the Arts and Sciences
   Bittner RM, 2017, 2017 AES INTERNATIONAL CONFERENCE ON SEMANTIC AUDIO
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen CJ, 2014, U.S. Patent, Patent No. [8,886,539, 8886539]
   Chen K, 2019, 2019 INTERNATIONAL WORKSHOP ON MULTILAYER MUSIC REPRESENTATION AND PROCESSING (MMRP 2019), P77, DOI [10.1109/MMRP.2019.8665362, 10.1109/MMRP.2019.00022]
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hadjeres G., 2017, 2017 IEEE S SER COMP, P1, DOI 10.1109/SSCI.2017.8280895
   Hiller L. A., 1959, Experimental Music: Composition with an Electronic Computer, DOI 10.2307/842857
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsieh TH, 2019, INT CONF ACOUST SPEE, P156, DOI 10.1109/ICASSP.2019.8682389
   Jeon W, 2011, INT CONF ACOUST SPEE, P2304
   Jiang JY, 2020, INT CONF ACOUST SPEE, P516, DOI [10.1109/ICASSP40776.2020.9054554, 10.1109/icassp40776.2020.9054554]
   Keerti, 2020, ARXIV PREPRINT ARXIV
   Lim, 2017, ARXIV PREPRINT ARXIV
   Mangal, 2019, ARXIV PREPRINT ARXIV
   Ouyang P, 2017, DES AUT CON, DOI 10.1145/3061639.3062187
   Razavi A, 2019, ADV NEUR IN, V32
   Salamon J., 2012, 13th Int. Soc. for Music Info. Retrieval Conf, P187
   Salamon J, 2012, IEEE T AUDIO SPEECH, V20, P1759, DOI 10.1109/TASL.2012.2188515
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Wu J, 2020, IEEE T CYBERNETICS, V50, P2749, DOI 10.1109/TCYB.2019.2953194
   Yamshchikov, 2017, ARXIV PREPRINT ARXIV
   Yang L.-C., 2017, ARXIV PREPRINT ARXIV, P324
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
NR 27
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28463
EP 28486
DI 10.1007/s11042-021-11049-x
EA JUN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658077800002
DA 2024-07-18
ER

PT J
AU Ben Rabah, C
   Coatrieux, G
   Abdelfattah, R
AF Ben Rabah, Chaima
   Coatrieux, Gouenou
   Abdelfattah, Riadh
TI Automatic source scanner identification using 1D convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source scanner identification; Scanned documents; Sensor pattern noise;
   Multimedia forensics; Convolutional neural network; Deep learning
AB In this digital world, digitized documents can be considered original or a piece of evidence; checking the authenticity of any suspicious image has become an unavoidable concern to preserve the trust in its legitimacy. However, identifying the source of a digital image without any prior embedded information is a very challenging task. This paper proposes a novel one-dimensional convolutional neural network (1D-CNN) model to solve the source scanner identification (SSI) problem blindly. Unlike traditional methods based on handcrafted features, the proposed framework can dynamically learn and extract scanner device-specific features. This work, comprised of the 1D-CNN and a support vector machine (SVM) as a classifier, was trained on nine scanners of different brands and models. The experimental result shows that our model achieves 98.15% accuracy on full images and overall accuracy of 93.13% on segments from test images, outperforming other state-of-art approaches. Our model also proves to be able to distinguish between scanners of the same model. Furthermore, the SVM classifier improved the 1D-CNN accuracy by approximately 3% compared to its original configuration.
C1 [Ben Rabah, Chaima; Coatrieux, Gouenou; Abdelfattah, Riadh] IMT Atlantique, LaTIM Inserm UMR1101, Technopole Brest Iroise, CS 83818, F-29238 Brest 3, France.
   [Ben Rabah, Chaima; Abdelfattah, Riadh] Univ Carthage, Higher Sch Commun Tunis, COSIM Lab, El Ghazala City 2083, Ariana, Tunisia.
C3 Institut National de la Sante et de la Recherche Medicale (Inserm); IMT
   - Institut Mines-Telecom; IMT Atlantique; Universite de Carthage
RP Ben Rabah, C (corresponding author), IMT Atlantique, LaTIM Inserm UMR1101, Technopole Brest Iroise, CS 83818, F-29238 Brest 3, France.; Ben Rabah, C (corresponding author), Univ Carthage, Higher Sch Commun Tunis, COSIM Lab, El Ghazala City 2083, Ariana, Tunisia.
EM Chaima.ben-rabah@imt-atlantique.fr
RI Ben Rabah, Chaima/GVS-9269-2022
FU French Ministry of Foreign Affairs and Ministry of higher education and
   research; Tunisian Ministry of higher education and scientific research
   in the CMCU [17G1405]
FX This work was financially supported by the "PHC Utique" program of the
   French Ministry of Foreign Affairs and Ministry of higher education and
   research and the Tunisian Ministry of higher education and scientific
   research in the CMCU project number 17G1405.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Abdelfattah, TRAIT SIGNAL
   Al Banna MH, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P626, DOI [10.1109/ICREST.2019.8644194, 10.1109/icrest.2019.8644194]
   Alain Guillaume, 2018, Understanding intermediate layers using linear classifier probes
   Arkah ZM, 2018, INT C INT SYST DES A, P1093
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Ben Rabah Chaima, 2019, 2019 International Conference on Internet of Things, Embedded Systems and Communications (IINTEC). Proceedings, P220, DOI 10.1109/IINTEC48298.2019.9112109
   Ben Rabah C, 2020, TRAIT SIGNAL, V37, P881, DOI 10.18280/ts.370601
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chollet F., 2015, Keras
   Damshenas M., 2014, Int. J. Cyber-Secur. Digit. Forensic, V3, P209
   Delp, 2007, SECURITY STEGANOGRAP, V6505, p65051K
   Ding XH, 2019, IEEE ACCESS, V7, P25878, DOI 10.1109/ACCESS.2019.2897360
   Egiazarian K, 2006, P 2 INT WORKSH VID P
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Gloe T, 2007, PROC SPIE, V6505, DOI 10.1117/12.704165
   Gumilang M, 2018, 2018 3 INT C INFORMA, P1
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Holst G.C., 1998, CCD arrays, cameras, and displays, V2nd
   Joshi Joshi S. S., NAT C COMP VIS PATT, V841 841, P281
   Khanna N, 2009, IEEE T INF FOREN SEC, V4, P123, DOI 10.1109/TIFS.2008.2009604
   Kim DG, 2019, NEUROCOMPUTING, V365, P219, DOI 10.1016/j.neucom.2019.07.084
   Kingma D. P., 2014, arXiv
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Krasnyanskiy M., 2018, INT MULT SCI GEOCONF, V18, P765
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Li Y, 2019, 2019 23 INT COMP SCI
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu AN, 2019, MULTIMED TOOLS APPL, V78, P26851, DOI 10.1007/s11042-016-4251-z
   Loc CV, 2018, INT CONF FRONT HAND, P303, DOI 10.1109/ICFHR-2018.2018.00060
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Mazumdar A, 2019, LECT NOTES COMPUT SC, V11941, P226, DOI 10.1007/978-3-030-34869-4_25
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rahim N, 2020, ADV INTELL SYST COMP, V978, P283, DOI 10.1007/978-3-030-36056-6_28
   Salau A. O., 2020, Accent classification of the three major nigerian indigenous languages using 1D CNN LSTM network model, P1, DOI [10.1007/978-981-15-2620-6_1, DOI 10.1007/978-981-15-2620-6_1]
   Sameer VU, 2020, MULTIMED TOOLS APPL, V79, P28079, DOI 10.1007/s11042-020-09106-y
   Sameer VU, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2660, DOI 10.1109/WiSPNET.2017.8300246
   Singh M. Tarsem, 2015, 2015 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2015.7157445
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sugawara S, 2014, FORENSIC SCI INT, V241, P69, DOI 10.1016/j.forsciint.2014.04.018
   Tang Y, 2015, DEEP LEARNING USING
   Tsai MJ, 2019, SIGNAL PROCESS-IMAGE, V70, P184, DOI 10.1016/j.image.2018.09.006
   Wikipedia Contributors, 2020, RADIAL BASIS FUNCTIO
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zou ZY, 2019, PROCEEDINGS OF 2019 2ND INTERNATIONAL CONFERENCE ON BIG DATA TECHNOLOGIES (ICBDT 2019), P211, DOI 10.1145/3358528.3358578
NR 47
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22789
EP 22806
DI 10.1007/s11042-021-10973-2
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000657212500003
DA 2024-07-18
ER

PT J
AU Li, X
   Lu, PX
   Hu, LT
   Wang, XG
   Lu, L
AF Li, Xin
   Lu, Peixin
   Hu, Lianting
   Wang, XiaoGuang
   Lu, Long
TI A novel self-learning semi-supervised deep learning network to detect
   fake news on social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake&#8201; news; Social &#8201; media; Semi-supervised&#8201;
   deep&#8201; learning&#8201; network; Confidence values
AB Social media has become a popular means for people to consume and share news. However, it also enables the extensive spread of fake news, that is, news that deliberately provides false information, which has a significant negative impact on society. Especially recently, the false information about the new coronavirus disease 2019 (COVID-19) has spread like a virus around the world. The state of the Internet is forcing the world's tech giants to take unprecedented action to protect the "information health" of the public. Despite many existing fake news datasets, comprehensive and effective algorithms for detecting fake news have become one of the major obstacles. In order to address this issue, we designed a self-learning semi-supervised deep learning network by adding a confidence network layer, which made it possible to automatically return and add correct results to help the neural network to accumulate positive sample cases, thus improving the accuracy of the neural network. Experimental results indicate that our network is more accurate than the existing mainstream machine learning methods and deep learning methods.
C1 [Li, Xin; Lu, Peixin; Hu, Lianting; Wang, XiaoGuang; Lu, Long] Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
C3 Wuhan University
RP Lu, L (corresponding author), Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
EM XinLi2020@whu.edu.cn; Lupx@whu.edu.cn; LiantingHu@whu.edu.cn;
   whu_wxg@126.com; lulong@whu.edu.cn
RI Hu, Lianting/KOC-2697-2024
OI Hu, Lianting/0000-0003-4573-3809
FU National Natural Science Foundation of China [61772375, 61936013,
   71921002]; National Social Science Fund of China [18ZDA325]; National
   Key R&D Program of China [2019YFC0120003]; Natural Science Foundation of
   Hubei Province of China [2019CFA025]; Independent Research Project of
   School of Information Management Wuhan University [413100032]
FX This research was funded by National Natural Science Foundation of China
   (61772375, 61936013, 71921002), The National Social Science Fund of
   China (18ZDA325), National Key R&D Program of China (2019YFC0120003),
   Natural Science Foundation of Hubei Province of China (2019CFA025); and
   Independent Research Project of School of Information Management Wuhan
   University (413100032).
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Mitra T, 2015, ICWSM 15
   Okoro E.M., 2018, Nigerian Journal of Technology, V37, P454, DOI [10.4314/njt.v37i2.22, DOI 10.4314/NJT.V37I2.22]
   Papanastasiou Y, 2017, SSRN ELECT J
   Rashed KAN, 2014, MULTIMED TOOLS APPL, V70, P1069, DOI 10.1007/s11042-012-1103-3
   Reis JCS, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P17, DOI 10.1145/3292522.3326027
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Santia GC, 2018, ICWSM 18
   Shu K., 2017, ARXIV PREPRINT ARXIV
   Shu K, 2018, FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media
   Singh L., 2020, ARXIV200313907
   Tacchini Eugenio, 2017, ARXIV170407506, P1, DOI [10.48550/arXiv.1704.07506, DOI 10.1257/JEP.31.2.211]
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Yang Y., 2018, Ti-cnn: Convolutional neural networks for fake news detection
   Zhang Jiawei, 2018, ARXIV180508751
NR 21
TC 19
Z9 19
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19341
EP 19349
DI 10.1007/s11042-021-11065-x
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000657212500001
PM 34093070
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhao, DX
   Qi, ZY
   Yang, RX
   Wang, ZH
AF Zhao, Dexin
   Qi, Zhiyang
   Yang, Ruixue
   Wang, Zhaohui
TI Attention-based dual context aggregation for image semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Attention module; Contextual information;
   Long-range dependencies
AB Recent works have extensively probed contextual relevance to enhance the scene understanding. However, most approaches tend to model the relationships between local regions due to the limitation of the convolution kernel, while rarely exploring long-range dependencies. In this paper, we come up with the Dual Context Aggregation Module (DCM) to effectively capture such important information. DCM splits into two attention modules to obtain dense contextual information via modeling relations between positions and channels. The spatial attention module generates huge attention maps by constructing pairwise relationships between positions in the same row or column. The channel attention module applies the Weight Calibrate Block to generate weights for all the channels to effectively get the correlation between different channels. We adopt an element addition to integrate the feature maps of the two modules. Moreover, we design a two-step decoder module to improve the feature representation. On the basis of these developments, we construct the Dual Context aggregation Network (DCNet). Extensive evaluation experiments on the benchmarks prove that our model leads to robust feature representation. Our method demonstrates competitive performance compared to state-of-the-art models, achieving the MIoU scores of 81.9% on Cityscapes and 45.54% on ADE20K.
C1 [Zhao, Dexin; Qi, Zhiyang; Yang, Ruixue; Wang, Zhaohui] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology
RP Qi, ZY (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM zhaodexin@email.tjut.edu.cn; qzy@stud.tjut.edu.cn;
   yangruixue@stud.tjut.edu.cn; wangzhaohuigg@163.com
CR [Anonymous], CoRR abs/1511.07122
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bulò SR, 2018, PROC CVPR IEEE, P5639, DOI 10.1109/CVPR.2018.00591
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LJ, 2018, ADV NEUR IN, V31
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Fan H, 2018, IEEE T INTELL TRANSP, V19, P3475, DOI 10.1109/TITS.2017.2775628
   Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Jun, 2019, IEEE Trans Image Process, DOI 10.1109/TIP.2019.2895460
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Y, 2020, PINT S NEUR NETW, P97
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yu Changqian, 2020, ARXIV200402147
   Yuan Y., 2018, ARXIV PREPRINT ARXIV
   Zhang H., 2018, ARXIV180508318
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang YH, 2020, IEEE INT CONF AUTOMA, P356, DOI 10.1109/FG47880.2020.00134
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 37
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28201
EP 28216
DI 10.1007/s11042-021-11094-6
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000656821700001
DA 2024-07-18
ER

PT J
AU Xu, J
   Mou, J
   Xiong, L
   Li, P
   Hao, J
AF Xu, Ji
   Mou, Jun
   Xiong, Li
   Li, Peng
   Hao, Jin
TI A flexible image encryption algorithm based on 3D CTBCS and DNA
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Discrete chaotic system; DNA encryption; Arnold matrix
   confusion-diffusion
ID CHAOTIC SYSTEM; COMPRESSION; PERMUTATION
AB In this paper, a novel image encryption algorithm based on a new discrete chaotic system is presented. The chaotic characteristics of the new chaotic system are analyzed by phase diagram, Lyapunov exponent, bifurcation diagram and complexity analysis. The randomness of chaotic sequences is test by the NIST SP 800-22 test package. The calculation time with different length sequence is recorded. Based on the analyses results, a flexible encryption scheme is designed for 2D image and 3D image. The hash value which is calculated from the SHA-256 hash function is used to change the initial conditions of the discrete system firstly. And then, the chaotic sequences are used to scramble and spread the value for the images by Arnold matrix and DNA diffusion algorithm. The security analysis shows that the proposed encryption algorithm possesses higher security features to preserve the subject and resist conventional attack. The results of this paper offer a different realization scheme for protection of image files.
C1 [Xu, Ji; Mou, Jun; Xiong, Li; Li, Peng; Hao, Jin] Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
C3 Dalian Polytechnic University
RP Mou, J (corresponding author), Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
EM moujun@csu.edu.cn
OI Mou, Jun/0000-0002-7774-2833
FU Natural Science Foundation of Liaoning province [2020-MS-274]
FX The Natural Science Foundation of Liaoning province(2020-MS-274)
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Al Sharif S, 2016 8 IFIP INT C NE, P1
   Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Ambrosi A, 2016, CHEM SOC REV, V45, P2740, DOI 10.1039/c5cs00714c
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Brown AC, 2013, AFRICON, P694
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Du JR, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9106132
   Eluard M., 2013, Actes de COmpression et REprsent. des Signaux Audiov., P7, DOI [10.13140/RG.2.1.3925.6165, DOI 10.13140/RG.2.1.3925.6165]
   GOGGIN ME, 1990, PHYS REV A, V41, P5705, DOI 10.1103/PhysRevA.41.5705
   Gong LH, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501424
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Hui Liu, 2017, International Journal of Network Security, V19, P347, DOI 10.6633/IJNS.201703.19(3).04
   Jin X, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9266-1
   Kaminsky W, 2014, POWDER DIFFR, V29, pS42, DOI 10.1017/S0885715614001092
   Lan R, 2018, IEEE T CYBERN
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P115, DOI 10.1109/TCYB.2019.2952710
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Liu WH, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501711
   Liu WH, 2017, NONLINEAR DYNAM, V89, P2521, DOI 10.1007/s11071-017-3601-3
   del Rey AM, 2015, LECT NOTES ARTIF INT, V9121, P427, DOI 10.1007/978-3-319-19644-2_36
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Melchels FPW, 2010, BIOMATERIALS, V31, P6121, DOI 10.1016/j.biomaterials.2010.04.050
   Millérioux G, 2008, IEEE T CIRCUITS-I, V55, P1695, DOI 10.1109/TCSI.2008.916555
   Mou J, 2021, MOBILE NETW APPL, V26, P1849, DOI 10.1007/s11036-019-01293-9
   Mukhopadhyay S, 2020, CHAOS, V30, DOI 10.1063/5.0009326
   Raj B, 2019, LECT NOTE DATA ENG, V29, P322, DOI 10.1007/978-3-030-12839-5_29
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Ventola C Lee, 2014, P T, V39, P704
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P33865, DOI 10.1007/s11042-019-08171-2
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xin Jin, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P119, DOI 10.1007/978-3-319-48890-5_12
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yang FF, 2019, PHYS SCRIPTA, V94, DOI 10.1088/1402-4896/ab0033
   Yu F, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501473
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang LM, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/10/100504
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 54
TC 6
Z9 6
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25711
EP 25740
DI 10.1007/s11042-021-10764-9
EA APR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642389000001
DA 2024-07-18
ER

PT J
AU Pak, C
   Kim, J
   Pang, R
   Song, O
   Kim, H
   Yun, I
   Kim, J
AF Pak, Chanil
   Kim, Jongtae
   Pang, Ryusung
   Song, Okchol
   Kim, Huigon
   Yun, Ilgwon
   Kim, Jinsim
TI A new color image encryption using 2D improved logistic coupling map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Chaotic system; Image encryption
ID CHAOTIC SYSTEM; SCHEME; ALGORITHM; PERMUTATION; LEVEL; LORENZ
AB This paper proposes a new 2D-ILCM (Two Dimension Improved Logistic Coupling Map) based on preceding works and performed the performance evaluation. Experimental results show that the proposed 2D-ILCM has better chaotic characteristics than the existing 2D chaotic maps. In order to confirm the application of the proposed 2D-ILCM to image encryptions, we propose a new image encryption algorithm which is simple in structure and combines bit level permutation, and pixel level diffusion and confirm the performance through experiments. Experimental results show that the proposed algorithm is robust to attacks and gives a good performance.
C1 [Pak, Chanil; Kim, Jongtae; Pang, Ryusung; Song, Okchol; Kim, Huigon] Kim Chaek Univ Technol, Inst Informat Technol, Pyongyang 950003, DEM REP CONGO.
   [Yun, Ilgwon; Kim, Jinsim] Kim Chaek Univ Technol, Int Technol Cooperat Ctr, Pyongyang 950003, DEM REP CONGO.
RP Pak, C (corresponding author), Kim Chaek Univ Technol, Inst Informat Technol, Pyongyang 950003, DEM REP CONGO.
EM pchi75826@star-co.net.kp
OI Pak, Chanil/0000-0003-2344-6438
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Ben Slimane N, 2018, MULTIMED TOOLS APPL, V77, P30993, DOI 10.1007/s11042-018-6145-8
   Bensikaddour EH, 2020, J KING SAUD UNIV-COM, V32, P50, DOI 10.1016/j.jksuci.2018.05.002
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Essaid M, 2019, J INF SECUR APPL, V47, P173, DOI 10.1016/j.jisa.2019.05.006
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kumar R. Ranjith, 2014, ICTACT J IMAGE VIDEO, V4, P795, DOI [10.21917/ijivp.2014.0114, DOI 10.21917/IJIVP.2014.0114]
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   NPCR YWu., 2011, JSAT, V4, P31
   Nunez JA, 1996, CELEST MECH DYN ASTR, V64, P43, DOI 10.1007/BF00051604
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Vidhya R, 2019, CHINESE J PHYS, V62, P26, DOI 10.1016/j.cjph.2019.09.011
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2016, OPT LASER ENG, V86, P248, DOI 10.1016/j.optlaseng.2016.06.008
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wen WY, 2015, OPT COMMUN, V341, P131, DOI 10.1016/j.optcom.2014.12.026
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan HM, 2017, SIGNAL PROCESS-IMAGE, V52, P87, DOI 10.1016/j.image.2017.01.002
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 51
TC 12
Z9 12
U1 3
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25367
EP 25387
DI 10.1007/s11042-021-10660-2
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600007
DA 2024-07-18
ER

PT J
AU Li, RL
   Zhang, YZ
   Zhu, SD
   Liu, SW
AF Li, Ruilong
   Zhang, Yunzhou
   Zhu, Shangdong
   Liu, Shuangwei
TI Person search via class activation map transferring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Person search; Pedestrian detection; Knowledge
   distillation; Multi-task learning
ID NEURAL-NETWORK
AB The methods to tackle person search problem can be divided into two categories. One is to train an end-to-end person search model to search target person from scene images. The other is to train a detection model and a re-identification (re-ID) model, which are then cascaded to locate and crop persons in scene images and find target person from cropped person images. Training a detection model and a re-ID model separately to achieve person search can avoid the conflict of optimizing different losses in multi-task learning. However, the cascading solutions usually cost more time and have more parameters than the end-to-end solutions. To take advantages and avoid disadvantages of cascading person search methods, we intend to use the knowledge distillation method to teach the end-to-end person search model by using the Class Activation Map of the well-trained person re-ID model as an auxiliary supervise signal and loading well-trained pedestrian detection as a pre-trained model. Besides, we adjust the spatial size of the feature map and select Resnet models to make the student model have higher performance or faster inference speed. Experimental results show that the mAP performance of our framework outperforms the state-of-the-art methods on the PRW dataset.
C1 [Li, Ruilong; Zhang, Yunzhou; Liu, Shuangwei] Northeastern Univ China, Coll Informat Sci & Engn, Shenyang, Peoples R China.
   [Zhu, Shangdong] Northeastern Univ China, Fac Robot Sci & Engn, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Zhang, YZ (corresponding author), Northeastern Univ China, Coll Informat Sci & Engn, Shenyang, Peoples R China.
EM rl_li@foxmail.com; zhangyunzhou@ise.neu.edu.cn; zhushangdong@gmail.com;
   1700915@stu.neu.cn
OI Zhu, Shangdong/0000-0003-4701-2028
FU Fundation of Key Laboratory of Aerospace System Simulation
   [6142002200301]; Fundation of Key Laboratory of Equipment Reliability
   [61420030302]; Distinguished Creative Talent Program of Liaoning
   Colleges and Universities [LR2019027]; Fundamental Research Funds for
   the Central Universities [N172608005, N182608004, N2004022]
FX This work is supported by Fundation of Key Laboratory of Aerospace
   System Simulation(6142002200301), Fundation of Key Laboratory of
   Equipment Reliability(61420030302), Distinguished Creative Talent
   Program of Liaoning Colleges and Universities (LR2019027) and
   Fundamental Research Funds for the Central Universities(N172608005,
   N182608004, N2004022).
CR [Anonymous], IEEE Journals & Magazine
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chen D, 2020, AAAI CONF ARTIF INTE, V34, P10518
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean J., 2015, NIPS DEEP LEARNING R
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   He HL, 2017, PR IEEE I C PROGR IN, P455, DOI 10.1109/PIC.2017.8359591
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZW, 2019, LECT NOTES COMPUT SC, V11362, P349, DOI 10.1007/978-3-030-20890-5_23
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   LI QQ, 2017, PROC CVPR IEEE, P7341, DOI DOI 10.1109/CVPR.2017.776
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu S., 2019, CVPR
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang XJ, 2020, MULTIMED TOOLS APPL, V79, P9299, DOI 10.1007/s11042-019-7387-9
   Zhai SL, 2019, MULTIMED TOOLS APPL, V78, P31605, DOI 10.1007/s11042-019-07939-w
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 42
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24271
EP 24286
DI 10.1007/s11042-021-10863-7
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636427800001
DA 2024-07-18
ER

PT J
AU Atta, R
   Ghanbari, M
   Elnahry, I
AF Atta, Randa
   Ghanbari, Mohammad
   Elnahry, Ibrahim
TI Advanced image steganography based on exploiting modification direction
   and neutrosophic set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Edge detection; Neutrosophic set
AB A new variant of image steganography based on exploiting modification directions (EMD) named advanced EMD (AEMD) is introduced. In this method the secret digits in m(n) -ary notional systems are embedded into a group of n pixels of the cover image. To increase data hiding capacity, edge masking characteristics of human visual system is exploited to embed more bits at image edge pixels than non-edge pixels. To do this, a neutrosophic set edge detector, named as MNSED is also introduced to classify cover image into 2 x 2 non-overlapping edge and non-edge blocks without any overhead information. Hence the secret digits in two different bases are embedded into the edge and non-edge blocks. Experimental results show that the proposed method provides higher embedding capacity and better quality compared to the existing schemes, while its resistance to steganographic attack is still higher.
C1 [Atta, Randa; Elnahry, Ibrahim] Port Said Univ, Elect Engn Dept, Port Said 42523, Egypt.
   [Ghanbari, Mohammad] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Egyptian Knowledge Bank (EKB); Port Said University; University of
   Tehran; University of Essex
RP Atta, R (corresponding author), Port Said Univ, Elect Engn Dept, Port Said 42523, Egypt.
EM r.atta@eng.psu.edu.eg; ghan@ut.ac.ir; ibrahim.farouk@eng.psu.edu.eg
RI Atta, Randa/I-8824-2019; Ghanbari, Mohammad/L-4053-2019
OI Atta, Randa/0000-0001-8294-7780; Ghanbari, Mohammad/0000-0002-5482-8378
CR Ahani S, 2015, IET IMAGE PROCESS, V9, P496, DOI 10.1049/iet-ipr.2014.0351
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Gubbi A, 2012, FUZZY INFERENCE SYST, P297
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Kaur K., 2010, INT J COMPUT APPL, V1, P57, DOI [10.5120/442-675, DOI 10.5120/442-675]
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Kuo WC, 2012, THIRD INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND INTELLIGENT CONTROL (ISIC 2012), P286, DOI 10.1109/ISIC.2012.6449762
   Lee C., 2015, INT J NETW SECURITY, V17, P607
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Niu XJ, 2015, INT J SECUR APPL, V9, P243, DOI 10.14257/ijsia.2015.9.5.24
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Saha S, 2018, ELECTRON LETT, V54, P498, DOI 10.1049/el.2017.3336
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Sahu AK, 2019, 3D RES, V10, DOI 10.1007/s13319-018-0211-x
   Sahu AK, 2018, CYBERN INF TECHNOL, V18, P69, DOI 10.2478/cait-2018-0006
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Suryakant N. K., 2012, Int. J. Adv. Res. Comput. Sci. Software Eng., V2, P38
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 37
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21751
EP 21769
DI 10.1007/s11042-021-10784-5
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630647100003
DA 2024-07-18
ER

PT J
AU Dakshayini, M
   Rashmi, R
AF Dakshayini, M.
   Rashmi, R.
TI Hierarchical cooperative-peers fog caching strategy to improve the
   performance of content centric networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content centric networking; Content packet; Interest packet; Peer nodes;
   Central content server
AB Content Centric Networking (CCN) is a novel paradigm to address challenges faced by traditional TCP/IP architecture. The motivation behind CCN is its inherent feature of caching. Caching at intermediate nodes is essential to reduce delay and to enhance performance of the network. However, determining as to how and where content should be cached to achieve this is the major challenge in CCN architecture. In this paper, we have proposed a Hierarchical Cooperative-peers Architecture (HCPA) and effective caching approaches to reduce the response time and increase the cache hit rate alleviating the server bottleneck and network traffic. The main idea is to utilize the resources of fog peer nodes near the user to deal with high latency and low bandwidth issues of the current communication pattern. This is achieved by pooling the cache space of cooperative fog peers of a region with a Regional demand-based fog Caching (RDFC) approach in two folds. First implementation is with replicated caching (RC) and the second one is using unique caching (UC). Both these approaches are implemented using CcnSim and the performance is evaluated based on cache hit rate, response time and bandwidth usage which has shown the significant improvement in the performance of the network.
C1 [Dakshayini, M.; Rashmi, R.] BMS Coll Engn, Dept ISE, Bangalore, Karnataka, India.
   [Dakshayini, M.; Rashmi, R.] VTU, Belgaum, India.
C3 BMS College of Engineering; Visvesvaraya Technological University
RP Dakshayini, M (corresponding author), BMS Coll Engn, Dept ISE, Bangalore, Karnataka, India.; Dakshayini, M (corresponding author), VTU, Belgaum, India.
EM dakshayini.ise@bmsce.ac.in; rashmir.ise@bmsce.ac.in
CR Bernardini C, 2014, 2014 IFIP NETWORKING CONFERENCE
   De Salve A, 2018, COMPUT SCI REV, V27, P154, DOI 10.1016/j.cosrev.2018.01.001
   Festor, 2015, IEEE GLOB COMMUN C G, V2015, P2015, DOI [10.1109/GLOCOM.2014.7417007, DOI 10.1109/GLOCOM.2014.7417007]
   Gupta A, 2016, INT J CHEM ENG, V2016, DOI 10.1155/2016/7086761
   Kaili, 2016, 2016 IEEE 27 ANN INT, P1, DOI [10.1109/PIMRC.2016.7794940, DOI 10.1109/PIMRC.2016.7794940]
   Lal N, 2019, COMPUT SCI REV, V31, P39, DOI 10.1016/j.cosrev.2018.11.001
   Du LP, 2017, 2017 31ST INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P628, DOI 10.1109/ICOIN.2017.7899573
   Li YH, 2013, INT CON DISTR COMP S, P62, DOI 10.1109/ICDCS.2013.71
   Li YQ, 2018, INT CONF UBIQ FUTUR, P159, DOI 10.1109/ICUFN.2018.8436597
   Li ZC, 2012, PROCEEDINGS OF THE ASME 6TH INTERNATIONAL CONFERENCE ON ENERGY SUSTAINABILITY - 2012, PTS A AND B, P1
   Mishra GP, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P198, DOI 10.1109/NGCT.2015.7375111
   Mishra GP, 2015, INT CONF COMM SYST, P925, DOI 10.1109/CSNT.2015.119
   Qiao XQ, 2014, CHINA COMMUN, V11, P24, DOI 10.1109/CC.2014.6895382
   QU H, 2018, 2017 17 IEEE INT C C, V2017, P1318, DOI DOI 10.1109/ICCT.2017.8359848
   Zhang M, 2015, IEEE COMMUN SURV TUT, V17, P1473, DOI 10.1109/COMST.2015.2420097
NR 15
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20345
EP 20368
DI 10.1007/s11042-021-10733-2
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700008
DA 2024-07-18
ER

PT J
AU Roy, P
   Chowdhury, C
AF Roy, Priya
   Chowdhury, Chandreyee
TI Designing an ensemble of classifiers for smartphone-based indoor
   localization irrespective of device configuration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor localization; RSS; Ensemble classifier; Base classifier; Neural
   Network; Back-propagation
ID CALIBRATION
AB WiFi-based indoor localization is a popular approach as most buildings and campuses are WiFi-enabled and its fingerprints are captured by smartphones carried by every individual. Due to the different WiFi sensitivity of the smartphones, an interesting challenge subject to varying ambient conditions emerges in this domain. Thus, a single supervised classifier may not be able to provide stable localization accuracy when the devices used for training and testing are different. Accordingly, a more generalized Neural Network-based Ensemble Learning for Indoor Localization System (NNELILS) is designed in this paper to address the challenge regarding device heterogeneity. NNELILS has a heterogeneous set of base classifiers and a Neural Network-based meta-classifier that combines the decisions of base classifiers. Accordingly, algorithms are proposed and implemented on real-life datasets. Our proposed system is found to improve the localization accuracy to 94% when the training and testing devices vary. It is even found to work better than the state-of-the-art approaches.
C1 [Roy, Priya; Chowdhury, Chandreyee] Jadavpur Univ, Comp Sci & Engn Dept, Kolkata, India.
C3 Jadavpur University
RP Chowdhury, C (corresponding author), Jadavpur Univ, Comp Sci & Engn Dept, Kolkata, India.
EM priyaroy.rs@jadavpuruniversity.in; chandreyee.chowdhury@gmail.com
RI Roy Karmakar, Priya/GLS-5145-2022
OI Roy Karmakar, Priya/0000-0001-8790-0017
FU State Government Fellowship scheme of Jadavpur University - Government
   of West Bengal, India; project entitled- "Developing Framework for
   Indoor Location Based Services with Seamless Indoor Outdoor Navigation
   by expanding Spatial Data Infrastructure" - Ministry of Science and
   Technology, Department of Science and Technology, NGP Division,
   Governmen [NRDMS/UG/NetworkingProject/e-13/2019(G)]
FX This research work is supported by the State Government Fellowship
   scheme of Jadavpur University funded by Government of West Bengal, India
   and the project entitled- "Developing Framework for Indoor Location
   Based Services with Seamless Indoor Outdoor Navigation by expanding
   Spatial Data Infrastructure", funded by the Ministry of Science and
   Technology, Department of Science and Technology, NGP Division,
   Government of India, ref no. NRDMS/UG/NetworkingProject/e-13/2019(G). We
   would like to thank Mr. Mausam Kundu for his cooperation. We would also
   like to thank the anonymous reviewers and the editor for considering our
   manuscript and providing valuable reviews which has greatly enhanced the
   quality of the paper.
CR Akre J, 2014, WIRELESS DAYS WD 201, P1, DOI [10.1109/WD.2014.7020802, DOI 10.1109/WD.2014.7020802]
   Belmonte-Fernández O, 2018, EXPERT SYST APPL, V105, P89, DOI 10.1016/j.eswa.2018.03.054
   Calderoni L, 2015, EXPERT SYST APPL, V42, P125, DOI 10.1016/j.eswa.2014.07.042
   Chriki A, 2017, INT WIREL COMMUN, P1144, DOI 10.1109/IWCMC.2017.7986446
   Dong XM, 2019, MULTIMED TOOLS APPL, V78, P29747, DOI 10.1007/s11042-018-6383-9
   Farid Z, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/6923931
   Ghosh D, 2016, 2016 IEEE INT C ADV, P1, DOI DOI 10.1109/ANTS.2016.7947872
   Górak R, 2016, LECT NOTES ARTIF INT, V9876, P147, DOI 10.1007/978-3-319-45246-3_14
   Hossain AKMM, 2015, COMPUT COMMUN, V66, P1, DOI 10.1016/j.comcom.2015.03.001
   Kriz P, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/2083094
   Li ZW, 2019, IEEE NETWORK, V33, P96, DOI 10.1109/MNET.2019.1800366
   Ma HS, 2017, IEEE SENS J, V17, P3551, DOI 10.1109/JSEN.2017.2696054
   Mascharka D., 2015, ARXIV PREPRINT ARXIV
   Menendez P., 2011, Proceedings of the 2011 11th International Conference on Intelligent Systems Design and Applications (ISDA), P1020, DOI 10.1109/ISDA.2011.6121792
   Mitchell T. M., 1997, MACH LEARN
   Padhy RP, 2018, PROCEDIA COMPUT SCI, V133, P643, DOI 10.1016/j.procs.2018.07.099
   Nguyen QH, 2017, MULTIMED TOOLS APPL, V76, P2645, DOI 10.1007/s11042-015-3204-2
   Roy P, 2018, PROCEEDINGS OF THE WORKSHOP PROGRAM OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING (ICDCN'18), DOI 10.1145/3170521.3170538
   Roy P, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET 2019): ADVANCING WIRELESS AND MOBILE COMMUNICATIONS TECHNOLOGIES FOR 2020 INFORMATION SOCIETY, P491, DOI [10.1109/WiSPNET45539.2019.9032859, 10.1109/wispnet45539.2019.9032859]
   Roy P, 2019, WIRELESS PERS COMMUN, V106, P739, DOI 10.1007/s11277-019-06188-2
   Roy P, 2018, PROC INT CONF EMERG
   Sánchez-Rodríguez D, 2015, SENSORS-BASEL, V15, P14809, DOI 10.3390/s150614809
   Sharma Kavita, 2019, International Journal of E-Services and Mobile Applications, V11, P1, DOI 10.4018/IJESMA.2019040101
   SHARMA K, 2018, NEXT GENERATION NETW, P555, DOI DOI 10.1007/978-981-10-6005-2_56
   Sharma K, 2019, FORENSIC INVESTIGATI, DOI 10.4018/978-1-5225-9554-0
   Sharma K, 2016, PROCEDIA COMPUT SCI, V78, P19, DOI 10.1016/j.procs.2016.02.005
   Shenoy MV, 2020, J AMB INTEL HUM COMP, V11, P2715, DOI 10.1007/s12652-019-01331-0
   Shrivastava G., 2018, HDB RES NETWORK FORE
   Shrivastava G, 2020, NEW AGE ANAL TRANSFO, DOI 10.1201/9781003007210
   Singh V, 2018, IEEE POW ENER SOC GE, P1, DOI DOI 10.1109/CCAA.2018.8777341
   Taniuchi D, 2014, IEEE CONF WIREL MOB, P592, DOI 10.1109/WiMOB.2014.6962230
   Torres-Sospedra J, 2014, INT C INDOOR POSIT, P261, DOI 10.1109/IPIN.2014.7275492
   Trawinski K, 2013, SOFT COMPUT, V17, P1817, DOI 10.1007/s00500-013-1019-5
   Wang He, 2012, P 10 INT C MOB SYST, P197, DOI DOI 10.1145/2307636.2307655
   Yan J, 2018, IEEE T VEH TECHNOL, V67, P2824, DOI 10.1109/TVT.2017.2774103
   Yang ZX, 2016, NEUROCOMPUTING, V174, P121, DOI 10.1016/j.neucom.2015.05.120
   Zafari F, 2019, IEEE COMMUN SURV TUT, V21, P2568, DOI 10.1109/COMST.2019.2911558
   Zhou M, 2018, IEEE INTERNET THINGS, V5, P3378, DOI 10.1109/JIOT.2017.2775199
NR 38
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20501
EP 20525
DI 10.1007/s11042-020-10456-w
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612700002
DA 2024-07-18
ER

PT J
AU Zhao, D
   Sun, JD
   Chen, L
   Wu, YL
   Zhou, HC
AF Zhao, Dong
   Sun, Jiande
   Chen, Lei
   Wu, Yulin
   Zhou, Hongchao
TI Variable-length image compression based on controllable learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossy image compression; Variable-length compression; Generative
   adversarial networks; Noise interference; Controllable learning
ID ALGORITHM
AB While neural-network-based lossy image compression methods have shown impressive performance, most of them output a fixed-length coding using a trained-specific network. However, it is essential to support the variable-length compression or meet a target rate with a high-coding performance in practice. This paper steps forward the neural-network-based image compression method, making it possible for a single network model to generate variable compression rates. Our network model combines an auto-encoder (AE) and a generative adversarial network (GAN) for generative compression. We introduce a noise interference mechanism to train the feature representation produced by the encoder, making the feature nodes training controllable and distributed from top to bottom according to their importance in feature expression. Based on this importance distribution, the latent nodes are quantized into bits and the variable-length compression can be achieved by discarding bits of those less-important feature nodes to meet the compression target. We propose several noise interference methods, and the experiments confirm the feasibility of method Random-add and Dropout in controllable learning. Further experiments illustrate that our compression method can not only achieve variable-length compression but also can recover high-quality compressed images at extremely low bit rates, outperforming that with a fixed rate.
C1 [Zhao, Dong; Chen, Lei; Wu, Yulin; Zhou, Hongchao] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
C3 Shandong University; Shandong Normal University
RP Zhou, HC (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
EM zhaodong_sdu@outlook.com; hongchao@sdu.edu.cn
OI Zhao, Dong/0000-0002-3991-9570
FU Natural Science Foundation for Distinguished Young Scholars of Shandong
   Province [JQ201718]; Natural Science Foundation of China [U1736122];
   National Natural Science Foundation of China [62001267]; Foundamental
   Research Funds of Shandong University [2020HW017]
FX This work is supported by Natural Science Foundation for Distinguished
   Young Scholars of Shandong Province (JQ201718), the Natural Science
   Foundation of China (U1736122), the National Natural Science Foundation
   of China under Grant No. 62001267, and the Foundamental Research Funds
   of Shandong University under Grant No. 2020HW017.
CR Agustsson E, 2017, ADV NEUR IN, V30
   Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Alain Guillaume, 2016, ARXIV161001644
   Arjovsky, 2017, ARXIV170104862
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Balle J, 2017, 5 INT C LEARN REPR I
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Denton E.L., 2015, CoRR, P1486
   Donahue J., 2016, ARXIV160509782
   Dosovitskiy A, 2016, 30 C NEURAL INFORM P, V29
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gregor K, 2016, ADV NEUR IN, V29
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Jiang J, 1999, SIGNAL PROCESS-IMAGE, V14, P737, DOI 10.1016/S0923-5965(98)00041-1
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Karras T, 2018, P INT C LEARN REPR I
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   MA S, 2019, IEEE INT SYMP CIRC S, pNI475, DOI DOI 10.1109/iscas.2019.8702172
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Rippel O., 2017, P 34 INT C MACH LEAR, P2922
   Salimans T, 2016, ADV NEUR IN, V29
   Santurkar S, 2018, PICT COD SYMP, P258, DOI 10.1109/PCS.2018.8456298
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Theis L., 2017, ICLR
   Theis L, 2015, ADV NEUR IN, V28
   Toderici G., 2016, P INT C LEARN REPR I
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Tschannen M, 2018, ADV NEUR IN, V31
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2004, MULTIMED TOOLS APPL, V13
   Wolf S, 2009, ITU T CONTRIBUTION
   Xu M, 2014, IEEE T CIRC SYST VID, V24, P1743, DOI 10.1109/TCSVT.2014.2317886
   Yu A, 2017, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2017.594
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu L, 2018, ADV INTEL SYS RES, V155, P101
   Zhang XF, 2018, IEEE T CIRC SYST VID, V28, P3387, DOI 10.1109/TCSVT.2017.2748382
   Zhou L., 2018, P IEEE C COMP VIS PA
NR 59
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20065
EP 20087
DI 10.1007/s11042-020-10346-1
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900002
DA 2024-07-18
ER

PT J
AU Zheng, QY
   Chen, Y
AF Zheng, Qiyuan
   Chen, Ying
TI Feature pyramid of bi-directional stepped concatenation for small object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Small objects; Feature fusion; Feature pyramid
AB In recent years, great breakthroughs have been made in object detection. However, performance of the most algorithms declines significantly when detecting small objects in an image. Thus, multi-scale feature maps are often used to develop network variants to generate multi-scale representations. Existing feature pyramid-based methods tend to keep the number of channels consistent and fuse different scales by adding corresponding elements or channel concatenation, which is prone to lose low-level detailed feature information in feature fusion process. To solve this problem, a bi-directional stepped concatenation feature pyramid construction method based on SSD (BSCF-SSD) is proposed. The stepped concatenation strategy helps to avoid the loss of information at the current layer during the pyramid construction process, and the bi-directional tactic ensures the fusion features contain both detailed and semantic information. Furthermore, an attentional interaction module is designed to better aggregate dual-stream features to improve network performance. The proposed method improves the detection accuracy of small objects with less speed loss. Experimental results show that the method achieves 80.3% and 82.4% mAP on Pascal VOC2007 using VGG16 and Resnet50, respectively. On the special aviation object dataset UCAS-AOD, BSCF-SSD with VGG16 still achieves moderate improvement.
C1 [Zheng, Qiyuan; Chen, Ying] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
EM zhengqiyuan@stu.jiangnan.edu.cn; chenying@jiangnan.edu.cn
RI Chen, Ying/AAA-2911-2022; Ying, Chen/GRX-5695-2022
OI Chen, Ying/0000-0002-1674-0869; 
FU National Natural Science Foundation of China [61573168]
FX This work is supported by the National Natural Science Foundation of
   China(grant no. 61573168)
CR [Anonymous], 2017, ADV SOFT COMPUTING M
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   Dai JF, 2016, ADV NEUR IN, V29
   Duan KW, 2020, IEEE T CIRC SYST VID, V30, P1639, DOI 10.1109/TCSVT.2019.2906246
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ivanov Y, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P97, DOI 10.1109/CADSM.2015.7230806
   Jeong J., 2017, P BRIT MACH VIS C, DOI [10.5244/C.31.76, DOI 10.5244/C.31.76]
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li Z., 2017, CORR
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross G., 2013, P IEEE COMP SOC C CO, P1
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shi WX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204276
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang W, 2020, IEEE T CYBERNETICS, V50, P3973, DOI 10.1109/TCYB.2019.2917078
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wei HR, 2021, IEEE T GEOSCI REMOTE, V59, P1645, DOI 10.1109/TGRS.2020.2999082
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   [姚群力 Yao Qunli], 2019, [测绘学报, Acta Geodetica et Cartographica Sinica], V48, P1266
   Yazhao Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13346, DOI 10.1109/CVPR42600.2020.01336
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhao H, 2020, NEURAL PROCESS LETT, V51, P2789, DOI 10.1007/s11063-020-10228-5
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhu HG, 2015, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2015.7351502
NR 47
TC 8
Z9 11
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20283
EP 20305
DI 10.1007/s11042-021-10718-1
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900003
DA 2024-07-18
ER

PT J
AU Bhargava, A
   Bansal, A
AF Bhargava, Anuja
   Bansal, Atul
TI Novel coronavirus (COVID-19) diagnosis using computer vision and
   artificial intelligence techniques: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer vision; Computed tomography; Machine learning; Coronavirus;
   COVID-19
ID FEATURES FUSION; CLASSIFICATION; CANCER; STOMACH
AB The universal transmission of pandemic COVID-19 (Coronavirus) causes an immediate need to commit in the fight across the whole human population. The emergencies for human health care are limited for this abrupt outbreak and abandoned environment. In this situation, inventive automation like computer vision (machine learning, deep learning, artificial intelligence), medical imaging (computed tomography, X-Ray) has developed an encouraging solution against COVID-19. In recent months, different techniques using image processing are done by various researchers. In this paper, a major review on image acquisition, segmentation, diagnosis, avoidance, and management are presented. An analytical comparison of the various proposed algorithm by researchers for coronavirus has been carried out. Also, challenges and motivation for research in the future to deal with coronavirus are indicated. The clinical impact and use of computer vision and deep learning were discussed and we hope that dermatologists may have better understanding of these areas from the study.
C1 [Bhargava, Anuja; Bansal, Atul] GLA Univ, Mathura, India.
C3 GLA University
RP Bhargava, A (corresponding author), GLA Univ, Mathura, India.
EM anuja1012@gmail.com; atul.bansal@gla.ac.in
RI BHARGAVA, ANUJA/AAP-5094-2021; Bansal, Atul/I-1823-2019
OI BHARGAVA, ANUJA/0000-0002-2387-2552; Bansal, Atul/0000-0002-8012-0349
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Amin SU, 2019, IEEE ACCESS, V7, P10745, DOI 10.1109/ACCESS.2019.2891390
   [Anonymous], RADIOLOGY, DOI [10.1148/radiol.2020200642, DOI 10.1148/RADIOL.2020200642, 10.5772/intechopen.80730, DOI 10.1148/radiol.2020200642]
   [Anonymous], Weekly
   [Anonymous], 2021, WHO director-generals' opening remarks at the media briefing on Covid 19
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Asnaoui K. E., 2003, ARXIV PREPRINT ARXIV, P14363
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Barstugan M, 2020, ARXIV200309424
   Behera SK, Detection of coronavirus disease (covid-19) based on deep features and support vector machine, 2020
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Cao CS, 2020, ANGEW CHEM INT EDIT, V59, P8586, DOI 10.1002/anie.201914596
   Chen Emily, 2020, JMIR Public Health Surveill, V6, pe19273, DOI 10.2196/19273
   Chen J., 2020, medRxiv
   Chen R, 2020, CAN J ANESTH, V67, P754, DOI 10.1007/s12630-020-01625-4
   Chen Y, 2020, J MED VIROL, V92, P418, DOI 10.1002/jmv.25681
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chiu W T, 2005, Asia Pac J Public Health, V17, P26, DOI 10.1177/101053950501700107
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Fellous JM, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01346
   Gaal G., 2020, CEUR WORKSHOP PROC, DOI DOI 10.48550/ARXIV.2003.10304
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Ghassemi, 2020, ARXIV200611988
   Ghoshal B., 2020, ARXIV200310769
   Gozes O., 2020, RAPID AI DEV CYCLE C
   Hao J, 2019, BMC MED GENOMICS, V12, DOI 10.1186/s12920-019-0624-2
   Hay EA, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006628
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Hölbl M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100470
   Huang L, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200075
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Jingyi Shen, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P287, DOI 10.1109/ICMLA.2019.00054
   Kanwal N., 2011, 2011 5th International Conference on Bioinformatics and Biomedical Engineering, P1
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Khan SA, 2019, MICROSC RES TECHNIQ, V82, P1256, DOI 10.1002/jemt.23275
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kim DW, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-018-36760-y, 10.1038/s41598-019-43372-7]
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Krishna BA, 2023, CLIN INFECT DIS, V76, P738, DOI 10.1093/cid/ciac630
   Lai CC, 2020, INT J ANTIMICROB AG, V55, DOI 10.1016/j.ijantimicag.2020.105924
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li Y, 2020, AM J ROENTGENOL, V214, P1280, DOI 10.2214/AJR.20.22954
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu TZ, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200025
   Liu W., 2020, ARXIV201007497
   Lu HZ, 2020, J MED VIROL, V92, P401, DOI [10.1002/jmv.2567, 10.1002/jmv.25678]
   Merhof D, 2018, 2018 IEEE INT INSTR, P1
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Monrat AA, 2019, IEEE ACCESS, V7, P117134, DOI 10.1109/ACCESS.2019.2936094
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Nguyen D., 2020, BLOCKCHAIN AI BASED, DOI [DOI 10.20944/PREPRINTS202004.0325.V1, 10.36227/techrxiv.12121962.v1, DOI 10.36227/TECHRXIV.12121962.V1]
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Paules CI, 2020, JAMA-J AM MED ASSOC, V323, P707, DOI 10.1001/jama.2020.0757
   Pearce Joshua M, 2020, F1000Res, V9, P218, DOI 10.12688/f1000research.22942.1
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Pisani P, 2013, WORLD J RADIOL, V5, P398, DOI 10.4329/wjr.v5.i11.398
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Reddy S, 2019, J ROY SOC MED, V112, P22, DOI 10.1177/0141076818815510
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sarker IH, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0258-4
   Sarker IH, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0219-y
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shen C, 2020, J PHARM ANAL, V10, P123, DOI 10.1016/j.jpha.2020.03.004
   Shi Feng, 2021, Phys Med Biol, DOI 10.1088/1361-6560/abe838
   Shi HS, 2020, LANCET INFECT DIS, V20, P425, DOI 10.1016/S1473-3099(20)30086-4
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Song YZ, 2022, IEEE T INTELL TRANSP, V23, P12287, DOI 10.1109/TITS.2021.3112458
   Speidel MA, 2006, MED PHYS, V33, P2714, DOI 10.1118/1.2208736
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tang L, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200044
   Tang ZY, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbf9e
   Uesawa Y, 2018, BIOORG MED CHEM LETT, V28, P3400, DOI 10.1016/j.bmcl.2018.08.032
   Wang G., 2020, arXiv
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang WL, 2020, JAMA-J AM MED ASSOC, V323, P1843, DOI 10.1001/jama.2020.3786
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Wang Y, 2020, ARCH DERMATOL RES, V312, P581, DOI 10.1007/s00403-020-02044-7
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   WHO, 2020, RATIONAL USE PERSONA, P28
   WHO, 2020, Coronavirus disease (COVID-19) pandemic
   Wrapp D, 2020, SCIENCE, V367, P1260, DOI [10.1126/science.abb2507, 10.1101/2020.02.11.944462]
   Xu X. W., 2020, ARXIV200209334
   Xu YW, 2019, CLIN CANCER RES, V25, P3266, DOI 10.1158/1078-0432.CCR-18-2495
   Yu F, ANN INTERN MED
   Yuan JB, 2019, LECT NOTES COMPUT SC, V11769, P721, DOI 10.1007/978-3-030-32226-7_80
   Yue HM, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm-20-3026
   Zhang DY, 2017, J INF SECUR APPL, V36, P135, DOI 10.1016/j.jisa.2017.09.003
   Zhang DY, 2017, J VIS COMMUN IMAGE R, V48, P281, DOI 10.1016/j.jvcir.2017.07.006
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhao J., 2020, ARXIV PREPRINT ARXIV
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
   Zhou SR, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105778
NR 105
TC 29
Z9 31
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19931
EP 19946
DI 10.1007/s11042-021-10714-5
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625037300002
PM 33686333
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Hassan, B
   Izquierdo, E
   Piatrik, T
AF Hassan, Bilal
   Izquierdo, Ebroul
   Piatrik, Tomas
TI Soft biometrics: a survey Benchmark analysis, open challenges and
   recommendations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft biometrics; Annotation; Distance; Permanence; Discrimination;
   Fusion
ID CONVOLUTIONAL NEURAL-NETWORKS; AGE ESTIMATION; GENDER CLASSIFICATION;
   FACE-RECOGNITION; FEATURES; DATABASE; IMAGES; SHAPE; BODY;
   REPRESENTATION
AB The field of biometrics research encompasses the need to associate an identity to an individual based on the persons physiological or behaviour traits. While the use of intrusive techniques such as retina scans and finger print identification has resulted in highly accurate systems, the scalability of such systems in real-world applications such as surveillance and border security has been limited. As a branch of biometrics research, the origin of soft biometrics could be traced back to need for non-intrusive solutions for extracting physiological traits of a person. Following high number of research outcomes reported in the literature on soft biometrics, this paper aims to consolidate the scope of soft biometrics research across four thematic schemes (i) a detailed review of soft biometrics research data sets, their annotation strategies and building a largest novel collection of soft traits; (ii) the assessment of metrics that affect the performance of soft biometrics system; (iii) a comparative analysis on feature and modality level fusion reported in the literature for enhancing the system performance; and (iv) a performance analysis of hybrid soft biometrics recognition system using multi-scale criterion. The paper also presents a detailed analysis on the global traits associated to person identity such as gender, age and ethnicity. The contribution of the paper is to provide a comprehensive review of scientific literature, identify open challenges and offer insights on new research directions in the filed.
C1 [Hassan, Bilal; Izquierdo, Ebroul; Piatrik, Tomas] Queen Mary Univ London, Sch Elect Engn & Comp Sci, Multimedia & Vis Lab, London, England.
C3 University of London; Queen Mary University London
RP Hassan, B (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, Multimedia & Vis Lab, London, England.
EM b.hassan@qmul.ac.uk; ebroul.izquierdo@qmul.ac.uk; t.piatrik@qmul.ac.uk
OI Piatrik, Tomas/0000-0002-1517-2054
CR Abdalrady NA, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P251, DOI [10.1109/ITCE48509.2020.9047798, 10.1109/itce48509.2020.9047798]
   Achkar R, 2019, INT CONF COMP INFO, P211, DOI 10.1109/cits.2019.8862004
   Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   Akinyemi J. D., 2016, 2016 IEEE S TECHN HO, P1
   Al-Dahoud A, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P1, DOI 10.1109/CW.2017.26
   Alhanjouri M, 2019, 2019 IEEE 7 PAL INT, P1
   Almeida V, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION CONTROL AND INTELLIGENT SYSTEMS (CCIS), P110, DOI 10.1109/CCIntelS.2016.7878211
   Almudhahka, 2018, SURVEILLANCE ACTION, P25, DOI DOI 10.1007/978-3-319-68533-5_2
   Almudhahka N., 2016, 2016 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), P1
   Almudhahka NY, 2018, IEEE T INF FOREN SEC, V13, P706, DOI 10.1109/TIFS.2017.2765519
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   Anand A., 2017, 2017 IEEE S SERIES C, P1, DOI DOI 10.1109/SSCI.2017.8285381
   Angeloni, 2019, P IEEE INT C COMP VI
   [Anonymous], 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   [Anonymous], 2004, FG NET WORKSH VIS OB
   Antipov G, 2017, PATTERN RECOGN, V72, P15, DOI 10.1016/j.patcog.2017.06.031
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Arianasab E, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P892, DOI 10.1109/KBEI.2015.7436161
   Arigbabu OA, 2015, PATTERN RECOGN LETT, V68, P278, DOI 10.1016/j.patrec.2015.07.014
   Arigbabu OA, 2015, VISUAL COMPUT, V31, P513, DOI 10.1007/s00371-014-0990-x
   Azam S, 2016, 2016 IEEE 15TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P535, DOI 10.1109/ICCI-CC.2016.7862089
   Bainbridge WA, 2013, J EXP PSYCHOL GEN, V142, P1323, DOI 10.1037/a0033872
   Barro PA, 2019, IFIP WIREL DAY
   Bekhouche, 2015, CONTR ENG INF TECHN, P1
   BenAbdelkader C., 2008, P 8 IEEE INT C AUT F, P1, DOI [DOI 10.1109/AFGR.2008.4813453, 10.1109/AFGR.2008.4813453]
   BenAbdelkader C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P499
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Benini, 2013, GOOGLE PATENTS
   Beveridge J. R., 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   Bolle R. M., 2013, Guide to biometrics
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Castrillón-Santana M, 2017, IMAGE VISION COMPUT, V57, P15, DOI 10.1016/j.imavis.2016.10.004
   Castrillón-Santana M, 2017, COMPUT VIS IMAGE UND, V156, P4, DOI 10.1016/j.cviu.2016.09.004
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Chen H., 2016, Where am I from?-East Asian Ethnicity Classification from Facial Recognition
   Chen J, 2019, IET IMAGE PROCESS, V13, P1146, DOI 10.1049/iet-ipr.2018.5972
   Chen SX, 2018, IEEE T MULTIMEDIA, V20, P2209, DOI 10.1109/TMM.2017.2786869
   Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86
   Chennu Jaya Venkata Phani Sekhar, 2016, 2016 IEEE 6th International Conference on Power Systems (ICPS), DOI 10.1109/ICPES.2016.7584074
   Christy C., 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P515, DOI 10.1109/ICECA.2019.8821974
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   De Carolis B, 2019, LECT NOTES ARTIF INT, V11606, P687, DOI 10.1007/978-3-030-22999-3_59
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Denman S, 2015, PATTERN RECOGN LETT, V68, P306, DOI 10.1016/j.patrec.2015.06.015
   Derakhshani R, 2018, 2018 IEEE 9 INT C BI, P1, DOI [DOI 10.1109/BTAS.2018.8698586, 10.1109/BTAS.2018.8698586]
   Derakhshani R, 2019, 2019 IEEE INT S TECH, P1
   Derakhshani R, 2019, 2019 IEEE INT S TECH, P1, DOI DOI 10.1109/HST47167.2019.9032976
   Dhomne Amit, 2018, Procedia Computer Science, V132, P2, DOI 10.1016/j.procs.2018.05.053
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115
   Dornaika F, 2019, MACH VISION APPL, V30, P177, DOI 10.1007/s00138-018-0976-1
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Escalera, 2015, ICCV CHALEARN LOOK P, V1, P4
   Eskandari M, 2019, IET BIOMETRICS, V8, P243, DOI 10.1049/iet-bmt.2018.5134
   Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347
   Fang J, 2019, NEUROCOMPUTING, V334, P114, DOI 10.1016/j.neucom.2018.12.073
   Fekri-Ershad S, 2020, ARXIV200110966
   Flynn, 2008, HDB BIOMETRICS
   Fosdick RB, 1915, J AM INST CRIM LAW C, V6, P363, DOI 10.2307/1132744
   Freire-Obregón D, 2014, IEEE IMAGE PROC, P4972, DOI 10.1109/ICIP.2014.7026007
   Galiyawala H, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P471
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Garg R, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P259, DOI 10.1109/PDGC.2018.8745766
   Geng L, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACVW.2017.8
   Ghalleb AE, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P252, DOI 10.1109/ATSIP.2016.7523078
   González-Briones A, 2018, COMPUT VIS IMAGE UND, V172, P98, DOI 10.1016/j.cviu.2018.01.012
   Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791
   Gonzalez-Sosa E, 2016, INT C PATT RECOG, P3061, DOI 10.1109/ICPR.2016.7900104
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Guo, 2017, SUPERVISED GEN CANON
   Guo Bingchen H., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P292, DOI 10.1109/TBIOM.2019.2943934
   Guo B. H., 2018, Ph. D. thesis), P1, DOI 10.1109/isba.2018.8311457
   Guo BH, 2018, INT C PATT RECOG, P3457, DOI 10.1109/ICPR.2018.8546071
   Gurnani A, 2019, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2019.00094
   Gürpinar F, 2016, IEEE COMPUT SOC CONF, P785, DOI 10.1109/CVPRW.2016.103
   Haider KZ, 2019, J REAL-TIME IMAGE PR, V16, P15, DOI 10.1007/s11554-017-0714-3
   Hamdy N, 2004, 2004 47 MIDW S CIRC, V1, pI
   Heng Z, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351370
   Heusch Guillaume, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P210, DOI 10.1109/TBIOM.2019.2927692
   Hoon Y, 2016, C IND ELECT APPL, P1, DOI 10.1109/IEACON.2016.8067346
   Huang G.B., 2014, LABELED FACES WILD U
   Huang J, 2017, MULTIMED TOOLS APPL, V76, P20231, DOI 10.1007/s11042-017-4646-5
   Huang K, 2016, ARXIV160307054
   Huri K, 2018, LECT NOTES COMPUT SC, V11141, P604, DOI 10.1007/978-3-030-01424-7_59
   Jaha E.S., 2019, 2019 7 INT S DIG, P1
   Jaha ES, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Jaha ES, 2016, IEEE T INF FOREN SEC, V11, P2377, DOI 10.1109/TIFS.2016.2584001
   Jaha ES, 2015, INT CONF BIOMETR, P73, DOI 10.1109/ICB.2015.7139078
   Jain A. K., 2006, Biometrics: personal identification in networked society, V479
   Jilani SK, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P170, DOI 10.1109/CW.2017.27
   Kakadiaris IA, 2016, IEEE IMAGE PROC, P3156, DOI 10.1109/ICIP.2016.7532941
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   KNIGHT WR, 1966, J AM STAT ASSOC, V61, P436, DOI 10.2307/2282833
   Kuijper A, 2019, 22 INT C INF FUS FUS, P2
   Kuijper A, 2020, ARXIV200209181
   Leal Tavares Henrique, 2019, 2019 XV Workshop de Visao Computacional (WVC) [2019 XV Computer Vision Workshop (WVC)]. Proceedings, P78, DOI 10.1109/WVC.2019.8876921
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Levi G, 2015, IEEE COMPUT SOC CONF
   Li C, 2017, ARXIV170809687
   Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007
   Lin X, 2020, IEEE T CYBERNETICS
   Liu H, 2019, IEEE T CIRC SYST VID, V29, P486, DOI 10.1109/TCSVT.2017.2782709
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739
   Lucas TA, 2015, AM J PHYS ANTHROPOL, V156, P207
   Mandal AS, 2017, 2017 C INF COMM TECH, P1
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Martinho-Corbishley D., 2015, Soft biometric recognition from comparative crowdsourced annotations
   Martinho-Corbishley D, 2019, IEEE T PATTERN ANAL, V41, P1486, DOI 10.1109/TPAMI.2018.2836900
   Martinho-Corbishley D, 2016, INT C PATT RECOG, P3067, DOI 10.1109/ICPR.2016.7900105
   Martinho-Corbishley D, 2016, IET BIOMETRICS, V5, P276, DOI 10.1049/iet-bmt.2015.0118
   Middleton L, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P723, DOI 10.1109/IROS.2006.282619
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Mohammad Ahmad Saeed, 2017, 2017 9th Computer Science and Electronic Engineering (CEEC). Proceedings, P219, DOI 10.1109/CEEC.2017.8101628
   Mohammad AS, 2019, IET BIOMETRICS, V8, P378, DOI 10.1049/iet-bmt.2018.5230
   Mohammad AS, 2018, COMPUT SCI ELECTR, P293, DOI 10.1109/CEEC.2018.8674194
   Morales A., 2019, ARXIV190200334
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Nam SH, 2020, IEEE ACCESS, V8, P17103, DOI 10.1109/ACCESS.2020.2967800
   Nambiar A, 2015, PATTERN RECOGN LETT, V68, P297, DOI 10.1016/j.patrec.2015.07.001
   Neal Tempestt J., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P109, DOI 10.1109/TBIOM.2019.2905868
   Ng CC, 2018, IMAGE VISION COMPUT, V69, P92, DOI 10.1016/j.imavis.2017.08.005
   Niinuma K, 2010, IEEE T INF FOREN SEC, V5, P771, DOI 10.1109/TIFS.2010.2075927
   Nixon MS, 2017, VIS COGN, V25, P524, DOI 10.1080/13506285.2016.1266426
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ouloul IM, 2019, MULTIMED TOOLS APPL, V78, P1913, DOI 10.1007/s11042-018-6275-z
   Ozbulak G., 2016, 2016 INT C BIOMETRIC, P1, DOI DOI 10.1109/BIOSIG.2016.7736925
   Pang YW, 2020, IEEE T CYBERNETICS, V50, P247, DOI 10.1109/TCYB.2018.2868742
   Pang YW, 2019, PROC CVPR IEEE, P7328, DOI 10.1109/CVPR.2019.00751
   Pang YW, 2019, IEEE T NEUR NET LEAR, V30, P2779, DOI 10.1109/TNNLS.2018.2886317
   Pang YW, 2017, IEEE T CYBERNETICS, V47, P4148, DOI 10.1109/TCYB.2016.2601438
   Pang YW, 2017, IEEE T CYBERNETICS, V47, P117, DOI 10.1109/TCYB.2015.2508603
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Pei WJ, 2020, IEEE T IMAGE PROCESS, V29, P1972, DOI 10.1109/TIP.2019.2948288
   Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Prakash A., 2014, International Journal of Network Security, V16, P65
   Proença H, 2017, IEEE T INF FOREN SEC, V12, P1637, DOI 10.1109/TIFS.2017.2680246
   Qawaqneh Z, 2017, EXPERT SYST APPL, V85, P76, DOI 10.1016/j.eswa.2017.05.037
   Ramanathan V, 2010, PATTERN RECOGN LETT, V31, P2425, DOI 10.1016/j.patrec.2010.07.011
   Rattani, 2017, 2017 IEEE INT S TECH, P1, DOI DOI 10.1109/THS.2017.7943489
   Rattani, 2019, SELFIE BIOMETRICS AD
   Rattani A, 2018, IET BIOMETRICS, V7, P423, DOI 10.1049/iet-bmt.2017.0171
   Rattani A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P756, DOI 10.1109/BTAS.2017.8272766
   Rattani A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P762, DOI 10.1109/BTAS.2017.8272767
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Rawls AW, 2009, LECT NOTES COMPUT SC, V5707, P17, DOI 10.1007/978-3-642-04391-8_3
   Rehman, 2018, 2018 5 INT MULT ICT, P1
   Reid DA, 2013, HANDB STAT, V31, P327, DOI 10.1016/B978-0-444-53859-8.00013-8
   Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219
   Reid DA, 2013, INT CONF BIOMETR
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Riccio D., 2012, 2012 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS 2012), DOI 10.1109/BIOMS.2012.6345776
   Robinette KM., Civilian American and European Surface Anthropometry Resource (CAESAR), V1, DOI DOI 10.21236/ADA406704
   Rodríguez P, 2017, PATTERN RECOGN, V72, P563, DOI 10.1016/j.patcog.2017.06.028
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Samangooei, 2010, THESIS U SOUTHAMPTON
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sawant M, 2019, MULTIMED TOOLS APPL, P1
   Sayed MR, 2019, IEEE WINT CONF APPL, P829, DOI 10.1109/WACV.2019.00093
   Scarborough SM, 2009, ALGORITHMS SYNTHETIC, V7337, p73370G
   Seely RD, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P135
   Semertzidis, 2016, SOFT BIOMETRICS LOW
   Serna, 2020, ARXIV200406592
   Shin M, 2017, IEEE ROMAN, P567, DOI 10.1109/ROMAN.2017.8172359
   Shutler JD, 2004, ADV SOFT COMP, P339
   Sikkandar H, 2020, IET IMAGE PROCESS, V14, P451, DOI 10.1049/iet-ipr.2019.0271
   Singh SK, 2017, 2017 IEEE INT C ID S, P1, DOI DOI 10.1109/ISBA.2017.7947693
   Srinidhi CL, 2019, IEEE T IMAGE PROCESS, V28, P2705, DOI 10.1109/TIP.2018.2889534
   Srinivas N, 2017, IEEE INT CONF AUTOMA, P953, DOI 10.1109/FG.2017.118
   Sundararajan A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309550
   Taheri S, 2019, NEUROCOMPUTING, V329, P300, DOI 10.1016/j.neucom.2018.10.071
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tome P, 2015, FORENSIC SCI INT, V257, P271, DOI 10.1016/j.forsciint.2015.09.002
   Tome P, 2014, IEEE T INF FOREN SEC, V9, P464, DOI 10.1109/TIFS.2014.2299975
   Tomicic I, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1115, DOI 10.23919/MIPRO.2018.8400203
   Unnikrishnan A, 2016, PROC TECH, V24, P1349, DOI 10.1016/j.protcy.2016.05.145
   Vasileiadis M, 2019, IEEE COMPUT SOC CONF, P2315, DOI 10.1109/CVPRW.2019.00285
   Vera-Rodriguez R., 2013, 2013 International Conference on Biometrics (ICB), P1, DOI DOI 10.1109/ICB.2013.6613014
   Vera-Rodriguez R, 2017, INT CARN CONF SECU
   Wan LP, 2018, INT CONF BIOMETR, P98, DOI 10.1109/ICB2018.2018.00025
   Wang HY, 2018, IEEE IMAGE PROC, P2675, DOI 10.1109/ICIP.2018.8451606
   Wang SZ, 2016, IEEE T CYBERNETICS, V46, P827, DOI 10.1109/TCYB.2015.2416321
   Wang XJ, 2019, PROCEEDINGS OF 2019 4TH INTERNATIONAL CONFERENCE ON BIOMEDICAL SIGNAL AND IMAGE PROCESSING (ICBIP 2019), P1, DOI 10.1145/3354031.3354033
   Xia LK, 2019, MULTIMED TOOLS APPL, V78, P11291, DOI 10.1007/s11042-018-6645-6
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Xiaobo Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P217, DOI 10.1109/ICPR.2010.62
   Xie JC, 2020, IEEE T INF FOREN SEC, V15, P2361, DOI 10.1109/TIFS.2020.2965298
   Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005
   Yaghoubi E., 2019, IEEE SYS MAN CYBERN, P1
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
   Yi Dong, 2014, ARXIV14117923
   Yichun Shi, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P56, DOI 10.1109/TBIOM.2019.2897807
   Yoo B, 2018, IEEE SIGNAL PROC LET, V25, P808, DOI 10.1109/LSP.2018.2822241
   Zaghbani S, 2018, COMPUT ELECTR ENG, V68, P337, DOI 10.1016/j.compeleceng.2018.04.012
   Zhang H, 2015, COMPUT VIS IMAGE UND, V137, P50, DOI 10.1016/j.cviu.2015.03.003
   Zheng DP, 2016, LECT NOTES COMPUT SC, V9772, P300, DOI 10.1007/978-3-319-42294-7_26
   ZHENG S., 2012, Visual image recognition system with object-level image representation
   Zhou Z, 2014, I C CONT AUTOMAT ROB, P234, DOI 10.1109/ICARCV.2014.7064310
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 215
TC 13
Z9 14
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15151
EP 15194
DI 10.1007/s11042-021-10622-8
EA MAR 2021
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000623716400001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Li, H
   Wang, JY
   Xu, LW
   Zhang, SJ
   Tao, Y
AF Li, Hui
   Wang, Junyin
   Xu, Lingwei
   Zhang, Shujun
   Tao, Ye
TI Efficient and accurate object detection for 3D point clouds in
   intelligent visual internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Object detection; 3D point clouds; Monocular camera;
   RGB-D image; LiDAR
ID NETWORK; VISION
AB Visual perception is a key technology in the Intelligent Visual Internet of Things. The research of object detection methods is of great significance for improving the safety and efficiency of unmanned driving technology and intelligent visual Internet of Things. 3D point clouds object detection of deep learning can not only use the deep network to automatically learn characteristics of the multi-layer abstract structure, improve calculation efficiency and detection accuracy of the model, but also have better performance in dealing with object occlusion, absence and data sparsity with obtained high-dimensional point clouds information. However, the current review of object detection methods for 3D point clouds based on deep learning is scarce. In order to provide a more comprehensive understanding and understanding of the security and efficiency development of driverless technology, this paper is divided into the monocular camera, RGB-D image and LiDAR point cloud, according to the main data of the network model, and further subdivides according to the different use methods of the model. Analyze the performance of various model detection methods. This article also summarizes current commonly used 3D point clouds datasets of object detection, organizes and describes detection metrics of commonly used 3D point clouds, and discusses research challenges and development trends. The real-time performance of 3D point cloud object detection under the intelligent vision Internet of Things needs to be improved.
C1 [Li, Hui; Wang, Junyin; Xu, Lingwei; Zhang, Shujun; Tao, Ye] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.
   [Xu, Lingwei] South Cent Univ Nationalities, Hubei Key Lab Intelligent Wireless Commun, Wuhan 430074, Peoples R China.
   [Xu, Lingwei] Lanzhou Jiaotong Univ, Minist Educ, Key Lab Optotechnol & Intelligent Control, Lanzhou 730070, Peoples R China.
C3 Qingdao University of Science & Technology; South Central Minzu
   University; Lanzhou Jiaotong University
RP Xu, LW (corresponding author), Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.; Xu, LW (corresponding author), South Cent Univ Nationalities, Hubei Key Lab Intelligent Wireless Commun, Wuhan 430074, Peoples R China.; Xu, LW (corresponding author), Lanzhou Jiaotong Univ, Minist Educ, Key Lab Optotechnol & Intelligent Control, Lanzhou 730070, Peoples R China.
EM lihui@qust.edu.cn; gaomilaojia2009@163.com
RI Xu, Lingwei/I-1675-2019
OI Tao, Ye/0000-0001-5470-9451
FU National Natural Science Foundation of China [61702295]; Shandong
   Province Natural Science Foundation [ZR2020QF003, ZR2017BF023]; Opening
   Foundation of Key Laboratory of Opto-Technology and Intelligent Control
   (Lanzhou Jiaotong University), The Ministry of Education [KFKT2020-09];
   Shandong Province Postdoctoral Innovation Project [201703032]; Shandong
   Province Colleges and Universities Young Talents Initiation Program
   [2019KJN047]; Doctoral Fund of QUST [1203043003480, 010029029]
FX This research was funded by the National Natural Science Foundation of
   China (No. 61702295), the Shandong Province Natural Science Foundation
   (No. ZR2020QF003, ZR2017BF023), the Opening Foundation of Key Laboratory
   of Opto-Technology and Intelligent Control (Lanzhou Jiaotong
   University), The Ministry of Education (No.KFKT2020-09), the Shandong
   Province Postdoctoral Innovation Project (No. 201703032), the Shandong
   Province Colleges and Universities Young Talents Initiation Program
   (No.2019KJN047), and the Doctoral Fund of QUST (No.1203043003480,
   010029029).
CR Ali W, 2019, LECT NOTES COMPUT SC, V11131, P716, DOI 10.1007/978-3-030-11015-4_54
   [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   Asvadi Alireza., 2017, 2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC), P1, DOI DOI 10.1109/ITSC.2017.8317880
   Beltrán J, 2018, IEEE INT C INTELL TR, P3517, DOI 10.1109/ITSC.2018.8569311
   Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Bruna J., 2014, P INT C LEARN REPR
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Deng J, 2019, IEEE INT C INTELL TR, P279, DOI [10.1109/ITSC.2019.8917126, 10.1109/itsc.2019.8917126]
   Deng Z, 2017, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2017.50
   DORAI C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1024, DOI 10.1109/ICCV.1995.466822
   Du XX, 2018, IEEE INT CONF ROBOT, P3194
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Feng MT, 2021, IEEE T IMAGE PROCESS, V30, P92, DOI 10.1109/TIP.2020.3031371
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gomez-Ojeda R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4211, DOI 10.1109/IROS.2016.7759620
   González A, 2017, IEEE T CYBERNETICS, V47, P3980, DOI 10.1109/TCYB.2016.2593940
   González A, 2015, IEEE INT VEH SYM, P356, DOI 10.1109/IVS.2015.7225711
   Gu XY, 2019, PROC CVPR IEEE, P3249, DOI 10.1109/CVPR.2019.00337
   Gulliver TA, 2020, IEEE INTERNET THINGS
   Gupta I, 2018, EUR C COMP VIS, P626
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He T, 2019, AAAI CONF ARTIF INTE, P8409
   Hegde D, 2019, PROC IEEE C COMPUT V
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Kuang HW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030704
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu H, 2020, IEEE T INSTRUM MEAS, V69, P950, DOI 10.1109/TIM.2019.2908715
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XY, 2019, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2019.00062
   Liu ZJ, 2019, ADV NEUR IN, V32
   LLC W, 2019, WAYM OP DAT AUT DRIV
   Mao JG, 2019, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2019.00166
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Naiden A, 2019, IEEE IMAGE PROC, P61, DOI [10.1109/ICIP.2019.8803397, 10.1109/icip.2019.8803397]
   Ngiam Jiquan, 2019, CORR
   Paigwar A, 2019, IEEE COMPUT SOC CONF, P1297, DOI 10.1109/CVPRW.2019.00169
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shen XK, 2020, IEEE WINT CONF APPL, P1687, DOI 10.1109/WACV45572.2020.9093276
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi W., 2020, P IEEE CVF C COMP VI, P1711, DOI DOI 10.1109/CVPR42600.2020.00178
   Simon M, 2019, IEEE COMPUT SOC CONF, P1190, DOI 10.1109/CVPRW.2019.00158
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   Tian YL, 2020, NEUROCOMPUTING, V411, P32, DOI 10.1016/j.neucom.2020.05.086
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang WY, 2018, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2018.00272
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Weng XS, 2019, IEEE INT CONF COMP V, P857, DOI 10.1109/ICCVW.2019.00114
   Wirges S, 2018, IEEE INT C INTELL TR, P3530, DOI 10.1109/ITSC.2018.8569433
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xie SN, 2018, PROC CVPR IEEE, P4606, DOI 10.1109/CVPR.2018.00484
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang JC, 2019, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2019.00344
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Ye MS, 2020, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR42600.2020.00170
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Zarzar J., 2019, COMPUT VIS PATTERN R
   Zeng YM, 2018, IEEE ROBOT AUTOM LET, V3, P3434, DOI 10.1109/LRA.2018.2852843
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhi S., 2017, Eurographics Workshop on 3D Object Retrieval, EG 3DOR, vol 2017-April, P9
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhou Yin, 2020, C ROBOT LEARNING, P923
NR 99
TC 1
Z9 1
U1 1
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31297
EP 31334
DI 10.1007/s11042-020-10475-7
EA FEB 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000621742800002
DA 2024-07-18
ER

PT J
AU Pan, BY
   Zhang, LM
   Yin, HX
   Lan, J
   Cao, FL
AF Pan, Baiyu
   Zhang, Liming
   Yin, Hanxiong
   Lan, Jun
   Cao, Feilong
TI An automatic 2D to 3D video conversion approach based on RGB-D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map; Depth image based rendering (DIBR); RGB-D sensor; 2D to 3D
   video conversion
AB 3D movies/videos have become increasingly popular in the market; however, they are usually produced by professionals. This paper presents a new technique for the automatic conversion of 2D to 3D video based on RGB-D sensors, which can be easily conducted by ordinary users. To generate a 3D image, one approach is to combine the original 2D color image and its corresponding depth map together to perform depth image-based rendering (DIBR). An RGB-D sensor is one of the inexpensive ways to capture an image and its corresponding depth map. The quality of the depth map and the DIBR algorithm are crucial to this process. Our approach is twofold. First, the depth maps captured directly by RGB-D sensors are generally of poor quality because there are many regions missing depth information, especially near the edges of objects. This paper proposes a new RGB-D sensor based depth map inpainting method that divides the regions with missing depths into interior holes and border holes. Different schemes are used to inpaint the different types of holes. Second, an improved hole filling approach for DIBR is proposed to synthesize the 3D images by using the corresponding color images and the inpainted depth maps. Extensive experiments were conducted on different evaluation datasets. The results show the effectiveness of our method.
C1 [Pan, Baiyu; Zhang, Liming; Yin, Hanxiong; Lan, Jun] Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
   [Cao, Feilong] China Jiliang Univ, Coll Sci, Hangzhou, Peoples R China.
C3 University of Macau; China Jiliang University
RP Pan, BY (corresponding author), Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
EM yb57458@um.edu.mo; lmzhang@um.edu.mo; 675734874@qq.com;
   758971331@qq.com; icteam@163.com
RI Zhang, Liming/ABG-5996-2020
OI Zhang, Liming/0000-0002-2664-8193; Pan, Baiyu/0000-0002-0170-9826
FU Science and Technology Development Fund of Macao SAR [FDCT079/2016/A2,
   MYRG2017-00218-FST, MYRG2018-00111-FST]
FX This study is supported by the research grants: The Science and
   Technology Development Fund of Macao SAR FDCT079/2016/A2, and
   MYRG2017-00218-FST, MYRG2018-00111-FST.
CR Ahmed MW., 2020, UHD J SCI TECHNOL, V4, P1, DOI DOI 10.21928/UHDJST.V4N1Y2020.PP1-8
   [Anonymous], 2018, ECCV
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], 2001, P INT C VIS IM IM PR
   [Anonymous], 2016, J MACH LEARN RES
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Basso F, 2018, IEEE T ROBOT, V34, P1315, DOI 10.1109/TRO.2018.2853742
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bhattacharya S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P868, DOI 10.1109/ICACCI.2014.6968427
   Chen L, 2017, IEEE T INTELL TRANSP, V18, P165, DOI 10.1109/TITS.2016.2564640
   Chen YZ, 2019, NEURAL PROCESS LETT, V49, P1355, DOI 10.1007/s11063-018-9877-6
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Fan, 2020, IEEE T NEUR NET LEAR
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Fehn, 2003, INT ASS SCI TECHN DE
   Fu HZ, 2015, PROC CVPR IEEE, P4428, DOI 10.1109/CVPR.2015.7299072
   Fu K., 2020, P IEEE CVF C COMP VI, P3052
   Hamout H, 2020, IEEE T CIRC SYST VID, V30, P1933, DOI 10.1109/TCSVT.2019.2918770
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang J.B., 2020, CVPR
   Kang SJ, 2014, IEEE T CONSUM ELECTR, V60, P710, DOI 10.1109/TCE.2014.7027347
   Kao CC, 2017, MULTIMED TOOLS APPL, V76, P12981, DOI 10.1007/s11042-016-3733-3
   Kim SY, 2012, IEEE T CONSUM ELECTR, V58, P971, DOI 10.1109/TCE.2012.6311344
   Klingensmith M, 2016, IEEE ROBOT AUTOM LET, V1, P1156, DOI 10.1109/LRA.2016.2518242
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Lei JJ, 2017, MULTIMED TOOLS APPL, V76, P7661, DOI 10.1007/s11042-016-3413-3
   Liang CW, 2018, IEEE T CIRC SYST VID, V28, P2920, DOI 10.1109/TCSVT.2017.2715045
   Liming Zhang, 2016, Proceedings of the International Conferences on Interfaces and Human-Computer Interaction 2016, Game and Entertainment Technologies 2016, and Computer Graphics, Visualization, Computer Vision and Image Processing 2016, P278
   Liu JY, 2012, INT C PATT RECOG, P2055
   Ma FC, 2019, IEEE INT CONF ROBOT, P3288, DOI [10.1109/ICRA.2019.8793637, 10.1109/icra.2019.8793637]
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   McMillan Jr L, 1997, IMAGE BASED APPROACH
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Miao D, 2012, IEEE INT SYMP CIRC S, P604, DOI 10.1109/ISCAS.2012.6272103
   Minoli D., 2010, 3DTV CONTENT CAPTURE, ENCODING AND TRANSMISSION: Bulding the transport infraestruture for commercial services
   Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Song R, 2015, J INF SCI ENG, V31, P1593
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang WS, 2020, IEEE T INTELL VEHICL, V5, P485, DOI 10.1109/TIV.2020.2973550
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu Y, 2019, IEEE I CONF COMP VIS, P2811, DOI 10.1109/ICCV.2019.00290
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yao L, 2019, MULTIMED TOOLS APPL, V78, P19325, DOI 10.1007/s11042-019-7236-x
   Yin HX, 2015, INT CONF CONTR AUTO, P313, DOI 10.1109/ICCAIS.2015.7338683
   Zhang HT, 2018, MULTIMED TOOLS APPL, V77, P9003, DOI 10.1007/s11042-017-4791-x
   Zhang Jiazhao, 2020, CVPR
   Zhang S, 2011, INT C INF TECHN COMP
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 59
TC 4
Z9 4
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19179
EP 19201
DI 10.1007/s11042-021-10662-0
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300005
DA 2024-07-18
ER

PT J
AU Placidi, G
   Avola, D
   Cinque, L
   Polsinelli, M
   Theodoridou, E
   Tavares, JMRS
AF Placidi, Giuseppe
   Avola, Danilo
   Cinque, Luigi
   Polsinelli, Matteo
   Theodoridou, Eleni
   Tavares, Joao Manuel R. S.
TI Data integration by two-sensors in a LEAP-based Virtual Glove for
   human-system interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual Glove (VG); Hand rehabilitation; Orthogonal LEAP motion sensors;
   Human-system interaction; Data-integration
AB Virtual Glove (VG) is a low-cost computer vision system that utilizes two orthogonal LEAP motion sensors to provide detailed 4D hand tracking in real-time. VG can find many applications in the field of human-system interaction, such as remote control of machines or tele-rehabilitation. An innovative and efficient data-integration strategy, based on the velocity calculation, for selecting data from one of the LEAPs at each time, is proposed for VG. The position of each joint of the hand model, when obscured to a LEAP, is guessed and tends to flicker. Since VG uses two LEAP sensors, two spatial representations are available each moment for each joint: the method consists of the selection of the one with the lower velocity at each time instant. Choosing the smoother trajectory leads to VG stabilization and precision optimization, reduces occlusions (parts of the hand or handling objects obscuring other hand parts) and/or, when both sensors are seeing the same joint, reduces the number of outliers produced by hardware instabilities. The strategy is experimentally evaluated, in terms of reduction of outliers with respect to a previously used data selection strategy on VG, and results are reported and discussed. In the future, an objective test set has to be imagined, designed, and realized, also with the help of an external precise positioning equipment, to allow also quantitative and objective evaluation of the gain in precision and, maybe, of the intrinsic limitations of the proposed strategy. Moreover, advanced Artificial Intelligence-based (AI-based) real-time data integration strategies, specific for VG, will be designed and tested on the resulting dataset.
C1 [Placidi, Giuseppe; Polsinelli, Matteo; Theodoridou, Eleni] Univ Aquila, Dept Life Hlth & Environm Sci, A2VI Lab, I-67100 Laquila, Italy.
   [Avola, Danilo; Cinque, Luigi] Sapienza Univ, Dept Comp Sci, I-00198 Rome, Italy.
   [Tavares, Joao Manuel R. S.] Univ Porto, Fac Engn, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Dept Engn Mecan, P-4200465 Porto, Portugal.
C3 University of L'Aquila; Sapienza University Rome; Universidade do Porto
RP Placidi, G (corresponding author), Univ Aquila, Dept Life Hlth & Environm Sci, A2VI Lab, I-67100 Laquila, Italy.
EM giuseppe.placidi@univaq.it; avola@di.uniroma1.it; cinque@di.uniroma1.it;
   matteo.polsinelli@graduate.univaq.it;
   eleni.theodoridou@graduate.univaq.it; tavares@fe.up.pt
RI Tavares, João Manuel R.S./M-5305-2013; Placidi, Giuseppe/R-4065-2019
OI Tavares, João Manuel R.S./0000-0001-7603-6526; Placidi,
   Giuseppe/0000-0002-4790-4029
FU Universit a degli Studi dell' Aquila
FX Open Access funding provided by Universit a degli Studi dell' Aquila
CR Ameur S, 2020, ENTERTAIN COMPUT, V35, DOI 10.1016/j.entcom.2020.100373
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P18387, DOI 10.1007/s11042-020-08758-0
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Avola D, 2013, COMPUT METH PROG BIO, V110, P490, DOI 10.1016/j.cmpb.2013.01.009
   Bachmann D, 2015, SENSORS-BASEL, V15, P214, DOI 10.3390/s150100214
   Battaglia E, 2016, IEEE T HAPTICS, V9, P121, DOI 10.1109/TOH.2015.2482478
   Carrieri M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00053
   Chaudhary A., 2011, Int J Comput Sci Eng Survey, V2, P122, DOI DOI 10.5121/IJCSES.2011.2109
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen SJ, 2015, LECT NOTES ARTIF INT, V9244, P581, DOI 10.1007/978-3-319-22879-2_53
   Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048
   Erden F, 2014, IEEE T CONSUM ELECTR, V60, P675, DOI 10.1109/TCE.2014.7027342
   Horv?th, 2011, INT J VIRT REALITY, V10, P1, DOI [10.20870/IJVR.2011.10.2.2805, DOI 10.20870/IJVR.2011.10.2.2805]
   Iacoviello D, 2016, IEEE T CYBERNETICS, V46, P3171, DOI 10.1109/TCYB.2015.2498974
   Imran J, 2020, VISUAL COMPUT, V36, P1233, DOI 10.1007/s00371-019-01725-3
   Jin HY, 2016, CAAI T INTELL TECHNO, V1, P104, DOI 10.1016/j.trit.2016.03.010
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Kiselev V, 2019, PROC CONF OPEN INNOV, P163, DOI [10.23919/FRUCT.2019.8711887, 10.23919/fruct.2019.8711887]
   Kumar P, 2018, PATTERN RECOGN LETT, V103, P1, DOI 10.1016/j.patrec.2017.12.014
   Liu YK, 2015, IEEE T AUTOM SCI ENG, V12, P769, DOI 10.1109/TASE.2014.2359006
   Luzhnica G, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P81, DOI 10.1109/3DUI.2016.7460035
   Mandikhanlou K, 2020, MULTIMED TOOLS APPL, V79, P22235, DOI 10.1007/s11042-020-08982-8
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Mehryar MohriAfshin Rostamizadeh Ameet Talwalkar., 2018, FDN MACHINE LEARNING
   Mizera C, 2020, IEEE SENS J, V20, P1642, DOI 10.1109/JSEN.2019.2947612
   Moro SB, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/3/036002
   Placidi G, 2007, COMPUT BIOL MED, V37, P1100, DOI 10.1016/j.compbiomed.2006.09.011
   Placidi G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030834
   Placidi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P184, DOI 10.5220/0006197801840192
   Placidi G, 2013, COMPUT BIOL MED, V43, P1927, DOI 10.1016/j.compbiomed.2013.08.026
   Prasad MG, 2019, IET CYBER-SYST ROBOT, V1, P81, DOI 10.1049/iet-csr.2019.0016
   Quintas J, 2017, IEEE T HUM-MACH SYST, V47, P323, DOI 10.1109/THMS.2016.2634923
   Shen H, 2019, IEEE ASME INT C ADV, P193, DOI [10.1109/aim.2019.8868827, 10.1109/AIM.2019.8868827]
   Shi Z., 2019, ADV ARTIFICIAL INTEL, V2nd ed.
   Sun R, 2020, J SYST ENG ELECTRON, V31, P45, DOI 10.21629/JSEE.2020.01.06
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Wang ZQ, 2020, IEEE T IND ELECTRON, V67, P7681, DOI 10.1109/TIE.2019.2924860
   Wei LJ, 2015, J TEKNOL, V74, P153
   Yang LC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072106
   Zhang W, 2019, APPL SCI, V9, P1
NR 41
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18263
EP 18277
DI 10.1007/s11042-020-10296-8
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700013
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Morel, O
   Seulin, R
   Mériaudeau, F
   Sidibé, D
AF Zhang, Yifei
   Morel, Olivier
   Seulin, Ralph
   Meriaudeau, Fabrice
   Sidibe, Desire
TI A central multimodal fusion framework for outdoor scene image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Multi-modality; Semantic segmentation; Deep learning
AB Robust multimodal fusion is one of the challenging research problems in semantic scene understanding. In real-world applications, the fusion system can overcome the drawbacks of individual sensors by taking different feature representations and statistical properties of multiple modalities (e.g., RGB-depth cameras, multispectral cameras). In this paper, we propose a novel central multimodal fusion framework for semantic image segmentation of road scenes, aiming to effectively learn joint feature representations and optimally combine deep neural networks with statistical priors. More specifically, the proposed fusion framework can automatically generate a central branch by sequentially mapping multimodal features into a common space, including both low-level and high-level features. Besides, in order to reduce the model uncertainty, we employ statistical fusion to compute the final prediction, which leads to significant performance improvement. We conduct extensive experiments on various outdoor scene datasets. Both qualitative and quantitative experiments demonstrate that our central fusion framework achieves competitive performance against existing multimodal fusion methods.
C1 [Zhang, Yifei; Morel, Olivier; Seulin, Ralph; Meriaudeau, Fabrice] Univ Bourgogne Franche Comte, VIBOT ERL CNRS 6000, ImViA, F-71200 Le Creusot, France.
   [Sidibe, Desire] Univ Evry, Univ Paris Saclay, IBISC, F-91020 Evry, France.
C3 Universite de Bourgogne; Universite Paris Saclay; Universite Paris Cite
RP Zhang, YF (corresponding author), Univ Bourgogne Franche Comte, VIBOT ERL CNRS 6000, ImViA, F-71200 Le Creusot, France.
EM yifei.zhang@u-bourgogne.fr
RI SIDIBE, DESIRE/AFQ-8070-2022; MOREL, Olivier/AAK-3190-2020; Zhang,
   Yifei/GRO-3001-2022
OI SIDIBE, DESIRE/0000-0002-5843-7139; MOREL, Olivier/0000-0001-5768-2821; 
FU French Agence Nationale de la Recherche (ANR) [ANR-17-CE22-0011]; NVIDIA
   Corporation; Agence Nationale de la Recherche (ANR) [ANR-17-CE22-0011]
   Funding Source: Agence Nationale de la Recherche (ANR)
FX This research was supported by the French Agence Nationale de la
   Recherche (ANR), under the ANR-17-CE22-0011 (project ICUB). We
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of GPUs used in this research.
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Arevalo J, 2017, ARXIV170201992
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Blanchon M, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P328, DOI 10.5220/0007360203280335
   Blum H, 2018, IEEE INT C INT ROBOT, P3670, DOI 10.1109/IROS.2018.8593786
   Burgard W, 2016, DEEP MULTISPECTRAL S
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2019, ARXIV190700135
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Harchanko John S., 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5888, P588815, DOI 10.1117/12.623542
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Jiang JingJing, 2018, How teens and parents navigate screen time and device distractions
   Kaymak C. C., 2019, Handbook of Deep Learning Applications, P161, DOI DOI 10.1007/978-3-030-11479-4
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Li YB, 2017, IEEE IMAGE PROC, P1262, DOI 10.1109/ICIP.2017.8296484
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Oberweger M., 2015, Hands deep in deep learning for hand pose estimation, P21, DOI DOI 10.1177/0093650215617505
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F., 2018, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-030-01234-2_49
   Simonyan K., 2014, CORR
   Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540
   Valada A, 2018, ARXIV180803833
   Vielzeuf V., 2018, P EUROPEAN C COMPUTE
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Yu F., 2015, ARXIV
   Zhang YF, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P336, DOI 10.5220/0007360403360343
NR 38
TC 3
Z9 3
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12047
EP 12060
DI 10.1007/s11042-020-10357-y
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000618948700003
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Liu, TT
   Cattani, C
   Cui, Q
   Liu, SX
AF Zhang, Yujin
   Liu, Tingting
   Cattani, Carlo
   Cui, Qing
   Liu, Shuxian
TI Diffusion-based image inpainting forensics via weighted least squares
   filtering enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Image forensics; Diffusion-based image inpainting; Blurring
   effect; Weighted least squares filtering
AB The rapid development of blockchain technology has greatly changed people's daily lives from financial market to healthcare field. Today, adulterated images appear in large numbers, causing a serious threat to personal privacy and social stability. At present, the research on blockchain is mainly focused on chain data transmission. Though the blockchain can ensure that the chain data transmission is not tampered, it is difficult to ensure that the data is real when placed on the system initially. In addition, the immutability will be destroyed when 51% attacks occur. Taking this point into consideration, it is necessary to identify the image authenticity on the blockchain. Diffusion-based inpainting is a common method of image tampering. Considering the blurring effect introduced by diffusion-based image inpainting, this paper proposes an image forensics method of diffusion-based image inpainting via weighted least squares filtering enhancement. The texture of the forged image is clear in the untouched regions, and the blurring effect leads to some texture changes in the inpainted regions. Weighted least squares filtering can preserve the texture structure of the untouched regions better and highlight the blurring effect of the inpainted regions. In view of the different reflects of the tampered information in different color channels, weighted least squares filtering is applied to enhance each color channel of the input image, which can capture the impact of image inpainting from multiple perspectives. The experimental results show that the proposed method not only makes up for the deficiency of previous blockchain forensics effectively, but also has better detection performance than the existing work.
C1 [Zhang, Yujin; Liu, Tingting] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
   [Zhang, Yujin] Shanghai Jiao Tong Univ, Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
   [Cattani, Carlo] Univ Tuscia, Engn Sch DEIM, I-01100 Viterbo, Italy.
   [Cui, Qing; Liu, Shuxian] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
C3 Shanghai University of Engineering Science; Shanghai Jiao Tong
   University; Tuscia University; Xinjiang University
RP Zhang, YJ (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.; Zhang, YJ (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
EM eeyjzhang@gmail.com
RI Cattani, Carlo/I-5051-2013
OI Cattani, Carlo/0000-0002-7504-0424
FU National Natural Science Foundation of China [61762085]; Natural Science
   Foundation of Shanghai [17ZR1411900]; Opening Project of Shanghai Key
   Laboratory of Integrated Administration Technologies for Information
   Security [AGK2015006]; Natural Science Foundation of Xinjiang
   [2020D01C047, 2019D01C081]; Founding Program for the Cultivation of
   Young University Teachers of Shanghai [ZZGCD15090]
FX This work is mainly funded by the National Natural Science Foundation of
   China (grant no. 61762085), the Natural Science Foundation of Shanghai
   (grant no. 17ZR1411900), the Opening Project of Shanghai Key Laboratory
   of Integrated Administration Technologies for Information Security
   (grant no. AGK2015006), the Natural Science Foundation of Xinjiang
   (grant nos. 2020D01C047, 2019D01C081), the Founding Program for the
   Cultivation of Young University Teachers of Shanghai (grant no.
   ZZGCD15090).
CR Amrani N, 2017, IEEE GEOSCI REMOTE S, V14, P1203, DOI 10.1109/LGRS.2017.2702106
   Arablouei R, 2012, IEEE T SIGNAL PROCES, V60, P6687, DOI 10.1109/TSP.2012.2217339
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Buyssens P, 2015, IEEE T IMAGE PROCESS, V24, P1809, DOI 10.1109/TIP.2015.2411437
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Islam MM, 2018, LECT NOTES COMPUT SC, V11304, P555, DOI 10.1007/978-3-030-04212-7_49
   Jiang Y, 2014, IET IMAGE PROCESS, V8, P183, DOI 10.1049/iet-ipr.2013.0429
   Kim WH, 2019, MULTIMED TOOLS APPL, V78, P16887, DOI 10.1007/s11042-018-6879-3
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Li SJ, 2017, IET IMAGE PROCESS, V11, P870, DOI 10.1049/iet-ipr.2016.0898
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Ren YX, 2019, IEEE T GEOSCI REMOTE, V57, P1265, DOI 10.1109/TGRS.2018.2865507
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sheng HD, 2018, IET IMAGE PROCESS, V12, P1815, DOI 10.1049/iet-ipr.2017.1131
   Shrestha R, 2019, IEEE ACCESS, V7, P95033, DOI 10.1109/ACCESS.2019.2928753
   Song YD, 2016, IEEE GEOSCI REMOTE S, V13, P18, DOI 10.1109/LGRS.2015.2492569
   Su ZY, 2021, IEEE T CIRC SYST VID, V31, P1648, DOI 10.1109/TCSVT.2020.3002146
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Wan W., 2018, MULTIMED TOOLS APPL, V49074930, P79
   Wang S, 2019, IEEE T SYST MAN CY-S, V49, P2266, DOI 10.1109/TSMC.2019.2895123
   Yao HP, 2019, IEEE T IND INFORM, V15, P3602, DOI 10.1109/TII.2019.2902563
   Zhang YJ, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2020.164196
NR 27
TC 12
Z9 13
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30725
EP 30739
DI 10.1007/s11042-021-10623-7
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000617861300003
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Das, N
   Sarkar, P
   Nasipuri, M
AF Ghosh, Swarnendu
   Das, Nibaran
   Sarkar, Priyam
   Nasipuri, Mita
TI JU-VNT: a multi-spectral dataset of indoor object recognition using
   visible, near-infrared and thermal spectrum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multispectral image processing; Thermal image; Near infrared image; Deep
   learning
ID IMAGERY
AB Detecting objects in natural scenes can be a very challenging task. In several real-life scenarios it is often found that visible spectrum is not ideal for typical computer vision tasks. Going beyond the range of visible light spectrum, such as the near infrared spectrum or the thermal spectrum allows us to capture many unique properties of objects that normally not captured with a normal camera. In this work we propose two multi-spectral dataset with three different spectrum, namely, the visible, near infrared and thermal spectrum. The first dataset is a single object dataset where we have common desk objects of 25 different categories comprising of various materials. The second dataset comprises of all possible combination using these 25 objects taking a pair at a time. The objects are captured from 8 different angles using the three different cameras. The images are registered and cropped and provided along with classification and localization ground truths. Additionally classification benchmarks have been provided using the ResNet, InceptionNet and DenseNet architectures on both the datasets. The dataset would be publicly available from .
C1 [Ghosh, Swarnendu; Das, Nibaran; Sarkar, Priyam; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, WB, India.
C3 Jadavpur University
RP Das, N (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, WB, India.
EM nibaran@gmail.com
FU SERB (Government of India) [SB/S3/EECE/054/2016]; Centre for
   Microprocessor Application for Training Education and Research, CSE
   Department, Jadavpur University
FX This work is supported by the project sponsored by SERB (Government of
   India, order no. SB/S3/EECE/054/2016) (dated 25/11/2016), and carried
   out at the Centre for Microprocessor Application for Training Education
   and Research, CSE Department, Jadavpur University. Special thanks to
   Somenath Kuiry for his contribution during revision.
CR Aguilera Cristhian, 2017, INT C PRACT APPL AG
   Alldieck T, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111947
   Ambinder, NAT J, V3
   Belford R, 2006, AUSTR SOC AGRON, V17
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Choe G, 2018, IEEE ROBOT AUTOM LET, V3, P1808, DOI 10.1109/LRA.2018.2801390
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Dutta A., 2020, 2020 IEEE INT C POWE, P1, DOI DOI 10.1109/PEDES49360.2020.9379823
   Farley V, 2007, P SOC PHOTO-OPT INS, V6739, P73918, DOI 10.1117/12.736864
   Ferwerda, 2005, CHARTING QUALITY FOR
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Higging K. T., 2013, Food Processing, USA, V74, P81
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Lacar FM, 2001, INT GEOSCI REMOTE SE, P2875, DOI 10.1109/IGARSS.2001.978191
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shahidi AM, 2013, EXP EYE RES, V113, P143, DOI 10.1016/j.exer.2013.06.001
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vermeulen, 2017, J SPECTRAL IMAG, V6
   Wang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040893
   Wilcox, 2012, ANALYTICAL COMPUTATI
NR 29
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17807
EP 17826
DI 10.1007/s11042-020-10302-z
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617417600005
DA 2024-07-18
ER

PT J
AU Lukman, A
   Yang, CK
AF Lukman, Achmad
   Yang, Chuan-Kai
TI An object recognition system based on convolutional neural networks and
   angular resolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Angular resolution; Incremental learning
AB The development of 3D object recognition often requires a huge amount of data in the training process, especially when deep learning methods are involved so that the training can be convergent. The problem is that the availability of free 3D object datasets is usually quite limited, so some researchers have proposed several techniques to overcome this problem. In this work, we propose a novel algorithm, making use of angular resolutions and convolutional neural networks for 3D object recognition, and it collects image shapes or contours from real objects by placing them on a rotating display to record the appearances from multiple angular views. The chosen angular resolution is in the range of 0-180 degrees, and the selection of viewing angle is done by a binary search. We have conducted a comparative experiment on the accuracy of 6 well-known network architectures, including GoogleNet, CaffeNet, SqueezeNet, ResNet18, ResNet32, and ResNet50, to see how far these architecture networks can adapt to the angular resolution techniques that we propose for the classification of objects outside the lab environment. We also propose another way with the use of incremental learning, where we integrate our proposed method that uses GoogleNet model with two existing weights pre-trained models, i.e., AlexNet and VGG16. In other words, our proposed method helps address the limitations of other models with the weights of existing pre-trained methods to recognize new classes that were not recognized.
C1 [Lukman, Achmad; Yang, Chuan-Kai] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM D10509802@mail.ntust.edu.tw; ckyang@cs.ntust.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST
   106-2221-E-011-148-MY3]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the grant MOST 106-2221-E-011-148-MY3.
CR Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gutstein S, 2015, IEEE IJCNN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, NEURAL NETW STAT MEC, V261, P276
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li WJ, 2008, IEEE T IMAGE PROCESS, V17, P2236, DOI 10.1109/TIP.2008.2003404
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Ma J, 2019, IEEE ELECTR POW ENER
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Moujahid A., 2018, PRACTICAL INTRO DEEP, V19, P2016
   Muresan H, 2018, ACTA U SAPIEN INFORM, V10, P26, DOI 10.2478/ausi-2018-0002
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Roy K, 2017, ARXIV171202719
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Serra J., 2018, arXiv:1801.01423
   Shmelkov K, 2017, IEEE I CONF COMP VIS, P3420, DOI 10.1109/ICCV.2017.368
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Wang ZD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041126
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yang Z, 2019, NEURAL COMPUT APPL, V31, P6469, DOI 10.1007/s00521-018-3468-3
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
   Zhou H, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P56, DOI 10.1145/3177404.3177433
NR 34
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 16059
EP 16085
DI 10.1007/s11042-020-10312-x
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000616158900002
DA 2024-07-18
ER

PT J
AU Mo, YH
   Zhang, PL
   Chen, ZJ
   Ran, B
AF Mo, Yanghui
   Zhang, Peilin
   Chen, Zhijun
   Ran, Bin
TI A method of vehicle-infrastructure cooperative perception based vehicle
   state information fusion using improved kalman filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle-infrastructure cooperative perception; Cooperative automated
   driving system; Position data fusion; Kalman filter
ID LIDAR; FRAMEWORK; TRACKING; CAMERA
AB For the purpose of overcoming the technical bottlenecks and limitations of autonomous vehicles on the information perception, and improving the sensing range and performance of vehicle driving environment and traffic information, a framework of vehicle-infrastructure cooperative perception for the Cooperative Automated Driving System is proposed in this paper. Taking the vehicle state information as an example, it also introduced a calculation method of data fusion for vehicle-infrastructure cooperative perception. Besides, considering that the intelligent roadside equipment may appear short-term sensing failure, the proposed method improved the traditional Kalman Filter to output position information even when the roadside fails. Compared with the vehicle-only perception, the simulation experiments verified that the proposed method could improve the average positioning accuracy under the normal condition and the intelligent roadside failure by 18% and 19%, respectively. The proposed framework provided a solution for coordinating and fusing perception intelligence and functions between connected automated vehicles, intelligent infrastructure and intelligent control system. The proposed improved Kalman Filter method provides flexible strategies for practical application.
C1 [Mo, Yanghui; Zhang, Peilin; Chen, Zhijun] Wuhan Univ Technol, Wuhan, Peoples R China.
   [Ran, Bin] Univ Wisconsin, Madison, WI USA.
C3 Wuhan University of Technology; University of Wisconsin System;
   University of Wisconsin Madison
RP Zhang, PL; Chen, ZJ (corresponding author), Wuhan Univ Technol, Wuhan, Peoples R China.
EM moyanghui@outlook.com; plzhanghq@126.com; chenzj556@whut.edu.cn;
   bran@wisc.edu
FU National Key R&D Program of China [2018YFB1600600]
FX The work presented in this paper was funded by National Key R&D Program
   of China under Grants 2018YFB1600600.
CR Arnold E, 2019, ARXIV191212147V2, V1, P1
   Bazzi A, 2017, IEEE T VEH TECHNOL, V66, P10419, DOI 10.1109/TVT.2017.2750803
   Bento LC, 2019, J INTELL TRANSPORT S, V23, P41, DOI 10.1080/15472450.2018.1501272
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   Dianati M, 2017, P 12 ITS EUR C, P1
   Fascista A, 2018, IEEE T INTELL TRANSP, V19, P2880, DOI 10.1109/TITS.2017.2769488
   Hoang GM, 2017, IEEE INT VEH SYM, P1372, DOI 10.1109/IVS.2017.7995902
   Gong XJ, 2013, OPT LASER ENG, V51, P394, DOI 10.1016/j.optlaseng.2012.11.015
   Gulati D, 2017, P 20 INT C INF FUS F, P1
   Gulati D, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2225, DOI 10.23919/ICIF.2018.8455268
   Gupta M, 2022, IEEE T SERV COMPUT, V15, P1912, DOI 10.1109/TSC.2020.3025993
   Huang G, 2021, P I MECH ENG D-J AUT, V235, P177, DOI 10.1177/0954407020943306
   Kim B, 2016, IFAC PAPERSONLINE, V49, P190, DOI 10.1016/j.ifacol.2016.08.029
   Kitazato T, 2016, 9 INT C MOBILE COMPU, P1
   Kong FY, 2020, MULTIMED TOOLS APPL, V79, P35195, DOI 10.1007/s11042-019-7614-4
   Lin PQ, 2017, IEEE INTEL TRANSP SY, V9, P37, DOI 10.1109/MITS.2017.2743167
   Liu ZC, 2019, TRANSPORT RES C-EMER, V106, P381, DOI 10.1016/j.trc.2019.07.022
   Ma SG, 2019, IEEE ACCESS, V7, P46114, DOI 10.1109/ACCESS.2019.2909796
   Malikopoulos AA, 2018, AUTOMATICA, V93, P244, DOI 10.1016/j.automatica.2018.03.056
   Milanés V, 2012, IEEE T INTELL TRANSP, V13, P49, DOI 10.1109/TITS.2011.2178839
   Montanaro U, 2018, IEEE INT C INTELL TR, P1258, DOI 10.1109/ITSC.2018.8569295
   Ni YZ, 2018, IEEE T VEH TECHNOL, V67, P4602, DOI 10.1109/TVT.2018.2796563
   PTP SLPP., 2019, ITE J, V89, P37
   Ran B., 2019, U.S. Patent, Patent No. [10,380,886, 10380886]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shi K, 2019, U.S. patent application, Patent No. [16/406,621, 16406621]
   Tekeli M, 2018, IEEE INT VEH SYM, P854, DOI 10.1109/IVS.2018.8500449
   Tian D., 2017, P 6 ACM S DEV AN INT, P85, DOI DOI 10.1145/3132340.3132347
   Tixiao S, 2020, LEGO LOAM
   Wan GW, 2018, IEEE INT CONF ROBOT, P4670, DOI 10.1109/ICRA.2018.8461224
   Wang C, 2018, IEEE INTEL TRANSP SY, V10, P180, DOI 10.1109/MITS.2018.2806627
   Wang M, 2014, TRANSPORT RES C-EMER, V40, P290, DOI 10.1016/j.trc.2013.11.024
   Wu Y, 2019, U.S. patent, Patent No. [10:692-365, 10692365]
   Xu B, 2019, IEEE T INTELL TRANSP, V20, P1390, DOI 10.1109/TITS.2018.2849029
   Yoon DD, 2019, IEEE T CONTR SYST T, P1
   Zhang FH, 2016, GEOINFORMATICA, V20, P159, DOI 10.1007/s10707-016-0244-3
   Zhao JX, 2019, TRANSPORT RES C-EMER, V100, P68, DOI 10.1016/j.trc.2019.01.007
   Zhao XM, 2017, OPTIK, V138, P407, DOI 10.1016/j.ijleo.2017.03.102
NR 39
TC 18
Z9 22
U1 13
U2 144
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4603
EP 4620
DI 10.1007/s11042-020-10488-2
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000615174300004
DA 2024-07-18
ER

PT J
AU Mangipudi, PS
   Pandey, HM
   Choudhary, A
AF Mangipudi, Partha Sarathi
   Pandey, Hari Mohan
   Choudhary, Ankur
TI Improved optic disc and cup segmentation in Glaucomatic images using
   deep learning architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Fundus image; Convolution filters; Overfitting; Optic disc;
   Optic cup
ID NEURAL-NETWORK; IDENTIFICATION; TRANSFORM
AB Glaucoma is an ailment causing permanent vision loss but can be prevented through the early detection. Optic disc to cup ratio is one of the key factors for glaucoma diagnosis. But accurate segmentation of disc and cup is still a challenge. To mitigate this challenge, an effective system for optic disc and cup segmentation using deep learning architecture is presented in this paper. Modified Groundtruth is utilized to train the proposed model. It works as fused segmentation marking by multiple experts that helps in improving the performance of the system. Extensive computer simulations are conducted to test the efficiency of the proposed system. For the implementation three standard benchmark datasets such as DRISHTI-GS, DRIONS-DB and RIM-ONE v3 are used. The performance of the proposed system is validated against the state-of-the-art methods. Results indicate an average overlapping score of 96.62%, 96.15% and 98.42% respectively for optic disc segmentation and an average overlapping score of 94.41% is achieved on DRISHTI-GS which is significant for optic cup segmentation.
C1 [Mangipudi, Partha Sarathi] Amity Univ, Dept Elect & Commun Engn, Noida, India.
   [Pandey, Hari Mohan] Edge Hill Univ, Dept Comp Sci, Ormskirk, Lancs, England.
   [Choudhary, Ankur] Sharda Univ, Dept Comp Sci & Engn, Greater Noida, India.
C3 Amity University Noida; Edge Hill University; Sharda University
RP Pandey, HM (corresponding author), Edge Hill Univ, Dept Comp Sci, Ormskirk, Lancs, England.
EM infiniti47@gmail.com; Pandeyh@edgehill.ac.uk; ankur.tomer@gmail.com
RI Pandey, Hari Mohan/M-9658-2015; Mangipudi, Parthasarathi/AAI-1805-2021
OI Pandey, Hari Mohan/0000-0002-9128-068X; Mangipudi,
   Parthasarathi/0000-0002-6186-6567
CR Abadi Martin, 2016, arXiv
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Acharya UR, 2016, COMPUT BIOL MED, V73, P131, DOI 10.1016/j.compbiomed.2016.04.009
   Agarwal A, 2016, INT CONF CONTEMP, P210
   [Anonymous], 2012, NIPS 12 P 25 INT C N, DOI DOI 10.5555/2999325.2999452
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Brox, DENT XRAY IMAGE SEGM
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chakravarty A, 2016, I S BIOMED IMAGING, P689, DOI 10.1109/ISBI.2016.7493360
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   DAMMS T, 1993, INVEST OPHTH VIS SCI, V34, P2246
   de la Rosa, 2015, ESTIMATION RELATIVE
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gao X., 2017, P IEEE INT C COMM, P1
   Ghoshal R, 2019, MULTIMED TOOLS APPL, V78, P25221, DOI 10.1007/s11042-019-7719-9
   Glaucoma Marsden J, NURS TIMES, V110, P42
   Glaucoma Research Foundation, 2017, 5 COMM GLAUC TESTS
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hagiwara Y, 2018, COMPUT METH PROG BIO, V165, P1, DOI 10.1016/j.cmpb.2018.07.012
   Hsu HY, 2020, COMPUT COMMUN, V160, P91, DOI 10.1016/j.comcom.2020.05.035
   Issac A, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION CONTROL AND INTELLIGENT SYSTEMS (CCIS), P76, DOI 10.1109/CCIntelS.2016.7878204
   Jiang Y, 2019, IEEE ACCESS, V7, P64483, DOI 10.1109/ACCESS.2019.2917508
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Koh JEW, 2018, APPL INTELL, V48, P1379, DOI 10.1007/s10489-017-1048-3
   Koh JEW, 2017, COMPUT BIOL MED, V84, P89, DOI 10.1016/j.compbiomed.2017.03.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lim G, 2015, PROC INT C TOOLS ART, P162, DOI 10.1109/ICTAI.2015.36
   Liu J, 2015, P OPTHM MED IM AN 2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Medeiros FA, 2019, LANCET DIGIT HEALTH, V1, pE151, DOI 10.1016/S2589-7500(19)30087-1
   Phasuk S, 2019, IEEE ENG MED BIO, P904, DOI [10.1109/embc.2019.8857136, 10.1109/EMBC.2019.8857136]
   QUIGLEY HA, 1979, OPHTHALMOLOGY, V86, P1803
   Raghavendra U, 2018, BIOCYBERN BIOMED ENG, V38, P170, DOI 10.1016/j.bbe.2017.11.002
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadhukhan S, 2018, LECT NOTES COMPUT SC, V11045, P369, DOI 10.1007/978-3-030-00889-5_42
   Sarathi MP, 2016, BIOMED SIGNAL PROCES, V25, P108, DOI 10.1016/j.bspc.2015.10.012
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Sevastopolsky A, 2019, PROC SPIE, V10949, DOI 10.1117/12.2511572
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2019, PROC SPIE, V11139, DOI 10.1117/12.2529429
   Sivaswamy J., 2015, JSM Biomedical Imaging Data Papers, V2, P1004
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Srivastava R, 2015, I S BIOMED IMAGING, P768, DOI 10.1109/ISBI.2015.7163985
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Yidong Chai, 2017, Smart Health. International Conference, ICSH 2017. Proceedings: LNCS 10347, P191, DOI 10.1007/978-3-319-67964-8_19
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zilly Julian G., 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P136, DOI 10.1007/978-3-319-24888-2_17
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
   2018, PROC CVPR IEEE
NR 61
TC 5
Z9 5
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30143
EP 30163
DI 10.1007/s11042-020-10430-6
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000613993900004
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Gao, CY
   Yao, R
   Zhou, Y
   Zhao, JQ
   Fang, L
   Hu, FY
AF Gao, Cunyuan
   Yao, Rui
   Zhou, Yong
   Zhao, Jiaqi
   Fang, Liang
   Hu, Fuyuan
TI Efficient lightweight video person re-identification with online
   difference discrimination module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video person re-identification; Spatial attention; Video temporal
   modeling
AB Video person re-identification (video Re-ID) is a key technology applied to video surveillance and security. Typical person re-identification is designed to retrieve the correct match of the target image (query) from gallery images, while video Re-ID extends this to query from gallery videos. The main factors affecting the video Re-ID model are: (i) a high-quality frame-level feature extractor, and (ii) temporal modeling that combines frame-level features into a feature for retrieval. In this work, we use ShuffleNet V2-based lightweight algorithm for video Re-ID, which can meet the demand for practical application and solve the problem of high consumption for computing resources, and maintain high performance. At the same time, the lightweight space attention mechanism Spatial Group-wise Enhance (SGE) module is used to view the person in more detail, which makes the feature representation more compact and effectively improves the retrieval accuracy. Finally, we design an Online Difference Discrimination (ODD) module to measure the feature gap between video frames, and use this module to make different temporal modeling for different quality video sequences. Experiments on three datasets (i.e., iLIDS-VID, PRID2011 and MARS) show that our method is competitive with state-of-the-art methods.
C1 [Gao, Cunyuan; Yao, Rui; Zhou, Yong; Zhao, Jiaqi; Fang, Liang] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Yao, Rui; Hu, Fuyuan] Suzhou Univ Sci & Technol, Suzhou Smart City Res Inst, Suzhou 215009, Peoples R China.
C3 China University of Mining & Technology; Suzhou University of Science &
   Technology
RP Yao, R (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Yao, R (corresponding author), Suzhou Univ Sci & Technol, Suzhou Smart City Res Inst, Suzhou 215009, Peoples R China.
EM cunyuangao@cumt.edu.cn; ruiyao@cumt.edu.cn; yzhou@cumt.edu.cn;
   jiaqizhao@cumt.edu.cn; liangfang@cumt.edu.cn
RI Fang, Liang/V-5019-2018
OI Yao, Rui/0000-0003-2734-915X
FU National Natural Science Foundation of China [61772530, 61806206,
   61876121]; State's Key Project of Research and Development Plan of China
   [2016YFC0600908]; Natural Science Foundation of Jiangsu Province of
   China [BK20171192, BK20180639]; Six Talent Peaks Project in Jiangsu
   Province [2018-XYDXX-044]; Open Foundation of the Suzhou Smart City
   Research Institute, Suzhou University of Science and Technology
   [SZSCR2019005]; Xuzhou Science and Technology Plan Funds [KC19005]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61772530, No. 61806206, No. 61876121), in part
   by the State's Key Project of Research and Development Plan of China
   (No.2016YFC0600908), in part by the Natural Science Foundation of
   Jiangsu Province of China (No. BK20171192, No. BK20180639), in part by
   the Six Talent Peaks Project in Jiangsu Province (No. 2018-XYDXX-044),
   in part by the Open Foundation of the Suzhou Smart City Research
   Institute, Suzhou University of Science and Technology (No.
   SZSCR2019005), and in part by the project supported by Xuzhou Science
   and Technology Plan Funds (No. KC19005).
CR Ahmed S, 2019, ARXIV190204856
   Chen D, 2016, LECT NOTES COMPUT SC, V9909, P122, DOI 10.1007/978-3-319-46454-1_8
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao XY, 2019, LECT NOTES COMPUT SC, V11366, P620, DOI 10.1007/978-3-030-20876-9_39
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Navaneet KL, 2019, INT CONF ACOUST SPEE, P2472, DOI 10.1109/ICASSP.2019.8682292
   Qiu W, 2020, IEEE T IMAGE PROCESS, V29, P100, DOI 10.1109/TIP.2019.2927458
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Su Xinxing, 2018, ARXIV180705799
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Zakria, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071291
   Zhang JF, 2018, PROC CVPR IEEE, P6781, DOI 10.1109/CVPR.2018.00709
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou QQ, 2019, IEEE T MULTIMEDIA, V21, P1183, DOI 10.1109/TMM.2018.2875360
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 40
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19169
EP 19181
DI 10.1007/s11042-021-10543-6
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000613057400007
DA 2024-07-18
ER

PT J
AU Feng, RW
   Cao, Y
   Liu, XC
   Chen, TT
   Chen, JT
   Chen, DZ
   Gao, H
   Wu, J
AF Feng, Ruiwei
   Cao, Yan
   Liu, Xuechen
   Chen, Tingting
   Chen, Jintai
   Chen, Danny Z.
   Gao, Honghao
   Wu, Jian
TI ChroNet: A multi-task learning based approach for prediction of multiple
   chronic diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chronic diseases; Prediction; Multi-task learning; Electronic medical
   records (EMR); Convolutional neural networks (CNNs)
ID HYPERTENSION; MODEL
AB Chronic diseases (such as diabetes, hypertension, etc) are generally of long duration and slow progression. These diseases may be implied in electronic medical records (EMR), and one chronic disease may be accompanied by another. Recently, many methods have been proposed for chronic disease prediction and early detection. However, previous methods mainly focused on predicting one individual disease, thus possibly neglecting potential correlations among multiple diseases. In this paper, we propose a new framework for chronic disease prediction which can take into account possible correlations among multiple chronic diseases, called ChroNet. We propose a Multi-task Learning (MTL) based framework, for multiple chronic disease prediction. First, based on the characteristics of EMR, we introduce a novel approach for data embedding, including Content Embedding and Spatial Embedding. Then, an MTL convolutional neural network (CNN) is designed to perform multiple chronic disease prediction simultaneously. We collect a dataset from 5 local hospitals, involving 48953 patients' records. Then we conduct abundant experiments for hypertension and type 2 diabetes prediction, based on our dataset. For both hypertension and type 2 diabetes prediction, our proposed framework outperforms known single-task models (with the same CNN layers yet a single branch). Further, our MTL-based framework outperforms several most commonly used traditional machine learning models and convolutional neural networks. Theoretically, our framework can capture general features of different diseases and focus its attention on those features that actually matter for each disease. The performance superiority in experiments indicates that our framework may be able to capture more detailed characteristics of medical structural data after specific embedding, comparing with known single-task models.
C1 [Feng, Ruiwei; Cao, Yan; Liu, Xuechen; Chen, Tingting; Chen, Jintai; Wu, Jian] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Feng, Ruiwei; Cao, Yan; Liu, Xuechen; Chen, Tingting; Chen, Jintai; Wu, Jian] Zhejiang Univ, Real Doctor AI Res Ctr, Hangzhou, Peoples R China.
   [Chen, Danny Z.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Gao, Honghao] Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
   [Gao, Honghao] Gachon Univ, Seongnam Si 461701, Gyeonggi Do, South Africa.
C3 Zhejiang University; Zhejiang University; University of Notre Dame;
   Shanghai University
RP Wu, J (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.; Wu, J (corresponding author), Zhejiang Univ, Real Doctor AI Res Ctr, Hangzhou, Peoples R China.; Gao, H (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.; Gao, H (corresponding author), Gachon Univ, Seongnam Si 461701, Gyeonggi Do, South Africa.
EM gaohonghao@shu.edu.cn; wujian2000@zju.edu.cn
RI ray, jay/GYV-3810-2022; Chen, Tingting/GYE-2046-2022; Gao,
   Honghao/AAX-4529-2020
OI Chen, Tingting/0000-0001-6705-4538; Gao, Honghao/0000-0001-6861-9684;
   Feng, Ruiwei/0000-0003-3732-7595
FU National Research and Development Program of China [2019YFB1404802,
   2019YFC0118802, 2018AAA0102102]; National Natural Science Foundation of
   China [61672453]; Zhejiang University Education Foundation
   [K18-511120-004, K17-511120-017, K17-518051-02]; Zhejiang public welfare
   technology research project [LGF20F020013]; Key Laboratory of Medical
   Neurobiology of Zhejiang Province; NSF [CCF-1617735]
FX The research of J. Wu was partially supported by the National Research
   and Development Program of China under grant No. 2019YFB1404802, No.
   2019YFC0118802, and No. 2018AAA0102102, the National Natural Science
   Foundation of China under grant No. 61672453, the Zhejiang University
   Education Foundation under grants No. K18-511120-004, No.
   K17-511120-017, and No. K17-518051-02, the Zhejiang public welfare
   technology research project under grant No. LGF20F020013, and the Key
   Laboratory of Medical Neurobiology of Zhejiang Province. D. Z. Chen's
   research was supported in part by NSF Grant CCF-1617735.
CR Apidechkul T, 2018, BMC PUBLIC HEALTH, V18, DOI 10.1186/s12889-018-5607-2
   Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663
   Bello-Ovosi BO, 2018, PAN AFR MED J, V29, DOI 10.11604/pamj.2018.29.97.14191
   Beratarrechea A, 2014, TELEMED E-HEALTH, V20, P75, DOI 10.1089/tmj.2012.0328
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   Ebrahim S, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001377
   Fu J, 2017, THESIS
   Goldstein BA, 2017, J AM MED INFORM ASSN, V24, P198, DOI 10.1093/jamia/ocw042
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Ke GL, 2017, ADV NEUR IN, V30
   Kim C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102170
   Kim MJ, 2015, HYPERTENS RES, V38, P783, DOI 10.1038/hr.2015.72
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Mancia G., 2016, DIALOGUES CARDIOVASC, V21, P91
   Martín V, 2016, BMC PUBLIC HEALTH, V16, DOI 10.1186/s12889-016-2728-3
   Mohanty S, 2018, INDAN J COMMUNITY HE, V30, P70
   Organization WH, 1998, WORLD HLTH REP 1998, P391
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Ruder S., 2016, ARXIV
   Safar ME, 2018, HYPERTENSION, V72, P796, DOI 10.1161/HYPERTENSIONAHA.118.11212
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tripathi S, 2019, LECT NOTES COMPUT SC, V11608, P54, DOI 10.1007/978-3-030-23281-8_5
   Wang AG, 2015, EXPERT SYST APPL, V42, P7601, DOI 10.1016/j.eswa.2015.06.012
   Yang Y., 2017, Trace norm regularised deep multi-task learning
   Zhang XQ, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00351
NR 30
TC 5
Z9 5
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41511
EP 41525
DI 10.1007/s11042-020-10482-8
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000612905100002
DA 2024-07-18
ER

PT J
AU Singh, I
   Lee, SW
AF Singh, Irish
   Lee, Seok-Won
TI Self-adaptive and secure mechanism for IoT based multimedia services: a
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-adaptive security; Multimedia in IoT; Mobile eHealth;
   Non-functional requirements
AB With the advent of internet of things (IoT) and IoT multimedia services in real-time applications, including smart healthcare, smart home, and smart connected transportation, IoT multimedia systems have significantly enhanced the lifestyle. However, the increased number of connected heterogeneous IoT multimedia devices have resulted in several vulnerabilities and cyberattacks. The existing multimedia in IoT multimedia security solutions are insufficient for detecting such complex attacks and require a self-adaptive security mechanism that can monitor the changing environment and detect, mitigate, plan, and prevent future prospective attacks in real time. In this study, we conduct a study of several self-adaptive security approaches for IoT multimedia and analyze them based on critical, security metrics to determine their level of support and the achieved satisfaction for IoT multimedia services. The evaluation results show significant insights, challenges, and concerns in the existing approaches, which can provide vital information for the development of future IoT multimedia security research. We propose a self-adaptive security model for IoT multimedia and discuss a case utilizing a mobile e-health system, where we use an adaptation model (using monitor-analyze-plan-execute over a shared knowledge adaptation loop) to determine the adaptation requirement based on the confidence level of several security factors. The adaptation requirement depicts that adaptation is required for stabilizing the security factors in a continuous context-changing sustainable e-health IoT multimedia environment.
C1 [Lee, Seok-Won] Ajou Univ, Dept Software & Comp Engn, Dept Artificial Intelligence, Suwon 443749, South Korea.
   [Singh, Irish] Ajou Univ, Dept Comp Engn, Suwon 443749, South Korea.
C3 Ajou University; Ajou University
RP Lee, SW (corresponding author), Ajou Univ, Dept Software & Comp Engn, Dept Artificial Intelligence, Suwon 443749, South Korea.
EM singhirish@ajou.ac.kr; leesw@ajou.ac.kr
OI Lee, Seok-Won/0000-0002-8569-0236; Singh, Irish/0000-0001-9388-7998
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science and ICT [NRF-2020R1F1A1075605]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science and ICT (NRF-2020R1F1A1075605).
CR Abie Habtamu, 2009, 2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems. MASS 2009, P810, DOI 10.1109/MOBHOC.2009.5336915
   Abie Habtamu, 2012, P 7 INT C BOD AR NET, P269
   Alia Mourad, 2008, 2008 IEEE 32nd International Computer Software and Applications Conference (COMPSAC), P943, DOI 10.1109/COMPSAC.2008.283
   Almorsy M, 2012, P 4 INT S CYB SAF SE
   Aman W, 2019, INT J ADV COMPUT SC, V10, P280
   [Anonymous], 2014, SECURITY PRIVACY TRU
   [Anonymous], 2011, P 7 LAT AM NETW OP M
   [Anonymous], 2010, EUR C SOFTW ARCH ECS
   AsSadhan B, 2020, MULTIMED TOOLS APPL, V79, P12727, DOI 10.1007/s11042-020-08653-8
   Bahtiyar E, 2014, ELECTRON COMMER R A, V13, P164, DOI 10.1016/j.elerap.2013.10.003
   Bailey C., 2011, Proceedings of the 2011 IEEE 9th International Conference on Dependable, Autonomic and Secure Computing (DASC 2011), P37, DOI 10.1109/DASC.2011.31
   Bailey C, 2014, J COMPUT SYST SCI, V80, P935, DOI 10.1016/j.jcss.2014.02.003
   Baresi L., 2010, Proceedings of the 2010 IEEE 18th International Conference on Requirements Engineering (RE2010), P125, DOI 10.1109/RE.2010.25
   Barnes JM, 2014, HOTSOS 2014 S BOOTC
   Ben Mahmoud M. S., 2010, P 29 DIG AV SYST C D
   Bennaceur A., 2014, P 9 INT S SOFTW ENG
   Berhanu  Y., 2013, P INT WORKSH AD SEC
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Brézillon P, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P154
   Briand L, 2015, J SYSTEMS SOFTWARE
   Burns J, 2001, DISCEX'01: DARPA INFORMATION SURVIVABILITY CONFERENCE & EXPOSITION II, VOL II, PROCEEDINGS, P12, DOI 10.1109/DISCEX.2001.932156
   Camilli M, 2015, 2015 IEEE 26TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING (ISSRE), P303, DOI 10.1109/ISSRE.2015.7381823
   Chigan CX, 2005, IEEE WCNC, P2118
   DARDENNE A, 1993, SCI COMPUT PROGRAM, V20, P3, DOI 10.1016/0167-6423(93)90021-G
   Debar H, 2007, J COMPUT VIROL HACKI, V3, P195, DOI 10.1007/s11416-007-0039-z
   Diniz, 2016, THESIS BRASIL
   Elkhodary Ahmed, 2007, 2007 International Workshop on Software Engineering for Adaptive and Self-Managing Systems, DOI 10.1109/SEAMS.2007.2
   Erlingsson U., 2000, DARPA INFORM SURVIVA, V2, P287
   Evesti A., 2010, 2010 Proceedings of 4th IEEE International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2010), P204, DOI 10.1109/SASO.2010.11
   Evesti A, 2013, COMPUTERS, V2, P34, DOI 10.3390/computers2010034
   García F, 2006, INFORM SOFTWARE TECH, V48, P631, DOI 10.1016/j.infsof.2005.07.001
   Giese, 2017, SOFTWARE ENG SELF AD
   Hashii B, 2000, COMPUT NETW, V33, P77, DOI 10.1016/S1389-1286(00)00075-X
   Herzog A, 2007, INT J INF SECUR PRIV, V1, P1, DOI 10.4018/jisp.2007100101
   Hu Vincent C., NIST SPECIAL PUBLICA, V800, P162
   Jabbour G, 2008, FOURTH INTERNATIONAL CONFERENCE ON AUTONOMIC AND AUTONOMOUS SYSTEMS (ICAS 2008), P188, DOI 10.1109/ICAS.2008.49
   Jean E, 2007, P IEEE WIC ACM INT C
   Juerjens J, 2008, LECT NOTES COMPUT SC, V4961, P292, DOI 10.1007/978-3-540-78743-3_21
   Jurjens J., 2001, Fundamental Approaches to Software Engineering. 4th International Conference, FASE 2001. Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2001. Proceedings (Lecture Notes in Computer Science Vol.2029), P187
   Jurjens J., 2002, UML 2002  The Unified Modeling Language, V2460, P1
   Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055
   Kirikova M, 1994, ENTERPRISE MODELLING
   Krupitzer C, 2015, PERVASIVE MOB COMPUT, V17, P184, DOI 10.1016/j.pmcj.2014.09.009
   La Neve, 2012, FUZZY LOGIC EMERGING
   Labraoui Nabila, 2010, 2010 5th International Symposium on Wireless Pervasive Computing (ISWPC), P325, DOI 10.1109/ISWPC.2010.5483752
   Lee, 2010, SELF ADAPTATION MODE
   Lee H., 2014, 2014 16th International Telecommunications Network Strategy and Planning Symposium (Networks), P1
   Lee K, 2007, 2 INT C DIG INF MAN, V1, P303
   Liu L, 2003, 11TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE, PROCEEDINGS, P151
   Liu L., 2009, Int. J. Softw. Inform., V3, P89
   Lodderstedt Torsten., 2002, UML 02 P 5 INT C UNI, P426, DOI [DOI 10.1007/3-540-45800-X_33, DOI 10.1007/3-540-45800-X33]
   Malek E, 2016, 13 WORK IEEE IFIP C
   Malek S, 2012, P 7 INT S SOFTW ENG
   Marcus L., 2003, INT WORKSH REQ HIGH
   Matulevicius R, 2008, LECT NOTES COMPUT SC, V5074, P541
   McKinley P. K., 2004, MSUCSE0417
   Montangero C., 2004, FCS'04, P301
   Morin B, 2010, P IEEE ACM INT C AUT
   Mouelhi T, 2008, LECT NOTES COMPUT SC, V5301, P537, DOI 10.1007/978-3-540-87875-9_38
   Mouratidis H, 2010, INT J INTELL SYST, V25, P813, DOI 10.1002/int.20432
   Mowafi Yaser, 2014, P 3 INT C CONT AW SY, P147
   Nauman A, 2020, IEEE ACCESS, V8, P8202, DOI 10.1109/ACCESS.2020.2964280
   Nuseibeh, 2019, ARXIV PREPRINT ARXIV
   Omoronyia I, 2014, P INT REQ ENG C RE, P111
   Pasquale L., 2012, 2012 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, P165, DOI 10.1109/SEAMS.2012.6224403
   Pasquale L, 2014, 9TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS (SEAMS 2014), P43, DOI 10.1145/2593929.2593939
   Perrin Chad., 2008, The CIA Triad
   Poslad S, 2014, EVALUATION FRAMEWORK
   Quandeng Gou, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1129, DOI 10.1109/GreenCom-iThings-CPSCom.2013.195
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Ryutov T, 2002, THIRD INTERNATION WORKSHOP ON POLICIES FOR DISTRIBUTED SYSTEMS AND NETWORKS, PROCEEDINGS, P128, DOI 10.1109/POLICY.2002.1011300
   Salehie M, 2012, P 1 INT WORKSH SOFTW
   Salehie M, 2009, ACM T AUTON ADAP SYS, V4, DOI 10.1145/1516533.1516538
   Sanchez-Cid F, 2008, INT WORKSHOP DATABAS, P305, DOI 10.1109/DEXA.2008.119
   Sandhu RS, 1996, COMPUTER, V29, P38, DOI 10.1109/2.485845
   Savola Reijo M., 2010, Proceedings of the 2010 Fourth International Conference on Emerging Security Information, Systems and Technologies (SECURWARE), P25, DOI 10.1109/SECURWARE.2010.12
   Schmerl B., 2014, CMUISR14109
   Sindre G, 2005, REQUIR ENG, V10, P34, DOI 10.1007/s00766-004-0194-4
   Sindre G., 2001, P 7 INT WORKSH REQ E
   Singh M, 2017, INT C CONTR AUTOMAT, P1646, DOI 10.23919/ICCAS.2017.8204251
   Sodhro AH, 2018, IEEE SENSOR J, V99
   Sodhro AH, 2018, IEEE ACCESS, V6, P42384, DOI 10.1109/ACCESS.2018.2859205
   Sodhro AH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030923
   Sodhro AH, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147717750030
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Tsigkanos C, 2014, INT REQUIR ENG CONF, P203, DOI 10.1109/RE.2014.6912262
   Tun T, 2018, P 13 INT S SOFTW ENG
   Van Lamsweerde A., 2003, RHAS, V3, P49
   Xiao L, 2007, P INT COMP SOFTW APP, P261
   Xiao L, 2009, INFORM SOFTWARE TECH, V51, P933, DOI 10.1016/j.infsof.2008.05.005
   Yu ESK, 1997, RE '97 - PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL SYMPOSIUM ON REQUIREMENTS ENGINEERING, P226, DOI 10.1109/ISRE.1997.566873
   Yu Y, 2019, ENG ADAPTIVE SOFTWAR, P135
   Yuan E., 2013, P 9 INT ACM SIGSOFT, P33, DOI DOI 10.1145/2465478.2465479
   Yuan E, 2014, ACM T AUTON ADAP SYS, V8, DOI 10.1145/2555611
   Zikria YB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082334
   Zou J, 2002, 2002 MILCOM PROCEEDINGS, VOLS 1 AND 2, P1145
NR 96
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26685
EP 26720
DI 10.1007/s11042-020-10493-5
EA JAN 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000612271000003
DA 2024-07-18
ER

PT J
AU Liu, JX
   Fan, K
   Li, H
   Yang, YT
AF Liu, Jianxing
   Fan, Kai
   Li, Hui
   Yang, Yintang
TI A blockchain-based privacy preservation scheme in multimedia network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Blockchain; Secure multi-party computation; Privacy
   preservation
ID WATERMARKING; SECURE
AB With networking, big data and rapid development and wide application of 5G networks, traditional network architecture cannot handle massive amounts of media data generated by a large number of mobile or PC devices. In recent years, events on multimedia and data copyright violations of a substantial increase, data security and privacy protection of many original multimedia users is suffering an unprecedented challenge. On the other hand, due to the center and the invariance of the block chain, block chain has become a promising multimedia security technology. Blockchain technology provides a common, digitized and distributed books, P2P network composed of all peer nodes interconnected to each other, all participating nodes are equal, collaborative service, compared to traditional architecture under a single central point, can greatly reduce the risk of single point of failure. In this paper, based access scheme in combination with the secure multi-computing protocol blockchain system, the user needs to conduct the authentication system under the multi-computing in order to receive the data, greatly enhance the data safety of multimedia in complicated communication sceneries. In addition, the program mentioned in the text and related simulations and proof of security, usability and reliability can be guaranteed.
C1 [Liu, Jianxing; Fan, Kai; Li, Hui; Yang, Yintang] Xidian Univ, Xian, Peoples R China.
C3 Xidian University
RP Liu, JX; Fan, K (corresponding author), Xidian Univ, Xian, Peoples R China.
EM suncorn_viper@163.com; kfan@mail.xidian.edu.cn
RI Fan, K/GXH-3734-2022
OI Fan, Kai/0000-0001-6870-6657
FU National Key RD Program of China [2017YFB0802300]; National Natural
   Science Foundation of China [61772403, U1836203]; Natural Science
   Foundation of Shaanxi Province [2019ZDLGY12-02]; Shaanxi Innovation Team
   Project [2018TD-007]; Xian Science and technology innovation plan
   [201809168CX9JC10]; National 111 Program of China [B16037]
FX This work is supported by the National Key RD Program of China
   (2017YFB0802300), the National Natural Science Foundation of China (No.
   61772403, U1836203), the Natural Science Foundation of Shaanxi Province
   (No. 2019ZDLGY12-02), the Shaanxi Innovation Team Project (No.
   2018TD-007), the Xian Science and technology innovation plan (No.
   201809168CX9JC10) and National 111 Program of China B16037.
CR Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming, P1
   Chan HT, 2015, J DISP TECHNOL, V11, P193, DOI 10.1109/JDT.2014.2367528
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Fudge, 2013, US Patent, Patent No. [8,472,792, 8472792]
   Li ZT, 2018, IEEE T IND INFORM, V14, P3690, DOI 10.1109/TII.2017.2786307
   Liang KT, 2015, FUTURE GENER COMP SY, V52, P95, DOI 10.1016/j.future.2014.11.016
   Lim Y, 2013, IEEE MULTIMEDIA, V20, P80, DOI 10.1109/MMUL.2013.7
   Mougayar W, 2016, BUSINESS BLOCKCHAIN
   Orsini G, 2015, 2015 8TH IFIP WIRELESS AND MOBILE NETWORKING CONFERENCE (WMNC), P112, DOI 10.1109/WMNC.2015.10
   Pande A, 2013, IEEE MULTIMEDIA, V20, P50, DOI 10.1109/MMUL.2012.29
   Perera C, 2015, IEEE TRANS COMPUT SO, V2, P171, DOI 10.1109/TCSS.2016.2515844
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Valenzise G, 2009, IEEE IMAGE PROC, P1265, DOI 10.1109/ICIP.2009.5413615
   Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183
   Wang S, 2007, IEEE T CIRC SYST VID, V17, P98, DOI 10.1109/TCSVT.2006.887086
   Wu J, 2019, IEEE T EMERG TOP COM, V7, P553, DOI 10.1109/TETC.2017.2747158
   Yamada T, 2016, J REAL-TIME IMAGE PR, V11, P211, DOI 10.1007/s11554-013-0335-4
   Yang YJ, 2016, PERVASIVE MOB COMPUT, V28, P122, DOI 10.1016/j.pmcj.2015.06.017
   Yli-Huumo J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163477
   Yu SC, 2010, IEEE INFOCOM SER, DOI 10.1109/INFCOM.2010.5462174
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang K, 2018, IEEE T DEPEND SECURE, V15, P607, DOI 10.1109/TDSC.2016.2626288
   Zhou L, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6766087
NR 26
TC 4
Z9 4
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30691
EP 30705
DI 10.1007/s11042-021-10513-y
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000609387900001
DA 2024-07-18
ER

PT J
AU Verma, B
   Choudhary, A
AF Verma, Bindu
   Choudhary, Ayesha
TI Affective state recognition from hand gestures and facial expressions
   using Grassmann manifolds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective state; Facial expression; Hand gesture; Grassmann manifold;
   Emotion recognition; Geodesic Flow Kernel
AB The emotional state of a person is important to understand their affective state. Affective states are an important aspect of our being "human". Therefore, for man-machine interaction to be natural and for machines to understand people, it is becoming necessary to understand a person's emotional state. Non-verbal behavioral cues such as facial expression and hand gestures provide a firm basis for understanding the affective state of a person. In this paper, we proposed a novel, real-time framework that focuses on extracting the dynamic information from a videos for multiple modalities to recognize a person's affective state. In the first step, we detect the face and hands of the person in the video and create the motion history images (MHI) of both the face and gesturing hands to encode the temporal dynamics of both these modalities. In the second step, features are extracted for both face and hand MHIs using deep residual network ResNet-101 and concatenated into one feature vector for recognition. We use these integrated features to create subspaces that lie on a Grassmann manifold. Then, we use Geodesic Flow Kernel (GFK) of this Grassmann manifold for domain adaptation and apply this GFK to adapt GGDA to robustly recognize a person's affective state from multiple modalities. An accuracy of 93.4% on FABO (Gunes and Piccardi 19) dataset and 92.7% on our own dataset shows that integrated face and hand modalities perform better than state-of-the-art methods for affective state recognition.
C1 [Verma, Bindu] Delhi Technol Univ, New Delhi, India.
   [Choudhary, Ayesha] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Delhi Technological University; Jawaharlal Nehru University, New Delhi
RP Choudhary, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM binduverma67@gmail.com; ayeshac@mail.jnu.ac.in
OI Choudhary, Ayesha/0000-0002-7544-4912
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Ambady N, 2000, ADV EXP SOC PSYCHOL, V32, P201, DOI 10.1016/S0065-2601(00)80006-4
   [Anonymous], 2007, P BMVC WARW UK 10 13
   [Anonymous], ARXIV160507678
   [Anonymous], 2008, HONEST SIGNALS, DOI DOI 10.7551/MITPRESS/8022.001.0001
   Barros P, 2017, NEUROCOMPUTING, V253, P104, DOI 10.1016/j.neucom.2017.01.096
   Barros P, 2015, NEURAL NETWORKS, V72, P140, DOI 10.1016/j.neunet.2015.09.009
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Berthouze, ARXIV200107739
   Cai HS, 2020, INFORM FUSION, V59, P127, DOI 10.1016/j.inffus.2020.01.008
   Chen LF, 2018, CHIN CONTR CONF, P9545, DOI 10.23919/ChiCC.2018.8483607
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Dellaert F, 1996, P 4 INT C SPOK LANG
   Dibia V., 2017, REAL TIME HAND TRACK
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   Gadanho SC, 2004, J MACH LEARN RES, V4, P385, DOI 10.1162/153244304773633870
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gu YY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066762
   Gunes H, 2006, INT C PATT RECOG, P1148
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Kapoor A., P 13 ANN ACM INT C M, P677
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kret ME, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00810
   Lisetti CL, 2004, EURASIP J APPL SIG P, V2004, P1672, DOI 10.1155/S1110865704406192
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Nakajima M, 2002, ITE TECHNICAL REPORT, V26, P1
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Psaltis A, 2016, IEEE CONF IMAGING SY, P435, DOI 10.1109/IST.2016.7738265
   Richmond Virginia P, 2008, Nonverbal behavior in interpersonal relations
   Roy D, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P363, DOI 10.1109/AFGR.1996.557292
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   Spexard TP, 2007, IEEE T ROBOT, V23, P852, DOI 10.1109/TRO.2007.904903
   Sun B, 2018, NEURAL NETWORKS, V105, P36, DOI 10.1016/j.neunet.2017.11.021
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Uddin M.A., 2020, IEEE Trans. Affect. Comput.
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang ZJ, 2017, INT CONF AFFECT, P236, DOI 10.1109/ACII.2017.8273606
   Yang ZJ, 2015, INT CONF ACOUST SPEE, P2234, DOI 10.1109/ICASSP.2015.7178368
NR 48
TC 10
Z9 10
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14019
EP 14040
DI 10.1007/s11042-020-10341-6
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609068600002
DA 2024-07-18
ER

PT J
AU Hazourli, AR
   Djeghri, A
   Salam, H
   Othmani, A
AF Hazourli, Ahmed Rachid
   Djeghri, Amine
   Salam, Hanan
   Othmani, Alice
TI Multi-facial patches aggregation network for facial expression
   recognition and facial regions contributions to emotion display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Facial expression recognition; Deep visual
   learning; multi-facial patches; Conditional generative adversarial
   network
ID CULTURAL-DIFFERENCES; HALLUCINATION
AB In this paper, an approach for Facial Expressions Recognition (FER) based on a multi-facial patches (MFP) aggregation network is proposed. Deep features are learned from facial patches using convolutional neural sub-networks and aggregated within one architecture for expression classification. Besides, a framework based on two data augmentation techniques is proposed to expand FER labels training datasets. Consequently, the proposed shallow convolutional neural networks (CNN) based approach does not need large datasets for training. The proposed framework is evaluated on three FER datasets. Results show that the proposed approach achieves state-of-art FER deep learning approaches performance when the model is trained and tested on images from the same dataset. Moreover, the proposed data augmentation techniques improve the expression recognition rate, and thus can be a solution for training deep learning FER models using small datasets. The accuracy degrades significantly when testing for dataset bias. A fine-tuning can overcome the problem of transition from laboratory-controlled conditions to in-the-wild conditions. Finally, the emotional face is mapped using the MFP-CNN and the contribution of the different facial areas in displaying emotion as well as their importance in the recognition of each facial expression are studied.
C1 [Hazourli, Ahmed Rachid] Univ Paris Saclay, F-91400 Orsay, France.
   [Djeghri, Amine] Sorbonne Univ, F-75006 Paris, France.
   [Salam, Hanan] Emlyon, F-69130 Ecully, France.
   [Othmani, Alice] Univ Paris Est Creteil, LISSI, F-94400 Vitry Sur Seine, France.
C3 Universite Paris Saclay; Universite Paris Cite; Sorbonne Universite;
   emlyon business school; Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Othmani, A (corresponding author), Univ Paris Est Creteil, LISSI, F-94400 Vitry Sur Seine, France.
EM alice.othmani@u-pec.fr
OI Hazourli, Ahmed Rachid/0000-0002-5054-6146; Salam,
   Hanan/0000-0001-6971-5264; OTHMANI, Alice/0000-0002-3442-0578
CR [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2017, ARXIV170307140
   [Anonymous], 2016, NIPS Workshop on Adversarial Training
   Cohen I, 2003, PROC CVPR IEEE, P595
   Cohn J. F., 1995, AM PSYCHOL SOC
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Dhall A, 2015, IEEE T AFFECT COMPUT, V6, P13, DOI 10.1109/TAFFC.2015.2397456
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Du LS, 2020, IET COMPUT VIS, V14, P73, DOI 10.1049/iet-cvi.2018.5127
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ekman P, 2002, FACIAL ACTION CODING
   el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181
   Gauthier JP, 2014, CONF P INDIUM PHOSPH
   Gedeon, 2011, TRCS1121
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hernández B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Ioannou SV, 2005, NEURAL NETWORKS, V18, P423, DOI 10.1016/j.neunet.2005.03.004
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jian MW, 2019, INFORM SCIENCES, V488, P181, DOI 10.1016/j.ins.2019.03.026
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Jingru Zhang, 2020, Recent Trends in Intelligent Computing, Communication and Devices. Proceedings of ICCD 2018. Advances in Intelligent Systems and Computing (AISC 1031), P113, DOI 10.1007/978-981-13-9406-5_15
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   KHORRAMI P, 2015, IEEE INT C COMPUT VI, DOI [DOI 10.1109/ICCVW.2015.12, 10.1109/ICCVW.2015.12]
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Li Shan, 2018, arXiv:1804.08348
   Liu MY, 2013, IEEE INT CONF AUTOMA
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Marsh AA, 2003, PSYCHOL SCI, V14, P373, DOI 10.1111/1467-9280.24461
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nicolle J., 2015, PROC 11 IEEE INT C W, V6, P1
   Nusseck M, 2008, J VISION, V8, DOI 10.1167/8.8.1
   Othmani A, 2020, COMPUT VIS IMAGE UND, V196, DOI 10.1016/j.cviu.2020.102961
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Rejaibi E., 2019, ARXIV190907208
   Salam H, 2018, VISUAL COMPUT, V34, P289, DOI 10.1007/s00371-016-1332-y
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Simcock G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010330
   Sun N, 2019, PATTERN RECOGN LETT, V119, P49, DOI 10.1016/j.patrec.2017.10.022
   Taiting Liu, 2020, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 15th International Conference on IIH-MSP in conjunction with the 12th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 157), P323, DOI 10.1007/978-981-13-9710-3_34
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tonguç G, 2020, COMPUT EDUC, V148, DOI 10.1016/j.compedu.2019.103797
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Wang W., 2020, ARXIV200106144
   Wegrzyn M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177239
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Yan H, 2012, IET BIOMETRICS, V1, P160, DOI 10.1049/iet-bmt.2012.0006
   Yang HY, 2018, IEEE INT CONF AUTOMA, P294, DOI 10.1109/FG.2018.00050
   Yu ZB, 2018, VISUAL COMPUT, V34, P1691, DOI 10.1007/s00371-017-1443-0
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang HP, 2020, PATTERN RECOGN LETT, V131, P128, DOI 10.1016/j.patrec.2019.12.013
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 73
TC 16
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13639
EP 13662
DI 10.1007/s11042-020-10332-7
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607985400002
DA 2024-07-18
ER

PT J
AU Su, GD
   Chang, CC
   Chen, CC
AF Su, Guo-Dong
   Chang, Chin-Chen
   Chen, Chih-Cheng
TI A hybrid-Sudoku based fragile watermarking scheme for image tampering
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Hybrid-Sudoku; Double perspective; Tampering
   detection; Image quality
AB Protection of intellectual property rights has become one of the focuses of social concerning. To reduce those disputations, the watermark is implanted into the media by the content owner to declare original copyright. Among which, the high payload can achieve the accurate tampering localization, but maybe bring low visual quality watermarked image. Both accurate tampering localization and high watermarked image quality seem contradictory. For this, this paper proposes a hybrid-Sudoku based fragile watermarking scheme for digital image tampering detection. The hybrid-Sudoku based scheme provides a double perspective mechanism to embed the watermark. In the first perspective of the Sudoku, the watermark is virtually embedded into each pixel pair, resulting in the temporary coordinate information. Then, the temporary coordinate information is concealed into cover image based on the second perspective of the Sudoku. Finally, several common attacks are utilized to evaluate the tampering detection performance of the proposed method. Experimental results show that the proposed scheme can achieve a considerable accuracy in tampering localization and provide the satisfactory visual quality of watermarked image, with PSNR of 47.80 dB. Additionally, the design enhances the security and imperceptive of the hidden watermark.
C1 [Su, Guo-Dong] Fujian Prov Univ, Fujian Polytech Normal Univ, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350300, Peoples R China.
   [Su, Guo-Dong; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chen, Chih-Cheng] Jimei Univ, Sch Informat Engn, Xiamen 361021, Peoples R China.
C3 Fujian Polytechnic Normal University; Fuzhou University; Feng Chia
   University; Jimei University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM gdsu0206@gmail.com; alan3c@gmail.com; 201761000018@jmu.edu.cn
RI Chang, Ching-Chun/JAN-6210-2023; Zhao, Xuan/JMR-2135-2023
FU Open Fund of Engineering Research Center for ICH Digitalization and
   Multi-Source Information Fusion of Fujian Province [FJ-ICH201901];
   Education-Scientific Research Project for Middle-Aged and Young of
   Fujian Province [JT180621, JAT190488, JAT201368]
FX This work was supported by the Open Fund of Engineering Research Center
   for ICH Digitalization and Multi-Source Information Fusion of Fujian
   Province (FJ-ICH201901), the Education-Scientific Research Project for
   Middle-Aged and Young of Fujian Province (JT180621, JAT190488 and
   JAT201368).
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2005, CP WORKSH MOD REF CO
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chen YL, 2013, ENTROPY-SWITZ, V15, P3170, DOI 10.3390/e15083260
   Ding WJ, 2019, MULTIMED TOOLS APPL, V78, P5305, DOI 10.1007/s11042-018-5732-z
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2013, PROC TECH, V10, P95, DOI 10.1016/j.protcy.2013.12.341
   Gong XH, 2020, MULTIMED TOOLS APPL, V79, P18071, DOI 10.1007/s11042-019-08594-x
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Gupta A, 2015, IEEE ACCESS, V3, P1206, DOI 10.1109/ACCESS.2015.2461602
   Ho ATS, 2004, EURASIP J APPL SIG P, V2004, P2174, DOI 10.1155/S111086570440506X
   Hong W, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P935, DOI 10.1109/IITA.2008.445
   Hong W, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P515, DOI 10.1109/ISISE.2008.153
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hui YC, 2013, INT J SECUR APPL, V7, P11
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lu HT, 2003, ELECTRON LETT, V39, P898, DOI 10.1049/el:20030589
   Mandal JK, 2013, ADV INTELL SYST, V177, P767
   Memon NA, 2020, IEEE ACCESS, V8, P75448, DOI 10.1109/ACCESS.2020.2989175
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Su GD, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102618
   Su GD, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11080996
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wong PW, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P374
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Yi FL, 2018, IEEE ACCESS, V6, P70113, DOI 10.1109/ACCESS.2018.2880730
   Zahariadis T., 2003, Communications Engineer, V1, P12, DOI 10.1049/ce:20030103
NR 33
TC 9
Z9 10
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12881
EP 12903
DI 10.1007/s11042-020-10451-1
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607504000008
DA 2024-07-18
ER

PT J
AU Kazemi, M
   Ghanbari, M
   Shirmohammadi, S
AF Kazemi, Mohammad
   Ghanbari, Mohammad
   Shirmohammadi, Shervin
TI A review of temporal video error concealment techniques and their
   suitability for HEVC and VVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Video error; loss concealment; Video transmission; Packet loss; HEVC;
   VVC
ID MOTION VECTOR RECOVERY; CODED VIDEO; FRAME LOSSES; ALGORITHM;
   COMMUNICATION; TRANSMISSION; SCHEME
AB Despite of the recent progresses in reliable and high bandwidth communication, packet loss is still probable and needs special attention in real-time video streaming applications. Congestion and bit error rate, which sometimes are more than the protection capability of the channel codes, are the sources of packet loss in video communication. One common approach to deal with video packet loss is to use error concealment techniques, which estimate the non-received data as close as possible to the actual data. This article reviews the temporal video error concealment methods that have been developed over the past 30 years. The techniques are categorized into 8 groups, and the methods are covered with enough details. The strengths and weaknesses of the 8 groups are also tabulated, and some suggestions for future work and open areas for research are provided.
C1 [Kazemi, Mohammad] Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
   [Ghanbari, Mohammad] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
   [Shirmohammadi, Shervin] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.
C3 University of Isfahan; University of Tehran; University of Essex;
   University of Ottawa
RP Kazemi, M (corresponding author), Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
EM m.kazemi@eng.ui.ac.ir; ghan@ut.ac.ir; shervin@eecs.uottawa.ca
RI Kazemi, Mohammad/G-7733-2017; Shirmohammadi, Shervin/E-6945-2012;
   Ghanbari, Mohammad/L-4053-2019
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Ghanbari,
   Mohammad/0000-0002-5482-8378
CR Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   Akbari A, 2017, IEEE T MULTIMEDIA, V19, P1339, DOI 10.1109/TMM.2017.2662203
   [Anonymous], 2019, MASSIVE IMPACT OTT F, P5
   Arthofer F., 2016, FUTURE TELEVISION
   Atzori L, 2001, IEEE T MULTIMEDIA, V3, P326, DOI 10.1109/6046.944476
   Belfiore S, 2005, IEEE T MULTIMEDIA, V7, P316, DOI 10.1109/TMM.2005.843347
   Bopardikar S, 2005, INT C SIGN PROC COMM
   Bormann C, 2012, IEEE INTERNET COMPUT, V16, P62, DOI 10.1109/MIC.2012.29
   Bross B., 2020, Versatile video coding
   Brown R, 1994, BROADCASTING CABLE, V124, P48
   Carreira J, 2014, IEEE IMAGE PROC, P2457, DOI 10.1109/ICIP.2014.7025497
   Chang YL, 2013, MOTION COMPENSATED E, DOI [10.1109/PV.2013.6691446, DOI 10.1109/PV.2013.6691446]
   Chen C, 2008, IEEE T CONSUM ELECTR, V54, P1422, DOI 10.1109/TCE.2008.4637636
   Chen J., 2020, JVETR2002V2 ITUT
   Chen MJ, 2005, IEEE T CIRC SYST VID, V15, P1385, DOI 10.1109/TCSVT.2005.857301
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Chen XM, 2010, IEEE T CONSUM ELECTR, V56, P2694, DOI 10.1109/TCE.2010.5681158
   Chen Y, 2004, PICT COD S SAN FRANC
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Cheng WJ, 2004, PROCEEDINGS OF THE IEEE 6TH CIRCUITS AND SYSTEMS SYMPOSIUM ON EMERGING TECHNOLOGIES: FRONTIERS OF MOBILE AND WIRELESS COMMUNICATION, VOLS 1 AND 2, P133
   Chien JT, 2010, IEEE T CONSUM ELECTR, V56, P1689, DOI 10.1109/TCE.2010.5606314
   Ching-Lung Ho, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P380, DOI 10.1109/InfoSEEE.2014.6948136
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Chung B, 2020, IEEE T CIRC SYST VID, V30, P1535, DOI 10.1109/TCSVT.2019.2909564
   Feng J, 1997, IEEE T CONSUM ELECTR, V43, P183, DOI 10.1109/30.585539
   Fleury M, 2013, MULTIMEDIA NETWORKING AND CODING, P175, DOI 10.4018/978-1-4666-2660-7.ch007
   Ghahremani S, 2017, MULTIMED TOOLS APPL, V76, P9033, DOI 10.1007/s11042-016-3471-6
   Ghanbari M, 2011, STANDARD CODECS IMAG, V9, P265
   Ghanbari S, 2002, 4 IEEE C MOB WIR COM, P9
   Ghotbou A, 2021, WIREL NETW, V27, P269, DOI 10.1007/s11276-020-02453-6
   Hadizadeh H, 2013, IEEE T MULTIMEDIA, V15, P2099, DOI 10.1109/TMM.2013.2281024
   Haskell P., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P545, DOI 10.1109/ICASSP.1992.226155
   Herrero R, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100168
   Herrero R, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100110
   Hojati S, 2020, MULTIMED TOOLS APPL, V79, P7449, DOI 10.1007/s11042-019-08538-5
   Hsia SC, 2005, IEEE T MULTIMEDIA, V7, P860, DOI 10.1109/TMM.2005.854432
   Hsia SC, 2016, IET IMAGE PROCESS, V10, P693, DOI 10.1049/iet-ipr.2016.0043
   Huang SC, 2008, IEEE T BROADCAST, V54, P499, DOI 10.1109/TBC.2008.2001150
   Huang YL, 2006, IEEE T CONSUM ELECTR, V52, P676, DOI 10.1109/TCE.2006.1649696
   Huang ZH, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P727, DOI 10.1109/ICCT.2018.8599966
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Hwang MC, 2008, IEEE T CONSUM ELECTR, V54, P163, DOI 10.1109/TCE.2008.4470039
   International Telecommunication Union, INF TECHN GEN COD MO
   Kazemi M, 2020, IEEE T IMAGE PROCESS, V29, P5937, DOI 10.1109/TIP.2020.2984356
   Kazemi M, 2014, MULTIMEDIA SYST, V20, P283, DOI 10.1007/s00530-013-0319-z
   Khan E, 2004, IEEE T CIRC SYST VID, V14, P1294, DOI 10.1109/TCSVT.2004.837018
   Kim DH, 2018, ETRI J, V40, P266, DOI 10.4218/etrij.2017-0078
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lee PJ, 2006, ETRI J, V28, P574, DOI 10.4218/etrij.06.0105.0246
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   Li H, 2013, MULTIMED TOOLS APPL, V65, P297, DOI 10.1007/s11042-011-0811-4
   Li YF, 2017, MULTIMED TOOLS APPL, V76, P14993, DOI 10.1007/s11042-017-4407-5
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P982, DOI 10.1109/TCSVT.2006.879119
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Lim CP, 1999, INT J IMAG SYST TECH, V10, P54, DOI 10.1002/(SICI)1098-1098(1999)10:1<54::AID-IMA6>3.0.CO;2-H
   Lin T, 2013, IEEE INT C SIGN PROC, DOI [10.1109/ICSPCC.2013.6664106, DOI 10.1109/ICSPCC.2013.6664106]
   Lin TL, 2017, MULTIMED TOOLS APPL, V76, P397, DOI 10.1007/s11042-015-3056-9
   Lin TL, 2016, J DISP TECHNOL, V12, P1451, DOI 10.1109/JDT.2016.2595640
   Lin TL, 2013, IEEE T BROADCAST, V59, P705, DOI 10.1109/TBC.2013.2275056
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P782, DOI 10.1109/TIP.2016.2623481
   Lui KJR, 2000, IEEE SIGNAL PROC MAG, V17, P9, DOI 10.1109/MSP.2000.855909
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Moiron S., 2011, RECENT PATENTS SIGNA, V1, P1, DOI DOI 10.2174/2210686311101020124
   Nam C, 2020, MULTIMED TOOLS APPL, V79, P1221, DOI 10.1007/s11042-019-08176-x
   Nauman A, 2020, IEEE ACCESS, V8, P8202, DOI 10.1109/ACCESS.2020.2964280
   Oztas B, 2012, IEEE I C ELECT CIRC, P785, DOI 10.1109/ICECS.2012.6463542
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Peng YT, 2014, CONF REC ASILOMAR C, P921, DOI 10.1109/ACSSC.2014.7094587
   Pereira R., 2016, PERVASIVE COMPUTING, P417
   Persson D, 2008, IEEE T IMAGE PROCESS, V17, P145, DOI 10.1109/TIP.2007.914151
   Persson D, 2009, IEEE T IMAGE PROCESS, V18, P1048, DOI 10.1109/TIP.2009.2014261
   Pongpadpinit W, 2006, IEE P-VIS IMAGE SIGN, V153, P63, DOI 10.1049/ip-vis:20045225
   Pyun JY, 2003, IEEE T CONSUM ELECTR, V49, P1013, DOI 10.1109/TCE.2003.1261189
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Radmehr A, 2016, SIGNAL IMAGE VIDEO P, V10, P311, DOI 10.1007/s11760-014-0743-3
   Rahman WU, 2019, IEEE ACCESS, V7, P39852, DOI 10.1109/ACCESS.2019.2907157
   Salama P, 2000, IEEE J SEL AREA COMM, V18, P1129, DOI 10.1109/49.848263
   Sankisa A, 2018, IEEE IMAGE PROC, P380, DOI 10.1109/ICIP.2018.8451090
   Schuster GM, 2006, IEEE T IMAGE PROCESS, V15, P501, DOI 10.1109/TIP.2005.863090
   Seth K, 2010, IEEE T BROADCAST, V56, P467, DOI 10.1109/TBC.2010.2058030
   Shanableh T, 2003, IEEE T MULTIMEDIA, V5, P257, DOI 10.1109/TMM.2003.811624
   Shirani S, 2000, IEEE J SEL AREA COMM, V18, P1122, DOI 10.1109/49.848261
   Shirani S, 2000, IEEE T MULTIMEDIA, V2, P185, DOI 10.1109/6046.865483
   Song K, 2007, IEEE T CONSUM ELECTR, V53, P704, DOI 10.1109/TCE.2007.381749
   Suh JW, 2002, IEEE T BROADCAST, V48, P299, DOI 10.1109/TBC.2002.806797
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Topiwala P, 2019, PROC SPIE, V11137, DOI 10.1117/12.2530559
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Turaga DS, 2002, IEEE T CIRC SYST VID, V12, P483, DOI 10.1109/TCSVT.2002.800318
   Usman M, 2016, IEEE T MULTIMEDIA, V18, P831, DOI 10.1109/TMM.2016.2537200
   Usman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P233, DOI 10.1109/PCS.2015.7170081
   WADA M, 1989, IEEE J SEL AREA COMM, V7, P807, DOI 10.1109/49.32344
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wu J, 2008, IEEE T CONSUM ELECTR, V54, P1880, DOI 10.1109/TCE.2008.4711249
   Wu ZY, 2006, IEEE INT SYMP CIRC S, P4463
   Xiang CY, 2019, INT CONF ACOUST SPEE, P1827, DOI 10.1109/icassp.2019.8683622
   Xu YL, 2008, IEEE T CONSUM ELECTR, V54, P1846, DOI 10.1109/TCE.2008.4711244
   Xu YL, 2004, IEEE T CONSUM ELECTR, V50, P1135, DOI 10.1109/TCE.2004.1362510
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yu W., 2017, INT S INT SIGN PROC
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhang Y, 2003, IEEE T IMAGE PROCESS, V12, P236, DOI 10.1109/TIP.2003.809003
   Zhang YB, 2012, IEEE T CIRC SYST VID, V22, P12, DOI 10.1109/TCSVT.2011.2130450
   Zhao C, 2013, IEEE INT S CIRC SYST
   Zheng JH, 2005, IEEE T MULTIMEDIA, V7, P507, DOI 10.1109/TMM.2005.843343
   Zheng JH, 2004, IEEE T MULTIMEDIA, V6, P801, DOI 10.1109/TMM.2004.837246
   Zhiliang X, 2009, INT C FUZZ SYST KNOW
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
NR 111
TC 14
Z9 15
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12685
EP 12730
DI 10.1007/s11042-020-10333-6
EA JAN 2021
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100006
DA 2024-07-18
ER

PT J
AU Abd Elaziz, M
   Nabil, N
   Moghdani, R
   Ewees, AA
   Cuevas, E
   Lu, SF
AF Abd Elaziz, Mohamed
   Nabil, Neggaz
   Moghdani, Reza
   Ewees, Ahmed A.
   Cuevas, Erik
   Lu, Songfeng
TI Multilevel thresholding image segmentation based on improved volleyball
   premier league algorithm using whale optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Swarm algorithm; Volleyball
   premier league algorithm; Whale optimization algorithm
ID SINE-COSINE ALGORITHM; MINIMUM CROSS-ENTROPY; PARTICLE SWARM; SCHEME
AB Multilevel thresholding image segmentation has received considerable attention in several image processing applications. However, the process of determining the optimal threshold values (as the preprocessing step) is time-consuming when traditional methods are used. Although these limitations can be addressed by applying metaheuristic methods, such approaches may be idle with a local solution. This study proposed an alternative multilevel thresholding image segmentation method called VPLWOA, which is an improved version of the volleyball premier league (VPL) algorithm using the whale optimization algorithm (WOA). In VPLWOA, the WOA is used as a local search system to improve the learning phase of the VPL algorithm. A set of experimental series is performed using two different image datasets to assess the performance of the VPLWOA in determining the values that may be optimal threshold, and the performance of this algorithm is compared with other approaches. Experimental results show that the proposed VPLWOA outperforms the other approaches in terms of several performance measures, such as signal-to-noise ratio and structural similarity index.
C1 [Abd Elaziz, Mohamed] Zagazig Univ, Dept Math, Fac Sci, Zagazig, Egypt.
   [Nabil, Neggaz] Univ Sci & Technol Oran Mohammed Boudiaf, USTO MB, Fac Math & Informat, Dept Informat,Lab SIMPA, BP 1505, El Mnaouer 31000, Oran, Algeria.
   [Moghdani, Reza] Persian Gulf Univ, Ind Management Dept, Boushehr, Iran.
   [Ewees, Ahmed A.] Damietta Univ, Dept Comp, Dumyat, Egypt.
   [Cuevas, Erik] Univ Guadalajara, CUCEI, Dept Elect, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [Lu, Songfeng] Huazhong Univ Sci & Technol, Sch Cyber Sci & Engn, Wuhan 430074, Peoples R China.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Universite des
   Sciences et de la Technologie d'Oran Mohamed Boudiaf; Persian Gulf
   University; Egyptian Knowledge Bank (EKB); Damietta University;
   Universidad de Guadalajara; Huazhong University of Science & Technology
RP Abd Elaziz, M (corresponding author), Zagazig Univ, Dept Math, Fac Sci, Zagazig, Egypt.; Lu, SF (corresponding author), Huazhong Univ Sci & Technol, Sch Cyber Sci & Engn, Wuhan 430074, Peoples R China.
EM abd_el_aziz_m@yahoo.com; nabil.neggaz@univ-usto.dz;
   reza.moghdani@gmail.com; ewees@du.edu.eg; lusongfeng@hust.edu.cn
RI Ewees, Ahmed A./O-8211-2016; , mohamed/AAH-8886-2019; NEGGAZ,
   Nabil/AAF-1272-2019
OI , mohamed/0000-0002-7682-6269; NEGGAZ, Nabil/0000-0002-8269-5672
FU Hubei Provincinal Science and Technology Major Project of China
   [2020AEA011]; Key Research & Developement Plan of Hubei Province of
   China [2020BAB100]
FX This work is supported by the Hubei Provincinal Science and Technology
   Major Project of China under Grant No. 2020AEA011 and the Key Research &
   Developement Plan of Hubei Province of China under Grant No. 2020BAB100.
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd Elaziz M, 2020, IEEE ACCESS, V8, P125306, DOI 10.1109/ACCESS.2020.3007928
   Abd Elaziz M, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106347
   Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P112, DOI 10.1016/j.eswa.2019.01.047
   Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Alwerfali HSN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030328
   [Anonymous], 2016, INT J ENG TECHNOL SC
   [Anonymous], 2013, Commun Comput Inform Sci, DOI DOI 10.1007/978-3-642-40567-9_4
   Awada W, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P356, DOI 10.1109/IRI.2012.6303031
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Bhandari AK, 2019, MULTIMED TOOLS APPL, V78, P35733, DOI 10.1007/s11042-019-08195-8
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Bohat VK, 2019, EXPERT SYST APPL, V117, P176, DOI 10.1016/j.eswa.2018.08.045
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Ewees AA, 2020, IEEE ACCESS, V8, P26304, DOI 10.1109/ACCESS.2020.2971249
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Farshi T. R., 2018, INT J, P1
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gupta S, 2019, KNOWL-BASED SYST, V165, P374, DOI 10.1016/j.knosys.2018.12.008
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Jia HM, 2019, IEEE ACCESS, V7, P32805, DOI 10.1109/ACCESS.2019.2903345
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Labati RD, 2011, IEEE IMAGE PROC
   Li YC, 2017, INT CONF COMP INFO, P1, DOI 10.1109/CITS.2017.8035303
   Liang J, 2018, FAST SAR IMAGE SEGME
   Ma L, 2017, J BIOMED INFORM, V66, P148, DOI 10.1016/j.jbi.2017.01.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Moghdani R, 2018, APPL SOFT COMPUT, V64, P161, DOI 10.1016/j.asoc.2017.11.043
   Oliva D, 2018, MULTIMED TOOLS APPL, V77, P25761, DOI 10.1007/s11042-018-5815-x
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Park SJ, 2018, PATTERN RECOGN LETT, V112, P249, DOI 10.1016/j.patrec.2018.07.032
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Reynolds AM, 2007, J EXP BIOL, V210, P3763, DOI 10.1242/jeb.009563
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Sharawi M, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P163, DOI 10.1109/ICACI.2017.7974502
   Sun GY, 2016, APPL SOFT COMPUT, V46, P703, DOI 10.1016/j.asoc.2016.01.054
   Tan ZP, 2020, J AMB INTEL HUM COMP, V11, P4983, DOI 10.1007/s12652-020-01777-7
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   WANG YJ, 2018, REMOTE SENS-BASEL, V10, DOI DOI 10.3390/RS10050781
   Wunnava A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103836
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P12007, DOI 10.1007/s11042-019-08566-1
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P1137, DOI 10.1007/s11042-019-08229-1
   Xiong W, 2018, OPTIK, V164, P218, DOI 10.1016/j.ijleo.2018.02.072
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 52
TC 28
Z9 29
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12435
EP 12468
DI 10.1007/s11042-020-10313-w
EA JAN 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038100001
PM 33456315
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gupta, D
   Choudhury, A
   Gupta, U
   Singh, P
   Prasad, M
AF Gupta, Deepak
   Choudhury, Ambika
   Gupta, Umesh
   Singh, Priyanka
   Prasad, Mukesh
TI Computational approach to clinical diagnosis of diabetes disease: a
   comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Diabetes; Support vector machines; Logistic
   regression; K-nearest neighbors; ELM
ID MACHINE LEARNING TECHNIQUES; LOGISTIC-REGRESSION; AUTOMATED DETECTION;
   DISCRIMINANT-ANALYSIS; GAUSSIAN-PROCESSES; RIDGE-REGRESSION;
   NEURAL-NETWORKS; RETINAL IMAGES; FUNDUS IMAGES; EXPERT-SYSTEM
AB Diabetes is one of the most prevalent non-communicable diseases and is the 6th leading cause of death worldwide. It's a chronic metabolic disorder which has no cure, however, it is a highly treatable condition, if diagnosed and managed on time to avoid its complications. This paper explores and compares various machine learning (ML) approaches that can help in determining the risk of diabetes at an early stage and aid in improving the medical diagnosis of diabetes. The paper considers two real-world datasets one is a diabetic clinical dataset (DCA) collected from a medical practitioner in the state of Assam, India during the year 2017-2018 and other is public PIMA Indian diabetic dataset. To analyze the various machine learning techniques on DCA and PIMA Indian diabetic datasets for the classification of diabetic and non-diabetic patients, different classifiers like perceptron, Gaussian process, linear discriminant analysis, quadratic discriminant analysis, statistical gradient descent, ridge regression classifier, support vector machines, k-nearest neighbors, decision tree, naive Bayes, logistic regression, random forest and ELM for multiquadric, RBF, sigmoid activation functions are used. The results of numerical experiments suggested that logistic regression yields better performance in comparison to the other techniques.
C1 [Gupta, Deepak; Choudhury, Ambika; Gupta, Umesh] Natl Inst Technol Arunachal Pradesh, Comp Sci & Engn, Yupia, India.
   [Singh, Priyanka; Prasad, Mukesh] Univ Technol Sydney, Sch Comp Sci, FEIT, Sydney, NSW, Australia.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh; University of Technology Sydney
RP Prasad, M (corresponding author), Univ Technol Sydney, Sch Comp Sci, FEIT, Sydney, NSW, Australia.
EM mukesh.prasad@uts.edu.au
RI Gupta, Deepak/H-4151-2019; GUPTA, UMESH/AAC-4589-2021
OI Gupta, Deepak/0000-0002-6375-8615; GUPTA, UMESH/0000-0002-1547-7974;
   Prasad, Mukesh/0000-0002-7745-9667
CR Acharya UR, 2009, P I MECH ENG H, V223, P545, DOI 10.1243/09544119JEIM486
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Alade OM, 2018, ADV INTELL SYST, V724, P14, DOI 10.1007/978-3-319-74980-8_2
   Albahli S, 2020, J MED IMAG HEALTH IN, V10, P1069, DOI 10.1166/jmihi.2020.3000
   Alfian G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072183
   Ali R, 2015, SENSORS-BASEL, V15, P15921, DOI 10.3390/s150715921
   Alic B, 2017, MEDD C EMBED COMPUT, P538
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   [Anonymous], 2018, IDF DIABETES ATLAS
   [Anonymous], 2019, DIABETES
   ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51, DOI 10.1109/TPAMI.1982.4767195
   Balakrishnama S., 1998, Institute for Signal and Information Processing, V1998, P1, DOI DOI 10.1073/PNAS.1715593115
   Ban HJ, 2010, BMC GENET, V11, DOI 10.1186/1471-2156-11-26
   Barakat NH, 2010, IEEE T INF TECHNOL B, V14, P1114, DOI 10.1109/TITB.2009.2039485
   Bashir S, 2014, INT CONF FRONT INFO, P226, DOI 10.1109/FIT.2014.50
   Bottou L., 1998, ONLINE LEARNING NEUR, V17, P142
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Butwall M., 2015, INT J COMPUT APPL, V120, P36
   Carrera EV, 2017, PROCEEDINGS OF THE 2017 IEEE XXIV INTERNATIONAL CONFERENCE ON ELECTRONICS, ELECTRICAL ENGINEERING AND COMPUTING (INTERCON), DOI 10.1109/INTERCON.2017.8079692
   Chaki J, 2022, J KING SAUD UNIV-COM, V34, P3204, DOI 10.1016/j.jksuci.2020.06.013
   Chakravorti T, 2019, RENEW ENERG FOCUS, V28, P78, DOI 10.1016/j.ref.2018.12.002
   Chikh MA, 2012, J MED SYST, V36, P2721, DOI 10.1007/s10916-011-9748-4
   Cohen J, 2003, APPL MULTIPLE REGRES, DOI DOI 10.4324/9780203774441
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dagliati Arianna, 2018, J Diabetes Sci Technol, V12, P295, DOI 10.1177/1932296817706375
   Dogantekin E, 2010, DIGIT SIGNAL PROCESS, V20, P1248, DOI 10.1016/j.dsp.2009.10.021
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Dudley Richard M., 2018, REAL ANAL PROBABILIT
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088
   FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Giraudo A, 2019, FOOD CONTROL, V99, P137, DOI 10.1016/j.foodcont.2018.12.033
   Giveki D., 2012, ARXIV PREPRINT ARXIV
   Gomez-Peralta F, 2020, REV CLIN ESP, V220, P305, DOI 10.1016/j.rce.2019.12.003
   Gregori D, 2011, J MED SYST, V35, P277, DOI 10.1007/s10916-009-9363-9
   Gupta U, 2020, ADV INTELL SYST COMP, V1040, P635, DOI 10.1007/978-981-15-1451-7_65
   Gupta U, 2019, ADV INTELL SYST COMP, V740, P431, DOI 10.1007/978-981-13-1280-9_40
   Hajmeer M, 2003, FOOD MICROBIOL, V20, P43, DOI 10.1016/S0740-0020(02)00104-1
   Han Wu, 2018, Informatics in Medicine Unlocked, V10, P100, DOI 10.1016/j.imu.2017.12.006
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hosmer DW, 2013, WILEY SER PROBAB ST, P89
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang YC, 2016, INT J POLYM SCI, V2016, DOI 10.1155/2016/6545362
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Jiang YH, 2011, IEEE INT VEH SYM, P613, DOI 10.1109/IVS.2011.5940440
   Joshi R., 2017, International Research Journal of Engineering and Technology, V4, P426
   Kandhasamy JP, 2015, PROCEDIA COMPUT SCI, V47, P45, DOI 10.1016/j.procs.2015.03.182
   Karegowda A., 2012, INT J COMPUTER APPL, V45, P45
   Karun S, 2019, ADV INTELL SYST COMP, V759, P177, DOI 10.1007/978-981-13-0341-8_16
   Kaur H, 2022, APPL COMPUT INFORM, V18, P90, DOI 10.1016/j.aci.2018.12.004
   Khalil RM, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND KNOWLEDGE ENGINEERING (IEEE ISKE), DOI 10.1109/ISKE.2017.8258766
   Kim KS, 2011, CURR APPL PHYS, V11, P740, DOI 10.1016/j.cap.2010.11.051
   Kopitar L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68771-z
   Kumar P, 2015, FASH TEXT, V2, DOI 10.1186/s40691-015-0027-8
   Kumari V. A., 2013, Int. J. Eng. Res. Appl., V3, P1797
   Lee BJ, 2014, IEEE J BIOMED HEALTH, V18, P555, DOI 10.1109/JBHI.2013.2264509
   Levi OU, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17030980
   Li CP, 2012, CHINESE MED J-PEKING, V125, P851, DOI 10.3760/cma.j.issn.0366-6999.2012.05.022
   Liou DR, 2013, LEARNING BEHAV PERCE
   Mani Subramani, 2012, AMIA Annu Symp Proc, V2012, P606
   Maniruzzaman M, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0095-z
   Maniruzzaman M, 2017, COMPUT METH PROG BIO, V152, P23, DOI 10.1016/j.cmpb.2017.09.004
   Marini Simone, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: HealthInf, P338
   Marini S, 2015, J BIOMED INFORM, V57, P369, DOI 10.1016/j.jbi.2015.08.021
   Mohan V, 2007, INDIAN J MED RES, V125, P217
   Murray I, 2008, INTRO GAUSSIAN PROCE
   Naz H, 2020, J DIABETES METAB DIS, V19, P391, DOI 10.1007/s40200-020-00520-5
   Parthiban G., 2011, International Journal of Computer Applications, V24, P7, DOI DOI 10.5120/2933-3887
   PIMA, 2019, IRV LEARN REP
   Polat K, 2008, EXPERT SYST APPL, V34, P482, DOI 10.1016/j.eswa.2006.09.012
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P702, DOI 10.1016/j.dsp.2006.09.005
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Priya R., 2013, ICTACT J. Soft Comput., V3, P563, DOI [10.21917/ijsc.2013.0083, DOI 10.21917/IJSC.2013.0083]
   Rajkumar M, 2019, INT RES J ENG TECHNO, V6, P7027
   Rakhonde AN, 2020, TEST ENG MANAGE, V81, P4431
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Rosenblatt F, 1957, CORNELL AERONAUTICAL, P85
   Roychowdhury S, 2014, IEEE J BIOMED HEALTH, V18, P1717, DOI 10.1109/JBHI.2013.2294635
   Samant P, 2018, COMPUT METH PROG BIO, V157, P121, DOI 10.1016/j.cmpb.2018.01.004
   Saunders C., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P515
   Schumacher M, 1996, COMPUT STAT DATA AN, V21, P661, DOI 10.1016/0167-9473(95)00032-1
   Singh A.K., 2019, P 2 INT C ADV COMP S
   Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261
   Sopharak A, 2010, J MOD OPTIC, V57, P124, DOI 10.1080/09500340903118517
   Sumangali K., 2016, 2016 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT), P389, DOI 10.1109/ICCICCT.2016.7987979
   Teliti M, 2018, DIABETES VASC DIS RE, V15, P424, DOI 10.1177/1479164118780808
   Temurtas H, 2009, EXPERT SYST APPL, V36, P8610, DOI 10.1016/j.eswa.2008.10.032
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   Thyde DN, 2021, J DIABETES SCI TECHN, V15, P98, DOI 10.1177/1932296820912411
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tiwari P, 2019, IEEE ACCESS, V7, P42354, DOI 10.1109/ACCESS.2019.2904624
   Tiwari P, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1815, DOI 10.1145/3269206.3269304
   U RA, 2008, J MED SYST, V32, P481, DOI 10.1007/s10916-008-9154-8
   Usher D, 2004, DIABETIC MED, V21, P84, DOI 10.1046/j.1464-5491.2003.01085.x
   Vago E., 2006, Applied Ecology and Environmental Research, V4, P171
   Vashist SK, 2013, DIAGNOSTICS, V3, P385, DOI 10.3390/diagnostics3040385
   Venables W N., 2002, Modern Applied Statistics with S, P498, DOI DOI 10.1007/978-0-387-21706-2
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   WHO, 2019, DIAB WHO PUBL
   Woldaregay AZ, 2020, J MED INTERNET RES, V22, DOI 10.2196/18912
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yadav B, 2018, ADV INTELL SYST, V624, P357, DOI 10.1007/978-981-10-5903-2_37
   Yu W, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-16
   Zhang Tong, 2004, P 21 INT C MACH LEAR, P116, DOI DOI 10.1145/1015330.1015332
NR 110
TC 17
Z9 17
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30091
EP 30116
DI 10.1007/s11042-020-10242-8
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000604816700005
DA 2024-07-18
ER

PT J
AU Liu, HF
   Yao, YZ
   Sun, ZR
   Li, XR
   Jia, K
   Tang, ZM
AF Liu, Huafeng
   Yao, Yazhou
   Sun, Zeren
   Li, Xiangrui
   Jia, Ke
   Tang, Zhenming
TI Road segmentation with image-LiDAR data fusion in deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road segmentation; Data fusion; Deep learning
ID COLLABORATIVE REPRESENTATION
AB Robust road segmentation is a key challenge in self-driving research. Though many image based methods have been studied and high performances in dataset evaluations have been reported, developing robust and reliable road segmentation is still a major challenge. Data fusion across different sensors to improve the performance of road segmentation is widely considered an important and irreplaceable solution. In this paper, we propose a novel structure to fuse image and LiDAR point cloud in an end-to-end semantic segmentation network, in which the fusion is performed at decoder stage instead of at, more commonly, encoder stage. During fusion, we improve the multi-scale LiDAR map generation to increase the precision of multi-scale LiDAR map by introducing pyramid projection method. Additionally, we adapted the multi-path refinement network with our fusion strategy and improve the road prediction compared with transpose convolution with skip layers. Our approach has been tested on KITTI ROAD dataset and have a competitive performance.
C1 [Liu, Huafeng; Yao, Yazhou; Sun, Zeren; Li, Xiangrui; Tang, Zhenming] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Jia, Ke] Chengdu Univ Informat Technol, Sch Comp Sci, Chengdu, Peoples R China.
C3 Nanjing University of Science & Technology; Chengdu University of
   Information Technology
RP Liu, HF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM liu.hua.feng@outlook.com; jiake@cuit.edu.cn; tzm.cs@njust.edu.cn
RI Tang, Zhenmin/AAY-6058-2020
OI Tang, Zhenmin/0000-0001-6708-2205; Liu, Huafeng/0000-0001-5396-3183
CR [Anonymous], 2016, NIPS WORKSH
   Asvadi A, 2018, PATTERN RECOGN LETT, V115, P20, DOI 10.1016/j.patrec.2017.09.038
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brox, 2016, INT C INT ROB SYST, V2016, P9
   Caltagirone L, 2017, IEEE INT VEH SYM, P1019
   Caltagirone L, 2019, ROBOT AUTON SYST, V111, P125, DOI 10.1016/j.robot.2018.11.002
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   CHEN L, 2018, EUR C COMP VIS, V2018, P833
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YF, 2017, IEEE INT C INT ROBOT, P1343, DOI 10.1109/IROS.2017.8202312
   CHEN Z, 2017, NEURAL INFORM PROCES, V2017, P677
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fritsch J, 2013, IEEE INT C INTELL TR, P1693, DOI 10.1109/ITSC.2013.6728473
   Han X., 2017, INT J ENV RES PUB HE, V14, P1, DOI DOI 10.3390/IJERPH14080886
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu HF, 2019, MULTIMED TOOLS APPL, V78, P24269, DOI 10.1007/s11042-018-6986-1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu KY, 2014, IEEE INT CONF ROBOT, P517, DOI 10.1109/ICRA.2014.6906904
   Muñoz-Bulnes J, 2017, IEEE INT C INTELL TR
   OLAF R, 2015, INT C MED IM COMP CO, V2015, P234
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Schlosser J, 2016, IEEE INT CONF ROBOT, P2198, DOI 10.1109/ICRA.2016.7487370
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang Z., 2016, IEEE INT C MULT EXP, V2016, P1
   Xiao L, 2018, INFORM SCIENCES, V432, P543, DOI 10.1016/j.ins.2017.04.048
   Xie GS, 2017, IEEE T CIRC SYST VID, V27, P1263, DOI 10.1109/TCSVT.2015.2511543
   Xie GS, 2017, INT J COMPUT VISION, V124, P145, DOI 10.1007/s11263-017-1007-9
   Xie GS, 2015, IEEE I CONF COMP VIS, P1179, DOI 10.1109/ICCV.2015.140
   Yang WK, 2018, IEEE ACCESS, V6, P7445, DOI 10.1109/ACCESS.2017.2784800
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Yang WK, 2013, APPL MATH COMPUT, V222, P13, DOI 10.1016/j.amc.2013.07.024
   Yao YZ, 2018, AAAI CONF ARTIF INTE, P523
   Yao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1085
   Yao YZ, 2019, IEEE T MULTIMEDIA, V21, P184, DOI 10.1109/TMM.2018.2847248
   Yao YZ, 2019, IEEE T IMAGE PROCESS, V28, P436, DOI 10.1109/TIP.2018.2869721
   Yao YZ, 2017, IEEE T MULTIMEDIA, V19, P1771, DOI 10.1109/TMM.2017.2684626
   Zhao MM, 2017, IEEE INT CON MULTI, P403, DOI 10.1109/ICME.2017.8019501
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 43
TC 9
Z9 10
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35503
EP 35518
DI 10.1007/s11042-019-07870-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900044
DA 2024-07-18
ER

PT J
AU Rani, SS
   Alzubi, JA
   Lakshmanaprabu, SK
   Gupta, D
   Manikandan, R
AF Rani, S. Sheeba
   Alzubi, Jafar A.
   Lakshmanaprabu, S. K.
   Gupta, Deepak
   Manikandan, Ramachandran
TI RETRACTED: Optimal users based secure data transmission on the internet
   of healthcare things (IoHT) with lightweight block ciphers (Retracted
   article. See MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Internet of things (IoT); Multimedia; Security; Optimization; Sensor
   network; Share creation; Block ciphers
AB The ever-growing advancement in communication innovation of modern smart objects carries with it a new era of improvement for the Internet of Things (IoT) based networks. The health care system is the best approach to store the patient's health data online with high privacy. Ensuring the privacy and confidentiality of patient information in the cloud is of utmost importance; here, the enhanced security model of healthcare data gives rise to trust. For the secure communication, the healthcare data sensed by the IoT sensor network is encrypted by Lightweight SIMON block cipher. For improving the privacy of healthcare data among individuals, we implemented the share generation model. Then, share creation model, i.e., Chinese Remainder Theorem (CRT) is developed to generate the copy of every ciphertext based on the selected number of users and the data is shared among the optimal number of users. The selection of the users in IoHT is made by the metaheuristic algorithm called Hybrid Teaching and Learning Based Optimization (HTLBO). Then, we present healthcare service providers for giving the full scope of medical services to people enrolled in IoHT. The performance of Secure Data is approved through simulations in terms of energy cost, computation time, etc., of the proposed algorithms and the outcomes demonstrate that Secure Data can be efficient while applying for ensuring security chances in IoT-based healthcare systems.
C1 [Rani, S. Sheeba] Sri Krishna Coll Engn & Technol, Coimbatore, Tamil Nadu, India.
   [Alzubi, Jafar A.] Al Balqa Appl Univ, Salt 19117, Jordan.
   [Lakshmanaprabu, S. K.] BS Abdur Rahman Crescent Inst Sci & Technol, Chennai, Tamil Nadu, India.
   [Gupta, Deepak] Maharaja Agrasen Inst Technol, Delhi, India.
   [Manikandan, Ramachandran] SASTRA Deemed Univ, Thanjavur, India.
C3 Sri Krishna College of Engineering & Technology; Al-Balqa Applied
   University; B. S. Abdur Rahman Crescent Institute of Science &
   Technology; Maharaja Agrasen Institute of Technology; Shanmugha Arts,
   Science, Technology & Research Academy (SASTRA)
RP Alzubi, JA (corresponding author), Al Balqa Appl Univ, Salt 19117, Jordan.
EM j.zubi@bau.edu.jo
RI SK, Lakshmanaprabu/L-1970-2018; Rani, S.Sheeba/R-3918-2019; Gupta,
   Deepak/AAV-2728-2020; Alzubi, Jafar A./G-7623-2017
OI Gupta, Deepak/0000-0002-3019-7161; Alzubi, Jafar A./0000-0001-6724-1421
CR Alagar V, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART INTERNET OF THINGS (SMARTIOT 2018), P122, DOI 10.1109/SmartIoT.2018.00-14
   Ammar M, 2018, J INF SECUR APPL, V38, P8, DOI 10.1016/j.jisa.2017.11.002
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Banerjee M, 2018, DIGIT COMMUN NETW, V4, P149, DOI 10.1016/j.dcan.2017.10.006
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Bhoyar P, 2018, AEU-INT J ELECTRON C, V90, P147, DOI 10.1016/j.aeue.2018.04.002
   Bi SQ, 2008, IEEE T COMPUT, V57, P1624, DOI 10.1109/TC.2008.126
   Chaudhury S, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P346, DOI 10.1109/IEMECON.2017.8079620
   Das AK, 2018, FUTURE GENER COMP SY, V89, P110, DOI 10.1016/j.future.2018.06.027
   El-hajj M., 2017, 2017 1st Cyber Security in Networking Conference (CSNet), P1, DOI DOI 10.1109/CSNET.2017.8242006
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Gupta D, 2018, COGN SYST RES, P1
   Haqaf H, 2018, INT J INFORM MANAGE, V43, P165, DOI 10.1016/j.ijinfomgt.2018.07.013
   Hossain M, 2018, FUTURE GENER COMP SY, V82, P422, DOI 10.1016/j.future.2017.11.020
   Huang CD, 2014, DECIS SUPPORT SYST, V61, P1, DOI 10.1016/j.dss.2013.10.011
   Jagdeo SM, 2018, SOFT COMPUTING THEOR, P251
   Leloglu E., 2017, Journal of Computer and Communications, V5, P121
   Martinez-Caro E, 2018, TECHNOL FORECAST SOC, P1
   Moosavi SR, 2016, FUTURE GENER COMP SY, V64, P108, DOI 10.1016/j.future.2016.02.020
   Risqi YSS, 2015, PROCEDIA COMPUT SCI, V72, P292, DOI 10.1016/j.procs.2015.12.143
   Rizk-Allah RM, APPL SOFT COMPUT, P1
   Sfar AR, 2018, DIGIT COMMUN NETW, V4, P118, DOI 10.1016/j.dcan.2017.04.003
   Sha KW, 2018, FUTURE GENER COMP SY, V83, P326, DOI 10.1016/j.future.2018.01.059
   Shah UA, 2017, ARXIV PREPRINT ARXIV
   Shankar K, 2020, J AMB INTEL HUM COMP, V11, P1821, DOI 10.1007/s12652-018-1161-0
   Steinbart PJ, ACC ORGAN SOC, P1
   Tao H, 2019, IEEE INTERNET THINGS, V6, P410, DOI 10.1109/JIOT.2018.2854714
   Ullah A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART INTERNET OF THINGS (SMARTIOT 2018), P166, DOI [10.1109/SmartIoT.2018.000-6, 10.1109/SmartIoT.2018.00038]
   Williams PAH, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P30, DOI 10.1109/WF-IoT.2016.7845455
   Yehia L., 2015, ADV INTERNET THINGS, V5, P21, DOI [10.4236/ait.2015.53004, DOI 10.4236/AIT.2015.53004]
NR 30
TC 41
Z9 41
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35405
EP 35424
DI 10.1007/s11042-019-07760-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900038
DA 2024-07-18
ER

PT J
AU Shahid, M
   Chien, IF
   Sarapugdi, W
   Miao, LL
   Hua, KL
AF Shahid, Mohammad
   Chien, I-Feng
   Sarapugdi, Wannaporn
   Miao, Lili
   Hua, Kai-Lung
TI Deep spatial-temporal networks for flame detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flame detection; Spatial-temporal networks; Deep learning
ID REAL-TIME FIRE; VIDEO FIRE; COMBINATION
AB Every year, fire accidents cause substantial economic losses and casualties. Being able to detect a fire at the early stage is the only way to avoid notable disasters. Although conventional fire alarm systems (CFAs) that depend on heat and flame sensors are used for a fire safety-catch in our society, they cannot be used effectively for large and open spaces due to performance parameters of the sensors. Recently, most of the state-of-the-art methods for fire detection are evolving based on deep learning (DL) technique. However, it is a difficult task to detect fire from visual scenes due to significant irregularities in the color, size, form, texture and flickering frequency of fire. In the present work, we proposed a two-stage cascaded architecture to improve accuracy. In the first stage, we introduced the Spatio-Temporal network, which efficiently and effectively combines both shape and motion flicker based characteristics to obtain heatmaps of fire regions in the input images. By analyzing the heatmaps with a threshold segmentation method, the candidate of the fire region in the input image can be automatically located. Besides, to minimize false-positive due to some object similar to flame, in the second stage, original image and heatmaps of candidate region are fused for improving abilities of classifier to distinguish whether it is a fire or not. Also, the center loss function is adopted to backpropagate fused features to overcome the impact of intraclass heterogeneity on the representation of features. Furthermore, we tested the proposed method on three different datasets, and the results of our experiments reveal that the proposed method has achieved better performance than the other existing state-of-the-art methods.
C1 [Shahid, Mohammad; Chien, I-Feng; Sarapugdi, Wannaporn; Miao, Lili; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM hua@mail.ntust.edu.tw
RI SHAHID, MOHAMMAD/AAL-2044-2021
OI Hua, Kai-Lung/0000-0002-7735-243X
CR Caron Mathilde, 2018, P EUR C COMP VIS ECC, P132, DOI [DOI 10.1007/978-3-030-01264-9_9, 10.48550/arXiv.1807.05520, DOI 10.48550/ARXIV.1807.05520]
   Chang YT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P91, DOI 10.1145/3123266.3123268
   Chen D, 2016, MATH PROBL ENG, V2016, P1, DOI DOI 10.5465/AMBPP.2016.13398ABSTRACT
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chenebert A, 2011, IEEE IMAGE PROC, P1741, DOI 10.1109/ICIP.2011.6115796
   Chino DYT, 2015, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2015.19
   Dunnings AJ, 2018, IEEE IMAGE PROC, P1358
   Evarts Ben., 2019, Fire loss in the United States during 2018
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Flyser P, 1991, OPTICAL FIRE SECURIT
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Guan S, 2020, IEEE J BIOMED HEALTH, V24, P568, DOI 10.1109/JBHI.2019.2912935
   Ha Dai Duong, 2012, Simulated Evolution and Learning. 9th International Conference, SEAL 2012. Proceedings, P331, DOI 10.1007/978-3-642-34859-4_33
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hua KL, 2018, IEEE T CYBERNETICS, V48, P423, DOI 10.1109/TCYB.2016.2640288
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y
   Kaiser T, 2000, 34TH ANNUAL 2000 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P262, DOI 10.1109/CCST.2000.891198
   Kim B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142862
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marbach G, 2006, FIRE SAFETY J, V41, P285, DOI 10.1016/j.firesaf.2006.02.001
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Shen DQ, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P416, DOI 10.1109/ICCAR.2018.8384711
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sommer L.W., 2016, 2016 IEEE WINTER C A, P1
   Srivastava RupeshKumar., 2015, CoRR
   Tao CY, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P150, DOI [10.1109/ICIICII.2016.68, 10.1109/ICIICII.2016.0045]
   Tasi CC, 2019, IEEE T IMAGE PROCESS, V28, P56, DOI 10.1109/TIP.2018.2861217
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yu CY, 2013, PROCEDIA ENGINEER, V62, P891, DOI 10.1016/j.proeng.2013.08.140
   Zhang QJ, 2016, ADV SOC SCI EDUC HUM, V47, P568
   Zhang ZC, 2018, IEEE T MED IMAGING, V37, P1407, DOI 10.1109/TMI.2018.2823338
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 46
TC 2
Z9 5
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35297
EP 35318
DI 10.1007/s11042-020-10079-1
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000591969300004
DA 2024-07-18
ER

PT J
AU Chapagain, B
   Alsadoon, A
   Prasad, PWC
   Ali, RS
   Pham, L
AF Chapagain, Binod
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Rasha S.
   Pham, Linh
TI A novel solution for real time video and path quality, and latency
   minimization: tele-training in surgical education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surgical tele-training; Video transcoding; Path quality; Heterogeneous
   wireless networks; Video quality
AB Surgical Tele-training has not been effectively implemented in telemedicine because of strict requirements for throughput and delay minimization during real-time high-quality video transmission. Therefore, the aim of this paper is to propose a new solution for surgical Tele-training with improved quality of real-time surgical video's transmission, through put and minimized end-to-end delay required during the training session. The proposed system consists of an Enhanced Path Quality, Video Quality, and Latency Minimization (EPQVQaLM) algorithm to reduce network latency and improve the quality of real-time video transmission by including predicted data delivery time and packet drop probability in path quality calculation. The system also consists of cloud-based online video transcoding for economic transcoding of large-volume videos while guarantying the QoS parameter in case of additional resource requirement. The result shows that EPQVQaLM achieves improvements in PSNR by an average of 5db over the state of art solution. Furthermore, the proposed solution can reduce the processing time and end-to-end delay by an average of 32.6 ms and 33.93 ms over the state of art solution respectively. The proposed system concentrates on reducing end-to-end transmission delay and improves quality of surgical video transmission by using an EPQVQaLM technique. Meanwhile, it provides the mechanism for dropping the packets and re-routing packets to the different path before congestion becomes critical. Thus, this study provides an efficient mechanism to intelligently distribute data chunks over multiple paths.
C1 [Chapagain, Binod; Alsadoon, Abeer; Prasad, P. W. C.; Pham, Linh] Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Bathurst, NSW 2795, Australia.
   [Ali, Rasha S.] Al Nisour Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
C3 Charles Sturt University; Al-Nisour University College
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Bathurst, NSW 2795, Australia.
EM alsadoon.abeer@gmail.com
RI Ali, Rasha Subhi/X-9445-2018; ALI, Rasha/JBJ-4318-2023; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Ali, Rasha Subhi/0000-0002-9767-7151; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; withana, chandana/0000-0002-3007-687X; Subhi,
   Rasha/0000-0001-6718-5618; Ali, Rasha/0000-0003-3427-423X; Pham,
   Linh/0000-0003-0311-9659
CR Abbas G, 2016, IEEE COMMUN SURV TUT, V18, P324, DOI 10.1109/COMST.2015.2463121
   Almadani B, 2016, MULTIMED TOOLS APPL, V75, P5841, DOI 10.1007/s11042-015-2551-3
   Boudi A, 2018, IEEE-CAA J AUTOMATIC, V5, P223, DOI 10.1109/JAS.2017.7510763
   Cheng R., 2014, 2 IEEE INT C MOB CLO, DOI [10.1109/mobilecloud.2014.31, DOI 10.1109/MOBILECLOUD.2014.31]
   Huang CM, 2011, IEEE COMMUN LETT, V15, P386, DOI 10.1109/LCOMM.2011.020111.102459
   Khor WS, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.23
   Shenai MB, 2014, J NEUROSURG, V121, P277, DOI 10.3171/2014.4.JNS131805
   Shoaib H, INT C VIRT AUGM REAL
   Wei L, 2017, IEEE T CIRC SYST VID, V27, P49, DOI 10.1109/TCSVT.2016.2589621
   Wu J., 2018, IEEE T MULTIMEDIA, V20
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2017, IEEE T MOBILE COMPUT, V16, P1090, DOI 10.1109/TMC.2016.2584049
   Wu JY, 2016, IEEE T PARALL DISTR, V27, P710, DOI 10.1109/TPDS.2015.2416736
   Xu CQ, 2013, IEEE T MOBILE COMPUT, V12, P2193, DOI 10.1109/TMC.2012.189
   Zheng X, 2017, IEEE T MOBILE COMPUT, V16, P1787, DOI 10.1109/TMC.2016.2613529
NR 15
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9615
EP 9638
DI 10.1007/s11042-020-10115-0
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300007
DA 2024-07-18
ER

PT J
AU Lu, T
   Zhou, Q
   Fang, WH
   Zhang, YD
AF Lu, Tao
   Zhou, Qiang
   Fang, Wenhua
   Zhang, Yanduo
TI Discriminative metric learning for face verification using enhanced
   Siamese neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metric learning; Discriminative feature; Siamese neural network; Face
   verification
ID RECOGNITION
AB Although face verification algorithms have made great success under controlled conditions in recent years, there's plenty of room at its performance under uncontrolled real-world due to lack of discriminative feature representation ability. From the perspective of metric learning, we proposed a context-aware based Siamese neural network (CASNN) to learn a simple yet powerful network for face verification task to enhance its discriminative feature representation ability. Firstly, a context-aware module is used to automatically focus on the key area of the input facial images without irrelevant background area. Then we design a Siamese network equipped with center-classification loss to compress intra-class features and enlarge between-class ones for discriminative metric learning. Finally, we propose a quantitative indicator named "D-score" to show the discriminative representation ability of the learnt features from different methods. The extensive experiments are conducted on LFW dataset, YouTube Face dataset (YTF) and real-world dataset. The results confirm that CASNN outperforms some state-of-the-art deep learning-based face verification methods.
C1 [Lu, Tao; Zhou, Qiang; Fang, Wenhua; Zhang, Yanduo] Wuhan Inst Technol, Sch Comp Sci & Engn, Hubei Key Lab Intelligent Robot, Wuhan 430073, Peoples R China.
C3 Wuhan Institute of Technology
RP Lu, T (corresponding author), Wuhan Inst Technol, Sch Comp Sci & Engn, Hubei Key Lab Intelligent Robot, Wuhan 430073, Peoples R China.
EM lutxyl@gmail.com
RI zheng, xin/JNS-5523-2023; Zhou, Qiang/B-1568-2015
OI Lu, Tao/0000-0001-8117-2012
FU National Natural Science Foundation of China [61502354, 61771353];
   Central Support Local Projects of China [2018ZYYD059]; Natural Science
   Foundation of HubeiProvince of China [2014CFA130, 2015CFB451];
   Scientific Research Foundation of Wuhan Institute of Technology
   [K201713]; 10th Graduate Education Innovation Fund of Wuhan Institute of
   Technology [CX2018213]; Hubei Province Technological Innovation Project
   [2019AAA045]; Wuhan Science and Technology Bureau Project
   [202001602011971]
FX This work is supported by the National Natural Science Foundation of
   China (61502354, 61771353), Central Support Local Projects of China
   (2018ZYYD059), the Natural Science Foundation of HubeiProvince of China
   (2014CFA130, 2015CFB451), Scientific Research Foundation of Wuhan
   Institute of Technology (K201713), The 10th Graduate Education
   Innovation Fund of Wuhan Institute of Technology(CX2018213), Hubei
   Province Technological Innovation Project(2019AAA045), Wuhan Science and
   Technology Bureau Project (202001602011971).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bledsoe WW, 1966, REP PR1, V15, P2
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   GOLDSTEIN AJ, 1971, PR INST ELECTR ELECT, V59, P748, DOI 10.1109/PROC.1971.8254
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang GB, 2014, 14003 U MASS DEP COM
   Kanade Takeo., 1974, Picture processing system by computer complex and recognition of human faces"
   KOCH G, 2015, 32 INT C MACH LEARN, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2002, ELECTRON LETT, V38, P787, DOI 10.1049/el:20020591
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 39
TC 10
Z9 10
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8563
EP 8580
DI 10.1007/s11042-020-09784-8
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500006
DA 2024-07-18
ER

PT J
AU Banerjee, S
   Chaudhuri, SS
AF Banerjee, Sriparna
   Chaudhuri, Sheli Sinha
TI Bacterial Foraging-Fuzzy synergism based Image Dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Bacterial Foraging (BF)-Fuzzy synergism based
   simultaneous edge &amp; noise detection; Fuzzy Inference (FI) rules
   based pixel-wise contrast enhancement; FI rules based edge-sharpening;
   FI rules based noise filtering; Edge-strengths; Constraints
ID QUALITY ASSESSMENT; ALGORITHM; REMOVAL; ENHANCEMENT; VISIBILITY
AB The proposed work introduces a novel Bacterial Foraging (BF)-Fuzzy synergism based dehazing method to enhance the visibility of degraded hazy images. The proposed method performs contrast enhancement, edge & noise detection, noise removal and edge-sharpening (all the four important aspects of dehazing). In the first step of the method, each pixel of the degraded V channel of hazy image is enhanced using unique defuzzified mapping constant which is evaluated depending upon its Haze-concentration and Log-sigmoid transformation function values to prevent poor or over-enhancement. Subsequently, in the next step simultaneous edge & noise detection is performed using BF algorithm in combination with one set of novel FI rules. These rules beside performing simultaneous edge & noise detection also evaluate edge-strengths of all possible edge directions. BF algorithm is used here to determine the most suitable direction for the movement of bacteria within each image patch. It also facilities the selection of true edge pixels by imposing constraints on defuzzified edge-strengths which eliminates any chances of false edge detection. Noisy pixels are filtered here according to their extent of corruption w.r.t each pixel located within their neighbourhood using another novel set of FI rules to prevent undesired edge-blurring. Finally, selected edges are sharpened using unique sharpening factors which are evaluated according to their respective edge-strength using a set of novel FI rules to prevent the occurrence of undesirable halo-artifacts in outputs. Comparative qualitative, quantitative and run-time complexity analyses' results also proved the excellence of the proposed work over several state-of-the art methods.
C1 [Banerjee, Sriparna; Chaudhuri, Sheli Sinha] Jadavpur Univ, ETCE Dept, Kolkata 700032, India.
C3 Jadavpur University
RP Banerjee, S (corresponding author), Jadavpur Univ, ETCE Dept, Kolkata 700032, India.
EM sriparnatinni@yahoo.in
CR Ancuti CO, 2018, ARXIV180405091V1, P1
   Ancuti CO, 2019, IEEE SIGNAL PROC LET, V26, P1413, DOI 10.1109/LSP.2019.2932189
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], NEW VISIBILITY METRI
   [Anonymous], 2006, P COMP VIS PATT REC
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   Banerjee S., 2018, IEEE INTELLISYS LOND, P1
   BERMAN D, 2016, IEEE C COMP VIS PATT, P1
   Cai B, 2016, ARXIV160107661V2, P1
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gao YK, 2018, IET IMAGE PROCESS, V12, P637, DOI 10.1049/iet-ipr.2017.0570
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang SC, 2014, IEEE T INTELL TRANSP, V15, P2321, DOI 10.1109/TITS.2014.2314696
   Jang DW, 2017, IET IMAGE PROCESS, V11, P587, DOI 10.1049/iet-ipr.2017.0192
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kumar Manoj, 2018, Journal of King Saud University - Computer and Information Sciences, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li HF, 2014, IEEE GEOSCI REMOTE S, V11, P975, DOI 10.1109/LGRS.2013.2283792
   Liu J, 2014, OPT EXPRESS, V22, P618, DOI 10.1364/OE.22.000618
   Liu Y, 2002, J OPTIMIZ THEORY APP, V115, P603, DOI 10.1023/A:1021207331209
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Lu L, 2015, IEEE SIGNAL PROC LET, V22, P833, DOI 10.1109/LSP.2014.2371332
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Makarau A, 2014, IEEE T GEOSCI REMOTE, V52, P5895, DOI 10.1109/TGRS.2013.2293662
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mustafa Z. A., 2011, 2011 1st Middle East Conference on Biomedical Engineering (MECBME), P180, DOI 10.1109/MECBME.2011.5752095
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Nayar SK, 1999, INT C COMP VIS, V1999, P1
   Negru M, 2015, IEEE T INTELL TRANSP, V16, P2257, DOI 10.1109/TITS.2015.2405013
   Ren W, 2016, SINGLE IMAGE DEHAZIN, P1, DOI 10.1038/srep25640
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P17, DOI 10.1109/ICCV.2001.937494
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Tang Ke Tang Ke, 2014, The Proceedings of China's Modern Agricultural Development Forum in 2014, Yunnan, China, 15-16 October, 2014, P1
   Tarel JP, 2009, IEEE INT VEH SYM, P15, DOI 10.1109/IVS.2009.5164245
   Tong SC, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION AND NETWORKING (ACN), P15, DOI 10.1109/ACN.2015.17
   Verma OP, 2013, MULTIDIM SYST SIGN P, V24, P181, DOI 10.1007/s11045-011-0164-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westland S., 2005, COMPUTATIONAL COLOUR
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Yoon I, 2012, IEEE T CONSUM ELECTR, V58, P111, DOI 10.1109/TCE.2012.6170062
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang TY, 2018, IEEE ACCESS, V6, P10644, DOI 10.1109/ACCESS.2018.2806372
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 54
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8377
EP 8421
DI 10.1007/s11042-020-09794-6
EA NOV 2020
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000585022600001
DA 2024-07-18
ER

PT J
AU Jin, X
   Zhang, HY
   Li, XD
   Sun, HB
   Zhang, Y
   Yu, MX
   Liu, RJ
AF Jin, Xin
   Zhang, Hongyu
   Li, Xiaodong
   Sun, Hongbo
   Zhang, Ying
   Yu, Mingxue
   Liu, Ruijun
TI Random base image representation for efficient blind vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy preserving; Blind vision; Random base image; Object detection
AB Viola-Jones algorithm (Viola and Jones 2001; Int J Comput Vis 57(2):137-154, 2004) is a milestone in the development of face detection technology. It greatly improves the efficiency of face detection on the premise of ensuring the accuracy, which indicates that the research results in the field of computer vision have the ability to put into practical applications. In an application scenario, the client uploads photos to the client server which has trained Viola-Jones detector to detect objects. In the process, privacy leakage of both side is the problem to be solved. Clients want to protect their photos and the cloud server wants to protect its algorithm parameters. Blind Vision (Avidan and Butman 2006), introduced by Avidan & Butman, combined OT(Obvious Transfer) protocol with Viola-Jones face detector to construct a secure face detection protocol. However, the efficiency of Blind Vision is not ideal. It will take a couple of hours to scan a single image. In this paper, we proposed the Random Base Image (RBI) Representation based secure object detection method to speed the process. The original image is divided into several pictures which are sent to the cloud randomly. At the same time, random numbers and redundant fake classifiers are generated to protect privacy parameters of the cloud. Compared with the traditional Blind Vision (Avidan and Butman 2006) method, we did not use OT protocol and Secure Millionaire protocol to calculate feture response of classifiers and compare them with thresholds, but uses random numbers and redundant fake classifiers to protect the privacy of both sides. In addition, the integral-graph can be used to accelerate the calculation of random base images. Experiments show that our method can achieve the same detection accuracy as the original Viola-Jones detector and is much faster than the traditional Blind Vision (Avidan and Butman 2006) method.
C1 [Jin, Xin; Zhang, Hongyu; Li, Xiaodong; Sun, Hongbo; Zhang, Ying] Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
   [Jin, Xin] State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
   [Yu, Mingxue] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Liu, Ruijun] Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; Xidian University;
   Beijing Technology & Business University
RP Li, XD (corresponding author), Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
EM lxdbesti@163.com
RI liang, liang/IAO-8518-2023; li, xiao/HJP-5134-2023; jin,
   xin/GQZ-5811-2022; li, xiao/GSN-6181-2022; Liu, Ruijun/AAA-4250-2020;
   li, xiaofeng/GXF-9442-2022; li, xiao/HKV-8405-2023
OI Liu, Ruijun/0000-0003-4871-8989; 
FU National Natural Science Foundation of China [62072014]; Beijing Natural
   Science Foundation [L192040]; Open Research Fund of Beijing Key
   Laboratory of Big Data Technology for Food Safety [BTBD-2018KF-07];
   Beijing Technology and Business University; Open Project Program of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University [VRLAB2019C03]; Fundamental Research Funds for the Central
   Universities [328201906]
FX Parts of the results and figures presented in this paper have previously
   appeared in our previous work [14]. We add more technical details and
   experimental results in this version. This work is partially supported
   by the National Natural Science Foundation of China (grant numbers
   62072014), the Beijing Natural Science Foundation (grant number
   L192040), the Open Research Fund of Beijing Key Laboratory of Big Data
   Technology for Food Safety (grant number BTBD-2018KF-07), Beijing
   Technology and Business University, the Open Project Program of State
   Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University (grant number VRLAB2019C03), and the Fundamental Research
   Funds for the Central Universities (grant number. 328201906).
CR [Anonymous], 1996, DESCRIPTION LIBOR SP
   AVIDAN S, 2006, ADV NEURAL INFORM PR, P57
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Bost R, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23241
   Chu CT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P837, DOI 10.1145/2647868.2655010
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   Çiftçi S, 2018, IEEE T MULTIMEDIA, V20, P68, DOI 10.1109/TMM.2017.2728479
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ergun OO, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P643, DOI 10.1109/APCCAS.2014.7032863
   Fanti G, 2013, IEEE SIGNAL PROC MAG, V30, P53, DOI 10.1109/MSP.2012.2229783
   Geng Z, 2015, J BEIJING ELECT SCI, P55
   Hui ZY, 2016, PROCEEDINGS OF THE FIFTH NORTHEAST ASIA INTERNATIONAL SYMPOSIUM ON LANGUAGE, LITERATURE AND TRANSLATION, P562
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jin X, 2017, IEEE INT CON MULTI, P673, DOI 10.1109/ICME.2017.8019497
   Ore O, 1988, NUMBER THEORY ITS HI, P129
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Rabin T., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P73, DOI 10.1145/73007.73014
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shashank J, 2008, 2008 IEEE COMP SOC C
   Sohn H, 2010, LECT NOTES COMPUT SC, V6297, P622, DOI 10.1007/978-3-642-15702-8_57
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola PA, 2001, IEEE 8 INT C COMP VI, P747
   Wang QZ, 2019, IEEE ACCESS, V7, P3918, DOI 10.1109/ACCESS.2018.2889782
NR 25
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7711
EP 7726
DI 10.1007/s11042-020-10124-z
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000006
DA 2024-07-18
ER

PT J
AU Gennari, R
   Matera, M
   Melonio, A
   Rizvi, M
   Roumelioti, E
AF Gennari, Rosella
   Matera, Maristella
   Melonio, Alessandra
   Rizvi, Mehdi
   Roumelioti, Eftychia
TI Reflection and awareness in the design process: children ideating,
   programming and prototyping smart objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Smart object; Design; Children; Reflection; Awareness
AB Design of new technology with children has been widely investigated, and lately several workshops have been organised with children for designing novel IoT or smart objects, e.g., for smart cities or parks. Gradually, the research focus has shifted, from an analysis of the technology itself, which children help create, towards an analysis of children's possible gains in design workshops. However, in spite of several recent efforts, it is still unclear what happens when children participate in diverse parts of a design process, ranging from ideation to prototyping. This paper investigates it, focussing on children's gains in relation to their knowledge of design. A structured design workshop can help obtain such gains and analyse their achievements. Therefore this paper presents a structured design workshop with 27 children, aged from 11 to 14 years old, ideating, programming and prototyping smart objects for their town park. The workshops was structured and centred around a board-game with cards, so as to playfully make children reflect about design, and promote their awareness of what they were doing. Data were gathered in relation to children's reflections from different perspectives, during the workshop, and in relation to their awareness of design, after the workshop. The analysis of the gathered data suggests that the workshop positively affected children's reflections on design and awareness of design, giving indications for future work concerning critical design with children.
C1 [Gennari, Rosella; Melonio, Alessandra; Roumelioti, Eftychia] Free Univ Bozen Bolzano, Bolzano, Italy.
   [Matera, Maristella; Rizvi, Mehdi] Politecn Milan, Milan, Italy.
C3 Free University of Bozen-Bolzano; Polytechnic University of Milan
RP Gennari, R (corresponding author), Free Univ Bozen Bolzano, Bolzano, Italy.
EM gennari@inf.unibz.it; maristella.matera@polimi.it;
   alessandra.melonio@unibz.it; syedmehdi.rizvi@polimi.it;
   eftychia.roumelioti@stud-inf.unibz.it
RI Gennari, Rosella/HIR-3964-2022; Gennari, Rosella/AAX-1802-2021; Rizvi,
   Mehdi/AAV-6017-2021
OI Gennari, Rosella/0000-0003-0063-0996; Roumelioti,
   Eftychia/0000-0003-3293-4521; Rizvi, Mehdi/0000-0001-8386-5779; MATERA,
   MARISTELLA/0000-0003-0552-8624; Melonio, Alessandra/0000-0001-6655-1946
FU PRIN; Free University of Bozen-Bolzano; Politecnico di Milano
FX The work reported in this paper was funded by means of: PRIN 2017
   "EMPATHY: EMpowering People in deAling with internet of THings
   ecosYstems; SNaP 2019 "Smart Nature Protagonists"; the Smart Design 2020
   research framework between the Free University of Bozen-Bolzano and
   Politecnico di Milano.
CR Adams E., 2009, Fundamentals of game design
   Baykal GE, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174166
   Berger A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300631
   Blikstein P., 2013, MAKERSMOVEMENT FABLA, P613, DOI DOI 10.1145/2485760.2485884
   Darzentas D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300801
   De Roeck D, 2019, DIS '19 COMPANION: COMPANION PUBLICATION OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P159, DOI 10.1145/3301019.3323686
   Dodero G., 2014, CHI 14 EXTENDED ABST, P707
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   ERIKSSON E, 2019, WIDENING SCOPE FABLE
   Foundation ME, 2019, MICR ED FDN MICR
   Foundation S, 2019, SCRATCH CARDS SCRATC
   Gennari F, 2019, SPR PROC BUS ECON, P137, DOI 10.1007/978-3-030-00335-7_9
   Gennari R, 2020, BEHAV INFORM TECHNOL, V39, P88, DOI 10.1080/0144929X.2019.1614226
   Gennari R, 2017, P 12 BIANN C IT SIGC, p26:1
   Gennari R, 2021, P METH INT SYST TECH
   Gennari R, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P405, DOI 10.1145/3341215.3356281
   Gianni F, 2017, INTERACT DES ARCHIT, P100
   Hourcade JP., 2015, Child Computer Interaction
   Huyghe J., 2014, P 32 ANN ACM C HUM F, P1975
   Iivari N, 2018, PDC 2018: PARTICIPATORY DESIGN, DEMOCRACY AND POLITICS, VOL 1, DOI 10.1145/3210586.3210600
   Iversen OS, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P27, DOI 10.1145/3078072.3079725
   Kinnula M, 2019, FABLEARN EUROPE 2019 - CONFERENCE ON CREATIVITY AND MAKING IN EDUCATION, DOI 10.1145/3335055.3335071
   Kinnula Marianne, 2017, ICIS
   Klapwijk R., 2018, P FABLEARN NETH 2018, P50, DOI [10.5281/zenodo.1413627, DOI 10.5281/ZENODO.1413627]
   Knowles B, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P751, DOI 10.1145/3322276.3322315
   Kortuem G, 2010, IEEE INTERNET COMPUT, V14, P44, DOI 10.1109/MIC.2009.143
   Lechelt S, 2020, PROCEEDINGS OF IDC 2020, P11, DOI 10.1145/3392063.3394401
   Lechelt Z, 2017, UB 2016 ADJ P 2016 A
   Mavroudi A, 2018, ADV INTELL SYST, V725, P294, DOI 10.1007/978-3-319-75175-7_31
   Melonio A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399828
   Microsoft, 2019, MICR MAK
   Mora S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P587, DOI 10.1145/3064663.3064699
   READ JC, 2016, P NORD 16 9 NORD C
   Root E., 2019, P MENSCH COMPUTER 20, P493, DOI [10.1145/3340764.3344445, DOI 10.1145/3340764.3344445]
   Roumelioti Eftychia, 2020, DIS '20: Companion Publication of the 2020 ACM Designing Interactive Systems Conference, P227, DOI 10.1145/3393914.3395849
   Said-Metwaly S., 2017, Creativity: Theories, Research, Applications, V4, P238, DOI 10.1515/ctra-2017-0013
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1
   Schut A, 2018, P PATT36 INT C 07
   Thang B., 2008, P 7 INT C INTERACTIO, P266
   Thinkers S, 2019, KHANDU BUILDING LITT
   Thoring K., 2011, Procedings of the Second Conference on Creativity and Innovation in Design, P137, DOI [10.1145/2079216.2079236, DOI 10.1145/2079216.2079236]
   Vaajakallio K, 2014, CODESIGN, V10, P63, DOI 10.1080/15710882.2014.881886
   Van Mechelen M, 2019, INT J HUM-COMPUT ST, V130, P179, DOI 10.1016/j.ijhcs.2019.06.013
   Ventä-Olkkonen L, 2019, LECT NOTES COMPUT SC, V11746, P418, DOI 10.1007/978-3-030-29381-9_27
   WOOD G, 2019, CHI 2019 P 2019 CHI
   Yilmaz S, 2016, DESIGN STUD, V46, P95, DOI 10.1016/j.destud.2016.05.001
NR 46
TC 13
Z9 13
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34909
EP 34932
DI 10.1007/s11042-020-09927-x
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000578652200001
DA 2024-07-18
ER

PT J
AU Sleem, L
   Couturier, R
AF Sleem, Lama
   Couturier, Raphael
TI Speck-R: An ultra light-weight cryptographic scheme for Internet of
   Things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Encryption; Internet of Things; Cryptography; Randomness;
   Confusion
ID BLOCK CIPHER; ENCRYPTION; EFFICIENT; AES; DESIGN
AB Lightweight cryptography (LWC) is an interesting research area in the field of information security. Some limitations like: increased components usage, time consumption, power consumption and memory requirement mandate the need for lightweight cryptography. One of the proposed algorithms in this field is Speck which was designed by the National Security Agency (NSA) in June 2013. In this paper, we propose a new ultra-lightweight cryptographic algorithm based on Speck known as Speck-R. Speck-R is a hybrid cipher, combining ARX architecture with a dynamic substitution layer. The novelty in this paper resides in adding a key-dynamic substitution layer that changes according to a dynamic key. With this modification, the number of rounds can be reduced from 26 (in Speck) to 7 (in Speck-R). Thus, the main contribution of this paper consists in reducing the execution time of Speck by at least 18% on limited devices to reach a reduction of 77% while keeping a high level of security. To backbone Speck-R's security, different security and statistical tests are exerted on Speck-R. In addition, a real hardware implementation on three different famous IoT devices is also presented where Speck-R outperformed Speck in terms of execution times. Finally, extensive tests show that Speck-R possesses the necessary criteria to be considered as a good cipher scheme that is suitable for lightweight devices.
C1 [Sleem, Lama; Couturier, Raphael] Univ Bourgogne Franche Comte UBFC, CNRS, FEMTO ST Inst, Belfort, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Franche-Comte; Universite de Technologie de Belfort-Montbeliard (UTBM)
RP Sleem, L (corresponding author), Univ Bourgogne Franche Comte UBFC, CNRS, FEMTO ST Inst, Belfort, France.
EM lama.sleem@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013
OI Couturier, Raphaël/0000-0003-1490-9592
FU EIPHI Graduate School [ANR-17-EURE-0002]
FX Part of the simulations was conducted on the servers of the "Mesocentre
   de calcul de Franche-Comte". We would like to thank them for accepting
   our request and for giving us access to their machines. This paper is
   also partially supported from the EIPHI Graduate School (contract
   "ANR-17-EURE-0002").
CR Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Alvarez J., 2010, La pesca de arrastre en Costa Rica, P1
   Andrea I, 2015, 2015 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P180, DOI 10.1109/ISCC.2015.7405513
   [Anonymous], 2014, IACR CRYPTOLOGY EPRI
   [Anonymous], 2006, THESIS
   Beaulieu R., 2017, 2017560 CRYPT EPRINT
   Beaulieu R., 2013, The SIMON and SPECK Families of Lightweight Block Ciphers
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biryukov A., 2017, Cryptology ePrint Archive
   Bodden D., 2016, P 37 S INF THEOR BEN
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Borghoff J, 2012, LECT NOTES COMPUT SC, V7658, P208, DOI 10.1007/978-3-642-34961-4_14
   Buhrow B, 2015, LECT NOTES COMPUT SC, V8895, P104, DOI 10.1007/978-3-319-16295-9_6
   Carlet C, 2005, LECT NOTES COMPUT SC, V3797, P49
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Cho JS, 2011, COMPUT COMMUN, V34, P391, DOI 10.1016/j.comcom.2010.02.029
   Crama Y., 2011, Boolean Functions: Theory, Algorithms, and Applications
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Dalai DK, 2004, LECT NOTES COMPUT SC, V3348, P92
   Ding C., 1991, The Stability Theory of Stream Ciphers, V561
   Dinur I, 2014, LECT NOTES COMPUT SC, V8781, P147, DOI 10.1007/978-3-319-13051-4_9
   Doty-Humphrey Chris., 2014, PractRand
   du Prel JB, 2009, DTSCH ARZTEBL INT, V106, P335, DOI 10.3238/arztebl.2009.0335
   Dwivedi AD, 2019, IEEE ACCESS, V7, P16476, DOI 10.1109/ACCESS.2019.2894337
   Eisler CG, 1999, US Patent, Patent No. [6,008,816, 6008816]
   Elbirt A.J., 2007, 21st International Conference on Advanced Information Networking and Applications Workshops, P396
   Engels D, 2011, INT WORKSH RAD FREQ, P1931
   Fan LM, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P206, DOI 10.1109/ICYCS.2008.302
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Gilbert H, 2005, FAST SOFTW ENCR 12 C
   Gong Z, 2012, LECT NOTES COMPUT SC, V7055, P1, DOI 10.1007/978-3-642-25286-0_1
   Gueron S, 2009, LECT NOTES COMPUT SC, V5665, P51, DOI 10.1007/978-3-642-03317-9_4
   Guilley S, 2004, INT FED INFO PROC, V153, P127
   Hatzivasilis G, 2018, J CRYPTOGR ENG, V8, P141, DOI 10.1007/s13389-017-0160-y
   Hong D, 2006, LECT NOTES COMPUT SC, V4249, P46, DOI 10.1007/11894063_4
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   INFSO DG, 2008, INT THINGS 2020 ROAD, pD4
   Kamalinejad P, 2015, IEEE COMMUN MAG, V53, P102, DOI 10.1109/MCOM.2015.7120024
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Lafitte F, 2012, BOOLFUN PACKAGE CRYP
   Lee H, 2009, ARXIV09110482
   Lemire D, 2018, TESTINGRNG
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   McKay K. A., 2017, Report on lightweight cryptography, DOI DOI 10.6028/NIST.IR.8114
   Mohd BJ, 2015, J NETW COMPUT APPL, V58, P73, DOI 10.1016/j.jnca.2015.09.001
   Moradi A, 2011, LECT NOTES COMPUT SC, V6632, P69, DOI 10.1007/978-3-642-20465-4_6
   Needham R., 1997, TEA EXTENSIONS
   Nithya R, 2016, PROC TECH, V25, P302, DOI 10.1016/j.protcy.2016.08.111
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P15457, DOI 10.1007/s11042-017-5124-9
   NSA, 2019, LIGHTW CRYPT
   Osvik DA, 2010, LECT NOTES COMPUT SC, V6147, P75, DOI 10.1007/978-3-642-13858-4_5
   Özkaynak F, 2020, IJST-T ELECTR ENG, V44, P89, DOI 10.1007/s40998-019-00230-6
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rivest R. L., 1994, INT WORKSH FAST SOFT, P86, DOI [10.1007/3-540-60590-8_7, DOI 10.1007/3-540-60590-8_7]
   Rivest RL, 1992, RC4 ENCRYPTION ALGOR, V12, P9
   Seberry J., 1993, P 1 ACM C COMPUTER C, P171
   Shu ZG, 2016, MOBILE NETW APPL, V21, P764, DOI 10.1007/s11036-016-0676-x
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Sleem L, 2020, MULTIMED TOOLS APPL, V79, P24075, DOI 10.1007/s11042-020-09108-w
   Steele GL, 2014, ACM SIGPLAN NOTICES, V49, P453, DOI [10.1145/2714064.2660195, 10.1145/2660193.2660195]
   Stein W, 2009, SAGE OPEN SOURCE MAT
   Taufik M, 2020, AIP CONF PROC, V2226, DOI 10.1063/5.0003527
   Team R.C, 2017, R LANG ENV STAT COMP
   Tillich S, 2006, LECT NOTES COMPUT SC, V4249, P270
   Tupsamudre H, 2014, 2014 WORKSHOP ON FAULT DIAGNOSIS AND TOLERANCE IN CRYPTOGRAPHY (FDTC 2014), P40, DOI 10.1109/FDTC.2014.14
   VanVoorhis CRW, 2007, TUTOR QUANT METHODS, V3, P43, DOI 10.20982/tqmp.03.2.p043
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Weddell AS, 2018, INT POWER ELECT ELEC, P111, DOI 10.1109/SPEEDAM.2018.8445323
   WHEELER PW, 1994, IEE CONF PUBL, P363
   Xu SJ, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P994
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang WT, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5459-7
NR 80
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17067
EP 17102
DI 10.1007/s11042-020-09625-8
EA OCT 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000577469700001
DA 2024-07-18
ER

PT J
AU Qiao, JJ
   Song, HH
   Zhang, KH
   Zhang, XL
AF Qiao, Jiaojiao
   Song, Huihui
   Zhang, Kaihua
   Zhang, Xiaolu
TI Conditional generative adversarial network with densely-connected
   residual learning for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Conditional generative adversarial network; Residual
   network; Deep convolutional neural network
AB Recently, generative adversarial network (GAN) has been widely employed in single image super-resolution (SISR), achieving favorably good perceptual effects. However, the SR outputs generated by GAN still have some fictitious details, which are quite different from the ground-truth images, resulting in a low PSNR value. In this paper, we leverage the ground-truth high-resolution (HR) image as a useful guide to learn an effective conditional GAN (CGAN) for SISR. Among it, we design the generator network via residual learning, which introduces dense connections to the residual blocks to effectively fuse low and high-level features across different layers. Extensive evaluations show that our proposed SR method performs much better than state-of-the-art methods in terms of PSNR, SSIM, and visual perception.
C1 [Qiao, Jiaojiao; Song, Huihui; Zhang, Kaihua; Zhang, Xiaolu] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol B DAT, Nanjing, Peoples R China.
   [Qiao, Jiaojiao; Song, Huihui; Zhang, Kaihua; Zhang, Xiaolu] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Zhang, KH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol B DAT, Nanjing, Peoples R China.; Zhang, KH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Peoples R China.
EM zhkhua@gmail.com
RI Song, Huihui/ABE-8521-2021; ZHANG, Kaihua/ABE-9067-2020
OI Song, Huihui/0000-0002-7275-9871; ZHANG, Kaihua/0000-0002-1613-3401
FU National Major Project of China for New Generation of AI
   [2018AAA0100400]; NSFC [61872189, 61876088]; NSF of Jiangsu Province
   [BK20191397, BK20170040]; 333 High-level Talents Cultivation Project of
   Jiangsu Province [BRA2020291]
FX This work is supported in part by National Major Project of China for
   New Generation of AI (No. 2018AAA0100400), in part by the NSFC
   (61872189, 61876088), in part by the NSF of Jiangsu Province
   (BK20191397, BK20170040), in part by the 333 High-level Talents
   Cultivation Project of Jiangsu Province (BRA2020291).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He XY, 2019, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2019.00183
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Qiao JJ, 2019, IET IMAGE PROCESS, V13, P2673, DOI 10.1049/iet-ipr.2018.6570
   Radford A., 2015, ARXIV
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vella M., 2019, P BMVC
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang YQ, 2019, ENERGY SCI ENG, V7, P899, DOI 10.1002/ese3.319
   Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang Q, 2020, MYCOKEYS, P1, DOI [10.3897/myookeys.67.49483, 10.3897/mycokeys.67.49483]
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 39
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4383
EP 4397
DI 10.1007/s11042-020-09817-2
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573766700003
DA 2024-07-18
ER

PT J
AU Jawahar, M
   Babu, NKC
   Vani, K
   Anbarasi, LJ
   Geetha, S
AF Jawahar, Malathy
   Babu, N. K. Chandra
   Vani, K.
   Anbarasi, L. Jani
   Geetha, S.
TI Vision based inspection system for leather surface defect detection
   using fast convergence particle swarm optimization ensemble classifier
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image analysis; Leather surface defect detection; segmentation; Fast
   convergence particle swarm optimization; Ensemble classifier
ID ALGORITHM; SEGMENTATION; STANDARD; FEATURES; BRAIN
AB Surface defect inspection plays a vital role in leather manufacturing. Current practice involves an expert to inspect each piece of leather individually and detect defects manually. However, such a manual inspection is highly subjective and varies quite considerably from one assorter to another. Computer vision system for natural material like leather is a challenging research problem. This study describes the application of computer vision system to capture leather surface images and use of a novel Fast Convergence Particle Swarm Optimization (FCPSO) algorithm on a set of handcrafted texture features viz., GLCM and classified using supervised classifiers viz., Multi Layer Perceptron (MLP), Decision Tree (DT), SVM, Naive Bayes, K-Nearest Neighbors (KNN) and Random Forest (RF). FCPSO using modified fitness function by selective band Shannon entropy is implemented to segment industrial leather images. Segmentation efficiency of the proposed FCPSO algorithm is evaluated and its performance is compared with other optimization algorithms. Efficiency of the segmentation algorithms is evaluated using performance measures such as average difference (AD), Area Error Rate (AER), Edge-based structural similarity index (ESSIM), F-Score, Normalized correlation coefficient (NK), Overlap Error (OE), structural content (SC), Structural similarity index (SSIM) and Zijdenbos similarity index (ZSI). Correlation of the segmented area using FCPSO with the experts' ground truth is found to be high with R value of 0.84. Feature extraction is carried out using GLCM texture features and the most prominent features were selected using statistical t-test and correlation coefficient. Experimental results showed encouraging results for random forest classifier confirming the potential of the proposed system for automatic leather defect classification.
C1 [Jawahar, Malathy; Babu, N. K. Chandra] CSIR Cent Leather Res Inst, Leather Proc Technol Div, Chennai 600020, Tamil Nadu, India.
   [Jawahar, Malathy; Babu, N. K. Chandra] Anna Univ, Dept Leather Technol, Chennai 600025, Tamil Nadu, India.
   [Vani, K.] Anna Univ, Dept Informat Sci & Technol, Chennai 600025, Tamil Nadu, India.
   [Anbarasi, L. Jani; Geetha, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai 600127, Tamil Nadu, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Leather Research Institute (CLRI); Anna University; Anna
   University Chennai; Anna University; Anna University Chennai; Vellore
   Institute of Technology (VIT); VIT Chennai
RP Jawahar, M (corresponding author), CSIR Cent Leather Res Inst, Leather Proc Technol Div, Chennai 600020, Tamil Nadu, India.; Jawahar, M (corresponding author), Anna Univ, Dept Leather Technol, Chennai 600025, Tamil Nadu, India.
EM malathy.jawahar@gmail.com; babunkc@yahoo.com; vani@anna.edu;
   janianbarasi.l@vit.ac.in; geetha.s@vit.ac.in
RI Jawahar, Malathy/AGF-0100-2022; l, j/JVZ-8480-2024; L, J/JEF-9564-2023;
   Jawahar, Dr. Malathy/AGF-0084-2022; S, Geetha/IYJ-9136-2023
OI Jawahar, Dr. Malathy/0000-0001-6865-2097; L, JANI
   ANBARASI/0000-0002-8904-2236
FU CSIR, New Delhi under the Supra Institutional Project S&T Revolution in
   Leather with a Green Touch (STRAIT) communication
   [A/2018/LPT/CSC0201/1275]
FX The authors acknowledge the financial support from CSIR, New Delhi under
   the Supra Institutional Project S&T Revolution in Leather with a Green
   Touch (STRAIT) communication no. A/2018/LPT/CSC0201/1275.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alkan A, 2014, MEASUREMENT, V47, P861, DOI 10.1016/j.measurement.2013.10.009
   Anil KJ, 1998, Texture analysis. The handbook of pattern recognition and computer vision, P207
   Bowman CC, 1996, P SOC PHOTO-OPT INS, V2908, P33, DOI 10.1117/12.257274
   Branca A., 1997, Computer Analysis of Images and Patterns. 7th International Conference, CAIP '97. Proceedings, P223, DOI 10.1007/3-540-63460-6_121
   Branca A., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P584
   Branca A, 1996, P SOC PHOTO-OPT INS, V2908, P97, DOI 10.1117/12.257252
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bruder M., 2019, P 35 INT UN LEATH TE
   Cao L, 2008, IMAGE VISION COMPUT, V26, P716, DOI 10.1016/j.imavis.2007.08.007
   Chang JF, 2005, J INF SCI ENG, V21, P809
   del Valle Y, 2008, IEEE T EVOLUT COMPUT, V12, P171, DOI 10.1109/TEVC.2007.896686
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dongping Tian EFPSO, 2018, J INFORM HIDING MULT, V9, P1365
   Duraisamy Sathya P., 2010, Journal of Intelligent Learning Systems and Applications, V2, P126, DOI 10.4236/jilsa.2010.23016
   EBERHART R., 2001, Swarm Intelligence
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Ge WF, 2017, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2017.9
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He FQ, 2006, KEY ENG MATER, V326-328, P469, DOI 10.4028/www.scientific.net/KEM.326-328.469
   He Fuqiang, 2006, TECHNOLOGY INNOVATIO, P2024
   Hemerson P., 2006, COMPIMAGE COMPUTATIO, P355
   Hoang K, 1996, MACH VISION APPL, V9, P119, DOI 10.1007/BF01216817
   Hu XH, 2004, IEEE C EVOL COMPUTAT, P90
   Jang-Woo Kwon, 2004, TENCON 2004. 2004 IEEE Region 10 Conference (IEEE Cat. No. 04CH37582), P327
   Jawahar M, 2019, J AM LEATHER CHEM AS, V114, P10
   Jawahar M, 2014, IEEE I C COMP INT CO, P1288
   Jawahar M, 2016, IEEE I C COMP INT CO, P933
   Jiang M, 2007, INFORM PROCESS LETT, V102, P8, DOI 10.1016/j.ipl.2006.10.005
   Kaloyan K, 2005, P INT C COMP SYST TE
   Kasi M, 2014, AM SOC TEST MATER, V1586, P1, DOI 10.1520/STP158620140029
   Kayalvizhi M, 2015, MEASUREMENT, V74, P103, DOI 10.1016/j.measurement.2015.06.021
   Khan SA, 2012, APPL INTELL, V36, P161, DOI 10.1007/s10489-010-0251-2
   Kornblith S., 2018, CoRR
   Krastev K, 2006, P INT C COMP SYST TE
   Kulkarni RV, 2010, IEEE T SYST MAN CY C, V40, P663, DOI 10.1109/TSMCC.2010.2049649
   Kwak C, 2000, J INTELL MANUF, V11, P485, DOI 10.1023/A:1008974314490
   Lerch A., 1991, Engineering Applications of Artificial Intelligence, V4, P433, DOI 10.1016/0952-1976(91)90032-2
   LIMASSERAFIM AF, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1357, DOI 10.1109/IECON.1993.339265
   Liong S.-T., 2019, ARXIV190312139
   Lovergine FP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P669, DOI 10.1109/ICIP.1997.638584
   Maitra M, 2008, MEASUREMENT, V41, P1124, DOI 10.1016/j.measurement.2008.03.002
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   MICHEL AN, 1992, 1992 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-6, P304, DOI 10.1109/ISCAS.1992.229953
   Mohagheghian E, 2018, FUEL, V223, P86, DOI 10.1016/j.fuel.2018.01.138
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Neto MM, 2005, INT FED INFO PROC, V159, P387
   Pereira RF, 2018, IEEE IJCNN
   Peters S, 2007, NEURAL NETW WORLD, V17, P507
   POLZLEITNER W, 1994, P SOC PHOTO-OPT INS, V2347, P50, DOI 10.1117/12.188759
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sathya P. D., 2010, International Journal of Computer Applications, V5, P39, DOI [10.5120/903-1279, DOI 10.5120/903-1279]
   SERAFIM AFL, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P41, DOI 10.1109/ICPR.1992.201923
   Sezgin M, 2000, PATTERN RECOGN LETT, V21, P151, DOI 10.1016/S0167-8655(99)00142-7
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sharon JJ, 2018, 2018 FIFTH HCT INFORMATION TECHNOLOGY TRENDS (ITT): EMERGING TECHNOLOGIES FOR ARTIFICIAL INTELLIGENCE, P41, DOI 10.1109/CTIT.2018.8649511
   Sindhu SSS, 2012, INT J SYST SCI, V43, P2334, DOI 10.1080/00207721.2011.577244
   Sobral JL, 2005, LECT NOTES COMPUT SC, V3523, P682
   Sorwar G., 2004, Malaysian Journal of Computer Science, V17, P13
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Teng, 2018, J INFORM HIDING MULT, V9
   Tofang-Sazi K, 2001, Intell. Data Anal., V5, P355
   Villar P, 2011, LECT NOTES COMPUT SC, V7042, P591, DOI 10.1007/978-3-642-25085-9_70
   Wang L, 1765, IEEE MACH LEARN CYB, V3, P2007
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   Yeh C, 2005, INT J ADV MANUF TECH, V25, P1197, DOI 10.1007/s00170-003-1945-y
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   ZWEIG MH, 1993, CLIN CHEM, V39, P561
NR 73
TC 17
Z9 20
U1 5
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4203
EP 4235
DI 10.1007/s11042-020-09727-3
EA SEP 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573572200001
DA 2024-07-18
ER

PT J
AU Thanki, R
   Kothari, A
AF Thanki, Rohit
   Kothari, Ashish
TI Multi-level security of medical images based on encryption and
   watermarking for telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold; Finite ridge transform (FRT); Medical image; Singular value
   decomposition (SVD); Telemedicine; Watermarking
ID DCT; SVD; PROJECTION; SCHEME; FACE; FRT
AB In this paper, a robust and hybrid domain watermarking scheme is proposed for the security of medical images in telemedicine applications. The secret identity of the patient is inserting into the cover medical image using the hybridization of ridgelet transform and singular value decomposition for the purposed of identification and authentication. For better security of watermarked medical image, the Arnold scrambling based encryption is applying to it before sending it at the receiver end. The main advantage of this scheme is multi-level security where secret patient information is inserted to cover medical image to get a secure watermarked medical image using watermarking. Then, encryption is applied to the watermarked medical image to generate its encrypted version. Thus, this proposed scheme provides multi-level security using watermarking and encryption. The advantage of multi-level security in the proposed scheme is that if an imposter or attacker tries to get patient identity from the medical image, he or she requires multiple information in terms of extraction steps and keys, etc. The other reason for proposed this scheme that it improves the payload capacity of many existing watermarking schemes. Experimental results of the scheme indicated that the proposed scheme provides high imperceptibility and more robustness against various types of attacks. Further, the performance of the proposed scheme is found better than existing medical watermarking schemes. Furthermore, quality checking of watermarked medical image is done by various quality measures which are indicated that the quality of the image has fulfilled the benefits of secure telemedicine applications.
C1 [Thanki, Rohit] Progn Labs, Dubai, U Arab Emirates.
   [Kothari, Ashish] Atmiya Univ, Rajkot, Gujarat, India.
RP Thanki, R (corresponding author), Progn Labs, Dubai, U Arab Emirates.
EM rohitthanki9@gmail.com
RI Thanki, Dr. Rohit/Q-9029-2017; Kothari, Ashish/AFQ-8291-2022
OI Thanki, Dr. Rohit/0000-0002-0645-6266; Kothari,
   Ashish/0000-0002-1981-8465
CR [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Ashour AS, 2017, STUD COMPUT INTELL, V660, P3, DOI 10.1007/978-3-319-44790-2_1
   Babu S., 2019, Int J Intell Inf Syst, V7, P38
   Banerjee Shubhendu, 2015, International Journal of Image, Graphics and Signal Processing, V7, P1, DOI 10.5815/ijigsp.2015.03.01
   Borra S, 2019, COMPUTER METHODBIO, P1
   Borra S., 2015, INT C SWARM EV MEM C, V9873, P29
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li M, 2013, ADV INTEL SYS RES, V84, P1309
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Menon V, 2016, IEEE GEOSCI REMOTE S, V13, P1275, DOI 10.1109/LGRS.2016.2581172
   Pirbhulal S, 2019, FUTURE GENER COMP SY, V95, P382, DOI 10.1016/j.future.2019.01.008
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Surekha B, 2011, INT J SECUR APPL, V5, P1
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   THANKI R, 2019, SPRINGERBR APPL SCI, P1
   Thanki RM, 2017, INTELLIGENT ANAL MUL, P431
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   2017, MULTIMED SYST APPL, P1
NR 32
TC 22
Z9 22
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4307
EP 4325
DI 10.1007/s11042-020-09941-z
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573567600003
DA 2024-07-18
ER

PT J
AU Arora, M
   Kumar, M
AF Arora, Malika
   Kumar, Munish
TI AutoFER: PCA and PSO based automatic facial emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Gradient; PCA; PSO; Human-computer interaction
ID MODELS
AB Automatic emotion recognition is a critical part of human-machine interactions. Reflection of emotions and to develop its understanding is crucial to provide dealings across human beings and machine frameworks. This work determines an automatic system that distinguishes different emotions connoted on the face. The framework is deliberated to apply the hybridization of feature extraction and optimization using PCA and PSO, respectively, to accomplish a high precision rate. PCA is used to get high-quality feature vectors for each category of emotion. Swarm intelligence, optimization is applied to get an optimized feature vector which is essential for classifying the features in the testing phase. For exploratory work, the authors have considered the Japanese Female Facial Expression (JAFFE) dataset. A maximum classification rate of 94.97% is achieved with the proposed technique. The proposed framework execution is assessed in terms of the false rejection rate, false acceptance rate, and accuracy.
C1 [Arora, Malika; Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Agrawal DD, 2014, INT J COMPUT VISION, V44, P365, DOI 10.1504/IJCVR.2014.065571
   [Anonymous], 2017, ARXIV170108071
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Chen SY, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P630, DOI 10.1109/ISM.2009.24
   Chiranjeevi P, 2015, IEEE T IMAGE PROCESS, V24, P2701, DOI 10.1109/TIP.2015.2421437
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   Krestinskaya O, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P752, DOI 10.1109/ICACCI.2017.8125932
   Kumar S, 2018, WIRELESS PERS COMMUN, V103, P2435, DOI 10.1007/s11277-018-5923-y
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Murtaza M, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P190, DOI 10.1109/CCWC.2019.8666602
   Saeed A, 2014, ADV HUM-COMPUT INTER, V2014, DOI 10.1155/2014/408953
   Sanchez A, 2011, NEUROCOMPUTING, V74, P1272, DOI 10.1016/j.neucom.2010.07.017
   Torres L., 1999, IEEE INT C IM PROC, P627, DOI 10.1109/ICIP.1999.81719
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
NR 22
TC 29
Z9 29
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3039
EP 3049
DI 10.1007/s11042-020-09726-4
EA SEP 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100001
DA 2024-07-18
ER

PT J
AU Qi, YL
   Yang, Z
   Lei, JQ
   Lian, J
   Liu, JZ
   Feng, W
   Ma, YD
AF Qi, Yunliang
   Yang, Zhen
   Lei, Junqiang
   Lian, Jing
   Liu, Jizhao
   Feng, Wen
   Ma, Yide
TI Morph_SPCNN model and its application in breast density segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast density; Image segmentation; Morph_SPCNN; SVM; SPCNN
ID IMAGE SEGMENTATION; NEURAL-NETWORK; PARENCHYMAL PATTERNS; CANCER RISK;
   LINKING; MRI
AB Breast density is known as a significant indicator of breast cancer risk prediction and greatly reduces the digital mammograms sensitivity. In this work, based on the simple pulse coupled neural network (SPCNN), a novel Morph_SPCNN model is proposed for dealing with the limitations of over-segmentation that commonly existed in density segmentation of mammograms. To evaluate the proposed model, the segmentation result is employed as a feature map of the breast density classification system. In addtion, the texture features of mammogram calculated based on the gray level co-occurrence matrix (GLCM) and the statistical features (mean, skewness, kurtosis) are extracted and input to the support vector machine (SVM) for breast density classification. Finally, the performance of SVM classifier is evaluated based on the ten-fold cross-validation. Our method is verified both on the MIAS dataset, DDSM database and hybrid dataset (MIAS database and Gansu Provincial Academy of Medical Sciences (GPAMS) database), respectively achieving 87.80%, 94.89% and 95.37% accuracy for breast density classification. The experimental results indicate that our proposed method has greatly improved the performance of breast density segmentation and classification.
C1 [Qi, Yunliang; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
   [Yang, Zhen; Lian, Jing] Lanzhou Jiaotong Univ, Sch Elect & Informat Engn, Lanzhou 730070, Gansu, Peoples R China.
   [Lei, Junqiang] Lanzhou Univ, Hosp 1, Lanzhou 730000, Gansu, Peoples R China.
   [Liu, Jizhao] Sun Yat Sen Univ, Sch Data Sci & Comp Sci, Guangzhou 510006, Peoples R China.
   [Feng, Wen] Lanzhou Univ, Sch Clin Med 1, Lanzhou 730000, Gansu, Peoples R China.
C3 Lanzhou University; Lanzhou Jiaotong University; Lanzhou University; Sun
   Yat Sen University; Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
EM yidema@gmail.com
OI Qi, Yunliang/0000-0002-3741-9177
FU Natural Science Foundation of Gansu Province [18JR3RA288]; Fundamental
   Research Funds for the Central Universities of China
FX This work is jointly supported by the Natural Science Foundation of
   Gansu Province (No.18JR3RA288) and the Fundamental Research Funds for
   the Central Universities of China (No.lzujbky-2017-it72 and
   No.lzujbky-2018-it61).
CR AC Society, 2019, CANC FACTS FIG 2019
   Anguita D, 2005, NEURAL NETWORKS 2005, DOI [10.1109/IJCNN.2005.1555964, DOI 10.1109/IJCNN.2005.1555964]
   Angulo J, 2016, NONLINEAR ANAL-THEOR, V134, P1, DOI 10.1016/j.na.2015.12.015
   [Anonymous], 2001, MIUA
   B.C. U.K, 2019, KEY FACTS BREAST CAN
   Bosch Anna., 2006, COMPUTER VISION PATT, V2, P1552, DOI DOI 10.1109/CVPR.2006.188
   Bowyer K, 1996, INT CONGR SER, V1119, P431
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   D'Orsi C.J., 2013, Breast Imaging Reporting and Data SystemACR BI-RADS Atlas
   Deng J, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105489
   [邓翔宇 Deng Xiangyu], 2012, [电子学报, Acta Electronica Sinica], V40, P955
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Ekblad U, 2004, NUCL INSTRUM METH A, V525, P392, DOI 10.1016/j.nima.2004.03.102
   Elshinawy MY, 2011, IEEE INT S BIOM IM N, DOI [10.1109/ISBI.2011.5872374, DOI 10.1109/ISBI.2011.5872374]
   Eng A, 2014, BREAST CANCER RES, V16, DOI 10.1186/s13058-014-0439-1
   Gong XN, 2019, MULTIMED TOOLS APPL, V78, P31185, DOI 10.1007/s11042-019-07917-2
   Gu XD, 2008, NEURAL PROCESS LETT, V27, P25, DOI 10.1007/s11063-007-9057-6
   Hage IS, 2013, COMPUT MED IMAG GRAP, V37, P466, DOI 10.1016/j.compmedimag.2013.08.003
   Hamidinekoo A, 2018, MED IMAGE ANAL, V35, P303
   Hassanien AE, 2012, J APPL LOGIC, V10, P277, DOI 10.1016/j.jal.2012.07.003
   He WD, 2011, BIOMED SIGNAL PROCES, V6, P321, DOI 10.1016/j.bspc.2011.03.008
   Holzinger A., 2020, KI KUNSTLICHE INTELL, P1, DOI DOI 10.1007/S13218-020-00636-Z
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jia T, 2015, J MED IMAG HEALTH IN, V5, P1936, DOI 10.1166/jmihi.2015.1673
   JOHNSON JL, 1993, OPT LETT, V18, P1253, DOI 10.1364/OL.18.001253
   Kinser JM, 1996, P SOC PHOTO-OPT INS, V2760, P563, DOI 10.1117/12.235951
   Kumar I, 2017, BIOCYBERN BIOMED ENG, V37, P217, DOI 10.1016/j.bbe.2017.01.001
   Kumar I, 2015, PROCEDIA COMPUT SCI, V70, P76, DOI 10.1016/j.procs.2015.10.042
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Lian J, 2020, CLIN BREAST CANCER, V12, P30
   Lian J, 2019, NEUROCOMPUTING, V333, P292, DOI 10.1016/j.neucom.2018.12.007
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Lu X, 2020, COMPUT VIS PATTERN R
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ma Y, 2002, CHINESE SCI BULL, V47, P167
   Ma Yi-de, 2002, Journal of China Institute of Communications, V23, P46
   Mac Parthaláin N, 2010, INTELL DATA ANAL, V14, P225, DOI 10.3233/IDA-2010-0418
   Machida Y, 2015, BREAST CANCER-TOKYO, V22, P253, DOI 10.1007/s12282-015-0602-2
   Malkov S, 2016, BREAST CANCER RES, V18, DOI 10.1186/s13058-016-0778-1
   Manduca A, 2009, CANCER EPIDEM BIOMAR, V18, P837, DOI 10.1158/1055-9965.EPI-08-0631
   MASCI J, 2013, LNCS, V7883, P329, DOI DOI 10.1007/978-3-642-38294-9_28
   McCormack VA, 2006, CANCER EPIDEM BIOMAR, V15, P1159, DOI 10.1158/1055-9965.EPI-06-0034
   Mellouli D, 2019, IEEE T NEUR NET LEAR, V30, P2876, DOI 10.1109/TNNLS.2018.2890334
   Moon WK, 2018, COMPUT METH PROG BIO, V154, P99, DOI 10.1016/j.cmpb.2017.11.008
   Mutra M, 2010, INT S ELM
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Oliver A, 2015, J DIGIT IMAGING, V28, P604, DOI 10.1007/s10278-015-9777-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petroudi S., 2013, 2013 IEEE 13 INT C B, P1, DOI DOI 10.1109/BIBE.2013.6701633
   Rampun A, 2017, COMM COM INF SC, V723, P365, DOI 10.1007/978-3-319-60964-5_32
   Rampun A, 2019, COMP MED SY, P646, DOI 10.1109/CBMS.2019.00133
   Ranganath HS, 1996, P SOC PHOTO-OPT INS, V2760, P543, DOI 10.1117/12.235943
   Remes V, 2015, 2015 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA UNDERSTANDING (IWCIM)
   Ribli D, 2017, SCI REP, V8, P1
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Strand F, 2016, BREAST CANCER RES, V10, DOI 10.1186/s13058-016-0761-x
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Surajudeen A, 2017, INT J COMPUT APPL, V161, P1
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   Virmani J, 2016, PCA PNN PCA SVM BASE, DOI [10.1007/978-3-319-21212-8_7, DOI 10.1007/978-3-319-21212-8_7]
   Wang J, 2017, J DIGIT IMAGING, V30, P215, DOI 10.1007/s10278-016-9922-9
   Wang Yuan-yuan, 2011, Optics and Precision Engineering, V19, P1398, DOI 10.3788/OPE.20111906.1398
   Williams C.K.I, 2003, Journal of the American Statistical Association, V98, P489, DOI [DOI 10.1198/JASA.2003.S269, 10.1198/jasa.2003.s, 10.1198/jasa.2003]
   WOLFE JN, 1976, CANCER-AM CANCER SOC, V37, P2486, DOI 10.1002/1097-0142(197605)37:5<2486::AID-CNCR2820370542>3.0.CO;2-8
   Yang Z, 2018, NEUROCOMPUTING, V285, P196, DOI 10.1016/j.neucom.2018.01.044
   Zhan K, 2017, ARCH COMPUT METHOD E, V24, P573, DOI 10.1007/s11831-016-9182-3
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhili Chen, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P351, DOI 10.1109/BMEI.2011.6098279
NR 79
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2821
EP 2845
DI 10.1007/s11042-020-09796-4
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570470300004
DA 2024-07-18
ER

PT J
AU Chen, X
   Zhou, QH
   Lan, RS
   Wang, SH
   Zhang, YD
   Luo, XN
AF Chen, Xi
   Zhou, Qinghua
   Lan, Rushi
   Wang, Shui-Hua
   Zhang, Yu-Dong
   Luo, Xiaonan
TI Sensorineural hearing loss classification via deep-HLNet and few-shot
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hearing loss; Few-shot learning; Deep-HLNet
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; SVR; ENTROPY
AB We propose a new method for hearing loss classification from magnetic resonance image (MRI), which can automatically detect tissue-specific features in a given MRI. Sensorineural hearing loss (SHNL) is highly prevalent in our society. Early diagnosis and intervention have a profound impact on patient outcomes. A solution to provide early diagnosis is the use of automated diagnostic systems. In this study, we propose a novel Deep-HLNet framework, based on few-shot learning, for the automated classification of SNHL. This research involves magnetic resonance (MRI) images from 60 participants of three balanced categories: left-sided SNHL, right-sided SNHL, and healthy controls. A convolutional neural network was employed for feature extraction from individual categories, while a neural network and a comparison classifier strategy constituted a tri-classifier for SNHL classification. In terms of experiment results and practicability of the algorithm, the classification performance was significantly better than the standard deep learning methods or other conventional methods, with an overall accuracy of 96.62%.
C1 [Chen, Xi; Lan, Rushi; Luo, Xiaonan] Guilin Univ Elect Technol, Guangxi Key Lab Image & Graph Intelligent Proc, Guilin 541004, Peoples R China.
   [Chen, Xi; Zhou, Qinghua; Wang, Shui-Hua; Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Guilin University of Electronic Technology; University of Leicester
RP Lan, RS (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Image & Graph Intelligent Proc, Guilin 541004, Peoples R China.; Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM rslan2016@163.com; yudongzhang@ieee.org
RI Wang, Shuihua/G-7326-2016; Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
FU Royal Society International Exchanges Cost Share Award, UK [RP202G0230];
   Medical Research Council Confidence in Concept Award, UK [MC_PC_17171];
   Hope Foundation for Cancer Research, UK [RM60G0680]; British Heart
   Foundation Accelerator Award, UK; study abroad program for graduate
   student of Guilin University of Electronic Technology
FX This work was supported in part by the Royal Society International
   Exchanges Cost Share Award, UK(RP202G0230), in part by the Medical
   Research Council Confidence in Concept Award, UK (MC_PC_17171), in part
   by the Hope Foundation for Cancer Research, UK(RM60G0680) and in part by
   the British Heart Foundation Accelerator Award, UK. This work was
   supported by the study abroad program for graduate student of Guilin
   University of Electronic Technology.
CR Altaf F, 2019, IEEE ACCESS, V7, P99540, DOI 10.1109/ACCESS.2019.2929365
   Antoniou Antreas, 2017, ARXIV171104340
   Bahadure N. B., 2017, INT J BIOMED IMAGING, V2017, P12
   Breininger K, 2018, INT J COMPUT ASS RAD, V13, P1221, DOI 10.1007/s11548-018-1779-6
   Cai W, 2020, COMPUTER VISION PATT
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Finn C, 2017, PR MACH LEARN RES, V70
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Hosseini-Asl E., 2016, ARXIV160700556
   Kim E, 2016, PROC SPIE, V9789, DOI 10.1117/12.2216468
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu FY, 2017, ADV INTEL SYS RES, V153, P49
   Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045
   Medela A, 2019, I S BIOMED IMAGING, P1860, DOI 10.1109/ISBI.2019.8759182
   Mondal Arnab Kumar, 2018, ARXIV181012241
   Muus JS, 2017, INT J PEDIATR OTORHI, V100, P107, DOI 10.1016/j.ijporl.2017.06.037
   Payan A., 2015, ARXIV150202506, V2, P355
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Ramos NR, 2017, 2017 INTERNATIONAL YOUNG ENGINEERS FORUM (YEF-ECE), P42, DOI 10.1109/YEF-ECE.2017.7935638
   Ravi S., 2016, INT C LEARN REPR ICL
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ren M, 2018, RXIV180300676
   Santoro A, 2016, PR MACH LEARN RES, V48
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tang Y., 2013, DEEP LEARNING USING
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang S, 2020, SPRINGER TRACTS NATU, DOI [10.1007/978-981-13-9263-4_6, DOI 10.1007/978-981-13-9263-4_6]
   Wang SH, 2017, LECT NOTES COMPUT SC, V10262, P541, DOI 10.1007/978-3-319-59081-3_63
   Wang SH, 2017, LECT NOTES COMPUT SC, V10337, P289, DOI 10.1007/978-3-319-59740-9_28
   Wang SH, 2017, FUND INFORM, V151, P505, DOI 10.3233/FI-2017-1507
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Wang-Lin SX, 2018, MABS-AUSTIN, V10, P1131, DOI 10.1080/19420862.2018.1494478
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
NR 48
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2109
EP 2122
DI 10.1007/s11042-020-09702-y
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700001
DA 2024-07-18
ER

PT J
AU Meng, LZ
   Liu, LS
   Tian, G
   Wang, XL
AF Meng, Lingzhuang
   Liu, Lianshan
   Tian, Gang
   Wang, Xiaoli
TI An adaptive reversible watermarking in IWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive embedding; Blind extraction; Reversible watermarking; Wavelet
   transforms
ID HISTOGRAM-MODIFICATION; SCHEME; TRANSFORM; BLIND; ALGORITHM
AB An adaptive reversible watermarking in integer wavelet transform (IWT) domain was proposed in this paper. It could adaptively embed according to the size of the watermark, achieve blind extraction, and the extracted image was completely lossless. A new method of embedding watermark into diagonal components based on the relationship between adjacent elements in the approximate component was used. First, an integer wavelet transform was performed on the carrier image, and a threshold was adaptively set using the element relationship in the approximate component. Then a block with a higher smoothness in the approximate component was selected, and the watermark was embedded into its corresponding diagonal component image block. Since the threshold, the length and width of the watermark were also embedded in the image, it became possible to extract the watermark without knowing the threshold and the size of the watermark. Experimental data show that compared with different carrier pictures and similar algorithms, this method has better visual effects and less distortion, and the extracted image does not have any pixel difference from the original image. It can be used for special applications, such as medical image transmission, forensic document verification, etc.
C1 [Meng, Lingzhuang; Liu, Lianshan; Tian, Gang; Wang, Xiaoli] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Liu, LS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM lzhmeng1688@163.com; lshliu6042@163.com; gtian@sdust.edu.cn;
   wangxiaoli6093@163.com
RI wang, xiao/HZI-9156-2023; Chen, Shuo/JEO-6350-2023; Li,
   June/JEF-1173-2023; meng, lingzhuang/IQR-7631-2023
OI meng, lingzhuang/0000-0002-6549-6989; liu, lianshan/0000-0003-4400-6490
FU National Natural Science Foundation of China [61702305]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61702305.
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2004, IEEE INT C AC
   Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   Carpentieri B, 2019, FUTURE GENER COMP SY, V90, P222, DOI 10.1016/j.future.2018.07.051
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Chen XD, 2010, INT CONF ACOUST SPEE, P2382, DOI 10.1109/ICASSP.2010.5496175
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Ghardallou A, 2016, INT C SCI TECHN AUT
   Girdhar A, 2019, J AMB INTEL HUM COMP, V10, P4947, DOI 10.1007/s12652-019-01179-4
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Haghighi BB, 2020, COGN COMPUT, V12, P863, DOI 10.1007/s12559-019-09700-9
   Hsu LY, 2019, IEEE ACCESS, V7, P107438, DOI 10.1109/ACCESS.2019.2932077
   Hu W-W, 2019, IEEE ACCESS PP, V99, P1
   Jialal I, 2014, J CLIN ENDOCR METAB, V99, P39, DOI 10.1210/jc.2013-3092
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kuslu M, 2016, IMAGING SCI J, V64, P471, DOI 10.1080/13682199.2016.1240945
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Li X, 2014, INT COMP C WAV ACT M
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu XY, 2019, MULTIMED TOOLS APPL, V78, P6355, DOI 10.1007/s11042-018-6361-2
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Luo GF, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2075-7
   Meerwald P, 2001, PHOTONICS W 2001 ELE, V4314
   Mehallegue N, 2020, MULTIMED TOOLS APPL, V79, P2031, DOI 10.1007/s11042-019-08271-z
   Nagarju P, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P62, DOI 10.1109/ISSP.2013.6526875
   Naik K, 2018, MULTIMED TOOLS APPL, V77, P13721, DOI 10.1007/s11042-017-4986-1
   Qasim AF, 2019, MULTIMED TOOLS APPL, V78, P16433, DOI 10.1007/s11042-018-7029-7
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thanki RM, 2020, J AMB INTEL HUM COMP, V11, P1835, DOI 10.1007/s12652-019-01295-1
   Uyyala R, 2019, IET IMAGE PROCESS, V13, P1986, DOI 10.1049/iet-ipr.2019.0038
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wen J, 2012, INT C INF SCI TECHN
   Weng CY, 2020, PEER PEER NETW APPL, V13, P514, DOI 10.1007/s12083-018-0709-2
   Yousefi S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2130
   Zhang T, 2019, J REAL-TIME IMAGE PR, V16, P661, DOI 10.1007/s11554-018-0845-1
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
NR 46
TC 22
Z9 22
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 711
EP 735
DI 10.1007/s11042-020-09686-9
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200004
DA 2024-07-18
ER

PT J
AU Alshehri, SA
AF Alshehri, Saleh Ali
TI Video compression using frame redundancy elimination and discrete cosine
   transform coefficient reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Image processing; Discrete cosine transform; Frame
   redundancy
ID IMAGE COMPRESSION
AB The need of human beings for better social media applications has increased tremendously. This increase has necessitated the need for a digital system with a larger storage capacity and more processing power. However, an increase in multimedia content size reduces the overall processing performance. This occurs because the process of storing and retrieving large files affects the execution time. Therefore, it is extremely important to reduce the multimedia content size. This reduction can be achieved by image and video compression. There are two types of image or video compression: lossy and lossless. In the latter compression, the decompressed image is an exact copy of the original image, while in the former compression, the original and the decompressed image differ from each other. Lossless compression is needed when every pixel matters. This can be found in autoimage processing applications. On the other hand, lossy compression is used in applications that are based on human visual system perception. In these applications, not every single pixel is important; rather, the overall image quality is important. Many video compression algorithms have been proposed. However, the balance between compression rate and video quality still needs further investigation. The algorithm developed in this research focuses on this balance. The proposed algorithm exhibits diversity of compression stages used for each type of information such as elimination of redundant and semi redundant frames, elimination by manipulating consecutive XORed frames, reducing the discrete cosine transform coefficients based on the wanted accuracy and compression ratio. Neural network is used to further reduce the frame size. The proposed method is a lossy compression type, but it can reach the near-lossless type in terms of image quality and compression ratio with comparable execution time.
C1 [Alshehri, Saleh Ali] Jubail Univ Coll, Royal Commiss Jubail, Dept Comp Sci & Engn, Industrial City, Jubail, Saudi Arabia.
C3 Jubail Industrial College
RP Alshehri, SA (corresponding author), Jubail Univ Coll, Royal Commiss Jubail, Dept Comp Sci & Engn, Industrial City, Jubail, Saudi Arabia.
EM shehri@ucj.edu.sa
RI Alshehri, Saleh/ITW-1450-2023
OI Alshehri, Saleh/0000-0002-6835-4820
CR Ahmed Nasir, 1991, Digit Signal Process, V1, P4, DOI [DOI 10.1016/1051-2004(91)90086-Z, 10.1016/1051-2004(91)90086-Z]
   Al-Ani M. S., 2011, International Journal on Soft Computing (IJSC), V2, P67, DOI [10.5121/ijsc.2011.2407, DOI 10.5121/IJSC.2011.2407]
   Alshehri SA, 2016, IET IMAGE PROCESS, V10, P222, DOI 10.1049/iet-ipr.2014.1039
   Bampis C, 2018, CORR VOL ABS 1808 03
   Chriqui M, 2003, P SOC PHOTO-OPT INS, V4796, P218, DOI 10.1117/12.452142
   Grgic S., 2004, Journal of Electrical Engineering, V55, P3
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Kavitha S, 2015, MULTIMED TOOLS APPL, V74, P7943, DOI 10.1007/s11042-014-2032-0
   Loukil H., 2012, INT J COMP APPL, V60, P32, DOI DOI 10.5120/9697-4138
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mrak M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P233
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Pathak K, 2019, J ADV RES DYNAMICAL, V11, P14
   Pullareddi M., 2017, ASIAN J PHARM CLIN R, V10, P373, DOI [10.22159/ajpcr.2017.v10-1.19760, DOI 10.22159/AJPCR.2017.V10-1.19760]
   Raz S, 2014, INT J SCI ENG APPL, V3, P143
   Rehman M., 2014, Res. J. Appl. Sci. Eng. Technol, V7, P656, DOI DOI 10.19026/RJASET.7.303
   Sandy T, 2019, NAT J PARALLEL SOFT, V1, P22
   Setyaningsih E., 2017, International Journal of Electrical and Computer Engineering, V7, P2206, DOI DOI 10.11591/IJECE.V7I4.PP2206-2214
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tawalbeh M, 2016, PROCEDIA COMPUT SCI, V94, P183, DOI 10.1016/j.procs.2016.08.028
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 21
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 367
EP 381
DI 10.1007/s11042-020-09038-7
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565480700005
DA 2024-07-18
ER

PT J
AU Zhao, ZM
   Xiong, SH
   Sun, WH
   He, XH
   Zhang, FR
AF Zhao, Zeming
   Xiong, Shuhua
   Sun, Weiheng
   He, Xiaohai
   Zhang, Feiran
TI An improved R-λ rate control model based on joint spatial-temporal
   domain information and HVS characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; Joint spatial-temporal domain information; Human visual
   system; High efficiency video coding; Adaptive coefficient correction;
   BFGS
ID OPTIMAL BIT ALLOCATION; FRAME RATE CONTROL
AB With the popularization of smart terminals and multimedia technologies, the video coding standard -H.264/Advanced Video Coding(AVC) andH.265/High Efficiency Video Coding(HEVC) have been unable to meet the needs of various high-definition videos, so the next generation standard -H.266/ Versatile Video Coding(VVC) is under study. In the actual transmission of a video communication channel, rate control plays an important role. However, HEVC rate control based on R-lambda model does not adequately take into account the characteristics of thehuman visual system(HVS). Also, the convergence speed ofLeast Mean Square(LMS) in HEVC is too slow. In this paper,an improved R-lambda(Lambda)rate controlmodel based on joint spatial-temporal domain information and HVS characteristics(IRLRC) is established. In this model, the joint spatial-temporal domain information based on gradient information is used to guide bit allocation for frame and CTU level, where the temporal coefficient is corrected adaptively. What's more, theBroyden Fletcher Goldfarb Shanno(BFGS) algorithm is introduced, which speeds up the convergence of the proposed model. The experimental results have clearly shown that the proposed IRLRC can achieve better coding performance than HEVC, VVC and other models. In particular, the video sequence based on the proposed IRLRC can meet the needs of HVS and achieve higher optimization for subjective quality.
C1 [Zhao, Zeming; Xiong, Shuhua; Sun, Weiheng; He, Xiaohai; Zhang, Feiran] Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Peoples R China.
   [He, Xiaohai] Minist Educ, Key Lab Wireless Power Transmiss, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Peoples R China.; He, XH (corresponding author), Minist Educ, Key Lab Wireless Power Transmiss, Chengdu 610065, Peoples R China.
EM hxh@scu.edu.cn
FU National Natural Science Foundation of China [61871279]; Industrial
   Cluster Collaborative Innovation Project of Chengdu
   [2016-XT00-00015-GX]; Sichuan Science and Technology Program
   [2018HH0143]; Sichuan Education Department Program [18ZB0355]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61871279, the Industrial Cluster Collaborative
   Innovation Project of Chengdu (No. 2016-XT00-00015-GX), the Sichuan
   Science and Technology Program (No. 2018HH0143) and the Sichuan
   Education Department Program (No. 18ZB0355).
CR [Anonymous], 2013, PROC VIS COMMUN IMAG
   Choi H, 2012, JCTVC OF ITU T SG16
   Feng ZQ, 2018, J PHYS CONF SER, V960, DOI 10.1088/1742-6596/960/1/012041
   Gao J, 2005, J ZHENGZHOU U LIGHT, V20, P100
   Güler O, 2009, OPTIM METHOD SOFTW, V24, P45, DOI 10.1080/10556780802367205
   Guo HW, 2019, IEEE T BROADCAST, V65, P270, DOI 10.1109/TBC.2018.2847445
   Guo YY, 2015, IEEE INT SYMP CIRC S, P1118, DOI 10.1109/ISCAS.2015.7168834
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Li L, 2018, IEEE T CIRC SYST VID, V28, P130, DOI 10.1109/TCSVT.2016.2598672
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li YY, 2016, INT J POLYM SCI, V2016, DOI 10.1155/2016/8769360
   Li Y, 2014, SIGNAL PROCESS-IMAGE, V29, P1046, DOI 10.1016/j.image.2014.09.004
   Lin HW, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043008
   Liu ZY, 2019, IEEE T IMAGE PROCESS, V28, P2558, DOI 10.1109/TIP.2018.2887200
   Nguyen T, 2011, IEEE IMAGE PROC, P753, DOI 10.1109/ICIP.2011.6116664
   Wang H, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351023
   Wang MH, 2016, IEEE T IMAGE PROCESS, V25, P2943, DOI 10.1109/TIP.2016.2552646
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang AS, 2016, INT CONF IMAG PROC
   Ye YY, 2018, MULTIMED TOOLS APPL, V77, P14557, DOI 10.1007/s11042-017-5047-5
   Zhou ML, 2017, J VIS COMMUN IMAGE R, V42, P46, DOI 10.1016/j.jvcir.2016.11.013
NR 22
TC 6
Z9 6
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 345
EP 366
DI 10.1007/s11042-020-09721-9
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565480700004
DA 2024-07-18
ER

PT J
AU Yan, ZP
   Zhang, JZ
   Tang, JL
AF Yan, Zheping
   Zhang, Jinzhong
   Tang, Jialing
TI Modified whale optimization algorithm for underwater image matching in a
   UUV vision system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Whale optimization algorithm (WOA); Levy flight strategy; Lateral
   inhibition (LI); Underwater image matching
ID LATERAL INHIBITION; ROBUST
AB In this paper, a hybrid whale optimization algorithm based on the Levy flight strategy (LWOA) and lateral inhibition (LI) is proposed to solve the underwater image matching problem in an unmanned underwater vehicle (UUV) vision system. The proposed image matching technique is called the LI-LWOA. The whale optimization algorithm (WOA) simulates encircling prey, bubble-net attacking and searching for prey to obtain the global optimal solution. The algorithm not only can balance the exploration and exploitation but also has high calculation accuracy. The Levy flight strategy can expand the search space to avoid premature convergence and enhance the global search ability. In addition, the lateral inhibition mechanism is applied to conduct image preprocessing, which enhances the intensity gradient and image characters, and improves the image matching accuracy. The LI-LWOA achieves the complementary advantages of the LWOA and lateral inhibition to improve the image matching accuracy and enhance the robustness. To verify the overall optimization performance of the LI-LWOA, a series of underwater image matching experiments that seek to maximize the fitness value are performed, and the matching results are compared with those of other algorithms. The experimental results show that the LI-LWOA has better fitness, higher matching accuracy and stronger robustness. In addition, the proposed algorithm is a more effective and feasible method for solving the underwater image matching problem.
C1 [Yan, Zheping; Zhang, Jinzhong; Tang, Jialing] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Zhang, JZ (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
EM zhangjinzhongz@126.com
RI Zhang, Jing/ISA-6627-2023; zhang, jin/GXV-9154-2022; zhang,
   jin/IXD-9872-2023
OI Zhang, Jing/0009-0003-5039-5688; 
FU National Nature Science Foundation of China [51679057]; Province Science
   Fund for Distinguished Young Scholars [J2016JQ0052]
FX This work was partially funded by the National Nature Science Foundation
   of China under Grant No. 51679057, and partly supported by the Province
   Science Fund for Distinguished Young Scholars under Grant No.
   J2016JQ0052.
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Barthelemy P, 2008, NATURE, V453, P495, DOI 10.1038/nature06948
   Burgmann Tatjana, 2019, ISPRS Journal of Photogrammetry and Remote Sensing, V158, P241, DOI 10.1016/j.isprsjprs.2019.09.010
   Chen H, 2019, PATTERN RECOGN LETT, V127, P3, DOI 10.1016/j.patrec.2018.10.036
   Cuevas E, 2013, EXPERT SYST APPL, V40, P6359, DOI 10.1016/j.eswa.2013.05.055
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dou JF, 2018, OPTIK, V171, P850, DOI 10.1016/j.ijleo.2018.06.094
   Duan HB, 2010, PATTERN RECOGN LETT, V31, P1868, DOI 10.1016/j.patrec.2009.12.005
   Huang LZ, 2014, OPTIK, V125, P414, DOI 10.1016/j.ijleo.2013.06.085
   Jung HG, 2019, PATTERN RECOGN LETT, V125, P584, DOI 10.1016/j.patrec.2019.06.019
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li B, 2016, OPTIK, V127, P5430, DOI 10.1016/j.ijleo.2016.02.056
   Li Y, 2015, OCEAN ENG, V110, P163, DOI 10.1016/j.oceaneng.2015.10.015
   Liu F, 2012, OPTIK, V123, P1955, DOI 10.1016/j.ijleo.2011.09.052
   Luo QF, 2019, MULTIMED TOOLS APPL, V78, P34277, DOI 10.1007/s11042-019-08081-3
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Sun HT, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107391
   Wang L, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P1
   Wang XH, 2013, OPTIK, V124, P5447, DOI 10.1016/j.ijleo.2013.03.124
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wu Q, 2019, INFRARED PHYS TECHN, V101, P88, DOI 10.1016/j.infrared.2019.05.020
   Xu J, 2019, OPTIK, V181, P588, DOI 10.1016/j.ijleo.2018.12.098
   Xu XG, 2019, MEASUREMENT, V146, P437, DOI 10.1016/j.measurement.2019.03.041
   Yan ZP, 2012, ENRGY PROCED, V17, P991, DOI 10.1016/j.egypro.2012.02.198
   Yan ZP, 2019, IEEE ACCESS, V7, P72567, DOI 10.1109/ACCESS.2019.2917791
   Yang WL, 2019, IFAC PAPERSONLINE, V52, P156, DOI 10.1016/j.ifacol.2019.12.300
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Zhang C, 2015, OPTIK, V126, P769, DOI 10.1016/j.ijleo.2015.02.005
   Zhang S, 2017, OPTIK, V130, P1229, DOI 10.1016/j.ijleo.2016.11.173
NR 32
TC 8
Z9 9
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 187
EP 213
DI 10.1007/s11042-020-09736-2
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400004
DA 2024-07-18
ER

PT J
AU Choi, JH
   Lee, KI
   Song, BC
AF Choi, Jun Ho
   Lee, Kang Il
   Song, Byung Cheol
TI Eye pupil localization algorithm using convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye pupil localization; Fully convolutional networks; Eyeglasses removal
AB Eye pupil localization is one of the indispensable technologies in various computer vision applications such as virtual reality and augmented reality. In general, the algorithm consists of finding the approximate eye region and finding the pupil position by extracting the semantic feature from each eye region. However, the performance of the eye pupil location is affected not only by illumination and image resolution but also by glasses wear. Therefore, this paper proposes an eye pupil localization algorithm which is robust against the above disturbance conditions and provides high accuracy. First, a face is detected from an input image and it is determined whether to wear glasses using the detected face. If glasses are present, the glasses are removed to find the correct eye region. Then, facial landmarks are extracted, and eye regions are detected based on facial landmarks. Next, the pupil region is segmented using fully convolutional networks. Finally, the position of the segmented pupil is calculated. Experimental results show that the proposed algorithm outperforms the state-of-the-art algorithms for public databases such as BioID and GI4E by up to 3.44% 0.5%, respectively.
C1 [Choi, Jun Ho; Lee, Kang Il; Song, Byung Cheol] Inha Univ, Dept Elect Engn, Inha Ro 100, Incheon 22212, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, Inha Ro 100, Incheon 22212, South Korea.
EM bcsong@inha.ac.kr
OI Song, Byung Cheol/0000-0001-8742-3433
CR Abbasi M, 2020, J GRID COMPUT, V18, P305, DOI 10.1007/s10723-019-09502-1
   [Anonymous], 2018, BRIT MACH VIS C
   Araujo GM, 2014, IEEE IMAGE PROC, P1366, DOI 10.1109/ICIP.2014.7025273
   BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gou C, 2017, PATTERN RECOGN, V67, P23, DOI 10.1016/j.patcog.2017.01.023
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Levinshtein A, 2018, IMAGE VISION COMPUT, V71, P17, DOI 10.1016/j.imavis.2018.01.003
   Li B, 2018, APPL COMPUT INTELL S, V2018, DOI 10.1155/2018/1439312
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seung-Jin Baek, 2013, IEEE Transactions on Consumer Electronics, V59, P125, DOI 10.1109/TCE.2013.6531125
   Sun YH, 2017, IEEE ICC
   Swirski L., 2012, P S EYE TRACK RES AP, P173
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Tonsen M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P139, DOI 10.1145/2857491.2857520
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Villanueva A, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501647
   Xia YF, 2019, IEEE-CAA J AUTOMATIC, V6, P1127, DOI 10.1109/JAS.2019.1911684
NR 25
TC 16
Z9 16
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32563
EP 32574
DI 10.1007/s11042-020-09711-x
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606600001
DA 2024-07-18
ER

PT J
AU Tekin, R
   Ertugrul, ÖF
   Kaya, Y
AF Tekin, Ramazan
   Ertugrul, Omer Faruk
   Kaya, Yilmaz
TI New local binary pattern approaches based on color channels in texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary patterns; Texture classification; Feature extraction; Image
   classification
ID GRAY-SCALE; RECOGNITION; COOCCURRENCE; EXTRACTION; TRANSFORM; FEATURES;
   LBP
AB In this paper, four novel, simple and robust approaches, which are left to right local binary patterns (LBPLL2R), top to down local binary patterns (LBPT2D), cube surface local binary pattern (LBPSurfaces), and cube diagonal local binary pattern (LBPDiagonal), were proposed in order to exact texture features in color images. These approaches were based on the local binary pattern (LBP), which is an effective statistical texture descriptor and can be employed in gray images. Proposed approaches were evaluated and validated in four datasets, which are Outex, KTH_TIPS, KTH_TIPS2, and USPtex datasets. The images in these datasets are in RGB, HSV, YIQ, and YCbCr color formats. Achieved results by these approaches were compared with the obtained results by the classical LBP and literature findings. As a result, the proposed approaches performed better than the traditional LBP method and they found effective in the classification of color texture images, especially in images, which are in RGB and HSV formats. Furthermore, noise robustness and time complexity of the proposed approaches were validated.
C1 [Tekin, Ramazan] Batman Univ, Dept Comp Engn, TR-72060 Batman, Turkey.
   [Ertugrul, Omer Faruk] Batman Univ, Dept Elect & Elect Engn, TR-72060 Batman, Turkey.
   [Kaya, Yilmaz] Siirt Univ, Dept Comp Engn, TR-56100 Siirt, Turkey.
C3 Batman University; Batman University; Siirt University
RP Tekin, R (corresponding author), Batman Univ, Dept Comp Engn, TR-72060 Batman, Turkey.
EM ramazan.tekin@batman.edu.tr
RI ERTUGRUL, Ömer Faruk/F-7057-2015; Tekin, Ramazan/I-1519-2014; KAYA,
   Yılmaz/C-3822-2017
OI ERTUGRUL, Ömer Faruk/0000-0003-0710-0867; Tekin,
   Ramazan/0000-0003-4325-6922; 
CR Ahonen Timo., 2007, Proceedings of the Finnish Signal Processing Symposium, FINSIG, P1
   Alam FI, 2011, EUR J SCI RES, V50, P543
   Andrearczyk V, 2018, PATTERN RECOGN, V76, P36, DOI 10.1016/j.patcog.2017.10.030
   Andrearczyk V, 2017, ELS MIC SOC BOOK SER, P95, DOI 10.1016/B978-0-12-812133-7.00004-1
   Backes AR, 2017, NEUROCOMPUTING, V266, P1, DOI 10.1016/j.neucom.2017.05.020
   Backes AR, 2012, PATTERN RECOGN, V45, P1984, DOI 10.1016/j.patcog.2011.11.009
   Berraho S, 2017, MULTIMED TOOLS APPL, V76, P18425, DOI 10.1007/s11042-016-4174-8
   Burçin K, 2011, EXPERT SYST APPL, V38, P8690, DOI 10.1016/j.eswa.2011.01.076
   Cantero SVAB, 2018, IEEE T CYBERNETICS, V50, P777
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Cernadas E, 2005, COMPUT VIS IMAGE UND, V98, P345, DOI 10.1016/j.cviu.2004.08.004
   Cernadas E, 2017, PATTERN RECOGN, V61, P120, DOI 10.1016/j.patcog.2016.07.002
   Chakraborti T, 2014, ENG APPL ARTIF INTEL, V33, P80, DOI 10.1016/j.engappai.2014.04.006
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   de MS, 2014, IEEE T IMAGE PROCESS, V23, P3751
   Depeursinge A, 2017, ELS MIC SOC BOOK SER, P1
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   El Merabet Y, 2019, ENG APPL ARTIF INTEL, V78, P158, DOI 10.1016/j.engappai.2018.11.011
   El Merabet Y, 2018, PATTERN RECOGN, V76, P303, DOI 10.1016/j.patcog.2017.11.005
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   García MA, 2007, IMAGE VISION COMPUT, V25, P1091, DOI 10.1016/j.imavis.2006.05.023
   García-Olalla O, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051048
   González E, 2016, INFORM SCIENCES, V361, P1, DOI 10.1016/j.ins.2016.04.044
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hadizadeh H, 2015, PATTERN RECOGN LETT, V65, P163, DOI 10.1016/j.patrec.2015.07.038
   Hafiane A, 2015, PATTERN RECOGN, V48, P2609, DOI 10.1016/j.patcog.2015.02.007
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Kandaswamy U, 2011, IEEE T IMAGE PROCESS, V20, P2260, DOI 10.1109/TIP.2010.2101612
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Kwak JT, 2015, EXPERT SYST APPL, V42, P4529, DOI 10.1016/j.eswa.2015.01.055
   Lan RS, 2020, NEURAL COMPUT APPL, V32, P4317, DOI 10.1007/s00521-018-03968-y
   Lan RS, 2014, IEEE INT CON MULTI
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Lian GY, 2015, J VIS COMMUN IMAGE R, V31, P1, DOI 10.1016/j.jvcir.2015.05.003
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu F, 2013, NEUROCOMPUTING, V120, P325, DOI 10.1016/j.neucom.2012.06.061
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lucieer A, 2005, INT J REMOTE SENS, V26, P2917, DOI 10.1080/01431160500057723
   Maani R, 2013, PATTERN RECOGN, V46, P2103, DOI 10.1016/j.patcog.2013.01.014
   Manninen S, 1998, RESPONSES OF PLANT METABOLISM TO AIR POLLUTION AND GLOBAL CHANGE, P371
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Nanni L, 2008, PATTERN RECOGN, V41, P3461, DOI 10.1016/j.patcog.2008.05.013
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090
   Naveed H, 2019, INT J MACH LEARN CYB, V10, P2329, DOI 10.1007/s13042-018-0870-1
   Nosaka R, 2014, PATTERN RECOGN, V47, P2428, DOI 10.1016/j.patcog.2013.09.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pan ZB, 2017, EXPERT SYST APPL, V88, P238, DOI 10.1016/j.eswa.2017.07.007
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Pietikäinen M, 2004, PATTERN RECOGN, V37, P313, DOI 10.1016/S0031-3203(03)00231-0
   Qi XB, 2015, IMAGE VISION COMPUT, V43, P16, DOI 10.1016/j.imavis.2015.07.005
   Raja GM, 2019, MULTIMED TOOLS APPL, P1
   Ren JF, 2015, PATTERN RECOGN, V48, P3180, DOI 10.1016/j.patcog.2015.02.001
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P21481, DOI 10.1007/s11042-017-5440-0
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shan SG, 2006, INT C PATT RECOG, P606
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Silva PM, 2019, PHYSICA A, V528, DOI 10.1016/j.physa.2019.121469
   Smeraldi F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020499
   [宋克臣 Song Kechen], 2013, [自动化学报, Acta Automatica Sinica], V39, P730
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   Sukhia KN, 2019, MULTIDIM SYST SIGN P, V30, P2167, DOI 10.1007/s11045-019-00643-w
   Tabatabaei NM, 2019, POWER SYST, P1, DOI 10.1007/978-3-319-94442-5
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Nguyen TP, 2016, NEUROCOMPUTING, V173, P1565, DOI 10.1016/j.neucom.2015.09.029
   Tong M, 2017, MULTIMED TOOLS APPL, V76, P3011, DOI 10.1007/s11042-016-3279-4
   Uddin MDA, 2017, IEEE ACCESS, V5, P21157, DOI 10.1109/ACCESS.2017.2759225
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Vishwakarma DK, 2015, EXPERT SYST APPL, V42, P6957, DOI 10.1016/j.eswa.2015.04.039
   Wang K, 2017, PATTERN RECOGN, V67, P213, DOI 10.1016/j.patcog.2017.01.034
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J., 2012, J BAMBOO RES, V31, P42
   Zhang W, 2018, IEEE T MULTIMEDIA, V20, P880, DOI 10.1109/TMM.2017.2760102
   Zhang Z, 2017, PATTERN RECOGN, V67, P263, DOI 10.1016/j.patcog.2017.02.021
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao Y, 2016, NEUROCOMPUTING, V207, P354, DOI 10.1016/j.neucom.2016.05.016
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zheng CX, 2006, TRENDS FOOD SCI TECH, V17, P113, DOI 10.1016/j.tifs.2005.11.006
   Zhou H, 2008, INFORM SCIENCES, V178, P4314, DOI 10.1016/j.ins.2008.07.015
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 96
TC 7
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32541
EP 32561
DI 10.1007/s11042-020-09698-5
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606600004
DA 2024-07-18
ER

PT J
AU Namitha, K
   Narayanan, A
AF Namitha, K.
   Narayanan, Athi
TI Preserving interactions among moving objects in surveillance video
   synopsis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video synopsis; Surveillance; Interaction; Tube grouping; Tube
   rearrangement
ID OPTIMIZATION
AB Video synopsis is an effective solution for fast browsing and retrieval of long surveillance videos. It aims to shorten long video sequences into its equivalent compact video representation by rearranging the video events in the temporal domain and/or spatial domain. Conventional video synopsis methods focus on reducing the collisions between tubes and maintaining their chronological order, which may alter the original interactions between tubes due to improper tube rearrangement. In this paper, we present an approach to preserve the relationships among tubes (tracks of moving objects) of the original video in the synopsis video. First, a recursive tube-grouping algorithm is proposed to determine the behavior interactions among tubes in a video and group the related tubes together to form tube sets. Second, to preserve the discovered relationships, a spatio-temporal cube voting algorithm is proposed. This cube voting method optimally rearranges the tube sets in the synopsis video, minimizing false collisions between tubes. Third, a method to estimate the duration of the synopsis video is proposed based on an entropy measure of tube collisions. The extensive experimental results demonstrate that the proposed video synopsis framework condenses videos by preserving the original tube interactions and reducing false tube collisions.
C1 [Namitha, K.; Narayanan, Athi] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amritapuri, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri
RP Namitha, K (corresponding author), Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amritapuri, India.
EM namitha.amrita@gmail.com; mail2athi@gmail.com
RI K, Namitha/AGZ-5273-2022
OI K, Dr. Namitha/0000-0003-3801-3117
CR Aarthi R, 2016, PROCEDIA COMPUT SCI, V78, P160, DOI 10.1016/j.procs.2016.02.026
   Ahmed SA, 2019, IEEE T INTELLIGENT T
   [Anonymous], 2006, Institution of Engineering and Technology Conference on Crime and Security, P445
   [Anonymous], 2012, 3 INT C COMP COMM NE
   [Anonymous], 2003, EXPLORING ARTIFICIAL
   [Anonymous], P 2006 IEEE COMP SOC
   Baskurt KB, 2019, COMPUT VIS IMAGE UND, V181, P26, DOI 10.1016/j.cviu.2019.02.004
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Blunsden S., 2010, ANN BMVA, V4, P4, DOI DOI 10.5465/19416521003654160
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Feng SK, 2012, PROC CVPR IEEE, P2082, DOI 10.1109/CVPR.2012.6247913
   Fisher R., 2003, Ec funded caviar project IST 2001 37540
   Fu W, 2012, IEEE IMAGE PROC, P29, DOI 10.1109/ICIP.2012.6466787
   Ghatak S, 2019, MULTIMED TOOLS APPL, P1
   Ghatak S, 2020, IEEE T CONSUM ELECTR, V66, P144, DOI 10.1109/TCE.2020.2981829
   He Y, 2017, NEUROCOMPUTING, V225, P64, DOI 10.1016/j.neucom.2016.11.011
   He Y, 2017, IEEE SIGNAL PROC LET, V24, P22, DOI 10.1109/LSP.2016.2633374
   Höferlin B, 2011, MULTIMED TOOLS APPL, V55, P127, DOI 10.1007/s11042-010-0606-z
   Hoshen Y, 2015, IEEE IMAGE PROC, P212, DOI 10.1109/ICIP.2015.7350790
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1417, DOI 10.1109/TCSVT.2014.2308603
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Kerner S, 2015, COMMENSALITY: FROM EVERYDAY FOOD TO FEAST, P1
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P65
   Li XL, 2018, IEEE T IMAGE PROCESS, V27, P3798, DOI 10.1109/TIP.2018.2823420
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705
   Li Z, 2009, IEEE T IMAGE PROCESS, V18, P2572, DOI 10.1109/TIP.2009.2026677
   Lu ML, 2013, INT CONF ACOUST SPEE, P2292, DOI 10.1109/ICASSP.2013.6638063
   Ma Y.-F., 2002, P IEEE INT C IM PROC, V1, P1
   Mahapatra A, 2016, SIGNAL PROCESS-IMAGE, V42, P31, DOI 10.1016/j.image.2016.01.002
   Cirne MVM, 2018, MULTIMED TOOLS APPL, V77, P857, DOI 10.1007/s11042-016-4300-7
   Narayanan A, 2018, IEEE INT C CIRC SYST
   Nie YW, 2020, IEEE T IMAGE PROCESS, V29, P1465, DOI 10.1109/TIP.2019.2942543
   Nie YW, 2013, IEEE T VIS COMPUT GR, V19, P1664, DOI 10.1109/TVCG.2012.176
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pritch Y, 2007, IEEE I CONF COMP VIS, P833
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Pritch Y, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P195, DOI 10.1109/AVSS.2009.53
   Ra M, 2018, IEEE SIGNAL PROC LET, V25, P1186, DOI 10.1109/LSP.2018.2848842
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ruan T, 2019, IEEE T IMAGE PROCESS
   Shu-Te Su, 2008, 2008 Digital Image Computing: Techniques and Applications, P24, DOI 10.1109/DICTA.2008.15
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Tang L, 2013, I CONF VLSI DESIGN, P1, DOI 10.1109/VLSID.2013.153
   Wang WC, 2017, 15 IAPR INT C MACH V
   Xu L, 2015, J AMB INTEL HUM COMP, V6, P623, DOI 10.1007/s12652-015-0278-7
   Zhao K, 2019, J ANIM PLANT SCI, V29, P971
   Zhu J, 2014, IEEE T CIRCUITS SYS, V25, P1113
   Zhu JQ, 2016, IEEE T CIRC SYST VID, V26, P1058, DOI 10.1109/TCSVT.2015.2430692
   Zhu XB, 2014, MACH VISION APPL, V25, P145, DOI 10.1007/s00138-013-0519-8
NR 52
TC 9
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32331
EP 32360
DI 10.1007/s11042-020-09493-2
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000002
DA 2024-07-18
ER

PT J
AU Jayanthi, N
   Rajput, V
   Indu, S
AF Jayanthi, N.
   Rajput, Vishal
   Indu, S.
TI Underwater haze removal using contrast boosted grayscale image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Contrast boosting; Histogram equalization; BRISQUE; UIQM;
   UCIQE
ID HISTOGRAM EQUALIZATION; QUALITY ASSESSMENT; ENHANCEMENT; COLOR;
   CONVERSION; ACCURATE; MODEL
AB Underwater images generally experience the ill effects of color shift, haze and contrast deterioration because of scattering and absorption of light in water. There are several techniques that can increase the contrast of an image but most of the techniques lose the originality of the image while increasing the contrast, making these techniques highly inefficient and undesirable. The main goal of the proposed work is to increase the contrast of an image along with the haze removal while keeping the original color intact. A two-step decolorization process is employed for the contrast boosting of the grayscale image, which is later used for reproducing the enhanced color image. Mean and standard deviation-based contrast mapping is used to increase the global contrast and Laplacian pyramids are used for enhancing the local contrast adaptively by identifying the edges in an image. Finally, by combining both the local and global approach a contrast boosted image is produced and the color image is retrieved by changing the L component in CIE Lab color space.
C1 [Jayanthi, N.; Indu, S.] Delhi Technol Univ, Delhi, India.
   [Rajput, Vishal] PDPM Indian Inst Informat & Technol Design & Mfg, Jabalpur, India.
C3 Delhi Technological University; Indian Institute of Information
   Technology Design & Manufacturing, Jabalpur
RP Jayanthi, N (corresponding author), Delhi Technol Univ, Delhi, India.
EM njayanthi@dce.ac.in; vishalrajput@iiitdmj.ac.in; s.indu@dce.ac.in
RI N, J/JOZ-6459-2023; Sreedevi, Indu/HCH-5463-2022; Sreedevi,
   Indu/AFU-2449-2022; , N. JAYANTHI/C-8722-2019
OI Sreedevi, Indu/0000-0002-4975-5047; Rajput, Vishal/0000-0001-7152-212X;
   , N. JAYANTHI/0000-0001-6734-0534
CR Akkaynak D., 2019, P IEEE C COMP VIS PA
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Cheng CY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P110, DOI 10.1109/ICSIPA.2015.7412173
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Chow LS, 2017, MAGN RESON IMAGING, V43, P74, DOI 10.1016/j.mri.2017.07.016
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Emberton S, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010001
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Kandhway P, 2019, MULTIDIM SYST SIGN P, V30, P1859, DOI 10.1007/s11045-019-00633-y
   Kansal S, 2019, MULTIMED TOOLS APPL, V78, P25241, DOI 10.1007/s11042-019-07744-5
   Keith J, 1997, YCBCR RGB CONSIDERAT
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   LI YC, 2016, INT J LIGHT ELECT OP, V127, P1326, DOI DOI 10.1016/J.IJLEO.2015.07.177
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Luczynski T, 2017, OCEAN ENG, V133, P9, DOI 10.1016/j.oceaneng.2017.01.029
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Nafchi HZ, 2017, IEEE SIGNAL PROC LET, V24, P1651, DOI 10.1109/LSP.2017.2755077
   Palanisamy G, 2019, SIGNAL IMAGE VIDEO P, V13, P719, DOI 10.1007/s11760-018-1401-y
   Paris S, 2015, COMMUN ACM, V58, P81, DOI 10.1145/2723694
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Sheinin M, 2016, P IEEE C COMP VIS PA
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Tian QC, 2018, SIGNAL PROCESS, V153, P210, DOI 10.1016/j.sigpro.2018.07.022
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Yamashita A, 2007, IEEE INT CONF ROBOT, P4570, DOI 10.1109/ROBOT.2007.364183
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 43
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31007
EP 31026
DI 10.1007/s11042-020-09429-w
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900001
DA 2024-07-18
ER

PT J
AU Xiang, HY
   Liu, LF
AF Xiang, Hongyue
   Liu, Lingfeng
TI An improved digital logistic map and its application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Digital chaotic map; Image encryption
ID CHAOTIC SYSTEM; SCHEME
AB Chaos maps are widely used in image encryption systems due to their intrinsic advantages such as extreme sensitivity to initial values., ergodicity and pseudo-randomness. 1D Logistic map has attracted the attention of researchers due to its simple structure and easy implementation, but also because of this, the map is easy to be affected by finite precision, resulting in dynamic degradation, at low precision, the sequence generated by this map not only enters a period quickly, but also has a shorter period. Thus, taking 1D Logistic map as an example, we proposed a method to suppress the dynamic degradation of digital chaotic systems by using parameter variables and state variables to influence each other, and using sine function as feedback function to destroy the state space. The simulation results show that the improved logistic mapping with the proposed method has better randomness and higher complexity than the original logistic mapping. To prove the practicability and applicability of the improved chaotic map, we design a new image encryption algorithm, which is suitable for both color image and grayscale image. The numerical results indicate that the proposed algorithm has high encryption efficiency, good resistance to various attacks and certain competitiveness with other encryption algorithms.
C1 [Xiang, Hongyue; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330029, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330029, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China [61862042]
FX This work is supported by the National Natural Science Foundation of
   China (61862042).
CR Alawida M, 2019, IEEE ACCESS, V7, P150609, DOI 10.1109/ACCESS.2019.2947561
   [Anonymous], 2011, CYPER J JSAT
   [Anonymous], 2020, SENSORS BASEL, DOI DOI 10.3390/S20010083
   [Anonymous], 2018, OPT LASERS ENG
   Arpaci B, 2020, J ELECTR ENG TECHNOL, V15, P1413, DOI 10.1007/s42835-020-00393-x
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Ben SN, 2018, INT J MOD PHYS C, V29, P7
   Benítez R, 2010, COMPUT MATH APPL, V60, P634, DOI 10.1016/j.camwa.2010.05.010
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Flores-Vergara A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030268
   Fuh CC, 2011, J VIB CONTROL, V17, P215, DOI 10.1177/1077546309350898
   Khedmati Y, 2020, INFORM SCIENCES, V512, P855, DOI 10.1016/j.ins.2019.10.028
   Khlebodarova TM, 2017, J BIOINF COMPUT BIOL, V15, DOI 10.1142/S0219720016500426
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Liu LF, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500591
   Liu LF, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501036
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu YQ, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750033X
   LvChen C, 2015, CHINESE PHYS B, V24, P82
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Tong XJ, 2014, NONLINEAR DYNAM, V78, P2277, DOI 10.1007/s11071-014-1564-1
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Wenhao L, 2017, INT J BIFURCAT CHAOS, V27, P11
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang W, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050504
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 40
TC 28
Z9 29
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30329
EP 30355
DI 10.1007/s11042-020-09595-x
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900014
DA 2024-07-18
ER

PT J
AU Khatibi, T
   Dezyani, P
AF Khatibi, Toktam
   Dezyani, Parastoo
TI Proposing novel methods for gynecologic surgical action recognition on
   laparoscopic videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimally-invasive surgery (MIS); Medical image processing;
   Multi-instance classification; Deep neural networks; Wrapper feature
   selection; Feature engineering
AB Laparoscopy or minimally-invasive surgery (MIS) is performed by inserting a camera called endoscope inside the body to display the surgical actions online with the ability to record and archive the video. Recognizing the surgical actions automatically from the laparoscopic videos have many applications such as surgical skill assessment, teaching purposes, and workflow recognition but is a challenging task. The main aim of this study is proposing novel automatic methods for surgical action recognition from the laparoscopic video frames. For this purpose, three different scenarios are designed, evaluated and compared using 5-fold cross validation strategy. The first and the second scenarios are based on deep neural networks and combination of pre-trained CNNs and conventional machine learning models, respectively. The last scenario combines handcraft feature extraction, pre-trained CNNs, feature engineering based on complex networks and conventional classifiers. Dataset analyzed in this study is ITEC LapGyn4 Gynecologic Laparoscopy Image dataset. Experimental results show that the second and the third scenarios have highly desirable performance for multi-instance surgical action recognition with the average accuracy of 99.20 and AUC of 99.12. On the other hand, for single-instance surgical action recognition, the third scenario outperforms the compared ones with the average accuracy of 99.05 and AUC of 96.41. Moreover, different feature sets in the third scenario are ranked and assigned the importance score based on "Mean Decrease of Accuracy" measure. The first-ranked features are the deep features extracted from our proposed CNNs in the first scenario and the second-ranked ones are the features engineered from the complex networks.
C1 [Khatibi, Toktam; Dezyani, Parastoo] Tarbiat Modares Univ, Sch Ind & Syst Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Khatibi, T (corresponding author), Tarbiat Modares Univ, Sch Ind & Syst Engn, Tehran, Iran.
EM toktamk.khatibi@modares.ac.ir
RI Khatibi, Toktam/HIR-8049-2022
OI Dezyani, Parastoo/0009-0004-4209-8920; Khatibi,
   Toktam/0000-0001-5824-9798
CR Barbosa D, 2009, 4 EUR C INT FED MED
   Bavelas A, 1948, APPL ANTHROPOL, V7, pA16
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buia Alexander, 2015, World J Methodol, V5, P238, DOI 10.5662/wjm.v5.i4.238
   Climent J, 2012, COMPUT BIOL MED, V42, P614, DOI 10.1016/j.compbiomed.2012.02.007
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Diykh M, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105116
   Fan XJ, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102659
   Han J, 2012, MOR KAUF D, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jin YM, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101572
   Kannan S, 2020, IEEE T MED IMAGING, V39, P556, DOI 10.1109/TMI.2019.2931158
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Kitaguchi D, 2020, SURG ENDOSC, V34, P4924, DOI 10.1007/s00464-019-07281-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Anand, 2016, Ann Maxillofac Surg, V6, P159, DOI 10.4103/2231-0746.200348
   Lahane A, 2012, IHI 12 P 2 ACM SIGHI
   Latora V., 2017, Complex Networks: Principles, Methods and Applications
   Leibetseder A, 2018, MMSYS 18 P 9 ACM MUL
   Loukas C, 2018, COMPUT METH PROG BIO, V165, P13, DOI 10.1016/j.cmpb.2018.07.004
   Luo XB, 2019, HEALTHC TECHNOL LETT, V6, P280, DOI 10.1049/htl.2019.0095
   Mackiewicz M, 2006, WIRELESS CAPSULE END
   Masood A, 2018, J BIOMED INFORM, V79, P117, DOI 10.1016/j.jbi.2018.01.005
   Moccia S, 2018, IEEE T BIO-MED ENG, V65, P2649, DOI 10.1109/TBME.2018.2813015
   Nikodem J, 2015, INT C COMP AID SYST
   Oropesa I, 2013, SURG ENDOSC, V27, P1029, DOI 10.1007/s00464-012-2513-z
   Petscharnig S, 2018, 2018 IEEE 31 INT S C
   Petscharnig S, 2018, MULTIMED TOOLS APPL, V77, P8061, DOI 10.1007/s11042-017-4699-5
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Sánchez-González P, 2011, MINIM INVASIV THER, V20, P311, DOI 10.3109/13645706.2010.541921
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh T, 2020, EGYPT INFORM J, V21, P105, DOI 10.1016/j.eij.2019.11.003
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Victoria AH, 2021, EVOL SYST-GER, V12, P217, DOI 10.1007/s12530-020-09345-2
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Voros S, 2007, INT J ROBOT RES, V26, P1173, DOI 10.1177/0278364907083395
   Wang C, 2018, ARXIVABS180308410
   Wirth R., 2000, Proceedings of the Fourth International Conference on the Practical Application of Knowledge Discovery and Data Mining, P29
   Xie CJ, 2020, J INFECT PUBLIC HEAL, V13, P1314, DOI 10.1016/j.jiph.2019.06.028
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 46
TC 15
Z9 15
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30111
EP 30133
DI 10.1007/s11042-020-09540-y
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000567227100002
DA 2024-07-18
ER

PT J
AU Zou, Z
   Li, CF
   Zheng, YH
   Xu, SK
AF Zou, Zhao
   Li, Chaofeng
   Zheng, Yuhui
   Xu, Shoukun
TI Two stages double attention convolutional neural network for crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Convolutional neural network; Double attention;
   Progressive training
ID ANOMALY DETECTION
AB Crowd counting has captured wide attention in computer vision, which aims to accurately count the number of people in still images or video scenes. However, it's still a challenging task due to the scale variation and cluttered background in crowd scenes. In this paper, we propose a 2-stage Double Attention convolutional neural network for crowd counting, and call it 2-DA-CNN, which could deal with scale variation and cluttered background in crowd counting. The proposed 2-DA-CNN includes three parts. The first part is the front-end module which consists of a set of convolution operations, whose function is to extract abundant feature of crowd. The second part is the first double attention module, which contains trunk branch and mask branch. The former is mainly composed by multi-column CNN module, which is to deal with scale variation in crowd scenes. The latter can generate two masks, which aims to assign interesting regions reasonably in cluttered situation. The third part is the second double attention module, similar to the first double attention module, which can enhance the performance of multi-column CNN module further. In addition, we propose progressive training method to improve the drawback of using geometry-adaptive kernels to generate ground truth. The experimental results on three mainstream datasets (ShanghaiTech part B, ShanghaiTech part A and UCF_CC_50) suggest that the proposed 2-DA-CNN is competitive with the state-of-the-art methods.
C1 [Zou, Zhao; Li, Chaofeng] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
   [Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Nanjing 210044, Peoples R China.
   [Xu, Shoukun] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
C3 Shanghai Maritime University; Nanjing University of Information Science
   & Technology; Changzhou University
RP Li, CF (corresponding author), Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
EM wxlichaofeng@126.com
OI Li, Chaofeng/0000-0002-3236-3143
FU National Natural Science Foundation of China [61771223]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61771223).
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chaker R, 2017, PATTERN RECOGN, V61, P266, DOI 10.1016/j.patcog.2016.06.016
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen JW, 2020, NEUROCOMPUTING, V382, P210, DOI 10.1016/j.neucom.2019.11.064
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao J, 2019, IEEE PAC RIM CONF CO, DOI 10.1109/pacrim47961.2019.8985116
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Paragios N, 2001, 2001 IEEE C COMP VIS
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Viresh R, 2018, EUR C COMP VIS ECCV
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Y, 2019, MULTIMED TOOLS APPL, V79, P1057
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YF, 2019, J ACUPUNCT TUINA SCI, V17, P9, DOI 10.1007/s11726-019-1083-1
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YM, 2019, NEUROCOMPUTING, V329, P144, DOI 10.1016/j.neucom.2018.10.058
   Zhou BL, 2011, PROC CVPR IEEE
   Zou ZK, 2019, NEUROCOMPUTING, V367, P75, DOI 10.1016/j.neucom.2019.08.009
   Zou ZK, 2018, IEEE ACCESS, V6, P60745, DOI 10.1109/ACCESS.2018.2875495
NR 35
TC 4
Z9 5
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29145
EP 29159
DI 10.1007/s11042-020-09541-x
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557319900002
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Tu, WT
   Chen, KR
   Wu, CH
   Li, L
   Ip, WH
   Chan, CY
AF Zhang, Yong
   Tu, Wentao
   Chen, Kairui
   Wu, C. H.
   Li, Li
   Ip, W. H.
   Chan, C. Y.
TI Bus passenger flow statistics algorithm based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Deep learning; Bus passenger flow statistics; SSD
   algorithm
AB Bus passenger flow statistics can be used to improve passenger travelling experience and reduce trip delay, this is very important for intelligent transportation. In this paper, a bus passenger flow statistics algorithm based on SSD (Single Shot MultiBox Detector) and Kalman filter is proposed to obtain passenger flow statistics from surveillance cameras on the buses. The method modifies the SSD model to a two-class model and trains the two-class SSD model using the bus dataset first, then the model is used to detect the position of the passengers in each frame and are tracked with the Kalman filter. Finally, according to the passenger trajectory, the traffic statistics of passenger getting on and off will be generated. The results of some conducted experiments show that the proposed bus passenger flow statistics algorithm is more accurate and robust than traditional methods.
C1 [Zhang, Yong; Tu, Wentao] Shenzhen Univ, ATR Key Lab Natl Def Technol, Shenzhen 518060, Peoples R China.
   [Zhang, Yong] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Zhang, Yong] Shenzhen Univ, Guangdong Lab Artificial Intelligence & Digital E, Shenzhen 518060, Peoples R China.
   [Chen, Kairui] Georgia Gwinnett Coll, Sch Sci & Technol, Lawrenceville, GA 30043 USA.
   [Wu, C. H.] Hang Seng Univ Hong Kong, Dept Supply Chain & Informat Management, Hong Kong 999077, Peoples R China.
   [Li, Li] Shenzhen Inst Informat Technol, Shenzhen 518172, Peoples R China.
   [Ip, W. H.] Univ Saskatchewan, Coll Engn, Saskatoon, SK, Canada.
   [Chan, C. Y.] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong 999077, Peoples R China.
C3 Shenzhen University; Shenzhen University; Guangming Laboratory; Shenzhen
   University; University System of Georgia; Georgia Gwinnett College; Hang
   Seng University of Hong Kong; Shenzhen Institute of Information
   Technology; University of Saskatchewan; Hong Kong Polytechnic University
RP Li, L (corresponding author), Shenzhen Inst Informat Technol, Shenzhen 518172, Peoples R China.
EM lilihitsz@163.com
RI IP, W.H./J-2941-2013; WU, Chun Ho/H-8815-2012
OI IP, W.H./0000-0001-6609-0713; WU, Chun Ho/0000-0003-1259-4048; Li,
   Li/0000-0003-2520-9583
FU Foundation of Nature Science of Guangdong [2015A030310172]
FX This work was supported by the Foundation of Nature Science of Guangdong
   (2015A030310172).
CR [Anonymous], 2018, ARXIV180404339
   Bin Li, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P136, DOI 10.1109/SMARTCOMP.2014.7043851
   Boggavarapu RK, 2016, IEEE I C COMP INT CO, P56
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen CH, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P565, DOI 10.1109/ISDA.2008.335
   Deng W, 2018, COMPUT SYST APPL, V27, P165
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Krizhevsky A., 2012, C WORKSHOP NEURAL IN
   Liu Lei, 2017, Journal of Shenzhen University Science and Engineering, V34, P584, DOI 10.3724/SP.J.1249.2017.06584
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vu TH, 2015, IEEE I CONF COMP VIS, P2893, DOI 10.1109/ICCV.2015.331
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   [文嘉俊 Wen Jiajun], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1729
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang Jun-jun, 2018, Computer Engineering and Science, V40, P282, DOI 10.3969/j.issn.1007-130X.2018.02.013
   Zheng G, 2017, J IND CONTROL COMPUT, V30, P48
NR 20
TC 5
Z9 6
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28785
EP 28806
DI 10.1007/s11042-020-09487-0
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300011
DA 2024-07-18
ER

PT J
AU Liang, JH
   Wang, LF
   Ma, M
AF Liang, Jianhui
   Wang, Lifang
   Ma, Miao
TI A new image segmentation method based on the ICSO-ISPCNN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chicken swarm optimization algorithm; Image segmentation; Pulse coupled
   neural network
ID ALGORITHM; PCNN
AB To address the issue of parameter settings in a pulse coupled neural network (PCNN), we propose a new image segmentation method based on the improved chicken swarm optimization algorithm and improved simplified PCNN (ICSO-ISPCNN) model. First, we improved a simplified PCNN model by modifying the dynamic threshold function and meanwhile improved the chicken swarm optimization (CSO) algorithm by introducing the survival of the fittest mechanism. Then, a product cross entropy is utilized as the fitness function of the ICSO algorithm, and the parameter values of the ISPCNN model are determined through the effective teamwork of roosters, hens, and chicks in the chicken swarm. Finally, we can achieve the automatic image segmentation via the ISPCNN model, which has the best parameter values. The detailed experiments indicate that our method has more superior performance in terms of convergence and segmentation accuracy than methods based on the genetic algorithm and ant colony optimization algorithm.
C1 [Liang, Jianhui; Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Liang, Jianhui] Hainan Univ, Coll Appl Sci & Technol, Danzhou 571737, Peoples R China.
   [Ma, Miao] Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
C3 Northwestern Polytechnical University; Hainan University; Shaanxi Normal
   University
RP Wang, LF (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.; Ma, M (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
EM wanglf@nwpu.edu.cn; mmthp@snnu.edu.cn
RI Lin, Lin/JTU-1595-2023; liang, jian/HNI-8846-2023; li,
   jian/IAQ-2794-2023
FU Hainan Provincial Natural Science Foundation of China [618QN220];
   Agricultural Science and Technology Innovation and Public Relations
   project of Shaanxi Province of China [2016NY-176]; National Natural
   Science Foundation of China [61877038, 61373120]
FX This work is supported by Hainan Provincial Natural Science Foundation
   of China (618QN220), the Agricultural Science and Technology Innovation
   and Public Relations project of Shaanxi Province of China (2016NY-176),
   and the National Natural Science Foundation of China (61877038,
   61373120).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen YL, 2015, IEEE T NEUR NET LEAR, V26, P1682, DOI 10.1109/TNNLS.2014.2351418
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   Eckhorn R., 1989, CAN J MICROBIOL, V46, P759
   Ganesh M, 2017, INTELL AUTOM SOFT CO, V23, P325, DOI 10.1080/10798587.2016.1231472
   Gao C, 2014, NEURAL PROCESS LETT, V39, P81, DOI 10.1007/s11063-013-9291-z
   Gao C, 2013, NEUROCOMPUTING, V119, P332, DOI 10.1016/j.neucom.2013.03.025
   Gómez W, 2016, NEUROCOMPUTING, V175, P877, DOI 10.1016/j.neucom.2015.04.121
   Gueguen L, 2014, J MATH IMAGING VIS, V48, P625, DOI 10.1007/s10851-013-0432-9
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Liang JH, 2018, MULTIMED TOOLS APPL, V77, P31787, DOI 10.1007/s11042-018-6119-x
   Liao Chuanzhu, 2014, Journal of Nanjing University of Science and Technology, V38, P558
   Lin YF, 2019, MULTIMED TOOLS APPL, V78, P29197, DOI 10.1007/s11042-018-6687-9
   Liu J., 2016, INTELL AUTOM SOFT CO, P1, DOI DOI 10.1080/10798587.2016.1196926
   Ma M, 2011, APPL SOFT COMPUT, V11, P5205, DOI 10.1016/j.asoc.2011.05.039
   Ma YD, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P743
   Ma Yi-de, 2002, Journal of China Institute of Communications, V23, P46
   Ma Yi-de, 2006, Journal of System Simulation, V18, P722
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI DOI 10.1145/1102351.1102424
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Oliva D, 2019, SOFT COMPUT, V23, P431, DOI 10.1007/s00500-017-2794-1
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Qu Shiru, 2015, High Power Laser and Particle Beams, V27, DOI 10.11884/HPLPB201527.051007
   Shih HC, 2016, IEEE T IMAGE PROCESS, V25, P4665, DOI 10.1109/TIP.2016.2586658
   Tiana F, 2017, J INTELL FUZZY SYST, V32, P1389, DOI 10.3233/JIFS-169136
   Unnikrishnan R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P394
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang Q, 2017, IEEE T VEH TECHNOL, V66, P8001, DOI 10.1109/TVT.2017.2685526
   Wu DH, 2016, IEEE ACCESS, V4, P9400, DOI 10.1109/ACCESS.2016.2604738
   Wu YP, 2017, MULTIMED TOOLS APPL, V76, P19781, DOI 10.1007/s11042-015-3192-2
   Xu XZ, 2017, INTELL AUTOM SOFT CO, V23, P303, DOI 10.1080/10798587.2016.1210258
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
NR 37
TC 3
Z9 3
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28131
EP 28154
DI 10.1007/s11042-019-08596-9
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800002
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Ertam, F
   Dogan, S
AF Tuncer, Turker
   Ertam, Fatih
   Dogan, Sengul
TI Automated malware recognition method based on local neighborhood binary
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LNBP; Malware recognition; Machine learning; Grayscale image processing;
   Cyber security
ID CLASSIFICATION
AB Malware recognition has been widely used in the literature. One of the malware recognition methods is the byte code based methods. These methods generally use image processing and machine learning methods together to recognize malware. In this article, a novel byte code based malware recognition method is presented, and it consists of feature extraction using the proposed local neighborhood binary pattern (LNBP), feature concatenation, feature selection with neighborhood component analysis (NCA), feature reduction using principal component analysis (PCA) and classification using linear discriminant analysis. A heterogeneous and mostly used byte-based malware dataset (Maligm) was chosen to evaluate the performance of the proposed LNBP based recognition method. The best accuracy rate was equal to 89.40%. The proposed LNBP based method was also compared to the state-of-art deep learning methods, and it achieved a higher success rate than them. These results clearly demonstrate prove the success of the proposed LNBP based method.
C1 [Tuncer, Turker; Ertam, Fatih; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
C3 Firat University
RP Tuncer, T (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
EM turkertuncer@firat.edu.tr; fatih.ertam@firat.edu.tr; sdogan@firat.edu.tr
RI DOGAN, Sengul/ABG-1141-2020; TUNCER, Türker/ABG-1146-2020; TUNCER,
   Turker/W-4846-2018; Ertam, Fatih/V-5288-2018; DOGAN, Sengul/W-4854-2018
OI DOGAN, Sengul/0000-0001-9677-5684; Ertam, Fatih/0000-0002-9736-8068;
   DOGAN, Sengul/0000-0001-9677-5684
CR Agarap AF., 2017, BUILDING INTELLIGENT
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Balakrishnama S, 1999, IEEE SOUTHEASTCON '99, PROCEEDINGS, P78, DOI 10.1109/SECON.1999.766096
   Banin S, 2018, DIGIT INVEST, V26, pS107, DOI 10.1016/j.diin.2018.04.019
   Boero L, 2017, 2017 29TH INTERNATIONAL TELETRAFFIC CONGRESS (ITC 29), VOL 3, P25, DOI [10.23919/ITC.2017.8065806, 10.1109/JTC29.147]
   Case A, 2016, DIGIT INVEST, V18, pS3, DOI 10.1016/j.diin.2016.04.017
   Chandrika MP, 2017, ETHICAL HACKING CYBE
   Dai YS, 2018, DIGIT INVEST, V27, P30, DOI 10.1016/j.diin.2018.09.006
   Demme J., 2013, P 40 ANN INT S COMP, P559, DOI [DOI 10.1145/2485922.2485970, 10.1145/2485922]
   Dong K, 2014, Obesity Interventions in Underserved Communities: Evidence and Directions, P106
   Egele M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2089125.2089126
   Feng Y, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23379
   Gibert D, 2020, J NETW COMPUT APPL, V153, DOI 10.1016/j.jnca.2019.102526
   Javaheri D, 2018, WIRELESS PERS COMMUN, V98, P119, DOI 10.1007/s11277-017-4859-y
   Jones K., 2020, PROC CONF MOBILE SEC, P1
   Kalash M, 2018, INT CONF NEW TECHNOL
   Khasawneh Khaled N., 2015, Research in Attacks, Intrusions and Defenses. 18th International Symposium, RAID 2015. Proceedings: LNCS 9404, P3, DOI 10.1007/978-3-319-26362-5_1
   Kirat D, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P403
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu JC, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P523, DOI 10.1109/CIS.2013.116
   Liu XB, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101682
   Mitsuhashi R., 2020, HIGH ACCURACY MALWAR
   Nataraj L., 2011, P P ACM C COMP COMM
   Nataraj L, 2016, IEEE SIGNAL PROC MAG, V33, P105, DOI 10.1109/MSP.2015.2507185
   Nataraj Lakshmanan, 2011, P 8 INT S VIS CYB SE, P1
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Ojala T., 1994, P INT C PATT REC
   Ozsoy M, 2015, INT S HIGH PERF COMP, P651, DOI 10.1109/HPCA.2015.7056070
   Raghu S, 2018, EXPERT SYST APPL, V113, P18, DOI 10.1016/j.eswa.2018.06.031
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Rudd EM, 2017, IEEE COMMUN SURV TUT, V19, P1145, DOI 10.1109/COMST.2016.2636078
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Smutz C, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23078
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Ucci D, 2019, COMPUT SECUR, V81, P123, DOI 10.1016/j.cose.2018.11.001
   Vasan D, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101748
   Vinayakumar R, 2019, IEEE ACCESS, V7, P46717, DOI 10.1109/ACCESS.2019.2906934
   Ye YF, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3073559
   Yuan BG, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101740
NR 42
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27815
EP 27832
DI 10.1007/s11042-020-09376-6
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554000001
DA 2024-07-18
ER

PT J
AU Chu, YH
   Lin, HF
   Yang, L
   Zhang, DY
   Zhang, SW
   Diao, YF
   Yan, DQ
AF Chu, Yonghe
   Lin, Hongfei
   Yang, Liang
   Zhang, Dongyu
   Zhang, Shaowu
   Diao, Yufeng
   Yan, Deqin
TI Fuzzy ELM for classification based on feature space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Classification; Membership degree; Feature
   mapping space
ID EXTREME LEARNING-MACHINE; REGRESSION; NETWORKS; ROBUST
AB As a competitive machine learning algorithm, extreme learning machine (ELM), with its simple theory and easy implementation, has been widely used in the field of pattern accuracy. Recently, researchers have proposed related research algorithms to accommodate noise and outlier data. With a proper fuzzy membership function, a fuzzy ELM can effectively reduce the effects of outliers when solving the classification problem. However, how to apply ELM for learning and accuracy in the presence of noise is still an important research topic.A novel fuzzy ELM (ANFELM) technique is proposed in this paper. In the algorithm, the membership degree of the sample is calculated in a feature mapping space instead of the data input space. The algorithm provides good performance in reducing the effects of outliers and significantly improves classification accuracy and generalization. Experiments on UCI datasets and textual datasets show that the proposed algorithm significantly improves the classification capability of ELM and is superior to other algorithms.
C1 [Chu, Yonghe; Lin, Hongfei; Yang, Liang; Zhang, Dongyu; Zhang, Shaowu; Diao, Yufeng] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
   [Yan, Deqin] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
C3 Dalian University of Technology; Liaoning Normal University
RP Lin, HF (corresponding author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
EM hflin@dlut.edu.cn
FU Natural Science Foundation of China [61632011, 61572102, 61702080,
   61602079]; Fundamental Research Funds for the Central Universities
   [DUT18ZD102, DUT17RC(3)016]
FX This work is partially supported by grant from the Natural Science
   Foundation of China (No. 61632011, 61572102, 61702080, 61602079) and the
   Fundamental Research Funds for the Central Universities (NO. DUT18ZD102,
   DUT17RC(3)016).
CR [Anonymous], SCH INF COMPUT SCI
   Cao FX, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112603
   Castaño A, 2013, NEURAL PROCESS LETT, V37, P377, DOI 10.1007/s11063-012-9253-x
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Fernández-Delgado M, 2014, NEURAL NETWORKS, V50, P60, DOI 10.1016/j.neunet.2013.11.002
   Gu Y, 2015, NEUROCOMPUTING, V166, P282, DOI 10.1016/j.neucom.2015.04.011
   Huang G, 2014, IEEE T CYBERNETICS, V44, P2405, DOI 10.1109/TCYB.2014.2307349
   Huang GB, 2006, IEEE T CIRCUITS-II, V53, P187, DOI 10.1109/TCSII.2005.857540
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Li L, 2018, NEUROCOMPUTING, V275, P1725, DOI 10.1016/j.neucom.2017.09.004
   Lin SB, 2015, IEEE T NEUR NET LEAR, V26, P21, DOI 10.1109/TNNLS.2014.2336665
   Liu B, 2016, NEURAL COMPUT APPL, V27, P255, DOI 10.1007/s00521-014-1777-8
   Liu SL, 2014, NEUROCOMPUTING, V144, P318, DOI 10.1016/j.neucom.2014.04.041
   Liu X, 2015, IEEE T NEUR NET LEAR, V26, P7, DOI 10.1109/TNNLS.2014.2335212
   Liu XY, 2012, NEURAL NETWORKS, V33, P58, DOI 10.1016/j.neunet.2012.04.002
   Lv F, 2017, IEEE ACCESS, V5, P9021, DOI 10.1109/ACCESS.2017.2706363
   Ma YP, 2018, APPL MATH COMPUT, V334, P214, DOI 10.1016/j.amc.2018.03.010
   Raghuwanshi BS, 2018, ENG APPL ARTIF INTEL, V74, P252, DOI 10.1016/j.engappai.2018.07.002
   Raghuwanshi BS, 2018, NEURAL NETWORKS, V105, P206, DOI 10.1016/j.neunet.2018.05.011
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sahani M, 2018, NEUROCOMPUTING, V310, P10, DOI 10.1016/j.neucom.2018.03.056
   Singh Lavneet, 2012, Algorithms and Architectures for Parallel Processing. Proceedings of the 12th International Conference (ICA3PP 2012), P292, DOI 10.1007/978-3-642-33065-0_31
   Su HJ, 2017, IEEE J-STARS, V10, P309, DOI 10.1109/JSTARS.2016.2591004
   Tang XL, 2010, KNOWL INF SYST, V23, P345, DOI 10.1007/s10115-009-0220-4
   Wang Q, 2016, NEUROCOMPUTING, V174, P18, DOI 10.1016/j.neucom.2015.03.116
   Wang XZ, 2013, NEUROCOMPUTING, V102, P3, DOI [10.1016/j.neucom.2011.11053, 10.1016/j.neucom.2011.12.053]
   Xia SX, 2015, COGN COMPUT, V7, P74, DOI 10.1007/s12559-014-9256-1
   Xiao WD, 2017, NEUROCOMPUTING, V261, P70, DOI 10.1016/j.neucom.2016.09.120
   Yu DY, 2015, J VISION, V15, DOI 10.1167/15.11.3
   Yu Q, 2013, NEUROCOMPUTING, V102, P45, DOI 10.1016/j.neucom.2012.02.040
   Zhang K, 2015, NEUROCOMPUTING, V151, P1519, DOI 10.1016/j.neucom.2014.09.022
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124
   Zhang WB, 2013, ELECTRON LETT, V49, P448, DOI 10.1049/el.2012.3642
   Zheng WB, 2013, NEURAL COMPUT APPL, V22, P447, DOI 10.1007/s00521-011-0808-y
   Zheng Y, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P524, DOI 10.1109/IMIS.2013.93
   Zhu WT, 2014, INT JOINT C NEUR NET, P6
   Zou QY, 2018, NEUROCOMPUTING, V275, P2864, DOI 10.1016/j.neucom.2017.11.030
NR 41
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27439
EP 27464
DI 10.1007/s11042-019-08321-6
EA JUL 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552512800001
DA 2024-07-18
ER

PT J
AU Gao, F
   Jin, YM
   Ge, YS
   Lu, SF
   Zhang, YM
AF Gao, Fei
   Jin, Yiming
   Ge, Yisu
   Lu, Shufang
   Zhang, Yuanming
TI Occluded person re-identification based on feature fusion and sparse
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occluded person re-identification; Sub-region derivation; Feature
   reconstruction; Feature fusion
ID NEURAL-NETWORK
AB Person Re-identification is one of the hotspots in the field of computer vision, especially for occluded person re-identification, which is still a challenge. In this paper, a feature fusion and sparse reconstruction based method of occluded person re-identification is proposed, which is suitable for person re-identification in various occlusion situations and where pose estimation is employed to obtain the occlusion body parts. A Full Occlusion Re-identification Network(FORN) is developed, where the obstruction is blackened. In the FORN, partial feature extraction and sparse feature reconstruction is combined through tree connections. The fusion features are facilitated in the FORN for occluded person similarity matching so that the matching rate of person re-identification under various occlusion situations is improved. On the occluded person re-identification datasets Partial-REID and Partial-iLIDS, the FORN method has obtained the experimental results of R-1 index 62.75% and 64.26%, and R-3 index 79.43% and 73.10%, respectively. Experiments are also conducted on conventional person re-identification datasets and the experimental results have verified the effectiveness and advancement of the proposed method.
C1 [Gao, Fei; Jin, Yiming; Ge, Yisu; Lu, Shufang; Zhang, Yuanming] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Gao, F (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM feig@zjut.edu.cn; 251715978@qq.com; geyisu@zjut.edu.cn;
   sflu@zjut.edu.cn; zym@zjut.edu.cn
OI gao, fei/0000-0002-4678-1936
FU National Natural Science Foundation of China [61976193]; Zhejiang
   Provincial Science and Technology Planning Key Project of China
   [2018C01064]; Zhejiang Provincial Natural Science Foundation of China
   [LY19F020027]
FX This work is being supported by the National Natural Science Foundation
   of China under Grant No. 61976193, the Zhejiang Provincial Science and
   Technology Planning Key Project of China under Grant No. 2018C01064 and
   the Zhejiang Provincial Natural Science Foundation of China under Grant
   No. LY19F020027.
CR [Anonymous], 2017, Beyond part models: Person retrieval with refined part pooling. Proceedings of European Conference on Computer Vision
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong SS, 2014, ADV MATER RES-SWITZ, V830, P139, DOI 10.4028/www.scientific.net/AMR.830.139
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He L., 2018, RECOGNIZING PARTIAL
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Kim J, 2017, IEEE IMAGE PROC, P3425, DOI 10.1109/ICIP.2017.8296918
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li K, 2019, IEEE T NEUR NET LEAR, V30, P1896, DOI 10.1109/TNNLS.2018.2875429
   Li SM, 2018, IEEE T CIRC SYST VID, V28, P1765, DOI 10.1109/TCSVT.2016.2637819
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XL, 2018, IEEE T NEUR NET LEAR, V29, P1314, DOI 10.1109/TNNLS.2016.2602855
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Matsukawa T, 2006, IEEE C COMP VIS PATT, P1363
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Patruno C, 2019, PATTERN RECOGN, V89, P77, DOI 10.1016/j.patcog.2019.01.003
   Pei JF, 2013, IEEE INT C BIOINFORM
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Quan R, 2019, AUTO REID SEARCHING
   Ristani E, 2016, 15 EUR C COMP VIS WO
   Sang HF, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7028107
   Song ZT, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P2020, DOI 10.1109/IAEAC.2017.8054370
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Yuan MY, 2019, J VIS COMMUN IMAGE R, V59, P527, DOI 10.1016/j.jvcir.2019.01.041
   Zeng MY, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301296
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zhang Z, 2018, IEEE INTERNET THINGS, V5, P3361, DOI 10.1109/JIOT.2017.2746901
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao XB, 2018, IEEE T NEUR NET LEAR, V29, P3701, DOI 10.1109/TNNLS.2017.2736640
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou SP, 2018, IEEE T MULTIMEDIA, V20, P593, DOI 10.1109/TMM.2017.2755983
NR 40
TC 5
Z9 5
U1 10
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15061
EP 15078
DI 10.1007/s11042-020-09361-z
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000551373900001
DA 2024-07-18
ER

PT J
AU Kriti
   Virmani, J
   Agarwal, R
AF Kriti
   Virmani, Jitendra
   Agarwal, Ravinder
TI Deep feature extraction and classification of breast ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Despeckling; Segmentation; Augmentation; Deep learning; Convolution
   neural network; ANFC classifier
ID CONVOLUTIONAL NEURAL-NETWORKS; COMPUTER-AIDED DIAGNOSIS; TUMOR
   CLASSIFICATION; LINGUISTIC HEDGES; TEXTURE; SYSTEM; FRAMEWORK;
   SELECTION; ENSEMBLE; DISEASE
AB Controlled despeckling (structure/edges/feature preservation with smoothing the homogeneous areas) is a desired pre-processing step for the design of computer-aided diagnostic (CAD) systems using ultrasound images as the presence of speckle noise masks diagnostically important information making interpretation difficult even for experienced radiologist. For efficiently classifying the breast tumors, the conventional CAD system designs use hand-crafted features. However, these features are not robust to the variations in size, shape and orientation of the tumors resulting in lower sensitivity. Thus deep feature extraction and classification of breast ultrasound images have recently gained attention from research community. The deep networks come with an advantage of directly learning the representative features from the images. However, these networks are difficult to train from scratch if the representative training data is small in size. Therefore transfer learning approach for deep feature extraction and classification of medical images has been widely used. In the present work the performance of four pre-trained convolutional neural networks VGG-19, SqueezeNet, ResNet-18 and GoogLeNet has been evaluated for differentiating between benign and malignant tumor types. From the results of the experiments, it is noted that CAD system design using GoogLeNet architecture for deep feature extraction followed by correlation based feature selection and fuzzy feature selection using ANFC-LH yields highest accuracy of 98.0% with individual class accuracy value of 100% and 96% for benign and malignant classes respectively. For differentiating between the breast tumors, the proposed CAD system design can be utilized in routine clinical environment.
C1 [Kriti; Agarwal, Ravinder] Thapar Inst Engn & Technol, Patiala 147004, Punjab, India.
   [Virmani, Jitendra] CSIO, CSIR, Chandigarh 160030, India.
C3 Thapar Institute of Engineering & Technology; Council of Scientific &
   Industrial Research (CSIR) - India; CSIR - Central Scientific
   Instruments Organisation (CSIO)
RP Virmani, J (corresponding author), CSIO, CSIR, Chandigarh 160030, India.
EM kriti.23gm@gmail.com; jitendra.virmani@gmail.com;
   ravinder.agarwal@gmail.com
RI Agarwal, Ravinder/ABA-8260-2020; , KRITI/AAC-4752-2021
OI Agarwal, Ravinder/0000-0001-8196-049X; , KRITI/0000-0002-3107-522X
CR Ahmed SS, 2017, MED BIOL ENG COMPUT, V55, P101, DOI 10.1007/s11517-016-1508-7
   Ai H, 2019, INVEST CLIN, V60, P1169
   Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   Al-Dhabyani W, 2019, INT J ADV COMPUT SC, V10, P618
   Alvarenga AV, 2012, MED PHYS, V39, P7350, DOI 10.1118/1.4766268
   Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Balagourouchetty L, 2020, IEEE J BIOMED HEALTH, V24, P1686, DOI 10.1109/JBHI.2019.2942774
   Byra M, 2018, BIOCYBERN BIOMED ENG, V38, P684, DOI 10.1016/j.bbe.2018.05.003
   Byra M, 2019, MED PHYS, V46, P746, DOI 10.1002/mp.13361
   Cao ZT, 2019, BMC MED IMAGING, V19, DOI 10.1186/s12880-019-0349-x
   Cetisli B, 2010, EXPERT SYST APPL, V37, P6093, DOI 10.1016/j.eswa.2010.02.108
   Cetisli B, 2010, EXPERT SYST APPL, V37, P6102, DOI 10.1016/j.eswa.2010.02.115
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen CY, 2009, ACAD RADIOL, V16, P1531, DOI 10.1016/j.acra.2009.07.024
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Chiao JY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015200
   Ciritsis A, 2019, EUR RADIOL, V29, P5458, DOI 10.1007/s00330-019-06118-7
   Crystal P, 2003, AM J ROENTGENOL, V181, P177, DOI 10.2214/ajr.181.1.1810177
   Ferreira Chelo, 2018, Alimentaria, P95
   Fletcher SW, 2003, NEW ENGL J MED, V348, P1672, DOI 10.1056/NEJMcp021804
   Fujioka T, 2019, JPN J RADIOL, V37, P466, DOI 10.1007/s11604-019-00831-5
   Gardezi SJS, 2019, J MED INTERNET RES, V21, DOI 10.2196/14464
   Gokhale Sudheer, 2009, Indian J Radiol Imaging, V19, P242, DOI 10.4103/0971-3026.54878
   GORDON PB, 1995, CANCER, V76, P626, DOI 10.1002/1097-0142(19950815)76:4<626::AID-CNCR2820760413>3.0.CO;2-Z
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hooda R, 2019, MULTIMED TOOLS APPL, V78, P31515, DOI 10.1007/s11042-019-07984-5
   Hu ZL, 2018, PATTERN RECOGN, V83, P134, DOI 10.1016/j.patcog.2018.05.014
   Huang YZ, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0626-5
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Indian Council of Medical Research, CONS DOC MAN BREAST
   Jain I, 2018, APPL SOFT COMPUT, V62, P203, DOI 10.1016/j.asoc.2017.09.038
   Kadah YM, 1996, IEEE T MED IMAGING, V15, P466, DOI 10.1109/42.511750
   Kameswari SSD., 2019, INT J INNOV TECHNOL, V8, P1340
   Kar S, 2014, APPL SOFT COMPUT, V15, P243, DOI 10.1016/j.asoc.2013.10.014
   Karimi B, 2014, LECT NOTES ARTIF INT, V8468, P131, DOI 10.1007/978-3-319-07176-3_12
   Key TJ, 2001, LANCET ONCOL, V2, P133, DOI 10.1016/S1470-2045(00)00254-0
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P536, DOI 10.1016/j.bbe.2019.02.004
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P100, DOI 10.1016/j.bbe.2018.10.002
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Kumar I, 2017, MULTIMED TOOLS APPL, V76, P18789, DOI 10.1007/s11042-016-4340-z
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lee CY, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8413403
   Liang HL, 2017, ASIA CONTROL CONF AS, P2340, DOI 10.1109/ASCC.2017.8287540
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Priego-Torres BM, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113387
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Meng D, 2017, IEEE ACCESS, V5, P5804, DOI 10.1109/ACCESS.2017.2689058
   Michalak K., 2006, International Journal of Applied Mathematics and Computer Science, P503
   Moon WK, 2012, ULTRASOUND MED BIOL, V38, P1251, DOI 10.1016/j.ultrasmedbio.2012.02.029
   Nibali A, 2017, INT J COMPUT ASS RAD, V12, P1799, DOI 10.1007/s11548-017-1605-6
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Prabusankarlal KM, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0029-y
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Qian XZ, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON UNIVERSAL VILLAGE (IEEE UV 2018)
   Rani VMK, 2020, MULTIMED TOOLS APPL, V79, P16967, DOI 10.1007/s11042-019-7487-6
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Rawat J, 2018, ARAB J SCI ENG, V43, P7041, DOI 10.1007/s13369-017-2959-3
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Rehman M, 2019, P AM INT C ART INT, P244
   Seokmin Han, 2019, The International Journal of Advanced Smart Convergence, V8, P24, DOI 10.7236/IJASC.2019.8.1.24
   Sharma A, 2017, P 4 INT C SIGN PROC, DOI [10.1109/ISPCC.2017.8269683, DOI 10.1109/ISPCC.2017.8269683]
   Sharma A, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3649
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh BK, 2019, BIOCYBERN BIOMED ENG, V39, P393, DOI 10.1016/j.bbe.2019.03.001
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Su Yanni, 2011, Open Med Inform J, V5, P26, DOI 10.2174/1874431101105010026
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Sun J, 2017, LECT NOTES COMPUT SC, V10554, P126, DOI 10.1007/978-3-319-67561-9_14
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tohno E, 2009, BREAST CANCER-TOKYO, V16, P18, DOI 10.1007/s12282-008-0082-8
   Übeyli ED, 2009, J MED SYST, V33, P353, DOI 10.1007/s10916-008-9197-x
   Vesal S, 2018, LECT NOTES COMPUT SC, V10882, P812, DOI 10.1007/978-3-319-93000-8_92
   Vianna V. Pavanelli, 2018, ARXIV180600839
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang J., 2017, ARXIV171204621V1
   Weiss N, 2018, LECT NOTES COMPUT SC, V10882, P727, DOI 10.1007/978-3-319-93000-8_82
   Wu WJ, 2008, ACAD RADIOL, V15, P873, DOI 10.1016/j.acra.2008.01.010
   Wu WJ, 2015, J DIGIT IMAGING, V28, P576, DOI 10.1007/s10278-014-9757-1
   Xiao T, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/4605191
   Xie XZ, 2018, LECT NOTES COMPUT SC, V11166, P200, DOI 10.1007/978-3-030-00764-5_19
   Yoshida H, 2003, PHYS MED BIOL, V48, P3735, DOI 10.1088/0031-9155/48/22/008
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zakeri FS, 2012, J MED SYST, V36, P1621, DOI 10.1007/s10916-010-9624-7
   Zeimarani B, 2019, IFMBE PROC, V70, P89, DOI 10.1007/978-981-13-2517-5_14
   Zhang EL, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab7e7d
NR 94
TC 34
Z9 34
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27257
EP 27292
DI 10.1007/s11042-020-09337-z
EA JUL 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551736600001
DA 2024-07-18
ER

PT J
AU Yang, YQ
   Yang, YM
   Yuan, Y
   Zheng, JY
   Zheng, ZX
AF Yang, Yongquan
   Yang, Yiming
   Yuan, Yong
   Zheng, Jiayi
   Zheng, Zhongxi
TI Detecting helicobacter pylori in whole slide images via weakly
   supervised multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Helicobacter pylori; Image semantic segmentation; Multi-task learning;
   Weakly supervised learning
ID SEGMENTATION; DIAGNOSIS; CLASSIFICATION; NETWORK
AB Due to the difficulty to accurately define the morphologies of Helicobacter Pylori (H. pylori) and the complexity of dealing with the whole slide images (WSIs), no computer-aided solution has currently been presented for detectingH. pyloriinfection in WSIs. We present the first image semantic segmentation solution for the computer-aided detection ofH. pyloriin WSIs. The solution only requires polygon annotations as weak supervision, which roughly, instead of pixel-level accurately, label theH. pyloriinfected areas in WSIs. We propose a new weakly supervised multi-task learning framework (WSMLF) that aims to improve the segmentation performance by more effectively exploiting the weak supervision. To make more effective usage of the weak supervision, we extract multiple inaccurate targets representing different modes of the true target from the available weak annotations. For improvement of the segmentation performance, we design a weakly supervised multi-task learning algorithm that can automatically learn from the weighted summarization of the extracted multiple inaccurate targets. These two advances constitute the resulting technique WSMLF. Introducing the proposed WSMLF to several common deep image semantic segmentation approaches for the detection ofH. pyloriin WSIs, we observe that WSMLF can enable these approaches to achieve more reasonable segmentation results, which eventually improve the detection performance ofH. pyloriby at most 6%. WSMLF provides new thoughts for more effectively employing weak supervision to achieve more effective results for image semantic segmentation.
C1 [Yang, Yongquan; Yang, Yiming; Yuan, Yong; Zheng, Zhongxi] Sichuan Univ, West China Hosp, Pathol Lab, 37 Guo Xue Rd, Chengdu 610041, Peoples R China.
   [Zheng, Jiayi] Univ San Francisco, Premed Sch, San Francisco, CA 94117 USA.
C3 Sichuan University; University of San Francisco
RP Zheng, ZX (corresponding author), Sichuan Univ, West China Hosp, Pathol Lab, 37 Guo Xue Rd, Chengdu 610041, Peoples R China.
EM digitalpathology@scu.edu.cn
RI yuan, Yuan/ISA-0923-2023; Yuan, Yu/HTM-9814-2023; yuan,
   yu/HZI-6841-2023; Yang, Yongquan/ABH-8736-2022; Yuan, Yuan/GVS-5120-2022
OI Yang, Yongquan/0000-0002-3965-4816; Zheng, Zhongxi/0000-0002-7046-8480
FU Sichuan Science and Technology Program [2020YFS0088]; 1.3.5 project for
   disciplines of excellence Clinical Research Incubation Project, West
   China Hospital, Sichuan University [2019HXFH036]; National Key Research
   and Development Program, China [2017YFC0113908]; Technological
   Innovation Project of Chengdu New Industrial Technology Research
   Institute [2017-CY02-00026-GX]; West China Hospital, Sichuan University
   [139170022]
FX This work was supported by the Sichuan Science and Technology Program
   (2020YFS0088); the 1 center dot 3 center dot 5 project for disciplines
   of excellence Clinical Research Incubation Project, West China Hospital,
   Sichuan University (2019HXFH036); the National Key Research and
   Development Program (2017YFC0113908), China; the Technological
   Innovation Project of Chengdu New Industrial Technology Research
   Institute (2017-CY02-00026-GX); and the West China Hospital, Sichuan
   University (139170022).
CR Ahn Jiwoon, 2018, P IEEE COMP SOC C CO
   Andermatt S, 2016, LECT NOTES COMPUT SC, V10008, P142, DOI 10.1007/978-3-319-46976-8_15
   [Anonymous], 2016, P INT C MED IM COMP
   [Anonymous], EXPLOITING LOCAL STR
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Caruana R., 1993, ICML, P41, DOI 10.1016/b978-1-55860-307-3.50012-5
   Chen L, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P833, DOI 10.1145/3269206.3271759
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   CUTLER AF, 1995, GASTROENTEROLOGY, V109, P136, DOI 10.1016/0016-5085(95)90278-3
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Duchi John C., 2010, COLT 2010 - The 23rd Conference on Learning Theory, Haifa, Israel, June 27-29, 2010
   Duong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P845
   Fan D.p., 2020, Camouflaged object detection. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Ford AC, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005583.pub2
   Foulds J, 2010, REV KNOWL ENG
   Frénay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Gao W, 2016, AAAI CONF ARTIF INTE, P1575
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Ghosh S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329784
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ishizawa T, 1998, DERMATOLOGY, V197, P388, DOI 10.1159/000018039
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2018, SEMANTIC EDGE DETECT
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2019, IN C IND ENG ENG MAN, P1002, DOI [10.1109/IEEM44572.2019.8978933, 10.1109/ieem44572.2019.8978933]
   Mentis A, 2015, HELICOBACTER, V20, P1, DOI 10.1111/hel.12250
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   O'Connor A, 2017, NAT REV GASTRO HEPAT, V14, P230, DOI 10.1038/nrgastro.2016.195
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Rajchl Martin, 2017, IEEE Trans Med Imaging, V36, P674, DOI 10.1109/TMI.2016.2621185
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., ARXIV160904747
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha M, 2018, IEEE T IMAGE PROCESS, V27, P2189, DOI 10.1109/TIP.2018.2795742
   Settles B., 2010, Machine Learning
   Shi FM, 2016, ZOOKEYS, P1, DOI 10.3897/zookeys.558.6165
   Shi M, 2016, LECT NOTES COMPUTER
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shichijo S, 2015, J GASTROEN HEPATOL, V30, P1260, DOI 10.1111/jgh.12946
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh SK, 2013, IERI PROC, V4, P351, DOI 10.1016/j.ieri.2013.11.050
   Stenström B, 2008, AUST FAM PHYSICIAN, V37, P608
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Wang L, 2017, IEEE T PATTERN ANAL, V39, P2074, DOI 10.1109/TPAMI.2016.2612187
   Warthin AS, 1922, J INFECT DIS, V30, P592, DOI 10.1093/infdis/30.6.592
   Yang AYQ, 2020, MULTIMED TOOLS APPL, V79, P18767, DOI 10.1007/s11042-020-08746-4
   Yang M, 2018, P IEEE COMP SOC C CO
   Yang Y., 2017, Trace norm regularised deep multi-task learning
   Yang YQ, 2019, MULTIMED TOOLS APPL, V78, P2269, DOI 10.1007/s11042-018-6347-0
   Yang YQ, 2018, MULTIMED TOOLS APPL, V77, P7283, DOI 10.1007/s11042-017-4633-x
   Yu F., 2015, ARXIV
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12
   Zhou ZH, 2018, REV NATL SCI
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu X, 2006, 1530 U WISC
NR 70
TC 8
Z9 9
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26787
EP 26815
DI 10.1007/s11042-020-09185-x
EA JUL 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549799000001
DA 2024-07-18
ER

PT J
AU Punn, NS
   Agarwal, S
AF Punn, Narinder Singh
   Agarwal, Sonali
TI Multi-modality encoded fusion with 3D inception U-net and decoder model
   for brain tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural networks; Healthcare; Medical image analysis;
   Multi-modalities; Segmentation
AB With deep learning playing a crucial role in biomedical image segmentation, multi-modality fusion-based techniques have gained rapid growth. For any radiologist, identification and segmentation of brain tumor (gliomas) via multi-sequence 3D volumetric MRI scan for diagnosis, monitoring, and treatment, are complex and time-consuming tasks. The brain tumor segmentation (BraTS) challenge offers 3D volumes of high-graded gliomas (HGG), and low-graded gliomas (LGG) MRI scans with four modalities: T1, T1c, T2 and FLAIR. In this article, the tumor segmentation is performed on the preprocessed multi-modalities by proposed 3D deep neural network components: multi-modalities fusion, tumor extractor, and tumor segmenter. The multi-modalities fusion component uses the deep inception based encoding to merge the multi-modalities. Tumor extractor component is passed with the fused images to recognise the tumor patterns using the 3D inception U-Net model. Finally, tumor segmenter utilises the progressive approach to decode the extracted feature maps into the tumor regions. The architecture segments each lesion region into the whole tumor (WT), core tumor (CT), and enhancing tumor (ET) using the five target classes: background, necrosis, edema, enhancing tumor and non-enhancing tumor. To tackle the class imbalance problem, the weighted segmentation loss function is proposed based on the dice coefficient and the Jaccard index. This article illustrates the significance of each component on the BraTS 2017 and 2018 datasets by achieving better segmentation results. The performance of the proposed approach is also compared with the other state-of-the-art methods.
C1 [Punn, Narinder Singh; Agarwal, Sonali] IIIT Allahabad, Prayagraj 211015, India.
C3 Indian Institute of Information Technology Allahabad
RP Punn, NS (corresponding author), IIIT Allahabad, Prayagraj 211015, India.
EM pse2017002@iiita.ac.in; sonali@iiita.ac.in
RI Punn, Narinder Singh/ABA-3787-2020; Agarwal, Sonali/AAT-1740-2020
OI Punn, Narinder Singh/0000-0003-1175-1865; Agarwal,
   Sonali/0000-0001-9083-5033
CR [Anonymous], CoRR abs/1511.07122
   Avants B.B., 2009, Insight j, V2, P1, DOI DOI 10.54294/UVNHIN
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Brownlee Jason, 2018, GENTLE INTRO EARLY S
   Chen C, 2019, LECT NOTES COMPUT SC, V11766, P184, DOI 10.1007/978-3-030-32248-9_21
   Chen LL, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293394
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Z, 2019, IEEE T RADIAT PLASMA, V3, P162, DOI [10.1109/TRPMS.2018.2890359, 10.1109/trpms.2018.2890359]
   Hatamizadeh A, 2019, LECT NOTES COMPUT SC, V11861, P187, DOI 10.1007/978-3-030-32692-0_22
   Hinton G. E., 2012, 12070580 ARXIV
   Isensee F, 2019, LECT NOTES COMPUT SC, V11384, P234, DOI 10.1007/978-3-030-11726-9_21
   Juntu J, 2005, ADV SOFT COMP, P543
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Preston DC, 2006, MRI BASICS CASE MED, V30
   Punn NS, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3376922
   Qin Y, 2018, LECT NOTES COMPUT SC, V11072, P603, DOI 10.1007/978-3-030-00931-1_69
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., 2016, ARXIV
   Sibi P., 2013, Journal of Theoretical and Applied Information Technology, V47, P1264
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Ulyanov Dmitry, 2016, arXiv
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Yang H, 2018, INT CONF CIRC SYST S, P267, DOI 10.1109/ICSIGSYS.2018.8372770
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
   Yuan HM, 2019, ELECTR CONTACT, P19, DOI [10.1109/holm.2019.8923871, 10.1109/HOLM.2019.8923871]
   Zhou CH, 2018, LECT NOTES COMPUT SC, V11072, P637, DOI 10.1007/978-3-030-00931-1_73
   Zhou XR, 2017, MED PHYS, V44, P5221, DOI 10.1002/mp.12480
NR 39
TC 26
Z9 28
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30305
EP 30320
DI 10.1007/s11042-020-09271-0
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000548128400004
DA 2024-07-18
ER

PT J
AU Dixit, A
   Bag, S
AF Dixit, Anuja
   Bag, Soumen
TI Utilization of edge operators for localization of copy-move image
   forgery using WLD-HOG features with connected component labeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block-based approach; Copy-move image forgery; Digital image forensics;
   Feature extraction; Passive authentication
ID ALGORITHM
AB One of the most popular image forgery technique is copy-move forgery. In this technique, one or more segments are copied and affixed at different positions within the image. This forgery technique is highly grievous as it can manipulate an image in various ways (such as by presenting additional information or by concealing the genuine information of image). We propose a novel blind forensic technique for copy-move image forgery detection. Our approach utilize different edge detection operators to extract high frequency features. Histogram of Oriented Gradients (HOG) and Weber Local Descriptor (WLD) are used to extract image block features. Radix and lexicographical sorting is enforced over feature vector matrix followed by correlation computation between feature vectors to detect similar feature vectors. Shift vectors are computed to locate similar group of blocks within image. Connected component labeling is applied as morphological operation to remove false matches. Proposed approach is robust to detect plain as well as multiple copy-move forgery in images with post-processing attacks such as contrast adjustment, image blurring, color reduction, and brightness change. Proposed approach achieve highest F-Measure(%) in comparision to other existing forgery detection methods.
C1 [Dixit, Anuja; Bag, Soumen] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Dixit, A (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM anu2010cse1@gmail.com; soumen@iitism.ac.in
RI Dixit, Anuja/K-1857-2017; Dixit, Anuja/HNJ-1955-2023
OI Dixit, Anuja/0000-0002-8649-0463; 
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2010, International Journal on Computer Science and Engineering
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P26503, DOI 10.1007/s11042-016-4179-3
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Dalal N., 2005, P IEEE COMPUTER SOC
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich A.J., P DIGITAL FORENSIC R
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li G., 2007, IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2007.4285009
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Luo W, 2006, IEEE INT C PATT REC, V4, P744
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Myrna A. N., 2008, 2007 International Conference on Computational Intelligence and Multimedia Applications, P371
   Pan XY, 2010, INT CONF ACOUST SPEE, P1706, DOI 10.1109/ICASSP.2010.5495482
   Popescu D.C., 2004, INF TECH TRANS PROCE
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Soni B., 2017, P INT C WAT IM PROC, DOI [10.1145/3150978.3150987, DOI 10.1145/3150978.3150987]
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang H, 2017, MULTIMED TOOLS APPL, V76, P12627, DOI 10.1007/s11042-016-3687-5
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 35
TC 7
Z9 7
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26061
EP 26097
DI 10.1007/s11042-020-09230-9
EA JUL 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547247600003
DA 2024-07-18
ER

PT J
AU Soulami, KB
   Kaabouch, N
   Saidi, MN
   Tamtaoui, A
AF Belhaj Soulami, Khaoula
   Kaabouch, Naima
   Saidi, Mohamed Nabil
   Tamtaoui, Ahmed
TI An evaluation and ranking of evolutionary algorithms in segmenting
   abnormal masses in digital mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammograms; Breast cancer; Mass; Segmentation; Metaheuristics;
   Evolutionary algorithms
ID INVASIVE WEED OPTIMIZATION; GENETIC ALGORITHM
AB Breast cancer is the most common cancer in women worldwide and the second main cause of cancer mortality after lung cancer. Up to now, there still no prevention nor early symptoms of breast cancer. Early detection can decrease significantly the mortality rate as the disease can be treated at an early stage. X-Ray is the current screening method that helps in detecting the most two common abnormalities of the breast, masses and micro-calcifications. However, interpreting mammograms is challenging in dense breasts as the abnormal masses and the normal glandular tissue of the breast have similar characteristics. Recently, the evolutionary algorithms have been widely used in image segmentation. In this paper, we evaluate and compare the performance of six most used evolutionary algorithms, invasive weed optimization (IWO), genetic algorithm (GA), particle swarm optimization (PSO), electromagnetism-like optimization (EMO), ant colony optimization (ACO), and artificial bee colony (ABC) in terms of clustering abnormal masses in the breast, particularly dense and extremely dense breasts. This evaluation is conducted based on quantitative metrics including Cohen's Kappa, correlation, and false positive and false negative rates. The evolutionary algorithms are then ranked based on two multi-criteria decision analysis methods, the Preference Ranking Organization Method for the Enrichment of Evaluations (PROMETHEE) and the Graphical Analysis for Interactive Aid (GAIA).
C1 [Belhaj Soulami, Khaoula; Tamtaoui, Ahmed] Natl Inst Posts & Telecommun INPT, STRS Lab, Rabat, Morocco.
   [Belhaj Soulami, Khaoula; Kaabouch, Naima] Univ North Dakota, Elect Engn Dept, Grand Forks, ND 58202 USA.
   [Saidi, Mohamed Nabil] Natl Inst Stat & Appl Econ INSEA, Lab Informat Syst SI2M, Rabat, Morocco.
C3 University of North Dakota Grand Forks
RP Soulami, KB (corresponding author), Natl Inst Posts & Telecommun INPT, STRS Lab, Rabat, Morocco.; Soulami, KB (corresponding author), Univ North Dakota, Elect Engn Dept, Grand Forks, ND 58202 USA.
EM k.belhajsoulami@gmail.com
CR Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   Alam MN, 2015, ELECTR POW SYST RES, V128, P39, DOI 10.1016/j.epsr.2015.06.018
   Anitha J, 2017, COMPUT METH PROG BIO, V138, P93, DOI 10.1016/j.cmpb.2016.10.026
   [Anonymous], 2019, USF DIGITAL MAMMOGRA
   Babu PH, 2015, PROCEDIA COMPUT SCI, V57, P868, DOI 10.1016/j.procs.2015.07.498
   Berber T, 2013, COMPUT METH PROG BIO, V110, P150, DOI 10.1016/j.cmpb.2012.11.003
   Bozorg-Haddad O, 2017, INVASIVE WEED OPTIMI
   Brans J.P., 1982, Laide a la Decision: Nature, Instruments et perspectives Davenir, P183
   Chowdhury A, 2011, LECT NOTES COMPUT SC, V7077, P105, DOI 10.1007/978-3-642-27242-4_13
   de Sampaio WB Silva, 2015, EXPERT SYSTEMS APPL
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Dorigo M, 1992, OPTIMIZATION LEARNIN, DOI DOI 10.1002/9780470549070
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Erik C, 2013, IMAGE SEGMENTATION U, DOI [10.1007/978-3-642-30504-7_38, DOI 10.1007/978-3-642-30504-7_38]
   Fan Y, 2013, INT CONF INSTR MEAS, P1650, DOI 10.1109/IMCCC.2013.365
   Ferlay, 2013, GLOBOCAN 2012 V10 CA
   Fihri WF, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P823, DOI 10.1109/CCWC.2018.8301616
   Guru KK, 2015, ADV INTELL SYST COMP, V309, P403
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hemeida AM, 2019, INT J INTERACT MULTI, V5, P102, DOI 10.9781/ijimai.2018.09.001
   Hermawanto D., 2013, Genetic Algorithm for Solving Simple Mathematical Equality Problem, P1
   Islam MM, 2013, INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 1: ADVANCES IN AEROSPACE TECHNOLOGY, P1
   Jadoun VK, 2014, INT T ELECT ENERGY S
   Jadoun VK, 2014, ADV ELECT ENG, V2014, P13
   Josiski H, 2014, SCI WORLD J, V2014
   Kaabouch N., 2009, Vis. Data Anal., V7243
   Kaabouch N, 2012, J DIABETES METAB, V3, DOI 10.4172/2155-6156.S5-003
   Kanglin G, 2010, IMAGE SEGMENTATION M, V86, P574, DOI [10.1007/978-3-642-19853-3_85, DOI 10.1007/978-3-642-19853-3_85]
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Karimkashi S, 2010, IEEE T ANTENN PROPAG, V58, P1269, DOI 10.1109/TAP.2010.2041163
   Kashyap KL, 2017, COMPUT BIOL MED, V87, P22, DOI 10.1016/j.compbiomed.2017.05.015
   Kennedy J, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P303, DOI 10.1109/ICEC.1997.592326
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kennedy J., 2001, Swarm Intelligence
   Kuo YC, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P662, DOI 10.1109/IS3C.2014.178
   Langerudi MF, 2014, OPTIMIZATION CONTROL
   Lin WC, 2014, 2014 INT S COMP CONS
   Liu XM, 2015, NEUROCOMPUTING, V152, P388, DOI 10.1016/j.neucom.2014.10.040
   Ma M, 2011, APPL SOFT COMPUT, V11, P5205, DOI 10.1016/j.asoc.2011.05.039
   Malisia A. R., 2006, 3 CAN C COMP ROB VIS, P26, DOI [10.1109/CRV.2006.42, DOI 10.1109/CRV.2006.42]
   Mehrabian AR, 2006, ECOL INFORM, V1, P355, DOI 10.1016/j.ecoinf.2006.07.003
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   Moallem P., 2012, Trends in Applied Sciences Research, V7, P445, DOI 10.3923/tasr.2012.445.455
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Murata T, 1996, COMPUT IND ENG, V30, P1061, DOI 10.1016/0360-8352(96)00053-8
   Neto OPS, 2017, MULTIMED TOOLS APPL, P1573
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Quadri A., 2016, IEEE Ubiquitous Computing, Electronics Mobile Communication Conference, P1
   Quadri A, 2017, IEEE 7 ANN COMP COMM, P1, DOI DOI 10.1109/CCWC.2017.7868388
   Quan H, 2014, NEUROCOMPUT, V127
   Rane VA, 2013, INT J INNOV DEV, V2
   Robinson J, 2004, IEEE T ANTENN PROPAG, V52, P397, DOI 10.1109/TAP.2004.823969
   Rusdi NA, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/8024762
   Sandhya G, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/6783209
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Sivakumar R, 2012, INT J ENG TECHNOLOGY
   Soulami K. B., 2017, 2017 INT C ADV TECHN, P1
   Soulami K. B., 2016, ADV UBIQUITOUS NETWO, P505
   Soulami KB, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P85, DOI [10.1109/eit.2019.8833677, 10.1109/EIT.2019.8833677]
   Soulami KB, 2019, MULTIMED TOOLS APPL, V78, P12835, DOI 10.1007/s11042-018-5934-4
   Taha AA, 2014, IEEE IMAGE PROC, P932, DOI 10.1109/ICIP.2014.7025187
   Wooldridge M, 2000, AUTON AGENT MULTI-AG, V3, P285, DOI 10.1023/A:1010071910869
   Xing B, 2014, Innovative computational intelligence: A rough guide to 134 clever algorithms, V62
   Zhao X, 2008, ALPIT 2008: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, PROCEEDINGS, P210, DOI 10.1109/ALPIT.2008.105
   Zhou Y, 2013, J APPL MATH
   Zhou YQ, 2015, NEUROCOMPUTING, V151, P1227, DOI 10.1016/j.neucom.2014.01.078
   Zhou YQ, 2014, NEUROCOMPUTING, V137, P285, DOI 10.1016/j.neucom.2013.05.063
NR 68
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 18941
EP 18979
DI 10.1007/s11042-019-08449-5
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500004
DA 2024-07-18
ER

PT J
AU Savyan, PV
   Bhanu, SMS
AF Savyan, P. V.
   Bhanu, S. Mary Saira
TI UbCadet: detection of compromised accounts in twitter based on user
   behavioural profiling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network analysis; Anomaly detection; Compromised accounts; Online
   social networks
ID ONLINE SOCIAL NETWORKS; THREATS; SPAM
AB Online Social Networks(OSNs) are generally at the risk of many potential dangers. Malicious attackers use compromised OSN accounts to spread fake news, to send spam messages and to promote malicious applications which in turn lead to substantial financial and reputation loss. The current scenario in the world is that heavily funded and sophisticated criminal groups execute these malicious activities. Numerous Twitter accounts are either fake or compromised as they are victims of these attacks. Detecting these compromised accounts is a challenging task due to various reasons, including the dynamic behaviour of OSN services and its users. A new framework titled User Behaviour Analytics based Compromised Account Detection(UbCadet) proposed in this paper. Some of the significant derived attributes proposed in this work to profile a Twitter user are Similarity of tweet text, Similarity of hashtag, time of tweeting and Geo-location information. In this work, User Behavioural Profile builds with derived attributes of a Twitter user. Based on this user profile, the tweets of each user converts to individual tweet patterns. These patterns are classified as normal or anomalous using k-Nearest Neighbour machine learning algorithm. Additionally, the ensemble method and Random Forest classifier has also experimented for pattern classification. An account classifies as compromised or benign based on the frequency of normal or anomalous tweets from that account. The dataset collected from Yelp, which is a popular crowd-sourced review forum is also used for the experiment in addition to the Twitter dataset, to examine the applicability of the proposed approach in other OSNs. Experimental results show that the proposed UbCadet achieves a high accuracy and reduced false-positive rate.
C1 [Savyan, P. V.] Natl Inst Technol Tiruchirappalli, Tiruchirappalli, Tamil Nadu, India.
   [Bhanu, S. Mary Saira] Natl Inst Technol Tiruchirappalli, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli
RP Savyan, PV (corresponding author), Natl Inst Technol Tiruchirappalli, Tiruchirappalli, Tamil Nadu, India.
EM 406116007@nitt.edu; msb@nitt.edu
RI Bhanu, S. Mary Saira/AAM-3148-2020
OI Bhanu, S. Mary Saira/0000-0001-8509-4461
CR Adewole KS, 2017, J NETW COMPUT APPL, V79, P41, DOI 10.1016/j.jnca.2016.11.030
   Al Hasib A, 2009, INT J COMPUT SCI NET, V9, P288
   Alqatawna J., 2017, Social Media Shaping e-Publishing and Academia, P121, DOI 10.1007/978-3-319-55354-2_10
   Amato F, 2018, COMPUT SECUR, V74, P355, DOI 10.1016/j.cose.2017.06.002
   [Anonymous], 2013, 20 ANN NETW DISTR SY
   [Anonymous], 2007, MULTIPLE CLASSIFIER
   [Anonymous], 2018, BBC
   Authority IR, 2018, COD REPR NAM LANG
   Barbon S, 2016, MULTIMED TOOLS APPL
   Benevenuto Fabricio., 2010, COLL EL MESS ANT SPA, V6, P12
   Bindu PV, 2016, J NETW COMPUT APPL, V68, P213, DOI 10.1016/j.jnca.2016.02.021
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai Z., 2012, PROC NETW DISTRIB SY, P1
   Cao JP, 2017, ADV INTELL SYST, V455, P123, DOI [10.1016/j.ins.2017.02.030, 10.1007/978-3-319-38771-0_12]
   CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164, DOI 10.1007/BFb0017012
   Chandola V., 2009, Anomaly detection for symbolic sequences and time series data
   Cresci S, 2017, IEEE T DEPENDABLE SE
   Egele M, 2017, IEEE T DEPEND SECURE, P1
   Enli G, 2018, INFORM COMMUN SOC, V21, P1081, DOI 10.1080/1369118X.2017.1301515
   Felix R, 2017, J BUS RES, V70, P118, DOI 10.1016/j.jbusres.2016.05.001
   Fire M, 2014, IEEE COMMUN SURV TUT, V16, P2019, DOI 10.1109/COMST.2014.2321628
   Gao Y, 2010, PROCEEDINGS OF THE ELEVENTH WEST LAKE INTERNATIONAL CONFERENCE ON SMALL & MEDIUM BUSINESS, P35
   Gomaa WH., 2013, international journal of Computer Applications, V68, P13, DOI 10.5120/11638-7118
   Grier C, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P27, DOI 10.1145/1866307.1866311
   Howley P, 2017, TECH REP
   Huang A., 2008, Proceedings of the sixth new zealand computer science research student conference (NZCSRSC2008), V4, P9
   Huang HC, 2018, COMPUT HUM BEHAV, V82, P111, DOI 10.1016/j.chb.2018.01.004
   Igawa R. A., 2015, P ANN C BRAZ S INF S, V1, P9
   Igawa RA, 2015, ISYS REV BRASILEIRA, V8, P64
   Kaur R, 2018, J NETW COMPUT APPL, V112, P53, DOI 10.1016/j.jnca.2018.03.015
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lee K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P435, DOI 10.1145/1835449.1835522
   Li Rui., 2012, P 18 ACM SIGKDD INT, P1023
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Luca Michael, 2011, Reviews, reputation, and revenue: The case of Yelp.com (March 15, DOI DOI 10.2139/SSRN.1928601
   Meire M, 2016, DECIS SUPPORT SYST, V89, P98, DOI 10.1016/j.dss.2016.06.013
   Menczer, 2017, SPREAD FAKE NEWS SOC
   Mustafaraj E, 2010, P 2011 5 INT AAAI C
   Nauta M, 2017, WEBIST: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, P19, DOI 10.5220/0006213600190031
   Prasath V, 2017, ARXIV170804321
   Ratkiewicz J, 2011, P 20 INT C COMP WORL
   Ruan X, 2016, IEEE T INF FOREN SEC, V11, P176, DOI 10.1109/TIFS.2015.2482465
   Sadeghian A, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P254, DOI 10.1109/ICICM.2013.50
   Savage D, 2014, SOC NETWORKS, V39, P62, DOI 10.1016/j.socnet.2014.05.002
   Seyler D, 2018, ARXIV180407247
   Shashanka M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1867, DOI 10.1109/BigData.2016.7840805
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Song J, 2011, LECT NOTES COMPUT SC, V6961, P301, DOI 10.1007/978-3-642-23644-0_16
   Srivastav G, 2017, COMPUT HUM BEHAV, V73, P55, DOI 10.1016/j.chb.2017.03.009
   Statista, 2018, NUMB SOC MED US WORL
   Statista I, 2018, LEAD SOC NETW WORLDW
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Turban E., 2017, Electronic Commerce 2018: A Managerial and Social Networks Perspective
   Twitter, 2018, TWEET OBJ
   Twitter, 2019, POSTR ENG TWEETS
   Vandam C, 2018, P IEEE ACM INT C ADV
   VanDam C, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P737, DOI 10.1145/3106426.3106543
   Vaughan P, 2017, 72 PEOPLE WHO COMPLA
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang C, 2011, LECT NOTES COMPUT SC, V6961, P318, DOI 10.1007/978-3-642-23644-0_17
   Yelp, 2019, DOC YELP FUS
   Zafarani Reza, 2014, Social Media Mining, DOI [DOI 10.1017/CBO9781139088510, 10.1017/CBO9781139088510]
NR 65
TC 14
Z9 16
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19349
EP 19385
DI 10.1007/s11042-020-08721-z
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500021
DA 2024-07-18
ER

PT J
AU de Geus, AR
   da Silva, SF
   Gontijo, AB
   Silva, FO
   Batista, MA
   Souza, JR
AF de Geus, Andre R.
   da Silva, Sergio F.
   Gontijo, Alexandre B.
   Silva, Flavio O.
   Batista, Marcos A.
   Souza, Jefferson R.
TI An analysis of timber sections and deep learning for wood species
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wood species classification; Amazon biome; Deep learning; Timber section
   analysis
ID NEURAL-NETWORK; RECOGNITION
AB The wood species classification is an essential field of investigation that can help to combat illegal logging, then providing the timber certification and allowing the application of correct timber taxing. Today, the wood classification relies on highly qualified professionals that analyze texture patterns on timber sections. However, these professionals are scarce, costly, and subject to failure. Therefore, the automation of this task using computational methods is promising. Deep learning has proven to be the ultimate technique in computer vision tasks, but it has not been much exploited to perform timber classification due to the difficulty of building large databases to train such networks. In this study, we introduced the biggest data set of wood timber microscope images to the date, with 281 species, having three types of timber sections: transverse, radial, and tangential. We investigated the use of transfer learning from pre-trained deep neural networks for wood species classification and compared their results with a state-of-art pre-designed feature method. The experimental results show that traverse section images using a densely connected network achieved 98.7% of correct classification against 85.9% of standard pre-designed features.
C1 [de Geus, Andre R.; Silva, Flavio O.; Souza, Jefferson R.] Univ Fed Uberlandia, Fac Comp, Uberlandia, MG, Brazil.
   [da Silva, Sergio F.; Batista, Marcos A.] Fed Univ Catalao, Fac Comp, Catalao, Brazil.
   [Gontijo, Alexandre B.] Brazilian Forest Serv, Forest Prod Lab, Brasilia, DF, Brazil.
C3 Universidade Federal de Uberlandia
RP de Geus, AR (corresponding author), Univ Fed Uberlandia, Fac Comp, Uberlandia, MG, Brazil.
EM geus.andre@gmail.com
RI Gontijo, Alexandre/AAR-5899-2021; Batista, Marcos A./E-1817-2013; Silva,
   Flávio de Oliveira/O-5591-2015
OI Gontijo, Alexandre/0000-0003-2728-0383; Silva, Flávio de
   Oliveira/0000-0001-7051-7396
FU CNPq [400699/2016-8]; CAPES agency; Federal University of Uberlandia;
   Federal University of Catalao
FX The Titan Xp graphics card used in this research was donated by the
   NVIDIA Corporation. This work was supported by the CNPq (Grant
   400699/2016-8), CAPES agency, Federal University of Uberlandia and
   Federal University of Catalao.
CR Barmpoutis P, 2018, COMPUT ELECTRON AGR, V144, P241, DOI 10.1016/j.compag.2017.12.011
   Bouarara HA, 2019, INT J SOFTW SCI COMP, V11, P31, DOI 10.4018/IJSSCI.2019100103
   da Silva NR, 2017, ANN FOREST SCI, V74, DOI 10.1007/s13595-017-0619-0
   Franke B, 2011, J ENG MECH, V137, P186, DOI 10.1061/(ASCE)EM.1943-7889.0000217
   Hafemann LG, 2014, INT C PATT RECOG, P1103, DOI 10.1109/ICPR.2014.199
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu SQ, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P702, DOI 10.1109/CISP.2015.7407968
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   IBRAHIM I, 2017, EUROPEAN J WOOD WOOD
   Ibrahim I, 2017, WOOD SCI TECHNOL, V51, P431, DOI 10.1007/s00226-016-0859-4
   Jing Yi Tou, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P8, DOI 10.1109/ICNC.2009.594
   Jordan R, 1998, ULTRASONICS, V36, P219, DOI 10.1016/S0041-624X(97)00148-0
   Khalid M., 2011, 2011 2nd International Conference on Instrumentation Control and Automation (ICA 2011), P6, DOI 10.1109/ICA.2011.6130117
   Kwon OhKyung Kwon OhKyung, 2017, Mokchae Konghak = Journal of the Korean Wood Science and Technology, V45, P797
   Li YJ, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2913700
   Nisgoski S, 2017, WOOD SCI TECHNOL, V51, P929, DOI 10.1007/s00226-017-0915-8
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Peng Z, 2013, OPTIK, V124, P2833, DOI 10.1016/j.ijleo.2012.08.058
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Sajjadi Mehdi, 2016, Advances in Neural Information Processing Systems, P1163
   Sundaram M, 2015, OPTIK, V126, P2884, DOI 10.1016/j.ijleo.2015.07.044
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wheeler EA, 2011, IAWA J, V32, P199, DOI 10.1163/22941932-90000051
   Yadav AR, 2013, NAT CONF COMPUT VIS
   Yingjie Zhang, 2019, International Journal of High Performance Computing and Networking, V13, P355
   YOSINSKI J, P 27 INT C NEURA INF, P3320
   Zamri MIP, 2016, COMPUT ELECTRON AGR, V124, P227, DOI 10.1016/j.compag.2016.04.004
   Zhao P, 2016, J FORESTRY RES, V27, P219, DOI 10.1007/s11676-015-0171-4
NR 30
TC 14
Z9 17
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34513
EP 34529
DI 10.1007/s11042-020-09212-x
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000543678900002
DA 2024-07-18
ER

PT J
AU Liu, Y
   Jiang, B
   Feng, J
   Hu, JZ
   Zhang, HB
AF Liu, Yang
   Jiang, Bo
   Feng, Jun
   Hu, Jingzhao
   Zhang, Haibo
TI Classification of EEG Signals for Epileptic Seizures Using Feature
   Dimension Reduction Algorithm based on LPP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epilepsy; Wavelet packet decomposition; Manifold learning; LPP; Machine
   learning
ID REPRESENTATION; ENTROPY
AB Computer-aided diagnosis of epilepsy based on Electroencephalography (EEG) analysis is a beneficial practice which adopts machine learning to increase the recognition rate and saves physicians from long hours of EEG inspection. However multi-channel epilepsy EEG signals reflect significant nonlinearity with different degrees of cross-talk among channels, which further leads to high dimensional features extracted from EEG. These shortcomings make the performance of epilepsy detection with machine learning difficult to improve. In order to get fast and accurate detection performance, a feature dimension reduction algorithm based on epilepsy locality preserving projections (E-LPP) is proposed. E-LPP, by preserving the low-dimensional manifold as much as possible, enables to analyze signals of non-linear, non-stationary and high-dimensional nature. To get the best performance, we determine the hyperparameters of E-LPP by grid search. Subsequently a fusion epilepsy detection framework combined feature extraction with E-LPP is proposed to classify whether subjects' seizure onset or not. We test our method on two well-known and widely studied datasets which includes ictal and interictal EEG recordings. The experimental result on recall, precision and F1 is superior to the common traditional dimensionality reduction algorithm, manifold learning algorithm and autoencoder based deep learning, which indicates this proposed method not only makes it possible to solve nonlinearity and cross-talk among channels in EEG, but also tackles the inherent difficulties regarding unbalanced epilepsy data with high metrics.
C1 [Liu, Yang; Jiang, Bo; Feng, Jun; Hu, Jingzhao; Zhang, Haibo] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Feng, Jun] Northwest Univ, Sch Informat Sci & Technol, State Prov Joint Engn & Res Ctr Adv Networking &, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Northwest University Xi'an
RP Zhang, HB (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM zhanghb@nwu.edu.cn
FU National Key Research and Development Program of China [2017YFB1002504];
   National Natural Science Foundation of China [41601353]; National
   Science Foundation for Young Scientists of China [61902317, 61801384];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2020JM-415]; Science and Technology Plan Program in Shaanxi Province of
   China [2019JQ-166]
FX The authors would like to thank the National Key Research and
   Development Program of China under grant No. 2017YFB1002504, National
   Natural Science Foundation of China under grant No. 41601353, National
   Science Foundation for Young Scientists of China under grant No.
   61902317 and 61801384,the Natural Science Basic Research Plan in Shaanxi
   Province of China (2020JM-415), the Science and Technology Plan Program
   in Shaanxi Province of China under Grant (No. 2019JQ-166) for
   supporting.
CR Alakus TB, 2017, 2017 10 INT C EL EL
   Bhati D, 2017, DIGIT SIGNAL PROCESS, V69, P309, DOI 10.1016/j.dsp.2017.07.008
   Bhati D, 2017, DIGIT SIGNAL PROCESS, V62, P259, DOI 10.1016/j.dsp.2016.12.004
   Bhattacharyya A, 2018, DIGIT SIGNAL PROCESS, V78, P185, DOI 10.1016/j.dsp.2018.02.020
   Bhattacharyya A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040385
   Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Birjandtalab J, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P595, DOI 10.1109/BHI.2016.7455968
   Birjandtalab J, 2017, COMPUT BIOL MED, V82, P49, DOI 10.1016/j.compbiomed.2017.01.011
   Chatterjee R, 2016, 2016 2 INT C COMP IN
   Chen JX, 2019, IEEE ACCESS, V7, P44317, DOI 10.1109/ACCESS.2019.2908285
   Ekong U, 2016, NEUROCOMPUTING, V199, P66, DOI 10.1016/j.neucom.2016.03.033
   Fergus P, 2015, BIOMED RES INT, P2015
   Garg HK, 2015, CIRC SYST SIGNAL PR, V34, P2643, DOI 10.1007/s00034-015-9982-y
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gupta S., 2018, 2018 INT JOINT C NEU
   Gupta V, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101569
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Howell E, 2010, SEIZURE-EUR J EPILEP, V19, P628, DOI 10.1016/j.seizure.2010.10.016
   Khanmohammadi S, 2016, LECT NOTES ARTIF INT, V9919, P233, DOI 10.1007/978-3-319-47103-7_23
   Kocadagli O, 2017, EXPERT SYST APPL, V88, P419, DOI 10.1016/j.eswa.2017.07.020
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Lin Q, 2016, LECT NOTES ARTIF INT, V9773, P802, DOI 10.1007/978-3-319-42297-8_74
   Pachori RB, 2015, STUD FUZZ SOFT COMP, V319, P367, DOI 10.1007/978-3-319-12883-2_13
   Qiu Y, 2018, IEEE T NEUR SYS REH, V26, P1717, DOI 10.1109/TNSRE.2018.2864306
   Rajaguru Harikumar, 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P500, DOI 10.1109/CESYS.2017.8321127
   Rejer I, 2013, LECT NOTES COMPUT SC, V8104, P108, DOI 10.1007/978-3-642-40925-7_11
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Saeedi J, 2014, CIRC SYST SIGNAL PR, V33, P2583, DOI 10.1007/s00034-014-9764-y
   Shahbazi M, 2018, IEEE GLOB CONF SIG, P469, DOI 10.1109/GlobalSIP.2018.8646505
   Sharma M, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400036
   Sharma M, 2017, PATTERN RECOGN LETT, V94, P172, DOI 10.1016/j.patrec.2017.03.023
   Sharma R, 2015, EXPERT SYST APPL, V42, P1106, DOI 10.1016/j.eswa.2014.08.030
   Sharma RR, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2018.2882622
   Sharma RR, 2018, IET SCI MEAS TECHNOL, V12, P72, DOI 10.1049/iet-smt.2017.0058
   Smart O, 2015, 2015 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P54
   Smith L.I., 2002, TUTORIAL PRINCIPAL C
   Stickel C, 2009, INT C UN ACC HUM COM
   Tanveer M, 2018, 2018 IEEE S SER COMP
   Tiwari AK, 2017, IEEE J BIOMED HEALTH, V21, P888, DOI 10.1109/JBHI.2016.2589971
   Tzimourta K. D., 2018, INT C BIOMEDICAL HLT, P165
   Verma Nischal K., 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036473
   Wang GJ, 2017, NEUROCOMPUTING, V228, P283, DOI 10.1016/j.neucom.2016.09.080
   Yildiz M., 2015, Balkan Journal of Electrical and Computer Engineering, V3, P236, DOI [10.17694/bajece.22796, DOI 10.17694/BAJECE.22796]
   [游荣义 You Rongyi], 2004, [生物物理学报, Acta Biophysica Sinica], V20, P77
   Zeng M, 2019, IEEE ACCESS, V7, P7889, DOI 10.1109/ACCESS.2019.2890895
NR 47
TC 15
Z9 16
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30261
EP 30282
DI 10.1007/s11042-020-09135-7
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000542539100001
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Zhao, YT
   Xie, J
   Li, C
   Hu, ZB
AF Zhang, Xialin
   Zhao, Yatao
   Xie, Jun
   Li, Chen
   Hu, Zhengbin
TI Geological big data acquisition based on speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Geological big data; Field data collection; Mineral
   resources exploration; Multimedia
ID GOLD DEPOSIT; INFORMATION
AB Geo-Spatial Data, or geospatial data, refer to quantitative measurement data, qualitative descriptions, and graphical image data related to spatial location information that express profound geological connotations. Digital and intelligent collection of field geology data is a basic step in the construction of mineral resources exploration data and plays an important role in the actual process of mineral resources exploration. Conventionally, geological data collection in mineral resource exploration adopts the means of using a traditional field book, which is inefficient and also not conducive to the digitization of data. To address this issue, our paper presents a method and system for field geological data collection based on a speech recognition technique. In the system, the mobile device firstly receives the voice and then recognizes the received voice through the voice recognition technology to obtain the corresponding text information. If a control instruction is received, then the corresponding instruction is generated; otherwise, the data acquisition and storage device performs corresponding actions or stores text information according to the control instruction. The system designed in this paper helps users to use voice to accomplish the data collection. It will automatically convert the input voice into text data and store it in the database. The system is simple and convenient to operate and can overcome the problem of inconvenient operation of the data acquisition device in the field, thereby improving the efficiency of geological data collection in the geological exploration.
C1 [Zhang, Xialin; Zhao, Yatao; Xie, Jun; Li, Chen; Hu, Zhengbin] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Zhang, Xialin] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
   [Zhang, Xialin] Minist Nat Resources China, Innovat Ctr Mineral Resources Explorat Engn Techn, Guiyang 550081, Peoples R China.
C3 China University of Geosciences; China University of Geosciences;
   Ministry of Natural Resources of the People's Republic of China
RP Zhang, XL (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.; Zhang, XL (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.; Zhang, XL (corresponding author), Minist Nat Resources China, Innovat Ctr Mineral Resources Explorat Engn Techn, Guiyang 550081, Peoples R China.
EM zhangxialin@cug.edu.cn; zhaoyt628@163.com; xieyingjun1105@163.com;
   lichen@cug.edu.cn; edoc1991@gmail.com
FU National Natural Science Foundation of China [U1711267]; Guizhou science
   and technology project "Development and application of big data
   management and intelligent processing system for manganese exploration
   and development" [[2017]2951]; China national uranium Co. Ltd. project
   "Digital uranium exploration system"; Geological research project of
   Guizhou Bureau of Geology and mineral resources exploration and
   development "Application of 3D geological modeling and data mining to
   the ultra-large type manganese deposits in northeastern Guizhou";
   Research and Development of Three-Dimensional Prediction System for Gold
   Deposits in Southwest Guizhou Based on Large Geological Data [[2018]07];
   Scientific and Technological Innovation Talents Team of Prediction and
   Evaluation of Manganese Mine Resources in Guizhou Province [[2018]5618]
FX This work was supported by the National Natural Science Foundation of
   China (No.U1711267). Guizhou science and technology project "Development
   and application of big data management and intelligent processing system
   for manganese exploration and development (No. [2017]2951)". China
   national uranium Co. Ltd. project "Digital uranium exploration system".
   Geological research project of Guizhou Bureau of Geology and mineral
   resources exploration and development "Application of 3D geological
   modeling and data mining to the ultra-large type manganese deposits in
   northeastern Guizhou", Research and Development of Three-Dimensional
   Prediction System for Gold Deposits in Southwest Guizhou Based on Large
   Geological Data(No. [2018]07), Scientific and Technological Innovation
   Talents Team of Prediction and Evaluation of Manganese Mine Resources in
   Guizhou Province(No. [2018]5618).
CR Almasi A, 2015, ARAB J GEOSCI, V8, P5935, DOI 10.1007/s12517-014-1625-2
   Darekar RV, 2018, BIOL INSPIR COGN ARC, V23, P35, DOI 10.1016/j.bica.2018.01.002
   Gabr SS, 2015, ORE GEOL REV, V71, P1, DOI 10.1016/j.oregeorev.2015.04.021
   Hameed A, 2016, COMPUTING, V98, P751, DOI 10.1007/s00607-014-0407-8
   Han WM, 2016, FRONT ENG MANAG, V3, P314, DOI 10.15302/J-FEM-2016050
   Jennings B, 2015, J NETW SYST MANAG, V23, P567, DOI 10.1007/s10922-014-9307-7
   Kanisha B, 2018, PERS UBIQUIT COMPUT, V3, P1
   Kweon S, 2014, INT J EPIDEMIOL, V43, P69, DOI 10.1093/ije/dyt228
   Liu D, 2015, J GEOINFORMATION SCI, V31, P121
   Luo CL, 2017, DIGITAL TECHNOLOGY A, V5, P174
   Luo CL, 2016, FUJIAN COMPUTER, V32, P30
   Mohamed AR, 2014, SCIENCE, V4
   Navimipour NJ, 2014, J NETW COMPUT APPL, V41, P389, DOI 10.1016/j.jnca.2013.09.013
   Oh SY, 2014, WIRELESS PERS COMMUN, V79, P2439, DOI 10.1007/s11277-014-1752-9
   Pennisi E, 2015, SCIENCE, V349, P369, DOI 10.1126/science.349.6246.369
   Petitjean F, 2015, IEEE INT C DAT MIN
   Pour AB, 2016, INT ARCH PHOTOGRAMM, V41, P409, DOI 10.5194/isprsarchives-XLI-B8-409-2016
   Qiao Y, 2017, E CHINA SCI TECHNOLO, V1
   Rao JB, 2014, IEEE COMMUN SURV TUT, V16, P154, DOI 10.1109/SURV.2013.042313.00226
   Rashmi S, 2018, HIDDEN MARKOV MODEL, V22, P123
   Saleem M, 2017, 6 INT C INN COMP TEC
   Shouliang Wang, 2014, Applied Mechanics and Materials, V448-453, P3792, DOI 10.4028/www.scientific.net/AMM.448-453.3792
   Wang YX, 2018, ACTA PETROL SIN, V34, P319
   [许金普 Xu Jinpu], 2015, [中国农业科学, Scientia Agricultura Sinica], V48, P449
   Xue JL, 2014, SCI CHINA EARTH SCI, V57, P644, DOI 10.1007/s11430-013-4706-2
   Yamashita M, 2015, EARTH PLANETS SPACE, V67, P1, DOI 10.1186/s40623-015-0214-2
   Yuan LL, 2014, ADV MAT RES, V962-965, P646, DOI [10.4028/www.scientific.net/AMR.962-965.646, DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.962-965.646]
   Zhai YH, 2017, CHINESE J TRADITIONA, V42
   Zhan ZH, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788397
   Zhang Y, 2015, ACTA GEOL SINICA, V88, P1329, DOI [10.1111/1755-6724.12380_54, DOI 10.1111/1755-6724.12380_54]
   Zhu D, 2014, INT S CHIN SPOK LANG
NR 31
TC 2
Z9 3
U1 8
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24413
EP 24428
DI 10.1007/s11042-020-09064-5
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541304000001
DA 2024-07-18
ER

PT J
AU Wang, J
   Wan, WB
AF Wang, Jun
   Wan, Wenbo
TI A novel attention-guided JND Model for improving robust image
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Just noticeable distortion; Visual attention; Logarithmic spread
   transform dither modulation; Gestalt principle; Robust watermarking
ID NOTICEABLE DISTORTION PROFILE; SALIENCY DETECTION; CROWD EVACUATION;
   TRANSFORM
AB Just noticeable distortion (JND) and visual attention (VA), which are two widely used mathematical models of human visual system (HVS) that aim to simulate the human brain mechanism, are sufficiently explored and applied to many researches including digital watermarking. The activity of human brain, however, is extremely complex and it can be more limited due to complicated fusion of spatial saliency for image domain. In this paper, we propose a novel VA guided JND model in which we fuse the final attention map from the low-level features by using two laws of Gestalt principle. Firstly, we demonstrate a classic JND model in DCT domain, which consists of spatial contrast sensitivity function (CSF), luminance adaptation (LA) and contrast masking (CM). The foveation effect and orientation feature are considered to obtain the CSF and CM factor. The foveation effect is affected by spatial attention, and the orientation features are modeled for CM effect together with traditional block texture strength through three direction-based AC coefficients in DCT domain. The attention features are integrated with a novel Gestalt principle-based weighting mechanism for the final block-based VA model, which is then used to modulate JND profiles with two non-linear functions. Finally, the proposed VA-guided JND model is incorporated into a logarithmic spread transform dither modulation (L-STDM) watermarking scheme. Experimental results show that the newly proposed algorithm can achieve good performance in term of robustness and get better visual quality.
C1 [Wang, Jun; Wan, Wenbo] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
C3 Shandong Normal University
RP Wan, WB (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
EM wanwenbo@sdnu.edu.cn
FU Natural Science Foundation of China [61601268, U1736122]; Natural
   Science Foundation for Distinguished Young Scholars of Shandong Province
   [JQ201718]; China Postdoctoral Science Foundation [2017M622261];
   Shandong Provincial Key Research and Development Plan [2017CXGC1504]
FX This work is partially supported by the Natural Science Foundation of
   China (61601268, U1736122), Natural Science Foundation for Distinguished
   Young Scholars of Shandong Province (JQ201718), Project funded by China
   Postdoctoral Science Foundation (2017M622261), and Shandong Provincial
   Key Research and Development Plan (2017CXGC1504).
CR Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Comesaña P, 2011, INT CONF ACOUST SPEE, P1840
   Cox I. J., 2002, Digital Watermarking
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Hadizadeh H, 2016, PATTERN RECOGN LETT, V84, P49, DOI 10.1016/j.patrec.2016.08.011
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Huang YL, 1999, INT CONF ACOUST SPEE, P3013, DOI 10.1109/ICASSP.1999.757475
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li J, 2019, IEEE ACCESS, V7, P41261, DOI 10.1109/ACCESS.2019.2904272
   LI Q, 2006, IEEE WORKSH MULT SIG
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2018, APPL SOFT COMPUT, V68, P360, DOI 10.1016/j.asoc.2018.04.015
   Liu H, 2018, INFORM SCIENCES, V436, P247, DOI 10.1016/j.ins.2018.01.023
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Ma LH, 2010, IEICE T INF SYST, VE93D, P843, DOI 10.1587/transinf.E93.D.843
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Niu YQ, 2013, SIGNAL PROCESS-IMAGE, V28, P917, DOI 10.1016/j.image.2012.07.009
   QIAO L, 2007, IEEE INT C AC
   Stevenson H., 2012, EMERGENCE GESTALT AP
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   WAN W, 2015, IMPROVED SPREAD TRAN, V24
   Wan WB, 2019, IEEE ACCESS, V7, P39826, DOI 10.1109/ACCESS.2019.2906912
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Wan WB, 2015, ELECTRON LETT, V51, P758, DOI 10.1049/el.2014.4329
   Wan W, 2018, STUD SECUR INT AFF, P1
   Wang HR, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/7064131
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu J., 2016, 2016 IEEE Wireless Communications and Networking Conference, P1, DOI DOI 10.1109/WCNC.2016.7565160
   Xing SN, 2019, NEUROCOMPUTING, V332, P417, DOI 10.1016/j.neucom.2018.12.027
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zong JX, 2017, KSII T INTERNET INF, V11, P3935, DOI 10.3837/tiis.2017.08.010
NR 39
TC 14
Z9 14
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24057
EP 24073
DI 10.1007/s11042-020-09102-2
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100004
DA 2024-07-18
ER

PT J
AU Gasparini, F
   Giltri, M
   Bandini, S
AF Gasparini, Francesca
   Giltri, Marta
   Bandini, Stefania
TI Discriminating affective state intensity using physiological responses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physiological responses; Affective state; Relaxation; Stressful state;
   Audio stimuli; Cognitive load
ID STRESS; EMOTIONS; STATISTICS; DATABASE; SIGNALS
AB In this paper we explore if physiological signals obtained from a person through wearable sensors permit the correct interpretation of human affective states. A crucial aspect within this field of research is the capability of inducingreal-lifeemotions in laboratory environments. To this end we designed a very strict and regulated experimental protocol. We consider two affective states: a relaxation state and a stressful one. To induce these two states we adopt audio tracks of natural or day-life sounds and math calculations. Moreover, to study different intensities of effectively induced relaxation, we consider two different audio players: a traditional pair of headphones and the Spherison Sound6D pillow & x24b8;, a special device that provides a complete spherical immersion in what users are listening to. We consider as physiological signals the Galvanic Skin Response (GSR) and the Photoplethysmography (PPG), as they are sensitive measures for emotional arousal. After an extensive analysis on our experimental data, we demonstrate that GSR and PPG signals can successfully distinguish relaxation and stressful states. Moreover, the same physiological signals can discriminate affective state intensity, especially when relaxation is induced adopting the Sound6D technology.
C1 [Gasparini, Francesca; Giltri, Marta; Bandini, Stefania] Univ Milano Bicocca, Dipartimento Informat, Milan, Italy.
   [Bandini, Stefania] Univ Tokyo, RCAST Res Ctr Adv Sci & Technol, Tokyo, Japan.
C3 University of Milano-Bicocca; University of Tokyo
RP Gasparini, F (corresponding author), Univ Milano Bicocca, Dipartimento Informat, Milan, Italy.
EM francesca.gasparini@unimib.it; m.giltri@campus.unimib.it;
   stefania.bandini@unimib.it
RI Gasparini, Francesca/AAI-5408-2021; Bandini, Stefania/AAC-2376-2022
OI Gasparini, Francesca/0000-0002-6279-6660; Bandini,
   Stefania/0000-0002-7056-0543
FU FONDAZIONE CARIPLO "LONGEVICITY-Social Inclusion for a Elderly through
   Walkability" [2017-0938]
FX This research is supported by the FONDAZIONE CARIPLO "LONGEVICITY-Social
   Inclusion for a Elderly through Walkability" (Rif. 2017-0938). We want
   to give our thanks to Eleonora Pizzi, a master student at the University
   of Milano-Bicocca, for her supporting work during the experimentation.
CR Abadi MK, 2015, IEEE T AFFECT COMPUT, V6, P209, DOI 10.1109/TAFFC.2015.2392932
   Alvarsson JJ, 2010, INT J ENV RES PUB HE, V7, P1036, DOI 10.3390/ijerph7031036
   [Anonymous], 2015, J LIT ART STUD
   [Anonymous], 2014, P 16 INT C MULT INT, DOI [10.1145/ 2663204.2663257, DOI 10.1145/2663204.2663257, 10.1145/2663204.2663257]
   Bandini S, 2020, P 5 IT WORKSH ART IN, V2559, P1
   Bandini S, 2019, LECT NOTES COMPUT SC, V11938, P335, DOI 10.1007/978-3-030-34770-3_28
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bradley MM., 2007, Technical report B-3
   Burns A, 2010, IEEE ENG MED BIO, P3759, DOI 10.1109/IEMBS.2010.5627535
   Can YS, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103139
   Chen LL, 2017, EXPERT SYST APPL, V85, P279, DOI 10.1016/j.eswa.2017.01.040
   Chiu MC, 2017, MULTIMED TOOLS APPL, V76, P15607, DOI 10.1007/s11042-016-3860-x
   Chung J, 2006, IASTED INT CONF SIGN, P393
   CLIFF N, 1993, PSYCHOL BULL, V114, P494, DOI 10.1037/0033-2909.114.3.494
   Clynes M, 1977, SENTICS TOUCH EMOTIO
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   Dey N, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0921-x
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Girardi D, 2017, INT CONF AFFECT, P125, DOI 10.1109/ACII.2017.8273589
   Guess H., 2017, ALZHEIMERS DIS IMPAC
   Hakimi N, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.11.115001
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Hernandez J, 2011, LECT NOTES COMPUT SC, V6974, P125, DOI 10.1007/978-3-642-24600-5_16
   Hernando-Gallego F., 2015, ARXIV150703482
   Honig F., 2007, P DOCTORAL CONSORTIU, P28
   Hu WL, 2015, PROCEDIA COMPUT SCI, V51, P1643, DOI 10.1016/j.procs.2015.05.298
   Janssen JH, 2012, USER MODEL USER-ADAP, V22, P255, DOI 10.1007/s11257-011-9107-7
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   Marchewka A, 2014, BEHAV RES METHODS, V46, P596, DOI 10.3758/s13428-013-0379-1
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Nardelli M, 2015, IEEE T AFFECT COMPUT, V6, P385, DOI 10.1109/TAFFC.2015.2432810
   Nasoz F., 2004, Cognition, Technology & Work, V6, P4, DOI 10.1007/s10111-003-0143-x
   Patrao B, 2016, INT J ONLINE ENG, V12, P37, DOI 10.3991/ijoe.v12i04.5098
   Picard R. W., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P829
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Plutchik R., 1980, Theories of Emotion, P3, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Quiroz JC, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10153
   Raglio A, 2015, FRONT NEUROL, V6, DOI 10.3389/fneur.2015.00185
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saibene A, 2019, COGNITIVE PHYSL RESP, V11938
   Sano A, 2013, INT CONF AFFECT, P671, DOI 10.1109/ACII.2013.117
   Sarsenbayeva Zhanna, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314411
   Serrano J. P. D., 2018, 2018 IEEE 10 INT C H, P1
   Setz C, 2010, IEEE T INF TECHNOL B, V14, P410, DOI 10.1109/TITB.2009.2036164
   Sriamprakash S, 2017, PROCEDIA COMPUT SCI, V115, P359, DOI 10.1016/j.procs.2017.09.090
   Subhani AR, 2018, COGN NEURODYNAMICS, V12, P1, DOI 10.1007/s11571-017-9460-2
   Subramanian Ramanathan, 2018, IEEE Transactions on Affective Computing, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Trochidis K., 2015, INT S COMP MUS MULT, P346
   Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101
   Wagner J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P941
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Wohlin C., 2012, Experimentation in Software Engineering
   Zangróniz R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102324
   Zubair M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101736
NR 55
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35845
EP 35865
DI 10.1007/s11042-020-09114-y
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000539939100002
DA 2024-07-18
ER

PT J
AU Lakra, M
   Kumar, S
AF Lakra, Mahima
   Kumar, Sanjeev
TI A CNN-based computational algorithm for nonlinear image diffusion
   problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Additive Gaussian noise; Cellular neural network; Edge preserving
   filters; Image denoising; Nonlinear diffusion
ID CELLULAR NEURAL-NETWORKS; ANISOTROPIC DIFFUSION; EDGE-DETECTION;
   EQUATION; SPACE
AB In the past, several partial differential equations (PDEs) based methods have been widely studied in image denoising. While solving these methods numerically, some parameters need to be chosen manually. This paper proposes a cellular neural network (CNN) based computational scheme for solving the nonlinear diffusion equation modeled for removing additive noise of digital images. The diffusion acts like smoothing on the noisy image, which is taken as an initial condition for the nonlinear PDE. In the proposed scheme, the template matrices of CNN evolve during the iterative diffusion and act as edge-preserving filters on the noisy images. The evolving diffusion ensures convergence of the diffusion process after a specific diffusion time. Therefore, the advantages of such a CNN-based solution scheme are more accurate restoration in terms of image quality with low computation and memory requirements. The experimental results show the effectiveness of the proposed algorithm on different sets of benchmark images degraded with additive noise.
C1 [Lakra, Mahima; Kumar, Sanjeev] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Lakra, M (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM mahima@ma.iitr.ac.in; malikfma@iitr.ac.in
RI Kumar, Sanjeev/JTV-5459-2023; Kumar, Sanjeev/HKN-6866-2023
OI Kumar, Sanjeev/0000-0001-7728-3668
FU University Grant Commision (UGC) [F.16-6(Dec.2016)/2017(NET)]
FX One of the authors Mahima is thankful the support of University Grant
   Commision (UGC) during her Ph.D through sanction order no.
   F.16-6(Dec.2016)/2017(NET).
CR [Anonymous], 2012, Cellular neural networks: chaos, complexity and VLSI processing
   [Anonymous], 1982, Digital Picture Processing
   [Anonymous], 1998, ANISOTROPIC DIFFUSIO
   Bai J, 2018, Journal of Financial Research, V10, P1
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chedjou JC, 2015, IEEE T NEUR NET LEAR, V26, P749, DOI 10.1109/TNNLS.2014.2323218
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1273, DOI 10.1109/31.7601
   CHUA LO, 1992, INT J CIRC THEOR APP, V20, P497, DOI 10.1002/cta.4490200506
   Corinto F, 2006, INT J CIRC THEOR APP, V34, P77, DOI 10.1002/cta.343
   CROUNSE KR, 1995, IEEE T CIRCUITS-I, V42, P583, DOI 10.1109/81.473566
   Gai S, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.032
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hu G, 2018, J SCI TECHNOL, V40, P506
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Lee CC, 1996, IEEE T NEURAL NETWOR, V7, P1086, DOI 10.1109/72.536306
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Liu Y., 2018, ARXIV180402864
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Maleki A, 2013, APPL COMPUT HARMON A, V35, P452, DOI 10.1016/j.acha.2012.11.003
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mukhopadhyay S, 2013, PROC TECH, V10, P680, DOI 10.1016/j.protcy.2013.12.410
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Nixon M., 2019, FEATURE EXTRACTION I, DOI 10.1016/C2011-0-06935-1
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PIVKA L, 1994, J FRANKLIN I, V331B, P705, DOI 10.1016/0016-0032(94)90087-6
   Puffer F., 1995, Proceedings 1995 URSI International Symposium on Signals, Systems, and Electronics. ISSSE '95. (Cat. No.95TH8047), P501, DOI 10.1109/ISSSE.1995.498041
   Roska T, 2003, J CIRCUIT SYST COMP, V12, P377, DOI 10.1142/S0218126603000921
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Slavova A., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P226, DOI 10.1109/ECCTD.2011.6043323
   Soltanayev S, 2018, ADV NEUR IN, V31
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Xu Y, 2017, PATTERN ANAL APPL, V20, P579, DOI 10.1007/s10044-016-0590-7
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 42
TC 6
Z9 7
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23887
EP 23908
DI 10.1007/s11042-020-09077-0
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540205200001
DA 2024-07-18
ER

PT J
AU Zou, GF
   Fu, GX
   Gao, ML
   Pan, JF
   Liu, Z
AF Zou, Guofeng
   Fu, Guixia
   Gao, Mingliang
   Pan, Jinfeng
   Liu, Zheng
TI A new approach for small sample face recognition with pose variation by
   fusing Gabor encoding features and deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-feature fusion; Data augmentation; Gabor encoding feature; Small
   scale adaptive deep CNN; Small sample problem; Pose-varied face
   recognition
ID CONVOLUTIONAL NEURAL-NETWORK; SPACE; REPRESENTATION
AB Small sample and pose variation are two critical technical problems in automatic face recognition (AFR). The combination of these two difficulties will seriously affect the performance of face recognition and restrict the wide application of AFR. To address this problem, we propose a new multi-feature fusion framework. First, we propose a pixel-level data augmentation algorithm based on manifold subspace partition, which constructs virtual samples in the original face image space to achieve training sample expansion and diversity enhancement. Then, we propose a feature-level data augmentation based on Gabor transformation, which can capture multi-level face features through multi-scale and multi-direction Gabor filters to realize the face expansion in feature space. To eliminate the data redundancy and interference information generated by Gabor feature augmentation, a Gabor feature encoding algorithm is proposed to construct the compressed Gabor feature vector. In addition, we propose a small scale adaptive deep CNN model, which is suitable for small sample datasets and can effectively extract nonlinear deep features of pose-varied faces. Finally, Gabor encoding features and nonlinear deep features are combined for small sample face recognition with pose variation. Experiment results based on two face datasets prove the effectiveness of the proposed multi-feature fusion framework.
C1 [Zou, Guofeng; Fu, Guixia; Gao, Mingliang; Pan, Jinfeng] Shandong Univ Technol, Coll Elect & Elect Engn, Zibo 255049, Peoples R China.
   [Liu, Zheng] Univ British Columbia, Sch Engn, Kelowna, BC V1V 1V7, Canada.
C3 Shandong University of Technology; University of British Columbia
RP Zou, GF (corresponding author), Shandong Univ Technol, Coll Elect & Elect Engn, Zibo 255049, Peoples R China.
EM gfzou@sdut.edu.cn
RI Gao, Mingliang/AEK-9687-2022; Liu, Zheng/D-8678-2016
OI Liu, Zheng/0000-0002-7241-3483; Zou, Guofeng/0000-0002-8023-0142
FU Visiting Project Funds of Shandong University of Technology; National
   Natural Science Foundation of China [61601266, 61801272]; Natural
   Science Foundation of Shandong Province of China [ZR2015FL029,
   ZR2016FL14]; Integration Funds of Shandong University of Technology and
   Zhangdian District [118228]
FX This research was funded by the Visiting Project Funds of Shandong
   University of Technology, the Integration Funds of Shandong University
   of Technology and Zhangdian District (No.118228), the National Natural
   Science Foundation of China (No. 61601266, No.61801272), the Natural
   Science Foundation of Shandong Province of China (No. ZR2015FL029,
   ZR2016FL14).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [叶长明 Ye Changming], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P219
   [Anonymous], ARXIVHEPTH150607310
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Cao B., 2018, IEEE T GEOSCI REMOTE, P1
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   [陈华杰 CHEN Huajie], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P1254
   Chen Y, 2016, OPTIK, V127, P946, DOI 10.1016/j.ijleo.2015.10.179
   Choe J, 2017, IEEE INT CONF COMP V, P1940, DOI 10.1109/ICCVW.2017.229
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   De Marsico M, 2013, IEEE T SYST MAN CY-S, V43, P149, DOI 10.1109/TSMCA.2012.2192427
   Deng CH, 2019, INT CONF CYBER DIST, P1, DOI 10.1109/CyberC.2019.00011
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   [杜成 Du Cheng], 2004, [光电子·激光, Journal of Optoelectronics·Laser], V15, P1498
   [黄凯奇 Huang Kaiqi], 2015, [计算机学报, Chinese Journal of Computers], V38, P1093
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leng B, 2017, NEUROCOMPUTING, V235, P10, DOI 10.1016/j.neucom.2016.12.013
   Li L, 2018, NEURAL PROCESS LETT, V47, P1197, DOI 10.1007/s11063-017-9693-4
   Liang Shu-Fen, 2014, Journal on Communications, V35, P154, DOI 10.3969/j.issn.1000-436x.2014.06.020
   Liang W., 2018, M2M GAN MANY TO MANY
   Lin ZX, 2009, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON AUTONOMOUS ROBOTS AND AGENTS, P185
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Lv JJ, 2017, NEUROCOMPUTING, V230, P184, DOI 10.1016/j.neucom.2016.12.025
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Masi I, 2019, IEEE T PATTERN ANAL, V41, P379, DOI 10.1109/TPAMI.2018.2792452
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Moon HM, 2017, SOFT COMPUT, V21, P4995, DOI 10.1007/s00500-016-2095-0
   Ng A, 2011, LECT NOTES STANFORD, V72, P1
   Nie G., 2019, 2019 IEEE INT C COMP, P3283
   Oh BS, 2018, IEEE T IMAGE PROCESS, V27, P2791, DOI 10.1109/TIP.2018.2809040
   PETKOV N, 1995, FUTURE GENER COMP SY, V11, P451, DOI 10.1016/0167-739X(95)00015-K
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   QIN HW, 2016, PROC CVPR IEEE, P3456, DOI DOI 10.1109/CVPR.2016.376
   Sharma A, 2012, COMPUT VIS IMAGE UND, V116, P1095, DOI 10.1016/j.cviu.2012.08.001
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   [王科俊 Wang Kejun], 2013, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V25, P865
   [王科俊 Wang KeJun], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P50
   Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955
   Xiao C, 2016, APPL RES COMPUTERS, V33, P2519
   Yin Bao-cai, 2007, Journal of Beijing University of Technology, V33, P320
   Yin X., 2019, P IEEE COMP VIS PATT
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Zhang HC, 2012, PATTERN RECOGN, V45, P1290, DOI 10.1016/j.patcog.2011.09.009
   Zhang YN, 2012, PATTERN RECOGN LETT, V33, P530, DOI 10.1016/j.patrec.2011.12.006
   Zhang YY, 2016, NEURAL PROCESS LETT, V43, P389, DOI 10.1007/s11063-015-9420-y
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235
   [赵振华 Zhao Zhenhua], 2013, [电子与信息学报, Journal of Electronics & Information Technology], V35, P463
   Zou GF, 2019, MULTIMED TOOLS APPL, V78, P6969, DOI 10.1007/s11042-018-6449-8
   [邹国锋 Zou Guofeng], 2017, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V40, P98
   [邹国锋 Zou Guofeng], 2015, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V28, P613
NR 54
TC 10
Z9 11
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23571
EP 23598
DI 10.1007/s11042-020-09076-1
EA JUN 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539889900003
DA 2024-07-18
ER

PT J
AU Chang, TY
   Tsai, CJ
   Yeh, JY
   Peng, CC
   Chen, PH
AF Chang, Ting-Yi
   Tsai, Cheng-Jung
   Yeh, Jen-Yuan
   Peng, Chun-Cheng
   Chen, Pei-Hsuan
TI New soft biometrics for limited resource in keystroke dynamics
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hard biometrics; Soft biometrics; Keystroke dynamics; Limited resource;
   Data mining
ID USER AUTHENTICATION; SYSTEM; FEATURES; SECURITY; STANDARD
AB In recent years, some researches on free text authentication by keystroke dynamics have been proposed. The main problem of these proposed researches is the requirement of a very long training time. To increase users' willingness to use the proposed authentication system, one simple and feasible way is shortening the training time. In this case, the training data is limited and is known as the limited resource problem. In this paper, we propose new soft biometrics and a new classifier for limited resources in free text authentication in English. Our new soft biometrics combines the idea of data mining and statistical prediction. Because our soft biometric is a mining result of limited resources, it is sensitive to outliers and a traditional statistical classifier cannot be applied. To solve this problem, the proposed classifiers considered the problem of an outlier and calculated the difference of cluster distribution. There are 114 participants in our experiments. Experimental results show that our approach can improve the accuracy of free text authentication in the case of limited resources.
C1 [Chang, Ting-Yi] Natl Changhua Univ Educ, Dept Ind Educ & Technol, Changhua, Taiwan.
   [Tsai, Cheng-Jung; Chen, Pei-Hsuan] Natl Changhua Univ Educ, Grad Inst Stat & Informat Sci, Changhua, Taiwan.
   [Yeh, Jen-Yuan] Natl Museum Nat Sci, Dept Operat Visitor Serv Collect & Informat Manag, Taichung, Taiwan.
   [Peng, Chun-Cheng] Chaoyang Univ Technol, Dept Informat & Commun Engn, Taichung, Taiwan.
C3 National Changhua University of Education; National Changhua University
   of Education; Chaoyang University of Technology
RP Tsai, CJ (corresponding author), Natl Changhua Univ Educ, Grad Inst Stat & Informat Sci, Changhua, Taiwan.
EM cjtsai@cc.ncue.edu.tw
FU Ministry of Science and Technology of Republic of China; MOST
   [107-2622-E-018 -002 -CC3, MOST 107-2221-E-018 -015, MOST
   108-2622-E-018-002 -CC3, MOST 109-2622-E-018 -002 -CC3]
FX This research was partially supported by the Ministry of Science and
   Technology of Republic of China under Grant Nos. MOST 107-2622-E-018
   -002 -CC3, MOST 107-2221-E-018 -015, MOST 108-2622-E-018-002 -CC3, and
   MOST 109-2622-E-018 -002 -CC3.
CR Ahmed AA, 2014, IEEE T CYBERNETICS, V44, P458, DOI 10.1109/TCYB.2013.2257745
   Ailisto H, 2006, PATTERN RECOGN LETT, V27, P325, DOI 10.1016/j.patrec.2005.08.018
   Alpar O, 2017, KNOWL-BASED SYST, V116, P163, DOI 10.1016/j.knosys.2016.11.006
   Alsultan A, 2018, APPL SOFT COMPUT, V70, P1024, DOI 10.1016/j.asoc.2017.11.018
   Alsultan A, 2017, PATTERN RECOGN LETT, V89, P53, DOI 10.1016/j.patrec.2017.02.010
   Alsultan A, 2016, IET BIOMETRICS, V5, P164, DOI 10.1049/iet-bmt.2015.0101
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   [Anonymous], 2012, P 2012 INT C CYB WAR, DOI DOI 10.1109/CYBERSEC.2012.6246096
   Araújo LCF, 2005, IEEE T SIGNAL PROCES, V53, P851, DOI 10.1109/TSP.2004.839903
   Bergadano F., 2003, Intelligent Data Analysis, V7, P469
   Bertillon A., 1896, Signaletic Instructions Including the Theory and Practice of Anthropometrical Identification
   Bhatia Aparna, 2018, J MODERN PHYS, V09, P112, DOI [10.4236/jmp.2018.92008, DOI 10.4236/JMP.2018.92008]
   Boechat GC, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P254
   Chang TY, 2016, SECUR COMMUN NETW, V9, P2674, DOI 10.1002/sec.1265
   Chang TY, 2012, J SYST SOFTWARE, V85, P1157, DOI 10.1016/j.jss.2011.12.044
   Chernick M. R., 2007, Bootstrap Methods: A Guide for Practitioners and Researchers, P225
   Choras M, 2007, LECT NOTES COMPUT SC, V4432, P424
   Collins JC, 2019, J ACCOUNTANCY, V227, P66
   Davoudi H., 2009, 2009 14th International CSI Computer Conference (CSICC 2009) (Postponed from July 2009), P570, DOI 10.1109/CSICC.2009.5349640
   El-Abed M, 2010, INT CARN CONF SECU, P170, DOI 10.1109/CCST.2010.5678678
   Gaines R. Stockton, 1980, RANDR2526NSF RAND CO
   Giot Romain, 2012, International Journal of Information Technology and Management, V11, P35, DOI 10.1504/IJITM.2012.044062
   Giot R, 2011, COMPUT SECUR, V30, P427, DOI 10.1016/j.cose.2011.03.004
   Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791
   Gunetti D., 2005, ACM Transactions on Information and Systems Security, V8, P312, DOI 10.1145/1085126.1085129
   Han J, 2012, MOR KAUF D, P1
   Hu J, 2008, IEEE ICC, P1556, DOI 10.1109/ICC.2008.301
   Itkis G, 2015, IEEE SIGNAL PROC MAG, V32, P42, DOI 10.1109/MSP.2015.2439717
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kambourakis G, 2016, SECUR COMMUN NETW, V9, P542, DOI 10.1002/sec.1061
   Kang P, 2015, INFORM SCIENCES, V308, P72, DOI 10.1016/j.ins.2014.08.070
   Kang P, 2015, J SYST SOFTWARE, V102, P1, DOI 10.1016/j.jss.2014.12.017
   Kim J, 2018, APPL SOFT COMPUT, V62, P1077, DOI 10.1016/j.asoc.2017.09.045
   Kolakowska A, 2018, ADV INTELL SYST, V551, P42, DOI 10.1007/978-3-319-62120-3_4
   Liu CL, 2015, J NETW COMPUT APPL, V53, P128, DOI 10.1016/j.jnca.2015.03.006
   Liu CL, 2012, J INTERNET TECHNOL, V13, P439
   Matyas SM, 2000, COMPUT SECUR, V19, P428, DOI 10.1016/S0167-4048(00)05029-X
   Messerman Arik., 2011, BIOMETRICS IJCB 2011, P1, DOI [DOI 10.1109/IJCB.2011.6117552, 10.1109/IJCB.2011.6117552]
   Mondal S, 2017, NEUROCOMPUTING, V230, P1, DOI 10.1016/j.neucom.2016.11.031
   Monrose F., 2002, International Journal of Information Security, V1, P69, DOI 10.1007/s102070100006
   Monrose F, 2000, FUTURE GENER COMP SY, V16, P351, DOI 10.1016/S0167-739X(99)00059-X
   Monrose F., 1997, Proc. 4th ACM Conf. Comput. Commun. Secur.-CCS, P48, DOI 10.1145/266420.266434
   Pisani PH, 2015, APPL SOFT COMPUT, V34, P178, DOI 10.1016/j.asoc.2015.05.008
   Samura Toshiharu, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3166
   Sicari S, 2015, COMPUT NETW, V76, P146, DOI 10.1016/j.comnet.2014.11.008
   Sulong A, 2009, CSPA: 2009 5TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, P151, DOI 10.1109/CSPA.2009.5069206
   Sunghoon Park, 2010, 2010 Second International Conference on Communication Systems, Networks and Applications (ICCSNA 2010), P433, DOI 10.1109/ICCSNA.2010.5588979
   Tappert CC, 2010, INT J INF SECUR PRIV, V4, P32, DOI 10.4018/jisp.2010010103
   Tasia CJ, 2014, SECUR COMMUN NETW, V7, P750, DOI 10.1002/sec.776
   Ting-Yi Chang, 2010, Information Management & Computer Security, V18, P72, DOI 10.1108/09685221011048328
   Tsai CJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107067
   Tsai CJ, 2019, APPL SOFT COMPUT, V80, P125, DOI 10.1016/j.asoc.2019.03.033
   Tsai CJ, 2012, INT J INNOV COMPUT I, V8, P7875
   Villani M., 2006, P 2006 C COMPUTER VI, P39
   Yin XF, 2021, IEEE T PATTERN ANAL, V43, P1085, DOI 10.1109/TPAMI.2019.2949299
NR 56
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23295
EP 23324
DI 10.1007/s11042-020-09042-x
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977700005
OA Bronze
DA 2024-07-18
ER

PT J
AU Nawaz, H
   Maqsood, M
   Afzal, S
   Aadil, F
   Mehmood, I
   Rho, S
AF Nawaz, Hina
   Maqsood, Muazzam
   Afzal, Sitara
   Aadil, Farhan
   Mehmood, Irfan
   Rho, Seungmin
TI A deep feature-based real-time system for Alzheimer disease stage
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer stage detection; Dementia; CNN; AlexNet; Deep features
ID FEATURE-RANKING; CLASSIFICATION; DIAGNOSIS; IMAGES
AB The origin of dementia can be largely attributed to Alzheimer's disease (AD). The progressive nature of AD causes the brain cell deterioration that eventfully leads to physical dependency and mental disability which hinders a person's normal life. A computer-aided diagnostic system is required that can aid physicians in diagnosing AD in real-time. The AD stages classification remains an important research area. To extract the deep-features, the traditional machine learning-based and deep learning-based methods often require large dataset and that leads to class imbalance and overfitting issues. To overcome this problem, the use an efficient transfer learning architecture to extract deep features which are further used for AD stage classification. In this study, an Alzheimer's stage detection system is proposed based on deep features using a pre-trained AlexNet model, by transferring the initial layers from pre-trained AlexNet model and extract the deep features from the Convolutional Neural Network (CNN). For the classification of extracted deep-features, we have used the widely used machine learning algorithms including support vector machine (SVM), k-nearest neighbor (KNN), and Random Forest (RF). The evaluation results of the proposed scheme show that a deep feature-based model outperformed handcrafted and deep learning method with 99.21% accuracy. The proposed model also outperforms existing state-of-the-art methods.
C1 [Nawaz, Hina; Maqsood, Muazzam; Afzal, Sitara; Aadil, Farhan] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock, Pakistan.
   [Mehmood, Irfan] Univ Bradford, Dept Media Design & Technol, Fac Engn & Informat, Bradford, W Yorkshire, England.
   [Rho, Seungmin] Sejong Univ, Dept Software, Seoul 05006, South Korea.
C3 COMSATS University Islamabad (CUI); University of Bradford; Sejong
   University
RP Maqsood, M (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock, Pakistan.
EM muazzam.maqsood@cuiatk.edu.pk
RI Aadil, Farhan/I-4043-2013; Maqsood, Muazzam/AAW-1539-2021; Rho,
   Seungmin/HTP-6683-2023; Afzal, Sitara/AAM-4140-2021; Maqsood,
   Muazzam/ABE-1733-2021
OI Aadil, Farhan/0000-0001-8737-2154; Maqsood, Muazzam/0000-0002-2709-0849
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1F1A1060668]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT)
   (NRF-2019R1F1A1060668).
CR Afzal S, 2019, IEEE ACCESS, V7, P115528, DOI 10.1109/ACCESS.2019.2932786
   Alkabawi EM, 2017, IEEE INT SYM MED MEA, P45, DOI 10.1109/MeMeA.2017.7985847
   Altaf T., 2017, IEEE FUT TECHN C
   Altaf T, 2018, BIOMED SIGNAL PROCES, V43, P64, DOI 10.1016/j.bspc.2018.02.019
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Beheshti I, 2017, COMPUT BIOL MED, V83, P109, DOI 10.1016/j.compbiomed.2017.02.011
   Beheshti I, 2016, MAGN RESON IMAGING, V34, P252, DOI 10.1016/j.mri.2015.11.009
   Belleville S, 2014, J ALZHEIMERS DIS, V42, pS375, DOI 10.3233/JAD-141470
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Chincarini A, 2011, NEUROIMAGE, V58, P469, DOI 10.1016/j.neuroimage.2011.05.083
   Chitradevi D, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105857
   Choi H, 2018, BEHAV BRAIN RES, V344, P103, DOI 10.1016/j.bbr.2018.02.017
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farouk Y, 2018, INT CONF INFORM COMM, P133, DOI 10.1109/IACS.2018.8355455
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Guerrero R, 2014, NEUROIMAGE, V94, P275, DOI 10.1016/j.neuroimage.2014.03.036
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   Hao XK, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101625
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027
   LIU Y, 2004, INT C MED IM COMP CO
   Mishra S, 2017, BIOMED SIGNAL PROCES, V33, P272, DOI 10.1016/j.bspc.2016.11.021
   Nanni L, 2016, PATTERN RECOGN LETT, V84, P259, DOI 10.1016/j.patrec.2016.10.010
   Park C, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112873
   Plocharski M, 2016, COMPUT METH PROG BIO, V133, P35, DOI 10.1016/j.cmpb.2016.05.009
   Ramaniharan AK, 2016, EXPERT SYST APPL, V59, P208, DOI 10.1016/j.eswa.2016.04.029
   Sarraf S, 2016, DEEPAD ALZHEIMERS DI, DOI DOI 10.1101/070441
   SHI YQ, 2012, 10 INT WORKSH IWDW 2, V7128
   Shikalgar Arifa, 2020, Computing in Engineering and Technology. Proceedings of ICCET 2019. Advances in Intelligent Systems and Computing (AISC 1025), P511, DOI 10.1007/978-981-32-9515-5_49
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Westman E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022506
NR 36
TC 49
Z9 50
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35789
EP 35807
DI 10.1007/s11042-020-09087-y
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000538977700006
DA 2024-07-18
ER

PT J
AU Hu, HD
   Pun, CM
   Liu, Y
   Lai, XJ
   Yang, ZY
   Gao, H
AF Hu, Haidong
   Pun, Chi-Man
   Liu, Ye
   Lai, Xiangjing
   Yang, Zeyu
   Gao, Hao
TI An artificial bee algorithm with a leading group and its application
   into image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; Artificial bee colony; Logistic chaotic; Convergence
   rate; Mutual information
ID COLONY ALGORITHM; DIFFERENTIAL EVOLUTION; GLOBAL OPTIMIZATION
AB A popular optimization algorithm, the artificial bee colony algorithm (ABC), has attracted great attention over the recent years for its powerful global search ability. However, its slow convergence rate limits its development. In this paper, to further enhance its performance, we first introduced a new concept of a leading group, which includes some individuals with excellent performance, into the traditional ABC. The updated bee then selects one individual from the group to follow, which accelerates the convergence rate of the population. Furthermore, to enable the ABC algorithm to acquire greater opprotunities to search within a larger space, a logistic chaotic operator was introduced into our algorithm to balance its global and local search abilities. The performance of the algorithm proposed is tested on the traditional 12 benchmark functions and an image registration problem. The results reveal that our algorithm provides more acceptable results compared with the other algorithms.
C1 [Hu, Haidong] Beijing Inst Control Engn, Beijing, Peoples R China.
   [Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Liu, Ye; Lai, Xiangjing; Yang, Zeyu; Gao, Hao] Nanjing Univ Posts & Telecommun, Nanjing, Peoples R China.
C3 University of Macau; Nanjing University of Posts & Telecommunications
RP Gao, H (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing, Peoples R China.
EM tsgaohao@gmail.com
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
CR Ali MM, 2005, J GLOBAL OPTIM, V31, P635, DOI 10.1007/s10898-004-9972-2
   Ayatollahi F., 2012, J Biomed Sci Eng, V05, P153, DOI [10.4236/jbise.2012.54020, DOI 10.4236/JBISE.2012.54020]
   Babaoglu I, 2015, APPL SOFT COMPUT, V34, P851, DOI 10.1016/j.asoc.2015.05.041
   Cui L, 2017, J FOOD SCI, P1
   Cui LZ, 2016, INFORM SCIENCES, V367, P1012, DOI 10.1016/j.ins.2016.07.022
   De Falco I, 2008, APPL SOFT COMPUT, V8, P1453, DOI 10.1016/j.asoc.2007.10.013
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao WF, 2013, IEEE T CYBERNETICS, V43, P1011, DOI 10.1109/TSMCB.2012.2222373
   Karaboga D., 2005, Technical Report-TR06
   Karaboga D, 2014, APPL SOFT COMPUT, V23, P227, DOI 10.1016/j.asoc.2014.06.035
   Kiran MS, 2015, INFORM SCIENCES, V300, P140, DOI 10.1016/j.ins.2014.12.043
   Kiran MS, 2015, APPL SOFT COMPUT, V26, P454, DOI 10.1016/j.asoc.2014.10.020
   Kuang FJ, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P235, DOI 10.1109/CEC.2014.6900278
   Li XN, 2016, IEEE C EVOL COMPUTAT, P2524, DOI 10.1109/CEC.2016.7744103
   Li XN, 2016, APPL SOFT COMPUT, V41, P362, DOI 10.1016/j.asoc.2015.12.046
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Song XY, 2017, APPL SOFT COMPUT, V55, P384, DOI 10.1016/j.asoc.2017.01.031
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI 10.1109/tevc.2004.826068
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Xue Y, 2018, SOFT COMPUT, V22, P2935, DOI 10.1007/s00500-017-2547-1
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zhang Q, 2014, P INT CONF NAT COMPU, P568, DOI 10.1109/ICNC.2014.6975897
   Zhu GP, 2010, APPL MATH COMPUT, V217, P3166, DOI 10.1016/j.amc.2010.08.049
NR 31
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14643
EP 14669
DI 10.1007/s11042-019-7211-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900019
DA 2024-07-18
ER

PT J
AU Kala, R
   Deepa, P
AF Kala, R.
   Deepa, P.
TI Adaptive fuzzy hexagonal bilateral filter for brain MRI denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Rician noise; Fuzzy logic; Denoising;
   Membership function; Bilateral filtering
ID NOISE REMOVAL; IMAGES
AB Magnetic resonance image (MRI) plays a crucial role in medical applications for visual analysis and processing. Rician noise which arises from the MRI during acquisition can affect the quality of the image. This crucial issue should be addressed by denoising method. The proposed adaptive rician noise removal based on the bilateral filter using fuzzy hexagonal membership function improves the denoising efficiency at various noise variances and preserves the fine structures and edges. The fuzzy weights were obtained with the local mean (mu(i)) and global mean (mu(g)) by constructing hexagonal membership function for local order filter and bilateral filter. Bilateral filter is used to preserve the edges by smoothening the noises in MRI image and local filter is used to preserve the edges and retrieve the structural information. Brain MRI images are restored by multiplying its corresponding fuzzy weight with the restored image of local order filter and bilateral filter. Experiments on synthetic and clinical Brain MRI data were done at different noise levels by the proposed method and the existing methods. The result shows that the proposed method restores the image in better visual quality and can be well utilized for the diagnostic purpose at both low and high densities of rician noise.
C1 [Kala, R.; Deepa, P.] Govt Coll Technol, Dept Elect & Commun Engn, Coimbatore 641013, Tamil Nadu, India.
RP Kala, R (corresponding author), Govt Coll Technol, Dept Elect & Commun Engn, Coimbatore 641013, Tamil Nadu, India.
EM kalarajamani04@gmail.com; deepap05@gmail.com
RI Deepa, P/ABF-9371-2021
OI r, kala/0000-0003-4101-6212; P, Deepa/0000-0002-5632-5213
CR Abazari R, 2017, CURR MED IMAGING, DOI [10.2174/157340561366617040515082, DOI 10.2174/157340561366617040515082]
   Abazari R, 2018, MULTIMED TOOLS APPL, V77, P17829, DOI 10.1007/s11042-018-5648-7
   Akar SA, 2016, APPL SOFT COMPUT, V43, P87, DOI 10.1016/j.asoc.2016.02.043
   Alhihi M., 2018, OPEN ELECT ELECT ENG, V12, P1, DOI DOI 10.2174/1874129001812010001
   Alhihi M, 2018, INT J ELECT COMPUTER, V8, P1629
   Alhihi M, 2017, TELKOMNIKA TELECOMMU, V15, P1701, DOI [10.12928/telkomnika.v15i4.6597, DOI 10.12928/TELKOMNIKA.V15I4.6597]
   Anand CS, 2010, MAGN RESON IMAGING, V28, P842, DOI 10.1016/j.mri.2010.03.013
   [Anonymous], 1990, Two-Dimensional Signal and Image Processing
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Dougherty G., 2009, DIGITAL IMAGE PROCES
   EDELSTEIN WA, 1986, MAGN RESON MED, V3, P604, DOI 10.1002/mrm.1910030413
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   HENKELMAN RM, 1985, MED PHYS, V12, P232, DOI 10.1118/1.595711
   Hu JR, 2016, MAGN RESON IMAGING, V34, P990, DOI 10.1016/j.mri.2016.04.008
   Isik A, 2018, BREAST J, V24, P89, DOI 10.1111/tbj.12838
   Joseph J, 2017, CURR MED IMAGING, V13, P58, DOI 10.2174/1573405612666160609131149
   Kala R, 2018, NEURAL COMPUT APPL, V29, P237, DOI 10.1007/s00521-017-2953-4
   Kaur P, 2018, CURR MED IMAGING REV, V14, P675, DOI 10.2174/1573405613666170428154156
   Khan SU, 2018, CURR MED IMAGING, V14, P867, DOI 10.2174/1573405613666170619093021
   Khosravi MR, 2018, J SUPERCOMPUT, V74, P696, DOI 10.1007/s11227-017-2148-x
   Khosravi MR, 2017, IEEE INT C POW CONTR
   Kumarganesh S, 2018, CURR MED IMAGING REV, V14, P271, DOI 10.2174/1573405613666161216122938
   Lujan HJ, 2018, SURG LAPARO ENDO PER, V28, P36, DOI 10.1097/SLE.0000000000000384
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Misra D, 2013, INT C TREND COMPUT C, P146, DOI 10.1109/ICE-CCN.2013.6528481
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Phophalia A, 2015, APPL SOFT COMPUT, V33, P1, DOI 10.1016/j.asoc.2015.04.005
   Riji R, 2015, SIGNAL IMAGE VIDEO P, V9, P1543, DOI 10.1007/s11760-013-0611-6
   Samsonov AA, 2004, MAGN RESON MED, V52, P798, DOI 10.1002/mrm.20207
   Sharif M, 2016, SIGNAL IMAGE VIDEO P, V10, P215, DOI 10.1007/s11760-014-0729-1
   Sharif M, 2015, MULTIMED TOOLS APPL, V74, P5533, DOI 10.1007/s11042-014-1867-8
   Sudeep PV, 2015, BIOMED SIGNAL PROCES, V20, P125, DOI 10.1016/j.bspc.2015.04.015
   Zhang Y-D, 2018, J COMPUT SCI, DOI [10.1016/j.jocs.2018.07.03, DOI 10.1016/J.J0CS.2018.07.03]
   Zhang YT, 2012, PATTERN RECOGN, V45, P2743, DOI 10.1016/j.patcog.2012.01.015
NR 36
TC 9
Z9 11
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15513
EP 15530
DI 10.1007/s11042-019-7459-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900063
DA 2024-07-18
ER

PT J
AU Li, Z
   Zhang, YD
AF Li, Zhong
   Zhang, Yu-Dong
TI 3D reconstruction method of forest landscape based on virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual technology; Forest landscape; 3D reconstruction; DEM spatial
   interpolation; Morphological feature points; Forstner operator
ID NETWORKS
AB In the research and development of forest resource management information visualization, the virtual forest environment provides very important technical support. Therefore, this paper proposes the use of virtual reality technology to achieve three-dimensional reconstruction of forest landscape, so as to manage forest resources more effectively. Firstly, the internal parameters of the camera are calibrated, and the improved Canny operator is used to obtain the complete forest landscape image edge information. The SIFT algorithm is used to extract the corner points of green plant images on both sides of the highway, and some pseudo feature points are eliminated. To establish a three-dimensional forest terrain, the digital elevation model is used to superimpose the ground texture image theory, and the objective surface morphological feature points in a certain region are approximated by using known actual scene sample points. The DEM spatial interpolation method is used to determine the forest boundary edge according to the grid point elevation value of a certain requirement. At the same time, the texture feature method is used to map the surface feature information of the scene in the drawn model. Secondly, based on the three-dimensional forest terrain model established in the previous section, the Forstner operator image feature extraction principle and the edge detection principle are combined with the image information extraction of the actual forest landscape. The three-dimensional reconstruction of the forest landscape based on the actual scene is realized by matching the forest landscape image feature points, the image edges and the three-dimensional forest terrain model. Experiments show that the three-dimensional reconstruction of virtual forests provides reliable data support for forest resource management.
C1 [Li, Zhong] Jiangsu Union Tech Inst, Changzhou Liu Guo Jun Branch, Changzhou, Peoples R China.
   [Zhang, Yu-Dong] Univ Leicester, Dept Comp Sci, Leicester, Leics, England.
C3 University of Leicester
RP Zhang, YD (corresponding author), Univ Leicester, Dept Comp Sci, Leicester, Leics, England.
EM yudongzhang@ieee.org
RI Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
CR Bähner KW, 2017, B ENTOMOL RES, V107, P563, DOI 10.1017/S0007485317000062
   Calì C, 2016, J COMP NEUROL, V524, P23, DOI 10.1002/cne.23852
   Sanchez GME, 2017, LANDSCAPE URBAN PLAN, V167, P98, DOI 10.1016/j.landurbplan.2017.05.018
   Erra U., 2018, INT J HUMAN COMPUTER, P1
   Gil-Tena A, 2016, EUR J FOREST RES, V135, P403, DOI 10.1007/s10342-016-0943-1
   Guerriero L, 2018, DIS COLON RECTUM, V61, P719, DOI 10.1097/DCR.0000000000001077
   Guldner IH, 2016, SCI REP, V6, P24
   Juliani AW, 2016, J ENVIRON PSYCHOL, V47, P155, DOI 10.1016/j.jenvp.2016.05.011
   Kaim D, 2016, APPL GEOGR, V67, P39, DOI 10.1016/j.apgeog.2015.12.003
   Kuglerová L, 2016, ECOSYSTEMS, V19, P170, DOI 10.1007/s10021-015-9927-0
   Liu S, 2019, MOBILE NETW APPL, V24, P5, DOI 10.1007/s11036-018-1134-8
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   McLean KA, 2016, LANDSCAPE ECOL, V31, P1849, DOI 10.1007/s10980-016-0367-9
   Milanesi P, 2017, ECOLOGY, V98, P393, DOI 10.1002/ecy.1645
   Nagel TA, 2014, ECOL APPL, V24, P663, DOI 10.1890/13-0632.1
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Patterson Z, 2017, LANDSCAPE URBAN PLAN, V157, P63, DOI 10.1016/j.landurbplan.2016.05.024
   Plotnick D., 2016, J ACOUSTICAL SOC AM, V140, P3347
   Temperli C, 2016, ECOSPHERE, V6, P1
   Urgenson LS, 2017, ENVIRON MANAGE, V59, P1
   Wang SH, 2018, J REAL-TIME IMAGE PR, V15, P631, DOI 10.1007/s11554-017-0717-0
   Wang SH, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00818
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
NR 25
TC 5
Z9 5
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16369
EP 16383
DI 10.1007/s11042-019-7320-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600031
DA 2024-07-18
ER

PT J
AU Wu, DM
   Pun, CM
   Xu, B
   Gao, H
   Wu, ZH
AF Wu, Dongmei
   Pun, Chi-Man
   Xu, Bin
   Gao, Hao
   Wu, Zhenghua
TI Vehicle power train optimization using multi-objective bird swarm
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bird swarm algorithm; MOBSA; Multi-objective optimization; Constraint;
   Vehicle power train optimization
ID MODEL
AB In this paper, a multi-objective bird swarm algorithm (MOBSA) is proposed to cope with multi-objective optimization problems. The algorithm is explored based on BSA which is an evolutionary algorithm suitable for single objective optimization. In this paper, non-dominated sorting approach is used to distinguish optimal solutions and parallel coordinates is applied to evaluate the distribution density of non-dominated solution and further update the external archive when it is full to overflowing, which ensure faster convergence and more widespread of Pareto front. Then, the MOBSA is adopted to optimize benchmark problems. The results demonstrate that MOBSA gets better performance compared with NSGA-II and MOPSO. Since a vehicle power train problem could be treated as a typical multi-objective optimization problem with constraints, with integration of constrained non-dominated solution, MOBSA is adopted to acquire optimal gear ratios and optimize vehicle power train. The results compared with other popular algorithm prove the proposed algorithm is more suitable for constrained multi-objective optimization problem in engineering field.
C1 [Wu, Dongmei] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing, Peoples R China.
   [Xu, Bin; Wu, Zhenghua] Nanjing Univ Posts & Telecommun, Nanjing, Peoples R China.
   [Gao, Hao] Nanjing Univ Posts & Telecommun, Inst Adv Technol, Nanjing, Peoples R China.
   [Pun, Chi-Man; Gao, Hao] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing University of Posts &
   Telecommunications; University of Macau
RP Wu, DM (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing, Peoples R China.
EM wudm@njupt.edu.cn; cmpun@umac.mo; Xubin.njupt@foxmail.com;
   tsgaohao@gmail.com; 1292715385@qq.com
RI Wu, Dongmei/AAS-6647-2020; Pun, Chi Man/GRJ-3703-2022
OI Wu, Dongmei/0000-0001-9830-0527; 
CR [Anonymous], 1 INT C GEN ALG HILL
   Coello CAC, 2002, IEEE C EVOL COMPUTAT, P1051, DOI 10.1109/CEC.2002.1004388
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 2014, EVOLUTIONARY COMPUTA, V7, P205, DOI DOI 10.1162/evco.1999.7.3.205
   Ferringer MP, 2006, J SPACECRAFT ROCKETS, V43, P1404, DOI 10.2514/1.18788
   Fonseca C. M., 1995, First International Conference on `Genetic Algorithms in Engineering Systems: Innovations and Applications' GALESIA (Conf. Publ. No.414), P45
   Knowles J, 1999, P 1999 C EV COMP CEC, P98, DOI [DOI 10.1109/CEC.1999.781913, 10.1109/cec.1999.781913]
   Lau HCW, 2009, EXPERT SYST APPL, V36, P8255, DOI 10.1016/j.eswa.2008.10.031
   Laumanns N, 2001, LECT NOTES COMPUT SC, V1993, P612
   Laumanns N, 2001, MULTIOBJECTIVE DESIG, P612
   Lu HM, 2017, IEEE INTER THINGS J, DOI [10.1109/JIOT.2017.2737479, DOI 10.1109/JI0T.2017.2737479]
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Tapia MGC, 2007, IEEE C EVOL COMPUTAT, P532, DOI 10.1109/CEC.2007.4424516
   Van Veldhuizen D. A., 1998, GEN PROGR C, P221
   Xu X, 2018, RAMSEY THEORY: UNSOLVED PROBLEMS AND RESULTS, P1, DOI 10.1515/9783110576702
   Zhang Y, 2013, NEUROCOMPUTING, V103, P172, DOI 10.1016/j.neucom.2012.09.019
   Zhou AM, 2006, IEEE C EVOL COMPUTAT, P892
NR 20
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14319
EP 14339
DI 10.1007/s11042-018-6522-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900001
DA 2024-07-18
ER

PT J
AU Yoon-Su, J
   Seung-Soo, S
AF Yoon-Su, Jeong
   Seung-Soo, Shin
TI RETRACTED: Staganography-based healthcare model for safe handling of
   multimedia health care information using VR (Retracted article. See vol.
   82, pg. 17517, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE VR; Staganography; Medical information; Multimedia; MRI; CT
ID WIRELESS SENSOR NETWORKS
AB Due to the development of the Internet of Things (IoT) in the medical field, special medical equipment such as CT and MRI, which are used in medical institutions, can be used for digital healthcare services by medical staff using VR. However, the integrity and confidentiality of multimedia health care information handled through special medical equipment using VR is still one of the major issues that cause many problems in the application sector of medical services. This paper proposes a steganography-based digital healthcare model to ensure the integrity of user multimedia image information processed through special medical equipment using VR. The proposed model aims to prevent illegal use by the medical team through VR of multimedia image information collected through special medical equipment without the consent of the user. The proposed model uses the user's signature and credentials in a hybrid cipher for multimedia health care information. The proposed model has features that ensure the integrity and confidentiality of the user's medical image information without disturbing the user's multimedia image quality filmed through special medical equipment. In addition, multimedia medical information viewed through VR is not exploited without the consent of users because the user's signature information was encrypted using steganography-based cryptography-based ciphering techniques. In particular, the proposed model provides real-time guidance related to users' health conditions and first-aid care in connection with the hospital health service to improve the management of medical image information for users in hospitals. As a result of the performance evaluation, the proposed model averaged 12.5% improvement in the management of the user's medical image information compared to the existing technique, and the user's accuracy in extracting medical image information was averaged 10.4% higher than that of the existing technique.
C1 [Yoon-Su, Jeong] Mokwon Univ, Dept Informat & Commun Convergence Engn, Daejeon, South Korea.
   [Seung-Soo, Shin] Tongmyong Univ, Dept Informat Secur, Busan, South Korea.
C3 Mokwon University; Tongmyong University
RP Yoon-Su, J (corresponding author), Mokwon Univ, Dept Informat & Commun Convergence Engn, Daejeon, South Korea.
EM bukmunro@mokwon.ac.kr; shinss@tu.ac.kr
OI Jeong, Yoon-Su/0000-0003-3455-5947
CR Al Ameen M, 2012, J MED SYST, V36, P93, DOI 10.1007/s10916-010-9449-4
   Bang DW, 2010, P 6 INT C NETW COMP, P1
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Fan R, 2011, J ZHEJIANG U-SCI C, V12, P550, DOI 10.1631/jzus.C1000377
   Garkoti G, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P195, DOI 10.1109/ICIT.2014.43
   Kester QA, 2015, 2015 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS (ICCSA), P8, DOI 10.1109/ICCSA.2015.8
   Khalil M. I., 2017, International Journal of Computer Network and Information Security, V9, P22, DOI 10.5815/ijcnis.2017.02.03
   Kim YH, 2014, J SOC BUSINESS STUDI, V19, P614
   Ko J, 2010, P IEEE, V98, P1947, DOI 10.1109/JPROC.2010.2065210
   Liu Duo, 2005, Tsinghua Science and Technology, V10, P145, DOI 10.1016/S1007-0214(05)70046-8
   Pierangeli SS, 2011, GERIATRIC RHEUMATOLOGY: A COMPREHENSIVE APPROACH, P231, DOI 10.1007/978-1-4419-5792-4_24
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rathi SC, 2012, TECHNOLOGY I MED IMA, V2, P292
   Saaty T. L., 2008, INT J SERV SCI, V1, P83, DOI [10.1504/IJSSCI.2008.017590, DOI 10.1504/IJSSCI.2008.017590]
   Seyyedi Seyyed Amin, 2016, International Journal of Network Security, V18, P124
   Virone G, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P95, DOI 10.1109/DDHH.2006.1624806
   Walters W, 2009, J CONSUMER ED JCE, V15, P1
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Yang T, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-46
NR 20
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16593
EP 16607
DI 10.1007/s11042-019-07833-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600044
DA 2024-07-18
ER

PT J
AU Zhang, SY
   Li, N
   Qiu, CC
   Yu, ZB
   Zheng, HY
   Zheng, B
AF Zhang, Shaoyong
   Li, Na
   Qiu, Chenchen
   Yu, Zhibin
   Zheng, Haiyong
   Zheng, Bing
TI Depth map prediction from a single image with generative adversarial
   nets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth prediction; Generative adversarial network; Image translation
AB A depth map is a fundamental component of 3D construction. Depth map prediction from a single image is a challenging task in computer vision. In this paper, we consider the depth prediction as an image-to-image task and propose an adversarial convolutional architecture called the Depth Generative Adversarial Network (DepthGAN) for depth prediction. To enhance the image translation ability, we take advantage of a Fully Convolutional Residual Network (FCRN) and combine it with a generative adversarial network, which has shown remarkable achievements in image-to-image tasks. We also present a new loss function including the scale-invariant (SI) error and the structural similarity (SSIM) loss function to improve our model and to output a high-quality depth map. Experiments show that the DepthGAN performs better in monocular depth prediction than the current best method on the NYU Depth v2 dataset.
C1 [Zhang, Shaoyong; Li, Na; Qiu, Chenchen; Yu, Zhibin; Zheng, Haiyong; Zheng, Bing] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
C3 Ocean University of China
RP Yu, ZB (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
EM yuzhibin@ouc.edu.cn
RI Yu, Zhibin/Z-1138-2019
OI Yu, Zhibin/0000-0003-4372-1767
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, ARXIV150407159
   Arjovsky M., 2017, ARXIV170107875
   Cao Y, 2010, LECT NOTES COMPUT SC, V6315, P729
   Cao Y, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351253
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Cherian A, 2009, IEEE INT CONF ROBOT, P519
   Clayden K, 2012, THESIS
   Dong H, 2017, ARXIV170706873
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harman P, 2002, PROC SPIE, V4660, P78, DOI 10.1117/12.468020
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jung JinWoo., 2010, Communications Workshops (ICC), 2010 IEEE International Conference on, P1
   Kaneko T., 2017, IEEE C COMP VIS PATT, V2
   Karacan L., 2016, Learning to generate images of outdoor scenes from attributes and semantic layouts. arXiv preprint arXiv:1612.00215
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Ledig C, 2016, P IEEE C COMP VIS PA
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lim Theodore, 2016, P INT C LEARN REPR
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu H, 2018, FUTURE GENERATION CO
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Radford A., 2015, ARXIV
   Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sonderby C. K., 2016, ARXIV161004490
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wang QZ, 2016, IEEE T IMAGE PROCESS, V25, P1425, DOI 10.1109/TIP.2016.2521180
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yang WB, 2017, COMM COM INF SC, V771, P696, DOI 10.1007/978-981-10-7299-4_58
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 6
Z9 6
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14357
EP 14374
DI 10.1007/s11042-018-6694-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900003
DA 2024-07-18
ER

PT J
AU Zhang, SL
   Huang, JL
   Hanan, J
   Qin, L
AF Zhang, Sulan
   Huang, Jinlong
   Hanan, Jim
   Qin, Lin
TI A hyperspectral GA-PLSR model for prediction of pine wilt disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pine wilt disease; Pinus massoniana; Spectral features; Partial least
   squares regression (PLSR); Prediction model
ID BURSAPHELENCHUS-XYLOPHILUS; GENETIC ALGORITHM; MASSONIANA; SPECTROSCOPY;
   REFLECTANCE; SELECTION; PEST; WOOD
AB Pine wilt disease caused by a forest-invasive alien species, the pine wood nematode (Bursaphelenchus xylophilus) is considered as one of the most destructive pest problems. In recent years, spectroscopic technologies have shown great potentials for the assessment of forest damage due to their nondestructive, noninvasive, cost-effective, and rapidly responsive nature. This paper first identified the hyperspectral characteristics of pine wilt disease by measuring and analyzing the changes in spectral reflectance of healthy and infectedPinus massonianatrees. Then 16 spectral features were extracted from the spectral bands covering the green region (510~580 nm), the red region (620~680 nm), the red edge (680~760 nm), the near-infrared region (780~1100 nm), and coded as genes composing the chromosome of a genetic algorithm (GA). Based on the optimal spectral features with suitable fitness from the GA, a partial least squares regression (PLSR) prediction model was built with highest determination coefficientR(c)(2) = 0.91,R-v(2) = 0.82, relative prediction deviationRPD = 3.3 and lowest root mean square errorRMSE(c) = 0.23,RMSEv = 0.33 on the calibration and validation datasets. Compared with other PLSR models, our proposed GA-based approach significantly improves the prediction accuracy with few input spectral features.
C1 [Zhang, Sulan; Huang, Jinlong] Yangtze Normal Univ, Coll Big Data & Intelligent Engn, Chongqing 408100, Peoples R China.
   [Zhang, Sulan; Hanan, Jim] Univ Queensland, Ctr Hort Sci, Queensland Alliance Agr & Food Innovat, Brisbane, Qld 4072, Australia.
   [Zhang, Sulan; Qin, Lin] Yangtze Normal Univ, Hyperspectral Remote Sensing Monitoring Ctr Ecol, Chongqing 408100, Peoples R China.
   [Qin, Lin] Yangtze Normal Univ, Coll Elect Informat Engn, Chongqing 408100, Peoples R China.
C3 Yangtze Normal University; University of Queensland; Yangtze Normal
   University; Yangtze Normal University
RP Huang, JL (corresponding author), Yangtze Normal Univ, Coll Big Data & Intelligent Engn, Chongqing 408100, Peoples R China.
EM slzhang@cqu.edu.cn; h.jinlong@yznu.edu.cn; j.hanan@uq.edu.au;
   qinlin0123@163.com
CR Abukhalaf N., 2014, Palestine Tech Univ Res J, V2, P1, DOI [10.53671/pturj.v2i1.21, DOI 10.53671/PTURJ.V2I1.21]
   Bolon-Canedo V., 2018, Recent Advances in Ensembles for Feature Selection
   Carnegie AJ, 2018, AUST FORESTRY, V81, P24, DOI 10.1080/00049158.2018.1440467
   Cheng T, 2014, REMOTE SENS ENVIRON, V143, P39, DOI 10.1016/j.rse.2013.11.018
   Coops N, 2003, PHYTOPATHOLOGY, V93, P1524, DOI 10.1094/PHYTO.2003.93.12.1524
   Duan FQ, 2014, MULTIMED TOOLS APPL, V73, P809, DOI 10.1007/s11042-012-1351-2
   Guo TJ, 2014, NEUROCOMPUTING, V144, P408, DOI 10.1016/j.neucom.2014.05.018
   Hernández-Clemente R, 2011, REMOTE SENS ENVIRON, V115, P2360, DOI 10.1016/j.rse.2011.04.036
   Holland I.H., 1975, ADAPTATION NATURAL A
   [黄明祥 Huang Mingxiang], 2012, [遥感技术与应用, Remote Sensing Technology and Application], V27, P954
   Hyun Min Woo, 2007, Mycobiology, V35, P159, DOI 10.4489/MYCO.2007.35.3.159
   Ju YW, 2014, NEMATOLOGY, V16, P1197, DOI 10.1163/15685411-00002846
   Kim SR, 2018, FORESTS, V9, DOI 10.3390/f9030115
   Kwon TS, 2011, FOREST ECOL MANAG, V261, P562, DOI 10.1016/j.foreco.2010.11.008
   Larsolle A, 2007, PRECIS AGRIC, V8, P37, DOI 10.1007/s11119-006-9027-4
   Li SJ, 2011, KNOWL-BASED SYST, V24, P40, DOI 10.1016/j.knosys.2010.07.003
   Lu JJ, 2008, KNOWL-BASED SYST, V21, P887, DOI 10.1016/j.knosys.2008.03.051
   Luther JE, 1997, REMOTE SENS ENVIRON, V59, P77, DOI 10.1016/S0034-4257(96)00108-3
   Mota MM, 1999, NEMATOLOGY, V1, P727, DOI 10.1163/156854199508757
   Mutanga O, 2004, REMOTE SENS ENVIRON, V89, P393, DOI 10.1016/j.rse.2003.11.001
   Nijat Kasim Nijat Kasim, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P208
   Ren W., 2016, ECOLOGY ENV MONITORI, V1, P52
   Sankaran S, 2011, COMPUT ELECTRON AGR, V77, P127, DOI 10.1016/j.compag.2011.03.004
   Shi Z, 2014, SCI CHINA EARTH SCI, V57, P1671, DOI 10.1007/s11430-013-4808-x
   Sousa E, 2013, PHYTOPARASITICA, V41, P143, DOI 10.1007/s12600-012-0272-y
   Suzuki K., 2002, Dendrobiology, V48, P71
   Nguyen TV, 2017, ECOL MODEL, V353, P54, DOI 10.1016/j.ecolmodel.2016.10.022
   Wang JJ, 2014, GEODERMA, V216, P1, DOI 10.1016/j.geoderma.2013.10.024
   Wang Z, 2013, PATTERN RECOGN, V46, P2267, DOI 10.1016/j.patcog.2013.01.023
   [王震 WANG Zhen], 2007, [遥感技术与应用, Remote sensing Technology and Application], V22, P367
   White JC, 2007, INT J REMOTE SENS, V28, P2111, DOI 10.1080/01431160600944028
   Wu JJ, 2018, GEODERMA, V316, P89, DOI 10.1016/j.geoderma.2017.12.015
   [伍南 Wu Nan], 2012, [植物保护, Plant Protection], V38, P72
   Xu HC, 2011, SPECTROSC SPECT ANAL, V31, P1352, DOI 10.3964/j.issn.1000-0593(2011)05-1352-05
   Xu ZH, 2013, SPECTROSC SPECT ANAL, V33, P428, DOI 10.3964/j.issn.1000-0593(2013)02-0428-06
   Zhang SL, 2019, SPECTROSC SPECT ANAL, V39, P865, DOI 10.3964/j.issn.1000-0593(2019)03-0865-08
   Zhu ZH, 2018, J ANAL ATOM SPECTROM, V33, P205, DOI 10.1039/c7ja00356k
NR 37
TC 11
Z9 11
U1 4
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16645
EP 16661
DI 10.1007/s11042-019-07976-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600047
DA 2024-07-18
ER

PT J
AU Zou, L
   Jin, X
   Wei, B
AF Zou, Ling
   Jin, Xin
   Wei, Bo
TI Film clips retrieval using image queries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Transfer learning; Film editing
AB The emergence of entertainment industry motivates the explosive growth of automatically film trailer. Manually finding desired clips from these large amounts of films is time-consuming and tedious, which makes finding the moments of user major or special preference becomes an urgent problem. Moreover, the user subjectivity over a film makes no fixed trailer caters to all tastes. This paper addresses these problems by posing a query-related film clip extraction framework which optimizes selected frames not only meet the semantic meaning of the queries but also have visual similarity on appearance between the query and selected clips. The experimental results show that our query-related film clip retrieval method is particularly useful for film editing, e.g. automatically finding movie clips to arouse audiences' interests on the film.
C1 [Zou, Ling] Beijing Film Acad, Digital Media Sch, Beijing, Peoples R China.
   [Jin, Xin] Beijing Elect Sci & Technol Inst, Beijing, Peoples R China.
   [Wei, Bo] Hangzhou Dianzi Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; Hangzhou Dianzi
   University
RP Zou, L (corresponding author), Beijing Film Acad, Digital Media Sch, Beijing, Peoples R China.
EM zouling@bfa.edu.cn
RI jin, xin/GQZ-5811-2022
CR [Anonymous], 2017, PAC RIM C MULT
   [Anonymous], 2017, C COMP VIS PATT REC
   Chen Jing, 2007, Infrared Laser Engineering, V36, P949
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Joshi N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766954
   Kulesza A, 2012, FOUND TRENDS MACH LE, V5, P123, DOI 10.1561/2200000044
   LEE YJ, 2012, PROC CVPR IEEE, V2012, P1346
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Sayad IE, 2011, ICME, P1
   Serikawa S, 2014, UNDERWATER IMAGE DEH
   Sharghi A, QUERY FOCUSED VIDEO
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   [王方石 Wang Fengshi], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P1752, DOI 10.1360/crad20051017
   [王晗 Wang Han], 2013, [计算机学报, Chinese Journal of Computers], V36, P2062
   Yan-Fenga LI, VIDEO ENG
   Yao T, 2013, ANNOTATION FREE VIDE, P977
   Zhang CL, DEFENSE FULLY CONNEC
NR 22
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14725
EP 14732
DI 10.1007/s11042-019-7297-x
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900023
DA 2024-07-18
ER

PT J
AU Chapron, K
   Bouchard, K
   Gaboury, S
AF Chapron, Kevin
   Bouchard, Kevin
   Gaboury, Sebastien
TI Real-time gait speed evaluation at home in a multi residents context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait speed evaluation; Smart home; Speed sensor; Multi resident
   identification; Wearable sensors
ID ACTIVITY RECOGNITION; WALKING SPEED; OLDER-ADULTS; PREDICTOR; GO
AB In recent years, the aging of the population has attracted considerable attention in the scientific community. An important fact is an increasing number of senior people will suffer from cognitive decline and there is almost no existing way to detect it early without the intervention of a clinician. Indeed, the sooner the cognitive decline is detected, the professional can elaborate a more adequate strategy to slow it down. In fact, Mild Cognitive Impairments (MCI) have been strongly correlated to a decreasing gait speed over the time. However, it would take a lot of human resources to carry out a standardized walking speed test every year to follow the evolution of this one. In fact, it is unthinkable in the current context of healthcare economics scarcity, thus finding a way of measuring it automatically at home could be a promising solution. This ambient sensor should be able to measure the gait speed of an inhabitant and automatically associate it to the right resident in a multi-resident context. In this paper, we present a new prototype to monitor gait speed continuously at home non intrusively. When coupled with a wristband capable of communicating through BLE, the gait speed can then be associated with the right person in a multi-resident context. The proposed prototype was tested in a realistic smart home context and results obtained are very encouraging.
C1 [Chapron, Kevin; Bouchard, Kevin; Gaboury, Sebastien] Univ Quebec Chicoutimi, Lab Intelligence Ambiante Reconnaissance Activite, Chicoutimi, PQ, Canada.
C3 University of Quebec; University of Quebec Chicoutimi
RP Chapron, K (corresponding author), Univ Quebec Chicoutimi, Lab Intelligence Ambiante Reconnaissance Activite, Chicoutimi, PQ, Canada.
EM Kevin.chapron1@uqac.ca
RI Bouchard, Kevin/AAC-6009-2019; Gopal, Suvetha/KFR-7088-2024
OI Bouchard, Kevin/0000-0002-5227-6602; CHAPRON, Kevin/0000-0002-7071-782X
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   Canadian Foundation for Innovation (CFI)
FX The authors would like to acknowledge the financial contribution of the
   Natural Sciences and Engineering Research Council of Canada (NSERC) and
   the Canadian Foundation for Innovation (CFI). Also, the authors would
   like to thank all participants, without them, this work would not have
   been possible.
CR Aicha AN, 2018, J AMB INTEL HUM COMP, V9, P589, DOI 10.1007/s12652-017-0456-x
   Bouchard B, 2006, J COMPUT, V1, P53
   Buracchio T, 2010, ARCH NEUROL-CHICAGO, V67, P980, DOI 10.1001/archneurol.2010.159
   Chapron K, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P55, DOI 10.1145/3342428.3342665
   Chapron K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010268
   Chen R, 2014, ENTROPY-SWITZ, V16, P2184, DOI 10.3390/e16042184
   Cleland I, 2013, SENSORS-BASEL, V13, P9183, DOI 10.3390/s130709183
   COOPER KH, 1968, J AMER MED ASSOC, V203, P201, DOI 10.1001/jama.203.3.201
   Frank E, 2016, The WEKA workbench. Online appendix for data mining: practical machine learning tools and techniques
   Fritz S, 2009, J GERIATR PHYS THER, V32, P2, DOI 10.1519/00139143-200932020-00002
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   Hayes Tamara L, 2009, Annu Int Conf IEEE Eng Med Biol Soc, V2009, P7248, DOI 10.1109/IEMBS.2009.5334746
   Kaushik Alka R, 2007, Technol Health Care, V15, P273
   Krasotkina O, 2015, LECT NOTES ARTIF INT, V9166, P425, DOI 10.1007/978-3-319-21024-7_30
   Lau Bernard, 2018, 12th European Conference on Antennas and Propagation (EuCAP 2018)
   Li GR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082487
   Liu LL, 2016, INT J MED INFORM, V91, P44, DOI 10.1016/j.ijmedinf.2016.04.007
   Mannini A, 2013, MED SCI SPORT EXER, V45, P2193, DOI 10.1249/MSS.0b013e31829736d6
   Marquis S, 2002, ARCH NEUROL-CHICAGO, V59, P601, DOI 10.1001/archneur.59.4.601
   MATHIAS S, 1986, ARCH PHYS MED REHAB, V67, P387
   McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49
   Mokhtari G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030908
   Naya F, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P212, DOI 10.1109/ISWC.2005.13
   Peel NM, 2013, J GERONTOL A-BIOL, V68, P39, DOI 10.1093/gerona/gls174
   PODSIADLO D, 1991, J AM GERIATR SOC, V39, P142, DOI 10.1111/j.1532-5415.1991.tb01616.x
   Population Division D, 2017, WORLD POP AG 2017, P1
   Prince, 2016, WORLD ALZHEIMER REPO
   Raspberry Pi Foundation, 2016, RASPB PI 3 MOD B
   Sadowski S, 2018, IEEE ACCESS, V6, P30149, DOI 10.1109/ACCESS.2018.2843325
   Salbach NM, 2015, GAIT POSTURE, V41, P341, DOI 10.1016/j.gaitpost.2014.10.002
   Stone EE, 2013, IEEE T BIO-MED ENG, V60, P2925, DOI 10.1109/TBME.2013.2266341
   Thaljaoui A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P2178, DOI 10.1109/ICIT.2015.7125418
   Titianova EB, 2004, J ELECTROMYOGR KINES, V14, P275, DOI 10.1016/S1050-6411(03)00077-4
   Verghese J, 2002, NEW ENGL J MED, V347, P1761, DOI 10.1056/NEJMoa020441
   Waite LM, 2005, J NEUROL SCI, V229, P89, DOI 10.1016/j.jns.2004.11.009
   Walsh L., 2011, P 5 INT ICST C PERVA, DOI [DOI 10.4108/ICST.PERVASIVEHEALTH.2011.246077, 10.4108/icst.pervasivehealth.2011.246077]
   Wang L, 2009, LECT NOTES COMPUT SC, V5859, P78, DOI 10.1007/978-3-642-05408-2_10
   Wilson Christopher M, 2013, Cardiopulm Phys Ther J, V24, P36
   Wilson DH, 2005, LECT NOTES COMPUT SC, V3468, P62
   Yang SZ, 2012, SENSORS-BASEL, V12, P6102, DOI 10.3390/s120506102
   Zapico AG, 2016, J CARDIOPULM REHABIL, V36, P203, DOI 10.1097/HCR.0000000000000174
NR 41
TC 5
Z9 8
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 12931
EP 12949
DI 10.1007/s11042-020-08962-y
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000559642600002
DA 2024-07-18
ER

PT J
AU Borah, S
   Borah, B
AF Borah, Sagarika
   Borah, Bhogeswar
TI Prediction Error Expansion (PEE) based Reversible polygon mesh
   watermarking scheme for regional tamper localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh watermarking; Semi-fragile; Authentication; Geometrical attacks;
   Tamper localization; Reversible watermarking; Prediction Error Expansion
   (PEE)
ID PUBLIC FRAGILE WATERMARKING; AUTHENTICATION
AB This paper proposes a block based semi-fragile reversible authentication scheme that achieves regional localization for different classes of geometry and topology based mesh attacks. First of all, the model bounding volume is spatially partitioned into sub-volumes using Octree data structure and for each sub-volume, the embeddable units are computed. Each embeddable unit is comprises of three vertices and one bit can be embedded to an embeddable unit using a Prediction Error Histogram (PEH) shifting strategy. In PEH shifting, few of the embeddable units are expandable and few are shiftable. To compute PEH, Vertex Normal Value Ordering (VNVO) is performed and the maximum prediction error value is expanded. During PEH generation, to achieve sharper histograms and to get minimum numbers of shiftable units, adaptive bin-width selection step is also added. Verification of each block is performed by computing CRC-8 using vertex information from the block and embedding to the expandable units of the corresponding block itself. The proposed method could generate a sharper histogram than the state of the art methods and the proposed embedding function incurred very low distortion to mesh surface. It also outperforms the prior arts by achieving regional taper localization for both geometrical as well as topological attacks. The results analysis justifies the superiority of the proposed work than state of the art methods.
C1 [Borah, Sagarika; Borah, Bhogeswar] Tezpur Univ, Dept Comp Sci & Engn, Tezpur, Assam, India.
C3 Tezpur University
RP Borah, S (corresponding author), Tezpur Univ, Dept Comp Sci & Engn, Tezpur, Assam, India.
EM sagarika08connect@gmail.com; bgb@tezu.ernet.in
RI Borah, Bhogeswar/O-4284-2015
OI Borah, Bhogeswar/0000-0002-9477-0908
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2006, SPIE OPTICS PHOTONIC
   Botsch M., 2010, Polygon Mesh Processing
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chen TY, 2009, INT J INNOV COMPUT I, V5, P4561
   Cheung YM, 2007, IEEE T CIRC SYST VID, V17, P1007, DOI 10.1109/TCSVT.2007.903553
   Chou CM, 2006, COMPUT AIDED DESIGN, V38, P1154, DOI 10.1016/j.cad.2006.06.009
   Chou CM, 2009, IEEE COMPUT GRAPH, V29, P72, DOI 10.1109/MCG.2009.20
   Chou D, 2009, INT J INNOV COMPUT I, V5, P1893
   Huang C.C., 2013, INT C IND ENG OTH AP, P566
   Huang YH, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0051-x
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jang HU, 2018, MULTIMED TOOLS APPL, V77, P5685, DOI 10.1007/s11042-017-4483-6
   Jiang RQ, 2018, MULTIMED TOOLS APPL, V77, P5263, DOI 10.1007/s11042-017-4430-6
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li YT, 2016, NONLINEAR DYNAM, V84, P2387, DOI 10.1007/s11071-016-2652-1
   Li YT, 2011, NEURAL COMPUT APPL, V20, P133, DOI 10.1007/s00521-010-0432-2
   Lin HYS, 2005, IEEE T MULTIMEDIA, V7, P997, DOI 10.1109/TMM.2005.858412
   Luo H, 2006, 2006 IEEE International Symposium on Signal Processing and Information Technology, Vols 1 and 2, P863, DOI 10.1109/ISSPIT.2006.270919
   Molaei AM, 2013, 3D RES, V4, DOI 10.1007/3DRes.04(2013)4
   Naskar R, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487272
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sun Z, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P593
   Thodi DM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P21, DOI 10.1109/IAI.2004.1300937
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Tsai YY, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/1096463
   Wang JT, 2014, L N INST COMP SCI SO, V131, P3, DOI 10.1007/978-3-319-11569-6_1
   Wang WB, 2008, COMPUT AIDED DESIGN, V40, P634, DOI 10.1016/j.cad.2008.03.001
   Wu HT, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P940, DOI 10.1109/WI.2006.140
   Wu HT, 2010, IEEE T INSTRUM MEAS, V59, P221, DOI 10.1109/TIM.2009.2022453
   Wu HT, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P801
   Wu HT, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P774
   Xinyu Xiang, 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P71, DOI 10.1145/300523.300531
   Yeo BL, 1999, IEEE COMPUT GRAPH, V19, P36, DOI 10.1109/38.736467
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhe-Ming Lu, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P233
NR 42
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11437
EP 11458
DI 10.1007/s11042-019-08411-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400008
DA 2024-07-18
ER

PT J
AU Chover, M
   Marin, C
   Rebollo, C
   Remolar, I
AF Chover, Miguel
   Marin, Carlos
   Rebollo, Cristina
   Remolar, Inmaculada
TI A game engine designed to simplify 2D video game development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game Engine; 2D video games; Game editor; Game logic
ID USER ACCEPTANCE
AB In recent years, the increasing popularity of casual games for mobile and web has promoted the development of new editors to make video games easier to create. The development of these interactive applications is on its way to becoming democratized, so that anyone who is interested, without any advanced knowledge of programming, can create them for devices such as mobile phones or consoles. Nevertheless, most game development environments rely on the traditional way of programming and need advanced technical skills, even despite today's improvements. This paper presents a new 2D game engine that reduces the complexity of video game development processes. The game specification has been simplified, decreasing the complexity of the engine architecture and introducing a very easy-to-use editing environment for game creation. The engine presented here allows the behaviour of the game objects to be defined using a very small set of conditions and actions, without the need to use complex data structures. Some experiments have been designed in order to validate its ease of use and its capacity in the creation of a wide variety of games. To test it, users with little experience in programming have developed arcade games using the presented environment as a proof of its easiness with respect to other comparable software. Results obtained endorse the concept and the hypothesis of its easiness of use and demonstrate the engine potential.
C1 [Chover, Miguel; Marin, Carlos; Rebollo, Cristina; Remolar, Inmaculada] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
C3 Universitat Jaume I
RP Marin, C (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
EM chover@uji.es; emarin@uji.es; rebollo@uji.es; remolar@uji.es
RI Chover Sellés, Miguel/P-9933-2018; Rebollo Santamaría,
   Cristina/T-1272-2017; Marin-Lora, Carlos/AAN-8230-2021; Remolar
   Quintana, Inmaculada/T-1268-2017
OI Chover Sellés, Miguel/0000-0002-0525-7038; Rebollo Santamaría,
   Cristina/0000-0002-1328-2110; Marin-Lora, Carlos/0000-0003-1055-7657;
   Remolar Quintana, Inmaculada/0000-0002-7743-2579
CR Ampatzoglou A, 2010, INFORM SOFTWARE TECH, V52, P888, DOI 10.1016/j.infsof.2010.05.004
   Anderson EF, 2008, P 2008 C FUT PLAY RE, P228, DOI [DOI 10.1145/1496984, DOI 10.1145/1496984.1497031, 10.1145/1496984.1497031]
   [Anonymous], GAM MAK
   [Anonymous], 2006, The cognitive style of PowerPoint: Pitching Out Corrupts within
   [Anonymous], DIGITOPOLIS
   [Anonymous], 6 OOPSL WORKSH DOM S
   [Anonymous], EPIC GAM
   [Anonymous], UNREAL ENGINE GAME D
   [Anonymous], GAME DEV CONSTRUCT
   [Anonymous], P 45 ACM TECHN S COM
   Bácsi S, 2019, ACTA CYBERN, V24, P5, DOI 10.14232/actacyb.24.1.2019.2
   Biswas PK, 2008, APPL SOFT COMPUT, V8, P127, DOI 10.1016/j.asoc.2006.11.009
   Blackwell AF, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P240, DOI 10.1109/VL.1996.545293
   Catto E., 2011, Box2d, a 2d physics engine for games
   Chang SE, 2005, COMPUT HUM BEHAV, V21, P713, DOI 10.1016/j.chb.2004.02.021
   Chao PY, 2016, COMPUT EDUC, V95, P202, DOI 10.1016/j.compedu.2016.01.010
   Chen C, 2016, TELEMAT INFORM, V33, P1155, DOI 10.1016/j.tele.2015.11.005
   Chen WK, 2007, IEEE T EDUC, V50, P197, DOI 10.1109/TE.2007.900026
   Correa JDC, 2015, DIGITOPOLIS
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Davis FD, 2004, IEEE T ENG MANAGE, V51, P31, DOI 10.1109/TEM.2003.822468
   Dekhane S., 2012, Journal of Computing Sciences in Colleges, V28, P117
   Deloura M., 2000, Game Programming Gems
   Folmer E, 2007, LECT NOTES COMPUT SC, V4608, P66
   Furtado AWB, 2011, IEEE SOFTWARE, V28, P30, DOI 10.1109/MS.2011.101
   Furtado AW, 2006, 6 OOPSL WORKSH DOM S
   Game Maker, 2019, GAM MAK
   GILCHRIST VJ, 1992, RES METH PR, V3, P70
   Guo B, 2012, MULTIMED TOOLS APPL, V59, P259, DOI 10.1007/s11042-010-0711-z
   Hanks K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P333
   Kiper JD, 1997, J VISUAL LANG COMPUT, V8, P175, DOI 10.1006/jvlc.1996.0034
   Koulouri T., 2014, ACM Transactions on Computing Education (TOCE), V14, P26
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Liu JJ, 2014, PROCEEDINGS OF THE 45TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'14), P169, DOI 10.1145/2538862.2538978
   Lystad RP, 2014, ORTHOP J SPORTS MED, V2, DOI 10.1177/2325967113518492
   Maloney J., 2010, ACM T COMPUT EDUC, V10, P16, DOI DOI 10.1145/1868358.1868363
   Menard M., 2011, Game development with unity, V1
   Messaoudi Farouk., 2015, 2015 international workshop on network and systems support for games (NetGames), P1
   Millington I., 2018, Artificial Intelligence for Games
   Millington Ian., 2010, GAME PHYS ENGINE DEV, V2nd
   Milne I., 2002, Education and Information Technologies, V7, P55, DOI 10.1023/A:1015362608943
   Ouahbi I, 2015, PROCD SOC BEHV, V191, P1479, DOI 10.1016/j.sbspro.2015.04.224
   Powers K., 2006, SIGCSE Bulletin, V38, P560, DOI 10.1145/1124706.1121514
   Reyno EM, 2008, GAMEON
   Robins A., 2003, COMPUT SCI EDUC, V13, P137, DOI [10.1076/csed.13.2.137.14200, DOI 10.1076/CSED.13.2.137.14200]
   Nuñez-Valdez ER, 2013, INT J INTERACT MULTI, V2, P33, DOI 10.9781/ijimai.2013.224
   Roy Krishnendu., 2012, 2012 Frontiers in Education Conference Proceedings, P1
   Salen K., 2006, GAME DESIGN READER R
   Stemkoski L, 2017, GAME DEV CONSTRUCT
   Treglia D., 2002, Game Programming Gems 3
   Unreal Engine, 2019, EPIC GAM
   Valcasara N, 2005, UNREAL ENGINE GAME D
   Van der Spuy R, 2015, LEARN PIXI JS
   Varma KVSRP, 2016, APPL SOFT COMPUT, V49, P137, DOI 10.1016/j.asoc.2016.05.010
   Williams D., 2002, International Journal of Media Management, V4, P41
   Wing JM, 2008, PHILOS T R SOC A, V366, P3717, DOI 10.1098/rsta.2008.0118
   Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Yao JR, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11061579
   Zarraonandia T, 2017, MULTIMED TOOLS APPL, V76, P9073, DOI 10.1007/s11042-016-3457-4
   Zarraonandia T, 2015, MULTIMED TOOLS APPL, V74, P4535, DOI 10.1007/s11042-013-1821-1
NR 61
TC 1
Z9 2
U1 5
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12307
EP 12328
DI 10.1007/s11042-019-08433-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400046
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, G
   Pu, PB
   Shen, TY
AF Wang, Ge
   Pu, Pengbo
   Shen, Tingyan
TI An efficient gene bigdata analysis using machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data analytics; Gene big data; Machine learning algorithms;
   Bioinformatics; Pattern recognition; Prediction
ID REGULATORY ELEMENTS; GENOME ANNOTATION; NEURAL-NETWORK; PRE-MIRNAS;
   CLASSIFICATION; PREDICTION; SEQUENCE; DNA
AB Bioinformatics is one of the emerging and rapidly developing research areas that is predominantly used for genetic data analysis and processing. Bioinformatics is characterized by its huge and voluminous data that is growing in nature which in turn complicates data analysis. In most cases, Bioinformatics data analysis and processing involve big data analytics due to the complex nature of the data. Previous research works handled data analytics using traditional tools and conventional big data analytical methods. However, it can be proved that machine learning algorithms and approaches can be effectively deployed to perform parallel, distributed and incremental processing of complex big data analytics especially in the case of gene big data analytics to enhance the efficiency in processing this large chunk of Bioinformatics-based gene big data. This paper provides a Machine Learning algorithm-based Convolution Neural Network (ML-CNN) approach for the process of identifying potential target genes, predicting miRNAs, visualizing the unique miRNA patterns, and validating genomes. The proposed approach has experimented with MATLAB software using deep learning toolbox on the pre - miRNA dataset. Experimental results indicate that machine learning algorithms certainly increases the efficiency of Bioinformatics-based methods of processing gene data in terms of prediction accuracy and reduced processing time. The mean performance of ML-CNN is improved 7% high than the existing system.
C1 [Wang, Ge; Pu, Pengbo] Shandong Univ Sci & Technol, Dept Informat Engn, Tai An, Shandong, Peoples R China.
   [Shen, Tingyan] Chinese Peoples Liberat Army Gen Hosp, Med Sch, Chinese PLA, Beijing 100853, Peoples R China.
C3 Shandong University of Science & Technology; Chinese People's Liberation
   Army General Hospital
RP Wang, G (corresponding author), Shandong Univ Sci & Technol, Dept Informat Engn, Tai An, Shandong, Peoples R China.
EM wanggeg@163.com; sdustppb@163.com; 492914016@qq.com
FU National Natural Science Foundation of China [91746104]
FX This research is supported by National Natural Science Foundation of
   China (Grant: 91746104). The author would like to thank all the students
   and teachers for their efforts. We are also appreciating the reviewers
   and editors for their valuable suggestions and comments to improve this
   work.
CR Akhtar MN, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-646
   Alexander RP, 2010, NAT REV GENET, V11, P559, DOI 10.1038/nrg2814
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556
   Ashley EA, 2015, JAMA-J AM MED ASSOC, V313, P2119, DOI 10.1001/jama.2015.3595
   Barash Y, 2010, NATURE, V465, P53, DOI 10.1038/nature09000
   Batuwita R, 2009, BIOINFORMATICS, V25, P989, DOI 10.1093/bioinformatics/btp107
   Benson DA, 2007, Res, V35, pD25, DOI DOI 10.1093/NAR/GKL986
   Chang TH, 2011, MED BIOL ENG COMPUT, V49, P463, DOI 10.1007/s11517-011-0732-4
   Danckwardt S, 2008, EMBO J, V27, P482, DOI 10.1038/sj.emboj.7601932
   de Klerk E, 2015, TRENDS GENET, V31, P128, DOI 10.1016/j.tig.2015.01.001
   Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475
   Elkon R, 2013, NAT REV GENET, V14, P496, DOI 10.1038/nrg3482
   Floudas CA, 2007, BIOTECHNOL BIOENG, V97, P207, DOI 10.1002/bit.21411
   Harrow J, 2012, GENOME RES, V22, P1760, DOI 10.1101/gr.135350.111
   Herrero J, 2002, J PROTEOME RES, V1, P467, DOI 10.1021/pr025521v
   Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126
   Kleftogiannis D, 2015, IEEE ACM T COMPUT BI, V12, P1183, DOI 10.1109/TCBB.2014.2388227
   Kozomara A, 2019, NUCLEIC ACIDS RES, V47, pD155, DOI 10.1093/nar/gky1141
   Laing C, 2011, CURR OPIN STRUC BIOL, V21, P306, DOI 10.1016/j.sbi.2011.03.015
   Lee TI, 2013, CELL, V152, P1237, DOI 10.1016/j.cell.2013.02.014
   Leung MKK, 2014, BIOINFORMATICS, V30, P121, DOI 10.1093/bioinformatics/btu277
   Li X, 2010, RNA, V16, P1096, DOI 10.1261/rna.2017210
   Lorenz R, 2011, ALGORITHM MOL BIOL, V6, DOI 10.1186/1748-7188-6-26
   Mande SS, 2012, BRIEF BIOINFORM, V13, P669, DOI 10.1093/bib/bbs054
   Martins P.V.L., 2018, THESIS
   Marx V, 2013, NATURE, V496, P253, DOI [10.1038/496253a, 10.1038/498255a]
   Maston GA, 2006, ANNU REV GENOM HUM G, V7, P29, DOI 10.1146/annurev.genom.7.080505.115623
   Ng KLS, 2007, BIOINFORMATICS, V23, P1321, DOI 10.1093/bioinformatics/btm026
   Park C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201056
   Pasaila D, 2011, ADV EXP MED BIOL, V696, P17, DOI 10.1007/978-1-4419-7046-6_2
   Rahman ME, 2012, GENOMICS, V99, P189, DOI 10.1016/j.ygeno.2012.02.001
   Rubin MA, 2015, NATURE, V520, P290, DOI 10.1038/520290a
   Saçar MD, 2014, METHODS MOL BIOL, V1107, P177, DOI 10.1007/978-1-62703-748-8_10
   Saeys Y, 2007, BIOINFORMATICS, V23, pI418, DOI 10.1093/bioinformatics/btm177
   Schatz MC, 2013, IEEE SPECTRUM, V50, P28, DOI 10.1109/MSPEC.2013.6545119
   Sonnenburg S, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S10-S7
   Stephens ZD, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002195
   Thomas J, 2017, ARXIV170403834
   Wan Y, 2011, NAT REV GENET, V12, P641, DOI 10.1038/nrg3049
   Wang LK, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4932-2
   Wang XW, 2008, BIOINFORMATICS, V24, P325, DOI 10.1093/bioinformatics/btm595
   Wang ZF, 2008, RNA, V14, P802, DOI 10.1261/rna.876308
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   XIAO JM, 2011, BMC BIOINFORMATICS, V12
   Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806
   Xiong HY, 2011, BIOINFORMATICS, V27, P2554, DOI 10.1093/bioinformatics/btr444
   Xue CH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-310
   Yandell M, 2012, NAT REV GENET, V13, P329, DOI 10.1038/nrg3174
   Yip KY, 2013, GENOME BIOL, V14, DOI 10.1186/gb-2013-14-5-205
   Zhou J, 2014, INT CONF MACH LEARN, P71, DOI 10.1109/ICMLC.2014.7009094
NR 51
TC 5
Z9 5
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9847
EP 9870
DI 10.1007/s11042-019-08358-7
EA APR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000523403000001
DA 2024-07-18
ER

PT J
AU Kalaivani, S
   Shantharajah, SP
   Padma, T
AF Kalaivani, S.
   Shantharajah, S. P.
   Padma, T.
TI Agricultural leaf blight disease segmentation using indices based
   histogram intensity segmentation approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cotton leaf disease; Indices based histogram intensity segmentation;
   Leaf disease identification; Solanum nigrum leaf disease; Validity
   measures
ID ALGORITHM
AB Grouping of pixels based on certain kind of similarity or discontinuity among the pixel called Segmentation. Segmentation of ROI from the given input image determines the success of analysis. Validity metrics helps to measure the similarity of the segmented image result. Most important and required for human survival is food. In that scenario Agriculture industry plays a vital role and the industry faces lose because of certain reasons. One of the reason to yield lose is unaware of disease diagnosis and most of the time farmer can predict disease at last moment. By implementing technological improvement in agriculture industry try to improve the crops lose and that results increasing farmer income. Indices based intensity histogram segmentation technique used to segment the disease affected part from unhealthy leaf with better accuracy rate. Segmentation is important stage in image processing technique and it helps to diagnose the diseased region. After categorizing the disease affected area it is most important to validate the segmented image. Validation algorithms are used to validate the segmented part and most famous similarity measures are Dice index measure, over lab coefficient measure, Jaccard coefficient measure, Cosine measure, Asymmetric measure, Dissimilarity measures etc. The introduced method successfully segments the affected region with 98.025% accuracy also the segmented region have 0.964% of mutual information.
C1 [Kalaivani, S.] Asan Coll Arts & Sci, Dept Comp Sci, Karur, India.
   [Shantharajah, S. P.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Padma, T.] Sona Coll Technol, Dept Master Comp Applicat, Salem, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Sona College of
   Technology
RP Kalaivani, S (corresponding author), Asan Coll Arts & Sci, Dept Comp Sci, Karur, India.
EM kalaivanideepan@gmail.com
OI Shantharajah, SP/0000-0001-5211-0066; Theagarajan,
   Padma/0000-0001-8213-5985
CR [Anonymous], CURR MED IMAGING REV
   [Anonymous], INT J ADV RES ARTIF
   [Anonymous], MED PLANTS
   [Anonymous], COTTON MARKET SUSTAI
   [Anonymous], ADV COMPUTER SCI INF
   [Anonymous], COMUNICATION COMPUTE
   [Anonymous], 2008, ASSESS IMAGE ANAL SO
   Barbedo JGA, 2017, EUR J PLANT PATHOL, V147, P349, DOI 10.1007/s10658-016-1007-6
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Correa-Tome FE, 2011, OPT ENG, V50, DOI 10.1117/1.3651799
   Jun Pang, 2011, 2011 International Conference on Image Analysis and Signal Processing (IASP 2011), P590, DOI 10.1109/IASP.2011.6109113
   Kalaivani S., 2017, J ADV RES DYNAMIC CO, V14, P1694
   Ma JC, 2017, COMPUT ELECTRON AGR, V142, P110, DOI 10.1016/j.compag.2017.08.023
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Padma T, 2017, STUD COMPUT INTELL, V705, P225, DOI 10.1007/978-3-319-53153-3_12
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Wang JL, 2013, COMPUT ELECTRON AGR, V96, P23, DOI 10.1016/j.compag.2013.04.014
NR 21
TC 20
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9145
EP 9159
DI 10.1007/s11042-018-7126-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600042
DA 2024-07-18
ER

PT J
AU Zhou, YJ
   Di, CA
AF Zhou, Yi-Jie
   Di, Chang-An
TI Human motion recognition based on Kalman random Forest algorithm and 3D
   multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action; Outline; Track; Self-adaption; Kalman; Random forest; 3D
   multimedia
AB A human motion recognition method based on Kalman random forest algorithm model is proposed to improve the accuracy and efficiency of tracking algorithm aiming at the multi-degree-of-freedom problem of traditional human motion recognition and tracking. Firstly, a simple explicit manifold space model of human motion parameters is established. Reconstruction of three-dimensional image features for human motion requires accurate identification of human behavioral features. The human motion process is highly random, and the sudden change in motion amplitude causes a sudden change in the number of shape-based parameters in the three-dimensional feature. The compact low-dimensional model simplifies the difficulty of human motion parameters contour tracking; Secondly, Kalman random forest algorithm is used to estimate the global transformation of action and the different distance measures of body action in each sub-state by using action characteristics through boundary approximation and action sequence updating, so as to reduce the computational complexity of the algorithm; Finally, the single shape change and the dynamic action in motion are modeled, and the dynamic tracking of human motion is realized through the linear combination of human motion shape and style factor decomposition.
C1 [Zhou, Yi-Jie; Di, Chang-An] Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Zhou, YJ (corresponding author), Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing 210094, Peoples R China.
EM yaxingxing26@163.com
CR Atrsaei A, 2016, J BIOMECH ENG-T ASME, V138, DOI 10.1115/1.4034170
   Cabras S, 2016, APPL STOCH MODEL BUS, V32, P209, DOI 10.1002/asmb.2145
   Cheng XM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040486
   Kang CW, 2016, IEEE SENS J, V16, P8953, DOI 10.1109/JSEN.2016.2607223
   Kuhner A, 2016, IEEE RSJ INT C INT R
   Kumpan P, 2017, INT C MECH
   Li NJ, 2016, PATTERN ANAL APPL, V19, P267, DOI 10.1007/s10044-015-0463-5
   Olivares A, 2016, COMPUT BIOL MED, V72, P229, DOI 10.1016/j.compbiomed.2015.08.007
NR 8
TC 1
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9891
EP 9899
DI 10.1007/s11042-019-08018-w
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600009
DA 2024-07-18
ER

PT J
AU Ben Farah, MA
   Guesmi, R
   Kachouri, A
   Samet, M
AF Ben Farah, M. A.
   Guesmi, R.
   Kachouri, A.
   Samet, M.
TI A new design of cryptosystem based on S-box and chaotic permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-box; Logistic map; Randomness; Nonlinearity; Optimization
ID ENCRYPTION SCHEME; ALGORITHM; MAP
AB In this paper, we present a new design of cryptosystem characterized by an optimized substitution box (S-box) and random permutation. Our proposed S-box is generated using a modified genetic algorithm. The crossover process is performed with sophisticated research using the best previous population. We use randomness and ergodicity of the logistic map to add complexity and robustness to our proposed method. Many tests proving the nonlinearity of our S-box have been carried out to demonstrate the efficiency of our algorithm. In the second part, we offer a new permutation algorithm based on a chaotic sequence generated from the logistic map. To show the performance of our proposition, we compare our results with previous algorithms. The results of its statistical analysis, like entropy value and correlation between adjacent pixels, show that the proposed image encryption scheme provides security for image encryption. The time speed of the proposed algorithm confirms the possibility of real-time implementation.
C1 [Ben Farah, M. A.; Guesmi, R.; Kachouri, A.; Samet, M.] Sfax Univ, LETI Lab, Natl Engn Sch Sfax, BPW 3038, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ben Farah, MA (corresponding author), Sfax Univ, LETI Lab, Natl Engn Sch Sfax, BPW 3038, Sfax, Tunisia.
EM aminefrh5@gmail.com; ramzi.guesmi@gmail.com;
   abdennaceur.kachouri@enis.rnu.tn; mounir.samet@enis.rnu.tn
RI Guesmi, Ramzi/AAD-1216-2020; Farah, Mohamed Amine Ben/AAI-1932-2019
OI Guesmi, Ramzi/0000-0001-8759-0151; Farah, Mohamed Amine
   Ben/0000-0002-0135-9942
CR Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Chidambaram N, 2019, MULTIMED TOOLS APPL, P1
   Farah A, 2018, NONLINEAR DYNAM, V93, P1451, DOI 10.1007/s11071-018-4271-5
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gueron S, 2019, US Patent, Patent No. [10,171,232, 10171232]
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Guesmi R, 2014, I C COMP SYST APPLIC, P678, DOI 10.1109/AICCSA.2014.7073265
   Hamza R., 2019, INFORM SCI
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Kanmani M, 2019, MULTIDIMENSIONAL SYS, P1
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Lawrence EB., 2010, SP 800-22 Rev. 1a. A statistical test suite for random and pseudorandom number generators for cryptographic applications
   Liang C, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1476-3
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Manoj RJ, 2019, CLUSTER COMPUT, V22, pS3953, DOI 10.1007/s10586-018-2550-z
   Nesa N, 2019, J INF SECUR APPL, V47, P320, DOI 10.1016/j.jisa.2019.05.017
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Parvees M. Y. M., 2018, ADV BIG DATA CLOUD C, P309
   Singh Gurpreet, 2013, INT J COMPUT APPL, V67
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
NR 39
TC 55
Z9 55
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19129
EP 19150
DI 10.1007/s11042-020-08718-8
EA MAR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300006
DA 2024-07-18
ER

PT J
AU Zheng, PJ
   Zhang, YH
AF Zheng, Peijia
   Zhang, Yonghong
TI A robust image watermarking scheme in hybrid transform domains resisting
   to rotation attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Robust watermarking; Rotation attack; Singular value
   decomposition (SVD)
ID TAMPER DETECTION; SVD; BLIND
AB Image watermarking provides a promising solution to digital media copyright protection. However, the robust performance of the watermarking scheme should be carefully considered. In this paper, we propose a robust image watermarking scheme, which shows good robustness against common watermarking attacks and rotation attacks. The hybrid method based on discrete wavelet transform (DWT) and discrete cosine transform (DCT) helps concentrate the image energy and improve the robust performance of the image watermarking scheme. Besides, the employment of singular value decomposition (SVD) makes the proposed scheme more robust against rotation attack. We conduct experiments on the visual quality and the robustness of our watermarking scheme. The experimental results are generally satisfactory.
C1 [Zheng, Peijia; Zhang, Yonghong] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
   [Zheng, Peijia] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Zheng, PJ (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.; Zheng, PJ (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Peoples R China.
EM zhpj@mail.sysu.edu.cn; zhangyh267@mail2.sysu.edu.cn
RI Zhang, Yonghong/AAU-3020-2020
OI Zhang, Yonghong/0000-0002-7305-9295
FU Guangdong Natural Science Foundation [2019A1515010746, 2015A030310319];
   Fundamental Research Funds for the Central Universities [19LGPY218];
   NSFC [61502547]; Opening Project of GuangDong Province Key Laboratory of
   Information Security Technology [2017B030314131]
FX This work was supported in part by the Guangdong Natural Science
   Foundation under Grant 2019A1515010746 and Grant 2015A030310319, in part
   by the Fundamental Research Funds for the Central Universities under
   Grant 19LGPY218, in part by the NSFC under Grant 61502547, and in part
   by the Opening Project of GuangDong Province Key Laboratory of
   Information Security Technology under Grant 2017B030314131.
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Cedillo-Hernandez M, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P715, DOI 10.1109/TSP.2012.6256390
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen MS, 2016, PROC SPIE, V10033, DOI 10.1117/12.2245059
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Deb K., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P458, DOI 10.1109/ICECE.2012.6471586
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gonzalez RC., 1977, DIGITAL IMAGE PROCES, P451, DOI DOI 10.1109/CVPR.2014.81
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hu WC, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033005
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   KASHYAP N, 2012, INT J MODERN ED COMP, V4, P50, DOI DOI 10.5815/IJMECS.2012.03.07
   Lee JS, 2014, IEEE MULTIMEDIA, V21, P60, DOI 10.1109/MMUL.2014.14
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Makbol NM, 2013, LECT NOTES COMPUT SC, V8237, P36, DOI 10.1007/978-3-319-02958-0_4
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Rahim Ansari, 2012, COMM INF COMP TECHN, P1
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Singh S.P., 2012, INT J EMERGING TECHN, V2, P300, DOI DOI 10.1016/J.PATCOG.2014.05.017
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   TREFETHEN LN, 1997, NUMERICAL LINEAR ALG, V50, DOI DOI 10.1016/J.NEUNET.2012.02.016
   Wang XY, 2013, NONLINEAR DYNAM, V73, P1945, DOI 10.1007/s11071-013-0915-7
   Zheng PJ, 2018, IEEE T IMAGE PROCESS, V27, P2541, DOI 10.1109/TIP.2018.2802199
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
NR 35
TC 15
Z9 15
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18343
EP 18365
DI 10.1007/s11042-019-08490-4
EA MAR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518068900004
DA 2024-07-18
ER

PT J
AU Roy, ND
   Biswas, A
AF Roy, Nilanjana Dutta
   Biswas, Arindam
TI Fast and robust retinal biometric key generation using deep neural nets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal feature extraction; Deep neural network; Image registration;
   Biometric features; Retinal vascular network
ID BLOOD-VESSELS; SEGMENTATION; IMAGES; EXTRACTION; NETWORKS; TRACKING;
   WAVELET
AB For biometric identification with retina, vascular structure based features bear significance in preparing retinal digital templates. This requires analysis of large amount of data from different sources. It needs a faster and robust automated system to extract the quantitative measures from huge amount of retinal images. Therefore, fast and accurate detection of existing retinal features is an important element for a successful biometric identification. In this work, we propose to design and implement a retinal biometric key generation framework with deep neural network. The purpose is to replace the semi-automated or automated retinal vascular feature identification methods. The approach begins with segmentation from coloured fundus images, followed by selection of some unique features like center of optic disc, macula center and distinct bifurcation points on a convolutional neural network model. For better understanding, the key generation process has finally been shown with the help of a graphical user interface. This network was trained and tested with the training and testing images of DRIVE dataset and some of our previously published result sets on automated feature extraction methods. The network was trained on NVIDIA Titan Xp GPU provided by NVIDIA corporation.
C1 [Roy, Nilanjana Dutta] Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
   [Biswas, Arindam] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Indian Institute
   of Engineering Science Technology Shibpur (IIEST)
RP Roy, ND (corresponding author), Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
EM nilanjanaduttaroy@gmail.com
RI Dutta Roy, Nilanjana/AAC-7347-2022
OI Dutta Roy, Nilanjana/0000-0002-8531-4361
CR Abdullah M, 2016, PEERJ, V4, DOI 10.7717/peerj.2003
   [Anonymous], 2018, PROC COMP SCI INT C
   [Anonymous], LECT NOTES COMPUTATI
   [Anonymous], VIPIMAGE 2015
   [Anonymous], INT C IM SIGN PROC B
   [Anonymous], 2016 IEEE 13 INT S B
   [Anonymous], INT C EL COMP EL UPC
   [Anonymous], COMMUNICATIONS COMPU
   [Anonymous], J ADV RES
   [Anonymous], 2016, INT C MED IM COMP CO
   [Anonymous], DRIVE DATABASE IIMAG
   [Anonymous], P INT JOINT C BIOM O
   [Anonymous], SPRINGERS AISC SERIE
   Arakala A, 2009, LECT NOTES COMPUT SC, V5558, P1250, DOI 10.1007/978-3-642-01793-3_126
   Arakala A., 2011, Biometrics (IJCB), 2011 International Joint Conference on, P1
   Chaki J, 2018, A Beginner's Guide to Image Preprocessing Techniques, DOI [DOI 10.1201/9780429441134, 10.1201/9780429441134]
   Chaki J, 2020, MULTIMED TOOLS APPL, V79, P11163, DOI 10.1007/s11042-019-7181-8
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Dai PS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127748
   Dasgupta A, 2017, I S BIOMED IMAGING, P248, DOI 10.1109/ISBI.2017.7950512
   Dashtbozorg B, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2263809
   Deng KX, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/906067
   Drechsler K, 2010, IEEE INT C BIOINFORM, P456, DOI 10.1109/BIBM.2010.5706609
   Farzin H, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/280635
   Fathi A, 2013, BIOMED SIGNAL PROCES, V8, P71, DOI 10.1016/j.bspc.2012.05.005
   Fraz M. M., 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P410
   Fraz MM, 2014, INT J COMPUT ASS RAD, V9, P795, DOI 10.1007/s11548-013-0965-9
   Fu HZ, 2016, I S BIOMED IMAGING, P698, DOI 10.1109/ISBI.2016.7493362
   GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074
   Hill R.B., 1999, Biometrics: Personal Identification in Networked Society
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Lajevardi SM, 2013, IEEE T IMAGE PROCESS, V22, P3625, DOI 10.1109/TIP.2013.2266257
   Lan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1003-9
   Li ZR, 2017, J MED IMAG HEALTH IN, V7, P639, DOI 10.1166/jmihi.2017.2082
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   LIU IC, 1993, IEEE T MED IMAGING, V12, P334, DOI 10.1109/42.232264
   Mariño C, 2006, PATTERN ANAL APPL, V9, P21, DOI 10.1007/s10044-005-0022-6
   Mariño C, 2003, LECT NOTES COMPUT SC, V2905, P306
   Moraru L., 2018, Soft Computing Based Medical Image Analysis, P149
   Muhammed LA, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/2815163
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Oinonen H, 2010, IEEE IMAGE PROC, P4089, DOI 10.1109/ICIP.2010.5650657
   Ortega M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/235746
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Shriranjani D., 2018, Computational Signal Processing and Analysis. Select Proceedings of ICNETS2: LNEE 490, P287, DOI 10.1007/978-981-10-8354-9_26
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sofka M, 2006, IEEE T MED IMAGING, V25, P1531, DOI 10.1109/TMI.2006.884190
   Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738
   Vega R, 2015, COMPUT BIOL MED, V58, P20, DOI 10.1016/j.compbiomed.2014.12.016
   Wang C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020168
   Wang D, 2019, OPTIK, V179, P99, DOI 10.1016/j.ijleo.2018.10.155
   Wang D, 2017, IEEE SENS J, V17, P1407, DOI 10.1109/JSEN.2016.2641501
   Wang R, 2017, MULTIMED TOOLS APPL, V76, P23309, DOI 10.1007/s11042-016-4146-z
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Welikala RA, 2017, COMPUT BIOL MED, V90, P23, DOI 10.1016/j.compbiomed.2017.09.005
   Xu ZW, 2006, LECT NOTES COMPUT SC, V3832, P770
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
NR 60
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6823
EP 6843
DI 10.1007/s11042-019-08507-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900062
DA 2024-07-18
ER

PT J
AU Sengar, SS
   Mukhopadhyay, S
AF Sengar, Sandeep Singh
   Mukhopadhyay, Susanta
TI Moving object detection using statistical background subtraction in
   wavelet compressed domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Moving object detection; Wavelet; Statistical
   parameters; Morphology
ID GLOBAL MOTION ESTIMATION; HILBERT TRANSFORM PAIRS; OPTICAL-FLOW;
   EFFICIENT; ROBUST; SEGMENTATION; ALGORITHMS
AB Moving object detection is a fundamental task and extensively used research area in modern world computer vision applications. Background subtraction is one of the widely used and the most efficient technique for it, which generates the initial background using different statistical parameters. Due to the enormous size of the video data, the segmentation process requires considerable amount of memory space and time. To reduce the above shortcomings, we propose a statistical background subtraction based motion segmentation method in a compressed transformed domain employing wavelet. We employ the weighted-mean and weighted-variance based background subtraction operations only on the detailed components of the wavelet transformed frame to reduce the computational complexity. Here, weight for each pixel location is computed using pixel-wise median operation between the successive frames. To detect the foreground objects, we employ adaptive threshold, the value of which is selected based on different statistical parameters. Finally, morphological operation, connected component analysis, and flood-fill algorithm are applied to efficiently and accurately detect the foreground objects. Our method is conceived, implemented, and tested on different real video sequences and experimental results show that the performance of our method is reasonably better compared to few other existing approaches.
C1 [Sengar, Sandeep Singh] SRM Univ AP, Dept Comp Sci & Engn, Amaravati 522502, Andhra Pradesh, India.
   [Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
C3 SRM University-AP; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Sengar, SS (corresponding author), SRM Univ AP, Dept Comp Sci & Engn, Amaravati 522502, Andhra Pradesh, India.
EM sandeep.iitdhanbad@gmail.com
OI Sengar, Dr. Sandeep Singh/0000-0003-2171-9332
CR Akula A, 2014, INFRARED PHYS TECHN, V63, P103, DOI 10.1016/j.infrared.2013.12.012
   [Anonymous], ARAB J SCI ENG
   [Anonymous], 7 DIG IM COMP TECHN
   [Anonymous], SIGNAL IMAGE VIDEO P
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2019, NEURAL NETWORKS
   [Anonymous], MULTIMED TOOLS APPL
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Arici T, 2014, MULTIMED TOOLS APPL, V72, P3045, DOI 10.1007/s11042-013-1591-9
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Bouwmans T, 2018, IEEE J-STSP, V12, P1127, DOI 10.1109/JSTSP.2018.2879245
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Choi JW, 2015, MULTIMED TOOLS APPL, V74, P199, DOI 10.1007/s11042-013-1756-6
   Dou JF, 2019, MULTIMED TOOLS APPL, V78, P14549, DOI 10.1007/s11042-018-6854-z
   Dougherty E.R., 2003, Hands-on morphological image processing, V71
   Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785
   Farina A, 1997, SIGNAL PROCESS, V59, P101, DOI 10.1016/S0165-1684(97)00040-6
   Gangal P., 2014, STUD C ENG SYST SCES, P1
   Gao T, 2010, J CENT SOUTH UNIV T, V17, P187, DOI 10.1007/s11771-010-0029-z
   Gao T, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P156, DOI 10.1109/ICINFA.2008.4607987
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HESS RF, 1994, VISION RES, V34, P2431, DOI 10.1016/0042-6989(94)90287-9
   Hong GS, 2016, MULTIMED TOOLS APPL, V75, P15229, DOI 10.1007/s11042-015-2455-2
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Huang JC, 2003, ELECTRON LETT, V39, P1380, DOI 10.1049/el:20030909
   Iqbal MZ, 2013, IEEE GEOSCI REMOTE S, V10, P451, DOI 10.1109/LGRS.2012.2208616
   Khare M, 2014, IET IMAGE PROCESS, V8, P334, DOI 10.1049/iet-ipr.2012.0428
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Kushwaha AKS, 2014, IEEE INT ADV COMPUT, P973, DOI 10.1109/IAdCC.2014.6779455
   Lama RK, 2016, MULTIMED TOOLS APPL, V75, P16487, DOI 10.1007/s11042-016-3245-1
   Li S. Z., 2009, Markov random field modeling in image analysis
   Li YF, 2015, BIO-MED MATER ENG, V26, pS1067, DOI 10.3233/BME-151403
   Lina JM, 1997, J MATH IMAGING VIS, V7, P211, DOI 10.1023/A:1008274210946
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P5867, DOI 10.1109/TIP.2016.2615812
   Sakkos D, 2018, MULTIMED TOOLS APPL, V77, P23023, DOI 10.1007/s11042-017-5460-9
   Sarwas G., 2015, ADV INTELLIGENT SYST, V313, P195
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Selesnick IW, 2001, IEEE SIGNAL PROC LET, V8, P170, DOI 10.1109/97.923042
   Sengar SS, 2017, J VIS COMMUN IMAGE R, V49, P89, DOI 10.1016/j.jvcir.2017.08.007
   Sengar SS, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2345, DOI 10.1109/WiSPNET.2016.7566561
   Sengar SS, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN INFORMATION TECHNOLOGY (RAIT), P467, DOI 10.1109/RAIT.2016.7507946
   Sengar SS, 2016, OPTIK, V127, P6258, DOI 10.1016/j.ijleo.2016.03.061
   Serbes G, 2015, APPL SOFT COMPUT, V37, P87, DOI 10.1016/j.asoc.2015.08.015
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Töreyin BU, 2005, SIGNAL PROCESS-IMAGE, V20, P255, DOI 10.1016/j.image.2004.12.002
   Tulsyan A, 2014, J PROCESS CONTR, V24, P460, DOI 10.1016/j.jprocont.2013.10.015
   Vaswani N, 2018, P IEEE, V106, P1274, DOI 10.1109/JPROC.2018.2853498
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Yang JG, 2003, MECH SYST SIGNAL PR, V17, P945, DOI 10.1006/mssp.2002.1524
   Yang L, 2015, IEEE T MOBILE COMPUT, V14, P2188, DOI 10.1109/TMC.2014.2381232
   Yu RY, 2005, IEEE T SIGNAL PROCES, V53, P4723, DOI 10.1109/TSP.2005.859261
   Zhang SS, 2016, MULTIMED TOOLS APPL, V75, P6263, DOI 10.1007/s11042-015-2571-z
   Zheng AH, 2019, NEUROCOMPUTING, V328, P113, DOI 10.1016/j.neucom.2018.02.101
NR 55
TC 27
Z9 28
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5919
EP 5940
DI 10.1007/s11042-019-08506-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900022
DA 2024-07-18
ER

PT J
AU Siddeq, MM
   Rodrigues, MA
AF Siddeq, Mohammed M.
   Rodrigues, Marcos A.
TI A novel Hexa data encoding method for 2D image crypto-compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D image compression; DWT; Hexadata encoding; Fast matching search
AB We proposed a novel method for 2D image compression-encryption whose quality is demonstrated through accurate 2D image reconstruction at higher compression ratios. The method is based on the DWT-Discrete Wavelet Transform where high frequency sub-bands are connected with a novel Hexadata crypto-compression algorithm at compression stage and a new fast matching search algorithm at decoding stage. The novel crypto-compression method consists of four main steps: 1) A five-level DWT is applied to an image to zoom out the low frequency sub-band and increase the number of high frequency sub-bands to facilitate the compression process; 2) The Hexa data compression algorithm is applied to each high frequency sub-band independently by using five different keys to reduce each sub-band to1/6of its original size; 3) Build a look up table of probability data to enable decoding of the original high frequency sub-bands, and 4) Apply arithmetic coding to the outputs of steps (2) and (3). At decompression stage a fast matching search algorithm is used to reconstruct all high frequency sub-bands. We have tested the technique on 2D images including streaming from videos (YouTube). Results show that the proposed crypto-compression method yields high compression ratios up to 99% with high perceptual quality images.
C1 [Siddeq, Mohammed M.; Rodrigues, Marcos A.] Sheffield Hallam Univ, GMPR Res Grp, Sheffield, S Yorkshire, England.
C3 Sheffield Hallam University
RP Rodrigues, MA (corresponding author), Sheffield Hallam Univ, GMPR Res Grp, Sheffield, S Yorkshire, England.
EM mamadmmx76@gmail.com; M.Rodrigues@shu.ac.uk
OI Siddeq, Mohammed/0000-0002-2836-0900
CR Akan R, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0883-8
   [Anonymous], 2000, ISO/IEC 15444-1
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Duan XT, 2019, J REAL-TIME IMAGE PR, V16, P765, DOI 10.1007/s11554-018-0826-4
   Enas K, 2018, J THEOR APPL INF TEC, V96
   Grobois R, 2001, P SPIE 46 ANN M APPL
   Jackson S, 2018, ROUT RES HIGH EDUC, P3
   Knuth D., 1997, The Art of Computer Programming, Volume 3, V3, P409
   Kumar RN, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0276-z
   Lin Y, 2018, DAT COMPR C SNOWB, P423423, DOI 10.1109/DCC.2018.00076
   Neetu S, 2018, IET IMAGE PROCESS, V12, P2128, DOI [10.1049/iet-ipr.2018.5596, DOI 10.1049/IET-IPR.2018.5596]
   Pan H, 2007, IET IMAGE PROCESS, V1, P353, DOI 10.1049/iet-ipr:20060195
   Siddeq MM, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0055-6
   Siddeq MM, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0461-4
   Siddeq MM, 2015, PROCEEDINGS OF THE INTERNATIONAL CONFERENCES ON INTERFACES AND HUMAN COMPUTER INTERACTION 2015, GAME AND ENTERTAINMENT TECHNOLOGIES 2015 AND COMPUTER GRAPHICS, VISUALIZATION, COMPUTER VISION AND IMAGE PROCESSING 2015, P195
   Siddeq Mohammed M, 2016, Patent No. [WO2016/135510A1, 2016135510]
   Taubman D., 2002, Image Compression Fundamentals, Standards and Practice
   Vizireanu DN, 2005, Telsiks 2005, Proceedings, Vols 1 and 2, P518
   Watanabe O, 2004, IEEE IMAGE PROC, P3435
   Wu YD, 2004, IEEE IMAGE PROC, P3447
   Yang CN, 2018, J REAL-TIME IMAGE PR, DOI [10.1007/s11554-0180829-1, DOI 10.1007/S11554-0180829-1]
   Yang X, 2018, MULTIMED TOOLS APPL, V77, P14
NR 23
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6045
EP 6059
DI 10.1007/s11042-019-08405-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900028
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Huang, JC
   Zhou, ZH
   Shang, JY
   Niu, C
AF Huang, Junchu
   Zhou, Zhiheng
   Shang, Junyuan
   Niu, Chang
TI Heterogeneous domain adaptation with label and structural consistency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous domain adaptation; Transfer learning; Reproducing Kernel
   Hilbert space; Subspace learning
ID NEURAL-NETWORKS; COVARIATE SHIFT; INVARIANT
AB Heterogeneous domain adaptation is a challenging problem due to the fact that it requires generalizing a learning model across training data and testing data with different distributions and features. To alleviate the difficulty of this task, most researchers usually perform some data preprocessing operations. However, such operations may lead to the loss of shareable information before domain adaptation. Moreover, most current work neglects the structural information between data, which is crucial for classification. To overcome the limitations mentioned above, we propose a novel algorithm, named as heterogeneous discriminative features learning and label propagation (HDL), which includes i) features learning with label consistency through two domain-specific projections, and ii) label propagation through exploiting structural information of data. Notably, each of the two sides reinforces each other. For each objective function, the corresponding analytical solutions are presented. Comprehensive experimental evidence on a large number of text categorization, image sclassification and text to image recognition datasets verifies the effectiveness and efficiency of the proposed approach over several state-of-the-art methods.
C1 [Huang, Junchu; Zhou, Zhiheng; Shang, Junyuan; Niu, Chang] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023
FU National Key RAMP;D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research projects
   (201902020008).
CR Asaei A, 2017, IEEE-ACM T AUDIO SPE, V25, P2433, DOI 10.1109/TASLP.2017.2738445
   Audhkhasi K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4759, DOI 10.1109/ICASSP.2018.8461935
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen TR, 2012, IEEE IJCNN
   Chen WY, 2016, LECT NOTES COMPUT SC, V9909, P399, DOI 10.1007/978-3-319-46454-1_25
   Chen XL, 2016, JMLR WORKSH CONF PRO, V51, P1270
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Dai Wenyuan., 2009, ANN C NEURAL INFORM, P353
   Donahue J, 2014, PR MACH LEARN RES, V32
   FRIEDJUNGOVA M, 2018, COMMUN COMPUT PHYS, P3
   Friedjungová M, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P17, DOI 10.5220/0006396700170027
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HOFFMAN J, 2013, INT C LEARN REPR 1 2
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Johnson Rie, 2015, Adv Neural Inf Process Syst, V28, P919
   Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058
   Lawrence S, 2000, IEEE IJCNN, P114, DOI 10.1109/IJCNN.2000.857823
   Li H., 2019, IEEE T NEURAL NETWOR
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liu HF, 2019, IEEE T KNOWL DATA EN, V31, P799, DOI 10.1109/TKDE.2018.2843342
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu H, 2018, IEEE T IMAGE PROCESS, V27, P3403, DOI 10.1109/TIP.2018.2819503
   Luo Y, 2018, IEEE T NEUR NET LEAR, V29, P4051, DOI 10.1109/TNNLS.2017.2750321
   Ma L, 2019, IEEE T GEOSCI REMOTE, V57, P2305, DOI 10.1109/TGRS.2018.2872850
   Mifdal J, 2017, INT GEOSCI REMOTE SE, P3373, DOI 10.1109/IGARSS.2017.8127721
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118
   Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Shi X, 2010, IEEE IMAGE PROC, P2849, DOI 10.1109/ICIP.2010.5652059
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vidovic MMC, 2016, IEEE T NEUR SYS REH, V24, P961, DOI 10.1109/TNSRE.2015.2492619
   Wen JF, 2014, PR MACH LEARN RES, V32, P631
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiao Min., 2013, P NIPS, P1259
   Xiaojin Z, 2002, CMUCALD02107
   YAO Y, 2019, ARXIV190810552
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Zhou JT, 2016, AAAI CONF ARTIF INTE, P2400
   Zhou JTY, 2014, JMLR WORKSH CONF PRO, V33, P1095
NR 49
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17923
EP 17943
DI 10.1007/s11042-020-08731-x
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516511300003
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhou, WJ
   Wang, YJ
   Xu, LJ
AF Zhang, Yong
   Zhou, Wenjun
   Wang, Yujie
   Xu, Linjia
TI A real-time recognition method of static gesture based on DSSD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; DSSD; K-means; Transfer learning; Real-time
AB Gesture recognition is of great significance for human-machine interaction and it has broad application prospects. In order to improve the detection accuracy and speed, a real-time recognition method of static gesture based on Deconvolutional Single Shot Detector (DSSD) is proposed in this paper. We have improved the original DSSD network and the deconvolution module, used the K-means clustering algorithm to select the aspect ratios of the prior boxes to improve the detection accuracy. The detection accuracy of small data set is improved by introducing transfer learning method, and the influences of three different base networks on the DSSD network model are discussed. In order to verify the effectiveness of the proposed method, we compared it with the gesture recognition methods based on SSD300, SSD321, YOLOV2 and DES in ASL dataset. The experimental results show that the proposed method has a recognition rate of 94.8%, which is 2.7%, 2.1% and 2.8%higher than SSD300, SSD321 and YOLOv2, respectively. The detection rate is close to the method of Single-Shot Object Detection with Enriched Semantics (DES), while still maintaining a reasonable detection speed of 27 FPS. In addition, since DSSD fuse the semantic information of each feature extraction layer, the proposed method also has good detection ability for small gesture objects.
C1 [Zhang, Yong; Zhou, Wenjun; Wang, Yujie; Xu, Linjia] Hefei Univ Technol, Sch Comp & Informat, 193 Tunxi Rd, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Zhang, Y (corresponding author), Hefei Univ Technol, Sch Comp & Informat, 193 Tunxi Rd, Hefei, Anhui, Peoples R China.
EM hfgdwhb@163.com; 15156697064@163.com; wjiejie@hfut.edu.cn;
   gowaterloo@163.com
RI zhang, yong/GZM-9560-2022; Zhou, Wenjun/AAE-3095-2020
OI Zhou, Wenjun/0000-0001-5357-9237
CR [Anonymous], 2017, COMPUT RES REPOS
   [Anonymous], 2018, 2018 IEEE C COMP VIS
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2016, 2017 IEEE C COMP VIS
   [Anonymous], 2018, 2018 IEEE C COMP VIS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma GW, 2015, ARAB J GEOSCI, V8, P1881, DOI 10.1007/s12517-014-1379-x
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shrivastava A, 2017, 2017 IEEE C COMP VIS
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
NR 13
TC 14
Z9 16
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17445
EP 17461
DI 10.1007/s11042-020-08725-9
EA FEB 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516251700002
DA 2024-07-18
ER

PT J
AU Abou Elazm, LA
   Ibrahim, S
   Egila, MG
   Shawky, H
   Elsaid, MKH
   El-Shafai, W
   Abd El-Samie, FE
AF Abou Elazm, Lamiaa A.
   Ibrahim, Sameh
   Egila, Mohamed G.
   Shawky, H.
   Elsaid, Mohamed K. H.
   El-Shafai, Walid
   Abd El-Samie, Fathi E.
TI Cancelable face and fingerprint recognition based on the 3D jigsaw
   transform and optical encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; 3D jigsaw transform; Optical encryption; 2D-FRFT;
   DRPE
ID IMAGE ENCRYPTION; TEMPLATE; BIOMETRICS; SYSTEM; SECURITY; PRIVACY
AB Biometric systems are widely used now for security applications. Two major problems are encountered in biometric systems: the security problem and the dependence on a single biometric for verification. The security problem arises from the utilization of the original biometrics in databases. So, if these databases are attacked, the biometrics are lost forever. Hence, there is a need to secure original biometrics by keeping them away from utilization in biometric databases. Cancelable biometrics is an emerging security trend in the field of biometric authentication. Cancelable biometric systems depend on the transformation of biometric features into new formats so that users can replace their biometric templates in the same or different systems. In this paper, we present a proposed cancelable face and fingerprint recognition algorithm based on the 3D jigsaw transform and optical encryption. The algorithm adopts the Fractional Fourier Transform (FRFT) in the optical encryption scheme with a single random phase mask. This structure can be implemented all optically with a single lens. The proposed cancelable biometric recognition algorithm employs an optical image encryption scheme that depends on two cascaded stages of 2D-FRFT with separable kernels in both dimensions. The two stages are separated with a random phase mask. A preceding bit plane permutation process is performed on the obtained biometrics prior to the FRFT operation to achieve a high level of security. To validate the proposed algorithm for cancelable biometric recognition, different sets of face and fingerprint images are used. A comparative study is presented between the proposed algorithm and the optical Double Random Phase Encoding (DRPE) algorithm. The simulations results obtained for performance evaluation show that the proposed algorithm is safe, reliable, and feasible. It has good encryption and cancelability that reveal good performance.
C1 [Abou Elazm, Lamiaa A.; Egila, Mohamed G.; Shawky, H.] ERI, Dept Microelect, Giza, Egypt.
   [Abou Elazm, Lamiaa A.; Ibrahim, Sameh; Elsaid, Mohamed K. H.] Ain Shams Univ, Dept Elect & Elect Commun Engn, Cairo, Egypt.
   [El-Shafai, Walid; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Abou Elazm, LA (corresponding author), ERI, Dept Microelect, Giza, Egypt.; Abou Elazm, LA (corresponding author), Ain Shams Univ, Dept Elect & Elect Commun Engn, Cairo, Egypt.
EM lamiaa.abouelazm@eri.sci.eg; sameh.ibrahim@eng.asu.edu.eg;
   mohamed.gamal@eri.sci.eg; heba_shawkey@eri.sci.eg; mkelsaid@gmail.com;
   eng.waled.elshafai@gmail.com; fathi_sayed@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021; Sayed, Fathi/HRA-4752-2023; Shawkey,
   Heba/GRE-8839-2022
OI El-Shafai, Walid/0000-0001-7509-2120; Sayed, Fathi/0000-0001-8749-9518; 
CR Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   Ali MAM, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P434, DOI 10.1109/ISCAIE.2018.8405512
   Ao M, 2009, LECT NOTES COMPUT SC, V5558, P376
   Cheung KH, 2005, CISST '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY: COMPUTER GRAPHICS, P40
   Enerstvedt OM, 2017, LAW GOV TECHNOL SER, V37, P307, DOI 10.1007/978-3-319-58139-2_7
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Gao QH, 2017, IET BIOMETRICS, V6, P448, DOI 10.1049/iet-bmt.2016.0192
   Grassi M, 2009, LECT NOTES COMPUT SC, V5517, P1216, DOI 10.1007/978-3-642-02478-8_152
   Jain A, 2006, SPRINGER SCI BUSINES, V479
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jegede A., 2017, Cancelable and Hybrid Biometric Cryptosystems: Current Directions and Open Research Issues
   Jeong MY, 2011, LECT NOTES COMPUT SC, V6540, P78, DOI 10.1007/978-3-642-19376-7_7
   Jin Z., 2017, MOBILE NETWORKS MANA, P378
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Khan MK, 2008, CHAOS SOLITON FRACT, V35, P519, DOI 10.1016/j.chaos.2006.05.061
   Khan MK, 2010, DIGIT SIGNAL PROCESS, V20, P179, DOI 10.1016/j.dsp.2009.05.004
   Kim Y., 2007, 1 INT C BIOMETRICS T, P1
   Kumar P, 2011, APPL OPTICS, V50, P1805, DOI 10.1364/AO.50.001805
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0221-7
   Manzoor SI, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P306, DOI 10.1109/PDGC.2018.8745722
   Moujahdi Chouaib, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P235, DOI 10.1007/978-3-642-31254-0_27
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Qiu J, 2018, IOP CONF SER-MAT SCI, V322, DOI 10.1088/1757-899X/322/5/052050
   Rachapalli D.R., 2017, 2017 2 INT C ELECT C, P1
   Rajpoot QM, 2014, IFIP ADV INF COMM TE, V428, P169
   Rane S, 2014, IEEE MULTIMEDIA, V21, P94, DOI 10.1109/MMUL.2014.65
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C., 2015, 3rd Intrl. Wrks on biometrics and forensics, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Rathgeb C., 2012, New Trends and Developments in Biometrics, DOI DOI 10.5772/52152
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Ross A., 2008, Handbook of Biometrics, P271
   Sandhya M, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560043
   Sarkar A, 2018, ADV INTELL SYST, V710, P265, DOI 10.1007/978-981-10-7871-2_26
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Sinha A, 2005, OPT ENG, V44, DOI 10.1117/1.1906240
   Sinha A., 2013, Opt Eng, V9, P158
   Soliman R, 2018, P NATL A SCI INDIA A, P1
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   Soliman RF, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1591-0
   Soliman RF., 2019, Ann Data Sci, V6, P223, DOI [10.1007/s40745-018-0172-1, DOI 10.1007/S40745-018-0172-1]
   Sreekumar S., 2016, PROC IEEE INT C COMP, P1
   Sui JB, 2010, PROCEEDINGS OF ANNUAL CONFERENCE OF CHINA INSTITUTE OF COMMUNICATIONS, P40
   Tarek Mayada, 2017, International Journal of Network Security, V19, P498, DOI 10.6633/IJNS.201707.19(4).02
   TARIF EB, 2018, MULTIMED TOOLS APPL, V77, P2485, DOI DOI 10.1007/s11042-016-4280-7
   Dang TK, 2016, IET BIOMETRICS, V5, P229, DOI 10.1049/iet-bmt.2015.0029
   Vezzetti E, 2014, AESTHET PLAST SURG, V38, P796, DOI 10.1007/s00266-014-0334-2
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Volte, 2013, INT C CRYPT NETW SEC, P74
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zakaria Y, 2019, MULTIMED TOOLS APPL, V78, P32333, DOI 10.1007/s11042-019-07824-6
   Zheng X., 2017, INT C MAN MACH ENV S, P423
   Zhou BY, 2017, INT C PAR DISTRIB SY, P578, DOI 10.1109/ICPADS.2017.00081
NR 57
TC 52
Z9 52
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14053
EP 14078
DI 10.1007/s11042-019-08462-8
EA FEB 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515999800003
DA 2024-07-18
ER

PT J
AU Kumar, KS
   Manigandan, T
   Chitra, D
   Murali, L
AF Kumar, K. Senthil
   Manigandan, T.
   Chitra, D.
   Murali, L.
TI Object recognition using Hausdorff distance for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Shape matching; Hausdorff distance; Digit
   recognition; MNIST database
ID SHAPE; DESCRIPTORS
AB The need for reliable and efficient systems for recognition of object from image is increasing day by day. A partial list of applications that may use such system includes searching and reading in hand written documents, recognizing digit on papers and others. In the existing work, Euclidean distance is used for recognizing object, but some of object it doesn't work well. The major aim of the work is to introduce new object recognition. So the proposed work recognizing object using a shape context and Hausdorff distance is introduced. The process analyses the layout of the image into digits. In the first step, the shape context is computed for two point set and Hungarian algorithm is used to find the correspondence between two point set. The process evaluates the similarity of the two point set using Hausdorff distance. Finally, the error rate is calculated by considering the affine cost and shape context cost. The algorithm tested using the MNIST, COIL data sets and a private collection of hand written digits and encouraging results were obtained. The error rate is reduced to 0.72%.
C1 [Kumar, K. Senthil] Tamilnadu Coll Engn, Dept EEE, Coimbatore, Tamil Nadu, India.
   [Manigandan, T.] PA Coll Engn & Technol, Pollachi, India.
   [Chitra, D.] PA Coll Engn & Technol, Dept Comp Sci & Engn, Pollachi, India.
   [Murali, L.] PA Coll Engn & Technol, Dept ECE, Pollachi, India.
RP Kumar, KS (corresponding author), Tamilnadu Coll Engn, Dept EEE, Coimbatore, Tamil Nadu, India.
EM senthilasia@gmail.com; manigandan_t@yahoo.com; chitrapacet@gmail.com;
   murlak37@gmail.com
RI Lakshmanan, Murali/K-3359-2016; Kandasamy, Dr.
   Senthilkumar/AAL-6205-2020; T, Manigandan/B-4173-2018; D,
   CHITRA/AAG-2596-2020
OI Lakshmanan, Murali/0000-0002-2622-0648; Kandasamy, Dr.
   Senthilkumar/0000-0002-0053-6142; T, Manigandan/0000-0002-8647-1115; 
CR Ali SS, 2014, INT CONF FRONT INFO, P303, DOI 10.1109/FIT.2014.63
   Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990
   [Anonymous], 2007, P COMP VIS PATT REC
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   FORSYTH D, 1991, IMAGE VISION COMPUT, V9, P130, DOI 10.1016/0262-8856(91)90023-I
   Hong BW, 2015, IEEE T PATTERN ANAL, V37, P151, DOI 10.1109/TPAMI.2014.2342215
   Hung WL, 2004, PATTERN RECOGN LETT, V25, P1603, DOI 10.1016/j.patrec.2004.06.006
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li SZ., 1999, SHAPE ANAL, V6, P203
   McIlhagga W, 2011, INT J COMPUT VISION, V91, P251, DOI 10.1007/s11263-010-0392-0
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591
   VANGOOL L, 1992, GEOMETRIC INVARIANCE, P193
   Zhao CJ, 2005, PATTERN RECOGN LETT, V26, P581, DOI 10.1016/j.patrec.2004.09.022
NR 20
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4099
EP 4114
DI 10.1007/s11042-019-07774-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700056
DA 2024-07-18
ER

PT J
AU Vivek, D
   Balasubramanie, P
AF Vivek, D.
   Balasubramanie, P.
TI An Expressive phrases identification supported with feature prediction
   consuming unstructured data collection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unstructured Data; n-grams; Phrases; MDD; Depression; Tree bank;
   Perplexity; Polarity
ID EMOTION
AB It's evident that, the rate of unstructured data is increasing from different sources of social media. In these days those data are being used by many researchers for their producing research results. The sentiment analysis is one of the key research perspective predicted by analysing unstructured data, but these analyses are majorly used for business intelligence. Hence, the huge unstructured data related to medical intelligence is not used properly. In this paper, the domain is introduced in sentiment analysis in the field of medical intelligence. Herewith the Major Depression Disorder (MDD) phrases are predicted by positive and negative polarity calculation. The phrases are framed by generating the UN-gram classification methodology, which is continuously splits the sentences to identify the exact emotional phrases. The experimental results are statistically proven by the probability distribution of n-gram classifier, which is compared with the sentiment tree bank generated with the value of perplexity and polarity distribution.
C1 [Vivek, D.] Anna Univ, Dept Informat & Commun Engn, Chennai, Tamil Nadu, India.
   [Balasubramanie, P.] Kongu Engn Coll, Dept Comp Sci & Engn, Erode, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Kongu Engineering College
RP Vivek, D (corresponding author), Anna Univ, Dept Informat & Commun Engn, Chennai, Tamil Nadu, India.
EM vivekprasanth87@gmail.com; pbalu_20032001@yahoo.co.in
RI P, Balasubramanie/AAL-8742-2020; vivek, Dr/ABE-7574-2021; Suresh,
   Vivek/HGU-7298-2022
OI P, Balasubramanie/0000-0003-0188-6205; vivek, Dr/0000-0003-1092-5958;
   Suresh, Vivek/0000-0003-1092-5958
CR Akay A, 2016, IEEE J BIOMED HEALTH, V20, P977, DOI 10.1109/JBHI.2016.2539972
   Akay A, 2015, IEEE J BIOMED HEALTH, V19, P210, DOI 10.1109/JBHI.2014.2336251
   [Anonymous], ICASSP IEEE INT C AC
   [Anonymous], IEEE ACM T COMPUT BI
   [Anonymous], IEEE ACCESS
   Bandhakavi A, 2017, IEEE INTELL SYST, V32, P102, DOI 10.1109/MIS.2017.22
   Dumoulin J, 2012, JOINT INT CONF SOFT, P1, DOI 10.1109/SCIS-ISIS.2012.6505411
   Kim J, 2015, IEEE J BIOMED HEALTH, V19, P1347, DOI 10.1109/JBHI.2015.2440764
   Larsen ME, 2015, IEEE J BIOMED HEALTH, V19, P1246, DOI 10.1109/JBHI.2015.2403839
   Likforman-Sulem L, 2017, IEEE T HUM-MACH SYST, V47, P273, DOI 10.1109/THMS.2016.2635441
   Luo ZL, 2017, IEEE T KNOWL DATA EN, V29, P2125, DOI 10.1109/TKDE.2017.2720734
   Schall M, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P156, DOI 10.1109/DAS.2016.43
   Scherer S, 2016, IEEE T AFFECT COMPUT, V7, P59, DOI 10.1109/TAFFC.2015.2440264
   Sim SY, 2017, IEEE J BIOMED HEALTH, V21, P407, DOI 10.1109/JBHI.2016.2529655
   Stratou G, 2017, IEEE T AFFECT COMPUT, V8, P190, DOI 10.1109/TAFFC.2016.2614300
   Tai CH, 2016, IEEE J BIOMED HEALTH, V20, P987, DOI 10.1109/JBHI.2016.2535721
   Thomas B, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P188, DOI 10.1109/CNSC.2014.6906656
NR 17
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3791
EP 3806
DI 10.1007/s11042-018-7059-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700038
DA 2024-07-18
ER

PT J
AU Wang, YF
   Huang, JW
   He, TT
   Tu, XH
AF Wang, Yufan
   Huang, Jiawei
   He, Tingting
   Tu, Xinhui
TI Dialogue intent classification with character-CNN-BGRU networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dialogue intent classification; CNN; BGRU; Character neural embeddings
AB Dialogue intent classification plays a significant role in human-computer interaction systems. In this paper, we present a hybrid convolutional neural network and bidirectional gated recurrent unit neural network (CNN-BGRU) architecture to classify the intent of a dialogue utterance. First, character embeddings are trained and used as the inputs of the proposed model. Second, a CNN is used to extract local features from each utterance, and a maximum pooling layer is applied to select the most crucial latent semantic factors. A bidirectional gated recurrent unit (BGRU) layer architecture is used to capture the contextual semantic information. Then, two feature maps, which are the outputs of the two architectures, are integrated into the final utterance representation. The proposed model can utilize local semantic and contextual information to recognize and classify the user dialogue intent in an efficient way. The proposed model is evaluated based on a social media processing (SMP) data set and a real conversational data set. The experimental results show that the proposed model outperforms the corresponding traditional methods. In addition, compared to the CNN and BGRU methods, the classification accuracy of the proposed model is 1.4% higher for the SMP data set.
C1 [Wang, Yufan; Huang, Jiawei; He, Tingting; Tu, Xinhui] Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
C3 Central China Normal University
RP He, TT (corresponding author), Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
EM yufan_wang@mails.ccnu.edu.cn; huangjava@mails.ccnu.edu.cn;
   tthe@mail.ccnu.edu.cn
RI Wang, yufan/GQH-5640-2022
OI Luangaphirom, Thananan/0000-0002-9082-1237
CR Ali S. A., 2009, Information Technology Journal, V8, P923, DOI 10.3923/itj.2009.923.928
   [Anonymous], SCI SIN INFORM
   [Anonymous], HYBRID SPEECH RECOGN
   [Anonymous], EUR C SPEECH COMM TE
   [Anonymous], 2013, BETTER WORD REPRESEN
   [Anonymous], AUTOMATIC SPEECH REC
   [Anonymous], 6 C NAT LANG PROC CH
   [Anonymous], SCI SIN INFORM
   [Anonymous], SHORT TERM MEMORY DE
   [Anonymous], 2015, ARXIV151108630
   [Anonymous], 2016, EFFICIENT CHARACTER
   [Anonymous], 2015, MINING USER CONSUMPT
   [Anonymous], 2015, RECURRENT CONVOLUTIO
   [Anonymous], AUT SPEECH REC UND 2
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, WORKSHOP SYNTAX SEMA
   [Anonymous], INT JOINT C ART INT
   [Anonymous], INT SMART CIT C
   [Anonymous], RATIONALE AUGMENTED
   [Anonymous], 2013, C EMPIRICAL METHODS
   [Anonymous], CONVOLUTIONAL NEURAL
   [Anonymous], 2015, Nature
   [Anonymous], DIALOGUE ACT MODELLI
   Celikyilmaz A., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P425, DOI 10.1109/ASRU.2011.6163969
   Chung J, 2014, P NIPS 2014 WORKSHOP
   Er MJ, 2016, INFORM SCIENCES, V373, P388, DOI 10.1016/j.ins.2016.08.084
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Liu B, 2016, DESTECH TRANS SOC
   Maas A.L, 2013, ICML
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Socher Richard, 2013, Long Papers, P455
   Surendran D., 2006, INTERSPEECH 2006 9 I, P1
   Wang J, 2017, IEEE ENG MED BIO, P291, DOI 10.1109/EMBC.2017.8036819
   Xu X, 2018, INT PSYCHOGERIATR, V30, P1355, DOI 10.1017/S1041610217002952
   Yao KS, 2014, IEEE W SP LANG TECH, P189, DOI 10.1109/SLT.2014.7078572
   Zhang X, 2015, ADV NEUR IN, V28
   Zhou Chunting, 2015, ARXIV
NR 38
TC 7
Z9 8
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4553
EP 4572
DI 10.1007/s11042-019-7678-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500017
DA 2024-07-18
ER

PT J
AU Couturier, R
   Noura, HN
   Chehab, A
AF Couturier, Raphael
   Noura, Hassan N.
   Chehab, Ali
TI ESSENCE: GPU-based and dynamic key-dependent efficient stream cipher for
   multimedia contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight GPU Stream cipher solution; Security and performance
   analysis; Parallel computing; Dynamic Key dependent cryptographic
   primitives; Cryptanalysis
AB Data Confidentiality (DC) is considered one of the most important security services. Currently, a set of existing cipher algorithms is being used to ensure DC. However, researchers constantly investigate the design and implementation of more efficient cipher schemes. To this end, different versions of AES have been implemented efficiently on GPUs to increase the efficiency over big data. However, AES implementation on GPU exhibits limitations in terms of latency and hence, it might not be a suitable solution for high data rates in modern systems and applications. This often leads to a trade-off between system performance and security level. To address these challenges, we propose "ESSENCE", a lightweight stream cipher scheme, which combines two different Pseudo-Random Number Generators (PRNG), and based on a dynamic key approach. The scheme achieves a high level of security with minimal latency and required resources when compared to existing cipher standards such as AES. Moreover, the implementation of the proposed dynamic key-dependent cipher scheme on GPU is more efficient compared to all existing AES implementations on GPUs. Experimental results indicate that the proposed cipher is highly efficient with a throughput more than 115 GB/s on a Titan X GPU, and more than 372 GB/s on a Titan V100 GPU. Thus, ESSENCE can be considered as a promising stream cipher candidate with high randomness degree (BigCrush of TestU01), periodicity, and key sensitivity.
C1 [Couturier, Raphael] Univ Bourgogne Franche Comte UBFC, CNRS, FEMTO ST Inst, Dijon, France.
   [Noura, Hassan N.; Chehab, Ali] Amer Univ Beirut, Dept Elect & Comp Engn, Beirut, Lebanon.
   [Noura, Hassan N.] Arab Open Univ, Dept Comp Sci, Beirut, Lebanon.
C3 Universite de Franche-Comte; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Centre National de la Recherche Scientifique
   (CNRS); American University of Beirut
RP Couturier, R (corresponding author), Univ Bourgogne Franche Comte UBFC, CNRS, FEMTO ST Inst, Dijon, France.
EM raphael.couturier@univ-fcomte.fr; hn49@aub.edu.lb; chehab@aub.edu.lb
RI Couturier, Raphaël/C-1095-2013; Noura, Hassan/U-8729-2018
OI Couturier, Raphaël/0000-0003-1490-9592; Chehab, Ali/0000-0002-1939-2740;
   Noura, Hassan/0000-0002-2589-5053
FU Maroun Semaan Faculty of Engineering and Architecture at the American
   University of Beirut; EIPHI Graduate School [ANR-17-EURE-0002]
FX This paper is partially funded by the Maroun Semaan Faculty of
   Engineering and Architecture at the American University of Beirut and by
   the EIPHI Graduate School (contract "ANR-17-EURE-0002"). We also thank
   the supercomputer facilities of the Mesocentre de calcul de
   Franche-Comte.
CR [Anonymous], 2013, DESIGNING SCI APPL G
   [Anonymous], 2009, Advanced Encryption Standard
   [Anonymous], 2017, J CRYPTOGR ENG
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Blackman D, 2018, CORR
   Chen L, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P310, DOI 10.1109/ISECS.2008.77
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Fluhrer S, WEAKNESSES KEY SCHED
   Guo GL, 2015, IEEE I C EMBED SOFTW, P1848, DOI 10.1109/HPCC-CSS-ICESS.2015.215
   Guyeux C, 2015, J SUPERCOMPUT, V71, P3877, DOI 10.1007/s11227-015-1479-8
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Klein A, 2008, DESIGN CODE CRYPTOGR, V48, P269, DOI 10.1007/s10623-008-9206-6
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Lee WK, 2016, CLUSTER COMPUT, V19, P335, DOI 10.1007/s10586-016-0536-2
   Li QJ, 2012, IEEE I C EMBED SOFTW, P843, DOI 10.1109/HPCC.2012.119
   Lim Rone Kwei, 2016, The New Codebreakers Essays Dedicated to David Kahn on the Occasion of His 85th Birthday. LNCS 9100, P125, DOI 10.1007/978-3-662-49301-4_8
   Mantin I, 2002, LECT NOTES COMPUT SC, V2355, P152
   Noura H N, 2018, MULTIMED TOOLS APPL, P1
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P15457, DOI 10.1007/s11042-017-5124-9
   Nvidia CUDA, C PROGR GUID VERS 9
   Paar C., 2009, UNDERSTANDING CRYPTO
   Panneton F., 2005, ACM Transactions on Modeling and Computer Simulation, V15, P346, DOI 10.1145/1113316.1113319
   Paul G., 2011, RC4 Stream Cipher and Its Variants
   Runtong Zhang, 2008, 2008 IEEE International Symposium on Industrial Electronics (ISIE 2008), P1463, DOI 10.1109/ISIE.2008.4676931
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Stallings W., 2017, CRYPTOGRAPHY NETWORK, V7th
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wellons C, 2017, FINDING BEST 64 BIT
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
NR 31
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13559
EP 13579
DI 10.1007/s11042-020-08613-2
EA JAN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515798800001
DA 2024-07-18
ER

PT J
AU Rabie, T
   Baziyad, M
AF Rabie, Tamer
   Baziyad, Mohammed
TI PixoComp: a novel video compression scheme utilizing temporal pixograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixogram; Video compression; MPEG; MJ2; Temporal redundancy;
   Segment-growing; Parallelization
AB This paper introduces a new compression scheme that exploits temporal redundancies in video segments utilizing the pixogram concept recently introduced in the literature. By taking into consideration the correlation between video pixels along the time domain, a pixogram has the ability to transform uncorrelated spatial areas of separate video-frames into highly correlated temporal vectors, thus increasing redundancy in the transform domain. This strategy allows for higher compression ratios in video streams. The proposed compression scheme is the first compression technique that utilizes the pixogram concept in video compression, and aims to challenge the traditional trade-off associated with high compression ratios leading to reduced visual quality. Comparisons with popular compression standards demonstrate the advantage this new approach has for highly correlated video segments. Moreover, the proposed technique is more suitable to parallelization, and thus outperforms other compression techniques in terms of execution time.
C1 [Rabie, Tamer] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
   [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; mbaziyad@sharjah.ac.ae
CR [Anonymous], INT C DEV BIOM ENG V
   [Anonymous], 1996, RFC 1951, DOI [10.17487/RFC1951, DOI 10.17487/RFC1951]
   [Anonymous], 2000, EE392J
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Boyadjis B, 2017, IEEE T CIRC SYST VID, V27, P892, DOI 10.1109/TCSVT.2015.2511879
   Grois D, 2013, PICT COD SYMP, P394, DOI 10.1109/PCS.2013.6737766
   LEWIS AS, 1990, ELECTRON LETT, V26, P396, DOI 10.1049/el:19900259
   Martini MG, 2012, SIGNAL PROCESS-IMAGE, V27, P875, DOI 10.1016/j.image.2012.01.012
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Pudlewski S, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2342202
   Rabie T, 2019, INT C COMM SIG PROC, P1
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063001
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P16657, DOI 10.1007/s11042-016-3942-9
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Ravi A, 2011, INT J WAVELETS MULTI, V9, P635, DOI 10.1142/S0219691311004341
   Santos L, 2012, IEEE J-STARS, V5, P451, DOI 10.1109/JSTARS.2011.2173906
   Servais M, 1997, COMSIG '97 - PROCEEDINGS OF THE 1997 SOUTH AFRICAN SYMPOSIUM ON COMMUNICATIONS AND SIGNAL PROCESSING, P27, DOI 10.1109/COMSIG.1997.629976
   Srinivasan S, 2004, SIGNAL PROCESS-IMAGE, V19, P851, DOI 10.1016/j.image.2004.06.005
   Tekalp A. M., 2015, Digital Video Processing, V2nd
   Vo DT, 2008, IEEE T CIRC SYST VID, V18, P609, DOI 10.1109/TCSVT.2008.918807
NR 24
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13179
EP 13196
DI 10.1007/s11042-020-08660-9
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515608600002
DA 2024-07-18
ER

PT J
AU Lee, GJ
   Jang, SW
   Kim, GY
AF Lee, Gyung-Ju
   Jang, Seok-Woo
   Kim, Gye-Young
TI Pupil detection and gaze tracking using a deformable template
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pupil detection; Gaze tracking; Head pose; Deformable template; Field of
   view
ID SYSTEM; INTERFACE
AB This paper suggests a method for tracking gaze of a person at a distance around 2 m, using a single pan-tilt-zoom (PTZ) camera. In the suggested method, images are acquired for gaze tracking by turning the camera to the wide angle mode, or the narrow angle mode, depending on the location of the person. The face that is present in the field of view (FOV) of a camera, is detected in the wide angle mode. Once the location of the face is calculated, the camera turns to the narrow angle mode. The images, which have been acquired in the narrow angle mode, contain information on the direction of gaze of the person, who is at a distance. The method for calculating the direction of gaze is comprised of the head pose estimation and gaze direction calculation steps. The head pose estimation is performed using the location information on the eyes and nose in the face. The direction of gaze is generated using the process of partitioning the pupil through a deformable template, and extracting the center of an eye using the end points of both eyes and head pose information. This paper shows that the proposed gaze tracking algorithm can effectively track the direction of a person's gaze, at varying distances.
C1 [Lee, Gyung-Ju; Kim, Gye-Young] Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 156743, South Korea.
   [Jang, Seok-Woo] Anyang Univ, Dept Software, 708-113,Anyang 5 Dong, Anyang 430714, South Korea.
C3 Soongsil University; Anyang University
RP Kim, GY (corresponding author), Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 156743, South Korea.
EM lkj0917@ssu.ac.kr; swjang7285@gmail.com; gykim11@ssu.ac.kr
OI Jang, Seok-Woo/0000-0001-5580-4098
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2018-0-01419]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2018-0-01419) supervised by the IITP(Institute for
   Information & communications Technology Promotion).
CR Alnajar F, 2017, INT J COMPUT VISION, V124, P223, DOI 10.1007/s11263-017-1014-x
   Arar NM, 2017, IEEE T CIRC SYST VID, V27, P2623, DOI 10.1109/TCSVT.2016.2595322
   Baker B W, 2001, Int J Adult Orthodon Orthognath Surg, V16, P108
   Chan CN, 2007, IEEE IND ELEC, P2389, DOI 10.1109/IECON.2007.4460366
   Cheng H, 2017, PATTERN RECOGN, V71, P36, DOI 10.1016/j.patcog.2017.04.026
   Cho DC, 2013, IEEE T BIO-MED ENG, V60, P3432, DOI 10.1109/TBME.2013.2266413
   Corcoran PM, 2012, IEEE T CONSUM ELECTR, V58, P347, DOI 10.1109/TCE.2012.6227433
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Fadda G, 2013, LECT NOTES COMPUT SC, V8156, P280
   Hallinan P. W., 1991, GEOMETRIC METHODS CO, V1570, P214, DOI DOI 10.1117/12.48426
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hennessey Craig., 2012, Proceedings of the Symposium on Eye Tracking Research and Applications, P249, DOI DOI 10.1145/2168556.2168608
   Horsley M., 2014, Current trends in eye tracking research, P1
   Iqbal N, 2013, IEEE T CONSUM ELECTR, V59, P161, DOI 10.1109/TCE.2013.6490255
   Jairath S, 2015, MACH INTELL, P131
   Kar A, 2017, IEEE ACCESS, V5, P16495, DOI 10.1109/ACCESS.2017.2735633
   Khade B.S., 2016, INT J COMPUTER SCI I, V5, P65
   Küblbeck C, 2006, IMAGE VISION COMPUT, V24, P564, DOI 10.1016/j.imavis.2005.08.005
   Lee HC, 2010, IEEE T CONSUM ELECTR, V56, P2577, DOI 10.1109/TCE.2010.5681143
   Lu F, 2017, IEEE T IMAGE PROCESS, V26, P1543, DOI 10.1109/TIP.2017.2657880
   Magee JJ, 2008, IEEE T SYST MAN CY A, V38, P1248, DOI 10.1109/TSMCA.2008.2003466
   Ramdane-Cherif Z, 2004, J Clin Monit Comput, V18, P39, DOI 10.1023/B:JOCM.0000025285.96795.d3
   Reale M, 2010, IEEE INT CON MULTI, P280, DOI 10.1109/ICME.2010.5583014
   Tamura K, 2018, IEEE ACCESS, V6, P10896, DOI 10.1109/ACCESS.2017.2734168
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wood E, 2004, P INT S EYE TRACK RE, P207
   Wu Tunhua, 2010, 2010 5th International Conference on Computer Science & Education (ICCSE 2010), P1092, DOI 10.1109/ICCSE.2010.5593420
   Yan S, 2016, INT HUM MACH SYST CY
   Yoo ByungIn., 2010, CHI EXTENDED ABSTRAC, P3709
NR 30
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12939
EP 12958
DI 10.1007/s11042-020-08638-7
EA JAN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900005
DA 2024-07-18
ER

PT J
AU Ahn, B
   Jeong, HY
AF Ahn, Byeongtae
   Jeong, Hwa-Young
TI Implement of an automated unmanned recording system for tracking objects
   on mobile phones by image processing method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto target tracking; Face detection; CAM-shift; Unmanned recording
   system
ID FEATURES
AB The use of the "selfie camera", which records many images and videos and shares them with others. Although this system is complex owing to its use of software-intensive technologies from the field of image processing, such as face detection, CAM-Shift, and FFMPEG, it has considerably better performance and efficiency than the existing unmanned recording system, which uses infrared signals in hardware-intensive technologies. This paper describes an unmanned recording system for tracking an object via image processing. Such a product had not been previously developed in the area of mobile phones. Therefore, this paper compared the developed product with the two best existing products that track via infrared signal rather than by image processing. We propose a system consisting of a commercially available mobile camera (on an 'Android' mobile OS), a servomotor for rotating the smartphone camera to the right or left, a micro-controller ('Arduino') for controlling the motor, and a wireless Bluetooth ear set for audio input.
C1 [Ahn, Byeongtae] Anyang Univ, Liberal & Arts Coll, 22,37 Beongil,Samdeok Ro, Anyang 430714, Gyeonggi Do, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul 130701, South Korea.
C3 Anyang University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul 130701, South Korea.
EM ahnbt@anyang.ac.kr; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Chen J, 2011, CLUSTER COMPUT, V14, P55, DOI 10.1007/s10586-009-0092-0
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Edelman G, 2010, FORENSIC SCI INT, V202, P26, DOI 10.1016/j.forsciint.2010.04.021
   Gentili M, 2016, COMPUT COMMUN, V89-90, P51, DOI 10.1016/j.comcom.2016.03.004
   He YJ, 2015, INFRARED PHYS TECHN, V73, P103, DOI 10.1016/j.infrared.2015.09.010
   Kim SH, 2013, CLUSTER COMPUT, V16, P757, DOI 10.1007/s10586-013-0267-6
   Lasluisa S, 2015, CLUSTER COMPUT, V18, P29, DOI 10.1007/s10586-014-0396-6
   Liu FY, 2016, IMAGE VISION COMPUT, V51, P84, DOI 10.1016/j.imavis.2016.04.008
   Liu JG, 2015, SIGNAL PROCESS, V110, P164, DOI 10.1016/j.sigpro.2014.08.028
   Liu L, 2010, CLUSTER COMPUT, V13, P181, DOI 10.1007/s10586-009-0108-9
   Raimondo D.M., 2010, IFAC P VOLUMES, V43, P61, DOI DOI 10.3182/20100913-2-FR-4014.00060
   Shen XW, 2016, PATTERN RECOGN, V53, P163, DOI 10.1016/j.patcog.2015.11.017
   Wang J, 2014, INFORM SCIENCES, V277, P512, DOI 10.1016/j.ins.2014.02.136
   Yasukawa S, 2016, NEURAL NETWORKS, V81, P29, DOI 10.1016/j.neunet.2016.05.002
   Yin JH, 2012, J NETW COMPUT APPL, V35, P1740, DOI 10.1016/j.jnca.2012.06.005
   Zhang P, 2016, NEUROCOMPUTING, V204, P87, DOI 10.1016/j.neucom.2015.07.149
   Zheng HC, 2015, OPTIK, V126, P3859, DOI 10.1016/j.ijleo.2015.07.160
NR 17
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34065
EP 34082
DI 10.1007/s11042-019-08556-3
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000505356500001
DA 2024-07-18
ER

PT J
AU Li, SG
   Cai, NN
   Yu, ZX
AF Li, Shugang
   Cai, Nannan
   Yu, Zhaoxu
TI Constructing friendship in social networks for precise peer influence
   marketing by consensus link prediction algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Friendship construction; CLPA; PIM; Social networks
ID WORD-OF-MOUTH; TRUST; FEATURES
AB In peer influence marketing (PIM), friendship can significantly influence customers' purchase decisions. While so far, existing researches ignore friendship construction among dissimilar influencers and target users in social networks, which help greatly to expand the friend count of influencers. Therefore, this study proposed a model to construct friendship among dissimilar users by smartly recommend friends to them. Specifically, for the sake of overcoming the influence of the scale-free topology on prediction accuracy, consensus link prediction algorithm (CLPA) is proposed to predict possible friendship between users in social networks by adaptively constructing the composite similarity index (SI) for specific user pairs. Based on the prediction results of CLPA, hill climbing algorithm (HCA) is developed to construct friendship among dissimilar users by increasing their similarity in social relationship. To share more consistency with other SIs in calculating user pair similarity, CLPA smartly combines the multiple SIs into one composite SI by using their total mean rough classification uniformity (TMRCU) and taboo search algorithm (TSA), where TMRCU is used to measure the consistency of various SIs in classifying the similar users and TSA is adopted to optimize the weights of SIs with different TMRCU. Furthermore, in CLPA, cluster consistency of user pairs is developed to identify the similar user pairs in the light of the high clustering consensus between the composite SI and other SIs. Finally, the experimental results in real social networks show that the proposed method is promising for precise PIM.
C1 [Li, Shugang; Cai, Nannan] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Cai, NN (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
EM westside_li@163.com; Cai_2018@sina.eom; yyzx@ecust.edu.cn
OI Yu, Zhaoxu/0000-0002-2375-0213
CR Aghabozorgi F, 2018, PHYSICA A, V501, P12, DOI 10.1016/j.physa.2018.02.010
   [Anonymous], 2013, Granular computing: Analysis and design of intelligent systems
   BACHMANN GR, 1993, ADV CONSUM RES, V20, P463
   Bapna R, 2015, MANAGE SCI, V61, P1902, DOI 10.1287/mnsc.2014.2081
   Bian JW, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P537, DOI 10.1145/2600428.2609616
   Chan VKY, 2016, ADV SOC SCI EDUC HUM, V54, P1297
   Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Dong YX, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P382, DOI 10.1109/ASONAM.2011.43
   Dou YF, 2013, INFORM SYST RES, V24, P164, DOI 10.1287/isre.1120.0463
   Engel J, 2001, NEUROSCIENTIST, V7, P340, DOI 10.1177/107385840100700410
   Escobar JW, 2014, TRANSPORT RES B-METH, V67, P344, DOI 10.1016/j.trb.2014.05.014
   Gupta AK, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P161, DOI [10.1109/iNIS.2016.045, 10.1109/iNIS.2016.32]
   Hajli N, 2014, INT J MARKET RES, V56, P673, DOI 10.2501/IJMR-2014-045
   He YL, 2015, EXPERT SYST APPL, V42, P21, DOI 10.1016/j.eswa.2014.07.018
   Kim AJ, 2010, J GLOB FASH MARK, V1, P164
   Korula N, 2016, IEEE INTERNET COMPUT, V20, P28, DOI 10.1109/MIC.2015.137
   LE BTN, 2014, NATURE, V207, P73
   Leung T, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P548, DOI 10.1109/ASONAM.2014.6921640
   Li Y, 2014, INT CONF CLOUD COMPU, P18, DOI 10.1109/CCIS.2014.7175696
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lin LY, 2010, TOUR REV, V65, P16, DOI 10.1108/16605371011083503
   Liu SX, 2015, INFORM SCIENCES, V306, P34, DOI 10.1016/j.ins.2015.01.034
   LIU W, 2015, J COMPUT INF SYST, V11, P1757
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Lü LY, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046122
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   McAuley J, 2014, ACM T KNOWL DISCOV D, V8, P73, DOI 10.1145/2556612
   MENON AK, 2011, P MACH LEARN KNOWL D, P5
   Ou Q, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.021102
   Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374
   SAUNDERS DA, 1991, CONSERV BIOL, V5, P18, DOI 10.1111/j.1523-1739.1991.tb00384.x
   Spring N, 2002, ACM SIGCOMM COMP COM, V32, P133, DOI 10.1145/964725.633039
   Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807
   Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Xie F, 2015, KNOWL-BASED SYST, V81, P148, DOI 10.1016/j.knosys.2015.02.013
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang Y, 2019, IEEE T KNOWL DATA EN, V31, P757, DOI 10.1109/TKDE.2018.2842190
   Yi XQ, 2016, IEEE IJCNN, P4451, DOI 10.1109/IJCNN.2016.7727782
   YU D, 2012, FACEBOOK FRIENDS OF
   Yuan WW, 2019, INFORM FUSION, V46, P1, DOI 10.1016/j.inffus.2018.04.004
   Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8
NR 45
TC 1
Z9 1
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7649
EP 7668
DI 10.1007/s11042-019-08317-2
EA JAN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600015
DA 2024-07-18
ER

PT J
AU Kumar, N
   Rawat, M
AF Kumar, Nitin
   Rawat, Manisha
TI RP-LPP : a random permutation based locality preserving projection for
   cancelable biometric recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptic; Revocable; PIN; Single sample
ID SLOW FEATURE ANALYSIS; FACE RECOGNITION; IMAGE; FILTERS
AB Biometrics are being increasingly used across the world, but it also raises privacy and security concerns of the enrolled identities. The main reason is due to the fact that biometrics are not cancelable and if compromised may give access to the intruder. Cancelable biometric template is a solution to this problem which can be reissued if compromised. In this paper, we suggest a simple and powerful method called Random Permutation Locality Preserving Projection (RP-LPP) for Cancelable Biometric Recognition. Here, we exploit the mathematical relationship between the eigenvalues and eigenvectors of the original biometric image and its randomly permuted version is exploited for carrying out cancelable biometric recognition. The proposed technique work in a cryptic manner by accepting the cancelable biometric template and a key (called PIN) issued to a user. The effectiveness of the proposed techniques is demonstrated on three freely available face (ORL), iris (UBIRIS) and ear (IITD) datasets against state-of-the-art methods. The advantages of proposed technique are (i) the classification accuracy remains unaffected due to cancelable biometric templates generated using random permutation, (ii) security and quality of generated templates and (iii) robustness across different biometrics. In addition, no image registration is required for performing recognition.
C1 [Kumar, Nitin; Rawat, Manisha] Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, N (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
EM nitin@nituk.ac.in; manisharawat615@gmail.com
RI Kumar, Nitin/AAT-9454-2020
OI Rawat, Dr. Manisha/0000-0002-6382-247X
CR Al-juboori AM, 2014, SCI WORLD J, DOI 10.1155/2014/246083
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], 2012, P 25 IEEE CAN C EL C
   [Anonymous], 2008, IEEE 19 INT C PATT R
   [Anonymous], 2001, MULTIDIMENSIONAL SCA
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Douxchamps D, 2008, LECT NOTES COMPUT SC, V4892, P1
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gao QH, 2017, IET BIOMETRICS, V6, P448, DOI 10.1049/iet-bmt.2016.0192
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   He Xiaofei., 2004, Advances in Neural Information Processing Systems, P16
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kaur H, 2017, P WORLD C ENG COMP S
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kumar N, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI'12), P938
   Lee DH, 2018, INT C PATT RECOG, P3390, DOI 10.1109/ICPR.2018.8545121
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Maiorana E, 2010, IEEE T SYST MAN CY A, V40, P525, DOI 10.1109/TSMCA.2010.2041653
   Marsico MD, 2016, PATTERN RECOGNITION
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2014, IET BIOMETRICS, V3, P207, DOI 10.1049/iet-bmt.2013.0049
   Samaria F. S., 1994, P 2 IEEE WORKSH APPL
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wiskott L, 2003, NEURAL COMPUT, V15, P2147, DOI 10.1162/089976603322297331
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wu SC, 2019, IEEE T INF FOREN SEC, V14, P1323, DOI 10.1109/TIFS.2018.2876838
   Xu WH, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P412, DOI 10.1109/ISECS.2008.100
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 51
TC 15
Z9 17
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2363
EP 2381
DI 10.1007/s11042-019-08228-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000028
DA 2024-07-18
ER

PT J
AU Wu, XH
   Lu, XB
   Leung, H
AF Wu, Xuehui
   Lu, Xiaobo
   Leung, Henry
TI A motion and lightness saliency approach for forest smoke segmentation
   and detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-based; Smoke segmentation; Smoke detection; Low-rank and sparse
   decomposition; Motion saliency; Lightness saliency; Group-sparse ROSL
ID BLOCK-SPARSE RPCA; BACKGROUND SUBTRACTION; PROBABILISTIC APPROACH; FIRE
   DETECTION; LOW-RANK; VIDEO; IMAGE; SEPARATION; FEATURES; MODEL
AB Most video-based detection systems rely on extracting visual features directly from divided original frames or detected motion regions achieved using conventional background subtraction. However, these approaches are not effective for smoke detection because conventional motion detection methods are sensitive to non-salient motion regions like waves, shaking tree leaves, camera jitter an so on. This tiny motion regions can be easily misclassified as smoke. Second, in the case of light smoke the background is visible with or without motion detection, such that it will deteriorate the feature quality. These regions usually occur far from smoke centers and present unstable and non-salient characteristics. This paper proposes an approach to separate the smoke region based on motion and lightness saliency detection. A low-rank and structured sparse decomposition method is used to extract the foreground regions. Saliency of smoke is then computed for further separation. These aforementioned measures ensure a reliable smoke component extraction. We propose a saliency measurement for group-sparse robust orthonormal subspace and learning (ROSL) in virtue of adaptive parameters. Experiments on challenging data sets demonstrate that the proposed method can work well on a wide range of smoke videos and give better smoke detection results.
C1 [Wu, Xuehui; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Wu, Xuehui; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
   [Leung, Henry] Univ Calgary, Dept Elect & Comp Engn, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.
C3 Southeast University - China; Southeast University - China; University
   of Calgary
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
EM xhwu@seu.edu.cn; xblu2013@126.com; lenugh@ucalgary.ca
FU National Natural Science Foundation of China [61871123]; Key Research
   and Development Program in Jiangsu Province; Priority Academic Program
   Development of Jiangsu Higher Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No.61871123), Key Research and Development Program in Jiangsu
   Province (No.BE2016739) and a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions.
CR [Anonymous], 2015, J ELECT COMPUT ENG
   [Anonymous], 2010, 100920105055 ARXIV
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], FIR SUPPR DET RES AP
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bengio S., 2009, Advances in Neural Information Processing Systems, V22, P82
   Cai M, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1504, DOI 10.1109/FSKD.2016.7603399
   Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1
   Çetin AE, 2013, DIGIT SIGNAL PROCESS, V23, P1827, DOI 10.1016/j.dsp.2013.07.003
   Chen THCH, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P104
   Chen TH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P427
   Cui Xinyi, 2009, P 17 ACM INT C MULT, P617, DOI DOI 10.1145/1631272.1631370
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Ganesh A, 2010, IEEE INT SYMP INFO, P1513, DOI 10.1109/ISIT.2010.5513538
   Gao Z, 2012, LECT NOTES COMPUT SC, V7576, P690, DOI 10.1007/978-3-642-33715-4_50
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Gopalakrishnan V, 2012, IEEE T CIRC SYST VID, V22, P683, DOI 10.1109/TCSVT.2011.2177177
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Ham S, 2011, PROC SPIE, V7877, DOI 10.1117/12.871995
   Hongda Tian, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P532, DOI 10.1109/ICME.2012.72
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1336, DOI 10.1109/TCSVT.2014.2308652
   Jia Y, 2016, FIRE TECHNOL, V52, P1271, DOI 10.1007/s10694-014-0453-y
   Kim W, 2014, IEEE T CIRC SYST VID, V24, P646, DOI 10.1109/TCSVT.2013.2290579
   Ko B, 2010, FIRE SAFETY J, V45, P262, DOI 10.1016/j.firesaf.2010.04.001
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Mairal J., 2010, NIPS
   Park J, 2013, IEEE WORK APP COMP, P200, DOI 10.1109/WACV.2013.6475019
   Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Toreyin, 2006, P 14 EUR SIGN PROC C, P1
   Toreyin B. Ugur, 2005, 2005 13th European Signal Processing Conference, P1
   Toreyin B. U., 2005, IEEE INT C IM PROC, V2, P1230
   Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10
   Wang SD, 2014, FIRE TECHNOL, V50, P959, DOI 10.1007/s10694-012-0321-6
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yang XP, 2010, INT CONF SIGN PROCES, P389, DOI 10.1109/ICOSP.2010.5657183
   Ye W, 2015, FIRE SAFETY J, V73, P91, DOI 10.1016/j.firesaf.2015.03.001
   Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Zhang ZJ, 2014, FIRE TECHNOL, V50, P745, DOI 10.1007/s10694-012-0253-1
   Zhou T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY (ICVES), P194, DOI 10.1109/ICVES.2013.6619629
NR 46
TC 12
Z9 13
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 69
EP 88
DI 10.1007/s11042-019-08047-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600004
DA 2024-07-18
ER

PT J
AU Liu, YB
   Geng, L
   Zhang, F
   Wu, J
   Zhang, L
   Xiao, ZT
AF Liu, Yanbei
   Geng, Lei
   Zhang, Fang
   Wu, Jun
   Zhang, Liang
   Xiao, Zhitao
TI Unsupervised feature selection based on local structure learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-dimensional data; Unsupervised feature selection; Local structure
   learning; Similarity matrix
AB Unsupervised feature selection has become a significant and ambitious issue due to vast amounts of high-dimensional unlabeled data in machine learning. Traditional unsupervised feature selection algorithms usually make use of the similarity matrix for feature selection, and they heavily rely on the learned structure. However, a large amount of actual data always contains many noise samples or features that may make the similarity matrix obtained from the original data unreliable. Using Ideal Local Structure Learning (LSL) method ,we propose a novel unsupervised feature selection to perform feature selection and local structure learning at the same time in this paper. In order that we can earn more exactly structure information, an ideal local structure with precisely c connected components of data (c is the number of clusters) is utilized to refine the similarity matrix. Moreover, in order to optimize our algorithm, an effectual and plain iterative algorithm is developed. Experiments on multiple public baseline datasets, including biomedical data, letter recognition digit data and face image data, reveals the outstanding performance of our algorithms in the most advanced aspects.
C1 [Liu, Yanbei; Geng, Lei; Zhang, Fang; Wu, Jun; Xiao, Zhitao] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
   [Liu, Yanbei; Geng, Lei; Zhang, Fang; Wu, Jun; Xiao, Zhitao] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Zhang, Liang] Civil Aviat Univ China, Sch Comp Sci & Technol, Tianjin 300300, Peoples R China.
C3 Tiangong University; Civil Aviation University of China
RP Xiao, ZT (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.; Xiao, ZT (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM liuyanbei@tjpu.edu.cn; genglei@tjpu.edu.cn; hhzhangfang@126.com;
   zhenkongwujun@163.com; vfleon@163.com; xiaozhitao@tjpu.edu.cn
RI Liu, Yanbei/IQR-5059-2023; geng, lei/KEZ-8801-2024
OI Geng, Lei/0000-0002-5010-2596
FU Plan Program of Tianjin Educational Science and Research [2017KJ087];
   Tianjin Science and Technology Major Projects and Engineering
   [17ZXHLSY00040, 17ZXSCSY00090]
FX This work was supported in part by Plan Program of Tianjin Educational
   Science and Research (Grant no.2017KJ087), Tianjin Science and
   Technology Major Projects and Engineering (grant No.17ZXHLSY00040 and
   No.17ZXSCSY00090).
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   Cai D., 2010, KDD, P333
   Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111
   Hou C., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1324, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-224
   Huang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3569
   Jiang Y., 2011, Proceedings of the 28th International Conference on Machine Learning (ICML-11), P89
   LI JHUX, 2017, IEEE INT C DAT MIN, P1003
   LI Z, 2012, P ASS ADV ART INT
   Liang DC, 2013, PUBLIC ADMINISTRATION IN THE TIME OF REGIONAL CHANGE (ICPM 2013), P131
   Liu YB, 2017, NEUROCOMPUTING, V219, P350, DOI 10.1016/j.neucom.2016.09.043
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Nie F., 2010, ADV NEURAL INFORM PR, V23, P1813, DOI DOI 10.5555/2997046.2997098
   NIE F, 2016, P ASS ADV ART INT
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Qian M., 2013, P 23 INT JOINT C ART, P1621
   Wang SH, 2015, AAAI CONF ARTIF INTE, P470
   Xu LY, 2006, Proceedings of the First International Conference on Maintenance Engineering, P1042
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   ZHAO Z, 2010, P ASS ADV ART INT
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
NR 22
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34571
EP 34585
DI 10.1007/s11042-019-08549-2
EA DEC 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000504164600008
DA 2024-07-18
ER

PT J
AU Luo, HB
   Ge, B
AF Luo, Haibo
   Ge, Bin
TI Image encryption based on Henon chaotic system with nonlinear term
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Henon chaotic system; Nonlinear term; Randomness; Image encryption; Bit
   recombination
ID ALGORITHM; CRYPTANALYSIS; BIFURCATION
AB Henon chaotic system is a kind of classical chaotic system which is widely studied and applied. However, when we analyze its chaotic characteristics, we can still find some shortcomings. In this paper, a Henon chaotic system with nonlinear terms is proposed and applied to image encryption. Our scheme first modifies the linear term y(n) of the original Henon chaotic system to the nonlinear term e(y(n)), and then obtains the new Henon chaotic system. Then, a series of methods such as bifurcation graph, Lyapunov exponent, linear complexity, histogram, balance, run characteristics and NIST test were used to verify the performance improvement of the new Henon chaotic system. And then, the random sequences generated by the new Henon chaotic system are combined with the image encryption algorithm to complete the image encryption through three steps: global confusion, bit recombination and pixel value diffusion. Finally, the security of the encryption algorithm is verified by secret key space analysis, anti-statistical attack analysis, anti-differential attack analysis, anti-shearing and noise attack analysis. In this paper, the improvement of Henon chaotic system and the design of encryption algorithm all have achieved good results.
C1 [Luo, Haibo; Ge, Bin] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan 232001, Peoples R China.
C3 Anhui University of Science & Technology
RP Ge, B (corresponding author), Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan 232001, Peoples R China.
EM mrluobo88@163.com; bge@aust.edu.cn
FU National Natural Science Fund project of China [61402012]
FX This work was supported by The National Natural Science Fund project of
   China (NO.61402012).
CR Ahmad J, 2017, NEURAL COMPUT APPL, V28, pS953, DOI 10.1007/s00521-016-2405-6
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   AQEELUR R, 2018, OPTIK STUTTGART, V153, P117
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Caraballo T, 2018, MATH METHOD APPL SCI, V41, P3934, DOI 10.1002/mma.4878
   [陈志刚 Chen Zhigang], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P1547
   Dong CW, 2018, CHINESE PHYS B, V27, DOI 10.1088/1674-1056/27/8/080501
   Elsadany AA, 2018, APPL MATH COMPUT, V338, P314, DOI 10.1016/j.amc.2018.06.008
   Huang Dong-Mei, 2016, Journal of Software, V27, P1729, DOI 10.13328/j.cnki.jos.005039
   JIANG H, 2014, CHINESE PHYS B, V23, P112
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Liao X, 2018, MULTIMED TOOLS APPL, P1
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Mezatio BA, 2019, CHAOS SOLITON FRACT, V120, P100, DOI 10.1016/j.chaos.2019.01.015
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Qin C, 2018, IEEE T CIRCUITS SYST, P1
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Sprott JC, 2018, CHAOS SOLITON FRACT, V113, P261, DOI 10.1016/j.chaos.2018.06.007
   Su MT, 2014, NONLINEAR DYNAM, V77, P243, DOI 10.1007/s11071-014-1287-3
   Tang HQ, 2018, IEEE ACCESS, V6, P26059, DOI 10.1109/ACCESS.2018.2832854
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Wang HJ, 2018, J APPL ANAL COMPUT, V8, P1307, DOI 10.11948/2018.1307
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Ye GD, 2013, J COMPUT THEOR NANOS, V10, P2789, DOI 10.1166/jctn.2013.3280
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang S, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418501675
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
NR 37
TC 23
Z9 24
U1 4
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34323
EP 34352
DI 10.1007/s11042-019-08072-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800006
DA 2024-07-18
ER

PT J
AU Nan, RJ
   Zhang, HQ
AF Nan, Ruijiang
   Zhang, Heqing
TI Multimedia learning platform development and implementation based on
   cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud environment; Cloud computing; Tourism major; Teaching platform
AB In recent years, with the rapid development of cloud computing, the massive storage capacity and massive computing power of cloud computing have brought new development opportunities to the security field. The traditional tourism professional multimedia teaching platform is also difficult to meet the current massive storage video. The demand for data, although there are work has been tried to deploy in the cloud environment, but a versatile platform is still an industry challenge. This paper designs and implements a cloud-based video surveillance platform based on the real-time, security, bandwidth dependence and high transmission cost of the multimedia professional teaching field. The cloud storage technology is used to solve the heterogeneity of video data. Use the cloud to solve the scalability of the platform. Then use H.264 video coding standard and RTSP video real-time transmission protocol to solve the problem of bandwidth dependence and real-time, and propose to build an embedded sensor network to carry out identity identification and centralized control separately. The network is dynamically tied to IP. The fixed video transmission method indirectly solves the instability of dynamic IP, and makes full use of FTTH resources, reducing the user cost.
C1 [Nan, Ruijiang] Hubei Univ Automot Technol, Sch Econ & Management, Shiyan, Peoples R China.
   [Zhang, Heqing] Guangzhou Univ, Tourism Coll, Guangzhou, Peoples R China.
C3 Hubei University of Automotive Technology; Guangzhou University
RP Zhang, HQ (corresponding author), Guangzhou Univ, Tourism Coll, Guangzhou, Peoples R China.
EM 20030020@huat.edu.cn; lyzhq8007@gzhu.edu.cn
RI Chen, Xupeng/KFA-5959-2024
CR Al-Ayyoub M, 2014, INT IBM CLOUD AC C
   Al-Janabi S, 2017, INT C DEV ES ENG
   [Anonymous], 2013, FUTURE GENERATION CO
   Armbrust M., 2010, Communications of the ACM
   Assuno MD, 2014, J PARALLEL DISTRIBUT
   Bono-Nuez A, 2017, NEURAL COMPUT APPL, V28, P3197, DOI 10.1007/s00521-016-2227-6
   Danenas P, 2015, EXPERT SYST APPL
   Do Q, 2018, COMPUT NETW, V138, P1, DOI 10.1016/j.comnet.2018.03.024
   Du Z, 2016, FUTURE GEN COMPUT SY
   Guinard D, 2010, IEEE T SERV COMPUT
   Hashem IAT, 2015, INFORM SYST
   Hosek J, 2014, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-07073-5_1
   Keramati A., 2014, APPL SOFT COMPUT J
   Li J L, 2013, INT C WAV ACT MED TE
   Liouane Z, 2018, APPL INTELL, V48, P2017, DOI 10.1007/s10489-017-1062-5
   Loukas A, 2012, INFORM SYST FRONT
   Patel A, 2017, REG 10 C
   Vafeiadis T, 2015, SIMULATION MODELLING
   Vazquez JI, 2010, PERV COMP COMM WORKS
   Wang Y, 2014, EXPERT SYST APPL
   Wang ZH, 2013, J RENEW SUSTAIN ENER, V5, DOI 10.1063/1.4850516
   Zhang M, 2017, INFOCOM 2017 IEEE C
NR 22
TC 8
Z9 8
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35651
EP 35664
DI 10.1007/s11042-019-08187-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800063
DA 2024-07-18
ER

PT J
AU Sarwar, S
   Ul Qayyum, Z
   Garcia-Castro, R
   Safyan, M
   Munir, RF
AF Sarwar, Sohail
   Ul Qayyum, Zia
   Garcia-Castro, Raul
   Safyan, Muhammad
   Munir, Rana Faisal
TI Ontology based E-learning framework: A personalized, adaptive and
   context aware model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontologies; E-Learning; Personalization; Adaptivity; Content Recommender
AB Enhancing the degree of learner productivity, one of the major challenges in E-Learning systems, may be catered through effective personalization, adaptivity and context awareness while recommending the learning contents to the learners. In this paper, an E-Learning framework has been proposed that profiles the learners, categorizes the learners based on profiles, makes personalized content recommendations and performs assessment based content adaptation. A mathematical model has been proposed for learner categorization using machine learning techniques (a hybrid of case based reasoning and neural networks). The learning contents have been annotated through CourseOntology in which three academic courses (each for language of C++, C and JAVA) have been modeled for the learners. A dynamic rule based recommender has been presented targeting a 'relative grading system' for maximizing the learner's productivity. Performance of proposed framework has been measured in terms of accurate learner categorization, personalized recommendation of the learning contents, completeness and correctness of ontological model and overall performance improvement of learners in academic sessions of 2015, 2016 and 2017. The comparative analysis of proposed framework exhibits visibly improved results compared to prevalent approaches. These improvements are signified to the comprehensive attribute selection in learner profiling, dynamic techniques for learner categorization and effective content recommendation while ensuring personalization and adaptivity.
C1 [Sarwar, Sohail; Ul Qayyum, Zia; Safyan, Muhammad] Univ Gujrat, Dept Comp, Gujrat, Pakistan.
   [Garcia-Castro, Raul] UPM, Madrid, Spain.
   [Munir, Rana Faisal] Univ Politecn Catalan, Barcelona, Spain.
C3 University of Gujrat; Universidad Politecnica de Madrid
RP Sarwar, S (corresponding author), Univ Gujrat, Dept Comp, Gujrat, Pakistan.
EM sohail.sarwar@seecs.edu.pk; zia.qayyum@uog.edu.pk; rgarcia@fi.upm.es;
   fmunir@essi.upc.edu
RI Sarwar, Sohail/KCJ-4936-2024; Castro, Raúl García/AAU-4456-2020
OI Sarwar, Sohail/0000-0001-7565-439X; Castro, Raúl
   García/0000-0002-0421-452X
CR AAMODT A, 1994, AI COMMUN, V7, P39
   ARDITI D, 1999, J COMPUT CIVIL ENG, V13, P578
   Bates T., 2005, TECHNOLOGY E LEARNIN
   Bouquet P, 2016, INT J INFORM ED TECH, V6
   Bozkurt A, 2015, INT REV RES OPEN DIS, V16, P330
   Bredeweg B, 2013, AI MAG, V34, P46, DOI 10.1609/aimag.v34i4.2489
   Cakula S, 2013, PROCEDIA COMPUT SCI, V26, P113, DOI 10.1016/j.procs.2013.12.011
   CONNOLLY P, 2011, INT STUD SOCIOL ED, V11, P107
   DAVID P, 2007, J COMPUT, V2, P99
   Ergen T, 2017, IEEE 25 SIGN PROC CO, DOI [10.1109/SIU.2017.7960218, DOI 10.1109/SIU.2017.7960218]
   Guarino N, 2004, HDB ONTOLOGIES
   Jahankhani H, 2015, INT J WEBOLOGY, V10
   Kaur P., 2015, INT C REC TRENDS COM
   Lafore R., OBJECT ORIENTED PROG
   LIN CC, 2008, WSEAS T INF SCI APPL, V5, P1416
   Luis E, 2013, INT C COMP SCI ED
   Mann C, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3277
   Mihaescu M. C., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P717
   Mohammad TZ, 2014, INT J COMPUTER SCI I
   Poveda-Villalon Maria, 2012, Knowledge Engineering and Knowledge Management. 18th International Conference, EKAW 2012. Proceedings, P267, DOI 10.1007/978-3-642-33876-2_24
   Rani M, 2016, COMPUT APPL ENG EDUC, V24, P706, DOI 10.1002/cae.21742
   Romero C, 2007, EXPERT SYST APPL, V33, P135, DOI 10.1016/j.eswa.2006.04.005
   Safyan M, 2017, CONTEXT AWARE PERSON
   SALAM F, 2015, J SOFTWARE, V10, P317
   Saleena B, 2015, J KING SAUD UNIV-COM, V27, P1, DOI 10.1016/j.jksuci.2014.03.007
   Sarwar Sohail, 2017, International Conference e-learning 2017. Proceedings, P159
   Sarwar S, 2016, SEMANTIC E LEARNING
   SARWAR S, 2018, INT J INFORM ED TECH, V8, P10
   SETERES V, 2012, INT J COMPUTERS ED, V58, P942
   SHEN L, 2005, INT J CONTINUED ENG, V15, P13
   SHUTE V, 2010, ED PSYCHOL, V38, P105
   STRUMILLO P, 2013, ADV SOFT COMPUTING, V19, P107
   TAMBE S, 2016, INT RES J ENG TECHNO, V3, P2062
   Vanbelle S, 2016, PSYCHOMETRIKA, V81, P399, DOI 10.1007/s11336-014-9439-4
   Viola SR, 2006, IEEE INT SYM MULTIM, P959
   Yarandi M, 2013, WEBOLOGY, V10
   YARANDI M, 2013, J WEBOLOGY, V10, P751
   Yathongchai C, 2013, IEEE C OP SYST ICOS
NR 38
TC 28
Z9 29
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34745
EP 34771
DI 10.1007/s11042-019-08125-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800024
DA 2024-07-18
ER

PT J
AU Wu, SL
   Wu, YB
   Cao, DH
   Zheng, CY
AF Wu, Songlin
   Wu, Yubin
   Cao, Danhua
   Zheng, Caiyun
TI A fast button surface defect detection method based on Siamese network
   with imbalanced samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface defect; Imbalanced issue; Machine-vision-based system; Siamese
   network
ID VISION INSPECTION SYSTEM; CLASSIFICATION
AB Surface defect detection for button is a tough task because of complex surface texture, variety of defects, and limited defect samples which often leads to an imbalanced issue. Aiming at solving these problems, a similarity metric method based on Siamese network is proposed for detecting defects of button and applied in a practical machine-vision-based system. In our system, the Siamese network with a specifically designed loss function is used for automatic feature extraction and similarity metric of samples. The learning process minimizes the specific loss function, which drives intra-class distance among positives to be smaller and inter-class distance to be larger in the feature space, so that after training, defect-free samples are clustered while defect samples are mapped to outliers. The proposed method is evaluated on button datasets of multiple kinds of defects including dent, crack, stain, hole, uneven etc. Experimental results show 98% detection precision for the proposed method, and 95% detection precision when dealing with imbalance issue, indicating its advantage over conventional methods. Comparison experiments show that for our task, the proposed loss function outperforms other recent published loss functions in face recognition or ReID field. Moreover, we optimize our method with different strategies. Our method reaches 6 fps detection speed on an embedded DSP platform, indicating its potential in providing an effective approach for online detection on production.
C1 [Wu, Songlin; Wu, Yubin; Cao, Danhua; Zheng, Caiyun] Huazhong Univ Sci & Technol, Sch Opt & Elect Informat, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Cao, DH (corresponding author), Huazhong Univ Sci & Technol, Sch Opt & Elect Informat, Wuhan 430074, Peoples R China.
EM dhcao@hust.edu.cn
CR [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2011, WORLD C ENG WCE 2011
   Cao JJ, 2017, MULTIMED TOOLS APPL, V76, P4141, DOI 10.1007/s11042-015-3041-3
   Capizzi G, 2015, ACSIS-ANN COMPUT SCI, V5, P861, DOI 10.15439/2015F258
   Çelik HI, 2014, J TEXT I, V105, P575, DOI 10.1080/00405000.2013.827393
   Cen YG, 2015, NEUROCOMPUTING, V149, P1206, DOI 10.1016/j.neucom.2014.09.007
   Chellapilla K., 2006, 10 INT WORKSHOP FRON
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Han Y, 2017, FRONT OPTOELECTRON, V10, P151, DOI 10.1007/s12200-017-0687-7
   Jian CX, 2017, MULTIMED TOOLS APPL, V76, P24413, DOI 10.1007/s11042-016-4199-z
   Jiang CC, 2016, APPL OPTICS, V55, P2331, DOI 10.1364/AO.55.002331
   Leibe B, 2017, P IEEE C COMP VIS PA
   Li WB, 2013, OPT LASER TECHNOL, V45, P654, DOI 10.1016/j.optlastec.2012.05.016
   Lin JF, 2018, ISMSI 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS, METAHEURISTICS & SWARM INTELLIGENCE, P1, DOI 10.1145/3206185.3206189
   Liu L, 2018, 2017 INT C OPT INSTR
   Liu Y, 2014, OPT LASER ENG, V55, P243, DOI 10.1016/j.optlaseng.2013.11.013
   Natarajan V, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P986, DOI 10.1109/ICIT.2017.7915495
   Park Y, 2016, IEEE T IND INFORM, V12, P597, DOI 10.1109/TII.2016.2522191
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Saimurugan M, 2011, EXPERT SYST APPL, V38, P3819, DOI 10.1016/j.eswa.2010.09.042
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shanmugamani R, 2015, MEASUREMENT, V60, P222, DOI 10.1016/j.measurement.2014.10.009
   Tajeripour F., 2008, EURASIP J. Adv. Signal Process., V2008, P60
   Tax D. M. J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P251
   Wang T, 2018, INT J ADV MANUF TECH, V94, P3465, DOI 10.1007/s00170-017-0882-0
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yang YX, 2016, SIGNAL PROCESS, V124, P54, DOI 10.1016/j.sigpro.2015.10.028
   Ye DH, 2018, IEEE GLOB CONF SIG, P1, DOI 10.1109/GlobalSIP.2018.8646669
   Yi L, 2017, STEEL RES INT, V88, P176, DOI 10.1002/srin.201600068
   Zhang C, 2017, P IEEE C COMP VIS PA
   Zhang XW, 2011, EXPERT SYST APPL, V38, P5930, DOI 10.1016/j.eswa.2010.11.030
   Zhou WJ, 2014, NEUROCOMPUTING, V123, P406, DOI 10.1016/j.neucom.2013.07.038
NR 32
TC 21
Z9 23
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34627
EP 34648
DI 10.1007/s11042-019-08042-w
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800018
DA 2024-07-18
ER

PT J
AU Fekri-Ershad, S
AF Fekri-Ershad, Shervan
TI Pap smear classification using combination of global significant value,
   texture statistical features and time series features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pap smear classification; Cervical cancer detection; Texture analysis;
   Global significant value; Statistical features
ID LOCAL BINARY PATTERNS; OPTIMIZATION; DIAGNOSIS
AB Pap smear test is routinely used today to diagnose cervical cancer. In the last 50 years, this simple test has saved millions of women's lives. Although successful, pap smears are not always perfectly analyzed and it is time-consuming work. Computer-assisted screening can be widely used for cervical cancer diagnosis today. So far, a variety of image processing based methods have been proposed for cervical cancer detection. Most of the previous methods usually addressed one of two challenges of accuracy or complexity. In most medical imaging laboratories the quality of the test images are low. Also, most of the pap smear classification methods are not resistant to rotation and gray-scale variations. Therefore, in this paper, the main motive is to provide a method that, along with the high diagnosis accuracy, has less computational complexity, and also is resistant to rotation and gray-scale variation. The proposed approach extracts textural and statistical information of the nucleus and cytoplasm of the cell image. Selected subset of harlick features, global significant value and time series features are employed in feature extraction phase. The proposed approach is evaluated using herlev dataset, which consist of 917 images in two normal and cancer classes. Our approach has been compared with some state-of-the-art methods. It is experimentally demonstrated that the proposed approach achieves the highest accuracy. Computational complexity is computed based on the running time and number of extracted dimensions. Low computational complexity and rotation invariant are some other advantages of the proposed approach.
C1 [Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.
   [Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.; Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
EM fekriershad@pco.iaun.ac.ir
RI Fekri-Ershad, Shervan/J-7600-2019
OI Fekri-Ershad, Shervan/0000-0003-1226-7610
CR Anuradha K., 2013, J GLOBAL RES COMPUTE, V4, P8
   Athinarayanan S, 2016, J IMAGE VIDEO PROCES, V6
   Attig Anja, 2011, Machine Learning and Data Mining in Pattern Recognition. Proceedings 7th International Conference, MLDM 2011, P524, DOI 10.1007/978-3-642-23199-5_39
   Bhargava A, 2018, ADV INTELL SYST, V624, P1491, DOI 10.1007/978-981-10-5903-2_155
   Bora K, 2017, COMPUT METH PROG BIO, V138, P31, DOI 10.1016/j.cmpb.2016.10.001
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Duanggate C., 2008, P INT C EMB SYST INT, P212
   Fekri-Ershad S, 2017, COMPUT J, V60, P1633, DOI 10.1093/comjnl/bxx033
   FEKRIERSHAD S, 2012, INDIAN J SCI TECHNOL, V5, P3197
   Fekriershad S, 2017, SENSOR REV, V37, P33, DOI 10.1108/SR-07-2016-0120
   Gençtav A, 2012, PATTERN RECOGN, V45, P4151, DOI 10.1016/j.patcog.2012.05.006
   Hariharan G, 2017, J COMPUT THEOR NANOS, V14, P3609, DOI [10.1166/jctn.2017.6865, DOI 10.1166/jctn.2017.6865]
   Jantzen J., 2005, Nature inspired Smart Information Systems (NiSIS 2005), P1
   Kainz P, 2017, NEURAL COMPUT APPL, V28, P1277, DOI 10.1007/s00521-016-2609-9
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Marinakis Y, 2008, EXPERT SYST APPL, V35, P1645, DOI 10.1016/j.eswa.2007.08.089
   Marinakis Y, 2009, EXPERT SYST, V26, P433, DOI 10.1111/j.1468-0394.2009.00506.x
   Mesquita Sa Junior Jarbas Joaci, 2018, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 22nd Iberoamerican Congress, CIARP 2017. Proceedings: LNCS 10657, P677, DOI 10.1007/978-3-319-75193-1_81
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Singh G., 2018, J BIOL TODAYS WORLD, V7, P30
   Sudarshan VK, 2017, COMPUT BIOL MED, V83, P48, DOI 10.1016/j.compbiomed.2017.01.019
   Taha B, 2017, COMM COM INF SC, V723, P261, DOI 10.1007/978-3-319-60964-5_23
   Tajeripour Farshad, 2011, Proceedings of 2011 International Conference on Computer Science and Network Technology, P2303
   Tajeripour F, 2012, P 11 WSEAS INT C SIG, V1, P116, DOI DOI 10.5555/2183379.2183403
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
NR 30
TC 31
Z9 32
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31121
EP 31136
DI 10.1007/s11042-019-07937-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000007
DA 2024-07-18
ER

PT J
AU Huang, J
   Jiang, W
   Li, L
   Wen, YQ
   Zhou, GJ
AF Huang, Jing
   Jiang, Wen
   Li, Lin
   Wen, Yuanqiao
   Zhou, Gaojing
TI DeeptransMap: a considerably deep transmission estimation network for
   single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Transmission estimation; Feature learning; Deep
   convolutional neural networks (CNNs)
ID WEATHER
AB Due to the ill-posed phenomenon of the classical physical model, single image dehazing based on the model has been a challenging vision task. In recent years, applying machine learning techniques to estimate a critical parameter transmission has proven to be an effective solution to this issue. Accordingly, the robustness and accuracy of learning-based transmission estimation model is extremely important, since it does impact on the final dehazing effects. The state-of-the-art dehazing algorithms by this means generally use haze-relevant features as the single input to their transmission estimation models. However, the used haze-relevant features sometimes are not sufficient and reliable in holding real intrinsic information related to haze due to their two shortcomings and ultimately bring about their less effectiveness for some dehazing cases. Based on related efforts on representation learning and deep convolutional neural networks, in this paper, we seek to achieve the robustness and accuracy of transmission estimation model for bolstering the effectiveness of single image dehazing. Specifically, we propose a hybrid model combining unsupervised and supervised learning in a considerably deep neural networks architecture, termed DeeptransMap, in order to achieve accurate transmission map from a single image. Experimental results demonstrate that our work performs favorably against several state-of-the-art dehazing methods with the same estimated goal and keeps efficient in terms of the computational complexity of transmission estimation.
C1 [Huang, Jing; Jiang, Wen; Li, Lin; Zhou, Gaojing] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430063, Hubei, Peoples R China.
   [Wen, Yuanqiao] Wuhan Univ Technol, Technol Sch Nav, Wuhan 430063, Hubei, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology
RP Huang, J (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430063, Hubei, Peoples R China.
EM huangjing@whut.edu.cn
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022
OI Huang, Jing/0000-0002-3294-5725
FU National Natural Science Foundation of China [51679180]; National Social
   Science Foundation of China [15BGL048]; Hubei Province Science and
   Technology Support Project, China [2015BAA072]
FX This work was supported by the National Natural Science Foundation of
   China (No. 51679180), the National Social Science Foundation of China
   (No. 15BGL048) and Hubei Province Science and Technology Support
   Project, China (2015BAA072). The authors greatly acknowledge all
   reviewers for their detailed comments.
CR Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], INT J COMPUT VIS
   [Anonymous], P SPIE INT SOC OPTIC
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], ARXIV150602351V8
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Bai S, 2017, MULTIMED TOOLS APPL, V76, P16145, DOI 10.1007/s11042-016-3900-6
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Economopoulos TL, 2010, IMAGE VISION COMPUT, V28, P45, DOI 10.1016/j.imavis.2009.04.011
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu J., 2017, CoRR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li B., 2017, ARXIV PREPRINT ARXIV
   Liou CY, 2008, NEUROCOMPUTING, V71, P3150, DOI 10.1016/j.neucom.2008.04.030
   McCartney EJ., 1975, Optics of Atmosphere: Scattering by Molecules and Particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xiaoliang Yu, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P286, DOI 10.1109/ICIG.2011.22
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   [禹晶 Yu Jing], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1561
   Zhang MW, 2018, MULTIMED TOOLS APPL, V77, P3303, DOI 10.1007/s11042-017-5116-9
   Zhang X., 2017, ARXIV170701083
NR 48
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30627
EP 30649
DI 10.1007/s11042-018-6536-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200056
DA 2024-07-18
ER

PT J
AU Jiang, LY
   Yuan, HH
   Li, CG
AF Jiang, Lianyuan
   Yuan, Haohao
   Li, Chungui
TI Circular hole detection algorithm based on image block
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Circular hole detection; Image block; Circle detection; Random sampling;
   Candidate circular hole; Evidence collecting; Randomized Hough transform
ID RANDOMIZED HOUGH TRANSFORM; CIRCLE DETECTION; SPEED-UP; STRATEGY; LINES
AB Circular hole detection is a common problem in computer vision and pattern recognition. Randomized Hough transform and randomized circle detection algorithm are commonly used in circle detection, with good detection robustness and accuracy. But for circular holes with smaller radius, the two algorithms will be too slow because of a large number of invalid sampling. Thus the circular hole detection algorithm based on image block is proposed in order to improve the speed of circular hole detection. The algorithm divides the image into several small blocks and 3 points from the same block are randomly selected for sampling each time. If a candidate circular hole can be obtained by calculating these 3 points, then the points in the 4 blocks (or less) closest to the center of the candidate hole will be used for evidence-collecting to determine whether the candidate circular hole is true. Experimental results on a large number of synthetic images and real images show that the detection speed of circular hole detection algorithm proposed is much faster than the speed of randomized Hough transform and randomized circle detection algorithm. In addition, the proposed algorithm has the same detection robustness and accuracy as the randomized circle detection algorithm. The block strategy proposed in this paper is also applicable to the detection of elliptical holes.
C1 [Jiang, Lianyuan] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Jiangsu, Peoples R China.
   [Jiang, Lianyuan; Yuan, Haohao; Li, Chungui] Guangxi Univ Sci & Technol, Coll Comp Sci & Commun Engn, Liuzhou 545006, Peoples R China.
   [Yuan, Haohao] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Guangxi University of
   Science & Technology; Guangxi Normal University
RP Jiang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Jiangsu, Peoples R China.; Jiang, LY (corresponding author), Guangxi Univ Sci & Technol, Coll Comp Sci & Commun Engn, Liuzhou 545006, Peoples R China.
EM jly_jly_jly@163.com
FU Natural Science Foundation of Guangxi [2016GXNSFBA380081]; National
   Natural Science Foundation of China [61751213, 61462008]; Guangxi
   Education Department [KY2016YB256, KY2016YB249]; Guangxi Key Lab of
   Multi-source Information Mining Security [MIMS17-04]; Key Laboratory of
   Industrial Process Intelligent Control Technology of Guangxi Higher
   Education Institutes [IPICT-2016-03]; Liuzhou Scientific Research and
   Technology Development Project [2016C050205]; Innovation Team Project of
   Guangxi University of Science and Technology
FX This work was supported by the Natural Science Foundation of Guangxi
   (2016GXNSFBA380081), the National Natural Science Foundation of China
   (61751213, 61462008), the Program of Guangxi Education Department
   (KY2016YB256, KY2016YB249), the Research Fund of Guangxi Key Lab of
   Multi-source Information Mining & Security (MIMS17-04), the Key
   Laboratory of Industrial Process Intelligent Control Technology of
   Guangxi Higher Education Institutes (IPICT-2016-03), Liuzhou Scientific
   Research and Technology Development Project (2016C050205), and the
   Innovation Team Project of Guangxi University of Science and Technology.
CR Ayala-Ramirez V, 2006, PATTERN RECOGN LETT, V27, P652, DOI 10.1016/j.patrec.2005.10.003
   Chen M, 2013, OPT REV, V20, P484, DOI 10.1007/s10043-013-0082-6
   Chen TC, 2001, COMPUT VIS IMAGE UND, V83, P172, DOI 10.1006/cviu.2001.0923
   Cheng HD, 2009, PATTERN RECOGN, V42, P1959, DOI 10.1016/j.patcog.2008.11.028
   Chiu SH, 2012, INT J INNOV COMPUT I, V8, P151
   Chung KL, 2008, J INF SCI ENG, V24, P503
   Chung KL, 2012, PATTERN RECOGN, V45, P252, DOI 10.1016/j.patcog.2011.07.004
   Cuevas E, 2015, IMAGING SCI J, V63, P34, DOI 10.1179/1743131X14Y.0000000079
   Cuevas E, 2013, APPL INTELL, V39, P101, DOI 10.1007/s10489-012-0396-2
   Cuevas E, 2012, SOFT COMPUT, V16, P281, DOI 10.1007/s00500-011-0741-0
   Cuevas E, 2012, EXPERT SYST APPL, V39, P713, DOI 10.1016/j.eswa.2011.07.063
   Cuevas E, 2011, PATTERN ANAL APPL, V14, P93, DOI 10.1007/s10044-010-0183-9
   Dasgupta S, 2010, SOFT COMPUT, V14, P1151, DOI 10.1007/s00500-009-0508-z
   De Marco T, 2015, PATTERN RECOGN, V48, P411, DOI 10.1016/j.patcog.2014.08.007
   Djekoune AO, 2017, OPTIK, V133, P17, DOI 10.1016/j.ijleo.2016.12.064
   Dong N, 2012, COMPUT MATH APPL, V64, P1886, DOI 10.1016/j.camwa.2012.03.040
   Huang YH, 2012, PATTERN RECOGN LETT, V33, P2071, DOI 10.1016/j.patrec.2012.06.016
   Jiang LY, 2009, OPTOELECTRON LETT, V5, P397, DOI 10.1007/s11801-009-9071-1
   Jiang LY, 2018, OPTIK, V158, P424, DOI 10.1016/j.ijleo.2017.12.064
   Jiang LY, 2016, OPTIK, V127, P232, DOI 10.1016/j.ijleo.2015.10.063
   Jiang LY, 2012, OPTIK, V123, P1834, DOI 10.1016/j.ijleo.2012.02.045
   Liu D, 2014, COMPUT ELECTR ENG, V40, P1415, DOI 10.1016/j.compeleceng.2014.03.011
   Liu WF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060590
   Manzanera A, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0149-y
   Mukhopadhyay P, 2015, PATTERN RECOGN, V48, P993, DOI 10.1016/j.patcog.2014.08.027
   Ok AO, 2015, IEEE GEOSCI REMOTE S, V12, P1347, DOI 10.1109/LGRS.2015.2401600
   Ok AO, 2014, IEEE T GEOSCI REMOTE, V52, P3125, DOI 10.1109/TGRS.2013.2270372
   Scitovski R, 2015, PATTERN RECOGN LETT, V52, P9, DOI 10.1016/j.patrec.2014.09.010
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Xu L, 2007, PATTERN RECOGN, V40, P2129, DOI 10.1016/j.patcog.2006.12.016
   Yao ZJ, 2016, EXPERT SYST APPL, V51, P26, DOI 10.1016/j.eswa.2015.12.019
   Yuan BD, 2015, PATTERN RECOGN, V48, P3268, DOI 10.1016/j.patcog.2015.01.003
   Zhang HQ, 2016, PATTERN RECOGN, V54, P218, DOI 10.1016/j.patcog.2015.12.004
NR 34
TC 3
Z9 3
U1 4
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29659
EP 29679
DI 10.1007/s11042-018-6135-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200003
OA Bronze
DA 2024-07-18
ER

PT J
AU Kannao, R
   Guha, P
AF Kannao, Raghvendra
   Guha, Prithwijit
TI Segmenting with style: detecting program and story boundaries in TV news
   broadcast videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV news broadcast; Semantic shot classification; News program detection;
   News story segmentation
ID SEGMENTATION; FUSION
AB Television news is an important medium to convey information to masses. This motivates several stakeholders to monitor and analyze the news broadcasts. Segmentation of streaming broadcast into programs and stories is a necessary first step for such analysis. Television news producers use predefined and unique presentation styles to create the channel content. Presentation styles vary with program and news story category, broadcast time, targeted audience etc. This motivated us to use presentation styles as features for segmenting news broadcasts. We propose a novel approach for characterization of spatio-temporal presentation styles. This involves characterization of spatial styles using a set of (presentation style specific) semantic shot categories derived from LSCOM-Lite Ontology. We also identify features and classifiers to automate the process of shot labeling for spatial style characterization. Further, the temporal presentation styles of shots are modeled using conditional random fields. This spatio-temporal modeling of presentation styles is used for segmenting the broadcast into programs and stories. We have also contributed a 360 hours broadcast video dataset acquired from three Indian English news channels with ground-truth marked semantic shot categories, program genres and story boundaries. Experimentations on this dataset have shown the utility of our proposal for news broadcast video segmentation.
C1 [Kannao, Raghvendra; Guha, Prithwijit] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Kannao, R (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
EM raghvendra@iitg.ac.in; pguha@iitg.ac.in
OI Kannao, Raghvendra/0000-0003-2083-2560
CR [Anonymous], CRF YET ANOTHER CRF
   [Anonymous], P TRECVID WORKSH
   [Anonymous], 2015, MULTIMED TOOLS APPL
   [Anonymous], 2018, COMPUTER VISION PATT
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, arXiv
   [Anonymous], P TRECVID WORKSH
   [Anonymous], COGNITIVE IMPACT TEL
   [Anonymous], 2013, 2013 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2013.6707043
   [Anonymous], 2013, INT C MULT RETR
   [Anonymous], BARC IND UND URB IND
   [Anonymous], 2003, TRECVID C GAITH WASH
   [Anonymous], 2004, Trecvid 2004-anoverview
   [Anonymous], INTELLIGENT MULTIMED
   [Anonymous], IMPORTANCE BROADCAST
   [Anonymous], 2004, Kernel methods in computational biology
   [Anonymous], IEEE ACM T COMPUTATI
   [Anonymous], IAPR AS C PATT REC A
   [Anonymous], 2018, LECT NOTES COMPUTER, DOI DOI 10.1007/978-3-030-11018-5_21
   [Anonymous], DUBLIN CITY U VIDEO
   [Anonymous], TENSORFLOW IMAGE REC
   [Anonymous], TREC VIDEO RETRIEVAL
   [Anonymous], CVPR WORKSHOPS
   [Anonymous], IMPORTANCE TV NEWS M
   [Anonymous], TECH REP
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2001, PROC 18 INT C MACH L
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Awad G., 2016, ITE Transactions on Media Technology and Applications, V4, P187, DOI DOI 10.3169/MTA.4.187
   Charlet D, 2015, INT CONF ACOUST SPEE, P5261, DOI 10.1109/ICASSP.2015.7178975
   Chatzis SP, 2013, IEEE T PATTERN ANAL, V35, P1523, DOI 10.1109/TPAMI.2012.208
   Chen YH, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P973, DOI 10.1109/ICME.2006.262695
   Chua T.-S., 2004, PROC ACMMM, P656, DOI [10.1145/1027527.1027679, DOI 10.1145/1027527.1027679]
   Claveau V, 2015, COMPUT SPEECH LANG, V29, P63, DOI 10.1016/j.csl.2014.04.006
   Dietterich T. G., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P15
   Elin Larry., 2004, DESIGNING PRODUCING
   Feng BL, 2014, MULTIMEDIA SYST, V20, P347, DOI 10.1007/s00530-013-0350-0
   Feng BL, 2012, INT CONF ACOUST SPEE, P1417, DOI 10.1109/ICASSP.2012.6288156
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Ghosh H, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/486487
   Grabe ME, 2006, COMMUN RES, V33, P346, DOI 10.1177/0093650206291479
   Graber D.A., 1988, Processing the news: How people tame the information tide, V2nd
   HEARST MA, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P9
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Iwan LH, 2017, MULTIMED TOOLS APPL, V76, P1379, DOI 10.1007/s11042-015-3130-3
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Jindal A., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P458, DOI 10.1109/ISM.2011.81
   Kannao Raghvendra, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P793, DOI 10.1007/978-3-319-27671-7_66
   Kannao R, 2017, PATTERN RECOGN, V68, P38, DOI 10.1016/j.patcog.2017.02.029
   Kim J, 2014, ENG APPL COMP FLUID, V8, P229
   Kim W, 2010, J SIGNAL PROCESS SYS, V61, P251, DOI 10.1007/s11265-009-0446-0
   Li Hongzhi., 2013, Proceedings of the 21st ACM international conference on Multimedia, P449
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lu XM, 2013, INT CONF ACOUST SPEE, P8465, DOI 10.1109/ICASSP.2013.6639317
   Meinedo H, 2003, INT CONF ACOUST SPEE, P5
   Misra H, 2010, LECT NOTES COMPUT SC, V5916, P347, DOI 10.1007/978-3-642-11301-7_36
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Nie XC, 2013, INT CONF ACOUST SPEE, P8312, DOI 10.1109/ICASSP.2013.6639286
   Poulisse GJ, 2010, MULTIMED TOOLS APPL, V48, P3, DOI 10.1007/s11042-009-0358-9
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Shah R, 2017, SOCIO AFFECT COMPUT, V6, P173, DOI 10.1007/978-3-319-61807-4_6
   Sidiropoulos Panagiotis., 2013, Analysis, Retrieval and Delivery of Multimedia Content, P3
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Ullah J, 2018, MULTIMED TOOLS APPL, V77, P7429, DOI 10.1007/s11042-017-4655-4
   Yan C, 2018, IEEE Trans Multimedia Early Access
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Young S.J., 1993, HTK HIDDEN MARKOV MO
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
   Zhang L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P587
NR 73
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31925
EP 31957
DI 10.1007/s11042-019-7699-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000042
DA 2024-07-18
ER

PT J
AU Laddi, A
   Prakash, NR
AF Laddi, Amit
   Prakash, Neelam Rup
TI Eye gaze tracking based directional control interface for interactive
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris center; Supervised; Unsupervised; Hybrid; Unconstrained
   environment; Eye gaze; Directional control interface; Interactive
   applications
ID FACE DETECTION
AB This paper proposes an unobtrusive and calibration-free framework towards eye gaze tracking based interactive directional control interface for desktop environment using simple webcam under unconstrained settings. The proposed eye gaze tracking involved hybrid approach designed by combining two different techniques based upon both supervised and unsupervised methods wherein the unsupervised image gradients method computes the iris centers over the eye regions extracted by the supervised regression based algorithm. Experiments performed by the proposed hybrid approach to detect eye regions along with iris centers over challenging face image datasets exhibited exciting results. Similar approach for eye gaze tracking worked well in real-time by using a simple web camera. Further, PC based interactive directional control interface based upon iris position has been designed that works without needing any prior calibrations unlike other Infrared illumination based eye trackers. The proposed work may be useful to the people with full body motor disabilities, who need interactive and unobtrusive eye gaze control based applications to live independently.
C1 [Laddi, Amit] CSIR Cent Sci Instruments Org CSIO, Biomed Instrumentat, Sect 30 C, Chandigarh 160030, India.
   [Prakash, Neelam Rup] Deemed Be Univ, Punjab Engn Coll, Dept Elect & Commun Engn, Sect 12, Chandigarh 160012, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO); Punjab Engineering
   College (Deemed University)
RP Laddi, A (corresponding author), CSIR Cent Sci Instruments Org CSIO, Biomed Instrumentat, Sect 30 C, Chandigarh 160030, India.
EM amitcsio@yahoo.com; neelamrprakash@pec.ac.in
OI LADDI, AMIT/0000-0002-5391-6624
CR [Anonymous], BIOID FACE DATABASE
   [Anonymous], 2001, COMPUTER VISION PATT
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Han ZC, 2014, MULTIMED TOOLS APPL, V68, P931, DOI 10.1007/s11042-012-1090-4
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Laddi A, 2015, SIGN PROC COMP CONTR
   Laddi A, 2017, IETE J RES, P1
   Laddi A, 2017, MULTIMED TOOLS APPL, V76, P7129, DOI 10.1007/s11042-016-3361-y
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Leo M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033033
   Li B, 2018, APPL COMPUT INTELL S, V2018, DOI 10.1155/2018/1439312
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu L, 2018, INT J COMPUT VIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   San Agustin J., 2010, Proceedings of the 2010 Symposium on Eye-Tracking Research Applications - ETRA '10, P77, DOI DOI 10.1145/1743666.1743685
   Sewell W., 2010, CHI 10 EXTENDED ABST, P3739, DOI DOI 10.1145/1753846.1754048
   Shaoqing R, 2014, COMP VIS PATT REC CV
   Timm F., 2011, P INT C COMP VIS THE
   Valenti R, 2008, COMP VIS PATT REC 20
   Xu Pingmei, 2015, CORR
   Xudong C, 2012, COMP VIS PATT REC CV
   Xuehan X, 2013, COMP VIS PATT REC CV
   Ye L, 2014, LECT NOTES COMPUT SC, V8833, P473, DOI 10.1007/978-3-319-12484-1_54
   Yuan-Pin L, 2005, 2005 IEEE ENG MED BI
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
NR 30
TC 14
Z9 15
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31215
EP 31230
DI 10.1007/s11042-019-07940-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000011
DA 2024-07-18
ER

PT J
AU Lee, JY
AF Lee, Jin Young
TI Deep learning ensemble with data augmentation using a transcoder in
   visual description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Ensemble; Data augmentation; Visual description;
   Transcoder
AB Visual description is very challenging work in computer vision. Since it is usually performed with compressed videos, its performance strongly depends on coding distortion. Therefore, it is very important that visual description networks are trained using video datasets with both high and low qualities. In order to generate them from a given training dataset, this paper introduces a new data augmentation method employing a transcoder. It converts one video quality into another by controlling a quantization parameter (QP). Two different networks are trained on the high and low quality videos, respectively, and then the proposed deep learning ensemble model determines optimum sentence among candidates generated from these networks. Experimental results show that the proposed method is very robust to the coding distortion.
C1 [Lee, Jin Young] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
C3 Sejong University
RP Lee, JY (corresponding author), Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
EM jinyounglee@sejong.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2018R1C1B5086072]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2018R1C1B5086072).
CR [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2015, C N AM CHAPT ASS COM
   [Anonymous], IEEE S SER COMP INT
   [Anonymous], ARXIV171209532V1
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, ACM MULTIMEDIA
   [Anonymous], METEOR UNIVERSAL LAN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], INT C COMP VIS
   Chen S, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/6359248
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Shaw D, 2011, IMPACT OF THE ECONOMIC CRISIS ON EAST ASIA: POLICY RESPONSES FROM FOUR ECONOMIES, P190
   Simonyan K., 2014, 14091556 ARXIV
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   Sutskever I, 2014, ADV NEUR IN, V27
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiang SJ, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8492672
   Yu H, 2016, IEEE INT CONF COMMUN
NR 25
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31231
EP 31243
DI 10.1007/s11042-019-07948-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000012
DA 2024-07-18
ER

PT J
AU Nam, C
   Chu, C
   Kim, T
   Han, S
AF Nam, Cholman
   Chu, Changgon
   Kim, Taeguk
   Han, Sokmin
TI A novel motion recovery using temporal and spatial correlation for a
   fast temporal error concealment over H.264 video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Motion recovery; H; 264; Temporal correlation;
   Spatial correlation
ID ALGORITHM
AB In this paper, we proposed an effective motion recovery method with low complexity for a fast temporal error concealment over H.264 video sequences. The proposed algorithm uses temporal and spatial motion vectors of a lost block and neighboring blocks. A neighboring block with minimum SAD-MV between its trajectory and trajectory of lost block is chosen as the most reliable candidate. In order to avoid the mosaic artifacts in the process of recombination of optimal blocks, final motion vector of the block is recalculated using H.264 partition information and then H,.264 1/4 interpolation is followed. The proposed method is faster and better in PSNR compared with previous algorithms. The proposed algorithm may be used as a powerful error concealment tools for real time video applications, such as mobile phone, tactile display and WSN cameras, using H.264/AVC decoder, especially in the ROI tracking applications, because of low memory requirement.
C1 [Nam, Cholman; Chu, Changgon; Kim, Taeguk; Han, Sokmin] KIM IL SUNG Univ, Coll Informat Sci, Pyongyang, North Korea.
RP Nam, C (corresponding author), KIM IL SUNG Univ, Coll Informat Sci, Pyongyang, North Korea.
EM cm.nam@ryongnamsan.edu.kp
CR Aldahdooh A, 2016, INT C QUAL MULT EXP
   Ameigeiras P, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0565-9
   [Anonymous], 2015, ACM T MULTIMEDIA COM
   [Anonymous], 2009, H 264 SOFTWARE COORD
   Behar R, 2015, 7 INT C EV INT, P26
   Chen SY, 2009, IEEE T CIRC SYST VID, V19, P422, DOI 10.1109/TCSVT.2009.2013504
   Chen XM, 2010, IEEE T CONSUM ELECTR, V56, P2694, DOI 10.1109/TCE.2010.5681158
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Dehghani M, 2015, WIRELESS PERS COMMUN, V80, P891, DOI 10.1007/s11277-014-2062-y
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Li J, 2008, SIGNAL PROCESS-IMAGE, V23, P451, DOI 10.1016/j.image.2008.04.008
   Marvasti-Zadeh SM, 2016, TURK J ELECTR ENG CO, V24, P5195, DOI 10.3906/elk-1409-88
   Maung HM, 2017, IEEE INT C CONS EL I, P374
   Nam CM, 2010, INT CONF SIGN PROCES, P1283, DOI 10.1109/ICOSP.2010.5657077
   NORTON RM, 1984, AM STAT, V38, P135, DOI 10.2307/2683252
   Piñol P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103495
   Pongpadpinit S, 2009, P IEEE DIGITAL SIGNA, P1
   Psannis KE, 2011, 2011 IEEE INT S BROA, V2011, P1
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   S Wenger, 1999, Q15I16R1 ITUT
   Shanableh T, 2015, SIGNAL IMAGE VIDEO P, V9, P581, DOI 10.1007/s11760-013-0489-3
   Suh JW, 2002, IEEE T BROADCAST, V48, P299, DOI 10.1109/TBC.2002.806797
   Suh JW, 2002, ELECTRON LETT, V38, P1020, DOI 10.1049/el:20020733
   Usman M, 2016, IEEE T MULTIMEDIA, V18, P831, DOI 10.1109/TMM.2016.2537200
   Wang J, 2009, CSPA: 2009 5TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, P243, DOI 10.1109/CSPA.2009.5069225
   Wu J, 2008, IEEE T CONSUM ELECTR, V54, P1880, DOI 10.1109/TCE.2008.4711249
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Zheng JH, 2005, IEEE T MULTIMEDIA, V7, P507, DOI 10.1109/TMM.2005.843343
   Zheng JH, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P133
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 33
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1221
EP 1240
DI 10.1007/s11042-019-08176-x
EA OCT 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492560000001
DA 2024-07-18
ER

PT J
AU Bajpai, S
   Kidwai, NR
   Singh, HV
   Singh, AK
AF Bajpai, Shrish
   Kidwai, Naimur Rahman
   Singh, Harsh Vikram
   Singh, Amit Kumar
TI Low memory block tree coding for hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image compression; Transform coding; Wavelet transform;
   Set partition coding scheme; Low memory image coder
ID COMPRESSION; EFFICIENT; TRANSFORM; ALGORITHM; LOSSY
AB Hyperspectral image sensors are resource constrained and have limited on-board memory. Processing of high volume hyperspectral images pose a challenge to the memory and resources of the sensor. Contemporary wavelet based image compression schemes have intensive memory requirement of which 3D-WBTC have superior coding performance due to through the exploitation of the inter sub-band & intra sub-band redundancy. This paper presents a low memory implementation of 3D-WBTC which is a listless scheme by using the fixed size state memory to keep track of block set partitioning and significance testing of wavelet coefficients of transformed hyperspectral images. Memory access time is significantly reduced due to the elimination of lists that leads to reduced complexity. Simulation results of the proposed scheme shows that proposed coder is fast and have very low memory requirement thereby making it a suitable candidate for implementation in resource constrained hyper spectral image sensor.
C1 [Bajpai, Shrish] Dr APJ Abdul Kalam Tech Univ, Elect Engn Dept, Lucknow, Uttar Pradesh, India.
   [Kidwai, Naimur Rahman] Integral Univ, Fac Engn, Dept ECE, Lucknow, Uttar Pradesh, India.
   [Singh, Harsh Vikram] KNIT, Dept Elect Engn, Sultanpur, Uttar Pradesh, India.
   [Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Integral University;
   Kamla Nehru Institute of Technology Sultanpur; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM shrishbajpai@gmail.com; naimkidwai@gmail.com; harshvikram@gmail.com;
   amit_245singh@yahoo.com
RI Kidwai, Naimur Rahman/C-1721-2018; Bajpai, Shrish/GPC-4732-2022; Singh,
   Harsh Vikram/Q-9457-2019; Singh, Amit Kumar/D-1300-2015
OI Singh, Harsh Vikram/0000-0002-8904-862X; Bajpai,
   Shrish/0000-0001-5598-1940; Kidwai, Naimur Rahman/0000-0002-2606-7401;
   Singh, Amit Kumar/0000-0001-7359-2068
CR Abousleman GP, 1997, IEEE T IMAGE PROCESS, V6, P566, DOI 10.1109/83.563321
   Ahmed K, 2012, AUSTRALAS ACCOUNT BU, V6
   Aiazzi B., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P435, DOI 10.1109/ICIP.1999.821646
   Alvarez-Cortés S, 2018, INT J REMOTE SENS, V39, P1971, DOI 10.1080/01431161.2017.1375617
   Amigo JM, 2015, ANAL CHIM ACTA, V896, P34, DOI 10.1016/j.aca.2015.09.030
   [Anonymous], 2007, P SPIE INT SOC OPT E
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], REMOTE SENSING GIS D
   [Anonymous], 2012, INT J SIGNAL PROCESS
   [Anonymous], IEEE INT C AC SPEECH
   Bajpai S., 2019, INT J INNOVATIVE TEC, V8, P64
   Bajpai S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P97, DOI 10.1109/MSPCT.2017.8363982
   Boettcher JB, 2007, IEEE DATA COMPR CONF, P377
   Bruylants T, 2015, SIGNAL PROCESS-IMAGE, V31, P112, DOI 10.1016/j.image.2014.12.007
   Cheng KJ, 2013, PROC SPIE, V8743, DOI 10.1117/12.2016200
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Datta A., 2017, ADV PRINCIPAL COMPON, P19, DOI DOI 10.1007/978-981-10-6704-4_2
   Datta A, 2019, CLOUD COMPUTING GEOS, V49, P265, DOI [10.1007/978-3-030-03359-0_13, DOI 10.1007/978-3-030-03359-0_13]
   Diwakar M., 2018, MULTIMED TOOLS APPL, P1
   Dusselaar R, 2017, J OPT SOC AM A, V34, P2170, DOI 10.1364/JOSAA.34.002170
   Goetz AFH, 2009, REMOTE SENS ENVIRON, V113, pS5, DOI 10.1016/j.rse.2007.12.014
   Gunasheela K.S., 2018, P INT C COGNITION RE, P187
   Islam A, 1998, P SOC PHOTO-OPT INS, V3653, P294, DOI 10.1117/12.334677
   Jayasankar U, 2021, J KING SAUD UNIV-COM, V33, P119, DOI 10.1016/j.jksuci.2018.05.006
   Jia S, 2007, IEEE T GEOSCI REMOTE, V45, P3867, DOI 10.1109/TGRS.2007.898443
   Khelifi F, 2008, IEEE SIGNAL PROC LET, V15, P69, DOI 10.1109/LSP.2007.911156
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kouadria N, 2017, AEU-INT J ELECTRON C, V74, P123, DOI 10.1016/j.aeue.2017.02.005
   Latte MV, 2006, DIGIT SIGNAL PROCESS, V16, P817, DOI 10.1016/j.dsp.2006.06.001
   Lim S, 2001, INT GEOSCI REMOTE SE, P109, DOI 10.1109/IGARSS.2001.976072
   Menegaz G, 2002, IEEE T IMAGE PROCESS, V11, P1053, DOI 10.1109/TIP.2002.802525
   Mohan BK, 2015, CURR SCI INDIA, V108, P833
   Moinuddin AA, 2008, IET IMAGE PROCESS, V2, P59, DOI 10.1049/iet-ipr:20070162
   Motta G, 2006, HYPERSPECTRAL DATA COMPRESSION, P107, DOI 10.1007/0-387-28600-4_5
   Ngadiran R., 2010, IEEE INT C COMP COMM, P1, DOI [10.1109/ICCCE.2010.5556843, DOI 10.1109/ICCCE.2010.5556843]
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Pearlman WA, 1998, SPRING INT SER ENG C, V450, P397
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Senapati RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3784-y
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Tang XL, 2003, PROC SPIE, V5022, P1037, DOI 10.1117/12.476516
   Tausif M, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P593, DOI 10.1109/UPCON.2017.8251116
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Wang LZ, 2018, FUTURE GENER COMP SY, V78, P353, DOI 10.1016/j.future.2016.06.009
   Wang XH, 2018, J INDIAN SOC REMOTE, V46, P667, DOI 10.1007/s12524-017-0735-1
   Zhang LF, 2015, NEUROCOMPUTING, V147, P358, DOI 10.1016/j.neucom.2014.06.052
   Zhang XR, 2018, MULTIMED TOOLS APPL, V77, P29759, DOI 10.1007/s11042-017-5552-6
NR 50
TC 11
Z9 12
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27193
EP 27209
DI 10.1007/s11042-019-07797-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000019
DA 2024-07-18
ER

PT J
AU Cai, LQ
   Xu, HB
   Yang, Y
   Yu, JM
AF Cai, Linqin
   Xu, Hongbo
   Yang, Yang
   Yu, Jimin
TI Robust facial expression recognition using RGB-D images and multichannel
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Saliency and entropy; Active appearance
   model; Support vector machine
AB Traditional and classical methods of facial expression recognition are mainly based on intensity image and are prone to be disturbed by illumination, poses, and disguise. This research aims to develop a robust facial expression recognition method using RGB-D images and multichannel features. Based on image entropy and visual saliency, facial texture features are firstly extracted from RGB images and depth images to construct the Histogram of Oriented Gradient (HOG) descriptors. And then, we extract geometric features of RGB images using Active Appearance Model (AAM). Combining the HOG texture features with the AAM geometric feature, we build a robust multichannel feature vector for facial expression recognition. On this basis, an improved Support Vector Machine (SVM) algorithm, namely GS-SVM, is used to classify facial expression recognition. The proposed GS-SVM algorithm applies Grid Search method to optimize the best parameters for SVM classifier and estimate the accuracy of each parameter combination in specified range. Finally, the proposed methods are tested and evaluated on the merged RGB-D database. Experimental results show that the proposed algorithm not only achieves a higher average recognition rate but also is robust to uncontrolled environments.
C1 [Cai, Linqin; Xu, Hongbo; Yang, Yang; Yu, Jimin] Chongqing Univ Posts & Telecommun, Minist Educ, Key Lab Ind Internet Things & Networked Control, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Cai, LQ (corresponding author), Chongqing Univ Posts & Telecommun, Minist Educ, Key Lab Ind Internet Things & Networked Control, Chongqing 400065, Peoples R China.
EM iamlqcai@163.com; jlxhb@qq.com; 499145278@qq.com; yujimin@163.com
RI Yu, Jimin/I-7770-2012; CAI, Linqin/AAC-8471-2022; xu,
   hong/GSD-8903-2022; cai, linqin/AFQ-8642-2022
OI CAI, Linqin/0000-0002-5663-8113; cai, linqin/0000-0002-5663-8113
FU Chongqing Research Program of Basic Research and Frontier Technology
   [cstc2015jcyjA40009]
FX This work was supported by Chongqing Research Program of Basic Research
   and Frontier Technology (No. cstc2015jcyjA40009). Authors would like to
   acknowledge Prof. Mayank Vatsa for providing the IIIT-D database, Dr.
   Jean-Luc Dugelay for the EURECOM database, Prof. Chih-Jen Lin for libsvm
   and Faruto for sharing some Matlab code for selecting parameters.
CR [Anonymous], 2001, Int J Comput Vis
   Azazi A, 2015, EXPERT SYST APPL, V42, P3056, DOI 10.1016/j.eswa.2014.10.042
   Beveridge JR, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2015.7163156
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen J, 2014, PROC INT WORKSHOPS E
   Cootes TF, 2015, ACTIVE SHAPE APPEARA
   Danelakis A, 2015, MULTIMED TOOLS APPL, V74, P5577, DOI 10.1007/s11042-014-1869-6
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Dornaika F, 2007, J REAL-TIME IMAGE PR, V2, P35, DOI 10.1007/s11554-007-0032-2
   Engel S, 1997, NATURE INT WEEKLY J, V388, P71
   Fan WT, 2015, MULTIMED TOOLS APPL, V74, P4303, DOI 10.1007/s11042-013-1548-z
   Goswami G, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Goswami G, 2014, IEEE T INF FOREN SEC, V9, P1629, DOI 10.1109/TIFS.2014.2343913
   Hg RI, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P42, DOI 10.1109/SITIS.2012.17
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Mao QR, 2015, FRONT INFORM TECH EL, V16, P272, DOI 10.1631/FITEE.1400209
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Moridpour S, 2015, 3RD INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS 2015), P264, DOI 10.1109/ICTIS.2015.7232119
   Murtaza M, 2011, INT ARAB J INF TECHN, V10, P388
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ni JJ, 2018, INT J FUZZY SYST, V20, P672, DOI 10.1007/s40815-017-0395-x
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Sang GL, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3563758
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sun YJ, 2016, IEEE SENS J, V16, P798, DOI 10.1109/JSEN.2015.2485258
   Xu X, 2015, PROC IEEE INT C MECH, DOI [10.1109/TIP.2015.2510498, DOI 10.1109/TIP.2015.2510498]
NR 33
TC 7
Z9 8
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28591
EP 28607
DI 10.1007/s11042-018-5981-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700014
DA 2024-07-18
ER

PT J
AU Cao, R
   Cao, JW
   Mei, JP
   Yin, C
   Huang, XG
AF Cao, Ru
   Cao, Jiuwen
   Mei, Jian-ping
   Yin, Chun
   Huang, Xuegang
TI Radar emitter identification with bispectrum and hierarchical extreme
   learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radar emitter identification (REI); Bispectrum; Sparse autoencoder(AE);
   Bispectrum based hierarchical extreme learning machine (BS plus H-ELM)
ID CLASSIFICATION
AB Radar Emitter Identification (REI) has been broadly used in military and civil fields. In this paper, a novel method is proposed for radar emitter signal identification, where the bispectrum estimation of radar signal is extracted and the recent hierarchical extreme learning machine (BS + H-ELM) is adopted for further feature learning and recognition. Conventional REI methods generally rely on the time-difference-of-arrival, carrier frequency, pulse width, pulse amplitude, direction-of-arrival, etc., for signal representation and recognition. However, the increasingly violent electronic confrontation and the emergence of new types of radar signals generally degrade the recognition performance. With this objective, we explore radar emitter signal representation and classification method with the high order spectrum and deep network based H-ELM. After extracting the bispectrum of radar signals, the sparse autoencoder (AE) in H-ELM is employed for feature learning. Simulations on four representative radar signals, namely, the continuous wave (CW), linear frequency modulation wave(LFM), nonlinear frequency modulation wave(NLFM) and binary phase shift keying wave (BPSK), are conducted for performance validation. In comparison to the existing multilayer ELM algorithm and the popular histogram of gradient (HOG) based feature extraction method are proved that the proposal is feasible and potentially applicable in real applications.
C1 [Cao, Ru; Cao, Jiuwen] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Mei, Jian-ping] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Yin, Chun] Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Huang, Xuegang] China Aerodynam Res & Dev Ctr, Hyperveloc Aerodynam Inst, Mianyang 621000, Sichuan, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University of Technology;
   University of Electronic Science & Technology of China
RP Cao, JW (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
EM jwcao@hdu.edu.cn; jpmei@zjut.edu.cn; yinchun.86416@163.com;
   emei-126@126.com
RI Huang, Xuegang/O-2942-2019; cao, jiuwen/C-9547-2009; Chen,
   YangQuan/A-2301-2008
OI Huang, Xuegang/0000-0002-9168-3040; Chen, YangQuan/0000-0002-7422-5988
FU National Natural Science Foundation of China [61503104, 61502420];
   Hangzhou Smart City Research Center of Zhejiang/Zhejiang Smart City
   Regional Collaborative Innovation Center [GK150906299001/019]; Natural
   Science Foundation of Zhejiang Province [LY16F020032]
FX This work was supported by the National Natural Science Foundation of
   China (61503104, 61502420), Hangzhou Smart City Research Center of
   Zhejiang/Zhejiang Smart City Regional Collaborative Innovation Center
   (GK150906299001/019), and the Natural Science Foundation of Zhejiang
   Province (LY16F020032).
CR [Anonymous], INTELLIGENT SYSTEMS
   Baldi P., 2012, P INT C UNS TRANSF L, P37
   Cao JW, 2016, J FRANKLIN I, V353, P4526, DOI 10.1016/j.jfranklin.2016.08.024
   Cao JW, 2016, NEURAL NETWORKS, V81, P91, DOI 10.1016/j.neunet.2016.06.001
   Cao JW, 2016, MULTIMED TOOLS APPL, V75, P2839, DOI 10.1007/s11042-014-2424-1
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Chen CX, 2014, CHINESE J ELECTRON, V23, P499
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   Guo G, 2014, J AIR FORCE WARNING, V28, P161
   Guo Q, 2015, J COMMUN NETW-S KOR, V17, P491, DOI 10.1109/JCN.2015.000087
   Guo QA, 2010, J SYST ENG ELECTRON, V21, P382, DOI 10.3969/j.issn.1004-4132.2010.03.006
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jin Weidong, 2006, Journal of Southwest Jiaotong University (English Edition), V14, P15
   Jin Y, 2016, MULTIMED TOOLS APPL, V75, P11831, DOI 10.1007/s11042-015-2650-1
   Kim LS, 2017, NEUROCOMPUTING, V248, P67, DOI 10.1016/j.neucom.2017.01.094
   Kishore TR, 2017, IEEE T AERO ELEC SYS, V53, P901, DOI 10.1109/TAES.2017.2667142
   Li JC, 2015, KSII T INTERNET INF, V9, P4573, DOI 10.3837/tiis.2015.11.018
   Li L, 2011, EXPERT SYST APPL, V38, P2140, DOI 10.1016/j.eswa.2010.07.155
   Li N., 2012, J BEIJING UNION U, V26, P26
   Li YB, 2014, J CENT SOUTH UNIV, V21, P4254, DOI 10.1007/s11771-014-2422-5
   Liang H.D., 2014, ACTA PHOTONICA SINIC, V43, P1
   Mingqiu Ren, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1641, DOI 10.1109/ICOSP.2008.4697451
   Nan SY, 2017, IEEE T NEUR NET LEAR, V28, P94, DOI 10.1109/TNNLS.2015.2504382
   Petrov N, 2013, PROCEDIA COMPUT SCI, V22, P1192, DOI 10.1016/j.procs.2013.09.206
   Shieh CS, 2002, IEEE T ANTENN PROPAG, V50, P1120, DOI 10.1109/TAP.2002.801387
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Wang Hai-hua, 2009, Systems Engineering and Electronics, V31, P809
   Wong CM, 2018, IEEE T NEUR NET LEAR, V29, P757, DOI 10.1109/TNNLS.2016.2636834
   [杨承志 Yang Chengzhi], 2013, [现代雷达, Modern Radar], V35, P41
   YONG Xiao-ju, 2011, MODERN DEFENCE TECHN, V39, P148, DOI DOI 10.3969/J.ISSN1009-086X.2011.03.031
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang ZC, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P1225, DOI 10.1109/ICMLC.2009.5212449
   Zhu B, 2012, LECT NOTES ELECT ENG, V154, P716, DOI [10.1007/978-1-4471-2386-6_93, DOI 10.1007/978-1-4471-2386-6_93]
NR 34
TC 26
Z9 30
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28953
EP 28970
DI 10.1007/s11042-018-6134-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700033
DA 2024-07-18
ER

PT J
AU Chellamuthu, S
   Sekaran, EC
AF Chellamuthu, Shanmugam
   Sekaran, E. Chandira
TI Fault detection in electrical equipment's images by using optimal
   features with deep learning classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared thermography images; Electrical equipment; Fault diagnosis;
   Feature Extraction; Optimal features; ODA and Deep Neural Network
ID INFRARED THERMOGRAPHY; DIAGNOSIS
AB Infrared imaging frameworks have been broadly utilized as a part of the military and civil fields, for example, target recognition, fault diagnosis, fire identification, and medical analysis. Evaluating and monitoring the electrical parts is necessary to analyze the thermal fault at the beginning period. The paper presents the IRT electrical images for diagnosing and classifying the faults by the feature extraction and classification process. At first, IRT segmented switch image (highly temperature zone) is considered, followed by the feature extraction procedure is applied where the images are selected based on the optimal features. The optimal features are accomplished by the inspired optimization algorithm i.e. Opposition based Dragonfly Algorithm (ODA). It chose the best features for the unproblematic classification process. With the intention of classifying the segmented portion as faulty and non-faulty IRT, an approach Deep Neural Network (DNN) is presented. On the basis of the optimal weight attained from learning algorithm, categorize the faulty electrical image easily. The results show that the proposed work accomplishes maximum classification accuracy i.e. 99.99% compared to existing classification approaches.
C1 [Chellamuthu, Shanmugam] Jansons Inst Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Sekaran, E. Chandira] Coimbatore Inst Technol, Dept Elect & Elect Engn, Coimbatore, Tamil Nadu, India.
C3 Coimbatore Institute of Technology
RP Chellamuthu, S (corresponding author), Jansons Inst Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM shanmugamc2078@gmail.com
RI chellamuthu, shanmugam/ABD-8645-2021
OI CHELLAMUTHU, SHANMUGAM/0000-0001-6477-0977
CR [Anonymous], 2013, INT J SCI RES PUBL
   Aujeszky T, 2017, 2017 15TH IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND GAMES (HAVE), P1
   Bagavathiappan S, 2013, INFRARED PHYS TECHN, V60, P35, DOI 10.1016/j.infrared.2013.03.006
   Chou YC, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P155, DOI 10.1109/SoCPaR.2009.41
   Sales RBC, 2017, APPL ERGON, V62, P142, DOI 10.1016/j.apergo.2017.03.003
   Dashtizadeh Z, 2012, POLYM-PLAST TECHNOL, V51, P1155, DOI 10.1080/03602559.2012.671427
   ditLeksir YL, 2017, INFRARED PHYS TECHN, P1
   Dutta T, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONTROL, MEASUREMENT AND INSTRUMENTATION (CMI), P311, DOI 10.1109/CMI.2016.7413761
   Glava H, 2018, J COSMET LASER THER, P1
   Glavas H, 2016, TEH VJESN, V23, P1533, DOI 10.17559/TV-20150702185559
   Glowacz A, 2017, INFRARED PHYS TECHN, V81, P7, DOI 10.1016/j.infrared.2016.12.003
   Huda ASN, 2013, INFRARED PHYS TECHN, V61, P184, DOI 10.1016/j.infrared.2013.04.012
   Huda ASN, 2013, APPL THERM ENG, V61, P220, DOI 10.1016/j.applthermaleng.2013.07.028
   Janssens O, 2015, INFRARED PHYS TECHN, V73, P78, DOI 10.1016/j.infrared.2015.09.004
   Liu H., 2017, P 2017 INT C CLOUD T, VVolume 910
   Lizak F., 2008, Acta Electrotechnica et Informatica, V8, P60
   Mafarja MM, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P12, DOI 10.1109/ICTCS.2017.43
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mlakic D, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND TECHNOLOGIES (SST), P55, DOI 10.1109/SST.2017.8188670
   Pareek S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONDITION ASSESSMENT TECHNIQUES IN ELECTRICAL SYSTEMS (CATCON), P183, DOI 10.1109/CATCON.2017.8280208
   Szafron C., 2008, APPL THERMAL IMAGING, P1
   Ullah I, 2017, ENERGIES, V10, DOI 10.3390/en10121987
   Vantuch T, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020182
   Zhang L, 2017, DECISION SUPPORT SYS
   Zheng Z., 2015, MOBILE CLOUD VISUAL, P201
   Zou H, 2015, CHIN CONTR CONF, P6372, DOI 10.1109/ChiCC.2015.7260642
NR 26
TC 6
Z9 7
U1 3
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27333
EP 27350
DI 10.1007/s11042-019-07847-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000025
DA 2024-07-18
ER

PT J
AU Dubey, SR
AF Dubey, Shiv Ram
TI Local directional relation pattern for unconstrained and robust face
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local descriptor; Face; Unconstrained; Robust; Retrieval; Directional
   relation
ID BINARY PATTERNS; FEATURE DESCRIPTOR; RECOGNITION; HISTOGRAM; ROTATION;
   REPRESENTATION; MODEL
AB Face recognition is still a very demanding area of research. This problem becomes more challenging in unconstrained environment and in the presence of several variations like pose, illumination, expression, etc. Local descriptors are widely used for this task. The most of the existing local descriptors consider only few immediate local neighbors and not able to utilize the wider local information to make the descriptor more discriminative. The wider local information based descriptors mainly suffer due to the increased dimensionality. In this paper, this problem is solved by encoding the relationship among directional neighbors in an efficient manner. The relationship between the center pixel and the encoded directional neighbors is utilized further to form the proposed local directional relation pattern (LDRP). The descriptor is inherently uniform illumination invariant. The multi-scale mechanism is also adapted to further boost the discriminative ability of the descriptor. The proposed descriptor is evaluated under the image retrieval framework over face databases. Very challenging databases like PaSC, LFW, PubFig, ESSEX, FERET, AT&T, and FaceScrub are used to test the discriminative ability and robustness of LDRP descriptor. Results are also compared with the recent state-of-the-art face descriptors such as LBP, LTP, LDP, LDN, LVP, DCP, LDGP and LGHP. Very promising performance is observed using the proposed descriptor over very appealing face databases as compared to the existing face descriptors. The proposed LDRP descriptor also outperforms the pre-trained ImageNet CNN models over large-scale FaceScrub face dataset. Moreover, it also outperforms the deep learning based DLib face descriptor in many scenarios.
C1 [Dubey, Shiv Ram] Indian Inst Informat Technol, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
RP Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
EM srdubey@iiits.in
RI Dubey, Shiv Ram/T-7541-2019
OI Dubey, Shiv Ram/0000-0002-4532-8996
FU IIIT Sri City, India through the Faculty Seed Research Grant
FX This research is funded by IIIT Sri City, India through the Faculty Seed
   Research Grant.
CR Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], BRIT MACH VIS C
   Arandjelovic O, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.12
   Beveridge J. R., 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992
   Chakraborty S, 2016, IEEE T CIRCUITS SYST
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Elaiwat S, 2014, IEEE SIGNAL PROC LET, V21, P172, DOI 10.1109/LSP.2013.2295119
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hong DF, 2015, NEUROCOMPUTING, V151, P511, DOI 10.1016/j.neucom.2014.09.013
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Jabid T, 2010, IEEE IMAGE PROC, P1605, DOI 10.1109/ICIP.2010.5652374
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Lumini Alessandra, 2017, Applied Computing and Informatics, V13, P79, DOI 10.1016/j.aci.2016.04.001
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Punnappuraih A., 2015, IEEE Trans. Image Process., V24, P2067
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ren CX, 2016, IEEE T CYBERNETICS, V46, P2656, DOI 10.1109/TCYB.2015.2484356
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang HL, 2013, SIGNAL PROCESS, V93, P2190, DOI 10.1016/j.sigpro.2012.04.002
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 73
TC 25
Z9 26
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28063
EP 28088
DI 10.1007/s11042-019-07908-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000057
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Prasetyo, H
   Hsia, CH
AF Prasetyo, Heri
   Hsia, Chih-Hsien
TI Improved multiple secret sharing using generalized chaotic image
   scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese remainder theorem; Exclusive OR; Generalized chaotic; Image
   scrambling; Secret sharing
ID SCHEME; WATERMARKING; ALGORITHM; SECURE; SVD
AB This paper presents a new technique on (n, n)-Multiple Secret Sharing (MSS) of color images. In this task, n shared images are generated from n secret images, while n recovered secret images can be reconstructed from n shared images. The proposed method employs the Chinese Remainder Theorem (CRT) and bitwise eXclusive-OR (XOR) operation for generating a set of shared image from a set of secret images. The proposed method improves the security level of (n, n)- MSS scheme by developing and utilizing the generalized chaotic image scrambling. This image scrambling effectively overcomes the problem on former existing MSS scheme while the number of secret images is odd number. As documented in experimental section, the proposed method offers a good result on (n, n)- MSS task. At the same time, the proposed method outperforms the former exising schemes in the MSS field.
C1 [Prasetyo, Heri] Univ Sebelas Maret, Dept Informat, Surakarta, Indonesia.
   [Hsia, Chih-Hsien] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
C3 Sebelas Maret University; National Ilan University
RP Hsia, CH (corresponding author), Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
EM heri.prasetyo@staff.uns.ac.id; chhsia625@gmail.com
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832; Hsia, Chih-Hsien/0000-0003-2665-0821
CR Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Bharti SS, 2018, MULTIMEDIA TOOLS APP
   Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Ghebleh M., 2017, MULTIMED TOOLS APPL, P1
   Guo C, 2017, MULTIMED TOOLS APPL, P1
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Harjito B, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P143, DOI 10.1109/ISESD.2016.7886708
   Hsia CH, 2018, IEEE SENS J, V18, P790, DOI 10.1109/JSEN.2017.2772799
   Hsia CH, 2015, IEEE SENS J, V15, P994, DOI 10.1109/JSEN.2014.2359225
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Mahato S, 2017, J INF SECUR APPL, V32, P1, DOI 10.1016/j.jisa.2016.11.005
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Wang C, 2018, OPT COMMUN, V407, P1, DOI 10.1016/j.optcom.2017.08.054
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Xing L, 2018, SIGNAL PROCESS, V145, P233, DOI 10.1016/j.sigpro.2017.12.013
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zarepour-Ahmadabadi J, 2018, MULTIMED TOOLS APPL, P1
NR 30
TC 14
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29089
EP 29120
DI 10.1007/s11042-018-6304-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700039
DA 2024-07-18
ER

PT J
AU Singh, MK
   Singh, AK
   Singh, N
AF Singh, Mahesh K.
   Singh, A. K.
   Singh, Narendra
TI Multimedia analysis for disguised voice and classification efficiency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic disguise voice; MFCC based acoustic feature; Classifiers
ID IDENTIFICATION
AB For multimedia analysis of electronic disguised method is a speech editing process in which the characteristics of voice have been changed. Frequency spectrum characteristics of the speech signal during electronic disguised have also changed. In this paper proposed a method for deriving an algorithm for extracted the efficiency of disguised voice from its normal voice. By using practical approaches for disguising the voice by a different semitone. Mel-frequency cepstral coefficients (MFCC), delta Mel-frequency cepstral coefficients (Delta MFCC), double delta Mel-frequency cepstral coefficients (Delta Delta MFCC) based feature extraction techniques compute the acoustic feature and its statistical moments mean and correlation coefficient. Acoustic feature and its statistical moments passed through the different types of the algorithm-based classifier. By using different classifier find the efficiency of disguised voice.
C1 [Singh, Mahesh K.; Singh, Narendra] JUET, Dept ECE, Guna, MP, India.
   [Singh, A. K.] Thapar Univ, Dept ECE, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, MK (corresponding author), JUET, Dept ECE, Guna, MP, India.
EM mahesh.092002.ece@gmail.com; ashutoshsingh79@yahoo.com;
   narendra.singh@juet.ac.in
RI Singh, Narendra/AAH-5380-2021; Singh, Mahesh Kumar/JNT-1040-2023; Singh,
   Major/P-9790-2019
OI Singh, Mahesh Kumar/0000-0002-5007-3721; Singh,
   Major/0000-0002-0247-861X; Singh, Dr. Mahesh K./0009-0006-5036-6037;
   Singh, Dr. Mahesh K./0000-0002-0790-119X
CR *AUD, FREE AUD ED REC
   CROCHIERE RE, 1981, P IEEE, V69, P300, DOI 10.1109/PROC.1981.11969
   Entezari-Maleki R, 2009, J CONVERG INFORM TEC, V4
   Gonzalez-Rodriguez J., 2004, P IEEE INT WORKSH SP, P1
   Grimaldi M, 2008, IEEE T AUDIO SPEECH, V16, P1097, DOI 10.1109/TASL.2008.2001109
   He JJ, 2016, INT CONF ACOUST SPEE, P321, DOI 10.1109/ICASSP.2016.7471689
   Jingxu C., 2004, P INT S COMP INF, V1, P96
   Kajarekar S. S., 2006, 2006 IEEE ODYSSEY TH, P1
   Kajarekar SS, 2005, INT CONF ACOUST SPEE, P173
   Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0
   Kunzel H., 2004, P OD 04 SPEAK LANG R, P1
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Rodman R., 1998, P CONSORTIUM SPEECH, P9
   Seresht HR, 2017, CIRC SYST SIGNAL PR, V36, P3222, DOI 10.1007/s00034-016-0434-0
   Wu HJ, 2014, IEEE T INF FOREN SEC, V9, P489, DOI 10.1109/TIFS.2014.2301912
   Wu HJ, 2013, INT CONF ACOUST SPEE, P3013, DOI 10.1109/ICASSP.2013.6638211
   Yao CL, 2010, RESEARCH PROGRESS IN PAPER INDUSTRY AND BIOREFINERY (4TH ISETPP), VOLS 1-3, P535
   Zhang CL, 2008, FORENSIC SCI INT, V175, P118, DOI 10.1016/j.forsciint.2007.05.019
   Zhu XL, 2007, IEEE T AUDIO SPEECH, V15, P1645, DOI 10.1109/TASL.2007.899236
NR 19
TC 17
Z9 17
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29395
EP 29411
DI 10.1007/s11042-018-6718-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700054
DA 2024-07-18
ER

PT J
AU Ren, Y
   Li, QL
   Liu, WQ
   Li, L
   Guan, W
AF Ren, Yan
   Li, Qilin
   Liu, Wanquan
   Li, Ling
   Guan, Wei
TI Semantics characterization for eye shapes based on directional
   triangle-area curve clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye shape representation; Curve clustering; Semantics extraction
ID IMAGE RETRIEVAL; FACE RECOGNITION; ROBUST; REPRESENTATION; LOCALIZATION
AB In this paper, we present a novel approach to address the problem of eye shape characterization via curve representation. Firstly, a directional triangle-area curve representation method (DTAR) is presented for this aim. Equipped with DTAR, the shape similarities between two eyes can be measured by the similarities between two corresponding DTAR curves. Secondly, in order to exploit the underlying information of eye shapes, a curve clustering algorithm is utilized to automatically discover a set of eye shape prototypes. Consequently, a semantics extraction method for eye shapes is proposed in terms of seven reference eye shapes. Finally, in order to validate the consistency of the clustering results and the extracted semantics, extensive experiments on AR and BU4DFE databases are designed and conducted, and all the results demonstrate the effectiveness of the proposed DTAR curve representation and the semantics extraction method.
C1 [Ren, Yan; Guan, Wei] Shenyang Aerosp Univ, Coll Automat, Shenyang 110136, Liaoning, Peoples R China.
   [Li, Qilin; Liu, Wanquan; Li, Ling] Curtin Univ, Dept Comp, Perth, WA 6102, Australia.
C3 Shenyang Aerospace University; Curtin University
RP Ren, Y (corresponding author), Shenyang Aerosp Univ, Coll Automat, Shenyang 110136, Liaoning, Peoples R China.
EM renyan1108@hotmail.com; kylinlovesummer@gmail.com; W.Liu@curtin.edu.au;
   L.Li@curtin.edu.au; guanweihaha@163.com
RI zhu, yujie/KBC-4009-2024; Zhao, YuHan/KIE-0813-2024; Huang,
   Liping/KIB-4430-2024
OI Li, Qilin/0000-0001-6584-8879; Ren, Yan/0000-0003-1149-9153; Li,
   Ling/0000-0001-9722-9503
FU State Scholarship Fund; Natural Science Foundations of China [61602321,
   61363066]; Aviation Science Foundation [2017ZC54007, 2017ZA54006];
   Science Fund Project of Liaoning Province Education Department
   [L201614]; Natural Science Fund Project of Liaoning Province
   [20170540694, 20170540692, 2015020069]; Doctor Startup Foundation of
   Shenyang Aerospace University [13YB11]
FX We appreciate the efforts of two reviewers and Associate Editor for
   their critical comments on this manuscript and make the quality of this
   paper improved significantly. This work is supported by State
   Scholarship Fund, Natural Science Foundations of China under Grant
   No.61602321 and No.61363066, Aviation Science Foundation with No.
   2017ZC54007 and 2017ZA54006, Science Fund Project of Liaoning Province
   Education Department with No.L201614, Natural Science Fund Project of
   Liaoning Province with No.20170540694, No.20170540692 and No.2015020069,
   and the Doctor Startup Foundation of Shenyang Aerospace University
   13YB11.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2008, ICPR2009, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Almudhahka NY, 2018, IEEE T INF FOREN SEC, V13, P706, DOI 10.1109/TIFS.2017.2765519
   An L, 2016, NEUROCOMPUTING, V172, P215, DOI 10.1016/j.neucom.2014.09.098
   [Anonymous], 2013, Finite mixture distributions
   [Anonymous], IJRCCT
   [Anonymous], WILEY
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Borràs A, 2005, LECT NOTES COMPUT SC, V3522, P325
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Castellano Giovanna, 2011, Fuzzy Logic and Applications. Proceedings 9th International Workshop, WILF 2011, P236, DOI 10.1007/978-3-642-23713-3_30
   Chen XJ, 2013, IEEE IMAGE PROC, P4367, DOI 10.1109/ICIP.2013.6738900
   Conilione P, 2012, COMPUT J, V55, P1130, DOI 10.1093/comjnl/bxs041
   Davies G, 1981, PERCEIVING REMEMBERI
   DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   El Rube I, 2005, LECT NOTES COMPUT SC, V3656, P415, DOI 10.1007/11559573_52
   Gaffney S, 2005, CURVE CLUSTERING TOO
   Gaffney S., 1999, 5 ACM SIGKDD INT C K, P63, DOI [10.1145/312129.312198, DOI 10.1145/312129.312198]
   Gaffney S. J., 2004, Probabilistic curve-aligned clustering and prediction with regression mixture models, P281
   Guler RA, 2016, PATTERN RECOGN, V49, P79, DOI 10.1016/j.patcog.2015.07.013
   Han CC, 2000, PATTERN RECOGN, V33, P1701, DOI 10.1016/S0031-3203(99)00141-7
   Hannachi A, 2001, Q J ROY METEOR SOC, V127, P939, DOI 10.1002/qj.49712757312
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Hsu RL, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA145
   Kim H, 2019, MULTIMED TOOLS APPL, V78, P3221, DOI 10.1007/s11042-018-6482-7
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Kovac J., 2003, HUMAN SKIN COLOR CLU, V2
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Liang A, 2014, INT C PATT RECOG, P538, DOI 10.1109/ICPR.2014.103
   Liang XW, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P292
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2019, MOBILE NETW APPL, V24, P5, DOI 10.1007/s11036-018-1134-8
   Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Martinez A., 1998, AR FACE DATABASE
   McLachlan G., 2004, FINITE MIXTURE MODEL
   McLachlan G.J., 1988, Statistics: Textbooks and Monographs
   Thang ND, 2011, INFORM SCIENCES, V181, P3162, DOI 10.1016/j.ins.2011.03.021
   Pedrycz W, 2008, IEEE T FUZZY SYST, V16, P1008, DOI 10.1109/TFUZZ.2008.917287
   Peng K, 2005, J COMPUT SCI TECHNOL, V5, P127
   Rajpoot NM, 2008, ANN BMVA, V2008, P17
   Ren Y, 2016, NEUROCOMPUTING, V171, P1462, DOI 10.1016/j.neucom.2015.07.096
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Shahabi C, 2007, MULTIMED TOOLS APPL, V32, P29, DOI 10.1007/s11042-006-0070-y
   Shanmugavadivu P, 2016, NEUROCOMPUTING, V171, P719, DOI 10.1016/j.neucom.2015.07.015
   Sheng WG, 2008, IEEE T INF FOREN SEC, V3, P183, DOI 10.1109/TIFS.2008.922056
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Smyth P, 1999, J ATMOS SCI, V56, P3704, DOI 10.1175/1520-0469(1999)056<3704:MRINHH>2.0.CO;2
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Tafaj E., 2012, P S EYE TRACK RES AP, P285, DOI DOI 10.1145/2168556.2168617
   Tzortzis G, 2014, PATTERN RECOGN, V47, P2505, DOI 10.1016/j.patcog.2014.01.015
   Wan R, 2013, IEEE VEHICLE POWER, P6
   Wang C, 2018, MULTIMED TOOLS APPL, V77, P1
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yin PY, 2008, PATTERN RECOGNITION
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 64
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25373
EP 25406
DI 10.1007/s11042-019-7659-4
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700008
DA 2024-07-18
ER

PT J
AU Tang, JY
   Yu, ZN
   Liu, LF
AF Tang, Jiyue
   Yu, Ziniu
   Liu, Lingfeng
TI A delay coupling method to reduce the dynamical degradation of digital
   chaotic maps and its application for image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Dynamical degradation; Image encryption
ID ALGORITHM; SYSTEM
AB In this study, a novel delayed coupled chaotic model to reduce the dynamical degradation of digital chaotic maps is firstly proposed. In this model, we introduce the delayed state variables in digital maps and use the state variable of one map to vary the control parameter of the other map. Numerical experimental results demonstrate that the delayed coupled system can effectively reduce the dynamical degradation of digital chaotic maps, and retain the phase space structure of the original system. Furthermore, we propose a simple image encryption algorithm based on the coupled model as a simple application. Numerical experiments show that our algorithm has high security level and can resist various attacks, which is competitive with some other chaotic image encryption algorithms.
C1 [Tang, Jiyue; Yu, Ziniu; Liu, Lingfeng] Nanchang Univ, Sch Software, 235 Nanjing East Rod, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, 235 Nanjing East Rod, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China [61601215, 61862042]
FX This work is supported by the National Natural Science Foundation of
   China (61601215, 61862042).
CR Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Cristina DA, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM), P339, DOI 10.1109/ICComm.2012.6262542
   Deng YS, 2015, INFORM SCIENCES, V305, P146, DOI 10.1016/j.ins.2015.01.028
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hu HP, 2008, CHAOS SOLITON FRACT, V38, P439, DOI 10.1016/j.chaos.2006.11.027
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jawad LM, 2015, NONLINEAR DYNAM, V81, P2079, DOI 10.1007/s11071-015-2127-9
   Kalouptsidis N., 1996, TELECOMMUNICATIONS S
   Kocarev L, 2006, IEEE T CIRCUITS-I, V53, P1300, DOI 10.1109/TCSI.2006.874181
   Li CY, 2012, IEEE T VLSI SYST, V20, P385, DOI 10.1109/TVLSI.2010.2103332
   Li SJ, 2001, PHYS LETT A, V290, P127, DOI 10.1016/S0375-9601(01)00612-0
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu LF, 2015, IMA J MATH CONTROL I, V32, P703, DOI 10.1093/imamci/dnu015
   Liu SB, 2009, CHINESE PHYS B, V18, P5219, DOI 10.1088/1674-1056/18/12/019
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Persohn KJ, 2012, CHAOS SOLITON FRACT, V45, P238, DOI 10.1016/j.chaos.2011.12.006
   PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Vaferi E, 2015, OPTIK, V126, P2474, DOI 10.1016/j.ijleo.2015.06.012
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XM, 2013, INFORM SCIENCES, V221, P555, DOI 10.1016/j.ins.2012.09.037
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhou Q, 2012, J SYST SOFTWARE, V85, P400, DOI 10.1016/j.jss.2011.08.032
   Zhou Y., 2012, IEEE T CYBERNETICS, V45, P2001, DOI DOI 10.1109/TCYB.2014.2363168
NR 32
TC 39
Z9 41
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24765
EP 24788
DI 10.1007/s11042-019-7602-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900050
DA 2024-07-18
ER

PT J
AU Chakravarthy, S
   Jagannathan, MA
   Ranjani, JJ
   Baluswamy, B
   Kadry, S
AF Chakravarthy, Sudharshan
   Jagannathan, Madhav Anand
   Ranjani, J. Jennifer
   Baluswamy, Balamurugan
   Kadry, Seifedine
TI An optimized hierarchical encryption technique for tamper recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Tamper detection; Discrete wavelet transform; Artificial
   neural network
ID ROBUST IMAGE WATERMARKING; SVD; AUTHENTICATION; DWT
AB Digital images contain sensitive information that needs to be watermarked for ownership authentication and copyright verification. It is crucial to have a method to detect and recognize tampering when images are sent over insecure channels. The watermarking scenario becomes more complicated when an intruder is precluded from obtaining a watermark signal from a watermarked image since it can expose future point-to-point correspondences. The proposed scheme utilizes a hierarchical strategy for improving the security of the semi-fragile watermarking scheme that requires fewer data to be exchanged before each transaction. Consequently, the proposed watermarking method obtains a trade-off between robustness and imperceptibility by using a meta-heuristic approach, namely, the Sine Cosine Algorithm (SCA). Furthermore, an Artificial Neural Network (ANN) is built using the Softmax classifier to recognize possible attacks that might be performed by an intruder. The whole scheme is presented in the form of a GUI with the attack recognition triggered from the receiver's side. Experimental results show improved image quality metrics like PSNR, correlation coefficient, and structural similarity when the scaling factor used in the watermarking algorithm is optimized using SCA.
C1 [Chakravarthy, Sudharshan] TCS Innovat Labs, Chennai, Tamil Nadu, India.
   [Jagannathan, Madhav Anand] Microsoft India R&D, Bangalore, Karnataka, India.
   [Ranjani, J. Jennifer] Birla Inst Technol & Sci, Dept CSIS, Pilani Campus, Pilani, Rajasthan, India.
   [Baluswamy, Balamurugan] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); Galgotias
   University; Beirut Arab University
RP Kadry, S (corresponding author), Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
EM s.kadry@bau.edu.lb
RI Kadry, Seifedine/C-7437-2011; Rajkumar, Jennifer Ranjani
   John/I-9753-2014
OI Kadry, Seifedine/0000-0002-1939-4842; Rajkumar, Jennifer Ranjani
   John/0000-0001-8555-929X
CR Amanipour V, 2018, IEEE T INSTRUM MEAS, V67, P505, DOI 10.1109/TIM.2017.2777620
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aznaveh AM, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/738972
   Baghel M, 2013, INT J COMPUT APPL, V62, P15
   Castiglione A, 2015, INT CON ADV INFO NET, P476, DOI 10.1109/AINA.2015.224
   CHAKRAVARTHY S, 2016, INDIAN J SCI TECHNOL, V9, pNI171, DOI DOI 10.17485/ijst/2016/v9i39/86519
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Elhoseny M, 2018, NEURAL COMPUTING APP
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Imran M, 2017, IEEE ACCESS, V5, P12843, DOI 10.1109/ACCESS.2017.2717842
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Khanduja V, 2015, DEF SCI J, V65
   Lai CC, 2013, DIGIT SIGNAL PROCESS, V23, P1333, DOI 10.1016/j.dsp.2013.02.005
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Laouamer L, 2018, IEEE ACCESS, V6, P26144, DOI 10.1109/ACCESS.2018.2831599
   Li CT, 2009, INT J DIGIT CRIME FO, V1, P32, DOI 10.4018/jdcf.2009062403
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mishra M., 2012, INT J CRYPTOGRAPHY I, V2, P131
   Oyedotun O. K., 2016, NEURAL COMPUTING APP
   Pizzolante R, 2012, 3 IEEE INT C INT NET, P698
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Sikder I, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P881, DOI 10.1109/ECACE.2017.7913027
   Singh P, 2018, IEEE T CIRC SYST VID, V28, P2116, DOI 10.1109/TCSVT.2017.2716828
   Tafaghodi M, 2015, CORR
   Thakur S., 2018, MULTIMEDIA TOOLS APP, P1
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
NR 33
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18693
EP 18712
DI 10.1007/s11042-019-7265-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200060
DA 2024-07-18
ER

PT J
AU He, L
   Tan, H
   Huang, ZC
AF He, Lang
   Tan, Hua
   Huang, Zhang-Can
TI Online handwritten signature verification based on association of
   curvature and torsion feature with Hausdorff distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online signature verification; Extreme point; Curvature; Torsion;
   Hausdorff distance
ID WRITER DEPENDENT FEATURES; SYMBOLIC REPRESENTATION; DYNAMIC SIGNATURE;
   CLASSIFIER; SYSTEM; INFORMATION; COMPETITION
AB The paper presents an efficient on-line signature verification method based on the dynamic features of a given signature. In the proposed approach, curvature and torsion feature are associated with Hausdorff distance measure which can be used in the verification process. In the feature extraction step, the signature trajectory is approximated as a spatial curve. A set of curvature and torsion value of extreme point is computed from both x coordinate, y coordinate and pressure feature so that the dimension of the curve is reduced. Therefore, a new composed signature feature is created for each person. For the obtained feature data, the most distinctive Hausdorff distance is further proposed to calculate the distances of the eight-dimensional feature vector between the test signature and corresponding template signatures for the verification of the test sample. Comprehensive experiments are implemented on three publicly available databases: the SVC2004, SUSIG and MCYT-100 database. A comparison of our results with some recent signature verification methods available in the literature is provided with equal error rate, and the results indicate that the proposed method would better recognize genuine signatures, random and skilled forgeries.
C1 [He, Lang; Tan, Hua; Huang, Zhang-Can] Wuhan Univ Technol, Sch Sci, Wuhan 430070, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Tan, H (corresponding author), Wuhan Univ Technol, Sch Sci, Wuhan 430070, Hubei, Peoples R China.
EM tanhua123@whut.edu.cn
RI Tan, tanhua/ISA-0905-2023
FU National College Students Innovation and entrepreneurship training
   program in Wuhan University of Technology [20161049714003]
FX This work was supported by National College Students Innovation and
   entrepreneurship training program in Wuhan University of Technology
   (Project No. 20161049714003). The authors would like to thank the
   reviewers for their invaluable comments and all the people who have
   provided their sample signatures used in this study.
CR Alaei A, 2017, IEEE T INF FOREN SEC, V12, P2360, DOI 10.1109/TIFS.2017.2707332
   Alpar O, 2016, LECT NOTES ARTIF INT, V9799, P145, DOI 10.1007/978-3-319-42007-3_13
   Ansari AQ, 2014, IET BIOMETRICS, V3, P113, DOI 10.1049/iet-bmt.2012.0048
   Barkoula K, 2013, INT J DOC ANAL RECOG, V16, P261, DOI 10.1007/s10032-012-0193-9
   Che C, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0456-1
   Cpalka K, 2014, EXPERT SYST APPL, V41, P4170, DOI 10.1016/j.eswa.2013.12.047
   Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419
   Doroz R, 2016, NEUROCOMPUTING, V171, P921, DOI 10.1016/j.neucom.2015.07.026
   Doroz R, 2011, COMM COM INF SC, V245, P128
   Fang L J, 2012, INFRARED PAPERS, V33, P9
   Fang X, 2017, 7 INT C COMP ENG NET, P1
   Ghosh R, 2017, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON 2017 DEVICES FOR INTEGRATED CIRCUIT (DEVIC), P522, DOI 10.1109/DEVIC.2017.8074005
   Guerbai Y, 2015, PATTERN RECOGN, V48, P103, DOI 10.1016/j.patcog.2014.07.016
   Guru DS, 2017, EXPERT SYST APPL, V80, P232, DOI 10.1016/j.eswa.2017.03.024
   Hafemann L. G., 2015, ARXIV150707909
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Impedovo D, 2014, INT CONF FRONT HAND, P639, DOI 10.1109/ICFHR.2014.112
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Kar B, 2018, IEEE T INSTRUM MEAS, V67, P2, DOI 10.1109/TIM.2017.2755898
   Khoh WH, 2014, SECUR COMMUN NETW, V7, P1067, DOI 10.1002/sec.829
   Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x
   Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346
   Liu S, 2005, JIANGSU MACHINE BUIL, V34, P60
   Liu Y., 2016, EVID-BASED COMPL ALT, P6230825, DOI [DOI 10.1007/S10291-016-0529-X, DOI 10.1155/2016/6230825]
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YS, 2015, IEEE T CYBERNETICS, V45, P2498, DOI 10.1109/TCYB.2014.2375959
   Liwicki M, 2012, INT C FRONT HANDWR R
   Liwicki M, 2011, PROC INT CONF DOC, P1480, DOI 10.1109/ICDAR.2011.294
   Malik MI, 2013, INT C DOC AN REC IEE
   Malik MI, 2015, PROC INT CONF DOC, P1186, DOI 10.1109/ICDAR.2015.7333948
   Mandal S, 2018, EXPERT SYST APPL, V97, P421, DOI 10.1016/j.eswa.2017.12.047
   Manjunatha KS, 2016, PATTERN RECOGN LETT, V80, P129, DOI 10.1016/j.patrec.2016.06.016
   Ooi SY, 2016, APPL SOFT COMPUT, V40, P274, DOI 10.1016/j.asoc.2015.11.039
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Palys M, 2013, 2013 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P103, DOI 10.1109/ICBAKE.2013.20
   Patel OP, 2019, SOFT COMPUT, V23, P3067, DOI 10.1007/s00500-017-2954-3
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Porwik P, 2016, PATTERN RECOGN, V60, P998, DOI 10.1016/j.patcog.2016.06.032
   Porwik P, 2014, LECT NOTES COMPUT SC, V8480, P377
   Rohilla S, 2016, P NATL ACAD SCI INDI, V87, P1
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472
   Sharma A, 2018, IEEE T CYBERNETICS, V48, P611, DOI 10.1109/TCYB.2017.2647826
   Sharma A, 2017, IEEE T INF FOREN SEC, V12, P705, DOI 10.1109/TIFS.2016.2632063
   Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015
   Soleimani B, 2017, GEOFLUIDS, P1, DOI 10.1155/2017/6265341
   Tahir M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONIC AND ELECTRICAL ENGINEERING (ICE CUBE), P100, DOI 10.1109/ICECUBE.2016.7495205
   Tang L, 2018, IEEE T INF FOREN SEC, V13, P861, DOI 10.1109/TIFS.2017.2769023
   Tolosana R, 2015, 2015 INT WORKSH BIOM
   Tolosana R, 2018, IEEE ACCESS, V6, P5128, DOI 10.1109/ACCESS.2018.2793966
   Vaseghi B, 2015, J ELECT COMMUNICATIO, V10, P48
   Wang WC, 2007, J XIAN U POSTS TELEC, V12, P91
   Xia XH, 2018, PATTERN RECOGN, V74, P422, DOI 10.1016/j.patcog.2017.09.033
   Xia XH, 2017, PATTERN RECOGN, V65, P188, DOI 10.1016/j.patcog.2016.12.019
   Yang L, 2018, SOFT COMPUT, V22, P7811, DOI 10.1007/s00500-018-3477-2
   Yang L, 2018, CONTEMP NURSE, V54, P630, DOI 10.1080/10376178.2018.1552525
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   Zalasinski M, 2015, LECT NOTES COMPUT SC, V9120, P175, DOI 10.1007/978-3-319-19369-4_17
   Zhu Yan-juan, 2005, Transactions of Nanjing University of Aeronautics & Astronautics, V22, P23
   [朱延娟 ZHU Yanjuan], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P164
NR 59
TC 21
Z9 21
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19253
EP 19278
DI 10.1007/s11042-019-7264-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800015
DA 2024-07-18
ER

PT J
AU Liu, XW
AF Liu, Xinwu
TI Total generalized variation and shearlet transform based Poissonian
   image deconvolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deconvolution; Poisson noise; Total generalized variation;
   Shearlet transform; Alternating minimization method
ID RESTORATION; ALGORITHM
AB Integrating the advantages of total generalized variation and shearlet transform, this article introduces a hybrid regularizers scheme for deconvolving Poissonian image. Computationally, a highly efficient alternating minimization algorithm associated with variable splitting approach is described to obtain the optimal solution in detail. Illustrationally, in comparison with several current state-of-the-art numerical methods, numerical simulations consistently demonstrate the outstanding performance of our proposed approach to deblurring Poissonian image, in terms of both restoration accuracy and feature-preserving ability.
C1 [Liu, Xinwu] Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
C3 Hunan University of Science & Technology
RP Liu, XW (corresponding author), Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
EM lxinwu@163.com
OI Liu, Xinwu/0000-0003-1909-3721
FU National Natural Science Foundation of China [61402166]; Hunan
   Provincial Natural Science Foundation of China [14JJ3105]
FX This work was supported by National Natural Science Foundation of China
   (61402166) and Hunan Provincial Natural Science Foundation of China
   (14JJ3105).
CR Bonettini S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/9/095001
   Bonettini S, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/1/015002
   BRATSOLIS E, 2011, ASTRON ASTROPHYS, V375, P1120
   Bredies K, 2013, LECT NOTES COMPUT SC, P149, DOI DOI 10.1007/978-3-642-38267-3_13
   Bredies K, 2012, 2012006 SFB U GRAZ I, P2012
   Bredies K, 2013, INT J COMPUT MATH, V90, P109, DOI 10.1080/00207160.2012.700400
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Brune C, 2010, PREPRINT
   Brune C, 2011, INT J COMPUT VISION, V92, P211, DOI 10.1007/s11263-010-0339-5
   Carlavan M, 2012, IEEE T IMAGE PROCESS, V21, P1834, DOI 10.1109/TIP.2011.2175934
   Chaux C, 2009, SIAM J IMAGING SCI, V2, P730, DOI 10.1137/080727749
   Chen DQ, 2014, SIAM J IMAGING SCI, V7, P716, DOI 10.1137/130932119
   Chen DQ, 2012, INVERSE PROBL, V28, DOI 10.1088/0266-5611/28/1/015004
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Guo WH, 2014, SIAM J IMAGING SCI, V7, P1309, DOI 10.1137/120904263
   Hajiaboli Mohammad Reza, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P94, DOI 10.2197/ipsjtcva.2.94
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hauser S., 2014, ARXIV12021773
   Huiqin Jiang, 2014, Breast Imaging. 12th International Workshop, IWDM 2014. Proceedings: LNCS 8539, P707, DOI 10.1007/978-3-319-07887-8_98
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Kryvanos A, 2005, P SOC PHOTO-OPT INS, V5674, P432, DOI 10.1117/12.586909
   Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Liu XW, 2016, COMPUT MATH APPL, V71, P1694, DOI 10.1016/j.camwa.2016.03.005
   Liu XW, 2014, MATH COMPUT SIMULAT, V97, P224, DOI 10.1016/j.matcom.2013.10.001
   Liu XW, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033007
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Sarder P, 2006, IEEE SIGNAL PROC MAG, V23, P32, DOI 10.1109/MSP.2006.1628876
   Sawatzky A., 2008, Nuclear Science Symposium Conference Record, P5133, DOI DOI 10.1109/NSSMIC.2008.4774392
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Shepp L A, 1982, IEEE Trans Med Imaging, V1, P113, DOI 10.1109/TMI.1982.4307558
   Valkonen T, 2013, SIAM J IMAGING SCI, V6, P487, DOI 10.1137/120867172
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 39
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18855
EP 18868
DI 10.1007/s11042-019-7247-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200067
DA 2024-07-18
ER

PT J
AU Lorbach, M
   Poppe, R
   Veltkamp, RC
AF Lorbach, Malte
   Poppe, Ronald
   Veltkamp, Remco C.
TI Interactive rodent behavior annotation in video using active learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rat social interaction; Rodent behavior; Automated behavior recognition;
   Active learning; Interactive annotation
ID MOUSE MODELS; RECOGNITION; HUNTINGTONS; TRACKING; SYSTEM
AB Manual annotation of rodent behaviors in video is time-consuming. By learning a classifier, we can automate the labeling process. Still, this strategy requires a sufficient number of labeled examples. Moreover, we need to train new classifiers when there is a change in the set of behaviors that we consider or in the manifestation of these behaviors in video. Consequently, there is a need for an efficient way to annotate rodent behaviors. In this paper we introduce a framework for interactive behavior annotation in video based on active learning. By putting a human in the loop, we alternate between learning and labeling. We apply the framework to three rodent behavior datasets and show that we can train accurate behavior classifiers with a strongly reduced number of labeled samples. We confirm the efficacy of the tool in a user study demonstrating that interactive annotation facilitates efficient, high-quality behavior measurements in practice.
C1 [Lorbach, Malte; Poppe, Ronald; Veltkamp, Remco C.] Univ Utrecht, Dept Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
C3 Utrecht University
RP Poppe, R (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
EM r.w.poppe@uu.nl
OI Poppe, Ronald/0000-0002-0843-7878
CR ALTMANN J, 1974, BEHAVIOUR, V49, P227, DOI 10.1163/156853974X00534
   Anderson DJ, 2014, NEURON, V84, P18, DOI 10.1016/j.neuron.2014.09.005
   Arakawa T, 2014, J NEUROSCI METH, V234, P127, DOI 10.1016/j.jneumeth.2014.04.012
   Bandla S, 2013, IEEE I CONF COMP VIS, P1833, DOI 10.1109/ICCV.2013.230
   Beglinger LJ, 2010, PSYCHIAT RES, V178, P414, DOI 10.1016/j.psychres.2010.04.030
   Benjamini Y, 2010, NEUROSCI BIOBEHAV R, V34, P1351, DOI 10.1016/j.neubiorev.2010.04.004
   Bianco S, 2015, COMPUT VIS IMAGE UND, V131, P88, DOI 10.1016/j.cviu.2014.06.015
   Burgos-Artizzu XP, 2012, PROC CVPR IEEE, P1322, DOI 10.1109/CVPR.2012.6247817
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   De Rosa R, 2017, PATTERN RECOGN LETT, V99, P48, DOI 10.1016/j.patrec.2017.03.005
   Dell AI, 2014, TRENDS ECOL EVOL, V29, P417, DOI 10.1016/j.tree.2014.05.004
   Egnor SER, 2016, ANNU REV NEUROSCI, V39, P217, DOI 10.1146/annurev-neuro-070815-013845
   Eyjolfsdottir E, 2014, LECT NOTES COMPUT SC, V8690, P772, DOI 10.1007/978-3-319-10605-2_50
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Freytag A, 2014, LECT NOTES COMPUT SC, V8692, P562, DOI 10.1007/978-3-319-10593-2_37
   Giancardo L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074557
   Heeren DJ, 2000, BEHAV RES METH INS C, V32, P56, DOI 10.3758/BF03200788
   Hong WZ, 2015, P NATL ACAD SCI USA, V112, pE5351, DOI 10.1073/pnas.1515982112
   Jhuang H, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1064
   Kabra M, 2013, NAT METHODS, V10, P64, DOI [10.1038/NMETH.2281, 10.1038/nmeth.2281]
   Kubat M., 1997, ICML, P179
   Laskov P, 2006, J MACH LEARN RES, V7, P1909
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Levitis DA, 2009, ANIM BEHAV, V78, P103, DOI 10.1016/j.anbehav.2009.03.018
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Liu XB, 2011, IEEE IMAGE PROC, P1225, DOI 10.1109/ICIP.2011.6115653
   Lorbach M, 2017, JOURNAL OF NEUROSCIE
   Lorbach M, 2015, LECT NOTES COMPUT SC, V9280, P565, DOI 10.1007/978-3-319-23234-8_52
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590
   Menalled LB, 2002, TRENDS PHARMACOL SCI, V23, P32, DOI 10.1016/S0165-6147(00)01884-8
   Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451
   Robie AA, 2017, J EXP BIOL, V220, P25, DOI 10.1242/jeb.142281
   Rousseau JBI, 2000, BEHAV RES METH INS C, V32, P63, DOI 10.3758/BF03200789
   Roy Nicholas, 2001, Toward optimal active learning through monte carlo estimation of error reduction, P441
   Safadi B, 2012, MULTIMED TOOLS APPL, V60, P403, DOI 10.1007/s11042-010-0599-7
   Schneider J, 2014, BIOL LETTERS, V10, DOI 10.1098/rsbl.2014.0749
   Settlemyer BW, 2011, IEEE S MASS STOR SYS
   Settles B, 2008, ADV NEURAL INFORM PR, V21, P1289
   Sillito RR, 2008, P C BRIT MACH VIS C, P1031
   Spampinato C, 2014, MACH VISION APPL, V25, P99, DOI 10.1007/s00138-013-0509-x
   Spruijt BM, 2014, J NEUROSCI METH, V234, P2, DOI 10.1016/j.jneumeth.2014.03.001
   Steele AD, 2007, P NATL ACAD SCI USA, V104, P1983, DOI 10.1073/pnas.0610779104
   Tanha J, 2012, PROC INT C TOOLS ART, P690, DOI 10.1109/ICTAI.2012.98
   van Dam EA, 2013, J NEUROSCI METH, V218, P214, DOI 10.1016/j.jneumeth.2013.05.012
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vijayanarasimhan S, 2010, PROC CVPR IEEE, P3035, DOI 10.1109/CVPR.2010.5540055
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516
   Zadrozny B, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P435, DOI 10.1109/icdm.2003.1250950
NR 50
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19787
EP 19806
DI 10.1007/s11042-019-7169-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800039
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sajedi, H
   Mohammadipanah, F
   Rahimi, SAH
AF Sajedi, Hedieh
   Mohammadipanah, Fatemeh
   Rahimi, Seyyed Amir Hosein
TI Actinobacterial strains recognition by Machine learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Actinobacterial strains; Colony features; Image processing; Deep neural
   network; Transfer learning; ResNet
ID IMAGE-ANALYSIS; DISCRIMINATION; DIAGNOSIS; LEUKEMIA; COLOR; PSO
AB Recognition of actinobacterial species on solid culture plates is an error-prone and time-consuming process which retard all the down-stream process after the isolation step. In this paper, we propose an optimized solution for the mentioned problem by using machine learning and image processing algorithms to diminish the cost and time and increase the accuracy of the detection. Three methods are compared in this paper for actinobacterial strains recognition. In the first method, two-level wavelet transform is applied on images of actinobacterial strains and statistical texture features are computed from wavelet subbands. Furthermore, some statistical color features are calculated from color information. In consequence, Principle Component Analysis (PCA) is employed for dimension reduction and finally, a Multi-Layer Perceptron (MLP) neural network was used for classification. In the second method, a Convolution Neural Network (CNN) is used to extract the features automatically. In the third method, transfer learning is employed for feature extraction and classfication. The first method is evaluated on two databases, UTMC.V1.DB and UTMC.V2.DB, and the accuracy obtained between 80.8% to 80.1%, respectively. Employing CNN as the feature extractor improved the accuracy about 4%. Transfer learnig results 85.96% accuracy on the UTMC.V2.DB and 91.90% on the subclasses of UTMC.V2.DB. The experiments have shown that using transfer learning of DCNN of type ResNet has better performance compared to the pervious methods. The proposed methods are universal and can be used for recognition of other circle-like colony-shape microorganisms. In particular, giving limited and unbalanced training data, which is a common failure in biological data sets, the proposed methods harbor remarkable accuracy. The data augmentation methods showed to be efficient and practical for the current purpose along with being easy to be implemented and integrated.
C1 [Sajedi, Hedieh; Rahimi, Seyyed Amir Hosein] Univ Tehran, Coll Sci, Sch Math Stat & Comp Sci, Dept Comp Sci, Tehran, Iran.
   [Mohammadipanah, Fatemeh] Univ Tehran, Sch Biol, Pharmaceut Biotechnol Lab, Tehran, Iran.
   [Mohammadipanah, Fatemeh] Univ Tehran, Coll Sci, Ctr Excellence Phylogeny Living Organisms, Tehran, Iran.
C3 University of Tehran; University of Tehran; University of Tehran
RP Sajedi, H (corresponding author), Univ Tehran, Coll Sci, Sch Math Stat & Comp Sci, Dept Comp Sci, Tehran, Iran.; Mohammadipanah, F (corresponding author), Univ Tehran, Sch Biol, Pharmaceut Biotechnol Lab, Tehran, Iran.; Mohammadipanah, F (corresponding author), Univ Tehran, Coll Sci, Ctr Excellence Phylogeny Living Organisms, Tehran, Iran.
EM hhsajedi@ut.ac.ir; fmohammadipanah@ut.ac.ir
OI sajedi, hedieh/0000-0003-4782-9222
CR Affonso C, 2017, EXPERT SYST APPL, V85, P114, DOI 10.1016/j.eswa.2017.05.039
   [Anonymous], CVPR 2015
   Arrigoni S, 2017, COMPUT BIOL MED, V88, P60, DOI 10.1016/j.compbiomed.2017.06.018
   Bahrami M, 2019, INTELLIGENT DATA ANA
   Banada PP, 2009, BIOSENS BIOELECTRON, V24, P1685, DOI 10.1016/j.bios.2008.08.053
   Cardona DAB, 2017, NEUROCOMPUTING, V265, P78, DOI 10.1016/j.neucom.2016.09.140
   Chiang PJ, 2015, J MICROBIOL METH, V108, P74, DOI 10.1016/j.mimet.2014.11.009
   Dopheide A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123179
   Ferrari A, 2017, PATTERN RECOGN, V61, P629, DOI 10.1016/j.patcog.2016.07.016
   Ferrari A, 2014, IEEE CONF IMAGING SY, P101, DOI 10.1109/IST.2014.6958454
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Isler Y, 2016, COMPUT BIOL MED, V76, P113, DOI 10.1016/j.compbiomed.2016.06.029
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2010, INT S CIRC SYST ISCA
   Lee DY, 2010, BIOTECHNIQUES, V49, P557, DOI 10.2144/000113451
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang C, 2016, 2016 INTERNATIONAL CONFERENCE ON PROBABILISTIC METHODS APPLIED TO POWER SYSTEMS (PMAPS)
   Lim CL, 2016, J FRANKLIN I, V353, P4715, DOI 10.1016/j.jfranklin.2016.08.012
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lv JJ, 2017, NEUROCOMPUTING, V230, P184, DOI 10.1016/j.neucom.2016.12.025
   Martinel N., 2016, P 10 INT C DISTR SMA
   Marzorati M, 2010, MICROB CELL FACT, V9, DOI 10.1186/1475-2859-9-12
   Mohapatra S, 2014, NEURAL COMPUT APPL, V24, P1887, DOI 10.1007/s00521-013-1438-3
   Mousa FA, 2016, PROCEDIA COMPUT SCI, V82, P49, DOI 10.1016/j.procs.2016.04.008
   Neoh SC, 2015, SCI REP-UK, V5, DOI 10.1038/srep14938
   Parvaresh H, 2018, 22 IEEE INT C INT EN
   Pérez-Llarena FJ, 2016, FRONT MICROBIOL, V7, DOI 10.3389/fmicb.2016.00410
   Putman M, 2005, J IMMUNOL METHODS, V302, P99, DOI 10.1016/j.jim.2005.05.003
   Rahimi SAH, 2017, IEEE 15 INT S INT S
   Razavi SF, 2016, IET IMAGE PROCESS, V10, P381, DOI 10.1049/iet-ipr.2015.0610
   Rohani A, 2018, RENEW ENERG, V115, P411, DOI 10.1016/j.renene.2017.08.061
   Sajedi H, 2018, FUTURE MICROBIOL, V13, P313, DOI 10.2217/fmb-2016-0096
   Salaken SM, 2017, NEUROCOMPUTING, V267, P516, DOI 10.1016/j.neucom.2017.06.037
   Singh AK, 2014, MBIO, V5, DOI 10.1128/mBio.01019-13
   Srisukkham W, 2017, APPL SOFT COMPUT, V56, P405, DOI 10.1016/j.asoc.2017.03.024
   VijayaLakshmi B, 2016, COMPUT ELECTRON AGR, V125, P99, DOI 10.1016/j.compag.2016.04.033
   Weng Q, 2018, INT J REMOTE SENS, V39, P6281, DOI 10.1080/01431161.2018.1458346
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zielinski B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184554
NR 41
TC 7
Z9 7
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20285
EP 20307
DI 10.1007/s11042-019-7379-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800061
DA 2024-07-18
ER

PT J
AU Soleymani, SH
   Taherinia, AH
   Mohajerzadeh, AH
AF Soleymani, Seyyed Hossein
   Taherinia, Amir Hossein
   Mohajerzadeh, Amir Hossein
TI WACA: a new blind robust watermarking method based on Arnold Cat map and
   amplified pseudo-noise strings with weak correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Watermarking; Robustness; Curvelet transform; Arnold Cat
   map; Weak correlation noises
ID LIFTING WAVELET TRANSFORM; IMAGE WATERMARKING; DITHER MODULATION;
   STEGANOGRAPHY; ALGORITHM; SYSTEM; SCHEME; SECURE
AB In this paper, a robust and blind watermarking method is proposed, which is highly resistant to the common image watermarking attacks, such as noises, compression, and image quality enhancement processing. In this method, Arnold Cat map is used as a pre-processing on the host image, which increases the security and imperceptibility of watermark embedding with a strong gain factor. Moreover, two pseudo-noise strings with weak correlation are used as the symbol of each 0 or 1 bit of the watermark. Accordingly, the accuracy increases in detecting the status of watermark bits at extraction phase in comparison to using two random pseudo-noise strings. Moreover, to increase the robustness and further imperceptibility of the embedding, the Arnold Cat mapped image is subjected to non-overlapping block. Then, the high-frequency coefficients of the approximation sub-band of FDCuT transform are used as the embedding location for each block. Comparison of the proposed method with recent robust related works under the same experimental conditions indicates the superiority of the proposed method.
C1 [Soleymani, Seyyed Hossein; Taherinia, Amir Hossein; Mohajerzadeh, Amir Hossein] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
   [Taherinia, Amir Hossein] Ferdowsi Univ Mashhad, Machine Vis Lab, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad; Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.; Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Machine Vis Lab, Mashhad, Razavi Khorasan, Iran.
EM seyyedhosein.soleymani@mail.um.ac.ir; taherinia@um.ac.ir;
   mohajerzadeh@um.ac.ir
RI Taherinia, Amir Hossein/HTP-1792-2023; Taherinia, Amir
   Hossein/AAC-9575-2020
OI Taherinia, Amir Hossein/0000-0002-5103-4812
CR Akter A., 2014, 3 INT C INF EL VIS M, P1
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   [Anonymous], 2016, SIPI IMAGE DATABASE
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Garg H, 2013, INT CONF CONTEMP, P313, DOI 10.1109/IC3.2013.6612211
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Kaur R, 2013, INT CONF EMERG TR, P19, DOI 10.1109/ICETET.2013.5
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Li LD, 2009, AEU-INT J ELECTRON C, V63, P123, DOI 10.1016/j.aeue.2007.11.007
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lutovac B, 2017, MULTIMED TOOLS APPL, V76, P23333, DOI 10.1007/s11042-016-4127-2
   Mehta R, 2013, INT CONF CONTEMP, P163, DOI 10.1109/IC3.2013.6612183
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Mohammadi FG, 2017, J VIS COMMUN IMAGE R, V44, P214, DOI 10.1016/j.jvcir.2016.12.003
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P3485, DOI 10.1007/s11042-016-3734-2
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P17913, DOI 10.1007/s11042-017-4506-3
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P3649, DOI 10.1007/s11042-016-3914-0
NR 32
TC 12
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19163
EP 19179
DI 10.1007/s11042-019-7282-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800011
DA 2024-07-18
ER

PT J
AU Bao, HF
   Fang, WN
   Guo, BY
   Wang, JX
AF Bao, Haifeng
   Fang, Weining
   Guo, Beiyuan
   Wang, Jianxin
TI Real-time wide-view eye tracking based on resolving the spatial depth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye tracking; Gaze estimation; Resolving spatial depth; Wearable
   Computering
ID GAZE ESTIMATION; MOVEMENTS
AB Current eye-tracking systems include many types that have been applied in numerous applications; however, they are unsuitable for industrial environments such as aircraft cockpits and train cabs. While wearable eye-tracking glasses have a wide field of view, they provide only a relative point of view in a captured video image; thus, they cannot function as a real-time interface to digital monitors. Desktop eye-tracking applications can interact with a single screen in real-time using pre-attached fixed cameras or infrared sensors; however, these applications allow only a narrow field of view. In this study, we developed a novel eye-tracking solution that integrates both the requirement for interaction and a wide field of view. The eye-tracking glasses gather eye movement data while a motion capture device provides data concerning the position and orientation of the head. A spatial depth-resolving algorithm is proposed to estimate the distance from the eyes to the digital screen, making it possible to locate the screens. Our proposed method is a generalized solution for estimating gaze points on wide screens; it is not dependent on specific devices. We tested the method in a virtual environment using unity3d and reached three conclusions: the algorithm theoretically has good accuracy and stability; it cannot be simplified; and when applied in a real environment it should have a satisfying and acceptable usability. Subsequently, we performed experiments in a real environment that validated the theory. Further applications: This type of unique wearable equipment can function as a real-time machine input interface to enhance the machine's perception of the user's situational awareness and improve the machine's dynamic service capabilities.
C1 [Bao, Haifeng; Fang, Weining; Guo, Beiyuan; Wang, Jianxin] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Sch Mech Elect & Control Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Fang, WN (corresponding author), Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Sch Mech Elect & Control Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
EM wnfang@bjtu.edu.cn
RI Wang, Jianxin/V-2800-2018; wang, jian/GVS-0711-2022
OI Bao, Haifeng/0000-0002-6132-1532
FU National Natural Science Foundation of China [51575037]; Research
   Foundation of State Key Laboratory of Rail Traffic Control and Safety
   [RCS2018ZT009]
FX Our research was supported by the National Natural Science Foundation of
   China under Grant No. 51575037 and Research Foundation of State Key
   Laboratory of Rail Traffic Control and Safety under Grant No.
   RCS2018ZT009.
CR Aungsakun S, 2011, COMM COM INF SC, V180, P714
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   Guo ZZ, 2017, MULTIMED TOOLS APPL, V76, P2203, DOI 10.1007/s11042-015-3182-4
   Hao Z, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL I, PROCEEDINGS, P306, DOI 10.1109/IITA.2008.177
   Lee EC, 2013, KSII T INTERNET INF, V7, P834, DOI 10.3837/tiis.2013.04.013
   Lin CS, 2006, OPT LASER ENG, V44, P597, DOI 10.1016/j.optlaseng.2005.06.005
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Lv Z, 2010, PATTERN RECOGN LETT, V31, P1041, DOI 10.1016/j.patrec.2009.12.017
   Ma JX, 2015, IEEE T BIO-MED ENG, V62, P876, DOI 10.1109/TBME.2014.2369483
   Manabe H, 2015, IEEE T BIO-MED ENG, V62, P1553, DOI 10.1109/TBME.2015.2394409
   Murawski K, 2013, ACTA PHYS POLONICA A, V124
   Panev S, 2015, INT WORKSH INT DATA, P276, DOI 10.1109/IDAACS.2015.7340743
   Rózanowski K, 2012, ACTA PHYS POL A, V122, P874
   Soltani S, 2016, COMPUT BIOL MED, V70, P163, DOI 10.1016/j.compbiomed.2016.01.012
   Sun L, 2015, INFORM SCIENCES, V320, P346, DOI 10.1016/j.ins.2015.02.004
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Wang P, 2017, APPL ERGON, V60, P260, DOI 10.1016/j.apergo.2016.11.013
   Xiong CS, 2014, INT C PATT RECOG, P1156, DOI 10.1109/ICPR.2014.208
NR 20
TC 4
Z9 4
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14633
EP 14655
DI 10.1007/s11042-018-6754-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700023
DA 2024-07-18
ER

PT J
AU Dagher, I
   Saliba, M
   Farah, R
AF Dagher, Issam
   Saliba, Mireille
   Farah, Rachelle
TI Hybrid DCT-HAAR block
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; Haar; Wavelet; Hybrid; PSNR
ID IMAGE COMPRESSION
AB In this paper we have constructed a new hybrid transform. We have combined the DCT block and the Haar block into one block which we have called hybrid DCT-HAAR block. This new block combines the advantages of the DCT which works extremely well for highly correlated data and the advantages of the Haar transform which gives superior results for images exhibiting rapid gradient variations. The DCT is applied to the upper left corner of the block. The Haar is applied to the remaining parts of the block. We derived the equations of the matrix M needed to recover the hybrid block. Our method increased the PSNR obtained by the DCT transform and enhanced the edge recovery of the Haar transform.
C1 [Dagher, Issam; Saliba, Mireille; Farah, Rachelle] Univ Balamand, Dept Comp Engn, El Koura, Lebanon.
C3 University Balamand
RP Dagher, I (corresponding author), Univ Balamand, Dept Comp Engn, El Koura, Lebanon.
EM dagheri@balamand.edu.lb
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Benchikh Salam, 2011, INT C ADV INF TECHN, P1
   Ding JJ, 2013, IEEE T IMAGE PROCESS, V22, P3664, DOI 10.1109/TIP.2013.2268971
   Fracastoro G, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2623489
   Fracastoro G, 2015, IEEE IMAGE PROC, P2631, DOI 10.1109/ICIP.2015.7351279
   Hu W, 2015, IEEE T IMAGE PROCESS, V24, P419, DOI 10.1109/TIP.2014.2378055
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Joshi Madhuri A, 2014, Image and video compression: Fundamentals, Techniques, and Applications
   Kekre H., 2012, International Conference on Communication, Information Computing Technology (ICCICT), P1
   Kozhemiakin R, 2016, P 9 INT KHARK S PHYS, P1
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Sahoo Rashmita, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P71, DOI 10.1109/ICCSP.2014.6949801
   Shrestha S, 2010, HYBRID DWT DCT ALGOR, P280
   Talukder KH, 2007, INT J APPL MATH, V3
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
NR 17
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17265
EP 17286
DI 10.1007/s11042-018-7039-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500067
DA 2024-07-18
ER

PT J
AU Liu, P
   Zhang, TX
   Li, X
AF Liu, Ping
   Zhang, Tongxun
   Li, Xiang
TI A new color image encryption algorithm based on DNA and spatial chaotic
   map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Spatial chaotic; Information security; DNA coding
AB In this paper, a color image encryption algorithm based on DNA encoding combined with logistic map and spatial map is proposed. Firstly, the algorithm carries out scrambling by logistic map for R, G, B channels. Then, XOR is operated between channels pixel and sequence matrix controlled by spatial map. After that, realizes the addition of R, G, B by DNA addition after DNA encoding and carries out complement operation by using the DNA sequence matrix controlled by spatial map. What is more, R G B channel images are got after DNA decoding. Finally, gets the encrypted R, G, B images by reconstructing R, G, B components. The results of several experimental, statistical analysis and key sensitivity tests show that the proposed image encryption algorithm provides an efficient and secure way for real-time image encryption and transmission.
C1 [Liu, Ping] Shandong Agr Univ, Coll Mech & Elect Engn, Tai An 271018, Shandong, Peoples R China.
   [Zhang, Tongxun] Shandong Agr Univ, Tai An 271018, Shandong, Peoples R China.
   [Li, Xiang] Shandong Agr Univ, Coll Life Sci, Tai An 271018, Shandong, Peoples R China.
C3 Shandong Agricultural University; Shandong Agricultural University;
   Shandong Agricultural University
RP Li, X (corresponding author), Shandong Agr Univ, Coll Life Sci, Tai An 271018, Shandong, Peoples R China.
EM lixiang@sdau.edu.cn
OI Li, Xiang/0000-0003-0517-3894
FU National Natural Science Foundation of China [31700644]; Postdoctoral
   Science Foundation of China [2015M582122 240, 2016T90644]; National Key
   Technology Support Program of China [2015BAF13B02]; Key research and
   development project of Shandong Province [2016ZDJS02A07, 2017GNC12105]
FX The work was supported by the National Natural Science Foundation of
   China (Nos. 31700644), Postdoctoral Science Foundation of China (No.
   2015M582122 240 and 2016T90644), the National Key Technology Support
   Program of China (No. 2015BAF13B02), Key research and development
   project of Shandong Province(No. 2016ZDJS02A07 and 2017GNC12105).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Cao Jian-qiu, 2010, Computer Engineering and Applications, V46, P192, DOI 10.3778/j.issn.1002-8331.2010.28.054
   Fang Dongxin, 2014, Computer Engineering, V40, P89, DOI 10.3969/j.issn.1000-3428.2014.12.016
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Halle KS, 1993, INT J BIFURCAT CHAOS, V3, P469, DOI 10.1142/S0218127493000374
   Hasler M, 2000, INT J BIFURCAT CHAOS, V10, P719, DOI 10.1142/S0218127400000505
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kang N, 2009, ARXIV09032693
   Kimsey IJ, 2015, NATURE, V519, P315, DOI 10.1038/nature14227
   Li CS, 2016, SPRINGER THESES-RECO, P131, DOI 10.1007/978-3-662-48673-3_7
   Liu Dongqi, 2014, Applied Mechanics and Materials, V644-650, P2202, DOI 10.4028/www.scientific.net/AMM.644-650.2202
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu XM, 2016, IEEE J BIOMED HEALTH, V20, P655, DOI 10.1109/JBHI.2015.2407157
   Lu Huibin, 2012, Computer Engineering and Applications, V48, P90, DOI 10.3778/j.issn.1002-8331.20t2.02.025
   Mathews R, 2011, P WORLD C ENG COMP S, P19
   Mathur N, 2016, PROCEDIA COMPUT SCI, V79, P1036, DOI 10.1016/j.procs.2016.03.131
   Peng C, 2013, P 2013 INT C MECH SC
   Rewagad P, 2013, INT CONF COMM SYST, P437, DOI 10.1109/CSNT.2013.97
   Singh G., 2013, INT J SCI ENG RES, V4, P2058
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu ZD, 2016, SOFT COMPUT, V20, P4907, DOI 10.1007/s00500-015-1778-2
   Xiang C, 2016, SOFT COMPUT, V20, P3735, DOI 10.1007/s00500-015-1759-5
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Zhang Jian, 2015, Computer Engineering and Design, V36, P613, DOI 10.16208/j.issn1000-7024.2015.03.011
NR 30
TC 25
Z9 26
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14823
EP 14835
DI 10.1007/s11042-018-6758-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700031
DA 2024-07-18
ER

PT J
AU Yeoh, WZ
   Teh, JS
   Chern, HR
AF Yeoh, Wei-Zhu
   Teh, Je Sen
   Chern, Huey Rong
TI A parallelizable chaos-based true random number generator based on
   mobile device cameras for the Android platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE True random number generator; Chaos theory; Android; Mobile device;
   Digital camera
ID SECURITY
AB True random number generators are used in high security applications such as cryptography where non-determinism is required. However, they are slower than their pseudorandom counterparts because they need to extract entropy from physical phenomenon. To overcome this drawback, generators have been designed to extract unpredictability from devices such as computer processing units or microphones. This paper introduces a new generator for the Android mobile platform based on images captured by a built-in camera. Although similar generators exist, they suffer from poor performance and a lack of proper security evaluation. The proposed generator implements a chaos-based postprocessing algorithm that eliminates statistical defects and increases its throughput. These goals are achieved by using the inherent properties of a chaotic system to amplify entropy extracted from the captured images. The proposed generator is evaluated in two phases: first, statistical test suites are executed to identify statistical defects. Next, the generator's forward and backward security is analysed. Results indicate that the proposed true random number generator is able to generate statistically secure true random number sequences faster than existing mobile-based generators. In addition, the generator is designed to support parallel processing, thus allowing its performance to scale according to the mobile device's multicore architecture.
C1 [Yeoh, Wei-Zhu; Chern, Huey Rong] Inti Int Coll Penang, Bayan Lepas, Malaysia.
   [Teh, Je Sen] Univ Sains Malaysia, Sch Comp Sci, Gelugor, Malaysia.
C3 INTI International University; Universiti Sains Malaysia
RP Teh, JS (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Gelugor, Malaysia.
EM jesen_teh@usm.my
RI Yeoh, Wei-Zhu/GQI-3451-2022; Teh, Je Sen/B-7368-2018; Yeoh,
   Wei-Zhu/GQI-3921-2022
OI Yeoh, Wei-Zhu/0000-0002-3605-345X; Teh, Je Sen/0000-0001-5571-4148;
   Yeoh, Wei-Zhu/0000-0002-3605-345X
FU Universiti Sains Malaysia [304/PKOMP/6315190]; National Natural Science
   Foundation of China [61702212]
FX This work has been partially supported by Universiti Sains Malaysia
   under Grant No. 304/PKOMP/6315190 and the National Natural Science
   Foundation of China under Grant No. 61702212.
CR Addabbo T, 2009, CHAOS BASED GENERATI, P355
   Aksoy S, 2001, PATTERN RECOGN LETT, V22, P563, DOI 10.1016/S0167-8655(00)00112-4
   Altaf M, 2018, MULTIMED TOOLS APPL, V77, P27981, DOI 10.1007/s11042-018-6022-5
   [Anonymous], J JPN SOC COMPUT STA
   Bassham L.E, 2010, tech. rep.
   Bouda J, 2009, LECT NOTES COMPUT SC, V5838, P179, DOI 10.1007/978-3-642-04766-4_13
   Brown RobertG., 2018, DIEHARDER
   CARTER JL, 1979, J COMPUT SYST SCI, V18, P143, DOI 10.1016/0022-0000(79)90044-8
   Cicek I, 2014, INTEGRATION, V47, P38, DOI 10.1016/j.vlsi.2013.06.003
   Coron JS, 1999, LECT NOTES COMPUT SC, V1560, P29
   Davis D., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P114
   Dodis Y., 2013, P 2013 ACM SIGSAC C, P647
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Kanak A, 2017, IEICE T FUND ELECTR, VE100A, P158, DOI 10.1587/transfun.E100.A.158
   Keuninckx L, 2017, SCI REP-UK, V7, DOI 10.1038/srep43428
   Marsaglia G., 1995, The Marsaglia random number CDROM including the diehard battery of tests of randomness
   Oteo JA, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036214
   Sanguinetti B, 2014, PHYS REV X, V4, DOI 10.1103/PhysRevX.4.031056
   Schindler W, 2002, LECT NOTES COMPUT SC, V2523, P431
   Suciu A., 2011, 2011 IEEE International Conference on Intelligent Computer Communication and Processing, P445, DOI 10.1109/ICCP.2011.6047913
   Teh JS, 2015, NONLINEAR DYNAM, V82, P1913, DOI 10.1007/s11071-015-2287-7
   Teh JS, 2015, NONLINEAR DYNAM, V81, P1067, DOI 10.1007/s11071-015-2049-6
   Walker J., 2008, ENTA Pseudorandom Number Sequence Test Program
   Wallace K, 2016, IEEE INTERNET THINGS, V3, P1189, DOI 10.1109/JIOT.2016.2572638
   Wei W, 2009, OPT LETT, V34, P1876, DOI 10.1364/OL.34.001876
   Xingyuan W, 2012, MATH PROBLEMS ENG
   Zhang XP, 2014, ELECTRON LETT, V50, P1841, DOI 10.1049/el.2014.2870
   Zhao L, 2009, CHAOS SOLITON FRACT, V42, P1692, DOI 10.1016/j.chaos.2009.03.068
NR 28
TC 8
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15929
EP 15949
DI 10.1007/s11042-018-7015-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500010
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Oveneke, MC
   Jiang, DM
   Sahli, H
AF Zhao, Yong
   Oveneke, Meshia Cedric
   Jiang, Dongmei
   Sahli, Hichem
TI A video prediction approach for animating single face image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression animation; Image-based; FCRBM; Reconstruction
   contractive auto-encoder; Emotion
ID MODEL
AB Generating dynamic 2D image-based facial expressions is a challenging task for facial animation. Much research work focused on performance-driven facial animation from given videos or images of a target face, while animating a single face image driven by emotion labels is a less explored problem. In this work, we treat the task of animating single face image from emotion labels as a conditional video prediction problem, and propose a novel framework by combining factored conditional restricted boltzmann machines (FCRBM) and reconstruction contractive auto-encoder (RCAE). A modified RCAE with an associated efficient training strategy is used to extract low dimensional features and reconstruct face images. FCRBM is used as animator to predict facial expression sequence in the feature space given discrete emotion labels and a frontal neutral face image as input. Both quantitative and qualitative evaluations on two facial expression databases, and comparison to state-of-the-art showed the effectiveness of our proposed framework for animating frontal neutral face image from given emotion labels.
C1 [Zhao, Yong; Jiang, Dongmei] Northwestern Polytech Univ, Sch Comp Sci, NPU VUB Joint AVSP Res Lab, 127 West Youyi Rd, Xian 710072, Peoples R China.
   [Zhao, Yong; Oveneke, Meshia Cedric; Sahli, Hichem] VUB, VUB NPU Joint AVSP Res Lab, Dept Elect & Informat ETRO, Pl Laan 2, B-1050 Brussels, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Kapeldreef 75, B-3001 Heverlee, Belgium.
C3 Northwestern Polytechnical University; Vrije Universiteit Brussel; IMEC
RP Zhao, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, NPU VUB Joint AVSP Res Lab, 127 West Youyi Rd, Xian 710072, Peoples R China.; Zhao, Y (corresponding author), VUB, VUB NPU Joint AVSP Res Lab, Dept Elect & Informat ETRO, Pl Laan 2, B-1050 Brussels, Belgium.
EM yzhao@etrovub.be; mcovenek@etrovub.be; jiangdm@nwpu.edu.cn;
   hsahli@etrovub.be
OI Sahli, Hichem/0000-0002-1774-2970; ZHAO, YONG/0000-0003-2644-952X
FU Chinese Scholarship Council (CSC) [201506290085]; Shaanxi Provincial
   International Science and Technology Collaboration Project
   [2017KW-ZD-14]; Natural Science Foundation of China [61273265]; VUB
   Interdisciplinary Research Program through the EMO-App project; Agency
   for Innovation by Science and Technology in Flanders (IWT) - PhD grant
   [131814]
FX We thank Averbuch-Elor et al. for kindly providing the sequence for
   comparison. We thank Tao Yang for the kindly processing of the facial
   expression recognition experiments and all the students for their
   participation to the subjective analysis. We would like to thank the
   reviewer for their detailed comments and suggestions for the manuscript.
   We believe that the comments have identified important areas which
   required improvement. This work is supported by the Chinese Scholarship
   Council (CSC) (grant 201506290085), the Shaanxi Provincial International
   Science and Technology Collaboration Project (grant 2017KW-ZD-14), the
   Natural Science Foundation of China (grant 61273265), the VUB
   Interdisciplinary Research Program through the EMO-App project, and the
   Agency for Innovation by Science and Technology in Flanders (IWT) - PhD
   grant nr. 131814.
CR Alain G, 2014, J MACH LEARN RES, V15, P3563
   Anderson R, 2013, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2013.434
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2017, P 34 INT C MACH LEAR
   [Anonymous], 2014, Computer Science
   [Anonymous], TECH REP
   [Anonymous], 2016, ARXIV161109232
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.262
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng Zhigang., 2008, DATA DRIVEN 3D FACIA, P1
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Ersotelos N, 2008, VISUAL COMPUT, V24, P13, DOI 10.1007/s00371-007-0175-y
   Fan B, 2015, INT CONF ACOUST SPEE, P4884, DOI 10.1109/ICASSP.2015.7178899
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jiang DM, 2014, MULTIMED TOOLS APPL, V73, P397, DOI 10.1007/s11042-013-1610-x
   Kingma D. P., 2013, STAT-US
   Liu ZC, 2001, COMP GRAPH, P271
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Shu Z., 2017, ARXIV170404131
   Stoiber Nicolas., 2009, Proceedings of the 14th International Conference on Intelligent User Interfaces, IUI'09, P207
   Susskind Joshua M., 2008, Generating facial expressions with deep belief nets
   Sutskever I., 2009, Advances in Neural Information Processing Systems, P1601
   Taylor G, 2009, P 26 ANN INT C MACH
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Wang LJ, 2015, MULTIMED TOOLS APPL, V74, P9849, DOI 10.1007/s11042-014-2118-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao Y, 2015, INT CONF AFFECT, P797, DOI 10.1109/ACII.2015.7344664
NR 40
TC 4
Z9 4
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16389
EP 16410
DI 10.1007/s11042-018-6952-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500030
DA 2024-07-18
ER

PT J
AU Ma, XQ
   Tao, DP
   Liu, WF
AF Ma, Xueqi
   Tao, Dapeng
   Liu, Weifeng
TI Effective human action recognition by combining manifold regularization
   and pairwise constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Local structure preserving; Manifold regularization;
   Pairwise constraints
ID INFORMATION; LAPLACIAN; FEATURES; FUSION
AB The ever-growing popularity of mobile networks and electronics has prompted intensive research on multimedia data (e.g. text, image, video, audio, etc.) management. This leads to the researches of semi-supervised learning that can incorporate a small number of labeled and a large number of unlabeled data by exploiting the local structure of data distribution. Manifold regularization and pairwise constraints are representative semi-supervised learning methods. In this paper, we introduce a novel local structure preserving approach by considering both manifold regularization and pairwise constraints. Specifically, we construct a new graph Laplacian that takes advantage of pairwise constraints compared with the traditional Laplacian. The proposed graph Laplacian can better preserve the local geometry of data distribution and achieve the effective recognition. Upon this, we build the graph regularized classifiers including support vector machines and kernel least squares as special cases for action recognition. Experimental results on a multimodal human action database (CAS-YNU-MHAD) show that our proposed algorithms outperform the general algorithms.
C1 [Ma, Xueqi; Liu, Weifeng] China Univ Petr East China, Qingdao 266580, Shandong, Peoples R China.
   [Tao, Dapeng] Yunnan Univ, Kunming 650091, Yunnan, Peoples R China.
C3 China University of Petroleum; Yunnan University
RP Liu, WF (corresponding author), China Univ Petr East China, Qingdao 266580, Shandong, Peoples R China.
EM liuwf@upc.edu.cn
RI ARSLAN, Okan/AAA-3232-2020; Tao, Dapeng/E-8649-2013; liu,
   weifeng/B-7909-2008
FU National Natural Science Foundation of China [61671480]; Fundamental
   Research Funds for the Central Universities, China University of
   Petroleum (East China) [14CX02203A, YCX2017059]
FX This paper is partly supported by the National Natural Science
   Foundation of China (Grant No. 61671480), the Fundamental Research Funds
   for the Central Universities, China University of Petroleum (East China)
   (Grant No. 14CX02203A, YCX2017059).
CR [Anonymous], 2008, TR1530 U WISC MAD
   Ballan L, 2012, IEEE T MULTIMEDIA, V14, P1234, DOI 10.1109/TMM.2012.2191268
   Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bernstein M., 2001, TECHNICAL REPORT, V24, P153
   Cevikalp H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P489
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Coyte JL, 2016, IEEE T SYST MAN CY-S, V46, P725, DOI 10.1109/TSMC.2015.2458964
   Ding SF, 2014, NEURAL COMPUT APPL, V24, P211, DOI 10.1007/s00521-012-1207-8
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Fu ZY, 2015, MULTIMED TOOLS APPL, V74, P3739, DOI 10.1007/s11042-013-1796-y
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936
   Guo YN, 2017, IEEE T SYST MAN CY-S, V47, P617, DOI 10.1109/TSMC.2016.2617465
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Huang KQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2449081
   Jalal A, 2012, IEEE T CONSUM ELECTR, V58, P863, DOI 10.1109/TCE.2012.6311329
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Li LJ, 2017, MULTIMED TOOLS APPL, V76, P13953, DOI 10.1007/s11042-016-3789-0
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu MX, 2016, IEEE T CYBERNETICS, V46, P298, DOI 10.1109/TCYB.2015.2401733
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Luo Yong, 2016, IJCAI, P1809
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sang JT, 2015, IEEE T MULTIMEDIA, V17, P2259, DOI 10.1109/TMM.2015.2486524
   SCHILLER H, 1990, SIGNAL PROCESS, V19, P61, DOI 10.1016/0165-1684(90)90007-L
   Seeger Matthias, 2000, Technical Report
   Tentori M, 2008, IEEE PERVAS COMPUT, V7, P51, DOI 10.1109/MPRV.2008.24
   Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263
   Wagstaff K., 2000, AAAI/IAAI, V1097, P577
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yan M, 2015, IEEE T MULTIMEDIA, V17, P1248, DOI 10.1109/TMM.2015.2446949
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Zhang D, 2007, SEMISUPERVISED DIMEN
   Zhang DQ, 2008, PATTERN RECOGN, V41, P1440, DOI 10.1016/j.patcog.2007.10.009
   Zhang JG, 2017, IEEE T CYBERNETICS, V47, P960, DOI 10.1109/TCYB.2016.2535122
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhao WT, 2012, INT C APPL ROBOT POW, P557, DOI 10.1109/CARPI.2012.6356377
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
NR 49
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13313
EP 13329
DI 10.1007/s11042-017-5172-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900032
DA 2024-07-18
ER

PT J
AU Mirehi, N
   Tahmasbi, M
   Targhi, AT
AF Mirehi, Narges
   Tahmasbi, Maryam
   Targhi, Alireza Tavakoli
TI Hand gesture recognition using topological features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Growing Neural Gas algorithm; Topological
   features; Adjacency matrix; Linear Discriminant Analysis (LDA); NTU Hand
   Digits dataset
ID GROWING NEURAL GAS; SURFACE RECONSTRUCTION; CLASSIFICATION; TRANSFORM
AB Hand Gestures Recognition (HGR) is one of the main areas of research for Human Computer Interaction applications. Most existing approaches are based on local or geometrical properties of pixels. Still, there are some serious challenges on HGR methods such as sensitivity to rotation, scale, illumination, perturbation, and occlusion. In this paper, we study HGR from graph viewpoints. We introduce a set of meaningful shape features based on a graph constructed by Growing Neural Gas (GNG) algorithm. These features are constructed from topological properties of this graph. Graph properties in conserving topological features improve stability against different deformations, scale, and noise. We evaluate our method on NTU Hand Digits dataset with state-of-the-art methods. We also prepared a comprehensive dataset (SBU-1) for different hand gestures containing 2170 images. This dataset includes many possible deformations and variations and some articulations. Most of the existing datasets don't capture these variations. We show the robustness of the algorithm to scale, rotation and noise, while preserving similar recognition rate in comparison with the state-of-the-art results.
C1 [Mirehi, Narges; Tahmasbi, Maryam; Targhi, Alireza Tavakoli] Shahid Beheshti Univ, Dept Comp Sci, Gc Tehran, Iran.
C3 Shahid Beheshti University
RP Tahmasbi, M (corresponding author), Shahid Beheshti Univ, Dept Comp Sci, Gc Tehran, Iran.
EM n_mirehi@sbu.ac.ir; m_tahmasbi@sbu.ac.ir; a_tavakoli@sbu.ac.ir
RI Tavakkoli, Alireza/AAL-7053-2021
OI Tavakkoli, Alireza/0000-0001-9460-1269
CR [Anonymous], 2006, THESIS U SOUTHAMPTON
   [Anonymous], P CHI SPARKS
   [Anonymous], 2015, Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on
   [Anonymous], 2000, Computational Geometry Algorithms and Applications
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bondy J. A, 1976, GTM
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Chaudhary A, 2011, COMM COM INF SC, V133, P46
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Fink O, 2015, MECH SYST SIGNAL PR, V50-51, P427, DOI 10.1016/j.ymssp.2014.04.022
   Flórez F, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P318, DOI 10.1109/AFGR.2002.1004173
   Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Hall E., 1959, The silent language, V3
   Holdstein Y, 2008, VISUAL COMPUT, V24, P295, DOI 10.1007/s00371-007-0202-z
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kirac F, 2014, PATTERN RECOGN LETT, V50, P91, DOI 10.1016/j.patrec.2013.09.003
   Klein H.A., 2012, SCI MEASUREMENT HIST
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Li Y, 2018, INFORM SCIENCES, V441, P66, DOI 10.1016/j.ins.2018.02.024
   Liu K, 2016, J REAL-TIME IMAGE PR, V11, P201, DOI 10.1007/s11554-013-0333-6
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Marcel S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P456, DOI 10.1109/AFGR.2000.840674
   Martinetz T, 1991, NEURALGAS NETWORK LE
   Memo A, 2018, MULTIMED TOOLS APPL, V77, P27, DOI 10.1007/s11042-016-4223-3
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Molina J, 2014, MACH VISION APPL, V25, P943, DOI 10.1007/s00138-013-0576-z
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Nai WZ, 2017, PATTERN RECOGN, V65, P1, DOI 10.1016/j.patcog.2016.11.022
   Orts-Escolano S, 2016, NEURAL PROCESS LETT, V43, P401, DOI 10.1007/s11063-015-9421-x
   Pattanaworapan K, 2016, J VIS COMMUN IMAGE R, V38, P658, DOI 10.1016/j.jvcir.2016.04.015
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shipeng Xie, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P553, DOI 10.1109/ICIG.2011.166
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Stergiopoulou E, 2014, ENG APPL ARTIF INTEL, V35, P54, DOI 10.1016/j.engappai.2014.06.006
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Tang B, 2013, IEEE SYS MAN CYBERN, P1, DOI 10.1109/SMC.2013.8
   Viola P, 2002, ADV NEUR IN, V14, P1311
   Wang C, 2017, SIGNAL PROCESS-IMAGE, V58, P87, DOI 10.1016/j.image.2017.06.015
   WANG YC, 2013, I SYMP CONSUM ELECTR, P17
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
NR 54
TC 16
Z9 16
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13361
EP 13386
DI 10.1007/s11042-019-7269-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900036
DA 2024-07-18
ER

PT J
AU Rhayma, H
   Makhloufi, A
   Hamam, H
   Ben Hamida, A
AF Rhayma, Hanen
   Makhloufi, Achraf
   Hamam, Habib
   Ben Hamida, Ahmed
TI Semi-fragile self-recovery watermarking scheme based on data
   representation through combination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-fragile watermarking; Data representation through combination; DWT;
   Self-recovery; Localization; Authentication
ID IMAGE AUTHENTICATION
AB The widely available multimedia editing tools and their large reconstruction capabilities make digital multimedia content more sensitive to malicious tampering and manipulations. Therefore, ensuring digital image integrity has become a crucial issue. Watermarking became a popular technique for image authentication. The goal of this paper is to propose a new semi-fragile watermarking scheme for image authentication, localization, and recovery, by using two different watermarks jointly. The embedded information watermark for content recovery is computed from discrete wavelet transform (DWT) approximation coefficients of second level decomposition of the original image and compressed by using Data Representation through Combination (DRC) in order to reduce watermark payload. On another hand, authentication watermark used for both authentication and localization of image tampering is computed by using the block-based watermarking algorithm. Three pseudo-random maps are generated in order to improve the security of the proposed scheme against local attack. Both watermarks are embedded into approximation sub-band of the first wavelet decomposition. Experimental results show that our proposed approach has not only an extremely high accuracy of tampering localization but also a relatively very high recovery rate. Besides, the scheme is able to detect perfectly the difference between malicious attacks and non-malicious attacks such as JPEG compression.
C1 [Rhayma, Hanen] Univ Gabes, ENIG, Gabes 6072, Tunisia.
   [Rhayma, Hanen; Makhloufi, Achraf; Ben Hamida, Ahmed] Univ Sfax, ATMS Adv Technol Med & Signals, Enis, Sfax, Tunisia.
   [Hamam, Habib] Univ Moncton, Fac Engn, Moncton, NB E1A 3E9, Canada.
C3 Universite de Gabes; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS); University of Moncton
RP Rhayma, H (corresponding author), Univ Gabes, ENIG, Gabes 6072, Tunisia.; Rhayma, H (corresponding author), Univ Sfax, ATMS Adv Technol Med & Signals, Enis, Sfax, Tunisia.
EM rhayma_hanen@yahoo.fr
RI Hamam, Habib/C-1761-2019
OI Hamam, Habib/0000-0002-5320-1012
CR [Anonymous], 2006, Introduction to Data Compression
   Boneh Dan, 2015, A graduate course in applied cryptography
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Hui Wang, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P72, DOI 10.1007/978-3-642-32205-1_8
   Li CL, 2015, MULTIMED TOOLS APPL, V74, P10581, DOI 10.1007/s11042-014-2188-7
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   LIN CY, P SOC PHOTO OPT INS, V3971, P140
   Liu C.L., 2010, A tutorial of the wavelet transform
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Poornima R., 2013, Int. JComput. Sci. Engin. Survey., V4, P23, DOI [10.5121/ijcses.2013.4102, DOI 10.5121/IJCSES.2013.4102]
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Said J, 2013, J INFORM SECURITY RE, V4, P1, DOI [10.4236/jis.2013.41001, DOI 10.4236/JIS.2013.41001]
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Salomon D., 2008, A Concise Introduction to Data Compression
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Tsai TH, 2014, J SIGNAL PROCESS SYS, V74, P203, DOI 10.1007/s11265-013-0772-0
   Ullah R, 2013, COMPUT ELECTR ENG, V39, P2019, DOI 10.1016/j.compeleceng.2013.04.024
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Chao-Ming, 2013, OPTICS PHOTONICS J, V3, P103, DOI DOI 10.4236/opj.2013.32B026
   Xiao D, 2012, OPT COMMUN, V285, P2596, DOI 10.1016/j.optcom.2012.02.002
   Zaid AO, 2009, SIGNAL IMAGE VIDEO P, V3, P197, DOI 10.1007/s11760-008-0094-z
   Zivic N., 2015, Robust Image Authentication Presence Noise, V1st, P43, DOI DOI 10.1007/978-3-319-13156-62
NR 31
TC 10
Z9 11
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 14067
EP 14089
DI 10.1007/s11042-019-7244-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900066
DA 2024-07-18
ER

PT J
AU Ballout, A
   Ghaddar, A
   Wehbi, H
AF Ballout, Ali
   Ghaddar, Alia
   Wehbi, Houssein
TI MMVS/COE: mobile multi-view video streaming with constant order encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile multi-view video encoding; H; 264; MVC; Wireless streaming;
   Inter-view dependency; Bi-directional prediction
ID MULTICAST
AB Multi-view video systems are designed to allow users to watch 3D videos or a scene recorded by multiple cameras from multiple viewpoints. They are actually used by crowd sourced journalism services or to cover events using a set of wireless drones/sensors filming the same scene, etc. Multi-view videos are captured by multiple cameras at different positions with significant correlations between neighboring views. Owing to the increased data volume of multi-view video, highly efficient encoding techniques are needed. The common idea for Multi-View Video Coding (MVC) is to further exploit the redundancy between adjacent views. In this paper, we focus on the acquisition phase of the multi-view video system. We propose a Mobile Multi-view Video Streaming scheme with Constant Order Encoding (MMVS/COE). It encodes by exploiting the inter/intra-view dependency to reduce redundancy and optimize the tradeoff between traffic volume (bite rate) and video quality. Evaluations' results show that MMVS/COE reduces traffic, compared to existing methods, mainly MVC/MC, by decreasing redundancies among video streams while maintaining video quality.
C1 [Ballout, Ali; Ghaddar, Alia] Lebanese Int Univ, Dept Comp Sci, Beirut, Lebanon.
   [Wehbi, Houssein] Lebanese Univ, Dept Comp Sci, LaRIFA, Beirut, Lebanon.
C3 Lebanese University
RP Ballout, A (corresponding author), Lebanese Int Univ, Dept Comp Sci, Beirut, Lebanon.
EM ballout619@gmail.com
RI Ballout, Ali/V-5624-2019
OI Ballout, Ali/0000-0002-7186-1831
CR [Anonymous], P 2013 ACM INT WORKS
   [Anonymous], 2005, JTC1SC29WG11 ISOIEC
   [Anonymous], 14496102008FDAM1 ISO
   [Anonymous], 2011, STANFORD MULTICAMERA
   ARTIGAS X, 2006, 7 NORD SIGN PROC S N
   Baruffa G, 2014, PYUV RAW VIDEO SEQUE
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Dufaux F, 2007, PROC SPIE, V6579, DOI 10.1117/12.719535
   Hamza A, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348824
   Jian-Guang Lou, 2005, 13th Annual ACM International Conference on Multimedia, P161
   Jiang DD, 2017, NEUROCOMPUTING, V220, P160, DOI 10.1016/j.neucom.2016.07.056
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14307, DOI 10.1007/s11042-015-3239-4
   Jiang DD, 2015, ANN TELECOMMUN, V70, P427, DOI 10.1007/s12243-015-0465-8
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P295, DOI [10.1109/ISM.2016.0065, 10.1109/ISM.2016.132]
   Kastrinakis M, 2017, COMPUT COMMUN, V109, P24, DOI 10.1016/j.comcom.2017.05.008
   Li B, 2003, IEEE NETWORK, V17, P24
   Li Shipeng, 2013, ADV MULTIMEDIA MODEL
   Liu JC, 2003, IEEE MULTIMEDIA, V10, P22, DOI 10.1109/MMUL.2003.1167919
   Matrawy Ashraf, 2003, IEEE Communications Surveys & Tutorials, V5, P22, DOI 10.1109/COMST.2003.5341336
   Matusik W., 2004, ACM T GRAPHIC, V24, P3
   Moustafa H, 2012, MEDIA NETWORKS: ARCHITECTURES, APPLICATIONS, AND STANDARDS, P1, DOI 10.1201/b12049
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Ouaret M., 2006, Proc. ACM Int. Workshop on Video Surveillance and Sensor Networks, P139, DOI DOI 10.1145/1178782.1178803
   Pulipaka A, 2013, IEEE T BROADCAST, V59, P382, DOI 10.1109/TBC.2013.2244792
   Seeling P, 2014, SCI WORLD J, DOI 10.1155/2014/189481
   Shiho K, 2015, MULTIVIEW VIDEO STRE, P1412, DOI [10.1109/GLOCOM.2014.7037006, DOI 10.1109/GL0C0M.2014.7037006]
   Sullivan GJ, 2008, JOINT VIDEO TEAM ITU
   Takuya F, 2012, TRAFFIC REDUCTION MU, P182, DOI [10.1109/ICME.2012.185, DOI 10.1109/ICME.2012.185]
   Tanimoto M, 2013, 3 DIMENSIONAL IMAGIN, P1
   Triantafyllidis GA, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/585216
   VETRO A, 2008, JVTAB204
   Wilburn B., 2004, High performance imaging using arrays of inexpensive cameras
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wyner A, 1976, IEEE T INFORM THEORY, V3, P45
   Xun G., 2006, VCIP, V38
   Zhi-Gang Li, 2004, Proceedings. Third International Conference on Image and Graphics, P353
NR 37
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10753
EP 10772
DI 10.1007/s11042-018-6564-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400055
DA 2024-07-18
ER

PT J
AU Fan, KB
   Wang, P
   Zhuang, S
AF Fan, Kaibo
   Wang, Ping
   Zhuang, Shuo
TI Human fall detection using slow feature analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Slow feature analysis; Support vector machine; Fall detection;
   Background subtraction; Human silhouette
ID DETECTION SYSTEM; HEALTH-CARE; RECOGNITION; VECTOR
AB Falls are reported to be the leading causes of accidental deaths among elderly people. Automatic detection of falls from video sequences is an assistant technology for low-cost health care systems. In this paper, we present a novel slow feature analysis based framework for fall detection in a house care environment. Firstly, a foreground human body is extracted by a background subtraction technique. After morphological operations, the human silhouette is refined and covered by a fitted ellipse. Secondly, six shape features are quantified from the covered silhouette to represent different human postures. With the help of the learned slow feature functions, the shape feature sequences are transformed into slow feature sequences with discriminative information about human actions. To represent the fall incidents, the squared first order temporal derivatives of the slow features are accumulated into a classification vector. Lastly, falls are distinguished from other daily actions, such as walking, crouching, and sitting, by the trained directed acyclic graph support vector machine. Experiments on the multiple-camera fall dataset and the SDUFall dataset demonstrate that our method is comparable to other state-of-the-art methods, achieving 94.00% recognition rate on the former dataset and 96.57% on the latter one.
C1 [Fan, Kaibo; Wang, Ping; Zhuang, Shuo] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Fan, KB (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM kaibofan@126.com
RI Zhuang, Shuo/IYS-1172-2023; Wang, Ping/GPP-2471-2022; Fan,
   Kaibo/ISU-6110-2023
OI Zhuang, Shuo/0000-0002-8052-3877; fan, kai bo/0000-0002-9359-2468
FU Department of Science and Technology in Hebei Province China
   [12213519D1]
FX This work was supported by Department of Science and Technology in Hebei
   Province China with Grant No. 12213519D1. The authors also would like to
   thank the anonymous editors and reviewers for their insightful comments
   and suggestions which improved this work.
CR Amin MG, 2016, IEEE SIGNAL PROC MAG, V33, P71, DOI 10.1109/MSP.2015.2502784
   [Anonymous], HEALTH
   [Anonymous], MATH PROBL ENG
   [Anonymous], ANOMALY DETECTION SC
   [Anonymous], 2010, TECHNICAL REPORT
   [Anonymous], TECHNICAL REPORT
   Aslan M, 2015, APPL SOFT COMPUT, V37, P1023, DOI 10.1016/j.asoc.2014.12.035
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9
   Bosch-Jorge M, 2014, EXPERT SYST APPL, V41, P7980, DOI 10.1016/j.eswa.2014.06.045
   Chaudhuri S, 2014, J GERIATR PHYS THER, V37, P178, DOI 10.1519/JPT.0b013e3182abe779
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Crispim CF Jr, 2016, IEEE T PATTERN ANAL, V38, P1598, DOI 10.1109/TPAMI.2016.2537323
   Duda R., 1973, Pattern Classification and Scene Analysis
   Erden F, 2016, IEEE SIGNAL PROC MAG, V33, P36, DOI 10.1109/MSP.2015.2489978
   Hamm J, 2016, J BIOMED INFORM, V59, P319, DOI 10.1016/j.jbi.2015.12.013
   Hassan MM, 2017, FUTURE GENER COMP SY, V66, P48, DOI 10.1016/j.future.2015.12.016
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Hossain MS, 2013, MULTIMED TOOLS APPL, V67, P433, DOI 10.1007/s11042-012-1006-3
   Igual R, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-66
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Khan MS, 2015, SIGNAL PROCESS, V110, P199, DOI 10.1016/j.sigpro.2014.08.021
   Khan SS, 2017, MED ENG PHYS, V39, P12, DOI 10.1016/j.medengphy.2016.10.014
   Koshmak G, 2016, J SENSORS, V2016, DOI 10.1155/2016/6931789
   Liu CL, 2010, EXPERT SYST APPL, V37, P7174, DOI 10.1016/j.eswa.2010.04.014
   Madarshahian R, 2016, EXPERT SYST APPL, V62, P263, DOI 10.1016/j.eswa.2016.06.027
   Meng L, 2017, MULTIMED TOOLS APPL, V76, P10779, DOI 10.1007/s11042-016-3267-8
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Olivieri DN, 2012, EXPERT SYST APPL, V39, P5935, DOI 10.1016/j.eswa.2011.11.109
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Su SZ, 2016, MULTIMED TOOLS APPL, V75, P8469, DOI 10.1007/s11042-015-2766-3
   Vapnik V., 2013, The nature of statistical learning theory
   Wang C, 2015, ARAB J GEOSCI, V8, P13, DOI 10.1007/s12517-013-1178-9
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wickramasinghe A, 2017, PERVASIVE MOB COMPUT, V34, P14, DOI 10.1016/j.pmcj.2016.06.004
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Yoon HJ, 2015, J AMB INTEL SMART EN, V7, P861, DOI 10.3233/AIS-150349
   Yu M, 2012, IEEE T INF TECHNOL B, V16, P1274, DOI 10.1109/TITB.2012.2214786
   Yun YX, 2016, NEUROCOMPUTING, V207, P726, DOI 10.1016/j.neucom.2016.05.058
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
NR 46
TC 23
Z9 25
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9101
EP 9128
DI 10.1007/s11042-018-5638-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800066
DA 2024-07-18
ER

PT J
AU Feng, YQ
   Wang, LW
   Zhang, MB
AF Feng, Yanqing
   Wang, Lunwen
   Zhang, Mengbo
TI A multi-scale target detection method for optical remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing image; Multi-scale; Object detection; Convolutional
   neural network
ID OBJECT DETECTION
AB Faster RCNN is a region proposal based object detection approach. It integrates the region proposal stage and classification stage into a single pipeline, which has both rapid speed and high detection accuracy. However, when the model is applied to the target detection of remote sensing imagery, faced with multi-scale targets, its performance is degraded. We analyze the influences of pooling operation and target size on region proposal, then a modified solution for region proposal is introduced to improve recall rate of multi-scale targets. To speed up the convergence of the region proposal networks, an improved generation strategy of foreground samples is proposed, which could suppresses the generation of non-effective foreground samples. Extensive evaluations on the remote sensing image dataset show that the proposed model can obviously improve detection accuracy for multi-scale targets, moreover the training of the model is rapid and high-efficient.
C1 [Feng, Yanqing; Wang, Lunwen; Zhang, Mengbo] Natl Univ Def Technol, Coll Elect Engn, Hefei, Anhui, Peoples R China.
   [Feng, Yanqing; Wang, Lunwen; Zhang, Mengbo] Natl Univ Def Technol, State Key Lab Pulsed Power & Laser Technol, Hefei, Anhui, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Feng, YQ (corresponding author), Natl Univ Def Technol, Coll Elect Engn, Hefei, Anhui, Peoples R China.; Feng, YQ (corresponding author), Natl Univ Def Technol, State Key Lab Pulsed Power & Laser Technol, Hefei, Anhui, Peoples R China.
EM eeifengyanqing@126.com; wanglunwen@163.com; zhangmengbo26@126.com
FU special region of national defence-related science and technology
   innovation of China [17-H863-01-ZT-003-204-03]
FX This work was supported in part by the special region of national
   defence-related science and technology innovation of China
   (17-H863-01-ZT-003-204-03). The authors would like to thank the
   associate editor and anonymous reviewers for their valuable comments and
   suggestions to improve this paper.
CR [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2572683
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Eggert C, 2016, INT C PATT RECOG, P651, DOI 10.1109/ICPR.2016.7899708
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hariharan B, 2017, IEEE T PATTERN ANAL, V39, P627, DOI 10.1109/TPAMI.2016.2578328
   Huang J, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9081418
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Li H, 2017, INT J REMOTE SENS, V38, P6281, DOI 10.1080/01431161.2017.1353159
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Nagaoka Y, 2017, PROC INT CONF DOC, P15, DOI 10.1109/ICDAR.2017.343
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wan LH, 2017, IEEE GEOSCI REMOTE S, V14, P1116, DOI 10.1109/LGRS.2017.2699329
   Wen XZ, 2015, IEEE T CIRC SYST VID, V25, P508, DOI 10.1109/TCSVT.2014.2358031
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 23
TC 8
Z9 7
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8751
EP 8766
DI 10.1007/s11042-018-6325-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800048
DA 2024-07-18
ER

PT J
AU Song, HT
   Tang, GM
   Kou, G
   Sun, YF
   Jiang, MM
AF Song, Hai-Tao
   Tang, Guang-Ming
   Kou, Guang
   Sun, Yi-Feng
   Jiang, Ming-Ming
TI Digital steganography model and embedding optimization strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganography model; Theoretical derivation; KL
   divergence; Embedding optimization
AB The existed digital steganography models and theories are not effective enough to guide the steganography processing. Based on previous studies, this paper proposes a complete digital steganography model based on additive noise. And then, with security analysis from KL divergence, the embedding optimization strategy is given through theoretical derivation needless of any side information: optimizing the embedding modification position and optimizing the embedding modification direction (+1 or-1). Through theoretical derivation, we also obtain the quantitative relationship between the pixels modification probability and the adjacent pixels difference, and prove that modification by +/- 1 randomly cannot enhance steganographic security definitely. The research in this paper can provide theoretical guidance for the design of steganography algorithms. Compared with previous studies, the proposed embedding optimization strategy has outstanding advantages of being easy to implement and being effective to improve steganographic security. The experiments by optimizing LSBM and MG algorithms show that the proposed embedding optimization strategy can effectively improve each algorithm's steganographic security at a relative small payload.
C1 [Song, Hai-Tao; Tang, Guang-Ming; Sun, Yi-Feng; Jiang, Ming-Ming] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Kou, Guang] Natl Innovat Inst Def Technol, Beijing, Peoples R China.
C3 PLA Information Engineering University
RP Kou, G (corresponding author), Natl Innovat Inst Def Technol, Beijing, Peoples R China.
EM kernelsong@yeah.net; 893018060@qq.com; kerneltao@163.com;
   yfsun001@163.com; jiangmingming1994@163.com
RI guang, kou/KHZ-1396-2024; song, haitao/KHV-3582-2024; TANG,
   Guang-Ming/E-5315-2013
CR [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   Denemark T., 2017, Electronic Imaging, V2017, P56
   Denemark T, 2015, IEEE INT WORKS INFOR
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Filler T, 2010, PROC SPIE, V7541, DOI 10.1117/12.838002
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ker AD, 2009, LECT NOTES COMPUT SC, V5806, P73, DOI 10.1007/978-3-642-04431-1_6
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Xi Ling, 2011, Journal of Information Engineering University, V12, P333
   Yang C, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9132-x
   Yi-feng Sun, 2012, Journal of Multimedia, V7, P19, DOI 10.4304/jmm.7.4.295-302
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 19
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8271
EP 8288
DI 10.1007/s11042-018-6810-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800022
DA 2024-07-18
ER

PT J
AU Su, QT
   Liu, YH
   Liu, DC
   Yuan, ZH
   Ning, HY
AF Su, Qingtang
   Liu, Yonghui
   Liu, Decheng
   Yuan, Zihan
   Ning, Hongye
TI A new watermarking scheme for colour image using QR decomposition and
   ternary coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR decomposition; Ternary coding; Blind watermarking; Colour image
ID TRANSFORM
AB At present, the binary images are often used as the original watermark images of many watermarking methods, but partial methods cannot be easily extended to colour image watermarking methods. For resolving this problem, we propose a new watermarking method using ternary coding and QR decomposition for colour image. In the procedure of embedding watermark, the colour image watermark is coded to ternary information; the colour host image is also separated into image blocks of sized 3x3, and these image blocks are further decomposed via QR decomposition; then, one ternary watermark is embedded into one orthogonal matrix Q of QR decomposition by the proposed rules. In the procedure of extracting watermark, the proposed method uses the blind-manner to extract the embedded ternary information. The novelty of this scheme lies in the proposed ternary coding for watermark image, which can improve the imperceptibility, embedded watermark capacity and real-time feature of the watermarking scheme. The results of simulation show the presented technique is better than other compared schemes with respect to imperceptibility, embedded watermark capacity and real-time feature under the similar robustness.
C1 [Su, Qingtang; Liu, Decheng; Yuan, Zihan; Ning, Hongye] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
   [Liu, Yonghui] Shanghai Dianji Univ, Sch Elect Engn, Shanghai 201306, Peoples R China.
C3 Ludong University; Shanghai Dianji University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsqt@163.com
FU National Natural Science Foundation of China [61771231, 61772253];
   Natural Science Foundation of Shandong Province [ZR2017MF010,
   ZR2017PF010]
FX This paper was partially supported by the National Natural Science
   Foundation of China (61771231, 61772253), and Natural Science Foundation
   of Shandong Province (ZR2017MF010, ZR2017PF010). We sincerely thank the
   anonymous reviewers for their valuable advice in improving the quality
   of this paper.
CR Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   DEMOOR B, 1992, SIAM J MATRIX ANAL A, V13, P993, DOI 10.1137/0613060
   Golear NEH, 2010, 2010 IEEE ACS INT C, P1
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   SU Q, 2015, PROC, V9, P991, DOI DOI 10.1007/s11760-013-0534-2
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   University of Granada. Computer Vision Group, 2012, CVG UGR IM DAT
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 22
TC 11
Z9 13
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8113
EP 8132
DI 10.1007/s11042-018-6632-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800013
DA 2024-07-18
ER

PT J
AU Yang, YY
   Li, ZH
   Xie, WC
   Zhang, ZZ
AF Yang, Yiyuan
   Li, Zhaohong
   Xie, Wenchao
   Zhang, Zhenzhen
TI High capacity and multilevel information hiding algorithm based on pu
   partition modes for HEVC videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video data hiding; HEVC; High capacity; Multilevel; PU partitioning
   modes
AB In order to realize copyright protection and piracy tracking for ever-increasing videos, video information hiding has gained more and more attention. For the latest video coding standard High Efficiency Video Coding (HEVC), most of the information hiding algorithms are based on the same characteristics as those in MPEG4 and H.264, such as DCT coefficients, intra prediction modules and motion vectors. However, few algorithms are reported to hide information based on the innovation modules introduced by HEVC. This paper has proposed a high capacity and multilevel information hiding algorithm based on PU partition modes in P-frames, which is considered to be one of the most important innovative features of HEVC. The proposed algorithm consists of two stages: first round calculation and modification process. The first round calculation is to record the PU partition modes selected by HEVC. The modification process is to force each of PU mode into one of the encoded groups according to the embedding binary bits, and then use the modified PU partition modes for the left HEVC encoding process. The experimental results show that the proposed algorithm can achieve high capacity and visual quality, and low bit rate increase, which significantly outperforms state-of-the-art works in embedding capacity.
C1 [Yang, Yiyuan] Beihang Univ, Sch Comp Sci & Engn, Beijing 100083, Peoples R China.
   [Li, Zhaohong; Xie, Wenchao] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Zhang, Zhenzhen] Beijing Inst Graph Commun, Sch Informat & Engn, Beijing 100026, Peoples R China.
C3 Beihang University; Beijing Jiaotong University
RP Li, ZH (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM zhhli2@bjtu.edu.cn
RI li, zh/HII-5698-2022; zhen, wang/KBA-3844-2024
FU National Natural Science Foundation of China [61702034]
FX This work was supported by the National Natural Science Foundation of
   China (No.61702034).
CR [Anonymous], 2018, IEEE T CIRCUITS SYST
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen Y, 2017, J COMPUTER APPL
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Lin TJ, 2013, J SYST SOFTWARE, V86, P604, DOI 10.1016/j.jss.2012.10.922
   Po CC, 2014, SIGN INF PROC ASS SU, P1
   [盛琪 Sheng Qi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P433
   Sheng Q, 2016, LECT NOTES COMPUT SC, V10039, P63, DOI 10.1007/978-3-319-48671-0_6
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang J., 2014, J. Comput. Inform. Syst., V10, P8933
   [王家骥 Wang Jiaji], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P942
   [王家骥 Wang Jiaji], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P1578
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Xie WC, 2018, LECT NOTES COMPUT SC, V11066, P252, DOI 10.1007/978-3-030-00015-8_22
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yi C, 2018, ARXIV180406628 CORR
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang J, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P535, DOI 10.1109/MMSP.2001.962788
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 21
TC 38
Z9 43
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8423
EP 8446
DI 10.1007/s11042-018-6859-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800030
DA 2024-07-18
ER

PT J
AU Genç, A
   Ekenel, HK
AF Genc, Anil
   Ekenel, Hazim Kemal
TI Cross-dataset person re-identification using deep convolutional neural
   networks: effects of context and domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Context adaptation; Domain adaptation;
   Cross-dataset; Convolutional neural networks; CycleGAN
AB Over the past years, the impact of surveillance systems on public safety increases dramatically. One significant challenge in this domain is person re-identification, which aims to detect whether a person has already been captured by another camera in the surveillance network or not. Most of the work that has been conducted on person re-identification problem uses a single dataset, in which the training and test data are coming from the same source. However, as we have shown in this work, there is a strong bias among the person re-identification datasets, therefore, a method that has been trained and optimized on a specific person re-identification dataset may not generalize well and perform successfully on the other datasets. This is a problem for many real-world applications, since it is not feasible to collect and annotate sufficient amount of data from the target application to train or fine-tune a deep convolutional neural network model. Taking this issue into account, in this work, we have focused on cross-dataset person re-identification problem and first explored and analyzed in detail the use of the state-of-the-art deep convolutional neural network architectures, namely AlexNet, VGGNet, GoogLeNet, ResNet, and DenseNet that have been developed for generic image classification task. These deep CNN models have been adapted to the person re-identification domain by fine-tuning them for each human body part separately, as well as on the entire body, with the two relatively large person re-identification datasets: CUHK03 and Market-1501. Then, the performance of each adapted model has been evaluated on two different publicly available datasets: VIPeR and PRID2011. We have shown that, even just a domain adaptation leads comparable results to the state-of-the-art cross-dataset approaches. Another point that we have addressed in this paper is context adaptation. It has been known that person re-identification approaches implicitly utilizes background as context information. Therefore, to have a consistent background across different camera views, we have employed the cycle-consistent generative adversarial network. We have shown that this further improves the performance.
C1 [Genc, Anil; Ekenel, Hazim Kemal] Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Technical University
RP Genç, A (corresponding author), Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
EM genca16@itu.edu.tr
RI EKENEL, HAZIM KEMAL/A-5293-2016
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548; , Anil/0000-0003-0430-2789
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2014, P AS C COMP VIS
   Barbosa IB, 2017, ARXIV170103153 CORR
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A, 2017, CORR ARXIV 1703 0773
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao S., 2014, JOINT DIMENSION REDU
   Ma AJ, 2015, IEEE T IMAGE PROCESS, V24, P1599, DOI 10.1109/TIP.2015.2395715
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   McLaughlin A, 2015, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2015.10
   Nanda A, 2019, MULTIMED TOOLS APPL, V78, P3885, DOI 10.1007/s11042-017-4875-7
   Nanda AJ, 2017, IEEE ACCESS, V5, P6471, DOI 10.1109/ACCESS.2017.2686438
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   Wu Q, 2017, MULTISCALE CONVOLUTI, DOI [10.2991/cnct-16.2017.115, DOI 10.2991/CNCT-16.2017.115]
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Zheng L, 2016, ARXIV161002984 CORR
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 37
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5843
EP 5861
DI 10.1007/s11042-018-6409-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100041
DA 2024-07-18
ER

PT J
AU Lin, Y
   Yang, J
   Mi, J
   Yang, JJ
   Zhang, X
AF Lin, Yu
   Yang, Jie
   Mi, Jing
   Yang, Jingjing
   Zhang, Xiao
TI RETRACTED: A novel registration and super-resolution jointed paradigm
   for medical images under internet of thing environment (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Medical image; Image registration; Image super-resolution; Internet of
   things; Data storage; Algorithm efficiency; Jointed paradigm
ID SINGLE; CT; IMPLEMENTATION; DEFORMATION; INFORMATION; SYSTEM; MR
AB This paper proposes a novel registration and super-resolution jointed paradigm for medical images under the Internet of thing environment. In the medical image processing, the matching issue is one catches wide attention with the domain of research. Image registration technique can be divided into similarity measure, optimization, geometric transformation, and interpolation, etc. As the first essential clue of our model, we propose the novel registration algorithm based on energy feature extraction. Generally, the matching energy function by the similarity measurement and a penalty constitution is called the external force and endogenic force separately. The matching is an external force and endogenic force mutual competition, eventually achieves the balanced process. Furtherly, we integrate the game analysis and area feature selection to achieve the better image super-resolution mode through the pretreatment of the image to change the initial value, so as to achieve the purpose of improving the performance. Besides the algorithm level innovation, we integrate the GPU and the IOT to construct the hardware based implementation of the proposed medical image processing system. The latency of registers to read and write data across a GPU's entire storage system is minimal, it is private to each thread, and can only be accessed by its owning thread. For each thread, the local memory is also private and it is often used to deal with the problem of overflow register, reducing the buffer overflow caused by the entire application of a substantial decline in the possibility and shared memory is visible to all threads within the thread block. We then achieve the optimal integration of IOT and GPU. The experimental result proves the robustness of the method.
C1 [Lin, Yu; Yang, Jie; Mi, Jing; Yang, Jingjing; Zhang, Xiao] Hebei North Univ, Zhangjiakou 075000, Hebei, Peoples R China.
C3 Hebei North University
RP Zhang, X (corresponding author), Hebei North Univ, Zhangjiakou 075000, Hebei, Peoples R China.
EM liuyu29oc@163.com
FU Population Health Informatization in Hebei Province Engineering
   Technology Research Center; Medical Informatics in Hebei Universities
   Application Technology Research and Development Center; Hebei province
   department of science and technology project [15217747D]; Hebei province
   department of health project [20160029]; Zhangjiakou department of
   science and technology project [1421012B]; Youth Foundation of the
   Education Department of Hebei Province [QN2016190]
FX This project was supported partially by the Population Health
   Informatization in Hebei Province Engineering Technology Research
   Center, Medical Informatics in Hebei Universities Application Technology
   Research and Development Center, Hebei province department of science
   and technology project(15217747D), Hebei province department of health
   project(20160029), Zhangjiakou department of science and technology
   project (1421012B), and Youth Foundation of the Education Department of
   Hebei Province (QN2016190).
CR Alaei A, 2016, COMPUT SCI REV
   Albalawi U, 2016, VLSI ISVLSI 2016 IE
   [Anonymous], SMART CLOUD STORAGE
   [Anonymous], FAST SINGLE IMAGE SU
   [Anonymous], ARXIV160406620
   [Anonymous], IEEE T IMAGE PROCESS
   Badshah G, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.1.017001
   Batten C. F., 2001, Scanning, V23, P112
   Bi C, 2015, INT COMP INT THINGS
   Bi CJ, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTERNET OF THINGS, P55, DOI 10.1109/ICAIOT.2015.7111537
   Blunt MJ, 2013, ADV WATER RESOUR, V51, P197, DOI 10.1016/j.advwatres.2012.03.003
   Cao JW, 2016, NEURAL NETWORKS, V81, P91, DOI 10.1016/j.neunet.2016.06.001
   Chae S, 2016, 2016 IE 10 INT C SEM
   Chen H, 2016, CLOUD SERVICE BROKER
   Chen HG, 2016, SIGNAL PROCESS-IMAGE, V43, P68, DOI 10.1016/j.image.2016.01.007
   Cho C, 2016, IEEE T IMAGE PROCESS, V25, P1617, DOI 10.1109/TIP.2016.2526785
   Cho O, 2013, RADIAT ONCOL, V8, DOI 10.1186/1748-717X-8-163
   Chuang TW, 2016, COMP CONS CONTR IS3C
   De Nigris D, 2012, IEEE T MED IMAGING, V31, P2343, DOI 10.1109/TMI.2012.2218116
   Debita G, 2016, INF SYST ARCH TECHN
   Dimitrovski I, 2016, INFORM SCIENCES, V329, P851, DOI 10.1016/j.ins.2015.05.012
   Do N. H., 2016, Thesis
   Dong-Xiao Z, 2016, IMAGE SUPER RESOLUTI, P641
   Elfes A., 2013, Occupancy grids: A stochastic spatial representation for active robot perception
   Gao Y, 2016, INT S BIOM IM ISBI
   Garg R, 2015, PATT REC MACH INT 6, V9124
   Glowacka D, 2016, ARXIV160309522
   Guler P, 2016, J REAL-TIME IMAGE PR, V11, P457, DOI 10.1007/s11554-013-0337-2
   Hindia MN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155077
   Hipwell JH, 2016, PHYS MED BIOL, V61, pR1, DOI 10.1088/0031-9155/61/2/R1
   Hong S, 2016, PROCEDIA COMPUT SCI, V80, P190, DOI 10.1016/j.procs.2016.05.309
   Hu J, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243617
   Hu YL, 2015, INT C ALG ARCH PAR P
   Huang X, 2016, INT CONTR AUT WCICA
   Javed Adeel, 2016, IOT PATTERNS LOCATIO, P195
   Jurkovic I, 2016, MED PHYS, V43, P3620, DOI 10.1118/1.4956866
   Kim S, 2019, J INTELL MANUF, V30, P383, DOI 10.1007/s10845-016-1253-7
   Kurugol S, 2015, INT C MED IM COMP CO
   Kwon Y, 2015, IEEE T PATTERN ANAL, V37, P1792, DOI 10.1109/TPAMI.2015.2389797
   Labine A, 2014, MED PHYS, V41, DOI 10.1118/1.4888139
   LEE JH, 1995, IEEE T CONSUM ELECTR, V41, P449, DOI 10.1109/30.468047
   Li J, 2016, NEUROCOMPUTING, V184, P196, DOI 10.1016/j.neucom.2015.07.139
   Li W, 2015, MATH PROBL ENG
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu W, 2015, 2015 IE INT C DIG SI
   Mansoor A, 2016, BIOM IM ISBI 2016 IE
   Tu NA, 2016, INFORM SCIENCES, V366, P99, DOI 10.1016/j.ins.2016.05.029
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Oro D, 2016, 2016 IEEE INT C AC S
   Parikh S, 2016, 2016 IE INT C CONS E
   Peddigari V, 2005, J IMAGING SCI TECHN, V49, P114
   Popple R, 2016, MED PHYS, V43, P3428, DOI 10.1118/1.4956004
   Radenovi Filip, 2016, ARXIV160402426
   Ramachandra M, 2016, INT THINGS APPL IOTA
   Salih Y. K., 2016, T EMERG TELECOMMUN T
   Samarin A, 2015, NUCL MED COMMUN, V36, P194, DOI 10.1097/MNM.0000000000000229
   Sandeep P, 2016, IEEE T IMAGE PROCESS, V25, P4233, DOI 10.1109/TIP.2016.2588319
   Schnabel JA, 2016, MED IMAGE ANAL, V33, P145, DOI 10.1016/j.media.2016.06.031
   Shah AJ, 2016, PROCEDIA COMPUT SCI, V85, P100, DOI 10.1016/j.procs.2016.05.186
   SHAO JC, 2016, ENERGY EFFICIENT PHA, P295, DOI DOI 10.1007/978-3-662-48868-3_47
   Shi Y, 2016, CONTR DEC C CCDC 201
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Song X, 2016, J AM COLL NUTR, P1
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Sundaresh R, 2016, 2016 IE SW S IM AN I
   Tandale SB, 2016, IMP J INTERDISCIPL R, V2
   Tang J, 2016, MULT EXP ICME 2016 I
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Vialard FX, 2012, INT J COMPUT VISION, V97, P229, DOI 10.1007/s11263-011-0481-8
   Wan C, 2016, J COMPUT THEOR NANOS, V13, P2753
   Wang H., 2013, Int. J. Signal Process., V6, P345
   Wang Haoxiang, 2014, 2014 IE 26 INT C TOO
   Wermelinger F, 2016, P PLATF ADV SCI COMP, DOI DOI 10.1145/2929908.2929914
   Wu W, 2016, P 8 INT C DIG IM PRO
   Xue JJ, 2016, ADV ENG SOFTW, V99, P73, DOI 10.1016/j.advengsoft.2016.05.006
   Yan F, 2016, QUANTUM INF PROCESS, V15, P1, DOI 10.1007/s11128-015-1195-6
   Yang JD, 2016, MITOCHONDRIAL DNA A, V27, P3327, DOI 10.3109/19401736.2015.1018206
   Yang X, 2014, SPIE MED IMAGING
   Yao Y, 2016, ULTRAMICROSCOPY, V166, P1, DOI 10.1016/j.ultramic.2016.04.001
   Ye LW, 2016, IEEE SIGNAL PROC LET, V23, P838, DOI 10.1109/LSP.2016.2558489
   Ye S, 2015, 2015 IE INT C AC SPE
   Yue B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030288
   Zhang LX, 2012, ADV INTEL SYS RES, V23
   Zhong Z, 2016, MED PHYS, V43, P3737, DOI 10.1118/1.4957427
   Zou HD, 2013, APPL MECH MATER, V397-400, P1523, DOI 10.4028/www.scientific.net/AMM.397-400.1523
NR 85
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5107
EP 5135
DI 10.1007/s11042-017-4385-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100002
DA 2024-07-18
ER

PT J
AU Tabash, FK
   Izharuddin, M
AF Tabash, Fatma K.
   Izharuddin, Muhammed
TI Efficient encryption technique for H.264/AVC videos based on CABAC and
   logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Video coding; CABAC; H; 264; AVC
ID SELECTIVE ENCRYPTION; SCHEME
AB Nowadays, the use of real time video communication is growing with a rapid pace. For example, Search and Rescue (SAR) applications like earthquake rescue, avalanche victims, wildfire monitoring in highway and surveillance are some of the applications of real time video communication. Most of these video communications require secure transmission of signals. For real time video communication, the processing time is considered as the most important metric to be optimized. Thus, finding a simple and time efficient encryption technique for securing the transmitted data becomes mandatory. The motive behind this work is to design a system that can process the video signal in real time providing a secure communication. In this paper, we present an efficient encryption technique which has low computation complexity. The proposed technique is based on Context-Adaptive Binary Arithmetic Coding (CABAC) where the bin-string of Intra-Prediction Mode, Motion Vector Difference (MVD) and residue coefficients are encrypted with the random behavior of chaotic systems. The random bit streams used for encryption are generated with chaotic systems using Logistic map. The experimental results show that the proposed technique is very effective for real-time applications and robust against different types of attacks.
C1 [Tabash, Fatma K.; Izharuddin, Muhammed] Aligarh Muslim Univ, Dept Comp Engn, Aligarh 202002, UP, India.
C3 Aligarh Muslim University
RP Tabash, FK (corresponding author), Aligarh Muslim Univ, Dept Comp Engn, Aligarh 202002, UP, India.
EM fatma.tabash86@gmail.com
OI , fatma/0000-0002-9851-4530
CR [Anonymous], 2012, AUD MULT SYST INFR H
   Bodke N, 2015, INT J COMPUT APPL, V128, P6
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Li Y, 2005, Proceedings of 2005 International Conference on Innovation & Management, P1120
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Lian SG, 2008, MULTIMED TOOLS APPL, V38, P75, DOI 10.1007/s11042-007-0150-7
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Liao X, 2017, J SIGNAL PROCESSING, V58, P156, DOI DOI 10.1016/j.image.2017.03.002
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   LIU Y, 2007, ICACT, V1, P583, DOI DOI 10.1109/ICACT.2007.358423
   Magli E, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1353, DOI 10.1109/ICME.2006.262810
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Podesser M, 2002, CD ROM P 5 IEEE NORD
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   SU P, TOOLS, V52, P529, DOI DOI 10.1007/s11042-009-0458-6
   Tong L, 2010, ELECTRON LETT, V46, P47, DOI 10.1049/el.2010.2068
   Wang YS, 2012, EUR SIGNAL PR CONF, P1752
   Yeung SKA, 2009, IEEE SIGNAL PROC LET, V16, P893, DOI 10.1109/LSP.2009.2026109
NR 18
TC 6
Z9 6
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7365
EP 7379
DI 10.1007/s11042-018-6494-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700043
DA 2024-07-18
ER

PT J
AU Yin, F
   Wu, R
   Yu, XY
   Sun, GG
AF Yin, Fang
   Wu, Rui
   Yu, Xiaoyang
   Sun, Guanglu
TI Video text localization based on Adaboost
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Text localization; Edge detection; Classifier; Adaboost; CART
AB Video text localization is an important step in video text recognition system for monitored control system, auto navigation system, content based image analysis system and so on. So it's necessary to find a good method to extract text from video image accurately and quickly. In this paper a new method of video text localization based on Adaboost is proposed. Firstly, the edge detection is performed using Sobel operator based on the gradient feature to extract text region in the image. Through the analysis the feature of the video image region, five kinds of features are extracted to form five weak classifiers, then these features are classified to construct Adaboost strong classifier with CART (Classification And Regression Tree) and the candidates text regions are sent to the classifier to get correct result of the text region detection. The experimental results show that this method can not only achieve good effect on the text localization in the video images with the text of various fonts, sizes and colors, but also can realize rapidly and accurately to meet the video text localization requires.
C1 [Yin, Fang; Sun, Guanglu] Harbin Univ Sci & Technol, Dept Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Yin, Fang; Yu, Xiaoyang] Harbin Univ Sci & Technol, Instrument Sci & Technol Postdoctoral Res Stn, Harbin, Heilongjiang, Peoples R China.
   [Wu, Rui] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology; Harbin Institute of Technology
RP Sun, GG (corresponding author), Harbin Univ Sci & Technol, Dept Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM 13936421412@163.com
OI Rui, Wu/0000-0003-0941-2688
FU research project of science and technology of Heilongjiang provincial
   education department [12541119]
FX This paper is supported by the research project of science and
   technology of Heilongjiang provincial education department (No.
   12541119).
CR Chen X, 2004, CVPR 2004 P I E COMP, V2, P11366
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Gao S, 2014, APPL RES COMPUT, V31, P3174
   Gudipati VK, 2016, 2016 ANN CONN C IND
   HUA XS, 2001, P ACM MULT 2001 WORK, P24
   Jiang M, 2017, COMPUT SCI, V44, P8
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Viola P, 2000, ADV NEURAL INF PROCE, P1311
   Wu D, 2013, RES VIDEO TEXT EXTRA
   Yu M, 2007, 2017 1 INT C EL INST
   Zhao M, 2010, IMAGE VISION COMPUT, V28, P1590, DOI 10.1016/j.imavis.2010.04.002
   Zhou Y, 2011, INT C DOC AN REC IEE
NR 14
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5345
EP 5354
DI 10.1007/s11042-018-6064-8
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100015
DA 2024-07-18
ER

PT J
AU Lan, CL
   Cui, ZQ
   Su, TX
AF Lan, Chunliang
   Cui, Zhiqin
   Su, Tiexiong
TI RETRACTED: Numerical analysis of catalytic efficiency of diesel exhaust
   purification based on multimedia aided regression model (Retracted
   article. See MAR, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Efficiency numerical analysis; Multimedia assisted regression model;
   Diesel engine; Exhaust gas treatment and purification
ID COMBUSTION; EMISSIONS
AB Automotive diesel has become an international trend, and more and more attention has been paid to the purification of diesel engine. In the face of the European emission standards, we need to develop emission control technologies applicable to high standards. Outside purification is the key to this technology. In this paper, the technology of diesel engine purification outside and outside of China is analyzed. The principle, characteristics, treatment effect and application prospect of various methods are analyzed. In this paper, the process and influence of the tail gas production in diesel engine fuel combustion are expounded. The chemical characteristics and chemical reaction equations of harmful tail gas, the emission hazard of diesel engine and the method and significance of exhaust gas treatment are listed. With the continuous development of multimedia technology, multimedia teaching plays a more and more important role in the field of modern teaching. At the same time, multimedia teaching is a breakthrough in the traditional backward teaching mode. Multimedia assisted instruction is widely used all over the world, and it also faces many problems caused by improper use while improving students' academic achievements. Multimedia assisted and regression models are adopted in this paper.
C1 [Lan, Chunliang; Cui, Zhiqin; Su, Tiexiong] North Univ China, Taiyuan, Shanxi, Peoples R China.
C3 North University of China
RP Lan, CL (corresponding author), North Univ China, Taiyuan, Shanxi, Peoples R China.
EM lanchunliang666@126.com
CR Govender S, 2017, CATALYSTS, V7, DOI 10.3390/catal7020062
   Han CB, 2015, ACS NANO, V9, P12552, DOI 10.1021/acsnano.5b06327
   Hasan MM, 2016, RENEW SUST ENERG REV, V57, P282, DOI 10.1016/j.rser.2015.12.157
   Hegner R, 2017, INT J HYDROGEN ENERG, V42, P1287, DOI 10.1016/j.ijhydene.2016.09.050
   Jinke G, 2013, CHINESE J ENV ENG, V2, P43
   Lee J, 2014, J MECH SCI TECHNOL, V28, P3395, DOI 10.1007/s12206-014-0752-8
   Li L, 2017, ACS APPL MAT INTERFA
   Liu HY, 2017, APPL ENERG, V185, P1393, DOI 10.1016/j.apenergy.2015.10.183
   Liu ShengJi Liu ShengJi, 2016, Transactions of the Chinese Society of Agricultural Engineering, V32, P60
   Omraei M, 2013, IND ENG CHEM RES, V52, P1829, DOI 10.1021/ie301418y
   Pisarenko EV, 2014, THEOR FOUND CHEM EN+, V48, P249, DOI 10.1134/S0040579514030166
   Vojtisek-Lom M, 2015, ATMOS ENVIRON, V109, P9, DOI 10.1016/j.atmosenv.2015.02.077
   Zhang GJ, 2015, J CENT SOUTH UNIV, V22, P4456, DOI 10.1007/s11771-015-2993-9
   Zhao F-q, 2013, MACHINERY, V1, P12
NR 14
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4437
EP 4461
DI 10.1007/s11042-018-5898-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200028
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, SK
AF Singh, Durgesh
   Singh, Sanjay K.
TI Block Truncation Coding based effective watermarking scheme for image
   authentication with recovery capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Self-embedding watermarking; Block
   truncation coding; Image authentication; Image restoration
ID SEMI-FRAGILE WATERMARKING; ROBUST; LOCALIZATION
AB Due to the advancement of photo-editing software, powerful computers and high resolution capturing devices, it has become tough to prevent the digital image from tampering. So, in these days just by looking a digital image we cannot say whether it is a genuine or not. This is why digital image authentication, as well as restoration, has become the essential issues, especially when it is utilized in medical science, evidence of court, and forensic science. This paper proposes an effective self-embedding fragile watermarking technique for the digital image authentication as well as recovery. The watermark is generated by quantization, and block truncation coding (BTC) of each 2 x 2 non-overlapping block and embedded in three least significant bits (LSBs) of the corresponding mapped block. The recovery bits are derived from most significant bits (MSBs) of the host image, and the authentication bits are derived from recovery bits, the spatial location of pixels and watermark keys. Even if tempering rate is 50%, the reconstruction of tampered image is achieved with high peak signal-to-noise ratio (PSNR) and normalized correlation coefficient (NCC). The experimental results demonstrate that the proposed scheme not only outperforms high-quality recovery fidelity but also negotiate the blocking artifacts additionally it improves the accuracy of tamper localization due to the use of very small size blocks.
C1 [Singh, Durgesh; Singh, Sanjay K.] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, D (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM durgeshcse@gmail.com; sks.cse@iitbhu.ac.in
RI kumar, Sanjay/ITT-3680-2023; Singh, Durgesh/AAZ-2801-2020; Singh, Sanjay
   Prithviraj/IQV-1492-2023; Singh, Sanjay Kumar/AAC-2031-2022
OI Singh, Durgesh/0000-0002-6078-1502; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762; Singh, Sanjay Kumar/0000-0002-9061-6313
CR Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Cox IJ., 2007, DIGITAL WATERMARKING
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   FRANTI P, 1995, IEEE T COMMUN, V43, P1677, DOI 10.1109/26.380217
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Singh D, 2016, MULTIMEDIA TOOLS APP
   Singh D, 2013, IJIG, V13
   Singh D., 2013, INTELLIGENT INTERACT, V10, P111, DOI DOI 10.1007/978-3-642-37463-0_10
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Song C, 2009, P POSTGR NETW S
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Walia E, 2014, SIGNAL IMAGE VIDEO P, V8, P859, DOI 10.1007/s11760-012-0312-6
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wu M, 1998, WATERMARKING IMAGE A, P437
   WU YY, 1991, IEEE T COMMUN, V39, P1283, DOI 10.1109/26.99132
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 35
TC 13
Z9 14
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4197
EP 4215
DI 10.1007/s11042-017-5454-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200017
DA 2024-07-18
ER

PT J
AU Zhou, CQ
   Yang, YW
   Wang, YJ
AF Zhou, Caiqiu
   Yang, Yuwang
   Wang, Yongjian
TI DV-Hop localization algorithm based on bacterial foraging optimization
   for wireless multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Bacterial foraging optimization;
   DV-Hop; Localization; Multimedia
AB DV-Hop localization algorithm is a classic range free localization algorithm in wireless sensor networks (WSNs). Although easy to be employed in low cost and resource limited WSNs, DV-Hop localization algorithm suffers from low localization accuracy as the other range free localization approaches. To improve the localization accuracy, in this paper we introduce Bacterial Foraging Optimization (BFO), an efficient optimization method that has been widely applied in a variety of scientific and engineering applications. We conduct extensive simulations under different network setting, the simulation results demonstrate that the proposed algorithm achieves significantly higher positioning accuracy than the basic DV-Hop algorithm.
C1 [Zhou, Caiqiu; Yang, Yuwang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wang, Yongjian] Natl Comp Network Emergency Response Tech Team Co, Beijing 100029, Peoples R China.
C3 Nanjing University of Science & Technology
RP Yang, YW (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM yuwangyang@njust.edu.cn
FU Natural Science Foundation of China [61640020]
FX This research was supported by the Natural Science Foundation of China
   No. 61640020.
CR Bermejo E, 2015, INFORM SCIENCES, V295, P160, DOI 10.1016/j.ins.2014.10.018
   Bermejo E, 2013, APPL SOFT COMPUT, V13, P3178, DOI 10.1016/j.asoc.2012.08.041
   Bulusu N, 2000, IEEE PERS COMMUN, V7, P28, DOI 10.1109/98.878533
   Camilo T, 2006, LECT NOTES COMPUT SC, V4150, P49, DOI 10.1007/11839088_5
   Chen HY, 2008, IEICE T FUND ELECTR, VE91A, P2232, DOI 10.1093/ietfec/e91-a.8.2232
   Devi S, 2014, EXPERT SYST APPL, V41, P2772, DOI 10.1016/j.eswa.2013.10.010
   Doherty L, 2001, IEEE INFOCOM SER, P1655, DOI 10.1109/INFCOM.2001.916662
   Dulman S, 2004, DEST INT WORKSH SIGN
   Guvenc I, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICU), P420
   Hatami A, 2006, IEEE WCNC, P2267
   He T., 2003, PROC 9 ANN INT C MOB, P81, DOI DOI 10.1145/938985.938995
   Hou SF, 2010, INT CONF COMP SCI, P243, DOI 10.1109/ICCSIT.2010.5565188
   Hu Fengsong, 2011, Computer Engineering and Applications, V47, P42, DOI 10.3778/j.issn.1002-8331.2011.28.010
   Ji W-W, 2006, INT C WIR COMM NETW, P1, DOI [10.1109/WiCOM.2006.257, DOI 10.1109/WICOM.2006.257]
   Kumar S, 2013, WIRELESS PERS COMMUN, V71, P1365, DOI 10.1007/s11277-012-0880-3
   LAZOS L, 2004, ACM WORKSH WIR SEC W
   [刘锋 Liu Feng], 2008, [电子与信息学报, Journal of Electronics & Information Technology], V30, P1222
   Liu Ke-zhong, 2006, Information and Control, V35, P787
   Liu Shaofei, 2009, Chinese Journal of Sensors and Actuators, V22, P1154
   Liu Z, 2017, IEEE T DEPEND SECURE, V14, P237, DOI 10.1109/TDSC.2016.2577022
   Niculescu D, 2003, IEEE INFOCOM SER, P1734
   Panda R, 2015, APPL SOFT COMPUT, V30, P722, DOI 10.1016/j.asoc.2015.02.021
   Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010
   Romer K, 2003, ACM USENIX INT C MOB
   Stoleru R, 2005, ACM C EMB NETW SENS
   Stoleru R, 2007, ADV INFORM SECUR, V30, P3
   Tan LJ, 2015, NEUROCOMPUTING, V151, P1208, DOI 10.1016/j.neucom.2014.03.082
   Tao Y, 2010, INT C MAN SCI ENG
   Verma OP, 2011, PATTERN RECOGN LETT, V32, P1187, DOI 10.1016/j.patrec.2011.03.008
   Xing W, 2006, 2006 6TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS PROCEEDINGS, P127
   Yang CC, 2016, INT J APPROX REASON, V69, P147, DOI 10.1016/j.ijar.2015.11.003
NR 31
TC 10
Z9 10
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4299
EP 4309
DI 10.1007/s11042-018-5674-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200020
DA 2024-07-18
ER

PT J
AU Ouloul, IM
   Moutakki, Z
   Afdel, K
   Amghar, A
AF Ouloul, Imad Mohamed
   Moutakki, Zakaria
   Afdel, Karim
   Amghar, Abdellah
TI Improvement of age estimation using an efficient wrinkles descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Facial images; Biometrics; Wrinkles; Local matched
   filter binary pattern
ID INVARIANT TEXTURE CLASSIFICATION; PATTERN; IMAGES; MODELS
AB Lately, automatic age estimation from facial images is in demand because of the usage of this technique in different fields including security, demographic analysis, access control and vending machines control. However, age estimation is difficult to conduct due to the aging process features' evolution complexity, such as the face shape and skin wrinkles. In this context, we propose a new descriptor called Local Matched Filter Binary Pattern (LMFBP) designed specifically for the detection and extraction of skin wrinkles. This descriptor is based on exploiting both the Matched Filter and the texture operator Local Binary Pattern (LBP). The Matched Filter handles the detection of wrinkles using template matching between the approximate shape of wrinkles and the face image patches. Furthermore, the LBP operator encodes the response of the Matched Filter into pattern codes to build the histogram of skin aging feature. The fusion of local features provided by the LMFBP with the global features of the appearance enabled us to propose a new age estimation method. In this method, we adopted the hierarchical approach in the learning phase, in order to consider the varying aging process from one age stage to another. The proposed age estimation method has been tested on both FGnetAD, HQfaces and PAL datasets, and the results provided are 4.95, 3.65 and 5.33 in terms of MAE, respectively. These results prove the efficiency of the proposed approach when compared to the state-of-the-art age estimation methods.
C1 [Ouloul, Imad Mohamed; Moutakki, Zakaria; Amghar, Abdellah] Ibnou Zohr Univ, Metrol & Informat Proc Lab, BP 80000, Agadir, Morocco.
   [Afdel, Karim] Ibnou Zohr Univ, Comp Syst & Vis Lab, BP 80000, Agadir, Morocco.
C3 Ibn Zohr University of Agadir; Ibn Zohr University of Agadir
RP Ouloul, IM (corresponding author), Ibnou Zohr Univ, Metrol & Informat Proc Lab, BP 80000, Agadir, Morocco.
EM md1.ouloul@gmail.com; k.afdel@uiz.ac.ma
RI amghar, Abdellah/GXF-5197-2022; Karim, AFDEL/AAC-7992-2019
OI Karim, AFDEL/0000-0002-0828-2116; abdellah, amghar/0000-0003-1463-9158;
   Moutakki, Zakaria/0000-0002-9629-2276
FU Centre National pour la Recherche Scientifique et Technique CNRST,
   project: PPR2;  [010UIZ2014]
FX This research work was supported by the Centre National pour la
   Recherche Scientifique et Technique CNRST, project: PPR2 and research
   grant No: 010UIZ2014.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], [No title captured]
   [Anonymous], 2008, P 2008 23 INT S COMP
   [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2007, P IEEE 11 INT C COMP
   [Anonymous], 2018, P IEEE WORKSH APPL C
   [Anonymous], 2013, ICB, DOI DOI 10.1109/ICB.2013.6613022
   [Anonymous], 2001, J Appl Sci Eng, DOI DOI 10.6180/JASE.2001.4.3.05
   Bukar AM, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061605
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cula GO, 2013, SKIN RES TECHNOL, V19, pE243, DOI 10.1111/j.1600-0846.2012.00635.x
   Nguyen DT, 2015, SENSORS-BASEL, V15, P21898, DOI 10.3390/s150921898
   Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115
   El Dib MY, 2010, IEEE IMAGE PROC, P1589, DOI 10.1109/ICIP.2010.5651440
   Fu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1383
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Fukai Hironobu, 2007, SICE '07. 46th SICE Annual Conference, P2808
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Ghufran RS, 2016, MULTIMED TOOLS APPL, V77, P1
   Guo GD, 2012, STUD COMPUT INTELL, V409, P101
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563041
   Hayashi J., 2001, Proceedings Seventh International Conference on Virtual Systems and Multimedia, P439, DOI 10.1109/VSMM.2001.969698
   Huerta I, 2015, PATTERN RECOGN LETT, V68, P239, DOI 10.1016/j.patrec.2015.06.006
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jun-Da Txia, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P885, DOI 10.1109/IIH-MSP.2009.142
   Kilinc M., 2013, COMPUTER VISION IMAG, P313, DOI DOI 10.1007/978-3-642-38241-3_21
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lai DH, 2017, MULTIMED TOOLS APPL, V76, P6551, DOI 10.1007/s11042-015-3230-0
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1027, DOI 10.1109/ICDSP.2002.1028265
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lemperle G, 2001, PLAST RECONSTR SURG, V108, P1735, DOI 10.1097/00006534-200111000-00048
   Liang YY, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/242846
   Liu JY, 2014, SIGNAL PROCESS, V94, P576, DOI 10.1016/j.sigpro.2013.07.025
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Ng C.-C., 2014, 12 AS C COMP VIS, P609
   Ng CC, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P675
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouloul IM, 2016, 2016 IEEE ACS 13 INT, P1, DOI [10. 1109/AICCSA. 2016. 7945649, DOI 10.1109/AICCSA.2016.7945649]
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182
   Vieira TF, 2014, VISUAL COMPUT, V30, P1333, DOI 10.1007/s00371-013-0884-3
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
   Wiskott L, 1997, IEEE T PATTERN ANAL
   Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481
   Ylioinas J, 2013, LECT NOTES COMPUT SC, V8156, P141
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhang L, 2012, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2012.6466800
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 62
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1913
EP 1947
DI 10.1007/s11042-018-6275-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700030
DA 2024-07-18
ER

PT J
AU Tian, R
   Zhang, YF
   Duan, MY
   Li, X
AF Tian, Rui
   Zhang, Yongfei
   Duan, Miyi
   Li, Xi
TI Adaptive intra mode decision for HEVC based on texture characteristics
   and multiple reference lines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Intra mode decision; Texture characteristics; Multiple reference
   lines; Adaptive threshold
ID EFFICIENCY
AB The High Efficiency Video Coding (HEVC) standard was designed to achieve significantly improved coding efficiency compared with the widespread use of H.264/AVC standards. This achievement was motivated by the ever-increasing popularity of high-definition and ultra-HD video application. However, this comes at the expense of a significant increase in encoder complexity, especially in intra-frame coding. To enhance the intra coding performance, a set of 35 intra prediction modes is adopted in HEVC. To reduce the complexity of intra prediction while maintaining the coding performance, an adaptive fast mode decision algorithm for HEVC intra coding based on texture characteristics and multiple reference lines is proposed in this paper. First, we take advantage of pixel values deviation (PVD) to obtain dominate texture direction of prediction unit (PU) and predict the texture prediction direction candidate set out of all 35 intra prediction modes based on texture direction with due consideration of texture complexity and PU size. Second, an adaptive multiple reference line-based intra prediction scheme will be utilized with classification strategy to improve coding efficiency. Third, the relation observed between the costs of two candidate modes will be exploited to improve the efficiency of prediction. Experimental results demonstrate that the proposed algorithm saves 20.45% intra encoding time on average without incurring noticeable performance degradation and outperforms the state-of-the-art intra mode decision algorithms by achieving a better RD performance with approximate encoding time saving.
C1 [Tian, Rui; Li, Xi] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhang, Yongfei] Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhang, Yongfei] State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Duan, Miyi] Chinese Acad Sci, Inst Comp Technol, Beijing 100191, Peoples R China.
C3 Beihang University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS
RP Zhang, YF (corresponding author), Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Zhang, YF (corresponding author), State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM real-tian@hotmail.com; yfzhang@buaa.edu.cn; scl@glc.cn.net;
   lix126@buaa.edu.cn
RI Zhang, Yongfei/A-1505-2010
OI Zhang, Yongfei/0000-0002-5080-1733
FU National Key Research and Development Plan [2016YFC0801001]; NSFC Key
   Project [61632001]; National Natural Science Foundation of China
   [61772054]
FX This work was partially supported by the National Key Research and
   Development Plan (Grant No. 2016YFC0801001), the NSFC Key Project (No.
   61632001) and the National Natural Science Foundation of China (No.
   61772054).
CR [Anonymous], 2012, P 2012 VISUAL COMMUN
   [Anonymous], WORKSH MULT SIGN PRO
   [Anonymous], 2016, 2016 INT C DIG IM CO
   Bossen F, 2013, ISO IEC JTC1 SC29 WG
   Jamali M, 2015, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2015.21
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee B, 2016, IEEE T IMAGE PROCESS, V25, P3787, DOI 10.1109/TIP.2016.2579559
   Lee B, 2011, IEEE SIGNAL PROC LET, V18, P571, DOI 10.1109/LSP.2011.2163935
   Lee H, 2016, IEEE T CIRC SYST VID, V26, P107, DOI 10.1109/TCSVT.2015.2450151
   Li JH, 2018, IEEE T CIRC SYST VID, V28, P947, DOI 10.1109/TCSVT.2016.2633377
   Liao W, 2017, P 2016 IEEE VIS COMM, P1, DOI DOI 10.1109/VCIP.2016.7805540
   Liu XG, 2017, IEEE T CIRC SYST VID, V27, P1737, DOI 10.1109/TCSVT.2016.2556278
   Matsuo S, 2009, P PCS09 CHIC IL, P1, DOI [10.1109/PCS.2009.5167430, DOI 10.1109/PCS.2009.5167430]
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Senzaki K, 2010, JOINT COLL TEAM VID
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Vaidyanathan G., 1989, SOUTHEASTCON '89 Proceedings. Energy and Information Technologies in the Southeast (Cat. No.89CH2672-4), P733, DOI 10.1109/SECON.1989.132497
   Zhang DD, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P510, DOI 10.1109/VCIP.2014.7051618
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao L., 2011, INT C INT MULT COMP, P300
   Zhao X, 2010, IEEE T CIRC SYST VID, V20, P647, DOI 10.1109/TCSVT.2010.2045803
NR 24
TC 10
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 289
EP 310
DI 10.1007/s11042-018-6001-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500016
DA 2024-07-18
ER

PT J
AU Al-Qershi, OM
   Khoo, BE
AF Al-Qershi, Osamah M.
   Khoo, Bee Ee
TI Evaluation of copy-move forgery detection: datasets and evaluation
   metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move; Digital image forensics; Image forgery
ID INVARIANT DETECTION; EFFICIENT; TRANSFORM; ALGORITHM; FORENSICS; DCT
AB Creating copy-move forgery became even easier using a wide range of software and platforms. Many algorithms have been proposed to solve the problem, but each one of those algorithms has its own drawbacks. Researchers face many challenges in developing copy-move detection algorithms, and in this paper, we focus on two challenges. The first is the benchmark dataset, and the second involves evaluation metrics. In this paper, we investigate the available copy-move datasets and their advantages and disadvantages. In addition, we discuss the different metrics that have been used by researchers to evaluate the copy-move forgery detection (CMFD) algorithms. On that basis, we suggest the standard specifications of the appropriate copy-move dataset and the metrics that should be used to evaluate the detection algorithms. The findings of this paper will help researchers evaluate their algorithms effectively and fairly essential for developing reliable algorithms.
C1 [Al-Qershi, Osamah M.; Khoo, Bee Ee] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Sains Malaysia
RP Khoo, BE (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM beekhoo@usm.my
RI Khoo, Bee Ee/D-8730-2011; Al-Qershi, Osamah/AAT-3203-2020
OI Khoo, Bee Ee/0000-0002-3492-2551; Al-Qershi, Osamah/0000-0002-1796-2009
FU Ministry of Education Malaysia through FRGS [203/PELECT/6071305]
FX The authors would like to acknowledge the financial assistance provided
   by the Ministry of Education Malaysia through FRGS grant number
   203/PELECT/6071305.
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], IEEE UP SECT C EL CO
   [Anonymous], P INT C INT C INT SY
   [Anonymous], 2014, IOSR J COMPUTER ENG
   [Anonymous], P 3 INT C FRONT INT
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], 17 DSP 2011 INT C DI
   [Anonymous], INT J MULTIMED UBIQU
   [Anonymous], P IEEE VIS COMM IM P
   [Anonymous], INT J DIGIT CONTENT, DOI DOI 10.4156/JDCTA.VOL5.ISSUE6.12
   [Anonymous], INT C SYST SIGN IM P
   [Anonymous], DEPTH SOCIAL MEDIA P
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2003, P DFRWS 2003
   [Anonymous], P SPIE
   [Anonymous], WHAT SIZE SHOULD ONL
   [Anonymous], 2015, J INFORM HIDING MULT
   [Anonymous], 2014, P 2014 INT S NEXT GE
   Ardizzone E., 2010, Proceedings of the 2nd acm workshop on multimedia in forensics, security and intelligence, P59
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Brownlee Jason., 2015, Machine Learning Mastery
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chihaoui T, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P125, DOI 10.1109/ATSIP.2014.6834590
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Doyoddorj M, 2014, L N INST COMP SCI SO, V132, P3, DOI 10.1007/978-3-319-14289-0_1
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Haizhen He, 2013, Information Technology Journal, V12, P2975, DOI 10.3923/itj.2013.2975.2979
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   Hsu H-C, 2012, ANTICOUNTERFEITING S, P1
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Kohavi R., 1998, Machine Learning, V30, P271
   Kulkarni V.S., 2014, SPVRYANS INT J ENG S, V1, P1
   Kumar S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P649, DOI 10.1109/ICIIP.2013.6707675
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P1061, DOI 10.1109/WICT.2012.6409232
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu F, 2014, INT J SECUR APPL, V8, P377, DOI 10.14257/ijsia.2014.8.5.33
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Liu L, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P626, DOI 10.1109/IIH-MSP.2014.162
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   Maind Rohini A, 2014, INT J SOFT COMPUT EN, V4, P49
   Manning C.D., 2009, Introduction to Infromation Retrieval, P151
   Manu VT, 2016, ADV INTELL SYST COMP, V425, P645, DOI 10.1007/978-3-319-28658-7_55
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   Oommen RS, 2016, ADV INTELL SYST COMP, V425, P559, DOI 10.1007/978-3-319-28658-7_47
   Park C-S, 2016, MULTIMED TOOLS APPL, V75, P1, DOI [10.1007/s11042-014-2221-x, DOI 10.1007/S11042-014-2221-X]
   Powers D.M.W., 2007, Technical Report, V2, P37
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sharma S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P795, DOI 10.1109/CICT.2015.88
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Singh VK, 2015, PROCEDIA COMPUT SCI, V54, P772, DOI 10.1016/j.procs.2015.06.091
   Sunil K., 2014, Ict and critical infrastructure: Proceedings of the 48th annual convention of computer society of india-vol, Vii, P577, DOI DOI 10.1007/978-3-319-03095-1_62
   Tao Wang, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P258, DOI 10.1109/ICIG.2013.61
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tralic D, 2014, INT CONF SYST SIGNAL, P167
   Uliyan DM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8070062
   Uliyan DM, 2015, IEEE CONF OPEN SYST, P7, DOI 10.1109/ICOS.2015.7377269
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Wang T, 2012, COMM COM INF SC, V321, P438
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Yang J., 2013, J COMPUT INF SYST, V9, P6399
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Yu LY, 2014, INT CONF CLOUD ENG, P510, DOI 10.1109/IC2E.2014.54
   Zhang J, 2008, 2008 11TH IEEE SINGAPORE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), VOLS 1-3, P362, DOI 10.1109/ICCS.2008.4737205
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 77
TC 27
Z9 27
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31807
EP 31833
DI 10.1007/s11042-018-6201-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000013
DA 2024-07-18
ER

PT J
AU Jansi, R
   Amutha, R
AF Jansi, R.
   Amutha, R.
TI A novel chaotic map based compressive classification scheme for human
   activity recognition using a tri-axial accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Accelerometer; Chaotic map; Classification;
   Compression
ID IMAGE COMPRESSION; SYSTEM; ALGORITHM; SENSORS; MODELS
AB Human activity recognition using wearable body sensors plays a vital role in the field of pervasive computing. In this paper, we present human activity recognition framework using compressive classification of data collected from a tri-axial accelerometer sensor. Inspired by the theories of random projection, we propose a novel chaotic map for dimensionality reduction of the accelerometer raw data. This framework also involves extraction of time and frequency domain features from the compressed data. These features are used for human activity recognition using a sparse based classifier. Thus, a simultaneous dimension reduction and classification approach is presented in this paper. We experimentally validate the effectiveness of our proposed framework by recognizing 8 common daily human activities performed by 15 subjects of varying age groups. Our proposed framework achieves superior performance in terms of specificity, precision, F-score and overall accuracy.
C1 [Jansi, R.] Anna Univ, SSN Coll Engn, Dept ECE, Madras, Tamil Nadu, India.
   [Amutha, R.] SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
C3 SSN College of Engineering; Anna University; Anna University Chennai;
   SSN College of Engineering
RP Jansi, R (corresponding author), Anna Univ, SSN Coll Engn, Dept ECE, Madras, Tamil Nadu, India.
EM jansir@ssn.edu.in
RI R, Jansi/ITT-3245-2023; Amutha, R./AAB-9399-2020
OI R, Jansi/0000-0001-9894-0006; 
CR Ayachi FS, 2016, IEEE T NEUR SYS REH, V24, P1060, DOI 10.1109/TNSRE.2016.2519413
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   Ding IJ, 2016, COMPUT ELECTR ENG, V49, P173, DOI 10.1016/j.compeleceng.2015.03.032
   Erden F, 2014, IEEE T CONSUM ELECTR, V60, P675, DOI 10.1109/TCE.2014.7027342
   Fahad LG, 2015, APPL SOFT COMPUT, V37, P992, DOI 10.1016/j.asoc.2015.03.045
   Gayathri KS, 2017, KNOWL-BASED SYST, V121, P173, DOI 10.1016/j.knosys.2017.01.025
   Gibson RM, 2017, BIOMED SIGNAL PROCES, V33, P96, DOI 10.1016/j.bspc.2016.10.016
   Giovanetti V, 2017, LIVEST SCI, V196, P42, DOI 10.1016/j.livsci.2016.12.011
   Guan QJ, 2014, PATTERN RECOGN LETT, V49, P231, DOI 10.1016/j.patrec.2014.07.018
   Guo P, 2014, MULTIMED TOOLS APPL, V68, P827, DOI 10.1007/s11042-012-1084-2
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Khan A, 2016, PATTERN RECOGN LETT, V73, P33, DOI 10.1016/j.patrec.2016.01.001
   Kumari P, 2017, BIOSENS BIOELECTRON, V90, P298, DOI 10.1016/j.bios.2016.12.001
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lee JS, 2017, EXPERT SYST APPL, V81, P299, DOI 10.1016/j.eswa.2017.03.062
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Machado IP, 2015, INFORM PROCESS MANAG, V51, P204, DOI 10.1016/j.ipm.2014.07.008
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mukhopadhyay SC, 2015, IEEE SENS J, V15, P1321, DOI 10.1109/JSEN.2014.2370945
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Rodgers MM, 2015, IEEE SENS J, V15, P3119, DOI 10.1109/JSEN.2014.2357257
   Sprott JC., 2003, CHAOS TIME SERIES AN
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Xiao L, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716679668
   Xiao YL, 2016, MULTIMED TOOLS APPL, V75, P13041, DOI 10.1007/s11042-015-2569-6
   Xu HL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16122048
   Yang CC, 2010, SENSORS-BASEL, V10, P7772, DOI 10.3390/s100807772
   Zhang K, 2017, MOBILE NETW APPL, P1
   Zhang M., 2011, P BODYNETS, P92
   Zhang M, 2013, IEEE J BIOMED HEALTH, V17, P553, DOI 10.1109/JBHI.2013.2253613
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
NR 40
TC 19
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31261
EP 31280
DI 10.1007/s11042-018-6117-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600050
DA 2024-07-18
ER

PT J
AU Medimegh, N
   Belaid, S
   Atri, M
   Werghi, N
AF Medimegh, Nassima
   Belaid, Samir
   Atri, Mohamed
   Werghi, Naoufel
TI 3D mesh watermarking using salient points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D watermarking; Salient points; Mesh segmentation; Statistical method
ID ALGORITHM; MODELS
AB In this paper, we propose a robust and blind watermarking algorithm for 3D mesh models. Firstly, we extract salient feature points using a robust salient point detector based on Auto Diffusion Function (ADF). Afterwards, the mesh is segmented into different regions according to the detected salient points. Finally, we embed the watermark statistically into each region. During watermark embedding, the vertex norms are decomposed into normalized bins. Then, the watermark is embedded by modifying the amplitude depending on the watermark bit and the mean of each bin. In the extraction process, we extract the signature from each re-segmented region. Experiments conducted with a variety of mesh models evidenced the competitive performance of our watermarking scheme, in terms of the robustness and invisibility, when compared to other state of the art methods.
C1 [Medimegh, Nassima; Atri, Mohamed] Univ Monastir, Microelect Lab, Fac Sci, Monastir, Tunisia.
   [Belaid, Samir] Univ Sousse, MARS Res Lab LR17ES05, Higher Inst Comp Sci & Telecom ISITCom, Sousse, Tunisia.
   [Werghi, Naoufel] Khalifa Univ, Dept Elect & Comp Engn, C2PS, Abu Dhabi, U Arab Emirates.
C3 Universite de Monastir; Universite de Sousse; Khalifa University of
   Science & Technology
RP Medimegh, N (corresponding author), Univ Monastir, Microelect Lab, Fac Sci, Monastir, Tunisia.
EM Medimegh_nassima@yahoo.fr; Samir.Belaid@fsm.rnu.tn;
   Mohamed.Atri@fsm.rnu.tn; Naoufel.Werghi@ku.ac.ae
RI ATRI, Mohamed/C-4069-2014; Medimegh, Nassima/AAB-3419-2022; Werghi,
   Naoufel/ABA-6280-2020; BELAID, Samir/AGA-5268-2022
OI ATRI, Mohamed/0000-0001-8528-5647; Medimegh,
   Nassima/0000-0001-5614-6736; Werghi, Naoufel/0000-0002-5542-448X;
   BELAID, Samir/0000-0003-3392-507X
CR [Anonymous], IEEE T INFORM FORENS
   [Anonymous], INT J MULTIMEDIA
   [Anonymous], ARXIV150505590CSCG
   [Anonymous], 6 IEEE INT C SOFTW E
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE INT C SHAP MOD
   [Anonymous], P IMMERSCOM
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cayre F, 2003, SIGNAL PROCESS-IMAGE, V18, P309, DOI 10.1016/S0923-5965(02)00147-9
   Chen LM, 2011, ATL AMB PERVAS INTEL, V4, P1, DOI 10.1097/COC.0b013e3181fe41ed
   Chen-Tsung Kuo, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P136, DOI 10.1109/IIH-MSP.2009.44
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Chou CM, 2007, INT J COMPUT SCI NET, V7, P328
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Harte T, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P661, DOI 10.1109/ICIP.2002.1039057
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Hu R, 2009, INT CONF ACOUST SPEE, P1501, DOI 10.1109/ICASSP.2009.4959880
   Jang HU, 2018, MULTIMED TOOLS APPL, V77, P5685, DOI 10.1007/s11042-017-4483-6
   Jing L., 2014, TELKOMNIKA Indonesian Journal of Electrical Engineering, V12, P1610, DOI DOI 10.11591/TELKOMNIKA.V12I2.3853
   Kai Wang, 2010, Proceedings of the Shape Modeling International (SMI 2010), P231, DOI 10.1109/SMI.2010.33
   Mao XY, 2001, PROC SPIE, V4314, P253, DOI 10.1117/12.435406
   Medimegh N, 2017, COMM COM INF SC, V684, P27, DOI 10.1007/978-3-319-60654-5_3
   Mohamed HH, 2015, NEUROCOMPUTING, V168, P790, DOI 10.1016/j.neucom.2015.05.045
   Mun SM, 2015, INT CONF 3D IMAG
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Pratikakis I., 2010, EUR WORKSH 3D OBJ RE, P7, DOI DOI 10.2312/3DOR/3DOR10/007-014
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Wang JR, 2012, VISUAL COMPUT, V28, P1049, DOI 10.1007/s00371-011-0650-3
   Wang K, 2012, COMPUT GRAPH-UK, V36, P808, DOI 10.1016/j.cag.2012.06.004
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yang Y, 2010, COMPUT GRAPH FORUM, V29, P1585, DOI 10.1111/j.1467-8659.2010.01767.x
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zhan YZ, 2014, J ZHEJIANG U-SCI C, V15, P351, DOI 10.1631/jzus.C1300306
NR 35
TC 9
Z9 11
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32287
EP 32309
DI 10.1007/s11042-018-6252-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000035
DA 2024-07-18
ER

PT J
AU Prabhakaran, N
   Ramakrishnan, SS
   Shanker, NR
AF Prabhakaran, N.
   Ramakrishnan, S. S.
   Shanker, N. R.
TI Geospatial analysis of terrain through optimized feature extraction and
   regression model with preserved convex region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cat optimization algorithm; Particle swarm optimization; Fuzzy shape
   model; Boundary region; Regression
AB In this paper, cat optimization algorithm for feature extraction in satellite image has been proposed. In cat optimization, cost function computes the pixel in the satellite image to preserve the boundary shape and avoid non-convex part of the contour of the image. However, the existing feature extraction optimization algorithm measures the distinct data framework and thematic information to insight land cover such as waterbody, urban and vegetation. The land cover is obtained from different optimized feature extraction algorithms never provide proper boundary shape and land feature. Furthermore, the proposed cat optimized algorithm distinguishes the inner, outer and extended boundary along with the land cover. The cat-optimised algorithm for low and high-resolution satellite image shows the better result of 85%, with the preserved convex region when compared with the existing feature extraction algorithm such as fuzzy and Particle Swarm Optimization (PSO).
C1 [Prabhakaran, N.] Vel Tech High Tech Dr Rangarajan Dr Sakunthala En, Madras 600062, Tamil Nadu, India.
   [Ramakrishnan, S. S.] Anna Univ, Inst Remote Sensing, Madras 600025, Tamil Nadu, India.
   [Shanker, N. R.] IAF, Aalim Muhammed Salegh Coll Engn, Madras 600055, Tamil Nadu, India.
C3 Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College; Anna
   University; Anna University Chennai
RP Prabhakaran, N (corresponding author), Vel Tech High Tech Dr Rangarajan Dr Sakunthala En, Madras 600062, Tamil Nadu, India.
EM captainprabhakar1982@yahoo.co.in; drssramakrishnan@yahoo.com;
   drnrshanker@gmail.com
RI Nagalingam, shanker/AAB-7227-2022; Rajendiran, Shanker/AAB-7228-2022;
   natarajan, prabhakaran/AAM-5667-2020; Nagalingam, shanker/AAF-9018-2019
OI Nagalingam, shanker/0000-0001-7821-3178; natarajan,
   prabhakaran/0000-0003-1673-1943; 
CR Bouzidi A, 2014, COLLOQ INF SCI TECH, P202, DOI 10.1109/CIST.2014.7016619
   Chen SZ, 2015, IEEE T GEOSCI REMOTE, V53, P1947, DOI 10.1109/TGRS.2014.2351395
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Dubey YK, 2016, ADV FUZZY SYST, V2016, DOI 10.1155/2016/3406406
   Espinoza-Molina D, 2015, IEEE J-STARS, V8, P1696, DOI 10.1109/JSTARS.2014.2371138
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Mekhalfi ML, 2015, IEEE GEOSCI REMOTE S, V12, P2155, DOI 10.1109/LGRS.2015.2453130
   Papa JP, 2016, IEEE J-STARS, V9, P2333, DOI 10.1109/JSTARS.2016.2557584
   Regniers O, 2016, IEEE T GEOSCI REMOTE, V54, P3722, DOI 10.1109/TGRS.2016.2526078
   Rozenstein O, 2015, IEEE J-STARS, V8, P2393, DOI 10.1109/JSTARS.2014.2371920
   Sharafi Y., 2013, 2013 3 IEEE INT C CO, P1
   Shih HC, 2016, IEEE J-STARS, V9, P2064, DOI 10.1109/JSTARS.2015.2504371
   Vakalopoulou M, 2016, IEEE J-STARS, V9, P2940, DOI 10.1109/JSTARS.2016.2557081
NR 13
TC 0
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31855
EP 31873
DI 10.1007/s11042-018-6190-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000015
DA 2024-07-18
ER

PT J
AU Zhao, JW
   Zhang, WD
   Cao, FL
AF Zhao, Jianwei
   Zhang, Weidong
   Cao, Feilong
TI Robust object tracking using a sparse coadjutant observation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Sparse representation; Observation model;
   Discriminative score model; Generative model
ID VISUAL TRACKING
AB This paper develops a classical visual tracker that is called a discriminative sparse similarity (DSS) tracker. Based on the classical Laplacian multi-task reverse sparse representation to get a DSS map in the DSS tracker, we introduce a sparse generative model (SGM) to handle the appearance variation in the DSS tracker. With the alliance of the DSS map and the SGM, our proposed method can track the object under the occlusion and appearance variations effectively. Numerous experiments on various challenging videos of a tracking benchmark illustrate that the proposed tracker performs favorably against several state-of-the-art trackers.
C1 [Zhao, Jianwei; Zhang, Weidong; Cao, Feilong] China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Cao, FL (corresponding author), China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
EM feilongcao@gmail.com
RI Zhang, Weidong/AAU-3038-2020
OI Zhang, Weidong/0000-0003-2495-4469
FU National Natural Science Foundation of China [61571410, 61672477];
   Zhejiang Provincial Nature Science Foundation of China [LY18F020018]
FX This work was funded by the National Natural Science Foundation of China
   (61571410 and 61672477) and the Zhejiang Provincial Nature Science
   Foundation of China (LY18F020018).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2015, PROC CVPR IEEE
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh T.B., 2011, P IEEE WORKSH APPL C, P642, DOI DOI 10.1109/WACV.2011.5711565
   Dong Wang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1751, DOI 10.1109/ICPR.2010.433
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu WM, 2011, INT J COMPUT VISION, V91, P303, DOI 10.1007/s11263-010-0399-6
   Ji H, 2012, IEEE COMP VIS PATT R, V2012, P1830
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Tseng Paul, 2008, Tech. Rep., V2, P3
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang XL, 2015, IEEE T PATTERN ANAL, V37, P28, DOI 10.1109/TPAMI.2014.2343221
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 42
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30969
EP 30991
DI 10.1007/s11042-018-6132-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600037
DA 2024-07-18
ER

PT J
AU Khalib, ZIA
   Ehtiba, FO
   Ahmad, RB
   Salim, NS
   Rahman, M
   Li, MF
AF Khalib, Zahereel Ishwar Abdul
   Ehtiba, Farij Omar
   Ahmad, R. Badlishah
   Salim, Naseer Sabri
   Rahman, Mostafijur
   Li, Mingfu
TI Optimize adaptive media playout using dynamic fuzzy logic control for
   video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive media playout; Buffer outage; Fuzzy logic control; Playout
   delay; Video streaming
AB Adaptive Media Playout (AMP) controls adapt playout rate to prevent buffer outage and to reduce delay in playout. Most AMP techniques use buffer fullness or its variation as indicator to adapt to playout rate. Nonetheless, selecting a convenient buffer threshold of particular design is a great challenge. Based on this principle, Dynamic Fuzzy Logic (DFL) controls principle fused with AMP technique to propose a new technique, known as DFLAMP. The technique is implemented to reduce playout delay and prevent buffer outage. Moreover, DFLAMP is also utilized to adjust playout rate based on arrival rate variation and adapt playout rate to keep the buffer fullness around the desired level. Simulation results have indicated that DFLAMP technique efficiently outperforms other AMP approaches. DFLAMP shows 14.5% less buffer underflow, 25% less buffer overflow, and 26.4% less distortion of variance as compared to APTA. Moreover, it depicts 7.5% decreased total playout delay as compared to DPTA-APTA.
C1 [Khalib, Zahereel Ishwar Abdul; Ehtiba, Farij Omar; Ahmad, R. Badlishah; Salim, Naseer Sabri] Univ Malaysia Perlis, Embedded Network & Adv Comp Res Sch Comp & Commun, Arau, Malaysia.
   [Ehtiba, Farij Omar] Misrata Univ, Fac Informat Technol, Misrata, Libya.
   [Ahmad, R. Badlishah] Univ Sultan Zainal Abidin, Kampus Gong Badak, Kuala Nerus 21300, Terengganu, Malaysia.
   [Rahman, Mostafijur] Daffodil Int Univ, Dept Software Engn, 102 Shukrabad, Dhaka 1207, Bangladesh.
   [Li, Mingfu] Chang Gung Univ, Coll Engn, Sch Elect & Comp Engn, Dept Elect Engn, Taoyuan 33302, Taiwan.
C3 Universiti Malaysia Perlis; Universiti Sultan Zainal Abidin; Daffodil
   International University; Chang Gung University
RP Khalib, ZIA (corresponding author), Univ Malaysia Perlis, Embedded Network & Adv Comp Res Sch Comp & Commun, Arau, Malaysia.
EM zahereel@unimap.edu.my
RI , Harry/K-6383-2019; Ahmad, R Badlishah/G-5892-2015; Rather, Raouf
   A/J-3509-2019; Ahmad, Badlishah/A-4703-2019; Ahmad, RB/U-3211-2019;
   Rahman, Dr. Md Mostafijur/C-9032-2011
OI , Harry/0000-0002-4812-8244; Ahmad, Badlishah/0000-0002-4862-2728;
   Ahmad, RB/0000-0002-4862-2728; Abdul Khalib, Zahereel
   Ishwar/0000-0003-3277-2163; Rahman, Dr. Md
   Mostafijur/0000-0001-6504-6331
FU Ministry of Higher Education, Malaysia (MoHE) through the Fundamental
   Research Grant Scheme (FRGS)
FX The research is funded by the Ministry of Higher Education, Malaysia
   (MoHE) through the Fundamental Research Grant Scheme (FRGS).
CR Al-Zoubi H, 2016, JORDANIAN J COMPUT I, V2, P86
   CHEN Y, 2016, MATH PROBL ENG, V2016, P1, DOI DOI 10.1155/2016/6564202
   Chuang HC, 2005, IEEE INT SYMP CIRC S, P3267
   Ehtiba FO, 2016, INT CONF ELECTRON D, P522, DOI 10.1109/ICED.2016.7804700
   Hamodi J, 2014, ARXIV14012542
   Hu H, 2010, IEEE T CONSUM ELECTR, V56, P2330, DOI 10.1109/TCE.2010.5681108
   Jiexi Wang, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P369, DOI 10.1109/ICMEW.2017.8026314
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   Li MF, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/2619438
   Li MF, 2012, MULTIMEDIA SYST, V18, P391, DOI 10.1007/s00530-012-0260-6
   Li MF, 2009, LECT NOTES COMPUT SC, V5630, P26
   Lindeberg M, 2011, MULTIMEDIA SYST, V17, P51, DOI 10.1007/s00530-010-0187-8
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Rui C, 2010, 2010 19 ANN WIR OPT, P1, DOI [10.1109/wocc20105510614, DOI 10.1109/WOCC20105510614]
   Su GM, 2016, WIREL NETW, V22, P1571, DOI 10.1007/s11276-015-1028-7
   Su YF, 2009, IEEE T MULTIMEDIA, V11, P1331, DOI 10.1109/TMM.2009.2030543
   Wu JY, 2016, IEEE T PARALL DISTR, V27, P710, DOI 10.1109/TPDS.2015.2416736
   Yang J, 2011, IEEE T MULTIMEDIA, V13, P1141, DOI 10.1109/TMM.2011.2160158
   Yang YH, 2006, IEEE INT SYM MULTIM, P415
   Zhang XY, 2012, COMPUT NETW, V56, P3548, DOI 10.1016/j.comnet.2012.06.013
NR 23
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28799
EP 28816
DI 10.1007/s11042-018-6073-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500042
DA 2024-07-18
ER

PT J
AU Liu, JQ
   Gou, JP
   Zhan, YZ
   Mao, QR
AF Liu, Junqi
   Gou, Jianping
   Zhan, Yongzhao
   Mao, Qirong
TI Discriminative self-adapted locality-sensitive sparse representation for
   video semantic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-adaptive; Locality-sensitive; Dictionary learning; Sparse
   representation; Video semantic concept detection
ID ROBUST FACE RECOGNITION; DICTIONARY
AB In recent years, sparse representation has attracted a blooming interest in the areas of pattern recognition, image processing, and computer vision. In video semantic analysis, the diversity of scene for the same semantic content in video always exists. Using dictionary learning in sparse representation can capture the latent relationship among the original diverse video semantic features. To enhance the discriminative ability of diverse video semantic features, the method of discriminative self-adapted locality-sensitive sparse representation for video semantic analysis is proposed. In the proposed method, a discriminative self-adaptive locality-sensitive dictionary learning method (DSALSDL) is designed. In DSALSDL, a self-adaptive local adapter is built to join in the process of dictionary learning for sparse representation, so as to obtain the potential information of the video data. Furthermore, in the self-adaptive locality-sensitive sparse representation, a discriminant loss function based on class-specific representation coefficients is imposed to further learn appropriate dictionary for video semantic analysis. Using the self-adaptive local adapter and discriminant loss function in dictionary learning, the sparse representation is exploited for video semantic concept detection. The proposed method is evaluated on the related video databases in comparison with existing relative sparse representation methods. Experimental results show that our method can improve the power of discrimination of video features and improve the accuracy of video semantic concept detection.
C1 [Liu, Junqi; Gou, Jianping; Zhan, Yongzhao; Mao, Qirong] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Liu, JQ (corresponding author), Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM ljq_ujs@163.com; goujianping@ujs.edu.cn; yzzhan@ujs.edu.cn;
   6662801@qq.com.cn
RI jin, li/IWU-4648-2023; Gou, Jianping/JQX-2453-2023
OI Gou, Jianping/0000-0003-1413-0693
FU National Natural Science Foundation of China [61672268, 61502208];
   Primary Research & Development Plan of Jiangsu Province of China
   [BE2015137]; Natural Science Foundation of Jiangsu Province of China
   [BK20150522]
FX This work was supported in part by National Natural Science Foundation
   of China (Grant Nos. 61672268, Grant Nos. 61502208), Primary Research &
   Development Plan of Jiangsu Province of China (Grant No. BE2015137) and
   Natural Science Foundation of Jiangsu Province of China (Grant No.
   BK20150522).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], WEAKLY SUPERVISED DE
   [Anonymous], TENCON 2005 IEEE REG
   [Anonymous], J JIANGSU U
   [Anonymous], COMPUT SCI
   [Anonymous], 2016, INT JOINT C ART INT
   [Anonymous], 2014, P INT C HUM CTR COMP
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x
   Khan HU, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P1, DOI 10.1109/ICE2T.2014.7006207
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Li HB, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P754, DOI 10.1109/ICIG.2009.101
   Li T., 2016, PROC IEEE INT C HIGH, P1
   Li T, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P333, DOI 10.1109/BigData.2015.7363773
   Li Z, 2017, IEEE T NEURAL NETW L, P1
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu WY, 2015, PATTERN RECOGN, V48, P3076, DOI 10.1016/j.patcog.2015.04.014
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Shan Dai, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P879, DOI 10.1109/GreenCom-iThings-CPSCom.2013.154
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Wang Bin, 2012, Robot, V34, P745, DOI 10.3724/SP.J.1218.2012.00745
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2012, NEUROCOMPUTING, V79, P125, DOI 10.1016/j.neucom.2011.10.013
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yi-Ding Wang, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P214, DOI 10.1109/ICWAPR.2011.6014480
   Zhan YZ, 2016, J VIS COMMUN IMAGE R, V41, P65, DOI 10.1016/j.jvcir.2016.09.006
   Zhang HC, 2013, PATTERN RECOGN, V46, P1511, DOI 10.1016/j.patcog.2012.10.025
NR 41
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29143
EP 29162
DI 10.1007/s11042-018-6090-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500058
DA 2024-07-18
ER

PT J
AU Ong, TS
   William, A
   Connie, T
   Goh, MKO
AF Ong, Thian Song
   William, Ardianto
   Connie, Tee
   Goh, Michael Kah Ong
TI Robust hybrid descriptors for multi-instance finger vein recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingervein recognition; Biometrics; Multi-instance recognition; Hybrid
   descriptors; Local Hybrid Binary Gradient Contour
ID EXTRACTION; DISTANCE; FUSION; SYSTEM
AB Finger vein recognition is a type of biometric technology that uses the vein pattern inside the human finger as a personal identifier. In this paper, Local Hybrid Binary Gradient Contour (LHBGC) and Hierarchical Local Binary Pattern (HLBP) are proposed as the texture descriptors for finger vein recognition to increase the discriminant capability of the finger vein texture. LHBGC extracts both sign and magnitude components of the finger vein image for recognition, while HLBP utilizes the LBP uniform texture pattern of the vein image without any training required. Furthermore, a multi-instance biometrics that fuses multiple evidences from an individual has also been proposed to address the problem of noisy data. Multi-instance biometrics is the most inexpensive way to obtain multiple biometric evidences from a biometric trait without multiple sensors and additional feature extraction algorithms. Experiments on several benchmark databases validate the efficiency of the proposed multi-instance approach. An equal error rate as low as 0.00002% is achieved using the combination of three fingers at score level fusion.
C1 [Ong, Thian Song; William, Ardianto; Connie, Tee; Goh, Michael Kah Ong] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
C3 Multimedia University
RP Connie, T (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM tsong@mmu.edu.my; william.ardianto@gmail.com; tee.connie@mmu.edu.my;
   michael.goh@mmu.edu.my
RI Ong, Thian Song/Q-6932-2018; Goh, Kah Ong Michael/F-8404-2012
OI Ong, Thian Song/0000-0002-5867-9517; Tee, Connie/0000-0002-0901-3831;
   Goh, Kah Ong Michael/0000-0002-9217-6390
FU MOSTI Science Fund Malaysia [01-02-01-SF0217]
FX Our thanks to the Group of Machine Learning and Applications, Shandong
   University and University Sains Malaysia for allowing us to use the
   SDUMLA-HMT and FV-USM Finger Vein Database they had collected. The
   project is supported in part by MOSTI Science Fund Malaysia
   (01-02-01-SF0217).
CR [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], 2012 IEEE COMP SOC C
   [Anonymous], 2006, Handbook of Multibiometrics
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   Beining Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1269, DOI 10.1109/ICPR.2010.316
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng YC, 2017, MULTIMED TOOLS APPL, V76, P11251, DOI 10.1007/s11042-016-3300-y
   Choi, 2009, FINGER VEIN EXTRACTI, DOI [10.1117/12.810458, DOI 10.1117/12.810458]
   Fernández A, 2011, OPT LASER ENG, V49, P1177, DOI 10.1016/j.optlaseng.2011.05.003
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   Guru DS, 2004, PATTERN RECOGN LETT, V25, P73, DOI 10.1016/j.patrec.2003.09.003
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Hsia C-H, 2017, MULTIMED TOOLS APPL, P1
   Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102
   장영균, 2008, [KIPS Transactions on Software and Data Engineering, 정보처리학회논문지. 소프트웨어 및 데이터 공학], V15, P275
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Lee EC, 2009, INT J IMAG SYST TECH, V19, P179, DOI 10.1002/ima.20193
   Lee HC, 2010, J ZHEJIANG U-SCI C, V11, P514, DOI 10.1631/jzus.C0910550
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Ong TS, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1730, DOI 10.1109/CISP.2013.6743955
   Rattani A, 2009, LECT NOTES COMPUT SC, V5558, P960, DOI 10.1007/978-3-642-01793-3_97
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Song W, 2011, PATTERN RECOGN LETT, V32, P1541, DOI 10.1016/j.patrec.2011.04.021
   Trabelsi RB, 2016, MULTIMED TOOLS APPL, V75, P687, DOI 10.1007/s11042-014-2315-5
   Uhl A, 2009, INT J BIOMETRICS, V1, P442, DOI 10.1504/IJBM.2009.027305
   Wang MW, 2017, MULTIMED TOOLS APPL, V76, P14937, DOI 10.1007/s11042-016-4285-2
   William A, 2015, ASIAPAC SIGN INFO PR, P1226, DOI 10.1109/APSIPA.2015.7415469
   Xi XM, 2013, SENSORS-BASEL, V13, P11243, DOI 10.3390/s130911243
   Yang GP, 2013, SENSORS-BASEL, V13, P12093, DOI 10.3390/s130912093
   Yang GP, 2012, SENSORS-BASEL, V12, P1738, DOI 10.3390/s120201738
   Yang Y, 2012, INT J DIGITAL CONTEN, V6, P86
   Yiding Wang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P367, DOI 10.1109/ICB.2012.6199778
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Yu CB, 2009, INTERDISCIP SCI, V1, P280, DOI 10.1007/s12539-009-0046-5
NR 39
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29163
EP 29191
DI 10.1007/s11042-018-6077-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500059
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Zhuang, ZH
   Zhou, JL
   Wang, XJ
   Xu, WH
AF Zhu, Haijiang
   Zhuang, Zhanhong
   Zhou, Jinglin
   Wang, Xuejing
   Xu, Wenhua
TI Improved graph-cut segmentation for ultrasound liver cyst image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound liver cyst segmentation; Graph-based method; PSO
ID NEURAL-NETWORK; LOCATION
AB An optimal contour segmentation for ultrasonic liver cyst image is presented through combining graph-based method with particle swarm optimization (PSO) in this paper. After automatic selecting the region of interest (ROI) for ultrasonic liver cyst image, our method developed firstly a kind of multiple classes merging scheme by jointing the graph-based segmented result with the intensity of original ultrasound image. Then the evaluation function in the PSO was modified to optimize the parameter. Finally, the liver cysts were segmented according to the optimized parameter. In the experiment, we tested the influence of weight value on the improved method. And five indicators, which included Hausdorff distance (HD), mean absolute distance (MD), true positive volume fraction (TPVF), false-negative volume fraction (FNVF) and false-positive volume fraction (FPVF), were estimated to verify the improved method. Experimental results have validated that the improved method may extract successfully and accurately the contour of liver cyst.
C1 [Zhu, Haijiang; Zhuang, Zhanhong; Zhou, Jinglin] Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
   [Wang, Xuejing] Beijing Univ Chem Technol, Informat Ctr, Beijing 100029, Peoples R China.
   [Xu, Wenhua] Guangdong Pharmaceut Univ, Coll Med Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Beijing University of Chemical Technology; Beijing University of
   Chemical Technology; Guangdong Pharmaceutical University
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
EM zhuhj@mail.buct.edu.cn
OI Zhu, Haijiang/0000-0002-0609-3610
FU National Natural Science Foundation of China [61672084, 61473025]; State
   Key Laboratory of Synthetical Automation for Process Industry at the
   Northeastern University in China
FX This work was supported in part by the National Natural Science
   Foundation of China under grant No. 61672084 and No. 61473025 and the
   open-project grant funded by the State Key Laboratory of Synthetical
   Automation for Process Industry at the Northeastern University in China.
   We also thank the reviewers' comments for this manuscript and Mr.
   Tengfei Yang, who participated in technical editing of the manuscript.
CR Abdolali F, 2016, COMPUT BIOL MED, V72, P108, DOI 10.1016/j.compbiomed.2016.03.014
   [Anonymous], ARXIV170603372
   Bernier M, 2017, COMPUT MED IMAG GRAP, V58, P1, DOI 10.1016/j.compmedimag.2017.03.004
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y., 2001, International Conference on Computer Vision, V1, P105, DOI DOI 10.1109/ICCV.2001.937505
   Ciurte A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100972
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Huang QH, 2012, ULTRASONICS, V52, P266, DOI 10.1016/j.ultras.2011.08.011
   Huang QH, 2014, NEUROCOMPUTING, V129, P216, DOI 10.1016/j.neucom.2013.09.038
   Ju W, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2488902
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kiruthika V, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P137, DOI 10.1109/ICSIP.2014.27
   Kuo JW, 2017, IEEE T ULTRASON FERR, V64, P1514, DOI 10.1109/TUFFC.2017.2737948
   Lee WL, 2005, INFORM SCIENCES, V175, P177, DOI 10.1016/j.ins.2005.01.007
   Li YG, 2012, CHIN CONTR CONF, P4006
   Lu F, 2017, INT J COMPUT ASS RAD, V12, P171, DOI 10.1007/s11548-016-1467-3
   Mukherjee S, 2017, I S BIOMED IMAGING, P1205, DOI 10.1109/ISBI.2017.7950733
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Öziç MÜ, 2014, SIG PROCESS COMMUN, P1999, DOI 10.1109/SIU.2014.6830650
   Saito A, 2017, INT J COMPUT ASS RAD, V12, P743, DOI 10.1007/s11548-017-1571-z
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Torbati N, 2014, COMPUT BIOL MED, V44, P76, DOI 10.1016/j.compbiomed.2013.10.029
   Zhang Q., 2012, International Conference on Information Science and Control Engineering, P1, DOI DOI 10.1049/CP.2012.2294
   Zhu HJ, 2017, MULTIMED TOOLS APPL, V76, P8951, DOI 10.1007/s11042-016-3486-z
   Zhu HJ, 2016, MULTIMED TOOLS APPL, V75, P10979, DOI 10.1007/s11042-015-2822-z
NR 27
TC 3
Z9 3
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28905
EP 28923
DI 10.1007/s11042-018-6076-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500047
DA 2024-07-18
ER

PT J
AU Al-Afandy, KA
   El-Shafai, W
   El-Rabaie, ESM
   Abd El-Samie, FE
   Faragallah, OS
   El-Mhalaway, A
   Shehata, AM
   El-Banby, GM
   El-Halawany, MM
AF Al-Afandy, Khalid A.
   El-Shafai, Walid
   El-Rabaie, El-Sayed M.
   Abd El-Samie, Fathi E.
   Faragallah, Osama S.
   El-Mhalaway, Ahmed
   Shehata, Ahmed M.
   El-Banby, Ghada M.
   El-Halawany, Mohamed M.
TI Robust hybrid watermarking techniques for different color imaging
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Homomorphic transform; SVD; DWT; DSWT; DCT; Color
   imaging systems
ID WAVELET TRANSFORM; DWT-SVD; ADABOOST; DCT
AB Digital watermarking is an efficient and promising mechanism for protecting the copyright of the transmitted multimedia information. Thus, this paper presents two robust hybrid color image watermarking techniques. The objective of the proposed watermarking techniques is to increase the immunity of the watermarked color images against attacks and to achieve adequate perceptual quality. The first proposed hybrid technique is the homomorphic transform based Singular Value Decomposition (SVD) in Discrete Wavelet Transform (DWT) domain. Firstly, the DWT is employed to divide an image into non-overlapping bands. Then, the reflectance components of the LL sub-bands are extracted using the homomorphic transform of each of the RGB (Red, Green, and Blue) color image components. After that, the watermark is embedded by applying the SVD on these reflectance components. The second proposed hybrid technique is the three-level Discrete Stationary Wavelet Transform (DSWT) in Discrete Cosine Transform (DCT) domain. In this technique, the RGB components of the host color image are separated, and then the DCT is applied on each separated color component. The three-level DSWT is employed to divide the DCT components into four sub-bands. These sub-bands are the A, H, V, and D matrices, which have the same host image size. The watermark image is then embedded into the determined matrix A. The two proposed hybrid watermarking techniques are compared with the current state-of-the-art techniques. This paper also presents a comparative study of the proposed techniques for different color imaging systems to determine their robustness and stability. The comparisons are based on the subjective visual results to detect any degradation in the watermarked image in addition to the objective results of the Peak Signal-to-Noise Ratio (PSNR) of the watermarked image, and the Normalized Correlation (NC) of the extracted watermark to test and evaluate the performance efficiency of the proposed watermarking techniques. Extensive experimental results show that the proposed hybrid watermarking techniques are both robust and have adequate immunity against different types of attacks compared to the traditional watermarking techniques. They achieve not only very good perceptual quality with appreciated PSNR values, but also high correlation coefficient values in the presence of different multimedia attacks.
C1 [Al-Afandy, Khalid A.; Faragallah, Osama S.; El-Mhalaway, Ahmed; Shehata, Ahmed M.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Shafai, Walid; El-Rabaie, El-Sayed M.; Abd El-Samie, Fathi E.; El-Halawany, Mohamed M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [El-Banby, Ghada M.] Menoufia Univ, Fac Elect Engn, Dept Ind Elect & Control Engn, Menoufia, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Menofia
   University; Taif University
RP Al-Afandy, KA (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
EM khalid_yuosif@yahoo.com; eng.waled.elshafai@gmail.com;
   elsayedelrabaie@gmail.com; fathi_sayed@yahoo.com; osam_sal@yahoo.com;
   ahmed.elmahalawy@el-eng.menofia.edu.eg; dr.ashehata@ymail.com;
   ghada.elbanby@el-eng.menofia.edu.eg; mmohamedelhalawany@gmail.com
RI AlAfandy, Khalid A./AAI-8104-2020; Faragallah, Osama S./AHB-8031-2022;
   El-Shafai, Walid/AAG-4796-2021; Sayed, Fathi/HRA-4752-2023; Elmahalawy,
   Ahmed Moustafa/AAB-9802-2022
OI AlAfandy, Khalid A./0000-0003-1465-4446; Faragallah, Osama
   S./0000-0003-1982-335X; El-Shafai, Walid/0000-0001-7509-2120; Sayed,
   Fathi/0000-0001-8749-9518; Elmahalawy, Ahmed
   Moustafa/0000-0001-5739-8628; EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR [Anonymous], COLOR IMAGE WATERMAR
   [Anonymous], SPRINGER INDIA
   [Anonymous], CONTROL COLOR IMAGIN
   [Anonymous], LECT NOTES ELECT ENG
   [Anonymous], ADV MAT SCI ENG
   [Anonymous], LECT NOTES ELECT ENG
   [Anonymous], ADV INTELLIGENT INFO
   [Anonymous], DIGITAL FORENSICS WA
   [Anonymous], 2015, INT S SMART GRAPH
   [Anonymous], 2014, P 2014 ANN IEEE IND
   [Anonymous], COMPUT ENG SCI
   [Anonymous], THESIS
   [Anonymous], 2008, COLOR ORDERED SURVEY
   [Anonymous], SOFT COMPUT
   [Anonymous], COMPUTER NETWORKS IN
   [Anonymous], IMAGE PROCESSING GIS
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Chauhan S, 2017, MULTIMED TOOLS APPL, P1
   Gonge SS, 2015, COMM COM INF SC, V536, P290, DOI 10.1007/978-3-319-22915-7_28
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Huang HN, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0073-6
   Ibraheem N.A., 2012, ARPN J. Sci. Technol., V2, P265
   Islam MS, 2015, COMPUT SCI APPL, V330, P7
   Joshi AM, 2017, ADV INTELL SYST, V468, P455, DOI 10.1007/978-981-10-1675-2_45
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Thirunavukkarasu V, 2018, WIRELESS PERS COMMUN, V98, P3039, DOI 10.1007/s11277-016-3941-1
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 43
TC 36
Z9 36
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25709
EP 25759
DI 10.1007/s11042-018-5814-y
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400048
DA 2024-07-18
ER

PT J
AU Benouini, R
   Batioua, I
   Zenkouar, K
   Najah, S
   Qjidaa, H
AF Benouini, Rachid
   Batioua, Imad
   Zenkouar, Khalid
   Najah, Said
   Qjidaa, Hassan
TI Efficient 3D object classification by using direct Krawtchouk moment
   invariants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moment invariants; Krawtchouk moments; Direct method; Indirect method;
   3D object classification; Numerical stability
ID PSEUDO-ZERNIKE MOMENTS; IMAGE-ANALYSIS; SCALE INVARIANTS;
   PATTERN-RECOGNITION; FAST COMPUTATION; TRANSLATION; ROTATION; BLUR
AB In this paper, we present an efficient set of moment invariants, named Direct Krawtchouk Moment Invariants (DKMI), for 3D objects recognition. This new set of invariants can be directly derived from the Krawtchouk moments, based on algebraic properties of Krawtchouk polynomials. The proposed computation approach is effectively compared with the classical method, which rely on the indirect computation of moment invariants by using the corresponding geometric moment invariants. Several experiments are carried out so as to evaluate the performance of the newly introduced invariants. Invariability property and noise robustness are firstly investigated. Secondly, the numerical stability is discussed. Then, the performance of the proposed moment invariants as pattern features for 3D object classification is compared with the existing Geometric, Krawtchouk, Tchebichef and Hahn Moment Invariants. Finally, a comparative analysis of computational time of these moment invariants is illustrated. The obtained results demonstrate the efficiency and the superiority of the proposed method.
C1 [Benouini, Rachid; Batioua, Imad; Zenkouar, Khalid; Najah, Said] Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
   [Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar el Mehraz, LESSI, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Benouini, R (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
EM rachid.benouini@usmba.ac.ma; imad.batioua@usmba.ac.ma;
   khalid.zenkouar@usmba.ac.ma; said.najah@usmba.ac.ma;
   hassan.qjidaa@usmba.ac.ma
RI Benouini, Rachid/R-6803-2019; najah, said/ABB-8982-2021; Benouini,
   Rachid/ABE-3754-2021
OI Benouini, Rachid/0000-0001-8586-5289; Hassan, qjidaa/0000-0003-4505-5243
FU Laboratory of Intelligent Systems and Applications (LSIA)
FX The authors thankfully acknowledge the Laboratory of Intelligent Systems
   and Applications (LSIA) for his support to achieve this work.
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Ananth J., 2012, FACE IMAGE RETRIEVAL
   [Anonymous], 2016, P 25 INT JOINT C ART
   Anuar FM, 2013, EXPERT SYST APPL, V40, P105, DOI 10.1016/j.eswa.2012.07.031
   BATIOUA I, 2017, 3D IMAGE ANAL SEPARA
   Batioua I, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0172-7
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Bharathi VS, 2008, PATTERN RECOGN LETT, V29, P1868, DOI 10.1016/j.patrec.2008.06.003
   Camacho-Bello C, 2014, J OPT SOC AM A, V31, P124, DOI 10.1364/JOSAA.31.000124
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Comtet, 2012, ADV COMBINATORICS AR
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai XB, 2010, PATTERN RECOGN, V43, P1152, DOI 10.1016/j.patcog.2009.07.009
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Goh HA, 2009, INT J IMAGE GRAPH, V9, P271, DOI 10.1142/S0219467809003435
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Krawtchouk M., 1929, Memoirs Agricultural Inst. Kyiv, V4, P21
   Lan X, 2017, 31 AAAI C ART INT
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Liang LM, 2018, OPT LASER ENG, V100, P141, DOI 10.1016/j.optlaseng.2017.08.005
   Liao S, 2002, INT C PATT RECOG, P485, DOI 10.1109/ICPR.2002.1047982
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Liu Y, 2015, 24 INT JOINT C ART I
   Liu Y, 2016, 13 AAAI C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 2005, TENCON 2005 2005 IEE, P1
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Ong L-Y, 2006, SCALE INVARIANTS 3 D, P1, DOI DOI 10.1109/TENCON.2006.344160
   Palaniappan R, 2000, PATTERN ANAL APPL, V3, P78, DOI 10.1007/s100440070014
   Pandey VK, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P255, DOI 10.1109/SPIN.2016.7566699
   Ping ZL, 2002, J OPT SOC AM A, V19, P1748, DOI 10.1364/JOSAA.19.001748
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Singh C, 2014, DIGIT SIGNAL PROCESS, V27, P95, DOI 10.1016/j.dsp.2013.12.004
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Singh C, 2012, OPT LASER TECHNOL, V44, P2249, DOI 10.1016/j.optlastec.2012.02.030
   Singh C, 2012, OPT LASER ENG, V50, P655, DOI 10.1016/j.optlaseng.2011.11.012
   Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0
   Suk T, 2015, PATTERN RECOGN, V48, P3516, DOI 10.1016/j.patcog.2015.05.007
   Tchebychev P., 1853, Theorie des mecanismes connus sous le nom de parallelogrammes
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Venkataramana A., 2007, 2007 6 INT C INFOR M, P1
   Wei MQ, 2018, OPT LASER ENG, V103, P110, DOI 10.1016/j.optlaseng.2017.11.014
   Wu H, 2013, MATH PROBL ENG, V2013
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhang L, 2007, CHIN OPT LETT, V5, P21
   Zhang YI, 2002, PATTERN RECOGN, V35, P211, DOI 10.1016/S0031-3203(01)00018-8
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 67
TC 14
Z9 14
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27517
EP 27542
DI 10.1007/s11042-018-5937-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500058
DA 2024-07-18
ER

PT J
AU Dhassi, Y
   Aarab, A
AF Dhassi, Younes
   Aarab, Abdellah
TI Visual tracking based on adaptive interacting multiple model particle
   filter by fusing multiples cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Particle filter; Interactive multiple model; Gaussien
   mixture model; Expectation maximization
ID OBJECT TRACKING
AB In visual tracking topic, developing a robust tracking method is very challenging, seen that there are many issues to look at, particularly, fast motion, target appearance changing, background clutter and camera motion. To override these problems, we present a new object tracking method with the fusion of interacting multiple models (IMM) and the particle filter (PF). First, the IMM is applied with a bank of parallel Ha filter to estimate the global motion, the target motion is efficiently represented using only two parametric single models, and an adaptive strategy is preformed to adjust automatically the parameters of the two sub models at each recursive time step. Second, the particle filter is performed to estimate the local motion, we fuse the color and texture features to describe the appearance of the tracked object, we use the alpha Gaussian mixture model (alpha-GMM) to model the color feature distribution, the parameter alpha allows the probability function to possesses a flatter distribution, and the texture feature is represented by the distinctive uniform local binary pattern histogram (DULBP) based on the uniform local binary pattern (ULBP) operator; we fuse then the two features to represent the target's appearance under the particle filter framework. We conduct quantitative and qualitative experiments on a variety of challenging public sequences; the results show that our method performs robustly and demonstrates strong accuracy.
C1 [Dhassi, Younes; Aarab, Abdellah] Sidi Mohamed Ben Abdellah Univ, Lab Elect Signals Syst & Comp, Fac Sci Dhar Mahraz, Dept Phys, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Dhassi, Y (corresponding author), Sidi Mohamed Ben Abdellah Univ, Lab Elect Signals Syst & Comp, Fac Sci Dhar Mahraz, Dept Phys, Fes, Morocco.
EM dyounes2003@gmail.com
RI DHASSI, Younes/JLM-7247-2023
CR Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Aristidou A, 2013, VISUAL COMPUT, V29, P7, DOI 10.1007/s00371-011-0671-y
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bhimani J, 2017, CLOUD COMP CLOUD 201
   Bhimani J, 2017, HIGH PERFORMANCE EXT
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Cui J, 2013, IEEE T SYST MAN CYBE, V43
   Dhassi Y, 2017, INT J IMAGING ROBOT, V17
   Dou JF, 2014, NEUROCOMPUTING, V135, P118, DOI 10.1016/j.neucom.2013.12.049
   Fan ZH, 2015, SIGNAL PROCESS-IMAGE, V36, P140, DOI 10.1016/j.image.2015.07.001
   Frank L.X. P., 2007, Optimal and Robust Estimation with an Introduction to Schotastic Control Theory
   Hu L, 2015, LECT NOTES ELECTR EN, V336, P431, DOI 10.1007/978-3-662-46469-4_46
   Karasulu B, 2011, MULTIMED TOOLS APPL, V55, P677, DOI 10.1007/s11042-010-0591-2
   Karavasilis V, 2015, COMPUT VIS IMAGE UND, V140, P43, DOI 10.1016/j.cviu.2015.07.003
   Kristan M., 2008, THESIS
   Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6
   Li X. R., 2004, IEEE T AERO ELEC SYS, V39, P1333
   Liu B, 2012, PROC INT CONF ANTI
   Liu L, 2016, 2016 30 NAT C ART IN
   Liu Y, 2016, 2015 24 INT C ART IN
   Liu Y, 2010, 16 INT C VIRT SYST M
   Liu Z, 2016, SIGNAL IMAGE VIDEO P, V10, P359, DOI 10.1007/s11760-015-0749-5
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Roemer J, 2015, 2014 I 11 INT C MOB
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   SUN W, 2014, J COMPUT INF SYST, V10, P681
   Sun X, 2014, SIGNAL IMAGE VIDEO P, V8, pS95, DOI 10.1007/s11760-014-0674-z
   Tamrakar D, 2015, PROCEDIA COMPUT SCI, V54, P491, DOI 10.1016/j.procs.2015.06.056
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Wang J, 2016, PERF COMP COMM C IPC
   Wang T, 2017, COMP COMM NETW ICCN
   Wang XY, 2014, SIGNAL IMAGE VIDEO P, V8, P1059, DOI 10.1007/s11760-014-0628-5
   Wu DL, 2009, NEURAL COMPUT, V21, P1776, DOI 10.1162/neco.2008.04-08-776
   Wu SG, 2005, PATTERN RECOGN, V38, P2143, DOI 10.1016/j.patcog.2005.01.020
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yang Z, 2017, CLOUD COMP TECHN SCI
   Yang Z, 2016, PERF COMP COMM C IPC
   Yin S, 2011, COMPUT VIS IMAGE UND, V115, P885, DOI 10.1016/j.cviu.2011.02.010
   Yu W, 2014, SIGNAL IMAGE VIDEO P, V8, pS155, DOI 10.1007/s11760-014-0652-5
   Zhao ZQ, 2017, MULTIMED TOOLS APPL, V76, P835, DOI 10.1007/s11042-015-3075-6
   Zhou ZY, 2016, OPTIK, V127, P613, DOI 10.1016/j.ijleo.2015.10.038
   Zhu HY, 2016, CHINESE J ELECTRON, V25, P270, DOI 10.1049/cje.2016.03.012
NR 48
TC 7
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26259
EP 26292
DI 10.1007/s11042-018-5852-5
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500005
DA 2024-07-18
ER

PT J
AU Wang, ZB
   Xu, GL
   Cheng, YH
   Guo, RP
   Wang, ZS
AF Wang, Zhengbing
   Xu, Guili
   Cheng, Yuehua
   Guo, Ruipeng
   Wang, Zhengsheng
TI A curvature salience descriptor for full and partial shape matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Corner points; Curvature; Shape representation; Shape matching
ID ANISOTROPIC DIFFUSION; OBJECT DETECTION; SCALE-SPACE; AREA V4;
   RECOGNITION; REPRESENTATION; RETRIEVAL; CONTEXTS; CONTOUR; IMAGES
AB Shape representation and matching is one of the fundamental problems in compute vision. In this paper, we propose a novel shape contour descriptor, called curvature salience descriptor (CSD), for full shape matching. The presented descriptor utilizes only the most representative information to globally describe shape contour and is invariant to translation, rotation, scaling and partial occlusion of shapes. Shape matching is performed using the Dynamic Time Warping (DTW) to establish the point-to-point correspondence. To the solution of partial shape matching, we slightly modify the descriptor and develop a new matching framework that can establish the correspondence between the open query and candidate from coarse to fine. Different from previous methods, a coarse matching process is implemented to fast reject the false candidates before we establish the point-to-point correspondence. We conduct the experiments on the public datasets but also in the context of some specific applications and the results demonstrate that the proposed technique can achieve favorable performance compared to the existing methods.
C1 [Wang, Zhengbing; Xu, Guili; Guo, Ruipeng] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210000, Jiangsu, Peoples R China.
   [Cheng, Yuehua] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210000, Jiangsu, Peoples R China.
   [Wang, Zhengsheng] Nanjing Univ Aeronaut & Astronaut, Coll Sci, Nanjing 210000, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics; Nanjing University of Aeronautics &
   Astronautics
RP Xu, GL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210000, Jiangsu, Peoples R China.
EM wangzhengbing248@sina.com; guilixu@nuaa.edu.cn; chengyuehua@nuaa.edu.cn;
   rpguo@nuaa.edu.cn; wangzhengsheng@nuaa.edu.cn
RI Wang, Zheng Bing/E-8043-2011
FU National Natural Science Foundation of China [61473148, 51505220];
   Funding of Jiangsu Innovation Program for Graduate Education
   [KYLX16-0337]
FX This project is supported by the National Natural Science Foundation of
   China (61473148,51505220) and the Funding of Jiangsu Innovation Program
   for Graduate Education (KYLX16-0337).
CR Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Birk H, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P261
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Bouagar S, 2016, MULTIMED TOOLS APPL, V75, P2989, DOI 10.1007/s11042-014-2417-0
   Chen LQ, 2008, LECT NOTES COMPUT SC, V5209, P1, DOI 10.1007/978-3-540-85538-5_1
   Cui M, 2009, PATTERN RECOGN LETT, V30, P1, DOI 10.1016/j.patrec.2008.08.013
   Cui M, 2007, VISUAL COMPUT, V23, P607, DOI 10.1007/s00371-007-0164-1
   Fan HJ, 2015, MACH VISION APPL, V26, P711, DOI 10.1007/s00138-015-0693-y
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu RX, 2012, PATTERN RECOGN, V45, P3222, DOI 10.1016/j.patcog.2012.02.020
   Laiche N, 2017, MULTIMED TOOLS APPL, V5, P1
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Ma TY, 2011, PROC CVPR IEEE, P1441, DOI 10.1109/CVPR.2011.5995591
   Michel D, 2011, IMAGE VISION COMPUT, V29, P459, DOI 10.1016/j.imavis.2011.01.008
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Niu D, 2016, VISUAL COMPUT, P1
   Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505, DOI 10.1152/jn.2001.86.5.2505
   Pasupathy A, 2002, NAT NEUROSCI, V5, P1332, DOI 10.1038/nn972
   Pedrosa GV, 2013, NEUROCOMPUTING, V120, P156, DOI 10.1016/j.neucom.2012.07.055
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Premachandran V, 2013, PATTERN RECOGN, V46, P2092, DOI 10.1016/j.patcog.2013.01.030
   Saber E, 2005, PATTERN RECOGN, V38, P1560, DOI 10.1016/j.patcog.2005.03.027
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007
   WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108
   Wolter D, 2004, LECT NOTES ARTIF INT, V3157, P693
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Xu GL, 2014, CHINESE J AERONAUT, V27, P102, DOI 10.1016/j.cja.2013.12.001
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 44
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27405
EP 27426
DI 10.1007/s11042-018-5929-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500052
DA 2024-07-18
ER

PT J
AU Chai, CL
   Liao, J
   Zou, N
   Sun, LY
AF Chai, Chunlei
   Liao, Jing
   Zou, Ning
   Sun, Lingyun
TI A one-to-many conditional generative adversarial network framework for
   multiple image-to-image translations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-to-image translation; Generative adversarial network; One-to-many
   conditional generative adversarial network; Deep learning
ID INFORMATION
AB Image-to-Image translation was proposed as a general form of many image learning problems. While generative adversarial networks were successfully applied on many image-to-image translations, many models were limited to specific translation tasks and were difficult to satisfy practical needs. In this work, we introduce a One-to-Many conditional generative adversarial network, which could learn from heterogeneous sources of images. This is achieved by training multiple generators against a discriminator in synthesized learning way. This framework supports generative models to generate images in each source, so output images follow corresponding target patterns. Two implementations, hybrid fake and cascading learning, of the synthesized adversarial training scheme are also proposed, and experimented on two benchmark datasets, UTZap50K and MVOD5K, as well as a new high-quality dataset BehTex7K. We consider five challenging image-to-image translation tasks: edges-to-photo, edges-to-similar-photo translation on UTZap50K, cross-view translation on MVOD5K, and grey-to-color, grey-to-Oil-Paint on BehTex7K. We show that both implementations are able to faithfully translate from an image to another image in edges-to-photo, edges-to-similar-photo, grey-to-color, and grey-to-Oil-Paint translation tasks. The quality of output images in cross-view translation need to be further boosted.
C1 [Chai, Chunlei; Liao, Jing; Zou, Ning; Sun, Lingyun] Zhejiang Univ, Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Zou, N (corresponding author), Zhejiang Univ, Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM dishengchai@126.com; jingl@zju.edu.cn; zouning@zju.edu.cn;
   sunly@zju.edu.cn
OI Liao, Jing/0000-0002-2948-5043; LIAO, Jing/0000-0001-7014-5377
FU National Natural Science Foundation of China [61303137]; National
   Science and Technology Support Program [2015BAH21F01]; Art Project for
   National Social-Science Foundation [15BG084]
FX This paper is supported by the National Natural Science Foundation of
   China (61303137), the National Science and Technology Support Program
   (2015BAH21F01) and the Art Project for National Social-Science
   Foundation (15BG084). We thank Dr. Preben Hansen from Stockholm
   University, Department of Computer Science, for assistance in
   proofreading and technical editing of the manuscript.
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], ARXIV161102019
   [Anonymous], MULTIMEDIA ANSWERING
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Calisir F, 2017, MULTIMED TOOLS APPL, V76, P12433, DOI 10.1007/s11042-016-3659-9
   Elgammal A., 2017, ARXIV170607068
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Ghosh A, 2017, ARXIV160607536
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jacob VG, 2009, IEEE IMAGE PROC, P1653, DOI 10.1109/ICIP.2009.5413392
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu M.Y., 2016, Coupled generative adversarial networks
   Liu Y., 2017, ARXIV170501908
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P109, DOI 10.1145/3123266.3123436
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Perarnau G, 2016, C WORKSH NEUR INF PR
   Salimans T, 2016, ADV NEUR IN, V29
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Vukotic V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P421, DOI 10.1145/3078971.3079038
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang X, 2016, ARXIV EPRINT ARXIV 1
   Wang Y, 2016, ARXIV EPRINT ARXIV 1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 37
TC 11
Z9 13
U1 1
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22339
EP 22366
DI 10.1007/s11042-018-5968-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500033
DA 2024-07-18
ER

PT J
AU Luo, YH
   Yin, D
   Wang, A
   Wu, WT
AF Luo, Yuhao
   Yin, Dong
   Wang, An
   Wu, Wentao
TI Pedestrian tracking in surveillance video based on modified CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian tracking; Surveillance video; Convolutional neural network;
   Siamese network
ID PARALLEL FRAMEWORK; CONTEXT
AB With the prevalence of surveillance video, surveillance data can be used in a wide variety of applications where moving object detection, object recognition and pedestrian tracking has become a significant field of research. Especially for pedestrian tracking, it has become an urgent problem to be solved. This paper proposes a novel method based on convolutional neural network called Matching-Siamese network for pedestrian tracking. First, the pedestrians are detected from surveillance videos through Faster-R-CNN and are numbered sequentially. Second, Matching-Siamese network is designed by modifying the structure of the traditional Siamese network to calculate the similarity of two input images. Third, using the image similarity determines whether the probe image of the target pedestrian and each pedestrian images are of the same identity or not. Finally, we track the target pedestrian in all videos by using the identity of probe image and pedestrian images. The results in this paper show that the proposed method outperforms most popular algorithms in terms of accuracy, overlap rate and computational efficiency, especially in the circumstances of object disappearing and reappearing. In addition, our method could use a latest probe pedestrian image to accomplish its tracking in videos ranging from randomly selected time and regions well.
C1 [Luo, Yuhao; Yin, Dong; Wang, An; Wu, Wentao] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Luo, Yuhao; Yin, Dong] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences
RP Yin, D (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.; Yin, D (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM lyhbo11@mail.ustc.edu.cn; yindong@ustc.edu.cn; anwang@ustc.edu.cn;
   wwt@ustc.edu.cn
FU Anhui Science and Technology Department project [1401b042001]; Security
   and Campus Management of USTC
FX This work is supported by Anhui Science and Technology Department
   project (No. 1401b042001) and Security and Campus Management of USTC.
CR An JW, 2011, COMM COM INF SC, V215, P81
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], 2016, EUR C COMP VIS
   Araujo A, 2017, IEEE T CIRCUITS SYST
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bontar J., 2015, J MACHINE LEARNING R, V17, P2287
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Feng P, 2017, NEUROCOMPUTING, V225, P92, DOI 10.1016/j.neucom.2016.11.009
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Oliva N, 2017, INT EL DEVICES MEET
   Rehman A, 2013, SIGNAL PROCESS-IMAGE, V28, P984, DOI 10.1016/j.image.2012.07.004
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen XW, 2016, PATTERN RECOGN, V53, P163, DOI 10.1016/j.patcog.2015.11.017
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Weng L, 2011, IFIP INT C COMM MULT
   Xu CY, 2016, IEEE T CIRC SYST VID, V26, P2273, DOI 10.1109/TCSVT.2015.2477937
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang T, 2017, MULTIMED TOOLS APPL, V76, P11021, DOI 10.1007/s11042-016-3461-8
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhong BN, 2015, NEUROCOMPUTING, V151, P710, DOI 10.1016/j.neucom.2014.06.083
   Zhu L, 2016, MED PHYS, V43, P3461, DOI 10.1118/1.4956134
NR 29
TC 15
Z9 18
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24041
EP 24058
DI 10.1007/s11042-018-5728-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900041
DA 2024-07-18
ER

PT J
AU Murugan, AS
   Devi, KS
   Sivaranjani, A
   Srinivasan, P
AF Murugan, A. Senthil
   Devi, K. Suganya
   Sivaranjani, A.
   Srinivasan, P.
TI A study on various methods used for video summarization and moving
   object detection for video surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Video summarization; Moving object detection;
   Security system; Tracking background subtraction; Frame differencing;
   Optical flow
ID SEGMENTATION
AB With the advancement in digital video technology, video surveillance has been playing its vital role for ensuring safety and security. The surveillance systems are deployed in wide range of applications to invigilate stuffs and to analyse the activities in the environment. From the single or multi surveillance camera, a huge amount of data is generated, stored and processed for security purpose. Due to time constraints, it is a very tedious process for an analyst to go through the full content. This limitation has been overcome by the use of video summarization. The video summarization is intended to afford comprehensible analysis of video by removing duplications and extracting key frames from the video. To make an easily interpreted outline, the various available video summarization methods will try to shot the summary of the main occurrences, scenes, or objects in a frame. Depending on the applications, it is required to summarize the happenings in the scene and detect the objects (static/dynamic) which is recorded in the video. Hence this paper provides the various methods used for video summarization and a comparative study of different techniques. It also presents different object detection, object classification and object tracking algorithms available in the literature.
C1 [Murugan, A. Senthil; Devi, K. Suganya; Sivaranjani, A.] Univ Coll Engn, Dept CSE, Panruti, India.
   [Srinivasan, P.] Univ Coll Engn, Dept Phys, Panruti, India.
RP Devi, KS (corresponding author), Univ Coll Engn, Dept CSE, Panruti, India.
EM viha.senthil@gmail.com; ssuganya.ucep@gmail.com;
   siv.ranjani2000@gmail.com; sril35@gmail.com
RI K, Suganya Devi/GLS-5627-2022; SIVARANJANI, A/KFA-0052-2024; k, suganya
   devi/AAD-6872-2021; Padmanabhan, Srinivasan/A-1803-2017
OI SIVARANJANI, A/0000-0002-7847-4025; Padmanabhan,
   Srinivasan/0000-0002-7473-0976; K, Suganya Devi/0000-0003-3945-8601
CR Adesh H, 2015, INT J COMPUT APPL IN, P1
   Ajmal M., 2012, Video Summarization Techniques and Classification, P1
   [Anonymous], FRAME DIFFERENCE KAL
   [Anonymous], INT J INF THEORY
   [Anonymous], 2010, J AERONAUTICS SPACE
   [Anonymous], 2014, Int. J. Comput. Applic., DOI DOI 10.5120/17828-8647
   Aslani S., 2013, INT J EL COMP ENG SY, V7, P1252
   Baohan X, 2016, P IEEE MULT, P1
   Chandrika K, 2005, BACKGROUND SUBTRACTI, P1
   Chinh D, 2014, IEEE T IMAGE PROCESS, V11982, P1
   Chung Yi-Nung, 2015, J IMAGE GRAPHICS, V3, P20, DOI [10.18178/joig.3.1.20-24, DOI 10.18178/JOIG.3.1.20-24]
   Congcong L, 2009, MOTION FOCUSING KEY, P4329
   Correia PL, 2003, IEEE T IMAGE PROCESS, V12, P186, DOI 10.1109/TIP.2002.807355
   Elkhattabi Z., 2015, International Journal of Computer and Information Engineering, V9, P928
   Fang-Lue Z, 2016, ACM T GRAPHIC, V35
   Gupta P., 2014, 3 INT C SYST MOD ADV, P151
   Huang H, 2014, IEEE J EM SEL TOP C, V4, P142, DOI 10.1109/JETCAS.2014.2298279
   Joshi K. A., 2012, INT J SOFT COMPUT EN, V2, P44
   Kansagara R, 2014, INT J INNOV RES COMP, V2, P2962
   Khan YS, 2015, INT J ADV COMPUT SC, V6, P256
   Klaus S, 2015, ACM COMPUT SURV, V48
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Kulchandani JS, 2015, IEEE, V22, P747
   Lin-Xie T, 2009, NEAR LOSSLESS VIDEO, P351
   Lu S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1959, DOI 10.1109/ICME.2004.1394645
   Mahesh CP, 2014, INT J EMERGING TREND, V3, P215
   Malmurugan N, 2014, ENG APLL ARTIF INTEL, V28, P210
   Matthieu C, 2008, COMPUTER GRAPHICS IM
   Mei H, 2004, MDA90402C0406
   Mumtaz A, 2014, PROC CVPR IEEE, P368, DOI 10.1109/CVPR.2014.54
   Nancy Emymal S, 2013, INT J COMPUT APPL EN, V3, P37
   Napoletano P, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431438
   Neha G, 2016, IEEE INT C POW EL IN, P1
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Pathan I., 2015, INT J COMPUT SCI INF, V6, P5212
   Paygude SS, 2013, VEHICLE DETECTION TR, P741
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Peter O, 2013, IEEE T PATTERN ANAL, P1
   Prajapati D., 2015, Int. J. Comput. Appl, V5, P168
   Rodríguez-Canosa GR, 2012, REMOTE SENS-BASEL, V4, P1090, DOI 10.3390/rs4041090
   Roshani KD, 2016, J INF KNOWL RES COMP, P769
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P5, DOI 10.1007/978-3-319-07386-6_2
   Srinivasan P, 2015, AUST J BASIC APPL SC, V9, P115
   Sukadev M, 2007, J LATEX CLASS FILES, V6, P1
   Sunitha MR, 2016, INT J ENG COMPUT SCI, V5, P16263
   Tinumol S, 2015, INT J COMPUT APPL, V132, P31
   Xu LQ, 2007, IEEE, V23, P10
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Ying Z, 2015, IEEE, V2, P1
   Yong-Jin L, 2015, IEEE, V7, P1
   Yuanyuan W, 2015, IEEE T INTELL TRANSP, P1, DOI DOI 10.1109/TITS.2015.2498180
   Zhang K, 2016, EUR C COMP VIS, P1
   Zhang L, 2013, VIDEOGRAPH NONLINEAR
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
NR 56
TC 31
Z9 34
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23273
EP 23290
DI 10.1007/s11042-018-5671-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900009
DA 2024-07-18
ER

PT J
AU Song, EM
   Cheng, N
   Liu, H
   Song, HM
AF Song, Enmin
   Cheng, Ning
   Liu, Hong
   Song, Huimin
TI Approach to weak signal detection via over-sampling and bidirectional
   saw-tooth shaped function in wearable devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weak signal detection; Bidirectional saw-tooth shaped function;
   Over-sampling; Nonlinearity of the starting point
AB Many biological signals that reflect the human health are relatively weak, and high-resolution Analog-Digital Converters (ADCs) are required to measure them. The over-sampling technology is a method for increasing the accuracy, equal to the accuracy of high resolution ADCs, when an ADC has low resolution. For high resolution ADCs, their accuracy from the over-sampling technology would break its maximum limitation. During our signal collection, there are two items which affect our results: 1. measurement error; 2. non-linear characteristics at the end points. In over-sampling method of detecting weak signal of wearable devices by using the unidirectional saw-tooth shaped function, the magnitude of the shaped function is as close as possible to the integer multiple of the quantization step size to reduce the additional measurement error. To reduce the difficulty of the adding shaped function, which features nonlinearity of the starting point, a new method of detecting the weak signal by adding the bidirectional saw-tooth shaped function is proposed. The experimental results show this method is feasible for improving the ADC resolution.
C1 [Song, Enmin; Cheng, Ning; Liu, Hong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Song, Huimin] Cent City Brewers & Distillers, 11411 Bridgeview Dr, Surrey, BC V3R 0C2, Canada.
C3 Huazhong University of Science & Technology
RP Liu, H (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM esong@hust.edu.cn; cning@hust.edu.cn; hongliu@hust.edu.cn;
   allen@centralcitybrewing.com
FU National Natural Science Foundation of China [61370179]
FX This work has been supported by National Natural Science Foundation of
   China under grant project No.61370179.
CR Analog Devices Inc, 2017, LOW POW 2 CHANN 24 B
   Chen M, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600410CM
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Cheng X., 2013, THESIS
   Kim J. M., 2007, Sampling Theory in Signal and Image Processing, V6, P185
   Li G, 2014, CIRC SYST SIGNAL PR, V33, P3003, DOI 10.1007/s00034-014-9794-5
   [李刚 LI Gang], 2008, [电子学报, Acta Electronica Sinica], V36, P756
   Li Hong-zheng, 2015, Instrument Technique and Sensor, P62
   Xu Wei, 2007, Control & Measurement, P75
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zhang Y, 2017, IEEE COMMUN MAG, V55, P94, DOI 10.1109/MCOM.2017.1601185
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
NR 12
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21923
EP 21933
DI 10.1007/s11042-017-5362-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500007
DA 2024-07-18
ER

PT J
AU Yang, XC
   Sun, QS
   Wang, TS
AF Yang, Xichen
   Sun, Quansen
   Wang, Tianshu
TI Image quality assessment improvement via local gray-scale fluctuation
   measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gray-scale fluctuation; Image quality assessment; Patch selection;
   Full-reference
ID INFORMATION; REGULARITY
AB When individuals view an image, they form an opinion by considering only some parts of the image, which are defined as regions of interest. Based on this hypothesis, in this paper, a local gray-scale fluctuation measurement is used to select image patches with rich structural information and texture that can attract human visual perception. First, a gray-scale fluctuation map (GFM) is calculated based on a specific primitive. The pixel values in the GFM reflect the gray-scale fluctuation level of the pixel in the same location in the corresponding image. Second, the patches are selected via the gray-scale fluctuation conditions in the GFM. Third, existing image quality assessment (IQA) methods are used to measure the quality of each patch. Additionally, the quality assessment results of each patch are combined as the quality score of the entire image. The experimental results on five open databases demonstrate that the proposed method has a positive effect on IQA for existing methods. Additionally, the proposed method can improve the prediction accuracy of the quality assessment of diversely distorted types.
C1 [Yang, Xichen; Sun, Quansen; Wang, Tianshu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Xiaolingwei 200, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Yang, XC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Xiaolingwei 200, Nanjing 210094, Jiangsu, Peoples R China.
EM yxcwudi@gmail.com
FU National Science Foundation of China [61673220]
FX This paper is supported by the National Science Foundation of China
   (Grant No. 61673220).
CR Alaei A, 2017, SIGNAL IMAGE VIDEO P, V11, P673, DOI 10.1007/s11760-016-1009-z
   [Anonymous], 2015, SPRINGER J CSI T ICT
   [Anonymous], SIGN SYST COMP 2004
   [Anonymous], 2004, ADV MOD RADIOELECTRO
   [Anonymous], IEEE INT C MICR MECH
   [Anonymous], COMPUT ELECT ENG
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Ji H., 2008, COMPUTER VISION PATT
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu DL, 2014, SIGNAL PROCESS-IMAGE, V29, P844, DOI 10.1016/j.image.2014.06.007
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P845, DOI 10.1016/j.jvcir.2012.04.010
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yang XC, 2018, COMPUT ELECTR ENG, V70, P349, DOI 10.1016/j.compeleceng.2016.08.014
   Yang XC, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064357
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yuan Y, 2015, NEUROCOMPUTING, V159, P227, DOI 10.1016/j.neucom.2015.01.066
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 35
TC 3
Z9 4
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24185
EP 24202
DI 10.1007/s11042-018-5740-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900048
DA 2024-07-18
ER

PT J
AU Covaci, A
   Ghinea, G
   Lin, CH
   Huang, SH
   Shih, JL
AF Covaci, Alexandra
   Ghinea, Gheorghita
   Lin, Chang-Hsin
   Huang, Shu-Hsien
   Shih, Ju-Ling
TI Multisensory games-based learning - lessons learnt from olfactory
   enhancement of a digital board game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Games; Olfaction; Learning; Multisensory interaction; History
ID COMPUTER GAMES; EMPIRICAL-EVIDENCE; EDUCATIONAL GAMES; PERFORMANCE;
   CHILDREN; BENEFITS; REALITY; IMPACT; AROMAS; MOOD
AB Serious games are becoming an alternative educational method in a variety of fields because of their potential to improve the quality of learning experiences and to facilitate knowledge acquisition and content understanding. Moreover, entertainment-driven learners are more easily motivated to benefit from the learning process through meaningful activities defined in a game context. Interfacing educational computer games with multisensorial interfaces allows for a seamless integration between virtual and physical environments. Multisensorial cues can improve memory and attention and increase the cognitive and sensory-motor performance. Despite of the increasing knowledge in sensory processes, multisensory experiences and interactions in computer based instruction remain insufficiently explored and understood. In this paper, we present a multisensory educational game-Fragrance Channel - and we investigate how enabling olfaction can contribute to users' learning performance, engagement and quality of experience. We compare results obtained after experiencing Fragrance Channel in the presence and absence of olfactory feedback on both a mobile and a PC. A knowledge test administered before and immediately after showed that our proposed educational game led to an improvement of performance in all the explored conditions. Subjective measurements carried out after the olfactory experience showed that students enjoyed the scenario and appreciated it as being relevant.
C1 [Covaci, Alexandra; Ghinea, Gheorghita] Brunel Univ, London, England.
   [Lin, Chang-Hsin; Huang, Shu-Hsien; Shih, Ju-Ling] Natl Univ Tainan, Tainan, Taiwan.
C3 Brunel University; National University Tainan
RP Ghinea, G (corresponding author), Brunel Univ, London, England.
EM alexandra.covaci@brunel.ac.uk; george.ghinea@brunel.ac.uk;
   changhsinlin1206@gmail.com; shuhsienhuang@gmail.com;
   juling@mail.nutn.edu.tw
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580
FU European Union's Horizon 2020 Research and Innovation programme [688503]
FX The work reported in this paper has received funding from the European
   Union's Horizon 2020 Research and Innovation programme under Grant
   Agreement no. 688503 (NEWTON - Networked Labs for Training in Sciences
   and Technologies).
CR Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   Ademoye OA, 2009, IEEE T MULTIMEDIA, V11, P561, DOI 10.1109/TMM.2009.2012927
   Alais D, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011283
   [Anonymous], ED INFORM TECHNOLOGI
   [Anonymous], 1983, DEV CHILDRENS THOUGH
   [Anonymous], MASARYK UJL TECH
   [Anonymous], ACM T MULTIMED COMPU
   [Anonymous], ROLE OLFACTORY TECHN
   Antunes M, 2012, J CHEM EDUC, V89, P517, DOI 10.1021/ed2003077
   Bellotti F, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/136864
   Boyle E, 2011, ENTERTAIN COMPUT, V2, P69, DOI 10.1016/j.entcom.2010.12.002
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Braghirolli LF, 2016, COMPUT HUM BEHAV, V58, P315, DOI 10.1016/j.chb.2015.12.063
   Broadbent HJ, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12554
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Coller BD, 2009, COMPUT EDUC, V53, P900, DOI 10.1016/j.compedu.2009.05.012
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Egenfeldt-Nielsen S., 2015, UNDERSTANDING VIDEO, V3
   Escobedo L, 2014, IEEE PERVAS COMPUT, V13, P38, DOI 10.1109/MPRV.2014.19
   Ferdig R.E., 2008, Handbook of research on effective electronic gaming in education
   Fifer Joanne M, 2013, F1000Res, V2, P34, DOI 10.12688/f1000research.2-34.v1
   Forsyth C.M., 2012, Proceedings of the 5th International Conference on Educational Data Mining, P172
   Franzwa Christopher., 2013, 2013 5th International conference on games and virtual worlds for serious applications (VS-GAMES), P1
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379794
   Gingras G, 2009, J NEUROSCI, V29, P4897, DOI 10.1523/JNEUROSCI.4120-08.2009
   Hancock PA, 2013, ERGONOMICS, V56, P729, DOI 10.1080/00140139.2013.771219
   Huang WD, 2013, INTERNET HIGH EDUC, V17, P58, DOI 10.1016/j.iheduc.2012.11.004
   Hung CM, 2014, J COMPUT EDUC, V1, P151, DOI 10.1007/s40692-014-0008-8
   Hwang GJ, 2013, COMPUT EDUC, V69, P121, DOI 10.1016/j.compedu.2013.07.008
   Jönsson FU, 2011, MEM COGNITION, V39, P1023, DOI 10.3758/s13421-011-0080-5
   Jordan KE, 2011, DEVELOPMENTAL SCI, V14, P205, DOI 10.1111/j.1467-7687.2010.00966.x
   Kapp K.M., 2013, GAMIFICATION LEARNIN
   Kruijff E, 2017, VISUAL COMPUT, V33, P471, DOI 10.1007/s00371-016-1294-0
   Li KF, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P136, DOI 10.1109/CISIS.2013.30
   Ma M., 2011, Serious Games and Edutainment Applications, DOI DOI 10.1016/j.vaccine.2015.04.036
   Mangen A, 2010, CONTEMP ISS EARLY CH, V11, P415, DOI 10.2304/ciec.2010.11.4.415
   Matassa A., 2015, Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers - UbiComp'15, P923, DOI DOI 10.1145/2800835.2806201
   Mayer R.E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9780511816819.016, 10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369]
   Moore AG, 2015, P IEEE VIRT REAL ANN, P237, DOI 10.1109/VR.2015.7223383
   Moss M, 2003, INT J NEUROSCI, V113, P15, DOI 10.1080/00207450390161903
   Moss M, 2008, INT J NEUROSCI, V118, P59, DOI 10.1080/00207450601042094
   Murray MM, 2004, NEUROIMAGE, V21, P125, DOI 10.1016/j.neuroimage.2003.09.035
   Nussbaum M, 2014, IEEE INT CONF ADV LE, P2, DOI 10.1109/ICALT.2014.9
   Pichierri G, 2012, BMC GERIATR, V12, DOI 10.1186/1471-2318-12-74
   Pieretti RA, 2015, COMMUN DISORD Q, V36, P131, DOI 10.1177/1525740114545360
   Psotka J, 2013, EDUC TECHNOL SOC, V16, P69
   Sar E, 2012, PROCD SOC BEHV, V55, P776, DOI 10.1016/j.sbspro.2012.09.563
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Sisler Vit, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P67, DOI 10.1007/978-3-642-33542-6_6
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Tijou A, 2006, LECT NOTES COMPUT SC, V3942, P1223, DOI 10.1007/11736639_152
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   Verduin ML, 2013, J SUBST ABUSE TREAT, V44, P316, DOI 10.1016/j.jsat.2012.08.006
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zhang LK, 2016, LECT NOTES COMPUT SC, V9654, P111, DOI 10.1007/978-3-319-40259-8_10
   Zou LH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P315, DOI 10.1145/3083187.3084014
NR 57
TC 29
Z9 30
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21245
EP 21263
DI 10.1007/s11042-017-5459-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300041
OA hybrid
DA 2024-07-18
ER

PT J
AU Guo, SF
   Liu, Y
   Gong, LH
   Yu, WQ
   Gong, YL
AF Guo, Shaofeng
   Liu, Ye
   Gong, Lihua
   Yu, Wenqian
   Gong, Yunliang
TI Bit-level image cryptosystem combining 2D hyper-chaos with a modified
   non-adjacent spatiotemporal chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image cryptosystem; Coupled map lattices; Piecewise-linear chaotic map;
   2D hyper-chaos
ID ENCRYPTION; PERMUTATION; OPERATION
AB A novel bit-level image cryptosystem is proposed by introducing a new coupled map lattices (CML). The modified non-adjacent spatiotemporal chaotic system with good dynamic performance is constructed by coupling the piecewise-linear chaotic map (PWLCM) in a non-adjacent manner. In the proposed bit-level image cryptosystem, the binary plain image is scrambled globally by a 2D hyper-chaos system. And the confused image is then diffused via the pseudo-random sequences produced quickly and efficiently from the fabricative CML. After converting the diffused binary matrix into its homologous decimal matrix, the cipher image is achieved. Computer simulations and performance comparisons with recent image encryption algorithms demonstrate the superior performance and high security of our proposed cryptosystem.
C1 [Guo, Shaofeng; Liu, Ye; Gong, Lihua; Yu, Wenqian; Gong, Yunliang] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Gong, Lihua] Shanghai Jiao Tong Univ, Shanghai Key Lab Integrate Adm Technol Informat S, Shanghai 200240, Peoples R China.
C3 Nanchang University; Shanghai Jiao Tong University
RP Liu, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM liuye@ncu.edu.cn
FU National Natural Science Foundation of China [61462061, 61262084]; Major
   Academic Discipline and Technical Leader of Jiangxi Province
   [20162BCB22011]; Shanghai Key Laboratory of Integrate Administration
   Technologies for Information Security [AGK201602]; Innovation Fund for
   graduates of Nanchang University [CX2016260]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61462061 and 61262084), the Major Academic Discipline
   and Technical Leader of Jiangxi Province (Grant No. 20162BCB22011), the
   Opening Project of Shanghai Key Laboratory of Integrate Administration
   Technologies for Information Security (Grant No. AGK201602) and the
   Innovation Fund for graduates of Nanchang University (Grant No.
   CX2016260).
CR [Anonymous], RESEARCH-CHINA, DOI DOI 10.18502/JDER.4069
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Galil Z., 1985, P ADV CRYPT CRYPTO 8, P128
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kaliski B, 1992, Tech. rep
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   Kar M, 2016, IETE TECH REV, V33, P651, DOI 10.1080/02564602.2015.1136245
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Mao Y., 2011, INT J BIFURCAT CHAOS, V14, P3613
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 33
TC 11
Z9 13
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21109
EP 21130
DI 10.1007/s11042-017-5570-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300035
DA 2024-07-18
ER

PT J
AU Takalkar, M
   Xu, M
   Wu, Q
   Chaczko, Z
AF Takalkar, Madhumita
   Xu, Min
   Wu, Qiang
   Chaczko, Zenon
TI A survey: facial micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expressions recognition; Feature detection; Feature extraction;
   Classification; Deep learning features
ID LOCAL BINARY PATTERNS; FACE DETECTION; OPTICAL-FLOW; HISTOGRAMS
AB Facial expression recognition plays a crucial role in a wide range of applications of psychotherapy, security systems, marketing, commerce and much more. Detecting a macro-expression, which is a direct representation of an 'emotion,' is a relatively straight-forward task. Playing a pivotal role as macro-expressions, micro-expressions are more accurate indicators of a train of thought or even subtle, passive or involuntary thoughts. Compared to macro-expressions, identifying micro-expressions is a much more challenging research question because their time spans are narrowed down to a fraction of a second, and can only be defined using a broader classification scale. This paper is an all-inclusive survey-cum-analysis of the various micro-expression recognition techniques. We analyze the general framework for micro-expression recognition system by decomposing the pipeline into fundamental components, namely face detecting, pre-processing, facial feature detection and extraction, datasets, and classification. We discuss the role of these elements and highlight the models and new trends that are followed in their design. Moreover, we provide an extensive analysis of micro-expression recognition systems by comparing their performance. We also discuss the new deep learning features that can, in the near future, replace the hand-crafted features for facial micro-expression recognition. This survey has been developed, focusing on the methodologies applied, databases used, performance regarding recognition accuracy and comparing these to distil the gaps in the efficiencies, future scope, and research potentials. Through this survey, we intend to look into this problem and develop a comprehensive and efficient recognition scheme. This study allows us to identify open issues and to determine future directions for designing real-world micro-expression recognition systems.
C1 [Takalkar, Madhumita; Xu, Min; Wu, Qiang; Chaczko, Zenon] Univ Technol Sydney, Sch Comp & Commun, Fac Engn & Informat Technol, 15 Broadway, Ultimo, NSW 2007, Australia.
C3 University of Technology Sydney
RP Takalkar, M (corresponding author), Univ Technol Sydney, Sch Comp & Commun, Fac Engn & Informat Technol, 15 Broadway, Ultimo, NSW 2007, Australia.
EM madhumita.a.takalkar@student.uts.edu.au; min.xu@uts.edu.au;
   qiang.wu@uts.edu.au; zenon.chaczko@uts.edu.au
RI Chaczko, Zenon/AAB-8472-2020; Takalkar, Madhumita/R-8371-2019
OI Takalkar, Madhumita/0000-0002-3413-0730; Chaczko,
   Zenon/0000-0002-2816-7510; Wu, Qiang/0000-0001-5641-2483; Xu,
   Min/0000-0001-9581-8849
CR Agarwal S, 2017, MULTIMED TOOLS APPL, V76, P1073, DOI 10.1007/s11042-015-3103-6
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875
   [Anonymous], 2014, ACCV, DOI DOI 10.1007/978-3-319-16865-4_34
   [Anonymous], 2014, ACCV WORKSH SING, DOI DOI 10.1007/978-3-319-16631-5_47
   [Anonymous], 2014, P 2014 ASIAN C COMPU
   [Anonymous], 2014, ECCV WORKSH ZUR, DOI DOI 10.1007/978-3-319-16178-5_23
   [Anonymous], DATABASE DIGITAL IMA
   [Anonymous], 2015, ARXIV151100423
   [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Ben-Hur A, 2010, METHODS MOL BIOL MET, V609
   Benyamin D, 2012, BLOG PRESS
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chavali GK, 2014, THESIS
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davison A.K., 2014, European conference on computer vision, P111
   Donia ManarMF., 2014, Computer and Information Science, V7, P31, DOI DOI 10.5539/CIS.V7N3P31
   Eckman Paul., 2003, EMOTIONS REVEALED
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Ekman P, 1978, FACIAL ACTION CODING
   Endres J, 2009, BMC MED EDUC, V9, DOI 10.1186/1472-6920-9-47
   Guo YJ, 2014, IEEE IJCNN, P3473, DOI 10.1109/IJCNN.2014.6889620
   Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   House C., 2015, PREPROCESSING DESCRI
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Kim Inseong, 2010, COMPUTER INFORM SCI, V3, P71
   Lajevardi SM, 2012, IEEE T IMAGE PROCESS, V21, P3721, DOI 10.1109/TIP.2012.2197628
   Li X, 2013, SCI WORLD J, DOI 10.1155/2013/364730
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucas B.D., 1985, GEN IMAGE MATCHING M
   LUN X., 2016, Int J Control Autom, V9, P361
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Patel D, 2015, LECT NOTES COMPUT SC, V9386, P369, DOI 10.1007/978-3-319-25903-1_32
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sampangi RV, 2014, WHO ARE YOU ADVENTUR
   Shen XB, 2012, J ZHEJIANG UNIV-SC B, V13, P221, DOI 10.1631/jzus.B1100063
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   Song Y, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P237, DOI 10.1145/2522848.2522851
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P, 2004, INT C PATT RECOG, P179, DOI 10.1109/ICPR.2004.1333733
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wang SJ, 2011, IEEE T IMAGE PROCESS, V20, P2490, DOI 10.1109/TIP.2011.2121084
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674
   Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zhang M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095018
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 65
TC 60
Z9 64
U1 3
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19301
EP 19325
DI 10.1007/s11042-017-5317-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500019
DA 2024-07-18
ER

PT J
AU Venkatesan, R
   Ganesh, AB
AF Venkatesan, R.
   Ganesh, A. Balaji
TI Deep recurrent neural networks based binaural speech segregation for the
   selection of closest target of interest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep recurrent neural network; binaural speech segregation; distance and
   position information; Computational Auditory Scene Analysis;
   direct-to-reverberant ratio(DRR)
ID REVERBERANT ENERGY RATIO; SOUND SOURCE DISTANCE; FILTER BANK FEATURES;
   SOURCE SEPARATION; CLASSIFICATION; LOCALIZATION; ENVIRONMENTS;
   INTELLIGIBILITY; ENHANCEMENT; RECOGNITION
AB An auditory attention model that consists of binaural source segregation and also full localization of a target speech signal in a multi-talker environment is presented. The joint acoustic features, such as monaural, binaural and direct to reverberant ratio (DRR) that are successfully incorporated into deep recurrent neural network (DRNN) based joint discriminative model for the speech source segregation process. The monaural and binaural features are extracted from binaural speech mixtures of two speakers by using mean Hilbert envelope coefficients (MHEC) and interaural time, and level differences, respectively. The performance of deep recurrent network based speech segregation is validated in terms of signal to interference, signal to distortion and signal to artifacts and compared with existing architectures, including deep neural network (DNN). The proposed system is observed and found to be more suitable than monaural speech segregation especially when the desired target and interfering sources are located at different positions. The study also proposes full localization of segregated speech source that created the possibility to select the desired speaker of interest from an input acoustic speech mixture in a reverberant environment. The developed system has the capability to handle binaural segregation problem in multi-source and reverberation conditions. The auditory attention model provides accurate information about speech sources even when the desired targets are located at 2 m and above with higher reverberation time.
C1 [Venkatesan, R.; Ganesh, A. Balaji] Velammal Engn Coll, Dept Elect & Elect Engn, Elect Syst Design Lab, Madras 600066, Tamil Nadu, India.
C3 Velammal Engineering College
RP Ganesh, AB (corresponding author), Velammal Engn Coll, Dept Elect & Elect Engn, Elect Syst Design Lab, Madras 600066, Tamil Nadu, India.
EM abganesh@velammal.edu.in
RI GANESH, A BALAJI/GOP-3284-2022; GANESH, DR. A/JJD-0095-2023
OI GANESH, DR. A/0000-0002-0692-6213
FU Department of Science and Technology (DST) [SR/CSI/09/2011]
FX The authors wish to thank Department of Science and Technology for
   awarding a project under Cognitive Science Initiative Programme (DST
   File No.: SR/CSI/09/2011) through which the work has been implemented.
   The authors would like to thank anonymous reviewers for their valuable
   and constructive suggestions that improved the quality of the
   manuscript.
CR [Anonymous], J ANAL BIOANAL TECH
   [Anonymous], 2007, APPL SIGN PROC AUD A
   Asano F, 2013, IEEE T AUDIO SPEECH, V21, P1953, DOI 10.1109/TASL.2013.2263140
   Cambell DR, 2005, COMPUT INF SYST, V9, P48
   Chen JT, 2014, IEEE-ACM T AUDIO SPE, V22, P1993, DOI 10.1109/TASLP.2014.2359159
   Ellis D.P. W., 2005, PLP and RASTA (and MFCC, and inversion) in Matlab
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Geng Y., 2016, ARXIV160908417
   Georganti E, 2011, IEEE T AUDIO SPEECH, V19, P1949, DOI 10.1109/TASL.2011.2104953
   Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541
   Hioka Y, 2010, INT CONF ACOUST SPEE, P149, DOI 10.1109/ICASSP.2010.5496103
   Hu K, 2011, IEEE T AUDIO SPEECH, V19, P1600, DOI 10.1109/TASL.2010.2093893
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   Huang PS, 2015, IEEE-ACM T AUDIO SPE, V23, P2136, DOI 10.1109/TASLP.2015.2468583
   Hummersone C, 2011, IEEE T AUDIO SPEECH, V19, P2039, DOI 10.1109/TASL.2011.2109380
   Hummersone C, 2010, IEEE T AUDIO SPEECH, V18, P1867, DOI 10.1109/TASL.2010.2051354
   Jeub M., 2009, P INT C DIG SIGN PRO, P1
   Jiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P2112, DOI 10.1109/TASLP.2014.2361023
   Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633
   Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603
   Kohlrausch A, 2013, TECHNOLOGY BINAURAL
   Kuster M, 2011, J ACOUST SOC AM, V130, P3781, DOI 10.1121/1.3658446
   Leglaive S, 2015, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2015.7177944
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Lu YC, 2011, SPEECH COMMUN, V53, P622, DOI 10.1016/j.specom.2010.06.001
   Lu YC, 2010, IEEE T AUDIO SPEECH, V18, P1793, DOI 10.1109/TASL.2010.2050687
   Lu YC, 2008, P INT WORKSH AC ECH, P1793
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   Maas AL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P22
   Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P1872, DOI 10.1109/TASL.2010.2052252
   May T, 2012, IEEE T AUDIO SPEECH, V20, P2016, DOI 10.1109/TASL.2012.2193391
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038
   Po-Sen Huang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1562, DOI 10.1109/ICASSP.2014.6853860
   Raspaud M, 2010, IEEE T AUDIO SPEECH, V18, P68, DOI 10.1109/TASL.2009.2023644
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005
   Schädler MR, 2015, J ACOUST SOC AM, V137, P2047, DOI 10.1121/1.4916618
   Schädler MR, 2012, J ACOUST SOC AM, V131, P4134, DOI 10.1121/1.3699200
   Shao Y, 2008, INT CONF ACOUST SPEE, P1589
   Spille C, 2013, INT CONF ACOUST SPEE, P7805, DOI 10.1109/ICASSP.2013.6639183
   Vesa S, 2009, IEEE T AUDIO SPEECH, V17, P1498, DOI 10.1109/TASL.2009.2022001
   Weninger Felix, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3709, DOI 10.1109/ICASSP.2014.6854294
   Woodruff J, 2013, IEEE T AUDIO SPEECH, V21, DOI 10.1109/TASL.2012.2236316
   Woodruff J, 2012, IEEE T AUDIO SPEECH, V20, P1503, DOI 10.1109/TASL.2012.2183869
   Woodruff J, 2010, IEEE T AUDIO SPEECH, V18, P1856, DOI 10.1109/TASL.2010.2050087
   Wrigley SN, 2008, LECT NOTES COMPUT SC, V4892, P271
   Yu Y, 2016, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-016-0085-x
NR 48
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20129
EP 20156
DI 10.1007/s11042-017-5458-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500055
DA 2024-07-18
ER

PT J
AU Wang, S
   Hou, YH
   Li, ZY
   Dong, JR
   Tang, C
AF Wang, Shuang
   Hou, Yonghong
   Li, Zhaoyang
   Dong, Jiarong
   Tang, Chang
TI Combining ConvNets with hand-crafted features for action recognition
   based on an HMM-SVM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Convolutional neural networks; Hidden Markov model;
   Support vector machine
ID ENSEMBLE
AB This paper proposes a new framework for RGB-D-based action recognition that takes advantages of hand-designed features from skeleton data and deeply learned features from depth maps, and exploits effectively both the local and global temporal information. Specifically, depth and skeleton data are firstly augmented for deep learning and making the recognition insensitive to view variance. Secondly, depth sequences are segmented using the handcrafted features based on skeleton joints motion histogram to exploit the local temporal information. All training segments are clustered using an Infinite Gaussian Mixture Model (IGMM) through Bayesian estimation and labelled for training Convolutional Neural Networks (ConvNets) on the depth maps. Thus, a depth sequence can be reliably encoded into a sequence of segment labels. Finally, the sequence of labels is fed into a joint Hidden Markov Model and Support Vector Machine (HMM-SVM) classifier to explore the global temporal information for final recognition. The proposed framework was evaluated on the widely used MSRAction-Pairs, MSRDailyActivity3D and UTD-MHAD datasets and achieved promising results.
C1 [Wang, Shuang; Hou, Yonghong; Li, Zhaoyang; Dong, Jiarong] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Tang, Chang] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
C3 Tianjin University; China University of Geosciences
RP Tang, C (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
EM happytangchang@gmail.com
RI hou, yonghong/N-9255-2013; Tang, Chang/AAU-8995-2020
OI Tang, Chang/0000-0002-6515-7696
FU National Natural Science Foundation of China [61571325, 61502357];
   Fundamental Research Funds for the Central Universities, China
   University of Geosciences (Wuhan) [CUG170654]
FX This work was funded by the National Natural Science Foundation of China
   (NO. 61571325 and 61502357) and the Fundamental Research Funds for the
   Central Universities, China University of Geosciences (Wuhan) (NO.
   CUG170654).
CR Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   [Anonymous], DICTA
   [Anonymous], 2014, P 22 ACM INT C MULT
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Eweiwi A, 2015, LECT NOTES COMPUT SC, V9007, P428, DOI 10.1007/978-3-319-16814-2_28
   Fraley C, 2007, J CLASSIF, V24, P155, DOI [10.1007/s00357-007-0004-5, 10.1007/s00357-007-0004-z]
   Gelman A., BAYESIAN DATA ANAL
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Griffiths TL, 2005, TECHNICAL REPORT
   Jia XF, 2012, INT C PATT RECOG, P3001
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Neal R. M., 2010, J COMPUTATIONAL GRAP, V9, P249
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rui PL, 2014, INFORMATION TECHNOLOGY AND COMPUTER APPLICATION ENGINEERING, P1
   Shao L, 2009, 2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P88, DOI 10.1109/CRV.2009.36
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wood Frank, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P1165
   Wu D, 2014, DEEP DYNAMIC NEURAL
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
NR 30
TC 12
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18983
EP 18998
DI 10.1007/s11042-017-5335-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500005
DA 2024-07-18
ER

PT J
AU Cho, W
   Na, I
   Kim, S
   Park, S
AF Cho, Wanhyun
   Na, Inseop
   Kim, Sangkyoon
   Park, Soonyoung
TI Variational Bayesian multinomial logistic Gaussian process
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian process model; Multinomial logistic likelihood function;
   Variational Bayesian inference; Prior distribution; Approximate
   posterior distribution; Predictive distribution; Synthetic and real
   datasets
AB The multinomial logistic Gaussian process is a flexible non-parametric model for multi-class classification tasks. These tasks are often involved in solving a pattern recognition problem in real life. In such contexts, the multinomial logistic function (or softmax function) is usually assumed to be the likelihood function. But, exact inferences for this model have proved challenging problem because it requires high-dimensional integration. In this paper, we propose approximate variational Bayesian inference for the multinomial logistic Gaussian process model. First, we compute the second-order approximation for the logarithm of the logistic likelihood function using Taylor series expansion, and derive the posterior distributions of all hidden variables and model parameters using the variational Bayesian inference method. Second, we derive the predictive distribution of the latent classification variable corresponding to the relevant test data point using the characteristics of the Cauchy product for a standard Gaussian process using a learning model parameter. We conducted experiments to verify the effectiveness of the proposed model using a number of synthetic and real datasets. The results show that the proposed model has superior classification capability to existing methods.
C1 [Cho, Wanhyun] Chonnam Natl Univ, Dept Stat, 77 Youngbong Ro, Gwangju, South Korea.
   [Na, Inseop] Chonnam Natl Univ, Comp Sci, 77 Youngbong Ro, Gwangju, South Korea.
   [Kim, Sangkyoon; Park, Soonyoung] Mokpo Natl Univ, Dept Elect Engn, Muan, South Korea.
C3 Chonnam National University; Chonnam National University; Mokpo National
   University
RP Na, I (corresponding author), Chonnam Natl Univ, Comp Sci, 77 Youngbong Ro, Gwangju, South Korea.
EM whcho@chonnam.ac.kr; ypencil@hanmail.net; narciss76@mokpo.ac.kr;
   sypark@mokpo.ac.kr
RI Na, In Seop/K-2508-2018
OI Na, In Seop/0000-0001-6471-043X
FU Korea National Research Foundation [NRF-2017R1D1A1B03028808]; Basic
   Science Research Program through the National Research Foundation of
   Korea(NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2015R1C1A1A02036495]
FX This work was partially supported by Korea National Research Foundation
   (NRF-2017R1D1A1B03028808) and Basic Science Research Program through the
   National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning(NRF-2015R1C1A1A02036495).
CR [Anonymous], 1997, THESIS U CAMBRIDGE
   [Anonymous], NEURAL INFORM PROCES
   Beal M. J., 2003, THESIS
   Chai KMA, 2012, J MACH LEARN RES, V13, P1745
   Csató L, 2000, ADV NEUR IN, V12, P251
   Drugowitsch J, 2014, ARXIV13105438V2
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Ghahramani Z, 2000, ADV NEUR IN, V12, P449
   Ghahramani Z., 2000, Advanced mean field methods-theory and practice
   Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477
   Girolani M, 2005, TR2005205 U GLASG DE
   Kim H.-C., 2006, IEEE T PAMI, V28, P1945
   Lama N, 2008, BIOINFORMATICS, V24, P135, DOI 10.1093/bioinformatics/btm535
   Mackay DJC, 1998, NIPS 97 TUTORIAL NOT
   Minka T., 2001, P 17 C UNC ART INT, P362
   Neal RM, 1998, REGRESSION CLASSIFIC, V6
   Nickisch H, 2008, J MACH LEARN RES, V9, P2035
   Opper M, 2009, NEURAL COMPUT, V21, P786, DOI 10.1162/neco.2008.08-07-592
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   SEEGER M, 2004, 661 TR U CAL BERK DE
   Shi JQ, 2003, INT J ADAPT CONTROL, V17, P149, DOI 10.1002/acs.744
   Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807
NR 22
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18563
EP 18582
DI 10.1007/s11042-017-5210-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900050
DA 2024-07-18
ER

PT J
AU Chung, KL
   Huang, YH
AF Chung, Kuo-Liang
   Huang, Yong-Huai
TI An effective directional interpolation- and inpainting-based algorithm
   for removing impulse noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Highly corrupted images; Directional interpolation; Impulse noise
   removal; Inpainting; Objective and subjective quality comparison
ID MEDIAN FILTERS; IMAGE
AB In this paper, an effective directional interpolation- and inpainting-based impulse noise removal algorithm is proposed. Firstly, each noisy pixel is classified to either the low-density noise or the middle/high density noise. Secondly, a directional interpolation-based noise removal procedure is proposed to denoise the low-density noise. Thirdly, an inpainting-based noise removal procedure is proposed to denoise the middle/high-density noise. Based on ten typical test images, each image with noise level ranging from 30 to 90%, the experimental results demonstrate that in terms of peak-signal-to-noise-ratio (PSNR), structural similarity index (SSIM), and visual effect, the proposed algorithm has the best quality performance when compared with six state-of-the-art noise removal algorithms.
C1 [Chung, Kuo-Liang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Huang, Yong-Huai] Jinwen Univ Sci & Technol, Dept Comp Sci & Informat Engn, New Taipei 23154, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
EM klchung01@gmail.com
FU  [MOST 104-2221-E-011-118-MY3];  [MOST 104-2221-E-228-006]
FX The authors appreciate the proofreading help of Ms. C. Harrington, the
   valuable comments of the three anonymous referees, and the support under
   the contracts MOST 104-2221-E-011-118-MY3 and MOST 104-2221-E-228-006.
CR Aiswarya K, 2010, ICCMS 2010, V4, DOI [10.1109/ICCMS.2010.310, DOI 10.1109/ICCMS.2010.310]
   Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Bertalmio M., 2001, PROC CVPR IEEE, V1, P1, DOI DOI 10.1109/CVPR.2001.990497
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chou HH, 2015, J VIS COMMUN IMAGE R, V30, P363, DOI 10.1016/j.jvcir.2015.05.007
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   LIN HM, 1988, IEEE T CIRCUITS SYST, V35, P675, DOI 10.1109/31.1805
   Lin PH, 2015, IEEE J DISPLAY TECHN
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YANG RK, 1995, IEEE T SIGNAL PROCES, V43, P591, DOI 10.1109/78.370615
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 21
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16477
EP 16493
DI 10.1007/s11042-017-5216-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300023
DA 2024-07-18
ER

PT J
AU Jalali, A
   Farsi, H
   Ghaemmaghami, S
AF Jalali, Arash
   Farsi, Hassan
   Ghaemmaghami, Shahrokh
TI A Universal Image Steganalysis System Based On Double Sparse
   Representation Classification (DSRC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Dictionary learning; Double sparse
   representation
ID FACE RECOGNITION; SIGNAL RECOVERY; DICTIONARIES
AB Achieving high rates of detection in low rates of embedding is still a challenging problem in many steganalysis systems. The newly proposed steganalysis system based on sparse representation classifier has shown remarkable detection rates in low embedding rate. In this paper, we propose a new steganalysis system based on double sparse representation classifier. We compare our proposed method with other steganalysis systems which use different classifier (including nearest neighbor, support vector machine, ensemble support vector machine and sparse representation). In all of our experiments, input features to the classifier are fixed and the ability of classifier is examined. Also we provide a complexity analysis in terms of execution time for different classifier. In most of experiments, our proposed method shows superior performance in terms of detection rate and complexity for low embedding rates.
C1 [Jalali, Arash; Farsi, Hassan] Univ Birjand, Elect & Comp Engn Dept, Birjand, Iran.
   [Ghaemmaghami, Shahrokh] Sharif Univ Technol, Elect Engn Dept, Tehran, Iran.
C3 University of Birjand; Sharif University of Technology
RP Farsi, H (corresponding author), Univ Birjand, Elect & Comp Engn Dept, Birjand, Iran.
EM a_jalali1367@birjand.ac.ir; hfarsi@birjand.ac.ir; ghaemmag@sharif.ir
RI Farsi, hassan/AAF-5297-2021
CR Abavisani Mahdi, 2015, 2015 IEEE Signal Processing in Medicine and Biology Symposium (SPMB). Proceedings, P1, DOI 10.1109/SPMB.2015.7405470
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2011, P 13 INF HID C PRAG
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Farhat F, 2015, IET IMAGE PROCESS, V9, P31, DOI 10.1049/iet-ipr.2013.0877
   Friedman JH, 2012, INT J FORECASTING, V28, P722, DOI 10.1016/j.ijforecast.2012.05.001
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gemmeke JF, 2011, IEEE T AUDIO SPEECH, V19, P2067, DOI 10.1109/TASL.2011.2112350
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goljan M, 2015, P SPIE EL IM MED WAT
   Gong R, 2012, OPT COMMUN, V285, P4961, DOI 10.1016/j.optcom.2012.07.121
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Huang JB, 2010, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2010.5539919
   Kuang-Yu C, 2014, CIRCUITS SYST SIGNAL, V1, P309
   Li WF, 2013, IEEE SIGNAL PROC LET, V20, P681, DOI 10.1109/LSP.2013.2245894
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liu QS, 2004, IEEE T SIGNAL PROCES, V52, P3403, DOI 10.1109/TSP.2004.837423
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Malekmohamadi H, 2009, IEEE INT CON MULTI, P1740
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nanni L, 2013, PLOS ONE PUBLIC LIB, V12, P7457
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Sigg CD, 2010, INT CONF ACOUST SPEE, P4758, DOI 10.1109/ICASSP.2010.5495157
   Srinivas U, 2015, IEEE T IMAGE PROCESS, V24, P1763, DOI 10.1109/TIP.2015.2409572
   Su JY, 2015, INT J SECUR APPL, V9, P69, DOI 10.14257/ijsia.2015.9.1.08
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao Yi Yu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1118, DOI 10.1109/IIH-MSP.2009.297
   Xu B, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P215
   Yamini B, 2013, IEEE 5 INT C ADV COM, V12, P543
   Yu XY, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P41, DOI 10.1109/MINES.2009.269
   Zhang S, 2017, CLUSTER COMPUT, V20, P1, DOI DOI 10.1007/s10586-016-0677-3
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhang Z, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P437, DOI 10.1109/CIS.2013.99
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 44
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16347
EP 16366
DI 10.1007/s11042-017-5201-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300016
DA 2024-07-18
ER

PT J
AU Xu, C
   Liu, JF
   Gan, JJ
   Luo, XY
AF Xu, Che
   Liu, Jiufen
   Gan, Junjun
   Luo, Xiangyang
TI Stego key recovery based on the optimal hypothesis test
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Extraction attacks; JPEG image; Random LSB steganography;
   Stego key
ID STEGANALYSIS; STEGANOGRAPHY; IMAGES
AB At present, research on steganalysis is mainly focused on the existence detection of hidden messages. However, the extraction of hidden messages, i.e., extraction attacks, also plays a decisive role in tasks such as obtaining evidence of covert communication and fighting against criminal activities. For steganography using a stego key, the purpose of an extraction attack is to recover the stego key. This paper mainly studies methods of recovering the stego key for least significant bit (LSB) steganography in the JPEG domain. Firstly, based on the differences in the statistical properties of the discrete cosine transform (DCT) coefficients between the paths generated by the correct and incorrect keys, a stego key recovery model based on the optimal hypothesis test is proposed. Moreover, formulas are given for calculating the desired sample size and threshold in the proposed stego key recovery model. Secondly, based on the difference in the distributions of odd and even coefficients between the correct and incorrect paths, a method of recovering the stego key for OutGuess steganography using this model is proposed. Finally, based on the difference in the distributions of zero and non-zero coefficients between the correct and incorrect paths, a method of recovering the stego key for F5 steganography (modified version) using this model is proposed. Experimental results for OutGuess 0.13b, OutGuess 0.2 and modified F5 steganography show that the proposed method can successfully recover the stego key and that its performance is superior to that of existing methods.
C1 [Xu, Che; Liu, Jiufen; Gan, Junjun; Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
   [Xu, Che; Liu, Jiufen; Gan, Junjun; Luo, Xiangyang] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Liu, Jiufen] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Xu, C (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.; Xu, C (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM cheyeweiwu@163.com; jiufenliu@163.com; 15932985953@163.com;
   xiangyangluo@126.com
RI 许, 澈/KPB-5787-2024
FU National Natural Science Foundation of China [61379151, 61572052,
   U1636219]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61379151, 61572052 and U1636219).
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 2 INT WORKSH DIG W
   Chen JY, 2013, INT J COMPUT INT SYS, V6, P639, DOI 10.1080/18756891.2013.802116
   Filler T., 2010, BOSS BREAK OUR STEGA
   Fridrich J, 2005, PROC SPIE, V5681, P631, DOI 10.1117/12.585987
   Fridrich J, 2004, PROC SPIE, V5306, P70, DOI 10.1117/12.521353
   Fridrich J, 2003, MULTIMEDIA SYST, V9, P288, DOI 10.1007/s00530-003-0100-9
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Jing Liu, 2012, Journal of Multimedia, V7, P309, DOI 10.4304/jmm.7.4.309-313
   Jiufen Liu, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P691, DOI 10.1109/MINES.2010.150
   LEHMANN E. L., 2006, Springer Texts in Statistics
   Liu J, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5526-8
   Pevny T, 2014, P 2 ACM WORKSH INF H, P109, DOI 10.1145/2600918.2600921
   Provos N., 2001, Proceedings of the 10th conference on USENIX Security Symposium, P24
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   University of Granada, 2012, CVG UGR IM DAT
   Ziou D, 2014, PATTERN ANAL APPL, V17, P279, DOI 10.1007/s10044-012-0303-9
NR 18
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17973
EP 17992
DI 10.1007/s11042-017-4878-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900022
DA 2024-07-18
ER

PT J
AU De Boom, C
   Agrawal, R
   Hansen, S
   Kumar, E
   Yon, R
   Chen, CW
   Demeester, T
   Dhoedt, B
AF De Boom, Cedric
   Agrawal, Rohan
   Hansen, Samantha
   Kumar, Esh
   Yon, Romain
   Chen, Ching-Wei
   Demeester, Thomas
   Dhoedt, Bart
TI Large-scale user modeling with recurrent neural networks for music
   discovery on multiple time scales
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Machine learning; Recurrent neural networks; Deep
   learning; Word2vec; Music information retrieval; Representation learning
AB The amount of content on online music streaming platforms is immense, and most users only access a tiny fraction of this content. Recommender systems are the application of choice to open up the collection to these users. Collaborative filtering has the disadvantage that it relies on explicit ratings, which are often unavailable, and generally disregards the temporal nature of music consumption. On the other hand, item co-occurrence algorithms, such as the recently introduced word2vec-based recommenders, are typically left without an effective user representation. In this paper, we present a new approach to model users through recurrent neural networks by sequentially processing consumed items, represented by any type of embeddings and other context features. This way we obtain semantically rich user representations, which capture a user's musical taste over time. Our experimental analysis on large-scale user data shows that our model can be used to predict future songs a user will likely listen to, both in the short and long term.
C1 [De Boom, Cedric; Demeester, Thomas; Dhoedt, Bart] Univ Ghent, IDLab Imec, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
   [Agrawal, Rohan; Hansen, Samantha; Kumar, Esh; Yon, Romain; Chen, Ching-Wei] Spotify Inc, 45 W 18th St, New York, NY 10011 USA.
C3 Ghent University; Spotify
RP De Boom, C (corresponding author), Univ Ghent, IDLab Imec, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
EM cedric.deboom@ugent.be; rohanag@spotify.com; slhansen@spotify.com;
   eshvk@spotify.com; romain@spotify.com; cw@spotify.com;
   thomas.demeester@ugent.be; bart.dhoedt@ugent.be
RI Demeester, Thomas/I-6382-2012
OI Demeester, Thomas/0000-0002-9901-5768
FU Research Foundation - Flanders (FWO)
FX Cedric De Boom is funded by a PhD grant of the Research Foundation -
   Flanders (FWO). We greatly thank Nvidia for its donation of a Tesla K40
   and Titan X GPU to support the research of the IDLab group at Ghent
   University.
CR [Anonymous], NEURAL COMPUT
   [Anonymous], ARXIV150602078V2
   [Anonymous], 2016, ARXIV160903499V2
   [Anonymous], 2016, ARXIV160502688V1
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2013, NEURAL INFORM PROCES
   [Anonymous], 2007, KDD CUP WORKSH
   [Anonymous], 2007, KDD CUP WORKSH
   [Anonymous], P NIPS 2000
   [Anonymous], 2016, P NIPS WORKSH EFF ME
   [Anonymous], 2015, ICLR 2015
   [Anonymous], 2013, AD VANCES NEURAL INF
   [Anonymous], 2014, INT C MACH LEARN ICM
   Barkan O, 2016, ITEM2VEC NEURAL ITEM
   Charikar M, 2002, S THEOR COMP STOC
   Chung J., 2014, ARXIV14123555V1
   Collobert R, 2011, J MACH LEARN RES
   De Boom C., 2016, PATTERN RECOGN LETT
   DOSSANTOS CN, 2014, INT C COMP LING COLI
   Dror Gideon., 2011, RECSYS
   Figueiredo F, 2016, INT SOC MUS INF RETR
   Goodman J, 2001, 2001 IEEE INT C AC S
   Greff K, 2015, ARXIV150304069V1
   Hidasi B, 2016, ARXIV151106939V4
   Hill Felix, 2016, T ASS COMPUTATIONAL
   Hu Y., 2008, IEEE INT C DAT MIN I
   Johnson C C, 2014, P ADV NEURAL INFORM
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Koren Y., 2009, Matrix factorization techniques for recommender systems
   Liang D, 2016, INT C MACH LEARN ICM
   Maas Andrew L., 2013, INT C MACH LEARN ICM
   Moore JL, 2013, INT SOC MUS INF RETR
   Ozsoy MG, 2016, ARXIV160101356V3
   Pan R., 2008, IEEE INT C DAT MIN I
   Rendle S., 2009, Uncertainty in Artificial Intelligence, UAI
   Sercu T., 2016, INTERSPEECH
   Tan YK, 2016, ARXIV160608117V2
NR 37
TC 7
Z9 9
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15385
EP 15407
DI 10.1007/s11042-017-5121-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200042
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Ershadi-Nasab, S
   Noury, E
   Kasaei, S
   Sanaei, E
AF Ershadi-Nasab, Sara
   Noury, Erfan
   Kasaei, Shohreh
   Sanaei, Esmaeil
TI Multiple human 3D pose estimation from multiview images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Multiview images; Multiple human; Fully connected
   model; Graphical model
ID PARALLEL FRAMEWORK; FLEXIBLE MIXTURES; HEVC; MODEL
AB Multiple human 3D pose estimation is a challenging task. It is mainly because of large variations in the scale and pose of humans, fast motions, multiple persons in the scene, and arbitrary number of visible body parts due to occlusion or truncation. Some of these ambiguities can be resolved by using multiview images. This is due to the fact that more evidences of body parts would be available in multiple views. In this work, a novel method for multiple human 3D pose estimation using evidences in multiview images is proposed. The proposed method utilizes a fully connected pairwise conditional random field that contains two types of pairwise terms. The first pairwise term encodes the spatial dependencies among human body joints based on an articulated human body configuration. The second pairwise term is based on the output of a 2D deep part detector. An approximate inference is then performed using the loopy belief propagation algorithm. The proposed method is evaluated on the Campus, Shelf, Utrecht Multi-Person Motion benchmark, Human3.6M, KTH Football II, and MPII Cooking datasets. Experimental results indicate that the proposed method achieves substantial improvements over the existing state-of-the-art methods in terms of the probability of correct pose and the mean per joint position error performance measures.
C1 [Ershadi-Nasab, Sara; Sanaei, Esmaeil] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Noury, Erfan; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM ershadinasab@ee.sharif.edu; noury@ce.sharif.edu; skasaei@sharif.edu;
   sanaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878
CR Afrouzian R, 2016, MULTIMED TOOLS APPL, V75, P6809, DOI 10.1007/s11042-015-2611-8
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Amin S, 2014, GERM C PATT REC, P253
   Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   [Anonymous], 2016, ARXIV160502914
   [Anonymous], 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.143
   [Anonymous], 2016, ECCV
   [Anonymous], ARXIV13127302
   [Anonymous], 2014, CVPR
   Belagiannis V, 2015, IEEE T PATTERN ANAL
   Belagiannis V, 2014, CHALEARN LOOK PEOPL
   Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Belagiannis V, 2014, LECT NOTES COMPUT SC, V8563, P20, DOI 10.1007/978-3-319-08849-5_3
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Charles J, 2016, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR.2016.334
   Charles James., 2014, Proceedings of the British Machine Vision Conference 2014, P1
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Dong J, 2014, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2014.113
   Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Holt B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1196, DOI 10.1109/ICCVW.2011.6130386
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21
   Jammalamadaka N, 2017, IMAGE VISION COMPUT, V59, P31, DOI 10.1016/j.imavis.2016.12.002
   Kazemi V, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.6
   Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48
   Kiefel M, 2014, LECT NOTES COMPUT SC, V8693, P331, DOI [10.1007/978-3-319-10602-1_22, 10.1007/978-3-319-11752-2_26]
   Li S., 2017, INT J COMPUT VISION, V122, P149, DOI [10. 1007/s11263-016-0962-x, DOI 10.1007/s11263-016-0962-x]
   Mooij JM, 2010, J MACH LEARN RES, V11, P2169
   Pavlakos G, 2017, P IEEE C COMP VIS PA
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Schick A, 2015, IEEE WINT CONF APPL, P140, DOI 10.1109/WACV.2015.26
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Tekin B, 2016, ARXIV160505180 CORR
   Tompson J, 2014, ADV NEUR IN, V27
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17
   van der Aa N. P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1264, DOI 10.1109/ICCVW.2011.6130396
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
   Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17
NR 59
TC 56
Z9 60
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15573
EP 15601
DI 10.1007/s11042-017-5133-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200050
DA 2024-07-18
ER

PT J
AU Xiang, GQ
   Jia, HZ
   Yang, MY
   Li, Y
   Xie, XD
AF Xiang, Guoqing
   Jia, Huizhu
   Yang, Mingyuan
   Li, Yuan
   Xie, Xiaodong
TI A novel adaptive quantization method for video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inter-frame dependency; Adaptive quantization; QP offset; SSIM;
   Subjective quality
ID STRUCTURAL SIMILARITY; PARALLEL FRAMEWORK; HEVC
AB In this paper, we propose a novel AQ (Adaptive Quantization) algorithm to improve the subjective coding performance. Firstly, the factors affecting a suitable adaptive quantization method are carefully analyzed. Two important conclusions are drawn to guide designing a suitable AQ method. Secondly, based on the drawn analysis, a novel SATD (Sum of the Transformed Difference) based temporal adaptive quantization method is proposed. The proposed method fully considers the temporal characteristics, which can produce more visual-friendly QP (quantization parameter) offset distribution. Experiments are performed on x264 and HM16.0, respectively. With SSIM (Structure Similarity) as the metric, more than 21.07% BD-Rate (Bjontegaard-Delta Rate) saving can be achieved on x264, and on HM16.0, 8.07% and 7.99% BD-Rate savings can be obtained for LDP (Low-Delay-main-P) and LDB (Low-Delay-main-B) configurations, respectively, which is better than the state-of-the-art methods.
C1 [Xiang, Guoqing; Jia, Huizhu; Li, Yuan; Xie, Xiaodong] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
   [Jia, Huizhu] Cooperat Medianet Innovat Ctr, Beijing, Peoples R China.
   [Jia, Huizhu] Beida Binhai Informat Res, Tianjin, Peoples R China.
   [Yang, Mingyuan] Beijing BOYA HUALU Technol Inc, Beijing 100080, Peoples R China.
C3 Peking University
RP Jia, HZ (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.; Jia, HZ (corresponding author), Cooperat Medianet Innovat Ctr, Beijing, Peoples R China.; Jia, HZ (corresponding author), Beida Binhai Informat Res, Tianjin, Peoples R China.
EM hzjia@pku.edu.cn
RI Li, Yuan/HDO-0750-2022
FU National High Technology Research and Development Program of China (863
   Program) [2015AA015903]; National Science Foundation of China [61421062,
   61502013]; Major National Scientific Instrument and Equipment
   Development Project of China [2013YQ030967]
FX This work is partially supported by the National High Technology
   Research and Development Program of China (863 Program) under contract
   No. 2015AA015903, the National Science Foundation of China (61421062,
   61502013), the Major National Scientific Instrument and Equipment
   Development Project of China under contract No. 2013YQ030967.
CR [Anonymous], 1993, 5 ISOIECJTC1SC29WG11
   [Anonymous], 2002, METH SUBJ ASS QUAL T
   [Anonymous], 2013, Technical Report JCTVC-L1100
   Beermann M, 2002, IEEE IMAGE PROC, P93
   Brooks AC, 2008, IEEE T IMAGE PROCESS, V17, P1261, DOI 10.1109/TIP.2008.926161
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Draft I, REC FIN DRAFT INT ST, P33
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Garrett-Glaser J., 2009, Tech. Rep
   Grassi G, 2005, INT J CIRC THEOR APP, V33, P53, DOI 10.1002/cta.303
   Guoqing Xiang, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P362, DOI 10.1109/ICCE.2017.7889356
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Li B, 2013, IEEE INT SYMP CIRC S, P477, DOI 10.1109/ISCAS.2013.6571884
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Lin RQ, 2016, IEEE DATA COMPR CONF, P617, DOI 10.1109/DCC.2016.83
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Rohaly A.M., 2000, ITU T STANDARDS CONT, P9
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tourapis AM, 2001, P SOC PHOTO-OPT INS, V4310, P883
   Wang MH, 2015, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2015.7168682
   WANG Yubing., 2006, SURVEY OBJECTIVE VID
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang T, 2012, MULT EXP ICME 2012 I, P85
   Yeo CH, 2013, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2013.6637940
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhu C, 2014, IEEE INT SYMP CIRC S, P5, DOI 10.1109/ISCAS.2014.6865051
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 37
TC 10
Z9 12
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14817
EP 14840
DI 10.1007/s11042-017-5064-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200016
DA 2024-07-18
ER

PT J
AU Ali, M
   Ahn, CW
   Pant, M
AF Ali, Musrrat
   Ahn, Chang Wook
   Pant, Millie
TI An efficient lossless robust watermarking scheme by integrating
   redistributed invariant wavelet and fractional Fourier transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete fractional Fourier transform; Visual cryptography; Lossless
   watermarking; Invariant wavelet transform
ID SINGULAR-VALUE DECOMPOSITION; COPYRIGHT PROTECTION SCHEME;
   SPREAD-SPECTRUM WATERMARKING; IMAGE WATERMARKING; VISUAL CRYPTOGRAPHY;
   DIFFERENTIAL EVOLUTION; ALGORITHM; SVD; DOMAIN; DCT
AB An ensemble lossless watermarking scheme is proposed in the present study by integrating different concepts like redistributed invariant wavelet transform, discrete fractional Fourier transform, singular value decomposition (SVD) and visual cryptography within the framework of a single algorithm. The invariant wavelet transform helps to obtain the transform domain, which is invariant to flipping and rotation of image, this is followed by discrete fractional Fourier transform to obtain the translation invariant domain. Finally, embedding positions are selected based on a key and reliable features are extracted by performing SVD on a window centered at these positions. Based on these reliable features a binary map is generated through which a master share is created. The corresponding ownership share is produced from the master share and the watermark. In verification process the same operations of the embedding process are applied to the test image to obtain the master share and the watermark is recovered by stacking it over the ownership share. There are two main features of the proposed scheme (1) The quality of the image to be watermarked do not degrade during the process and (2) the extracted watermark can still be identified even from a seriously distorted image. These findings are also demonstrated with the help of a comparative study with several related schemes.
C1 [Ali, Musrrat] Glocal Univ, Sch Technol, Saharanpur 247122, India.
   [Ahn, Chang Wook] GIST, Sch Elect Engn & Comp Sci, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
   [Pant, Millie] IIT Roorkee, Dept Appl Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Gwangju Institute of Science & Technology (GIST); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Roorkee
RP Ahn, CW (corresponding author), GIST, Sch Elect Engn & Comp Sci, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
EM musrrat.iitr@gmail.com; cwan@gist.ac.kr; mllifpt@iitr.ernet.in
RI ali, musrrat/AAV-6655-2020; Pant, Millie/O-5740-2019; PANT,
   Millie/C-9911-2018
OI ali, musrrat/0000-0002-4837-1850; Ahn, Chang Wook/0000-0002-9902-5966
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIP) [B0717-17-0070]; National Research Foundation of
   Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A02062017]
FX This research was supported by Institute for Information &
   communications Technology Promotion (IITP) grant funded by the Korea
   government (MSIP) (No. B0717-17-0070). It was also supported by the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2015R1D1A1A02062017).
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], 2012, INT J ENG RES TECHNO
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Chen TH, 2009, COMPUT STAND INTER, V31, P1, DOI 10.1016/j.csi.2007.09.001
   Cox I., 2001, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Gao L, 2013, J SIGNAL PROCESS SYS, V72, P133, DOI 10.1007/s11265-012-0722-2
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Li L, 2011, J SYST SOFTWARE, V84, P923, DOI 10.1016/j.jss.2011.01.025
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Ozaktas HM, 1996, IEEE T SIGNAL PROCES, V44, P2141, DOI 10.1109/78.536672
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Pei SC, 1999, IEEE T SIGNAL PROCES, V47, P1335, DOI 10.1109/78.757221
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sejdic E, 2011, SIGNAL PROCESS, V91, P1351, DOI 10.1016/j.sigpro.2010.10.008
   Sheskin J.D., 2004, Handbook of Parametric and Nonparametric Statistical Procedures, VThird
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 36
TC 25
Z9 25
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11751
EP 11773
DI 10.1007/s11042-017-4815-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100007
DA 2024-07-18
ER

PT J
AU Lee, K
   Nam, Y
   Min, SD
AF Lee, Keonsoo
   Nam, Yunyoung
   Min, Se Dong
TI An indoor localization solution using Bluetooth RSSI and multiple
   sensors on a smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bluetooth; RSSI; Accelerometer; Magnetic field sensor; Barometer; Indoor
   positioning
AB In this paper, we propose an indoor positioning system using a Bluetooth receiver, an accelerometer, a magnetic field sensor, and a barometer on a smartphone. The Bluetooth receiver is used to estimate distances from beacons. The accelerometer and magnetic field sensor are used to trace the movement of moving people in the given space. The horizontal location of the person is determined by received signal strength indications (RSSIs) and the traced movement. The barometer is used to measure the vertical position where a person is located. By combining RSSIs, the traced movement, and the vertical position, the proposed system estimates the indoor position of moving people. In experiments, the proposed approach showed excellent performance in localization with an overall error of 4.8%.
C1 [Lee, Keonsoo; Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 336745, South Korea.
   [Min, Se Dong] Soonchunhyang Univ, Dept Med IT Engn, Asan 336745, South Korea.
C3 Soonchunhyang University; Soonchunhyang University
RP Nam, Y (corresponding author), Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 336745, South Korea.
EM keonsoo@sch.ac.kr; ynam@sch.ac.kr; sedongmin@sch.ac.kr
RI Min, Dong/O-1002-2013; Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394; Min, Se Dong/0000-0002-9112-2673
FU Soonchunhyang University; Bio & Medical Technology Development Program
   of the National Research Foundation (NRF) - the Ministry of Science, ICT
   & Future Planning (MSIP), Republic of Korea [NRF-2015M3A9D7067388]
FX This work was supported by the Soonchunhyang University Research Fund
   and also supported by a grant (NRF-2015M3A9D7067388) of the Bio &
   Medical Technology Development Program of the National Research
   Foundation (NRF) funded by the Ministry of Science, ICT & Future
   Planning (MSIP), Republic of Korea
CR [Anonymous], 2013, PROC IEEE INT C INDO, DOI DOI 10.1109/IPIN.2013.6817855
   [Anonymous], 2014, P IEEE 17 INT C INF
   Barshan B, 1998, ELECTRON LETT, V34, P1616, DOI 10.1049/el:19981127
   Bohonos S, 2007, UNIVERSAL REAL TIME, P83, DOI [10.1145/1248054.1248080, DOI 10.1145/1248054.1248080]
   Chan S, 2012, REMOTE SENS SPAT INF, V4, P1
   Clarke R., 2001, Information Technology & People, V14, P206, DOI 10.1108/09593840110695767
   Faulkner WT, 2010, P INT TECH M I NAVIG, P198
   Fischer Gunter, 2004, P 1 WORKSH POS NAV C
   FRIIS HT, 1946, P IRE, V34, P254, DOI 10.1109/JRPROC.1946.234568
   Jayatilleke L, 2013, ANN IEEE SYST CONF, P448, DOI 10.1109/SysCon.2013.6549921
   Lanzisera S, 2011, IEEE SENS J, V11, P837, DOI 10.1109/JSEN.2010.2072496
   Li WWL, 2013, IEEE GLOB COMM CONF, P3335, DOI 10.1109/GLOCOM.2013.6831587
   Liang J., 2013, Comp. for Geosp. Research and Appl
   Loeffler A., 2010, 2010 IEEE International Conference on RFID-Technology and Applications (RFID-TA), P43, DOI 10.1109/RFID-TA.2010.5529857
   McKenna SJ, 1997, INT C AUD AND VID BA
   Ojeda L., 2007, P IEEE INT WORKSH SA, P1, DOI DOI 10.1109/SSRR.2007.4381271
   Quan M, 2010, COMPUT ENG
   Shahidi Shervin., 2015, Indoor Positioning and Indoor Navigation (IPIN), 2015 International Conference on, P1
   Viani F, 2010, INVERSE PROBL, V26, DOI 10.1088/0266-5611/26/7/074003
NR 19
TC 20
Z9 22
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12635
EP 12654
DI 10.1007/s11042-017-4908-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100044
DA 2024-07-18
ER

PT J
AU Wang, G
   Zhang, YF
   Li, B
   Fan, R
   Zhou, ML
AF Wang, Gang
   Zhang, Yongfei
   Li, Bo
   Fan, Rui
   Zhou, Mingliang
TI A fast and HEVC-compatible perceptual video coding scheme using a
   transform-domain Multi-Channel JND model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Just noticeable distortion (JND); Perceptual video coding (PVC); High
   efficiency video coding (HEVC)
ID PARALLEL FRAMEWORK; IMAGE; PROFILE; TOOLS
AB Coding optimization methods incorporating the just noticeable distortion (JND) model, called perceptual video coding (PVC), have drawn much attention in recent years for better video coding performance. To further remove perceptual redundancy in every channel and improve the coding performance, this paper proposes a fast PVC scheme in the latest High Efficiency Video Coding (HEVC) framework based on our proposed variable block-size transform-domain multi-channel JND model. Firstly, through extensive experiments, we find out for the first time that the contrast masking (CM) effects for chroma channels show a lowpass property in frequency, which differs from the luma channel that has a bypass property. Based on this observation, CM effects in chroma blue (Cb) and chroma red (Cr) channels are modeled as a continuous function for variable-sized blocks, respectively. Secondly, since different characteristics of the human visual system (HVS) exhibit quite distinct effects in luma and chroma channels and effects in chroma channels were not well explored, we develop a new JND model through comprehensive consideration for both luma and chroma channels of five typical HVS effects, with especial focus on parameterized modeling of chroma channels in each effect. Finally, to incorporate the proposed JND model into the latest HEVC coding framework, a multi-channel coefficients suppression method based on JND thresholds and quantization parameter (QP) ranges is proposed in the transform and quantization process, which can decrease the computational complexity. Extensive experimental results show that the proposed PVC scheme implemented in HEVC reference software (HM15.0) can yields significant bit saving of up to 25.91% and on average 9.42% with similar subjective quality, compared to HM15.0, and consistently outperforms two PVC schemes with much reduced bitrate and complexity overhead.
C1 [Wang, Gang; Zhang, Yongfei; Li, Bo; Fan, Rui; Zhou, Mingliang] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Zhang, Yongfei; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, YF (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing, Peoples R China.; Zhang, YF (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM yfzhang@buaa.edu.cn
RI Li, bo/IWL-9318-2023; Zhang, Yongfei/A-1505-2010; Zhou,
   Mingliang/HPC-0298-2023; Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888; Zhang, Yongfei/0000-0002-5080-1733
FU National Key Research and Development Plan [2016YFC0801001]; NSFC Key
   Project [61632001]
FX This work is partially supported by the National Key Research and
   Development Plan (Grant No. 2016YFC0801001) and the NSFC Key Project
   (No. 61632001).
CR [Anonymous], 2012, document JCTVC-H1100 of JCT-VC
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P3343, DOI 10.1109/TIP.2016.2568459
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P3227, DOI 10.1109/TIP.2014.2327808
   Chang HW, 2015, NEUROCOMPUTING, V151, P1142, DOI 10.1016/j.neucom.2014.04.081
   Chen H, 2010, IEEE INT CON MULTI, P713, DOI 10.1109/ICME.2010.5583897
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Deng X, 2013, P 2013 6 INT C ADV C, P19
   Flynn D, 2016, IEEE T CIRC SYST VID, V26, P4, DOI 10.1109/TCSVT.2015.2478707
   Guraya FFE, 2015, NEUROCOMPUTING, V149, P1348, DOI 10.1016/j.neucom.2014.08.062
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jarsky T, 2011, J NEUROSCI, V31, P11003, DOI 10.1523/JNEUROSCI.2631-11.2011
   Kim I-K, 2014, JCTVCQ1002 ITUTISOIE
   Kim J, 2015, IEEE T CIRC SYST VID, V25, P1786, DOI 10.1109/TCSVT.2015.2389491
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Lin YC, 2016, MULTIMED TOOLS APPL, V75, P9861, DOI 10.1007/s11042-015-2778-z
   Liu TI, 2008, C IND ELECT APPL, P1, DOI 10.1109/ICIEA.2008.4582469
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   PETERSON HA, 1993, P SOC PHOTO-OPT INS, V1913, P191, DOI 10.1117/12.152693
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tsai DS, 2014, MULTIMED TOOLS APPL, V70, P1825, DOI 10.1007/s11042-012-1206-x
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu H.R., 2005, DIGITAL VIDEO IMAGE
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P4892, DOI 10.1109/TIP.2013.2279934
   Xu M, 2014, IEEE J-STSP, V8, P475, DOI 10.1109/JSTSP.2014.2314864
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zeng HQ, 2016, MULTIMED TOOLS APPL, V75, P10383, DOI 10.1007/s11042-015-2997-3
   Zhong GY, 2015, MULTIMED TOOLS APPL, V74, P11023, DOI 10.1007/s11042-014-2216-7
   Zhong SH, 2016, NEUROCOMPUTING, P1
NR 37
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12777
EP 12803
DI 10.1007/s11042-017-4914-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100050
DA 2024-07-18
ER

PT J
AU Zhang, DY
   Liang, ZS
   Yang, GB
   Li, QG
   Li, LD
   Sun, XM
AF Zhang, Dengyong
   Liang, Zaoshan
   Yang, Gaobo
   Li, Qingguo
   Li, Leida
   Sun, Xingming
TI A robust forgery detection algorithm for object removal by
   exemplar-based image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Passive image forensics; Exemplar-based image inpainting;
   Post-processing; Joint probability density matrix
AB Object removal is a malicious image forgery technique, which is usually achieved by exemplar-based image inpainting in a visually plausible way. Most existing forgery detection approaches utilize similar block pairs between inpainted area and the rest areas, but they invalidate when those inpainted images are further subjected to some post-processing operations such as JPEG compression, Gaussian noise addition and blurring. It is desirable to develop a forensic method which is robust to object removal with post-processing. From some preliminary experiments, we observe that post-processing destroys the similarity of block pairs and simultaneously disturbs the correlations among adjacent pixels to some extent. Inspired by the strong ability of joint probability density matrix (JPDM) in characterizing such correlation, we propose a hybrid forensics strategy. Firstly, our earlier method is employed to detect whether a candidate image is forged or not. Secondly, for those undetected images after the first step, JPDM is computed for each difference array to model the correlations among adjacent DCT coefficients, and the average of these matrixes are computed as feature vectors to further expose tampering traces. Experimental results show that the proposed approach can effectively detect object removal by exemplar-based inpainting either with or without post-processing.
C1 [Zhang, Dengyong; Liang, Zaoshan; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Dengyong] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410005, Hunan, Peoples R China.
   [Li, Qingguo] Hunan Univ, Coll Math & Econ, Changsha 410082, Hunan, Peoples R China.
   [Li, Leida] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 2211166, Jiangsu, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology; Hunan
   University; China University of Mining & Technology; Nanjing University
   of Information Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI Li, Li/AEM-3636-2022; Sun, Xingming/AAD-1866-2019; li, li/HII-4157-2022
FU National Natural Science Foundation of China [61572183, 61379143];
   Specialized Research Fund for the Doctoral Program of Higher Education
   [20120161110014]; Scientific Research Fund of Hunan Provincial Education
   Department of China [14C0029]; Natural Science Foundation of Hunan
   Province [2016JJ2005]
FX We would like to thank the anonymous reviewers for their professional
   comments and valuable suggestions. This work is partially or fully
   sponsored by National Natural Science Foundation of China (61572183,
   61379143), the Specialized Research Fund for the Doctoral Program of
   Higher Education (20120161110014), the Scientific Research Fund of Hunan
   Provincial Education Department of China (14C0029), Natural Science
   Foundation of Hunan Province (2016JJ2005). The authors appreciate the
   nice help from Mr Moses Odero for his improving the English usages.
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Bacchuwar KS, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P723, DOI 10.1109/iMac4s.2013.6526502
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kirchner M, 2010, SPIE ELECT IMAG INT
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liu QZ, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2560365
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Shi YQ, 2008, LECT NOTES COMPUT SC, V5041, P158
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wu Q, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1222, DOI 10.1109/ICMLC.2008.4620591
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhao XD, 2013, IEEE IMAGE PROC, P4462, DOI 10.1109/ICIP.2013.6738919
NR 25
TC 48
Z9 53
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11823
EP 11842
DI 10.1007/s11042-017-4829-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100010
DA 2024-07-18
ER

PT J
AU Abdollahpouri, A
   Qavami, R
   Moradi, P
AF Abdollahpouri, Alireza
   Qavami, Reyhan
   Moradi, Parham
TI On the synthetic dataset generation for IPTV services based on user
   behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Synthetic dataset; User behavior; Recommender systems
AB The adoption of the paradigm shift from push-based media broadcasting to pull-based media streaming has seen a significant growth in the recent decade. IPTV is good example to illustrate this claim. In IPTV systems hundreds (or maybe thousands in near future) of live TV channels and video contents are available to subscribers. In many application domains a clear understanding of access pattern to the items is necessary. However, for security reasons, in IPTV systems this kind of information is not publicly available. In this paper, taking into account a model which mimics the behavior of a typical IPTV user, and with the aid of MovieLens dataset, we produce a trace file or synthetic dataset, named UBSDI. We then show that, this dataset can reflect many properties of real datasets quite realistically. This dataset is publically available and can be used in many applications such as recommender systems, network capacity planning, network dimensioning, and system performance optimization.
C1 [Abdollahpouri, Alireza; Qavami, Reyhan; Moradi, Parham] Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
C3 University of Kurdistan
RP Abdollahpouri, A (corresponding author), Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
EM abdollahpour@uok.ac.ir; Reyhan.ghavamy.191@gmail.com; P.moradi@uok.ac.ir
RI Abdollahpouri, Alireza/AAD-9976-2021; Moradi, Parham/ABH-5151-2020
OI Moradi, Parham/0000-0002-5604-565X; Abdollahpouri,
   Alireza/0000-0003-3281-5944
CR Abdollahpouri A, 2011, ELABORATION FORMAL D
   Amatriain X., 2008, P 8 ACM SIGCOMM C IN
   [Anonymous], 2013, CISC VIS NETW IND FO
   Bambini R, 2011, RECOMMENDER SYSTEMS HANDBOOK, P299, DOI 10.1007/978-0-387-85820-3_9
   Beyragh AA, 2014, MULTIMED TOOLS APPL, V72, P1049, DOI 10.1007/s11042-013-1414-z
   Cha M, 2008, P ACM SIGCOMM
   Cong J, 2006, P 1 INT C PERF EV ME
   Cremonesi P, 2009, P 3 ACM C REC SYST, P4
   Elmisery AM, 2014, MULTIMED TOOLS APPL, P1
   Khosroshahi AA, 2015, MULTIMED TOOLS APPL, P1
   Kim E, 2011, IEEE T BROADCAST, V57, P674, DOI 10.1109/TBC.2011.2161409
   Krstic M, 2012, IEEE T CONSUM ELECTR, V58, P1301, DOI 10.1109/TCE.2012.6414999
   Kwon HJ, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P467, DOI 10.1109/ICCE.2011.5722687
   Park YJ, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P11
   Song SB, 2012, IEEE T MULTIMEDIA, V14, P1528, DOI 10.1109/TMM.2012.2217118
   Sripanidkulchai K, 2004, P 4 ACM SIGCOMM C IN
   VELOSO E, 2002, P 2 ACM SIGCOMM WORK
   Yu G, 2009, 2009 IE INT S BROADB
   Zare S, 2015, MULTIMEDIA TOOLS APP
NR 19
TC 3
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8475
EP 8493
DI 10.1007/s11042-017-4746-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800031
DA 2024-07-18
ER

PT J
AU Bakthula, R
   Shivani, S
   Agarwal, S
AF Bakthula, Rajitha
   Shivani, Shivendra
   Agarwal, Suneeta
TI Self authenticating medical X-ray images for telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Tamper localization; X-ray images; E-health; Medical image
   security; Telehelth
ID ELECTRONIC PATIENT RECORD; TAMPER DETECTION; REVERSIBLE WATERMARKING;
   RECOVERY; RELIABILITY; INTEGRITY; SECURITY; SCHEME; ROBUST; SYSTEM
AB Telemedicine focuses on sharing medical images over network among doctors for better consultation. Hence medical images must be protected from unwanted modifications (intentional/unintentional) over network. Digital watermarking can be used for this purpose. ROI based watermarking hide's ROI (Region of Interest) information in NROI (Non-Interested Regions of Interest) regions in general. Most of the existing watermarking methods used in telemedicine are block based. Main drawback of block based watermarking is exact localization of exact tampered pixels, as even if single pixel of a block is altered the whole block is detected as tampered. Thus this paper proposes a pixel based watermark technique so that alteration can be detected exactly. This method works in three phases: first, separates the ROI and NROI, second some information depending on the relative size of ROI and NROI the ROI is embedded in NROI using LSBs of ROI. Third, a tamper detection algorithm is proposed for detecting the tampered pixels exactly. Performance of proposed method when compared with state-of-art block based approaches is found to be best having 33db of PSNR value and 80% of accuracy on an average.
C1 [Bakthula, Rajitha; Agarwal, Suneeta] Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
   [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Thapar Institute of Engineering & Technology
RP Bakthula, R (corresponding author), Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM rajitha@mnnit.ac.in; shivendrashivani@gmail.com; suneeta@mnnit.ac.in
RI B, Rajitha/HHR-8738-2022; Shivani, Shivendra/AFN-2368-2022
OI Shivani, Shivendra/0000-0002-5931-6603
CR Agung B. W. R., 2012, 2012 IEEE International Conference on Communication, Networks and Satellite (ComNetSat 2012), P167, DOI 10.1109/ComNetSat.2012.6380799
   Al-Gindy Ahmed, 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P191, DOI 10.1109/ISSPIT.2010.5711776
   Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   [Anonymous], 2009, P INT C MED SYST ENG
   [Anonymous], MULTIMEDIA TOOLS APP
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Calcote S, 1997, Healthc Financ Manage, V51, P68
   Cao L., 2006, Singular value decomposition applied to digital image processing
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Coatrieux G, 2007, P ANN INT IEEE EMBS, P5654
   Coatrieux G, 2005, P ANN INT IEEE EMBS, P2224, DOI 10.1109/IEMBS.2005.1616905
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Deng XH, 2013, J NANOSCI NANOTECHNO, V13, P2099, DOI 10.1166/jnn.2013.6872
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Fontani M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P161
   Gravel P, 2004, IEEE T MED IMAGING, V23, P1221, DOI 10.1109/TMI.2004.832656
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Kim KS, 2011, COMPUT VIS IMAGE UND, V115, P1308, DOI 10.1016/j.cviu.2011.05.001
   Kobayashi LOM, 2009, J DIGIT IMAGING, V22, P71, DOI 10.1007/s10278-008-9103-6
   Kong X, 2001, IEEE T INF TECHNOL B, V5, P195, DOI 10.1109/4233.945290
   Lehmann Thomas M, 2006, IMPACT LOSSLESS IMAG
   Li-Qun Kuang, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1047, DOI 10.1109/ICISE.2009.60
   Liew S.-C., 2010, COMPUTER SCI INFORM, V5, P417
   Louwerse K, 1998, INT J MED INFORM, V49, P39, DOI 10.1016/S1386-5056(98)00008-2
   Kobayashi LOM, 2009, IEEE T INF TECHNOL B, V13, P582, DOI 10.1109/TITB.2009.2014751
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Münch H, 2004, ACAD RADIOL, V11, P661, DOI 10.1016/j.acra.2004.03.047
   Nambakhsh MS, 2011, COMPUT METH PROG BIO, V104, P418, DOI 10.1016/j.cmpb.2010.08.016
   Pan W, 2010, LECT NOTES COMPUT SC, V5939, P153
   Priyanka Maheshkar S, 2016, MULTIMED TOOLS APPL, P1
   Rajith B., 2016, Emerging Research in Computing, Information, Communication and Applications, P449, DOI 10.1007/978-81-322-2553-9_41
   Ruotsalainen P, 2010, EUR J RADIOL, V73, P31, DOI 10.1016/j.ejrad.2009.10.018
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Singh S, 2016, MICROCHIM ACTA, P1
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Thakkar FN, 2016, MULTIMED TOOLS APPL, P1
   Viswanathan P, 2013, IEEE J BIOMED HLTH I
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Zain J. M., 2006, 28 ANN INT C IEEE EN, P3270
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
NR 43
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8375
EP 8392
DI 10.1007/s11042-017-4738-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800027
DA 2024-07-18
ER

PT J
AU Praveenkumar, P
   Devi, NK
   Ravichandran, D
   Avila, J
   Thenmozhi, K
   Rayappan, JBB
   Amirtharajan, R
AF Praveenkumar, Padmapriya
   Devi, N. Kerthana
   Ravichandran, Dhivya
   Avila, J.
   Thenmozhi, K.
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Transreceiving of encrypted medical image - a cognitive approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA; Chaoticmaps; Cognitive radio; USRP
ID CHAOS; SEGMENTATION
AB Recently, there is an increasing demand for efficient and secure transreception of medical images in telemedicine applications. Though a fixed spectrum is allocated to each user, most of the time it remains unused by the concerned user. Cognitive Radio (CR) is a technology that utilizes the unused spectrum efficiently by adopting spectrum sensing concept. This paper proposes an efficient and secure transmission of medical images by adopting CR technology and image encryption technique. Firstly, the novel medical image encryption algorithm is proposed to encrypt the DICOM (Digital Imaging and Communications in Medicine) image effectively. Then, the spectrum sensing technique is carried out via Universal Software Radio Peripheral (USRP) to sense the unused frequency band to transmit the encrypted bio signal. The proposed encryption algorithm combines DNA (Deoxyribo Nucleic Acid) sequence operation and chaotic maps to successfully encrypt the DICOM image pixels. Experimental results are done and various analysis such as Unified Average Changing Intensity (UACI), Number of Pixel Changing Rate (NPCR), entropy estimation and chi-square tests are carried out to validate the sternness of the encryption algorithm.
C1 [Praveenkumar, Padmapriya; Devi, N. Kerthana; Ravichandran, Dhivya; Avila, J.; Thenmozhi, K.; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI praveenkumar, padmapriya/AAH-9426-2019; RAVICHANDRAN, Dr
   DHIVYA/S-7457-2019; Amirtharajan, Rengarajan/C-6471-2011; Rayappan, John
   Bosco Balaguru/K-6842-2013
OI praveenkumar, padmapriya/0000-0001-8483-1538; RAVICHANDRAN, Dr
   DHIVYA/0000-0002-0312-4880; Amirtharajan,
   Rengarajan/0000-0003-1574-3045; jayapalan, Avila/0000-0002-1370-0423;
   Rayappan, John Bosco Balaguru/0000-0003-4641-9870; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189
FU SASTRA University under RM fund [R&M/0027/SEEE - 010/2012-13]
FX Authors would like to express their sincere thanks to SASTRA University,
   for the financial support under R&M fund (R&M/0027/SEEE - 010/2012-13)
   to carry out this research work. Also, we are grateful to Dr. S. Vanoli,
   Medical Superintendent, Government Hospital, Ariyalur, for his valuable
   suggestions in carrying out this work.
CR Akyildiz IF, 2008, IEEE COMMUN MAG, V46, P40, DOI 10.1109/MCOM.2008.4481339
   Al-Ayyoub M, 2016, J SYST SOFTWARE, V117, P15, DOI 10.1016/j.jss.2016.02.014
   Alsaedi M, 2017, MULTIMED TOOLS APPL, V76, P24527, DOI 10.1007/s11042-016-4206-4
   Althunibat S, 2016, AD HOC NETW, V41, P47, DOI 10.1016/j.adhoc.2015.10.008
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Boriga R, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/409586
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Dridi M., 2014, P GLOB SUMM COMP INF, P1
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Heider D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-176
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Khan MK, 2004, LECT NOTES COMPUT SC, V3338, P629
   Khan MK, 2007, LECT NOTES ARTIF INT, V4682, P1141
   Khan MK, 2011, FUTURE GENER COMP SY, V27, P411, DOI 10.1016/j.future.2010.05.019
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Leier A, 2000, BIOSYSTEMS, V57, P13, DOI 10.1016/S0303-2647(00)00083-6
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lima JC, 2015, INORGANICS, V3, P1, DOI 10.3390/inorganics3010001
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Moumen A, 2015, NONLINEAR DYNAM, V82, P1475, DOI 10.1007/s11071-015-2253-4
   Nazeer M, 2013, INT J ADV COMPUT SC, V4, P131
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Praveenkumar P, 2015, COMPUT BIOL MED, V62, P264, DOI 10.1016/j.compbiomed.2015.04.031
   Troncoso-Pastoriza JR, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P519
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Tragos EZ, 2013, IEEE COMMUN SURV TUT, V15, P1108, DOI 10.1109/SURV.2012.121112.00047
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 40
TC 19
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8393
EP 8418
DI 10.1007/s11042-017-4741-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800028
DA 2024-07-18
ER

PT J
AU Huang, W
   Wan, CY
   Zeng, J
   Ding, HJ
   Zhang, P
   Chen, G
AF Huang, Wei
   Wan, Chuyu
   Zeng, Jing
   Ding, Huijun
   Zhang, Peng
   Chen, Guang
TI Pixel-wise partial volume effects correction on arterial spin labeling
   magnetic resonance images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial volume effects; Magnetic resonance images; LASSO; Proximal
   gradient descent
ID ALZHEIMERS-DISEASE; EMISSION-TOMOGRAPHY; CLASSIFICATION; SELECTION;
   DEMENTIA; PATTERNS; BRAIN; MRI; PET
AB Arterial spin labeling is a recently emerging imaging modality in functional magnetic resonance, and it is widely acknowledged to be effective in directly measuring the cerebral blood flow of patients while being scanned, which makes it a promising indicator in contemporary dementia disease diagnosis studies. However, partial volume effects mainly caused by signal cross-contamination due to pixel heterogeneity and limited spatial resolution of the arterial spin labeling scanning protocol often prevent the cerebral blood flow from being accurately measured. In order to correct the partial volume effects, contemporary studies usually rely on neighboring pixles to solve indefinite equations of partial volume correction, which makes shortcomings of blurring and brain tissue details loss inevitable in their correction outcomes. In this study, a novel pixel-wise correction method is proposed to tackle partial volume effects in arterial spin labeling images. The main idea is to formalize the correction problem as a series of quadratic programming sub-problems using split-Bregman iterations, then formulate each sub-problem via the regularization of least absolute shrinkage and selection operator, and finally solve the regularization sub-problem via the fast proximal gradient descent approach. A real-patients database composed of 360 demented patients is incorporated for experimental evaluation of the pixel-wise method. Extensive experiments and comprehensive statistical analysis are carried out to demonstrate the superiority of the pixel-wise method with comparisons towards the popular region-based method. Promising results are reported from the statistical point of view.
C1 [Huang, Wei; Wan, Chuyu; Zeng, Jing] Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Ding, Huijun] Shenzhen Univ, Sch Biomed Engn, Shenzhen, Peoples R China.
   [Zhang, Peng] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Chen, Guang] Xian Commun Inst, Xian, Shaanxi, Peoples R China.
C3 Nanchang University; Shenzhen University; Northwestern Polytechnical
   University
RP Ding, HJ (corresponding author), Shenzhen Univ, Sch Biomed Engn, Shenzhen, Peoples R China.
EM huangwei@pmail.ntu.edu.sg; hjding@szu.edu.cn
RI zhang, yueqi/JXM-4287-2024; Zhang, Penghui/HGB-7353-2022; zeng,
   jing/JDW-4350-2023
OI Zhang, Penghui/0000-0002-9518-7079; 
FU National Natural Science Foundation of China [61403182, 61363046,
   61571362]; Scientific Research Foundation for Returned Overseas Chinese
   Scholars, Ministry of Education, China [[2014]1685]; Provincial Young
   Scientist Program by Jiangxi Provincial Department of Science and
   Technology, China [20153BCB23029]; Jiangxi Provincial Department of
   Education [JXJG-15-1-26]
FX The authors would like to acknowledge Grants 61403182, 61363046 and
   61571362 approved by the National Natural Science Foundation of China,
   the Grant [2014]1685 approved by the Scientific Research Foundation for
   Returned Overseas Chinese Scholars, Ministry of Education, China, the
   2015 Provincial Young Scientist Program 20153BCB23029 approved by the
   Jiangxi Provincial Department of Science and Technology, China, as well
   as the Grant JXJG-15-1-26 approved by the Jiangxi Provincial Department
   of Education for supporting this study.
CR Asllani I, 2008, MAGN RESON MED, V60, P1362, DOI 10.1002/mrm.21670
   Boyd S., 2004, CONVEX OPTIMIZATION
   BRANTZAWADZKI M, 1992, RADIOLOGY, V182, P769, DOI 10.1148/radiology.182.3.1535892
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Bruening D., 2015, INT C IEEE ENG MED B
   Chappell MA, 2011, MAGN RESON MED, V65, P1173, DOI 10.1002/mrm.22641
   Chen Y, 2011, NEUROLOGY, V77, P1977, DOI 10.1212/WNL.0b013e31823a0ef7
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   Erlandsson K, 2012, PHYS MED BIOL, V57, pR119, DOI 10.1088/0031-9155/57/21/R119
   Galton CJ, 2001, NEUROLOGY, V57, P216, DOI 10.1212/WNL.57.2.216
   Gold G, 2005, STROKE, V36, P1184, DOI 10.1161/01.STR.0000166052.89772.b5
   Goldstein T., 2008, 0829 UCLA CAM, P1
   Howard AL., 1977, Bull. Amer. Math. Soc. (N.S.), V1, P521
   Iaccarino HF, 2016, NATURE, V540, P230, DOI 10.1038/nature20587
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055
   Abad VM, 2016, MAGN RESON IMAGING, V34, P334, DOI 10.1016/j.mri.2015.11.002
   MELTZER CC, 1990, J COMPUT ASSIST TOMO, V14, P561, DOI 10.1097/00004728-199007000-00011
   Musiek ES, 2012, ALZHEIMERS DEMENT, V8, P51, DOI 10.1016/j.jalz.2011.06.003
   Oliver R, 2015, THESIS
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   un, World population prospects
   Wee CY, 2013, HUM BRAIN MAPP, V34, P3411, DOI 10.1002/hbm.22156
   Zhou LP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021935
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 25
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6913
EP 6932
DI 10.1007/s11042-017-4609-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700022
DA 2024-07-18
ER

PT J
AU Kang, D
   Shim, H
   Yoon, K
AF Kang, Dongwann
   Shim, Hyounoh
   Yoon, Kyunghyun
TI A method for extracting emotion using colors comprise the painting image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image scale; Emotion of painting; Color combinations; Image
   exploration
ID PREFERENCE; MEANINGS
AB Paintings can evoke emotions in viewers. In this paper, we propose a method for extracting emotions from paintings by using the colors that comprise the paintings. The proposed approach is based on a color image scale, which is one of the popular experimental scales focusing on the relation between colors and emotions. We first construct a color combination and emotional word dataset. To this end, we create a color spectrum from the input painting. We then search for the best matching color combination from the dataset, which is most similar to the color spectrum. The best matching color combination is mapped to the corresponding emotional word. Afterward, we extract the emotional word as the emotion evoked by the painting. To evaluate the proposed method, we compared the results of the proposed algorithm to those of a user study on the extraction of emotions from several paintings. Through several experiments, we show that the proposed method exhibits excellent performance with respect to predicting the emotions evoked by a painting. Finally, we propose an image exploration system based on the emotion extraction method mentioned above. In this system, users can explore painting images emotionally coherently.
C1 [Kang, Dongwann] Bournemouth Univ, Fac Sci & Technol SciTech, Bournemouth, Dorset, England.
   [Shim, Hyounoh] Affect Comp Real Life Acryl, Seoul, South Korea.
   [Yoon, Kyunghyun] Chung Ang Univ, Comp Sci & Engn, Seoul, South Korea.
C3 Bournemouth University; Chung Ang University
RP Yoon, K (corresponding author), Chung Ang Univ, Comp Sci & Engn, Seoul, South Korea.
EM khyoon@cau.ac.kr
RI Li, Mengqi/AAG-6804-2021
FU Chung-Ang University Research Scholarship Grants; Ministry of Culture,
   Sports and Tourism (MCST); Korea Creative Content Agency (KOCCA) in the
   Culture Technology (CT) Research AMP; Development Program
FX This research was supported by the Chung-Ang University Research
   Scholarship Grants in 2014 and Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2014.
CR ADAMS FM, 1973, J CROSS CULT PSYCHOL, V4, P135, DOI 10.1177/002202217300400201
   Ahmad J, 2017, J REAL-TIME IMAGE PR, V13, P431, DOI 10.1007/s11554-015-0536-0
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   [Anonymous], SIGGRAPH ASIA 2016 T
   [Anonymous], P COMP GRAPH INT 201
   [Anonymous], COL SCHEM CONV MIND
   [Anonymous], P 18 ACM CONF MULT
   [Anonymous], P C ASS INT DE LA CO
   [Anonymous], P INT MULT ENG COMP
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Icoglu Oguz, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P749
   Ipeirotis Panagiotis G., 2010, XRDS: Crossroads, V17, P16, DOI [10.1145/1869086.1869094, DOI 10.1145/1869086.1869094]
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   KOBAYASHI S, 1981, COLOR RES APPL, V6, P93, DOI 10.1002/col.5080060210
   Kobayashi S, 1991, COLOR IMAGE SCALE KO
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   Lee MH, 2014, MULTIMED TOOLS APPL, V73, P901, DOI 10.1007/s11042-013-1383-2
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Ou LC, 2004, COLOR RES APPL, V29, P292, DOI 10.1002/col.20024
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Rho S, 2013, J SUPERCOMPUT, V65, P274, DOI 10.1007/s11227-010-0447-6
   Seo S, 2016, J SUPERCOMPUT, V72, P3478, DOI 10.1007/s11227-015-1510-0
   Tak YS, 2012, MULTIMED TOOLS APPL, V61, P51, DOI 10.1007/s11042-010-0687-8
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   WRIGHT B, 1962, J GEN PSYCHOL, V67, P89, DOI 10.1080/00221309.1962.9711531
   Yanulevskaya V, 2012, P 20 ACM INT C MULT, P349, DOI [10.1145/2393347.2393399, DOI 10.1145/2393347.2393399]
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zujovic J., 2009, IEEE INT WORKSHOP MU, P1
NR 31
TC 15
Z9 22
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4985
EP 5002
DI 10.1007/s11042-017-4667-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500050
DA 2024-07-18
ER

EF